[{"id": "1902.00006", "submitter": "Isaac Lage", "authors": "Isaac Lage, Emily Chen, Jeffrey He, Menaka Narayanan, Been Kim, Sam\n  Gershman, Finale Doshi-Velez", "title": "An Evaluation of the Human-Interpretability of Explanation", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.00682", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a boom in interest in machine learning systems that\ncan provide a human-understandable rationale for their predictions or\ndecisions. However, exactly what kinds of explanation are truly\nhuman-interpretable remains poorly understood. This work advances our\nunderstanding of what makes explanations interpretable under three specific\ntasks that users may perform with machine learning systems: simulation of the\nresponse, verification of a suggested response, and determining whether the\ncorrectness of a suggested response changes under a change to the inputs.\nThrough carefully controlled human-subject experiments, we identify\nregularizers that can be used to optimize for the interpretability of machine\nlearning systems. Our results show that the type of complexity matters:\ncognitive chunks (newly defined concepts) affect performance more than variable\nrepetitions, and these trends are consistent across tasks and domains. This\nsuggests that there may exist some common design principles for explanation\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 02:08:22 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 22:29:45 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Lage", "Isaac", ""], ["Chen", "Emily", ""], ["He", "Jeffrey", ""], ["Narayanan", "Menaka", ""], ["Kim", "Been", ""], ["Gershman", "Sam", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1902.00016", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razdehi, Slava Voloshynovskiy", "title": "Network Parameter Learning Using Nonlinear Transforms, Local\n  Representation Goals and Local Propagation Constraints", "comments": "arXiv admin note: text overlap with arXiv:1805.07802", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel concept for learning of the parameters in\na neural network. Our idea is grounded on modeling a learning problem that\naddresses a trade-off between (i) satisfying local objectives at each node and\n(ii) achieving desired data propagation through the network under (iii) local\npropagation constraints. We consider two types of nonlinear transforms which\ndescribe the network representations. One of the nonlinear transforms serves as\nactivation function. The other one enables a locally adjusted, deviation\ncorrective components to be included in the update of the network weights in\norder to enable attaining target specific representations at the last network\nnode. Our learning principle not only provides insight into the understanding\nand the interpretation of the learning dynamics, but it offers theoretical\nguarantees over decoupled and parallel parameter estimation strategy that\nenables learning in synchronous and asynchronous mode. Numerical experiments\nvalidate the potential of our approach on image recognition task. The\npreliminary results show advantages in comparison to the state-of-the-art\nmethods, w.r.t. the learning time and the network size while having competitive\nrecognition accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:43:55 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razdehi", "Behrooz", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1902.00033", "submitter": "Scott Gigante", "authors": "Scott Gigante, Jay S. Stanley III, Ngan Vu, David van Dijk, Kevin\n  Moon, Guy Wolf, Smita Krishnaswamy", "title": "Compressed Diffusion", "comments": "4 pages double column, published in SampTA 2019", "journal-ref": "Sampling Theory & Applications (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion maps are a commonly used kernel-based method for manifold learning,\nwhich can reveal intrinsic structures in data and embed them in low dimensions.\nHowever, as with most kernel methods, its implementation requires a heavy\ncomputational load, reaching up to cubic complexity in the number of data\npoints. This limits its usability in modern data analysis. Here, we present a\nnew approach to computing the diffusion geometry, and related embeddings, from\na compressed diffusion process between data regions rather than data points.\nOur construction is based on an adaptation of the previously proposed\nmeasure-based Gaussian correlation (MGC) kernel that robustly captures the\nlocal geometry around data points. We use this MGC kernel to efficiently\ncompress diffusion relations from pointwise to data region resolution. Finally,\na spectral embedding of the data regions provides coordinates that are used to\ninterpolate and approximate the pointwise diffusion map embedding of data. We\nanalyze theoretical connections between our construction and the original\ndiffusion geometry of diffusion maps, and demonstrate the utility of our method\nin analyzing big datasets, where it outperforms competing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:00:52 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 22:58:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gigante", "Scott", ""], ["Stanley", "Jay S.", "III"], ["Vu", "Ngan", ""], ["van Dijk", "David", ""], ["Moon", "Kevin", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1902.00040", "submitter": "David Melhart", "authors": "David Melhart, Ahmad Azadvar, Alessandro Canossa, Antonios Liapis,\n  Georgios N. Yannakakis", "title": "Your Gameplay Says It All: Modelling Motivation in Tom Clancy's The\n  Division", "comments": "Version accepted for IEEE Conference on Games, 2019", "journal-ref": "Proceedings of the 2019 International IEEE Conference on Games\n  (CoG 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to predict the motivation of players just by observing their\ngameplay data? Even if so, how should we measure motivation in the first place?\nTo address the above questions, on the one end, we collect a large dataset of\ngameplay data from players of the popular game Tom Clancy's The Division. On\nthe other end, we ask them to report their levels of competence, autonomy,\nrelatedness and presence using the Ubisoft Perceived Experience Questionnaire.\nAfter processing the survey responses in an ordinal fashion we employ\npreference learning methods based on support vector machines to infer the\nmapping between gameplay and the reported four motivation factors. Our key\nfindings suggest that gameplay features are strong predictors of player\nmotivation as the best obtained models reach accuracies of near certainty, from\n92% up to 94% on unseen players.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:15:04 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 09:04:06 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Melhart", "David", ""], ["Azadvar", "Ahmad", ""], ["Canossa", "Alessandro", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "1902.00045", "submitter": "Andrija Petrovic", "authors": "Andrija Petrovi\\'c and Mladen Nikoli\\'c and Milo\\v{s} Jovanovi\\'c and\n  Boris Deliba\\v{s}i\\'c", "title": "Gaussian Conditional Random Fields for Classification", "comments": "Draft paper without experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian conditional random fields (GCRF) are a well-known used structured\nmodel for continuous outputs that uses multiple unstructured predictors to form\nits features and at the same time exploits dependence structure among outputs,\nwhich is provided by a similarity measure. In this paper, a Gaussian\nconditional random fields model for structured binary classification (GCRFBC)\nis proposed. The model is applicable to classification problems with undirected\ngraphs, intractable for standard classification CRFs. The model representation\nof GCRFBC is extended by latent variables which yield some appealing\nproperties. Thanks to the GCRF latent structure, the model becomes tractable,\nefficient and open to improvements previously applied to GCRF regression\nmodels. In addition, the model allows for reduction of noise, that might appear\nif structures were defined directly between discrete outputs. Additionally, two\ndifferent forms of the algorithm are presented: GCRFBCb (GCRGBC - Bayesian) and\nGCRFBCnb (GCRFBC - non Bayesian). The extended method of local variational\napproximation of sigmoid function is used for solving empirical Bayes in\nBayesian GCRFBCb variant, whereas MAP value of latent variables is the basis\nfor learning and inference in the GCRFBCnb variant. The inference in GCRFBCb is\nsolved by Newton-Cotes formulas for one-dimensional integration. Both models\nare evaluated on synthetic data and real-world data. It was shown that both\nmodels achieve better prediction performance than unstructured predictors.\nFurthermore, computational and memory complexity is evaluated. Advantages and\ndisadvantages of the proposed GCRFBCb and GCRFBCnb are discussed in detail.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:33:13 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Petrovi\u0107", "Andrija", ""], ["Nikoli\u0107", "Mladen", ""], ["Jovanovi\u0107", "Milo\u0161", ""], ["Deliba\u0161i\u0107", "Boris", ""]]}, {"id": "1902.00057", "submitter": "Yuesong Shen", "authors": "Yuesong Shen, Tao Wu, Csaba Domokos, Daniel Cremers", "title": "Probabilistic Discriminative Learning with Layered Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are traditionally known for their successes in\ngenerative modeling. In this work, we advocate layered graphical models (LGMs)\nfor probabilistic discriminative learning. To this end, we design LGMs in close\nanalogy to neural networks (NNs), that is, they have deep hierarchical\nstructures and convolutional or local connections between layers. Equipped with\ntensorized truncated variational inference, our LGMs can be efficiently trained\nvia backpropagation on mainstream deep learning frameworks such as PyTorch. To\ndeal with continuous valued inputs, we use a simple yet effective soft-clamping\nstrategy for efficient inference. Through extensive experiments on image\nclassification over MNIST and FashionMNIST datasets, we demonstrate that LGMs\nare capable of achieving competitive results comparable to NNs of similar\narchitectures, while preserving transparent probabilistic modeling.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 20:14:03 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Shen", "Yuesong", ""], ["Wu", "Tao", ""], ["Domokos", "Csaba", ""], ["Cremers", "Daniel", ""]]}, {"id": "1902.00067", "submitter": "Yue Cao", "authors": "Yue Cao and Yang Shen", "title": "Bayesian active learning for optimization and uncertainty quantification\n  in protein docking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivation: Ab initio protein docking represents a major challenge for\noptimizing a noisy and costly \"black box\"-like function in a high-dimensional\nspace. Despite progress in this field, there is no docking method available for\nrigorous uncertainty quantification (UQ) of its solution quality (e.g.\ninterface RMSD or iRMSD).\n  Results: We introduce a novel algorithm, Bayesian Active Learning (BAL), for\noptimization and UQ of such black-box functions and flexible protein docking.\nBAL directly models the posterior distribution of the global optimum (or native\nstructures for protein docking) with active sampling and posterior estimation\niteratively feeding each other. Furthermore, we use complex normal modes to\nrepresent a homogeneous Euclidean conformation space suitable for\nhigh-dimension optimization and construct funnel-like energy models for\nencounter complexes. Over a protein docking benchmark set and a CAPRI set\nincluding homology docking, we establish that BAL significantly improve against\nboth starting points by rigid docking and refinements by particle swarm\noptimization, providing for one third targets a top-3 near-native prediction.\nBAL also generates tight confidence intervals with half range around 25% of\niRMSD and confidence level at 85%. Its estimated probability of a prediction\nbeing native or not achieves binary classification AUROC at 0.93 and AUPRC over\n0.60 (compared to 0.14 by chance); and also found to help ranking predictions.\nTo the best of our knowledge, this study represents the first uncertainty\nquantification solution for protein docking, with theoretical rigor and\ncomprehensive assessment.\n  Source codes are available at https://github.com/Shen-Lab/BAL.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 20:52:06 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Cao", "Yue", ""], ["Shen", "Yang", ""]]}, {"id": "1902.00071", "submitter": "Nidham Gazagnadou", "authors": "Nidham Gazagnadou and Robert M. Gower and Joseph Salmon", "title": "Optimal mini-batch and step sizes for SAGA", "comments": "34 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it has been shown that the step sizes of a family of variance\nreduced gradient methods called the JacSketch methods depend on the expected\nsmoothness constant. In particular, if this expected smoothness constant could\nbe calculated a priori, then one could safely set much larger step sizes which\nwould result in a much faster convergence rate. We fill in this gap, and\nprovide simple closed form expressions for the expected smoothness constant and\ncareful numerical experiments verifying these bounds. Using these bounds, and\nsince the SAGA algorithm is part of this JacSketch family, we suggest a new\nstandard practice for setting the step sizes and mini-batch size for SAGA that\nare competitive with a numerical grid search. Furthermore, we can now show that\nthe total complexity of the SAGA algorithm decreases linearly in the mini-batch\nsize up to a pre-defined value: the optimal mini-batch size. This is a rare\nresult in the stochastic variance reduced literature, only previously shown for\nthe Katyusha algorithm. Finally we conjecture that this is the case for many\nother stochastic variance reduced methods and that our bounds and analysis of\nthe expected smoothness constant is key to extending these results.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 21:14:19 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 11:14:28 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 09:38:32 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gazagnadou", "Nidham", ""], ["Gower", "Robert M.", ""], ["Salmon", "Joseph", ""]]}, {"id": "1902.00080", "submitter": "Geoffrey Wolfer", "authors": "Geoffrey Wolfer and Aryeh Kontorovich", "title": "Minimax Testing of Identity to a Reference Ergodic Markov Chain", "comments": "A previous version of this print contained a mistake in a proof. We\n  have now fixed it", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit an efficient procedure for testing, based on a single long state\nsequence, whether an unknown Markov chain is identical to or $\\varepsilon$-far\nfrom a given reference chain. We obtain nearly matching (up to logarithmic\nfactors) upper and lower sample complexity bounds for our notion of distance,\nwhich is based on total variation. Perhaps surprisingly, we discover that the\nsample complexity depends solely on the properties of the known reference chain\nand does not involve the unknown chain at all, which is not even assumed to be\nergodic.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 21:24:54 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 11:21:16 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 18:52:29 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wolfer", "Geoffrey", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1902.00087", "submitter": "Christopher Tran", "authors": "Christopher Tran and Elena Zheleva", "title": "Learning Triggers for Heterogeneous Treatment Effects", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33015183", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal effect of a treatment can vary from person to person based on\ntheir individual characteristics and predispositions. Mining for patterns of\nindividual-level effect differences, a problem known as heterogeneous treatment\neffect estimation, has many important applications, from precision medicine to\nrecommender systems. In this paper we define and study a variant of this\nproblem in which an individual-level threshold in treatment needs to be\nreached, in order to trigger an effect. One of the main contributions of our\nwork is that we do not only estimate heterogeneous treatment effects with fixed\ntreatments but can also prescribe individualized treatments. We propose a\ntree-based learning method to find the heterogeneity in the treatment effects.\nOur experimental results on multiple datasets show that our approach can learn\nthe triggers better than existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:01:50 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 19:52:12 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 15:30:42 GMT"}, {"version": "v4", "created": "Fri, 10 May 2019 12:27:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tran", "Christopher", ""], ["Zheleva", "Elena", ""]]}, {"id": "1902.00089", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Yinhai Wang, Ziyuan Pu, Jingyun Hu, Xuesong Wang, Ruimin\n  Ke", "title": "Safe, Efficient, and Comfortable Velocity Control based on Reinforcement\n  Learning for Autonomous Driving", "comments": "Under the first-round revision for transportation research part c", "journal-ref": "Transportation Research Part C: Emerging Technologies 2020", "doi": "10.1016/j.trc.2020.102662", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model used for velocity control during car following was proposed based on\ndeep reinforcement learning (RL). To fulfil the multi-objectives of car\nfollowing, a reward function reflecting driving safety, efficiency, and comfort\nwas constructed. With the reward function, the RL agent learns to control\nvehicle speed in a fashion that maximizes cumulative rewards, through trials\nand errors in the simulation environment. A total of 1,341 car-following events\nextracted from the Next Generation Simulation (NGSIM) dataset were used to\ntrain the model. Car-following behavior produced by the model were compared\nwith that observed in the empirical NGSIM data, to demonstrate the model's\nability to follow a lead vehicle safely, efficiently, and comfortably. Results\nshow that the model demonstrates the capability of safe, efficient, and\ncomfortable velocity control in that it 1) has small percentages (8\\%) of\ndangerous minimum time to collision values (\\textless\\ 5s) than human drivers\nin the NGSIM data (35\\%); 2) can maintain efficient and safe headways in the\nrange of 1s to 2s; and 3) can follow the lead vehicle comfortably with smooth\nacceleration. The results indicate that reinforcement learning methods could\ncontribute to the development of autonomous driving systems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:04:40 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 03:57:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhu", "Meixin", ""], ["Wang", "Yinhai", ""], ["Pu", "Ziyuan", ""], ["Hu", "Jingyun", ""], ["Wang", "Xuesong", ""], ["Ke", "Ruimin", ""]]}, {"id": "1902.00091", "submitter": "Cristina White", "authors": "Cristina White, Daniela Ushizima, Charbel Farhat", "title": "Fast Neural Network Predictions from Constrained Aerodynamics Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating computational fluid dynamics in the design process of jets,\nspacecraft, or gas turbine engines is often challenged by the required\ncomputational resources and simulation time, which depend on the chosen\nphysics-based computational models and grid resolutions. An ongoing problem in\nthe field is how to simulate these systems faster but with sufficient accuracy.\nWhile many approaches involve simplified models of the underlying physics,\nothers are model-free and make predictions based only on existing simulation\ndata. We present a novel model-free approach in which we reformulate the\nsimulation problem to effectively increase the size of constrained pre-computed\ndatasets and introduce a novel neural network architecture (called a cluster\nnetwork) with an inductive bias well-suited to highly nonlinear computational\nfluid dynamics solutions. Compared to the state-of-the-art in model-based\napproximations, we show that our approach is nearly as accurate, an order of\nmagnitude faster, and easier to apply. Furthermore, we show that our method\noutperforms other model-free approaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 03:58:17 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 20:28:21 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 18:05:19 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 03:43:09 GMT"}, {"version": "v5", "created": "Fri, 6 Dec 2019 03:09:06 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["White", "Cristina", ""], ["Ushizima", "Daniela", ""], ["Farhat", "Charbel", ""]]}, {"id": "1902.00097", "submitter": "Emanuele Fabbiani", "authors": "Emanuele Fabbiani, Andrea Marziali and Giuseppe De Nicolao", "title": "Ensembling methods for countrywide short term forecasting of gas demand", "comments": null, "journal-ref": "Int. J. Oil, Gas and Coal Technology, Vol. 26, No. 2, pp.184-201\n  (2021)", "doi": "10.1504/IJOGCT.2021.10035077", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gas demand is made of three components: Residential, Industrial, and\nThermoelectric Gas Demand. Herein, the one-day-ahead prediction of each\ncomponent is studied, using Italian data as a case study. Statistical\nproperties and relationships with temperature are discussed, as a preliminary\nstep for an effective feature selection. Nine \"base forecasters\" are\nimplemented and compared: Ridge Regression, Gaussian Processes, Nearest\nNeighbours, Artificial Neural Networks, Torus Model, LASSO, Elastic Net, Random\nForest, and Support Vector Regression (SVR). Based on them, four ensemble\npredictors are crafted: simple average, weighted average, subset average, and\nSVR aggregation. We found that ensemble predictors perform consistently better\nthan base ones. Moreover, our models outperformed Transmission System Operator\n(TSO) predictions in a two-year out-of-sample validation. Such results suggest\nthat combining predictors may lead to significant performance improvements in\ngas demand forecasting.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:11:38 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 15:45:24 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 15:42:07 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2021 17:32:56 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fabbiani", "Emanuele", ""], ["Marziali", "Andrea", ""], ["De Nicolao", "Giuseppe", ""]]}, {"id": "1902.00101", "submitter": "Iago Carvalho M.Sc.", "authors": "Iago A Carvalho", "title": "On the statistical evaluation of algorithmic's computational\n  experimentation with infeasible solutions", "comments": "4 pages, 1 figure, 1 table, 17 references", "journal-ref": "CARVALHO, Iago A. On the statistical evaluation of algorithmic's\n  computational experimentation with infeasible solutions. Information\n  Processing Letters, 2019, vol. 143, p. 24-27", "doi": "10.1016/j.ipl.2018.11.003", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The experimental evaluation of algorithms results in a large set of data\nwhich generally do not follow a normal distribution or are not heteroscedastic.\nBesides, some of its entries may be missing, due to the inability of an\nalgorithm to find a feasible solution until a time limit is met. Those\ncharacteristics restrict the statistical evaluation of computational\nexperiments. This work proposes a bi-objective lexicographical ranking scheme\nto evaluate datasets with such characteristics. The output ranking can be used\nas input to any desired statistical test. We used the proposed ranking scheme\nto assess the results obtained by the Iterative Rounding heuristic (IR). A\nFriedman's test and a subsequent post-hoc test carried out on the ranked data\ndemonstrated that IR performed significantly better than the Feasibility Pump\nheuristic when solving 152 benchmark problems of Nonconvex Mixed-Integer\nNonlinear Problems. However, is also showed that the RECIPE heuristic was\nsignificantly better than IR when solving the same benchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:17:36 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Carvalho", "Iago A", ""]]}, {"id": "1902.00127", "submitter": "Shehroz Khan", "authors": "Amir Ahmad, Shehroz S. Khan", "title": "initKmix -- A Novel Initial Partition Generation Algorithm for\n  Clustering Mixed Data using k-means-based Clustering", "comments": "41 page, 3 Figures, 19 Tables, 5 Algorithms", "journal-ref": null, "doi": "10.13140/RG.2.2.21979.62244", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed datasets consist of both numeric and categorical attributes. Various\nk-means-based clustering algorithms have been developed for these datasets.\nGenerally, these algorithms use random partition as a starting point, which\ntends to produce different clustering results for different runs. In this\npaper, we propose, initKmix, a novel algorithm for finding an initial partition\nfor k-means-based clustering algorithms for mixed datasets. In the initKmix\nalgorithm, a k-means-based clustering algorithm is run many times, and in each\nrun, one of the attributes is used to create initial clusters for that run. The\nclustering results of various runs are combined to produce the initial\npartition. This initial partition is then used as a seed to a k-means-based\nclustering algorithm to cluster mixed data. Experiments with various\ncategorical and mixed datasets showed that initKmix produced accurate and\nconsistent results, and outperformed the random initial partition method and\nother state-of-the-art initialization methods. Experiments also showed that\nk-means-based clustering for mixed datasets with initKmix performed similar to\nor better than many state-of-the-art clustering algorithms for categorical and\nmixed datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:32:31 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 09:34:25 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 21:13:30 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Ahmad", "Amir", ""], ["Khan", "Shehroz S.", ""]]}, {"id": "1902.00137", "submitter": "Kyungjae Lee", "authors": "Kyungjae Lee and Sungyub Kim and Sungbin Lim and Sungjoon Choi and\n  Songhwai Oh", "title": "Tsallis Reinforcement Learning: A Unified Framework for Maximum Entropy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new class of Markov decision processes (MDPs),\ncalled Tsallis MDPs, with Tsallis entropy maximization, which generalizes\nexisting maximum entropy reinforcement learning (RL). A Tsallis MDP provides a\nunified framework for the original RL problem and RL with various types of\nentropy, including the well-known standard Shannon-Gibbs (SG) entropy, using an\nadditional real-valued parameter, called an entropic index. By controlling the\nentropic index, we can generate various types of entropy, including the SG\nentropy, and a different entropy results in a different class of the optimal\npolicy in Tsallis MDPs. We also provide a full mathematical analysis of Tsallis\nMDPs, including the optimality condition, performance error bounds, and\nconvergence. Our theoretical result enables us to use any positive entropic\nindex in RL. To handle complex and large-scale problems, we propose a\nmodel-free actor-critic RL method using Tsallis entropy maximization. We\nevaluate the regularization effect of the Tsallis entropy with various values\nof entropic indices and show that the entropic index controls the exploration\ntendency of the proposed method. For a different type of RL problems, we find\nthat a different value of the entropic index is desirable. The proposed method\nis evaluated using the MuJoCo simulator and achieves the state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:59:34 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 00:27:53 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Lee", "Kyungjae", ""], ["Kim", "Sungyub", ""], ["Lim", "Sungbin", ""], ["Choi", "Sungjoon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1902.00139", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli, Florent Krzakala, Pierfrancesco Urbani, and\n  Lenka Zdeborov\\'a", "title": "Passed & Spurious: Descent Algorithms and Local Minima in Spiked\n  Matrix-Tensor Models", "comments": "12 pages + appendix, 10 figures. Appears in Proceedings of the\n  International Conference on Machine Learning (ICML 2019)", "journal-ref": "International Conference on Machine Learning, 4333-4342 (ICML\n  2019)", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyse quantitatively the interplay between the loss\nlandscape and performance of descent algorithms in a prototypical inference\nproblem, the spiked matrix-tensor model. We study a loss function that is the\nnegative log-likelihood of the model. We analyse the number of local minima at\na fixed distance from the signal/spike with the Kac-Rice formula, and locate\ntrivialization of the landscape at large signal-to-noise ratios. We evaluate in\na closed form the performance of a gradient flow algorithm using\nintegro-differential PDEs as developed in physics of disordered systems for the\nLangevin dynamics. We analyze the performance of an approximate message passing\nalgorithm estimating the maximum likelihood configuration via its state\nevolution. We conclude by comparing the above results: while we observe a\ndrastic slow down of the gradient flow dynamics even in the region where the\nlandscape is trivial, both the analyzed algorithms are shown to perform well\neven in the part of the region of parameters where spurious local minima are\npresent.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 00:12:37 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:16:43 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 08:13:43 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 15:10:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Krzakala", "Florent", ""], ["Urbani", "Pierfrancesco", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1902.00141", "submitter": "Julien Hendrickx", "authors": "Julien M. Hendrickx, Alex Olshevsky and Venkatesh Saligrama", "title": "Graph Resistance and Learning from Pairwise Comparisons", "comments": "15 pages, including 5 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the qualities of a collection of items by\nperforming noisy comparisons among them. Following the standard paradigm, we\nassume there is a fixed \"comparison graph\" and every neighboring pair of items\nin this graph is compared $k$ times according to the Bradley-Terry-Luce model\n(where the probability than an item wins a comparison is proportional the item\nquality). We are interested in how the relative error in quality estimation\nscales with the comparison graph in the regime where $k$ is large. We prove\nthat, after a known transition period, the relevant graph-theoretic quantity is\nthe square root of the resistance of the comparison graph. Specifically, we\nprovide an algorithm that is minimax optimal. The algorithm has a relative\nerror decay that scales with the square root of the graph resistance, and\nprovide a matching lower bound (up to log factors). The performance guarantee\nof our algorithm, both in terms of the graph and the skewness of the item\nquality distribution, outperforms earlier results.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 00:22:46 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 16:16:12 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Hendrickx", "Julien M.", ""], ["Olshevsky", "Alex", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1902.00146", "submitter": "Ananda Theertha Suresh", "authors": "Mehryar Mohri, Gary Sivek, Ananda Theertha Suresh", "title": "Agnostic Federated Learning", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key learning scenario in large-scale applications is that of federated\nlearning, where a centralized model is trained based on data originating from a\nlarge number of clients. We argue that, with the existing training and\ninference, federated models can be biased towards different clients. Instead,\nwe propose a new framework of agnostic federated learning, where the\ncentralized model is optimized for any target distribution formed by a mixture\nof the client distributions. We further show that this framework naturally\nyields a notion of fairness. We present data-dependent Rademacher complexity\nguarantees for learning with this objective, which guide the definition of an\nalgorithm for agnostic federated learning. We also give a fast stochastic\noptimization algorithm for solving the corresponding optimization problem, for\nwhich we prove convergence bounds, assuming a convex loss function and\nhypothesis set. We further empirically demonstrate the benefits of our approach\nin several datasets. Beyond federated learning, our framework and algorithm can\nbe of interest to other learning scenarios such as cloud computing, domain\nadaptation, drifting, and other contexts where the training and test\ndistributions do not coincide.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 01:34:49 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Mohri", "Mehryar", ""], ["Sivek", "Gary", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1902.00148", "submitter": "Xueyu Zhu", "authors": "Chuan Lu and Xueyu Zhu", "title": "Bifidelity data-assisted neural networks in nonintrusive reduced-order\n  modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new nonintrusive reduced basis method when a\ncheap low-fidelity model and expensive high-fidelity model are available. The\nmethod relies on proper orthogonal decomposition (POD) to generate the\nhigh-fidelity reduced basis and a shallow multilayer perceptron to learn the\nhigh-fidelity reduced coefficients. In contrast to other methods, one distinct\nfeature of the proposed method is to incorporate the features extracted from\nthe low-fidelity data as the input feature, this approach not only improves the\npredictive capability of the neural network but also enables the decoupling the\nhigh-fidelity simulation from the online stage. Due to its nonintrusive nature,\nit is applicable to general parameterized problems. We also provide several\nnumerical examples to illustrate the effectiveness and performance of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 01:43:32 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 04:05:28 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Lu", "Chuan", ""], ["Zhu", "Xueyu", ""]]}, {"id": "1902.00151", "submitter": "Meixia Lin", "authors": "Meixia Lin, Defeng Sun, Kim-Chuan Toh, Yancheng Yuan", "title": "A dual Newton based preconditioned proximal point algorithm for\n  exclusive lasso models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exclusive lasso (also known as elitist lasso) regularization has become\npopular recently due to its superior performance on group sparsity. Compared to\nthe group lasso regularization which enforces the competition on variables\namong different groups, the exclusive lasso regularization also enforces the\ncompetition within each group. In this paper, we propose a highly efficient\ndual Newton based preconditioned proximal point algorithm (PPDNA) to solve\nmachine learning models involving the exclusive lasso regularizer. As an\nimportant ingredient, we provide a rigorous proof for deriving the closed-form\nsolution to the proximal mapping of the weighted exclusive lasso regularizer.\nIn addition, we derive the corresponding HS-Jacobian to the proximal mapping\nand analyze its structure --- which plays an essential role in the efficient\ncomputation of the PPA subproblem via applying a semismooth Newton method on\nits dual. Various numerical experiments in this paper demonstrate the superior\nperformance of the proposed PPDNA against other state-of-the-art numerical\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 02:20:40 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:33:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lin", "Meixia", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""], ["Yuan", "Yancheng", ""]]}, {"id": "1902.00154", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Asli Celikyilmaz, Yizhe Zhang, Liqun Chen, Xin Wang,\n  Jianfeng Gao, Lawrence Carin", "title": "Towards Generating Long and Coherent Text with Multi-Level Latent\n  Variable Models", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have received much attention recently as an\nend-to-end architecture for text generation with latent variables. In this\npaper, we investigate several multi-level structures to learn a VAE model to\ngenerate long, and coherent text. In particular, we use a hierarchy of\nstochastic layers between the encoder and decoder networks to generate more\ninformative latent codes. We also investigate a multi-level decoder structure\nto learn a coherent long-term structure by generating intermediate sentence\nrepresentations as high-level plan vectors. Empirical results demonstrate that\na multi-level VAE model produces more coherent and less repetitive long text\ncompared to the standard VAE models and can further mitigate the\nposterior-collapse issue.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 02:42:55 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 20:22:13 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shen", "Dinghan", ""], ["Celikyilmaz", "Asli", ""], ["Zhang", "Yizhe", ""], ["Chen", "Liqun", ""], ["Wang", "Xin", ""], ["Gao", "Jianfeng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1902.00159", "submitter": "Angeline Aguinaldo", "authors": "Angeline Aguinaldo, Ping-Yeh Chiang, Alex Gain, Ameya Patil, Kolten\n  Pearson, Soheil Feizi", "title": "Compressing GANs using Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been used in several machine\nlearning tasks such as domain transfer, super resolution, and synthetic data\ngeneration. State-of-the-art GANs often use tens of millions of parameters,\nmaking them expensive to deploy for applications in low SWAP (size, weight, and\npower) hardware, such as mobile devices, and for applications with real time\ncapabilities. There has been no work found to reduce the number of parameters\nused in GANs. Therefore, we propose a method to compress GANs using knowledge\ndistillation techniques, in which a smaller \"student\" GAN learns to mimic a\nlarger \"teacher\" GAN. We show that the distillation methods used on MNIST,\nCIFAR-10, and Celeb-A datasets can compress teacher GANs at ratios of 1669:1,\n58:1, and 87:1, respectively, while retaining the quality of the generated\nimage. From our experiments, we observe a qualitative limit for GAN's\ncompression. Moreover, we observe that, with a fixed parameter budget,\ncompressed GANs outperform GANs trained using standard training methods. We\nconjecture that this is partially owing to the optimization landscape of\nover-parameterized GANs which allows efficient training using alternating\ngradient descent. Thus, training an over-parameterized GAN followed by our\nproposed compression scheme provides a high quality generative model with a\nsmall number of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 03:24:26 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Aguinaldo", "Angeline", ""], ["Chiang", "Ping-Yeh", ""], ["Gain", "Alex", ""], ["Patil", "Ameya", ""], ["Pearson", "Kolten", ""], ["Feizi", "Soheil", ""]]}, {"id": "1902.00172", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Prince Jain, Partha Talukdar", "title": "CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side\n  Information", "comments": "Accepted at WWW 2018", "journal-ref": "International World Wide Web Conferences Steering Committee 2018", "doi": "10.1145/3178876.3186030", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Information Extraction (OpenIE) methods extract (noun phrase, relation\nphrase, noun phrase) triples from text, resulting in the construction of large\nOpen Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in\nsuch Open KBs are not canonicalized, leading to the storage of redundant and\nambiguous facts. Recent research has posed canonicalization of Open KBs as\nclustering over manuallydefined feature spaces. Manual feature engineering is\nexpensive and often sub-optimal. In order to overcome this challenge, we\npropose Canonicalization using Embeddings and Side Information (CESI) - a novel\napproach which performs canonicalization over learned embeddings of Open KBs.\nCESI extends recent advances in KB embedding by incorporating relevant NP and\nrelation phrase side information in a principled manner. Through extensive\nexperiments on multiple real-world datasets, we demonstrate CESI's\neffectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:18:49 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Jain", "Prince", ""], ["Talukdar", "Partha", ""]]}, {"id": "1902.00174", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Philip S. Thomas, Gerome Miklau", "title": "Privacy Preserving Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning applications involve the use of data that is\nsensitive, such as medical records of patients or financial information.\nHowever, most current reinforcement learning methods can leak information\ncontained within the (possibly sensitive) data on which they are trained. To\naddress this problem, we present the first differentially private approach for\noff-policy evaluation. We provide a theoretical analysis of the\nprivacy-preserving properties of our algorithm and analyze its utility (speed\nof convergence). After describing some results of this theoretical analysis, we\nshow empirically that our method outperforms previous methods (which are\nrestricted to the on-policy setting).\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:26:34 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Xie", "Tengyang", ""], ["Thomas", "Philip S.", ""], ["Miklau", "Gerome", ""]]}, {"id": "1902.00175", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Shib Sankar Dasgupta, Swayambhu Nath Ray, Partha\n  Talukdar", "title": "Dating Documents using Graph Convolution Networks", "comments": "Accepted at ACL 2018", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document date is essential for many important tasks, such as document\nretrieval, summarization, event detection, etc. While existing approaches for\nthese tasks assume accurate knowledge of the document date, this is not always\navailable, especially for arbitrary documents from the Web. Document Dating is\na challenging problem which requires inference over the temporal structure of\nthe document. Prior document dating systems have largely relied on handcrafted\nfeatures while ignoring such document internal structures. In this paper, we\npropose NeuralDater, a Graph Convolutional Network (GCN) based document dating\napproach which jointly exploits syntactic and temporal graph structures of\ndocument in a principled way. To the best of our knowledge, this is the first\napplication of deep learning for the problem of document dating. Through\nextensive experiments on real-world datasets, we find that NeuralDater\nsignificantly outperforms state-of-the-art baseline by 19% absolute (45%\nrelative) accuracy points.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:30:42 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Dasgupta", "Shib Sankar", ""], ["Ray", "Swayambhu Nath", ""], ["Talukdar", "Partha", ""]]}, {"id": "1902.00177", "submitter": "George Stamatescu", "authors": "George Stamatescu, Federica Gerace, Carlo Lucibello, Ian Fuss,\n  Langford B. White", "title": "Critical initialisation in continuous approximations of binary neural\n  networks", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of stochastic neural network models with binary ($\\pm1$) weights\nand activations via continuous surrogate networks is investigated. We derive\nnew surrogates using a novel derivation based on writing the stochastic neural\nnetwork as a Markov chain. This derivation also encompasses existing variants\nof the surrogates presented in the literature. Following this, we theoretically\nstudy the surrogates at initialisation. We derive, using mean field theory, a\nset of scalar equations describing how input signals propagate through the\nrandomly initialised networks. The equations reveal whether so-called critical\ninitialisations exist for each surrogate network, where the network can be\ntrained to arbitrary depth. Moreover, we predict theoretically and confirm\nnumerically, that common weight initialisation schemes used in standard\ncontinuous networks, when applied to the mean values of the stochastic binary\nweights, yield poor training performance. This study shows that, contrary to\ncommon intuition, the means of the stochastic binary weights should be\ninitialised close to $\\pm 1$, for deeper networks to be trainable.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:39:20 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 03:07:50 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Stamatescu", "George", ""], ["Gerace", "Federica", ""], ["Lucibello", "Carlo", ""], ["Fuss", "Ian", ""], ["White", "Langford B.", ""]]}, {"id": "1902.00179", "submitter": "Ryan Spring", "authors": "Ryan Spring, Anastasios Kyrillidis, Vijai Mohan, Anshumali Shrivastava", "title": "Compressing Gradient Optimizers via Count-Sketches", "comments": "Initially submitted to WWW 2019 (November 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many popular first-order optimization methods (e.g., Momentum, AdaGrad, Adam)\naccelerate the convergence rate of deep learning models. However, these\nalgorithms require auxiliary parameters, which cost additional memory\nproportional to the number of parameters in the model. The problem is becoming\nmore severe as deep learning models continue to grow larger in order to learn\nfrom complex, large-scale datasets. Our proposed solution is to maintain a\nlinear sketch to compress the auxiliary variables. We demonstrate that our\ntechnique has the same performance as the full-sized baseline, while using\nsignificantly less space for the auxiliary variables. Theoretically, we prove\nthat count-sketch optimization maintains the SGD convergence rate, while\ngracefully reducing memory usage for large-models. On the large-scale 1-Billion\nWord dataset, we save 25% of the memory used during training (8.6 GB instead of\n11.7 GB) by compressing the Adam optimizer in the Embedding and Softmax layers\nwith negligible accuracy and performance loss. For an Amazon extreme\nclassification task with over 49.5 million classes, we also reduce the training\ntime by 38%, by increasing the mini-batch size 3.5x using our count-sketch\noptimizer.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:43:08 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:58:26 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Spring", "Ryan", ""], ["Kyrillidis", "Anastasios", ""], ["Mohan", "Vijai", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1902.00183", "submitter": "Yash Chandak", "authors": "Yash Chandak, Georgios Theocharous, James Kostas, Scott Jordan, Philip\n  S. Thomas", "title": "Learning Action Representations for Reinforcement Learning", "comments": "In Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most model-free reinforcement learning methods leverage state representations\n(embeddings) for generalization, but either ignore structure in the space of\nactions or assume the structure is provided a priori. We show how a policy can\nbe decomposed into a component that acts in a low-dimensional space of action\nrepresentations and a component that transforms these representations into\nactual actions. These representations improve generalization over large, finite\naction sets by allowing the agent to infer the outcomes of actions similar to\nactions already taken. We provide an algorithm to both learn and use action\nrepresentations and provide conditions for its convergence. The efficacy of the\nproposed method is demonstrated on large-scale real-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:58:40 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 20:29:40 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Chandak", "Yash", ""], ["Theocharous", "Georgios", ""], ["Kostas", "James", ""], ["Jordan", "Scott", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1902.00194", "submitter": "Raaz Dwivedi", "authors": "Raaz Dwivedi, Nhat Ho, Koulik Khamaru, Martin J. Wainwright, Michael\n  I. Jordan, Bin Yu", "title": "Sharp Analysis of Expectation-Maximization for Weakly Identifiable\n  Models", "comments": "30 pages, 4 figures. The first three authors contributed equally to\n  this work. To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of weakly identifiable location-scale mixture models for\nwhich the maximum likelihood estimates based on $n$ i.i.d. samples are known to\nhave lower accuracy than the classical $n^{- \\frac{1}{2}}$ error. We\ninvestigate whether the Expectation-Maximization (EM) algorithm also converges\nslowly for these models. We provide a rigorous characterization of EM for\nfitting a weakly identifiable Gaussian mixture in a univariate setting where we\nprove that the EM algorithm converges in order $n^{\\frac{3}{4}}$ steps and\nreturns estimates that are at a Euclidean distance of order ${ n^{-\n\\frac{1}{8}}}$ and ${ n^{-\\frac{1} {4}}}$ from the true location and scale\nparameter respectively. Establishing the slow rates in the univariate setting\nrequires a novel localization argument with two stages, with each stage\ninvolving an epoch-based argument applied to a different surrogate EM operator\nat the population level. We demonstrate several multivariate ($d \\geq 2$)\nexamples that exhibit the same slow rates as the univariate case. We also prove\nslow statistical rates in higher dimensions in a special case, when the fitted\ncovariance is constrained to be a multiple of the identity.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 06:07:08 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 01:22:51 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 19:42:45 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Dwivedi", "Raaz", ""], ["Ho", "Nhat", ""], ["Khamaru", "Koulik", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""], ["Yu", "Bin", ""]]}, {"id": "1902.00202", "submitter": "Yiding Chen", "authors": "Yiding Chen, Xiaojin Zhu", "title": "Optimal Attack against Autoregressive Models by Manipulating the\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an optimal adversarial attack formulation against autoregressive\ntime series forecast using Linear Quadratic Regulator (LQR). In this threat\nmodel, the environment evolves according to a dynamical system; an\nautoregressive model observes the current environment state and predicts its\nfuture values; an attacker has the ability to modify the environment state in\norder to manipulate future autoregressive forecasts. The attacker's goal is to\nforce autoregressive forecasts into tracking a target trajectory while\nminimizing its attack expenditure. In the white-box setting where the attacker\nknows the environment and forecast models, we present the optimal attack using\nLQR for linear models, and Model Predictive Control (MPC) for nonlinear models.\nIn the black-box setting, we combine system identification and MPC. Experiments\ndemonstrate the effectiveness of our attacks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 06:46:47 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 19:19:06 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 05:34:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Chen", "Yiding", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1902.00215", "submitter": "Harikesh Nair", "authors": "Ruihuan Du, Yu Zhong, Harikesh Nair, Bo Cui, and Ruyang Shou", "title": "Causally Driven Incremental Multi Touch Attribution Using a Recurrent\n  Neural Network", "comments": "arXiv admin note: text overlap with arXiv:1506.00019 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a practical system for Multi Touch Attribution (MTA) for\nuse by a publisher of digital ads. We developed this system for JD.com, an\neCommerce company, which is also a publisher of digital ads in China. The\napproach has two steps. The first step ('response modeling') fits a user-level\nmodel for purchase of a product as a function of the user's exposure to ads.\nThe second ('credit allocation') uses the fitted model to allocate the\nincremental part of the observed purchase due to advertising, to the ads the\nuser is exposed to over the previous T days. To implement step one, we train a\nRecurrent Neural Network (RNN) on user-level conversion and exposure data. The\nRNN has the advantage of flexibly handling the sequential dependence in the\ndata in a semi-parametric way. The specific RNN formulation we implement\ncaptures the impact of advertising intensity, timing, competition, and\nuser-heterogeneity, which are known to be relevant to ad-response. To implement\nstep two, we compute Shapley Values, which have the advantage of having\naxiomatic foundations and satisfying fairness considerations. The specific\nformulation of the Shapley Value we implement respects incrementality by\nallocating the overall incremental improvement in conversion to the exposed\nads, while handling the sequence-dependence of exposures on the observed\noutcomes. The system is under production at JD.com, and scales to handle the\nhigh dimensionality of the problem on the platform (attribution of the orders\nof about 300M users, for roughly 160K brands, across 200+ ad-types, served\nabout 80B ad-impressions over a typical 15-day period).\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 08:13:25 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 04:19:48 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 06:47:54 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Du", "Ruihuan", ""], ["Zhong", "Yu", ""], ["Nair", "Harikesh", ""], ["Cui", "Bo", ""], ["Shou", "Ruyang", ""]]}, {"id": "1902.00236", "submitter": "Yuval Bahat", "authors": "Yuval Bahat, Michal Irani and Gregory Shakhnarovich", "title": "Natural and Adversarial Error Detection using Invariance to Image\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to distinguish between correct and incorrect image\nclassifications. Our approach can detect misclassifications which either occur\n$\\it{unintentionally}$ (\"natural errors\"), or due to\n$\\it{intentional~adversarial~attacks}$ (\"adversarial errors\"), both in a single\n$\\it{unified~framework}$. Our approach is based on the observation that\ncorrectly classified images tend to exhibit robust and consistent\nclassifications under certain image transformations (e.g., horizontal flip,\nsmall image translation, etc.). In contrast, incorrectly classified images\n(whether due to adversarial errors or natural errors) tend to exhibit large\nvariations in classification results under such transformations. Our approach\ndoes not require any modifications or retraining of the classifier, hence can\nbe applied to any pre-trained classifier. We further use state of the art\ntargeted adversarial attacks to demonstrate that even when the adversary has\nfull knowledge of our method, the adversarial distortion needed for bypassing\nour detector is $\\it{no~longer~imperceptible~to~the~human~eye}$. Our approach\nobtains state-of-the-art results compared to previous adversarial detection\nmethods, surpassing them by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:00:54 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Bahat", "Yuval", ""], ["Irani", "Michal", ""], ["Shakhnarovich", "Gregory", ""]]}, {"id": "1902.00247", "submitter": "Cong Fang", "authors": "Cong Fang, Zhouchen Lin, Tong Zhang", "title": "Sharp Analysis for Nonconvex SGD Escaping from Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a sharp analysis for Stochastic Gradient Descent (SGD)\nand prove that SGD is able to efficiently escape from saddle points and find an\n$(\\epsilon, O(\\epsilon^{0.5}))$-approximate second-order stationary point in\n$\\tilde{O}(\\epsilon^{-3.5})$ stochastic gradient computations for generic\nnonconvex optimization problems, when the objective function satisfies\ngradient-Lipschitz, Hessian-Lipschitz, and dispersive noise assumptions. This\nresult subverts the classical belief that SGD requires at least\n$O(\\epsilon^{-4})$ stochastic gradient computations for obtaining an\n$(\\epsilon,O(\\epsilon^{0.5}))$-approximate second-order stationary point. Such\nSGD rate matches, up to a polylogarithmic factor of problem-dependent\nparameters, the rate of most accelerated nonconvex stochastic optimization\nalgorithms that adopt additional techniques, such as Nesterov's momentum\nacceleration, negative curvature search, as well as quadratic and cubic\nregularization tricks. Our novel analysis gives new insights into nonconvex SGD\nand can be potentially generalized to a broad class of stochastic optimization\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:35:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 12:23:24 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Fang", "Cong", ""], ["Lin", "Zhouchen", ""], ["Zhang", "Tong", ""]]}, {"id": "1902.00249", "submitter": "Mohammed AlQuraishi", "authors": "Mohammed AlQuraishi", "title": "ProteinNet: a standardized data set for machine learning of protein\n  structure", "comments": "8 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Rapid progress in deep learning has spurred its application to bioinformatics\nproblems including protein structure prediction and design. In classic machine\nlearning problems like computer vision, progress has been driven by\nstandardized data sets that facilitate fair assessment of new methods and lower\nthe barrier to entry for non-domain experts. While data sets of protein\nsequence and structure exist, they lack certain components critical for machine\nlearning, including high-quality multiple sequence alignments and insulated\ntraining / validation splits that account for deep but only weakly detectable\nhomology across protein space. We have created the ProteinNet series of data\nsets to provide a standardized mechanism for training and assessing data-driven\nmodels of protein sequence-structure relationships. ProteinNet integrates\nsequence, structure, and evolutionary information in programmatically\naccessible file formats tailored for machine learning frameworks. Multiple\nsequence alignments of all structurally characterized proteins were created\nusing substantial high-performance computing resources. Standardized data\nsplits were also generated to emulate the difficulty of past CASP (Critical\nAssessment of protein Structure Prediction) experiments by resetting protein\nsequence and structure space to the historical states that preceded six prior\nCASPs. Utilizing sensitive evolution-based distance metrics to segregate\ndistantly related proteins, we have additionally created validation sets\ndistinct from the official CASP sets that faithfully mimic their difficulty.\nProteinNet thus represents a comprehensive and accessible resource for training\nand assessing machine-learned models of protein structure.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:43:50 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["AlQuraishi", "Mohammed", ""]]}, {"id": "1902.00255", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Murray Shanahan, Claudia Clopath", "title": "Policy Consolidation for Continual Reinforcement Learning", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for tackling catastrophic forgetting in deep\nreinforcement learning that is \\textit{agnostic} to the timescale of changes in\nthe distribution of experiences, does not require knowledge of task boundaries,\nand can adapt in \\textit{continuously} changing environments. In our\n\\textit{policy consolidation} model, the policy network interacts with a\ncascade of hidden networks that simultaneously remember the agent's policy at a\nrange of timescales and regularise the current policy by its own history,\nthereby improving its ability to learn without forgetting. We find that the\nmodel improves continual learning relative to baselines on a number of\ncontinuous control tasks in single-task, alternating two-task, and multi-agent\ncompetitive self-play settings.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:59:10 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 12:45:41 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kaplanis", "Christos", ""], ["Shanahan", "Murray", ""], ["Clopath", "Claudia", ""]]}, {"id": "1902.00275", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, Pieter Abbeel", "title": "Flow++: Improving Flow-Based Generative Models with Variational\n  Dequantization and Architecture Design", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models are powerful exact likelihood models with\nefficient sampling and inference. Despite their computational efficiency,\nflow-based models generally have much worse density modeling performance\ncompared to state-of-the-art autoregressive models. In this paper, we\ninvestigate and improve upon three limiting design choices employed by\nflow-based models in prior work: the use of uniform noise for dequantization,\nthe use of inexpressive affine flows, and the use of purely convolutional\nconditioning networks in coupling layers. Based on our findings, we propose\nFlow++, a new flow-based model that is now the state-of-the-art\nnon-autoregressive model for unconditional density estimation on standard image\nbenchmarks. Our work has begun to close the significant performance gap that\nhas so far existed between autoregressive models and flow-based models. Our\nimplementation is available at https://github.com/aravindsrinivas/flowpp\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 11:13:40 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 23:16:06 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ho", "Jonathan", ""], ["Chen", "Xi", ""], ["Srinivas", "Aravind", ""], ["Duan", "Yan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1902.00282", "submitter": "Chang Liu", "authors": "Chang Liu, Jingwei Zhuo, Jun Zhu", "title": "Understanding MCMC Dynamics as Flows on the Wasserstein Space", "comments": "References refined", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the Langevin dynamics used in MCMC is the gradient flow of\nthe KL divergence on the Wasserstein space, which helps convergence analysis\nand inspires recent particle-based variational inference methods (ParVIs). But\nno more MCMC dynamics is understood in this way. In this work, by developing\nnovel concepts, we propose a theoretical framework that recognizes a general\nMCMC dynamics as the fiber-gradient Hamiltonian flow on the Wasserstein space\nof a fiber-Riemannian Poisson manifold. The \"conservation + convergence\"\nstructure of the flow gives a clear picture on the behavior of general MCMC\ndynamics. The framework also enables ParVI simulation of MCMC dynamics, which\nenriches the ParVI family with more efficient dynamics, and also adapts ParVI\nadvantages to MCMCs. We develop two ParVI methods for a particular MCMC\ndynamics and demonstrate the benefits in experiments.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 11:33:13 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 06:02:34 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 10:24:04 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Liu", "Chang", ""], ["Zhuo", "Jingwei", ""], ["Zhu", "Jun", ""]]}, {"id": "1902.00340", "submitter": "Anastasiia Koloskova", "authors": "Anastasia Koloskova, Sebastian U. Stich, Martin Jaggi", "title": "Decentralized Stochastic Optimization and Gossip Algorithms with\n  Compressed Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decentralized stochastic optimization with the objective function\n(e.g. data samples for machine learning task) being distributed over $n$\nmachines that can only communicate to their neighbors on a fixed communication\ngraph. To reduce the communication bottleneck, the nodes compress (e.g.\nquantize or sparsify) their model updates. We cover both unbiased and biased\ncompression operators with quality denoted by $\\omega \\leq 1$ ($\\omega=1$\nmeaning no compression). We (i) propose a novel gossip-based stochastic\ngradient descent algorithm, CHOCO-SGD, that converges at rate\n$\\mathcal{O}\\left(1/(nT) + 1/(T \\delta^2 \\omega)^2\\right)$ for strongly convex\nobjectives, where $T$ denotes the number of iterations and $\\delta$ the\neigengap of the connectivity matrix. Despite compression quality and network\nconnectivity affecting the higher order terms, the first term in the rate,\n$\\mathcal{O}(1/(nT))$, is the same as for the centralized baseline with exact\ncommunication. We (ii) present a novel gossip algorithm, CHOCO-GOSSIP, for the\naverage consensus problem that converges in time\n$\\mathcal{O}(1/(\\delta^2\\omega) \\log (1/\\epsilon))$ for accuracy $\\epsilon >\n0$. This is (up to our knowledge) the first gossip algorithm that supports\narbitrary compressed messages for $\\omega > 0$ and still exhibits linear\nconvergence. We (iii) show in experiments that both of our algorithms do\noutperform the respective state-of-the-art baselines and CHOCO-SGD can reduce\ncommunication by at least two orders of magnitudes.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:11:20 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Koloskova", "Anastasia", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1902.00342", "submitter": "Tam Le", "authors": "Tam Le, Makoto Yamada, Kenji Fukumizu, Marco Cuturi", "title": "Tree-Sliced Variants of Wasserstein Distances", "comments": "Camera-ready for NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (\\OT) theory defines a powerful set of tools to compare\nprobability distributions. \\OT~suffers however from a few drawbacks,\ncomputational and statistical, which have encouraged the proposal of several\nregularized variants of OT in the recent literature, one of the most notable\nbeing the \\textit{sliced} formulation, which exploits the closed-form formula\nbetween univariate distributions by projecting high-dimensional measures onto\nrandom lines. We consider in this work a more general family of ground metrics,\nnamely \\textit{tree metrics}, which also yield fast closed-form computations\nand negative definite, and of which the sliced-Wasserstein distance is a\nparticular case (the tree is a chain). We propose the tree-sliced Wasserstein\ndistance, computed by averaging the Wasserstein distance between these measures\nusing random tree metrics, built adaptively in either low or high-dimensional\nspaces. Exploiting the negative definiteness of that distance, we also propose\na positive definite kernel, and test it against other baselines on a few\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:12:52 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 06:47:40 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 08:27:25 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Le", "Tam", ""], ["Yamada", "Makoto", ""], ["Fukumizu", "Kenji", ""], ["Cuturi", "Marco", ""]]}, {"id": "1902.00358", "submitter": "Li Xiao", "authors": "Li Xiao, Yijie Peng, Jeff Hong, Zewu Ke, Shuhuai Yang", "title": "Training Artificial Neural Networks by Generalized Likelihood Ratio\n  Method: Exploring Brain-like Learning to Improve Robustness", "comments": "12 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a generalized likelihood ratio method capable of\ntraining the artificial neural networks with some biological brain-like\nmechanisms,.e.g., (a) learning by the loss value, (b) learning via neurons with\ndiscontinuous activation and loss functions. The traditional back propagation\nmethod cannot train the artificial neural networks with aforementioned\nbrain-like learning mechanisms. Numerical results show that the robustness of\nvarious artificial neural networks trained by the new method is significantly\nimproved when the input data is affected by both the natural noises and\nadversarial attacks. Code is available:\n\\url{https://github.com/LX-doctorAI/GLR_ADV} .\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:14:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 06:58:45 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Xiao", "Li", ""], ["Peng", "Yijie", ""], ["Hong", "Jeff", ""], ["Ke", "Zewu", ""], ["Yang", "Shuhuai", ""]]}, {"id": "1902.00375", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Astrid Bunge and Carolin Hainke and Leon\n  Sindelar and Matthias Vogelsang", "title": "Dynamic fairness - Breaking vicious cycles in automatic decision making", "comments": "preprint of a paper accepted for oral presentation at the 27th\n  European Symposium on Artificial Neural Networks (ESANN 2019)", "journal-ref": "Proc. ESANN (2019), 477-482", "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning techniques have been increasingly applied\nin sensitive decision making processes, raising fairness concerns. Past\nresearch has shown that machine learning may reproduce and even exacerbate\nhuman bias due to biased training data or flawed model assumptions, and thus\nmay lead to discriminatory actions. To counteract such biased models,\nresearchers have proposed multiple mathematical definitions of fairness\naccording to which classifiers can be optimized. However, it has also been\nshown that the outcomes generated by some fairness notions may be\nunsatisfactory.\n  In this contribution, we add to this research by considering decision making\nprocesses in time. We establish a theoretic model in which even perfectly\naccurate classifiers which adhere to almost all common fairness definitions\nlead to stable long-term inequalities due to vicious cycles. Only demographic\nparity, which enforces equal rates of positive decisions across groups, avoids\nthese effects and establishes a virtuous cycle, which leads to perfectly\naccurate and fair classification in the long term.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:47:01 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 16:29:34 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Bunge", "Astrid", ""], ["Hainke", "Carolin", ""], ["Sindelar", "Leon", ""], ["Vogelsang", "Matthias", ""]]}, {"id": "1902.00383", "submitter": "Xiaofang Wang", "authors": "Shengcao Cao, Xiaofang Wang, Kris M. Kitani", "title": "Learnable Embedding Space for Efficient Neural Architecture Compression", "comments": "ICLR 2019 - Code available here:\n  https://github.com/Friedrich1006/ESNAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to incrementally learn an embedding space over the domain\nof network architectures, to enable the careful selection of architectures for\nevaluation during compressed architecture search. Given a teacher network, we\nsearch for a compressed network architecture by using Bayesian Optimization\n(BO) with a kernel function defined over our proposed embedding space to select\narchitectures for evaluation. We demonstrate that our search algorithm can\nsignificantly outperform various baseline methods, such as random search and\nreinforcement learning (Ashok et al., 2018). The compressed architectures found\nby our method are also better than the state-of-the-art manually-designed\ncompact architecture ShuffleNet (Zhang et al., 2018). We also demonstrate that\nthe learned embedding space can be transferred to new settings for architecture\nsearch, such as a larger teacher network or a teacher network in a different\narchitecture family, without any training. Code is publicly available here:\nhttps://github.com/Friedrich1006/ESNAC .\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:54:17 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 15:03:04 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Cao", "Shengcao", ""], ["Wang", "Xiaofang", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1902.00407", "submitter": "Sahil Singla", "authors": "Sahil Singla, Eric Wallace, Shi Feng and Soheil Feizi", "title": "Understanding Impacts of High-Order Loss Approximations and Features in\n  Deep Learning Interpretation", "comments": "Proceedings of the 36th International Conference on Machine Learning,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods to interpret deep learning models by generating saliency maps\ngenerally rely on two key assumptions. First, they use first-order\napproximations of the loss function neglecting higher-order terms such as the\nloss curvatures. Second, they evaluate each feature's importance in isolation,\nignoring their inter-dependencies. In this work, we study the effect of\nrelaxing these two assumptions. First, by characterizing a closed-form formula\nfor the Hessian matrix of a deep ReLU network, we prove that, for a\nclassification problem with a large number of classes, if an input has a high\nconfidence classification score, the inclusion of the Hessian term has small\nimpacts in the final solution. We prove this result by showing that in this\ncase the Hessian matrix is approximately of rank one and its leading\neigenvector is almost parallel to the gradient of the loss function. Our\nempirical experiments on ImageNet samples are consistent with our theory. This\nresult can have implications in other related problems such as adversarial\nexamples as well. Second, we compute the importance of group-features in deep\nlearning interpretation by introducing a sparsity regularization term. We use\nthe $L_0-L_1$ relaxation technique along with the proximal gradient descent to\nhave an efficient computation of group feature importance scores. Our empirical\nresults indicate that considering group features can improve deep learning\ninterpretation significantly.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 15:42:46 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 01:45:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Singla", "Sahil", ""], ["Wallace", "Eric", ""], ["Feng", "Shi", ""], ["Feizi", "Soheil", ""]]}, {"id": "1902.00415", "submitter": "Yogesh Balaji", "authors": "Yogesh Balaji, Rama Chellappa and Soheil Feizi", "title": "Normalized Wasserstein Distance for Mixture Distributions with\n  Applications in Adversarial Learning and Domain Adaptation", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding proper distance measures between distributions is at the core\nof several learning tasks such as generative models, domain adaptation,\nclustering, etc. In this work, we focus on mixture distributions that arise\nnaturally in several application domains where the data contains different\nsub-populations. For mixture distributions, established distance measures such\nas the Wasserstein distance do not take into account imbalanced mixture\nproportions. Thus, even if two mixture distributions have identical mixture\ncomponents but different mixture proportions, the Wasserstein distance between\nthem will be large. This often leads to undesired results in distance-based\nlearning methods for mixture distributions. In this paper, we resolve this\nissue by introducing the Normalized Wasserstein measure. The key idea is to\nintroduce mixture proportions as optimization variables, effectively\nnormalizing mixture proportions in the Wasserstein formulation. Using the\nproposed normalized Wasserstein measure leads to significant performance gains\nfor mixture distributions with imbalanced mixture proportions compared to the\nvanilla Wasserstein distance. We demonstrate the effectiveness of the proposed\nmeasure in GANs, domain adaptation and adversarial clustering in several\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 15:50:43 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 10:57:49 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Balaji", "Yogesh", ""], ["Chellappa", "Rama", ""], ["Feizi", "Soheil", ""]]}, {"id": "1902.00434", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Kimia Nadjahi, Umut Simsekli, Roland Badeau, Gustavo\n  K. Rohde", "title": "Generalized Sliced Wasserstein Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance and its variations, e.g., the sliced-Wasserstein\n(SW) distance, have recently drawn attention from the machine learning\ncommunity. The SW distance, specifically, was shown to have similar properties\nto the Wasserstein distance, while being much simpler to compute, and is\ntherefore used in various applications including generative modeling and\ngeneral supervised/unsupervised learning. In this paper, we first clarify the\nmathematical connection between the SW distance and the Radon transform. We\nthen utilize the generalized Radon transform to define a new family of\ndistances for probability measures, which we call generalized\nsliced-Wasserstein (GSW) distances. We also show that, similar to the SW\ndistance, the GSW distance can be extended to a maximum GSW (max-GSW) distance.\nWe then provide the conditions under which GSW and max-GSW distances are indeed\ndistances. Finally, we compare the numerical performance of the proposed\ndistances on several generative modeling tasks, including SW flows and SW\nauto-encoders.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:16:14 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Kolouri", "Soheil", ""], ["Nadjahi", "Kimia", ""], ["Simsekli", "Umut", ""], ["Badeau", "Roland", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1902.00440", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu and Yao Xie", "title": "Spatial-Temporal-Textual Point Processes with Applications in Crime\n  Linkage Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crimes emerge out of complex interactions of human behaviors and situations.\nLinkages between crime events are highly complex. Detecting crime linkage given\na set of events is a highly challenging task since we only have limited\ninformation, including text descriptions, event times, and locations; moreover,\nthe link among incidents is subtle. In practice, there are very few labeled\ndata about related cases. We present a statistical modeling framework for\npolice reports based on multivariate marked spatio-temporal Hawkes processes.\nInspired by the notion of modus operandi (M.O.) in crime analysis, we perform\ntext embedding for police reports and treat embedding vectors as marks of the\nHawkes process. The embedding is performed by regularized Restricted Boltzmann\nMachine (RBM) to promote the probabilistic sparsity of selected keywords.\nNumerical results using real data demonstrate the competitive performance and\ninterpretability of our method. The proposed method can be used in other\nsimilar data in social networks, electronic health records.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:26:51 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 04:57:44 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 21:07:57 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 20:22:27 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 16:15:46 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhu", "Shixiang", ""], ["Xie", "Yao", ""]]}, {"id": "1902.00448", "submitter": "Jakub Tomczak Ph.D.", "authors": "Changyong Oh and Jakub M. Tomczak and Efstratios Gavves and Max\n  Welling", "title": "Combinatorial Bayesian Optimization using the Graph Cartesian Product", "comments": "Accepted to NeurIPS 2019, code: https://github.com/QUVA-Lab/COMBO", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on Bayesian Optimization (BO) for objectives on\ncombinatorial search spaces, including ordinal and categorical variables.\nDespite the abundance of potential applications of Combinatorial BO, including\nchipset configuration search and neural architecture search, only a handful of\nmethods have been proposed. We introduce COMBO, a new Gaussian Process (GP) BO.\nCOMBO quantifies \"smoothness\" of functions on combinatorial search spaces by\nutilizing a combinatorial graph. The vertex set of the combinatorial graph\nconsists of all possible joint assignments of the variables, while edges are\nconstructed using the graph Cartesian product of the sub-graphs that represent\nthe individual variables. On this combinatorial graph, we propose an ARD\ndiffusion kernel with which the GP is able to model high-order interactions\nbetween variables leading to better performance. Moreover, using the Horseshoe\nprior for the scale parameter in the ARD diffusion kernel results in an\neffective variable selection procedure, making COMBO suitable for high\ndimensional problems. Computationally, in COMBO the graph Cartesian product\nallows the Graph Fourier Transform calculation to scale linearly instead of\nexponentially. We validate COMBO in a wide array of realistic benchmarks,\nincluding weighted maximum satisfiability problems and neural architecture\nsearch. COMBO outperforms consistently the latest state-of-the-art while\nmaintaining computational and statistical efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:46:17 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 09:22:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Oh", "Changyong", ""], ["Tomczak", "Jakub M.", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "1902.00450", "submitter": "Ioana Bica", "authors": "Ioana Bica, Ahmed M. Alaa, Mihaela van der Schaar", "title": "Time Series Deconfounder: Estimating Treatment Effects over Time in the\n  Presence of Hidden Confounders", "comments": null, "journal-ref": "In Proc. 37th International Conference on Machine Learning (ICML\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of treatment effects is a pervasive problem in medicine.\nExisting methods for estimating treatment effects from longitudinal\nobservational data assume that there are no hidden confounders, an assumption\nthat is not testable in practice and, if it does not hold, leads to biased\nestimates. In this paper, we develop the Time Series Deconfounder, a method\nthat leverages the assignment of multiple treatments over time to enable the\nestimation of treatment effects in the presence of multi-cause hidden\nconfounders. The Time Series Deconfounder uses a novel recurrent neural network\narchitecture with multitask output to build a factor model over time and infer\nlatent variables that render the assigned treatments conditionally independent;\nthen, it performs causal inference using these latent variables that act as\nsubstitutes for the multi-cause unobserved confounders. We provide a\ntheoretical analysis for obtaining unbiased causal effects of time-varying\nexposures using the Time Series Deconfounder. Using both simulated and real\ndata we show the effectiveness of our method in deconfounding the estimation of\ntreatment responses over time.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 16:49:51 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 17:43:22 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 20:42:06 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2020 12:43:27 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Bica", "Ioana", ""], ["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1902.00460", "submitter": "Indranil Chakraborty", "authors": "Indranil Chakraborty, Deboleena Roy, Aayush Ankit and Kaushik Roy", "title": "Efficient Hybrid Network Architectures for Extremely Quantized Neural\n  Networks Enabling Intelligence at the Edge", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of `Internet of Things' (IOT) has increased the demand for\nenabling AI-based edge computing. This has necessitated the search for\nefficient implementations of neural networks in terms of both computations and\nstorage. Although extreme quantization has proven to be a powerful tool to\nachieve significant compression over full-precision networks, it can result in\nsignificant degradation in performance. In this work, we propose extremely\nquantized hybrid network architectures with both binary and full-precision\nsections to emulate the classification performance of full-precision networks\nwhile ensuring significant energy efficiency and memory compression. We explore\nseveral hybrid network architectures and analyze the performance of the\nnetworks in terms of accuracy, energy efficiency and memory compression. We\nperform our analysis on ResNet and VGG network architectures. Among the\nproposed network architectures, we show that the hybrid networks with\nfull-precision residual connections emerge as the optimum by attaining\naccuracies close to full-precision networks while achieving excellent memory\ncompression, up to 21.8x in case of VGG-19. This work demonstrates an effective\nway of hybridizing networks which achieve performance close to full-precision\nnetworks while attaining significant compression, furthering the feasibility of\nusing such networks for energy-efficient neural computing in IOT-based edge\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:16:05 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Chakraborty", "Indranil", ""], ["Roy", "Deboleena", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "1902.00465", "submitter": "David Budden", "authors": "Peter Buchlovsky, David Budden, Dominik Grewe, Chris Jones, John\n  Aslanides, Frederic Besse, Andy Brock, Aidan Clark, Sergio G\\'omez\n  Colmenarejo, Aedan Pope, Fabio Viola and Dan Belov", "title": "TF-Replicator: Distributed Machine Learning for Researchers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe TF-Replicator, a framework for distributed machine learning\ndesigned for DeepMind researchers and implemented as an abstraction over\nTensorFlow. TF-Replicator simplifies writing data-parallel and model-parallel\nresearch code. The same models can be effortlessly deployed to different\ncluster architectures (i.e. one or many machines containing CPUs, GPUs or TPU\naccelerators) using synchronous or asynchronous training regimes. To\ndemonstrate the generality and scalability of TF-Replicator, we implement and\nbenchmark three very different models: (1) A ResNet-50 for ImageNet\nclassification, (2) a SN-GAN for class-conditional ImageNet image generation,\nand (3) a D4PG reinforcement learning agent for continuous control. Our results\nshow strong scalability performance without demanding any distributed systems\nexpertise of the user. The TF-Replicator programming model will be open-sourced\nas part of TensorFlow 2.0 (see\nhttps://github.com/tensorflow/community/pull/25).\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:26:07 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Buchlovsky", "Peter", ""], ["Budden", "David", ""], ["Grewe", "Dominik", ""], ["Jones", "Chris", ""], ["Aslanides", "John", ""], ["Besse", "Frederic", ""], ["Brock", "Andy", ""], ["Clark", "Aidan", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Pope", "Aedan", ""], ["Viola", "Fabio", ""], ["Belov", "Dan", ""]]}, {"id": "1902.00468", "submitter": "Masahiro Fujisawa", "authors": "Masahiro Fujisawa and Issei Sato", "title": "Multi-level Monte Carlo Variational Inference", "comments": "added/fixed some theorems, lemmas, proposition, and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a variance reduction framework for variational inference using the\nmulti-level Monte Carlo (MLMC) method. The proposed framework \"recycles\"\nparameters obtained from past update history in optimization and can be\ncompatible with reparameterized gradient estimators. Our framework provides a\nnovel optimization algorithm based on the stochastic gradient method and\nadaptively estimates the sample size for stochastic gradient estimation per\nlevel according to the ratio of the variance and computation cost in each\niteration. We also analyze the convergence of the gradient norm in the\nstochastic gradient method, the scale of the gradient estimator's variance, and\nthe estimator's quality in each optimization step on the basis of the\n\\textit{signal-to-noise} ratio. Finally, we experimentally evaluate the\nproposed method by comparing it with baseline methods on several benchmark data\nsets. The results confirm that the proposed method achieves faster convergence\nand reduces the variance of the gradient estimator compared with the other\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:37:21 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 08:45:47 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 12:05:32 GMT"}, {"version": "v4", "created": "Sun, 12 Apr 2020 03:03:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Fujisawa", "Masahiro", ""], ["Sato", "Issei", ""]]}, {"id": "1902.00469", "submitter": "Andrawes Al Bahou", "authors": "Andrawes Al Bahou, Christine Tanner, Orcun Goksel", "title": "SCATGAN for Reconstruction of Ultrasound Scatterers Using Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational simulation of ultrasound (US) echography is essential for\ntraining sonographers. Realistic simulation of US interaction with microscopic\ntissue structures is often modeled by a tissue representation in the form of\npoint scatterers, convolved with a spatially varying point spread function.\nThis yields a realistic US B-mode speckle texture, given that a scatterer\nrepresentation for a particular tissue type is readily available. This is often\nnot the case and scatterers are nontrivial to determine. In this work we\npropose to estimate scatterer maps from sample US B-mode images of a tissue, by\nformulating this inverse mapping problem as image translation, where we learn\nthe mapping with Generative Adversarial Networks, using a US simulation\nsoftware for training. We demonstrate robust reconstruction results, invariant\nto US viewing and imaging settings such as imaging direction and center\nfrequency. Our method is shown to generalize beyond the trained imaging\nsettings, demonstrated on in-vivo US data. Our inference runs orders of\nmagnitude faster than optimization-based techniques, enabling future extensions\nfor reconstructing 3D B-mode volumes with only linear computational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:38:17 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Bahou", "Andrawes Al", ""], ["Tanner", "Christine", ""], ["Goksel", "Orcun", ""]]}, {"id": "1902.00470", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari", "title": "An Information-Theoretic Approach to Minimax Regret in Partial\n  Monitoring", "comments": "29 pages, to appear in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new minimax theorem connecting the worst-case Bayesian regret and\nminimax regret under partial monitoring with no assumptions on the space of\nsignals or decisions of the adversary. We then generalise the\ninformation-theoretic tools of Russo and Van Roy (2016) for proving Bayesian\nregret bounds and combine them with the minimax theorem to derive minimax\nregret bounds for various partial monitoring settings. The highlight is a clean\nanalysis of `non-degenerate easy' and `hard' finite partial monitoring, with\nnew regret bounds that are independent of arbitrarily large game-dependent\nconstants. The power of the generalised machinery is further demonstrated by\nproving that the minimax regret for k-armed adversarial bandits is at most\nsqrt{2kn}, improving on existing results by a factor of 2. Finally, we provide\na simple analysis of the cops and robbers game, also improving best known\nconstants.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:39:36 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 08:20:37 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1902.00491", "submitter": "Vaibhav B Sinha", "authors": "Vaibhav B Sinha, Sneha Kudugunta, Adepu Ravi Sankar, Surya Teja\n  Chavali, Purushottam Kar, Vineeth N Balasubramanian", "title": "DANTE: Deep AlterNations for Training nEural networks", "comments": "19 pages", "journal-ref": "Neural Networks 131 (2020) 127-143", "doi": "10.1016/j.neunet.2020.07.026", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present DANTE, a novel method for training neural networks using the\nalternating minimization principle. DANTE provides an alternate perspective to\ntraditional gradient-based backpropagation techniques commonly used to train\ndeep networks. It utilizes an adaptation of quasi-convexity to cast training a\nneural network as a bi-quasi-convex optimization problem. We show that for\nneural network configurations with both differentiable (e.g. sigmoid) and\nnon-differentiable (e.g. ReLU) activation functions, we can perform the\nalternations effectively in this formulation. DANTE can also be extended to\nnetworks with multiple hidden layers. In experiments on standard datasets,\nneural networks trained using the proposed method were found to be promising\nand competitive to traditional backpropagation techniques, both in terms of\nquality of the solution, as well as training speed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:30:22 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 20:57:06 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 21:26:21 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sinha", "Vaibhav B", ""], ["Kudugunta", "Sneha", ""], ["Sankar", "Adepu Ravi", ""], ["Chavali", "Surya Teja", ""], ["Kar", "Purushottam", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1902.00505", "submitter": "Aj Piergiovanni", "authors": "AJ Piergiovanni, Anelia Angelova, Michael S. Ryoo", "title": "Differentiable Grammars for Videos", "comments": null, "journal-ref": "AAAI-2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel algorithm which learns a formal regular grammar\nfrom real-world continuous data, such as videos. Learning latent terminals,\nnon-terminals, and production rules directly from continuous data allows the\nconstruction of a generative model capturing sequential structures with\nmultiple possibilities. Our model is fully differentiable, and provides easily\ninterpretable results which are important in order to understand the learned\nstructures. It outperforms the state-of-the-art on several challenging datasets\nand is more accurate for forecasting future activities in videos. We plan to\nopen-source the code. https://sites.google.com/view/differentiable-grammars\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:58:18 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 16:38:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Piergiovanni", "AJ", ""], ["Angelova", "Anelia", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "1902.00506", "submitter": "Nolan Bard", "authors": "Nolan Bard, Jakob N. Foerster, Sarath Chandar, Neil Burch, Marc\n  Lanctot, H. Francis Song, Emilio Parisotto, Vincent Dumoulin, Subhodeep\n  Moitra, Edward Hughes, Iain Dunning, Shibl Mourad, Hugo Larochelle, Marc G.\n  Bellemare, Michael Bowling", "title": "The Hanabi Challenge: A New Frontier for AI Research", "comments": "32 pages, 5 figures, In Press (Artificial Intelligence)", "journal-ref": null, "doi": "10.1016/j.artint.2019.103216", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the early days of computing, games have been important testbeds for\nstudying how well machines can do sophisticated decision making. In recent\nyears, machine learning has made dramatic advances with artificial agents\nreaching superhuman performance in challenge domains like Go, Atari, and some\nvariants of poker. As with their predecessors of chess, checkers, and\nbackgammon, these game domains have driven research by providing sophisticated\nyet well-defined challenges for artificial intelligence practitioners. We\ncontinue this tradition by proposing the game of Hanabi as a new challenge\ndomain with novel problems that arise from its combination of purely\ncooperative gameplay with two to five players and imperfect information. In\nparticular, we argue that Hanabi elevates reasoning about the beliefs and\nintentions of other agents to the foreground. We believe developing novel\ntechniques for such theory of mind reasoning will not only be crucial for\nsuccess in Hanabi, but also in broader collaborative efforts, especially those\nwith human partners. To facilitate future research, we introduce the\nopen-source Hanabi Learning Environment, propose an experimental framework for\nthe research community to evaluate algorithmic advances, and assess the\nperformance of current state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:59:07 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 22:15:35 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bard", "Nolan", ""], ["Foerster", "Jakob N.", ""], ["Chandar", "Sarath", ""], ["Burch", "Neil", ""], ["Lanctot", "Marc", ""], ["Song", "H. Francis", ""], ["Parisotto", "Emilio", ""], ["Dumoulin", "Vincent", ""], ["Moitra", "Subhodeep", ""], ["Hughes", "Edward", ""], ["Dunning", "Iain", ""], ["Mourad", "Shibl", ""], ["Larochelle", "Hugo", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1902.00522", "submitter": "Eliu Huerta", "authors": "Gabrielle Allen, Igor Andreoni, Etienne Bachelet, G. Bruce Berriman,\n  Federica B. Bianco, Rahul Biswas, Matias Carrasco Kind, Kyle Chard, Minsik\n  Cho, Philip S. Cowperthwaite, Zachariah B. Etienne, Daniel George, Tom Gibbs,\n  Matthew Graham, William Gropp, Anushri Gupta, Roland Haas, E. A. Huerta,\n  Elise Jennings, Daniel S. Katz, Asad Khan, Volodymyr Kindratenko, William T.\n  C. Kramer, Xin Liu, Ashish Mahabal, Kenton McHenry, J. M. Miller, M. S.\n  Neubauer, Steve Oberlin, Alexander R. Olivas Jr, Shawn Rosofsky, Milton Ruiz,\n  Aaron Saxton, Bernard Schutz, Alex Schwing, Ed Seidel, Stuart L. Shapiro,\n  Hongyu Shen, Yue Shen, Brigitta M. Sip\\H{o}cz, Lunan Sun, John Towns,\n  Antonios Tsokaros, Wei Wei, Jack Wells, Timothy J. Williams, Jinjun Xiong,\n  Zhizhen Zhao", "title": "Deep Learning for Multi-Messenger Astrophysics: A Gateway for Discovery\n  in the Big Data Era", "comments": "15 pages, no figures. White paper based on the \"Deep Learning for\n  Multi-Messenger Astrophysics: Real-time Discovery at Scale\" workshop, hosted\n  at NCSA, October 17-19, 2018\n  http://www.ncsa.illinois.edu/Conferences/DeepLearningLSST/", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report provides an overview of recent work that harnesses the Big Data\nRevolution and Large Scale Computing to address grand computational challenges\nin Multi-Messenger Astrophysics, with a particular emphasis on real-time\ndiscovery campaigns. Acknowledging the transdisciplinary nature of\nMulti-Messenger Astrophysics, this document has been prepared by members of the\nphysics, astronomy, computer science, data science, software and\ncyberinfrastructure communities who attended the NSF-, DOE- and NVIDIA-funded\n\"Deep Learning for Multi-Messenger Astrophysics: Real-time Discovery at Scale\"\nworkshop, hosted at the National Center for Supercomputing Applications,\nOctober 17-19, 2018. Highlights of this report include unanimous agreement that\nit is critical to accelerate the development and deployment of novel,\nsignal-processing algorithms that use the synergy between artificial\nintelligence (AI) and high performance computing to maximize the potential for\nscientific discovery with Multi-Messenger Astrophysics. We discuss key aspects\nto realize this endeavor, namely (i) the design and exploitation of scalable\nand computationally efficient AI algorithms for Multi-Messenger Astrophysics;\n(ii) cyberinfrastructure requirements to numerically simulate astrophysical\nsources, and to process and interpret Multi-Messenger Astrophysics data; (iii)\nmanagement of gravitational wave detections and triggers to enable\nelectromagnetic and astro-particle follow-ups; (iv) a vision to harness future\ndevelopments of machine and deep learning and cyberinfrastructure resources to\ncope with the scale of discovery in the Big Data Era; (v) and the need to build\na community that brings domain experts together with data scientists on equal\nfooting to maximize and accelerate discovery in the nascent field of\nMulti-Messenger Astrophysics.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 19:02:18 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Allen", "Gabrielle", ""], ["Andreoni", "Igor", ""], ["Bachelet", "Etienne", ""], ["Berriman", "G. Bruce", ""], ["Bianco", "Federica B.", ""], ["Biswas", "Rahul", ""], ["Kind", "Matias Carrasco", ""], ["Chard", "Kyle", ""], ["Cho", "Minsik", ""], ["Cowperthwaite", "Philip S.", ""], ["Etienne", "Zachariah B.", ""], ["George", "Daniel", ""], ["Gibbs", "Tom", ""], ["Graham", "Matthew", ""], ["Gropp", "William", ""], ["Gupta", "Anushri", ""], ["Haas", "Roland", ""], ["Huerta", "E. A.", ""], ["Jennings", "Elise", ""], ["Katz", "Daniel S.", ""], ["Khan", "Asad", ""], ["Kindratenko", "Volodymyr", ""], ["Kramer", "William T. C.", ""], ["Liu", "Xin", ""], ["Mahabal", "Ashish", ""], ["McHenry", "Kenton", ""], ["Miller", "J. M.", ""], ["Neubauer", "M. S.", ""], ["Oberlin", "Steve", ""], ["Olivas", "Alexander R.", "Jr"], ["Rosofsky", "Shawn", ""], ["Ruiz", "Milton", ""], ["Saxton", "Aaron", ""], ["Schutz", "Bernard", ""], ["Schwing", "Alex", ""], ["Seidel", "Ed", ""], ["Shapiro", "Stuart L.", ""], ["Shen", "Hongyu", ""], ["Shen", "Yue", ""], ["Sip\u0151cz", "Brigitta M.", ""], ["Sun", "Lunan", ""], ["Towns", "John", ""], ["Tsokaros", "Antonios", ""], ["Wei", "Wei", ""], ["Wells", "Jack", ""], ["Williams", "Timothy J.", ""], ["Xiong", "Jinjun", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1902.00528", "submitter": "Hao Liu", "authors": "Hao Liu, Alexander Trott, Richard Socher, Caiming Xiong", "title": "Competitive Experience Replay", "comments": "Published as a conference paper at Seventh International Conference\n  on Learning Representations(ICLR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved remarkable successes in solving challenging\nreinforcement learning (RL) problems when dense reward function is provided.\nHowever, in sparse reward environment it still often suffers from the need to\ncarefully shape reward function to guide policy optimization. This limits the\napplicability of RL in the real world since both reinforcement learning and\ndomain-specific knowledge are required. It is therefore of great practical\nimportance to develop algorithms which can learn from a binary signal\nindicating successful task completion or other unshaped, sparse reward signals.\nWe propose a novel method called competitive experience replay, which\nefficiently supplements a sparse reward by placing learning in the context of\nan exploration competition between a pair of agents. Our method complements the\nrecently proposed hindsight experience replay (HER) by inducing an automatic\nexploratory curriculum. We evaluate our approach on the tasks of reaching\nvarious goal locations in an ant maze and manipulating objects with a robotic\narm. Each task provides only binary rewards indicating whether or not the goal\nis achieved. Our method asymmetrically augments these sparse rewards for a pair\nof agents each learning the same task, creating a competitive game designed to\ndrive exploration. Extensive experiments demonstrate that this method leads to\nfaster converge and improved task performance.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 19:23:58 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 23:55:04 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 21:46:01 GMT"}, {"version": "v4", "created": "Sun, 17 Feb 2019 00:23:55 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liu", "Hao", ""], ["Trott", "Alexander", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1902.00532", "submitter": "Zhiyun Lu", "authors": "Zhiyun Lu, Chao-Kai Chiang, and Fei Sha", "title": "Hyper-parameter Tuning under a Budget Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a budgeted hyper-parameter tuning problem, where we optimize the\ntuning result under a hard resource constraint. We propose to solve it as a\nsequential decision making problem, such that we can use the partial training\nprogress of configurations to dynamically allocate the remaining budget. Our\nalgorithm combines a Bayesian belief model which estimates the future\nperformance of configurations, with an action-value function which balances\nexploration-exploitation tradeoff, to optimize the final output. It\nautomatically adapts the tuning behaviors to different constraints, which is\nuseful in practice. Experiment results demonstrate superior performance over\nexisting algorithms, including the-state-of-the-art one, on real-world tuning\ntasks across a range of different budgets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 19:29:38 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Lu", "Zhiyun", ""], ["Chiang", "Chao-Kai", ""], ["Sha", "Fei", ""]]}, {"id": "1902.00541", "submitter": "Cory Cornelius", "authors": "Cory Cornelius, Nilaksh Das, Shang-Tse Chen, Li Chen, Michael E.\n  Kounavis, Duen Horng Chau", "title": "The Efficacy of SHIELD under Different Threat Models", "comments": "Appraisal paper of existing method accepted for oral presentation at\n  KDD LEMINCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this appraisal paper, we evaluate the efficacy of SHIELD, a\ncompression-based defense framework for countering adversarial attacks on image\nclassification models, which was published at KDD 2018. Here, we consider\nalternative threat models not studied in the original work, where we assume\nthat an adaptive adversary is aware of the ensemble defense approach, the\ndefensive pre-processing, and the architecture and weights of the models used\nin the ensemble. We define scenarios with varying levels of threat and\nempirically analyze the proposed defense by varying the degree of information\navailable to the attacker, spanning from a full white-box attack to the\ngray-box threat model described in the original work. To evaluate the\nrobustness of the defense against an adaptive attacker, we consider the\ntargeted-attack success rate of the Projected Gradient Descent (PGD) attack,\nwhich is a strong gradient-based adversarial attack proposed in adversarial\nmachine learning research. We also experiment with training the SHIELD ensemble\nfrom scratch, which is different from re-training using a pre-trained model as\ndone in the original work. We find that the targeted PGD attack has a success\nrate of 64.3% against the original SHIELD ensemble in the full white box\nscenario, but this drops to 48.9% if the models used in the ensemble are\ntrained from scratch instead of being retrained. Our experiments further reveal\nthat an ensemble whose models are re-trained indeed have higher correlation in\nthe cosine similarity space, and models that are trained from scratch are less\nvulnerable to targeted attacks in the white-box and gray-box scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 20:10:12 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 20:48:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Cornelius", "Cory", ""], ["Das", "Nilaksh", ""], ["Chen", "Shang-Tse", ""], ["Chen", "Li", ""], ["Kounavis", "Michael E.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1902.00562", "submitter": "Nathaniel Bastian PhD", "authors": "Timothy J. Kiely and Nathaniel D. Bastian", "title": "The Spatially-Conscious Machine Learning Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully predicting gentrification could have many social and commercial\napplications; however, real estate sales are difficult to predict because they\nbelong to a chaotic system comprised of intrinsic and extrinsic\ncharacteristics, perceived value, and market speculation. Using New York City\nreal estate as our subject, we combine modern techniques of data science and\nmachine learning with traditional spatial analysis to create robust real estate\nprediction models for both classification and regression tasks. We compare\nseveral cutting edge machine learning algorithms across spatial, semi-spatial\nand non-spatial feature engineering techniques, and we empirically show that\nspatially-conscious machine learning models outperform non-spatial models when\nmarried with advanced prediction techniques such as feed-forward artificial\nneural networks and gradient boosting machine models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 20:58:34 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kiely", "Timothy J.", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "1902.00563", "submitter": "T\\'arik S. Salem", "authors": "T\\'arik S. Salem, Karan Kathuria, Heri Ramampiaro, Helge Langseth", "title": "Forecasting Intra-Hour Imbalances in Electric Power Systems", "comments": "Accepted at the Thirty-First Annual Conference on Innovative\n  Applications of Artificial Intelligence (IAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keeping the electricity production in balance with the actual demand is\nbecoming a difficult and expensive task in spite of an involvement of\nexperienced human operators. This is due to the increasing complexity of the\nelectric power grid system with the intermittent renewable production as one of\nthe contributors. A beforehand information about an occurring imbalance can\nhelp the transmission system operator to adjust the production plans, and thus\nensure a high security of supply by reducing the use of costly balancing\nreserves, and consequently reduce undesirable fluctuations of the 50 Hz power\nsystem frequency. In this paper, we introduce the relatively new problem of an\nintra-hour imbalance forecasting for the transmission system operator (TSO). We\nfocus on the use case of the Norwegian TSO, Statnett. We present a\ncomplementary imbalance forecasting tool that is able to support the TSO in\ndetermining the trend of future imbalances, and show the potential to\nproactively alleviate imbalances with a higher accuracy compared to the\ncontemporary solution.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 20:58:51 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Salem", "T\u00e1rik S.", ""], ["Kathuria", "Karan", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""]]}, {"id": "1902.00566", "submitter": "Laurens Weitkamp", "authors": "Laurens Weitkamp, Elise van der Pol, Zeynep Akata", "title": "Visual Rationalizations in Deep Reinforcement Learning for Atari Games", "comments": "presented as oral talk at BNAIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the capability of deep learning to perform well in high dimensional\nproblems, deep reinforcement learning agents perform well in challenging tasks\nsuch as Atari 2600 games. However, clearly explaining why a certain action is\ntaken by the agent can be as important as the decision itself. Deep\nreinforcement learning models, as other deep learning models, tend to be opaque\nin their decision-making process. In this work, we propose to make deep\nreinforcement learning more transparent by visualizing the evidence on which\nthe agent bases its decision. In this work, we emphasize the importance of\nproducing a justification for an observed action, which could be applied to a\nblack-box decision agent.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 21:29:17 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Weitkamp", "Laurens", ""], ["van der Pol", "Elise", ""], ["Akata", "Zeynep", ""]]}, {"id": "1902.00567", "submitter": "Zekun Xu", "authors": "Zekun Xu, Deovrat Kakde, Arin Chaudhuri", "title": "Automatic Hyperparameter Tuning Method for Local Outlier Factor, with\n  Applications to Anomaly Detection", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006151", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been many practical applications of anomaly\ndetection such as in predictive maintenance, detection of credit fraud, network\nintrusion, and system failure. The goal of anomaly detection is to identify in\nthe test data anomalous behaviors that are either rare or unseen in the\ntraining data. This is a common goal in predictive maintenance, which aims to\nforecast the imminent faults of an appliance given abundant samples of normal\nbehaviors. Local outlier factor (LOF) is one of the state-of-the-art models\nused for anomaly detection, but the predictive performance of LOF depends\ngreatly on the selection of hyperparameters. In this paper, we propose a novel,\nheuristic methodology to tune the hyperparameters in LOF. A tuned LOF model\nthat uses the proposed method shows good predictive performance in both\nsimulations and real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 21:32:21 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Xu", "Zekun", ""], ["Kakde", "Deovrat", ""], ["Chaudhuri", "Arin", ""]]}, {"id": "1902.00577", "submitter": "Sascha Saralajew", "authors": "Sascha Saralajew and Lars Holdijk and Maike Rees and Thomas Villmann", "title": "Robustness of Generalized Learning Vector Quantization Models against\n  Adversarial Attacks", "comments": "to be published in 13th International Workshop on Self-Organizing\n  Maps and Learning Vector Quantization, Clustering and Data Visualization", "journal-ref": null, "doi": "10.1007/978-3-030-19642-4_19", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks and the development of (deep) neural networks robust\nagainst them are currently two widely researched topics. The robustness of\nLearning Vector Quantization (LVQ) models against adversarial attacks has\nhowever not yet been studied to the same extent. We therefore present an\nextensive evaluation of three LVQ models: Generalized LVQ, Generalized Matrix\nLVQ and Generalized Tangent LVQ. The evaluation suggests that both Generalized\nLVQ and Generalized Tangent LVQ have a high base robustness, on par with the\ncurrent state-of-the-art in robust neural network methods. In contrast to this,\nGeneralized Matrix LVQ shows a high susceptibility to adversarial attacks,\nscoring consistently behind all other models. Additionally, our numerical\nevaluation indicates that increasing the number of prototypes per class\nimproves the robustness of the models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 22:28:56 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 23:29:01 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Saralajew", "Sascha", ""], ["Holdijk", "Lars", ""], ["Rees", "Maike", ""], ["Villmann", "Thomas", ""]]}, {"id": "1902.00600", "submitter": "Marc Vuffray", "authors": "Marc Vuffray, Sidhant Misra, Andrey Y. Lokhov", "title": "Efficient Learning of Discrete Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are useful tools for describing structured high-dimensional\nprobability distributions. Development of efficient algorithms for learning\ngraphical models with least amount of data remains an active research topic.\nReconstruction of graphical models that describe the statistics of discrete\nvariables is a particularly challenging problem, for which the maximum\nlikelihood approach is intractable. In this work, we provide the first\nsample-efficient method based on the Interaction Screening framework that\nallows one to provably learn fully general discrete factor models with\nnode-specific discrete alphabets and multi-body interactions, specified in an\narbitrary basis. We identify a single condition related to model\nparametrization that leads to rigorous guarantees on the recovery of model\nstructure and parameters in any error norm, and is readily verifiable for a\nlarge class of models. Importantly, our bounds make explicit distinction\nbetween parameters that are proper to the model and priors used as an input to\nthe algorithm. Finally, we show that the Interaction Screening framework\nincludes all models previously considered in the literature as special cases,\nand for which our analysis shows a systematic improvement in sample complexity.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 00:54:57 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 06:31:44 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Vuffray", "Marc", ""], ["Misra", "Sidhant", ""], ["Lokhov", "Andrey Y.", ""]]}, {"id": "1902.00610", "submitter": "Baekjin Kim", "authors": "Baekjin Kim, Ambuj Tewari", "title": "On the Optimality of Perturbations in Stochastic and Adversarial\n  Multi-armed Bandit Problems", "comments": "Advances in Neural Information Processing Systems 32 (NIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the optimality of perturbation based algorithms in the\nstochastic and adversarial multi-armed bandit problems. For the stochastic\ncase, we provide a unified regret analysis for both sub-Weibull and bounded\nperturbations when rewards are sub-Gaussian. Our bounds are instance optimal\nfor sub-Weibull perturbations with parameter 2 that also have a matching lower\ntail bound, and all bounded support perturbations where there is sufficient\nprobability mass at the extremes of the support. For the adversarial setting,\nwe prove rigorous barriers against two natural solution approaches using tools\nfrom discrete choice theory and extreme value theory. Our results suggest that\nthe optimal perturbation, if it exists, will be of Frechet-type.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 01:20:49 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 16:12:22 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 22:03:37 GMT"}, {"version": "v4", "created": "Tue, 10 Dec 2019 07:38:51 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Kim", "Baekjin", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1902.00613", "submitter": "Abraham Frandsen", "authors": "Abraham Frandsen, Rong Ge", "title": "Understanding Composition of Word Embeddings via Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is a powerful tool in natural language processing. In this\npaper we consider the problem of word embedding composition \\--- given vector\nrepresentations of two words, compute a vector for the entire phrase. We give a\ngenerative model that can capture specific syntactic relations between words.\nUnder our model, we prove that the correlations between three words (measured\nby their PMI) form a tensor that has an approximate low rank Tucker\ndecomposition. The result of the Tucker decomposition gives the word embeddings\nas well as a core tensor, which can be used to produce better compositions of\nthe word embeddings. We also complement our theoretical results with\nexperiments that verify our assumptions, and demonstrate the effectiveness of\nthe new composition method.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 01:34:56 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Frandsen", "Abraham", ""], ["Ge", "Rong", ""]]}, {"id": "1902.00618", "submitter": "Chi Jin", "authors": "Chi Jin, Praneeth Netrapalli, Michael I. Jordan", "title": "What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?", "comments": "This paper has been published at ICML2020. This new version made a\n  correction to Proposition 19, and added more related works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax optimization has found extensive applications in modern machine\nlearning, in settings such as generative adversarial networks (GANs),\nadversarial training and multi-agent reinforcement learning. As most of these\napplications involve continuous nonconvex-nonconcave formulations, a very basic\nquestion arises---\"what is a proper definition of local optima?\"\n  Most previous work answers this question using classical notions of\nequilibria from simultaneous games, where the min-player and the max-player act\nsimultaneously. In contrast, most applications in machine learning, including\nGANs and adversarial training, correspond to sequential games, where the order\nof which player acts first is crucial (since minimax is in general not equal to\nmaximin due to the nonconvex-nonconcave nature of the problems). The main\ncontribution of this paper is to propose a proper mathematical definition of\nlocal optimality for this sequential setting---local minimax, as well as to\npresent its properties and existence results. Finally, we establish a strong\nconnection to a basic local search algorithm---gradient descent ascent (GDA):\nunder mild conditions, all stable limit points of GDA are exactly local minimax\npoints up to some degenerate points.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 02:08:28 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 06:56:15 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 05:13:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jin", "Chi", ""], ["Netrapalli", "Praneeth", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.00621", "submitter": "Xuanyuan Luo", "authors": "Jian Li, Xuanyuan Luo, Mingda Qiao", "title": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex\n  Learning", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization error (also known as the out-of-sample error) measures how\nwell the hypothesis learned from training data generalizes to previously unseen\ndata. Proving tight generalization error bounds is a central question in\nstatistical learning theory. In this paper, we obtain generalization error\nbounds for learning general non-convex objectives, which has attracted\nsignificant attention in recent years. We develop a new framework, termed\nBayes-Stability, for proving algorithm-dependent generalization error bounds.\nThe new framework combines ideas from both the PAC-Bayesian theory and the\nnotion of algorithmic stability. Applying the Bayes-Stability method, we obtain\nnew data-dependent generalization bounds for stochastic gradient Langevin\ndynamics (SGLD) and several other noisy gradient methods (e.g., with momentum,\nmini-batch and acceleration, Entropy-SGD). Our result recovers (and is\ntypically tighter than) a recent result in Mou et al. (2018) and improves upon\nthe results in Pensia et al. (2018). Our experiments demonstrate that our\ndata-dependent bounds can distinguish randomly labelled data from normal data,\nwhich provides an explanation to the intriguing phenomena observed in Zhang et\nal. (2017a). We also study the setting where the total loss is the sum of a\nbounded loss and an additional \\ell_2 regularization term. We obtain new\ngeneralization bounds for the continuous Langevin dynamic in this setting by\ndeveloping a new Log-Sobolev inequality for the parameter distribution at any\ntime. Our new bounds are more desirable when the noisy level of the process is\nnot small, and do not become vacuous even when T tends to infinity.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 02:15:25 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 10:17:13 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 02:30:33 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 03:36:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Jian", ""], ["Luo", "Xuanyuan", ""], ["Qiao", "Mingda", ""]]}, {"id": "1902.00626", "submitter": "Marwan Mattar", "authors": "Marwan Mattar, Michael Ross, Erik Learned-Miller", "title": "Nonparametric Curve Alignment", "comments": "4 pages, IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congealing is a flexible nonparametric data-driven framework for the joint\nalignment of data. It has been successfully applied to the joint alignment of\nbinary images of digits, binary images of object silhouettes, grayscale MRI\nimages, color images of cars and faces, and 3D brain volumes. This research\nenhances congealing to practically and effectively apply it to curve data. We\ndevelop a parameterized set of nonlinear transformations that allow us to apply\ncongealing to this type of data. We present positive results on aligning\nsynthetic and real curve data sets and conclude with a discussion on extending\nthis work to simultaneous alignment and clustering.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 02:29:24 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Mattar", "Marwan", ""], ["Ross", "Michael", ""], ["Learned-Miller", "Erik", ""]]}, {"id": "1902.00629", "submitter": "Hoi-To Wai", "authors": "Belhal Karimi, Blazej Miasojedow, Eric Moulines, Hoi-To Wai", "title": "Non-asymptotic Analysis of Biased Stochastic Approximation Scheme", "comments": "Accepted to COLT 2019; 32 pages. Minor updates in Section 3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Stochastic approximation (SA) is a key method used in statistical learning.\nRecently, its non-asymptotic convergence analysis has been considered in many\npapers. However, most of the prior analyses are made under restrictive\nassumptions such as unbiased gradient estimates and convex objective function,\nwhich significantly limit their applications to sophisticated tasks such as\nonline and reinforcement learning. These restrictions are all essentially\nrelaxed in this work. In particular, we analyze a general SA scheme to minimize\na non-convex, smooth objective function. We consider update procedure whose\ndrift term depends on a state-dependent Markov chain and the mean field is not\nnecessarily of gradient type, covering approximate second-order method and\nallowing asymptotic bias for the one-step updates. We illustrate these settings\nwith the online EM algorithm and the policy-gradient method for average reward\nmaximization in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 02:45:49 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 17:18:11 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 08:15:01 GMT"}, {"version": "v4", "created": "Sun, 16 Jun 2019 23:27:38 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Karimi", "Belhal", ""], ["Miasojedow", "Blazej", ""], ["Moulines", "Eric", ""], ["Wai", "Hoi-To", ""]]}, {"id": "1902.00632", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Efficient estimation of AUC in a sliding window", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-10925-7_41", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, monitoring area under the ROC curve (AUC) in a sliding\nwindow over a data stream is a natural way of detecting changes in the system.\nThe drawback is that computing AUC in a sliding window is expensive, especially\nif the window size is large and the data flow is significant.\n  In this paper we propose a scheme for maintaining an approximate AUC in a\nsliding window of length $k$. More specifically, we propose an algorithm that,\ngiven $\\epsilon$, estimates AUC within $\\epsilon / 2$, and can maintain this\nestimate in $O((\\log k) / \\epsilon)$ time, per update, as the window slides.\nThis provides a speed-up over the exact computation of AUC, which requires\n$O(k)$ time, per update. The speed-up becomes more significant as the size of\nthe window increases. Our estimate is based on grouping the data points\ntogether, and using these groups to calculate AUC. The grouping is designed\ncarefully such that ($i$) the groups are small enough, so that the error stays\nsmall, ($ii$) the number of groups is small, so that enumerating them is not\nexpensive, and ($iii$) the definition is flexible enough so that we can\nmaintain the groups efficiently.\n  Our experimental evaluation demonstrates that the average approximation error\nin practice is much smaller than the approximation guarantee $\\epsilon / 2$,\nand that we can achieve significant speed-ups with only a modest sacrifice in\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 03:03:01 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1902.00635", "submitter": "Tingran Gao", "authors": "Yuanyuan Feng, Tingran Gao, Lei Li, Jian-Guo Liu, Yulong Lu", "title": "Uniform-in-Time Weak Error Analysis for Stochastic Gradient Descent\n  Algorithms via Diffusion Approximation", "comments": "22 pages, 3 figures. To appear in Comm. Math. Sci. (2019+)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion approximation provides weak approximation for stochastic gradient\ndescent algorithms in a finite time horizon. In this paper, we introduce new\ntools motivated by the backward error analysis of numerical stochastic\ndifferential equations into the theoretical framework of diffusion\napproximation, extending the validity of the weak approximation from finite to\ninfinite time horizon. The new techniques developed in this paper enable us to\ncharacterize the asymptotic behavior of constant-step-size SGD algorithms for\nstrongly convex objective functions, a goal previously unreachable within the\ndiffusion approximation framework. Our analysis builds upon a truncated formal\npower expansion of the solution of a stochastic modified equation arising from\ndiffusion approximation, where the main technical ingredient is a\nuniform-in-time weak error bound controlling the long-term behavior of the\nexpansion coefficient functions near the global minimum. We expect these new\ntechniques to greatly expand the range of applicability of diffusion\napproximation to cover wider and deeper aspects of stochastic optimization\nalgorithms in data science.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 03:28:32 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 04:56:15 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Feng", "Yuanyuan", ""], ["Gao", "Tingran", ""], ["Li", "Lei", ""], ["Liu", "Jian-Guo", ""], ["Lu", "Yulong", ""]]}, {"id": "1902.00636", "submitter": "Reza Asadi Mr", "authors": "Reza Asadi and Amelia Regan", "title": "A Spatial-Temporal Decomposition Based Deep Neural Network for Time\n  Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial time series forecasting problems arise in a broad range of\napplications, such as environmental and transportation problems. These problems\nare challenging because of the existence of specific spatial, short-term and\nlong-term patterns, and the curse of dimensionality. In this paper, we propose\na deep neural network framework for large-scale spatial time series forecasting\nproblems. We explicitly designed the neural network architecture for capturing\nvarious types of patterns. In preprocessing, a time series decomposition method\nis applied to separately feed short-term, long-term and spatial patterns into\ndifferent components of a neural network. A fuzzy clustering method finds\ncluster of neighboring time series based on similarity of time series\nresiduals; as they can be meaningful short-term patterns for spatial time\nseries. In neural network architecture, each kernel of a multi-kernel\nconvolution layer is applied to a cluster of time series to extract short-term\nfeatures in neighboring areas. The output of convolution layer is concatenated\nby trends and followed by convolution-LSTM layer to capture long-term patterns\nin larger regional areas. To make a robust prediction when faced with missing\ndata, an unsupervised pretrained denoising autoencoder reconstructs the output\nof the model in a fine-tuning step. The experimental results illustrate the\nmodel outperforms baseline and state of the art models in a traffic flow\nprediction dataset.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 03:28:34 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Asadi", "Reza", ""], ["Regan", "Amelia", ""]]}, {"id": "1902.00640", "submitter": "Xinshi Chen", "authors": "Xinshi Chen, Hanjun Dai, Le Song", "title": "Particle Flow Bayes' Rule", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:1022-1031, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a particle flow realization of Bayes' rule, where an ODE-based\nneural operator is used to transport particles from a prior to its posterior\nafter a new observation. We prove that such an ODE operator exists. Its neural\nparameterization can be trained in a meta-learning framework, allowing this\noperator to reason about the effect of an individual observation on the\nposterior, and thus generalize across different priors, observations and to\nsequential Bayesian inference. We demonstrated the generalization ability of\nour particle flow Bayes operator in several canonical and high dimensional\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 04:34:37 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:47:52 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2020 04:27:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chen", "Xinshi", ""], ["Dai", "Hanjun", ""], ["Song", "Le", ""]]}, {"id": "1902.00641", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, A. Salman Avestimehr", "title": "CodedPrivateML: A Fast and Privacy-Preserving Framework for Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to train a machine learning model while keeping the data private and\nsecure? We present CodedPrivateML, a fast and scalable approach to this\ncritical problem. CodedPrivateML keeps both the data and the model\ninformation-theoretically private, while allowing efficient parallelization of\ntraining across distributed workers. We characterize CodedPrivateML's privacy\nthreshold and prove its convergence for logistic (and linear) regression.\nFurthermore, via extensive experiments on Amazon EC2, we demonstrate that\nCodedPrivateML provides significant speedup over cryptographic approaches based\non multi-party computing (MPC).\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 05:09:39 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 20:01:10 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1902.00648", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda", "title": "Fast Approximation and Estimation Bounds of Kernel Quadrature for\n  Infinitely Wide Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An infinitely wide model is a weighted integration $\\int \\varphi(x,v) d\n\\mu(v)$ of feature maps. This model excels at handling an infinite number of\nfeatures, and thus it has been adopted to the theoretical study of deep\nlearning. Kernel quadrature is a kernel-based numerical integration scheme\ndeveloped for fast approximation of expectations $\\int f(x) d p(x)$. In this\nstudy, regarding the weight $\\mu$ as a signed (or complex/vector-valued)\ndistribution of parameters, we develop the general kernel quadrature (GKQ) for\nparameter distributions. The proposed method can achieve a fast approximation\nrate $O(e^{-p})$ with parameter number $p$, which is faster than the\ntraditional Barron's rate, and a fast estimation rate $\\widetilde{O}(1/n)$ with\nsample size $n$. As a result, we have obtained a new norm-based complexity\nmeasure for infinitely wide models. Since the GKQ implicitly conducts the\nempirical risk minimization, we can understand that the complexity measure also\nreflects the generalization performance in the gradient learning setup.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 06:17:49 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 09:28:25 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 16:23:37 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 14:31:58 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Sonoda", "Sho", ""]]}, {"id": "1902.00655", "submitter": "Chuzhe Tang", "authors": "Chuzhe Tang, Zhiyuan Dong, Minjie Wang, Zhaoguo Wang, Haibo Chen", "title": "Learned Indexes for Dynamic Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proposal of learned index structures opens up a new perspective on\nhow traditional range indexes can be optimized. However, the current learned\nindexes assume the data distribution is relatively static and the access\npattern is uniform, while real-world scenarios consist of skew query\ndistribution and evolving data. In this paper, we demonstrate that the missing\nconsideration of access patterns and dynamic data distribution notably hinders\nthe applicability of learned indexes. To this end, we propose solutions for\nlearned indexes for dynamic workloads (called Doraemon). To improve the latency\nfor skew queries, Doraemon augments the training data with access frequencies.\nTo address the slow model re-training when data distribution shifts, Doraemon\ncaches the previously-trained models and incrementally fine-tunes them for\nsimilar access patterns and data distribution. Our preliminary result shows\nthat, Doraemon improves the query latency by 45.1% and reduces the model\nre-training time to 1/20.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:03:00 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tang", "Chuzhe", ""], ["Dong", "Zhiyuan", ""], ["Wang", "Minjie", ""], ["Wang", "Zhaoguo", ""], ["Chen", "Haibo", ""]]}, {"id": "1902.00681", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Mark Sellke", "title": "First-Order Bayesian Regret Analysis of Thompson Sampling", "comments": "42 pages. v2 adds results on graphical feedback and contextual\n  bandit, and tightens previous results using Tsallis entropy and log barrier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address online combinatorial optimization when the player has a prior over\nthe adversary's sequence of losses. In this framework, Russo and Van Roy\nproposed an information-theoretic analysis of Thompson Sampling based on the\n{\\em information ratio}, resulting in optimal worst-case regret bounds. In this\npaper we introduce three novel ideas to this line of work. First we propose a\nnew quantity, the scale-sensitive information ratio, which allows us to obtain\nmore refined first-order regret bounds (i.e., bounds of the form $\\sqrt{L^*}$\nwhere $L^*$ is the loss of the best combinatorial action). Second we replace\nthe entropy over combinatorial actions by a coordinate entropy, which allows us\nto obtain the first optimal worst-case bound for Thompson Sampling in the\ncombinatorial setting. Finally, we introduce a novel link between Bayesian\nagents and frequentist confidence intervals. Combining these ideas we show that\nthe classical multi-armed bandit first-order regret bound $\\tilde{O}(\\sqrt{d\nL^*})$ still holds true in the more challenging and more general semi-bandit\nscenario. This latter result improves the previous state of the art bound\n$\\tilde{O}(\\sqrt{(d+m^3)L^*})$ by Lykouris, Sridharan and Tardos.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 10:05:54 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 21:39:12 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Sellke", "Mark", ""]]}, {"id": "1902.00693", "submitter": "Santiago Mazuelas", "authors": "Santiago Mazuelas and Andrea Zanoni and Aritz Perez", "title": "Supervised classification via minimax probabilistic transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional techniques for supervised classification constrain the\nclassification rules considered and use surrogate losses for classification 0-1\nloss. Favored families of classification rules are those that enjoy parametric\nrepresentations suitable for surrogate loss minimization, and low complexity\nproperties suitable for overfitting control. This paper presents classification\ntechniques based on robust risk minimization (RRM) that we call linear\nprobabilistic classifiers (LPCs). The proposed techniques consider\nunconstrained classification rules, optimize the classification 0-1 loss, and\nprovide performance bounds during learning. LPCs enable efficient learning by\nusing linear optimization, and avoid overffiting by using RRM over polyhedral\nuncertainty sets of distributions. We also provide finite-sample generalization\nbounds for LPCs and show their competitive performance with state-of-the-art\ntechniques using benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 11:15:56 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 09:52:21 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 00:44:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Mazuelas", "Santiago", ""], ["Zanoni", "Andrea", ""], ["Perez", "Aritz", ""]]}, {"id": "1902.00715", "submitter": "Yu Lei", "authors": "Yu Lei, Wenjie Li", "title": "When Collaborative Filtering Meets Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a multi-step interactive recommendation problem,\nwhere the item recommended at current step may affect the quality of future\nrecommendations. To address the problem, we develop a novel and effective\napproach, named CFRL, which seamlessly integrates the ideas of both\ncollaborative filtering (CF) and reinforcement learning (RL). More\nspecifically, we first model the recommender-user interactive recommendation\nproblem as an agent-environment RL task, which is mathematically described by a\nMarkov decision process (MDP). Further, to achieve collaborative\nrecommendations for the entire user community, we propose a novel CF-based MDP\nby encoding the states of all users into a shared latent vector space. Finally,\nwe propose an effective Q-network learning method to learn the agent's optimal\npolicy based on the CF-based MDP. The capability of CFRL is demonstrated by\ncomparing its performance against a variety of existing methods on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:22:35 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 14:45:32 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Lei", "Yu", ""], ["Li", "Wenjie", ""]]}, {"id": "1902.00719", "submitter": "Miguel Alonso Jr", "authors": "Miguel Alonso Jr", "title": "Learning User Preferences via Reinforcement Learning with Spatial\n  Interface Valuing", "comments": "Submitted to HCI International 2019 Parallel Session on Spatial\n  Interaction for Universal Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Machine Learning is concerned with creating systems that operate\nin environments alongside humans to achieve a task. A typical use is to extend\nor amplify the capabilities of a human in cognitive or physical ways, requiring\nthe machine to adapt to the users' intentions and preferences. Often, this\ntakes the form of a human operator providing some type of feedback to the user,\nwhich can be explicit feedback, implicit feedback, or a combination of both.\nExplicit feedback, such as through a mouse click, carries a high cognitive\nload. The focus of this study is to extend the current state of the art in\ninteractive machine learning by demonstrating that agents can learn a human\nuser's behavior and adapt to preferences with a reduced amount of explicit\nhuman feedback in a mixed feedback setting. The learning agent perceives a\nvalue of its own behavior from hand gestures given via a spatial interface.\nThis feedback mechanism is termed Spatial Interface Valuing. This method is\nevaluated experimentally in a simulated environment for a grasping task using a\nrobotic arm with variable grip settings. Preliminary results indicate that\nlearning agents using spatial interface valuing can learn a value function\nmapping spatial gestures to expected future rewards much more quickly as\ncompared to those same agents just receiving explicit feedback, demonstrating\nthat an agent perceiving feedback from a human user via a spatial interface can\nserve as an effective complement to existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:45:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Alonso", "Miguel", "Jr"]]}, {"id": "1902.00743", "submitter": "Linghao Song", "authors": "Linghao Song, Fan Chen, Steven R. Young, Catherine D. Schuman, Gabriel\n  Perdue, Thomas E. Potok", "title": "Deep Learning for Vertex Reconstruction of Neutrino-Nucleus Interaction\n  Events with Combined Energy and Time Data", "comments": "To appear in 2019 International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning approach for vertex reconstruction of\nneutrino-nucleus interaction events, a problem in the domain of high energy\nphysics. In this approach, we combine both energy and timing data that are\ncollected in the MINERvA detector to perform classification and regression\ntasks. We show that the resulting network achieves higher accuracy than\nprevious results while requiring a smaller model size and less training time.\nIn particular, the proposed model outperforms the state-of-the-art by 4.00% on\nclassification accuracy. For the regression task, our model achieves 0.9919 on\nthe coefficient of determination, higher than the previous work (0.96).\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:13:37 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Song", "Linghao", ""], ["Chen", "Fan", ""], ["Young", "Steven R.", ""], ["Schuman", "Catherine D.", ""], ["Perdue", "Gabriel", ""], ["Potok", "Thomas E.", ""]]}, {"id": "1902.00744", "submitter": "Haowei He", "authors": "Haowei He, Gao Huang and Yang Yuan", "title": "Asymmetric Valleys: Beyond Sharp and Flat Local Minima", "comments": "submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the non-convex nature of their loss functions, deep neural networks\nare known to generalize well when optimized with stochastic gradient descent\n(SGD). Recent work conjectures that SGD with proper configuration is able to\nfind wide and flat local minima, which have been proposed to be associated with\ngood generalization performance. In this paper, we observe that local minima of\nmodern deep networks are more than being flat or sharp. Specifically, at a\nlocal minimum there exist many asymmetric directions such that the loss\nincreases abruptly along one side, and slowly along the opposite side--we\nformally define such minima as asymmetric valleys. Under mild assumptions, we\nprove that for asymmetric valleys, a solution biased towards the flat side\ngeneralizes better than the exact minimizer. Further, we show that simply\naveraging the weights along the SGD trajectory gives rise to such biased\nsolutions implicitly. This provides a theoretical explanation for the\nintriguing phenomenon observed by Izmailov et al. (2018). In addition, we\nempirically find that batch normalization (BN) appears to be a major cause for\nasymmetric valleys.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:14:52 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 01:58:12 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["He", "Haowei", ""], ["Huang", "Gao", ""], ["Yuan", "Yang", ""]]}, {"id": "1902.00746", "submitter": "Jaehyeok Shin", "authors": "Jaehyeok Shin, Aaditya Ramdas, Alessandro Rinaldo", "title": "On the bias, risk and consistency of sample means in multi-armed bandits", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample mean is among the most well studied estimators in statistics,\nhaving many desirable properties such as unbiasedness and consistency. However,\nwhen analyzing data collected using a multi-armed bandit (MAB) experiment, the\nsample mean is biased and much remains to be understood about its properties.\nFor example, when is it consistent, how large is its bias, and can we bound its\nmean squared error? This paper delivers a thorough and systematic treatment of\nthe bias, risk and consistency of MAB sample means. Specifically, we identify\nfour distinct sources of selection bias (sampling, stopping, choosing and\nrewinding) and analyze them both separately and together. We further\ndemonstrate that a new notion of \\emph{effective sample size} can be used to\nbound the risk of the sample mean under suitable loss functions. We present\nseveral carefully designed examples to provide intuition on the different\nsources of selection bias we study. Our treatment is nonparametric and\nalgorithm-agnostic, meaning that it is not tied to a specific algorithm or\ngoal. In a nutshell, our proofs combine variational representations of\ninformation-theoretic divergences with new martingale concentration\ninequalities.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:23:08 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:11:31 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 03:41:45 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Shin", "Jaehyeok", ""], ["Ramdas", "Aaditya", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1902.00751", "submitter": "Neil Houlsby", "authors": "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone,\n  Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, Sylvain Gelly", "title": "Parameter-Efficient Transfer Learning for NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning large pre-trained models is an effective transfer mechanism in\nNLP. However, in the presence of many downstream tasks, fine-tuning is\nparameter inefficient: an entire new model is required for every task. As an\nalternative, we propose transfer with adapter modules. Adapter modules yield a\ncompact and extensible model; they add only a few trainable parameters per\ntask, and new tasks can be added without revisiting previous ones. The\nparameters of the original network remain fixed, yielding a high degree of\nparameter sharing. To demonstrate adapter's effectiveness, we transfer the\nrecently proposed BERT Transformer model to 26 diverse text classification\ntasks, including the GLUE benchmark. Adapters attain near state-of-the-art\nperformance, whilst adding only a few parameters per task. On GLUE, we attain\nwithin 0.4% of the performance of full fine-tuning, adding only 3.6% parameters\nper task. By contrast, fine-tuning trains 100% of the parameters per task.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 16:29:47 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 17:48:30 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Houlsby", "Neil", ""], ["Giurgiu", "Andrei", ""], ["Jastrzebski", "Stanislaw", ""], ["Morrone", "Bruna", ""], ["de Laroussilhe", "Quentin", ""], ["Gesmundo", "Andrea", ""], ["Attariyan", "Mona", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1902.00768", "submitter": "Ross Boczar", "authors": "Max Simchowitz, Ross Boczar, Benjamin Recht", "title": "Learning Linear Dynamical Systems with Semi-Parametric Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a simple prefiltered variation of the least squares estimator for\nthe problem of estimation with biased, semi-parametric noise, an error model\nstudied more broadly in causal statistics and active learning. We prove an\noracle inequality which demonstrates that this procedure provably mitigates the\nvariance introduced by long-term dependencies. We then demonstrate that\nprefiltered least squares yields, to our knowledge, the first algorithm that\nprovably estimates the parameters of partially-observed linear systems that\nattains rates which do not not incur a worst-case dependence on the rate at\nwhich these dependencies decay. The algorithm is provably consistent even for\nsystems which satisfy the weaker marginal stability condition obeyed by many\nclassical models based on Newtonian mechanics. In this context, our\nsemi-parametric framework yields guarantees for both stochastic and worst-case\nnoise.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 19:06:28 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Simchowitz", "Max", ""], ["Boczar", "Ross", ""], ["Recht", "Benjamin", ""]]}, {"id": "1902.00773", "submitter": "Ioannis Rafail Christoforidis", "authors": "Giannis Christoforidis, Pavlos Kefalas, Apostolos N. Papadopoulos and\n  Yannis Manolopoulos", "title": "RELINE: Point-of-Interest Recommendations using Multiple Network\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of users' involvement in Location-Based Social Networks\n(LBSNs) has led to the expeditious growth of the data on a global scale. The\nneed of accessing and retrieving relevant information close to users'\npreferences is an open problem which continuously raises new challenges for\nrecommendation systems. The exploitation of Points-of-Interest (POIs)\nrecommendation by existing models is inadequate due to the sparsity and the\ncold start problems. To overcome these problems many models were proposed in\nthe literature, but most of them ignore important factors such as: geographical\nproximity, social influence, or temporal and preference dynamics, which tackle\ntheir accuracy while personalize their recommendations. In this work, we\ninvestigate these problems and present a unified model that jointly learns\nusers and POI dynamics. Our proposal is termed RELINE (REcommendations with\nmuLtIple Network Embeddings). More specifically, RELINE captures: i) the\nsocial, ii) the geographical, iii) the temporal influence, and iv) the users'\npreference dynamics, by embedding eight relational graphs into one shared\nlatent space. We have evaluated our approach against state-of-the-art methods\nwith three large real-world datasets in terms of accuracy. Additionally, we\nhave examined the effectiveness of our approach against the cold-start problem.\nPerformance evaluation results demonstrate that significant performance\nimprovement is achieved in comparison to existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 19:31:48 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Christoforidis", "Giannis", ""], ["Kefalas", "Pavlos", ""], ["Papadopoulos", "Apostolos N.", ""], ["Manolopoulos", "Yannis", ""]]}, {"id": "1902.00778", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Certified Reinforcement Learning with Logic Guidance", "comments": "This article draws from arXiv:1801.08099, arXiv:1809.07823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first model-free Reinforcement Learning (RL)\nframework to synthesise policies for unknown, and continuous-state Markov\nDecision Processes (MDPs), such that a given linear temporal property is\nsatisfied. We convert the given property into a Limit Deterministic Buchi\nAutomaton (LDBA), namely a finite-state machine expressing the property.\nExploiting the structure of the LDBA, we shape a synchronous reward function\non-the-fly, so that an RL algorithm can synthesise a policy resulting in traces\nthat probabilistically satisfy the linear temporal property. This probability\n(certificate) is also calculated in parallel with policy learning when the\nstate space of the MDP is finite: as such, the RL algorithm produces a policy\nthat is certified with respect to the property. Under the assumption of finite\nstate space, theoretical guarantees are provided on the convergence of the RL\nalgorithm to an optimal policy, maximising the above probability. We also show\nthat our method produces ''best available'' control policies when the logical\nproperty cannot be satisfied. In the general case of a continuous state space,\nwe propose a neural network architecture for RL and we empirically show that\nthe algorithm finds satisfying policies, if there exist such policies. The\nperformance of the proposed framework is evaluated via a set of numerical\nexamples and benchmarks, where we observe an improvement of one order of\nmagnitude in the number of iterations required for the policy synthesis,\ncompared to existing approaches whenever available.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 20:09:32 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 00:13:32 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 11:09:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1902.00792", "submitter": "Tomasz Ku\\'smierczyk", "authors": "Tomasz Ku\\'smierczyk, Joseph Sakaya, Arto Klami", "title": "Variational Bayesian Decision-making for Continuous Utilities", "comments": "Appearing at Neural Information Processing Systems 32 (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian decision theory outlines a rigorous framework for making optimal\ndecisions based on maximizing expected utility over a model posterior. However,\npractitioners often do not have access to the full posterior and resort to\napproximate inference strategies. In such cases, taking the eventual\ndecision-making task into account while performing the inference allows for\ncalibrating the posterior approximation to maximize the utility. We present an\nautomatic pipeline that co-opts continuous utilities into variational inference\nalgorithms to account for decision-making. We provide practical strategies for\napproximating and maximizing the gain, and empirically demonstrate consistent\nimprovement when calibrating approximations for specific utilities.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 20:59:36 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 15:58:52 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 16:21:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ku\u015bmierczyk", "Tomasz", ""], ["Sakaya", "Joseph", ""], ["Klami", "Arto", ""]]}, {"id": "1902.00800", "submitter": "Jason Klusowski M", "authors": "Andrew R. Barron, Jason M. Klusowski", "title": "Complexity, Statistical Risk, and Metric Entropy of Deep Nets Using\n  Total Path Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any ReLU network there is a representation in which the sum of the\nabsolute values of the weights into each node is exactly $1$, and the input\nlayer variables are multiplied by a value $V$ coinciding with the total\nvariation of the path weights. Implications are given for Gaussian complexity,\nRademacher complexity, statistical risk, and metric entropy, all of which are\nshown to be proportional to $V$. There is no dependence on the number of nodes\nper layer, except for the number of inputs $d$. For estimation with\nsub-Gaussian noise, the mean square generalization error bounds that can be\nobtained are of order $V \\sqrt{L + \\log d}/\\sqrt{n}$, where $L$ is the number\nof layers and $n$ is the sample size.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 21:41:49 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 20:16:55 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Barron", "Andrew R.", ""], ["Klusowski", "Jason M.", ""]]}, {"id": "1902.00813", "submitter": "Yuejiang Liu", "authors": "Yuejiang Liu, Parth Kothari, Alexandre Alahi", "title": "Collaborative Sampling in Generative Adversarial Networks", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard practice in Generative Adversarial Networks (GANs) discards the\ndiscriminator during sampling. However, this sampling method loses valuable\ninformation learned by the discriminator regarding the data distribution. In\nthis work, we propose a collaborative sampling scheme between the generator and\nthe discriminator for improved data generation. Guided by the discriminator,\nour approach refines the generated samples through gradient-based updates at a\nparticular layer of the generator, shifting the generator distribution closer\nto the real data distribution. Additionally, we present a practical\ndiscriminator shaping method that can smoothen the loss landscape provided by\nthe discriminator for effective sample refinement. Through extensive\nexperiments on synthetic and image datasets, we demonstrate that our proposed\nmethod can improve generated samples both quantitatively and qualitatively,\noffering a new degree of freedom in GAN sampling.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 23:43:25 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 12:18:25 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 15:54:24 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liu", "Yuejiang", ""], ["Kothari", "Parth", ""], ["Alahi", "Alexandre", ""]]}, {"id": "1902.00814", "submitter": "Andr\\'as Gily\\'en", "authors": "Andr\\'as Gily\\'en and Tongyang Li", "title": "Distributional property testing in a quantum world", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in statistics and learning theory is to test properties\nof distributions. We show that quantum computers can solve such problems with\nsignificant speed-ups. In particular, we give fast quantum algorithms for\ntesting closeness between unknown distributions, testing independence between\ntwo distributions, and estimating the Shannon / von Neumann entropy of\ndistributions. The distributions can be either classical or quantum, however\nour quantum algorithms require coherent quantum access to a process preparing\nthe samples. Our results build on the recent technique of quantum singular\nvalue transformation, combined with more standard tricks such as\ndivide-and-conquer. The presented approach is a natural fit for distributional\nproperty testing both in the classical and the quantum case, demonstrating the\nfirst speed-ups for testing properties of density operators that can be\naccessed coherently rather than only via sampling; for classical distributions\nour algorithms significantly improve the precision dependence of some earlier\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 23:43:53 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Gily\u00e9n", "Andr\u00e1s", ""], ["Li", "Tongyang", ""]]}, {"id": "1902.00819", "submitter": "Sakshi Arya", "authors": "Sakshi Arya, Yuhong Yang", "title": "Randomized Allocation with Nonparametric Estimation for Contextual\n  Multi-Armed Bandits with Delayed Rewards", "comments": "Added simulations and some minor typographical changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-armed bandit problem with covariates in a setting where\nthere is a possible delay in observing the rewards. Under some mild assumptions\non the probability distributions for the delays and using an appropriate\nrandomization to select the arms, the proposed strategy is shown to be strongly\nconsistent.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 00:05:17 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 02:21:54 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 22:28:58 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Arya", "Sakshi", ""], ["Yang", "Yuhong", ""]]}, {"id": "1902.00829", "submitter": "Jonghyun Choi", "authors": "Dahyun Kim, Jihwan Bae, Yeonsik Jo, Jonghyun Choi", "title": "Incremental Learning with Maximum Entropy Regularization: Rethinking\n  Forgetting and Intransigence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Incremental learning suffers from two challenging problems; forgetting of old\nknowledge and intransigence on learning new knowledge. Prediction by the model\nincrementally learned with a subset of the dataset are thus uncertain and the\nuncertainty accumulates through the tasks by knowledge transfer. To prevent\noverfitting to the uncertain knowledge, we propose to penalize confident\nfitting to the uncertain knowledge by the Maximum Entropy Regularizer (MER).\nAdditionally, to reduce class imbalance and induce a self-paced curriculum on\nnew classes, we exclude a few samples from the new classes in every mini-batch,\nwhich we call DropOut Sampling (DOS). We further rethink evaluation metrics for\nforgetting and intransigence in incremental learning by tracking each sample's\nconfusion at the transition of a task since the existing metrics that compute\nthe difference in accuracy are often misleading. We show that the proposed\nmethod, named 'MEDIC', outperforms the state-of-the-art incremental learning\nalgorithms in accuracy, forgetting, and intransigence measured by both the\nexisting and the proposed metrics by a large margin in extensive empirical\nvalidations on CIFAR100 and a popular subset of ImageNet dataset\n(TinyImageNet).\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 02:09:26 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kim", "Dahyun", ""], ["Bae", "Jihwan", ""], ["Jo", "Yeonsik", ""], ["Choi", "Jonghyun", ""]]}, {"id": "1902.00832", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Peter L. Bartlett, Michael I. Jordan", "title": "Quantitative Weak Convergence for Discrete Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we quantitative convergence in $W_2$ for a family of\nLangevin-like stochastic processes that includes stochastic gradient descent\nand related gradient-based algorithms. Under certain regularity assumptions, we\nshow that the iterates of these stochastic processes converge to an invariant\ndistribution at a rate of $\\tilde{O}\\lrp{1/\\sqrt{k}}$ where $k$ is the number\nof steps; this rate is provably tight up to log factors. Our result reduces to\na quantitative form of the classical Central Limit Theorem in the special case\nwhen the potential is quadratic.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 02:42:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 05:50:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Cheng", "Xiang", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.00843", "submitter": "Francisco Garcia", "authors": "Francisco M. Garcia and Philip S. Thomas", "title": "A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning", "comments": "Accepted as Extended Abstract, AAMAS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of how a reinforcement learning agent\nthat is tasked with solving a sequence of reinforcement learning problems (a\nsequence of Markov decision processes) can use knowledge acquired early in its\nlifetime to improve its ability to solve new problems. We argue that previous\nexperience with similar problems can provide an agent with information about\nhow it should explore when facing a new but related problem. We show that the\nsearch for an optimal exploration strategy can be formulated as a reinforcement\nlearning problem itself and demonstrate that such strategy can leverage\npatterns found in the structure of related problems. We conclude with\nexperiments that show the benefits of optimizing an exploration strategy using\nour proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 04:44:11 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Garcia", "Francisco M.", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1902.00851", "submitter": "Changhua Pei", "authors": "Changhua Pei, Xinru Yang, Qing Cui, Xiao Lin, Fei Sun, Peng Jiang,\n  Wenwu Ou and Yongfeng Zhang", "title": "Value-aware Recommendation based on Reinforced Profit Maximization in\n  E-commerce Systems", "comments": "to appear at the webconf 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing recommendation algorithms mostly focus on optimizing traditional\nrecommendation measures, such as the accuracy of rating prediction in terms of\nRMSE or the quality of top-$k$ recommendation lists in terms of precision,\nrecall, MAP, etc. However, an important expectation for commercial\nrecommendation systems is to improve the final revenue/profit of the system.\nTraditional recommendation targets such as rating prediction and top-$k$\nrecommendation are not directly related to this goal. In this work, we blend\nthe fundamental concepts in online advertising and micro-economics into\npersonalized recommendation for profit maximization. Specifically, we propose\nvalue-aware recommendation based on reinforcement learning, which directly\noptimizes the economic value of candidate items to generate the recommendation\nlist. In particular, we generalize the basic concept of click conversion rate\n(CVR) in computational advertising into the conversation rate of an arbitrary\nuser action (XVR) in E-commerce, where the user actions can be clicking, adding\nto cart, adding to wishlist, etc. In this way, each type of user action is\nmapped to its monetized economic value. Economic values of different user\nactions are further integrated as the reward of a ranking list, and\nreinforcement learning is used to optimize the recommendation list for the\nmaximum total value. Experimental results in both offline benchmarks and online\ncommercial systems verified the improved performance of our framework, in terms\nof both traditional top-$k$ ranking tasks and the economic profits of the\nsystem.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 05:34:36 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Pei", "Changhua", ""], ["Yang", "Xinru", ""], ["Cui", "Qing", ""], ["Lin", "Xiao", ""], ["Sun", "Fei", ""], ["Jiang", "Peng", ""], ["Ou", "Wenwu", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1902.00869", "submitter": "Min-Hsiu Hsieh", "authors": "Ximing Wang and Yuechi Ma and Min-Hsiu Hsieh and Manhong Yung", "title": "Quantum Speedup in Adaptive Boosting of Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical machine learning, a set of weak classifiers can be adaptively\ncombined to form a strong classifier for improving the overall performance, a\ntechnique called adaptive boosting (or AdaBoost). However, constructing the\nstrong classifier for a large data set is typically resource consuming. Here we\npropose a quantum extension of AdaBoost, demonstrating a quantum algorithm that\ncan output the optimal strong classifier with a quadratic speedup in the number\nof queries of the weak classifiers. Our results also include a generalization\nof the standard AdaBoost to the cases where the output of each classifier may\nbe probabilistic even for the same input. We prove that the update rules and\nthe query complexity of the non-deterministic classifiers are the same as those\nof deterministic classifiers, which may be of independent interest to the\nclassical machine-learning community. Furthermore, the AdaBoost algorithm can\nalso be applied to data encoded in the form of quantum states; we show how the\ntraining set can be simplified by using the tools of t-design. Our approach\ndescribes a model of quantum machine learning where quantum speedup is achieved\nin finding the optimal classifier, which can then be applied for classical\nmachine-learning applications.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 10:22:33 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wang", "Ximing", ""], ["Ma", "Yuechi", ""], ["Hsieh", "Min-Hsiu", ""], ["Yung", "Manhong", ""]]}, {"id": "1902.00873", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Jiahui Yu, Xingjian Li, Jun Huan, Thomas S. Huang", "title": "An Empirical Study on Regularization of Deep Neural Networks by Local\n  Rademacher Complexity", "comments": "Updated the link to the open source PaddlePaddle code of LRC\n  Regularization as well as the author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization of Deep Neural Networks (DNNs) for the sake of improving their\ngeneralization capability is important and challenging. The development in this\nline benefits theoretical foundation of DNNs and promotes their usability in\ndifferent areas of artificial intelligence. In this paper, we investigate the\nrole of Rademacher complexity in improving generalization of DNNs and propose a\nnovel regularizer rooted in Local Rademacher Complexity (LRC). While Rademacher\ncomplexity is well known as a distribution-free complexity measure of function\nclass that help boost generalization of statistical learning methods, extensive\nstudy shows that LRC, its counterpart focusing on a restricted function class,\nleads to sharper convergence rates and potential better generalization given\nfinite training sample. Our LRC based regularizer is developed by estimating\nthe complexity of the function class centered at the minimizer of the empirical\nloss of DNNs. Experiments on various types of network architecture demonstrate\nthe effectiveness of LRC regularization in improving generalization. Moreover,\nour method features the state-of-the-art result on the CIFAR-$10$ dataset with\nnetwork architecture found by neural architecture search.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 10:37:25 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 00:42:51 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 16:02:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yang", "Yingzhen", ""], ["Yu", "Jiahui", ""], ["Li", "Xingjian", ""], ["Huan", "Jun", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1902.00898", "submitter": "Yanjie Wang", "authors": "Yanjie Wang, Samuel Broscheit, Rainer Gemulla", "title": "A Relational Tucker Decomposition for Multi-Relational Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Relational Tucker3 (RT) decomposition for multi-relational\nlink prediction in knowledge graphs. We show that many existing knowledge graph\nembedding models are special cases of the RT decomposition with certain\npredefined sparsity patterns in its components. In contrast to these prior\nmodels, RT decouples the sizes of entity and relation embeddings, allows\nparameter sharing across relations, and does not make use of a predefined\nsparsity pattern. We use the RT decomposition as a tool to explore whether it\nis possible and beneficial to automatically learn sparsity patterns, and\nwhether dense models can outperform sparse models (using the same number of\nparameters). Our experiments indicate that---depending on the dataset--both\nquestions can be answered affirmatively.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 14:09:39 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wang", "Yanjie", ""], ["Broscheit", "Samuel", ""], ["Gemulla", "Rainer", ""]]}, {"id": "1902.00908", "submitter": "Yunwen Lei", "authors": "Yunwen Lei, Ting Hu, Guiying Li and Ke Tang", "title": "Stochastic Gradient Descent for Nonconvex Learning without Bounded\n  Gradient Assumptions", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning\n  Systems. DOI: 10.1109/TNNLS.2019.2952219", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is a popular and efficient method with wide\napplications in training deep neural nets and other nonconvex models. While the\nbehavior of SGD is well understood in the convex learning setting, the existing\ntheoretical results for SGD applied to nonconvex objective functions are far\nfrom mature. For example, existing results require to impose a nontrivial\nassumption on the uniform boundedness of gradients for all iterates encountered\nin the learning process, which is hard to verify in practical implementations.\nIn this paper, we establish a rigorous theoretical foundation for SGD in\nnonconvex learning by showing that this boundedness assumption can be removed\nwithout affecting convergence rates. In particular, we establish sufficient\nconditions for almost sure convergence as well as optimal convergence rates for\nSGD applied to both general nonconvex objective functions and\ngradient-dominated objective functions. A linear convergence is further derived\nin the case with zero variances.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 15:18:11 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 07:27:22 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 05:26:34 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Lei", "Yunwen", ""], ["Hu", "Ting", ""], ["Li", "Guiying", ""], ["Tang", "Ke", ""]]}, {"id": "1902.00923", "submitter": "Lei Ying", "authors": "R. Srikant and Lei Ying", "title": "Finite-Time Error Bounds For Linear Stochastic Approximation and TD\n  Learning", "comments": "Fixed a few minor typos and added a reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamics of a linear stochastic approximation algorithm\ndriven by Markovian noise, and derive finite-time bounds on the moments of the\nerror, i.e., deviation of the output of the algorithm from the equilibrium\npoint of an associated ordinary differential equation (ODE). We obtain\nfinite-time bounds on the mean-square error in the case of constant step-size\nalgorithms by considering the drift of an appropriately chosen Lyapunov\nfunction. The Lyapunov function can be interpreted either in terms of Stein's\nmethod to obtain bounds on steady-state performance or in terms of Lyapunov\nstability theory for linear ODEs. We also provide a comprehensive treatment of\nthe moments of the square of the 2-norm of the approximation error. Our\nanalysis yields the following results: (i) for a given step-size, we show that\nthe lower-order moments can be made small as a function of the step-size and\ncan be upper-bounded by the moments of a Gaussian random variable; (ii) we show\nthat the higher-order moments beyond a threshold may be infinite in\nsteady-state; and (iii) we characterize the number of samples needed for the\nfinite-time bounds to be of the same order as the steady-state bounds. As a\nby-product of our analysis, we also solve the open problem of obtaining\nfinite-time bounds for the performance of temporal difference learning\nalgorithms with linear function approximation and a constant step-size, without\nrequiring a projection step or an i.i.d. noise assumption.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:41:49 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 19:54:18 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 19:07:59 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Srikant", "R.", ""], ["Ying", "Lei", ""]]}, {"id": "1902.00925", "submitter": "Alpha Albert Lee", "authors": "Yao Zhang and Alpha A. Lee", "title": "Bayesian semi-supervised learning for uncertainty-calibrated prediction\n  of molecular properties and active learning", "comments": "Chemical Science, in press", "journal-ref": null, "doi": "10.1039/C9SC00616H", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting bioactivity and physical properties of small molecules is a\ncentral challenge in drug discovery. Deep learning is becoming the method of\nchoice but studies to date focus on mean accuracy as the main metric. However,\nto replace costly and mission-critical experiments by models, a high mean\naccuracy is not enough: Outliers can derail a discovery campaign, thus models\nneed reliably predict when it will fail, even when the training data is biased;\nexperiments are expensive, thus models need to be data-efficient and suggest\ninformative training sets using active learning. We show that uncertainty\nquantification and active learning can be achieved by Bayesian semi-supervised\ngraph convolutional neural networks. The Bayesian approach estimates\nuncertainty in a statistically principled way through sampling from the\nposterior distribution. Semi-supervised learning disentangles representation\nlearning and regression, keeping uncertainty estimates accurate in the low data\nlimit and allowing the model to start active learning from a small initial pool\nof training data. Our study highlights the promise of Bayesian deep learning\nfor chemistry.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:52:50 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 09:33:40 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zhang", "Yao", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1902.00941", "submitter": "Andreas Ekstrom", "authors": "A. Ekstr\\\"om, C. Forss\\'en, C. Dimitrakakis, D. Dubhashi, H. T.\n  Johansson, A. S. Muhammad, H. Salomonsson, A. Schliep", "title": "Bayesian optimization in ab initio nuclear physics", "comments": "33 pages, 14 figures", "journal-ref": null, "doi": "10.1088/1361-6471/ab2b14", "report-no": null, "categories": "nucl-th cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical models of the strong nuclear interaction contain unknown coupling\nconstants (parameters) that must be determined using a pool of calibration\ndata. In cases where the models are complex, leading to time consuming\ncalculations, it is particularly challenging to systematically search the\ncorresponding parameter domain for the best fit to the data. In this paper, we\nexplore the prospect of applying Bayesian optimization to constrain the\ncoupling constants in chiral effective field theory descriptions of the nuclear\ninteraction. We find that Bayesian optimization performs rather well with\nlow-dimensional parameter domains and foresee that it can be particularly\nuseful for optimization of a smaller set of coupling constants. A specific\nexample could be the determination of leading three-nucleon forces using data\nfrom finite nuclei or three-nucleon scattering experiments.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 18:07:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ekstr\u00f6m", "A.", ""], ["Forss\u00e9n", "C.", ""], ["Dimitrakakis", "C.", ""], ["Dubhashi", "D.", ""], ["Johansson", "H. T.", ""], ["Muhammad", "A. S.", ""], ["Salomonsson", "H.", ""], ["Schliep", "A.", ""]]}, {"id": "1902.00947", "submitter": "Adrien B. Taylor", "authors": "Adrien Taylor, Francis Bach", "title": "Stochastic first-order methods: non-asymptotic and computer-aided\n  analyses via potential functions", "comments": "Accepted to COLT2019; 12 pages + appendix; code available at\n  https://github.com/AdrienTaylor/Potential-functions-for-first-order-methods.\n  [V5: typos & minor improvements to appendix E.4]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel computer-assisted technique for systematically analyzing\nfirst-order methods for optimization. In contrast with previous works, the\napproach is particularly suited for handling sublinear convergence rates and\nstochastic oracles. The technique relies on semidefinite programming and\npotential functions. It allows simultaneously obtaining worst-case guarantees\non the behavior of those algorithms, and assisting in choosing appropriate\nparameters for tuning their worst-case performances. The technique also\nbenefits from comfortable tightness guarantees, meaning that unsatisfactory\nresults can be improved only by changing the setting. We use the approach for\nanalyzing deterministic and stochastic first-order methods under different\nassumptions on the nature of the stochastic noise. Among others, we treat\nunstructured noise with bounded variance, different noise models arising in\nover-parametrized expectation minimization problems, and randomized\nblock-coordinate descent schemes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 18:22:33 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 09:52:08 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:26:54 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 18:46:42 GMT"}, {"version": "v5", "created": "Sun, 5 Apr 2020 16:26:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Taylor", "Adrien", ""], ["Bach", "Francis", ""]]}, {"id": "1902.00956", "submitter": "Sanna Wager C", "authors": "Sanna Wager, George Tzanetakis, Cheng-i Wang, Lijiang Guo, Aswin\n  Sivaraman, Minje Kim", "title": "Deep Autotuner: A Data-Driven Approach to Natural-Sounding Pitch\n  Correction for Singing Voice in Karaoke Performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a machine-learning approach to pitch correcting a solo singing\nperformance in a karaoke setting, where the solo voice and accompaniment are on\nseparate tracks. The proposed approach addresses the situation where no musical\nscore of the vocals nor the accompaniment exists: It predicts the amount of\ncorrection from the relationship between the spectral contents of the vocal and\naccompaniment tracks. Hence, the pitch shift in cents suggested by the model\ncan be used to make the voice sound in tune with the accompaniment. This\napproach differs from commercially used automatic pitch correction systems,\nwhere notes in the vocal tracks are shifted to be centered around notes in a\nuser-defined score or mapped to the closest pitch among the twelve\nequal-tempered scale degrees. We train the model using a dataset of 4,702\namateur karaoke performances selected for good intonation. We present a\nConvolutional Gated Recurrent Unit (CGRU) model to accomplish this task. This\nmethod can be extended into unsupervised pitch correction of a vocal\nperformance, popularly referred to as autotuning.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 19:05:24 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wager", "Sanna", ""], ["Tzanetakis", "George", ""], ["Wang", "Cheng-i", ""], ["Guo", "Lijiang", ""], ["Sivaraman", "Aswin", ""], ["Kim", "Minje", ""]]}, {"id": "1902.00980", "submitter": "Chen-Yu Wei", "authors": "Yifang Chen, Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei", "title": "A New Algorithm for Non-stationary Contextual Bandits: Efficient,\n  Optimal, and Parameter-free", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first contextual bandit algorithm that is parameter-free,\nefficient, and optimal in terms of dynamic regret. Specifically, our algorithm\nachieves dynamic regret $\\mathcal{O}(\\min\\{\\sqrt{ST},\n\\Delta^{\\frac{1}{3}}T^{\\frac{2}{3}}\\})$ for a contextual bandit problem with\n$T$ rounds, $S$ switches and $\\Delta$ total variation in data distributions.\nImportantly, our algorithm is adaptive and does not need to know $S$ or\n$\\Delta$ ahead of time, and can be implemented efficiently assuming access to\nan ERM oracle.\n  Our results strictly improve the $\\mathcal{O}(\\min\n\\{S^{\\frac{1}{4}}T^{\\frac{3}{4}}, \\Delta^{\\frac{1}{5}}T^{\\frac{4}{5}}\\})$ bound\nof (Luo et al., 2018), and greatly generalize and improve the\n$\\mathcal{O}(\\sqrt{ST})$ result of (Auer et al, 2018) that holds only for the\ntwo-armed bandit problem without contextual information. The key novelty of our\nalgorithm is to introduce replay phases, in which the algorithm acts according\nto its previous decisions for a certain amount of time in order to detect\nnon-stationarity while maintaining a good balance between exploration and\nexploitation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 22:25:26 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 06:51:37 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 05:01:03 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Chen", "Yifang", ""], ["Lee", "Chung-Wei", ""], ["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""]]}, {"id": "1902.00981", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Lorenz Linhardt, Stefan Bauer, Joachim M. Buhmann,\n  Walter Karlen", "title": "Learning Counterfactual Representations for Estimating Individual\n  Dose-Response Curves", "comments": "published at AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i04.6014", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating what would be an individual's potential response to varying levels\nof exposure to a treatment is of high practical relevance for several important\nfields, such as healthcare, economics and public policy. However, existing\nmethods for learning to estimate counterfactual outcomes from observational\ndata are either focused on estimating average dose-response curves, or limited\nto settings with only two treatments that do not have an associated dosage\nparameter. Here, we present a novel machine-learning approach towards learning\ncounterfactual representations for estimating individual dose-response curves\nfor any number of treatments with continuous dosage parameters with neural\nnetworks. Building on the established potential outcomes framework, we\nintroduce performance metrics, model selection criteria, model architectures,\nand open benchmarks for estimating individual dose-response curves. Our\nexperiments show that the methods developed in this work set a new\nstate-of-the-art in estimating individual dose-response.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 22:26:50 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 13:21:39 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 10:56:20 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Schwab", "Patrick", ""], ["Linhardt", "Lorenz", ""], ["Bauer", "Stefan", ""], ["Buhmann", "Joachim M.", ""], ["Karlen", "Walter", ""]]}, {"id": "1902.00985", "submitter": "Hisham Husain", "authors": "Hisham Husain, Richard Nock, Robert C. Williamson", "title": "Adversarial Networks and Autoencoders: The Primal-Dual Relationship and\n  Generalization Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction of Generative Adversarial Networks (GANs) and\nVariational Autoencoders (VAE), the literature on generative modelling has\nwitnessed an overwhelming resurgence. The impressive, yet elusive empirical\nperformance of GANs has lead to the rise of many GAN-VAE hybrids, with the\nhopes of GAN level performance and additional benefits of VAE, such as an\nencoder for feature reduction, which is not offered by GANs. Recently, the\nWasserstein Autoencoder (WAE) was proposed, achieving performance similar to\nthat of GANs, yet it is still unclear whether the two are fundamentally\ndifferent or can be further improved into a unified model. In this work, we\nstudy the $f$-GAN and WAE models and make two main discoveries. First, we find\nthat the $f$-GAN and WAE objectives partake in a primal-dual relationship and\nare equivalent under some assumptions, which then allows us to explicate the\nsuccess of WAE. Second, the equivalence result allows us to, for the first\ntime, prove generalization bounds for Autoencoder models, which is a pertinent\nproblem when it comes to theoretical analyses of generative models.\nFurthermore, we show that the WAE objective is related to other statistical\nquantities such as the $f$-divergence and in particular, upper bounded by the\nWasserstein distance, which then allows us to tap into existing efficient\n(regularized) optimal transport solvers. Our findings thus present the first\nprimal-dual relationship between GANs and Autoencoder models, comment on\ngeneralization abilities and make a step towards unifying these models.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 22:56:18 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 08:51:29 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Husain", "Hisham", ""], ["Nock", "Richard", ""], ["Williamson", "Robert C.", ""]]}, {"id": "1902.00995", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Kenneth L. Clarkson, Michael W. Mahoney,\n  Manfred K. Warmuth", "title": "Minimax experimental design: Bridging the gap between statistical and\n  worst-case approaches to least squares regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In experimental design, we are given a large collection of vectors, each with\na hidden response value that we assume derives from an underlying linear model,\nand we wish to pick a small subset of the vectors such that querying the\ncorresponding responses will lead to a good estimator of the model. A classical\napproach in statistics is to assume the responses are linear, plus zero-mean\ni.i.d. Gaussian noise, in which case the goal is to provide an unbiased\nestimator with smallest mean squared error (A-optimal design). A related\napproach, more common in computer science, is to assume the responses are\narbitrary but fixed, in which case the goal is to estimate the least squares\nsolution using few responses, as quickly as possible, for worst-case inputs.\nDespite many attempts, characterizing the relationship between these two\napproaches has proven elusive. We address this by proposing a framework for\nexperimental design where the responses are produced by an arbitrary unknown\ndistribution. We show that there is an efficient randomized experimental design\nprocedure that achieves strong variance bounds for an unbiased estimator using\nfew responses in this general model. Nearly tight bounds for the classical\nA-optimality criterion, as well as improved bounds for worst-case responses,\nemerge as special cases of this result. In the process, we develop a new\nalgorithm for a joint sampling distribution called volume sampling, and we\npropose a new i.i.d. importance sampling method: inverse score sampling. A key\nnovelty of our analysis is in developing new expected error bounds for\nworst-case regression by controlling the tail behavior of i.i.d. sampling via\nthe jointness of volume sampling. Our result motivates a new minimax-optimality\ncriterion for experimental design which can be viewed as an extension of both\nA-optimal design and sampling for worst-case regression.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 00:16:32 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Clarkson", "Kenneth L.", ""], ["Mahoney", "Michael W.", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1902.00996", "submitter": "Yi-An Ma", "authors": "Yi-An Ma and Niladri Chatterji and Xiang Cheng and Nicolas Flammarion\n  and Peter Bartlett and Michael I. Jordan", "title": "Is There an Analog of Nesterov Acceleration for MCMC?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate gradient-based Markov chain Monte Carlo (MCMC) sampling as\noptimization on the space of probability measures, with Kullback-Leibler (KL)\ndivergence as the objective functional. We show that an underdamped form of the\nLangevin algorithm performs accelerated gradient descent in this metric. To\ncharacterize the convergence of the algorithm, we construct a Lyapunov\nfunctional and exploit hypocoercivity of the underdamped Langevin algorithm. As\nan application, we show that accelerated rates can be obtained for a class of\nnonconvex functions with the Langevin algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 00:22:32 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 05:55:37 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ma", "Yi-An", ""], ["Chatterji", "Niladri", ""], ["Cheng", "Xiang", ""], ["Flammarion", "Nicolas", ""], ["Bartlett", "Peter", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.01000", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Amirhossein Esmaili, Massoud Pedram", "title": "BottleNet: A Deep Learning Architecture for Intelligent Mobile Cloud\n  Computing Services", "comments": "arXiv admin note: text overlap with arXiv:1902.00147", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown the latency and energy consumption of deep neural\nnetworks can be significantly improved by splitting the network between the\nmobile device and cloud. This paper introduces a new deep learning\narchitecture, called BottleNet, for reducing the feature size needed to be sent\nto the cloud. Furthermore, we propose a training method for compensating for\nthe potential accuracy loss due to the lossy compression of features before\ntransmitting them to the cloud. BottleNet achieves on average 30x improvement\nin end-to-end latency and 40x improvement in mobile energy consumption compared\nto the cloud-only approach with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 01:15:41 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Esmaili", "Amirhossein", ""], ["Pedram", "Massoud", ""]]}, {"id": "1902.01005", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, H. Zhao, R. C. de Lamare, Y. Zakharov and L. Lu", "title": "Study of Robust Distributed Diffusion RLS Algorithms with Side\n  Information for Adaptive Networks", "comments": "15 figures, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops robust diffusion recursive least squares algorithms to\nmitigate the performance degradation often experienced in networks of agents in\nthe presence of impulsive noise. The first algorithm minimizes an exponentially\nweighted least-squares cost function subject to a time-dependent constraint on\nthe squared norm of the intermediate update at each node. A recursive strategy\nfor computing the constraint is proposed using side information from the\nneighboring nodes to further improve the robustness. We also analyze the\nmean-square convergence behavior of the proposed algorithm. The second proposed\nalgorithm is a modification of the first one based on the dichotomous\ncoordinate descent iterations. It has a performance similar to that of the\nformer, however its complexity is significantly lower especially when input\nregressors of agents have a shift structure and it is well suited to practical\nimplementation. Simulations show the superiority of the proposed algorithms\nover previously reported techniques in various impulsive noise scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 01:38:58 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yu", "Y.", ""], ["Zhao", "H.", ""], ["de Lamare", "R. C.", ""], ["Zakharov", "Y.", ""], ["Lu", "L.", ""]]}, {"id": "1902.01012", "submitter": "Jianbin Tang", "authors": "Subhrajit Roy, Umar Asif, Jianbin Tang, and Stefan Harrer", "title": "Seizure Type Classification using EEG signals and Machine Learning:\n  Setting a benchmark", "comments": "5 pages, 2 figure, 4 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate classification of seizure types plays a crucial role in the\ntreatment and disease management of epileptic patients. Epileptic seizure types\nnot only impact the choice of drugs but also the range of activities a patient\ncan safely engage in. With recent advances being made towards artificial\nintelligence enabled automatic seizure detection, the next frontier is the\nautomatic classification of seizure types. On that note, in this paper, we\nexplore the application of machine learning algorithms for multi-class seizure\ntype classification. We used the recently released TUH EEG seizure corpus\n(V1.4.0 and V1.5.2) and conducted a thorough search space exploration to\nevaluate the performance of a combination of various pre-processing techniques,\nmachine learning algorithms, and corresponding hyperparameters on this task. We\nshow that our algorithms can reach a weighted $F1$ score of up to 0.901 for\nseizure-wise cross validation and 0.561 for patient-wise cross validation\nthereby setting a benchmark for scalp EEG based multi-class seizure type\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 02:30:32 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 02:35:00 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Roy", "Subhrajit", ""], ["Asif", "Umar", ""], ["Tang", "Jianbin", ""], ["Harrer", "Stefan", ""]]}, {"id": "1902.01020", "submitter": "Katsuhiko Ishiguro", "authors": "Katsuhiko Ishiguro, Shin-ichi Maeda, and Masanori Koyama", "title": "Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph\n  Neural Networks in Molecular Graph Analysis", "comments": "Augmented experiments, title slightly modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) is a popular architecture for the analysis of\nchemical molecules, and it has numerous applications in material and medicinal\nscience. Current lines of GNNs developed for molecular analysis, however, do\nnot fit well on the training set, and their performance does not scale well\nwith the complexity of the network. In this paper, we propose an auxiliary\nmodule to be attached to a GNN that can boost the representation power of the\nmodel without hindering with the original GNN architecture. Our auxiliary\nmodule can be attached to a wide variety of GNNs, including those that are used\ncommonly in biochemical applications. With our auxiliary architecture, the\nperformances of many GNNs used in practice improve more consistently, achieving\nthe state-of-the-art performance on popular molecular graph datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 03:23:40 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 06:37:35 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 01:47:17 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 08:00:31 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ishiguro", "Katsuhiko", ""], ["Maeda", "Shin-ichi", ""], ["Koyama", "Masanori", ""]]}, {"id": "1902.01028", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li", "title": "Can SGD Learn Recurrent Neural Networks with Provable Generalization?", "comments": "V2 polishes writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are among the most popular models in\nsequential data analysis. Yet, in the foundational PAC learning language, what\nconcept class can it learn? Moreover, how can the same recurrent unit\nsimultaneously learn functions from different input tokens to different output\ntokens, without affecting each other? Existing generalization bounds for RNN\nscale exponentially with the input length, significantly limiting their\npractical implications.\n  In this paper, we show using the vanilla stochastic gradient descent (SGD),\nRNN can actually learn some notable concept class efficiently, meaning that\nboth time and sample complexity scale polynomially in the input length (or\nalmost polynomially, depending on the concept). This concept class at least\nincludes functions where each output token is generated from inputs of earlier\ntokens using a smooth two-layer neural network.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 04:21:00 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 10:43:43 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1902.01040", "submitter": "Sharath M Shankaranarayana Mr", "authors": "Sharath M Shankaranarayana, Keerthi Ram, Kaushik Mitra, Mohanasankar\n  Sivaprakasam", "title": "Fully Convolutional Networks for Monocular Retinal Depth Estimation and\n  Optic Disc-Cup Segmentation", "comments": "Under review in IEEE JBHI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glaucoma is a serious ocular disorder for which the screening and diagnosis\nare carried out by the examination of the optic nerve head (ONH). The color\nfundus image (CFI) is the most common modality used for ocular screening. In\nCFI, the central r\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 05:46:47 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Shankaranarayana", "Sharath M", ""], ["Ram", "Keerthi", ""], ["Mitra", "Kaushik", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1902.01046", "submitter": "Wolfgang Grieskamp", "authors": "Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex\n  Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone\\v{c}n\\'y, Stefano\n  Mazzocchi, H. Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel\n  Ramage, Jason Roselander", "title": "Towards Federated Learning at Scale: System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a distributed machine learning approach which enables\nmodel training on a large corpus of decentralized data. We have built a\nscalable production system for Federated Learning in the domain of mobile\ndevices, based on TensorFlow. In this paper, we describe the resulting\nhigh-level design, sketch some of the challenges and their solutions, and touch\nupon the open problems and future directions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 06:27:41 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 20:25:57 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Bonawitz", "Keith", ""], ["Eichner", "Hubert", ""], ["Grieskamp", "Wolfgang", ""], ["Huba", "Dzmitry", ""], ["Ingerman", "Alex", ""], ["Ivanov", "Vladimir", ""], ["Kiddon", "Chloe", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Mazzocchi", "Stefano", ""], ["McMahan", "H. Brendan", ""], ["Van Overveldt", "Timon", ""], ["Petrou", "David", ""], ["Ramage", "Daniel", ""], ["Roselander", "Jason", ""]]}, {"id": "1902.01056", "submitter": "Takuo Kaneko", "authors": "Takuo Kaneko, Issei Sato, Masashi Sugiyama", "title": "Online Multiclass Classification Based on Prediction Margin for Partial\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online multiclass classification with partial\nfeedback, where an algorithm predicts a class for a new instance in each round\nand only receives its correctness. Although several methods have been developed\nfor this problem, recent challenging real-world applications require further\nperformance improvement. In this paper, we propose a novel online learning\nalgorithm inspired by recent work on learning from complementary labels, where\na complementary label indicates a class to which an instance does not belong.\nThis allows us to handle partial feedback deterministically in a margin-based\nway, where the prediction margin has been recognized as a key to superior\nempirical performance. We provide a theoretical guarantee based on a cumulative\nloss bound and experimentally demonstrate that our method outperforms existing\nmethods which are non-margin-based and stochastic.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 07:18:19 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kaneko", "Takuo", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1902.01064", "submitter": "Qinyi Luo", "authors": "Qinyi Luo, Jinkun Lin, Youwei Zhuo and Xuehai Qian", "title": "Hop: Heterogeneity-Aware Decentralized Training", "comments": null, "journal-ref": null, "doi": "10.1145/3297858.3304009", "report-no": null, "categories": "cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that decentralized algorithms can deliver superior\nperformance over centralized ones in the context of machine learning. The two\napproaches, with the main difference residing in their distinct communication\npatterns, are both susceptible to performance degradation in heterogeneous\nenvironments. Although vigorous efforts have been devoted to supporting\ncentralized algorithms against heterogeneity, little has been explored in\ndecentralized algorithms regarding this problem.\n  This paper proposes Hop, the first heterogeneity-aware decentralized training\nprotocol. Based on a unique characteristic of decentralized training that we\nhave identified, the iteration gap, we propose a queue-based synchronization\nmechanism that can efficiently implement backup workers and bounded staleness\nin the decentralized setting. To cope with deterministic slowdown, we propose\nskipping iterations so that the effect of slower workers is further mitigated.\nWe build a prototype implementation of Hop on TensorFlow. The experiment\nresults on CNN and SVM show significant speedup over standard decentralized\ntraining in heterogeneous settings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 07:50:44 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 17:25:30 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Luo", "Qinyi", ""], ["Lin", "Jinkun", ""], ["Zhuo", "Youwei", ""], ["Qian", "Xuehai", ""]]}, {"id": "1902.01073", "submitter": "Santtu Tikka", "authors": "Santtu Tikka, Antti Hyttinen, Juha Karvanen", "title": "Causal Effect Identification from Multiple Incomplete Data Sources: A\n  General Search-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal effect identification considers whether an interventional probability\ndistribution can be uniquely determined without parametric assumptions from\nmeasured source distributions and structural knowledge on the generating\nsystem. While complete graphical criteria and procedures exist for many\nidentification problems, there are still challenging but important extensions\nthat have not been considered in the literature. To tackle these new settings,\nwe present a search algorithm directly over the rules of do-calculus. Due to\ngenerality of do-calculus, the search is capable of taking more advanced\ndata-generating mechanisms into account along with an arbitrary type of both\nobservational and experimental source distributions. The search is enhanced via\na heuristic and search space reduction techniques. The approach, called\ndo-search, is provably sound, and it is complete with respect to\nidentifiability problems that have been shown to be completely characterized by\ndo-calculus. When extended with additional rules, the search is capable of\nhandling missing data problems as well. With the versatile search, we are able\nto approach new problems such as combined transportability and selection bias,\nor multiple sources of selection bias. We perform a systematic analysis of\nbivariate missing data problems and study causal inference under case-control\ndesign. We also present the R package dosearch that provides an interface for a\nC++ implementation of the search.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:12:04 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 08:19:27 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 13:36:36 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:00:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tikka", "Santtu", ""], ["Hyttinen", "Antti", ""], ["Karvanen", "Juha", ""]]}, {"id": "1902.01080", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi, Sina D\\\"aubener, Asja Fischer", "title": "Predictive Uncertainty Quantification with Compound Density Networks", "comments": "Bayesian deep learning workshop, NeuRIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the huge success of deep neural networks (NNs), finding good\nmechanisms for quantifying their prediction uncertainty is still an open\nproblem. Bayesian neural networks are one of the most popular approaches to\nuncertainty quantification. On the other hand, it was recently shown that\nensembles of NNs, which belong to the class of mixture models, can be used to\nquantify prediction uncertainty. In this paper, we build upon these two\napproaches. First, we increase the mixture model's flexibility by replacing the\nfixed mixing weights by an adaptive, input-dependent distribution (specifying\nthe probability of each component) represented by NNs, and by considering\nuncountably many mixture components. The resulting class of models can be seen\nas the continuous counterpart to mixture density networks and is therefore\nreferred to as compound density networks (CDNs). We employ both maximum\nlikelihood and variational Bayesian inference to train CDNs, and empirically\nshow that they yield better uncertainty estimates on out-of-distribution data\nand are more robust to adversarial examples than the previous approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:39:06 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 12:59:03 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["D\u00e4ubener", "Sina", ""], ["Fischer", "Asja", ""]]}, {"id": "1902.01086", "submitter": "Akshay Degwekar", "authors": "Akshay Degwekar, Preetum Nakkiran, Vinod Vaikuntanathan", "title": "Computational Limitations in Robust Classification and Win-Win Results", "comments": "Merge of [DegwekarVaikuntanathan19](arXiv:1902.01086) and\n  [Nakkiran19](arXiv:1901.00532)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the study of statistical/computational tradeoffs in learning\nrobust classifiers, following the recent work of Bubeck, Lee, Price and\nRazenshteyn who showed examples of classification tasks where (a) an efficient\nrobust classifier exists, in the small-perturbation regime; (b) a non-robust\nclassifier can be learned efficiently; but (c) it is computationally hard to\nlearn a robust classifier, assuming the hardness of factoring large numbers.\nThe question of whether a robust classifier for their task exists in the large\nperturbation regime seems related to important open questions in computational\nnumber theory. In this work, we extend their work in three directions.\n  First, we demonstrate classification tasks where computationally efficient\nrobust classification is impossible, even when computationally unbounded robust\nclassifiers exist. For this, we rely on the existence of average-case hard\nfunctions.\n  Second, we show hard-to-robustly-learn classification tasks in the\nlarge-perturbation regime. Namely, we show that even though an efficient\nclassifier that is robust to large perturbations exists, it is computationally\nhard to learn any non-trivial robust classifier. Our first construction relies\non the existence of one-way functions, and the second on the hardness of the\nlearning parity with noise problem. In the latter setting, not only does a\nnon-robust classifier exist, but also an efficient algorithm that generates\nfresh new labeled samples given access to polynomially many training examples\n(termed as generation by Kearns et. al. (1994)).\n  Third, we show that any such counterexample implies the existence of\ncryptographic primitives such as one-way functions. This leads us to a win-win\nscenario: either we can learn an efficient robust classifier, or we can\nconstruct new instances of cryptographic primitives.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:55:33 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 14:34:59 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Degwekar", "Akshay", ""], ["Nakkiran", "Preetum", ""], ["Vaikuntanathan", "Vinod", ""]]}, {"id": "1902.01108", "submitter": "Rafal Wcislo", "authors": "Witold Dzwinel, Rafal Wcislo, Stan Matwin", "title": "2-D Embedding of Large and High-dimensional Data with Minimal Memory and\n  Computational Time Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the advent of big data era, interactive visualization of large data sets\nconsisting of M*10^5+ high-dimensional feature vectors of length N (N ~ 10^3+),\nis an indispensable tool for data exploratory analysis. The state-of-the-art\ndata embedding (DE) methods of N-D data into 2-D (3-D) visually perceptible\nspace (e.g., based on t-SNE concept) are too demanding computationally to be\nefficiently employed for interactive data analytics of large and\nhigh-dimensional datasets. Herein we present a simple method, ivhd (interactive\nvisualization of high-dimensional data tool), which radically outperforms the\nmodern data-embedding algorithms in both computational and memory loads, while\nretaining high quality of N-D data embedding in 2-D (3-D). We show that DE\nproblem is equivalent to the nearest neighbor nn-graph visualization, where\nonly indices of a few nearest neighbors of each data sample has to be known,\nand binary distance between data samples -- 0 to the nearest and 1 to the other\nsamples -- is defined. These improvements reduce the time-complexity and memory\nload from O(M log M) to O(M), and ensure minimal O(M) proportionality\ncoefficient as well. We demonstrate high efficiency, quality and robustness of\nivhd on popular benchmark datasets such as MNIST, 20NG, NORB and RCV1.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:13:36 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Dzwinel", "Witold", ""], ["Wcislo", "Rafal", ""], ["Matwin", "Stan", ""]]}, {"id": "1902.01119", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Shie Mannor", "title": "The Natural Language of Actions", "comments": "Published in the proceedings of the 36th International Conference on\n  Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Act2Vec, a general framework for learning context-based action\nrepresentation for Reinforcement Learning. Representing actions in a vector\nspace help reinforcement learning algorithms achieve better performance by\ngrouping similar actions and utilizing relations between different actions. We\nshow how prior knowledge of an environment can be extracted from demonstrations\nand injected into action vector representations that encode natural compatible\nbehavior. We then use these for augmenting state representations as well as\nimproving function approximation of Q-values. We visualize and test action\nembeddings in three domains including a drawing task, a high dimensional\nnavigation task, and the large action space domain of StarCraft II.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:46:53 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 07:35:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "1902.01139", "submitter": "Markus Frohme", "authors": "Markus Theo Frohme", "title": "Active Automata Learning with Adaptive Distinguishing Sequences", "comments": "Master thesis, 97 pages. This document is closely based on the Master\n  thesis of Markus Theo Frohme, submitted at TU Dortmund University, Germany on\n  September 21st, 2015 and may be used as the reference for the \"ADT\" algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document investigates the integration of adaptive distinguishing\nsequences into the process of active automata learning (AAL). A novel AAL\nalgorithm \"ADT\" (adaptive discrimination tree) is developed and presented.\nSince the submission of the original thesis, the presented algorithm has been\nintegrated into LearnLib - an open-source library for active automata learning\n- and has been successfully used in related fields of research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 12:05:38 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Frohme", "Markus Theo", ""]]}, {"id": "1902.01144", "submitter": "Bamdev Mishra", "authors": "Hiroyuki Kasai, Pratik Jawanpuria, and Bamdev Mishra", "title": "Riemannian adaptive stochastic gradient algorithms on matrix manifolds", "comments": "In International Conference on Machine Learning (ICML), PMLR\n  97:3262-3271, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive stochastic gradient algorithms in the Euclidean space have attracted\nmuch attention lately. Such explorations on Riemannian manifolds, on the other\nhand, are relatively new, limited, and challenging. This is because of the\nintrinsic non-linear structure of the underlying manifold and the absence of a\ncanonical coordinate system. In machine learning applications, however, most\nmanifolds of interest are represented as matrices with notions of row and\ncolumn subspaces. In addition, the implicit manifold-related constraints may\nalso lie on such subspaces. For example, the Grassmann manifold is the set of\ncolumn subspaces. To this end, such a rich structure should not be lost by\ntransforming matrices to just a stack of vectors while developing optimization\nalgorithms on manifolds. We propose novel stochastic gradient algorithms for\nproblems on Riemannian matrix manifolds by adapting the row and column\nsubspaces of gradients. Our algorithms are provably convergent and they achieve\nthe convergence rate of order $\\mathcal{O}(\\log (T)/\\sqrt{T})$, where $T$ is\nthe number of iterations. Our experiments illustrate the efficacy of the\nproposed algorithms on several applications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 12:14:52 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 14:24:42 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 12:00:20 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 07:24:38 GMT"}, {"version": "v5", "created": "Fri, 28 Jun 2019 08:58:40 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Jawanpuria", "Pratik", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1902.01147", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah\n  Hanif, Maurizio Martina, Muhammad Shafique", "title": "Is Spiking Secure? A Comparative Study on the Security Vulnerabilities\n  of Spiking and Deep Neural Networks", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207297", "report-no": null, "categories": "cs.LG cs.CR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) claim to present many advantages in terms of\nbiological plausibility and energy efficiency compared to standard Deep Neural\nNetworks (DNNs). Recent works have shown that DNNs are vulnerable to\nadversarial attacks, i.e., small perturbations added to the input data can lead\nto targeted or random misclassifications. In this paper, we aim at\ninvestigating the key research question: ``Are SNNs secure?'' Towards this, we\nperform a comparative study of the security vulnerabilities in SNNs and DNNs\nw.r.t. the adversarial noise. Afterwards, we propose a novel black-box attack\nmethodology, i.e., without the knowledge of the internal structure of the SNN,\nwhich employs a greedy heuristic to automatically generate imperceptible and\nrobust adversarial examples (i.e., attack images) for the given SNN. We perform\nan in-depth evaluation for a Spiking Deep Belief Network (SDBN) and a DNN\nhaving the same number of layers and neurons (to obtain a fair comparison), in\norder to study the efficiency of our methodology and to understand the\ndifferences between SNNs and DNNs w.r.t. the adversarial examples. Our work\nopens new avenues of research towards the robustness of the SNNs, considering\ntheir similarities to the human brain's functionality.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 12:23:11 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 21:33:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Nanfa", "Giorgio", ""], ["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1902.01148", "submitter": "Alexandre Araujo", "authors": "Rafael Pinot, Laurent Meunier, Alexandre Araujo, Hisashi Kashima,\n  Florian Yger, C\\'edric Gouy-Pailler, Jamal Atif", "title": "Theoretical evidence for adversarial robustness through randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the theory of robustness against adversarial attacks.\nIt focuses on the family of randomization techniques that consist in injecting\nnoise in the network at inference time. These techniques have proven effective\nin many contexts, but lack theoretical arguments. We close this gap by\npresenting a theoretical analysis of these approaches, hence explaining why\nthey perform well in practice. More precisely, we make two new contributions.\nThe first one relates the randomization rate to robustness to adversarial\nattacks. This result applies for the general family of exponential\ndistributions, and thus extends and unifies the previous approaches. The second\ncontribution consists in devising a new upper bound on the adversarial\ngeneralization gap of randomized neural networks. We support our theoretical\nclaims with a set of experiments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 12:25:05 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 16:04:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Pinot", "Rafael", ""], ["Meunier", "Laurent", ""], ["Araujo", "Alexandre", ""], ["Kashima", "Hisashi", ""], ["Yger", "Florian", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1902.01151", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Muhammad Abdullah Hanif, Mohammad Taghi Teimoori,\n  Muhammad Shafique", "title": "CapStore: Energy-Efficient Design and Management of the On-Chip Memory\n  for CapsuleNet Inference Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been established as the state-of-the-art\nalgorithm for advanced machine learning applications. Recently, CapsuleNets\nhave improved the generalization ability, as compared to DNNs, due to their\nmulti-dimensional capsules. However, they pose high computational and memory\nrequirements, which makes energy-efficient inference a challenging task. In\nthis paper, we perform an extensive analysis to demonstrate their key\nlimitations due to intense memory accesses and large on-chip memory\nrequirements. To enable efficient CaspuleNet inference accelerators, we propose\na specialized on-chip memory hierarchy which minimizes the off-chip memory\naccesses, while efficiently feeding the data to the accelerator. We analyze the\non-chip memory requirements for each memory component of the architecture. By\nleveraging this analysis, we propose a methodology to explore different on-chip\nmemory designs and a power-gating technique to further reduce the energy\nconsumption, depending upon the utilization across different operations of a\nCapsuleNet. Our memory designs can significantly reduce the energy consumption\nof the on-chip memory by up to 86%, when compared to a state-of-the-art memory\ndesign. Since the power consumption of the memory elements is the major\ncontributor in the power breakdown of the CapsuleNet accelerator, as we will\nalso show in our analyses, the proposed memory design can effectively reduce\nthe overall energy consumption of the complete CapsuleNet accelerator\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 12:38:40 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 14:24:06 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Marchisio", "Alberto", ""], ["Hanif", "Muhammad Abdullah", ""], ["Teimoori", "Mohammad Taghi", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1902.01177", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Yu-An Chung, Peter Szolovits", "title": "Unsupervised Clinical Language Translation", "comments": "Accepted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As patients' access to their doctors' clinical notes becomes common,\ntranslating professional, clinical jargon to layperson-understandable language\nis essential to improve patient-clinician communication. Such translation\nyields better clinical outcomes by enhancing patients' understanding of their\nown health conditions, and thus improving patients' involvement in their own\ncare. Existing research has used dictionary-based word replacement or\ndefinition insertion to approach the need. However, these methods are limited\nby expert curation, which is hard to scale and has trouble generalizing to\nunseen datasets that do not share an overlapping vocabulary. In contrast, we\napproach the clinical word and sentence translation problem in a completely\nunsupervised manner. We show that a framework using representation learning,\nbilingual dictionary induction and statistical machine translation yields the\nbest precision at 10 of 0.827 on professional-to-consumer word translation, and\nmean opinion scores of 4.10 and 4.28 out of 5 for clinical correctness and\nlayperson readability, respectively, on sentence translation. Our\nfully-unsupervised strategy overcomes the curation problem, and the clinically\nmeaningful evaluation reduces biases from inappropriate evaluators, which are\ncritical in clinical machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:47:18 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 08:35:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Chung", "Yu-An", ""], ["Szolovits", "Peter", ""]]}, {"id": "1902.01182", "submitter": "Jalil Taghia", "authors": "Jalil Taghia, Maria B\\r{a}nkestad, Fredrik Lindsten, Thomas B. Sch\\\"on", "title": "Constructing the Matrix Multilayer Perceptron and its Application to the\n  VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like most learning algorithms, the multilayer perceptrons (MLP) is designed\nto learn a vector of parameters from data. However, in certain scenarios we are\ninterested in learning structured parameters (predictions) in the form of\nsymmetric positive definite matrices. Here, we introduce a variant of the MLP,\nreferred to as the matrix MLP, that is specialized at learning symmetric\npositive definite matrices. We also present an application of the model within\nthe context of the variational autoencoder (VAE). Our formulation of the VAE\nextends the vanilla formulation to the cases where the recognition and the\ngenerative networks can be from the parametric family of distributions with\ndense covariance matrices. Two specific examples are discussed in more detail:\nthe dense covariance Gaussian and its generalization, the power exponential\ndistribution. Our new developments are illustrated using both synthetic and\nreal data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:51:03 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Taghia", "Jalil", ""], ["B\u00e5nkestad", "Maria", ""], ["Lindsten", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1902.01194", "submitter": "Patrick Schlachter", "authors": "Patrick Schlachter, Yiwen Liao and Bin Yang", "title": "Deep One-Class Classification Using Intra-Class Splitting", "comments": "IEEE Data Science Workshop 2019 (DSW 2019)", "journal-ref": null, "doi": "10.1109/DSW.2019.8755576", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a generic method which enables to use conventional deep\nneural networks as end-to-end one-class classifiers. The method is based on\nsplitting given data from one class into two subsets. In one-class\nclassification, only samples of one normal class are available for training.\nDuring inference, a closed and tight decision boundary around the training\nsamples is sought which conventional binary or multi-class neural networks are\nnot able to provide. By splitting data into typical and atypical normal\nsubsets, the proposed method can use a binary loss and defines an auxiliary\nsubnetwork for distance constraints in the latent space. Various experiments on\nthree well-known image datasets showed the effectiveness of the proposed method\nwhich outperformed seven baselines and had a better or comparable performance\nto the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 14:12:30 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 08:59:49 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 11:02:03 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 11:32:25 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Schlachter", "Patrick", ""], ["Liao", "Yiwen", ""], ["Yang", "Bin", ""]]}, {"id": "1902.01208", "submitter": "Rakshit Agrawal", "authors": "Rakshit Agrawal and Luca de Alfaro and David Helmbold", "title": "A New Family of Neural Networks Provably Resistant to Adversarial\n  Attacks", "comments": "arXiv admin note: text overlap with arXiv:1809.09262", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks add perturbations to the input features with the intent\nof changing the classification produced by a machine learning system. Small\nperturbations can yield adversarial examples which are misclassified despite\nbeing virtually indistinguishable from the unperturbed input. Classifiers\ntrained with standard neural network techniques are highly susceptible to\nadversarial examples, allowing an adversary to create misclassifications of\ntheir choice.\n  We introduce a new type of network unit, called MWD (max of weighed distance)\nunits that have a built-in resistant to adversarial attacks. These units are\nhighly non-linear, and we develop the techniques needed to effectively train\nthem. We show that simple interval techniques for propagating perturbation\neffects through the network enables the efficient computation of robustness\n(i.e., accuracy guarantees) for MWD networks under any perturbations, including\nadversarial attacks.\n  MWD networks are significantly more robust to input perturbations than ReLU\nnetworks. On permutation invariant MNIST, when test examples can be perturbed\nby 20% of the input range, MWD networks provably retain accuracy above 83%,\nwhile the accuracy of ReLU networks drops below 5%. The provable accuracy of\nMWD networks is superior even to the observed accuracy of ReLU networks trained\nwith the help of adversarial examples. In the absence of adversarial attacks,\nMWD networks match the performance of sigmoid networks, and have accuracy only\nslightly below that of ReLU networks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 00:56:13 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Agrawal", "Rakshit", ""], ["de Alfaro", "Luca", ""], ["Helmbold", "David", ""]]}, {"id": "1902.01219", "submitter": "Joseph Lam-Weil", "authors": "Joseph Lam-Weil, Alexandra Carpentier, Bharath K. Sriperumbudur", "title": "Local minimax rates for closeness testing of discrete distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the closeness testing problem for discrete distributions. The\ngoal is to distinguish whether two samples are drawn from the same unspecified\ndistribution, or whether their respective distributions are separated in\n$L_1$-norm. In this paper, we focus on adapting the rate to the shape of the\nunderlying distributions, i.e. we consider \\textit{a local minimax setting}. We\nprovide, to the best of our knowledge, the first local minimax rate for the\nseparation distance up to logarithmic factors, together with a test that\nachieves it. In view of the rate, closeness testing turns out to be\nsubstantially harder than the related one-sample testing problem over a wide\nrange of cases.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 12:42:12 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 14:59:51 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 15:47:42 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lam-Weil", "Joseph", ""], ["Carpentier", "Alexandra", ""], ["Sriperumbudur", "Bharath K.", ""]]}, {"id": "1902.01224", "submitter": "Geoffrey Wolfer", "authors": "Geoffrey Wolfer and Aryeh Kontorovich", "title": "Estimating the Mixing Time of Ergodic Markov Chains", "comments": "Upload the extended version submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating the mixing time $t_{\\mathsf{mix}}$ of an\narbitrary ergodic finite-state Markov chain from a single trajectory of length\n$m$. The reversible case was addressed by Hsu et al. [2019], who left the\ngeneral case as an open problem. In the reversible case, the analysis is\ngreatly facilitated by the fact that the Markov operator is self-adjoint, and\nWeyl's inequality allows for a dimension-free perturbation analysis of the\nempirical eigenvalues. As Hsu et al. point out, in the absence of reversibility\n(which induces asymmetric pair probabilities matrices), the existing\nperturbation analysis has a worst-case exponential dependence on the number of\nstates $d$. Furthermore, even if an eigenvalue perturbation analysis with\nbetter dependence on $d$ were available, in the non-reversible case the\nconnection between the spectral gap and the mixing time is not nearly as\nstraightforward as in the reversible case. Our key insight is to estimate the\npseudo-spectral gap $\\gamma_{\\mathsf{ps}}$ instead, which allows us to overcome\nthe loss of symmetry and to achieve a polynomial dependence on the minimal\nstationary probability $\\pi_\\star$ and $\\gamma_{\\mathsf{ps}}$. Additionally, in\nthe reversible case, we obtain simultaneous nearly (up to logarithmic factors)\nminimax rates in $t_{\\mathsf{mix}}$ and precision $\\varepsilon$, closing a gap\nin Hsu et al., who treated $\\varepsilon$ as constant in the lower bounds.\nFinally, we construct fully empirical confidence intervals for\n$\\gamma_{\\mathsf{ps}}$, which shrink to zero at a rate of roughly $1/\\sqrt{m}$,\nand improve the state of the art in even the reversible case.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 08:13:58 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 09:07:31 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 13:43:25 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wolfer", "Geoffrey", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1902.01235", "submitter": "Soheil Feizi", "authors": "Sahil Singla and Soheil Feizi", "title": "Robustness Certificates Against Adversarial Examples for ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have achieved high performance in different learning\ntasks, their accuracy drops significantly in the presence of small adversarial\nperturbations to inputs. Defenses based on regularization and adversarial\ntraining are often followed by new attacks to defeat them. In this paper, we\npropose attack-agnostic robustness certificates for a multi-label\nclassification problem using a deep ReLU network. Although computing the exact\ndistance of a given input sample to the classification decision boundary\nrequires solving a non-convex optimization, we characterize two lower bounds\nfor such distances, namely the simplex certificate and the decision boundary\ncertificate. These robustness certificates leverage the piece-wise linear\nstructure of ReLU networks and use the fact that in a polyhedron around a given\nsample, the prediction function is linear. In particular, the proposed simplex\ncertificate has a closed-form, is differentiable and is an order of magnitude\nfaster to compute than the existing methods even for deep networks. In addition\nto theoretical bounds, we provide numerical results for our certificates over\nMNIST and compare them with some existing upper bounds.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 15:36:34 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 21:36:18 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Singla", "Sahil", ""], ["Feizi", "Soheil", ""]]}, {"id": "1902.01239", "submitter": "Etienne Boursier", "authors": "Etienne Boursier, Emilie Kaufmann, Abbas Mehrabian, Vianney Perchet", "title": "A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among\n  Players", "comments": "AISTATS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multiplayer stochastic multi-armed bandit problem in which players\ncannot communicate, and if two or more players pull the same arm, a collision\noccurs and the involved players receive zero reward. We consider the\nchallenging heterogeneous setting, in which different arms may have different\nmeans for different players, and propose a new and efficient algorithm that\ncombines the idea of leveraging forced collisions for implicit communication\nand that of performing matching eliminations. We present a finite-time analysis\nof our algorithm, giving the first sublinear minimax regret bound for this\nproblem, and prove that if the optimal assignment of players to arms is unique,\nour algorithm attains the optimal $O(\\ln(T))$ regret, solving an open question\nraised at NeurIPS 2018.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 15:10:34 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 09:10:47 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 12:49:07 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 16:05:47 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Boursier", "Etienne", ""], ["Kaufmann", "Emilie", ""], ["Mehrabian", "Abbas", ""], ["Perchet", "Vianney", ""]]}, {"id": "1902.01240", "submitter": "Paavo Parmas", "authors": "Paavo Parmas, Carl Edward Rasmussen, Jan Peters, Kenji Doya", "title": "PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, the exploding gradient problem has been explained to be central\nin deep learning and model-based reinforcement learning, because it causes\nnumerical issues and instability in optimization. Our experiments in\nmodel-based reinforcement learning imply that the problem is not just a\nnumerical issue, but it may be caused by a fundamental chaos-like nature of\nlong chains of nonlinear computations. Not only do the magnitudes of the\ngradients become large, the direction of the gradients becomes essentially\nrandom. We show that reparameterization gradients suffer from the problem,\nwhile likelihood ratio gradients are robust. Using our insights, we develop a\nmodel-based policy search framework, Probabilistic Inference for Particle-Based\nPolicy Search (PIPPS), which is easily extensible, and allows for almost\narbitrary models and policies, while simultaneously matching the performance of\nprevious data-efficient learning algorithms. Finally, we invent the total\npropagation algorithm, which efficiently computes a union over all pathwise\nderivative depths during a single backwards pass, automatically giving greater\nweight to estimators with lower variance, sometimes improving over\nreparameterization gradients by $10^6$ times.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 15:12:55 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Parmas", "Paavo", ""], ["Rasmussen", "Carl Edward", ""], ["Peters", "Jan", ""], ["Doya", "Kenji", ""]]}, {"id": "1902.01304", "submitter": "Nantia Makrynioti", "authors": "Nantia Makrynioti (1), Vasilis Vassalos (1) ((1) Athens University of\n  Economics and Business)", "title": "Declarative Data Analytics: a Survey", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of declarative data analytics explores the application of the\ndeclarative paradigm on data science and machine learning. It proposes\ndeclarative languages for expressing data analysis tasks and develops systems\nwhich optimize programs written in those languages. The execution engine can be\neither centralized or distributed, as the declarative paradigm advocates\nindependence from particular physical implementations. The survey explores a\nwide range of declarative data analysis frameworks by examining both the\nprogramming model and the optimization techniques used, in order to provide\nconclusions on the current state of the art in the area and identify open\nchallenges.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 16:52:40 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Makrynioti", "Nantia", ""], ["Vassalos", "Vasilis", ""]]}, {"id": "1902.01313", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "An Effective Approach to Unsupervised Machine Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine translation has traditionally relied on large amounts of\nparallel corpora, a recent research line has managed to train both Neural\nMachine Translation (NMT) and Statistical Machine Translation (SMT) systems\nusing monolingual corpora only. In this paper, we identify and address several\ndeficiencies of existing unsupervised SMT approaches by exploiting subword\ninformation, developing a theoretically well founded unsupervised tuning\nmethod, and incorporating a joint refinement procedure. Moreover, we use our\nimproved SMT system to initialize a dual NMT model, which is further fine-tuned\nthrough on-the-fly back-translation. Together, we obtain large improvements\nover the previous state-of-the-art in unsupervised machine translation. For\ninstance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points\nmore than the previous best unsupervised system, and 0.5 points more than the\n(supervised) shared task winner back in 2014.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:08:32 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 22:23:38 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1902.01348", "submitter": "Michael Ekstrand", "authors": "Michael D. Ekstrand and Joseph A. Konstan", "title": "Recommender Systems Notation: Proposed Common Notation for Teaching and\n  Research", "comments": null, "journal-ref": "Boise State University Computer Science Faculty Publications and\n  Presentations 177", "doi": "10.18122/cs_facpubs/177/boisestate", "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the field of recommender systems has developed, authors have used a myriad\nof notations for describing the mathematical workings of recommendation\nalgorithms. These notations ap-pear in research papers, books, lecture notes,\nblog posts, and software documentation. The dis-ciplinary diversity of the\nfield has not contributed to consistency in notation; scholars whose home base\nis in information retrieval have different habits and expectations than those\nin ma-chine learning or human-computer interaction.\n  In the course of years of teaching and research on recommender systems, we\nhave seen the val-ue in adopting a consistent notation across our work. This\nhas been particularly highlighted in our development of the Recommender Systems\nMOOC on Coursera (Konstan et al. 2015), as we need to explain a wide variety of\nalgorithms and our learners are not well-served by changing notation between\nalgorithms.\n  In this paper, we describe the notation we have adopted in our work, along\nwith its justification and some discussion of considered alternatives. We\npresent this in hope that it will be useful to others writing and teaching\nabout recommender systems. This notation has served us well for some time now,\nin research, online education, and traditional classroom instruction. We feel\nit is ready for broad use.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:11:23 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Ekstrand", "Michael D.", ""], ["Konstan", "Joseph A.", ""]]}, {"id": "1902.01370", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Qi Liu and Kyunghyun Cho", "title": "Insertion-based Decoding with automatically Inferred Generation Order", "comments": "Camera ready. Accepted by TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional neural autoregressive decoding commonly assumes a fixed\nleft-to-right generation order, which may be sub-optimal. In this work, we\npropose a novel decoding algorithm -- InDIGO -- which supports flexible\nsequence generation in arbitrary orders through insertion operations. We extend\nTransformer, a state-of-the-art sequence generation model, to efficiently\nimplement the proposed approach, enabling it to be trained with either a\npre-defined generation order or adaptive orders obtained from beam-search.\nExperiments on four real-world tasks, including word order recovery, machine\ntranslation, image caption and code generation, demonstrate that our algorithm\ncan generate sequences following arbitrary orders, while achieving competitive\nor even better performance compared to the conventional left-to-right\ngeneration. The generated sequences show that InDIGO adopts adaptive generation\norders based on input information.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:35:59 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:56:48 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 07:55:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gu", "Jiatao", ""], ["Liu", "Qi", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.01378", "submitter": "Arthur Juliani", "authors": "Arthur Juliani, Ahmed Khalifa, Vincent-Pierre Berges, Jonathan Harper,\n  Ervin Teng, Hunter Henry, Adam Crespi, Julian Togelius, Danny Lange", "title": "Obstacle Tower: A Generalization Challenge in Vision, Control, and\n  Planning", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid pace of recent research in AI has been driven in part by the\npresence of fast and challenging simulation environments. These environments\noften take the form of games; with tasks ranging from simple board games, to\ncompetitive video games. We propose a new benchmark - Obstacle Tower: a high\nfidelity, 3D, 3rd person, procedurally generated environment. An agent playing\nObstacle Tower must learn to solve both low-level control and high-level\nplanning problems in tandem while learning from pixels and a sparse reward\nsignal. Unlike other benchmarks such as the Arcade Learning Environment,\nevaluation of agent performance in Obstacle Tower is based on an agent's\nability to perform well on unseen instances of the environment. In this paper\nwe outline the environment and provide a set of baseline results produced by\ncurrent state-of-the-art Deep RL methods as well as human players. These\nalgorithms fail to produce agents capable of performing near human level.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:45:46 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 20:58:01 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Juliani", "Arthur", ""], ["Khalifa", "Ahmed", ""], ["Berges", "Vincent-Pierre", ""], ["Harper", "Jonathan", ""], ["Teng", "Ervin", ""], ["Henry", "Hunter", ""], ["Crespi", "Adam", ""], ["Togelius", "Julian", ""], ["Lange", "Danny", ""]]}, {"id": "1902.01384", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Quanquan Gu", "title": "Generalization Error Bounds of Gradient Descent for Learning\n  Over-parameterized Deep ReLU Networks", "comments": "27 pages. This version simplifies the proof and improves the\n  presentation in Version 3. In AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical studies show that gradient-based methods can learn deep neural\nnetworks (DNNs) with very good generalization performance in the\nover-parameterization regime, where DNNs can easily fit a random labeling of\nthe training data. Very recently, a line of work explains in theory that with\nover-parameterization and proper random initialization, gradient-based methods\ncan find the global minima of the training loss for DNNs. However, existing\ngeneralization error bounds are unable to explain the good generalization\nperformance of over-parameterized DNNs. The major limitation of most existing\ngeneralization bounds is that they are based on uniform convergence and are\nindependent of the training algorithm. In this work, we derive an\nalgorithm-dependent generalization error bound for deep ReLU networks, and show\nthat under certain assumptions on the data distribution, gradient descent (GD)\nwith proper random initialization is able to train a sufficiently\nover-parameterized DNN to achieve arbitrarily small generalization error. Our\nwork sheds light on explaining the good generalization performance of\nover-parameterized deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:52:43 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 18:57:24 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 17:57:59 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 07:08:38 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1902.01385", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh,\n  Dhruv Batra", "title": "Embodied Multimodal Multitask Learning", "comments": "See https://devendrachaplot.github.io/projects/EMML for demo videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts on training visual navigation agents conditioned on language\nusing deep reinforcement learning have been successful in learning policies for\ndifferent multimodal tasks, such as semantic goal navigation and embodied\nquestion answering. In this paper, we propose a multitask model capable of\njointly learning these multimodal tasks, and transferring knowledge of words\nand their grounding in visual objects across the tasks. The proposed model uses\na novel Dual-Attention unit to disentangle the knowledge of words in the\ntextual representations and visual concepts in the visual representations, and\nalign them with each other. This disentangled task-invariant alignment of\nrepresentations facilitates grounding and knowledge transfer across both tasks.\nWe show that the proposed model outperforms a range of baselines on both tasks\nin simulated 3D environments. We also show that this disentanglement of\nrepresentations makes our model modular, interpretable, and allows for transfer\nto instructions containing new words by leveraging object detectors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:53:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Lee", "Lisa", ""], ["Salakhutdinov", "Ruslan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.01388", "submitter": "Guokun Lai", "authors": "Zihang Dai, Guokun Lai, Yiming Yang, Shinjae Yoo", "title": "Re-examination of the Role of Latent Variables in Sequence Modeling", "comments": "Code available at https://github.com/zihangdai/reexamine-srnn,\n  accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With latent variables, stochastic recurrent models have achieved\nstate-of-the-art performance in modeling sound-wave sequence. However, opposite\nresults are also observed in other domains, where standard recurrent networks\noften outperform stochastic models. To better understand this discrepancy, we\nre-examine the roles of latent variables in stochastic recurrent models for\nspeech density estimation. Our analysis reveals that under the restriction of\nfully factorized output distribution in previous evaluations, the stochastic\nmodels were implicitly leveraging intra-step correlation but the standard\nrecurrent baselines were prohibited to do so, resulting in an unfair\ncomparison. To correct the unfairness, we remove such restriction in our\nre-examination, where all the models can explicitly leverage intra-step\ncorrelation with an auto-regressive structure. Over a diverse set of sequential\ndata, including human speech, MIDI music, handwriting trajectory and\nframe-permuted speech, our results show that stochastic recurrent models fail\nto exhibit any practical advantage despite the claimed theoretical superiority.\nIn contrast, standard recurrent models equipped with an auto-regressive output\ndistribution consistently perform better, significantly advancing the\nstate-of-the-art results on three speech datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:57:05 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 05:33:29 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Dai", "Zihang", ""], ["Lai", "Guokun", ""], ["Yang", "Yiming", ""], ["Yoo", "Shinjae", ""]]}, {"id": "1902.01395", "submitter": "Muhammad Abubakar Yamin", "authors": "A. Yamin, M. Dayan, L. Squarcina, P. Brambilla, V. Murino, V.\n  Diwadkar, and D. Sona", "title": "Comparison of brain connectomes using geodesic distance on manifold:a\n  twin study", "comments": "Paper is accepted for presentation in ISBI 2019. Camera ready has\n  been submitted on 15 Jan 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  fMRI is a unique non-invasive approach for understanding the functional\norganization of the human brain, and task-based fMRI promotes identification of\nfunctionally relevant brain regions associated with a given task. Here, we use\nfMRI (using the Poffenberger Paradigm) data collected in mono- and dizygotic\ntwin pairs to propose a novel approach for assessing similarity in functional\nnetworks. In particular, we compared network similarity between pairs of twins\nin task-relevant and task-orthogonal networks. The proposed method measures the\nsimilarity between functional networks using a geodesic distance between graph\nLaplacians. With method we show that networks are more similar in monozygotic\ntwins compared to dizygotic twins. Furthermore, the similarity in monozygotic\ntwins is higher for task-relevant, than task-orthogonal networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:48:38 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Yamin", "A.", ""], ["Dayan", "M.", ""], ["Squarcina", "L.", ""], ["Brambilla", "P.", ""], ["Murino", "V.", ""], ["Diwadkar", "V.", ""], ["Sona", "D.", ""]]}, {"id": "1902.01426", "submitter": "Sergio Martin-del-Campo", "authors": "Sergio Martin-del-Campo, Fredrik Sandin and Daniel Str\\\"ombergsson", "title": "Dictionary learning approach to monitoring of wind turbine drivetrain\n  bearings", "comments": "22 pages, 10 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condition monitoring is central to the efficient operation of wind farms due\nto the challenging operating conditions, rapid technology development and large\nnumber of aging wind turbines. In particular, predictive maintenance planning\nrequires the early detection of faults with few false positives. Achieving this\ntype of detection is a challenging problem due to the complex and weak\nsignatures of some faults, particularly the faults that occur in some of the\ndrivetrain bearings. Here, we investigate recently proposed condition\nmonitoring methods based on unsupervised dictionary learning using vibration\ndata recorded over 46 months under typical industrial operations. Thus, we\ncontribute novel test results and real world data that are made publicly\navailable. The results of former studies addressing condition monitoring tasks\nusing dictionary learning indicate that unsupervised feature learning is useful\nfor diagnosis and anomaly detection purposes. However, these studies are based\non small sets of labeled data from test rigs operating under controlled\nconditions that focus on classification tasks, which are useful for\nquantitative method comparisons but gives little insight into how useful these\napproaches are in practice. In this study, dictionaries are learned from\ngearbox vibrations in six different turbines, and the dictionaries are\nsubsequently propagated over a few years of monitoring data when faults are\nknown to occur. We perform the experiment using two different sparse coding\nalgorithms to investigate if the algorithm selected affects the features of\nabnormal conditions. We calculate the dictionary distance between the initial\nand propagated dictionaries and find the time periods of abnormal dictionary\nadaptation starting six months before a drivetrain bearing replacement and one\nyear before the resulting gearbox replacement.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:07:57 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 18:33:48 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Martin-del-Campo", "Sergio", ""], ["Sandin", "Fredrik", ""], ["Str\u00f6mbergsson", "Daniel", ""]]}, {"id": "1902.01435", "submitter": "Yang Li", "authors": "Yang Li, Tianxiang Gao, Junier B. Oliva", "title": "A Forest from the Trees: Generation through Neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to learn a generative model using both learned\nfeatures (through a latent space) and memories (through neighbors). Although\nhuman learning makes seamless use of both learned perceptual features and\ninstance recall, current generative learning paradigms only make use of one of\nthese two components. Take, for instance, flow models, which learn a latent\nspace of invertible features that follow a simple distribution. Conversely,\nkernel density techniques use instances to shift a simple distribution into an\naggregate mixture model. Here we propose multiple methods to enhance the latent\nspace of a flow model with neighborhood information. Not only does our proposed\nframework represent a more human-like approach by leveraging both learned\nfeatures and memories, but it may also be viewed as a step forward in\nnon-parametric methods. The efficacy of our model is shown empirically with\nstandard image datasets. We observe compelling results and a significant\nimprovement over baselines.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:24:48 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:24:25 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Li", "Yang", ""], ["Gao", "Tianxiang", ""], ["Oliva", "Junier B.", ""]]}, {"id": "1902.01436", "submitter": "Luis Scoccola", "authors": "Alexander Rolle and Luis Scoccola", "title": "Visualization tools for parameter selection in cluster analysis", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm, HPREF (Hierarchical Partitioning by Repeated\nFeatures), that produces a hierarchical partition of a set of clusterings of a\nfixed dataset, such as sets of clusterings produced by running a clustering\nalgorithm with a range of parameters. This gives geometric structure to such\nsets of clustering, and can be used to visualize the set of results one obtains\nby running a clustering algorithm with a range of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:25:30 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 21:15:55 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 16:29:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rolle", "Alexander", ""], ["Scoccola", "Luis", ""]]}, {"id": "1902.01437", "submitter": "Junhao Li", "authors": "Junhao Li, Hang Zhang", "title": "Blaze: Simplified High Performance Cluster Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  MapReduce and its variants have significantly simplified and accelerated the\nprocess of developing parallel programs. However, most MapReduce\nimplementations focus on data-intensive tasks while many real-world tasks are\ncompute intensive and their data can fit distributedly into the memory. For\nthese tasks, the speed of MapReduce programs can be much slower than those\nhand-optimized ones. We present Blaze, a C++ library that makes it easy to\ndevelop high performance parallel programs for such compute intensive tasks. At\nthe core of Blaze is a highly-optimized in-memory MapReduce function, which has\nthree main improvements over conventional MapReduce implementations: eager\nreduction, fast serialization, and special treatment for a small fixed key\nrange. We also offer additional conveniences that make developing parallel\nprograms similar to developing serial programs. These improvements make Blaze\nan easy-to-use cluster computing library that approaches the speed of\nhand-optimized parallel code. We apply Blaze to some common data mining tasks,\nincluding word frequency count, PageRank, k-means, expectation maximization\n(Gaussian mixture model), and k-nearest neighbors. Blaze outperforms Apache\nSpark by more than 10 times on average for these tasks, and the speed of Blaze\nscales almost linearly with the number of nodes. In addition, Blaze uses only\nthe MapReduce function and 3 utility functions in its implementation while\nSpark uses almost 30 different parallel primitives in its official\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:28:15 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 02:59:19 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Li", "Junhao", ""], ["Zhang", "Hang", ""]]}, {"id": "1902.01449", "submitter": "Baruch Epstein", "authors": "Baruch Epstein, Ron Meir", "title": "Generalization Bounds For Unsupervised and Semi-Supervised Learning With\n  Autoencoders", "comments": "Submitted to COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are widely used for unsupervised learning and as a\nregularization scheme in semi-supervised learning. However, theoretical\nunderstanding of their generalization properties and of the manner in which\nthey can assist supervised learning has been lacking. We utilize recent\nadvances in the theory of deep learning generalization, together with a novel\nreconstruction loss, to provide generalization bounds for autoencoders. To the\nbest of our knowledge, this is the first such bound. We further show that,\nunder appropriate assumptions, an autoencoder with good generalization\nproperties can improve any semi-supervised learning scheme. We support our\ntheoretical results with empirical demonstrations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 20:10:31 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Epstein", "Baruch", ""], ["Meir", "Ron", ""]]}, {"id": "1902.01453", "submitter": "Johan Mathe", "authors": "Johan Mathe, Nina Miolane, Nicolas Sebastien, Jeremie Lequeux", "title": "PVNet: A LRCN Architecture for Spatio-Temporal Photovoltaic\n  PowerForecasting from Numerical Weather Prediction", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photovoltaic (PV) power generation has emerged as one of the lead renewable\nenergy sources. Yet, its production is characterized by high uncertainty, being\ndependent on weather conditions like solar irradiance and temperature.\nPredicting PV production, even in the 24-hour forecast, remains a challenge and\nleads energy providers to left idling - often carbon emitting - plants. In this\npaper, we introduce a Long-Term Recurrent Convolutional Network using Numerical\nWeather Predictions (NWP) to predict, in turn, PV production in the 24-hour and\n48-hour forecast horizons. This network architecture fully leverages both\ntemporal and spatial weather data, sampled over the whole geographical area of\ninterest. We train our model on an NWP dataset from the National Oceanic and\nAtmospheric Administration (NOAA) to predict spatially aggregated PV production\nin Germany. We compare its performance to the persistence model and\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 20:30:24 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 20:02:30 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 00:57:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Mathe", "Johan", ""], ["Miolane", "Nina", ""], ["Sebastien", "Nicolas", ""], ["Lequeux", "Jeremie", ""]]}, {"id": "1902.01475", "submitter": "Sheng Zhou", "authors": "Sheng Zhou, Jiajun Bu, Xin Wang, Jiawei Chen, Can Wang", "title": "HAHE: Hierarchical Attentive Heterogeneous Information Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Heterogeneous information network (HIN) embedding has recently attracted much\nattention due to its effectiveness in dealing with the complex heterogeneous\ndata. Meta path, which connects different object types with various semantic\nmeanings, is widely used by existing HIN embedding works. However, several\nchallenges have not been addressed so far. First, different meta paths convey\ndifferent semantic meanings, while existing works assume that all nodes share\nsame weights for meta paths and ignore the personalized preferences of\ndifferent nodes on different meta paths. Second, given a meta path, nodes in\nHIN are connected by path instances while existing works fail to fully explore\nthe differences between path instances that reflect nodes' preferences in the\nsemantic space. rTo tackle the above challenges, we propose aHierarchical\nAttentive Heterogeneous information network Embedding (HAHE) model to capture\nthe personalized preferences on meta paths and path instances in each semantic\nspace. As path instances are based on a particular meta path, a hierarchical\nattention mechanism is naturally utilized to model the personalized preference\non meta paths and path instances. Extensive experiments on several real-world\ndatasets show that our proposed \\model model significantly outperforms the\nstate-of-the-art methods in terms of various data mining tasks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 01:35:18 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 04:59:01 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhou", "Sheng", ""], ["Bu", "Jiajun", ""], ["Wang", "Xin", ""], ["Chen", "Jiawei", ""], ["Wang", "Can", ""]]}, {"id": "1902.01480", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti, Taneli Mielikainen, Aristides Gionis, Heikki Mannila", "title": "What is the dimension of your binary data?", "comments": null, "journal-ref": null, "doi": "10.1109/ICDM.2006.167", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many 0/1 datasets have a very large number of variables; on the other hand,\nthey are sparse and the dependency structure of the variables is simpler than\nthe number of variables would suggest. Defining the effective dimensionality of\nsuch a dataset is a nontrivial problem. We consider the problem of defining a\nrobust measure of dimension for 0/1 datasets, and show that the basic idea of\nfractal dimension can be adapted for binary data. However, as such the fractal\ndimension is difficult to interpret. Hence we introduce the concept of\nnormalized fractal dimension. For a dataset $D$, its normalized fractal\ndimension is the number of columns in a dataset $D'$ with independent columns\nand having the same (unnormalized) fractal dimension as $D$. The normalized\nfractal dimension measures the degree of dependency structure of the data. We\nstudy the properties of the normalized fractal dimension and discuss its\ncomputation. We give empirical results on the normalized fractal dimension,\ncomparing it against baseline measures such as PCA. We also study the\nrelationship of the dimension of the whole dataset and the dimensions of\nsubgroups formed by clustering. The results indicate interesting differences\nbetween and within datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 22:19:10 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Tatti", "Nikolaj", ""], ["Mielikainen", "Taneli", ""], ["Gionis", "Aristides", ""], ["Mannila", "Heikki", ""]]}, {"id": "1902.01482", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis", "title": "Bootstrapped Coordinate Search for Multidimensional Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a unified framework for gradient-free Multidimensional Scaling\n(MDS) based on Coordinate Search (CS) is proposed. This family of algorithms is\nan instance of General Pattern Search (GPS) methods which avoid the explicit\ncomputation of derivatives but instead evaluate the objective function while\nsearching on coordinate steps of the embedding space. The backbone element of\nCSMDS framework is the corresponding probability matrix that correspond to how\nlikely is each corresponding coordinate to be evaluated. We propose a\nBootstrapped instance of CSMDS (BS CSMDS) which enhances the probability of the\ndirection that decreases the most the objective function while also reducing\nthe corresponding probability of all the other coordinates. BS CSMDS manages to\navoid unnecessary function evaluations and result to significant speedup over\nother CSMDS alternatives while also obtaining the same error rate. Experiments\non both synthetic and real data reveal that BS CSMDS performs consistently\nbetter than other CSMDS alternatives under various experimental setups.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 22:26:55 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Tzinis", "Efthymios", ""]]}, {"id": "1902.01487", "submitter": "Ivo D\\\"untsch", "authors": "Ivo D\\\"untsch and G\\\"unther Gediga", "title": "Confusion matrices and rough set data analysis", "comments": "Equal authorship implied. To appear in the Proceedings of the 2019\n  International Conference on Pattern Recognition and Intelligent Systems (PRIS\n  2019)", "journal-ref": null, "doi": "10.1088/1742-6596/1229/1/012055", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widespread approach in machine learning to evaluate the quality of a\nclassifier is to cross -- classify predicted and actual decision classes in a\nconfusion matrix, also called error matrix. A classification tool which does\nnot assume distributional parameters but only information contained in the data\nis based on the rough set data model which assumes that knowledge is given only\nup to a certain granularity. Using this assumption and the technique of\nconfusion matrices, we define various indices and classifiers based on rough\nconfusion matrices.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 22:47:12 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["D\u00fcntsch", "Ivo", ""], ["Gediga", "G\u00fcnther", ""]]}, {"id": "1902.01500", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Francesco Orabona", "title": "Parameter-Free Online Convex Optimization with Sub-Exponential Noise", "comments": "v1: Accepted to COLT'19, v2: adjusted Theorem 3, w_t closed form\n  solution, and typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of unconstrained online convex optimization (OCO)\nwith sub-exponential noise, a strictly more general problem than the standard\nOCO. In this setting, the learner receives a subgradient of the loss functions\ncorrupted by sub-exponential noise and strives to achieve optimal regret\nguarantee, without knowledge of the competitor norm, i.e., in a parameter-free\nway. Recently, Cutkosky and Boahen (COLT 2017) proved that, given unbounded\nsubgradients, it is impossible to guarantee a sublinear regret due to an\nexponential penalty. This paper shows that it is possible to go around the\nlower bound by allowing the observed subgradients to be unbounded via\nstochastic noise. However, the presence of unbounded noise in unconstrained OCO\nis challenging; existing algorithms do not provide near-optimal regret bounds\nor fail to have a guarantee. So, we design a novel parameter-free OCO algorithm\nfor Banach space, which we call BANCO, via a reduction to betting on noisy\ncoins. We show that BANCO achieves the optimal regret rate in our problem.\nFinally, we show the application of our results to obtain a parameter-free\nlocally private stochastic subgradient descent algorithm, and the connection to\nthe law of iterated logarithms.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 00:12:00 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 20:13:27 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 21:14:34 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Orabona", "Francesco", ""]]}, {"id": "1902.01506", "submitter": "Jackson Killian", "authors": "Jackson A. Killian, Bryan Wilder, Amit Sharma, Daksha Shah, Vinod\n  Choudhary, Bistra Dilkina, Milind Tambe", "title": "Learning to Prescribe Interventions for Tuberculosis Patients Using\n  Digital Adherence Data", "comments": "10 pages, 6 figures", "journal-ref": "KDD 2019: The 25th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining", "doi": "10.1145/3292500.3330777", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Adherence Technologies (DATs) are an increasingly popular method for\nverifying patient adherence to many medications. We analyze data from one city\nserved by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB)\ntreatment in India where nearly 3 million people are afflicted with the disease\neach year. The data contains nearly 17,000 patients and 2.1M dose records. We\nlay the groundwork for learning from this real-world data, including a method\nfor avoiding the effects of unobserved interventions in training data used for\nmachine learning. We then construct a deep learning model, demonstrate its\ninterpretability, and show how it can be adapted and trained in different\nclinical scenarios to better target and improve patient care. In the real-time\nrisk prediction setting our model could be used to proactively intervene with\n21% more patients and before 76% more missed doses than current heuristic\nbaselines. For outcome prediction, our model performs 40% better than baseline\nmethods, allowing cities to target more resources to clinics with a heavier\nburden of patients at risk of failure. Finally, we present a case study\ndemonstrating how our model can be trained in an end-to-end decision focused\nlearning setting to achieve 15% better solution quality in an example decision\nproblem faced by health workers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 00:59:44 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:05:38 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 07:19:55 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Killian", "Jackson A.", ""], ["Wilder", "Bryan", ""], ["Sharma", "Amit", ""], ["Shah", "Daksha", ""], ["Choudhary", "Vinod", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1902.01509", "submitter": "Omer Levy", "authors": "Vladimir Karpukhin, Omer Levy, Jacob Eisenstein, Marjan Ghazvininejad", "title": "Training on Synthetic Noise Improves Robustness to Natural Noise in\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of making machine translation more robust to\ncharacter-level variation at the source side, such as typos. Existing methods\nachieve greater coverage by applying subword models such as byte-pair encoding\n(BPE) and character-level encoders, but these methods are highly sensitive to\nspelling mistakes. We show how training on a mild amount of random synthetic\nnoise can dramatically improve robustness to these variations, without\ndiminishing performance on clean text. We focus on translation performance on\nnatural noise, as captured by frequent corrections in Wikipedia edit logs, and\nshow that robustness to such noise can be achieved using a balanced diet of\nsimple synthetic noises at training time, without access to the natural noise\ndata or distribution.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 01:17:07 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Karpukhin", "Vladimir", ""], ["Levy", "Omer", ""], ["Eisenstein", "Jacob", ""], ["Ghazvininejad", "Marjan", ""]]}, {"id": "1902.01514", "submitter": "Yuma Kishi", "authors": "Yuma Kishi, Tsutomu Ikegami, Shin-ichi O'uchi, Ryousei Takano, Wakana\n  Nogami, Tomohiro Kudoh", "title": "Perturbative GAN: GAN with Perturbation Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perturbative GAN, which replaces convolution layers of existing convolutional\nGANs (DCGAN, WGAN-GP, BIGGAN, etc.) with perturbation layers that adds a fixed\nnoise mask, is proposed. Compared with the convolu-tional GANs, the number of\nparameters to be trained is smaller, the convergence of training is faster, the\nincep-tion score of generated images is higher, and the overall training cost\nis reduced. Algorithmic generation of the noise masks is also proposed, with\nwhich the training, as well as the generation, can be boosted with hardware\nacceleration. Perturbative GAN is evaluated using con-ventional datasets\n(CIFAR10, LSUN, ImageNet), both in the cases when a perturbation layer is\nadopted only for Generators and when it is introduced to both Generator and\nDiscriminator.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 01:43:35 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Kishi", "Yuma", ""], ["Ikegami", "Tsutomu", ""], ["O'uchi", "Shin-ichi", ""], ["Takano", "Ryousei", ""], ["Nogami", "Wakana", ""], ["Kudoh", "Tomohiro", ""]]}, {"id": "1902.01520", "submitter": "Akshay Krishnamurthy", "authors": "Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins, Chicheng\n  Zhang", "title": "Contextual Bandits with Continuous Actions: Smoothing, Zooming, and\n  Adapting", "comments": "41 pages, 1 figure, preliminary version in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual bandit learning with an abstract policy class and\ncontinuous action space. We obtain two qualitatively different regret bounds:\none competes with a smoothed version of the policy class under no continuity\nassumptions, while the other requires standard Lipschitz assumptions. Both\nbounds exhibit data-dependent \"zooming\" behavior and, with no tuning, yield\nimproved guarantees for benign problems. We also study adapting to unknown\nsmoothness parameters, establishing a price-of-adaptivity and deriving optimal\nadaptive algorithms that require no additional information.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 02:00:05 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 16:29:07 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 04:02:33 GMT"}, {"version": "v4", "created": "Sat, 20 Jun 2020 18:57:20 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Langford", "John", ""], ["Slivkins", "Aleksandrs", ""], ["Zhang", "Chicheng", ""]]}, {"id": "1902.01541", "submitter": "Fei Liu", "authors": "Fei Liu and Luke Zettlemoyer and Jacob Eisenstein", "title": "The Referential Reader: A Recurrent Entity Network for Anaphora\n  Resolution", "comments": "Published at the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL) 2019. Source code available at:\n  https://github.com/liufly/refreader", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new architecture for storing and accessing entity mentions\nduring online text processing. While reading the text, entity references are\nidentified, and may be stored by either updating or overwriting a cell in a\nfixed-length memory. The update operation implies coreference with the other\nmentions that are stored in the same cell; the overwrite operation causes these\nmentions to be forgotten. By encoding the memory operations as differentiable\ngates, it is possible to train the model end-to-end, using both a supervised\nanaphora resolution objective as well as a supplementary language modeling\nobjective. Evaluation on a dataset of pronoun-name anaphora demonstrates strong\nperformance with purely incremental text processing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 04:41:55 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 07:10:21 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Liu", "Fei", ""], ["Zettlemoyer", "Luke", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1902.01542", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh and Rahul Mazumder", "title": "Learning Hierarchical Interactions at Scale: A Convex Optimization\n  Approach", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many learning settings, it is beneficial to augment the main features with\npairwise interactions. Such interaction models can be often enhanced by\nperforming variable selection under the so-called strong hierarchy constraint:\nan interaction is non-zero only if its associated main features are non-zero.\nExisting convex optimization based algorithms face difficulties in handling\nproblems where the number of main features $p \\sim 10^3$ (with total number of\nfeatures $\\sim p^2$). In this paper, we study a convex relaxation which\nenforces strong hierarchy and develop a highly scalable algorithm based on\nproximal gradient descent. We introduce novel screening rules that allow for\nsolving the complicated proximal problem in parallel. In addition, we introduce\na specialized active-set strategy with gradient screening for avoiding costly\ngradient computations. The framework can handle problems having dense design\nmatrices, with $p = 50,000$ ($\\sim 10^9$ interactions)---instances that are\nmuch larger than current state of the art. Experiments on real and synthetic\ndata suggest that our toolkit hierScale outperforms the state of the art in\nterms of prediction and variable selection and can achieve over a 4900x\nspeed-up.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 04:47:54 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 23:48:45 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 03:29:03 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 00:54:39 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 01:13:02 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1902.01544", "submitter": "Jayanta Dey", "authors": "Jayanta Dey, Md Sanzid Bin Hossain, Mohammad Ariful Haque", "title": "An Ensemble SVM-based Approach for Voice Activity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Voice activity detection (VAD), used as the front end of speech enhancement,\nspeech and speaker recognition algorithms, determines the overall accuracy and\nefficiency of the algorithms. Therefore, a VAD with low complexity and high\naccuracy is highly desirable for speech processing applications. In this paper,\nwe propose a novel training method on large dataset for supervised\nlearning-based VAD system using support vector machine (SVM). Despite of high\nclassification accuracy of support vector machines (SVM), trivial SVM is not\nsuitable for classification of large data sets needed for a good VAD system\nbecause of high training complexity. To overcome this problem, a novel\nensemble-based approach using SVM has been proposed in this paper.The\nperformance of the proposed ensemble structure has been compared with a\nfeedforward neural network (NN). Although NN performs better than single\nSVM-based VAD trained on a small portion of the training data, ensemble SVM\ngives accuracy comparable to neural network-based VAD. Ensemble SVM and NN give\n88.74% and 86.28% accuracy respectively whereas the stand-alone SVM shows\n57.05% accuracy on average on the test dataset.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 04:48:17 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Dey", "Jayanta", ""], ["Hossain", "Md Sanzid Bin", ""], ["Haque", "Mohammad Ariful", ""]]}, {"id": "1902.01554", "submitter": "Daewoo Kim", "authors": "Daewoo Kim, Sangwoo Moon, David Hostallero, Wan Ju Kang, Taeyoung Lee,\n  Kyunghwan Son, Yung Yi", "title": "Learning to Schedule Communication in Multi-agent Reinforcement Learning", "comments": "Accepted in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world reinforcement learning tasks require multiple agents to make\nsequential decisions under the agents' interaction, where well-coordinated\nactions among the agents are crucial to achieve the target goal better at these\ntasks. One way to accelerate the coordination effect is to enable multiple\nagents to communicate with each other in a distributed manner and behave as a\ngroup. In this paper, we study a practical scenario when (i) the communication\nbandwidth is limited and (ii) the agents share the communication medium so that\nonly a restricted number of agents are able to simultaneously use the medium,\nas in the state-of-the-art wireless networking standards. This calls for a\ncertain form of communication scheduling. In that regard, we propose a\nmulti-agent deep reinforcement learning framework, called SchedNet, in which\nagents learn how to schedule themselves, how to encode the messages, and how to\nselect actions based on received messages. SchedNet is capable of deciding\nwhich agents should be entitled to broadcasting their (encoded) messages, by\nlearning the importance of each agent's partially observed information. We\nevaluate SchedNet against multiple baselines under two different applications,\nnamely, cooperative communication and navigation, and predator-prey. Our\nexperiments show a non-negligible performance gap between SchedNet and other\nmechanisms such as the ones without communication and with vanilla scheduling\nmethods, e.g., round robin, ranging from 32% to 43%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 05:51:36 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Kim", "Daewoo", ""], ["Moon", "Sangwoo", ""], ["Hostallero", "David", ""], ["Kang", "Wan Ju", ""], ["Lee", "Taeyoung", ""], ["Son", "Kyunghwan", ""], ["Yi", "Yung", ""]]}, {"id": "1902.01568", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Yuting Wang, Pritish Sahu, Vladimir Pavlovic", "title": "Relevance Factor VAE: Learning and Identifying Disentangled Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel VAE-based deep auto-encoder model that can learn\ndisentangled latent representations in a fully unsupervised manner, endowed\nwith the ability to identify all meaningful sources of variation and their\ncardinality. Our model, dubbed Relevance-Factor-VAE, leverages the total\ncorrelation (TC) in the latent space to achieve the disentanglement goal, but\nalso addresses the key issue of existing approaches which cannot distinguish\nbetween meaningful and nuisance factors of latent variation, often the source\nof considerable degradation in disentanglement performance. We tackle this\nissue by introducing the so-called relevance indicator variables that can be\nautomatically learned from data, together with the VAE parameters. Our model\neffectively focuses the TC loss onto the relevant factors only by tolerating\nlarge prior KL divergences, a desideratum justified by our semi-parametric\ntheoretical analysis. Using a suite of disentanglement metrics, including a\nnewly proposed one, as well as qualitative evidence, we demonstrate that our\nmodel outperforms existing methods across several challenging benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 06:55:36 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Kim", "Minyoung", ""], ["Wang", "Yuting", ""], ["Sahu", "Pritish", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1902.01575", "submitter": "Emilie Kaufmann", "authors": "Lilian Besson (IRISA), Emilie Kaufmann (CNRS, CRIStAL, Scool),\n  Odalric-Ambrym Maillard (Scool), Julien Seznec (Scool)", "title": "Efficient Change-Point Detection for Tackling Piecewise-Stationary\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GLR-klUCB, a novel algorithm for the piecewise iid\nnon-stationary bandit problem with bounded rewards. This algorithm combines an\nefficient bandit algorithm, kl-UCB, with an efficient, parameter-free,\nchangepoint detector, the Bernoulli Generalized Likelihood Ratio Test, for\nwhich we provide new theoretical guarantees of independent interest. Unlike\nprevious non-stationary bandit algorithms using a change-point detector,\nGLR-klUCB does not need to be calibrated based on prior knowledge on the arms'\nmeans. We prove that this algorithm can attain a $O(\\sqrt{TA\n\\Upsilon_T\\log(T)})$ regret in $T$ rounds on some \"easy\" instances, where A is\nthe number of arms and $\\Upsilon_T$ the number of change-points, without prior\nknowledge of $\\Upsilon_T$. In contrast with recently proposed algorithms that\nare agnostic to $\\Upsilon_T$, we perform a numerical study showing that\nGLR-klUCB is also very efficient in practice, beyond easy instances.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 07:37:48 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 11:12:25 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Besson", "Lilian", "", "IRISA"], ["Kaufmann", "Emilie", "", "CNRS, CRIStAL, Scool"], ["Maillard", "Odalric-Ambrym", "", "Scool"], ["Seznec", "Julien", "", "Scool"]]}, {"id": "1902.01600", "submitter": "Michel  Barlaud", "authors": "Michel Barlaud and Antonin Chambolle and Jean-Baptiste Caillau", "title": "Robust supervised classification and feature selection using a\n  primal-dual method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with supervised classification and feature selection in high\ndimensional space. A classical approach is to project data on a low dimensional\nspace and classify by minimizing an appropriate quadratic cost. A strict\ncontrol on sparsity is moreover obtained by adding an $\\ell_1$ constraint, here\non the matrix of weights used for projecting the data. Tuning the sparsity\nbound results in selecting the relevant features for supervised classification.\nIt is well known that using a quadratic cost is not robust to outliers. We cope\nwith this problem by using an $\\ell_1$ norm both for the constraint and for the\nloss function. In this case, the criterion is convex but not gradient Lipschitz\nanymore. Another second issue is that we optimize simultaneously the projection\nmatrix and the centers used for classification. In this paper, we provide a\nnovel tailored constrained primal-dual method to compute jointly selected\nfeatures and classifiers. Extending our primal-dual method to other criteria is\neasy provided that efficient projection (on the dual ball for the loss data\nterm) and prox (for the regularization term) algorithms are available. We\nillustrate such an extension in the case of a Frobenius norm for the loss term.\nWe provide a convergence proof of our primal-dual method, and demonstrate its\neffectiveness on three datasets (one synthetic, two from biological data) on\nwhich we compare $\\ell_1$ and $\\ell_2$ costs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 09:20:44 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 07:05:53 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 12:01:56 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 07:56:37 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Barlaud", "Michel", ""], ["Chambolle", "Antonin", ""], ["Caillau", "Jean-Baptiste", ""]]}, {"id": "1902.01605", "submitter": "Simon Leglaive", "authors": "Simon Leglaive, Laurent Girin, Radu Horaud", "title": "A variance modeling framework based on variational autoencoders for\n  speech enhancement", "comments": "6 pages, 3 figures", "journal-ref": "Proc. of the IEEE International Workshop on Machine Learning for\n  Signal Processing (MLSP), Aalborg, Denmark, September 2018", "doi": "10.1109/MLSP.2018.8516711", "report-no": "hal-01832826v1", "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of enhancing speech signals in noisy\nmixtures using a source separation approach. We explore the use of neural\nnetworks as an alternative to a popular speech variance model based on\nsupervised non-negative matrix factorization (NMF). More precisely, we use a\nvariational autoencoder as a speaker-independent supervised generative speech\nmodel, highlighting the conceptual similarities that this approach shares with\nits NMF-based counterpart. In order to be free of generalization issues\nregarding the noisy recording environments, we follow the approach of having a\nsupervised model only for the target speech signal, the noise model being based\non unsupervised NMF. We develop a Monte Carlo expectation-maximization\nalgorithm for inferring the latent variables in the variational autoencoder and\nestimating the unsupervised model parameters. Experiments show that the\nproposed method outperforms a semi-supervised NMF baseline and a\nstate-of-the-art fully supervised deep learning approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 09:36:18 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Leglaive", "Simon", ""], ["Girin", "Laurent", ""], ["Horaud", "Radu", ""]]}, {"id": "1902.01613", "submitter": "Hidehito Yabuuchi", "authors": "Hidehito Yabuuchi, Daisuke Taniwaki, Shingo Omura", "title": "Low-latency job scheduling with preemption for the development of deep\n  learning", "comments": "10 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One significant challenge in the job scheduling of computing clusters for the\ndevelopment of deep learning algorithms is the efficient scheduling of\ntrial-and-error (TE) job, the type of job in which the users seek to conduct\nsmall-scale experiments while monitoring their processes. Unfortunately, the\nexisting job schedulers to date do not feature well-balanced scheduling for the\nmixture of TE jobs and best-effort (BE) jobs, or they can handle the mixture in\nlimited situations at most. To fill in this niche, we propose an algorithm that\ncan significantly reduce the latency of TE jobs in versatile situations without\ngreatly elongating the slowdown of the BE jobs. Our algorithm efficiently\nschedules both TE and BE jobs by selectively preempting the BE jobs that can\nbe, when the time comes, resumed without much delay. In our simulation study\nwith synthetic and real workloads, we were able to reduce the 95th percentile\nof the slowdown rates for the TE jobs in the standard FIFO strategy by 96.6%,\nwhile compromising the median of the BE slowdown rates by only 18.0% and the\n95th percentile by only 23.9%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 09:46:53 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Yabuuchi", "Hidehito", ""], ["Taniwaki", "Daisuke", ""], ["Omura", "Shingo", ""]]}, {"id": "1902.01632", "submitter": "Steven Squires", "authors": "Steven Squires, Adam Prugel Bennett and Mahesan Niranjan", "title": "Minimum description length as an objective function for non-negative\n  matrix factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a dimensionality reduction\ntechnique which tends to produce a sparse representation of data. Commonly, the\nerror between the actual and recreated matrices is used as an objective\nfunction, but this method may not produce the type of representation we desire\nas it allows for the complexity of the model to grow, constrained only by the\nsize of the subspace and the non-negativity requirement. If additional\nconstraints, such as sparsity, are imposed the question of parameter selection\nbecomes critical. Instead of adding sparsity constraints in an ad-hoc manner we\npropose a novel objective function created by using the principle of minimum\ndescription length (MDL). Our formulation, MDL-NMF, automatically trades off\nbetween the complexity and accuracy of the model using a principled approach\nwith little parameter selection or the need for domain expertise. We\ndemonstrate our model works effectively on three heterogeneous data-sets and on\na range of semi-synthetic data showing the broad applicability of our method.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 10:25:14 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Squires", "Steven", ""], ["Bennett", "Adam Prugel", ""], ["Niranjan", "Mahesan", ""]]}, {"id": "1902.01635", "submitter": "Boris Shustin", "authors": "Boris Shustin and Haim Avron", "title": "Preconditioned Riemannian Optimization on the Generalized Stiefel\n  Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization problems on the generalized Stiefel manifold (and products of\nit) are prevalent across science and engineering. For example, in computational\nscience they arise in the symmetric (generalized) eigenvalue problem, in\nnonlinear eigenvalue problems, and in electronic structures computations, to\nname a few problems. In statistics and machine learning, they arise, for\nexample, in various dimensionality reduction techniques such as canonical\ncorrelation analysis. In deep learning, regularization and improved stability\ncan be obtained by constraining some layers to have parameter matrices that\nbelong to the Stiefel manifold. Solving problems on the generalized Stiefel\nmanifold can be approached via the tools of Riemannian optimization. However,\nusing the standard geometric components for the generalized Stiefel manifold\nhas two possible shortcoming: computing some of the geometric components can be\ntoo expensive and converge can be rather slow in certain cases. Both\nshortcomings can be addressed using a technique called Riemannian\npreconditioning, which amounts to using geometric components derived using a\nprecoditioner that defines a Riemannian metric on the constraint manifold. In\nthis paper we develop the geometric components required to perform Riemannian\noptimization on the generalized Stiefel manifold equipped with a non-standard\nmetric, and illustrate theoretically and numerically the use of those\ncomponents and the effect of Riemannian preconditioning for solving\noptimization problems on the generalized Stiefel manifold.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 10:42:00 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 06:32:05 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 16:17:53 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Shustin", "Boris", ""], ["Avron", "Haim", ""]]}, {"id": "1902.01637", "submitter": "Kfir Levy Yehuda", "authors": "Francis Bach, Kfir Y. Levy", "title": "A Universal Algorithm for Variational Inequalities Adaptive to\n  Smoothness and Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider variational inequalities coming from monotone operators, a\nsetting that includes convex minimization and convex-concave saddle-point\nproblems. We assume an access to potentially noisy unbiased values of the\nmonotone operators and assess convergence through a compatible gap function\nwhich corresponds to the standard optimality criteria in the aforementioned\nsubcases. We present a universal algorithm for these inequalities based on the\nMirror-Prox algorithm. Concretely, our algorithm simultaneously achieves the\noptimal rates for the smooth/non-smooth, and noisy/noiseless settings. This is\ndone without any prior knowledge of these properties, and in the general set-up\nof arbitrary norms and compatible Bregman divergences. For convex minimization\nand convex-concave saddle-point problems, this leads to new adaptive\nalgorithms. Our method relies on a novel yet simple adaptive choice of the\nstep-size, which can be seen as the appropriate extension of AdaGrad to handle\nconstrained problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 10:48:14 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Bach", "Francis", ""], ["Levy", "Kfir Y.", ""]]}, {"id": "1902.01639", "submitter": "Lorenzo Rimella", "authors": "Lorenzo Rimella, Nick Whiteley", "title": "Exploiting locality in high-dimensional factorial hidden Markov models", "comments": "30 pages, 50 pages of appendix, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms for approximate filtering and smoothing in\nhigh-dimensional factorial hidden Markov models. The approximation involves\ndiscarding, in a principled way, likelihood factors according a notion of\nlocality in a factor graph associated with the emission distribution. This\nallows the exponential-in-dimension cost of exact filtering and smoothing to be\navoided. We prove that the approximation accuracy, measured in a local total\nvariation norm, is `dimension-free' in the sense that as the overall dimension\nof the model increases the error bounds we derive do not necessarily degrade. A\nkey step in the analysis is to quantify the error introduced by localizing the\nlikelihood function in a Bayes' rule update. The factorial structure of the\nlikelihood function which we exploit arises naturally when data have known\nspatial or network structure. We demonstrate the new algorithms on synthetic\nexamples and a London Underground passenger flow problem, where the factor\ngraph is effectively given by the train network.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 10:56:46 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 18:20:36 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Rimella", "Lorenzo", ""], ["Whiteley", "Nick", ""]]}, {"id": "1902.01644", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "On the Convergence of Projected-Gradient Methods with Low-Rank\n  Projections for Smooth Convex Minimization over Trace-Norm Balls and Related\n  Problems", "comments": "Accepted to SIAM Journal on Optimization (SIOPT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth convex minimization over the unit trace-norm ball is an important\noptimization problem in machine learning, signal processing, statistics and\nother fields, that underlies many tasks in which one wishes to recover a\nlow-rank matrix given certain measurements. While first-order methods for\nconvex optimization enjoy optimal convergence rates, they require in worst-case\nto compute a full-rank SVD on each iteration, in order to compute the\nprojection onto the trace-norm ball. These full-rank SVD computations however\nprohibit the application of such methods to large problems. A simple and\nnatural heuristic to reduce the computational cost is to approximate the\nprojection using only a low-rank SVD. This raises the question if, and under\nwhat conditions, this simple heuristic can indeed result in provable\nconvergence to the optimal solution. In this paper we show that any optimal\nsolution is a center of a Euclid. ball inside-which the projected-gradient\nmapping admits rank that is at most the multiplicity of the largest singular\nvalue of the gradient vector. Moreover, the radius of the ball scales with the\nspectral gap of this gradient vector. We show how this readily implies the\nlocal convergence (i.e., from a \"warm-start\" initialization) of standard\nfirst-order methods, using only low-rank SVD computations. We also quantify the\neffect of \"over-parameterization\", i.e., using SVD computations with higher\nrank, on the radius of this ball, showing it can increase dramatically with\nmoderately larger rank. We extend our results also to the setting of\noptimization with trace-norm regularization and optimization over bounded-trace\npositive semidefinite matrices. Our theoretical investigation is supported by\nconcrete empirical evidence that demonstrates the \\textit{correct} convergence\nof first-order methods with low-rank projections on real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 11:21:18 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 19:08:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1902.01659", "submitter": "Michael Moor", "authors": "Michael Moor and Max Horn and Bastian Rieck and Damian Roqueiro and\n  Karsten Borgwardt", "title": "Early Recognition of Sepsis with Gaussian Process Temporal Convolutional\n  Networks and Dynamic Time Warping", "comments": "Accepted at the Machine Learning for Healthcare 2019 Conference\n  (MLHC). Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a life-threatening host response to infection associated with high\nmortality, morbidity, and health costs. Its management is highly time-sensitive\nsince each hour of delayed treatment increases mortality due to irreversible\norgan damage. Meanwhile, despite decades of clinical research, robust\nbiomarkers for sepsis are missing. Therefore, detecting sepsis early by\nutilizing the affluence of high-resolution intensive care records has become a\nchallenging machine learning problem. Recent advances in deep learning and data\nmining promise to deliver a powerful set of tools to efficiently address this\ntask. This empirical study proposes two novel approaches for the early\ndetection of sepsis: a deep learning model and a lazy learner based on time\nseries distances. Our deep learning model employs a temporal convolutional\nnetwork that is embedded in a Multi-task Gaussian Process Adapter framework,\nmaking it directly applicable to irregularly-spaced time series data. Our lazy\nlearner, by contrast, is an ensemble approach that employs dynamic time\nwarping. We frame the timely detection of sepsis as a supervised time series\nclassification task. For this, we derive the most recent sepsis definition in\nan hourly resolution to provide the first fully accessible early sepsis\ndetection environment. Seven hours before sepsis onset, our methods improve\narea under the precision--recall curve from 0.25 to 0.35/0.40 over the state of\nthe art. This demonstrates that they are well-suited for detecting sepsis in\nthe crucial earlier stages when management is most effective.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 12:35:54 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 12:53:23 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 13:18:53 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 12:44:49 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Moor", "Michael", ""], ["Horn", "Max", ""], ["Rieck", "Bastian", ""], ["Roqueiro", "Damian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1902.01670", "submitter": "Anis Najar", "authors": "Anis Najar, Olivier Sigaud, Mohamed Chetouani", "title": "Interactively shaping robot behaviour with unlabeled human instructions", "comments": null, "journal-ref": "Auton Agent Multi-Agent Syst 34, 35 (2020)", "doi": "10.1007/s10458-020-09459-6", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework that enables a human teacher to shape a\nrobot behaviour by interactively providing it with unlabeled instructions. We\nground the meaning of instruction signals in the task-learning process, and use\nthem simultaneously for guiding the latter. We implement our framework as a\nmodular architecture, named TICS (Task-Instruction-Contingency-Shaping) that\ncombines different information sources: a predefined reward function, human\nevaluative feedback and unlabeled instructions. This approach provides a novel\nperspective for robotic task learning that lies between Reinforcement Learning\nand Supervised Learning paradigms. We evaluate our framework both in simulation\nand with a real robot. The experimental results demonstrate the effectiveness\nof our framework in accelerating the task-learning process and in reducing the\nnumber of required teaching signals.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 13:26:53 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:33:55 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Najar", "Anis", ""], ["Sigaud", "Olivier", ""], ["Chetouani", "Mohamed", ""]]}, {"id": "1902.01686", "submitter": "Sergei Volodin", "authors": "El-Mahdi El-Mhamdi, Rachid Guerraoui, Andrei Kucharavy, Sergei Volodin", "title": "The Probabilistic Fault Tolerance of Neural Networks in the Continuous\n  Limit", "comments": "10 pages (without references), 2 figures, 2 tables, 1 algorithm, 26\n  pages of supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss of a few neurons in a brain rarely results in any visible loss of\nfunction. However, the insight into what \"few\" means in this context is\nunclear. How many random neuron failures will it take to lead to a visible loss\nof function? In this paper, we address the fundamental question of the impact\nof the crash of a random subset of neurons on the overall computation of a\nneural network and the error in the output it produces. We study fault\ntolerance of neural networks subject to small random neuron/weight crash\nfailures in a probabilistic setting. We give provable guarantees on the\nrobustness of the network to these crashes. Our main contribution is a bound on\nthe error in the output of a network under small random Bernoulli crashes\nproved by using a Taylor expansion in the continuous limit, where close-by\nneurons at a layer are similar. The failure mode we adopt in our model is\ncharacteristic of neuromorphic hardware, a promising technology to speed up\nartificial neural networks, as well as of biological networks. We show that our\ntheoretical bounds can be used to compare the fault tolerance of different\narchitectures and to design a regularizer improving the fault tolerance of a\ngiven architecture. We design an algorithm achieving fault tolerance using a\nreasonable number of neurons. In addition to the theoretical proof, we also\nprovide experimental validation of our results and suggest a connection to the\ngeneralization capacity problem.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:08:21 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:18:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Kucharavy", "Andrei", ""], ["Volodin", "Sergei", ""]]}, {"id": "1902.01687", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Ben Boukai, Zuofeng Shang", "title": "Optimal Nonparametric Inference via Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network is a state-of-art method in modern science and\ntechnology. Much statistical literature have been devoted to understanding its\nperformance in nonparametric estimation, whereas the results are suboptimal due\nto a redundant logarithmic sacrifice. In this paper, we show that such\nlog-factors are not necessary. We derive upper bounds for the $L^2$ minimax\nrisk in nonparametric estimation. Sufficient conditions on network\narchitectures are provided such that the upper bounds become optimal (without\nlog-sacrifice). Our proof relies on an explicitly constructed network estimator\nbased on tensor product B-splines. We also derive asymptotic distributions for\nthe constructed network and a relating hypothesis testing procedure. The\ntesting procedure is further proven as minimax optimal under suitable network\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:09:17 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Liu", "Ruiqi", ""], ["Boukai", "Ben", ""], ["Shang", "Zuofeng", ""]]}, {"id": "1902.01697", "submitter": "Alinson Santos Xavier", "authors": "Alinson S. Xavier, Feng Qiu and Shabbir Ahmed", "title": "Learning to Solve Large-Scale Security-Constrained Unit Commitment\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security-Constrained Unit Commitment (SCUC) is a fundamental problem in power\nsystems and electricity markets. In practical settings, SCUC is repeatedly\nsolved via Mixed-Integer Linear Programming, sometimes multiple times per day,\nwith only minor changes in input data. In this work, we propose a number of\nmachine learning (ML) techniques to effectively extract information from\npreviously solved instances in order to significantly improve the computational\nperformance of MIP solvers when solving similar instances in the future. Based\non statistical data, we predict redundant constraints in the formulation, good\ninitial feasible solutions and affine subspaces where the optimal solution is\nlikely to lie, leading to significant reduction in problem size. Computational\nresults on a diverse set of realistic and large-scale instances show that,\nusing the proposed techniques, SCUC can be solved on average 4.3x faster with\noptimality guarantees, and 10.2x faster without optimality guarantees, but with\nno observed reduction in solution quality. Out-of-distribution experiments\nprovides evidence that the method is somewhat robust against dataset shift.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:36:52 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 16:04:29 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Xavier", "Alinson S.", ""], ["Qiu", "Feng", ""], ["Ahmed", "Shabbir", ""]]}, {"id": "1902.01722", "submitter": "Paavo Parmas", "authors": "Paavo Parmas", "title": "Total stochastic gradient algorithms and applications in reinforcement\n  learning", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation and the chain rule of derivatives have been prominent;\nhowever, the total derivative rule has not enjoyed the same amount of\nattention. In this work we show how the total derivative rule leads to an\nintuitive visual framework for creating gradient estimators on graphical\nmodels. In particular, previous \"policy gradient theorems\" are easily derived.\nWe derive new gradient estimators based on density estimation, as well as a\nlikelihood ratio gradient, which \"jumps\" to an intermediate node, not directly\nto the objective function. We evaluate our methods on model-based policy\ngradient algorithms, achieve good performance, and present evidence towards\ndemystifying the success of the popular PILCO algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:54:05 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Parmas", "Paavo", ""]]}, {"id": "1902.01724", "submitter": "Kai Arulkumaran", "authors": "Kai Arulkumaran, Antoine Cully, Julian Togelius", "title": "AlphaStar: An Evolutionary Computation Perspective", "comments": "Genetic and EvolutionaryComputation Conference Companion 2019", "journal-ref": null, "doi": "10.1145/3319619.3321894", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In January 2019, DeepMind revealed AlphaStar to the world-the first\nartificial intelligence (AI) system to beat a professional player at the game\nof StarCraft II-representing a milestone in the progress of AI. AlphaStar draws\non many areas of AI research, including deep learning, reinforcement learning,\ngame theory, and evolutionary computation (EC). In this paper we analyze\nAlphaStar primarily through the lens of EC, presenting a new look at the system\nand relating it to many concepts in the field. We highlight some of its most\ninteresting aspects-the use of Lamarckian evolution, competitive co-evolution,\nand quality diversity. In doing so, we hope to provide a bridge between the\nwider EC community and one of the most significant AI systems developed in\nrecent times.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:57:15 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 15:05:35 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 16:16:44 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Arulkumaran", "Kai", ""], ["Cully", "Antoine", ""], ["Togelius", "Julian", ""]]}, {"id": "1902.01729", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Shuo Lei, Liang Zhao, Arnold P. Boedihardjo, Chang-Tien\n  Lu", "title": "Robust Regression via Online Feature Selection under Adversarial Data\n  Corruption", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of data corruption in user-generated streaming data, such as\nsocial media, motivates a new fundamental problem that learns reliable\nregression coefficient when features are not accessible entirely at one time.\nUntil now, several important challenges still cannot be handled concurrently:\n1) corrupted data estimation when only partial features are accessible; 2)\nonline feature selection when data contains adversarial corruption; and 3)\nscaling to a massive dataset. This paper proposes a novel RObust regression\nalgorithm via Online Feature Selection (\\textit{RoOFS}) that concurrently\naddresses all the above challenges. Specifically, the algorithm iteratively\nupdates the regression coefficients and the uncorrupted set via a robust online\nfeature substitution method. We also prove that our algorithm has a restricted\nerror bound compared to the optimal solution. Extensive empirical experiments\nin both synthetic and real-world datasets demonstrated that the effectiveness\nof our new method is superior to that of existing methods in the recovery of\nboth feature selection and regression coefficients, with very competitive\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:05:32 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Zhang", "Xuchao", ""], ["Lei", "Shuo", ""], ["Zhao", "Liang", ""], ["Boedihardjo", "Arnold P.", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1902.01737", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Antonio Bruno", "title": "Deep Tree Transductions - A Short Survey", "comments": "To appear in the Proceedings of the 2019 INNS Big Data and Deep\n  Learning (INNSBDDL 2019). arXiv admin note: text overlap with\n  arXiv:1809.09096", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper surveys recent extensions of the Long-Short Term Memory networks to\nhandle tree structures from the perspective of learning non-trivial forms of\nisomorph structured transductions. It provides a discussion of modern TreeLSTM\nmodels, showing the effect of the bias induced by the direction of tree\nprocessing. An empirical analysis is performed on real-world benchmarks,\nhighlighting how there is no single model adequate to effectively approach all\ntransduction problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:18:47 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Bacciu", "Davide", ""], ["Bruno", "Antonio", ""]]}, {"id": "1902.01738", "submitter": "Max Aalto", "authors": "Max Aalto and Nakul Verma", "title": "Metric Learning on Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature has shown that symbolic data, such as text and graphs, is\noften better represented by points on a curved manifold, rather than in\nEuclidean space. However, geometrical operations on manifolds are generally\nmore complicated than in Euclidean space, and thus many techniques for\nprocessing and analysis taken for granted in Euclidean space are difficult on\nmanifolds. A priori, it is not obvious how we may generalize such methods to\nmanifolds. We consider specifically the problem of distance metric learning,\nand present a framework that solves it on a large class of manifolds, such that\nsimilar data are located in closer proximity with respect to the manifold\ndistance function. In particular, we extend the existing metric learning\nalgorithms, and derive the corresponding sample complexity rates for the case\nof manifolds. Additionally, we demonstrate an improvement of performance in\n$k$-means clustering and $k$-nearest neighbor classification on real-world\ncomplex networks using our methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:21:22 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Aalto", "Max", ""], ["Verma", "Nakul", ""]]}, {"id": "1902.01753", "submitter": "Ji Xu", "authors": "Ji Xu and Arian Maleki and Kamiar Rahnama Rad and Daniel Hsu", "title": "Consistent Risk Estimation in Moderately High-Dimensional Linear\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk estimation is at the core of many learning systems. The importance of\nthis problem has motivated researchers to propose different schemes, such as\ncross validation, generalized cross validation, and Bootstrap. The theoretical\nproperties of such estimates have been extensively studied in the\nlow-dimensional settings, where the number of predictors $p$ is much smaller\nthan the number of observations $n$. However, a unifying methodology\naccompanied with a rigorous theory is lacking in high-dimensional settings.\nThis paper studies the problem of risk estimation under the moderately\nhigh-dimensional asymptotic setting $n,p \\rightarrow \\infty$ and $n/p\n\\rightarrow \\delta>1$ ($\\delta$ is a fixed number), and proves the consistency\nof three risk estimates that have been successful in numerical studies, i.e.,\nleave-one-out cross validation (LOOCV), approximate leave-one-out (ALO), and\napproximate message passing (AMP)-based techniques. A corner stone of our\nanalysis is a bound that we obtain on the discrepancy of the `residuals'\nobtained from AMP and LOOCV. This connection not only enables us to obtain a\nmore refined information on the estimates of AMP, ALO, and LOOCV, but also\noffers an upper bound on the convergence rate of each estimate.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:52:39 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 03:57:47 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 17:38:15 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Xu", "Ji", ""], ["Maleki", "Arian", ""], ["Rad", "Kamiar Rahnama", ""], ["Hsu", "Daniel", ""]]}, {"id": "1902.01777", "submitter": "Bastian Seifert", "authors": "Katharina Korn and Bastian Seifert and Christian Uhl", "title": "Dynamical Component Analysis (DyCA) and its application on epileptic EEG", "comments": "5 pages, 4 figures, accepted for IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP) 2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682601", "report-no": null, "categories": "eess.SP cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical Component Analysis (DyCA) is a recently-proposed method to detect\nprojection vectors to reduce the dimensionality of multi-variate deterministic\ndatasets. It is based on the solution of a generalized eigenvalue problem and\ntherefore straight forward to implement. DyCA is introduced and applied to EEG\ndata of epileptic seizures. The obtained eigenvectors are used to project the\nsignal and the corresponding trajectories in phase space are compared with PCA\nand ICA-projections. The eigenvalues of DyCA are utilized for seizure detection\nand the obtained results in terms of specificity, false discovery rate and miss\nrate are compared to other seizure detection algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:38:58 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Korn", "Katharina", ""], ["Seifert", "Bastian", ""], ["Uhl", "Christian", ""]]}, {"id": "1902.01780", "submitter": "Stephan Alaniz", "authors": "Stephan Alaniz, Diego Marcos, Bernt Schiele, Zeynep Akata", "title": "Learning Decision Trees Recurrently Through Communication", "comments": "Accepted in IEEE CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated interpretability without sacrificing the prediction accuracy of\ndecision making algorithms has the potential of greatly improving their value\nto the user. Instead of assigning a label to an image directly, we propose to\nlearn iterative binary sub-decisions, inducing sparsity and transparency in the\ndecision making process. The key aspect of our model is its ability to build a\ndecision tree whose structure is encoded into the memory representation of a\nRecurrent Neural Network jointly learned by two models communicating through\nmessage passing. In addition, our model assigns a semantic meaning to each\ndecision in the form of binary attributes, providing concise, semantic and\nrelevant rationalizations to the user. On three benchmark image classification\ndatasets, including the large-scale ImageNet, our model generates human\ninterpretable binary decision sequences explaining the predictions of the\nnetwork while maintaining state-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:40:34 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 12:00:07 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 19:26:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Alaniz", "Stephan", ""], ["Marcos", "Diego", ""], ["Schiele", "Bernt", ""], ["Akata", "Zeynep", ""]]}, {"id": "1902.01785", "submitter": "Thomas Frerix", "authors": "Thomas Frerix, Matthias Nie{\\ss}ner, Daniel Cremers", "title": "Homogeneous Linear Inequality Constraints for Neural Network Activations", "comments": "CVPR 2020 DeepVision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to impose homogeneous linear inequality constraints of\nthe form $Ax\\leq 0$ on neural network activations. The proposed method allows a\ndata-driven training approach to be combined with modeling prior knowledge\nabout the task. One way to achieve this task is by means of a projection step\nat test time after unconstrained training. However, this is an expensive\noperation. By directly incorporating the constraints into the architecture, we\ncan significantly speed-up inference at test time; for instance, our\nexperiments show a speed-up of up to two orders of magnitude over a projection\nmethod. Our algorithm computes a suitable parameterization of the feasible set\nat initialization and uses standard variants of stochastic gradient descent to\nfind solutions to the constrained network. Thus, the modeling constraints are\nalways satisfied during training. Crucially, our approach avoids to solve an\noptimization problem at each training step or to manually trade-off data and\nconstraint fidelity with additional hyperparameters. We consider constrained\ngenerative modeling as an important application domain and experimentally\ndemonstrate the proposed method by constraining a variational autoencoder.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:44:55 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 10:23:41 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 17:12:12 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 10:18:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Frerix", "Thomas", ""], ["Nie\u00dfner", "Matthias", ""], ["Cremers", "Daniel", ""]]}, {"id": "1902.01799", "submitter": "Seyedroohollah Hosseini", "authors": "Seyedroohollah Hosseini, Xuan Guo", "title": "Deep Convolutional Neural Network for Automated Detection of Mind\n  Wandering using EEG Signals", "comments": "4 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mind wandering (MW) is a ubiquitous phenomenon which reflects a shift in\nattention from task-related to task-unrelated thoughts. There is a need for\nintelligent interfaces that can reorient attention when MW is detected due to\nits detrimental effects on performance and productivity. In this paper, we\npropose a deep learning model for MW detection using Electroencephalogram (EEG)\nsignals. Specifically, we develop a channel-wise deep convolutional neural\nnetwork (CNN) model to classify the features of focusing state and MW extracted\nfrom EEG signals. This is the first study that employs CNN to automatically\ndetect MW using only EEG data. The experimental results on the collected\ndataset demonstrate promising performance with 91.78% accuracy, 92.84%\nsensitivity, and 90.73% specificity.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 17:13:06 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Hosseini", "Seyedroohollah", ""], ["Guo", "Xuan", ""]]}, {"id": "1902.01813", "submitter": "Felix Dangel", "authors": "Felix Dangel, Stefan Harmeling, Philipp Hennig", "title": "Modular Block-diagonal Curvature Approximations for Feedforward\n  Architectures", "comments": "9 pages, 5 figures, 1 table, supplements included (13 pages, 6\n  figures, 2 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modular extension of backpropagation for the computation of\nblock-diagonal approximations to various curvature matrices of the training\nobjective (in particular, the Hessian, generalized Gauss-Newton, and\npositive-curvature Hessian). The approach reduces the otherwise tedious manual\nderivation of these matrices into local modules, and is easy to integrate into\nexisting machine learning libraries. Moreover, we develop a compact notation\nderived from matrix differential calculus. We outline different strategies\napplicable to our method. They subsume recently-proposed block-diagonal\napproximations as special cases, and are extended to convolutional neural\nnetworks in this work.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 17:39:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 16:36:08 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 18:23:23 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Dangel", "Felix", ""], ["Harmeling", "Stefan", ""], ["Hennig", "Philipp", ""]]}, {"id": "1902.01838", "submitter": "Amritanshu Agrawal", "authors": "Amritanshu Agrawal, Wei Fu, Di Chen, Xipeng Shen, Tim Menzies", "title": "How to \"DODGE\" Complex Software Analytics?", "comments": "13 Pages, Accepted to IEEE Transactions in Software Engineering, 2019", "journal-ref": null, "doi": "10.1109/TSE.2019.2945020", "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques applied to software engineering tasks can be\nimproved by hyperparameter optimization, i.e., automatic tools that find good\nsettings for a learner's control parameters.\n  We show that such hyperparameter optimization can be unnecessarily slow,\nparticularly when the optimizers waste time exploring \"redundant tunings\"',\ni.e., pairs of tunings which lead to indistinguishable results. By ignoring\nredundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while\nalso generating learners with more accurate predictions than seen in prior\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 18:16:56 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 23:45:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Agrawal", "Amritanshu", ""], ["Fu", "Wei", ""], ["Chen", "Di", ""], ["Shen", "Xipeng", ""], ["Menzies", "Tim", ""]]}, {"id": "1902.01843", "submitter": "Grant Rotskoff", "authors": "Grant Rotskoff, Samy Jelassi, Joan Bruna, and Eric Vanden-Eijnden", "title": "Global convergence of neuron birth-death dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with a large number of parameters admit a mean-field\ndescription, which has recently served as a theoretical explanation for the\nfavorable training properties of \"overparameterized\" models. In this regime,\ngradient descent obeys a deterministic partial differential equation (PDE) that\nconverges to a globally optimal solution for networks with a single hidden\nlayer under appropriate assumptions. In this work, we propose a non-local mass\ntransport dynamics that leads to a modified PDE with the same minimizer. We\nimplement this non-local dynamics as a stochastic neuronal birth-death process\nand we prove that it accelerates the rate of convergence in the mean-field\nlimit. We subsequently realize this PDE with two classes of numerical schemes\nthat converge to the mean-field equation, each of which can easily be\nimplemented for neural networks with finite numbers of parameters. We\nillustrate our algorithms with two models to provide intuition for the\nmechanism through which convergence is accelerated.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 18:24:10 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 15:30:25 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Rotskoff", "Grant", ""], ["Jelassi", "Samy", ""], ["Bruna", "Joan", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "1902.01846", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Nicol\\`o Cesa-Bianchi, Csaba Szepesv\\'ari", "title": "Distribution-Dependent Analysis of Gibbs-ERM Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs-ERM learning is a natural idealized model of learning with stochastic\noptimization algorithms (such as Stochastic Gradient Langevin Dynamics and\n---to some extent--- Stochastic Gradient Descent), while it also arises in\nother contexts, including PAC-Bayesian theory, and sampling mechanisms. In this\nwork we study the excess risk suffered by a Gibbs-ERM learner that uses\nnon-convex, regularized empirical risk with the goal to understand the\ninterplay between the data-generating distribution and learning in large\nhypothesis spaces. Our main results are distribution-dependent upper bounds on\nseveral notions of excess risk. We show that, in all cases, the\ndistribution-dependent excess risk is essentially controlled by the effective\ndimension $\\mathrm{tr}\\left(\\boldsymbol{H}^{\\star} (\\boldsymbol{H}^{\\star} +\n\\lambda \\boldsymbol{I})^{-1}\\right)$ of the problem, where\n$\\boldsymbol{H}^{\\star}$ is the Hessian matrix of the risk at a local minimum.\nThis is a well-established notion of effective dimension appearing in several\nprevious works, including the analyses of SGD and ridge regression, but ours is\nthe first work that brings this dimension to the analysis of learning using\nGibbs densities. The distribution-dependent view we advocate here improves upon\nearlier results of Raginsky et al. (2017), and can yield much tighter bounds\ndepending on the interplay between the data-generating distribution and the\nloss function. The first part of our analysis focuses on the localized excess\nrisk in the vicinity of a fixed local minimizer. This result is then extended\nto bounds on the global excess risk, by characterizing probabilities of local\nminima (and their complement) under Gibbs densities, a results which might be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 18:31:23 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1902.01856", "submitter": "Ehsan Kazemi Dr", "authors": "Ehsan Kazemi, Liqiang Wang", "title": "Asynchronous Delay-Aware Accelerated Proximal Coordinate Descent for\n  Nonconvex Nonsmooth Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex and nonsmooth problems have recently attracted considerable\nattention in machine learning. However, developing efficient methods for the\nnonconvex and nonsmooth optimization problems with certain performance\nguarantee remains a challenge. Proximal coordinate descent (PCD) has been\nwidely used for solving optimization problems, but the knowledge of PCD methods\nin the nonconvex setting is very limited. On the other hand, the asynchronous\nproximal coordinate descent (APCD) recently have received much attention in\norder to solve large-scale problems. However, the accelerated variants of APCD\nalgorithms are rarely studied. In this paper, we extend APCD method to the\naccelerated algorithm (AAPCD) for nonsmooth and nonconvex problems that\nsatisfies the sufficient descent property, by comparing between the function\nvalues at proximal update and a linear extrapolated point using a delay-aware\nmomentum value. To the best of our knowledge, we are the first to provide\nstochastic and deterministic accelerated extension of APCD algorithms for\ngeneral nonconvex and nonsmooth problems ensuring that for both bounded delays\nand unbounded delays every limit point is a critical point. By leveraging\nKurdyka-Lojasiewicz property, we will show linear and sublinear convergence\nrates for the deterministic AAPCD with bounded delays. Numerical results\ndemonstrate the practical efficiency of our algorithm in speed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 00:40:26 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Wang", "Liqiang", ""]]}, {"id": "1902.01870", "submitter": "Moustafa AboulAtta", "authors": "Moustafa AboulAtta, Matthias Ossadnik, Seyed-Ahmad Ahmadi", "title": "Stabilizing Inputs to Approximated Nonlinear Functions for Inference\n  with Homomorphic Encryption in Deep Neural Networks", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveled Homomorphic Encryption (LHE) offers a potential solution that could\nallow sectors with sensitive data to utilize the cloud and securely deploy\ntheir models for remote inference with Deep Neural Networks (DNN). However,\nthis application faces several obstacles due to the limitations of LHE. One of\nthe main problems is the incompatibility of commonly used nonlinear functions\nin DNN with the operations supported by LHE, i.e. addition and multiplication.\nAs common in LHE approaches, we train a model with a nonlinear function, and\nreplace it with a low-degree polynomial approximation at inference time on\nprivate data. While this typically leads to approximation errors and loss in\nprediction accuracy, we propose a method that reduces this loss to small values\nor eliminates it entirely, depending on simple hyper-parameters. This is\nachieved by the introduction of a novel and elegantly simple Min-Max\nnormalization scheme, which scales inputs to nonlinear functions into ranges\nwith low approximation error. While being intuitive in its concept and trivial\nto implement, we empirically show that it offers a stable and effective\napproximation solution to nonlinear functions in DNN. In return, this can\nenable deeper networks with LHE, and facilitate the development of security-\nand privacy-aware analytics applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:07:07 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["AboulAtta", "Moustafa", ""], ["Ossadnik", "Matthias", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "1902.01878", "submitter": "Sagar Sharma", "authors": "Sagar Sharma, Keke Chen", "title": "Disguised-Nets: Image Disguising for Privacy-preserving Outsourced Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning model developers often use cloud GPU resources to experiment\nwith large data and models that need expensive setups. However, this practice\nraises privacy concerns. Adversaries may be interested in: 1) personally\nidentifiable information or objects encoded in the training images, and 2) the\nmodels trained with sensitive data to launch model-based attacks. Learning deep\nneural networks (DNN) from encrypted data is still impractical due to the large\ntraining data and the expensive learning process. A few recent studies have\ntried to provide efficient, practical solutions to protect data privacy in\noutsourced deep-learning. However, we find out that they are vulnerable under\ncertain attacks. In this paper, we specifically identify two types of unique\nattacks on outsourced deep-learning: 1) the visual re-identification attack on\nthe training data, and 2) the class membership attack on the learned models,\nwhich can break existing privacy-preserving solutions. We develop an image\ndisguising approach to address these attacks and design a suite of methods to\nevaluate the levels of attack resilience for a privacy-preserving solution for\noutsourced deep learning. The experimental results show that our\nimage-disguising mechanisms can provide a high level of protection against the\ntwo attacks while still generating high-quality DNN models for image\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:20:02 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 04:31:54 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Sharma", "Sagar", ""], ["Chen", "Keke", ""]]}, {"id": "1902.01879", "submitter": "Tomasz Arodz", "authors": "Seyran Saeedi and Tom Arodz", "title": "Quantum Sparse Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the computational complexity of Quantum Sparse Support Vector\nMachine, a linear classifier that minimizes the hinge loss and the $L_1$ norm\nof the feature weights vector and relies on a quantum linear programming solver\ninstead of a classical solver. Sparse SVM leads to sparse models that use only\na small fraction of the input features in making decisions, and is especially\nuseful when the total number of features, $p$, approaches or exceeds the number\nof training samples, $m$. We prove a $\\Omega(m)$ worst-case lower bound for\ncomputational complexity of any quantum training algorithm relying on black-box\naccess to training samples; quantum sparse SVM has at least linear worst-case\ncomplexity. However, we prove that there are realistic scenarios in which a\nsparse linear classifier is expected to have high accuracy, and can be trained\nin sublinear time in terms of both the number of training samples and the\nnumber of features.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:20:21 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 02:29:03 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 17:25:56 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Saeedi", "Seyran", ""], ["Arodz", "Tom", ""]]}, {"id": "1902.01883", "submitter": "Peter Henderson", "authors": "Joshua Romoff, Peter Henderson, Ahmed Touati, Emma Brunskill, Joelle\n  Pineau, Yann Ollivier", "title": "Separating value functions across time-scales", "comments": "Full version accepted to ICML 2019. Extended abstract also to be\n  presented at RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many finite horizon episodic reinforcement learning (RL) settings, it is\ndesirable to optimize for the undiscounted return - in settings like Atari, for\ninstance, the goal is to collect the most points while staying alive in the\nlong run. Yet, it may be difficult (or even intractable) mathematically to\nlearn with this target. As such, temporal discounting is often applied to\noptimize over a shorter effective planning horizon. This comes at the risk of\npotentially biasing the optimization target away from the undiscounted goal. In\nsettings where this bias is unacceptable - where the system must optimize for\nlonger horizons at higher discounts - the target of the value function\napproximator may increase in variance leading to difficulties in learning. We\npresent an extension of temporal difference (TD) learning, which we call\nTD($\\Delta$), that breaks down a value function into a series of components\nbased on the differences between value functions with smaller discount factors.\nThe separation of a longer horizon value function into these components has\nuseful properties in scalability and performance. We discuss these properties\nand show theoretic and empirical improvements over standard TD learning in\ncertain settings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:45:08 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 05:49:34 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 20:12:47 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Romoff", "Joshua", ""], ["Henderson", "Peter", ""], ["Touati", "Ahmed", ""], ["Brunskill", "Emma", ""], ["Pineau", "Joelle", ""], ["Ollivier", "Yann", ""]]}, {"id": "1902.01889", "submitter": "Nicolas Papernot", "authors": "Nicholas Frosst, Nicolas Papernot, Geoffrey Hinton", "title": "Analyzing and Improving Representations with the Soft Nearest Neighbor\n  Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore and expand the $\\textit{Soft Nearest Neighbor Loss}$ to measure\nthe $\\textit{entanglement}$ of class manifolds in representation space: i.e.,\nhow close pairs of points from the same class are relative to pairs of points\nfrom different classes. We demonstrate several use cases of the loss. As an\nanalytical tool, it provides insights into the evolution of class similarity\nstructures during learning. Surprisingly, we find that $\\textit{maximizing}$\nthe entanglement of representations of different classes in the hidden layers\nis beneficial for discrimination in the final layer, possibly because it\nencourages representations to identify class-independent similarity structures.\nMaximizing the soft nearest neighbor loss in the hidden layers leads not only\nto improved generalization but also to better-calibrated estimates of\nuncertainty on outlier data. Data that is not from the training distribution\ncan be recognized by observing that in the hidden layers, it has fewer than the\nnormal number of neighbors from the predicted class.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:58:31 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Frosst", "Nicholas", ""], ["Papernot", "Nicolas", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1902.01893", "submitter": "Micha Livne", "authors": "Micha Livne and David Fleet", "title": "TzK: Flow-Based Conditional Generative Model", "comments": "8 pages, 9 figures, 2 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a new class of conditional generative models based on\nprobability flows. Trained with maximum likelihood, it provides efficient\ninference and sampling from class-conditionals or the joint distribution, and\ndoes not require a priori knowledge of the number of classes or the\nrelationships between classes. This allows one to train generative models from\nmultiple, heterogeneous datasets, while retaining strong prior models over\nsubsets of the data (e.g., from a single dataset, class label, or attribute).\nIn this paper, in addition to end-to-end learning, we show how one can learn a\nsingle model from multiple datasets with a relatively weak Glow architecture,\nand then extend it by conditioning on different knowledge types (e.g., a single\ndataset). This yields log likelihood comparable to state-of-the-art, compelling\nsamples from conditional priors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:09:06 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 22:22:24 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 16:00:49 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 15:35:28 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Livne", "Micha", ""], ["Fleet", "David", ""]]}, {"id": "1902.01894", "submitter": "Ang Li", "authors": "Ang Li, Ola Spyra, Sagi Perel, Valentin Dalibard, Max Jaderberg,\n  Chenjie Gu, David Budden, Tim Harley, Pramod Gupta", "title": "A Generalized Framework for Population Based Training", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population Based Training (PBT) is a recent approach that jointly optimizes\nneural network weights and hyperparameters which periodically copies weights of\nthe best performers and mutates hyperparameters during training. Previous PBT\nimplementations have been synchronized glass-box systems. We propose a general,\nblack-box PBT framework that distributes many asynchronous \"trials\" (a small\nnumber of training steps with warm-starting) across a cluster, coordinated by\nthe PBT controller. The black-box design does not make assumptions on model\narchitectures, loss functions or training procedures. Our system supports\ndynamic hyperparameter schedules to optimize both differentiable and\nnon-differentiable metrics. We apply our system to train a state-of-the-art\nWaveNet generative model for human voice synthesis. We show that our PBT system\nachieves better accuracy, less sensitivity and faster convergence compared to\nexisting methods, given the same computational resource.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:11:17 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Li", "Ang", ""], ["Spyra", "Ola", ""], ["Perel", "Sagi", ""], ["Dalibard", "Valentin", ""], ["Jaderberg", "Max", ""], ["Gu", "Chenjie", ""], ["Budden", "David", ""], ["Harley", "Tim", ""], ["Gupta", "Pramod", ""]]}, {"id": "1902.01899", "submitter": "Fei Wu", "authors": "Fei Wu, Yang Cao, Thomas Robertazzi", "title": "Reinforcement Learning for Optimal Load Distribution Sequencing in\n  Resource-Sharing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divisible Load Theory (DLT) is a powerful tool for modeling divisible load\nproblems in data-intensive systems. This paper studied an optimal divisible\nload distribution sequencing problem using a machine learning framework. The\nproblem is to decide the optimal sequence to distribute divisible load to\nprocessors in order to achieve minimum finishing time. The scheduling is\nperformed in a resource-sharing system where each physical processor is\nvirtualized to multiple virtual processors. A reinforcement learning method\ncalled Multi-armed bandit (MAB) is used for our problem. We first provide a\nnaive solution using the MAB algorithm and then several optimizations are\nperformed. Various numerical tests are conducted. Our algorithm shows an\nincreasing performance during the training progress and the global optimum will\nbe acheived when the sample size is large enough.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:34:34 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Wu", "Fei", ""], ["Cao", "Yang", ""], ["Robertazzi", "Thomas", ""]]}, {"id": "1902.01902", "submitter": "Prateek Jaiswal", "authors": "Prateek Jaiswal, Vinayak A. Rao and Harsha Honnappa", "title": "Asymptotic Consistency of $\\alpha-$R\\'enyi-Approximate Posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic consistency properties of $\\alpha$-R\\'enyi\napproximate posteriors, a class of variational Bayesian methods that\napproximate an intractable Bayesian posterior with a member of a tractable\nfamily of distributions, the member chosen to minimize the $\\alpha$-R\\'enyi\ndivergence from the true posterior. Unique to our work is that we consider\nsettings with $\\alpha > 1$, resulting in approximations that upperbound the\nlog-likelihood, and consequently have wider spread than traditional variational\napproaches that minimize the Kullback-Liebler (KL) divergence from the\nposterior. Our primary result identifies sufficient conditions under which\nconsistency holds, centering around the existence of a 'good' sequence of\ndistributions in the approximating family that possesses, among other\nproperties, the right rate of convergence to a limit distribution. We further\ncharacterize the good sequence by demonstrating that a sequence of\ndistributions that converges too quickly cannot be a good sequence. We also\nextend our analysis to the setting where $\\alpha$ equals one, corresponding to\nthe minimizer of the reverse KL divergence, and to models with local latent\nvariables. We also illustrate the existence of good sequence with a number of\nexamples. Our results complement a growing body of work focused on the\nfrequentist properties of variational Bayesian methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:41:39 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 02:02:35 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 17:45:09 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Jaiswal", "Prateek", ""], ["Rao", "Vinayak A.", ""], ["Honnappa", "Harsha", ""]]}, {"id": "1902.01903", "submitter": "Udaya Ghai", "authors": "Udaya Ghai, Elad Hazan, Yoram Singer", "title": "Exponentiated Gradient Meets Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (stochastic) gradient descent and the multiplicative update method are\nprobably the most popular algorithms in machine learning. We introduce and\nstudy a new regularization which provides a unification of the additive and\nmultiplicative updates. This regularization is derived from an hyperbolic\nanalogue of the entropy function, which we call hypentropy. It is motivated by\na natural extension of the multiplicative update to negative numbers. The\nhypentropy has a natural spectral counterpart which we use to derive a family\nof matrix-based updates that bridge gradient methods and the multiplicative\nmethod for matrices. While the latter is only applicable to positive\nsemi-definite matrices, the spectral hypentropy method can naturally be used\nwith general rectangular matrices. We analyze the new family of updates by\nderiving tight regret bounds. We study empirically the applicability of the new\nupdate for settings such as multiclass learning, in which the parameters\nconstitute a general rectangular matrix.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:41:57 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Ghai", "Udaya", ""], ["Hazan", "Elad", ""], ["Singer", "Yoram", ""]]}, {"id": "1902.01909", "submitter": "Mark Koren", "authors": "Mark Koren, Saud Alsaif, Ritchie Lee, and Mykel J. Kochenderfer", "title": "Adaptive Stress Testing for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for testing the decision making systems of\nautonomous vehicles. Our approach involves perturbing stochastic elements in\nthe vehicle's environment until the vehicle is involved in a collision. Instead\nof applying direct Monte Carlo sampling to find collision scenarios, we\nformulate the problem as a Markov decision process and use reinforcement\nlearning algorithms to find the most likely failure scenarios. This paper\npresents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL)\nsolutions that can scale to large environments. We show that DRL can find more\nlikely failure scenarios than MCTS with fewer calls to the simulator. A\nsimulation scenario involving a vehicle approaching a crosswalk is used to\nvalidate the framework. Our proposed approach is very general and can be easily\napplied to other scenarios given the appropriate models of the vehicle and the\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:10:37 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Koren", "Mark", ""], ["Alsaif", "Saud", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1902.01911", "submitter": "Andreas Maurer", "authors": "Andreas Maurer, Massimiliano Pontil", "title": "Uniform concentration and symmetrization for weak interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method to derive uniform bounds with Gaussian and Rademacher complexities\nis extended to the case where the sample average is replaced by a nonlinear\nstatistic. Tight bounds are obtained for U-statistics, smoothened L-statistics\nand error functionals of l2-regularized algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:16:55 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 22:36:41 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 19:30:27 GMT"}, {"version": "v4", "created": "Fri, 10 May 2019 06:27:14 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Maurer", "Andreas", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1902.01917", "submitter": "Mark Grobman Mr.", "authors": "Eldad Meller, Alexander Finkelstein, Uri Almog, Mark Grobman", "title": "Same, Same But Different - Recovering Neural Network Quantization Error\n  Through Weight Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization of neural networks has become common practice, driven by the\nneed for efficient implementations of deep neural networks on embedded devices.\nIn this paper, we exploit an oft-overlooked degree of freedom in most networks\n- for a given layer, individual output channels can be scaled by any factor\nprovided that the corresponding weights of the next layer are inversely scaled.\nTherefore, a given network has many factorizations which change the weights of\nthe network without changing its function. We present a conceptually simple and\neasy to implement method that uses this property and show that proper\nfactorizations significantly decrease the degradation caused by quantization.\nWe show improvement on a wide variety of networks and achieve state-of-the-art\ndegradation results for MobileNets. While our focus is on quantization, this\ntype of factorization is applicable to other domains such as network-pruning,\nneural nets regularization and network interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:23:03 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Meller", "Eldad", ""], ["Finkelstein", "Alexander", ""], ["Almog", "Uri", ""], ["Grobman", "Mark", ""]]}, {"id": "1902.01923", "submitter": "Mouloud Belbahri", "authors": "Ali Vahdat, Mouloud Belbahri, Vahid Partovi Nia", "title": "Active Learning for High-Dimensional Binary Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erbium-doped fiber amplifier (EDFA) is an optical amplifier/repeater device\nused to boost the intensity of optical signals being carried through a fiber\noptic communication system. A highly accurate EDFA model is important because\nof its crucial role in optical network management and optimization. The input\nchannels of an EDFA device are treated as either on or off, hence the input\nfeatures are binary. Labeled training data is very expensive to collect for\nEDFA devices, therefore we devise an active learning strategy suitable for\nbinary variables to overcome this issue. We propose to take advantage of sparse\nlinear models to simplify the predictive model. This approach simultaneously\nimproves prediction and accelerates active learning query generation. We show\nthe performance of our proposed active learning strategies on simulated data\nand real EDFA data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:46:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 15:23:31 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Vahdat", "Ali", ""], ["Belbahri", "Mouloud", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1902.01926", "submitter": "Nagender Aneja", "authors": "Sandhya Aneja, Nagender Aneja, Md Shohidul Islam", "title": "IoT Device Fingerprint using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1109/IOTAIS.2018.8600824", "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Device Fingerprinting (DFP) is the identification of a device without using\nits network or other assigned identities including IP address, Medium Access\nControl (MAC) address, or International Mobile Equipment Identity (IMEI)\nnumber. DFP identifies a device using information from the packets which the\ndevice uses to communicate over the network. Packets are received at a router\nand processed to extract the information. In this paper, we worked on the DFP\nusing Inter Arrival Time (IAT). IAT is the time interval between the two\nconsecutive packets received. This has been observed that the IAT is unique for\na device because of different hardware and the software used for the device.\nThe existing work on the DFP uses the statistical techniques to analyze the IAT\nand to further generate the information using which a device can be identified\nuniquely. This work presents a novel idea of DFP by plotting graphs of IAT for\npackets with each graph plotting 100 IATs and subsequently processing the\nresulting graphs for the identification of the device. This approach improves\nthe efficiency to identify a device DFP due to achieved benchmark of the deep\nlearning libraries in the image processing. We configured Raspberry Pi to work\nas a router and installed our packet sniffer application on the Raspberry Pi .\nThe packet sniffer application captured the packet information from the\nconnected devices in a log file. We connected two Apple devices iPad4 and\niPhone 7 Plus to the router and created IAT graphs for these two devices. We\nused Convolution Neural Network (CNN) to identify the devices and observed the\naccuracy of 86.7%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 03:28:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Aneja", "Sandhya", ""], ["Aneja", "Nagender", ""], ["Islam", "Md Shohidul", ""]]}, {"id": "1902.01931", "submitter": "Igor Colin", "authors": "Igor Colin, Albert Thomas, Moez Draief", "title": "Parallel Contextual Bandits in Wireless Handover Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cellular networks become denser, a scalable and dynamic tuning of wireless\nbase station parameters can only be achieved through automated optimization.\nAlthough the contextual bandit framework arises as a natural candidate for such\na task, its extension to a parallel setting is not straightforward: one needs\nto carefully adapt existing methods to fully leverage the multi-agent structure\nof this problem. We propose two approaches: one derived from a deterministic\nUCB-like method and the other relying on Thompson sampling. Thanks to its\nbayesian nature, the latter is intuited to better preserve the\nexploration-exploitation balance in the bandit batch. This is verified on toy\nexperiments, where Thompson sampling shows robustness to the variability of the\ncontexts. Finally, we apply both methods on a real base station network dataset\nand evidence that Thompson sampling outperforms both manual tuning and\ncontextual UCB.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 12:45:15 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Colin", "Igor", ""], ["Thomas", "Albert", ""], ["Draief", "Moez", ""]]}, {"id": "1902.01933", "submitter": "Alex Sun", "authors": "Alexander Y. Sun, Bridget R. Scanlon, Zizhan Zhang, David Walling,\n  Soumendra N. Bhanja, Abhijit Mukherjee, Zhi Zhong", "title": "Combining Physically-Based Modeling and Deep Learning for Fusing GRACE\n  Satellite Data: Can We Learn from Mismatch?", "comments": null, "journal-ref": "Water Resources Research, 2019", "doi": "10.1029/2018WR023333", "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global hydrological and land surface models are increasingly used for\ntracking terrestrial total water storage (TWS) dynamics, but the utility of\nexisting models is hampered by conceptual and/or data uncertainties related to\nvarious underrepresented and unrepresented processes, such as groundwater\nstorage. The gravity recovery and climate experiment (GRACE) satellite mission\nprovided a valuable independent data source for tracking TWS at regional and\ncontinental scales. Strong interests exist in fusing GRACE data into global\nhydrological models to improve their predictive performance. Here we develop\nand apply deep convolutional neural network (CNN) models to learn the\nspatiotemporal patterns of mismatch between TWS anomalies (TWSA) derived from\nGRACE and those simulated by NOAH, a widely used land surface model. Once\ntrained, our CNN models can be used to correct the NOAH simulated TWSA without\nrequiring GRACE data, potentially filling the data gap between GRACE and its\nfollow-on mission, GRACE-FO. Our methodology is demonstrated over India, which\nhas experienced significant groundwater depletion in recent decades that is\nnevertheless not being captured by the NOAH model. Results show that the CNN\nmodels significantly improve the match with GRACE TWSA, achieving a\ncountry-average correlation coefficient of 0.94 and Nash-Sutcliff efficient of\n0.87, or 14\\% and 52\\% improvement respectively over the original NOAH TWSA. At\nthe local scale, the learned mismatch pattern correlates well with the observed\nin situ groundwater storage anomaly data for most parts of India, suggesting\nthat deep learning models effectively compensate for the missing groundwater\ncomponent in NOAH for this study region.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:28:16 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Sun", "Alexander Y.", ""], ["Scanlon", "Bridget R.", ""], ["Zhang", "Zizhan", ""], ["Walling", "David", ""], ["Bhanja", "Soumendra N.", ""], ["Mukherjee", "Abhijit", ""], ["Zhong", "Zhi", ""]]}, {"id": "1902.01946", "submitter": "Jingjing Wang", "authors": "Jingjing Wang and Chunxiao Jiang and Haijun Zhang and Yong Ren and\n  Kwang-Cheng Chen and Lajos Hanzo", "title": "Thirty Years of Machine Learning: The Road to Pareto-Optimal Wireless\n  Networks", "comments": "46 pages, 22 figs", "journal-ref": null, "doi": "10.1109/COMST.2020.2965856", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future wireless networks have a substantial potential in terms of supporting\na broad range of complex compelling applications both in military and civilian\nfields, where the users are able to enjoy high-rate, low-latency, low-cost and\nreliable information services. Achieving this ambitious goal requires new radio\ntechniques for adaptive learning and intelligent decision making because of the\ncomplex heterogeneous nature of the network structures and wireless services.\nMachine learning (ML) algorithms have great success in supporting big data\nanalytics, efficient parameter estimation and interactive decision making.\nHence, in this article, we review the thirty-year history of ML by elaborating\non supervised learning, unsupervised learning, reinforcement learning and deep\nlearning. Furthermore, we investigate their employment in the compelling\napplications of wireless networks, including heterogeneous networks (HetNets),\ncognitive radios (CR), Internet of things (IoT), machine to machine networks\n(M2M), and so on. This article aims for assisting the readers in clarifying the\nmotivation and methodology of the various ML algorithms, so as to invoke them\nfor hitherto unexplored services as well as scenarios of future wireless\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 03:52:53 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 13:08:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Jingjing", ""], ["Jiang", "Chunxiao", ""], ["Zhang", "Haijun", ""], ["Ren", "Yong", ""], ["Chen", "Kwang-Cheng", ""], ["Hanzo", "Lajos", ""]]}, {"id": "1902.01950", "submitter": "Kristy Choi", "authors": "Mike Wu, Kristy Choi, Noah Goodman, Stefano Ermon", "title": "Meta-Amortized Variational Inference and Learning", "comments": "First 2 authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success in probabilistic modeling and their applications,\ngenerative models trained using traditional inference techniques struggle to\nadapt to new distributions, even when the target distribution may be closely\nrelated to the ones seen during training. In this work, we present a\ndoubly-amortized variational inference procedure as a way to address this\nchallenge. By sharing computation across not only a set of query inputs, but\nalso a set of different, related probabilistic models, we learn transferable\nlatent representations that generalize across several related distributions. In\nparticular, given a set of distributions over images, we find the learned\nrepresentations to transfer to different data transformations. We empirically\ndemonstrate the effectiveness of our method by introducing the MetaVAE, and\nshow that it significantly outperforms baselines on downstream image\nclassification tasks on MNIST (10-50%) and NORB (10-35%).\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:06:25 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 06:09:30 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wu", "Mike", ""], ["Choi", "Kristy", ""], ["Goodman", "Noah", ""], ["Ermon", "Stefano", ""]]}, {"id": "1902.01951", "submitter": "Thai Son Nguyen", "authors": "Thai-Son Nguyen, Sebastian Stueker, Alex Waibel", "title": "Using multi-task learning to improve the performance of acoustic-to-word\n  and conventional hybrid models", "comments": "submitted newer work which includes this paper results", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic-to-word (A2W) models that allow direct mapping from acoustic signals\nto word sequences are an appealing approach to end-to-end automatic speech\nrecognition due to their simplicity. However, prior works have shown that\nmodelling A2W typically encounters issues of data sparsity that prevent\ntraining such a model directly. So far, pre-training initialization is the only\napproach proposed to deal with this issue. In this work, we propose to build a\nshared neural network and optimize A2W and conventional hybrid models in a\nmulti-task manner. Our results show that training an A2W model is much more\nstable with our multi-task model without pre-training initialization, and\nresults in a significant improvement compared to a baseline model. Experiments\nalso reveal that the performance of a hybrid acoustic model can be further\nimproved when jointly training with a sequence-level optimization criterion\nsuch as acoustic-to-word.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:33:48 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 20:29:06 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Nguyen", "Thai-Son", ""], ["Stueker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1902.01958", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila, Francis Bach, Alessandro Rudi", "title": "A General Theory for Structured Prediction with Smooth Convex Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide a theoretical framework for structured prediction\nthat generalizes the existing theory of surrogate methods for binary and\nmulticlass classification based on estimating conditional probabilities with\nsmooth convex surrogates (e.g. logistic regression). The theory relies on a\nnatural characterization of structural properties of the task loss and allows\nto derive statistical guarantees for many widely used methods in the context of\nmultilabeling, ranking, ordinal regression and graph matching. In particular,\nwe characterize the smooth convex surrogates compatible with a given task loss\nin terms of a suitable Bregman divergence composed with a link function. This\nallows to derive tight bounds for the calibration function and to obtain novel\nresults on existing surrogate frameworks for structured prediction such as\nconditional random fields and quadratic surrogates.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:27:24 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 17:19:29 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Nowak-Vila", "Alex", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "1902.01967", "submitter": "Kevin O'Connor", "authors": "Christopher Bender, Kevin O'Connor, Yang Li, Juan Jose Garcia, Manzil\n  Zaheer, Junier Oliva", "title": "Exchangeable Generative Models with Flow Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a new approach to generative density estimation for\nexchangeable, non-i.i.d. data. The proposed framework, FlowScan, combines\ninvertible flow transformations with a sorted scan to flexibly model the data\nwhile preserving exchangeability. Unlike most existing methods, FlowScan\nexploits the intradependencies within sets to learn both global and local\nstructure. FlowScan represents the first approach that is able to apply\nsequential methods to exchangeable density estimation without resorting to\naveraging over all possible permutations. We achieve new state-of-the-art\nperformance on point cloud and image set modeling.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:53:27 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 02:33:41 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 18:31:30 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Bender", "Christopher", ""], ["O'Connor", "Kevin", ""], ["Li", "Yang", ""], ["Garcia", "Juan Jose", ""], ["Zaheer", "Manzil", ""], ["Oliva", "Junier", ""]]}, {"id": "1902.01973", "submitter": "Harish Kumar", "authors": "Harish Kumar, Balaraman Ravindran", "title": "Polyphonic Music Composition with LSTM Neural Networks and Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of algorithmic music composition, machine learning-driven\nsystems eliminate the need for carefully hand-crafting rules for composition.\nIn particular, the capability of recurrent neural networks to learn complex\ntemporal patterns lends itself well to the musical domain. Promising results\nhave been observed across a number of recent attempts at music composition\nusing deep RNNs. These approaches generally aim at first training neural\nnetworks to reproduce subsequences drawn from existing songs. Subsequently,\nthey are used to compose music either at the audio sample-level or at the\nnote-level. We designed a representation that divides polyphonic music into a\nsmall number of monophonic streams. This representation greatly reduces the\ncomplexity of the problem and eliminates an exponential number of probably poor\ncompositions. On top of our LSTM neural network that learnt musical sequences\nin this representation, we built an RL agent that learnt to find combinations\nof songs whose joint dominance produced pleasant compositions. We present\nAmadeus, an algorithmic music composition system that composes music that\nconsists of intricate melodies, basic chords, and even occasional contrapuntal\nsequences.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 23:22:05 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 20:10:05 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Kumar", "Harish", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1902.01981", "submitter": "Saurav Prakash", "authors": "Amirhossein Reisizadeh, Saurav Prakash, Ramtin Pedarsani, Amir Salman\n  Avestimehr", "title": "CodedReduce: A Fast and Robust Framework for Gradient Aggregation in\n  Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the commonly used synchronous Gradient Descent paradigm for\nlarge-scale distributed learning, for which there has been a growing interest\nto develop efficient and robust gradient aggregation strategies that overcome\ntwo key system bottlenecks: communication bandwidth and stragglers' delays. In\nparticular, Ring-AllReduce (RAR) design has been proposed to avoid bandwidth\nbottleneck at any particular node by allowing each worker to only communicate\nwith its neighbors that are arranged in a logical ring. On the other hand,\nGradient Coding (GC) has been recently proposed to mitigate stragglers in a\nmaster-worker topology by allowing carefully designed redundant allocation of\nthe data set to the workers. We propose a joint communication topology design\nand data set allocation strategy, named CodedReduce (CR), that combines the\nbest of both RAR and GC. That is, it parallelizes the communications over a\ntree topology leading to efficient bandwidth utilization, and carefully designs\na redundant data set allocation and coding strategy at the nodes to make the\nproposed gradient aggregation scheme robust to stragglers. In particular, we\nquantify the communication parallelization gain and resiliency of the proposed\nCR scheme, and prove its optimality when the communication topology is a\nregular tree. Furthermore, we empirically evaluate the performance of our\nproposed CR design over Amazon EC2 and demonstrate that it achieves speedups of\nup to 27.2x and 7.0x, respectively over the benchmarks GC and RAR.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 00:05:21 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 06:06:19 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Reisizadeh", "Amirhossein", ""], ["Prakash", "Saurav", ""], ["Pedarsani", "Ramtin", ""], ["Avestimehr", "Amir Salman", ""]]}, {"id": "1902.01990", "submitter": "Milad Afzalan", "authors": "Milad Afzalan, Farrokh Jazizadeh", "title": "An Automated Spectral Clustering for Multi-scale Data", "comments": "Submitted to Neurocomputing, 2019", "journal-ref": null, "doi": "10.1016/j.neucom.2019.03.008", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering algorithms typically require a priori selection of input\nparameters such as the number of clusters, a scaling parameter for the affinity\nmeasure, or ranges of these values for parameter tuning. Despite efforts for\nautomating the process of spectral clustering, the task of grouping data in\nmulti-scale and higher dimensional spaces is yet to be explored. This study\npresents a spectral clustering heuristic algorithm that obviates the need for\nan input by estimating the parameters from the data itself. Specifically, it\nintroduces the heuristic of iterative eigengap search with (1) global scaling\nand (2) local scaling. These approaches estimate the scaling parameter and\nimplement iterative eigengap quantification along a search tree to reveal\ndissimilarities at different scales of a feature space and identify clusters.\nThe performance of these approaches has been tested on various real-world\ndatasets of power variation with multi-scale nature and gene expression. Our\nfindings show that iterative eigengap search with a PCA-based global scaling\nscheme can discover different patterns with an accuracy of higher than 90% in\nmost cases without asking for a priori input information.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 00:57:08 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Afzalan", "Milad", ""], ["Jazizadeh", "Farrokh", ""]]}, {"id": "1902.01996", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Samy Bengio and Yoram Singer", "title": "Are All Layers Created Equal?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding deep neural networks has been a major research objective in\nrecent years with notable theoretical progress. A focal point of those studies\nstems from the success of excessively large networks which defy the classical\nwisdom of uniform convergence and learnability. We study empirically the\nlayer-wise functional structure of overparameterized deep models. We provide\nevidence for the heterogeneous characteristic of layers. To do so, we introduce\nthe notion of robustness to post-training re-initialization and\nre-randomization. We show that the layers can be categorized as either\n``ambient'' or ``critical''. Resetting the ambient layers to their initial\nvalues has no negative consequence, and in many cases they barely change\nthroughout training. On the contrary, resetting the critical layers completely\ndestroys the predictor and the performance drops to chanceh. Our study provides\nfurther evidence that mere parameter counting or norm accounting is too coarse\nin studying generalization of deep models, and flatness or robustness analysis\nof the models needs to respect the network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 01:29:01 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 18:56:11 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 21:21:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Bengio", "Samy", ""], ["Singer", "Yoram", ""]]}, {"id": "1902.01998", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Yeshwanth Cherapanamjeri, Nicolas Flammarion, Peter L. Bartlett", "title": "Fast Mean Estimation with Sub-Gaussian Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an estimator for the mean of a random vector in $\\mathbb{R}^d$\nthat can be computed in time $O(n^4+n^2d)$ for $n$ i.i.d.~samples and that has\nerror bounds matching the sub-Gaussian case. The only assumptions we make about\nthe data distribution are that it has finite mean and covariance; in\nparticular, we make no assumptions about higher-order moments. Like the\npolynomial time estimator introduced by Hopkins, 2018, which is based on the\nsum-of-squares hierarchy, our estimator achieves optimal statistical efficiency\nin this challenging setting, but it has a significantly faster runtime and a\nsimpler analysis.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 01:33:05 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Cherapanamjeri", "Yeshwanth", ""], ["Flammarion", "Nicolas", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1902.01999", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Yeshwanth Cherapanamjeri, Peter L. Bartlett", "title": "Testing Markov Chains without Hitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identity testing of markov chains. In this setting,\nwe are given access to a single trajectory from a markov chain with unknown\ntransition matrix $Q$ and the goal is to determine whether $Q = P$ for some\nknown matrix $P$ or $\\text{Dist}(P, Q) \\geq \\epsilon$ where $\\text{Dist}$ is\nsuitably defined. In recent work by Daskalakis, Dikkala and Gravin, 2018, it\nwas shown that it is possible to distinguish between the two cases provided the\nlength of the observed trajectory is at least super-linear in the hitting time\nof $P$ which may be arbitrarily large.\n  In this paper, we propose an algorithm that avoids this dependence on hitting\ntime thus enabling efficient testing of markov chains even in cases where it is\ninfeasible to observe every state in the chain. Our algorithm is based on\ncombining classical ideas from approximation algorithms with techniques for the\nspectral analysis of markov chains.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 01:33:43 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Cherapanamjeri", "Yeshwanth", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1902.02004", "submitter": "Keigo Kawamura", "authors": "Keigo Kawamura, Yoshimasa Tsuruoka", "title": "Neural Fictitious Self-Play on ELF Mini-RTS", "comments": "AAAI-19 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the notable successes in video games such as Atari 2600, current AI\nis yet to defeat human champions in the domain of real-time strategy (RTS)\ngames. One of the reasons is that an RTS game is a multi-agent game, in which\nsingle-agent reinforcement learning methods cannot simply be applied because\nthe environment is not a stationary Markov Decision Process. In this paper, we\npresent a first step toward finding a game-theoretic solution to RTS games by\napplying Neural Fictitious Self-Play (NFSP), a game-theoretic approach for\nfinding Nash equilibria, to Mini-RTS, a small but nontrivial RTS game provided\non the ELF platform. More specifically, we show that NFSP can be effectively\ncombined with policy gradient reinforcement learning and be applied to\nMini-RTS. Experimental results also show that the scalability of NFSP can be\nsubstantially improved by pretraining the models with simple self-play using\npolicy gradients, which by itself gives a strong strategy despite its lack of\ntheoretical guarantee of convergence.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 02:46:07 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Kawamura", "Keigo", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1902.02009", "submitter": "Bo Liu", "authors": "Bo Liu, Hongyu Wu, Yingchen Zhang, Rui Yang, Andrey Bernstein", "title": "Robust Matrix Completion State Estimation in Distribution Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the insufficient measurements in the distribution system state\nestimation (DSSE), full observability and redundant measurements are difficult\nto achieve without using the pseudo measurements. The matrix completion state\nestimation (MCSE) combines the matrix completion and power system model to\nestimate voltage by exploring the low-rank characteristics of the matrix. This\npaper proposes a robust matrix completion state estimation (RMCSE) to estimate\nthe voltage in a distribution system under a low-observability condition.\nTradition state estimation weighted least squares (WLS) method requires full\nobservability to calculate the states and needs redundant measurements to\nproceed a bad data detection. The proposed method improves the robustness of\nthe MCSE to bad data by minimizing the rank of the matrix and measurements\nresidual with different weights. It can estimate the system state in a\nlow-observability system and has robust estimates without the bad data\ndetection process in the face of multiple bad data. The method is numerically\nevaluated on the IEEE 33-node radial distribution system. The estimation\nperformance and robustness of RMCSE are compared with the WLS with the largest\nnormalized residual bad data identification (WLS-LNR), and the MCSE.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 03:18:28 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 00:52:28 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 00:01:25 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 00:37:54 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liu", "Bo", ""], ["Wu", "Hongyu", ""], ["Zhang", "Yingchen", ""], ["Yang", "Rui", ""], ["Bernstein", "Andrey", ""]]}, {"id": "1902.02037", "submitter": "Hao Wang", "authors": "Hao Wang, Chengzhi Mao, Hao He, Mingmin Zhao, Tommi S. Jaakkola, Dina\n  Katabi", "title": "Bidirectional Inference Networks: A Class of Deep Bayesian Networks for\n  Health Profiling", "comments": "Appeared at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the values of an arbitrary set of\nvariables (e.g., risk of diseases) given other observed variables (e.g.,\nsymptoms and diagnosed diseases) and high-dimensional signals (e.g., MRI images\nor EEG). This is a common problem in healthcare since variables of interest\noften differ for different patients. Existing methods including Bayesian\nnetworks and structured prediction either do not incorporate high-dimensional\nsignals or fail to model conditional dependencies among variables. To address\nthese issues, we propose bidirectional inference networks (BIN), which stich\ntogether multiple probabilistic neural networks, each modeling a conditional\ndependency. Predictions are then made via iteratively updating variables using\nbackpropagation (BP) to maximize corresponding posterior probability.\nFurthermore, we extend BIN to composite BIN (CBIN), which involves the\niterative prediction process in the training stage and improves both accuracy\nand computational efficiency by adaptively smoothing the optimization\nlandscape. Experiments on synthetic and real-world datasets (a sleep study and\na dermatology dataset) show that CBIN is a single model that can achieve\nstate-of-the-art performance and obtain better accuracy in most inference tasks\nthan multiple models each specifically trained for a different task.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 06:10:46 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Wang", "Hao", ""], ["Mao", "Chengzhi", ""], ["He", "Hao", ""], ["Zhao", "Mingmin", ""], ["Jaakkola", "Tommi S.", ""], ["Katabi", "Dina", ""]]}, {"id": "1902.02041", "submitter": "Sunghwan Joo", "authors": "Juyeon Heo, Sunghwan Joo, Taesup Moon", "title": "Fooling Neural Network Interpretations via Adversarial Model\n  Manipulation", "comments": null, "journal-ref": "NeurIPS 2019, ICCV workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ask whether the neural network interpretation methods can be fooled via\nadversarial model manipulation, which is defined as a model fine-tuning step\nthat aims to radically alter the explanations without hurting the accuracy of\nthe original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating\nthe interpretation results directly in the penalty term of the objective\nfunction for fine-tuning, we show that the state-of-the-art saliency map based\ninterpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with\nour model manipulation. We propose two types of fooling, Passive and Active,\nand demonstrate such foolings generalize well to the entire validation set as\nwell as transfer to other interpretation methods. Our results are validated by\nboth visually showing the fooled explanations and reporting quantitative\nmetrics that measure the deviations from the original explanations. We claim\nthat the stability of neural network interpretation method with respect to our\nadversarial model manipulation is an important criterion to check for\ndeveloping robust and reliable neural network interpretation method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 06:28:09 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:31:14 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 00:16:17 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Heo", "Juyeon", ""], ["Joo", "Sunghwan", ""], ["Moon", "Taesup", ""]]}, {"id": "1902.02056", "submitter": "Fabrice Rossi", "authors": "Aichetou Bouchareb (SAMM), Marc Boull\\'e, Fabrice Rossi (SAMM),\n  Fabrice Cl\\'erot", "title": "Un mod\\`ele Bay\\'esien de co-clustering de donn\\'ees mixtes", "comments": "in French", "journal-ref": "Extraction et gestion des connaissances 2018, Jan 2018, Paris,\n  France. Revue des Nouvelles Technologies de l'Information, RNTI-E-34,\n  pp.275-280, 2018, Actes de la 18{\\`e}eme Conf{\\'e}rence Internationale\n  Francophone sur l'Extraction et gestion des connaissances (EGC'2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a MAP Bayesian approach to perform and evaluate a co-clustering of\nmixed-type data tables. The proposed model infers an optimal segmentation of\nall variables then performs a co-clustering by minimizing a Bayesian model\nselection cost function. One advantage of this approach is that it is user\nparameter-free. Another main advantage is the proposed criterion which gives an\nexact measure of the model quality, measured by probability of fitting it to\nthe data. Continuous optimization of this criterion ensures finding better and\nbetter models while avoiding data over-fitting. The experiments conducted on\nreal data show the interest of this co-clustering approach in exploratory data\nanalysis of large data sets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 07:46:10 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Bouchareb", "Aichetou", "", "SAMM"], ["Boull\u00e9", "Marc", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"], ["Cl\u00e9rot", "Fabrice", ""]]}, {"id": "1902.02060", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng and Shao-Bo Lin and Yuan Yao and Ding-Xuan Zhou", "title": "On ADMM in Deep Learning: Convergence and Saturation-Avoidance", "comments": "This is a revised version of our previous one entitled \"A Convergence\n  Analysis of Nonlinearly Constrained ADMM in Deep Learning, arXiv:1902.02060\"\n  with some significantly changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an alternating direction method of multipliers\n(ADMM) for deep neural networks training with sigmoid-type activation functions\n(called \\textit{sigmoid-ADMM pair}), mainly motivated by the gradient-free\nnature of ADMM in avoiding the saturation of sigmoid-type activations and the\nadvantages of deep neural networks with sigmoid-type activations (called deep\nsigmoid nets) over their rectified linear unit (ReLU) counterparts (called deep\nReLU nets) in terms of approximation. In particular, we prove that the\napproximation capability of deep sigmoid nets is not worse than deep ReLU nets\nby showing that ReLU activation fucntion can be well approximated by deep\nsigmoid nets with two hidden layers and finitely many free parameters but not\nvice-verse. We also establish the global convergence of the proposed ADMM for\nthe nonlinearly constrained formulation of the deep sigmoid nets training to a\nKarush-Kuhn-Tucker (KKT) point at a rate of order ${\\cal O}(1/k)$. Compared\nwith the widely used stochastic gradient descent (SGD) algorithm for the deep\nReLU nets training (called ReLU-SGD pair), the proposed sigmoid-ADMM pair is\npractically stable with respect to the algorithmic hyperparameters including\nthe learning rate, initial schemes and the pro-processing of the input data.\nMoreover, we find that to approximate and learn simple but important functions\nthe proposed sigmoid-ADMM pair numerically outperforms the ReLU-SGD pair.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 08:22:08 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 10:04:13 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zeng", "Jinshan", ""], ["Lin", "Shao-Bo", ""], ["Yao", "Yuan", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1902.02068", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi and Yoshinobu Kawahara", "title": "Knowledge-Based Regularization in Generative Modeling", "comments": "12 pages, 7 figures, 9 tables, presented in IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/331", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior domain knowledge can greatly help to learn generative models. However,\nit is often too costly to hard-code prior knowledge as a specific model\narchitecture, so we often have to use general-purpose models. In this paper, we\npropose a method to incorporate prior knowledge of feature relations into the\nlearning of general-purpose generative models. To this end, we formulate a\nregularizer that makes the marginals of a generative model to follow prescribed\nrelative dependence of features. It can be incorporated into off-the-shelf\nlearning methods of many generative models, including variational autoencoders\nand generative adversarial networks, as its gradients can be computed using\nstandard backpropagation techniques. We show the effectiveness of the proposed\nmethod with experiments on multiple types of datasets and generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 09:02:58 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 21:25:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1902.02075", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis,\n  Athanasios Voulodimos", "title": "Common Mode Patterns for Supervised Tensor Subspace Learning", "comments": "To be presented in IEEE International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method for reducing the dimensionality of tensor\nobjects in a binary classification framework. The proposed Common Mode Patterns\nmethod takes into consideration the labels' information, and ensures that\ntensor objects that belong to different classes do not share common features\nafter the reduction of their dimensionality. We experimentally validate the\nproposed supervised subspace learning technique and compared it against\nMultilinear Principal Component Analysis using a publicly available\nhyperspectral imaging dataset. Experimental results indicate that the proposed\nCMP method can efficiently reduce the dimensionality of tensor objects, while,\nat the same time, increasing the inter-class separability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 09:15:02 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Doulamis", "Anastasios", ""], ["Doulamis", "Nikolaos", ""], ["Voulodimos", "Athanasios", ""]]}, {"id": "1902.02095", "submitter": "Nikita Kazeev", "authors": "Leonid Gremyachikh, Dmitrii Dubov, Nikita Kazeev, Andrey Kulibaba,\n  Andrey Skuratov, Anton Tereshkin, Andrey Ustyuzhanin, Lubov Shiryaeva, Sergej\n  Shishkin", "title": "Space Navigator: a Tool for the Optimization of Collision Avoidance\n  Maneuvers", "comments": "Submitted to AAS Advances in the Astronautical Sciences, presented at\n  IAA SciTech Forum 2018", "journal-ref": "Advances in the Astronautical Sciences 2020 First IAA/AAS SciTech\n  Forum on Space Flight Mechanics and Space Structures and Materials\n  Conference, volume 170", "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of space objects will grow several times in a few years due to the\nplanned launches of constellations of thousands microsatellites. It leads to a\nsignificant increase in the threat of satellite collisions. Spacecraft must\nundertake collision avoidance maneuvers to mitigate the risk. According to\npublicly available information, conjunction events are now manually handled by\noperators on the Earth. The manual maneuver planning requires qualified\npersonnel and will be impractical for constellations of thousands satellites.\nIn this paper we propose a new modular autonomous collision avoidance system\ncalled \"Space Navigator\". It is based on a novel maneuver optimization approach\nthat combines domain knowledge with Reinforcement Learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 10:23:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Gremyachikh", "Leonid", ""], ["Dubov", "Dmitrii", ""], ["Kazeev", "Nikita", ""], ["Kulibaba", "Andrey", ""], ["Skuratov", "Andrey", ""], ["Tereshkin", "Anton", ""], ["Ustyuzhanin", "Andrey", ""], ["Shiryaeva", "Lubov", ""], ["Shishkin", "Sergej", ""]]}, {"id": "1902.02102", "submitter": "Lars Maal{\\o}e", "authors": "Lars Maal{\\o}e, Marco Fraccaro, Valentin Li\\'evin, Ole Winther", "title": "BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the introduction of the variational autoencoder (VAE), probabilistic\nlatent variable models have received renewed attention as powerful generative\nmodels. However, their performance in terms of test likelihood and quality of\ngenerated samples has been surpassed by autoregressive models without\nstochastic units. Furthermore, flow-based models have recently been shown to be\nan attractive alternative that scales well to high-dimensional data. In this\npaper we close the performance gap by constructing VAE models that can\neffectively utilize a deep hierarchy of stochastic variables and model complex\ncovariance structures. We introduce the Bidirectional-Inference Variational\nAutoencoder (BIVA), characterized by a skip-connected generative model and an\ninference network formed by a bidirectional stochastic inference path. We show\nthat BIVA reaches state-of-the-art test likelihoods, generates sharp and\ncoherent natural images, and uses the hierarchy of latent variables to capture\ndifferent aspects of the data distribution. We observe that BIVA, in contrast\nto recent results, can be used for anomaly detection. We attribute this to the\nhierarchy of latent variables which is able to extract high-level semantic\nfeatures. Finally, we extend BIVA to semi-supervised classification tasks and\nshow that it performs comparably to state-of-the-art results by generative\nadversarial networks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 10:36:57 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 12:21:18 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 16:48:34 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Maal\u00f8e", "Lars", ""], ["Fraccaro", "Marco", ""], ["Li\u00e9vin", "Valentin", ""], ["Winther", "Ole", ""]]}, {"id": "1902.02113", "submitter": "Max Frenzel", "authors": "Max F. Frenzel, Bogdan Teleaga, Asahi Ushio", "title": "Latent Space Cartography: Generalised Metric-Inspired Measures and\n  Measure-Based Transformations for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are universal tools for learning data distributions on\nhigh dimensional data spaces via a mapping to lower dimensional latent spaces.\nWe provide a study of latent space geometries and extend and build upon\nprevious results on Riemannian metrics. We show how a class of heuristic\nmeasures gives more flexibility in finding meaningful, problem-specific\ndistances, and how it can be applied to diverse generator types such as\nautoregressive generators commonly used in e.g. language and other sequence\nmodeling. We further demonstrate how a diffusion-inspired transformation\npreviously studied in cartography can be used to smooth out latent spaces,\nstretching them according to a chosen measure. In addition to providing more\nmeaningful distances directly in latent space, this also provides a unique tool\nfor novel kinds of data visualizations. We believe that the proposed methods\ncan be a valuable tool for studying the structure of latent spaces and learned\ndata distributions of generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:15:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Frenzel", "Max F.", ""], ["Teleaga", "Bogdan", ""], ["Ushio", "Asahi", ""]]}, {"id": "1902.02119", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Agnieszka Pocha, Jan Kaczmarczyk, Krzysztof Rataj,\n  Micha{\\l} Warcho{\\l}", "title": "Mol-CycleGAN - a generative model for molecular optimization", "comments": null, "journal-ref": "Journal of Cheminformatics 12, 2 (2020)", "doi": "10.1186/s13321-019-0404-1", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a molecule with desired properties is one of the biggest challenges\nin drug development, as it requires optimization of chemical compound\nstructures with respect to many complex properties. To augment the compound\ndesign process we introduce Mol-CycleGAN - a CycleGAN-based model that\ngenerates optimized compounds with high structural similarity to the original\nones. Namely, given a molecule our model generates a structurally similar one\nwith an optimized value of the considered property. We evaluate the performance\nof the model on selected optimization objectives related to structural\nproperties (presence of halogen groups, number of aromatic rings) and to a\nphysicochemical property (penalized logP). In the task of optimization of\npenalized logP of drug-like molecules our model significantly outperforms\nprevious results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:32:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["Pocha", "Agnieszka", ""], ["Kaczmarczyk", "Jan", ""], ["Rataj", "Krzysztof", ""], ["Warcho\u0142", "Micha\u0142", ""]]}, {"id": "1902.02120", "submitter": "Mohamed Ezzeldin A. Elshaer", "authors": "Mohamed Ezzeldin A. ElShaer, Scott Wisdom, Taniya Mishra", "title": "Transfer Learning From Sound Representations For Anger Detection in\n  Speech", "comments": "5 pages, 2 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we train fully convolutional networks to detect anger in\nspeech. Since training these deep architectures requires large amounts of data\nand the size of emotion datasets is relatively small, we use transfer learning.\nHowever, unlike previous approaches that use speech or emotion-based tasks for\nthe source model, we instead use SoundNet, a fully convolutional neural network\ntrained multimodally on a massive video dataset to classify audio, with\nground-truth labels provided by vision-based classifiers. As a result of\ntransfer learning from SoundNet, our trained anger detection model improves\nperformance and generalizes well on a variety of acted, elicited, and natural\nemotional speech datasets. We also test the cross-lingual effectiveness of our\nmodel by evaluating our English-trained model on Mandarin Chinese speech\nemotion data. Furthermore, our proposed system has low latency suitable for\nreal-time applications, only requiring 1.2 seconds of audio to make a reliable\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:34:44 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["ElShaer", "Mohamed Ezzeldin A.", ""], ["Wisdom", "Scott", ""], ["Mishra", "Taniya", ""]]}, {"id": "1902.02169", "submitter": "Lukas Schmelzeisen", "authors": "Lukas Schmelzeisen and Steffen Staab", "title": "Learning Taxonomies of Concepts and not Words using Contextualized Word\n  Representations: A Position Paper", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Taxonomies are semantic hierarchies of concepts. One limitation of current\ntaxonomy learning systems is that they define concepts as single words. This\nposition paper argues that contextualized word representations, which recently\nachieved state-of-the-art results on many competitive NLP tasks, are a\npromising method to address this limitation. We outline a novel approach for\ntaxonomy learning that (1) defines concepts as synsets, (2) learns\ndensity-based approximations of contextualized word representations, and (3)\ncan measure similarity and hypernymy among them.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 17:18:42 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Schmelzeisen", "Lukas", ""], ["Staab", "Steffen", ""]]}, {"id": "1902.02181", "submitter": "Andrea Galassi", "authors": "Andrea Galassi, Marco Lippi, Paolo Torroni", "title": "Attention in Natural Language Processing", "comments": "18 pages, 8 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2020)", "doi": "10.1109/TNNLS.2020.3019893", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is an increasingly popular mechanism used in a wide range of neural\narchitectures. The mechanism itself has been realized in a variety of formats.\nHowever, because of the fast-paced advances in this domain, a systematic\noverview of attention is still missing. In this article, we define a unified\nmodel for attention architectures in natural language processing, with a focus\non those designed to work with vector representations of the textual data. We\npropose a taxonomy of attention models according to four dimensions: the\nrepresentation of the input, the compatibility function, the distribution\nfunction, and the multiplicity of the input and/or output. We present the\nexamples of how prior information can be exploited in attention models and\ndiscuss ongoing research efforts and open challenges in the area, providing the\nfirst extensive categorization of the vast body of literature in this exciting\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:09:50 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 10:52:29 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Galassi", "Andrea", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "1902.02186", "submitter": "Razvan Pascanu", "authors": "Wojciech Marian Czarnecki, Razvan Pascanu, Simon Osindero, Siddhant M.\n  Jayakumar, Grzegorz Swirszcz, Max Jaderberg", "title": "Distilling Policy Distillation", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer of knowledge from one policy to another is an important tool in\nDeep Reinforcement Learning. This process, referred to as distillation, has\nbeen used to great success, for example, by enhancing the optimisation of\nagents, leading to stronger performance faster, on harder domains [26, 32, 5,\n8]. Despite the widespread use and conceptual simplicity of distillation, many\ndifferent formulations are used in practice, and the subtle variations between\nthem can often drastically change the performance and the resulting objective\nthat is being optimised. In this work, we rigorously explore the entire\nlandscape of policy distillation, comparing the motivations and strengths of\neach variant through theoretical and empirical analysis. Our results point to\nthree distillation techniques, that are preferred depending on specifics of the\ntask. Specifically a newly proposed expected entropy regularised distillation\nallows for quicker learning in a wide range of situations, while still\nguaranteeing convergence.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 14:01:34 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["Pascanu", "Razvan", ""], ["Osindero", "Simon", ""], ["Jayakumar", "Siddhant M.", ""], ["Swirszcz", "Grzegorz", ""], ["Jaderberg", "Max", ""]]}, {"id": "1902.02192", "submitter": "Sean Welleck", "authors": "Sean Welleck, Kiant\\'e Brantley, Hal Daum\\'e III, Kyunghyun Cho", "title": "Non-Monotonic Sequential Text Generation", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard sequential generation methods assume a pre-specified generation\norder, such as text generation methods which generate words from left to right.\nIn this work, we propose a framework for training models of text generation\nthat operate in non-monotonic orders; the model directly learns good orders,\nwithout any additional annotation. Our framework operates by generating a word\nat an arbitrary position, and then recursively generating words to its left and\nthen words to its right, yielding a binary tree. Learning is framed as\nimitation learning, including a coaching method which moves from imitating an\noracle to reinforcing the policy's own preferences. Experimental results\ndemonstrate that using the proposed method, it is possible to learn policies\nwhich generate text without pre-specifying a generation order, while achieving\ncompetitive performance with conventional left-to-right generation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:02:45 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 08:24:04 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 19:48:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Welleck", "Sean", ""], ["Brantley", "Kiant\u00e9", ""], ["Daum\u00e9", "Hal", "III"], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.02208", "submitter": "Shervin Rahimzadeh Arashloo", "authors": "Shervin Rahimzadeh Arashloo and Josef Kittler", "title": "Robust One-Class Kernel Spectral Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel null-space technique and its regression-based formulation (called\none-class kernel spectral regression, a.k.a. OC-KSR) is known to be an\neffective and computationally attractive one-class classification framework.\nDespite its outstanding performance, the applicability of kernel null-space\nmethod is limited due to its susceptibility to possible training data\ncorruptions and inability to rank training observations according to their\nconformity with the model. This work addresses these shortcomings by studying\nthe effect of regularising the solution of the null-space kernel Fisher\nmethodology in the context of its regression-based formulation (OC-KSR). In\nthis respect, first, the effect of a Tikhonov regularisation in the Hilbert\nspace is analysed where the one-class learning problem in presence of\ncontaminations in the training set is posed as a sensitivity analysis problem.\nNext, driven by the success of the sparse representation methodology, the\neffect of a sparsity regularisation on the solution is studied. For both\nalternative regularisation schemes, iterative algorithms are proposed which\nrecursively update label confidences and rank training observations based on\ntheir fit with the model. Through extensive experiments conducted on different\ndata sets, the proposed methodology is found to enhance robustness against\ncontamination in the training set as compared with the baseline kernel\nnull-space technique as well as other existing approaches in a one-class\nclassification paradigm while providing the functionality to rank training\nsamples effectively.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 14:35:53 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Arashloo", "Shervin Rahimzadeh", ""], ["Kittler", "Josef", ""]]}, {"id": "1902.02223", "submitter": "Evgeny Burnaev", "authors": "Ivan Makhotin and Dmitry Koroteev and Evgeny Burnaev", "title": "Gradient Boosting to Boost the Efficiency of Hydraulic Fracturing", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a data-driven model for forecasting the production\nincrease after hydraulic fracturing (HF). We use data from fracturing jobs\nperformed at one of the Siberian oilfields. The data includes features,\ncharacterizing the jobs, and geological information. To predict an oil rate\nafter the fracturing machine learning (ML) technique was applied. We compared\nthe ML-based prediction to a prediction based on the experience of reservoir\nand production engineers responsible for the HF-job planning. We discuss the\npotential for further development of ML techniques for predicting changes in\noil rate after HF.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 07:34:07 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 09:04:59 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 07:03:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Makhotin", "Ivan", ""], ["Koroteev", "Dmitry", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1902.02234", "submitter": "Shaofeng Zou", "authors": "Shaofeng Zou and Tengyu Xu and Yingbin Liang", "title": "Finite-Sample Analysis for SARSA with Linear Function Approximation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SARSA is an on-policy algorithm to learn a Markov decision process policy in\nreinforcement learning. We investigate the SARSA algorithm with linear function\napproximation under the non-i.i.d.\\ data, where a single sample trajectory is\navailable. With a Lipschitz continuous policy improvement operator that is\nsmooth enough, SARSA has been shown to converge asymptotically\n\\cite{perkins2003convergent,melo2008analysis}. However, its non-asymptotic\nanalysis is challenging and remains unsolved due to the non-i.i.d. samples and\nthe fact that the behavior policy changes dynamically with time. In this paper,\nwe develop a novel technique to explicitly characterize the stochastic bias of\na type of stochastic approximation procedures with time-varying Markov\ntransition kernels. Our approach enables non-asymptotic convergence analyses of\nthis type of stochastic approximation algorithms, which may be of independent\ninterest. Using our bias characterization technique and a gradient descent type\nof analysis, we provide the finite-sample analysis on the mean square error of\nthe SARSA algorithm. We then further study a fitted SARSA algorithm, which\nincludes the original SARSA algorithm and its variant in\n\\cite{perkins2003convergent} as special cases. This fitted SARSA algorithm\nprovides a more general framework for \\textit{iterative} on-policy fitted\npolicy iteration, which is more memory and computationally efficient. For this\nfitted SARSA algorithm, we also provide its finite-sample analysis.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:33:45 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 18:10:46 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 15:53:40 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zou", "Shaofeng", ""], ["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""]]}, {"id": "1902.02236", "submitter": "Arinbj\\\"orn Kolbeinsson", "authors": "Naman Shukla, Arinbj\\\"orn Kolbeinsson, Ken Otwell, Lavanya Marla and\n  Kartik Yellepeddi", "title": "Dynamic Pricing for Airline Ancillaries with Customer Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancillaries have become a major source of revenue and profitability in the\ntravel industry. Yet, conventional pricing strategies are based on business\nrules that are poorly optimized and do not respond to changing market\nconditions. This paper describes the dynamic pricing model developed by Deepair\nsolutions, an AI technology provider for travel suppliers. We present a pricing\nmodel that provides dynamic pricing recommendations specific to each customer\ninteraction and optimizes expected revenue per customer. The unique nature of\npersonalized pricing provides the opportunity to search over the market space\nto find the optimal price-point of each ancillary for each customer, without\nviolating customer privacy. In this paper, we present and compare three\napproaches for dynamic pricing of ancillaries, with increasing levels of\nsophistication: (1) a two-stage forecasting and optimization model using a\nlogistic mapping function; (2) a two-stage model that uses a deep neural\nnetwork for forecasting, coupled with a revenue maximization technique using\ndiscrete exhaustive search; (3) a single-stage end-to-end deep neural network\nthat recommends the optimal price. We describe the performance of these models\nbased on both offline and online evaluations. We also measure the real-world\nbusiness impact of these approaches by deploying them in an A/B test on an\nairline's internet booking website. We show that traditional machine learning\ntechniques outperform human rule-based approaches in an online setting by\nimproving conversion by 36% and revenue per offer by 10%. We also provide\nresults for our offline experiments which show that deep learning algorithms\noutperform traditional machine learning techniques for this problem. Our\nend-to-end deep learning model is currently being deployed by the airline in\ntheir booking system.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:38:06 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Shukla", "Naman", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Otwell", "Ken", ""], ["Marla", "Lavanya", ""], ["Yellepeddi", "Kartik", ""]]}, {"id": "1902.02242", "submitter": "Yahav Bechavod", "authors": "Yahav Bechavod, Katrina Ligett, Aaron Roth, Bo Waggoner, Zhiwei Steven\n  Wu", "title": "Equal Opportunity in Online Classification with Partial Feedback", "comments": "The Conference version of this paper appears in the Proceedings of\n  NeurIPS 2019. 29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online classification problem with partial feedback in which\nindividuals arrive one at a time from a fixed but unknown distribution, and\nmust be classified as positive or negative. Our algorithm only observes the\ntrue label of an individual if they are given a positive classification. This\nsetting captures many classification problems for which fairness is a concern:\nfor example, in criminal recidivism prediction, recidivism is only observed if\nthe inmate is released; in lending applications, loan repayment is only\nobserved if the loan is granted. We require that our algorithms satisfy common\nstatistical fairness constraints (such as equalizing false positive or negative\nrates -- introduced as \"equal opportunity\" in Hardt et al. (2016)) at every\nround, with respect to the underlying distribution. We give upper and lower\nbounds characterizing the cost of this constraint in terms of the regret rate\n(and show that it is mild), and give an oracle efficient algorithm that\nachieves the upper bound.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:45:17 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 12:16:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bechavod", "Yahav", ""], ["Ligett", "Katrina", ""], ["Roth", "Aaron", ""], ["Waggoner", "Bo", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1902.02244", "submitter": "Chen-Yu Wei", "authors": "Alina Beygelzimer, D\\'avid P\\'al, Bal\\'azs Sz\\\"or\\'enyi, Devanathan\n  Thiruvenkatachari, Chen-Yu Wei, Chicheng Zhang", "title": "Bandit Multiclass Linear Classification: Efficient Algorithms for the\n  Separable Case", "comments": "41 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficient online multiclass linear classification\nwith bandit feedback, where all examples belong to one of $K$ classes and lie\nin the $d$-dimensional Euclidean space. Previous works have left open the\nchallenge of designing efficient algorithms with finite mistake bounds when the\ndata is linearly separable by a margin $\\gamma$. In this work, we take a first\nstep towards this problem. We consider two notions of linear separability:\nstrong and weak.\n  1. Under the strong linear separability condition, we design an efficient\nalgorithm that achieves a near-optimal mistake bound of $O\\left( K/\\gamma^2\n\\right)$.\n  2. Under the more challenging weak linear separability condition, we design\nan efficient algorithm with a mistake bound of $\\min (2^{\\widetilde{O}(K \\log^2\n(1/\\gamma))}, 2^{\\widetilde{O}(\\sqrt{1/\\gamma} \\log K)})$. Our algorithm is\nbased on kernel Perceptron, which is inspired by the work of (Klivans and\nServedio, 2008) on improperly learning intersection of halfspaces.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:47:38 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 05:38:34 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Beygelzimer", "Alina", ""], ["P\u00e1l", "D\u00e1vid", ""], ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", ""], ["Thiruvenkatachari", "Devanathan", ""], ["Wei", "Chen-Yu", ""], ["Zhang", "Chicheng", ""]]}, {"id": "1902.02248", "submitter": "Anant Gupta", "authors": "Anant Gupta, Srivas Venkatesh, Sumit Chopra, Christian Ledig", "title": "Generative Image Translation for Data Augmentation of Bone Lesion\n  Pathology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insufficient training data and severe class imbalance are often limiting\nfactors when developing machine learning models for the classification of rare\ndiseases. In this work, we address the problem of classifying bone lesions from\nX-ray images by increasing the small number of positive samples in the training\nset. We propose a generative data augmentation approach based on a\ncycle-consistent generative adversarial network that synthesizes bone lesions\non images without pathology. We pose the generative task as an image-patch\ntranslation problem that we optimize specifically for distinct bones (humerus,\ntibia, femur). In experimental results, we confirm that the described method\nmitigates the class imbalance problem in the binary classification task of bone\nlesion detection. We show that the augmented training sets enable the training\nof superior classifiers achieving better performance on a held-out test set.\nAdditionally, we demonstrate the feasibility of transfer learning and apply a\ngenerative model that was trained on one body part to another.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:57:39 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Gupta", "Anant", ""], ["Venkatesh", "Srivas", ""], ["Chopra", "Sumit", ""], ["Ledig", "Christian", ""]]}, {"id": "1902.02263", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Unsupervised Polyglot Text To Speech", "comments": "The paper will be presented at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a TTS neural network that is able to produce speech in multiple\nlanguages. The proposed network is able to transfer a voice, which was\npresented as a sample in a source language, into one of several target\nlanguages. Training is done without using matching or parallel data, i.e.,\nwithout samples of the same speaker in multiple languages, making the method\nmuch more applicable. The conversion is based on learning a polyglot network\nthat has multiple per-language sub-networks and adding loss terms that preserve\nthe speaker's identity in multiple languages. We evaluate the proposed polyglot\nneural network for three languages with a total of more than 400 speakers and\ndemonstrate convincing conversion capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 16:28:26 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1902.02300", "submitter": "Kalvik Jakkala", "authors": "Kalvik Jakkala, Arupjyoti Bhuya, Zhi Sun, Pu Wang and Zhuo Cheng", "title": "Deep CSI Learning for Gait Biometric Sensing and Recognition", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gait is a person's natural walking style and a complex biological process\nthat is unique to each person. Recently, the channel state information (CSI) of\nWiFi devices have been exploited to capture human gait biometrics for user\nidentification. However, the performance of existing CSI-based gait\nidentification systems is far from satisfactory. They can only achieve limited\nidentification accuracy (maximum $93\\%$) only for a very small group of people\n(i.e., between 2 to 10). To address such challenge, an end-to-end deep CSI\nlearning system is developed, which exploits deep neural networks to\nautomatically learn the salient gait features in CSI data that are\ndiscriminative enough to distinguish different people Firstly, the raw CSI data\nare sanitized through window-based denoising, mean centering and normalization.\nThe sanitized data is then passed to a residual deep convolutional neural\nnetwork (DCNN), which automatically extracts the hierarchical features of\ngait-signatures embedded in the CSI data. Finally, a softmax classifier\nutilizes the extracted features to make the final prediction about the identity\nof the user. In a typical indoor environment, a top-1 accuracy of $97.12 \\pm\n1.13\\%$ is achieved for a dataset of 30 people.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 17:51:04 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Jakkala", "Kalvik", ""], ["Bhuya", "Arupjyoti", ""], ["Sun", "Zhi", ""], ["Wang", "Pu", ""], ["Cheng", "Zhuo", ""]]}, {"id": "1902.02302", "submitter": "Aditya Chattopadhyay", "authors": "Aditya Chattopadhyay, Piyushi Manupriya, Anirban Sarkar and Vineeth N\n  Balasubramanian", "title": "Neural Network Attributions: A Causal Perspective", "comments": "17 pages, 10 Figures. Accepted in the Proceedings of the 36th\n  International Conference on Machine Learning (ICML2019). Modifications: Added\n  github link to code and fixed a typo in Fig. 3", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning 97 (2019) 981-990", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new attribution method for neural networks developed using first\nprinciples of causality (to the best of our knowledge, the first such). The\nneural network architecture is viewed as a Structural Causal Model, and a\nmethodology to compute the causal effect of each feature on the output is\npresented. With reasonable assumptions on the causal structure of the input\ndata, we propose algorithms to efficiently compute the causal effects, as well\nas scale the approach to data with large dimensionality. We also show how this\nmethod can be used for recurrent neural networks. We report experimental\nresults on both simulated and real datasets showcasing the promise and\nusefulness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 17:53:07 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 01:43:18 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 06:46:18 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 07:58:24 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Chattopadhyay", "Aditya", ""], ["Manupriya", "Piyushi", ""], ["Sarkar", "Anirban", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1902.02308", "submitter": "Muhammed Sit", "authors": "Muhammed Sit and Ibrahim Demir", "title": "Decentralized Flood Forecasting Using Deep Neural Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting flood for any location at times of extreme storms is a\nlongstanding problem that has utmost importance in emergency management.\nConventional methods that aim to predict water levels in streams use advanced\nhydrological models still lack of giving accurate forecasts everywhere. This\nstudy aims to explore artificial deep neural networks' performance on flood\nprediction. While providing models that can be used in forecasting stream\nstage, this paper presents a dataset that focuses on the connectivity of data\npoints on river networks. It also shows that neural networks can be very\nhelpful in time-series forecasting as in flood events, and support improving\nexisting models through data assimilation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:05:41 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 21:24:04 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sit", "Muhammed", ""], ["Demir", "Ibrahim", ""]]}, {"id": "1902.02311", "submitter": "Alex Tong Lin", "authors": "Alex Tong Lin, Mark J. Debord, Katia Estabridis, Gary Hewer, Guido\n  Montufar, Stanley Osher", "title": "Decentralized Multi-Agents by Imitation of a Centralized Controller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-agent reinforcement learning problem where each agent\nseeks to maximize a shared reward while interacting with other agents, and they\nmay or may not be able to communicate. Typically the agents do not have access\nto other agent policies and thus each agent is situated in a non-stationary and\npartially-observable environment. In order to obtain multi-agents that act in a\ndecentralized manner, we introduce a novel algorithm under the popular\nframework of centralized training, but decentralized execution. This training\nframework first obtains solutions to a multi-agent problem with a single\ncentralized joint-space learner, which is then used to guide imitation learning\nfor independent decentralized multi-agents. This framework has the flexibility\nto use any reinforcement learning algorithm to obtain the expert as well as any\nimitation learning algorithm to obtain the decentralized agents. This is in\ncontrast to other multi-agent learning algorithms that, for example, can\nrequire more specific structures. We present some theoretical bounds for our\nmethod, and we show that one can obtain decentralized solutions to a\nmulti-agent problem through imitation learning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:14:31 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 14:48:32 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 01:39:00 GMT"}, {"version": "v4", "created": "Thu, 22 Apr 2021 18:59:26 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lin", "Alex Tong", ""], ["Debord", "Mark J.", ""], ["Estabridis", "Katia", ""], ["Hewer", "Gary", ""], ["Montufar", "Guido", ""], ["Osher", "Stanley", ""]]}, {"id": "1902.02322", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:38:02 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "1902.02336", "submitter": "Jacob Jackson", "authors": "Jacob Jackson, John Schulman", "title": "Semi-Supervised Learning by Label Gradient Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present label gradient alignment, a novel algorithm for semi-supervised\nlearning which imputes labels for the unlabeled data and trains on the imputed\nlabels. We define a semantically meaningful distance metric on the input space\nby mapping a point (x, y) to the gradient of the model at (x, y). We then\nformulate an optimization problem whose objective is to minimize the distance\nbetween the labeled and the unlabeled data in this space, and we solve it by\ngradient descent on the imputed labels. We evaluate label gradient alignment\nusing the standardized architecture introduced by Oliver et al. (2018) and\ndemonstrate state-of-the-art accuracy in semi-supervised CIFAR-10\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:53:39 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Jackson", "Jacob", ""], ["Schulman", "John", ""]]}, {"id": "1902.02354", "submitter": "Zohar Ringel", "authors": "Oded Ben-David, Zohar Ringel", "title": "The role of a layer in deep neural networks: a Gaussian Process\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in deep learning concerns the role played by\nindividual layers in a deep neural network (DNN) and the transferable\nproperties of the data representations which they learn. To the extent that\nlayers have clear roles, one should be able to optimize them separately using\nlayer-wise loss functions. Such loss functions would describe what is the set\nof good data representations at each depth of the network and provide a target\nfor layer-wise greedy optimization (LEGO). Here we derive a novel\ncorrespondence between Gaussian Processes and SGD trained deep neural networks.\nLeveraging this correspondence, we derive the Deep Gaussian Layer-wise loss\nfunctions (DGLs) which, we believe, are the first supervised layer-wise loss\nfunctions which are both explicit and competitive in terms of accuracy. Being\nhighly structured and symmetric, the DGLs provide a promising analytic route to\nunderstanding the internal representations generated by DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:00:03 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 14:19:01 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 11:59:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ben-David", "Oded", ""], ["Ringel", "Zohar", ""]]}, {"id": "1902.02366", "submitter": "Guillaume Alain", "authors": "Guillaume Alain, Nicolas Le Roux, Pierre-Antoine Manzagol", "title": "Negative eigenvalues of the Hessian in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss function of deep networks is known to be non-convex but the precise\nnature of this nonconvexity is still an active area of research. In this work,\nwe study the loss landscape of deep networks through the eigendecompositions of\ntheir Hessian matrix. In particular, we examine how important the negative\neigenvalues are and the benefits one can observe in handling them\nappropriately.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:18:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Alain", "Guillaume", ""], ["Roux", "Nicolas Le", ""], ["Manzagol", "Pierre-Antoine", ""]]}, {"id": "1902.02368", "submitter": "Ibrahim Ekren", "authors": "Erhan Bayraktar, Ibrahim Ekren and Yili Zhang", "title": "On the asymptotic optimality of the comb strategy for prediction with\n  expert advice", "comments": "To appear in Annals of Applied Probabilty", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of prediction with expert advice in the adversarial setting\nwith geometric stopping, we compute the exact leading order expansion for the\nlong time behavior of the value function. Then, we use this expansion to prove\nthat as conjectured in Gravin et al. [12], the comb strategies are indeed\nasymptotically optimal for the adversary in the case of 4 experts.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:20:53 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 20:40:49 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Ekren", "Ibrahim", ""], ["Zhang", "Yili", ""]]}, {"id": "1902.02375", "submitter": "Jixuan Wang", "authors": "Jixuan Wang, Kuan-Chieh Wang, Marc Law, Frank Rudzicz, Michael Brudno", "title": "Centroid-based deep metric learning for speaker recognition", "comments": "ICASSP 2019 (44th International Conference on Acoustics, Speech, and\n  Signal Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embedding models that utilize neural networks to map utterances to a\nspace where distances reflect similarity between speakers have driven recent\nprogress in the speaker recognition task. However, there is still a significant\nperformance gap between recognizing speakers in the training set and unseen\nspeakers. The latter case corresponds to the few-shot learning task, where a\ntrained model is evaluated on unseen classes. Here, we optimize a speaker\nembedding model with prototypical network loss (PNL), a state-of-the-art\napproach for the few-shot image classification task. The resulting embedding\nmodel outperforms the state-of-the-art triplet loss based models in both\nspeaker verification and identification tasks, for both seen and unseen\nspeakers.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:40:33 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wang", "Jixuan", ""], ["Wang", "Kuan-Chieh", ""], ["Law", "Marc", ""], ["Rudzicz", "Frank", ""], ["Brudno", "Michael", ""]]}, {"id": "1902.02376", "submitter": "Christopher Rackauckas", "authors": "Chris Rackauckas, Mike Innes, Yingbo Ma, Jesse Bettencourt, Lyndon\n  White, Vaibhav Dixit", "title": "DiffEqFlux.jl - A Julia Library for Neural Differential Equations", "comments": "Julialang Blog post, DiffEqFlux.jl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DiffEqFlux.jl is a library for fusing neural networks and differential\nequations. In this work we describe differential equations from the viewpoint\nof data science and discuss the complementary nature between machine learning\nmodels and differential equations. We demonstrate the ability to incorporate\nDifferentialEquations.jl-defined differential equation problems into a\nFlux-defined neural network, and vice versa. The advantages of being able to\nuse the entire DifferentialEquations.jl suite for this purpose is demonstrated\nby counter examples where simple integration strategies fail, but the\nsophisticated integration strategies provided by the DifferentialEquations.jl\nlibrary succeed. This is followed by a demonstration of delay differential\nequations and stochastic differential equations inside of neural networks. We\nshow high-level functionality for defining neural ordinary differential\nequations (neural networks embedded into the differential equation) and\ndescribe the extra models in the Flux model zoo which includes neural\nstochastic differential equations. We conclude by discussing the various\nadjoint methods used for backpropogation of the differential equation solvers.\nDiffEqFlux.jl is an important contribution to the area, as it allows the full\nweight of the differential equation solvers developed from decades of research\nin the scientific computing field to be readily applied to the challenges posed\nby machine learning and data science.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:42:14 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Rackauckas", "Chris", ""], ["Innes", "Mike", ""], ["Ma", "Yingbo", ""], ["Bettencourt", "Jesse", ""], ["White", "Lyndon", ""], ["Dixit", "Vaibhav", ""]]}, {"id": "1902.02380", "submitter": "Artem Grachev", "authors": "Artem M. Grachev and Dmitry I. Ignatov and Andrey V. Savchenko", "title": "Compression of Recurrent Neural Networks for Efficient Language Modeling", "comments": "25 pages, 3 tables, 4 figures", "journal-ref": null, "doi": "10.1016/j.asoc.2019.03.057", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have proved to be an effective method for\nstatistical language modeling. However, in practice their memory and run-time\ncomplexity are usually too large to be implemented in real-time offline mobile\napplications. In this paper we consider several compression techniques for\nrecurrent neural networks including Long-Short Term Memory models. We make\nparticular attention to the high-dimensional output problem caused by the very\nlarge vocabulary size. We focus on effective compression methods in the context\nof their exploitation on devices: pruning, quantization, and matrix\ndecomposition approaches (low-rank factorization and tensor train\ndecomposition, in particular). For each model we investigate the trade-off\nbetween its size, suitability for fast inference and perplexity. We propose a\ngeneral pipeline for applying the most suitable methods to compress recurrent\nneural networks for language modeling. It has been shown in the experimental\nstudy with the Penn Treebank (PTB) dataset that the most efficient results in\nterms of speed and compression-perplexity balance are obtained by matrix\ndecomposition techniques.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:49:22 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Grachev", "Artem M.", ""], ["Ignatov", "Dmitry I.", ""], ["Savchenko", "Andrey V.", ""]]}, {"id": "1902.02383", "submitter": "Yiming Wang", "authors": "Yiming Wang, Xing Fan, I-Fan Chen, Yuzong Liu, Tongfei Chen, Bj\\\"orn\n  Hoffmeister", "title": "End-to-end Anchored Speech Recognition", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-controlled house-hold devices, like Amazon Echo or Google Home, face\nthe problem of performing speech recognition of device-directed speech in the\npresence of interfering background speech, i.e., background noise and\ninterfering speech from another person or media device in proximity need to be\nignored. We propose two end-to-end models to tackle this problem with\ninformation extracted from the \"anchored segment\". The anchored segment refers\nto the wake-up word part of an audio stream, which contains valuable speaker\ninformation that can be used to suppress interfering speech and background\nnoise. The first method is called \"Multi-source Attention\" where the attention\nmechanism takes both the speaker information and decoder state into\nconsideration. The second method directly learns a frame-level mask on top of\nthe encoder output. We also explore a multi-task learning setup where we use\nthe ground truth of the mask to guide the learner. Given that audio data with\ninterfering speech is rare in our training data set, we also propose a way to\nsynthesize \"noisy\" speech from \"clean\" speech to mitigate the mismatch between\ntraining and test data. Our proposed methods show up to 15% relative reduction\nin WER for Amazon Alexa live data with interfering background speech without\nsignificantly degrading on clean speech.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:50:23 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wang", "Yiming", ""], ["Fan", "Xing", ""], ["Chen", "I-Fan", ""], ["Liu", "Yuzong", ""], ["Chen", "Tongfei", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1902.02384", "submitter": "Mark Ibrahim", "authors": "Mark Ibrahim, Melissa Louie, Ceena Modarres, John Paisley", "title": "Global Explanations of Neural Networks: Mapping the Landscape of\n  Predictions", "comments": "published at ACM/AAAI AIES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A barrier to the wider adoption of neural networks is their lack of\ninterpretability. While local explanation methods exist for one prediction,\nmost global attributions still reduce neural network decisions to a single set\nof features. In response, we present an approach for generating global\nattributions called GAM, which explains the landscape of neural network\npredictions across subpopulations. GAM augments global explanations with the\nproportion of samples that each attribution best explains and specifies which\nsamples are described by each attribution. Global explanations also have\ntunable granularity to detect more or fewer subpopulations. We demonstrate that\nGAM's global explanations 1) yield the known feature importances of simulated\ndata, 2) match feature weights of interpretable statistical models on real\ndata, and 3) are intuitive to practitioners through user studies. With more\ntransparent predictions, GAM can help ensure neural network decisions are\ngenerated for the right reasons.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:58:48 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Ibrahim", "Mark", ""], ["Louie", "Melissa", ""], ["Modarres", "Ceena", ""], ["Paisley", "John", ""]]}, {"id": "1902.02399", "submitter": "Jae-Wook Ahn", "authors": "Payel Das, Brian Quanz, Pin-Yu Chen, Jae-wook Ahn, Dhruv Shah", "title": "Toward A Neuro-inspired Creative Decoder", "comments": "Accepted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity, a process that generates novel and meaningful ideas, involves\nincreased association between task-positive (control) and task-negative\n(default) networks in the human brain. Inspired by this seminal finding, in\nthis study we propose a creative decoder within a deep generative framework,\nwhich involves direct modulation of the neuronal activation pattern after\nsampling from the learned latent space. The proposed approach is fully\nunsupervised and can be used off-the-shelf. Several novelty metrics and human\nevaluation were used to evaluate the creative capacity of the deep decoder. Our\nexperiments on different image datasets (MNIST, FMNIST, MNIST+FMNIST, WikiArt\nand CelebA) reveal that atypical co-activation of highly activated and weakly\nactivated neurons in a deep decoder promotes generation of novel and meaningful\nartifacts.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:06:58 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 17:09:42 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 18:24:27 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 02:42:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Das", "Payel", ""], ["Quanz", "Brian", ""], ["Chen", "Pin-Yu", ""], ["Ahn", "Jae-wook", ""], ["Shah", "Dhruv", ""]]}, {"id": "1902.02401", "submitter": "Brian Xu", "authors": "Brian Xu, Mitra Mohtarami, James Glass", "title": "Adversarial Domain Adaptation for Stance Detection", "comments": "Accepted at NIPS-CL-2018, Stance Detection, Fact Checking,\n  Adversarial Domain Adaptation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of stance detection which aims to predict the\nperspective (or stance) of a given document with respect to a given claim.\nStance detection is a major component of automated fact checking. As annotating\nstances in different domains is a tedious and costly task, automatic methods\nbased on machine learning are viable alternatives. In this paper, we focus on\nadversarial domain adaptation for stance detection where we assume there exists\nsufficient labeled data in the source domain and limited labeled data in the\ntarget domain. Extensive experiments on publicly available datasets show the\neffectiveness of our domain adaption model in transferring knowledge for\naccurate stance detection across domains.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:17:57 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Xu", "Brian", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""]]}, {"id": "1902.02405", "submitter": "Tim Cooijmans", "authors": "Tim Cooijmans and James Martens", "title": "On the Variance of Unbiased Online Recurrent Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Unbiased Online Recurrent Optimization algorithm (UORO,\narXiv:1702.05043) uses an unbiased approximation of RTRL to achieve fully\nonline gradient-based learning in RNNs. In this work we analyze the variance of\nthe gradient estimate computed by UORO, and propose several possible changes to\nthe method which reduce this variance both in theory and practice. We also\ncontribute significantly to the theoretical and intuitive understanding of UORO\n(and its existing variance reduction technique), and demonstrate a fundamental\nconnection between its gradient estimate and the one that would be computed by\nREINFORCE if small amounts of noise were added to the RNN's hidden units.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:46:34 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Cooijmans", "Tim", ""], ["Martens", "James", ""]]}, {"id": "1902.02412", "submitter": "Quinten Meertens", "authors": "Q. A. Meertens, C. G. H. Diks, H. J. van den Herik, F W Takes", "title": "A Bayesian Approach for Accurate Classification-Based Aggregates", "comments": "9 pages, 5 figures, accepted conference paper, SIAM International\n  Conference on Data Mining 2019 (SDM19)", "journal-ref": null, "doi": "10.1137/1.9781611975673.35", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the accuracy of values aggregated over classes\npredicted by a classification algorithm. The problem is that the resulting\naggregates (e.g., sums of a variable) are known to be biased. The bias can be\nlarge even for highly accurate classification algorithms, in particular when\ndealing with class-imbalanced data. To correct this bias, the algorithm's\nclassification error rates have to be estimated. In this estimation, two issues\narise when applying existing bias correction methods. First, inaccuracies in\nestimating classification error rates have to be taken into account. Second,\nimpermissible estimates, such as a negative estimate for a positive value, have\nto be dismissed. We show that both issues are relevant in applications where\nthe true labels are known only for a small set of data points. We propose a\nnovel bias correction method using Bayesian inference. The novelty of our\nmethod is that it imposes constraints on the model parameters. We show that our\nmethod solves the problem of biased classification-based aggregates as well as\nthe two issues above, in the general setting of multi-class classification. In\nthe empirical evaluation, using a binary classifier on a real-world dataset of\ncompany tax returns, we show that our method outperforms existing methods in\nterms of mean squared error.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 22:18:42 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Meertens", "Q. A.", ""], ["Diks", "C. G. H.", ""], ["Herik", "H. J. van den", ""], ["Takes", "F W", ""]]}, {"id": "1902.02416", "submitter": "Santu Rana", "authors": "Tinu Theckel Joy, Santu Rana, Sunil Gupta, Svetha Venkatesh", "title": "Fast Hyperparameter Tuning using Bayesian Optimization with Directional\n  Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a Bayesian optimization based hyperparameter tuning\nframework inspired by statistical learning theory for classifiers. We utilize\ntwo key facts from PAC learning theory; the generalization bound will be higher\nfor a small subset of data compared to the whole, and the highest accuracy for\na small subset of data can be achieved with a simple model. We initially tune\nthe hyperparameters on a small subset of training data using Bayesian\noptimization. While tuning the hyperparameters on the whole training data, we\nleverage the insights from the learning theory to seek more complex models. We\nrealize this by using directional derivative signs strategically placed in the\nhyperparameter search space to seek a more complex model than the one obtained\nwith small data. We demonstrate the performance of our method on the tasks of\ntuning the hyperparameters of several machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 22:26:45 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Joy", "Tinu Theckel", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1902.02422", "submitter": "Qiwei Xie", "authors": "Qiwei Xie and Liang Tang and Weifu Li and Vijay John and Yong Hu", "title": "Principal Model Analysis Based on Partial Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the Bagging Partial Least Squares (PLS) and Principal Component\nAnalysis (PCA) algorithms, we propose a Principal Model Analysis (PMA) method\nin this paper. In the proposed PMA algorithm, the PCA and the PLS are combined.\nIn the method, multiple PLS models are trained on sub-training sets, derived\nfrom the original training set based on the random sampling with replacement\nmethod. The regression coefficients of all the sub-PLS models are fused in a\njoint regression coefficient matrix. The final projection direction is then\nestimated by performing the PCA on the joint regression coefficient matrix. The\nproposed PMA method is compared with other traditional dimension reduction\nmethods, such as PLS, Bagging PLS, Linear discriminant analysis (LDA) and\nPLS-LDA. Experimental results on six public datasets show that our proposed\nmethod can achieve better classification performance and is usually more\nstable.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 22:47:54 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Xie", "Qiwei", ""], ["Tang", "Liang", ""], ["Li", "Weifu", ""], ["John", "Vijay", ""], ["Hu", "Yong", ""]]}, {"id": "1902.02434", "submitter": "Akshay Rangamani", "authors": "Akshay Rangamani, Nam H. Nguyen, Abhishek Kumar, Dzung Phan, Sang H.\n  Chin, Trac D. Tran", "title": "A Scale Invariant Flatness Measure for Deep Network Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It has been empirically observed that the flatness of minima obtained from\ntraining deep networks seems to correlate with better generalization. However,\nfor deep networks with positively homogeneous activations, most measures of\nsharpness/flatness are not invariant to rescaling of the network parameters,\ncorresponding to the same function. This means that the measure of\nflatness/sharpness can be made as small or as large as possible through\nrescaling, rendering the quantitative measures meaningless. In this paper we\nshow that for deep networks with positively homogenous activations, these\nrescalings constitute equivalence relations, and that these equivalence\nrelations induce a quotient manifold structure in the parameter space. Using\nthis manifold structure and an appropriate metric, we propose a Hessian-based\nmeasure for flatness that is invariant to rescaling. We use this new measure to\nconfirm the proposition that Large-Batch SGD minima are indeed sharper than\nSmall-Batch SGD minima.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 23:51:53 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Rangamani", "Akshay", ""], ["Nguyen", "Nam H.", ""], ["Kumar", "Abhishek", ""], ["Phan", "Dzung", ""], ["Chin", "Sang H.", ""], ["Tran", "Trac D.", ""]]}, {"id": "1902.02441", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Carmichael Ong, Sharada Prasanna Mohanty,\n  Jennifer Hicks, Sean F. Carroll, Bo Zhou, Hongsheng Zeng, Fan Wang, Rongzhong\n  Lian, Hao Tian, Wojciech Ja\\'skowski, Garrett Andersen, Odd Rune Lykkeb{\\o},\n  Nihat Engin Toklu, Pranav Shyam, Rupesh Kumar Srivastava, Sergey Kolesnikov,\n  Oleksii Hrinchuk, Anton Pechenko, Mattias Ljungstr\\\"om, Zhen Wang, Xu Hu,\n  Zehong Hu, Minghui Qiu, Jun Huang, Aleksei Shpilman, Ivan Sosin, Oleg\n  Svidchenko, Aleksandra Malysheva, Daniel Kudenko, Lance Rane, Aditya Bhatt,\n  Zhengfei Wang, Penghui Qi, Zeyang Yu, Peng Peng, Quan Yuan, Wenxin Li,\n  Yunsheng Tian, Ruihan Yang, Pingchuan Ma, Shauharda Khadka, Somdeb Majumdar,\n  Zach Dwiel, Yinyin Liu, Evren Tumer, Jeremy Watson, Marcel Salath\\'e, Sergey\n  Levine, Scott Delp", "title": "Artificial Intelligence for Prosthetics - challenge solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the NeurIPS 2018 Artificial Intelligence for Prosthetics challenge,\nparticipants were tasked with building a controller for a musculoskeletal model\nwith a goal of matching a given time-varying velocity vector. Top participants\nwere invited to describe their algorithms. In this work, we describe the\nchallenge and present thirteen solutions that used deep reinforcement learning\napproaches. Many solutions use similar relaxations and heuristics, such as\nreward shaping, frame skipping, discretization of the action space, symmetry,\nand policy blending. However, each team implemented different modifications of\nthe known algorithms by, for example, dividing the task into subtasks, learning\nlow-level control, or by incorporating expert knowledge and using imitation\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 01:17:17 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Ong", "Carmichael", ""], ["Mohanty", "Sharada Prasanna", ""], ["Hicks", "Jennifer", ""], ["Carroll", "Sean F.", ""], ["Zhou", "Bo", ""], ["Zeng", "Hongsheng", ""], ["Wang", "Fan", ""], ["Lian", "Rongzhong", ""], ["Tian", "Hao", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Andersen", "Garrett", ""], ["Lykkeb\u00f8", "Odd Rune", ""], ["Toklu", "Nihat Engin", ""], ["Shyam", "Pranav", ""], ["Srivastava", "Rupesh Kumar", ""], ["Kolesnikov", "Sergey", ""], ["Hrinchuk", "Oleksii", ""], ["Pechenko", "Anton", ""], ["Ljungstr\u00f6m", "Mattias", ""], ["Wang", "Zhen", ""], ["Hu", "Xu", ""], ["Hu", "Zehong", ""], ["Qiu", "Minghui", ""], ["Huang", "Jun", ""], ["Shpilman", "Aleksei", ""], ["Sosin", "Ivan", ""], ["Svidchenko", "Oleg", ""], ["Malysheva", "Aleksandra", ""], ["Kudenko", "Daniel", ""], ["Rane", "Lance", ""], ["Bhatt", "Aditya", ""], ["Wang", "Zhengfei", ""], ["Qi", "Penghui", ""], ["Yu", "Zeyang", ""], ["Peng", "Peng", ""], ["Yuan", "Quan", ""], ["Li", "Wenxin", ""], ["Tian", "Yunsheng", ""], ["Yang", "Ruihan", ""], ["Ma", "Pingchuan", ""], ["Khadka", "Shauharda", ""], ["Majumdar", "Somdeb", ""], ["Dwiel", "Zach", ""], ["Liu", "Yinyin", ""], ["Tumer", "Evren", ""], ["Watson", "Jeremy", ""], ["Salath\u00e9", "Marcel", ""], ["Levine", "Sergey", ""], ["Delp", "Scott", ""]]}, {"id": "1902.02443", "submitter": "Sunil Mallya", "authors": "Sunil Mallya, Marc Overhage, Navneet Srivastava, Tatsuya Arai, Cole\n  Erdman", "title": "Effectiveness of LSTMs in Predicting Congestive Heart Failure Onset", "comments": "LSTMs, Electronic Health Records", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a Recurrent neural networks (RNN) based architecture\nthat achieves an AUCROC of 0.9147 for predicting the onset of Congestive Heart\nFailure (CHF) 15 months in advance using a 12-month observation window on a\nlarge cohort of 216,394 patients. We believe this to be the largest study in\nCHF onset prediction with respect to the number of CHF case patients in the\ncohort and the test set (3,332 CHF patients) on which the AUC metrics are\nreported. We explore the extent to which LSTM (Long Short Term Memory) based\nmodel, a variant of RNNs, can accurately predict the onset of CHF when compared\nto known linear baselines like Logistic Regression, Random Forests and deep\nlearning based models such as Multi-Layer Perceptron and Convolutional Neural\nNetworks. We utilize demographics, medical diagnosis and procedure data from\n21,405 CHF and 194,989 control patients to as our features. We describe our\nfeature embedding strategy for medical diagnosis codes that accommodates the\nsparse, irregular, longitudinal, and high-dimensional characteristics of EHR\ndata. We empirically show that LSTMs can capture the longitudinal aspects of\nEHR data better than the proposed baselines. As an attempt to interpret the\nmodel, we present a temporal data analysis-based technique on false positives\nto attribute feature importance. A model capable of predicting the onset of\ncongestive heart failure months in the future with this level of accuracy and\nprecision can support efforts of practitioners to implement risk factor\nreduction strategies and researchers to begin to systematically evaluate\ninterventions to potentially delay or avert development of the disease with\nhigh mortality, morbidity and significant costs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 01:47:28 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 06:13:02 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Mallya", "Sunil", ""], ["Overhage", "Marc", ""], ["Srivastava", "Navneet", ""], ["Arai", "Tatsuya", ""], ["Erdman", "Cole", ""]]}, {"id": "1902.02449", "submitter": "Se Young Chun", "authors": "Byung Hyun Lee and Se Young Chun", "title": "Empirically Accelerating Scaled Gradient Projection Using Deep Neural\n  Network For Inverse Problems In Image Processing", "comments": "10 pages, 6 figures, 3 tables, ICASSP 2021, this is a long version of\n  it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have shown advantages in accelerating\noptimization algorithms. One approach is to unfold finite number of iterations\nof conventional optimization algorithms and to learn parameters in the\nalgorithms. However, these are forward methods and are indeed neither iterative\nnor convergent. Here, we present a novel DNN-based convergent iterative\nalgorithm that accelerates conventional optimization algorithms. We train a DNN\nto yield parameters in scaled gradient projection method. So far, these\nparameters have been chosen heuristically, but have shown to be crucial for\ngood empirical performance. In simulation results, the proposed method\nsignificantly improves the empirical convergence rate over conventional\noptimization methods for various large-scale inverse problems in image\nprocessing.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 02:19:53 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 05:18:41 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 03:00:39 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Lee", "Byung Hyun", ""], ["Chun", "Se Young", ""]]}, {"id": "1902.02452", "submitter": "Se Young Chun", "authors": "Magauiya Zhussip, Shakarim Soltanayev, Se Young Chun", "title": "Extending Stein's unbiased risk estimator to train deep denoisers with\n  correlated pairs of noisy images", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Stein's unbiased risk estimator (SURE) has been applied to\nunsupervised training of deep neural network Gaussian denoisers that\noutperformed classical non-deep learning based denoisers and yielded comparable\nperformance to those trained with ground truth. While SURE requires only one\nnoise realization per image for training, it does not take advantage of having\nmultiple noise realizations per image when they are available (e.g., two\nuncorrelated noise realizations per image for Noise2Noise). Here, we propose an\nextended SURE (eSURE) to train deep denoisers with correlated pairs of noise\nrealizations per image and applied it to the case with two uncorrelated\nrealizations per image to achieve better performance than SURE based method and\ncomparable results to Noise2Noise. Then, we further investigated the case with\nimperfect ground truth (i.e., mild noise in ground truth) that may be obtained\nconsidering painstaking, time-consuming, and even expensive processes of\ncollecting ground truth images with multiple noisy images. For the case of\ngenerating noisy training data by adding synthetic noise to imperfect ground\ntruth to yield correlated pairs of images, our proposed eSURE based training\nmethod outperformed conventional SURE based method as well as Noise2Noise.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 02:44:55 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 11:33:32 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Zhussip", "Magauiya", ""], ["Soltanayev", "Shakarim", ""], ["Chun", "Se Young", ""]]}, {"id": "1902.02455", "submitter": "Hee-Soo Heo", "authors": "Hee-Soo Heo, Jee-weon Jung, IL-Ho Yang, Sung-Hyun Yoon, Hye-jin Shim,\n  and Ha-Jin Yu", "title": "End-to-end losses based on speaker basis vectors and all-speaker hard\n  negative mining for speaker verification", "comments": "5 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, speaker verification has primarily performed using deep\nneural networks that are trained to output embeddings from input features such\nas spectrograms or Mel-filterbank energies. Studies that design various loss\nfunctions, including metric learning have been widely explored. In this study,\nwe propose two end-to-end loss functions for speaker verification using the\nconcept of speaker bases, which are trainable parameters. One loss function is\ndesigned to further increase the inter-speaker variation, and the other is\ndesigned to conduct the identical concept with hard negative mining. Each\nspeaker basis is designed to represent the corresponding speaker in the process\nof training deep neural networks. In contrast to the conventional loss\nfunctions that can consider only a limited number of speakers included in a\nmini-batch, the proposed loss functions can consider all the speakers in the\ntraining set regardless of the mini-batch composition. In particular, the\nproposed loss functions enable hard negative mining and calculations of\nbetween-speaker variations with consideration of all speakers. Through\nexperiments on VoxCeleb1 and VoxCeleb2 datasets, we confirmed that the proposed\nloss functions could supplement conventional softmax and center loss functions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 02:55:02 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 08:20:17 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 11:52:38 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Heo", "Hee-Soo", ""], ["Jung", "Jee-weon", ""], ["Yang", "IL-Ho", ""], ["Yoon", "Sung-Hyun", ""], ["Shim", "Hye-jin", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "1902.02476", "submitter": "Andrew Wilson", "authors": "Wesley Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, Andrew\n  Gordon Wilson", "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose\napproach for uncertainty representation and calibration in deep learning.\nStochastic Weight Averaging (SWA), which computes the first moment of\nstochastic gradient descent (SGD) iterates with a modified learning rate\nschedule, has recently been shown to improve generalization in deep learning.\nWith SWAG, we fit a Gaussian using the SWA solution as the first moment and a\nlow rank plus diagonal covariance also derived from the SGD iterates, forming\nan approximate posterior distribution over neural network weights; we then\nsample from this Gaussian distribution to perform Bayesian model averaging. We\nempirically find that SWAG approximates the shape of the true posterior, in\naccordance with results describing the stationary distribution of SGD iterates.\nMoreover, we demonstrate that SWAG performs well on a wide variety of tasks,\nincluding out of sample detection, calibration, and transfer learning, in\ncomparison to many popular alternatives including MC dropout, KFAC Laplace,\nSGLD, and temperature scaling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 05:15:46 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 08:28:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Maddox", "Wesley", ""], ["Garipov", "Timur", ""], ["Izmailov", "Pavel", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1902.02492", "submitter": "David Barmherzig", "authors": "David A. Barmherzig, Ju Sun, Emmanuel J. Cand\\`es, T.J. Lane, Po-Nan\n  Li", "title": "Dual-Reference Design for Holographic Coherent Diffraction Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.NA math.NA math.OC physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new reference design is introduced for holographic coherent diffraction\nimaging. This consists in two references - \"block\" and \"pinhole\" shaped regions\n- placed adjacent to the imaging specimen. An efficient recovery algorithm is\nprovided for the resulting holographic phase retrieval problem, which is based\non solving a structured, overdetermined linear system. Analysis of the expected\nrecovery error on noisy data, which is contaminated by Poisson shot noise,\nshows that this simple modification synergizes the individual references and\nhence leads to uniformly superior performance over single-reference schemes.\nNumerical experiments on simulated data confirm the theoretical prediction, and\nthe proposed dual-reference scheme achieves a smaller recovery error than\nleading single-reference schemes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 06:47:17 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 02:46:44 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Barmherzig", "David A.", ""], ["Sun", "Ju", ""], ["Cand\u00e8s", "Emmanuel J.", ""], ["Lane", "T. J.", ""], ["Li", "Po-Nan", ""]]}, {"id": "1902.02495", "submitter": "Romain Lopez", "authors": "Romain Lopez, Chenchen Li, Xiang Yan, Junwu Xiong, Michael I. Jordan,\n  Yuan Qi, Le Song", "title": "Cost-Effective Incentive Allocation via Structured Counterfactual\n  Inference", "comments": null, "journal-ref": "Association for the Advancement of Artificial Intelligence (AAAI)\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a practical problem ubiquitous in modern marketing campaigns, in\nwhich a central agent tries to learn a policy for allocating strategic\nfinancial incentives to customers and observes only bandit feedback. In\ncontrast to traditional policy optimization frameworks, we take into account\nthe additional reward structure and budget constraints common in this setting,\nand develop a new two-step method for solving this constrained counterfactual\npolicy optimization problem. Our method first casts the reward estimation\nproblem as a domain adaptation problem with supplementary structure, and then\nsubsequently uses the estimators for optimizing the policy with constraints. We\nalso establish theoretical error bounds for our estimation procedure and we\nempirically show that the approach leads to significant improvement on both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:02:34 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:20:15 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 05:41:27 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lopez", "Romain", ""], ["Li", "Chenchen", ""], ["Yan", "Xiang", ""], ["Xiong", "Junwu", ""], ["Jordan", "Michael I.", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "1902.02497", "submitter": "Xinrui Cui", "authors": "Xinrui Cui, Dan Wang, and Z. Jane Wang", "title": "CHIP: Channel-wise Disentangled Interpretation of Deep Convolutional\n  Neural Networks", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread applications of deep convolutional neural networks\n(DCNNs), it becomes increasingly important for DCNNs not only to make accurate\npredictions but also to explain how they make their decisions. In this work, we\npropose a CHannel-wise disentangled InterPretation (CHIP) model to give the\nvisual interpretation to the predictions of DCNNs. The proposed model distills\nthe class-discriminative importance of channels in networks by utilizing the\nsparse regularization. Here, we first introduce the network perturbation\ntechnique to learn the model. The proposed model is capable to not only distill\nthe global perspective knowledge from networks but also present the\nclass-discriminative visual interpretation for specific predictions of\nnetworks. It is noteworthy that the proposed model is able to interpret\ndifferent layers of networks without re-training. By combining the distilled\ninterpretation knowledge in different layers, we further propose the Refined\nCHIP visual interpretation that is both high-resolution and\nclass-discriminative. Experimental results on the standard dataset demonstrate\nthat the proposed model provides promising visual interpretation for the\npredictions of networks in image classification task compared with existing\nvisual interpretation methods. Besides, the proposed method outperforms related\napproaches in the application of ILSVRC 2015 weakly-supervised localization\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:17:03 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 19:01:48 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Cui", "Xinrui", ""], ["Wang", "Dan", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1902.02498", "submitter": "Anshul Thakur", "authors": "Anshul Thakur, Pulkit Sharma, Vinayak Abrol, Padmanabhan Rajan", "title": "Conv-codes: Audio Hashing For Bird Species Classification", "comments": "Accepted for presentation at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a supervised, convex representation based audio\nhashing framework for bird species classification. The proposed framework\nutilizes archetypal analysis, a matrix factorization technique, to obtain\nconvex-sparse representations of a bird vocalization. These convex\nrepresentations are hashed using Bloom filters with non-cryptographic hash\nfunctions to obtain compact binary codes, designated as conv-codes. The\nconv-codes extracted from the training examples are clustered using\nclass-specific k-medoids clustering with Jaccard coefficient as the similarity\nmetric. A hash table is populated using the cluster centers as keys while hash\nvalues/slots are pointers to the species identification information. During\ntesting, the hash table is searched to find the species information\ncorresponding to a cluster center that exhibits maximum similarity with the\ntest conv-code. Hence, the proposed framework classifies a bird vocalization in\nthe conv-code space and requires no explicit classifier or reconstruction error\ncalculations. Apart from that, based on min-hash and direct addressing, we also\npropose a variant of the proposed framework that provides faster and effective\nclassification. The performances of both these frameworks are compared with\nexisting bird species classification frameworks on the audio recordings of 50\ndifferent bird species.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:18:39 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Thakur", "Anshul", ""], ["Sharma", "Pulkit", ""], ["Abrol", "Vinayak", ""], ["Rajan", "Padmanabhan", ""]]}, {"id": "1902.02502", "submitter": "Jinyang Yuan", "authors": "Jinyang Yuan, Bin Li, Xiangyang Xue", "title": "Spatial Mixture Models with Learnable Deep Priors for Perceptual\n  Grouping", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans perceive the seemingly chaotic world in a structured and compositional\nway with the prerequisite of being able to segregate conceptual entities from\nthe complex visual scenes. The mechanism of grouping basic visual elements of\nscenes into conceptual entities is termed as perceptual grouping. In this work,\nwe propose a new type of spatial mixture models with learnable priors for\nperceptual grouping. Different from existing methods, the proposed method\ndisentangles the attributes of an object into ``shape'' and ``appearance''\nwhich are modeled separately by the mixture weights and the mixture components.\nMore specifically, each object in the visual scene is fully characterized by\none latent representation, which is in turn transformed into parameters of the\nmixture weight and the mixture component by two neural networks. The mixture\nweights focus on modeling spatial dependencies (i.e., shape) and the mixture\ncomponents deal with intra-object variations (i.e., appearance). In addition,\nthe background is separately modeled as a special component complementary to\nthe foreground objects. Our extensive empirical tests on two perceptual\ngrouping datasets demonstrate that the proposed method outperforms the\nstate-of-the-art methods under most experimental configurations. The learned\nconceptual entities are generalizable to novel visual scenes and insensitive to\nthe diversity of objects. Code is available at\nhttps://github.com/jinyangyuan/learnable-deep-priors.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:33:12 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 07:05:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Yuan", "Jinyang", ""], ["Li", "Bin", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1902.02507", "submitter": "Hoang Tai", "authors": "Tai Hoang, Huy Le, Tho Quan", "title": "Towards Autoencoding Variational Inference for Aspect-based Opinion\n  Summary", "comments": "20 pages, 11 figures", "journal-ref": "Applied Artificial Intelligence, 33 (2019) 796-816", "doi": "10.1080/08839514.2019.1630148", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based Opinion Summary (AOS), consisting of aspect discovery and\nsentiment classification steps, has recently been emerging as one of the most\ncrucial data mining tasks in e-commerce systems. Along this direction, the\nLDA-based model is considered as a notably suitable approach, since this model\noffers both topic modeling and sentiment classification. However, unlike\ntraditional topic modeling, in the context of aspect discovery it is often\nrequired some initial seed words, whose prior knowledge is not easy to be\nincorporated into LDA models. Moreover, LDA approaches rely on sampling\nmethods, which need to load the whole corpus into memory, making them hardly\nscalable. In this research, we study an alternative approach for AOS problem,\nbased on Autoencoding Variational Inference (AVI). Firstly, we introduce the\nAutoencoding Variational Inference for Aspect Discovery (AVIAD) model, which\nextends the previous work of Autoencoding Variational Inference for Topic\nModels (AVITM) to embed prior knowledge of seed words. This work includes\nenhancement of the previous AVI architecture and also modification of the loss\nfunction. Ultimately, we present the Autoencoding Variational Inference for\nJoint Sentiment/Topic (AVIJST) model. In this model, we substantially extend\nthe AVI model to support the JST model, which performs topic modeling for\ncorresponding sentiment. The experimental results show that our proposed models\nenjoy higher topic coherent, faster convergence time and better accuracy on\nsentiment classification, as compared to their LDA-based counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:44:03 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 02:59:58 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 02:04:17 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hoang", "Tai", ""], ["Le", "Huy", ""], ["Quan", "Tho", ""]]}, {"id": "1902.02509", "submitter": "Quentin Bertrand", "authors": "Quentin Bertrand (PARIETAL), Mathurin Massias (PARIETAL), Alexandre\n  Gramfort (PARIETAL), Joseph Salmon (IMAG)", "title": "Handling correlated and repeated measurements with the smoothed\n  multivariate square-root Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity promoting norms are frequently used in high dimensional regression.\nA limitation of such Lasso-type estimators is that the optimal regularization\nparameter depends on the unknown noise level. Estimators such as the\nconcomitant Lasso address this dependence by jointly estimating the noise level\nand the regression coefficients. Additionally, in many applications, the data\nis obtained by averaging multiple measurements: this reduces the noise\nvariance, but it dramatically reduces sample sizes and prevents refined noise\nmodeling. In this work, we propose a concomitant estimator that can cope with\ncomplex noise structure by using non-averaged measurements. The resulting\noptimization problem is convex and amenable, thanks to smoothing theory, to\nstate-of-the-art optimization techniques that leverage the sparsity of the\nsolutions. Practical benefits are demonstrated on toy datasets, realistic\nsimulated data and real neuroimaging data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 07:44:54 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 07:49:35 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 09:21:11 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 17:03:49 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bertrand", "Quentin", "", "PARIETAL"], ["Massias", "Mathurin", "", "PARIETAL"], ["Gramfort", "Alexandre", "", "PARIETAL"], ["Salmon", "Joseph", "", "IMAG"]]}, {"id": "1902.02517", "submitter": "Takafumi Kajihara", "authors": "Takafumi Kajihara, Motonobu Kanagawa, Yuuki Nakaguchi, Kanishka\n  Khandelwal, Kenji Fukumiziu", "title": "Model Selection for Simulator-based Statistical Models: A Kernel\n  Approach", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to model selection for simulator-based\nstatistical models. The proposed approach defines a mixture of candidate\nmodels, and then iteratively updates the weight coefficients for those models\nas well as the parameters in each model simultaneously; this is done by\nrecursively applying Bayes' rule, using the recently proposed kernel recursive\nABC algorithm. The practical advantage of the method is that it can be used\neven when a modeler lacks appropriate prior knowledge about the parameters in\neach model. We demonstrate the effectiveness of the proposed approach with a\nnumber of experiments, including model selection for dynamical systems in\necology and epidemiology.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 08:22:31 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Kajihara", "Takafumi", ""], ["Kanagawa", "Motonobu", ""], ["Nakaguchi", "Yuuki", ""], ["Khandelwal", "Kanishka", ""], ["Fukumiziu", "Kenji", ""]]}, {"id": "1902.02527", "submitter": "Tiago Ramalho", "authors": "Tiago Ramalho, Marta Garnelo", "title": "Adaptive Posterior Learning: few-shot learning with a surprise-based\n  memory module", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to generalize quickly from few observations is crucial for\nintelligent systems. In this paper we introduce APL, an algorithm that\napproximates probability distributions by remembering the most surprising\nobservations it has encountered. These past observations are recalled from an\nexternal memory module and processed by a decoder network that can combine\ninformation from different memory slots to generalize beyond direct recall. We\nshow this algorithm can perform as well as state of the art baselines on\nfew-shot classification benchmarks with a smaller memory footprint. In\naddition, its memory compression allows it to scale to thousands of unknown\nlabels. Finally, we introduce a meta-learning reasoning task which is more\nchallenging than direct classification. In this setting, APL is able to\ngeneralize with fewer than one example per class via deductive reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:00:51 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Ramalho", "Tiago", ""], ["Garnelo", "Marta", ""]]}, {"id": "1902.02530", "submitter": "Sunghwan Joo", "authors": "Sunghwan Joo, Sungmin Cha, and Taesup Moon", "title": "DoPAMINE: Double-sided Masked CNN for Pixel Adaptive Multiplicative\n  Noise Despeckling", "comments": "AAAI 2019 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DoPAMINE, a new neural network based multiplicative noise\ndespeckling algorithm. Our algorithm is inspired by Neural AIDE (N-AIDE), which\nis a recently proposed neural adaptive image denoiser. While the original\nN-AIDE was designed for the additive noise case, we show that the same\nframework, i.e., adaptively learning a network for pixel-wise affine denoisers\nby minimizing an unbiased estimate of MSE, can be applied to the multiplicative\nnoise case as well. Moreover, we derive a double-sided masked CNN architecture\nwhich can control the variance of the activation values in each layer and\nconverge fast to high denoising performance during supervised training. In the\nexperimental results, we show our DoPAMINE possesses high adaptivity via\nfine-tuning the network parameters based on the given noisy image and achieves\nsignificantly better despeckling results compared to SAR-DRN, a\nstate-of-the-art CNN-based algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:08:18 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Joo", "Sunghwan", ""], ["Cha", "Sungmin", ""], ["Moon", "Taesup", ""]]}, {"id": "1902.02542", "submitter": "Panos Parpas", "authors": "Panos Parpas, Corey Muir", "title": "Predict Globally, Correct Locally: Parallel-in-Time Optimal Control of\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The links between optimal control of dynamical systems and neural networks\nhave proved beneficial both from a theoretical and from a practical point of\nview. Several researchers have exploited these links to investigate the\nstability of different neural network architectures and develop memory\nefficient training algorithms. We also adopt the dynamical systems view of\nneural networks, but our aim is different from earlier works. We exploit the\nlinks between dynamical systems, optimal control, and neural networks to\ndevelop a novel distributed optimization algorithm. The proposed algorithm\naddresses the most significant obstacle for distributed algorithms for neural\nnetwork optimization: the network weights cannot be updated until the forward\npropagation of the data, and backward propagation of the gradients are\ncomplete. Using the dynamical systems point of view, we interpret the layers of\na (residual) neural network as the discretized dynamics of a dynamical system\nand exploit the relationship between the co-states (adjoints) of the optimal\ncontrol problem and backpropagation. We then develop a parallel-in-time method\nthat updates the parameters of the network without waiting for the forward or\nback propagation algorithms to complete in full. We establish the convergence\nof the proposed algorithm. Preliminary numerical results suggest that the\nalgorithm is competitive and more efficient than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:44:26 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Parpas", "Panos", ""], ["Muir", "Corey", ""]]}, {"id": "1902.02544", "submitter": "Shlomo Bugdary", "authors": "Shlomo Bugdary, Shay Maymon", "title": "Online Clustering by Penalized Weighted GMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the dawn of the Big Data era, data sets are growing rapidly. Data is\nstreaming from everywhere - from cameras, mobile phones, cars, and other\nelectronic devices. Clustering streaming data is a very challenging problem.\nUnlike the traditional clustering algorithms where the dataset can be stored\nand scanned multiple times, clustering streaming data has to satisfy\nconstraints such as limit memory size, real-time response, unknown data\nstatistics and an unknown number of clusters. In this paper, we present a novel\nonline clustering algorithm which can be used to cluster streaming data without\nknowing the number of clusters a priori. Results on both synthetic and real\ndatasets show that the proposed algorithm produces partitions which are close\nto what you could get if you clustered the whole data at one time.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:50:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Bugdary", "Shlomo", ""], ["Maymon", "Shay", ""]]}, {"id": "1902.02554", "submitter": "Malik Tiomoko", "authors": "Malik Tiomoko, Florent Bouchard, Guillaume Ginholac, Romain Couillet", "title": "Random Matrix Improved Covariance Estimation for a Large Class of\n  Metrics", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/abcaf2", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relying on recent advances in statistical estimation of covariance distances\nbased on random matrix theory, this article proposes an improved covariance and\nprecision matrix estimation for a wide family of metrics. The method is shown\nto largely outperform the sample covariance matrix estimate and to compete with\nstate-of-the-art methods, while at the same time being computationally simpler.\nApplications to linear and quadratic discriminant analyses also demonstrate\nsignificant gains, therefore suggesting practical interest to statistical\nmachine learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 10:24:26 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Tiomoko", "Malik", ""], ["Bouchard", "Florent", ""], ["Ginholac", "Guillaume", ""], ["Couillet", "Romain", ""]]}, {"id": "1902.02580", "submitter": "Vicen\\c{c} G\\'omez Cerd\\`a", "authors": "Fabrizio Germano, Vicen\\c{c} G\\'omez, Ga\\\"el Le Mens", "title": "The few-get-richer: a surprising consequence of popularity-based\n  rankings", "comments": "7 pages, 3 figures, 1 table, Proceedings of The Web Conference (WWW\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 12:00:35 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:51:50 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Germano", "Fabrizio", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["Mens", "Ga\u00ebl Le", ""]]}, {"id": "1902.02595", "submitter": "Antonino Sabetta", "authors": "Serena E. Ponta, Henrik Plate, Antonino Sabetta, Michele Bezzi,\n  C\\'edric Dangremont", "title": "A Manually-Curated Dataset of Fixes to Vulnerabilities of Open-Source\n  Software", "comments": "This is a pre-print version of the paper that appears in the\n  proceedings of The 16th International Conference on Mining Software\n  Repositories (MSR), Data Showcase track", "journal-ref": "Proceedings of The 16th International Conference on Mining\n  Software Repositories (Data Showcase track), 2019", "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancing our understanding of software vulnerabilities, automating their\nidentification, the analysis of their impact, and ultimately their mitigation\nis necessary to enable the development of software that is more secure. While\noperating a vulnerability assessment tool that we developed and that is\ncurrently used by hundreds of development units at SAP, we manually collected\nand curated a dataset of vulnerabilities of open-source software and the\ncommits fixing them. The data was obtained both from the National Vulnerability\nDatabase (NVD) and from project-specific Web resources that we monitor on a\ncontinuous basis. From that data, we extracted a dataset that maps 624 publicly\ndisclosed vulnerabilities affecting 205 distinct open-source Java projects,\nused in SAP products or internal tools, onto the 1282 commits that fix them.\nOut of 624 vulnerabilities, 29 do not have a CVE identifier at all and 46,\nwhich do have a CVE identifier assigned by a numbering authority, are not\navailable in the NVD yet. The dataset is released under an open-source license,\ntogether with supporting scripts that allow researchers to automatically\nretrieve the actual content of the commits from the corresponding repositories\nand to augment the attributes available for each instance. Also, these scripts\nallow to complement the dataset with additional instances that are not security\nfixes (which is useful, for example, in machine learning applications). Our\ndataset has been successfully used to train classifiers that could\nautomatically identify security-relevant commits in code repositories. The\nrelease of this dataset and the supporting code as open-source will allow\nfuture research to be based on data of industrial relevance; also, it\nrepresents a concrete step towards making the maintenance of this dataset a\nshared effort involving open-source communities, academia, and the industry.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 12:47:13 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 09:06:58 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 10:33:34 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ponta", "Serena E.", ""], ["Plate", "Henrik", ""], ["Sabetta", "Antonino", ""], ["Bezzi", "Michele", ""], ["Dangremont", "C\u00e9dric", ""]]}, {"id": "1902.02597", "submitter": "Adrien Lagrange", "authors": "Adrien Lagrange, Mathieu Fauvel, St\\'ephane May, Jos\\'e Bioucas-Dias\n  and Nicolas Dobigeon", "title": "Matrix Cofactorization for Joint Representation Learning and Supervised\n  Classification -- Application to Hyperspectral Image Analysis", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.12.068", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised classification and representation learning are two widely used\nclasses of methods to analyze multivariate images. Although complementary,\nthese methods have been scarcely considered jointly in a hierarchical modeling.\nIn this paper, a method coupling these two approaches is designed using a\nmatrix cofactorization formulation. Each task is modeled as a factorization\nmatrix problem and a term relating both coding matrices is then introduced to\ndrive an appropriate coupling. The link can be interpreted as a clustering\noperation over a low-dimensional representation vectors. The attribution\nvectors of the clustering are then used as features vectors for the\nclassification task, i.e., the coding vectors of the corresponding\nfactorization problem. A proximal gradient descent algorithm, ensuring\nconvergence to a critical point of the objective function, is then derived to\nsolve the resulting non-convex non-smooth optimization problem. An evaluation\nof the proposed method is finally conducted both on synthetic and real data in\nthe specific context of hyperspectral image interpretation, unifying two\nstandard analysis techniques, namely unmixing and classification.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 12:54:56 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 09:28:56 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 18:40:04 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 18:53:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Lagrange", "Adrien", ""], ["Fauvel", "Mathieu", ""], ["May", "St\u00e9phane", ""], ["Bioucas-Dias", "Jos\u00e9", ""], ["Dobigeon", "Nicolas", ""]]}, {"id": "1902.02603", "submitter": "Changyong Oh", "authors": "Changyong Oh, Kamil Adamczewski, Mijung Park", "title": "Radial and Directional Posteriors for Bayesian Neural Networks", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variational family for Bayesian neural networks. We\ndecompose the variational posterior into two components, where the radial\ncomponent captures the strength of each neuron in terms of its magnitude; while\nthe directional component captures the statistical dependencies among the\nweight parameters. The dependencies learned via the directional density provide\nbetter modeling performance compared to the widely-used Gaussian\nmean-field-type variational family. In addition, the strength of input and\noutput neurons learned via the radial density provides a structured way to\ncompress neural networks. Indeed, experiments show that our variational family\nimproves predictive performance and yields compressed networks simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 13:06:43 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 20:13:47 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Oh", "Changyong", ""], ["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "1902.02627", "submitter": "Thong Nguyen", "authors": "Thong Nguyen, Tianjian Lu, Ken Wu and Jose Schutt-Aine", "title": "Fast Transient Simulation of High-Speed Channels Using Recurrent Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating eye diagrams by using a circuit simulator can be very\ncomputationally intensive, especially in the presence of nonlinearities. It\noften involves multiple Newton-like iterations at every time step when a\nSPICE-like circuit simulator handles a nonlinear system in the transient\nregime. In this paper, we leverage machine learning methods, to be specific,\nthe recurrent neural network (RNN), to generate black-box macromodels and\nachieve significant reduction of computation time. Through the proposed\napproach, an RNN model is first trained and then validated on a relatively\nshort sequence generated from a circuit simulator. Once the training completes,\nthe RNN can be used to make predictions on the remaining sequence in order to\ngenerate an eye diagram. The training cost can also be amortized when the\ntrained RNN starts making predictions. Besides, the proposed approach requires\nno complex circuit simulations nor substantial domain knowledge. We use two\nhigh-speed link examples to demonstrate that the proposed approach provides\nadequate accuracy while the computation time can be dramatically reduced. In\nthe high-speed link example with a PAM4 driver, the eye diagram generated by\nRNN models shows good agreement with that obtained from a commercial circuit\nsimulator. This paper also investigates the impacts of various RNN topologies,\ntraining schemes, and tunable parameters on both the accuracy and the\ngeneralization capability of an RNN model. It is found out that the long\nshort-term memory (LSTM) network outperforms the vanilla RNN in terms of the\naccuracy in predicting transient waveforms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 07:14:40 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 02:57:49 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Nguyen", "Thong", ""], ["Lu", "Tianjian", ""], ["Wu", "Ken", ""], ["Schutt-Aine", "Jose", ""]]}, {"id": "1902.02629", "submitter": "Mario Zusag", "authors": "Mario Zusag, Sujal Desai, Marcello Di Paolo, Thomas Semple, Anand\n  Shah, Elsa Angelini", "title": "SAPSAM - Sparsely Annotated Pathological Sign Activation Maps - A novel\n  approach to train Convolutional Neural Networks on lung CT scans using binary\n  labels only", "comments": "Accepted paper for ISBI2019", "journal-ref": "https://biomedicalimaging.org/2019/", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic Pulmonary Aspergillosis (CPA) is a complex lung disease caused by\ninfection with Aspergillus. Computed tomography (CT) images are frequently\nrequested in patients with suspected and established disease, but the\nradiological signs on CT are difficult to quantify making accurate follow-up\nchallenging. We propose a novel method to train Convolutional Neural Networks\nusing only regional labels on the presence of pathological signs, to not only\ndetect CPA, but also spatially localize pathological signs. We use average\nintensity projections within different ranges of Hounsfield-unit (HU) values,\ntransforming input 3D CT scans into 2D RGB-like images. CNN architectures are\ntrained for hierarchical tasks, leading to precise activation maps of\npathological patterns. Results on a cohort of 352 subjects demonstrate high\nclassification accuracy, localization precision and predictive power of 2 year\nsurvival. Such tool opens the way to CPA patient stratification and\nquantitative follow-up of CPA pathological signs, for patients under drug\ntherapy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 13:17:03 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Zusag", "Mario", ""], ["Desai", "Sujal", ""], ["Di Paolo", "Marcello", ""], ["Semple", "Thomas", ""], ["Shah", "Anand", ""], ["Angelini", "Elsa", ""]]}, {"id": "1902.02660", "submitter": "Ludmila Kuncheva", "authors": "Iain A. D. Gunn and Ludmila I. Kuncheva", "title": "Bounds for the VC Dimension of 1NN Prototype Sets", "comments": "12 pages + 8 pages of extra material. 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In Statistical Learning, the Vapnik-Chervonenkis (VC) dimension is an\nimportant combinatorial property of classifiers. To our knowledge, no\ntheoretical results yet exist for the VC dimension of edited nearest-neighbour\n(1NN) classifiers with reference set of fixed size. Related theoretical results\nare scattered in the literature and their implications have not been made\nexplicit. We collect some relevant results and use them to provide explicit\nlower and upper bounds for the VC dimension of 1NN classifiers with a prototype\nset of fixed size. We discuss the implications of these bounds for the size of\ntraining set needed to learn such a classifier to a given accuracy. Further, we\nprovide a new lower bound for the two-dimensional case, based on a new\ngeometrical argument.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 14:52:33 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Gunn", "Iain A. D.", ""], ["Kuncheva", "Ludmila I.", ""]]}, {"id": "1902.02661", "submitter": "Divya Grover", "authors": "Divya Grover, Debabrota Basu, Christos Dimitrakakis", "title": "Bayesian Reinforcement Learning via Deep, Sparse Sampling", "comments": "Published in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of Bayesian reinforcement learning using efficient\nmodel-based online planning. We propose an optimism-free Bayes-adaptive\nalgorithm to induce deeper and sparser exploration with a theoretical bound on\nits performance relative to the Bayes optimal policy, with a lower\ncomputational complexity. The main novelty is the use of a candidate policy\ngenerator, to generate long-term options in the planning tree (over beliefs),\nwhich allows us to create much sparser and deeper trees. Experimental results\non different environments show that in comparison to the state-of-the-art, our\nalgorithm is both computationally more efficient, and obtains significantly\nhigher reward in discrete environments.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 14:52:37 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 15:20:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 10:32:19 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 16:31:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Grover", "Divya", ""], ["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1902.02671", "submitter": "Asa Cooper Stickland", "authors": "Asa Cooper Stickland and Iain Murray", "title": "BERT and PALs: Projected Attention Layers for Efficient Adaptation in\n  Multi-Task Learning", "comments": "Accepted for publication at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning shares information between related tasks, sometimes\nreducing the number of parameters required. State-of-the-art results across\nmultiple natural language understanding tasks in the GLUE benchmark have\npreviously used transfer from a single large task: unsupervised pre-training\nwith BERT, where a separate BERT model was fine-tuned for each task. We explore\nmulti-task approaches that share a single BERT model with a small number of\nadditional task-specific parameters. Using new adaptation modules, PALs or\n`projected attention layers', we match the performance of separately fine-tuned\nmodels on the GLUE benchmark with roughly 7 times fewer parameters, and obtain\nstate-of-the-art results on the Recognizing Textual Entailment dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 15:05:46 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 11:13:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Stickland", "Asa Cooper", ""], ["Murray", "Iain", ""]]}, {"id": "1902.02675", "submitter": "Peng Xiao", "authors": "Peng Xiao and Samuel Cheng", "title": "Neural Network for NILM Based on Operational State Change Classification", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy disaggregation in a non-intrusive way estimates appliance level\nelectricity consumption from a single meter that measures the whole house\nelectricity demand. Recently, with the ongoing increment of energy data, there\nare many data-driven deep learning architectures being applied to solve the\nnon-intrusive energy disaggregation problem. However, most proposed methods try\nto estimate the on-off state or the power consumption of appliance, which need\nnot only large amount of parameters, but also hyper-parameter optimization\nprior to training and even preprocessing of energy data for a specified\nappliance. In this paper, instead of estimating on-off state or power\nconsumption, we adapt a neural network to estimate the operational state change\nof appliance. Our proposed solution is more feasible across various appliances\nand lower complexity comparing to previous methods. The simulated experiments\nin the low sample rate dataset REDD show the competitive performance of the\ndesigned method, with respect to other two benchmark methods, Hidden Markov\nModel-based and Graph Signal processing-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 03:55:26 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 08:51:46 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Xiao", "Peng", ""], ["Cheng", "Samuel", ""]]}, {"id": "1902.02693", "submitter": "Alessandro Corbetta", "authors": "Joost Visser, Alessandro Corbetta, Vlado Menkovski, Federico Toschi", "title": "StampNet: unsupervised multi-class object discovery", "comments": null, "journal-ref": "IEEE International Conference on Image Processing (ICIP 2019), pp.\n  2951-2955, 2019", "doi": "10.1109/ICIP.2019.8803767", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised object discovery in images involves uncovering recurring\npatterns that define objects and discriminates them against the background.\nThis is more challenging than image clustering as the size and the location of\nthe objects are not known: this adds additional degrees of freedom and\nincreases the problem complexity. In this work, we propose StampNet, a novel\nautoencoding neural network that localizes shapes (objects) over a simple\nbackground in images and categorizes them simultaneously. StampNet consists of\na discrete latent space that is used to categorize objects and to determine the\nlocation of the objects. The object categories are formed during the training,\nresulting in the discovery of a fixed set of objects. We present a set of\nexperiments that demonstrate that StampNet is able to localize and cluster\nmultiple overlapping shapes with varying complexity including the digits from\nthe MNIST dataset. We also present an application of StampNet in the\nlocalization of pedestrians in overhead depth-maps.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 15:35:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Visser", "Joost", ""], ["Corbetta", "Alessandro", ""], ["Menkovski", "Vlado", ""], ["Toschi", "Federico", ""]]}, {"id": "1902.02715", "submitter": "Yi Zhou", "authors": "Yi Zhou, Zhe Wang, Kaiyi Ji, Yingbin Liang, Vahid Tarokh", "title": "Momentum Schemes with Stochastic Variance Reduction for Nonconvex\n  Composite Optimization", "comments": "We are merging the results of this paper with another paper at\n  arXiv:1810.10690. Therefore, we want to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two new stochastic variance-reduced algorithms named SARAH and SPIDER have\nbeen recently proposed, and SPIDER has been shown to achieve a near-optimal\ngradient oracle complexity for nonconvex optimization. However, the theoretical\nadvantage of SPIDER does not lead to substantial improvement of practical\nperformance over SVRG. To address this issue, momentum technique can be a good\ncandidate to improve the performance of SPIDER. However, existing momentum\nschemes used in variance-reduced algorithms are designed specifically for\nconvex optimization, and are not applicable to nonconvex scenarios. In this\npaper, we develop novel momentum schemes with flexible coefficient settings to\naccelerate SPIDER for nonconvex and nonsmooth composite optimization, and show\nthat the resulting algorithms achieve the near-optimal gradient oracle\ncomplexity for achieving a generalized first-order stationary condition.\nFurthermore, we generalize our algorithm to online nonconvex and nonsmooth\noptimization, and establish an oracle complexity result that matches the\nstate-of-the-art. Our extensive experiments demonstrate the superior\nperformance of our proposed algorithm over other stochastic variance-reduced\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:24:46 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 15:09:31 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 18:32:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhou", "Yi", ""], ["Wang", "Zhe", ""], ["Ji", "Kaiyi", ""], ["Liang", "Yingbin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1902.02719", "submitter": "Chinmay S Kulkarni", "authors": "Chinmay S. Kulkarni", "title": "Sparse Regression and Adaptive Feature Generation for the Discovery of\n  Dynamical Systems", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of sparse regression methods and propose new\ntechniques to distill the governing equations of dynamical systems from data.\nWe first look at the generic methodology of learning interpretable equation\nforms from data, proposed by Brunton et al., followed by performance of LASSO\nfor this purpose. We then propose a new algorithm that uses the dual of LASSO\noptimization for higher accuracy and stability. In the second part, we propose\na novel algorithm that learns the candidate function library in a completely\ndata-driven manner to distill the governing equations of the dynamical system.\nThis is achieved via sequentially thresholded ridge regression (STRidge) over a\northogonal polynomial space. The performance of the three discussed methods is\nillustrated by looking the Lorenz 63 system and the quadratic Lorenz system.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:32:45 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 20:56:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Kulkarni", "Chinmay S.", ""]]}, {"id": "1902.02721", "submitter": "Edouard Pineau", "authors": "Edouard Pineau and Nathan de Lara", "title": "Variational Recurrent Neural Networks for Graph Classification", "comments": "Representation Learning on Graphs and Manifolds workshop, ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of graph classification based only on structural\ninformation. Inspired by natural language processing techniques (NLP), our\nmodel sequentially embeds information to estimate class membership\nprobabilities. Besides, we experiment with NLP-like variational regularization\ntechniques, making the model predict the next node in the sequence as it reads\nit. We experimentally show that our model achieves state-of-the-art\nclassification results on several standard molecular datasets. Finally, we\nperform a qualitative analysis and give some insights on whether the node\nprediction helps the model better classify graphs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:34:53 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 08:17:19 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 08:16:52 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 12:12:26 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Pineau", "Edouard", ""], ["de Lara", "Nathan", ""]]}, {"id": "1902.02725", "submitter": "Iuri Frosio", "authors": "Greg Heinrich and Iuri Frosio", "title": "Metaoptimization on a Distributed System for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training intelligent agents through reinforcement learning is a notoriously\nunstable procedure. Massive parallelization on GPUs and distributed systems has\nbeen exploited to generate a large amount of training experiences and\nconsequently reduce instabilities, but the success of training remains strongly\ninfluenced by the choice of the hyperparameters. To overcome this issue, we\nintroduce HyperTrick, a new metaoptimization algorithm, and show its effective\napplication to tune hyperparameters in the case of deep reinforcement learning,\nwhile learning to play different Atari games on a distributed system. Our\nanalysis provides evidence of the interaction between the identification of the\noptimal hyperparameters and the learned policy, that is typical of the case of\nmetaoptimization for deep reinforcement learning. When compared with\nstate-of-the-art metaoptimization algorithms, HyperTrick is characterized by a\nsimpler implementation and it allows learning similar policies, while making a\nmore effective use of the computational resources in a distributed system.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 16:48:31 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Heinrich", "Greg", ""], ["Frosio", "Iuri", ""]]}, {"id": "1902.02752", "submitter": "Alexandre Kaspar", "authors": "Alexandre Kaspar, Tae-Hyun Oh, Liane Makatura, Petr Kellnhofer,\n  Jacqueline Aslarus and Wojciech Matusik", "title": "Neural Inverse Knitting: From Images to Manufacturing Instructions", "comments": "Project page: http://deepknitting.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent potential of mass customization brought by\nwhole-garment knitting machines, we introduce the new problem of automatic\nmachine instruction generation using a single image of the desired physical\nproduct, which we apply to machine knitting. We propose to tackle this problem\nby directly learning to synthesize regular machine instructions from real\nimages. We create a cured dataset of real samples with their instruction\ncounterpart and propose to use synthetic images to augment it in a novel way.\nWe theoretically motivate our data mixing framework and show empirical results\nsuggesting that making real images look more synthetic is beneficial in our\nproblem setup.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 18:05:17 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 19:32:16 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kaspar", "Alexandre", ""], ["Oh", "Tae-Hyun", ""], ["Makatura", "Liane", ""], ["Kellnhofer", "Petr", ""], ["Aslarus", "Jacqueline", ""], ["Matusik", "Wojciech", ""]]}, {"id": "1902.02767", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, Balaji\n  Lakshminarayanan", "title": "Hybrid Models with Deep and Invertible Features", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural hybrid model consisting of a linear model defined on a\nset of features computed by a deep, invertible transformation (i.e. a\nnormalizing flow). An attractive property of our model is that both\np(features), the density of the features, and p(targets | features), the\npredictive distribution, can be computed exactly in a single feed-forward pass.\nWe show that our hybrid model, despite the invertibility constraints, achieves\nsimilar accuracy to purely predictive models. Moreover the generative component\nremains a good model of the input features despite the hybrid optimization\nobjective. This offers additional capabilities such as detection of\nout-of-distribution inputs and enabling semi-supervised learning. The\navailability of the exact joint density p(targets, features) also allows us to\ncompute many quantities readily, making our hybrid model a useful building\nblock for downstream applications of probabilistic deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 18:49:47 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 13:52:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nalisnick", "Eric", ""], ["Matsukawa", "Akihiro", ""], ["Teh", "Yee Whye", ""], ["Gorur", "Dilan", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1902.02771", "submitter": "S.H. Shabbeer Basha", "authors": "S.H. Shabbeer Basha, Shiv Ram Dubey, Viswanath Pulabaigari, Snehasis\n  Mukherjee", "title": "Impact of Fully Connected Layers on Performance of Convolutional Neural\n  Networks for Image Classification", "comments": "This paper is accepted for publication in Neurocomputing Journal", "journal-ref": null, "doi": "10.1016/j.neucom.2019.10.008", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolutional Neural Networks (CNNs), in domains like computer vision,\nmostly reduced the need for handcrafted features due to its ability to learn\nthe problem-specific features from the raw input data. However, the selection\nof dataset-specific CNN architecture, which mostly performed by either\nexperience or expertise is a time-consuming and error-prone process. To\nautomate the process of learning a CNN architecture, this paper attempts at\nfinding the relationship between Fully Connected (FC) layers with some of the\ncharacteristics of the datasets. The CNN architectures, and recently datasets\nalso, are categorized as deep, shallow, wide, etc. This paper tries to\nformalize these terms along with answering the following questions. (i) What is\nthe impact of deeper/shallow architectures on the performance of the CNN w.r.t.\nFC layers?, (ii) How the deeper/wider datasets influence the performance of CNN\nw.r.t. FC layers?, and (iii) Which kind of architecture (deeper/ shallower) is\nbetter suitable for which kind of (deeper/ wider) datasets. To address these\nfindings, we have performed experiments with three CNN architectures having\ndifferent depths. The experiments are conducted by varying the number of FC\nlayers. We used four widely used datasets including CIFAR-10, CIFAR-100, Tiny\nImageNet, and CRCHistoPhenotypes to justify our findings in the context of the\nimage classification problem. The source code of this research is available at\nhttps://github.com/shabbeersh/Impact-of-FC-layers.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 07:42:26 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 04:35:05 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 05:28:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Basha", "S. H. Shabbeer", ""], ["Dubey", "Shiv Ram", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1902.02778", "submitter": "Nischal Agrawal", "authors": "Nischal Agrawal and Prasanna Chaporkar", "title": "KLUCB Approach to Copeland Bandits", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandit(MAB) problem is a reinforcement learning framework where\nan agent tries to maximise her profit by proper selection of actions through\nabsolute feedback for each action. The dueling bandits problem is a variation\nof MAB problem in which an agent chooses a pair of actions and receives\nrelative feedback for the chosen action pair. The dueling bandits problem is\nwell suited for modelling a setting in which it is not possible to provide\nquantitative feedback for each action, but qualitative feedback for each action\nis preferred as in the case of human feedback. The dueling bandits have been\nsuccessfully applied in applications such as online rank elicitation,\ninformation retrieval, search engine improvement and clinical online\nrecommendation. We propose a new method called Sup-KLUCB for K-armed dueling\nbandit problem specifically Copeland bandit problem by converting it into a\nstandard MAB problem. Instead of using MAB algorithm independently for each\naction in a pair as in Sparring and in Self-Sparring algorithms, we combine a\npair of action and use it as one action. Previous UCB algorithms such as\nRelative Upper Confidence Bound(RUCB) can be applied only in case of Condorcet\ndueling bandits, whereas this algorithm applies to general Copeland dueling\nbandits, including Condorcet dueling bandits as a special case. Our empirical\nresults outperform state of the art Double Thompson Sampling(DTS) in case of\nCopeland dueling bandits.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 18:59:16 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agrawal", "Nischal", ""], ["Chaporkar", "Prasanna", ""]]}, {"id": "1902.02783", "submitter": "Limor Gultchin", "authors": "Limor Gultchin (University of Oxford), Genevieve Patterson (TRASH),\n  Nancy Baym (Microsoft Research), Nathaniel Swinger (Lexington High School),\n  Adam Tauman Kalai (Microsoft Research)", "title": "Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humor is often thought to be beyond the reach of Natural Language\nProcessing, we show that several aspects of single-word humor correlate with\nsimple linear directions in Word Embeddings. In particular: (a) the word\nvectors capture multiple aspects discussed in humor theories from various\ndisciplines; (b) each individual's sense of humor can be represented by a\nvector, which can predict differences in people's senses of humor on new,\nunrated, words; and (c) upon clustering humor ratings of multiple demographic\ngroups, different humor preferences emerge across the different groups. Humor\nratings are taken from the work of Engelthaler and Hills (2017) as well as from\nan original crowdsourcing study of 120,000 words. Our dataset further includes\nannotations for the theoretically-motivated humor features we identify.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:36:43 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 19:00:59 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 21:04:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gultchin", "Limor", "", "University of Oxford"], ["Patterson", "Genevieve", "", "TRASH"], ["Baym", "Nancy", "", "Microsoft Research"], ["Swinger", "Nathaniel", "", "Lexington High School"], ["Kalai", "Adam Tauman", "", "Microsoft Research"]]}, {"id": "1902.02808", "submitter": "Sindhu Ghanta", "authors": "Sindhu Ghanta, Sriram Subramanian, Lior Khermosh, Swaminathan\n  Sundararaman, Harshil Shah, Yakov Goldberg, Drew Roselli, Nisha Talagala", "title": "ML Health: Fitness Tracking for Production Models", "comments": "This paper has been submitted to the Data Science track of KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of machine learning (ML) algorithms in production for extended\nperiods of time has uncovered new challenges such as monitoring and management\nof real-time prediction quality of a model in the absence of labels. However,\nsuch tracking is imperative to prevent catastrophic business outcomes resulting\nfrom incorrect predictions. The scale of these deployments makes manual\nmonitoring prohibitive, making automated techniques to track and raise alerts\nimperative. We present a framework, ML Health, for tracking potential drops in\nthe predictive performance of ML models in the absence of labels. The framework\nemploys diagnostic methods to generate alerts for further investigation. We\ndevelop one such method to monitor potential problems when production data\npatterns do not match training data distributions. We demonstrate that our\nmethod performs better than standard \"distance metrics\", such as RMSE,\nKL-Divergence, and Wasserstein at detecting issues with mismatched data sets.\nFinally, we present a working system that incorporates the ML Health approach\nto monitor and manage ML deployments within a realistic full production ML\nlifecycle.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 19:15:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Ghanta", "Sindhu", ""], ["Subramanian", "Sriram", ""], ["Khermosh", "Lior", ""], ["Sundararaman", "Swaminathan", ""], ["Shah", "Harshil", ""], ["Goldberg", "Yakov", ""], ["Roselli", "Drew", ""], ["Talagala", "Nisha", ""]]}, {"id": "1902.02812", "submitter": "Jianwen Xie", "authors": "Jianwen Xie, Zilong Zheng, Xiaolin Fang, Song-Chun Zhu, Ying Nian Wu", "title": "Cooperative Training of Fast Thinking Initializer and Slow Thinking\n  Solver for Conditional Learning", "comments": "16 pages", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI) 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning the conditional distribution of a\nhigh-dimensional output given an input, where the output and input may belong\nto two different domains, e.g., the output is a photo image and the input is a\nsketch image. We solve this problem by cooperative training of a fast thinking\ninitializer and slow thinking solver. The initializer generates the output\ndirectly by a non-linear transformation of the input as well as a noise vector\nthat accounts for latent variability in the output. The slow thinking solver\nlearns an objective function in the form of a conditional energy function, so\nthat the output can be generated by optimizing the objective function, or more\nrigorously by sampling from the conditional energy-based model. We propose to\nlearn the two models jointly, where the fast thinking initializer serves to\ninitialize the sampling of the slow thinking solver, and the solver refines the\ninitial output by an iterative algorithm. The solver learns from the difference\nbetween the refined output and the observed output, while the initializer\nlearns from how the solver refines its initial output. We demonstrate the\neffectiveness of the proposed method on various conditional learning tasks,\ne.g., class-to-image generation, image-to-image translation, and image\nrecovery. The advantage of our method over GAN-based methods is that our method\nis equipped with a slow thinking process that refines the solution guided by a\nlearned objective function.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 19:30:44 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 18:26:46 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 08:22:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Xie", "Jianwen", ""], ["Zheng", "Zilong", ""], ["Fang", "Xiaolin", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1902.02823", "submitter": "Joni Pajarinen", "authors": "Joni Pajarinen, Hong Linh Thai, Riad Akrour, Jan Peters, Gerhard\n  Neumann", "title": "Compatible Natural Gradient Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust-region methods have yielded state-of-the-art results in policy search.\nA common approach is to use KL-divergence to bound the region of trust\nresulting in a natural gradient policy update. We show that the natural\ngradient and trust region optimization are equivalent if we use the natural\nparameterization of a standard exponential policy distribution in combination\nwith compatible value function approximation. Moreover, we show that standard\nnatural gradient updates may reduce the entropy of the policy according to a\nwrong schedule leading to premature convergence. To control entropy reduction\nwe introduce a new policy search method called compatible policy search (COPOS)\nwhich bounds entropy loss. The experimental results show that COPOS yields\nstate-of-the-art results in challenging continuous control tasks and in\ndiscrete partially observable tasks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 20:03:17 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pajarinen", "Joni", ""], ["Thai", "Hong Linh", ""], ["Akrour", "Riad", ""], ["Peters", "Jan", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1902.02829", "submitter": "Houpu Yao", "authors": "Houpu Yao, Jingjing Wen, Yi Ren, Bin Wu, Ze Ji", "title": "Low-cost Measurement of Industrial Shock Signals via Deep Learning\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Special high-end sensors with expensive hardware are usually needed to\nmeasure shock signals with high accuracy. In this paper, we show that cheap\nlow-end sensors calibrated by deep neural networks are also capable to measure\nhigh-g shocks accurately. Firstly we perform drop shock tests to collect a\ndataset of shock signals measured by sensors of different fidelity. Secondly,\nwe propose a novel network to effectively learn both the signal peak and\noverall shape. The results show that the proposed network is capable to map\nlow-end shock signals to its high-end counterparts with satisfactory accuracy.\nTo the best of our knowledge, this is the first work to apply deep learning\ntechniques to calibrate shock sensors.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 20:20:29 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Yao", "Houpu", ""], ["Wen", "Jingjing", ""], ["Ren", "Yi", ""], ["Wu", "Bin", ""], ["Ji", "Ze", ""]]}, {"id": "1902.02860", "submitter": "Saeed Khaki", "authors": "Saeed Khaki and Lizhi Wang", "title": "Crop Yield Prediction Using Deep Neural Networks", "comments": "9 pages, Presented at 2018 INFORMS Conference on Business Analytics\n  and Operations Research (Baltimore, MD, USA). One of the winning solutions to\n  the 2018 Syngenta Crop Challenge", "journal-ref": "Frontiers in Plant Science, 10:621, 2019", "doi": "10.3389/fpls.2019.00621", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crop yield is a highly complex trait determined by multiple factors such as\ngenotype, environment, and their interactions. Accurate yield prediction\nrequires fundamental understanding of the functional relationship between yield\nand these interactive factors, and to reveal such relationship requires both\ncomprehensive datasets and powerful algorithms. In the 2018 Syngenta Crop\nChallenge, Syngenta released several large datasets that recorded the genotype\nand yield performances of 2,267 maize hybrids planted in 2,247 locations\nbetween 2008 and 2016 and asked participants to predict the yield performance\nin 2017. As one of the winning teams, we designed a deep neural network (DNN)\napproach that took advantage of state-of-the-art modeling and solution\ntechniques. Our model was found to have a superior prediction accuracy, with a\nroot-mean-square-error (RMSE) being 12% of the average yield and 50% of the\nstandard deviation for the validation dataset using predicted weather data.\nWith perfect weather data, the RMSE would be reduced to 11% of the average\nyield and 46% of the standard deviation. We also performed feature selection\nbased on the trained DNN model, which successfully decreased the dimension of\nthe input space without significant drop in the prediction accuracy. Our\ncomputational results suggested that this model significantly outperformed\nother popular methods such as Lasso, shallow neural networks (SNN), and\nregression tree (RT). The results also revealed that environmental factors had\na greater effect on the crop yield than genotype.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 21:54:00 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 21:53:26 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 18:20:24 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Khaki", "Saeed", ""], ["Wang", "Lizhi", ""]]}, {"id": "1902.02880", "submitter": "Phan-Minh Nguyen", "authors": "Phan-Minh Nguyen", "title": "Mean Field Limit of the Learning Dynamics of Multilayer Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can multilayer neural networks -- typically constructed as highly complex\nstructures with many nonlinearly activated neurons across layers -- behave in a\nnon-trivial way that yet simplifies away a major part of their complexities? In\nthis work, we uncover a phenomenon in which the behavior of these complex\nnetworks -- under suitable scalings and stochastic gradient descent dynamics --\nbecomes independent of the number of neurons as this number grows sufficiently\nlarge. We develop a formalism in which this many-neurons limiting behavior is\ncaptured by a set of equations, thereby exposing a previously unknown operating\nregime of these networks. While the current pursuit is mathematically\nnon-rigorous, it is complemented with several experiments that validate the\nexistence of this behavior.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 23:06:41 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Nguyen", "Phan-Minh", ""]]}, {"id": "1902.02881", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Yike Guo", "title": "Combining learning rate decay and weight decay with complexity gradient\n  descent - Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of $L^2$ regularization, in the specific case of deep neural\nnetworks rather than more traditional machine learning models, is still not\nfully elucidated. We hypothesize that this complex interplay is due to the\ncombination of overparameterization and high dimensional phenomena that take\nplace during training and make it unamenable to standard convex optimization\nmethods. Using insights from statistical physics and random fields theory, we\nintroduce a parameter factoring in both the level of the loss function and its\nremaining nonconvexity: the \\emph{complexity}. We proceed to show that it is\ndesirable to proceed with \\emph{complexity gradient descent}. We then show how\nto use this intuition to derive novel and efficient annealing schemes for the\nstrength of $L^2$ regularization when performing standard stochastic gradient\ndescent in deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 23:12:57 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Guo", "Yike", ""]]}, {"id": "1902.02890", "submitter": "Leighton Barnes", "authors": "Leighton Pate Barnes, Yanjun Han, and Ayfer Ozgur", "title": "Lower Bounds for Learning Distributions under Communication Constraints\n  via Fisher Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning high-dimensional, nonparametric and\nstructured (e.g. Gaussian) distributions in distributed networks, where each\nnode in the network observes an independent sample from the underlying\ndistribution and can use $k$ bits to communicate its sample to a central\nprocessor. We consider three different models for communication. Under the\nindependent model, each node communicates its sample to a central processor by\nindependently encoding it into $k$ bits. Under the more general sequential or\nblackboard communication models, nodes can share information interactively but\neach node is restricted to write at most $k$ bits on the final transcript. We\ncharacterize the impact of the communication constraint $k$ on the minimax risk\nof estimating the underlying distribution under $\\ell^2$ loss. We develop\nminimax lower bounds that apply in a unified way to many common statistical\nmodels and reveal that the impact of the communication constraint can be\nqualitatively different depending on the tail behavior of the score function\nassociated with each model. A key ingredient in our proofs is a geometric\ncharacterization of Fisher information from quantized samples.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 23:58:09 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:51:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Barnes", "Leighton Pate", ""], ["Han", "Yanjun", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "1902.02893", "submitter": "Silviu Pitis", "authors": "Silviu Pitis", "title": "Rethinking the Discount Factor in Reinforcement Learning: A Decision\n  Theoretic Approach", "comments": "8 pages + 1 page supplement. In proceedings of AAAI 2019. Slides,\n  poster and bibtex available at\n  https://silviupitis.com/#rethinking-the-discount-factor-in-reinforcement-learning-a-decision-theoretic-approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents have traditionally been tasked with\nmaximizing the value function of a Markov decision process (MDP), either in\ncontinuous settings, with fixed discount factor $\\gamma < 1$, or in episodic\nsettings, with $\\gamma = 1$. While this has proven effective for specific tasks\nwith well-defined objectives (e.g., games), it has never been established that\nfixed discounting is suitable for general purpose use (e.g., as a model of\nhuman preferences). This paper characterizes rationality in sequential decision\nmaking using a set of seven axioms and arrives at a form of discounting that\ngeneralizes traditional fixed discounting. In particular, our framework admits\na state-action dependent \"discount\" factor that is not constrained to be less\nthan 1, so long as there is eventual long run discounting. Although this\nbroadens the range of possible preference structures in continuous settings, we\nshow that there exists a unique \"optimizing MDP\" with fixed $\\gamma < 1$ whose\noptimal value function matches the true utility of the optimal policy, and we\nquantify the difference between value and utility for suboptimal policies. Our\nwork can be seen as providing a normative justification for (a slight\ngeneralization of) Martha White's RL task formalism (2017) and other recent\ndepartures from the traditional RL, and is relevant to task specification in\nRL, inverse RL and preference-based RL.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 00:30:53 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pitis", "Silviu", ""]]}, {"id": "1902.02904", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Xiang Yan, Pascal Van Hentenryck", "title": "Modeling Heterogeneity in Mode-Switching Behavior Under a\n  Mobility-on-Demand Transit System: An Interpretable Machine Learning Approach", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increased focus on interpretability and the\nuse of machine learning to inform policy analysis and decision making. This\npaper applies machine learning to examine travel behavior and, in particular,\non modeling changes in travel modes when individuals are presented with a novel\n(on-demand) mobility option. It addresses the following question: Can machine\nlearning be applied to model individual taste heterogeneity (preference\nheterogeneity for travel modes and response heterogeneity to travel attributes)\nin travel mode choice? This paper first develops a high-accuracy classifier to\npredict mode-switching behavior under a hypothetical Mobility-on-Demand Transit\nsystem (i.e., stated-preference data), which represents the case study\nunderlying this research. We show that this classifier naturally captures\nindividual heterogeneity available in the data. Moreover, the paper derives\ninsights on heterogeneous switching behaviors through the generation of\nmarginal effects and elasticities by current travel mode, partial dependence\nplots, and individual conditional expectation plots. The paper also proposes\ntwo new model-agnostic interpretation tools for machine learning, i.e.,\nconditional partial dependence plots and conditional individual partial\ndependence plots, specifically designed to examine response heterogeneity. The\nresults on the case study show that the machine-learning classifier, together\nwith model-agnostic interpretation tools, provides valuable insights on travel\nmode switching behavior for different individuals and population segments. For\nexample, the existing drivers are more sensitive to additional pickups than\npeople using other travel modes, and current transit users are generally\nwilling to share rides but reluctant to take any additional transfers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:15:09 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Zhao", "Xilei", ""], ["Yan", "Xiang", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1902.02905", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo, Mikelson MomPremier, Richard Y. Hwang, Salman J.\n  Yousuf, Steven L. Williams, Joshua Grant", "title": "Mobile Artificial Intelligence Technology for Detecting Macula Edema and\n  Subretinal Fluid on OCT Scans: Initial Results from the DATUM alpha Study", "comments": "Initial results of the DATUM alpha Study were initially presented on\n  August 13th 2018 in the Keynote Address at the 116th National Medical\n  Association Annual Meeting & Scientific Assembly's New Innovations in\n  Ophthalmology Session. The results were also presented on September 21st 2018\n  in a Podium Lecture during Alumni Day at the University of Michigan--Ann\n  Arbor Kellogg Eye Center", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is necessary to address the large and growing\ndeficit in retina and healthcare access globally. And mobile AI diagnostic\nplatforms running in the Cloud may effectively and efficiently distribute such\nAI capability. Here we sought to evaluate the feasibility of Cloud-based mobile\nartificial intelligence for detection of retinal disease. And to evaluate the\naccuracy of a particular such system for detection of subretinal fluid (SRF)\nand macula edema (ME) on OCT scans. A multicenter retrospective image analysis\nwas conducted in which board-certified ophthalmologists with fellowship\ntraining in retina evaluated OCT images of the macula. They noted the presence\nor absence of ME or SRF, then compared their assessment to that obtained from\nFluid Intelligence, a mobile AI app that detects SRF and ME on OCT scans.\nInvestigators consecutively selected retinal OCTs, while making effort to\nbalance the number of scans with retinal fluid and scans without. Exclusion\ncriteria included poor scan quality, ambiguous features, macula holes,\nretinoschisis, and dense epiretinal membranes. Accuracy in the form of\nsensitivity and specificity of the AI mobile App was determined by comparing\nits assessments to those of the retina specialists. At the time of this\nsubmission, five centers have completed their initial studies. This consists of\na total of 283 OCT scans of which 155 had either ME or SRF (\"wet\") and 128 did\nnot (\"dry\"). The sensitivity ranged from 82.5% to 97% with a weighted average\nof 89.3%. The specificity ranged from 52% to 100% with a weighted average of\n81.23%. CONCLUSION: Cloud-based Mobile AI technology is feasible for the\ndetection retinal disease. In particular, Fluid Intelligence (alpha version),\nis sufficiently accurate as a screening tool for SRF and ME, especially in\nunderserved areas. Further studies and technology development is needed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:15:23 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 23:50:23 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Odaibo", "Stephen G.", ""], ["MomPremier", "Mikelson", ""], ["Hwang", "Richard Y.", ""], ["Yousuf", "Salman J.", ""], ["Williams", "Steven L.", ""], ["Grant", "Joshua", ""]]}, {"id": "1902.02907", "submitter": "Silviu Pitis", "authors": "Silviu Pitis", "title": "Source Traces for Temporal Difference Learning", "comments": "8 pages. In proceedings of AAAI 2018. Slides and bibtex available at\n  https://silviupitis.com/#source-traces-for-temporal-difference-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper motivates and develops source traces for temporal difference (TD)\nlearning in the tabular setting. Source traces are like eligibility traces, but\nmodel potential histories rather than immediate ones. This allows TD errors to\nbe propagated to potential causal states and leads to faster generalization.\nSource traces can be thought of as the model-based, backward view of successor\nrepresentations (SR), and share many of the same benefits. This view, however,\nsuggests several new ideas. First, a TD($\\lambda$)-like source learning\nalgorithm is proposed and its convergence is proven. Then, a novel algorithm\nfor learning the source map (or SR matrix) is developed and shown to outperform\nthe previous algorithm. Finally, various approaches to using the source/SR\nmodel are explored, and it is shown that source traces can be effectively\ncombined with other model-based methods like Dyna and experience replay.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:21:17 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pitis", "Silviu", ""]]}, {"id": "1902.02910", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Ruizhou Ding, Diana Marculescu", "title": "AdaScale: Towards Real-time Video Object Detection Using Adaptive\n  Scaling", "comments": "Accepted to SysML 2019 (http://www.sysml.cc/) as oral contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vision-enabled autonomous systems such as robots and autonomous cars,\nvideo object detection plays a crucial role, and both its speed and accuracy\nare important factors to provide reliable operation. The key insight we show in\nthis paper is that speed and accuracy are not necessarily a trade-off when it\ncomes to image scaling. Our results show that re-scaling the image to a lower\nresolution will sometimes produce better accuracy. Based on this observation,\nwe propose a novel approach, dubbed AdaScale, which adaptively selects the\ninput image scale that improves both accuracy and speed for video object\ndetection. To this end, our results on ImageNet VID and mini\nYouTube-BoundingBoxes datasets demonstrate 1.3 points and 2.7 points mAP\nimprovement with 1.6x and 1.8x speedup, respectively. Additionally, we improve\nstate-of-the-art video acceleration work by an extra 1.25x speedup with\nslightly better mAP on ImageNet VID dataset.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:31:02 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Ding", "Ruizhou", ""], ["Marculescu", "Diana", ""]]}, {"id": "1902.02918", "submitter": "Jeremy Cohen", "authors": "Jeremy M Cohen and Elan Rosenfeld and J. Zico Kolter", "title": "Certified Adversarial Robustness via Randomized Smoothing", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to turn any classifier that classifies well under Gaussian noise\ninto a new classifier that is certifiably robust to adversarial perturbations\nunder the $\\ell_2$ norm. This \"randomized smoothing\" technique has been\nproposed recently in the literature, but existing guarantees are loose. We\nprove a tight robustness guarantee in $\\ell_2$ norm for smoothing with Gaussian\nnoise. We use randomized smoothing to obtain an ImageNet classifier with e.g. a\ncertified top-1 accuracy of 49% under adversarial perturbations with $\\ell_2$\nnorm less than 0.5 (=127/255). No certified defense has been shown feasible on\nImageNet except for smoothing. On smaller-scale datasets where competing\napproaches to certified $\\ell_2$ robustness are viable, smoothing delivers\nhigher certified accuracies. Our strong empirical results suggest that\nrandomized smoothing is a promising direction for future research into\nadversarially robust classification. Code and models are available at\nhttp://github.com/locuslab/smoothing.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 02:08:19 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 07:40:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Cohen", "Jeremy M", ""], ["Rosenfeld", "Elan", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1902.02930", "submitter": "Divam Gupta", "authors": "Divam Gupta, Kushagra Singh, Soumen Chakrabarti, Tanmoy Chakraborty", "title": "Multi-task Learning for Target-dependent Sentiment Classification", "comments": "PAKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and aggregating sentiments toward people, organizations, and events\nexpressed in unstructured social media have become critical text mining\noperations. Early systems detected sentiments over whole passages, whereas more\nrecently, target-specific sentiments have been of greater interest. In this\npaper, we present MTTDSC, a multi-task target-dependent sentiment\nclassification system that is informed by feature representation learnt for the\nrelated auxiliary task of passage-level sentiment classification. The auxiliary\ntask uses a gated recurrent unit (GRU) and pools GRU states, followed by an\nauxiliary fully-connected layer that outputs passage-level predictions. In the\nmain task, these GRUs contribute auxiliary per-token representations over and\nabove word embeddings. The main task has its own, separate GRUs. The auxiliary\nand main GRUs send their states to a different fully connected layer, trained\nfor the main task. Extensive experiments using two auxiliary datasets and three\nbenchmark datasets (of which one is new, introduced by us) for the main task\ndemonstrate that MTTDSC outperforms state-of-the-art baselines. Using\nword-level sensitivity analysis, we present anecdotal evidence that prior\nsystems can make incorrect target-specific predictions because they miss\nsentiments expressed by words independent of target.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 03:58:09 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Gupta", "Divam", ""], ["Singh", "Kushagra", ""], ["Chakrabarti", "Soumen", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1902.02934", "submitter": "Yang Guo", "authors": "Na Lei, Yang Guo, Dongsheng An, Xin Qi, Zhongxuan Luo, Shing-Tung Yau,\n  Xianfeng Gu", "title": "Mode Collapse and Regularity of Optimal Transportation Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work builds the connection between the regularity theory of optimal\ntransportation map, Monge-Amp\\`{e}re equation and GANs, which gives a theoretic\nunderstanding of the major drawbacks of GANs: convergence difficulty and mode\ncollapse.\n  According to the regularity theory of Monge-Amp\\`{e}re equation, if the\nsupport of the target measure is disconnected or just non-convex, the optimal\ntransportation mapping is discontinuous. General DNNs can only approximate\ncontinuous mappings. This intrinsic conflict leads to the convergence\ndifficulty and mode collapse in GANs.\n  We test our hypothesis that the supports of real data distribution are in\ngeneral non-convex, therefore the discontinuity is unavoidable using an\nAutoencoder combined with discrete optimal transportation map (AE-OT framework)\non the CelebA data set. The testing result is positive. Furthermore, we propose\nto approximate the continuous Brenier potential directly based on discrete\nBrenier theory to tackle mode collapse. Comparing with existing method, this\nmethod is more accurate and effective.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 04:30:38 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Lei", "Na", ""], ["Guo", "Yang", ""], ["An", "Dongsheng", ""], ["Qi", "Xin", ""], ["Luo", "Zhongxuan", ""], ["Yau", "Shing-Tung", ""], ["Gu", "Xianfeng", ""]]}, {"id": "1902.02940", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg", "title": "Generating the support with extreme value losses", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When optimizing against the mean loss over a distribution of predictions in\nthe context of a regression task, then even if there is a distribution of\ntargets the optimal prediction distribution is always a delta function at a\nsingle value. Methods of constructing generative models need to overcome this\ntendency. We consider a simple method of summarizing the prediction error, such\nthat the optimal strategy corresponds to outputting a distribution of\npredictions with a support that matches the support of the distribution of\ntargets --- optimizing against the minimal value of the loss given a set of\nsamples from the prediction distribution, rather than the mean. We show that\nmodels trained against this loss learn to capture the support of the target\ndistribution and, when combined with an auxiliary classifier-like prediction\ntask, can be projected via rejection sampling to reproduce the full\ndistribution of targets. The resulting method works well compared to other\ngenerative modeling approaches particularly in low dimensional spaces with\nhighly non-trivial distributions, due to mode collapse solutions being globally\nsuboptimal with respect to the extreme value loss. However, the method is less\nsuited to high-dimensional spaces such as images due to the scaling of the\nnumber of samples needed in order to accurately estimate the extreme value loss\nwhen the dimension of the data manifold becomes large.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 04:58:50 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Guttenberg", "Nicholas", ""]]}, {"id": "1902.02947", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Jiawei Su", "title": "Understanding the One-Pixel Attack: Propagation Maps and Locality\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks were shown to be vulnerable to single pixel\nmodifications. However, the reason behind such phenomena has never been\nelucidated. Here, we propose Propagation Maps which show the influence of the\nperturbation in each layer of the network. Propagation Maps reveal that even in\nextremely deep networks such as Resnet, modification in one pixel easily\npropagates until the last layer. In fact, this initial local perturbation is\nalso shown to spread becoming a global one and reaching absolute difference\nvalues that are close to the maximum value of the original feature maps in a\ngiven layer. Moreover, we do a locality analysis in which we demonstrate that\nnearby pixels of the perturbed one in the one-pixel attack tend to share the\nsame vulnerability, revealing that the main vulnerability lies in neither\nneurons nor pixels but receptive fields. Hopefully, the analysis conducted in\nthis work together with a new technique called propagation maps shall shed\nlight into the inner workings of other adversarial samples and be the basis of\nnew defense systems to come.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 06:06:01 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Su", "Jiawei", ""]]}, {"id": "1902.02948", "submitter": "Shivang Agarwal", "authors": "Shivang Agarwal, C. Ravindranath Chowdary, Shripriya Maheshwari", "title": "EILearn: Learning Incrementally Using Previous Knowledge Obtained From\n  an Ensemble of Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an algorithm for incremental learning of classifiers. The proposed\nmethod enables an ensemble of classifiers to learn incrementally by\naccommodating new training data. We use an effective mechanism to overcome the\nstability-plasticity dilemma. In incremental learning, the general convention\nis to use only the knowledge acquired in the previous phase but not the\npreviously seen data. We follow this convention by retaining the previously\nacquired knowledge which is relevant and using it along with the current data.\nThe performance of each classifier is monitored to eliminate the poorly\nperforming classifiers in the subsequent phases. Experimental results show that\nthe proposed approach outperforms the existing incremental learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 06:06:22 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Agarwal", "Shivang", ""], ["Chowdary", "C. Ravindranath", ""], ["Maheshwari", "Shripriya", ""]]}, {"id": "1902.02950", "submitter": "Sungyong Seo", "authors": "Sungyong Seo, Yan Liu", "title": "Differentiable Physics-informed Graph Networks", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While physics conveys knowledge of nature built from an interplay between\nobservations and theory, it has been considered less importantly in deep neural\nnetworks. Especially, there are few works leveraging physics behaviors when the\nknowledge is given less explicitly. In this work, we propose a novel\narchitecture called Differentiable Physics-informed Graph Networks (DPGN) to\nincorporate implicit physics knowledge which is given from domain experts by\ninforming it in latent space. Using the concept of DPGN, we demonstrate that\nclimate prediction tasks are significantly improved. Besides the experiment\nresults, we validate the effectiveness of the proposed module and provide\nfurther applications of DPGN, such as inductive learning and multistep\npredictions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 06:24:41 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 02:09:12 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Seo", "Sungyong", ""], ["Liu", "Yan", ""]]}, {"id": "1902.02953", "submitter": "L.A. Prashanth", "authors": "Vinay Praneeth Boda and Prashanth L. A", "title": "Correlated bandits or: How to minimize mean-squared error online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the objective in traditional multi-armed bandit problems is to find the\narm with the highest mean, in many settings, finding an arm that best captures\ninformation about other arms is of interest. This objective, however, requires\nlearning the underlying correlation structure and not just the means of the\narms. Sensors placement for industrial surveillance and cellular network\nmonitoring are a few applications, where the underlying correlation structure\nplays an important role. Motivated by such applications, we formulate the\ncorrelated bandit problem, where the objective is to find the arm with the\nlowest mean-squared error (MSE) in estimating all the arms. To this end, we\nderive first an MSE estimator, based on sample variances and covariances, and\nshow that our estimator exponentially concentrates around the true MSE. Under a\nbest-arm identification framework, we propose a successive rejects type\nalgorithm and provide bounds on the probability of error in identifying the\nbest arm. Using minmax theory, we also derive fundamental performance limits\nfor the correlated bandit problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 06:38:29 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 10:10:12 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Boda", "Vinay Praneeth", ""], ["A", "Prashanth L.", ""]]}, {"id": "1902.02970", "submitter": "Koki Kishimoto", "authors": "Koki Kishimoto, Katsuhiko Hayashi, Genki Akai, Masashi Shimbo, and\n  Kazunori Komatani", "title": "Binarized Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorization has become an increasingly popular approach to knowledge\ngraph completion(KGC), which is the task of automatically predicting missing\nfacts in a knowledge graph. However, even with a simple model like\nCANDECOMP/PARAFAC(CP) tensor decomposition, KGC on existing knowledge graphs is\nimpractical in resource-limited environments, as a large amount of memory is\nrequired to store parameters represented as 32-bit or 64-bit floating point\nnumbers. This limitation is expected to become more stringent as existing\nknowledge graphs, which are already huge, keep steadily growing in scale. To\nreduce the memory requirement, we present a method for binarizing the\nparameters of the CP tensor decomposition by introducing a quantization\nfunction to the optimization problem. This method replaces floating\npoint-valued parameters with binary ones after training, which drastically\nreduces the model size at run time. We investigate the trade-off between the\nquality and size of tensor factorization models for several KGC benchmark\ndatasets. In our experiments, the proposed method successfully reduced the\nmodel size by more than an order of magnitude while maintaining the task\nperformance. Moreover, a fast score computation technique can be developed with\nbitwise operations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 08:27:25 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Kishimoto", "Koki", ""], ["Hayashi", "Katsuhiko", ""], ["Akai", "Genki", ""], ["Shimbo", "Masashi", ""], ["Komatani", "Kazunori", ""]]}, {"id": "1902.02979", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Manuel Gomez-Rodriguez, Bernhard Sch\\\"olkopf, Krikamol\n  Muandet, Isabel Valera", "title": "Fair Decisions Despite Imperfect Predictions", "comments": "earlier version appeared at AISTATS 2020\n  http://proceedings.mlr.press/v108/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consequential decisions are increasingly informed by sophisticated\ndata-driven predictive models. However, to consistently learn accurate\npredictive models, one needs access to ground truth labels. Unfortunately, in\npractice, labels may only exist conditional on certain decisions---if a loan is\ndenied, there is not even an option for the individual to pay back the loan.\nHence, the observed data distribution depends on how decisions are being made.\nIn this paper, we show that in this selective labels setting, learning a\npredictor directly only from available labeled data is suboptimal in terms of\nboth fairness and utility. To avoid this undesirable behavior, we propose to\ndirectly learn decision policies that maximize utility under fairness\nconstraints and thereby take into account how decisions affect which data is\nobserved in the future. Our results suggest the need for a paradigm shift in\nthe context of fair machine learning from the currently prevalent idea of\nsimply building predictive models from a single static dataset via risk\nminimization, to a more interactive notion of \"learning to decide\". In\nparticular, such policies should not entirely neglect part of the input space,\ndrawing connections to explore/exploit tradeoffs in reinforcement learning,\ndata missingness, and potential outcomes in causal inference. Experiments on\nsynthetic and real-world data illustrate the favorable properties of learning\nto decide in terms of utility and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 08:50:31 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 08:15:45 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 01:22:11 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 08:09:32 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kilbertus", "Niki", ""], ["Gomez-Rodriguez", "Manuel", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Muandet", "Krikamol", ""], ["Valera", "Isabel", ""]]}, {"id": "1902.02992", "submitter": "Yoshihiro Nagano", "authors": "Yoshihiro Nagano, Shoichiro Yamaguchi, Yasuhiro Fujita, Masanori\n  Koyama", "title": "A Wrapped Normal Distribution on Hyperbolic Space for Gradient-Based\n  Learning", "comments": "20 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic space is a geometry that is known to be well-suited for\nrepresentation learning of data with an underlying hierarchical structure. In\nthis paper, we present a novel hyperbolic distribution called\n\\textit{pseudo-hyperbolic Gaussian}, a Gaussian-like distribution on hyperbolic\nspace whose density can be evaluated analytically and differentiated with\nrespect to the parameters. Our distribution enables the gradient-based learning\nof the probabilistic models on hyperbolic space that could never have been\nconsidered before. Also, we can sample from this hyperbolic probability\ndistribution without resorting to auxiliary means like rejection sampling. As\napplications of our distribution, we develop a hyperbolic-analog of variational\nautoencoder and a method of probabilistic word embedding on hyperbolic space.\nWe demonstrate the efficacy of our distribution on various datasets including\nMNIST, Atari 2600 Breakout, and WordNet.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 09:42:06 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 03:12:01 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Nagano", "Yoshihiro", ""], ["Yamaguchi", "Shoichiro", ""], ["Fujita", "Yasuhiro", ""], ["Koyama", "Masanori", ""]]}, {"id": "1902.03002", "submitter": "Sylvain Courtain", "authors": "Guillaume Guex, Sylvain Courtain and Marco Saerens", "title": "Covariance and Correlation Kernels on a Graph in the Generalized\n  Bag-of-Paths Formalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work derives closed-form expressions computing the expectation of\nco-presence and of number of co-occurrences of nodes on paths sampled from a\nnetwork according to general path weights (a bag of paths). The underlying idea\nis that two nodes are considered as similar when they often appear together on\n(preferably short) paths of the network. The different expressions are obtained\nfor both regular and hitting paths and serve as a basis for computing new\ncovariance and correlation measures between nodes, which are valid positive\nsemi-definite kernels on a graph. Experiments on semi-supervised classification\nproblems show that the introduced similarity measures provide competitive\nresults compared to other state-of-the-art distance and similarity measures\nbetween nodes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 10:16:02 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 09:40:40 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 11:26:23 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 09:23:02 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Guex", "Guillaume", ""], ["Courtain", "Sylvain", ""], ["Saerens", "Marco", ""]]}, {"id": "1902.03020", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, Thomas A. Trost, Marius Mosbach, Michael Backes,\n  Dietrich Klakow", "title": "On the security relevance of weights in deep learning", "comments": "16 pages, 18 figures, long version of paper published at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a weight-based attack on stochastic gradient descent inducing\noverfitting has been proposed. We show that the threat is broader: A\ntask-independent permutation on the initial weights suffices to limit the\nachieved accuracy to for example 50% on the Fashion MNIST dataset from\ninitially more than $90$%. These findings are confirmed on MNIST and CIFAR. We\nformally confirm that the attack succeeds with high likelihood and does not\ndepend on the data. Empirically, weight statistics and loss appear\nunsuspicious, making it hard to detect the attack if the user is not aware. Our\npaper is thus a call for action to acknowledge the importance of the initial\nweights in deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 11:14:08 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 08:38:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Grosse", "Kathrin", ""], ["Trost", "Thomas A.", ""], ["Mosbach", "Marius", ""], ["Backes", "Michael", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1902.03035", "submitter": "Wojciech Kot{\\l}owski", "authors": "Wojciech Kot{\\l}owski, Gergely Neu", "title": "Bandit Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a partial-feedback variant of the well-studied online PCA problem\nwhere a learner attempts to predict a sequence of $d$-dimensional vectors in\nterms of a quadratic loss, while only having limited feedback about the\nenvironment's choices. We focus on a natural notion of bandit feedback where\nthe learner only observes the loss associated with its own prediction. Based on\nthe classical observation that this decision-making problem can be lifted to\nthe space of density matrices, we propose an algorithm that is shown to achieve\na regret of $O(d^{3/2}\\sqrt{T})$ after $T$ rounds in the worst case. We also\nprove data-dependent bounds that improve on the basic result when the loss\nmatrices of the environment have bounded rank or the loss of the best action is\nbounded. One version of our algorithm runs in $O(d)$ time per trial which\nmassively improves over every previously known online PCA method. We complement\nthese results by a lower bound of $\\Omega(d\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 11:57:48 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Kot\u0142owski", "Wojciech", ""], ["Neu", "Gergely", ""]]}, {"id": "1902.03043", "submitter": "Ross Harper", "authors": "Ross Harper and Joshua Southern", "title": "A Bayesian Deep Learning Framework for End-To-End Prediction of Emotion\n  from Heartbeat", "comments": "8 pages, 2 tables", "journal-ref": null, "doi": "10.1109/TAFFC.2020.2981610", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic prediction of emotion promises to revolutionise human-computer\ninteraction. Recent trends involve fusion of multiple data modalities - audio,\nvisual, and physiological - to classify emotional state. However, in practice,\ncollection of physiological data `in the wild' is currently limited to\nheartbeat time series of the kind generated by affordable wearable heart\nmonitors. Furthermore, real-world applications of emotion prediction often\nrequire some measure of uncertainty over model output, in order to inform\ndownstream decision-making. We present here an end-to-end deep learning model\nfor classifying emotional valence from unimodal heartbeat time series. We\nfurther propose a Bayesian framework for modelling uncertainty over these\nvalence predictions, and describe a probabilistic procedure for choosing to\naccept or reject model output according to the intended application. We\nbenchmarked our framework against two established datasets and achieved peak\nclassification accuracy of 90%. These results lay the foundation for\napplications of affective computing in real-world domains such as healthcare,\nwhere a high premium is placed on non-invasive collection of data, and\npredictive certainty.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:10:45 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 10:31:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Harper", "Ross", ""], ["Southern", "Joshua", ""]]}, {"id": "1902.03045", "submitter": "Lei Feng", "authors": "Lei Feng, Bo An", "title": "Partial Label Learning with Self-Guided Retraining", "comments": "8 pages, accepted by AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label learning deals with the problem where each training instance is\nassigned a set of candidate labels, only one of which is correct. This paper\nprovides the first attempt to leverage the idea of self-training for dealing\nwith partially labeled examples. Specifically, we propose a unified formulation\nwith proper constraints to train the desired model and perform pseudo-labeling\njointly. For pseudo-labeling, unlike traditional self-training that manually\ndifferentiates the ground-truth label with enough high confidence, we introduce\nthe maximum infinity norm regularization on the modeling outputs to\nautomatically achieve this consideratum, which results in a convex-concave\noptimization problem. We show that optimizing this convex-concave problem is\nequivalent to solving a set of quadratic programming (QP) problems. By\nproposing an upper-bound surrogate objective function, we turn to solving only\none QP problem for improving the optimization efficiency. Extensive experiments\non synthesized and real-world datasets demonstrate that the proposed approach\nsignificantly outperforms the state-of-the-art partial label learning\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:12:14 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Feng", "Lei", ""], ["An", "Bo", ""]]}, {"id": "1902.03046", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (PSL, SIERRA), Dmitrii Ostrovskii (PSL, SIERRA),\n  Francis Bach (PSL, SIERRA), Alessandro Rudi (PSL, SIERRA)", "title": "Beyond Least-Squares: Fast Rates for Regularized Empirical Risk\n  Minimization through Self-Concordance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning methods based on the regularization of a convex\nempirical risk by a squared Hilbertian norm, a setting that includes linear\npredictors and non-linear predictors through positive-definite kernels. In\norder to go beyond the generic analysis leading to convergence rates of the\nexcess risk as $O(1/\\sqrt{n})$ from $n$ observations, we assume that the\nindividual losses are self-concordant, that is, their third-order derivatives\nare bounded by their second-order derivatives. This setting includes\nleast-squares, as well as all generalized linear models such as logistic and\nsoftmax regression. For this class of losses, we provide a bias-variance\ndecomposition and show that the assumptions commonly made in least-squares\nregression, such as the source and capacity conditions, can be adapted to\nobtain fast non-asymptotic rates of convergence by improving the bias terms,\nthe variance terms or both.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:18:05 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 13:37:59 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 14:40:41 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "PSL, SIERRA"], ["Ostrovskii", "Dmitrii", "", "PSL, SIERRA"], ["Bach", "Francis", "", "PSL, SIERRA"], ["Rudi", "Alessandro", "", "PSL, SIERRA"]]}, {"id": "1902.03047", "submitter": "Lei Feng", "authors": "Lei Feng, Bo An, Shuo He", "title": "Collaboration based Multi-Label Learning", "comments": "Accepted by AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that exploiting label correlations is crucially important to\nmulti-label learning. Most of the existing approaches take label correlations\nas prior knowledge, which may not correctly characterize the real relationships\namong labels. Besides, label correlations are normally used to regularize the\nhypothesis space, while the final predictions are not explicitly correlated. In\nthis paper, we suggest that for each individual label, the final prediction\ninvolves the collaboration between its own prediction and the predictions of\nother labels. Based on this assumption, we first propose a novel method to\nlearn the label correlations via sparse reconstruction in the label space.\nThen, by seamlessly integrating the learned label correlations into model\ntraining, we propose a novel multi-label learning approach that aims to\nexplicitly account for the correlated predictions of labels while training the\ndesired model simultaneously. Extensive experimental results show that our\napproach outperforms the state-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:18:27 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Feng", "Lei", ""], ["An", "Bo", ""], ["He", "Shuo", ""]]}, {"id": "1902.03055", "submitter": "Xavier Siebert", "authors": "Boris Ndjia Njike, Xavier Siebert", "title": "K-nn active learning under local smoothness condition", "comments": "This work has been submitted twice. It is a duplicate of 2001.06485.\n  Sorry about that", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of work on convergence rates either in passive or\nactive learning. Here we outline some of the results that have been obtained,\nmore specifically in a nonparametric setting under assumptions about the\nsmoothness and the margin noise. We also discuss the relative merits of these\nunderlying assumptions by putting active learning in perspective with recent\nwork on passive learning. We provide a novel active learning algorithm with a\nrate of convergence better than in passive learning, using a particular\nsmoothness assumption customized for $k$-nearest neighbors. This smoothness\nassumption provides a dependence on the marginal distribution of the instance\nspace unlike other recent algorithms.\n  Our algorithm thus avoids the strong density assumption that supposes the\nexistence of the density function of the marginal distribution of the instance\nspace and is therefore more generally applicable.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:32:49 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 21:16:32 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 16:17:22 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Njike", "Boris Ndjia", ""], ["Siebert", "Xavier", ""]]}, {"id": "1902.03077", "submitter": "Tim Finin", "authors": "Ankur Padia, Kostantinos Kalpakis, Francis Ferraro, Tim Finin", "title": "Knowledge Graph Fact Prediction via Knowledge-Enriched Tensor\n  Factorization", "comments": "accepted by the Journal of Web Semantics, to appear 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of novel methods for embedding knowledge graphs into\nreal-valued tensors. These tensor-based embeddings capture the ordered\nrelations that are typical in the knowledge graphs represented by semantic web\nlanguages like RDF. Unlike many previous models, our methods can easily use\nprior background knowledge provided by users or extracted automatically from\nexisting knowledge graphs. In addition to providing more robust methods for\nknowledge graph embedding, we provide a provably-convergent, linear tensor\nfactorization algorithm. We demonstrate the efficacy of our models for the task\nof predicting new facts across eight different knowledge graphs, achieving\nbetween 5% and 50% relative improvement over existing state-of-the-art\nknowledge graph embedding techniques. Our empirical evaluation shows that all\nof the tensor decomposition models perform well when the average degree of an\nentity in a graph is high, with constraint-based models doing better on graphs\nwith a small number of highly similar relations and regularization-based models\ndominating for graphs with relations of varying degrees of similarity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 13:42:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Padia", "Ankur", ""], ["Kalpakis", "Kostantinos", ""], ["Ferraro", "Francis", ""], ["Finin", "Tim", ""]]}, {"id": "1902.03079", "submitter": "Zehong Cao Prof.", "authors": "Zehong Cao, Chin-Teng Lin", "title": "Reinforcement Learning from Hierarchical Critics", "comments": "This paper is submitted to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate the use of global information to speed up the\nlearning process and increase the cumulative rewards of reinforcement learning\n(RL) in competition tasks. Within the actor-critic RL, we introduce multiple\ncooperative critics from two levels of the hierarchy and propose a\nreinforcement learning from hierarchical critics (RLHC) algorithm. In our\napproach, each agent receives value information from local and global critics\nregarding a competition task and accesses multiple cooperative critics in a\ntop-down hierarchy. Thus, each agent not only receives low-level details but\nalso considers coordination from higher levels, thereby obtaining global\ninformation to improve the training performance. Then, we test the proposed\nRLHC algorithm against the benchmark algorithm, proximal policy optimisation\n(PPO), for two experimental scenarios performed in a Unity environment\nconsisting of tennis and soccer agents' competitions. The results showed that\nRLHC outperforms the benchmark on both competition tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 13:55:11 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 01:59:25 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 14:34:16 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2020 12:20:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Cao", "Zehong", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1902.03081", "submitter": "Sankalp Garg", "authors": "Sankalp Garg, Aniket Bajpai, Mausam", "title": "Size Independent Neural Transfer for RDDL Planning", "comments": "Published in ICAPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural planners for RDDL MDPs produce deep reactive policies in an offline\nfashion. These scale well with large domains, but are sample inefficient and\ntime-consuming to train from scratch for each new problem. To mitigate this,\nrecent work has studied neural transfer learning, so that a generic planner\ntrained on other problems of the same domain can rapidly transfer to a new\nproblem. However, this approach only transfers across problems of the same\nsize. We present the first method for neural transfer of RDDL MDPs that can\ntransfer across problems of different sizes. Our architecture has two key\ninnovations to achieve size independence: (1) a state encoder, which outputs a\nfixed length state embedding by max pooling over varying number of object\nembeddings, (2) a single parameter-tied action decoder that projects object\nembeddings into action probabilities for the final policy. On the two\nchallenging RDDL domains of SysAdmin and Game Of Life, our approach powerfully\ntransfers across problem sizes and has superior learning curves over training\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:01:48 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 21:03:42 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Garg", "Sankalp", ""], ["Bajpai", "Aniket", ""], ["Mausam", "", ""]]}, {"id": "1902.03083", "submitter": "Yossi Adi", "authors": "Felix Kreuk, Yossi Adi, Bhiksha Raj, Rita Singh, Joseph Keshet", "title": "Hide and Speak: Towards Deep Neural Networks for Speech Steganography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography is the science of hiding a secret message within an ordinary\npublic message, which is referred to as Carrier. Traditionally, digital signal\nprocessing techniques, such as least significant bit encoding, were used for\nhiding messages. In this paper, we explore the use of deep neural networks as\nsteganographic functions for speech data. We showed that steganography models\nproposed for vision are less suitable for speech, and propose a new model that\nincludes the short-time Fourier transform and inverse-short-time Fourier\ntransform as differentiable layers within the network, thus imposing a vital\nconstraint on the network outputs. We empirically demonstrated the\neffectiveness of the proposed method comparing to deep learning based on\nseveral speech datasets and analyzed the results quantitatively and\nqualitatively. Moreover, we showed that the proposed approach could be applied\nto conceal multiple messages in a single carrier using multiple decoders or a\nsingle conditional decoder. Lastly, we evaluated our model under different\nchannel distortions. Qualitative experiments suggest that modifications to the\ncarrier are unnoticeable by human listeners and that the decoded messages are\nhighly intelligible.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 13:48:28 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:20:30 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kreuk", "Felix", ""], ["Adi", "Yossi", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""], ["Keshet", "Joseph", ""]]}, {"id": "1902.03089", "submitter": "Sima Sharifirad", "authors": "Sima Sharifirad, Borna Jafarpour, Stan Matwin", "title": "How is Your Mood When Writing Sexist tweets? Detecting the Emotion Type\n  and Intensity of Emotion Using Natural Language Processing Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social platforms have been the battlefield of users with different\nemotions and attitudes toward each other in recent years. While sexism has been\nconsidered as a category of hateful speech in the literature, there is no\ncomprehensive definition and category of sexism attracting natural language\nprocessing techniques. Categorizing sexism as either benevolent or hostile\nsexism is so broad that it easily ignores the other categories of sexism on\nsocial media. Sharifirad S and Matwin S 2018 proposed a well-defined category\nof sexism including indirect harassment, information threat, sexual harassment\nand physical harassment, inspired from social science for the purpose of\nnatural language processing techniques. In this article, we take advantage of a\nnewly released dataset in SemEval-2018 task1: Affect in tweets, to show the\ntype of emotion and intensity of emotion in each category. We train, test and\nevaluate different classification methods on the SemEval- 2018 dataset and\nchoose the classifier with highest accuracy for testing on each category of\nsexist tweets to know the mental state and the affectual state of the user who\ntweets in each category. It is a nice avenue to explore because not all the\ntweets are directly sexist and they carry different emotions from the users.\nThis is the first work experimenting on affect detection this in depth on\nsexist tweets. Based on our best knowledge they are all new contributions to\nthe field; we are the first to demonstrate the power of such in-depth sentiment\nanalysis on the sexist tweets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:58:14 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Sharifirad", "Sima", ""], ["Jafarpour", "Borna", ""], ["Matwin", "Stan", ""]]}, {"id": "1902.03093", "submitter": "Alfredo Kalaitzis", "authors": "Laure Delisle, Alfredo Kalaitzis, Krzysztof Majewski, Archy de Berker,\n  Milena Marin, Julien Cornebise", "title": "A large-scale crowdsourced analysis of abuse against women journalists\n  and politicians on Twitter", "comments": "Workshop on AI for Social Good, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the first, to the best of our knowledge, hand-in-hand collaboration\nbetween human rights activists and machine learners, leveraging crowd-sourcing\nto study online abuse against women on Twitter. On a technical front, we\ncarefully curate an unbiased yet low-variance dataset of labeled tweets,\nanalyze it to account for the variability of abuse perception, and establish\nbaselines, preparing it for release to community research efforts. On a social\nimpact front, this study provides the technical backbone for a media campaign\naimed at raising public and deciders' awareness and elevating the standards\nexpected from social media companies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:59:01 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Delisle", "Laure", ""], ["Kalaitzis", "Alfredo", ""], ["Majewski", "Krzysztof", ""], ["de Berker", "Archy", ""], ["Marin", "Milena", ""], ["Cornebise", "Julien", ""]]}, {"id": "1902.03097", "submitter": "Georgios Giasemidis Dr", "authors": "Georgios Giasemidis and Nikolaos Kaplis and Ioannis Agrafiotis and\n  Jason R. C. Nurse", "title": "A semi-supervised approach to message stance classification", "comments": "33 pages, 8 figures, 1 table", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, November 2018", "doi": "10.1109/TKDE.2018.2880192", "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media communications are becoming increasingly prevalent; some useful,\nsome false, whether unwittingly or maliciously. An increasing number of rumours\ndaily flood the social networks. Determining their veracity in an autonomous\nway is a very active and challenging field of research, with a variety of\nmethods proposed. However, most of the models rely on determining the\nconstituent messages' stance towards the rumour, a feature known as the \"wisdom\nof the crowd\". Although several supervised machine-learning approaches have\nbeen proposed to tackle the message stance classification problem, these have\nnumerous shortcomings. In this paper we argue that semi-supervised learning is\nmore effective than supervised models and use two graph-based methods to\ndemonstrate it. This is not only in terms of classification accuracy, but\nequally important, in terms of speed and scalability. We use the Label\nPropagation and Label Spreading algorithms and run experiments on a dataset of\n72 rumours and hundreds of thousands messages collected from Twitter. We\ncompare our results on two available datasets to the state-of-the-art to\ndemonstrate our algorithms' performance regarding accuracy, speed and\nscalability for real-time applications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:57:53 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Giasemidis", "Georgios", ""], ["Kaplis", "Nikolaos", ""], ["Agrafiotis", "Ioannis", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1902.03098", "submitter": "Jinyun Yan", "authors": "Jinyun Yan, Birjodh Tiwana, Souvik Ghosh, Haishan Liu, Shaunak\n  Chatterjee", "title": "Measuring Long-term Impact of Ads on LinkedIn Feed", "comments": "Needs more polish", "journal-ref": "2018 Conference on Digital Experimentation (CODE)", "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organic updates (from a member's network) and sponsored updates (or ads, from\nadvertisers) together form the newsfeed on LinkedIn. The newsfeed, the default\nhomepage for members, attracts them to engage, brings them value and helps\nLinkedIn grow. Engagement and Revenue on feed are two critical, yet often\nconflicting objectives. Hence, it is important to design a good\nRevenue-Engagement Tradeoff (RENT) mechanism to blend ads in the feed. In this\npaper, we design experiments to understand how members' behavior evolve over\ntime given different ads experiences. These experiences vary on ads density,\nwhile the quality of ads (ensured by relevance models) is held constant. Our\nexperiments have been conducted on randomized member buckets and we use two\nexperimental designs to measure the short term and long term effects of the\nvarious treatments. Based on the first three months' data, we observe that the\nlong term impact is at a much smaller scale than the short term impact in our\napplication. Furthermore, we observe different member cohorts (based on user\nactivity level) adapt and react differently over time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 05:33:44 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 19:32:24 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yan", "Jinyun", ""], ["Tiwana", "Birjodh", ""], ["Ghosh", "Souvik", ""], ["Liu", "Haishan", ""], ["Chatterjee", "Shaunak", ""]]}, {"id": "1902.03099", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Jean Honorio", "title": "Exact Inference with Latent Variables in an Arbitrary Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the necessary and sufficient conditions for exact inference of a\nlatent model. In latent models, each entity is associated with a latent\nvariable following some probability distribution. The challenging question we\ntry to solve is: can we perform exact inference without observing the latent\nvariables, even without knowing what the domain of the latent variables is? We\nshow that exact inference can be achieved using a semidefinite programming\n(SDP) approach without knowing either the latent variables or their domain. Our\nanalysis predicts the experimental correctness of SDP with high accuracy,\nshowing the suitability of our focus on the Karush-Kuhn-Tucker (KKT) conditions\nand the spectrum of a properly defined matrix. As a byproduct of our analysis,\nwe also provide concentration inequalities with dependence on latent variables,\nboth for bounded moment generating functions as well as for the spectra of\nmatrices. To the best of our knowledge, these results are novel and could be\nuseful for many other problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:27:08 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 17:54:31 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 01:17:29 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "1902.03102", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti, Michael Mampaey", "title": "Using Background Knowledge to Rank Itemsets", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-010-0188-4", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the quality of discovered results is an important open problem in\ndata mining. Such assessment is particularly vital when mining itemsets, since\ncommonly many of the discovered patterns can be easily explained by background\nknowledge. The simplest approach to screen uninteresting patterns is to compare\nthe observed frequency against the independence model. Since the parameters for\nthe independence model are the column margins, we can view such screening as a\nway of using the column margins as background knowledge.\n  In this paper we study techniques for more flexible approaches for infusing\nbackground knowledge. Namely, we show that we can efficiently use additional\nknowledge such as row margins, lazarus counts, and bounds of ones. We\ndemonstrate that these statistics describe forms of data that occur in practice\nand have been studied in data mining.\n  To infuse the information efficiently we use a maximum entropy approach. In\nits general setting, solving a maximum entropy model is infeasible, but we\ndemonstrate that for our setting it can be solved in polynomial time.\nExperiments show that more sophisticated models fit the data better and that\nusing more information improves the frequency prediction of itemsets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:36:13 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Tatti", "Nikolaj", ""], ["Mampaey", "Michael", ""]]}, {"id": "1902.03110", "submitter": "Mehrnoosh Mirtaheri", "authors": "Mehrnoosh Mirtaheri, Sami Abu-El-Haija, Fred Morstatter, Greg Ver\n  Steeg, Aram Galstyan", "title": "Identifying and Analyzing Cryptocurrency Manipulations in Social Media", "comments": "Section 4. Prediction tasks: The training setup and algorithm\n  revised. The details of the training algorithm added. More features added to\n  the feature set. Section 5. Botometer score added as the likelihood of a user\n  being bot. More analysis added on bot activity in clusters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest surrounding cryptocurrencies, digital or virtual currencies that are\nused as a medium for financial transactions, has grown tremendously in recent\nyears. The anonymity surrounding these currencies makes investors particularly\nsusceptible to fraud---such as \"pump and dump\" scams---where the goal is to\nartificially inflate the perceived worth of a currency, luring victims into\ninvesting before the fraudsters can sell their holdings. Because of the speed\nand relative anonymity offered by social platforms such as Twitter and\nTelegram, social media has become a preferred platform for scammers who wish to\nspread false hype about the cryptocurrency they are trying to pump. In this\nwork we propose and evaluate a computational approach that can automatically\nidentify pump and dump scams as they unfold by combining information across\nsocial media platforms. We also develop a multi-modal approach for predicting\nwhether a particular pump attempt will succeed or not. Finally, we analyze the\nprevalence of bots in cryptocurrency related tweets, and observe a significant\nincrease in bot activity during the pump attempts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 21:37:38 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 22:24:30 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Mirtaheri", "Mehrnoosh", ""], ["Abu-El-Haija", "Sami", ""], ["Morstatter", "Fred", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1902.03111", "submitter": "Meysam Ghaffari", "authors": "Meysam Ghaffari, Ashok Srinivasan, Xiuwen Liu", "title": "High-resolution home location prediction from tweets using deep learning\n  with dynamic structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely and high-resolution estimates of the home locations of a sufficiently\nlarge subset of the population are critical for effective disaster response and\npublic health intervention, but this is still an open problem. Conventional\ndata sources, such as census and surveys, have a substantial time lag and\ncannot capture seasonal trends. Recently, social media data has been exploited\nto address this problem by leveraging its large user-base and real-time nature.\nHowever, inherent sparsity and noise, along with large estimation uncertainty\nin home locations, have limited their effectiveness. Consequently, much of\nprevious research has aimed only at a coarse spatial resolution, with accuracy\nbeing limited for high-resolution methods. In this paper, we develop a\ndeep-learning solution that uses a two-phase dynamic structure to deal with\nsparse and noisy social media data. In the first phase, high recall is achieved\nusing a random forest, producing more balanced home location candidates. Then\ntwo deep neural networks are used to detect home locations with high accuracy.\nWe obtained over 90% accuracy for large subsets on a commonly used dataset.\nCompared to other high-resolution methods, our approach yields up to 60% error\nreduction by reducing high-resolution home prediction error from over 21% to\nless than 8%. Systematic comparisons show that our method gives the highest\naccuracy both for the entire sample and for subsets. Evaluation on a real-world\npublic health problem further validates the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 21:36:23 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 23:43:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ghaffari", "Meysam", ""], ["Srinivasan", "Ashok", ""], ["Liu", "Xiuwen", ""]]}, {"id": "1902.03124", "submitter": "Janu Verma", "authors": "Janu Verma, Srishti Gupta, Debdoot Mukherjee, Tanmoy Chakraborty", "title": "Heterogeneous Edge Embeddings for Friend Recommendation", "comments": "To appear in ECIR, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a friend recommendation system (an application of link prediction)\nusing edge embeddings on social networks. Most real-world social networks are\nmulti-graphs, where different kinds of relationships (e.g. chat, friendship)\nare possible between a pair of users. Existing network embedding techniques do\nnot leverage signals from different edge types and thus perform inadequately on\nlink prediction in such networks. We propose a method to mine network\nrepresentation that effectively exploits heterogeneity in multi-graphs. We\nevaluate our model on a real-world, active social network where this system is\ndeployed for friend recommendation for millions of users. Our method\noutperforms various state-of-the-art baselines on Hike's social network in\nterms of accuracy as well as user satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 10:42:08 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Verma", "Janu", ""], ["Gupta", "Srishti", ""], ["Mukherjee", "Debdoot", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1902.03125", "submitter": "Chariton Chalvatzis", "authors": "Chariton Chalvatzis, Dimitrios Hristu-Varsakelis", "title": "High-performance stock index trading: making effective use of a deep\n  LSTM neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep long short-term memory (LSTM)-based neural network for\npredicting asset prices, together with a successful trading strategy for\ngenerating profits based on the model's predictions. Our work is motivated by\nthe fact that the effectiveness of any prediction model is inherently coupled\nto the trading strategy it is used with, and vise versa. This highlights the\ndifficulty in developing models and strategies which are jointly optimal, but\nalso points to avenues of investigation which are broader than prevailing\napproaches. Our LSTM model is structurally simple and generates predictions\nbased on price observations over a modest number of past trading days. The\nmodel's architecture is tuned to promote profitability, as opposed to accuracy,\nunder a strategy that does not trade simply based on whether the price is\npredicted to rise or fall, but rather takes advantage of the distribution of\npredicted returns, and the fact that a prediction's position within that\ndistribution carries useful information about the expected profitability of a\ntrade. The proposed model and trading strategy were tested on the S&P 500, Dow\nJones Industrial Average (DJIA), NASDAQ and Russel 2000 stock indices, and\nachieved cumulative returns of 340%, 185%, 371% and 360%, respectively, over\n2010-2018, far outperforming the benchmark buy-and-hold strategy as well as\nother recent efforts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:08:07 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 07:51:55 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Chalvatzis", "Chariton", ""], ["Hristu-Varsakelis", "Dimitrios", ""]]}, {"id": "1902.03127", "submitter": "Hossein Yazdani", "authors": "Hossein Yazdani", "title": "Bounded Fuzzy Possibilistic Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Bounded Fuzzy Possibilistic Method (BFPM) by addressing\nseveral issues that previous clustering/classification methods have not\nconsidered. In fuzzy clustering, object's membership values should sum to 1.\nHence, any object may obtain full membership in at most one cluster.\nPossibilistic clustering methods remove this restriction. However, BFPM differs\nfrom previous fuzzy and possibilistic clustering approaches by allowing the\nmembership function to take larger values with respect to all clusters.\nFurthermore, in BFPM, a data object can have full membership in multiple\nclusters or even in all clusters. BFPM relaxes the boundary conditions\n(restrictions) in membership assignment. The proposed methodology satisfies the\nnecessity of obtaining full memberships and overcomes the issues with\nconventional methods on dealing with overlapping. Analysing the objects'\nmovements from their own cluster to another (mutation) is also proposed in this\npaper. BFPM has been applied in different domains in geometry, set theory,\nanomaly detection, risk management, diagnosis diseases, and other disciplines.\nValidity and comparison indexes have been also used to evaluate the accuracy of\nBFPM. BFPM has been evaluated in terms of accuracy, fuzzification constant\n(different norms), objects' movement analysis, and covering diversity. The\npromising results prove the importance of considering the proposed methodology\nin learning methods to track the behaviour of data objects, in addition to\nobtain accurate results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:53:59 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Yazdani", "Hossein", ""]]}, {"id": "1902.03129", "submitter": "Amirata Ghorbani", "authors": "Amirata Ghorbani, James Wexler, James Zou, Been Kim", "title": "Towards Automatic Concept-based Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has become an important topic of research as more machine\nlearning (ML) models are deployed and widely used to make important decisions.\n  Most of the current explanation methods provide explanations through feature\nimportance scores, which identify features that are important for each\nindividual input. However, how to systematically summarize and interpret such\nper sample feature importance scores itself is challenging. In this work, we\npropose principles and desiderata for \\emph{concept} based explanation, which\ngoes beyond per-sample features to identify higher-level human-understandable\nconcepts that apply across the entire dataset. We develop a new algorithm, ACE,\nto automatically extract visual concepts. Our systematic experiments\ndemonstrate that \\alg discovers concepts that are human-meaningful, coherent\nand important for the neural network's predictions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 03:18:54 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 18:53:03 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 09:28:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Wexler", "James", ""], ["Zou", "James", ""], ["Kim", "Been", ""]]}, {"id": "1902.03149", "submitter": "Marc G. Bellemare", "authors": "Marc G. Bellemare, Nicolas Le Roux, Pablo Samuel Castro, Subhodeep\n  Moitra", "title": "Distributional reinforcement learning with linear function approximation", "comments": "To appear", "journal-ref": "Proceedings of AISTATS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many algorithmic advances, our theoretical understanding of practical\ndistributional reinforcement learning methods remains limited. One exception is\nRowland et al. (2018)'s analysis of the C51 algorithm in terms of the Cram\\'er\ndistance, but their results only apply to the tabular setting and ignore C51's\nuse of a softmax to produce normalized distributions. In this paper we adapt\nthe Cram\\'er distance to deal with arbitrary vectors. From it we derive a new\ndistributional algorithm which is fully Cram\\'er-based and can be combined to\nlinear function approximation, with formal guarantees in the context of policy\nevaluation. In allowing the model's prediction to be any real vector, we lose\nthe probabilistic interpretation behind the method, but otherwise maintain the\nappealing properties of distributional approaches. To the best of our\nknowledge, ours is the first proof of convergence of a distributional algorithm\ncombined with function approximation. Perhaps surprisingly, our results provide\nevidence that Cram\\'er-based distributional methods may perform worse than\ndirectly approximating the value function.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 15:31:42 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Bellemare", "Marc G.", ""], ["Roux", "Nicolas Le", ""], ["Castro", "Pablo Samuel", ""], ["Moitra", "Subhodeep", ""]]}, {"id": "1902.03151", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Indranil Chakraborty and Kaushik Roy", "title": "Discretization based Solutions for Secure Machine Learning against\n  Adversarial Attacks", "comments": "8 pages, 8 Figures, 6 Tables", "journal-ref": "IEEE Access, 2019", "doi": "10.1109/ACCESS.2019.2919463", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are perturbed inputs that are designed (from a deep\nlearning network's (DLN) parameter gradients) to mislead the DLN during test\ntime. Intuitively, constraining the dimensionality of inputs or parameters of a\nnetwork reduces the 'space' in which adversarial examples exist. Guided by this\nintuition, we demonstrate that discretization greatly improves the robustness\nof DLNs against adversarial attacks. Specifically, discretizing the input space\n(or allowed pixel levels from 256 values or 8-bit to 4 values or 2-bit)\nextensively improves the adversarial robustness of DLNs for a substantial range\nof perturbations for minimal loss in test accuracy. Furthermore, we find that\nBinary Neural Networks (BNNs) and related variants are intrinsically more\nrobust than their full precision counterparts in adversarial scenarios.\nCombining input discretization with BNNs furthers the robustness even waiving\nthe need for adversarial training for certain magnitude of perturbation values.\nWe evaluate the effect of discretization on MNIST, CIFAR10, CIFAR100 and\nImagenet datasets. Across all datasets, we observe maximal adversarial\nresistance with 2-bit input discretization that incurs an adversarial accuracy\nloss of just ~1-2% as compared to clean test accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 15:38:24 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 18:15:55 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Chakraborty", "Indranil", ""], ["Roy", "Kaushik", ""]]}, {"id": "1902.03175", "submitter": "Edwin Fong", "authors": "Edwin Fong, Simon Lyddon, Chris Holmes", "title": "Scalable Nonparametric Sampling from Multimodal Posteriors with the\n  Posterior Bootstrap", "comments": "Accepted at International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly complex datasets pose a number of challenges for Bayesian\ninference. Conventional posterior sampling based on Markov chain Monte Carlo\ncan be too computationally intensive, is serial in nature and mixes poorly\nbetween posterior modes. Further, all models are misspecified, which brings\ninto question the validity of the conventional Bayesian update. We present a\nscalable Bayesian nonparametric learning routine that enables posterior\nsampling through the optimization of suitably randomized objective functions. A\nDirichlet process prior on the unknown data distribution accounts for model\nmisspecification, and admits an embarrassingly parallel posterior bootstrap\nalgorithm that generates independent and exact samples from the nonparametric\nposterior distribution. Our method is particularly adept at sampling from\nmultimodal posterior distributions via a random restart mechanism. We\ndemonstrate our method on Gaussian mixture model and sparse logistic regression\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:37:25 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 14:51:22 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Fong", "Edwin", ""], ["Lyddon", "Simon", ""], ["Holmes", "Chris", ""]]}, {"id": "1902.03187", "submitter": "Jason Allred", "authors": "Jason M. Allred and Kaushik Roy", "title": "Controlled Forgetting: Targeted Stimulation and Dopaminergic Plasticity\n  Modulation for Unsupervised Lifelong Learning in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2020.00007", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent requires that training samples be drawn from a\nuniformly random distribution of the data. For a deployed system that must\nlearn online from an uncontrolled and unknown environment, the ordering of\ninput samples often fails to meet this criterion, making lifelong learning a\ndifficult challenge. We exploit the locality of the unsupervised Spike Timing\nDependent Plasticity (STDP) learning rule to target local representations in a\nSpiking Neural Network (SNN) to adapt to novel information while protecting\nessential information in the remainder of the SNN from catastrophic forgetting.\nIn our Controlled Forgetting Networks (CFNs), novel information triggers\nstimulated firing and heterogeneously modulated plasticity, inspired by\nbiological dopamine signals, to cause rapid and isolated adaptation in the\nsynapses of neurons associated with outlier information. This targeting\ncontrols the forgetting process in a way that reduces the degradation of\naccuracy for older tasks while learning new tasks. Our experimental results on\nthe MNIST dataset validate the capability of CFNs to learn successfully over\ntime from an unknown, changing environment, achieving 95.36% accuracy, which we\nbelieve is the best unsupervised accuracy ever achieved by a fixed-size,\nsingle-layer SNN on a completely disjoint MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:50:33 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 15:42:10 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Allred", "Jason M.", ""], ["Roy", "Kaushik", ""]]}, {"id": "1902.03190", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Chao Zhang and Phil Woodland", "title": "Speaker diarisation using 2D self-attentive combination of embeddings", "comments": "ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarisation systems often cluster audio segments using speaker\nembeddings such as i-vectors and d-vectors. Since different types of embeddings\nare often complementary, this paper proposes a generic framework to improve\nperformance by combining them into a single embedding, referred to as a\nc-vector. This combination uses a 2-dimensional (2D) self-attentive structure,\nwhich extends the standard self-attentive layer by averaging not only across\ntime but also across different types of embeddings. Two types of 2D\nself-attentive structure in this paper are the simultaneous combination and the\nconsecutive combination, adopting a single and multiple self-attentive layers\nrespectively. The penalty term in the original self-attentive layer which is\njointly minimised with the objective function to encourage diversity of\nannotation vectors is also modified to obtain not only different local peaks\nbut also the overall trends in the multiple annotation vectors. Experiments on\nthe AMI meeting corpus show that our modified penalty term improves the d-\nvector relative speaker error rate (SER) by 6% and 21% for d-vector systems,\nand a 10% further relative SER reduction can be obtained using the c-vector\nfrom our best 2D self-attentive structure.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:54:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Chao", ""], ["Woodland", "Phil", ""]]}, {"id": "1902.03192", "submitter": "Panagiotis Mousouliotis", "authors": "Panagiotis G. Mousouliotis and Loukas P. Petrou", "title": "Software-Defined FPGA Accelerator Design for Mobile Deep Learning\n  Applications", "comments": "Accepted to be presented in the 15th International Symposium on\n  Applied Reconfigurable Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the field of deep learning has received great attention by the\nscientific community and it is used to provide improved solutions to many\ncomputer vision problems. Convolutional neural networks (CNNs) have been\nsuccessfully used to attack problems such as object recognition, object\ndetection, semantic segmentation, and scene understanding. The rapid\ndevelopment of deep learning goes hand by hand with the adaptation of GPUs for\naccelerating its processes, such as network training and inference. Even though\nFPGA design exists long before the use of GPUs for accelerating computations\nand despite the fact that high-level synthesis (HLS) tools are getting more\nattractive, the adaptation of FPGAs for deep learning research and application\ndevelopment is poor due to the requirement of hardware design related\nexpertise. This work presents a workflow for deep learning mobile application\nacceleration on small low-cost low-power FPGA devices using HLS tools. This\nworkflow eases the design of an improved version of the SqueezeJet accelerator\nused for the speedup of mobile-friendly low-parameter ImageNet class CNNs, such\nas the SqueezeNet v1.1 and the ZynqNet. Additionally, the workflow includes the\ndevelopment of an HLS-driven analytical model which is used for performance\nestimation of the accelerator. This model can be also used to direct the design\nprocess and lead to future design improvements and optimizations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 17:08:39 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:23:57 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Mousouliotis", "Panagiotis G.", ""], ["Petrou", "Loukas P.", ""]]}, {"id": "1902.03210", "submitter": "Martin Jankowiak", "authors": "Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Justin Chiu, Neeraj\n  Pradhan, Alexander Rush, Noah Goodman", "title": "Tensor Variable Elimination for Plated Factor Graphs", "comments": "To appear at ICML; 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide class of machine learning algorithms can be reduced to variable\nelimination on factor graphs. While factor graphs provide a unifying notation\nfor these algorithms, they do not provide a compact way to express repeated\nstructure when compared to plate diagrams for directed graphical models. To\nexploit efficient tensor algebra in graphs with plates of variables, we\ngeneralize undirected factor graphs to plated factor graphs and variable\nelimination to a tensor variable elimination algorithm that operates directly\non plated factor graphs. Moreover, we generalize complexity bounds based on\ntreewidth and characterize the class of plated factor graphs for which\ninference is tractable. As an application, we integrate tensor variable\nelimination into the Pyro probabilistic programming language to enable exact\ninference in discrete latent variable models with repeated structure. We\nvalidate our methods with experiments on both directed and undirected graphical\nmodels, including applications to polyphonic music modeling, animal movement\nmodeling, and latent sentiment analysis.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:00:08 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 00:31:30 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Obermeyer", "Fritz", ""], ["Bingham", "Eli", ""], ["Jankowiak", "Martin", ""], ["Chiu", "Justin", ""], ["Pradhan", "Neeraj", ""], ["Rush", "Alexander", ""], ["Goodman", "Noah", ""]]}, {"id": "1902.03223", "submitter": "Apurv Shukla", "authors": "Daniel Bienstock, Apurv Shukla, SeYoung Yun", "title": "Non-Stationary Streaming PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider the problem of streaming principal component analysis (PCA) when\nthe observations are noisy and generated in a non-stationary environment. Given\n$T$, $p$-dimensional noisy observations sampled from a non-stationary variant\nof the spiked covariance model, our goal is to construct the best linear\n$k$-dimensional subspace of the terminal observations. We study the effect of\nnon-stationarity by establishing a lower bound on the number of samples and the\ncorresponding recovery error obtained by any algorithm. We establish the\nconvergence behaviour of the noisy power method using a novel proof technique\nwhich maybe of independent interest. We conclude that the recovery guarantee of\nthe noisy power method matches the fundamental limit, thereby generalizing\nexisting results on streaming PCA to a non-stationary setting.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:31:38 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 19:48:06 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Bienstock", "Daniel", ""], ["Shukla", "Apurv", ""], ["Yun", "SeYoung", ""]]}, {"id": "1902.03228", "submitter": "Venkata Krishna Pillutla", "authors": "Krishna Pillutla, Vincent Roulet, Sham M. Kakade, Zaid Harchaoui", "title": "A Smoother Way to Train Structured Prediction Models", "comments": "Short version appeared in Neural Information Processing Systems\n  (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to train a structured prediction model by performing\nsmoothing on the inference algorithm it builds upon. Smoothing overcomes the\nnon-smoothness inherent to the maximum margin structured prediction objective,\nand paves the way for the use of fast primal gradient-based optimization\nalgorithms. We illustrate the proposed framework by developing a novel primal\nincremental optimization algorithm for the structural support vector machine.\nThe proposed algorithm blends an extrapolation scheme for acceleration and an\nadaptive smoothing scheme and builds upon the stochastic variance-reduced\ngradient algorithm. We establish its worst-case global complexity bound and\nstudy several practical variants, including extensions to deep structured\nprediction. We present experimental results on two real-world problems, namely\nnamed entity recognition and visual object localization. The experimental\nresults show that the proposed framework allows us to build upon efficient\ninference algorithms to develop large-scale optimization algorithms for\nstructured prediction which can achieve competitive performance on the two\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:38:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pillutla", "Krishna", ""], ["Roulet", "Vincent", ""], ["Kakade", "Sham M.", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1902.03229", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Mojm\\'ir Mutn\\'y, Nicole Hiller, Rasmus Ischebeck,\n  Andreas Krause", "title": "Adaptive and Safe Bayesian Optimization in High Dimensions via\n  One-Dimensional Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is known to be difficult to scale to high dimensions,\nbecause the acquisition step requires solving a non-convex optimization problem\nin the same search space. In order to scale the method and keep its benefits,\nwe propose an algorithm (LineBO) that restricts the problem to a sequence of\niteratively chosen one-dimensional sub-problems that can be solved efficiently.\nWe show that our algorithm converges globally and obtains a fast local rate\nwhen the function is strongly convex. Further, if the objective has an\ninvariant subspace, our method automatically adapts to the effective dimension\nwithout changing the algorithm. When combined with the SafeOpt algorithm to\nsolve the sub-problems, we obtain the first safe Bayesian optimization\nalgorithm with theoretical guarantees applicable in high-dimensional settings.\nWe evaluate our method on multiple synthetic benchmarks, where we obtain\ncompetitive performance. Further, we deploy our algorithm to optimize the beam\nintensity of the Swiss Free Electron Laser with up to 40 parameters while\nsatisfying safe operation constraints.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:41:24 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 15:15:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kirschner", "Johannes", ""], ["Mutn\u00fd", "Mojm\u00edr", ""], ["Hiller", "Nicole", ""], ["Ischebeck", "Rasmus", ""], ["Krause", "Andreas", ""]]}, {"id": "1902.03233", "submitter": "Onur Ozdemir", "authors": "Onur Ozdemir, Rebecca L. Russell, Andrew A. Berlin", "title": "A 3D Probabilistic Deep Learning System for Detection and Diagnosis of\n  Lung Cancer Using Low-Dose CT Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new computer aided detection and diagnosis system for lung\ncancer screening with low-dose CT scans that produces meaningful probability\nassessments. Our system is based entirely on 3D convolutional neural networks\nand achieves state-of-the-art performance for both lung nodule detection and\nmalignancy classification tasks on the publicly available LUNA16 and Kaggle\nData Science Bowl challenges. While nodule detection systems are typically\ndesigned and optimized on their own, we find that it is important to consider\nthe coupling between detection and diagnosis components. Exploiting this\ncoupling allows us to develop an end-to-end system that has higher and more\nrobust performance and eliminates the need for a nodule detection false\npositive reduction stage. Furthermore, we characterize model uncertainty in our\ndeep learning systems, a first for lung CT analysis, and show that we can use\nthis to provide well-calibrated classification probabilities for both nodule\ndetection and patient malignancy diagnosis. These calibrated probabilities\ninformed by model uncertainty can be used for subsequent risk-based decision\nmaking towards diagnostic interventions or disease treatments, as we\ndemonstrate using a probability-based patient referral strategy to further\nimprove our results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 18:53:27 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 01:03:32 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 02:27:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ozdemir", "Onur", ""], ["Russell", "Rebecca L.", ""], ["Berlin", "Andrew A.", ""]]}, {"id": "1902.03240", "submitter": "Harjot Singh Parmar", "authors": "Harjot Singh Parmar", "title": "Land Use Classification Using Multi-neighborhood LBPs", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we propose the use of multiple local binary patterns(LBPs) to\neffectively classify land use images. We use the UC Merced 21 class land use\nimage dataset. Task is challenging for classification as the dataset contains\nintra class variability and inter class similarities. Our proposed method of\nusing multi-neighborhood LBPs combined with nearest neighbor classifier is able\nto achieve an accuracy of 77.76%. Further class wise analysis is conducted and\nsuitable suggestion are made for further improvements to classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 23:37:27 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Parmar", "Harjot Singh", ""]]}, {"id": "1902.03249", "submitter": "Mitchell Stern", "authors": "Mitchell Stern, William Chan, Jamie Kiros, Jakob Uszkoreit", "title": "Insertion Transformer: Flexible Sequence Generation via Insertion\n  Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Insertion Transformer, an iterative, partially autoregressive\nmodel for sequence generation based on insertion operations. Unlike typical\nautoregressive models which rely on a fixed, often left-to-right ordering of\nthe output, our approach accommodates arbitrary orderings by allowing for\ntokens to be inserted anywhere in the sequence during decoding. This\nflexibility confers a number of advantages: for instance, not only can our\nmodel be trained to follow specific orderings such as left-to-right generation\nor a binary tree traversal, but it can also be trained to maximize entropy over\nall valid insertions for robustness. In addition, our model seamlessly\naccommodates both fully autoregressive generation (one insertion at a time) and\npartially autoregressive generation (simultaneous insertions at multiple\nlocations). We validate our approach by analyzing its performance on the WMT\n2014 English-German machine translation task under various settings for\ntraining and decoding. We find that the Insertion Transformer outperforms many\nprior non-autoregressive approaches to translation at comparable or better\nlevels of parallelism, and successfully recovers the performance of the\noriginal Transformer while requiring only logarithmically many iterations\nduring decoding.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:00:04 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Stern", "Mitchell", ""], ["Chan", "William", ""], ["Kiros", "Jamie", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1902.03251", "submitter": "Ilya Feige", "authors": "Ilya Feige", "title": "Invariant-equivariant representation learning for multi-class data", "comments": "8 pages, 5 figures, 2 tables, 2 appendices", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations learnt through deep neural networks tend to be highly\ninformative, but opaque in terms of what information they learn to encode. We\nintroduce an approach to probabilistic modelling that learns to represent data\nwith two separate deep representations: an invariant representation that\nencodes the information of the class from which the data belongs, and an\nequivariant representation that encodes the symmetry transformation defining\nthe particular data point within the class manifold (equivariant in the sense\nthat the representation varies naturally with symmetry transformations). This\napproach is based primarily on the strategic routing of data through the two\nlatent variables, and thus is conceptually transparent, easy to implement, and\nin-principle generally applicable to any data comprised of discrete classes of\ncontinuous distributions (e.g. objects in images, topics in language,\nindividuals in behavioural data). We demonstrate qualitatively compelling\nrepresentation learning and competitive quantitative performance, in both\nsupervised and semi-supervised settings, versus comparable modelling approaches\nin the literature with little fine tuning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:01:13 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:03:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Feige", "Ilya", ""]]}, {"id": "1902.03253", "submitter": "Alceu Emanuel Bissoto", "authors": "Alceu Bissoto, F\\'abio Perez, Eduardo Valle and Sandra Avila", "title": "Skin Lesion Synthesis with Generative Adversarial Networks", "comments": "Conference: ISIC Skin Image Analysis Workshop and Challenge @ MICCAI\n  2018", "journal-ref": null, "doi": "10.1007/978-3-030-01201-4_32", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is by far the most common type of cancer. Early detection is the\nkey to increase the chances for successful treatment significantly. Currently,\nDeep Neural Networks are the state-of-the-art results on automated skin cancer\nclassification. To push the results further, we need to address the lack of\nannotated data, which is expensive and require much effort from specialists. To\nbypass this problem, we propose using Generative Adversarial Networks for\ngenerating realistic synthetic skin lesion images. To the best of our\nknowledge, our results are the first to show visually-appealing synthetic\nimages that comprise clinically-meaningful information.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:03:41 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Bissoto", "Alceu", ""], ["Perez", "F\u00e1bio", ""], ["Valle", "Eduardo", ""], ["Avila", "Sandra", ""]]}, {"id": "1902.03264", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Jiahui Yu, Nebojsa Jojic, Jun Huan, Thomas S. Huang", "title": "FSNet: Compression of Deep Convolutional Neural Networks by Filter\n  Summary", "comments": "published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method of compression of deep Convolutional Neural\nNetworks (CNNs) by weight sharing through a new representation of convolutional\nfilters. The proposed method reduces the number of parameters of each\nconvolutional layer by learning a 1D vector termed Filter Summary (FS). The\nconvolutional filters are located in FS as overlapping 1D segments, and nearby\nfilters in FS share weights in their overlapping regions in a natural way. The\nresultant neural network based on such weight sharing scheme, termed Filter\nSummary CNNs or FSNet, has a FS in each convolution layer instead of a set of\nindependent filters in the conventional convolution layer. FSNet has the same\narchitecture as that of the baseline CNN to be compressed, and each convolution\nlayer of FSNet has the same number of filters from FS as that of the basline\nCNN in the forward process. With compelling computational acceleration ratio,\nthe parameter space of FSNet is much smaller than that of the baseline CNN. In\naddition, FSNet is quantization friendly. FSNet with weight quantization leads\nto even higher compression ratio without noticeable performance loss. We\nfurther propose Differentiable FSNet where the way filters share weights is\nlearned in a differentiable and end-to-end manner. Experiments demonstrate the\neffectiveness of FSNet in compression of CNNs for computer vision tasks\nincluding image classification and object detection, and the effectiveness of\nDFSNet is evidenced by the task of Neural Architecture Search.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:26:46 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 21:20:09 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 08:35:40 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Yang", "Yingzhen", ""], ["Yu", "Jiahui", ""], ["Jojic", "Nebojsa", ""], ["Huan", "Jun", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1902.03266", "submitter": "Arjun Seshadri", "authors": "Arjun Seshadri, Alexander Peysakhovich, Johan Ugander", "title": "Discovering Context Effects from Raw Choice Data", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications in preference learning assume that decisions come from the\nmaximization of a stable utility function. Yet a large experimental literature\nshows that individual choices and judgements can be affected by \"irrelevant\"\naspects of the context in which they are made. An important class of such\ncontexts is the composition of the choice set. In this work, our goal is to\ndiscover such choice set effects from raw choice data. We introduce an\nextension of the Multinomial Logit (MNL) model, called the context dependent\nrandom utility model (CDM), which allows for a particular class of choice set\neffects. We show that the CDM can be thought of as a second-order approximation\nto a general choice system, can be inferred optimally using maximum likelihood\nand, importantly, is easily interpretable. We apply the CDM to both real and\nsimulated choice data to perform principled exploratory analyses for the\npresence of choice set effects.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:37:00 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 20:30:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Seshadri", "Arjun", ""], ["Peysakhovich", "Alexander", ""], ["Ugander", "Johan", ""]]}, {"id": "1902.03272", "submitter": "Michael Lingzhi Li", "authors": "Dimitris Bertsimas, Michael Lingzhi Li", "title": "Scalable Holistic Linear Regression", "comments": "Accepted by Operation Research Letters", "journal-ref": null, "doi": "10.1016/j.orl.2020.02.008", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scalable algorithm for holistic linear regression building\non Bertsimas & King (2016). Specifically, we develop new theory to model\nsignificance and multicollinearity as lazy constraints rather than checking the\nconditions iteratively. The resulting algorithm scales with the number of\nsamples $n$ in the 10,000s, compared to the low 100s in the previous framework.\nComputational results on real and synthetic datasets show it greatly improves\nfrom previous algorithms in accuracy, false detection rate, computational time\nand scalability.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:01:47 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 00:05:23 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Li", "Michael Lingzhi", ""]]}, {"id": "1902.03273", "submitter": "Nicolas Troquard", "authors": "Ana Ozaki and Nicolas Troquard", "title": "Learning Ontologies with Epistemic Reasoning: The EL Case", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning description logic ontologies from\nentailments via queries, using epistemic reasoning. We introduce a new learning\nmodel consisting of epistemic membership and example queries and show that\npolynomial learnability in this model coincides with polynomial learnability in\nAngluin's exact learning model with membership and equivalence queries. We then\ninstantiate our learning framework to EL and show some complexity results for\nan epistemic extension of EL where epistemic operators can be applied over the\naxioms. Finally, we transfer known results for EL ontologies and its fragments\nto our learning model based on epistemic reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:06:36 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ozaki", "Ana", ""], ["Troquard", "Nicolas", ""]]}, {"id": "1902.03283", "submitter": "Bruna Wundervald", "authors": "Bruna D. Wundervald, Walmes M. Zeviani", "title": "Machine learning and chord based feature engineering for genre\n  prediction in popular Brazilian music", "comments": "10 pages, 10 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre can be hard to describe: many factors are involved, such as\nstyle, music technique, and historical context. Some genres even have\noverlapping characteristics. Looking for a better understanding of how music\ngenres are related to musical harmonic structures, we gathered data about the\nmusic chords for thousands of popular Brazilian songs. Here, 'popular' does not\nonly refer to the genre named MPB (Brazilian Popular Music) but to nine\ndifferent genres that were considered particular to the Brazilian case. The\nmain goals of the present work are to extract and engineer harmonically related\nfeatures from chords data and to use it to classify popular Brazilian music\ngenres towards establishing a connection between harmonic relationships and\nBrazilian genres. We also emphasize the generalization of the method for\nobtaining the data, allowing for the replication and direct extension of this\nwork. Our final model is a combination of multiple classification trees, also\nknown as the random forest model. We found that features extracted from\nharmonic elements can satisfactorily predict music genre for the Brazilian\ncase, as well as features obtained from the Spotify API. The variables\nconsidered in this work also give an intuition about how they relate to the\ngenres.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:38:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wundervald", "Bruna D.", ""], ["Zeviani", "Walmes M.", ""]]}, {"id": "1902.03306", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Isgr\\`o, Roberto Prevete", "title": "A simple and efficient architecture for trainable activation functions", "comments": null, "journal-ref": "Neurocomputing 370 (2019) 1-15", "doi": "10.1016/j.neucom.2019.08.065", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning automatically the best activation function for the task is an active\ntopic in neural network research. At the moment, despite promising results, it\nis still difficult to determine a method for learning an activation function\nthat is at the same time theoretically simple and easy to implement. Moreover,\nmost of the methods proposed so far introduce new parameters or adopt different\nlearning techniques. In this work we propose a simple method to obtain trained\nactivation function which adds to the neural network local subnetworks with a\nsmall amount of neurons. Experiments show that this approach could lead to\nbetter result with respect to using a pre-defined activation function, without\nintroducing a large amount of extra parameters that need to be learned.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 22:13:54 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 14:13:06 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Apicella", "Andrea", ""], ["Isgr\u00f2", "Francesco", ""], ["Prevete", "Roberto", ""]]}, {"id": "1902.03326", "submitter": "Bhav Ashok", "authors": "Anubhav Ashok", "title": "Architecture Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach to model compression termed\nArchitecture Compression. Instead of operating on the weight or filter space of\nthe network like classical model compression methods, our approach operates on\nthe architecture space. A 1-D CNN encoder-decoder is trained to learn a mapping\nfrom discrete architecture space to a continuous embedding and back.\nAdditionally, this embedding is jointly trained to regress accuracy and\nparameter count in order to incorporate information about the architecture's\neffectiveness on the dataset. During the compression phase, we first encode the\nnetwork and then perform gradient descent in continuous space to optimize a\ncompression objective function that maximizes accuracy and minimizes parameter\ncount. The final continuous feature is then mapped to a discrete architecture\nusing the decoder. We demonstrate the merits of this approach on visual\nrecognition tasks such as CIFAR-10, CIFAR-100, Fashion-MNIST and SVHN and\nachieve a greater than 20x compression on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 23:26:12 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 08:42:42 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 09:10:49 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Ashok", "Anubhav", ""]]}, {"id": "1902.03327", "submitter": "Jelena Bradic", "authors": "Alexander Hanbo Li, Jelena Bradic", "title": "Censored Quantile Regression Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are powerful non-parametric regression method but are severely\nlimited in their usage in the presence of randomly censored observations, and\nnaively applied can exhibit poor predictive performance due to the incurred\nbiases. Based on a local adaptive representation of random forests, we develop\nits regression adjustment for randomly censored regression quantile models.\nRegression adjustment is based on new estimating equations that adapt to\ncensoring and lead to quantile score whenever the data do not exhibit\ncensoring. The proposed procedure named censored quantile regression forest,\nallows us to estimate quantiles of time-to-event without any parametric\nmodeling assumption. We establish its consistency under mild model\nspecifications. Numerical studies showcase a clear advantage of the proposed\nprocedure.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 23:29:50 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Bradic", "Jelena", ""]]}, {"id": "1902.03336", "submitter": "Andrew Ferguson", "authors": "Wei Chen, Hythem Sidky, Andrew L Ferguson", "title": "Nonlinear Discovery of Slow Molecular Modes using State-Free Reversible\n  VAMPnets", "comments": null, "journal-ref": null, "doi": "10.1063/1.5092521", "report-no": null, "categories": "stat.ML cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of enhanced sampling molecular simulations that accelerate along\ncollective variables (CVs) is predicated on the availability of variables\ncoincident with the slow collective motions governing the long-time\nconformational dynamics of a system. It is challenging to intuit these slow CVs\nfor all but the simplest molecular systems, and their data-driven discovery\ndirectly from molecular simulation trajectories has been a central focus of the\nmolecular simulation community to both unveil the important physical mechanisms\nand to drive enhanced sampling. In this work, we introduce state-free\nreversible VAMPnets (SRV) as a deep learning architecture that learns nonlinear\nCV approximants to the leading slow eigenfunctions of the spectral\ndecomposition of the transfer operator that evolves equilibrium-scaled\nprobability distributions through time. Orthogonality of the learned CVs is\nnaturally imposed within network training without added regularization. The CVs\nare inherently explicit and differentiable functions of the input coordinates\nmaking them well-suited to use in enhanced sampling calculations. We\ndemonstrate the utility of SRVs in capturing parsimonious nonlinear\nrepresentations of complex system dynamics in applications to 1D and 2D toy\nsystems where the true eigenfunctions are exactly calculable and to molecular\ndynamics simulations of alanine dipeptide and the WW domain protein.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 00:17:47 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 02:02:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Wei", ""], ["Sidky", "Hythem", ""], ["Ferguson", "Andrew L", ""]]}, {"id": "1902.03350", "submitter": "Nicholas James Mr", "authors": "Nick James, Roman Marchant, Richard Gerlach, Sally Cripps", "title": "Bayesian Nonparametric Adaptive Spectral Density Estimation for\n  Financial Time Series", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination between non-stationarity and long-range dependency is a\ndifficult and long-standing issue in modelling financial time series. This\npaper uses an adaptive spectral technique which jointly models the\nnon-stationarity and dependency of financial time series in a non-parametric\nfashion assuming that the time series consists of a finite, but unknown number,\nof locally stationary processes, the locations of which are also unknown. The\nmodel allows a non-parametric estimate of the dependency structure by modelling\nthe auto-covariance function in the spectral domain. All our estimates are made\nwithin a Bayesian framework where we use aReversible Jump Markov Chain Monte\nCarlo algorithm for inference. We study the frequentist properties of our\nestimates via a simulation study, and present a novel way of generating time\nseries data from a nonparametric spectrum. Results indicate that our techniques\nperform well across a range of data generating processes. We apply our method\nto a number of real examples and our results indicate that several financial\ntime series exhibit both long-range dependency and non-stationarity.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 01:58:48 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["James", "Nick", ""], ["Marchant", "Roman", ""], ["Gerlach", "Richard", ""], ["Cripps", "Sally", ""]]}, {"id": "1902.03355", "submitter": "Panayotis Mertikopoulos", "authors": "Radu Ioan Bot and Panayotis Mertikopoulos and Mathias Staudigl and\n  Phan Tu Vuong", "title": "Forward-backward-forward methods with variance reduction for stochastic\n  variational inequalities", "comments": "34 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new stochastic algorithm with variance reduction for solving\npseudo-monotone stochastic variational inequalities. Our method builds on\nTseng's forward-backward-forward (FBF) algorithm, which is known in the\ndeterministic literature to be a valuable alternative to Korpelevich's\nextragradient method when solving variational inequalities over a convex and\nclosed set governed by pseudo-monotone, Lipschitz continuous operators. The\nmain computational advantage of Tseng's algorithm is that it relies only on a\nsingle projection step and two independent queries of a stochastic oracle. Our\nalgorithm incorporates a variance reduction mechanism and leads to almost sure\n(a.s.) convergence to an optimal solution. To the best of our knowledge, this\nis the first stochastic look-ahead algorithm achieving this by using only a\nsingle projection at each iteration..\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 02:32:53 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Bot", "Radu Ioan", ""], ["Mertikopoulos", "Panayotis", ""], ["Staudigl", "Mathias", ""], ["Vuong", "Phan Tu", ""]]}, {"id": "1902.03356", "submitter": "Eunbyung Park", "authors": "Eunbyung Park, Junier B. Oliva", "title": "Meta-Curvature", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose meta-curvature (MC), a framework to learn curvature information\nfor better generalization and fast model adaptation. MC expands on the\nmodel-agnostic meta-learner (MAML) by learning to transform the gradients in\nthe inner optimization such that the transformed gradients achieve better\ngeneralization performance to a new task. For training large scale neural\nnetworks, we decompose the curvature matrix into smaller matrices in a novel\nscheme where we capture the dependencies of the model's parameters with a\nseries of tensor products. We demonstrate the effects of our proposed method on\nseveral few-shot learning tasks and datasets. Without any task specific\ntechniques and architectures, the proposed method achieves substantial\nimprovement upon previous MAML variants and outperforms the recent\nstate-of-the-art methods. Furthermore, we observe faster convergence rates of\nthe meta-training process. Finally, we present an analysis that explains better\ngeneralization performance with the meta-trained curvature.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 02:34:53 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 05:06:57 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 06:57:55 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Park", "Eunbyung", ""], ["Oliva", "Junier B.", ""]]}, {"id": "1902.03361", "submitter": "Houpu Yao", "authors": "Houpu Yao, Malcolm Regan, Yezhou Yang, Yi Ren", "title": "Image Decomposition and Classification through a Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate in this paper that a generative model can be designed to\nperform classification tasks under challenging settings, including adversarial\nattacks and input distribution shifts. Specifically, we propose a conditional\nvariational autoencoder that learns both the decomposition of inputs and the\ndistributions of the resulting components. During test, we jointly optimize the\nlatent variables of the generator and the relaxed component labels to find the\nbest match between the given input and the output of the generator. The model\ndemonstrates promising performance at recognizing overlapping components from\nthe multiMNIST dataset, and novel component combinations from a traffic sign\ndataset. Experiments also show that the proposed model achieves high robustness\non MNIST and NORB datasets, in particular for high-strength gradient attacks\nand non-gradient attacks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 02:40:04 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yao", "Houpu", ""], ["Regan", "Malcolm", ""], ["Yang", "Yezhou", ""], ["Ren", "Yi", ""]]}, {"id": "1902.03362", "submitter": "Xu Dong", "authors": "Xu Dong, Swapnil Vekhande, Guohua Cao", "title": "Sinogram interpolation for sparse-view micro-CT with deep learning\n  neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sparse-view Computed Tomography (CT), only a small number of projection\nimages are taken around the object, and sinogram interpolation method has a\nsignificant impact on final image quality. When the amount of sparsity (the\namount of missing views in sinogram data) is not high, conventional\ninterpolation methods have yielded good results. When the amount of sparsity is\nhigh, more advanced sinogram interpolation methods are needed. Recently,\nseveral deep learning (DL) based sinogram interpolation methods have been\nproposed. However, those DL-based methods have mostly tested so far on computer\nsimulated sinogram data rather experimentally acquired sinogram data. In this\nstudy, we developed a sinogram interpolation method for sparse-view micro-CT\nbased on the combination of U-Net and residual learning. We applied the method\nto sinogram data obtained from sparse-view micro-CT experiments, where the\nsparsity reached 90%. The interpolated sinogram by the DL neural network was\nfed to FBP algorithm for reconstruction. The result shows that both RMSE and\nSSIM of CT image are greatly improved. The experimental results demonstrate\nthat this sinogram interpolation method produce significantly better results\nover standard linear interpolation methods when the sinogram data are extremely\nsparse.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 02:46:12 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 19:48:49 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Dong", "Xu", ""], ["Vekhande", "Swapnil", ""], ["Cao", "Guohua", ""]]}, {"id": "1902.03373", "submitter": "Lijun Ding", "authors": "Lijun Ding, Alp Yurtsever, Volkan Cevher, Joel A. Tropp and Madeleine\n  Udell", "title": "An Optimal-Storage Approach to Semidefinite Programming using\n  Approximate Complementarity", "comments": "35 pages, 24 pages of main text, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new storage-optimal algorithm that provably solves\ngeneric semidefinite programs (SDPs) in standard form. This method is\nparticularly effective for weakly constrained SDPs. The key idea is to\nformulate an approximate complementarity principle: Given an approximate\nsolution to the dual SDP, the primal SDP has an approximate solution whose\nrange is contained in the eigenspace with small eigenvalues of the dual slack\nmatrix. For weakly constrained SDPs, this eigenspace has very low dimension, so\nthis observation significantly reduces the search space for the primal\nsolution.\n  This result suggests an algorithmic strategy that can be implemented with\nminimal storage:\n  (1) Solve the dual SDP approximately;\n  (2) compress the primal SDP to the eigenspace with small eigenvalues of the\ndual slack matrix;\n  (3) solve the compressed primal SDP.\n  The paper also provides numerical experiments showing that this approach is\nsuccessful for a range of interesting large-scale SDPs.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 05:03:00 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 21:19:52 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Ding", "Lijun", ""], ["Yurtsever", "Alp", ""], ["Cevher", "Volkan", ""], ["Tropp", "Joel A.", ""], ["Udell", "Madeleine", ""]]}, {"id": "1902.03376", "submitter": "Yu Cheng", "authors": "Zihao Zhu, Changchang Yin, Buyue Qian, Yu Cheng, Jishang Wei, Fei Wang", "title": "Measuring Patient Similarities via a Deep Architecture with Medical\n  Concept Embedding", "comments": "Published in ICDM 2016, arXiv version. Code link is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the clinical similarities between pairwise patients is a\nfundamental problem in healthcare informatics. A proper patient similarity\nmeasure enables various downstream applications, such as cohort study and\ntreatment comparative effectiveness research. One major carrier for conducting\npatient similarity research is Electronic Health Records(EHRs), which are\nusually heterogeneous, longitudinal, and sparse. Though existing studies on\nlearning patient similarity from EHRs have shown being useful in solving real\nclinical problems, their applicability is limited due to the lack of medical\ninterpretations. Moreover, most previous methods assume a vector-based\nrepresentation for patients, which typically requires aggregation of medical\nevents over a certain time period. As a consequence, temporal information will\nbe lost. In this paper, we propose a patient similarity evaluation framework\nbased on the temporal matching of longitudinal patient EHRs. Two efficient\nmethods are presented, unsupervised and supervised, both of which preserve the\ntemporal properties in EHRs. The supervised scheme takes a convolutional neural\nnetwork architecture and learns an optimal representation of patient clinical\nrecords with medical concept embedding. The empirical results on real-world\nclinical data demonstrate substantial improvement over the baselines. We make\nour code and sample data available for further study.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 05:36:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhu", "Zihao", ""], ["Yin", "Changchang", ""], ["Qian", "Buyue", ""], ["Cheng", "Yu", ""], ["Wei", "Jishang", ""], ["Wang", "Fei", ""]]}, {"id": "1902.03380", "submitter": "C. H. Huck Yang", "authors": "Chao-Han Huck Yang, Yi-Chieh Liu, Pin-Yu Chen, Xiaoli Ma, Yi-Chang\n  James Tsai", "title": "When Causal Intervention Meets Adversarial Examples and Image Masking\n  for Deep Neural Networks", "comments": "Noted our camera-ready version has changed the title. \"When Causal\n  Intervention Meets Adversarial Examples and Image Masking for Deep Neural\n  Networks\" as the v3 official paper title in IEEE Proceeding. Please use it in\n  your formal reference. Accepted at IEEE ICIP 2019. Pytorch code has released\n  on https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg", "journal-ref": "2019 26th IEEE International Conference on Image Processing\n  (ICIP). IEEE", "doi": null, "report-no": "pages={3811--3815}", "categories": "cs.CV cs.AI cs.LG cs.SC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Discovering and exploiting the causality in deep neural networks (DNNs) are\ncrucial challenges for understanding and reasoning causal effects (CE) on an\nexplainable visual model. \"Intervention\" has been widely used for recognizing a\ncausal relation ontologically. In this paper, we propose a causal inference\nframework for visual reasoning via do-calculus. To study the intervention\neffects on pixel-level features for causal reasoning, we introduce pixel-wise\nmasking and adversarial perturbation. In our framework, CE is calculated using\nfeatures in a latent space and perturbed prediction from a DNN-based model. We\nfurther provide the first look into the characteristics of discovered CE of\nadversarially perturbed images generated by gradient-based methods\n\\footnote{~~https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg}.\nExperimental results show that CE is a competitive and robust index for\nunderstanding DNNs when compared with conventional methods such as\nclass-activation mappings (CAMs) on the Chest X-Ray-14 dataset for\nhuman-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds\npromises for detecting adversarial examples as it possesses distinct\ncharacteristics in the presence of adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 06:44:13 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 19:11:24 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 15:07:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Liu", "Yi-Chieh", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Tsai", "Yi-Chang James", ""]]}, {"id": "1902.03389", "submitter": "Yuki Saito", "authors": "Hiroki Tamaru, Yuki Saito, Shinnosuke Takamichi, Tomoki Koriyama,\n  Hiroshi Saruwatari", "title": "Generative Moment Matching Network-based Random Modulation Post-filter\n  for DNN-based Singing Voice Synthesis and Neural Double-tracking", "comments": "5 pages, to appear in IEEE ICASSP 2019 (Paper Code: SLP-P22.11,\n  Session: Speech Synthesis III)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.MM cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generative moment matching network (GMMN)-based\npost-filter that provides inter-utterance pitch variation for deep neural\nnetwork (DNN)-based singing voice synthesis. The natural pitch variation of a\nhuman singing voice leads to a richer musical experience and is used in\ndouble-tracking, a recording method in which two performances of the same\nphrase are recorded and mixed to create a richer, layered sound. However,\nsinging voices synthesized using conventional DNN-based methods never vary\nbecause the synthesis process is deterministic and only one waveform is\nsynthesized from one musical score. To address this problem, we use a GMMN to\nmodel the variation of the modulation spectrum of the pitch contour of natural\nsinging voices and add a randomized inter-utterance variation to the pitch\ncontour generated by conventional DNN-based singing voice synthesis.\nExperimental evaluations suggest that 1) our approach can provide perceptible\ninter-utterance pitch variation while preserving speech quality. We extend our\napproach to double-tracking, and the evaluation demonstrates that 2) GMMN-based\nneural double-tracking is perceptually closer to natural double-tracking than\nconventional signal processing-based artificial double-tracking is.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 07:49:42 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Tamaru", "Hiroki", ""], ["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Koriyama", "Tomoki", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1902.03393", "submitter": "Mehrdad Farajtabar", "authors": "Seyed-Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro\n  Matsukawa, Hassan Ghasemzadeh", "title": "Improved Knowledge Distillation via Teacher Assistant", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that deep neural networks are powerful models and achieve\nappealing results on many tasks, they are too large to be deployed on edge\ndevices like smartphones or embedded sensor nodes. There have been efforts to\ncompress these networks, and a popular method is knowledge distillation, where\na large (teacher) pre-trained network is used to train a smaller (student)\nnetwork. However, in this paper, we show that the student network performance\ndegrades when the gap between student and teacher is large. Given a fixed\nstudent network, one cannot employ an arbitrarily large teacher, or in other\nwords, a teacher can effectively transfer its knowledge to students up to a\ncertain size, not smaller. To alleviate this shortcoming, we introduce\nmulti-step knowledge distillation, which employs an intermediate-sized network\n(teacher assistant) to bridge the gap between the student and the teacher.\nMoreover, we study the effect of teacher assistant size and extend the\nframework to multi-step distillation. Theoretical analysis and extensive\nexperiments on CIFAR-10,100 and ImageNet datasets and on CNN and ResNet\narchitectures substantiate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 09:06:01 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 01:11:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mirzadeh", "Seyed-Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Li", "Ang", ""], ["Levine", "Nir", ""], ["Matsukawa", "Akihiro", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1902.03394", "submitter": "Lei Li", "authors": "Lei Li and Yingzhou Li and Jian-Guo Liu and Zibu Liu and Jianfeng Lu", "title": "A stochastic version of Stein Variational Gradient Descent for efficient\n  sampling", "comments": null, "journal-ref": "Commun. Appl. Math. Comput. Sci. 15 (2020) 37-63", "doi": "10.2140/camcos.2020.15.37", "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this work RBM-SVGD, a stochastic version of Stein Variational\nGradient Descent (SVGD) method for efficiently sampling from a given\nprobability measure and thus useful for Bayesian inference. The method is to\napply the Random Batch Method (RBM) for interacting particle systems proposed\nby Jin et al to the interacting particle systems in SVGD. While keeping the\nbehaviors of SVGD, it reduces the computational cost, especially when the\ninteracting kernel has long range. Numerical examples verify the efficiency of\nthis new version of SVGD.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 09:22:24 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 00:48:19 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Lei", ""], ["Li", "Yingzhou", ""], ["Liu", "Jian-Guo", ""], ["Liu", "Zibu", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1902.03427", "submitter": "Felipe Tobar", "authors": "Cristobal Valenzuela and Felipe Tobar", "title": "Low-pass filtering as Bayesian inference", "comments": "Accepted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian nonparametric method for low-pass filtering that can\nnaturally handle unevenly-sampled and noise-corrupted observations. The\nproposed model is constructed as a latent-factor model for time series, where\nthe latent factors are Gaussian processes with non-overlapping spectra. With\nthis construction, the low-pass version of the time series can be identified as\nthe low-frequency latent component, and therefore it can be found by means of\nBayesian inference. We show that the model admits exact training and can be\nimplemented with minimal numerical approximations. Finally, the proposed model\nis validated against standard linear filters on synthetic and real-world time\nseries.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 14:09:32 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Valenzuela", "Cristobal", ""], ["Tobar", "Felipe", ""]]}, {"id": "1902.03429", "submitter": "Yu Zong Chen", "authors": "Chu Qin, Ying Tan, Shang Ying Chen, Xian Zeng, Xingxing Qi, Tian Jin,\n  Huan Shi, Yiwei Wan, Yu Chen, Jingfeng Li, Weidong He, Yali Wang, Peng Zhang,\n  Feng Zhu, Hongping Zhao, Yuyang Jiang, Yuzong Chen", "title": "Clustering Bioactive Molecules in 3D Chemical Space with Unsupervised\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised clustering has broad applications in data stratification,\npattern investigation and new discovery beyond existing knowledge. In\nparticular, clustering of bioactive molecules facilitates chemical space\nmapping, structure-activity studies, and drug discovery. These tasks,\nconventionally conducted by similarity-based methods, are complicated by data\ncomplexity and diversity. We ex-plored the superior learning capability of deep\nautoencoders for unsupervised clustering of 1.39 mil-lion bioactive molecules\ninto band-clusters in a 3-dimensional latent chemical space. These\nband-clusters, displayed by a space-navigation simulation software, band\nmolecules of selected bioactivity classes into individual band-clusters\npossessing unique sets of common sub-structural features beyond structural\nsimilarity. These sub-structural features form the frameworks of the\nliterature-reported pharmacophores and privileged fragments. Within each\nband-cluster, molecules are further banded into selected sub-regions with\nrespect to their bioactivity target, sub-structural features and molecular\nscaffolds. Our method is potentially applicable for big data clustering tasks\nof different fields.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 14:31:09 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Qin", "Chu", ""], ["Tan", "Ying", ""], ["Chen", "Shang Ying", ""], ["Zeng", "Xian", ""], ["Qi", "Xingxing", ""], ["Jin", "Tian", ""], ["Shi", "Huan", ""], ["Wan", "Yiwei", ""], ["Chen", "Yu", ""], ["Li", "Jingfeng", ""], ["He", "Weidong", ""], ["Wang", "Yali", ""], ["Zhang", "Peng", ""], ["Zhu", "Feng", ""], ["Zhao", "Hongping", ""], ["Jiang", "Yuyang", ""], ["Chen", "Yuzong", ""]]}, {"id": "1902.03440", "submitter": "James Tan", "authors": "James P.L. Tan", "title": "Simulating extrapolated dynamics with parameterization networks", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An artificial neural network architecture, parameterization networks, is\nproposed for simulating extrapolated dynamics beyond observed data in dynamical\nsystems. Parameterization networks are used to ensure the long term integrity\nof extrapolated dynamics, while careful tuning of model hyperparameters against\nvalidation errors controls overfitting. A parameterization network is\ndemonstrated on the logistic map, where chaos and other nonlinear phenomena\nconsistent with the underlying model can be extrapolated from non-chaotic\ntraining time series with good fidelity. The stated results are a lot less\nfantastical than they appear to be because the neural network is only\nextrapolating between quadratic return maps. Nonetheless, the results do\nsuggest that successful extrapolation of qualitatively different behaviors\nrequires learning to occur on a level of abstraction where the corresponding\nbehaviors are more similar in nature.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 16:37:34 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Tan", "James P. L.", ""]]}, {"id": "1902.03442", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, Pavel Krizek, David Hurych, Ibrahim Sobh, Senthil\n  Yogamani and Patrick Denny", "title": "Yes, we GAN: Applying Adversarial Techniques for Autonomous Driving", "comments": "Accepted for publication in Electronic Imaging, Autonomous Vehicles\n  and Machines 2019. arXiv admin note: text overlap with arXiv:1606.05908 by\n  other authors", "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2019.15.AVM-048", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have gained a lot of popularity from\ntheir introduction in 2014 till present. Research on GAN is rapidly growing and\nthere are many variants of the original GAN focusing on various aspects of deep\nlearning. GAN are perceived as the most impactful direction of machine learning\nin the last decade. This paper focuses on the application of GAN in autonomous\ndriving including topics such as advanced data augmentation, loss function\nlearning, semi-supervised learning, etc. We formalize and review key\napplications of adversarial techniques and discuss challenges and open problems\nto be addressed.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 16:42:47 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 18:22:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Uricar", "Michal", ""], ["Krizek", "Pavel", ""], ["Hurych", "David", ""], ["Sobh", "Ibrahim", ""], ["Yogamani", "Senthil", ""], ["Denny", "Patrick", ""]]}, {"id": "1902.03444", "submitter": "Yasin Yaz{\\i}c{\\i}", "authors": "Yasin Yaz{\\i}c{\\i}, Bruno Lecouat, Chuan-Sheng Foo, Stefan Winkler,\n  Kim-Hui Yap, Georgios Piliouras, Vijay Chandrasekhar", "title": "Venn GAN: Discovering Commonalities and Particularities of Multiple\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a GAN design which models multiple distributions effectively and\ndiscovers their commonalities and particularities. Each data distribution is\nmodeled with a mixture of $K$ generator distributions. As the generators are\npartially shared between the modeling of different true data distributions,\nshared ones captures the commonality of the distributions, while non-shared\nones capture unique aspects of them. We show the effectiveness of our method on\nvarious datasets (MNIST, Fashion MNIST, CIFAR-10, Omniglot, CelebA) with\ncompelling results.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 16:57:17 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yaz\u0131c\u0131", "Yasin", ""], ["Lecouat", "Bruno", ""], ["Foo", "Chuan-Sheng", ""], ["Winkler", "Stefan", ""], ["Yap", "Kim-Hui", ""], ["Piliouras", "Georgios", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1902.03451", "submitter": "Adnane Boukhayma", "authors": "Adnane Boukhayma, Rodrigo de Bem, Philip H.S. Torr", "title": "3D Hand Shape and Pose from Images in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this work the first end-to-end deep learning based method that\npredicts both 3D hand shape and pose from RGB images in the wild. Our network\nconsists of the concatenation of a deep convolutional encoder, and a fixed\nmodel-based decoder. Given an input image, and optionally 2D joint detections\nobtained from an independent CNN, the encoder predicts a set of hand and view\nparameters. The decoder has two components: A pre-computed articulated mesh\ndeformation hand model that generates a 3D mesh from the hand parameters, and a\nre-projection module controlled by the view parameters that projects the\ngenerated hand into the image domain. We show that using the shape and pose\nprior knowledge encoded in the hand model within a deep learning framework\nyields state-of-the-art performance in 3D pose prediction from images on\nstandard benchmarks, and produces geometrically valid and plausible 3D\nreconstructions. Additionally, we show that training with weak supervision in\nthe form of 2D joint annotations on datasets of images in the wild, in\nconjunction with full supervision in the form of 3D joint annotations on\nlimited available datasets allows for good generalization to 3D shape and pose\npredictions on images in the wild.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 17:30:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Boukhayma", "Adnane", ""], ["de Bem", "Rodrigo", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1902.03453", "submitter": "Mostafa Razavi Ghods", "authors": "Mostafa Razavi Ghods, Mohammad Hossein Moattar, Yahya Forghani", "title": "Distance metric learning based on structural neighborhoods for\n  dimensionality reduction and classification performance improvement", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distance metric learning can be viewed as one of the fundamental interests in\npattern recognition and machine learning, which plays a pivotal role in the\nperformance of many learning methods. One of the effective methods in learning\nsuch a metric is to learn it from a set of labeled training samples. The issue\nof data imbalance is the most important challenge of recent methods. This\nresearch tries not only to preserve the local structures but also covers the\nissue of imbalanced datasets. To do this, the proposed method first tries to\nextract a low dimensional manifold from the input data. Then, it learns the\nlocal neighborhood structures and the relationship of the data points in the\nambient space based on the adjacencies of the same data points on the embedded\nlow dimensional manifold. Using the local neighborhood relationships extracted\nfrom the manifold space, the proposed method learns the distance metric in a\nway which minimizes the distance between similar data and maximizes their\ndistance from the dissimilar data points. The evaluations of the proposed\nmethod on numerous datasets from the UCI repository of machine learning, and\nalso the KDDCup98 dataset as the most imbalance dataset, justify the supremacy\nof the proposed approach in comparison with other approaches especially when\nthe imbalance factor is high.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 17:33:37 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 10:31:42 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ghods", "Mostafa Razavi", ""], ["Moattar", "Mohammad Hossein", ""], ["Forghani", "Yahya", ""]]}, {"id": "1902.03455", "submitter": "Sam Wenke", "authors": "Sam Wenke, Jim Fleming", "title": "Contextual Recurrent Neural Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an implicit assumption that by unfolding recurrent neural networks\n(RNN) in finite time, the misspecification of choosing a zero value for the\ninitial hidden state is mitigated by later time steps. This assumption has been\nshown to work in practice and alternative initialization may be suggested but\noften overlooked. In this paper, we propose a method of parameterizing the\ninitial hidden state of an RNN. The resulting architecture, referred to as a\nContextual RNN, can be trained end-to-end. The performance on an associative\nretrieval task is found to improve by conditioning the RNN initial hidden state\non contextual information from the input sequence. Furthermore, we propose a\nnovel method of conditionally generating sequences using the hidden state\nparameterization of Contextual RNN.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 17:41:56 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wenke", "Sam", ""], ["Fleming", "Jim", ""]]}, {"id": "1902.03466", "submitter": "Jos\\'e Solomon", "authors": "Jose Solomon and Francois Charette", "title": "Hierarchical Multi-task Deep Neural Network Architecture for End-to-End\n  Driving", "comments": "18 pages, 17 plots and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel hierarchical Deep Neural Network (DNN) model is presented to address\nthe task of end-to-end driving. The model consists of a master classifier\nnetwork which determines the driving task required from an input stereo image\nand directs said image to one of a set of subservient network regression models\nthat perform inference and output a steering command. These subservient\nnetworks are designed and trained for a specific driving task: straightaway,\nswerve maneuver, tight turn, gradual turn, and chicane. Using this modular\nnetwork strategy allows for two primary advantages: an overall reduction in the\namount of data required to train the complete system, and for model tailoring\nwhere more complex models can be used for more challenging tasks while\nsimplified networks can handle more mundane tasks. It is this latter facet of\nthe model that makes the approach attractive to a number of applications beyond\nthe current vehicle steering strategy.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 18:23:51 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 01:26:54 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Solomon", "Jose", ""], ["Charette", "Francois", ""]]}, {"id": "1902.03468", "submitter": "Roi Livni", "authors": "Olivier Bousquet and Roi Livni and Shay Moran", "title": "Synthetic Data Generators: Sequential and Private", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of private synthetic data generation over an\nunbounded sized class of statistical queries, and show that any class that is\nprivately proper PAC learnable admits a private synthetic data generator\n(perhaps non-efficient). Previous work on synthetic data generators focused on\nthe case that the query class $\\mathcal{D}$ is finite and obtained sample\ncomplexity bounds that scale logarithmically with the size $|\\mathcal{D}|$.\nHere we construct a private synthetic data generator whose sample complexity is\nindependent of the domain size, and we replace finiteness with the assumption\nthat $\\mathcal{D}$ is privately PAC learnable (a formally weaker task, hence we\nobtain equivalence between the two tasks).\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 18:35:39 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 09:15:13 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 04:50:03 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 09:45:10 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Bousquet", "Olivier", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""]]}, {"id": "1902.03475", "submitter": "Wouter Koolen", "authors": "R\\'emy Degenne, Wouter M. Koolen", "title": "Pure Exploration with Multiple Correct Answers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the sample complexity of pure exploration bandit problems with\nmultiple good answers. We derive a lower bound using a new game equilibrium\nargument. We show how continuity and convexity properties of single-answer\nproblems ensures that the Track-and-Stop algorithm has asymptotically optimal\nsample complexity. However, that convexity is lost when going to the\nmultiple-answer setting. We present a new algorithm which extends\nTrack-and-Stop to the multiple-answer case and has asymptotic sample complexity\nmatching the lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 19:08:22 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Degenne", "R\u00e9my", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "1902.03477", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Ruslan Salakhutdinov, Joshua B. Tenenbaum", "title": "The Omniglot challenge: a 3-year progress report", "comments": "In press at Current Opinion in Behavioral Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three years ago, we released the Omniglot dataset for one-shot learning,\nalong with five challenge tasks and a computational model that addresses these\ntasks. The model was not meant to be the final word on Omniglot; we hoped that\nthe community would build on our work and develop new approaches. In the time\nsince, we have been pleased to see wide adoption of the dataset. There has been\nnotable progress on one-shot classification, but researchers have adopted new\nsplits and procedures that make the task easier. There has been less progress\non the other four tasks. We conclude that recent approaches are still far from\nhuman-like concept learning on Omniglot, a challenge that requires performing\nmany tasks with a single model.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 19:13:31 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:01:27 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lake", "Brenden M.", ""], ["Salakhutdinov", "Ruslan", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1902.03489", "submitter": "Mohammad Habibi", "authors": "Mohammad Habibi, Ahmad Ayatollahi, Niyoosha Dallalazar, Ali Kermani", "title": "Lumen boundary detection using neutrosophic c-means in IVOCT images", "comments": "Accepted on knowledge_based engineering and innovation (KBEI 2019), 6\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel method for lumen boundary identification is proposed\nusing Neutrosophic c_means. This method clusters pixels of the intravascular\noptical coherence tomography image into several clusters using indeterminacy\nand Neutrosophic theory, which aims to detect the boundaries. Intravascular\noptical coherence tomography images are cross-sectional and high-resolution\nimages which are taken from the coronary arterial wall. Coronary Artery Disease\ncause a lot of death each year. The first step for diagnosing this kind of\ndiseases is to detect lumen boundary. Employing this approach, we obtained\n0.972, 0.019, 0.076 mm2, 0.32 mm, and 0.985 as mean value for Jaccard measure\n(JACC), the percentage of area difference (PAD), average distance (AD),\nHausdorff distance (HD), and dice index (DI), respectively. Based on our\nresults, this method enjoys high accuracy performance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:06:28 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 19:44:22 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Habibi", "Mohammad", ""], ["Ayatollahi", "Ahmad", ""], ["Dallalazar", "Niyoosha", ""], ["Kermani", "Ali", ""]]}, {"id": "1902.03493", "submitter": "Mohammad Tofighi", "authors": "Yuelong Li, Mohammad Tofighi, Junyi Geng, Vishal Monga, and Yonina C.\n  Eldar", "title": "Deep Algorithm Unrolling for Blind Image Deblurring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind image deblurring remains a topic of enduring interest. Learning based\napproaches, especially those that employ neural networks have emerged to\ncomplement traditional model based methods and in many cases achieve vastly\nenhanced performance. That said, neural network approaches are generally\nempirically designed and the underlying structures are difficult to interpret.\nIn recent years, a promising technique called algorithm unrolling has been\ndeveloped that has helped connect iterative algorithms such as those for sparse\ncoding to neural network architectures. However, such connections have not been\nmade yet for blind image deblurring. In this paper, we propose a neural network\narchitecture based on this idea. We first present an iterative algorithm that\nmay be considered as a generalization of the traditional total-variation\nregularization method in the gradient domain. We then unroll the algorithm to\nconstruct a neural network for image deblurring which we refer to as Deep\nUnrolling for Blind Deblurring (DUBLID). Key algorithm parameters are learned\nwith the help of training images. Our proposed deep network DUBLID achieves\nsignificant practical performance gains while enjoying interpretability at the\nsame time. Extensive experimental results show that DUBLID outperforms many\nstate-of-the-art methods and in addition is computationally faster.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:19:35 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 20:40:09 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 16:40:59 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Li", "Yuelong", ""], ["Tofighi", "Mohammad", ""], ["Geng", "Junyi", ""], ["Monga", "Vishal", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1902.03498", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Gil Kur, Ohad Shamir", "title": "Space lower bounds for linear prediction in the streaming model", "comments": "Added a minor correction in referencing the prior work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that fundamental learning tasks, such as finding an approximate\nlinear separator or linear regression, require memory at least \\emph{quadratic}\nin the dimension, in a natural streaming setting. This implies that such\nproblems cannot be solved (at least in this setting) by scalable\nmemory-efficient streaming algorithms. Our results build on a memory lower\nbound for a simple linear-algebraic problem -- finding orthogonal vectors --\nand utilize the estimates on the packing of the Grassmannian, the manifold of\nall linear subspaces of fixed dimension.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:44:40 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 01:54:32 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 23:33:58 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Dagan", "Yuval", ""], ["Kur", "Gil", ""], ["Shamir", "Ohad", ""]]}, {"id": "1902.03501", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sorelle A. Friedler, Carlos Scheidegger, and Chitradeep\n  Dutta Roy", "title": "Assessing the Local Interpretability of Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing adoption of machine learning tools has led to calls for\naccountability via model interpretability. But what does it mean for a machine\nlearning model to be interpretable by humans, and how can this be assessed? We\nfocus on two definitions of interpretability that have been introduced in the\nmachine learning literature: simulatability (a user's ability to run a model on\na given input) and \"what if\" local explainability (a user's ability to\ncorrectly determine a model's prediction under local changes to the input,\ngiven knowledge of the model's original prediction). Through a user study with\n1,000 participants, we test whether humans perform well on tasks that mimic the\ndefinitions of simulatability and \"what if\" local explainability on models that\nare typically considered locally interpretable. To track the relative\ninterpretability of models, we employ a simple metric, the runtime operation\ncount on the simulatability task. We find evidence that as the number of\noperations increases, participant accuracy on the local interpretability tasks\ndecreases. In addition, this evidence is consistent with the common intuition\nthat decision trees and logistic regression models are interpretable and are\nmore interpretable than neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:49:36 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 23:17:38 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Slack", "Dylan", ""], ["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Roy", "Chitradeep Dutta", ""]]}, {"id": "1902.03510", "submitter": "Xiaohui Yang", "authors": "Xiao-Hui Yang, Li Tian, Yun-Mei Chen, Li-Jun Yang, Shuang Xu, and\n  Wen-Ming Wu", "title": "Inverse Projection Representation and Category Contribution Rate for\n  Robust Tumor Recognition", "comments": "14 pages, 19 figures, 10 tables", "journal-ref": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2018", "doi": "10.1109/TCBB.2018.2886334", "report-no": null, "categories": "q-bio.QM cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representation based classification (SRC) methods have achieved\nremarkable results. SRC, however, still suffer from requiring enough training\nsamples, insufficient use of test samples and instability of representation. In\nthis paper, a stable inverse projection representation based classification\n(IPRC) is presented to tackle these problems by effectively using test samples.\nAn IPR is firstly proposed and its feasibility and stability are analyzed. A\nclassification criterion named category contribution rate is constructed to\nmatch the IPR and complete classification. Moreover, a statistical measure is\nintroduced to quantify the stability of representation-based classification\nmethods. Based on the IPRC technique, a robust tumor recognition framework is\npresented by interpreting microarray gene expression data, where a two-stage\nhybrid gene selection method is introduced to select informative genes.\nFinally, the functional analysis of candidate's pathogenicity-related genes is\ngiven. Extensive experiments on six public tumor microarray gene expression\ndatasets demonstrate the proposed technique is competitive with\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 23:07:22 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 04:07:28 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yang", "Xiao-Hui", ""], ["Tian", "Li", ""], ["Chen", "Yun-Mei", ""], ["Yang", "Li-Jun", ""], ["Xu", "Shuang", ""], ["Wu", "Wen-Ming", ""]]}, {"id": "1902.03511", "submitter": "Shashank Singh", "authors": "Ananya Uppal, Shashank Singh, Barnab\\'as P\\'oczos", "title": "Nonparametric Density Estimation & Convergence Rates for GANs under\n  Besov IPM Losses", "comments": "Advances in Neural Information Processing Systems. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a nonparametric probability density under\na large family of losses called Besov IPMs, which include, for example,\n$\\mathcal{L}^p$ distances, total variation distance, and generalizations of\nboth Wasserstein and Kolmogorov-Smirnov distances. For a wide variety of\nsettings, we provide both lower and upper bounds, identifying precisely how the\nchoice of loss function and assumptions on the data interact to determine the\nminimax optimal convergence rate. We also show that linear distribution\nestimates, such as the empirical distribution or kernel density estimator,\noften fail to converge at the optimal rate. Our bounds generalize, unify, or\nimprove several recent and classical results. Moreover, IPMs can be used to\nformalize a statistical model of generative adversarial networks (GANs). Thus,\nwe show how our results imply bounds on the statistical error of a GAN,\nshowing, for example, that GANs can strictly outperform the best linear\nestimator.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 23:24:43 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 20:02:36 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 20:29:19 GMT"}, {"version": "v4", "created": "Mon, 13 Jan 2020 15:12:33 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Uppal", "Ananya", ""], ["Singh", "Shashank", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1902.03515", "submitter": "Karren Yang", "authors": "Karren D. Yang, Caroline Uhler", "title": "Multi-Domain Translation by Learning Uncoupled Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain translation seeks to learn a probabilistic coupling between\nmarginal distributions that reflects the correspondence between different\ndomains. We assume that data from different domains are generated from a shared\nlatent representation based on a structural equation model. Under this\nassumption, we show that the problem of computing a probabilistic coupling\nbetween marginals is equivalent to learning multiple uncoupled autoencoders\nthat embed to a given shared latent distribution. In addition, we propose a new\nframework and algorithm for multi-domain translation based on learning the\nshared latent distribution and training autoencoders under distributional\nconstraints. A key practical advantage of our framework is that new\nautoencoders (i.e., new domains) can be added sequentially to the model without\nretraining on the other domains, which we demonstrate experimentally on image\nas well as genomics datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 23:46:22 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yang", "Karren D.", ""], ["Uhler", "Caroline", ""]]}, {"id": "1902.03517", "submitter": "Arnaud Fickinger", "authors": "Arnaud Fickinger", "title": "Biadversarial Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the original version of the Variational Autoencoder, Kingma et al. assume\nGaussian distributions for the approximate posterior during the inference and\nfor the output during the generative process. This assumptions are good for\ncomputational reasons, e.g. we can easily optimize the parameters of a neural\nnetwork using the reparametrization trick and the KL divergence between two\nGaussians can be computed in closed form. However it results in blurry images\ndue to its difficulty to represent multimodal distributions. We show that using\ntwo adversarial networks, we can optimize the parameters without any Gaussian\nassumptions.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 23:57:06 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:30:56 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Fickinger", "Arnaud", ""]]}, {"id": "1902.03519", "submitter": "Ali Vakilian", "authors": "Arturs Backurs, Piotr Indyk, Krzysztof Onak, Baruch Schieber, Ali\n  Vakilian, Tal Wagner", "title": "Scalable Fair Clustering", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fair variant of the classic $k$-median problem introduced by\nChierichetti et al. [2017]. In the standard $k$-median problem, given an input\npointset $P$, the goal is to find $k$ centers $C$ and assign each input point\nto one of the centers in $C$ such that the average distance of points to their\ncluster center is minimized.\n  In the fair variant of $k$-median, the points are colored, and the goal is to\nminimize the same average distance objective while ensuring that all clusters\nhave an \"approximately equal\" number of points of each color.\n  Chierichetti et al. proposed a two-phase algorithm for fair $k$-clustering.\nIn the first step, the pointset is partitioned into subsets called fairlets\nthat satisfy the fairness requirement and approximately preserve the $k$-median\nobjective. In the second step, fairlets are merged into $k$ clusters by one of\nthe existing $k$-median algorithms. The running time of this algorithm is\ndominated by the first step, which takes super-quadratic time.\n  In this paper, we present a practical approximate fairlet decomposition\nalgorithm that runs in nearly linear time. Our algorithm additionally allows\nfor finer control over the balance of resulting clusters than the original\nwork. We complement our theoretical bounds with empirical evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 00:04:34 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 18:19:34 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Backurs", "Arturs", ""], ["Indyk", "Piotr", ""], ["Onak", "Krzysztof", ""], ["Schieber", "Baruch", ""], ["Vakilian", "Ali", ""], ["Wagner", "Tal", ""]]}, {"id": "1902.03538", "submitter": "Shupeng Gui", "authors": "Shupeng Gui (1), Haotao Wang (2), Chen Yu (1), Haichuan Yang (1),\n  Zhangyang Wang (2) and Ji Liu (3) ((1) University of Rochester, (2) Texas A&M\n  University, (3) Ytech Seattle AI lab, FeDA lab, AI platform, Kwai Inc)", "title": "Model Compression with Adversarial Robustness: A Unified Optimization\n  Framework", "comments": "14 pages, NeurIPS 2019. The first two authors Gui and Wang\n  contributed equally and are listed alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep model compression has been extensively studied, and state-of-the-art\nmethods can now achieve high compression ratios with minimal accuracy loss.\nThis paper studies model compression through a different lens: could we\ncompress models without hurting their robustness to adversarial attacks, in\naddition to maintaining accuracy? Previous literature suggested that the goals\nof robustness and compactness might sometimes contradict. We propose a novel\nAdversarially Trained Model Compression (ATMC) framework. ATMC constructs a\nunified constrained optimization formulation, where existing compression means\n(pruning, factorization, quantization) are all integrated into the constraints.\nAn efficient algorithm is then developed. An extensive group of experiments are\npresented, demonstrating that ATMC obtains remarkably more favorable trade-off\namong model size, accuracy and robustness, over currently available\nalternatives in various settings. The codes are publicly available at:\nhttps://github.com/shupenggui/ATMC.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 04:55:44 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:55:01 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 21:23:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gui", "Shupeng", ""], ["Wang", "Haotao", ""], ["Yu", "Chen", ""], ["Yang", "Haichuan", ""], ["Wang", "Zhangyang", ""], ["Liu", "Ji", ""]]}, {"id": "1902.03544", "submitter": "Salimeh Yasaei Sekeh", "authors": "Salimeh Yasaei Sekeh and Alfred O. Hero", "title": "Feature Selection for multi-labeled variables via Dependency\n  Maximization", "comments": "5 pages, 3 Figures, 1 Table", "journal-ref": "ICASSP 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection and reducing the dimensionality of data is an essential\nstep in data analysis. In this work, we propose a new criterion for feature\nselection that is formulated as conditional information between features given\nthe labeled variable. Instead of using the standard mutual information measure\nbased on Kullback-Leibler divergence, we use our proposed criterion to filter\nout redundant features for the purpose of multiclass classification. This\napproach results in an efficient and fast non-parametric implementation of\nfeature selection as it can be directly estimated using a geometric measure of\ndependency, the global Friedman-Rafsky (FR) multivariate run test statistic\nconstructed by a global minimal spanning tree (MST). We demonstrate the\nadvantages of our proposed feature selection approach through simulation. In\naddition the proposed feature selection method is applied to the MNIST data\nset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 06:17:30 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 16:54:55 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 18:27:37 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Sekeh", "Salimeh Yasaei", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1902.03545", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran,\n  Subhransu Maji, Charless Fowlkes, Stefano Soatto, Pietro Perona", "title": "Task2Vec: Task Embedding for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to provide vectorial representations of visual\nclassification tasks which can be used to reason about the nature of those\ntasks and their relations. Given a dataset with ground-truth labels and a loss\nfunction defined over those labels, we process images through a \"probe network\"\nand compute an embedding based on estimates of the Fisher information matrix\nassociated with the probe network parameters. This provides a fixed-dimensional\nembedding of the task that is independent of details such as the number of\nclasses and does not require any understanding of the class label semantics. We\ndemonstrate that this embedding is capable of predicting task similarities that\nmatch our intuition about semantic and taxonomic relations between different\nvisual tasks (e.g., tasks based on classifying different types of plants are\nsimilar) We also demonstrate the practical value of this framework for the\nmeta-task of selecting a pre-trained feature extractor for a new task. We\npresent a simple meta-learning framework for learning a metric on embeddings\nthat is capable of predicting which feature extractors will perform well.\nSelecting a feature extractor with task embedding obtains a performance close\nto the best available feature extractor, while costing substantially less than\nexhaustively training and evaluating on all available feature extractors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 06:27:25 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Achille", "Alessandro", ""], ["Lam", "Michael", ""], ["Tewari", "Rahul", ""], ["Ravichandran", "Avinash", ""], ["Maji", "Subhransu", ""], ["Fowlkes", "Charless", ""], ["Soatto", "Stefano", ""], ["Perona", "Pietro", ""]]}, {"id": "1902.03569", "submitter": "Tom Tirer", "authors": "Oded Bialer, Noa Garnett and Tom Tirer", "title": "Performance Advantages of Deep Neural Networks for Angle of Arrival\n  Estimation", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the number of sources and their angles of arrival\nfrom a single antenna array observation has been an active area of research in\nthe signal processing community for the last few decades. When the number of\nsources is large, the maximum likelihood estimator is intractable due to its\nvery high complexity, and therefore alternative signal processing methods have\nbeen developed with some performance loss. In this paper, we apply a deep\nneural network (DNN) approach to the problem and analyze its advantages with\nrespect to signal processing algorithms. We show that an appropriate designed\nnetwork can attain the maximum likelihood performance with feasible complexity\nand outperform other feasible signal processing estimation methods over various\nsignal to noise ratios and array response inaccuracies.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 10:33:27 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 13:49:01 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Bialer", "Oded", ""], ["Garnett", "Noa", ""], ["Tirer", "Tom", ""]]}, {"id": "1902.03570", "submitter": "Deshraj Yadav", "authors": "Deshraj Yadav, Rishabh Jain, Harsh Agrawal, Prithvijit Chattopadhyay,\n  Taranjeet Singh, Akash Jain, Shiv Baran Singh, Stefan Lee, Dhruv Batra", "title": "EvalAI: Towards Better Evaluation Systems for AI Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EvalAI, an open source platform for evaluating and comparing\nmachine learning (ML) and artificial intelligence algorithms (AI) at scale.\nEvalAI is built to provide a scalable solution to the research community to\nfulfill the critical need of evaluating machine learning models and agents\nacting in an environment against annotations or with a human-in-the-loop. This\nwill help researchers, students, and data scientists to create, collaborate,\nand participate in AI challenges organized around the globe. By simplifying and\nstandardizing the process of benchmarking these models, EvalAI seeks to lower\nthe barrier to entry for participating in the global scientific effort to push\nthe frontiers of machine learning and artificial intelligence, thereby\nincreasing the rate of measurable progress in this domain.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 10:34:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yadav", "Deshraj", ""], ["Jain", "Rishabh", ""], ["Agrawal", "Harsh", ""], ["Chattopadhyay", "Prithvijit", ""], ["Singh", "Taranjeet", ""], ["Jain", "Akash", ""], ["Singh", "Shiv Baran", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.03589", "submitter": "Sumanth Chennupati", "authors": "Ganesh Sistu, Isabelle Leang, Sumanth Chennupati, Ciaran Hughes,\n  Stefan Milz, Senthil Yogamani and Samir Rawashdeh", "title": "NeurAll: Towards a Unified Model for Visual Perception in Automated\n  Driving", "comments": "Accepted for Oral Presentation at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are successfully used for the important\nautomotive visual perception tasks including object recognition, motion and\ndepth estimation, visual SLAM, etc. However, these tasks are typically\nindependently explored and modeled. In this paper, we propose a joint\nmulti-task network design for learning several tasks simultaneously. Our main\nmotivation is the computational efficiency achieved by sharing the expensive\ninitial convolutional layers between all tasks. Indeed, the main bottleneck in\nautomated driving systems is the limited processing power available on\ndeployment hardware. There is also some evidence for other benefits in\nimproving accuracy for some tasks and easing development effort. It also offers\nscalability to add more tasks leveraging existing features and achieving better\ngeneralization. We survey various CNN based solutions for visual perception\ntasks in automated driving. Then we propose a unified CNN model for the\nimportant tasks and discuss several advanced optimization and architecture\ndesign techniques to improve the baseline model. The paper is partly review and\npartly positional with demonstration of several preliminary results promising\nfor future research. We first demonstrate results of multi-stream learning and\nauxiliary learning which are important ingredients to scale to a large\nmulti-task model. Finally, we implement a two-stream three-task network which\nperforms better in many cases compared to their corresponding single-task\nmodels, while maintaining network size.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 12:45:49 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 16:39:56 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Sistu", "Ganesh", ""], ["Leang", "Isabelle", ""], ["Chennupati", "Sumanth", ""], ["Hughes", "Ciaran", ""], ["Milz", "Stefan", ""], ["Yogamani", "Senthil", ""], ["Rawashdeh", "Samir", ""]]}, {"id": "1902.03609", "submitter": "Radin Hamidi Rad", "authors": "Radin Hamidi Rad, Maryam Amir Haeri", "title": "Hybrid Forest: A Concept Drift Aware Data Stream Mining Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays with a growing number of online controlling systems in the\norganization and also a high demand of monitoring and stats facilities that\nuses data streams to log and control their subsystems, data stream mining\nbecomes more and more vital. Hoeffding Trees (also called Very Fast Decision\nTrees a.k.a. VFDT) as a Big Data approach in dealing with the data stream for\nclassification and regression problems showed good performance in handling\nfacing challenges and making the possibility of any-time prediction. Although\nthese methods outperform other methods e.g. Artificial Neural Networks (ANN)\nand Support Vector Regression (SVR), they suffer from high latency in adapting\nwith new concepts when the statistical distribution of incoming data changes.\nIn this article, we introduced a new algorithm that can detect and handle\nconcept drift phenomenon properly. This algorithms also benefits from fast\nstartup ability which helps systems to be able to predict faster than other\nalgorithms at the beginning of data stream arrival. We also have shown that our\napproach will overperform other controversial approaches for classification and\nregression tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 14:35:33 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Rad", "Radin Hamidi", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "1902.03616", "submitter": "Erich Schubert", "authors": "Erich Schubert and Arthur Zimek", "title": "ELKI: A large open-source library for data analysis - ELKI Release 0.7.5\n  \"Heidelberg\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper documents the release of the ELKI data mining framework, version\n0.7.5.\n  ELKI is an open source (AGPLv3) data mining software written in Java. The\nfocus of ELKI is research in algorithms, with an emphasis on unsupervised\nmethods in cluster analysis and outlier detection. In order to achieve high\nperformance and scalability, ELKI offers data index structures such as the\nR*-tree that can provide major performance gains. ELKI is designed to be easy\nto extend for researchers and students in this domain, and welcomes\ncontributions of additional methods. ELKI aims at providing a large collection\nof highly parameterizable algorithms, in order to allow easy and fair\nevaluation and benchmarking of algorithms.\n  We will first outline the motivation for this release, the plans for the\nfuture, and then give a brief overview over the new functionality in this\nversion. We also include an appendix presenting an overview on the overall\nimplemented functionality.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 15:04:44 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Schubert", "Erich", ""], ["Zimek", "Arthur", ""]]}, {"id": "1902.03619", "submitter": "Victoria Fernandez Abrevaya", "authors": "Victoria Fernandez Abrevaya, Adnane Boukhayma, Stefanie Wuhrer, Edmond\n  Boyer", "title": "A Decoupled 3D Facial Shape Model by Adversarial Training", "comments": "camera-ready version for ICCV'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven generative 3D face models are used to compactly encode facial\nshape data into meaningful parametric representations. A desirable property of\nthese models is their ability to effectively decouple natural sources of\nvariation, in particular identity and expression. While factorized\nrepresentations have been proposed for that purpose, they are still limited in\nthe variability they can capture and may present modeling artifacts when\napplied to tasks such as expression transfer. In this work, we explore a new\ndirection with Generative Adversarial Networks and show that they contribute to\nbetter face modeling performances, especially in decoupling natural factors,\nwhile also achieving more diverse samples. To train the model we introduce a\nnovel architecture that combines a 3D generator with a 2D discriminator that\nleverages conventional CNNs, where the two components are bridged by a geometry\nmapping layer. We further present a training scheme, based on auxiliary\nclassifiers, to explicitly disentangle identity and expression attributes.\nThrough quantitative and qualitative results on standard face datasets, we\nillustrate the benefits of our model and demonstrate that it outperforms\ncompeting state of the art methods in terms of decoupling and diversity.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 15:15:44 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 14:02:33 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 17:19:26 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Abrevaya", "Victoria Fernandez", ""], ["Boukhayma", "Adnane", ""], ["Wuhrer", "Stefanie", ""], ["Boyer", "Edmond", ""]]}, {"id": "1902.03633", "submitter": "Andrew Cohen", "authors": "Andrew Cohen and Xingye Qiao and Lei Yu and Elliot Way and Xiangrong\n  Tong", "title": "Diverse Exploration via Conjugate Policies for Policy Gradient Methods", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of effective exploration while maintaining good\nperformance in policy gradient methods. As a solution, we propose diverse\nexploration (DE) via conjugate policies. DE learns and deploys a set of\nconjugate policies which can be conveniently generated as a byproduct of\nconjugate gradient descent. We provide both theoretical and empirical results\nshowing the effectiveness of DE at achieving exploration, improving policy\nperformance, and the advantage of DE over exploration by random policy\nperturbations.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 17:18:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Cohen", "Andrew", ""], ["Qiao", "Xingye", ""], ["Yu", "Lei", ""], ["Way", "Elliot", ""], ["Tong", "Xiangrong", ""]]}, {"id": "1902.03638", "submitter": "Elliott Zaresky-Williams", "authors": "Elliott Zaresky-Williams", "title": "An Algorithm for Approximating Continuous Functions on Compact Subsets\n  with a Neural Network with one Hidden Layer", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  George Cybenko's landmark 1989 paper showed that there exists a feedforward\nneural network, with exactly one hidden layer (and a finite number of neurons),\nthat can arbitrarily approximate a given continuous function $f$ on the unit\nhypercube. The paper did not address how to find the weight/parameters of such\na network, or if finding them would be computationally feasible. This paper\noutlines an algorithm for a neural network with exactly one hidden layer to\nreconstruct any continuous scalar or vector valued continuous function.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 17:38:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zaresky-Williams", "Elliott", ""]]}, {"id": "1902.03639", "submitter": "Jason Zhang", "authors": "Jason Zhang", "title": "Machine Learning With Feature Selection Using Principal Component\n  Analysis for Malware Detection: A Case Study", "comments": "Sophos Technical Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security threats have been growing significantly in both volume and\nsophistication over the past decade. This poses great challenges to malware\ndetection without considerable automation. In this paper, we have proposed a\nnovel approach by extending our recently suggested artificial neural network\n(ANN) based model with feature selection using the principal component analysis\n(PCA) technique for malware detection. The effectiveness of the approach has\nbeen successfully demonstrated with the application in PDF malware detection. A\nvarying number of principal components is examined in the comparative study.\nOur evaluation shows that the model with PCA can significantly reduce feature\nredundancy and learning time with minimum impact on data information loss, as\nconfirmed by both training and testing results based on around 105,000\nreal-world PDF documents. Of the evaluated models using PCA, the model with 32\nprincipal feature components exhibits very similar training accuracy to the\nmodel using the 48 original features, resulting in around 33% dimensionality\nreduction and 22% less learning time. The testing results further confirm the\neffectiveness and show that the model is able to achieve 93.17% true positive\nrate (TPR) while maintaining the same low false positive rate (FPR) of 0.08% as\nthe case when no feature selection is applied, which significantly outperforms\nall evaluated seven well known commercial antivirus (AV) scanners of which the\nbest scanner only has a TPR of 84.53%.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 17:39:21 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhang", "Jason", ""]]}, {"id": "1902.03642", "submitter": "Anton Mallasto", "authors": "Anton Mallasto, Jes Frellsen, Wouter Boomsma, Aasa Feragen", "title": "(q,p)-Wasserstein GANs: Comparing Ground Metrics for Wasserstein GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversial Networks (GANs) have made a major impact in computer\nvision and machine learning as generative models. Wasserstein GANs (WGANs)\nbrought Optimal Transport (OT) theory into GANs, by minimizing the\n$1$-Wasserstein distance between model and data distributions as their\nobjective function. Since then, WGANs have gained considerable interest due to\ntheir stability and theoretical framework. We contribute to the WGAN literature\nby introducing the family of $(q,p)$-Wasserstein GANs, which allow the use of\nmore general $p$-Wasserstein metrics for $p\\geq 1$ in the GAN learning\nprocedure. While the method is able to incorporate any cost function as the\nground metric, we focus on studying the $l^q$ metrics for $q\\geq 1$. This is a\nnotable generalization as in the WGAN literature the OT distances are commonly\nbased on the $l^2$ ground metric. We demonstrate the effect of different\n$p$-Wasserstein distances in two toy examples. Furthermore, we show that the\nground metric does make a difference, by comparing different $(q,p)$ pairs on\nthe MNIST and CIFAR-10 datasets. Our experiments demonstrate that changing the\nground metric and $p$ can notably improve on the common $(q,p) = (2,1)$ case.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 17:59:37 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Mallasto", "Anton", ""], ["Frellsen", "Jes", ""], ["Boomsma", "Wouter", ""], ["Feragen", "Aasa", ""]]}, {"id": "1902.03653", "submitter": "Yanyao Shen", "authors": "Yanyao Shen and Sujay Sanghavi", "title": "Iterative Least Trimmed Squares for Mixed Linear Regression", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a linear regression setting, Iterative Least Trimmed Squares (ILTS)\ninvolves alternating between (a) selecting the subset of samples with lowest\ncurrent loss, and (b) re-fitting the linear model only on that subset. Both\nsteps are very fast and simple. In this paper we analyze ILTS in the setting of\nmixed linear regression with corruptions (MLR-C). We first establish\ndeterministic conditions (on the features etc.) under which the ILTS iterate\nconverges linearly to the closest mixture component. We also provide a global\nalgorithm that uses ILTS as a subroutine, to fully solve mixed linear\nregressions with corruptions. We then evaluate it for the widely studied\nsetting of isotropic Gaussian features, and establish that we match or better\nexisting results in terms of sample complexity. Finally, we provide an ODE\nanalysis for a gradient-descent variant of ILTS that has optimal time\ncomplexity.\n  Our results provide initial theoretical evidence that iteratively fitting to\nthe best subset of samples -- a potentially widely applicable idea -- can\nprovably provide state of the art performance in bad training data settings.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 19:12:14 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 06:33:03 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Shen", "Yanyao", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1902.03657", "submitter": "Urs Bergmann", "authors": "Andreas Merentitis, Kashif Rasul, Roland Vollgraf, Abdul-Saboor\n  Sheikh, Urs Bergmann", "title": "A Bandit Framework for Optimal Selection of Reinforcement Learning\n  Agents", "comments": "Published at the 32nd Conference on Neural Information Processing\n  Systems (NIPS 2018), Montreal, Canada. Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has been shown to be very successful in complex\ngames, e.g. Atari or Go. These games have clearly defined rules, and hence\nallow simulation. In many practical applications, however, interactions with\nthe environment are costly and a good simulator of the environment is not\navailable. Further, as environments differ by application, the optimal\ninductive bias (architecture, hyperparameters, etc.) of a reinforcement agent\ndepends on the application. In this work, we propose a multi-arm bandit\nframework that selects from a set of different reinforcement learning agents to\nchoose the one with the best inductive bias. To alleviate the problem of sparse\nrewards, the reinforcement learning agents are augmented with surrogate\nrewards. This helps the bandit framework to select the best agents early, since\nthese rewards are smoother and less sparse than the environment reward. The\nbandit has the double objective of maximizing the reward while the agents are\nlearning and selecting the best agent after a finite number of learning steps.\nOur experimental results on standard environments show that the proposed\nframework is able to consistently select the optimal agent after a finite\nnumber of steps, while collecting more cumulative reward compared to selecting\na sub-optimal architecture or uniformly alternating between different agents.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 19:39:28 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Merentitis", "Andreas", ""], ["Rasul", "Kashif", ""], ["Vollgraf", "Roland", ""], ["Sheikh", "Abdul-Saboor", ""], ["Bergmann", "Urs", ""]]}, {"id": "1902.03667", "submitter": "L. Thorne McCarty", "authors": "L. Thorne McCarty", "title": "Differential Similarity in Higher Dimensional Spaces: Theory and\n  Applications", "comments": "67 pages, 29 figures. Revised and expanded to include Section 7 on\n  the CIFAR-10 dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension and an elaboration of the theory of\ndifferential similarity, which was originally proposed in arXiv:1401.2411\n[cs.LG]. The goal is to develop an algorithm for clustering and coding that\ncombines a geometric model with a probabilistic model in a principled way. For\nsimplicity, the geometric model in the earlier paper was restricted to the\nthree-dimensional case. The present paper removes this restriction, and\nconsiders the full $n$-dimensional case. Although the mathematical model is the\nsame, the strategies for computing solutions in the $n$-dimensional case are\ndifferent, and one of the main purposes of this paper is to develop and analyze\nthese strategies. Another main purpose is to devise techniques for estimating\nthe parameters of the model from sample data, again in $n$ dimensions. We\nevaluate the solution strategies and the estimation techniques by applying them\nto two familiar real-world examples: the classical MNIST dataset and the\nCIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 20:30:29 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 17:13:45 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["McCarty", "L. Thorne", ""]]}, {"id": "1902.03680", "submitter": "Ryutaro Tanno", "authors": "Ryutaro Tanno, Ardavan Saeedi, Swami Sankaranarayanan, Daniel C.\n  Alexander, Nathan Silberman", "title": "Learning From Noisy Labels By Regularized Estimation Of Annotator\n  Confusion", "comments": "CVPR 2019, code snippets included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive performance of supervised learning algorithms depends on the\nquality of labels. In a typical label collection process, multiple annotators\nprovide subjective noisy estimates of the \"truth\" under the influence of their\nvarying skill-levels and biases. Blindly treating these noisy labels as the\nground truth limits the accuracy of learning algorithms in the presence of\nstrong disagreement. This problem is critical for applications in domains such\nas medical imaging where both the annotation cost and inter-observer\nvariability are high. In this work, we present a method for simultaneously\nlearning the individual annotator model and the underlying true label\ndistribution, using only noisy observations. Each annotator is modeled by a\nconfusion matrix that is jointly estimated along with the classifier\npredictions. We propose to add a regularization term to the loss function that\nencourages convergence to the true annotator confusion matrix. We provide a\ntheoretical argument as to how the regularization is essential to our approach\nboth for the case of single annotator and multiple annotators. Despite the\nsimplicity of the idea, experiments on image classification tasks with both\nsimulated and real labels show that our method either outperforms or performs\non par with the state-of-the-art methods and is capable of estimating the\nskills of annotators even with a single label available per image.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 23:01:33 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 12:14:05 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 07:34:07 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Tanno", "Ryutaro", ""], ["Saeedi", "Ardavan", ""], ["Sankaranarayanan", "Swami", ""], ["Alexander", "Daniel C.", ""], ["Silberman", "Nathan", ""]]}, {"id": "1902.03694", "submitter": "Bin Shi", "authors": "Bin Shi and Simon S. Du and Weijie J. Su and Michael I. Jordan", "title": "Acceleration via Symplectic Discretization of High-Resolution\n  Differential Equations", "comments": "Published in Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study first-order optimization methods obtained by discretizing ordinary\ndifferential equations (ODEs) corresponding to Nesterov's accelerated gradient\nmethods (NAGs) and Polyak's heavy-ball method. We consider three discretization\nschemes: an explicit Euler scheme, an implicit Euler scheme, and a symplectic\nscheme. We show that the optimization algorithm generated by applying the\nsymplectic scheme to a high-resolution ODE proposed by Shi et al. [2018]\nachieves an accelerated rate for minimizing smooth strongly convex functions.\nOn the other hand, the resulting algorithm either fails to achieve acceleration\nor is impractical when the scheme is implicit, the ODE is low-resolution, or\nthe scheme is explicit.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 01:13:18 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 18:27:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shi", "Bin", ""], ["Du", "Simon S.", ""], ["Su", "Weijie J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.03701", "submitter": "Gregory Kahn", "authors": "Katie Kang, Suneel Belkhale, Gregory Kahn, Pieter Abbeel, Sergey\n  Levine", "title": "Generalization through Simulation: Integrating Simulated and Real Data\n  into Deep Reinforcement Learning for Vision-Based Autonomous Flight", "comments": "First three authors contributed equally. Accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning provides a promising approach for vision-based\ncontrol of real-world robots. However, the generalization of such models\ndepends critically on the quantity and variety of data available for training.\nThis data can be difficult to obtain for some types of robotic systems, such as\nfragile, small-scale quadrotors. Simulated rendering and physics can provide\nfor much larger datasets, but such data is inherently of lower quality: many of\nthe phenomena that make the real-world autonomous flight problem challenging,\nsuch as complex physics and air currents, are modeled poorly or not at all, and\nthe systematic differences between simulation and the real world are typically\nimpossible to eliminate. In this work, we investigate how data from both\nsimulation and the real world can be combined in a hybrid deep reinforcement\nlearning algorithm. Our method uses real-world data to learn about the dynamics\nof the system, and simulated data to learn a generalizable perception system\nthat can enable the robot to avoid collisions using only a monocular camera. We\ndemonstrate our approach on a real-world nano aerial vehicle collision\navoidance task, showing that with only an hour of real-world data, the\nquadrotor can avoid collisions in new environments with various lighting\nconditions and geometry. Code, instructions for building the aerial vehicles,\nand videos of the experiments can be found at github.com/gkahn13/GtS\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 01:45:53 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kang", "Katie", ""], ["Belkhale", "Suneel", ""], ["Kahn", "Gregory", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1902.03717", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Nicolas Honnorat, Ehsan Adeli, Kilian M. Pohl", "title": "Truncated Gaussian-Mixture Variational AutoEncoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variation Autoencoder (VAE) has become a powerful tool in modeling the\nnon-linear generative process of data from a low-dimensional latent space.\nRecently, several studies have proposed to use VAE for unsupervised clustering\nby using mixture models to capture the multi-modal structure of latent\nrepresentations. This strategy, however, is ineffective when there are outlier\ndata samples whose latent representations are meaningless, yet contaminating\nthe estimation of key major clusters in the latent space. This exact problem\narises in the context of resting-state fMRI (rs-fMRI) analysis, where\nclustering major functional connectivity patterns is often hindered by heavy\nnoise of rs-fMRI and many minor clusters (rare connectivity patterns) of no\ninterest to analysis. In this paper we propose a novel generative process, in\nwhich we use a Gaussian-mixture to model a few major clusters in the data, and\nuse a non-informative uniform distribution to capture the remaining data. We\nembed this truncated Gaussian-Mixture model in a Variational AutoEncoder\nframework to obtain a general joint clustering and outlier detection approach,\ncalled tGM-VAE. We demonstrated the applicability of tGM-VAE on the MNIST\ndataset and further validated it in the context of rs-fMRI connectivity\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 03:50:29 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 20:46:54 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 01:11:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Qingyu", ""], ["Honnorat", "Nicolas", ""], ["Adeli", "Ehsan", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "1902.03718", "submitter": "Bingxin Zhou", "authors": "Bingxin Zhou, Junbin Gao, Minh-Ngoc Tran, Richard Gerlach", "title": "Manifold Optimization Assisted Gaussian Variational Approximation", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian variational approximation is a popular methodology to approximate\nposterior distributions in Bayesian inference especially in high dimensional\nand large data settings. To control the computational cost while being able to\ncapture the correlations among the variables, the low rank plus diagonal\nstructure was introduced in the previous literature for the Gaussian covariance\nmatrix. For a specific Bayesian learning task, the uniqueness of the solution\nis usually ensured by imposing stringent constraints on the parameterized\ncovariance matrix, which could break down during the optimization process. In\nthis paper, we consider two special covariance structures by applying the\nStiefel manifold and Grassmann manifold constraints, to address the\noptimization difficulty in such factorization architectures. To speed up the\nupdating process with minimum hyperparameter-tuning efforts, we design two new\nschemes of Riemannian stochastic gradient descent methods and compare them with\nother existing methods of optimizing on manifolds. In addition to fixing the\nidentification issue, results from both simulation and empirical experiments\nprove the ability of the proposed methods of obtaining competitive accuracy and\ncomparable converge speed in both high-dimensional and large-scale learning\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 04:05:11 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 05:37:04 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhou", "Bingxin", ""], ["Gao", "Junbin", ""], ["Tran", "Minh-Ngoc", ""], ["Gerlach", "Richard", ""]]}, {"id": "1902.03720", "submitter": "Kaige Yang Mr", "authors": "Kaige Yang, Xiaowen Dong, Laura Toni", "title": "Error Analysis on Graph Laplacian Regularized Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We provide a theoretical analysis of the representation learning problem\naimed at learning the latent variables (design matrix) $\\Theta$ of observations\n$Y$ with the knowledge of the coefficient matrix $X$. The design matrix is\nlearned under the assumption that the latent variables $\\Theta$ are smooth with\nrespect to a (known) topological structure $\\mathcal{G}$. To learn such latent\nvariables, we study a graph Laplacian regularized estimator, which is the\npenalized least squares estimator with penalty term proportional to a Laplacian\nquadratic form. This type of estimators has recently received considerable\nattention due to its capability in incorporating underlying topological graph\nstructure of variables into the learning process. While the estimation problem\ncan be solved efficiently by state-of-the-art optimization techniques, its\nstatistical consistency properties have been largely overlooked. In this work,\nwe develop a non-asymptotic bound of estimation error under the classical\nstatistical setting, where sample size is larger than the ambient dimension of\nthe latent variables. This bound illustrates theoretically the impact of the\nalignment between the data and the graph structure as well as the graph\nspectrum on the estimation accuracy. It also provides theoretical evidence of\nthe advantage, in terms of convergence rate, of the graph Laplacian regularized\nestimator over classical ones (that ignore the graph structure) in case of a\nsmoothness prior. Finally, we provide empirical results of the estimation error\nto corroborate the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 04:06:29 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yang", "Kaige", ""], ["Dong", "Xiaowen", ""], ["Toni", "Laura", ""]]}, {"id": "1902.03731", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, Cass R. Sunstein", "title": "Discrimination in the Age of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The law forbids discrimination. But the ambiguity of human decision-making\noften makes it extraordinarily hard for the legal system to know whether anyone\nhas actually discriminated. To understand how algorithms affect discrimination,\nwe must therefore also understand how they affect the problem of detecting\ndiscrimination. By one measure, algorithms are fundamentally opaque, not just\ncognitively but even mathematically. Yet for the task of proving\ndiscrimination, processes involving algorithms can provide crucial forms of\ntransparency that are otherwise unavailable. These benefits do not happen\nautomatically. But with appropriate requirements in place, the use of\nalgorithms will make it possible to more easily examine and interrogate the\nentire decision process, thereby making it far easier to know whether\ndiscrimination has occurred. By forcing a new level of specificity, the use of\nalgorithms also highlights, and makes transparent, central tradeoffs among\ncompeting values. Algorithms are not only a threat to be regulated; with the\nright safeguards in place, they have the potential to be a positive force for\nequity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 04:58:11 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kleinberg", "Jon", ""], ["Ludwig", "Jens", ""], ["Mullainathan", "Sendhil", ""], ["Sunstein", "Cass R.", ""]]}, {"id": "1902.03736", "submitter": "Praneeth Netrapalli", "authors": "Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M. Kakade and Michael I.\n  Jordan", "title": "A Short Note on Concentration Inequalities for Random Vectors with\n  SubGaussian Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we derive concentration inequalities for random vectors with\nsubGaussian norm (a generalization of both subGaussian random vectors and norm\nbounded random vectors), which are tight up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 05:41:28 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Jin", "Chi", ""], ["Netrapalli", "Praneeth", ""], ["Ge", "Rong", ""], ["Kakade", "Sham M.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.03738", "submitter": "Yuehe Zhu", "authors": "Yue-he Zhu and Ya-zhong Luo", "title": "Fast Evaluation of Low-Thrust Transfers via Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of low-thrust-based multitarget interplanetary missions requires a\nmethod to quickly and accurately evaluate the low-thrust transfer between any\ntwo visiting targets. Complete evaluation of the low-thrust transfer includes\nnot only the estimation of the optimal fuel consumption but also the judgment\nof transfer feasibility. In this paper, a deep neural network (DNN)-based\nmethod is proposed for quickly evaluating low-thrust transfer. An efficient\ndatabase generation method is developed for obtaining both the infeasible and\noptimal transfers. A classification DNN and a regression DNN are trained based\non the infeasible and optimal transfers to judge the transfer feasibility and\nestimate the optimal fuel consumption, respectively. The simulation results\nshow that the well-trained DNNs are capable of quickly determining the transfer\nfeasibility with a correct rate of greater than 98% and approximating the\noptimal transfer fuel consumption with a relative estimation error of less than\n0.4%. The tests on two asteroid chains further show the superiority of the\nDNN-based method for application to the design of low-thrust-based multitarget\ninterplanetary missions\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 05:43:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhu", "Yue-he", ""], ["Luo", "Ya-zhong", ""]]}, {"id": "1902.03740", "submitter": "Bin Liu", "authors": "Bin Liu", "title": "Harnessing Low-Fidelity Data to Accelerate Bayesian Optimization via\n  Posterior Regularization", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a powerful paradigm for derivative-free global\noptimization of a black-box objective function (BOF) that is expensive to\nevaluate. However, the overhead of BO can still be prohibitive for problems\nwith highly expensive function evaluations. In this paper, we investigate how\nto reduce the required number of function evaluations for BO without compromise\nin solution quality. We explore the idea of posterior regularization to harness\nlow fidelity (LF) data within the Gaussian process upper confidence bound\n(GP-UCB) framework. The LF data can arise from previous evaluations of an LF\napproximation of the BOF or of a related optimization task. An extra GP model\ncalled LF-GP is trained to fit the LF data. We develop an operator termed\ndynamic weighted product of experts (DW-POE) fusion. The regularization is\ninduced by this operator on the posterior of the BOF. The impact of the LF GP\nmodel on the resulting regularized posterior is adaptively adjusted via\nBayesian formalism. Extensive experimental results on benchmark BOF\noptimization tasks demonstrate the superior performance of the proposed\nalgorithm over state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 05:46:11 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 15:51:31 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 02:02:52 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 07:45:25 GMT"}, {"version": "v5", "created": "Mon, 16 Dec 2019 21:40:04 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Liu", "Bin", ""]]}, {"id": "1902.03755", "submitter": "Dmitrii Ostrovskii", "authors": "Dmitry Babichev (SIERRA, Inria, PSL), Dmitrii Ostrovskii (SIERRA,\n  Inria, PSL), Francis Bach (SIERRA, Inria, PSL)", "title": "Efficient Primal-Dual Algorithms for Large-Scale Multiclass\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop efficient algorithms to train $\\ell_1$-regularized linear\nclassifiers with large dimensionality $d$ of the feature space, number of\nclasses $k$, and sample size $n$. Our focus is on a special class of losses\nthat includes, in particular, the multiclass hinge and logistic losses. Our\napproach combines several ideas: (i) passing to the equivalent saddle-point\nproblem with a quasi-bilinear objective; (ii) applying stochastic mirror\ndescent with a proper choice of geometry which guarantees a favorable accuracy\nbound; (iii) devising non-uniform sampling schemes to approximate the matrix\nproducts. In particular, for the multiclass hinge loss we propose a\n\\textit{sublinear} algorithm with iterations performed in $O(d+n+k)$ arithmetic\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 07:39:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Babichev", "Dmitry", "", "SIERRA, Inria, PSL"], ["Ostrovskii", "Dmitrii", "", "SIERRA,\n  Inria, PSL"], ["Bach", "Francis", "", "SIERRA, Inria, PSL"]]}, {"id": "1902.03760", "submitter": "Mohammed Amer", "authors": "Mohammed Amer, Tom\\'as Maul", "title": "Path Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network (CapsNet) was introduced as an enhancement over convolutional\nneural networks, supplementing the latter's invariance properties with\nequivariance through pose estimation. CapsNet achieved a very decent\nperformance with a shallow architecture and a significant reduction in\nparameters count. However, the width of the first layer in CapsNet is still\ncontributing to a significant number of its parameters and the shallowness may\nbe limiting the representational power of the capsules. To address these\nlimitations, we introduce Path Capsule Network (PathCapsNet), a deep parallel\nmulti-path version of CapsNet. We show that a judicious coordination of depth,\nmax-pooling, regularization by DropCircuit and a new fan-in routing by\nagreement technique can achieve better or comparable results to CapsNet, while\nfurther reducing the parameter count significantly.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 07:56:19 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 12:19:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Amer", "Mohammed", ""], ["Maul", "Tom\u00e1s", ""]]}, {"id": "1902.03765", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Latent Space Reinforcement Learning for Steering Angle Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning has recently been shown to successfully\nlearn navigation policies from raw sensor data. In this work, we address the\nproblem of learning driving policies for an autonomous agent in a high-fidelity\nsimulator. Building upon recent research that applies deep reinforcement\nlearning to navigation problems, we present a modular deep reinforcement\nlearning approach to predict the steering angle of the car from raw images. The\nfirst module extracts a low-dimensional latent semantic representation of the\nimage. The control module trained with reinforcement learning takes the latent\nvector as input to predict the correct steering angle. The experimental results\nhave showed that our method is capable of learning to maneuver the car without\nany human control signals.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 08:14:34 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.03777", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Semantic Label Reduction Techniques for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation maps can be used as input to models for maneuvering the\ncontrols of a car. However, not all labels may be necessary for making the\ncontrol decision. One would expect that certain labels such as road lanes or\nsidewalks would be more critical in comparison with labels for vegetation or\nbuildings which may not have a direct influence on the car's driving decision.\nIn this appendix, we evaluate and quantify how sensitive and important the\ndifferent semantic labels are for controlling the car. Labels that do not\ninfluence the driving decision are remapped to other classes, thereby\nsimplifying the task by reducing to only labels critical for driving of the\nvehicle.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 08:38:26 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.03793", "submitter": "Xiao Dong", "authors": "Xiao Dong, Ling Zhou", "title": "Understanding over-parameterized deep networks by geometrization", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete understanding of the widely used over-parameterized deep networks\nis a key step for AI. In this work we try to give a geometric picture of\nover-parameterized deep networks using our geometrization scheme. We show that\nthe Riemannian geometry of network complexity plays a key role in understanding\nthe basic properties of over-parameterizaed deep networks, including the\ngeneralization, convergence and parameter sensitivity. We also point out deep\nnetworks share lots of similarities with quantum computation systems. This can\nbe regarded as a strong support of our proposal that geometrization is not only\nthe bible for physics, it is also the key idea to understand deep learning\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 09:53:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Dong", "Xiao", ""], ["Zhou", "Ling", ""]]}, {"id": "1902.03794", "submitter": "Pierre Perrault", "authors": "Pierre Perrault, Vianney Perchet, Michal Valko", "title": "Exploiting Structure of Uncertainty for Efficient Matroid Semi-Bandits", "comments": "Accepted to ICML 2019, Long Beach", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the efficiency of algorithms for stochastic \\emph{combinatorial\nsemi-bandits}. In most interesting problems, state-of-the-art algorithms take\nadvantage of structural properties of rewards, such as \\emph{independence}.\nHowever, while being optimal in terms of asymptotic regret, these algorithms\nare inefficient. In our paper, we first reduce their implementation to a\nspecific \\emph{submodular maximization}. Then, in case of \\emph{matroid}\nconstraints, we design adapted approximation routines, thereby providing the\nfirst efficient algorithms that rely on reward structure to improve regret\nbound. In particular, we improve the state-of-the-art efficient gap-free regret\nbound by a factor $\\sqrt{m}/\\log m$, where $m$ is the maximum action size.\nFinally, we show how our improvement translates to more general \\emph{budgeted\ncombinatorial semi-bandits}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 09:59:05 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 02:28:28 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Perrault", "Pierre", ""], ["Perchet", "Vianney", ""], ["Valko", "Michal", ""]]}, {"id": "1902.03806", "submitter": "Chandramouli Kamanchi", "authors": "Chandramouli Kamanchi, Raghuram Bharadwaj Diddigi, Prabuchandran K.\n  J., Shalabh Bhatnagar", "title": "An Online Sample Based Method for Mode Estimation using ODE Analysis of\n  Stochastic Approximation Algorithms", "comments": null, "journal-ref": "IEEE Control Systems Letters 2019", "doi": "10.1109/LCSYS.2019.2916467", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the popular measures of central tendency that provides better\nrepresentation and interesting insights of the data compared to the other\nmeasures like mean and median is the metric mode. If the analytical form of the\ndensity function is known, mode is an argument of the maximum value of the\ndensity function and one can apply the optimization techniques to find mode. In\nmany of the practical applications, the analytical form of the density is not\nknown and only the samples from the distribution are available. Most of the\ntechniques proposed in the literature for estimating the mode from the samples\nassume that all the samples are available beforehand. Moreover, some of the\ntechniques employ computationally expensive operations like sorting. In this\nwork we provide a computationally effective, on-line iterative algorithm that\nestimates the mode of a unimodal smooth density given only the samples\ngenerated from the density. Asymptotic convergence of the proposed algorithm\nusing an ordinary differential equation (ODE) based analysis is provided. We\nalso prove the stability of estimates by utilizing the concept of\nregularization. Experimental results further demonstrate the effectiveness of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 10:27:57 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 13:47:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kamanchi", "Chandramouli", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["J.", "Prabuchandran K.", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1902.03825", "submitter": "Vivek Kumar Mr.", "authors": "Vivek Kumar, Brojo Kishore Mishra, Manuel Mazzara, Dang N. H. Thanh,\n  Abhishek Verma", "title": "Prediction of Malignant & Benign Breast Cancer: A Data Mining Approach\n  in Healthcare Applications", "comments": "8 Pages, 2 Figures, 4 Tables. Conference- Advances in Data Science\n  and Management - Proceedings of ICDSM 2019 To be published with- Springer,\n  Lecture Notes on Data Engineering and Communications Technologies series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As much as data science is playing a pivotal role everywhere, healthcare also\nfinds it prominent application. Breast Cancer is the top rated type of cancer\namongst women; which took away 627,000 lives alone. This high mortality rate\ndue to breast cancer does need attention, for early detection so that\nprevention can be done in time. As a potential contributor to state-of-art\ntechnology development, data mining finds a multi-fold application in\npredicting Brest cancer. This work focuses on different classification\ntechniques implementation for data mining in predicting malignant and benign\nbreast cancer. Breast Cancer Wisconsin data set from the UCI repository has\nbeen used as experimental dataset while attribute clump thickness being used as\nan evaluation class. The performances of these twelve algorithms: Ada Boost M\n1, Decision Table, J Rip, Lazy IBK, Logistics Regression, Multiclass\nClassifier, Multilayer Perceptron, Naive Bayes, Random forest and Random Tree\nare analyzed on this data set. Keywords- Data Mining, Classification\nTechniques, UCI repository, Breast Cancer, Classification Algorithms\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 11:31:38 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 19:07:05 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 10:05:44 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 17:21:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kumar", "Vivek", ""], ["Mishra", "Brojo Kishore", ""], ["Mazzara", "Manuel", ""], ["Thanh", "Dang N. H.", ""], ["Verma", "Abhishek", ""]]}, {"id": "1902.03833", "submitter": "Ga\\\"el Beck", "authors": "Ga\\\"el Beck, Tarn Duong, Mustapha Lebbah, Hanane Azzag, Christophe\n  C\\'erin", "title": "A Distributed and Approximated Nearest Neighbors Algorithm for an\n  Efficient Large Scale Mean Shift Clustering", "comments": "Algorithms are available at\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we target the class of modal clustering methods where clusters\nare defined in terms of the local modes of the probability density function\nwhich generates the data. The most well-known modal clustering method is the\nk-means clustering. Mean Shift clustering is a generalization of the k-means\nclustering which computes arbitrarily shaped clusters as defined as the basins\nof attraction to the local modes created by the density gradient ascent paths.\nDespite its potential, the Mean Shift approach is a computationally expensive\nmethod for unsupervised learning. Thus, we introduce two contributions aiming\nto provide clustering algorithms with a linear time complexity, as opposed to\nthe quadratic time complexity for the exact Mean Shift clustering. Firstly we\npropose a scalable procedure to approximate the density gradient ascent.\nSecond, our proposed scalable cluster labeling technique is presented. Both\npropositions are based on Locality Sensitive Hashing (LSH) to approximate\nnearest neighbors. These two techniques may be used for moderate sized\ndatasets. Furthermore, we show that using our proposed approximations of the\ndensity gradient ascent as a pre-processing step in other clustering methods\ncan also improve dedicated classification metrics. For the latter, a\ndistributed implementation, written for the Spark/Scala ecosystem is proposed.\nFor all these considered clustering methods, we present experimental results\nillustrating their labeling accuracy and their potential to solve concrete\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 12:00:06 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Beck", "Ga\u00ebl", ""], ["Duong", "Tarn", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["C\u00e9rin", "Christophe", ""]]}, {"id": "1902.03856", "submitter": "Abbas Siddiqui", "authors": "Abbas Siddiqui and Dionysios Georgiadis", "title": "Global Collaboration through Local Interaction in Competitive Learning", "comments": "The behavior via simulation can be viewed at:\n  https://www.youtube.com/watch?v=lTxlVHXGO2Q", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature maps, that preserve the global topology of arbitrary datasets, can be\nformed by self-organizing competing agents. So far, it has been presumed that\nglobal interaction of agents is necessary for this process. We establish that\nthis is not the case, and that global topology can be uncovered through\nstrictly local interactions. Enforcing uniformity of map quality across all\nagents, results in an algorithm that is able to consistently uncover the global\ntopology of diversely challenging datasets.The applicability and scalability of\nthis approach is further tested on a large point cloud dataset, revealing a\nlinear relation between map training time and size. The presented work not only\nreduces algorithmic complexity but also constitutes first step towards a\ndistributed self organizing map.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:15:43 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Siddiqui", "Abbas", ""], ["Georgiadis", "Dionysios", ""]]}, {"id": "1902.03865", "submitter": "Yashar Kiarashinejad", "authors": "Yashar Kiarashinejad, Sajjad Abdollahramezani, and Ali Adibi", "title": "Deep learning approach based on dimensionality reduction for designing\n  electromagnetic nanostructures", "comments": null, "journal-ref": "npj Comput Mater 6, 12 (2020)", "doi": "10.1038/s41524-020-0276-y", "report-no": null, "categories": "cs.LG physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate a computationally efficient new approach based\non deep learning (DL) techniques for analysis, design, and optimization of\nelectromagnetic (EM) nanostructures. We use the strong correlation among\nfeatures of a generic EM problem to considerably reduce the dimensionality of\nthe problem and thus, the computational complexity, without imposing\nconsiderable errors. By employing the dimensionality reduction concept using\nthe more recently demonstrated autoencoder technique, we redefine the\nconventional many-to-one design problem in EM nanostructures into a one-to-one\nproblem plus a much simpler many-to-one problem, which can be simply solved\nusing an analytic formulation. This approach reduces the computational\ncomplexity in solving both the forward problem (i.e., analysis) and the inverse\nproblem (i.e., design) by orders of magnitude compared to conventional\napproaches. In addition, it provides analytic formulations that, despite their\ncomplexity, can be used to obtain intuitive understanding of the physics and\ndynamics of EM wave interaction with nanostructures with minimal computation\nrequirements. As a proof-of-concept, we applied such an efficacious method to\ndesign a new class of on-demand reconfigurable optical metasurfaces based on\nphase-change materials (PCM). We envision that the integration of such a\nDL-based technique with full-wave commercial software packages offers a\npowerful toolkit to facilitate the analysis, design, and optimization of the EM\nnanostructures as well as explaining, understanding, and predicting the\nobserved responses in such structures.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:33:55 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 20:31:27 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 20:46:42 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kiarashinejad", "Yashar", ""], ["Abdollahramezani", "Sajjad", ""], ["Adibi", "Ali", ""]]}, {"id": "1902.03871", "submitter": "Ruiqi Gao", "authors": "Ruiqi Gao, Jianwen Xie, Siyuan Huang, Yufan Ren, Song-Chun Zhu and\n  Ying Nian Wu", "title": "Learning vector representation of local content and matrix\n  representation of local motion, with implications for V1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a representational model for image pair such as\nconsecutive video frames that are related by local pixel displacements, in the\nhope that the model may shed light on motion perception in primary visual\ncortex (V1). The model couples the following two components. (1) The vector\nrepresentations of local contents of images. (2) The matrix representations of\nlocal pixel displacements caused by the relative motions between the agent and\nthe objects in the 3D scene. When the image frame undergoes changes due to\nlocal pixel displacements, the vectors are multiplied by the matrices that\nrepresent the local displacements. Our experiments show that our model can\nlearn to infer local motions. Moreover, the model can learn Gabor-like filter\npairs of quadrature phases.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:09:19 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 23:22:38 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 05:51:22 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 09:18:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gao", "Ruiqi", ""], ["Xie", "Jianwen", ""], ["Huang", "Siyuan", ""], ["Ren", "Yufan", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1902.03876", "submitter": "Jo Schlemper", "authors": "Jo Schlemper, Jose Caballero, Andy Aitken, Joost van Amersfoort", "title": "Deep Hashing using Entropy Regularised Product Quantisation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large scale systems, approximate nearest neighbour search is a crucial\nalgorithm to enable efficient data retrievals. Recently, deep learning-based\nhashing algorithms have been proposed as a promising paradigm to enable data\ndependent schemes. Often their efficacy is only demonstrated on data sets with\nfixed, limited numbers of classes. In practical scenarios, those labels are not\nalways available or one requires a method that can handle a higher input\nvariability, as well as a higher granularity. To fulfil those requirements, we\nlook at more flexible similarity measures. In this work, we present a novel,\nflexible, end-to-end trainable network for large-scale data hashing. Our method\nworks by transforming the data distribution to behave as a uniform distribution\non a product of spheres. The transformed data is subsequently hashed to a\nbinary form in a way that maximises entropy of the output, (i.e. to fully\nutilise the available bit-rate capacity) while maintaining the correctness\n(i.e. close items hash to the same key in the map). We show that the method\noutperforms baseline approaches such as locality-sensitive hashing and product\nquantisation in the limited capacity regime.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:55:48 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Schlemper", "Jo", ""], ["Caballero", "Jose", ""], ["Aitken", "Andy", ""], ["van Amersfoort", "Joost", ""]]}, {"id": "1902.03896", "submitter": "Bernard \\v{Z}enko", "authors": "Marc G. Leguia and Zoran Levnajic and Ljupco Todorovski and Bernard\n  Zenko", "title": "Reconstructing dynamical networks via feature ranking", "comments": null, "journal-ref": "Chaos 29, 093107 (2019)", "doi": "10.1063/1.5092170", "report-no": null, "categories": "math.DS cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical data on real complex systems are becoming increasingly available.\nParallel to this is the need for new methods of reconstructing (inferring) the\ntopology of networks from time-resolved observations of their node-dynamics.\nThe methods based on physical insights often rely on strong assumptions about\nthe properties and dynamics of the scrutinized network. Here, we use the\ninsights from machine learning to design a new method of network reconstruction\nthat essentially makes no such assumptions. Specifically, we interpret the\navailable trajectories (data) as features, and use two independent feature\nranking approaches -- Random forest and RReliefF -- to rank the importance of\neach node for predicting the value of each other node, which yields the\nreconstructed adjacency matrix. We show that our method is fairly robust to\ncoupling strength, system size, trajectory length and noise. We also find that\nthe reconstruction quality strongly depends on the dynamical regime.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 14:35:01 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 12:47:29 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Leguia", "Marc G.", ""], ["Levnajic", "Zoran", ""], ["Todorovski", "Ljupco", ""], ["Zenko", "Bernard", ""]]}, {"id": "1902.03932", "submitter": "Andrew Wilson", "authors": "Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, Andrew Gordon\n  Wilson", "title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posteriors over neural network weights are high dimensional and\nmultimodal. Each mode typically characterizes a meaningfully different\nrepresentation of the data. We develop Cyclical Stochastic Gradient MCMC\n(SG-MCMC) to automatically explore such distributions. In particular, we\npropose a cyclical stepsize schedule, where larger steps discover new modes,\nand smaller steps characterize each mode. We also prove non-asymptotic\nconvergence of our proposed algorithm. Moreover, we provide extensive\nexperimental results, including ImageNet, to demonstrate the scalability and\neffectiveness of cyclical SG-MCMC in learning complex multimodal distributions,\nespecially for fully Bayesian inference with modern deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:03:30 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 20:49:28 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Zhang", "Ruqi", ""], ["Li", "Chunyuan", ""], ["Zhang", "Jianyi", ""], ["Chen", "Changyou", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1902.03964", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Jan Kralj, Janez Konc, Marko Robnik-\\v{S}ikonja,\n  Nada Lavra\\v{c}", "title": "Deep Node Ranking: Structural Network Embedding and End-to-End Node\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are used as an abstraction for systems modeling in physics,\nbiology, sociology, and other areas. We propose an algorithm, named Deep Node\nRanking (DNR), based on fast personalized node ranking and raw approximation\npower of deep learning for learning supervised and unsupervised network\nembeddings as well as for classifying network nodes directly. The experiments\ndemonstrate that the DNR algorithm is competitive with strong baselines on nine\nnode classification benchmarks from the domains of molecular biology, finance,\nsocial media and language processing in terms of speed, as well as predictive\naccuracy. Embeddings, obtained by the proposed algorithm, are also a viable\noption for network visualization.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:13:11 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 07:51:28 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 17:31:13 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 07:01:18 GMT"}, {"version": "v5", "created": "Tue, 22 Sep 2020 07:40:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Kralj", "Jan", ""], ["Konc", "Janez", ""], ["Robnik-\u0160ikonja", "Marko", ""], ["Lavra\u010d", "Nada", ""]]}, {"id": "1902.03968", "submitter": "Constantin Grigo", "authors": "Constantin Grigo, Phaedon-Stelios Koutsourelakis", "title": "A physics-aware, probabilistic machine learning framework for\n  coarse-graining high-dimensional systems in the Small Data regime", "comments": "43 pages, 17 figures", "journal-ref": "Journal of Computational Physics 397 (2019) 108842", "doi": "10.1016/j.jcp.2019.05.053", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated construction of coarse-grained models represents a pivotal\ncomponent in computer simulation of physical systems and is a key enabler in\nvarious analysis and design tasks related to uncertainty quantification.\nPertinent methods are severely inhibited by the high-dimension of the\nparametric input and the limited number of training input/output pairs that can\nbe generated when computationally demanding forward models are considered. Such\ncases are frequently encountered in the modeling of random heterogeneous media\nwhere the scale of the microstructure necessitates the use of high-dimensional\nrandom vectors and very fine discretizations of the governing equations. The\npresent paper proposes a probabilistic Machine Learning framework that is\ncapable of operating in the presence of Small Data by exploiting aspects of the\nphysical structure of the problem as well as contextual knowledge. As a result,\nit can perform comparably well under extrapolative conditions. It unifies the\ntasks of dimensionality and model-order reduction through an encoder-decoder\nscheme that simultaneously identifies a sparse set of salient lower-dimensional\nmicrostructural features and calibrates an inexpensive, coarse-grained model\nwhich is predictive of the output. Information loss is accounted for and\nquantified in the form of probabilistic predictive estimates. The learning\nengine is based on Stochastic Variational Inference. We demonstrate how the\nvariational objectives can be used not only to train the coarse-grained model,\nbut also to suggest refinements that lead to improved predictions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:24:54 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:01:43 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Grigo", "Constantin", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "1902.03983", "submitter": "Fabricio Olivetti de Franca", "authors": "Fabricio Olivetti de Franca and Guilherme Seidyo Imai Aldeia", "title": "Interaction-Transformation Evolutionary Algorithm for Symbolic\n  Regression", "comments": "25 pages, 9 tables, 3 figures, submitted to Evolutionary Computation\n  Journal, September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Interaction-Transformation (IT) is a new representation for Symbolic\nRegression that restricts the search space into simpler, but expressive,\nfunction forms. This representation has the advantage of creating a smoother\nsearch space unlike the space generated by Expression Trees, the common\nrepresentation used in Genetic Programming. This paper introduces an\nEvolutionary Algorithm capable of evolving a population of IT expressions\nsupported only by the mutation operator. The results show that this\nrepresentation is capable of finding better approximations to real-world data\nsets when compared to traditional approaches and a state-of-the-art Genetic\nProgramming algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:43:32 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 16:45:20 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 17:33:29 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 14:04:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["de Franca", "Fabricio Olivetti", ""], ["Aldeia", "Guilherme Seidyo Imai", ""]]}, {"id": "1902.03984", "submitter": "Thanh-Tung Hoang", "authors": "Hoang Thanh-Tung, Truyen Tran, Svetha Venkatesh", "title": "Improving Generalization and Stability of Generative Adversarial\n  Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are one of the most popular tools for\nlearning complex high dimensional distributions. However, generalization\nproperties of GANs have not been well understood. In this paper, we analyze the\ngeneralization of GANs in practical settings. We show that discriminators\ntrained on discrete datasets with the original GAN loss have poor\ngeneralization capability and do not approximate the theoretically optimal\ndiscriminator. We propose a zero-centered gradient penalty for improving the\ngeneralization of the discriminator by pushing it toward the optimal\ndiscriminator. The penalty guarantees the generalization and convergence of\nGANs. Experiments on synthetic and large scale datasets verify our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:44:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Thanh-Tung", "Hoang", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1902.03993", "submitter": "Frederik Benzing", "authors": "Frederik Benzing, Marcelo Matheus Gauy, Asier Mujika, Anders\n  Martinsson, Angelika Steger", "title": "Optimal Kronecker-Sum Approximation of Real Time Recurrent Learning", "comments": "ICML 2019 camera ready version; new version includes additional plots\n  in the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central goals of Recurrent Neural Networks (RNNs) is to learn\nlong-term dependencies in sequential data. Nevertheless, the most popular\ntraining method, Truncated Backpropagation through Time (TBPTT), categorically\nforbids learning dependencies beyond the truncation horizon. In contrast, the\nonline training algorithm Real Time Recurrent Learning (RTRL) provides\nuntruncated gradients, with the disadvantage of impractically large\ncomputational costs. Recently published approaches reduce these costs by\nproviding noisy approximations of RTRL. We present a new approximation\nalgorithm of RTRL, Optimal Kronecker-Sum Approximation (OK). We prove that OK\nis optimal for a class of approximations of RTRL, which includes all approaches\npublished so far. Additionally, we show that OK has empirically negligible\nnoise: Unlike previous algorithms it matches TBPTT in a real world task\n(character-level Penn TreeBank) and can exploit online parameter updates to\noutperform TBPTT in a synthetic string memorization task. Code availiable on\ngithub.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:51:12 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 08:17:05 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Benzing", "Frederik", ""], ["Gauy", "Marcelo Matheus", ""], ["Mujika", "Asier", ""], ["Martinsson", "Anders", ""], ["Steger", "Angelika", ""]]}, {"id": "1902.03999", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist", "title": "KTBoost: Combined Kernel and Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel boosting algorithm called `KTBoost' which combines\nkernel boosting and tree boosting. In each boosting iteration, the algorithm\nadds either a regression tree or reproducing kernel Hilbert space (RKHS)\nregression function to the ensemble of base learners. Intuitively, the idea is\nthat discontinuous trees and continuous RKHS regression functions complement\neach other, and that this combination allows for better learning of functions\nthat have parts with varying degrees of regularity such as discontinuities and\nsmooth parts. We empirically show that KTBoost significantly outperforms both\ntree and kernel boosting in terms of predictive accuracy in a comparison on a\nwide array of data sets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 17:02:10 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 07:02:40 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 14:28:32 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 14:38:38 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 07:06:15 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sigrist", "Fabio", ""]]}, {"id": "1902.04043", "submitter": "Mikayel Samvelyan", "authors": "Mikayel Samvelyan, Tabish Rashid, Christian Schroeder de Witt, Gregory\n  Farquhar, Nantas Nardelli, Tim G. J. Rudner, Chia-Man Hung, Philip H. S.\n  Torr, Jakob Foerster, Shimon Whiteson", "title": "The StarCraft Multi-Agent Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, deep multi-agent reinforcement learning (RL) has\nbecome a highly active area of research. A particularly challenging class of\nproblems in this area is partially observable, cooperative, multi-agent\nlearning, in which teams of agents must learn to coordinate their behaviour\nwhile conditioning only on their private observations. This is an attractive\nresearch area since such problems are relevant to a large number of real-world\nsystems and are also more amenable to evaluation than general-sum problems.\nStandardised environments such as the ALE and MuJoCo have allowed single-agent\nRL to move beyond toy domains, such as grid worlds. However, there is no\ncomparable benchmark for cooperative multi-agent RL. As a result, most papers\nin this field use one-off toy problems, making it difficult to measure real\nprogress. In this paper, we propose the StarCraft Multi-Agent Challenge (SMAC)\nas a benchmark problem to fill this gap. SMAC is based on the popular real-time\nstrategy game StarCraft II and focuses on micromanagement challenges where each\nunit is controlled by an independent agent that must act based on local\nobservations. We offer a diverse set of challenge maps and recommendations for\nbest practices in benchmarking and evaluations. We also open-source a deep\nmulti-agent RL learning framework including state-of-the-art algorithms. We\nbelieve that SMAC can provide a standard benchmark environment for years to\ncome. Videos of our best agents for several SMAC scenarios are available at:\nhttps://youtu.be/VZ7zmQ_obZ0.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 18:43:53 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 13:42:54 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 19:38:36 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 14:52:00 GMT"}, {"version": "v5", "created": "Mon, 9 Dec 2019 07:26:52 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Samvelyan", "Mikayel", ""], ["Rashid", "Tabish", ""], ["de Witt", "Christian Schroeder", ""], ["Farquhar", "Gregory", ""], ["Nardelli", "Nantas", ""], ["Rudner", "Tim G. J.", ""], ["Hung", "Chia-Man", ""], ["Torr", "Philip H. S.", ""], ["Foerster", "Jakob", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1902.04056", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, Thorsten Joachims", "title": "Policy Learning for Fairness in Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Learning-to-Rank (LTR) methods optimize the utility of the\nrankings to the users, but they are oblivious to their impact on the ranked\nitems. However, there has been a growing understanding that the latter is\nimportant to consider for a wide range of ranking applications (e.g. online\nmarketplaces, job placement, admissions). To address this need, we propose a\ngeneral LTR framework that can optimize a wide range of utility metrics (e.g.\nNDCG) while satisfying fairness of exposure constraints with respect to the\nitems. This framework expands the class of learnable ranking functions to\nstochastic ranking policies, which provides a language for rigorously\nexpressing fairness specifications. Furthermore, we provide a new LTR algorithm\ncalled Fair-PG-Rank for directly searching the space of fair ranking policies\nvia a policy-gradient approach. Beyond the theoretical evidence in deriving the\nframework and the algorithm, we provide empirical results on simulated and\nreal-world datasets verifying the effectiveness of the approach in individual\nand group-fairness settings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 18:56:10 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 20:15:35 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Singh", "Ashudeep", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1902.04057", "submitter": "Or Sharir", "authors": "Or Sharir, Yoav Levine, Noam Wies, Giuseppe Carleo and Amnon Shashua", "title": "Deep autoregressive models for the efficient variational simulation of\n  many-body quantum systems", "comments": null, "journal-ref": "Phys. Rev. Lett. 124, 020503 (2020)", "doi": "10.1103/PhysRevLett.124.020503", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks were recently shown to be an efficient\nrepresentation of highly-entangled many-body quantum states. In practical\napplications, neural-network states inherit numerical schemes used in\nVariational Monte Carlo, most notably the use of Markov-Chain Monte-Carlo\n(MCMC) sampling to estimate quantum expectations. The local stochastic sampling\nin MCMC caps the potential advantages of neural networks in two ways: (i) Its\nintrinsic computational cost sets stringent practical limits on the width and\ndepth of the networks, and therefore limits their expressive capacity; (ii) Its\ndifficulty in generating precise and uncorrelated samples can result in\nestimations of observables that are very far from their true value. Inspired by\nthe state-of-the-art generative models used in machine learning, we propose a\nspecialized Neural Network architecture that supports efficient and exact\nsampling, completely circumventing the need for Markov Chain sampling. We\ndemonstrate our approach for two-dimensional interacting spin models,\nshowcasing the ability to obtain accurate results on larger system sizes than\nthose currently accessible to neural-network quantum states.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 18:58:39 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 05:41:45 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2020 16:16:00 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Sharir", "Or", ""], ["Levine", "Yoav", ""], ["Wies", "Noam", ""], ["Carleo", "Giuseppe", ""], ["Shashua", "Amnon", ""]]}, {"id": "1902.04072", "submitter": "Andr\\'es Marafioti MSc", "authors": "Andr\\'es Marafioti, Nicki Holighaus, Nathana\\\"el Perraudin, Piotr\n  Majdak", "title": "Adversarial Generation of Time-Frequency Features with application in\n  audio synthesis", "comments": "Accepted for publication at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-frequency (TF) representations provide powerful and intuitive features\nfor the analysis of time series such as audio. But still, generative modeling\nof audio in the TF domain is a subtle matter. Consequently, neural audio\nsynthesis widely relies on directly modeling the waveform and previous attempts\nat unconditionally synthesizing audio from neurally generated invertible TF\nfeatures still struggle to produce audio at satisfying quality. In this\narticle, focusing on the short-time Fourier transform, we discuss the\nchallenges that arise in audio synthesis based on generated invertible TF\nfeatures and how to overcome them. We demonstrate the potential of deliberate\ngenerative TF modeling by training a generative adversarial network (GAN) on\nshort-time Fourier features. We show that by applying our guidelines, our\nTF-based network was able to outperform a state-of-the-art GAN generating\nwaveforms directly, despite the similar architecture in the two networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 14:11:04 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:35:51 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Marafioti", "Andr\u00e9s", ""], ["Holighaus", "Nicki", ""], ["Perraudin", "Nathana\u00ebl", ""], ["Majdak", "Piotr", ""]]}, {"id": "1902.04094", "submitter": "Alex Wang", "authors": "Alex Wang, Kyunghyun Cho", "title": "BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field\n  Language Model", "comments": "NeuralGen 2019;\n  https://colab.research.google.com/drive/1MxKZGtQ9SSBjTK5ArsZ5LKhkztzg52RV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that BERT (Devlin et al., 2018) is a Markov random field language\nmodel. This formulation gives way to a natural procedure to sample sentences\nfrom BERT. We generate from BERT and find that it can produce high-quality,\nfluent generations. Compared to the generations of a traditional left-to-right\nlanguage model, BERT generates sentences that are more diverse but of slightly\nworse quality.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:02:27 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 18:01:28 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Wang", "Alex", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1902.04107", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "Divergence-Based Motivation for Online EM and Combining Hidden Variable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation-Maximization (EM) is a prominent approach for parameter\nestimation of hidden (aka latent) variable models. Given the full batch of\ndata, EM forms an upper-bound of the negative log-likelihood of the model at\neach iteration and updates to the minimizer of this upper-bound. We first\nprovide a \"model level\" interpretation of the EM upper-bound as sum of relative\nentropy divergences to a set of singleton models, induced by the set of\nobservations. Our alternative motivation unifies the \"observation level\" and\nthe \"model level\" view of the EM. As a result, we formulate an online version\nof the EM algorithm by adding an analogous inertia term which corresponds to\nthe relative entropy divergence to the old model. Our motivation is more widely\napplicable than the previous approaches and leads to simple online updates for\nmixture of exponential distributions, hidden Markov models, and the first known\nonline update for Kalman filters. Additionally, the finite sample form of the\ninertia term lets us derive online updates when there is no closed-form\nsolution. Finally, we extend the analysis to the distributed setting where we\nmotivate a systematic way of combining multiple hidden variable models.\nExperimentally, we validate the results on synthetic as well as real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:35:13 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 06:56:59 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1902.04114", "submitter": "Victor Veitch", "authors": "Victor Veitch, Yixin Wang, David M. Blei", "title": "Using Embeddings to Correct for Unobserved Confounding in Networks", "comments": "An earlier version also addressed the use of text embeddings. That\n  material has been expanded and moved to arxiv:1905.12741, \"Using Text\n  Embeddings for Causal Inference\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider causal inference in the presence of unobserved confounding. We\nstudy the case where a proxy is available for the unobserved confounding in the\nform of a network connecting the units. For example, the link structure of a\nsocial network carries information about its members. We show how to\neffectively use the proxy to do causal inference. The main idea is to reduce\nthe causal estimation problem to a semi-supervised prediction of both the\ntreatments and outcomes. Networks admit high-quality embedding models that can\nbe used for this semi-supervised prediction. We show that the method yields\nvalid inferences under suitable (weak) conditions on the quality of the\npredictive model. We validate the method with experiments on a semi-synthetic\nsocial network dataset. Code is available at\ngithub.com/vveitch/causal-network-embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:47:17 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 17:33:12 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Veitch", "Victor", ""], ["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1902.04118", "submitter": "Sean Sedwards", "authors": "Jaeyoung Lee, Aravind Balakrishnan, Ashish Gaurav, Krzysztof\n  Czarnecki, Sean Sedwards", "title": "WiseMove: A Framework for Safe Deep Reinforcement Learning for\n  Autonomous Driving", "comments": null, "journal-ref": "International Conference on Quantitative Evaluation of Systems\n  (QEST 2019)", "doi": "10.1007/978-3-030-30281-8_20", "report-no": null, "categories": "cs.LG cs.NE cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can provide efficient solutions to the complex problems\nencountered in autonomous driving, but ensuring their safety remains a\nchallenge. A number of authors have attempted to address this issue, but there\nare few publicly-available tools to adequately explore the trade-offs between\nfunctionality, scalability, and safety.\n  We thus present WiseMove, a software framework to investigate safe deep\nreinforcement learning in the context of motion planning for autonomous\ndriving. WiseMove adopts a modular learning architecture that suits our current\nresearch questions and can be adapted to new technologies and new questions. We\npresent the details of WiseMove, demonstrate its use on a common traffic\nscenario, and describe how we use it in our ongoing safe learning research.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:59:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lee", "Jaeyoung", ""], ["Balakrishnan", "Aravind", ""], ["Gaurav", "Ashish", ""], ["Czarnecki", "Krzysztof", ""], ["Sedwards", "Sean", ""]]}, {"id": "1902.04132", "submitter": "Alekh Karkada Ashok", "authors": "Alekh Karkada Ashok, Chandan G, Adithya Bhat, Kausthubh Karnataki,\n  Ganesh Shankar", "title": "Automatic Inspection of Utility Scale Solar Power Plants using Deep\n  Learning", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar energy has the potential to become the backbone energy source for the\nworld. Utility scale solar power plants (more than 50 MW) could have more than\n100K individual solar modules and be spread over more than 200 acres of land.\nTraditionally methods of monitoring each module become too costly in the\nutility scale. We demonstrate an alternative using the recent advances in deep\nlearning to automatically analyze drone footage. We show that this can be a\nquick and reliable alternative. We show that it can save huge amounts of power\nand the impact the developing world hugely.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 14:26:36 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Ashok", "Alekh Karkada", ""], ["G", "Chandan", ""], ["Bhat", "Adithya", ""], ["Karnataki", "Kausthubh", ""], ["Shankar", "Ganesh", ""]]}, {"id": "1902.04139", "submitter": "Veeru Talreja", "authors": "Veeru Talreja, Fariborz Taherkhani, Matthew C. Valenti, and Nasser M.\n  Nasrabadi", "title": "Using Deep Cross Modal Hashing and Error Correcting Codes for Improving\n  the Efficiency of Attribute Guided Facial Image Retrieval", "comments": "To be published in Proc. IEEE Global SIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With benefits of fast query speed and low storage cost, hashing-based image\nretrieval approaches have garnered considerable attention from the research\ncommunity. In this paper, we propose a novel Error-Corrected Deep Cross Modal\nHashing (CMH-ECC) method which uses a bitmap specifying the presence of certain\nfacial attributes as an input query to retrieve relevant face images from the\ndatabase. In this architecture, we generate compact hash codes using an\nend-to-end deep learning module, which effectively captures the inherent\nrelationships between the face and attribute modality. We also integrate our\ndeep learning module with forward error correction codes to further reduce the\ndistance between different modalities of the same subject. Specifically, the\nproperties of deep hashing and forward error correction codes are exploited to\ndesign a cross modal hashing framework with high retrieval performance.\nExperimental results using two standard datasets with facial attributes-image\nmodalities indicate that our CMH-ECC face image retrieval model outperforms\nmost of the current attribute-based face image retrieval approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 20:42:52 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Talreja", "Veeru", ""], ["Taherkhani", "Fariborz", ""], ["Valenti", "Matthew C.", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1902.04147", "submitter": "C. H. Huck Yang", "authors": "Yi-Chieh Liu, Hao-Hsiang Yang, Chao-Han Huck Yang, Jia-Hong Huang,\n  Meng Tian, Hiromasa Morikawa, Yi-Chang James Tsai, Jesper Tegner", "title": "Synthesizing New Retinal Symptom Images by Multiple Generative Models", "comments": null, "journal-ref": "AI for Retinal Image Analysis Workshop ACCV 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Age-Related Macular Degeneration (AMD) is an asymptomatic retinal disease\nwhich may result in loss of vision. There is limited access to high-quality\nrelevant retinal images and poor understanding of the features defining\nsub-classes of this disease. Motivated by recent advances in machine learning\nwe specifically explore the potential of generative modeling, using Generative\nAdversarial Networks (GANs) and style transferring, to facilitate clinical\ndiagnosis and disease understanding by feature extraction. We design an\nanalytic pipeline which first generates synthetic retinal images from clinical\nimages; a subsequent verification step is applied. In the synthesizing step we\nmerge GANs (DCGANs and WGANs architectures) and style transferring for the\nimage generation, whereas the verified step controls the accuracy of the\ngenerated images. We find that the generated images contain sufficient\npathological details to facilitate ophthalmologists' task of disease\nclassification and in discovery of disease relevant features. In particular,\nour system predicts the drusen and geographic atrophy sub-classes of AMD.\nFurthermore, the performance using CFP images for GANs outperforms the\nclassification based on using only the original clinical dataset. Our results\nare evaluated using existing classifier of retinal diseases and class activated\nmaps, supporting the predictive power of the synthetic images and their utility\nfor feature extraction. Our code examples are available online.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 21:07:14 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Liu", "Yi-Chieh", ""], ["Yang", "Hao-Hsiang", ""], ["Yang", "Chao-Han Huck", ""], ["Huang", "Jia-Hong", ""], ["Tian", "Meng", ""], ["Morikawa", "Hiromasa", ""], ["Tsai", "Yi-Chang James", ""], ["Tegner", "Jesper", ""]]}, {"id": "1902.04149", "submitter": "Veeru Talreja", "authors": "Veeru Talreja, Sobhan Soleymani, Matthew C. Valenti, and Nasser M.\n  Nasrabadi", "title": "Learning to Authenticate with Deep Multibiometric Hashing and Neural\n  Network Decoding", "comments": "To be published in Proc. IEEE ICC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel multimodal deep hashing neural decoder\n(MDHND) architecture, which integrates a deep hashing framework with a neural\nnetwork decoder (NND) to create an effective multibiometric authentication\nsystem. The MDHND consists of two separate modules: a multimodal deep hashing\n(MDH) module, which is used for feature-level fusion and binarization of\nmultiple biometrics, and a neural network decoder (NND) module, which is used\nto refine the intermediate binary codes generated by the MDH and compensate for\nthe difference between enrollment and probe biometrics (variations in pose,\nillumination, etc.). Use of NND helps to improve the performance of the overall\nmultimodal authentication system. The MDHND framework is trained in 3 steps\nusing joint optimization of the two modules. In Step 1, the MDH parameters are\ntrained and learned to generate a shared multimodal latent code; in Step 2, the\nlatent codes from Step 1 are passed through a conventional error-correcting\ncode (ECC) decoder to generate the ground truth to train a neural network\ndecoder (NND); in Step 3, the NND decoder is trained using the ground truth\nfrom Step 2 and the MDH and NND are jointly optimized. Experimental results on\na standard multimodal dataset demonstrate the superiority of our method\nrelative to other current multimodal authentication systems\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 21:08:10 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:48:25 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 15:54:15 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Talreja", "Veeru", ""], ["Soleymani", "Sobhan", ""], ["Valenti", "Matthew C.", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1902.04151", "submitter": "Rony Gelman", "authors": "Rony Gelman", "title": "Evaluation of Transfer Learning for Classification of: (1) Diabetic\n  Retinopathy by Digital Fundus Photography and (2) Diabetic Macular Edema,\n  Choroidal Neovascularization and Drusen by Optical Coherence Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning has been successfully applied to a variety of image\nclassification tasks. There has been keen interest to apply deep learning in\nthe medical domain, particularly specialties that heavily utilize imaging, such\nas ophthalmology. One issue that may hinder application of deep learning to the\nmedical domain is the vast amount of data necessary to train deep neural\nnetworks (DNNs). Because of regulatory and privacy issues associated with\nmedicine, and the generally proprietary nature of data in medical domains,\nobtaining large datasets to train DNNs is a challenge, particularly in the\nophthalmology domain.\n  Transfer learning is a technique developed to address the issue of applying\nDNNs for domains with limited data. Prior reports on transfer learning have\nexamined custom networks to fully train or used a particular DNN for transfer\nlearning. However, to the best of my knowledge, no work has systematically\nexamined a suite of DNNs for transfer learning for classification of diabetic\nretinopathy, diabetic macular edema, and two key features of age-related\nmacular degeneration. This work attempts to investigate transfer learning for\nclassification of these ophthalmic conditions. Part I gives a condensed\noverview of neural networks and the DNNs under evaluation. Part II gives the\nreader the necessary background concerning diabetic retinopathy and prior work\non classification using retinal fundus photographs. The methodology and results\nof transfer learning for diabetic retinopathy classification are presented,\nshowing that transfer learning towards this domain is feasible, with promising\naccuracy. Part III gives an overview of diabetic macular edema, choroidal\nneovascularization and drusen (features associated with age-related macular\ndegeneration), and presents results for transfer learning evaluation using\noptical coherence tomography to classify these entities.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 22:26:29 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Gelman", "Rony", ""]]}, {"id": "1902.04166", "submitter": "Hakime \\\"Ozt\\\"urk", "authors": "Hakime \\\"Ozt\\\"urk, Elif Ozkirimli, Arzucan \\\"Ozg\\\"ur", "title": "WideDTA: prediction of drug-target binding affinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Prediction of the interaction affinity between proteins and\ncompounds is a major challenge in the drug discovery process. WideDTA is a\ndeep-learning based prediction model that employs chemical and biological\ntextual sequence information to predict binding affinity.\n  Results: WideDTA uses four text-based information sources, namely the protein\nsequence, ligand SMILES, protein domains and motifs, and maximum common\nsubstructure words to predict binding affinity. WideDTA outperformed one of the\nstate of the art deep learning methods for drug-target binding affinity\nprediction, DeepDTA on the KIBA dataset with a statistical significance. This\nindicates that the word-based sequence representation adapted by WideDTA is a\npromising alternative to the character-based sequence representation approach\nin deep learning models for binding affinity prediction, such as the one used\nin DeepDTA. In addition, the results showed that, given the protein sequence\nand ligand SMILES, the inclusion of protein domain and motif information as\nwell as ligand maximum common substructure words do not provide additional\nuseful information for the deep learning model. Interestingly, however, using\nonly domain and motif information to represent proteins achieved similar\nperformance to using the full protein sequence, suggesting that important\nbinding relevant information is contained within the protein motifs and\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:24:41 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["\u00d6zt\u00fcrk", "Hakime", ""], ["Ozkirimli", "Elif", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "1902.04177", "submitter": "Yifu Wu", "authors": "Yifu Wu, Jin Wei and Rigoberto Roche", "title": "Domain Constraint Approximation based Semi Supervision", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning for supervised learning has achieved astonishing performance in\nvarious machine learning applications. However, annotated data is expensive and\nrare. In practice, only a small portion of data samples are annotated.\nPseudo-ensembling-based approaches have achieved state-of-the-art results in\ncomputer vision related tasks. However, it still relies on the quality of an\ninitial model built by labeled data. Less labeled data may degrade model\nperformance a lot. Domain constraint is another way regularize the posterior\nbut has some limitation. In this paper, we proposed a fuzzy\ndomain-constraint-based framework which loses the requirement of traditional\nconstraint learning and enhances the model quality for semi supervision.\nSimulations results show the effectiveness of our design.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:11:33 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 08:18:49 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wu", "Yifu", ""], ["Wei", "Jin", ""], ["Roche", "Rigoberto", ""]]}, {"id": "1902.04178", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang, Clement H. C. Leung, and Vienne W. K. Sung", "title": "Stochastic Reinforcement Learning", "comments": "AIKE 2018", "journal-ref": null, "doi": "10.1109/AIKE.2018.00055", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning episodes, the rewards and punishments are often\nnon-deterministic, and there are invariably stochastic elements governing the\nunderlying situation. Such stochastic elements are often numerous and cannot be\nknown in advance, and they have a tendency to obscure the underlying rewards\nand punishments patterns. Indeed, if stochastic elements were absent, the same\noutcome would occur every time and the learning problems involved could be\ngreatly simplified. In addition, in most practical situations, the cost of an\nobservation to receive either a reward or punishment can be significant, and\none would wish to arrive at the correct learning conclusion by incurring\nminimum cost. In this paper, we present a stochastic approach to reinforcement\nlearning which explicitly models the variability present in the learning\nenvironment and the cost of observation. Criteria and rules for learning\nsuccess are quantitatively analyzed, and probabilities of exceeding the\nobservation cost bounds are also obtained.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:13:32 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""], ["Sung", "Vienne W. K.", ""]]}, {"id": "1902.04179", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang, Clement H. C. Leung", "title": "Performance Dynamics and Termination Errors in Reinforcement Learning: A\n  Unifying Perspective", "comments": "Short Paper in AIKE 2018", "journal-ref": null, "doi": "10.1109/AIKE.2018.00028", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, a decision needs to be made at some point as to\nwhether it is worthwhile to carry on with the learning process or to terminate\nit. In many such situations, stochastic elements are often present which govern\nthe occurrence of rewards, with the sequential occurrences of positive rewards\nrandomly interleaved with negative rewards. For most practical learners, the\nlearning is considered useful if the number of positive rewards always exceeds\nthe negative ones. A situation that often calls for learning termination is\nwhen the number of negative rewards exceeds the number of positive rewards.\nHowever, while this seems reasonable, the error of premature termination,\nwhereby termination is enacted along with the conclusion of learning failure\ndespite the positive rewards eventually far outnumber the negative ones, can be\nsignificant. In this paper, using combinatorial analysis we study the error\nprobability in wrongly terminating a reinforcement learning activity which\nundermines the effectiveness of an optimal policy, and we show that the\nresultant error can be quite high. Whilst we demonstrate mathematically that\nsuch errors can never be eliminated, we propose some practical mechanisms that\ncan effectively reduce such errors. Simulation experiments have been carried\nout, the results of which are in close agreement with our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:13:50 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1902.04181", "submitter": "Ga\\\"el Beck", "authors": "Ga\\\"el Beck, Tarn Duong, Mustapha Lebbah, Hanane Azzag", "title": "Nearest Neighbor Median Shift Clustering for Binary Data", "comments": "Algorithms are available at\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe in this paper the theory and practice behind a new modal\nclustering method for binary data. Our approach (BinNNMS) is based on the\nnearest neighbor median shift. The median shift is an extension of the\nwell-known mean shift, which was designed for continuous data, to handle binary\ndata. We demonstrate that BinNNMS can discover accurately the location of\nclusters in binary data with theoretical and experimental analyses.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:34:21 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Beck", "Ga\u00ebl", ""], ["Duong", "Tarn", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""]]}, {"id": "1902.04186", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai and Bamdev Mishra", "title": "Riemannian joint dimensionality reduction and dictionary learning on\n  symmetric positive definite manifold", "comments": "European Signal Processing Conference (EUSIPCO 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary leaning (DL) and dimensionality reduction (DR) are powerful tools\nto analyze high-dimensional noisy signals. This paper presents a proposal of a\nnovel Riemannian joint dimensionality reduction and dictionary learning\n(R-JDRDL) on symmetric positive definite (SPD) manifolds for classification\ntasks. The joint learning considers the interaction between dimensionality\nreduction and dictionary learning procedures by connecting them into a unified\nframework. We exploit a Riemannian optimization framework for solving DL and DR\nproblems jointly. Finally, we demonstrate that the proposed R-JDRDL outperforms\nexisting state-of-the-arts algorithms when used for image classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:49:03 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1902.04187", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Michael I. Jordan", "title": "LS-Tree: Model Interpretation When the Data Are Linguistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of interpreting trained classification models in the\nsetting of linguistic data sets. Leveraging a parse tree, we propose to assign\nleast-squares based importance scores to each word of an instance by exploiting\nsyntactic constituency structure. We establish an axiomatic characterization of\nthese importance scores by relating them to the Banzhaf value in coalitional\ngame theory. Based on these importance scores, we develop a principled method\nfor detecting and quantifying interactions between words in a sentence. We\ndemonstrate that the proposed method can aid in interpretability and\ndiagnostics for several widely-used language models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:58:22 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chen", "Jianbo", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.04198", "submitter": "Rohin Shah", "authors": "Rohin Shah, Dmitrii Krasheninnikov, Jordan Alexander, Pieter Abbeel,\n  Anca Dragan", "title": "Preferences Implicit in the State of the World", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents optimize only the features specified in a\nreward function and are indifferent to anything left out inadvertently. This\nmeans that we must not only specify what to do, but also the much larger space\nof what not to do. It is easy to forget these preferences, since these\npreferences are already satisfied in our environment. This motivates our key\ninsight: when a robot is deployed in an environment that humans act in, the\nstate of the environment is already optimized for what humans want. We can\ntherefore use this implicit preference information from the state to fill in\nthe blanks. We develop an algorithm based on Maximum Causal Entropy IRL and use\nit to evaluate the idea in a suite of proof-of-concept environments designed to\nshow its properties. We find that information from the initial state can be\nused to infer both side effects that should be avoided as well as preferences\nfor how the environment should be organized. Our code can be found at\nhttps://github.com/HumanCompatibleAI/rlsp.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 00:50:56 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 22:15:37 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Shah", "Rohin", ""], ["Krasheninnikov", "Dmitrii", ""], ["Alexander", "Jordan", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "1902.04202", "submitter": "Siwei Lyu", "authors": "Yuezun Li and Siwei Lyu", "title": "De-identification without losing faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of deep learning models for computer vision requires large image or\nvideo datasets from real world. Often, in collecting such datasets, we need to\nprotect the privacy of the people captured in the images or videos, while still\npreserve the useful attributes such as facial expressions. In this work, we\ndescribe a new face de-identification method that can preserve essential facial\nattributes in the faces while concealing the identities. Our method takes\nadvantage of the recent advances in face attribute transfer models, while\nmaintaining a high visual quality. Instead of changing factors of the original\nfaces or synthesizing faces completely, our method use a trained facial\nattribute transfer model to map non-identity related facial attributes to the\nface of donors, who are a small number (usually 2 to 3) of consented subjects.\nUsing the donors' faces ensures that the natural appearance of the synthesized\nfaces, while ensuring the identity of the synthesized faces are changed. On the\nother hand, the FATM blends the donors' facial attributes to those of the\noriginal faces to diversify the appearance of the synthesized faces.\nExperimental results on several sets of images and videos demonstrate the\neffectiveness of our face de-ID algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:15:15 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Li", "Yuezun", ""], ["Lyu", "Siwei", ""]]}, {"id": "1902.04205", "submitter": "Sung Min Lee", "authors": "Bukweon Kim, Sung Min Lee and Jin Keun Seo", "title": "Improving learnability of neural networks: adding supplementary axes to\n  disentangle data representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks have proven to be able to learn an\narbitrary dataset with 100$\\%$ training accuracy. Because of a risk of\noverfitting and computational cost issues, we cannot afford to increase the\nnumber of network nodes if we want achieve better training results for medical\nimages. Previous deep learning research shows that the training ability of a\nneural network improves dramatically (for the same epoch of training) when a\nfew nodes with supplementary information are added to the network. These few\ninformative nodes allow the network to learn features that are otherwise\ndifficult to learn by generating a disentangled data representation. This paper\nanalyzes how concatenation of additional information as supplementary axes\naffects the training of the neural networks. This analysis was conducted for a\nsimple multilayer perceptron (MLP) classification model with a rectified linear\nunit (ReLU) on two-dimensional training data. We compared the networks with and\nwithout concatenation of supplementary information to support our analysis. The\nmodel with concatenation showed more robust and accurate training results\ncompared to the model without concatenation. We also confirmed that our\nfindings are valid for deeper convolutional neural networks (CNN) using\nultrasound images and for a conditional generative adversarial network (cGAN)\nusing the MNIST data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:22:00 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Kim", "Bukweon", ""], ["Lee", "Sung Min", ""], ["Seo", "Jin Keun", ""]]}, {"id": "1902.04208", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Xiang Kong, Shanghang Zhang, Eduard Hovy", "title": "MaCow: Masked Convolutional Generative Flow", "comments": "In Proceedings of Thirty-third Conference on Neural Information\n  Processing Systems (NeurIPS-2019)", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models, conceptually attractive due to tractability of\nboth the exact log-likelihood computation and latent-variable inference, and\nefficiency of both training and sampling, has led to a number of impressive\nempirical successes and spawned many advanced variants and theoretical\ninvestigations. Despite their computational efficiency, the density estimation\nperformance of flow-based generative models significantly falls behind those of\nstate-of-the-art autoregressive models. In this work, we introduce masked\nconvolutional generative flow (MaCow), a simple yet effective architecture of\ngenerative flow using masked convolution. By restricting the local connectivity\nin a small kernel, MaCow enjoys the properties of fast and stable training, and\nefficient sampling, while achieving significant improvements over Glow for\ndensity estimation on standard image benchmarks, considerably narrowing the gap\nto autoregressive models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:31:06 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 18:34:51 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 18:46:40 GMT"}, {"version": "v4", "created": "Sat, 15 Jun 2019 15:33:07 GMT"}, {"version": "v5", "created": "Sun, 27 Oct 2019 00:45:11 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ma", "Xuezhe", ""], ["Kong", "Xiang", ""], ["Zhang", "Shanghang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1902.04217", "submitter": "Omar Montasser", "authors": "Omar Montasser, Steve Hanneke, Nathan Srebro", "title": "VC Classes are Adversarially Robustly Learnable, but Only Improperly", "comments": "COLT 2019 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of learning an adversarially robust predictor. We show\nthat any hypothesis class $\\mathcal{H}$ with finite VC dimension is robustly\nPAC learnable with an improper learning rule. The requirement of being improper\nis necessary as we exhibit examples of hypothesis classes $\\mathcal{H}$ with\nfinite VC dimension that are not robustly PAC learnable with any proper\nlearning rule.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 02:23:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:36:15 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Montasser", "Omar", ""], ["Hanneke", "Steve", ""], ["Srebro", "Nathan", ""]]}, {"id": "1902.04224", "submitter": "Myungsu Chae", "authors": "Dae-Woong Jeong, Jaehun Kim, Youngseok Kim, Tae-Ho Kim and Myungsu\n  Chae", "title": "Effective Network Compression Using Simulation-Guided Iterative Pruning", "comments": "Submitted to NIPS 2018 MLPCD2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing high-performance deep learning models require very intensive\ncomputing. For this reason, it is difficult to embed a deep learning model into\na system with limited resources. In this paper, we propose the novel idea of\nthe network compression as a method to solve this limitation. The principle of\nthis idea is to make iterative pruning more effective and sophisticated by\nsimulating the reduced network. A simple experiment was conducted to evaluate\nthe method; the results showed that the proposed method achieved higher\nperformance than existing methods at the same pruning level.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 03:21:44 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Jeong", "Dae-Woong", ""], ["Kim", "Jaehun", ""], ["Kim", "Youngseok", ""], ["Kim", "Tae-Ho", ""], ["Chae", "Myungsu", ""]]}, {"id": "1902.04228", "submitter": "Majid Abdolshah", "authors": "Majid Abdolshah, Alistair Shilton, Santu Rana, Sunil Gupta, Svetha\n  Venkatesh", "title": "Multi-objective Bayesian optimisation with preferences over objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-objective Bayesian optimisation algorithm that allows the\nuser to express preference-order constraints on the objectives of the type\n\"objective A is more important than objective B\". These preferences are defined\nbased on the stability of the obtained solutions with respect to preferred\nobjective functions. Rather than attempting to find a representative subset of\nthe complete Pareto front, our algorithm selects those Pareto-optimal points\nthat satisfy these constraints. We formulate a new acquisition function based\non expected improvement in dominated hypervolume (EHI) to ensure that the\nsubset of Pareto front satisfying the constraints is thoroughly explored. The\nhypervolume calculation is weighted by the probability of a point satisfying\nthe constraints from a gradient Gaussian Process model. We demonstrate our\nalgorithm on both synthetic and real-world problems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 03:47:16 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:21:54 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 04:24:25 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Abdolshah", "Majid", ""], ["Shilton", "Alistair", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1902.04236", "submitter": "Vignesh R", "authors": "Vignesh Ravichandran, Balamurali Murugesan, Vaishali Balakarthikeyan,\n  Sharath M Shankaranarayana, Keerthi Ram, Preejith S.P, Jayaraj Joseph and\n  Mohanasankar Sivaprakasam", "title": "RespNet: A deep learning model for extraction of respiration from\n  photoplethysmogram", "comments": "Under review at EMBC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory ailments afflict a wide range of people and manifests itself\nthrough conditions like asthma and sleep apnea. Continuous monitoring of\nchronic respiratory ailments is seldom used outside the intensive care ward due\nto the large size and cost of the monitoring system. While Electrocardiogram\n(ECG) based respiration extraction is a validated approach, its adoption is\nlimited by access to a suitable continuous ECG monitor. Recently, due to the\nwidespread adoption of wearable smartwatches with in-built Photoplethysmogram\n(PPG) sensor, it is being considered as a viable candidate for continuous and\nunobtrusive respiration monitoring. Research in this domain, however, has been\npredominantly focussed on estimating respiration rate from PPG. In this work, a\nnovel end-to-end deep learning network called RespNet is proposed to perform\nthe task of extracting the respiration signal from a given input PPG as opposed\nto extracting respiration rate. The proposed network was trained and tested on\ntwo different datasets utilizing different modalities of reference respiration\nsignal recordings. Also, the similarity and performance of the proposed network\nagainst two conventional signal processing approaches for extracting\nrespiration signal were studied. The proposed method was tested on two\nindependent datasets with a Mean Squared Error of 0.262 and 0.145. The\nCross-Correlation coefficient of the respective datasets were found to be 0.933\nand 0.931. The reported errors and similarity was found to be better than\nconventional approaches. The proposed approach would aid clinicians to provide\ncomprehensive evaluation of sleep-related respiratory conditions and chronic\nrespiratory ailments while being comfortable and inexpensive for the patient.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 04:36:34 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 10:11:24 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Ravichandran", "Vignesh", ""], ["Murugesan", "Balamurali", ""], ["Balakarthikeyan", "Vaishali", ""], ["Shankaranarayana", "Sharath M", ""], ["Ram", "Keerthi", ""], ["P", "Preejith S.", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "1902.04238", "submitter": "Xiaolei Liu", "authors": "Xiaolei Liu, Xiaojiang Du, Xiaosong Zhang, Qingxin Zhu, Mohsen Guizani", "title": "Adversarial Samples on Android Malware Detection Systems for IoT Systems", "comments": null, "journal-ref": null, "doi": "10.3390/s19040974", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT(Internet of Things) systems run Android systems or Android-like\nsystems. With the continuous development of machine learning algorithms, the\nlearning-based Android malware detection system for IoT devices has gradually\nincreased. However, these learning-based detection models are often vulnerable\nto adversarial samples. An automated testing framework is needed to help these\nlearning-based malware detection systems for IoT devices perform security\nanalysis. The current methods of generating adversarial samples mostly require\ntraining parameters of models and most of the methods are aimed at image data.\nTo solve this problem, we propose a \\textbf{t}esting framework for\n\\textbf{l}earning-based \\textbf{A}ndroid \\textbf{m}alware \\textbf{d}etection\nsystems(TLAMD) for IoT Devices. The key challenge is how to construct a\nsuitable fitness function to generate an effective adversarial sample without\naffecting the features of the application. By introducing genetic algorithms\nand some technical improvements, our test framework can generate adversarial\nsamples for the IoT Android Application with a success rate of nearly 100\\% and\ncan perform black-box testing on the system.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 04:56:07 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Liu", "Xiaolei", ""], ["Du", "Xiaojiang", ""], ["Zhang", "Xiaosong", ""], ["Zhu", "Qingxin", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1902.04247", "submitter": "Kento Nozawa", "authors": "Kento Nozawa, Issei Sato", "title": "PAC-Bayes Analysis of Sentence Representation", "comments": "fix styles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sentence vectors from an unlabeled corpus has attracted attention\nbecause such vectors can represent sentences in a lower dimensional and\ncontinuous space. Simple heuristics using pre-trained word vectors are widely\napplied to machine learning tasks. However, they are not well understood from a\ntheoretical perspective. We analyze learning sentence vectors from a transfer\nlearning perspective by using a PAC-Bayes bound that enables us to understand\nexisting heuristics. We show that simple heuristics such as averaging and\ninverse document frequency weighted averaging are derived by our formulation.\nMoreover, we propose novel sentence vector learning algorithms on the basis of\nour PAC-Bayes analysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 05:49:34 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 11:41:49 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Nozawa", "Kento", ""], ["Sato", "Issei", ""]]}, {"id": "1902.04248", "submitter": "Alexander Lapanowski", "authors": "Alexander F. Lapanowski and Irina Gaynanova", "title": "Sparse Feature Selection in Kernel Discriminant Analysis via Optimal\n  Scoring", "comments": "24 pages", "journal-ref": "AISTATS; Proceedings of Machine Learning Research, PMLR\n  89:1704-1713, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the two-group classification problem and propose a kernel\nclassifier based on the optimal scoring framework. Unlike previous approaches,\nwe provide theoretical guarantees on the expected risk consistency of the\nmethod. We also allow for feature selection by imposing structured sparsity\nusing weighted kernels. We propose fully-automated methods for selection of all\ntuning parameters, and in particular adapt kernel shrinkage ideas for ridge\nparameter selection. Numerical studies demonstrate the superior classification\nperformance of the proposed approach compared to existing nonparametric\nclassifiers.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 05:58:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Lapanowski", "Alexander F.", ""], ["Gaynanova", "Irina", ""]]}, {"id": "1902.04250", "submitter": "Michinari Kono", "authors": "Kohei Toyoda, Michinari Kono, Jun Rekimoto", "title": "Post-Data Augmentation to Improve Deep Pose Estimation of Extreme and\n  Wild Motions", "comments": "Accepted to IEEE VR 2019 Workshop on Human Augmentation and its\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contributions of recent deep-neural-network (DNN) based techniques have been\nplaying a significant role in human-computer interaction (HCI) and user\ninterface (UI) domains. One of the commonly used DNNs is human pose estimation.\nThis kind of technique is widely used for motion capturing of humans, and to\ngenerate or modify virtual avatars. However, in order to gain accuracy and to\nuse such systems, large and precise datasets are required for the machine\nlearning (ML) procedure. This can be especially difficult for extreme/wild\nmotions such as acrobatic movements or motions in specific sports, which are\ndifficult to estimate in typically provided training models. In addition,\ntraining may take a long duration, and will require a high-grade GPU for\nsufficient speed. To address these issues, we propose a method to improve the\npose estimation accuracy for extreme/wild motions by using pre-trained models,\ni.e., without performing the training procedure by yourselves. We assume our\nmethod to encourage usage of these DNN techniques for users in application\nareas that are out of the ML field, and to help users without high-end\ncomputers to apply them for personal and end use cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 06:14:01 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Toyoda", "Kohei", ""], ["Kono", "Michinari", ""], ["Rekimoto", "Jun", ""]]}, {"id": "1902.04251", "submitter": "Seungki Min", "authors": "Seungki Min, Costis Maglaras, Ciamac C. Moallemi", "title": "Thompson Sampling with Information Relaxation Penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a finite-horizon multi-armed bandit (MAB) problem in a Bayesian\nsetting, for which we propose an information relaxation sampling framework.\nWith this framework, we define an intuitive family of control policies that\ninclude Thompson sampling (TS) and the Bayesian optimal policy as endpoints.\nAnalogous to TS, which, at each decision epoch pulls an arm that is best with\nrespect to the randomly sampled parameters, our algorithms sample entire future\nreward realizations and take the corresponding best action. However, this is\ndone in the presence of \"penalties\" that seek to compensate for the\navailability of future information.\n  We develop several novel policies and performance bounds for MAB problems\nthat vary in terms of improving performance and increasing computational\ncomplexity between the two endpoints. Our policies can be viewed as natural\ngeneralizations of TS that simultaneously incorporate knowledge of the time\nhorizon and explicitly consider the exploration-exploitation trade-off. We\nprove associated structural results on performance bounds and suboptimality\ngaps. Numerical experiments suggest that this new class of policies perform\nwell, in particular in settings where the finite time horizon introduces\nsignificant exploration-exploitation tension into the problem. Finally,\ninspired by the finite-horizon Gittins index, we propose an index policy that\nbuilds on our framework that particularly outperforms the state-of-the-art\nalgorithms in our numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 06:18:33 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 16:44:31 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Min", "Seungki", ""], ["Maglaras", "Costis", ""], ["Moallemi", "Ciamac C.", ""]]}, {"id": "1902.04256", "submitter": "Mingda Qiao", "authors": "Mingda Qiao, Gregory Valiant", "title": "A Theory of Selective Prediction", "comments": "COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model of selective prediction, where the prediction algorithm\nis given a data sequence in an online fashion and asked to predict a\npre-specified statistic of the upcoming data points. The algorithm is allowed\nto choose when to make the prediction as well as the length of the prediction\nwindow, possibly depending on the observations so far. We prove that, even\nwithout any distributional assumption on the input data stream, a large family\nof statistics can be estimated to non-trivial accuracy. To give one concrete\nexample, suppose that we are given access to an arbitrary binary sequence $x_1,\n\\ldots, x_n$ of length $n$. Our goal is to accurately predict the average\nobservation, and we are allowed to choose the window over which the prediction\nis made: for some $t < n$ and $m \\le n - t$, after seeing $t$ observations we\npredict the average of $x_{t+1}, \\ldots, x_{t+m}$. This particular problem was\nfirst studied in Drucker (2013) and referred to as the \"density prediction\ngame\". We show that the expected squared error of our prediction can be bounded\nby $O(\\frac{1}{\\log n})$ and prove a matching lower bound, which resolves an\nopen question raised in Drucker (2013). This result holds for any sequence\n(that is not adaptive to when the prediction is made, or the predicted value),\nand the expectation of the error is with respect to the randomness of the\nprediction algorithm. Our results apply to more general statistics of a\nsequence of observations, and we highlight several open directions for future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 06:45:07 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 03:12:27 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 22:00:58 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Qiao", "Mingda", ""], ["Valiant", "Gregory", ""]]}, {"id": "1902.04257", "submitter": "Dilip Arumugam", "authors": "Dilip Arumugam, Jun Ki Lee, Sophie Saskin, Michael L. Littman", "title": "Deep Reinforcement Learning from Policy-Dependent Human Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To widen their accessibility and increase their utility, intelligent agents\nmust be able to learn complex behaviors as specified by (non-expert) human\nusers. Moreover, they will need to learn these behaviors within a reasonable\namount of time while efficiently leveraging the sparse feedback a human trainer\nis capable of providing. Recent work has shown that human feedback can be\ncharacterized as a critique of an agent's current behavior rather than as an\nalternative reward signal to be maximized, culminating in the COnvergent\nActor-Critic by Humans (COACH) algorithm for making direct policy updates based\non human feedback. Our work builds on COACH, moving to a setting where the\nagent's policy is represented by a deep neural network. We employ a series of\nmodifications on top of the original COACH algorithm that are critical for\nsuccessfully learning behaviors from high-dimensional observations, while also\nsatisfying the constraint of obtaining reduced sample complexity. We\ndemonstrate the effectiveness of our Deep COACH algorithm in the rich 3D world\nof Minecraft with an agent that learns to complete tasks by mapping from raw\npixels to actions using only real-time human feedback in 10-15 minutes of\ninteraction.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 06:45:21 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Arumugam", "Dilip", ""], ["Lee", "Jun Ki", ""], ["Saskin", "Sophie", ""], ["Littman", "Michael L.", ""]]}, {"id": "1902.04272", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Towards Self-Supervised High Level Sensor Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework to control a self-driving car by fusing\nraw information from RGB images and depth maps. A deep neural network\narchitecture is used for mapping the vision and depth information,\nrespectively, to steering commands. This fusion of information from two sensor\nsources allows to provide redundancy and fault tolerance in the presence of\nsensor failures. Even if one of the input sensors fails to produce the correct\noutput, the other functioning sensor would still be able to maneuver the car.\nSuch redundancy is crucial in the critical application of self-driving cars.\nThe experimental results have showed that our method is capable of learning to\nuse the relevant sensor information even when one of the sensors fail without\nany explicit signal.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 07:53:55 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.04294", "submitter": "Hojun Lee", "authors": "Jaeyoung Yoo, Hojun Lee, Nojun Kwak", "title": "Density Estimation and Incremental Learning of Latent Vector for\n  Generative Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we treat the image generation task using the autoencoder, a\nrepresentative latent model. Unlike many studies regularizing the latent\nvariable's distribution by assuming a manually specified prior, we approach the\nimage generation task using an autoencoder by directly estimating the latent\ndistribution. To do this, we introduce 'latent density estimator' which\ncaptures latent distribution explicitly and propose its structure. In addition,\nwe propose an incremental learning strategy of latent variables so that the\nautoencoder learns important features of data by using the structural\ncharacteristics of under-complete autoencoder without an explicit\nregularization term in the objective function. Through experiments, we show the\neffectiveness of the proposed latent density estimator and the incremental\nlearning strategy of latent variables. We also show that our generative model\ngenerates images with improved visual quality compared to previous generative\nmodels based on autoencoders.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 09:41:36 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Yoo", "Jaeyoung", ""], ["Lee", "Hojun", ""], ["Kwak", "Nojun", ""]]}, {"id": "1902.04326", "submitter": "Yue Tan", "authors": "Yue Tan, Kan Zheng, Lei Lei", "title": "An In-Vehicle KWS System with Multi-Source Fusion for Vehicle\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to maximize detection precision rate as well as the recall rate,\nthis paper proposes an in-vehicle multi-source fusion scheme in Keyword\nSpotting (KWS) System for vehicle applications. Vehicle information, as a new\nsource for the original system, is collected by an in-vehicle data acquisition\nplatform while the user is driving. A Deep Neural Network (DNN) is trained to\nextract acoustic features and make a speech classification. Based on the\nposterior probabilities obtained from DNN, the vehicle information including\nthe speed and direction of vehicle is applied to choose the suitable parameter\nfrom a pair of sensitivity values for the KWS system. The experimental results\nshow that the KWS system with the proposed multi-source fusion scheme can\nachieve better performances in term of precision rate, recall rate, and mean\nsquare error compared to the system without it.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 10:58:59 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 02:42:39 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tan", "Yue", ""], ["Zheng", "Kan", ""], ["Lei", "Lei", ""]]}, {"id": "1902.04335", "submitter": "Ryota Suzuki", "authors": "Ryota Suzuki, Ryusuke Takahama, Shun Onoda", "title": "Hyperbolic Disk Embeddings for Directed Acyclic Graphs", "comments": "Accepted for ICML 2019; Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining continuous representations of structural data such as directed\nacyclic graphs (DAGs) has gained attention in machine learning and artificial\nintelligence. However, embedding complex DAGs in which both ancestors and\ndescendants of nodes are exponentially increasing is difficult. Tackling in\nthis problem, we develop Disk Embeddings, which is a framework for embedding\nDAGs into quasi-metric spaces. Existing state-of-the-art methods, Order\nEmbeddings and Hyperbolic Entailment Cones, are instances of Disk Embedding in\nEuclidean space and spheres respectively. Furthermore, we propose a novel\nmethod Hyperbolic Disk Embeddings to handle exponential growth of relations.\nThe results of our experiments show that our Disk Embedding models outperform\nexisting methods especially in complex DAGs other than trees.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 11:23:30 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 03:03:55 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 04:54:22 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Suzuki", "Ryota", ""], ["Takahama", "Ryusuke", ""], ["Onoda", "Shun", ""]]}, {"id": "1902.04337", "submitter": "Jose Vilar", "authors": "Jose M. G. Vilar", "title": "Winning the Big Data Technologies Horizon Prize: Fast and reliable\n  forecasting of electricity grid traffic by identification of recurrent\n  fluctuations", "comments": "Approach and methodology used in winning the European Union Big Data\n  Technologies Horizon Prize\n  (https://ec.europa.eu/research/horizonprize/index.cfm?pg=prizes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cond-mat.stat-mech cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a description of the approach and methodology I used in\nwinning the European Union Big Data Technologies Horizon Prize on data-driven\nprediction of electricity grid traffic. The methodology relies on identifying\ntypical short-term recurrent fluctuations, which is subsequently refined\nthrough a regression-of-fluctuations approach. The key points and strategic\nconsiderations that led to selecting or discarding different methodological\naspects are also discussed. The criteria include adaptability to changing\nconditions, reliability with outliers and missing data, robustness to noise,\nand efficiency in implementation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 11:38:25 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Vilar", "Jose M. G.", ""]]}, {"id": "1902.04340", "submitter": "Julius Kunze", "authors": "Julius Kunze, Louis Kirsch, Hippolyt Ritter, David Barber", "title": "Gaussian Mean Field Regularizes by Limiting Learned Information", "comments": null, "journal-ref": null, "doi": "10.3390/e21080758", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference with a factorized Gaussian posterior estimate is a\nwidely used approach for learning parameters and hidden variables. Empirically,\na regularizing effect can be observed that is poorly understood. In this work,\nwe show how mean field inference improves generalization by limiting mutual\ninformation between learned parameters and the data through noise. We quantify\na maximum capacity when the posterior variance is either fixed or learned and\nconnect it to generalization error, even when the KL-divergence in the\nobjective is rescaled. Our experiments demonstrate that bounding information\nbetween parameters and data effectively regularizes neural networks on both\nsupervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 11:44:21 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kunze", "Julius", ""], ["Kirsch", "Louis", ""], ["Ritter", "Hippolyt", ""], ["Barber", "David", ""]]}, {"id": "1902.04341", "submitter": "Can Firtina", "authors": "Can Firtina, Jeremie S. Kim, Mohammed Alser, Damla Senol Cali, A.\n  Ercument Cicek, Can Alkan, Onur Mutlu", "title": "Apollo: A Sequencing-Technology-Independent, Scalable, and Accurate\n  Assembly Polishing Algorithm", "comments": "9 pages, 1 figure. Accepted in Bioinformatics", "journal-ref": "Bioinformatics . 2020 Jun 1;36(12):3669-3679", "doi": "10.1093/bioinformatics/btaa179", "report-no": null, "categories": "q-bio.GN cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long reads produced by third-generation sequencing technologies are used to\nconstruct an assembly (i.e., the subject's genome), which is further used in\ndownstream genome analysis. Unfortunately, long reads have high sequencing\nerror rates and a large proportion of bps in these long reads are incorrectly\nidentified. These errors propagate to the assembly and affect the accuracy of\ngenome analysis. Assembly polishing algorithms minimize such error propagation\nby polishing or fixing errors in the assembly by using information from\nalignments between reads and the assembly (i.e., read-to-assembly alignment\ninformation). However, assembly polishing algorithms can only polish an\nassembly using reads either from a certain sequencing technology or from a\nsmall assembly. Such technology-dependency and assembly-size dependency require\nresearchers to 1) run multiple polishing algorithms and 2) use small chunks of\na large genome to use all available read sets and polish large genomes. We\nintroduce Apollo, a universal assembly polishing algorithm that scales well to\npolish an assembly of any size (i.e., both large and small genomes) using reads\nfrom all sequencing technologies (i.e., second- and third-generation). Our goal\nis to provide a single algorithm that uses read sets from all available\nsequencing technologies to improve the accuracy of assembly polishing and that\ncan polish large genomes. Apollo 1) models an assembly as a profile hidden\nMarkov model (pHMM), 2) uses read-to-assembly alignment to train the pHMM with\nthe Forward-Backward algorithm, and 3) decodes the trained model with the\nViterbi algorithm to produce a polished assembly. Our experiments with real\nread sets demonstrate that Apollo is the only algorithm that 1) uses reads from\nany sequencing technology within a single run and 2) scales well to polish\nlarge assemblies without splitting the assembly into multiple parts.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 11:45:55 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 23:31:34 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Firtina", "Can", ""], ["Kim", "Jeremie S.", ""], ["Alser", "Mohammed", ""], ["Cali", "Damla Senol", ""], ["Cicek", "A. Ercument", ""], ["Alkan", "Can", ""], ["Mutlu", "Onur", ""]]}, {"id": "1902.04376", "submitter": "Xavier Fontaine", "authors": "Xavier Fontaine and Shie Mannor and Vianney Perchet", "title": "An adaptive stochastic optimization algorithm for resource allocation", "comments": "ALT2020, 45 pages, 9 figures", "journal-ref": "Proceedings of Machine Learning Research (PMLR), volume 117, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical problem of sequential resource allocation where a\ndecision maker must repeatedly divide a budget between several resources, each\nwith diminishing returns. This can be recast as a specific stochastic\noptimization problem where the objective is to maximize the cumulative reward,\nor equivalently to minimize the regret. We construct an algorithm that is {\\em\nadaptive} to the complexity of the problem, expressed in term of the regularity\nof the returns of the resources, measured by the exponent in the {\\L}ojasiewicz\ninequality (or by their universal concavity parameter). Our\nparameter-independent algorithm recovers the optimal rates for strongly-concave\nfunctions and the classical fast rates of multi-armed bandit (for linear reward\nfunctions). Moreover, the algorithm improves existing results on stochastic\noptimization in this regret minimization setting for intermediate cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 13:26:26 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 14:39:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 09:38:20 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Fontaine", "Xavier", ""], ["Mannor", "Shie", ""], ["Perchet", "Vianney", ""]]}, {"id": "1902.04394", "submitter": "Alex B\\\"auerle", "authors": "Alex B\\\"auerle, Christian van Onzenoodt, and Timo Ropinski", "title": "Net2Vis -- A Visual Grammar for Automatically Generating\n  Publication-Tailored CNN Architecture Visualizations", "comments": null, "journal-ref": null, "doi": "10.1109/TVCG.2021.3057483", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To convey neural network architectures in publications, appropriate\nvisualizations are of great importance. While most current deep learning papers\ncontain such visualizations, these are usually handcrafted just before\npublication, which results in a lack of a common visual grammar, significant\ntime investment, errors, and ambiguities. Current automatic network\nvisualization tools focus on debugging the network itself and are not ideal for\ngenerating publication visualizations. Therefore, we present an approach to\nautomate this process by translating network architectures specified in Keras\ninto visualizations that can directly be embedded into any publication. To do\nso, we propose a visual grammar for convolutional neural networks (CNNs), which\nhas been derived from an analysis of such figures extracted from all ICCV and\nCVPR papers published between 2013 and 2019. The proposed grammar incorporates\nvisual encoding, network layout, layer aggregation, and legend generation. We\nhave further realized our approach in an online system available to the\ncommunity, which we have evaluated through expert feedback, and a quantitative\nstudy. It not only reduces the time needed to generate network visualizations\nfor publications, but also enables a unified and unambiguous visualization\ndesign.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:13:58 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 12:36:21 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 13:28:54 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 12:01:15 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 07:10:22 GMT"}, {"version": "v6", "created": "Wed, 10 Feb 2021 09:46:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["B\u00e4uerle", "Alex", ""], ["van Onzenoodt", "Christian", ""], ["Ropinski", "Timo", ""]]}, {"id": "1902.04401", "submitter": "Zhitao Guan", "authors": "Dongliang Xu, Bailing Wang, XiaoJiang Du, Xiaoyan Zhu, zhitao Guan,\n  Xiaoyan Yu, Jingyu Liu", "title": "Verification Code Recognition Based on Active and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A verification code is an automated test method used to distinguish between\nhumans and computers. Humans can easily identify verification codes, whereas\nmachines cannot. With the development of convolutional neural networks,\nautomatically recognizing a verification code is now possible for machines.\nHowever, the advantages of convolutional neural networks depend on the data\nused by the training classifier, particularly the size of the training set.\nTherefore, identifying a verification code using a convolutional neural network\nis difficult when training data are insufficient. This study proposes an active\nand deep learning strategy to obtain new training data on a special\nverification code set without manual intervention. A feature learning model for\na scene with less training data is presented in this work, and the verification\ncode is identified by the designed convolutional neural network. Experiments\nshow that the method can considerably improve the recognition accuracy of a\nneural network when the amount of initial training data is small.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:19:10 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Xu", "Dongliang", ""], ["Wang", "Bailing", ""], ["Du", "XiaoJiang", ""], ["Zhu", "Xiaoyan", ""], ["Guan", "zhitao", ""], ["Yu", "Xiaoyan", ""], ["Liu", "Jingyu", ""]]}, {"id": "1902.04412", "submitter": "M. Hanefi Calp", "authors": "M. Hanefi Calp", "title": "An Estimation of Personnel Food Demand Quantity for Businesses by Using\n  Artificial Neural Networks", "comments": "13 Pages, 5 Figures, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, many public or private institutions provide professional food service\nfor personnels working in their own organizations. Regarding the planning of\nthe said service, there are some obstacles due to the fact that the number of\nthe personnel working in the institutions is generally high and the personnel\nare out of the institution due to personal or institutional reasons. Because of\nthis, it is difficult to determine the daily food demand, and this causes cost,\ntime and labor loss for the institutions. Statistical or heuristic methods are\nused to remove or at least minimize these losses. In this study, an artificial\nintelligence model was proposed, which estimates the daily food demand quantity\nusing artificial neural networks for businesses. The data are obtained from a\nrefectory database of a private institution with a capacity of 110 people\nserving daily meals and serving at different levels, covering the last two\nyears (2016-2018). The model was created using the MATLAB package program. The\nperformance of the model was determinde by the Regression values, the Mean\nAbsolute Percentage Error (MAPE) and the Mean Squared Error (MSE). In the\ntraining of the ANN model, feed forward back propagation network architecture\nis used. The best model obtained as a result of the experiments is a\nmulti-layer (8-10-10-1) structure with a training R ratio of 0,9948, a testing\nR ratio of 0,9830 and an error rate of 0,003783, respectively. Experimental\nresults demonstrated that the model has low error rate, high performance and\npositive effect of using artificial neural networks for demand estimating.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 18:38:55 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Calp", "M. Hanefi", ""]]}, {"id": "1902.04413", "submitter": "Do Le Quoc", "authors": "Roland Kunkel and Do Le Quoc and Franz Gregor and Sergei Arnautov and\n  Pramod Bhatotia and Christof Fetzer", "title": "TensorSCONE: A Secure TensorFlow Framework using Intel SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has become a critical component of modern data-driven online\nservices. Typically, the training phase of machine learning techniques requires\nto process large-scale datasets which may contain private and sensitive\ninformation of customers. This imposes significant security risks since modern\nonline services rely on cloud computing to store and process the sensitive\ndata. In the untrusted computing infrastructure, security is becoming a\nparamount concern since the customers need to trust the thirdparty cloud\nprovider. Unfortunately, this trust has been violated multiple times in the\npast. To overcome the potential security risks in the cloud, we answer the\nfollowing research question: how to enable secure executions of machine\nlearning computations in the untrusted infrastructure? To achieve this goal, we\npropose a hardware-assisted approach based on Trusted Execution Environments\n(TEEs), specifically Intel SGX, to enable secure execution of the machine\nlearning computations over the private and sensitive datasets. More\nspecifically, we propose a generic and secure machine learning framework based\non Tensorflow, which enables secure execution of existing applications on the\ncommodity untrusted infrastructure. In particular, we have built our system\ncalled TensorSCONE from ground-up by integrating TensorFlow with SCONE, a\nshielded execution framework based on Intel SGX. The main challenge of this\nwork is to overcome the architectural limitations of Intel SGX in the context\nof building a secure TensorFlow system. Our evaluation shows that we achieve\nreasonable performance overheads while providing strong security properties\nwith low TCB.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:48:25 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kunkel", "Roland", ""], ["Quoc", "Do Le", ""], ["Gregor", "Franz", ""], ["Arnautov", "Sergei", ""], ["Bhatotia", "Pramod", ""], ["Fetzer", "Christof", ""]]}, {"id": "1902.04420", "submitter": "Lea Duncker", "authors": "Lea Duncker, Gergo Bohner, Julien Boussard, Maneesh Sahani", "title": "Learning interpretable continuous-time models of latent stochastic\n  dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an approach to learn an interpretable semi-parametric model of a\nlatent continuous-time stochastic dynamical system, assuming noisy\nhigh-dimensional outputs sampled at uneven times. The dynamics are described by\na nonlinear stochastic differential equation (SDE) driven by a Wiener process,\nwith a drift evolution function drawn from a Gaussian process (GP) conditioned\non a set of learnt fixed points and corresponding local Jacobian matrices. This\nform yields a flexible nonparametric model of the dynamics, with a\nrepresentation corresponding directly to the interpretable portraits routinely\nemployed in the study of nonlinear dynamical systems. The learning algorithm\ncombines inference of continuous latent paths underlying observed data with a\nsparse variational description of the dynamical process. We demonstrate our\napproach on simulated data from different nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:50:51 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Duncker", "Lea", ""], ["Bohner", "Gergo", ""], ["Boussard", "Julien", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1902.04422", "submitter": "Andrew Webb", "authors": "Andrew M. Webb, Charles Reynolds, Wenlin Chen, Henry Reeve, Dan-Andrei\n  Iliescu, Mikel Lujan, Gavin Brown", "title": "To Ensemble or Not Ensemble: When does End-To-End Training Fail?", "comments": "Code: https://github.com/grey-area/modular-loss-experiments. Preprint\n  updated to reflect version accepted for publication at ECML", "journal-ref": null, "doi": "10.13140/RG.2.2.28091.46880", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-End training (E2E) is becoming more and more popular to train complex\nDeep Network architectures. An interesting question is whether this trend will\ncontinue-are there any clear failure cases for E2E training? We study this\nquestion in depth, for the specific case of E2E training an ensemble of\nnetworks. Our strategy is to blend the gradient smoothly in between two\nextremes: from independent training of the networks, up to to full E2E\ntraining. We find clear failure cases, where over-parameterized models cannot\nbe trained E2E. A surprising result is that the optimum can sometimes lie in\nbetween the two, neither an ensemble or an E2E system. The work also uncovers\nlinks to Dropout, and raises questions around the nature of ensemble diversity\nand multi-branch networks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:56:06 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 11:15:03 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 10:25:34 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 09:48:03 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Webb", "Andrew M.", ""], ["Reynolds", "Charles", ""], ["Chen", "Wenlin", ""], ["Reeve", "Henry", ""], ["Iliescu", "Dan-Andrei", ""], ["Lujan", "Mikel", ""], ["Brown", "Gavin", ""]]}, {"id": "1902.04484", "submitter": "Lin Zhu", "authors": "Lin Zhu, Yihong Chen, Bowen He", "title": "A Domain Generalization Perspective on Listwise Context Modeling", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the most popular techniques for solving the ranking problem in\ninformation retrieval, Learning-to-rank (LETOR) has received a lot of attention\nboth in academia and industry due to its importance in a wide variety of data\nmining applications. However, most of existing LETOR approaches choose to learn\na single global ranking function to handle all queries, and ignore the\nsubstantial differences that exist between queries. In this paper, we propose a\ndomain generalization strategy to tackle this problem. We propose\nQuery-Invariant Listwise Context Modeling (QILCM), a novel neural architecture\nwhich eliminates the detrimental influence of inter-query variability by\nlearning \\textit{query-invariant} latent representations, such that the ranking\nsystem could generalize better to unseen queries. We evaluate our techniques on\nbenchmark datasets, demonstrating that QILCM outperforms previous\nstate-of-the-art approaches by a substantial margin.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 16:39:35 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Zhu", "Lin", ""], ["Chen", "Yihong", ""], ["He", "Bowen", ""]]}, {"id": "1902.04485", "submitter": "Jonathan Donier", "authors": "Jonathan Donier", "title": "Capacity allocation analysis of neural networks: A tool for principled\n  architecture design", "comments": "25 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing neural network architectures is a task that lies somewhere between\nscience and art. For a given task, some architectures are eventually preferred\nover others, based on a mix of intuition, experience, experimentation and luck.\nFor many tasks, the final word is attributed to the loss function, while for\nsome others a further perceptual evaluation is necessary to assess and compare\nperformance across models. In this paper, we introduce the concept of capacity\nallocation analysis, with the aim of shedding some light on what network\narchitectures focus their modelling capacity on, when used on a given task. We\nfocus more particularly on spatial capacity allocation, which analyzes a\nposteriori the effective number of parameters that a given model has allocated\nfor modelling dependencies on a given point or region in the input space, in\nlinear settings. We use this framework to perform a quantitative comparison\nbetween some classical architectures on various synthetic tasks. Finally, we\nconsider how capacity allocation might translate in non-linear settings.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 16:43:36 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Donier", "Jonathan", ""]]}, {"id": "1902.04487", "submitter": "Diedre Carmo", "authors": "Diedre Carmo, Bruna Silva, Clarissa Yasuda, Let\\'icia Rittner, Roberto\n  Lotufo", "title": "Extended 2D Consensus Hippocampus Segmentation", "comments": "This was published as an extended abstract in MIDL 2019\n  [arXiv:1907.08612]. An alpha version of the code is available at\n  https://github.com/dscarmo/e2dhipseg. More experiments on improvements to the\n  method and code are ongoing. Future updates are to be expected. A new, more\n  complete paper is published in arXiv:2001.05058", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/Sygx97DaKV", "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hippocampus segmentation plays a key role in diagnosing various brain\ndisorders such as Alzheimer's disease, epilepsy, multiple sclerosis, cancer,\ndepression and others. Nowadays, segmentation is still mainly performed\nmanually by specialists. Segmentation done by experts is considered to be a\ngold-standard when evaluating automated methods, buts it is a time consuming\nand arduos task, requiring specialized personnel. In recent years, efforts have\nbeen made to achieve reliable automated segmentation. For years the best\nperforming authomatic methods were multi atlas based with around 80-85% Dice\ncoefficient and very time consuming, but machine learning methods are recently\nrising with promising time and accuracy performance. A method for volumetric\nhippocampus segmentation is presented, based on the consensus of tri-planar\nU-Net inspired fully convolutional networks (FCNNs), with some modifications,\nincluding residual connections, VGG weight transfers, batch normalization and a\npatch extraction technique employing data from neighbor patches. A study on the\nimpact of our modifications to the classical U-Net architecture was performed.\nOur method achieves cutting edge performance in our dataset, with around 96%\nvolumetric Dice accuracy in our test data. In a public validation dataset,\nHARP, we achieve 87.48% DICE. GPU execution time is in the order of seconds per\nvolume, and source code is publicly available. Also, masks are shown to be\nsimilar to other recent state-of-the-art hippocampus segmentation methods in a\nthird dataset, without manual annotations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 16:44:35 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 16:11:41 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 20:21:52 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 00:26:48 GMT"}, {"version": "v5", "created": "Wed, 13 May 2020 22:01:47 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Carmo", "Diedre", ""], ["Silva", "Bruna", ""], ["Yasuda", "Clarissa", ""], ["Rittner", "Let\u00edcia", ""], ["Lotufo", "Roberto", ""]]}, {"id": "1902.04495", "submitter": "Linjun Zhang", "authors": "T. Tony Cai, Yichen Wang and Linjun Zhang", "title": "The Cost of Privacy: Optimal Rates of Convergence for Parameter\n  Estimation with Differential Privacy", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving data analysis is a rising challenge in contemporary\nstatistics, as the privacy guarantees of statistical methods are often achieved\nat the expense of accuracy. In this paper, we investigate the tradeoff between\nstatistical accuracy and privacy in mean estimation and linear regression,\nunder both the classical low-dimensional and modern high-dimensional settings.\nA primary focus is to establish minimax optimality for statistical estimation\nwith the $(\\varepsilon,\\delta)$-differential privacy constraint. To this end,\nwe find that classical lower bound arguments fail to yield sharp results, and\nnew technical tools are called for.\n  By refining the \"tracing adversary\" technique for lower bounds in the\ntheoretical computer science literature, we formulate a general lower bound\nargument for minimax risks with differential privacy constraints, and apply\nthis argument to high-dimensional mean estimation and linear regression\nproblems. We also design computationally efficient algorithms that attain the\nminimax lower bounds up to a logarithmic factor. In particular, for the\nhigh-dimensional linear regression, a novel private iterative hard thresholding\npursuit algorithm is proposed, based on a privately truncated version of\nstochastic gradient descent. The numerical performance of these algorithms is\ndemonstrated by simulation studies and applications to real data containing\nsensitive information, for which privacy-preserving statistical methods are\nnecessary.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 16:59:15 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 01:09:36 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 20:29:28 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:16:51 GMT"}, {"version": "v5", "created": "Tue, 10 Nov 2020 16:57:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Cai", "T. Tony", ""], ["Wang", "Yichen", ""], ["Zhang", "Linjun", ""]]}, {"id": "1902.04510", "submitter": "Andrii Trelin", "authors": "Andrii Trelin and Ales Prochazka", "title": "Binary Stochastic Filtering: a Method for Neural Network Size\n  Minimization and Supervised Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Binary Stochastic Filtering (BSF), the algorithm for feature selection and\nneuron pruning is proposed in this work. The method defines filtering layer\nwhich penalizes amount of the information involved in the training process.\nThis information could be the input data or output of the previous layer, which\ndirectly leads to the feature selection or neuron pruning respectively,\nproducing \\textit{ad hoc} subset of features or selecting optimal number of\nneurons in each layer. Filtering layer stochastically passes or drops features\nbased on individual weights, which are tuned with standard backpropagation\nalgorithm during the training process. Multifold decrease of neural network\nsize has been achieved in the experiments. Besides, the method was able to\nselect minimal number of features, surpassing literature references by the\naccuracy/dimensionality ratio.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:32:28 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 13:32:06 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Trelin", "Andrii", ""], ["Prochazka", "Ales", ""]]}, {"id": "1902.04521", "submitter": "Argyris Kalogeratos", "authors": "Batiste Le Bars and Argyris Kalogeratos", "title": "A Probabilistic Framework to Node-level Anomaly Detection in\n  Communication Networks", "comments": "9 pages, 4 figures", "journal-ref": "IEEE International Conference on Computer Communications 2019\n  (INFOCOM), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the task of detecting abnormal communication volume\noccurring at node-level in communication networks. The signal of the\ncommunication activity is modeled by means of a clique stream: each occurring\ncommunication event is instantaneous and activates an undirected subgraph\nspanning over a set of equally participating nodes. We present a probabilistic\nframework to model and assess the communication volume observed at any single\nnode. Specifically, we employ non-parametric regression to learn the\nprobability that a node takes part in a certain event knowing the set of other\nnodes that are involved. On the top of that, we present a concentration\ninequality around the estimated volume of events in which a node could\nparticipate, which in turn allows us to build an efficient and interpretable\nanomaly scoring function. Finally, the superior performance of the proposed\napproach is empirically demonstrated in real-world sensor network data, as well\nas using synthetic communication activity that is in accordance with that\nlatter setting.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:56:34 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Bars", "Batiste Le", ""], ["Kalogeratos", "Argyris", ""]]}, {"id": "1902.04522", "submitter": "Jerry Ma", "authors": "Yuandong Tian, Jerry Ma, Qucheng Gong, Shubho Sengupta, Zhuoyuan Chen,\n  James Pinkerton, C. Lawrence Zitnick", "title": "ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero", "comments": "Published as a conference paper at ICML 2019. This version contains\n  supplementary appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The AlphaGo, AlphaGo Zero, and AlphaZero series of algorithms are remarkable\ndemonstrations of deep reinforcement learning's capabilities, achieving\nsuperhuman performance in the complex game of Go with progressively increasing\nautonomy. However, many obstacles remain in the understanding of and usability\nof these promising approaches by the research community. Toward elucidating\nunresolved mysteries and facilitating future research, we propose ELF OpenGo,\nan open-source reimplementation of the AlphaZero algorithm. ELF OpenGo is the\nfirst open-source Go AI to convincingly demonstrate superhuman performance with\na perfect (20:0) record against global top professionals. We apply ELF OpenGo\nto conduct extensive ablation studies, and to identify and analyze numerous\ninteresting phenomena in both the model training and in the gameplay inference\nprocedures. Our code, models, selfplay datasets, and auxiliary data are\npublicly available.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:59:38 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 14:54:44 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 00:01:31 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 18:24:50 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Tian", "Yuandong", ""], ["Ma", "Jerry", ""], ["Gong", "Qucheng", ""], ["Sengupta", "Shubho", ""], ["Chen", "Zhuoyuan", ""], ["Pinkerton", "James", ""], ["Zitnick", "C. Lawrence", ""]]}, {"id": "1902.04524", "submitter": "Diego Agudelo-Espa\\~na", "authors": "Diego Agudelo-Espa\\~na, Sebastian Gomez-Gonzalez, Stefan Bauer,\n  Bernhard Sch\\\"olkopf and Jan Peters", "title": "Bayesian Online Prediction of Change Points", "comments": "shortened title, updated references, added section about\n  hyperparameter learning, extended background section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online detection of instantaneous changes in the generative process of a data\nsequence generally focuses on retrospective inference of such change points\nwithout considering their future occurrences. We extend the Bayesian Online\nChange Point Detection algorithm to also infer the number of time steps until\nthe next change point (i.e., the residual time). This enables to handle\nobservation models which depend on the total segment duration, which is useful\nto model data sequences with temporal scaling. The resulting inference\nalgorithm for segment detection can be deployed in an online fashion, and we\nillustrate applications to synthetic and to two medical real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:01:35 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:13:58 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Agudelo-Espa\u00f1a", "Diego", ""], ["Gomez-Gonzalez", "Sebastian", ""], ["Bauer", "Stefan", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Peters", "Jan", ""]]}, {"id": "1902.04546", "submitter": "Harris Chan", "authors": "Harris Chan, Yuhuai Wu, Jamie Kiros, Sanja Fidler, Jimmy Ba", "title": "ACTRCE: Augmenting Experience via Teacher's Advice For Multi-Goal\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse reward is one of the most challenging problems in reinforcement\nlearning (RL). Hindsight Experience Replay (HER) attempts to address this issue\nby converting a failed experience to a successful one by relabeling the goals.\nDespite its effectiveness, HER has limited applicability because it lacks a\ncompact and universal goal representation. We present Augmenting experienCe via\nTeacheR's adviCE (ACTRCE), an efficient reinforcement learning technique that\nextends the HER framework using natural language as the goal representation. We\nfirst analyze the differences among goal representation, and show that ACTRCE\ncan efficiently solve difficult reinforcement learning problems in challenging\n3D navigation tasks, whereas HER with non-language goal representation failed\nto learn. We also show that with language goal representations, the agent can\ngeneralize to unseen instructions, and even generalize to instructions with\nunseen lexicons. We further demonstrate it is crucial to use hindsight advice\nto solve challenging tasks, and even small amount of advice is sufficient for\nthe agent to achieve good performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:43:56 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chan", "Harris", ""], ["Wu", "Yuhuai", ""], ["Kiros", "Jamie", ""], ["Fidler", "Sanja", ""], ["Ba", "Jimmy", ""]]}, {"id": "1902.04552", "submitter": "Kelsey Allen", "authors": "Kelsey R. Allen, Evan Shelhamer, Hanul Shin, Joshua B. Tenenbaum", "title": "Infinite Mixture Prototypes for Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose infinite mixture prototypes to adaptively represent both simple\nand complex data distributions for few-shot learning. Our infinite mixture\nprototypes represent each class by a set of clusters, unlike existing\nprototypical methods that represent each class by a single cluster. By\ninferring the number of clusters, infinite mixture prototypes interpolate\nbetween nearest neighbor and prototypical representations, which improves\naccuracy and robustness in the few-shot regime. We show the importance of\nadaptive capacity for capturing complex data distributions such as alphabets,\nwith 25% absolute accuracy improvements over prototypical networks, while still\nmaintaining or improving accuracy on the standard Omniglot and mini-ImageNet\nbenchmarks. In clustering labeled and unlabeled data by the same clustering\nrule, infinite mixture prototypes achieves state-of-the-art semi-supervised\naccuracy. As a further capability, we show that infinite mixture prototypes can\nperform purely unsupervised clustering, unlike existing prototypical methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:55:18 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Allen", "Kelsey R.", ""], ["Shelhamer", "Evan", ""], ["Shin", "Hanul", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1902.04553", "submitter": "Ramya Korlakai Vinayak", "authors": "Ramya Korlakai Vinayak, Weihao Kong, Gregory Valiant and Sham M.\n  Kakade", "title": "Maximum Likelihood Estimation for Learning Populations of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a setting with $N$ independent individuals, each with an unknown\nparameter, $p_i \\in [0, 1]$ drawn from some unknown distribution $P^\\star$.\nAfter observing the outcomes of $t$ independent Bernoulli trials, i.e., $X_i\n\\sim \\text{Binomial}(t, p_i)$ per individual, our objective is to accurately\nestimate $P^\\star$. This problem arises in numerous domains, including the\nsocial sciences, psychology, health-care, and biology, where the size of the\npopulation under study is usually large while the number of observations per\nindividual is often limited. Our main result shows that, in the regime where $t\n\\ll N$, the maximum likelihood estimator (MLE) is both statistically minimax\noptimal and efficiently computable. Precisely, for sufficiently large $N$, the\nMLE achieves the information theoretic optimal error bound of\n$\\mathcal{O}(\\frac{1}{t})$ for $t < c\\log{N}$, with regards to the earth\nmover's distance (between the estimated and true distributions). More\ngenerally, in an exponentially large interval of $t$ beyond $c \\log{N}$, the\nMLE achieves the minimax error bound of $\\mathcal{O}(\\frac{1}{\\sqrt{t\\log\nN}})$. In contrast, regardless of how large $N$ is, the naive \"plug-in\"\nestimator for this problem only achieves the sub-optimal error of\n$\\Theta(\\frac{1}{\\sqrt{t}})$.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:55:31 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Vinayak", "Ramya Korlakai", ""], ["Kong", "Weihao", ""], ["Valiant", "Gregory", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1902.04560", "submitter": "Manaar Alam", "authors": "Manaar Alam, Arnab Bag, Debapriya Basu Roy, Dirmanto Jap, Jakub\n  Breier, Shivam Bhasin, Debdeep Mukhopadhyay", "title": "Enhancing Fault Tolerance of Neural Networks for Security-Critical\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NN) have recently emerged as backbone of several sensitive\napplications like automobile, medical image, security, etc. NNs inherently\noffer Partial Fault Tolerance (PFT) in their architecture; however, the biased\nPFT of NNs can lead to severe consequences in applications like cryptography\nand security critical scenarios. In this paper, we propose a revised\nimplementation which enhances the PFT property of NN significantly with\ndetailed mathematical analysis. We evaluated the performance of revised NN\nconsidering both software and FPGA implementation for a cryptographic primitive\nlike AES SBox. The results show that the PFT of NNs can be significantly\nincreased with the proposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 11:53:48 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Alam", "Manaar", ""], ["Bag", "Arnab", ""], ["Roy", "Debapriya Basu", ""], ["Jap", "Dirmanto", ""], ["Breier", "Jakub", ""], ["Bhasin", "Shivam", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1902.04601", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Contrastive Variational Autoencoder Enhances Salient Features", "comments": "Submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders are powerful algorithms for identifying dominant\nlatent structure in a single dataset. In many applications, however, we are\ninterested in modeling latent structure and variation that are enriched in a\ntarget dataset compared to some background---e.g. enriched in patients compared\nto the general population. Contrastive learning is a principled framework to\ncapture such enriched variation between the target and background, but\nstate-of-the-art contrastive methods are limited to linear models. In this\npaper, we introduce the contrastive variational autoencoder (cVAE), which\ncombines the benefits of contrastive learning with the power of deep generative\nmodels. The cVAE is designed to identify and enhance salient latent features.\nThe cVAE is trained on two related but unpaired datasets, one of which has\nminimal contribution from the salient latent features. The cVAE explicitly\nmodels latent features that are shared between the datasets, as well as those\nthat are enriched in one dataset relative to the other, which allows the\nalgorithm to isolate and enhance the salient latent features. The algorithm is\nstraightforward to implement, has a similar run-time to the standard VAE, and\nis robust to noise and dataset purity. We conduct experiments across diverse\ntypes of data, including gene expression and facial images, showing that the\ncVAE effectively uncovers latent structure that is salient in a particular\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 19:32:48 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1902.04610", "submitter": "Peifeng Yu", "authors": "Peifeng Yu and Mosharaf Chowdhury", "title": "Salus: Fine-Grained GPU Sharing Primitives for Deep Learning\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU computing is becoming increasingly more popular with the proliferation of\ndeep learning (DL) applications. However, unlike traditional resources such as\nCPU or the network, modern GPUs do not natively support fine-grained sharing\nprimitives. Consequently, implementing common policies such as time sharing and\npreemption are expensive. Worse, when a DL application cannot completely use a\nGPU's resources, the GPU cannot be efficiently shared between multiple\napplications, leading to GPU underutilization.\n  We present Salus to enable two GPU sharing primitives: fast job switching and\nmemory sharing, in order to achieve fine-grained GPU sharing among multiple DL\napplications. Salus implements an efficient, consolidated execution service\nthat exposes the GPU to different DL applications, and enforces fine-grained\nsharing by performing iteration scheduling and addressing associated memory\nmanagement issues. We show that these primitives can then be used to implement\nflexible sharing policies such as fairness, prioritization, and packing for\nvarious use cases. Our integration of Salus with TensorFlow and evaluation on\npopular DL jobs show that Salus can improve the average completion time of DL\ntraining jobs by $3.19\\times$, GPU utilization for hyper-parameter tuning by\n$2.38\\times$, and GPU utilization of DL inference applications by $42\\times$\nover not sharing the GPU and $7\\times$ over NVIDIA MPS with small overhead.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 19:56:55 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yu", "Peifeng", ""], ["Chowdhury", "Mosharaf", ""]]}, {"id": "1902.04615", "submitter": "Taco Cohen", "authors": "Taco S. Cohen, Maurice Weiler, Berkay Kicanaoglu, Max Welling", "title": "Gauge Equivariant Convolutional Networks and the Icosahedral CNN", "comments": "Proceedings of the International Conference on Machine Learning\n  (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of equivariance to symmetry transformations enables a\ntheoretically grounded approach to neural network architecture design.\nEquivariant networks have shown excellent performance and data efficiency on\nvision and medical imaging problems that exhibit symmetries. Here we show how\nthis principle can be extended beyond global symmetries to local gauge\ntransformations. This enables the development of a very general class of\nconvolutional neural networks on manifolds that depend only on the intrinsic\ngeometry, and which includes many popular methods from equivariant and\ngeometric deep learning. We implement gauge equivariant CNNs for signals\ndefined on the surface of the icosahedron, which provides a reasonable\napproximation of the sphere. By choosing to work with this very regular\nmanifold, we are able to implement the gauge equivariant convolution using a\nsingle conv2d call, making it a highly scalable and practical alternative to\nSpherical CNNs. Using this method, we demonstrate substantial improvements over\nprevious methods on the task of segmenting omnidirectional images and global\nclimate patterns.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 17:01:05 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 09:50:05 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 23:03:52 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Cohen", "Taco S.", ""], ["Weiler", "Maurice", ""], ["Kicanaoglu", "Berkay", ""], ["Welling", "Max", ""]]}, {"id": "1902.04620", "submitter": "Xinyi Chen", "authors": "Xinyi Chen, Naman Agarwal, Elad Hazan, Cyril Zhang, Yi Zhang", "title": "Extreme Tensoring for Low-Memory Preconditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models are now trained with billions of parameters, reaching\nhardware limits in terms of memory consumption. This has created a recent\ndemand for memory-efficient optimizers. To this end, we investigate the limits\nand performance tradeoffs of memory-efficient adaptively preconditioned\ngradient methods. We propose extreme tensoring for high-dimensional stochastic\noptimization, showing that an optimizer needs very little memory to benefit\nfrom adaptive preconditioning. Our technique applies to arbitrary models (not\nnecessarily with tensor-shaped parameters), and is accompanied by regret and\nconvergence guarantees, which shed light on the tradeoffs between\npreconditioner quality and expressivity. On a large-scale NLP model, we reduce\nthe optimizer memory overhead by three orders of magnitude, without degrading\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:24:01 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Chen", "Xinyi", ""], ["Agarwal", "Naman", ""], ["Hazan", "Elad", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1902.04622", "submitter": "Michael Banf", "authors": "Michael Banf", "title": "Learning Theory and Support Vector Machines - a primer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main goal of statistical learning theory is to provide a fundamental\nframework for the problem of decision making and model construction based on\nsets of data. Here, we present a brief introduction to the fundamentals of\nstatistical learning theory, in particular the difference between empirical and\nstructural risk minimization, including one of its most prominent\nimplementations, i.e. the Support Vector Machine.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:28:09 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Banf", "Michael", ""]]}, {"id": "1902.04629", "submitter": "Lev Reyzin", "authors": "Shelby Heinecke and Lev Reyzin", "title": "Crowdsourced PAC Learning under Classification Noise", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze PAC learnability from labels produced by\ncrowdsourcing. In our setting, unlabeled examples are drawn from a distribution\nand labels are crowdsourced from workers who operate under classification\nnoise, each with their own noise parameter. We develop an end-to-end\ncrowdsourced PAC learning algorithm that takes unlabeled data points as input\nand outputs a trained classifier. Our three-step algorithm incorporates\nmajority voting, pure-exploration bandits, and noisy-PAC learning. We prove\nseveral guarantees on the number of tasks labeled by workers for PAC learning\nin this setting and show that our algorithm improves upon the baseline by\nreducing the total number of tasks given to workers. We demonstrate the\nrobustness of our algorithm by exploring its application to additional\nrealistic crowdsourcing settings.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:54:44 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Heinecke", "Shelby", ""], ["Reyzin", "Lev", ""]]}, {"id": "1902.04639", "submitter": "Tyler Sypherd", "authors": "Tyler Sypherd, Mario Diaz, Lalitha Sankar, Peter Kairouz", "title": "A Tunable Loss Function for Binary Classification", "comments": "9 pages, 1 figure, ISIT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present $\\alpha$-loss, $\\alpha \\in [1,\\infty]$, a tunable loss function\nfor binary classification that bridges log-loss ($\\alpha=1$) and $0$-$1$ loss\n($\\alpha = \\infty$). We prove that $\\alpha$-loss has an equivalent margin-based\nform and is classification-calibrated, two desirable properties for a good\nsurrogate loss function for the ideal yet intractable $0$-$1$ loss. For\nlogistic regression-based classification, we provide an upper bound on the\ndifference between the empirical and expected risk at the empirical risk\nminimizers for $\\alpha$-loss by exploiting its Lipschitzianity along with\nrecent results on the landscape features of empirical risk functions. Finally,\nwe show that $\\alpha$-loss with $\\alpha = 2$ performs better than log-loss on\nMNIST for logistic regression.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 21:15:33 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 21:27:15 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Sypherd", "Tyler", ""], ["Diaz", "Mario", ""], ["Sankar", "Lalitha", ""], ["Kairouz", "Peter", ""]]}, {"id": "1902.04646", "submitter": "Debmalya Mandal", "authors": "Debmalya Mandal and David Parkes", "title": "Weighted Tensor Completion for Time-Series Causal Inference", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal Structural Models (MSM) are the most popular models for causal\ninference from time-series observational data. However, they have two main\ndrawbacks: (a) they do not capture subject heterogeneity, and (b) they only\nconsider fixed time intervals and do not scale gracefully with longer\nintervals. In this work, we propose a new family of MSMs to address these two\nconcerns. We model the potential outcomes as a three-dimensional tensor of low\nrank, where the three dimensions correspond to the agents, time periods and the\nset of possible histories. Unlike the traditional MSM, we allow the dimensions\nof the tensor to increase with the number of agents and time periods. We set up\na weighted tensor completion problem as our estimation procedure, and show that\nthe solution to this problem converges to the true model in an appropriate\nsense. Then we show how to solve the estimation problem, providing conditions\nunder which we can approximately and efficiently solve the estimation problem.\nFinally we propose an algorithm based on projected gradient descent, which is\neasy to implement, and evaluate its performance on a simulated dataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 21:36:31 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 06:25:24 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 16:20:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mandal", "Debmalya", ""], ["Parkes", "David", ""]]}, {"id": "1902.04650", "submitter": "Arnak Dalalyan S.", "authors": "Amir-Hossein Bateni and Arnak S. Dalalyan", "title": "Confidence regions and minimax rates in outlier-robust estimation on the\n  probability simplex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the mean of a distribution supported by\nthe $k$-dimensional probability simplex in the setting where an $\\varepsilon$\nfraction of observations are subject to adversarial corruption. A simple\nparticular example is the problem of estimating the distribution of a discrete\nrandom variable. Assuming that the discrete variable takes $k$ values, the\nunknown parameter $\\boldsymbol \\theta$ is a $k$-dimensional vector belonging to\nthe probability simplex. We first describe various settings of contamination\nand discuss the relation between these settings. We then establish minimax\nrates when the quality of estimation is measured by the total-variation\ndistance, the Hellinger distance, or the $\\mathbb L^2$-distance between two\nprobability measures. We also provide confidence regions for the unknown mean\nthat shrink at the minimax rate. Our analysis reveals that the minimax rates\nassociated to these three distances are all different, but they are all\nattained by the sample average. Furthermore, we show that the latter is\nadaptive to the possible sparsity of the unknown vector. Some numerical\nexperiments illustrating our theoretical findings are reported.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 21:52:30 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 10:08:24 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bateni", "Amir-Hossein", ""], ["Dalalyan", "Arnak S.", ""]]}, {"id": "1902.04664", "submitter": "Mohammadreza Soltani", "authors": "Mohammadreza Soltani, Swayambhoo Jain, Abhinav Sambasivan", "title": "Learning Generative Models of Structured Signals from Their\n  Superposition Using GANs with Application to Denoising and Demixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Generative Adversarial Networks (GANs) have emerged as a popular\nalternative for modeling complex high dimensional distributions. Most of the\nexisting works implicitly assume that the clean samples from the target\ndistribution are easily available. However, in many applications, this\nassumption is violated. In this paper, we consider the observation setting when\nthe samples from target distribution are given by the superposition of two\nstructured components and leverage GANs for learning the structure of the\ncomponents. We propose two novel frameworks: denoising-GAN and demixing-GAN.\nThe denoising-GAN assumes access to clean samples from the second component and\ntry to learn the other distribution, whereas demixing-GAN learns the\ndistribution of the components at the same time. Through extensive numerical\nexperiments, we demonstrate that proposed frameworks can generate clean samples\nfrom unknown distributions, and provide competitive performance in tasks such\nas denoising, demixing, and compressive sensing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 22:50:45 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Soltani", "Mohammadreza", ""], ["Jain", "Swayambhoo", ""], ["Sambasivan", "Abhinav", ""]]}, {"id": "1902.04674", "submitter": "Mahdi Soltanolkotabi", "authors": "Samet Oymak and Mahdi Soltanolkotabi", "title": "Towards moderate overparameterization: global convergence guarantees for\n  training shallow neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern neural network architectures are trained in an overparameterized\nregime where the parameters of the model exceed the size of the training\ndataset. Sufficiently overparameterized neural network architectures in\nprinciple have the capacity to fit any set of labels including random noise.\nHowever, given the highly nonconvex nature of the training landscape it is not\nclear what level and kind of overparameterization is required for first order\nmethods to converge to a global optima that perfectly interpolate any labels. A\nnumber of recent theoretical works have shown that for very wide neural\nnetworks where the number of hidden units is polynomially large in the size of\nthe training data gradient descent starting from a random initialization does\nindeed converge to a global optima. However, in practice much more moderate\nlevels of overparameterization seems to be sufficient and in many cases\noverparameterized models seem to perfectly interpolate the training data as\nsoon as the number of parameters exceed the size of the training data by a\nconstant factor. Thus there is a huge gap between the existing theoretical\nliterature and practical experiments. In this paper we take a step towards\nclosing this gap. Focusing on shallow neural nets and smooth activations, we\nshow that (stochastic) gradient descent when initialized at random converges at\na geometric rate to a nearby global optima as soon as the square-root of the\nnumber of network parameters exceeds the size of the training data. Our results\nalso benefit from a fast convergence rate and continue to hold for\nnon-differentiable activations such as Rectified Linear Units (ReLUs).\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 23:42:45 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Oymak", "Samet", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1902.04686", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Ayush Sekhari, Ohad Shamir, Nathan Srebro, Karthik\n  Sridharan, Blake Woodworth", "title": "The Complexity of Making the Gradient Small in Stochastic Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give nearly matching upper and lower bounds on the oracle complexity of\nfinding $\\epsilon$-stationary points ($\\| \\nabla F(x) \\| \\leq\\epsilon$) in\nstochastic convex optimization. We jointly analyze the oracle complexity in\nboth the local stochastic oracle model and the global oracle (or, statistical\nlearning) model. This allows us to decompose the complexity of finding\nnear-stationary points into optimization complexity and sample complexity, and\nreveals some surprising differences between the complexity of stochastic\noptimization versus learning. Notably, we show that in the global\noracle/statistical learning model, only logarithmic dependence on smoothness is\nrequired to find a near-stationary point, whereas polynomial dependence on\nsmoothness is necessary in the local stochastic oracle model. In other words,\nthe separation in complexity between the two models can be exponential, and\nthat the folklore understanding that smoothness is required to find stationary\npoints is only weakly true for statistical learning.\n  Our upper bounds are based on extensions of a recent \"recursive\nregularization\" technique proposed by Allen-Zhu (2018). We show how to extend\nthe technique to achieve near-optimal rates, and in particular show how to\nleverage the extra information available in the global oracle model. Our\nalgorithm for the global model can be implemented efficiently through finite\nsum methods, and suggests an interesting new computational-statistical\ntradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 00:29:23 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 07:04:59 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Foster", "Dylan J.", ""], ["Sekhari", "Ayush", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""], ["Sridharan", "Karthik", ""], ["Woodworth", "Blake", ""]]}, {"id": "1902.04688", "submitter": "Mehrdad Showkatbakhsh", "authors": "Mehrdad Showkatbakhsh, Can Karakus, Suhas Diggavi", "title": "Privacy-Utility Trade-off of Linear Regression under Random Projections\n  and Additive Noise", "comments": "A short version is published in ISIT 2018", "journal-ref": null, "doi": "10.1109/ISIT.2018.8437722", "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is an important concern in machine learning, and is\nfundamentally at odds with the task of training useful learning models, which\ntypically require the acquisition of large amounts of private user data. One\npossible way of fulfilling the machine learning task while preserving user\nprivacy is to train the model on a transformed, noisy version of the data,\nwhich does not reveal the data itself directly to the training procedure. In\nthis work, we analyze the privacy-utility trade-off of two such schemes for the\nproblem of linear regression: additive noise, and random projections. In\ncontrast to previous work, we consider a recently proposed notion of\ndifferential privacy that is based on conditional mutual information (MI-DP),\nwhich is stronger than the conventional $(\\epsilon, \\delta)$-differential\nprivacy, and use relative objective error as the utility metric. We find that\nprojecting the data to a lower-dimensional subspace before adding noise attains\na better trade-off in general. We also make a connection between privacy\nproblem and (non-coherent) SIMO, which has been extensively studied in wireless\ncommunication, and use tools from there for the analysis. We present numerical\nresults demonstrating the performance of the schemes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 00:42:03 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Showkatbakhsh", "Mehrdad", ""], ["Karakus", "Can", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1902.04697", "submitter": "Peilin Zhong", "authors": "Peilin Zhong, Yuchen Mo, Chang Xiao, Pengyu Chen, Changxi Zheng", "title": "Rethinking Generative Mode Coverage: A Pointwise Guaranteed Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many generative models have to combat $\\textit{missing modes}$. The\nconventional wisdom to this end is by reducing through training a statistical\ndistance (such as $f$-divergence) between the generated distribution and\nprovided data distribution. But this is more of a heuristic than a guarantee.\nThe statistical distance measures a $\\textit{global}$, but not\n$\\textit{local}$, similarity between two distributions. Even if it is small, it\ndoes not imply a plausible mode coverage. Rethinking this problem from a\ngame-theoretic perspective, we show that a complete mode coverage is firmly\nattainable. If a generative model can approximate a data distribution\nmoderately well under a global statistical distance measure, then we will be\nable to find a mixture of generators that collectively covers $\\textit{every}$\ndata point and thus $\\textit{every}$ mode, with a lower-bounded generation\nprobability. Constructing the generator mixture has a connection to the\nmultiplicative weights update rule, upon which we propose our algorithm. We\nprove that our algorithm guarantees complete mode coverage. And our experiments\non real and synthetic datasets confirm better mode coverage over recent\napproaches, ones that also use generator mixtures but rely on global\nstatistical distances.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 01:42:11 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 02:01:45 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 05:51:07 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 17:44:47 GMT"}, {"version": "v5", "created": "Thu, 30 May 2019 05:07:06 GMT"}, {"version": "v6", "created": "Tue, 11 Jun 2019 00:40:57 GMT"}, {"version": "v7", "created": "Thu, 24 Oct 2019 20:19:03 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhong", "Peilin", ""], ["Mo", "Yuchen", ""], ["Xiao", "Chang", ""], ["Chen", "Pengyu", ""], ["Zheng", "Changxi", ""]]}, {"id": "1902.04698", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Samy Bengio and Moritz Hardt and Michael C. Mozer\n  and Yoram Singer", "title": "Identity Crisis: Memorization and Generalization under Extreme\n  Overparameterization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between memorization and generalization of\noverparameterized networks in the extreme case of a single training example and\nan identity-mapping task. We examine fully-connected and convolutional networks\n(FCN and CNN), both linear and nonlinear, initialized randomly and then trained\nto minimize the reconstruction error. The trained networks stereotypically take\none of two forms: the constant function (memorization) and the identity\nfunction (generalization). We formally characterize generalization in\nsingle-layer FCNs and CNNs. We show empirically that different architectures\nexhibit strikingly different inductive biases. For example, CNNs of up to 10\nlayers are able to generalize from a single example, whereas FCNs cannot learn\nthe identity function reliably from 60k examples. Deeper CNNs often fail, but\nnonetheless do astonishing work to memorize the training output: because CNN\nbiases are location invariant, the model must progressively grow an output\npattern from the image boundaries via the coordination of many layers. Our work\nhelps to quantify and visualize the sensitivity of inductive biases to\narchitectural choices such as depth, kernel width, and number of channels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 01:45:30 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 00:29:36 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 23:29:28 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 04:31:25 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Bengio", "Samy", ""], ["Hardt", "Moritz", ""], ["Mozer", "Michael C.", ""], ["Singer", "Yoram", ""]]}, {"id": "1902.04699", "submitter": "Anders Host-Madsen", "authors": "Mojtaba Abolfazli, Anders Host-Madsen, June Zhang", "title": "Differential Description Length for Hyperparameter Selection in Machine\n  Learning", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method for model selection and more generally\nhyperparameter selection in machine learning. Minimum description length (MDL)\nis an established method for model selection, which is however not directly\naimed at minimizing generalization error, which is often the primary goal in\nmachine learning. The paper demonstrates a relationship between generalization\nerror and a difference of description lengths of the training data; we call\nthis difference differential description length (DDL). This allows prediction\nof generalization error from the training data alone by performing encoding of\nthe training data. DDL can then be used for model selection by choosing the\nmodel with the smallest predicted generalization error. We show how this method\ncan be used for linear regression and neural networks and deep learning.\nExperimental results show that DDL leads to smaller generalization error than\ncross-validation and traditional MDL and Bayes methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 01:48:58 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 08:30:16 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Abolfazli", "Mojtaba", ""], ["Host-Madsen", "Anders", ""], ["Zhang", "June", ""]]}, {"id": "1902.04704", "submitter": "Tal Golan", "authors": "Nikolaus Kriegeskorte and Tal Golan", "title": "Neural network models and deep learning - a primer for biologists", "comments": "14 pages, 4 figures; added references, minor corrections", "journal-ref": "Current Biology 29(7) (2019) R231-R236", "doi": "10.1016/j.cub.2019.02.034", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originally inspired by neurobiology, deep neural network models have become a\npowerful tool of machine learning and artificial intelligence, where they are\nused to approximate functions and dynamics by learning from examples. Here we\ngive a brief introduction to neural network models and deep learning for\nbiologists. We introduce feedforward and recurrent networks and explain the\nexpressive power of this modeling framework and the backpropagation algorithm\nfor setting the parameters. Finally, we consider how deep neural networks might\nhelp us understand the brain's computations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 02:09:26 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 00:19:24 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Kriegeskorte", "Nikolaus", ""], ["Golan", "Tal", ""]]}, {"id": "1902.04706", "submitter": "Devin Schwab", "authors": "Devin Schwab, Tobias Springenberg, Murilo F. Martins, Thomas Lampe,\n  Michael Neunert, Abbas Abdolmaleki, Tim Hertweck, Roland Hafner, Francesco\n  Nori, Martin Riedmiller", "title": "Simultaneously Learning Vision and Feature-based Control Policies for\n  Real-world Ball-in-a-Cup", "comments": "Videos can be found at\n  https://sites.google.com/view/rss-2019-sawyer-bic/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for fast training of vision based control policies on\nreal robots. The key idea behind our method is to perform multi-task\nReinforcement Learning with auxiliary tasks that differ not only in the reward\nto be optimized but also in the state-space in which they operate. In\nparticular, we allow auxiliary task policies to utilize task features that are\navailable only at training-time. This allows for fast learning of auxiliary\npolicies, which subsequently generate good data for training the main,\nvision-based control policies. This method can be seen as an extension of the\nScheduled Auxiliary Control (SAC-X) framework. We demonstrate the efficacy of\nour method by using both a simulated and real-world Ball-in-a-Cup game\ncontrolled by a robot arm. In simulation, our approach leads to significant\nlearning speed-ups when compared to standard SAC-X. On the real robot we show\nthat the task can be learned from-scratch, i.e., with no transfer from\nsimulation and no imitation learning. Videos of our learned policies running on\nthe real robot can be found at\nhttps://sites.google.com/view/rss-2019-sawyer-bic/.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 02:14:13 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 21:57:35 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Schwab", "Devin", ""], ["Springenberg", "Tobias", ""], ["Martins", "Murilo F.", ""], ["Lampe", "Thomas", ""], ["Neunert", "Michael", ""], ["Abdolmaleki", "Abbas", ""], ["Hertweck", "Tim", ""], ["Hafner", "Roland", ""], ["Nori", "Francesco", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1902.04714", "submitter": "Juho Lee", "authors": "Fadhel Ayed, Juho Lee, Fran\\c{c}ois Caron", "title": "Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical\n  Models with Double Power-law Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric approaches, in particular the Pitman-Yor process and\nthe associated two-parameter Chinese Restaurant process, have been successfully\nused in applications where the data exhibit a power-law behavior. Examples\ninclude natural language processing, natural images or networks. There is also\ngrowing empirical evidence that some datasets exhibit a two-regime power-law\nbehavior: one regime for small frequencies, and a second regime, with a\ndifferent exponent, for high frequencies. In this paper, we introduce a class\nof completely random measures which are doubly regularly-varying. Contrary to\nthe Pitman-Yor process, we show that when completely random measures in this\nclass are normalized to obtain random probability measures and associated\nrandom partitions, such partitions exhibit a double power-law behavior. We\ndiscuss in particular three models within this class: the beta prime process\n(Broderick et al. (2015, 2018), a novel process called generalized BFRY\nprocess, and a mixture construction. We derive efficient Markov chain Monte\nCarlo algorithms to estimate the parameters of these models. Finally, we show\nthat the proposed models provide a better fit than the Pitman-Yor process on\nvarious datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 02:34:52 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 06:19:40 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ayed", "Fadhel", ""], ["Lee", "Juho", ""], ["Caron", "Fran\u00e7ois", ""]]}, {"id": "1902.04728", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Daniel M. Kane, Adam R. Klivans", "title": "Learning Ising Models with Independent Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first efficient algorithm for learning the structure of an Ising\nmodel that tolerates independent failures; that is, each entry of the observed\nsample is missing with some unknown probability p. Our algorithm matches the\nessentially optimal runtime and sample complexity bounds of recent work for\nlearning Ising models due to Klivans and Meka (2017).\n  We devise a novel unbiased estimator for the gradient of the Interaction\nScreening Objective (ISO) due to Vuffray et al. (2016) and apply a stochastic\nmultiplicative gradient descent algorithm to minimize this objective. Solutions\nto this minimization recover the neighborhood information of the underlying\nIsing model on a node by node basis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 03:37:44 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Goel", "Surbhi", ""], ["Kane", "Daniel M.", ""], ["Klivans", "Adam R.", ""]]}, {"id": "1902.04741", "submitter": "Shay Moran", "authors": "Alon Cohen and Avinatan Hassidim and Haim Kaplan and Yishay Mansour\n  and Shay Moran", "title": "Learning to Screen", "comments": "15 pages, 1 figure. Extended the model and the results, changed the\n  title, and added a new lower bound", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a large firm with multiple departments that plans a large\nrecruitment. Candidates arrive one-by-one, and for each candidate the firm\ndecides, based on her data (CV, skills, experience, etc), whether to summon her\nfor an interview. The firm wants to recruit the best candidates while\nminimizing the number of interviews. We model such scenarios as an assignment\nproblem between items (candidates) and categories (departments): the items\narrive one-by-one in an online manner, and upon processing each item the\nalgorithm decides, based on its value and the categories it can be matched\nwith, whether to retain or discard it (this decision is irrevocable). The goal\nis to retain as few items as possible while guaranteeing that the set of\nretained items contains an optimal matching.\n  We consider two variants of this problem: (i) in the first variant it is\nassumed that the $n$ items are drawn independently from an unknown distribution\n$D$. (ii) In the second variant it is assumed that before the process starts,\nthe algorithm has an access to a training set of $n$ items drawn independently\nfrom the same unknown distribution (e.g.\\ data of candidates from previous\nrecruitment seasons). We give tight bounds on the minimum possible number of\nretained items in each of these variants. These results demonstrate that one\ncan retain exponentially less items in the second variant (with the training\nset).\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 05:02:12 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 20:51:00 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 14:44:59 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Cohen", "Alon", ""], ["Hassidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Moran", "Shay", ""]]}, {"id": "1902.04742", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Uniform convergence may be unable to explain generalization in deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aimed at explaining the surprisingly good generalization behavior of\noverparameterized deep networks, recent works have developed a variety of\ngeneralization bounds for deep learning, all based on the fundamental\nlearning-theoretic technique of uniform convergence. While it is well-known\nthat many of these existing bounds are numerically large, through numerous\nexperiments, we bring to light a more concerning aspect of these bounds: in\npractice, these bounds can {\\em increase} with the training dataset size.\nGuided by our observations, we then present examples of overparameterized\nlinear classifiers and neural networks trained by gradient descent (GD) where\nuniform convergence provably cannot ``explain generalization'' -- even if we\ntake into account the implicit bias of GD {\\em to the fullest extent possible}.\nMore precisely, even if we consider only the set of classifiers output by GD,\nwhich have test errors less than some small $\\epsilon$ in our settings, we show\nthat applying (two-sided) uniform convergence on this set of classifiers will\nyield only a vacuous generalization guarantee larger than $1-\\epsilon$. Through\nthese findings, we cast doubt on the power of uniform convergence-based\ngeneralization bounds to provide a complete picture of why overparameterized\ndeep networks generalize well.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 05:09:38 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 17:20:02 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 20:09:41 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1902.04760", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Scaling Limits of Wide Neural Networks with Weight Sharing: Gaussian\n  Process Behavior, Gradient Independence, and Neural Tangent Kernel Derivation", "comments": "tldr: A theoretical tool for understanding the behavior of large\n  width randomly initialized neural networks for almost all deep learning\n  architectures. For a gentler introduction to Gaussian Process results here\n  and several extensions, we recommend the reader to look at arXiv:1910.12478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent trends in machine learning theory and practice, from the\ndesign of state-of-the-art Gaussian Process to the convergence analysis of deep\nneural nets (DNNs) under stochastic gradient descent (SGD), have found it\nfruitful to study wide random neural networks. Central to these approaches are\ncertain scaling limits of such networks. We unify these results by introducing\na notion of a straightline \\emph{tensor program} that can express most neural\nnetwork computations, and we characterize its scaling limit when its tensors\nare large and randomized. From our framework follows (1) the convergence of\nrandom neural networks to Gaussian processes for architectures such as\nrecurrent neural networks, convolutional neural networks, residual networks,\nattention, and any combination thereof, with or without batch normalization;\n(2) conditions under which the \\emph{gradient independence assumption} -- that\nweights in backpropagation can be assumed to be independent from weights in the\nforward pass -- leads to correct computation of gradient dynamics, and\ncorrections when it does not; (3) the convergence of the Neural Tangent Kernel,\na recently proposed kernel used to predict training dynamics of neural networks\nunder gradient descent, at initialization for all architectures in (1) without\nbatch normalization. Mathematically, our framework is general enough to\nrederive classical random matrix results such as the semicircle and the\nMarchenko-Pastur laws, as well as recent results in neural network Jacobian\nsingular values. We hope our work opens a way toward design of even stronger\nGaussian Processes, initialization schemes to avoid gradient\nexplosion/vanishing, and deeper understanding of SGD dynamics in modern\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 06:09:18 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:02:40 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 22:53:19 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1902.04763", "submitter": "Yue Xu", "authors": "Yue Xu, Feng Yin, Wenjun Xu, Jiaru Lin, Shuguang Cui", "title": "Wireless Traffic Prediction with Scalable Gaussian Process: Framework,\n  Algorithms, and Verification", "comments": null, "journal-ref": "IEEE Journal on Selected Areas in Communications ( Volume: 37 ,\n  Issue: 6 , June 2019 )", "doi": "10.1109/JSAC.2019.2904330", "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud radio access network (C-RAN) is a promising paradigm to meet the\nstringent requirements of the fifth generation (5G) wireless systems.\nMeanwhile, wireless traffic prediction is a key enabler for C-RANs to improve\nboth the spectrum efficiency and energy efficiency through load-aware network\nmanagements. This paper proposes a scalable Gaussian process (GP) framework as\na promising solution to achieve large-scale wireless traffic prediction in a\ncost-efficient manner. Our contribution is three-fold. First, to the best of\nour knowledge, this paper is the first to empower GP regression with the\nalternating direction method of multipliers (ADMM) for parallel hyper-parameter\noptimization in the training phase, where such a scalable training framework\nwell balances the local estimation in baseband units (BBUs) and information\nconsensus among BBUs in a principled way for large-scale executions. Second, in\nthe prediction phase, we fuse local predictions obtained from the BBUs via a\ncross-validation based optimal strategy, which demonstrates itself to be\nreliable and robust for general regression tasks. Moreover, such a\ncross-validation based optimal fusion strategy is built upon a well\nacknowledged probabilistic model to retain the valuable closed-form GP\ninference properties. Third, we propose a C-RAN based scalable wireless\nprediction architecture, where the prediction accuracy and the time consumption\ncan be balanced by tuning the number of the BBUs according to the real-time\nsystem demands. Experimental results show that our proposed scalable GP model\ncan outperform the state-of-the-art approaches considerably, in terms of\nwireless traffic prediction performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 06:20:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Yue", ""], ["Yin", "Feng", ""], ["Xu", "Wenjun", ""], ["Lin", "Jiaru", ""], ["Cui", "Shuguang", ""]]}, {"id": "1902.04768", "submitter": "Yong Liu", "authors": "Yong Liu and Jian Li and Guangjun Wu and Lizhong Ding and Weiping Wang", "title": "Efficient Cross-Validation for Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold regularization, such as laplacian regularized least squares (LapRLS)\nand laplacian support vector machine (LapSVM), has been widely used in\nsemi-supervised learning, and its performance greatly depends on the choice of\nsome hyper-parameters. Cross-validation (CV) is the most popular approach for\nselecting the optimal hyper-parameters, but it has high complexity due to\nmultiple times of learner training. In this paper, we provide a method to\napproximate the CV for manifold regularization based on a notion of robust\nstatistics, called Bouligand influence function (BIF). We first provide a\nstrategy for approximating the CV via the Taylor expansion of BIF. Then, we\nshow how to calculate the BIF for general loss function,and further give the\napproximate CV criteria for model selection in manifold regularization. The\nproposed approximate CV for manifold regularization requires training only\nonce, hence can significantly improve the efficiency of traditional CV.\nExperimental results show that our approximate CV has no statistical\ndiscrepancy with the original one, but much smaller time cost.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 06:51:58 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Liu", "Yong", ""], ["Li", "Jian", ""], ["Wu", "Guangjun", ""], ["Ding", "Lizhong", ""], ["Wang", "Weiping", ""]]}, {"id": "1902.04774", "submitter": "Guodong Shi", "authors": "Deming Yuan, Alexandre Proutiere, Guodong Shi", "title": "Distributed Online Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online linear regression problems in a distributed setting, where\nthe data is spread over a network. In each round, each network node proposes a\nlinear predictor, with the objective of fitting the \\emph{network-wide} data.\nIt then updates its predictor for the next round according to the received\nlocal feedback and information received from neighboring nodes. The predictions\nmade at a given node are assessed through the notion of regret, defined as the\ndifference between their cumulative network-wide square errors and those of the\nbest off-line network-wide linear predictor. Various scenarios are\ninvestigated, depending on the nature of the local feedback (full information\nor bandit feedback), on the set of available predictors (the decision set), and\nthe way data is generated (by an oblivious or adaptive adversary). We propose\nsimple and natural distributed regression algorithms, involving, at each node\nand in each round, a local gradient descent step and a communication and\naveraging step where nodes aim at aligning their predictors to those of their\nneighbors. We establish regret upper bounds typically in ${\\cal O}(T^{3/4})$\nwhen the decision set is unbounded and in ${\\cal O}(\\sqrt{T})$ in case of\nbounded decision set.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 07:37:03 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yuan", "Deming", ""], ["Proutiere", "Alexandre", ""], ["Shi", "Guodong", ""]]}, {"id": "1902.04779", "submitter": "Lin Yang", "authors": "Lin F. Yang, Mengdi Wang", "title": "Sample-Optimal Parametric Q-Learning Using Linearly Additive Features", "comments": "Accepted to ICML, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a Markov decision process (MDP) that admits a set of state-action\nfeatures, which can linearly express the process's probabilistic transition\nmodel. We propose a parametric Q-learning algorithm that finds an\napproximate-optimal policy using a sample size proportional to the feature\ndimension $K$ and invariant with respect to the size of the state space. To\nfurther improve its sample efficiency, we exploit the monotonicity property and\nintrinsic noise structure of the Bellman operator, provided the existence of\nanchor state-actions that imply implicit non-negativity in the feature space.\nWe augment the algorithm using techniques of variance reduction, monotonicity\npreservation, and confidence bounds. It is proved to find a policy which is\n$\\epsilon$-optimal from any initial state with high probability using\n$\\widetilde{O}(K/\\epsilon^2(1-\\gamma)^3)$ sample transitions for arbitrarily\nlarge-scale MDP with a discount factor $\\gamma\\in(0,1)$. A matching\ninformation-theoretical lower bound is proved, confirming the sample optimality\nof the proposed method with respect to all parameters (up to polylog factors).\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 08:26:47 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 20:20:23 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Yang", "Lin F.", ""], ["Wang", "Mengdi", ""]]}, {"id": "1902.04782", "submitter": "Roi Livni", "authors": "Pravesh K. Kothari and Roi Livni", "title": "On the Expressive Power of Kernel Methods and the Efficiency of Kernel\n  Learning by Association Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressive power of kernel methods and the algorithmic\nfeasibility of multiple kernel learning for a special rich class of kernels.\n  Specifically, we define \\emph{Euclidean kernels}, a diverse class that\nincludes most, if not all, families of kernels studied in literature such as\npolynomial kernels and radial basis functions. We then describe the geometric\nand spectral structure of this family of kernels over the hypercube (and to\nsome extent for any compact domain). Our structural results allow us to prove\nmeaningful limitations on the expressive power of the class as well as derive\nseveral efficient algorithms for learning kernels over different domains.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 08:29:38 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Livni", "Roi", ""]]}, {"id": "1902.04811", "submitter": "Chi Jin", "authors": "Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M. Kakade and Michael I.\n  Jordan", "title": "On Nonconvex Optimization for Machine Learning: Gradients,\n  Stochasticity, and Saddle Points", "comments": "A preliminary version of this paper, with a subset of the results\n  that are presented here, was presented at ICML 2017 (also as\n  arXiv:1703.00887)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent (GD) and stochastic gradient descent (SGD) are the\nworkhorses of large-scale machine learning. While classical theory focused on\nanalyzing the performance of these methods in convex optimization problems, the\nmost notable successes in machine learning have involved nonconvex\noptimization, and a gap has arisen between theory and practice. Indeed,\ntraditional analyses of GD and SGD show that both algorithms converge to\nstationary points efficiently. But these analyses do not take into account the\npossibility of converging to saddle points. More recent theory has shown that\nGD and SGD can avoid saddle points, but the dependence on dimension in these\nanalyses is polynomial. For modern machine learning, where the dimension can be\nin the millions, such dependence would be catastrophic. We analyze perturbed\nversions of GD and SGD and show that they are truly efficient---their dimension\ndependence is only polylogarithmic. Indeed, these algorithms converge to\nsecond-order stationary points in essentially the same time as they take to\nconverge to classical first-order stationary points.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:44:02 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 03:26:59 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Jin", "Chi", ""], ["Netrapalli", "Praneeth", ""], ["Ge", "Rong", ""], ["Kakade", "Sham M.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.04812", "submitter": "Hicham Janati", "authors": "Hicham Janati (ENSAE ParisTech, PARIETAL), Thomas Bazeille (PARIETAL),\n  Bertrand Thirion (PARIETAL), Marco Cuturi (CREST, ENSAE ParisTech ),\n  Alexandre Gramfort (PARIETAL)", "title": "Group level MEG/EEG source imaging via optimal transport: minimum\n  Wasserstein estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography (MEG) and electroencephalogra-phy (EEG) are\nnon-invasive modalities that measure the weak electromagnetic fields generated\nby neural activity. Inferring the location of the current sources that\ngenerated these magnetic fields is an ill-posed inverse problem known as source\nimaging. When considering a group study, a baseline approach consists in\ncarrying out the estimation of these sources independently for each subject.\nThe ill-posedness of each problem is typically addressed using sparsity\npromoting regularizations. A straightforward way to define a common pattern for\nthese sources is then to average them. A more advanced alternative relies on a\njoint localization of sources for all subjects taken together, by enforcing\nsome similarity across all estimated sources. An important advantage of this\napproach is that it consists in a single estimation in which all measurements\nare pooled together, making the inverse problem better posed. Such a joint\nestimation poses however a few challenges, notably the selection of a valid\nregularizer that can quantify such spatial similarities. We propose in this\nwork a new procedure that can do so while taking into account the geometrical\nstructure of the cortex. We call this procedure Minimum Wasserstein Estimates\n(MWE). The benefits of this model are twofold. First, joint inference allows to\npool together the data of different brain geometries, accumulating more spatial\ninformation. Second, MWE are defined through Optimal Transport (OT) metrics\nwhich provide a tool to model spatial proximity between cortical sources of\ndifferent subjects, hence not enforcing identical source location in the group.\nThese benefits allow MWE to be more accurate than standard MEG source\nlocalization techniques. To support these claims, we perform source\nlocalization on realistic MEG simulations based on forward operators derived\nfrom MRI scans. On a visual task dataset, we demonstrate how MWE infer neural\npatterns similar to functional Magnetic Resonance Imaging (fMRI) maps.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:44:09 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Janati", "Hicham", "", "ENSAE ParisTech, PARIETAL"], ["Bazeille", "Thomas", "", "PARIETAL"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Cuturi", "Marco", "", "CREST, ENSAE ParisTech"], ["Gramfort", "Alexandre", "", "PARIETAL"]]}, {"id": "1902.04818", "submitter": "Kevin Roth", "authors": "Kevin Roth, Yannic Kilcher, Thomas Hofmann", "title": "The Odds are Odd: A Statistical Test for Detecting Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate conditions under which test statistics exist that can reliably\ndetect examples, which have been adversarially manipulated in a white-box\nattack. These statistics can be easily computed and calibrated by randomly\ncorrupting inputs. They exploit certain anomalies that adversarial attacks\nintroduce, in particular if they follow the paradigm of choosing perturbations\noptimally under p-norm constraints. Access to the log-odds is the only\nrequirement to defend models. We justify our approach empirically, but also\nprovide conditions under which detectability via the suggested test statistics\nis guaranteed to be effective. In our experiments, we show that it is even\npossible to correct test time predictions for adversarial attacks with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:51:34 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 16:35:40 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Roth", "Kevin", ""], ["Kilcher", "Yannic", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1902.04850", "submitter": "Angelo Porrello", "authors": "Angelo Porrello, Davide Abati, Simone Calderara, Rita Cucchiara", "title": "Classifying Signals on Irregular Domains via Convolutional Cluster\n  Pooling", "comments": "12 pages, 6 figures. To appear in the Proceedings of the 22nd\n  International Conference on Artificial Intelligence and Statistics (AISTATS)\n  2019, Naha, Okinawa, Japan. PMLR: Volume 89", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and hierarchical approach for supervised classification of\nsignals spanning over a fixed graph, reflecting shared properties of the\ndataset. To this end, we introduce a Convolutional Cluster Pooling layer\nexploiting a multi-scale clustering in order to highlight, at different\nresolutions, locally connected regions on the input graph. Our proposal\ngeneralises well-established neural models such as Convolutional Neural\nNetworks (CNNs) on irregular and complex domains, by means of the exploitation\nof the weight sharing property in a graph-oriented architecture. In this work,\nsuch property is based on the centrality of each vertex within its\nsoft-assigned cluster. Extensive experiments on NTU RGB+D, CIFAR-10 and 20NEWS\ndemonstrate the effectiveness of the proposed technique in capturing both local\nand global patterns in graph-structured data out of different domains.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 10:49:50 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Porrello", "Angelo", ""], ["Abati", "Davide", ""], ["Calderara", "Simone", ""], ["Cucchiara", "Rita", ""]]}, {"id": "1902.04880", "submitter": "Jukka Hirvasniemi", "authors": "Jukka Hirvasniemi, Willem Paul Gielis, Saeed Arbabi, Rintje Agricola,\n  Willem Evert van Spil, Vahid Arbabi, Harrie Weinans", "title": "Bone Texture Analysis for Prediction of Incident Radio-graphic Hip\n  Osteoarthritis Using Machine Learning: Data from the Cohort Hip and Cohort\n  Knee (CHECK) study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our aim was to assess the ability of radiography-based bone texture\nparameters in proximal femur and acetabulum to predict incident radiographic\nhip osteoarthritis (rHOA) over a 10 years period. Pelvic radiographs from CHECK\n(Cohort Hip and Cohort Knee) at baseline (987 hips) were analyzed for bone\ntexture using fractal signature analysis in proximal femur and acetabulum.\nElastic net (machine learning) was used to predict the incidence of rHOA\n(Kellgren-Lawrence grade (KL) > 1 or total hip replacement (THR)), joint space\nnarrowing score (JSN, range 0-3), and osteophyte score (OST, range 0-3) after\n10 years. Performance of prediction models was assessed using the area under\nthe receiver operating characteristic curve (ROC AUC). Of the 987 hips without\nrHOA at baseline, 435 (44%) had rHOA at 10-year follow-up. Of the 667 hips with\nJSN grade 0 at baseline, 471 (71%) had JSN grade > 0 at 10-year follow-up. Of\nthe 613 hips with OST grade 0 at baseline, 526 (86%) had OST grade > 0 at\n10-year follow-up. AUCs for the models including age, gender, and body mass\nindex to predict incident rHOA, JSN, and OST were 0.59, 0.54, and 0.51,\nrespectively. The inclusion of bone texture parameters in the models improved\nthe prediction of incident rHOA (ROC AUC 0.66 and 0.71 when baseline KL was\nalso included in the model) and JSN (ROC AUC 0.62), but not incident OST (ROC\nAUC 0.53). Bone texture analysis provides additional information for predicting\nincident rHOA or THR over 10 years.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 13:05:21 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Hirvasniemi", "Jukka", ""], ["Gielis", "Willem Paul", ""], ["Arbabi", "Saeed", ""], ["Agricola", "Rintje", ""], ["van Spil", "Willem Evert", ""], ["Arbabi", "Vahid", ""], ["Weinans", "Harrie", ""]]}, {"id": "1902.04885", "submitter": "Yang Liu", "authors": "Qiang Yang, Yang Liu, Tianjian Chen, Yongxin Tong", "title": "Federated Machine Learning: Concept and Applications", "comments": null, "journal-ref": "ACM Transactions on Intelligent Systems and Technology (TIST)\n  Volume 10 Issue 2, Article No. 12, January 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's AI still faces two major challenges. One is that in most industries,\ndata exists in the form of isolated islands. The other is the strengthening of\ndata privacy and security. We propose a possible solution to these challenges:\nsecure federated learning. Beyond the federated learning framework first\nproposed by Google in 2016, we introduce a comprehensive secure federated\nlearning framework, which includes horizontal federated learning, vertical\nfederated learning and federated transfer learning. We provide definitions,\narchitectures and applications for the federated learning framework, and\nprovide a comprehensive survey of existing works on this subject. In addition,\nwe propose building data networks among organizations based on federated\nmechanisms as an effective solution to allow knowledge to be shared without\ncompromising user privacy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 13:16:46 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yang", "Qiang", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Tong", "Yongxin", ""]]}, {"id": "1902.04886", "submitter": "Angelo Porrello", "authors": "Luca Bergamini, Angelo Porrello, Andrea Capobianco Dondona, Ercole Del\n  Negro, Mauro Mattioli, Nicola D'Alterio, Simone Calderara", "title": "Multi-views Embedding for Cattle Re-identification", "comments": "8 pages, 3 figures. Accepted in the 14th International Conference on\n  SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  People re-identification task has seen enormous improvements in the latest\nyears, mainly due to the development of better image features extraction from\ndeep Convolutional Neural Networks (CNN) and the availability of large\ndatasets. However, little research has been conducted on animal identification\nand re-identification, even if this knowledge may be useful in a rich variety\nof different scenarios. Here, we tackle cattle re-identification exploiting\ndeep CNN and show how this task is poorly related with the human one,\npresenting unique challenges that makes it far from being solved. We present\nvarious baselines, both based on deep architectures or on standard machine\nlearning algorithms, and compared them with our solution. Finally, a rich\nablation study has been conducted to further investigate the unique\npeculiarities of this task.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 13:16:50 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Bergamini", "Luca", ""], ["Porrello", "Angelo", ""], ["Dondona", "Andrea Capobianco", ""], ["Del Negro", "Ercole", ""], ["Mattioli", "Mauro", ""], ["D'Alterio", "Nicola", ""], ["Calderara", "Simone", ""]]}, {"id": "1902.04893", "submitter": "Junghoon Seo", "authors": "Beomsu Kim, Junghoon Seo, SeungHyun Jeon, Jamyoung Koo, Jeongyeol\n  Choe, Taegyun Jeon", "title": "Why are Saliency Maps Noisy? Cause of and Solution to Noisy Saliency\n  Maps", "comments": "Accepted at the 2019 ICCV Workshop on Interpreting and Explaining\n  Visual AI Models (VXAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency Map, the gradient of the score function with respect to the input,\nis the most basic technique for interpreting deep neural network decisions.\nHowever, saliency maps are often visually noisy. Although several hypotheses\nwere proposed to account for this phenomenon, there are few works that provide\nrigorous analyses of noisy saliency maps. In this paper, we firstly propose a\nnew hypothesis that noise may occur in saliency maps when irrelevant features\npass through ReLU activation functions. Then, we propose Rectified Gradient, a\nmethod that alleviates this problem through layer-wise thresholding during\nbackpropagation. Experiments with neural networks trained on CIFAR-10 and\nImageNet showed effectiveness of our method and its superiority to other\nattribution methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 13:25:39 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 05:36:09 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 15:55:32 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kim", "Beomsu", ""], ["Seo", "Junghoon", ""], ["Jeon", "SeungHyun", ""], ["Koo", "Jamyoung", ""], ["Choe", "Jeongyeol", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1902.04942", "submitter": "Kyle Luther", "authors": "Kyle Luther, H. Sebastian Seung", "title": "Sample Variance Decay in Randomly Initialized ReLU Networks", "comments": "Submitted to Neurips2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before training a neural net, a classic rule of thumb is to randomly\ninitialize the weights so the variance of activations is preserved across\nlayers. This is traditionally interpreted using the total variance due to\nrandomness in both weights \\emph{and} samples. Alternatively, one can interpret\nthe rule of thumb as preservation of the variance over samples for a fixed\nnetwork. The two interpretations differ little for a shallow net, but the\ndifference is shown to grow with depth for a deep ReLU net by decomposing the\ntotal variance into the network-averaged sum of the sample variance and square\nof the sample mean. We demonstrate that even when the total variance is\npreserved, the sample variance decays in the later layers through an analytical\ncalculation in the limit of infinite network width, and numerical simulations\nfor finite width. We show that Batch Normalization eliminates this decay and\nprovide empirical evidence that preserving the sample variance instead of only\nthe total variance at initialization time can have an impact on the training\ndynamics of a deep network.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 14:58:07 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 01:13:20 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Luther", "Kyle", ""], ["Seung", "H. Sebastian", ""]]}, {"id": "1902.04952", "submitter": "Xiang Li", "authors": "Xiang Li, Shusen Wang, Zhihua Zhang", "title": "Do Subsampled Newton Methods Work for High-Dimensional Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampled Newton methods approximate Hessian matrices through subsampling\ntechniques, alleviating the cost of forming Hessian matrices but using\nsufficient curvature information. However, previous results require $\\Omega\n(d)$ samples to approximate Hessians, where $d$ is the dimension of data\npoints, making it less practically feasible for high-dimensional data. The\nsituation is deteriorated when $d$ is comparably as large as the number of data\npoints $n$, which requires to take the whole dataset into account, making\nsubsampling useless. This paper theoretically justifies the effectiveness of\nsubsampled Newton methods on high dimensional data. Specifically, we prove only\n$\\widetilde{\\Theta}(d^\\gamma_{\\rm eff})$ samples are needed in the\napproximation of Hessian matrices, where $d^\\gamma_{\\rm eff}$ is the\n$\\gamma$-ridge leverage and can be much smaller than $d$ as long as $n\\gamma\n\\gg 1$. Additionally, we extend this result so that subsampled Newton methods\ncan work for high-dimensional data on both distributed optimization problems\nand non-smooth regularized problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 15:30:10 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 14:45:13 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1902.04954", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Risk Prediction of Peer-to-Peer Lending Market by a LSTM Model with\n  Macroeconomic Factor", "comments": null, "journal-ref": null, "doi": "10.1145/3374135.3385287", "report-no": null, "categories": "cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the peer to peer (P2P) lending platform, investors hope to maximize their\nreturn while minimizing the risk through a comprehensive understanding of the\nP2P market. A low and stable average default rate across all the borrowers\ndenotes a healthy P2P market and provides investors more confidence in a\npromising investment. Therefore, having a powerful model to describe the trend\nof the default rate in the P2P market is crucial. Different from previous\nstudies that focus on modeling the default rate at the individual level, in\nthis paper, we are the first to comprehensively explore the monthly trend of\nthe default rate at the aggregative level for the P2P data from October 2007 to\nJanuary 2016 in the US. We use the long short term memory (LSTM) approach to\nsequentially predict the default risk of the borrowers in Lending Club, which\nis the largest P2P lending platform in the US. Although being first applied in\nmodeling the P2P sequential data, the LSTM approach shows its great potential\nby outperforming traditionally utilized time series models in our experiments.\nFurthermore, incorporating the macroeconomic feature \\textit{unemp\\_rate}\n(i.e., unemployment rate) can improve the LSTM performance by decreasing RMSE\non both the training and the testing datasets. Our study can broaden the\napplications of the LSTM algorithm by using it on the sequential P2P data and\nguide the investors in making investment strategies.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 15:42:27 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 20:08:49 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "1902.04972", "submitter": "Seyedehsara Nayer", "authors": "Seyedehsara Nayer, Praneeth Narayanamurthy, Namrata Vaswani", "title": "Provable Low Rank Phase Retrieval", "comments": "A short version of this work is in ICML 2019, this longer version is\n  published in IEEE Trans. Info. Th on March 2020. Fixing minor but important\n  errors in Lemmas 3.10, 3.11, 3.12 statements and in proof of the Term1 bound.\n  No change to Theorem statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Low Rank Phase Retrieval (LRPR) problem defined as follows:\nrecover an $n \\times q$ matrix $X^*$ of rank $r$ from a different and\nindependent set of $m$ phaseless (magnitude-only) linear projections of each of\nits columns. To be precise, we need to recover $X^*$ from $y_k := |A_k{}'\nx^*_k|, k=1,2,\\dots, q$ when the measurement matrices $A_k$ are mutually\nindependent. Here $y_k$ is an $m$ length vector, $A_k$ is an $n \\times m$\nmatrix, and $'$ denotes matrix transpose. The question is when can we solve\nLRPR with $m \\ll n$? A reliable solution can enable fast and low-cost phaseless\ndynamic imaging, e.g., Fourier ptychographic imaging of live biological\nspecimens. In this work, we develop the first provably correct approach for\nsolving this LRPR problem. Our proposed algorithm, Alternating Minimization for\nLow-Rank Phase Retrieval (AltMinLowRaP), is an AltMin based solution and hence\nis also provably fast (converges geometrically). Our guarantee shows that\nAltMinLowRaP solves LRPR to $\\epsilon$ accuracy, with high probability, as long\nas $m q \\ge C n r^4 \\log(1/\\epsilon)$, the matrices $A_k$ contain i.i.d.\nstandard Gaussian entries, and the right singular vectors of $X^*$ satisfy the\nincoherence assumption from matrix completion literature. Here $C$ is a\nnumerical constant that only depends on the condition number of $X^*$ and on\nits incoherence parameter. Its time complexity is only $ C mq nr\n\\log^2(1/\\epsilon)$. Since even the linear (with phase) version of the above\nproblem is not fully solved, the above result is also the first complete\nsolution and guarantee for the linear case. Finally, we also develop a simple\nextension of our results for the dynamic LRPR setting.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 15:56:12 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 05:15:23 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 21:23:55 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 22:47:13 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 21:44:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Nayer", "Seyedehsara", ""], ["Narayanamurthy", "Praneeth", ""], ["Vaswani", "Namrata", ""]]}, {"id": "1902.04980", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Oliver S. Kirsebom, F\\'abio Fraz\\~ao, Ronan Fablet and\n  Stan Matwin", "title": "Recurrent Neural Networks with Stochastic Layers for Acoustic Novelty\n  Detection", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682901", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we adapt Recurrent Neural Networks with Stochastic Layers,\nwhich are the state-of-the-art for generating text, music and speech, to the\nproblem of acoustic novelty detection. By integrating uncertainty into the\nhidden states, this type of network is able to learn the distribution of\ncomplex sequences. Because the learned distribution can be calculated\nexplicitly in terms of probability, we can evaluate how likely an observation\nis then detect low-probability events as novel. The model is robust, highly\nunsupervised, end-to-end and requires minimum preprocessing, feature\nengineering or hyperparameter tuning. An experiment on a benchmark dataset\nshows that our model outperforms the state-of-the-art acoustic novelty\ndetectors.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:13:52 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Nguyen", "Duong", ""], ["Kirsebom", "Oliver S.", ""], ["Fraz\u00e3o", "F\u00e1bio", ""], ["Fablet", "Ronan", ""], ["Matwin", "Stan", ""]]}, {"id": "1902.04981", "submitter": "Michael Kampffmeyer", "authors": "Michael Kampffmeyer, Sigurd L{\\o}kse, Filippo M. Bianchi, Lorenzo\n  Livi, Arnt-B{\\o}rre Salberg, Robert Jenssen", "title": "Deep Divergence-Based Approach to Clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.01.015", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising direction in deep learning research consists in learning\nrepresentations and simultaneously discovering cluster structure in unlabeled\ndata by optimizing a discriminative loss function. As opposed to supervised\ndeep learning, this line of research is in its infancy, and how to design and\noptimize suitable loss functions to train deep neural networks for clustering\nis still an open question. Our contribution to this emerging field is a new\ndeep clustering network that leverages the discriminative power of\ninformation-theoretic divergence measures, which have been shown to be\neffective in traditional clustering. We propose a novel loss function that\nincorporates geometric regularization constraints, thus avoiding degenerate\nstructures of the resulting clustering partition. Experiments on synthetic\nbenchmarks and real datasets show that the proposed network achieves\ncompetitive performance with respect to other state-of-the-art methods, scales\nwell to large datasets, and does not require pre-training steps.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:16:09 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Kampffmeyer", "Michael", ""], ["L\u00f8kse", "Sigurd", ""], ["Bianchi", "Filippo M.", ""], ["Livi", "Lorenzo", ""], ["Salberg", "Arnt-B\u00f8rre", ""], ["Jenssen", "Robert", ""]]}, {"id": "1902.04982", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Noam Brown, Tuomas Sandholm", "title": "Stable-Predictive Optimistic Counterfactual Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CFR framework has been a powerful tool for solving large-scale\nextensive-form games in practice. However, the theoretical rate at which past\nCFR-based algorithms converge to the Nash equilibrium is on the order of\n$O(T^{-1/2})$, where $T$ is the number of iterations. In contrast, first-order\nmethods can be used to achieve a $O(T^{-1})$ dependence on iterations, yet\nthese methods have been less successful in practice. In this work we present\nthe first CFR variant that breaks the square-root dependence on iterations. By\ncombining and extending recent advances on predictive and stable regret\nminimizers for the matrix-game setting we show that it is possible to leverage\n\"optimistic\" regret minimizers to achieve a $O(T^{-3/4})$ convergence rate\nwithin CFR. This is achieved by introducing a new notion of\nstable-predictivity, and by setting the stability of each counterfactual regret\nminimizer relative to its location in the decision tree. Experiments show that\nthis method is faster than the original CFR algorithm, although not as fast as\nnewer variants, in spite of their worst-case $O(T^{-1/2})$ dependence on\niterations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:18:21 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1902.04994", "submitter": "Linyi Yang", "authors": "Linyi Yang, Zheng Zhang, Su Xiong, Lirui Wei, James Ng, Lina Xu,\n  Ruihai Dong", "title": "Explainable Text-Driven Neural Network for Stock Prediction", "comments": "10 pages, Proceedings of CCIS2018", "journal-ref": "2018 5th IEEE International Conference on Cloud Computing and\n  Intelligence Systems", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that financial news leads to the fluctuation of stock\nprices. However, previous work on news-driven financial market prediction\nfocused only on predicting stock price movement without providing an\nexplanation. In this paper, we propose a dual-layer attention-based neural\nnetwork to address this issue. In the initial stage, we introduce a\nknowledge-based method to adaptively extract relevant financial news. Then, we\nuse input attention to pay more attention to the more influential news and\nconcatenate the day embeddings with the output of the news representation.\nFinally, we use an output attention mechanism to allocate different weights to\ndifferent days in terms of their contribution to stock price movement. Thorough\nempirical studies based upon historical prices of several individual stocks\ndemonstrate the superiority of our proposed method in stock price prediction\ncompared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:37:32 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yang", "Linyi", ""], ["Zhang", "Zheng", ""], ["Xiong", "Su", ""], ["Wei", "Lirui", ""], ["Ng", "James", ""], ["Xu", "Lina", ""], ["Dong", "Ruihai", ""]]}, {"id": "1902.04999", "submitter": "Youssef Mroueh", "authors": "Pierre Dognin, Igor Melnyk, Youssef Mroueh, Jerret Ross, Cicero Dos\n  Santos, Tom Sercu", "title": "Wasserstein Barycenter Model Ensembling", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose to perform model ensembling in a multiclass or a\nmultilabel learning setting using Wasserstein (W.) barycenters. Optimal\ntransport metrics, such as the Wasserstein distance, allow incorporating\nsemantic side information such as word embeddings. Using W. barycenters to find\nthe consensus between models allows us to balance confidence and semantics in\nfinding the agreement between the models. We show applications of Wasserstein\nensembling in attribute-based classification, multilabel learning and image\ncaptioning generation. These results show that the W. ensembling is a viable\nalternative to the basic geometric or arithmetic mean ensembling.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:43:32 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Dognin", "Pierre", ""], ["Melnyk", "Igor", ""], ["Mroueh", "Youssef", ""], ["Ross", "Jerret", ""], ["Santos", "Cicero Dos", ""], ["Sercu", "Tom", ""]]}, {"id": "1902.05009", "submitter": "Dongyu Liu", "authors": "Qianwen Wang, Yao Ming, Zhihua Jin, Qiaomu Shen, Dongyu Liu, Micah J.\n  Smith, Kalyan Veeramachaneni, Huamin Qu", "title": "ATMSeer: Increasing Transparency and Controllability in Automated\n  Machine Learning", "comments": "Published in the ACM Conference on Human Factors in Computing Systems\n  (CHI), 2019, Glasgow, Scotland UK", "journal-ref": "In Proceedings of the 2019 CHI Conference on Human Factors in\n  Computing Systems (CHI '19). Association for Computing Machinery, New York,\n  NY, USA, Paper 681, 1-12", "doi": "10.1145/3290605.3300911", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To relieve the pain of manually selecting machine learning algorithms and\ntuning hyperparameters, automated machine learning (AutoML) methods have been\ndeveloped to automatically search for good models. Due to the huge model search\nspace, it is impossible to try all models. Users tend to distrust automatic\nresults and increase the search budget as much as they can, thereby undermining\nthe efficiency of AutoML. To address these issues, we design and implement\nATMSeer, an interactive visualization tool that supports users in refining the\nsearch space of AutoML and analyzing the results. To guide the design of\nATMSeer, we derive a workflow of using AutoML based on interviews with machine\nlearning experts. A multi-granularity visualization is proposed to enable users\nto monitor the AutoML process, analyze the searched models, and refine the\nsearch space in real time. We demonstrate the utility and usability of ATMSeer\nthrough two case studies, expert interviews, and a user study with 13 end\nusers.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 17:03:33 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Qianwen", ""], ["Ming", "Yao", ""], ["Jin", "Zhihua", ""], ["Shen", "Qiaomu", ""], ["Liu", "Dongyu", ""], ["Smith", "Micah J.", ""], ["Veeramachaneni", "Kalyan", ""], ["Qu", "Huamin", ""]]}, {"id": "1902.05017", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Yishay Mansour, Yossi Matias, Uri Stemmer", "title": "Differentially Private Learning of Geometric Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present differentially private efficient algorithms for learning union of\npolygons in the plane (which are not necessarily convex). Our algorithms\nachieve $(\\alpha,\\beta)$-PAC learning and $(\\epsilon,\\delta)$-differential\nprivacy using a sample of size $\\tilde{O}\\left(\\frac{1}{\\alpha\\epsilon}k\\log\nd\\right)$, where the domain is $[d]\\times[d]$ and $k$ is the number of edges in\nthe union of polygons.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 17:24:35 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Matias", "Yossi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1902.05026", "submitter": "Justice Amoh", "authors": "Justice Amoh and Kofi Odame", "title": "An Optimized Recurrent Unit for Ultra-Low-Power Keyword Spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in being able to run neural networks on sensors,\nwearables and internet-of-things (IoT) devices. However, the computational\ndemands of neural networks make them difficult to deploy on\nresource-constrained edge devices.\n  To meet this need, our work introduces a new recurrent unit architecture that\nis specifically adapted for on-device low power acoustic event detection (AED).\nThe proposed architecture is based on the gated recurrent unit (`GRU') but\nfeatures optimizations that make it implementable on ultra-low power\nmicro-controllers such as the Arm Cortex M0+.\n  Our new architecture, the Embedded Gated Recurrent Unit (eGRU) is\ndemonstrated to be highly efficient and suitable for short-duration AED and\nkeyword spotting tasks. A single eGRU cell is 60x faster and 10x smaller than a\nGRU cell. Despite its optimizations, eGRU compares well with GRU across tasks\nof varying complexities.\n  The practicality of eGRU is investigated in a wearable acoustic event\ndetection application. An eGRU model is implemented and tested on the Arm\nCortex M0-based Atmel ATSAMD21E18 processor. The Arm M0+ implementation of the\neGRU model compares favorably with a full precision GRU that is running on a\nworkstation. The embedded eGRU model achieves a classification accuracy 95.3%,\nwhich is only 2% less than the full precision GRU.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 17:41:15 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Amoh", "Justice", ""], ["Odame", "Kofi", ""]]}, {"id": "1902.05040", "submitter": "Pedro H. P. Savarese", "authors": "Pedro Savarese, Itay Evron, Daniel Soudry, Nathan Srebro", "title": "How do infinite width bounded norm networks look in function space?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the question of what functions can be captured by ReLU networks\nwith an unbounded number of units (infinite width), but where the overall\nnetwork Euclidean norm (sum of squares of all weights in the system, except for\nan unregularized bias term for each unit) is bounded; or equivalently what is\nthe minimal norm required to approximate a given function. For functions $f :\n\\mathbb R \\rightarrow \\mathbb R$ and a single hidden layer, we show that the\nminimal network norm for representing $f$ is $\\max(\\int |f''(x)| dx,\n|f'(-\\infty) + f'(+\\infty)|)$, and hence the minimal norm fit for a sample is\ngiven by a linear spline interpolation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 18:11:33 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Savarese", "Pedro", ""], ["Evron", "Itay", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "1902.05062", "submitter": "Alexander Julian Ty", "authors": "Alexander J. A. Ty, Zheng Fang, Rivver A. Gonzalez, Paul J. Rozdeba,\n  Henry D. I. Abarbanel", "title": "Machine Learning of Time Series Using Time-delay Embedding and Precision\n  Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasking machine learning to predict segments of a time series requires\nestimating the parameters of a ML model with input/output pairs from the time\nseries. Using the equivalence between statistical data assimilation and\nsupervised machine learning, we revisit this task. The training method for the\nmachine utilizes a precision annealing approach to identifying the global\nminimum of the action (-log[P]). In this way we are able to identify the number\nof training pairs required to produce good generalizations (predictions) for\nthe time series. We proceed from a scalar time series $s(t_n); t_n = t_0 + n\n\\Delta t$ and using methods of nonlinear time series analysis show how to\nproduce a $D_E > 1$ dimensional time delay embedding space in which the time\nseries has no false neighbors as does the observed $s(t_n)$ time series. In\nthat $D_E$-dimensional space we explore the use of feed forward multi-layer\nperceptrons as network models operating on $D_E$-dimensional input and\nproducing $D_E$-dimensional outputs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:54:37 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 18:04:36 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ty", "Alexander J. A.", ""], ["Fang", "Zheng", ""], ["Gonzalez", "Rivver A.", ""], ["Rozdeba", "Paul J.", ""], ["Abarbanel", "Henry D. I.", ""]]}, {"id": "1902.05064", "submitter": "Matthew England Dr", "authors": "S. Deshpande, J. Shuttleworth, J. Yang, S. Taramonli and M. England", "title": "PLIT: An alignment-free computational tool for identification of long\n  non-coding RNAs in plant transcriptomic datasets", "comments": "36 pages. Author's accepted version (Green OA)", "journal-ref": "Computers in Biology and Medicine, 105, pp. 169 - 181, Elevier,\n  2019", "doi": "10.1016/j.compbiomed.2018.12.014", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long non-coding RNAs (lncRNAs) are a class of non-coding RNAs which play a\nsignificant role in several biological processes. RNA-seq based transcriptome\nsequencing has been extensively used for identification of lncRNAs. However,\naccurate identification of lncRNAs in RNA-seq datasets is crucial for exploring\ntheir characteristic functions in the genome as most coding potential\ncomputation (CPC) tools fail to accurately identify them in transcriptomic\ndata. Well-known CPC tools such as CPC2, lncScore, CPAT are primarily designed\nfor prediction of lncRNAs based on the GENCODE, NONCODE and CANTATAdb\ndatabases. The prediction accuracy of these tools often drops when tested on\ntranscriptomic datasets. This leads to higher false positive results and\ninaccuracy in the function annotation process. In this study, we present a\nnovel tool, PLIT, for the identification of lncRNAs in plants RNA-seq datasets.\nPLIT implements a feature selection method based on L1 regularization and\niterative Random Forests (iRF) classification for selection of optimal\nfeatures. Based on sequence and codon-bias features, it classifies the RNA-seq\nderived FASTA sequences into coding or long non-coding transcripts. Using L1\nregularization, 31 optimal features were obtained based on lncRNA and\nprotein-coding transcripts from 8 plant species. The performance of the tool\nwas evaluated on 7 plant RNA-seq datasets using 10-fold cross-validation. The\nanalysis exhibited superior accuracy when evaluated against currently available\nstate-of-the-art CPC tools.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 23:16:37 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Deshpande", "S.", ""], ["Shuttleworth", "J.", ""], ["Yang", "J.", ""], ["Taramonli", "S.", ""], ["England", "M.", ""]]}, {"id": "1902.05066", "submitter": "Weijia Zhang", "authors": "Weijia Zhang and Jiuyong Li and Lin Liu", "title": "Robust Multi-instance Learning with Stable Instances", "comments": "In Proceedings of the Twenty-Fourth European Conference on Artificial\n  Intelligence (ECAI'20)", "journal-ref": null, "doi": "10.3233/FAIA200280", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-instance learning (MIL) deals with tasks where data is represented by a\nset of bags and each bag is described by a set of instances. Unlike standard\nsupervised learning, only the bag labels are observed whereas the label for\neach instance is not available to the learner. Previous MIL studies typically\nfollow the i.i.d. assumption, that the training and test samples are\nindependently drawn from the same distribution. However, such assumption is\noften violated in real-world applications. Efforts have been made towards\naddressing distribution changes by importance weighting the training data with\nthe density ratio between the training and test samples. Unfortunately, models\noften need to be trained without seeing the test distributions. In this paper\nwe propose possibly the first framework for addressing distribution change in\nMIL without requiring access to the unlabeled test data. Our framework builds\nupon identifying a novel connection between MIL and the potential outcome\nframework in causal effect estimation. Experimental results on synthetic\ndistribution change datasets, real-world datasets with synthetic distribution\nbiases and real distributional biased image classification datasets validate\nthe effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 03:55:36 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 23:08:50 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 11:11:11 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 01:42:19 GMT"}, {"version": "v5", "created": "Mon, 26 Apr 2021 13:34:21 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Weijia", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""]]}, {"id": "1902.05068", "submitter": "Zhanyu Ma", "authors": "Zhanyu Ma, Jalil Taghia, Jun Guo", "title": "On the Convergence of Extended Variational Inference for Non-Gaussian\n  Statistical Models", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) is a widely used framework in Bayesian estimation.\nFor most of the non-Gaussian statistical models, it is infeasible to find an\nanalytically tractable solution to estimate the posterior distributions of the\nparameters. Recently, an improved framework, namely the extended variational\ninference (EVI), has been introduced and applied to derive analytically\ntractable solution by employing lower-bound approximation to the variational\nobjective function. Two conditions required for EVI implementation, namely the\nweak condition and the strong condition, are discussed and compared in this\npaper. In practical implementation, the convergence of the EVI depends on the\nselection of the lower-bound approximation, no matter with the weak condition\nor the strong condition. In general, two approximation strategies, the single\nlower-bound (SLB) approximation and the multiple lower-bounds (MLB)\napproximation, can be applied to carry out the lower-bound approximation. To\nclarify the differences between the SLB and the MLB, we will also discuss the\nconvergence properties of the aforementioned two approximations. Extensive\ncomparisons are made based on some existing EVI-based non-Gaussian statistical\nmodels. Theoretical analysis are conducted to demonstrate the differences\nbetween the weak and the strong conditions. Qualitative and quantitative\nexperimental results are presented to show the advantages of the SLB\napproximation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 07:35:54 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 15:13:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ma", "Zhanyu", ""], ["Taghia", "Jalil", ""], ["Guo", "Jun", ""]]}, {"id": "1902.05069", "submitter": "Royal Jain", "authors": "Royal Jain", "title": "Improving performance and inference on audio classification tasks using\n  capsule networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Classification of audio samples is an important part of many auditory\nsystems. Deep learning models based on the Convolutional and the Recurrent\nlayers are state-of-the-art in many such tasks. In this paper, we approach\naudio classification tasks using capsule networks trained by recently proposed\ndynamic routing-by-agreement mechanism. We propose an architecture for capsule\nnetworks fit for audio classification tasks and study the impact of various\nparameters on classification accuracy. Further, we suggest modifications for\nregularization and multi-label classification. We also develop insights into\nthe data using capsule outputs and show the utility of the learned network for\ntransfer learning. We perform experiments on 7 datasets of different domains\nand sizes and show significant improvements in performance compared to strong\nbaseline models. To the best of our knowledge, this is the first detailed study\nabout the application of capsule networks in the audio domain.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 08:36:19 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Jain", "Royal", ""]]}, {"id": "1902.05083", "submitter": "Nicolas Le Roux", "authors": "Nicolas Le Roux", "title": "Anytime Tail Averaging", "comments": "Added a specific section on the case of multiple accumulators when\n  k_t is a constant", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tail averaging consists in averaging the last examples in a stream. Common\ntechniques either have a memory requirement which grows with the number of\nsamples to average, are not available at every timestep or do not accomodate\ngrowing windows. We propose two techniques with a low constant memory cost that\nperform tail averaging with access to the average at every time step. We also\nshow how one can improve the accuracy of that average at the cost of increased\nmemory consumption.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 19:00:25 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 19:00:20 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Roux", "Nicolas Le", ""]]}, {"id": "1902.05113", "submitter": "Zhijian Li", "authors": "Zhijian Li, Xiyang Luo, Bao Wang, Andrea L. Bertozzi, and Jack Xin", "title": "A Study on Graph-Structured Recurrent Neural Networks and Sparsification\n  with Application to Epidemic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study epidemic forecasting on real-world health data by a graph-structured\nrecurrent neural network (GSRNN). We achieve state-of-the-art forecasting\naccuracy on the benchmark CDC dataset. To improve model efficiency, we sparsify\nthe network weights via transformed-$\\ell_1$ penalty and maintain prediction\naccuracy at the same level with 70% of the network weights being zero.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 20:29:51 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Li", "Zhijian", ""], ["Luo", "Xiyang", ""], ["Wang", "Bao", ""], ["Bertozzi", "Andrea L.", ""], ["Xin", "Jack", ""]]}, {"id": "1902.05116", "submitter": "Nicol\\'o Fusi", "authors": "Francesco Paolo Casale, Jonathan Gordon, Nicolo Fusi", "title": "Probabilistic Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural architecture search (NAS), the space of neural network\narchitectures is automatically explored to maximize predictive accuracy for a\ngiven task. Despite the success of recent approaches, most existing methods\ncannot be directly applied to large scale problems because of their prohibitive\ncomputational complexity or high memory usage. In this work, we propose a\nProbabilistic approach to neural ARchitecture SEarCh (PARSEC) that drastically\nreduces memory requirements while maintaining state-of-the-art computational\ncomplexity, making it possible to directly search over more complex\narchitectures and larger datasets. Our approach only requires as much memory as\nis needed to train a single architecture from our search space. This is due to\na memory-efficient sampling procedure wherein we learn a probability\ndistribution over high-performing neural network architectures. Importantly,\nthis framework enables us to transfer the distribution of architectures learnt\non smaller problems to larger ones, further reducing the computational cost. We\nshowcase the advantages of our approach in applications to CIFAR-10 and\nImageNet, where our approach outperforms methods with double its computational\ncost and matches the performance of methods with costs that are three orders of\nmagnitude larger.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 20:38:18 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Casale", "Francesco Paolo", ""], ["Gordon", "Jonathan", ""], ["Fusi", "Nicolo", ""]]}, {"id": "1902.05146", "submitter": "Vincent Corlay", "authors": "Vincent Corlay, Joseph J. Boutros, Philippe Ciblat, and Loic Brunel", "title": "On the CVP for the root lattices via folding with deep ReLU neural\n  networks", "comments": "Submitted to 2019 IEEE International Symposium on Information Theory\n  (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point lattices and their decoding via neural networks are considered in this\npaper. Lattice decoding in Rn, known as the closest vector problem (CVP),\nbecomes a classification problem in the fundamental parallelotope with a\npiecewise linear function defining the boundary. Theoretical results are\nobtained by studying root lattices. We show how the number of pieces in the\nboundary function reduces dramatically with folding, from exponential to\nlinear. This translates into a two-layer ReLU network requiring a number of\nneurons growing exponentially in n to solve the CVP, whereas this complexity\nbecomes polynomial in n for a deep ReLU network.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:20:18 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:45:01 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Corlay", "Vincent", ""], ["Boutros", "Joseph J.", ""], ["Ciblat", "Philippe", ""], ["Brunel", "Loic", ""]]}, {"id": "1902.05148", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Probabilistic Generative Deep Learning for Molecular Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic generative deep learning for molecular design involves the\ndiscovery and design of new molecules and analysis of their structure,\nproperties and activities by probabilistic generative models using the deep\nlearning approach. It leverages the existing huge databases and publications of\nexperimental results, and quantum-mechanical calculations, to learn and explore\nmolecular structure, properties and activities. We discuss the major components\nof probabilistic generative deep learning for molecular design, which include\nmolecular structure, molecular representations, deep generative models,\nmolecular latent representations and latent space, molecular structure-property\nand structure-activity relationships, molecular similarity and molecular\ndesign. We highlight significant recent work using or applicable to this new\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:21:08 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1902.05180", "submitter": "Vedhas Pandit", "authors": "Vedhas Pandit, Bj\\\"orn Schuller", "title": "The Many-to-Many Mapping Between the Concordance Correlation Coefficient\n  and the Mean Square Error", "comments": "Why this discovery, or the mapping formulation is important:\n  MSE1<MSE2 does not necessarily mean CCC1>CCC2. In other words, MSE\n  minimisation does not necessarily guarantee CCC maximisation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the mapping between two of the most pervasive utility functions,\nthe mean square error ($MSE$) and the concordance correlation coefficient (CCC,\n$\\rho_c$). Despite its drawbacks, $MSE$ is one of the most popular performance\nmetrics (and a loss function); along with lately $\\rho_c$ in many of the\nsequence prediction challenges. Despite the ever-growing simultaneous usage,\ne.g., inter-rater agreement, assay validation, a mapping between the two\nmetrics is missing, till date. While minimisation of $L_p$ norm of the errors\nor of its positive powers (e.g., $MSE$) is aimed at $\\rho_c$ maximisation, we\nreason the often-witnessed ineffectiveness of this popular loss function with\ngraphical illustrations. The discovered formula uncovers not only the\ncounterintuitive revelation that `$MSE_1<MSE_2$' does not imply\n`$\\rho_{c_1}>\\rho_{c_2}$', but also provides the precise range for the $\\rho_c$\nmetric for a given $MSE$. We discover the conditions for $\\rho_c$ optimisation\nfor a given $MSE$; and as a logical next step, for a given set of errors. We\ngeneralise and discover the conditions for any given $L_p$ norm, for an even p.\nWe present newly discovered, albeit apparent, mathematical paradoxes. The study\ninspires and anticipates a growing use of $\\rho_c$-inspired loss functions\ne.g., $\\left|\\frac{MSE}{\\sigma_{XY}}\\right|$, replacing the traditional\n$L_p$-norm loss functions in multivariate regressions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 01:36:27 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 00:20:05 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 01:55:21 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 22:11:09 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 18:58:02 GMT"}, {"version": "v6", "created": "Wed, 1 Jul 2020 18:01:35 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Pandit", "Vedhas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1902.05197", "submitter": "Linshan Jiang", "authors": "Linshan Jiang and Rui Tan and Xin Lou and Guosheng Lin", "title": "On Lightweight Privacy-Preserving Collaborative Learning for IoT Objects", "comments": "12 pages,IOTDI 2019", "journal-ref": null, "doi": "10.1145/3302505.3310070", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. This paper considers the design and\nimplementation of a practical privacy-preserving collaborative learning scheme,\nin which a curious learning coordinator trains a better machine learning model\nbased on the data samples contributed by a number of IoT objects, while the\nconfidentiality of the raw forms of the training data is protected against the\ncoordinator. Existing distributed machine learning and data encryption\napproaches incur significant computation and communication overhead, rendering\nthem ill-suited for resource-constrained IoT objects. We study an approach that\napplies independent Gaussian random projection at each IoT object to obfuscate\ndata and trains a deep neural network at the coordinator based on the projected\ndata from the IoT objects. This approach introduces light computation overhead\nto the IoT objects and moves most workload to the coordinator that can have\nsufficient computing resources. Although the independent projections performed\nby the IoT objects address the potential collusion between the curious\ncoordinator and some compromised IoT objects, they significantly increase the\ncomplexity of the projected data. In this paper, we leverage the superior\nlearning capability of deep learning in capturing sophisticated patterns to\nmaintain good learning performance. Extensive comparative evaluation shows that\nthis approach outperforms other lightweight approaches that apply additive\nnoisification for differential privacy and/or support vector machines for\nlearning in the applications with light data pattern complexities.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 06:31:21 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Lou", "Xin", ""], ["Lin", "Guosheng", ""]]}, {"id": "1902.05213", "submitter": "Zhi Xu", "authors": "Devavrat Shah and Qiaomin Xie and Zhi Xu", "title": "Non-Asymptotic Analysis of Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the popular tree-based search strategy within the\nframework of reinforcement learning, the Monte Carlo Tree Search (MCTS), in the\ncontext of infinite-horizon discounted cost Markov Decision Process (MDP).\nWhile MCTS is believed to provide an approximate value function for a given\nstate with enough simulations, the claimed proof in the seminal works is\nincomplete. This is due to the fact that the variant, the Upper Confidence\nBound for Trees (UCT), analyzed in prior works utilizes \"logarithmic\" bonus\nterm for balancing exploration and exploitation within the tree-based search,\nfollowing the insights from stochastic multi-arm bandit (MAB) literature. In\neffect, such an approach assumes that the regret of the underlying recursively\ndependent non-stationary MABs concentrates around their mean exponentially in\nthe number of steps, which is unlikely to hold as pointed out in literature,\neven for stationary MABs. As the key contribution of this work, we establish\npolynomial concentration property of regret for a class of non-stationary MAB.\nThis in turn establishes that the MCTS with appropriate polynomial rather than\nlogarithmic bonus term in UCB has the claimed property. Using this as a\nbuilding block, we argue that MCTS, combined with nearest neighbor supervised\nlearning, acts as a \"policy improvement\" operator: it iteratively improves\nvalue function approximation for all states, due to combining with supervised\nlearning, despite evaluating at only finitely many states. In effect, we\nestablish that to learn an $\\varepsilon$ approximation of the value function\nwith respect to $\\ell_\\infty$ norm, MCTS combined with nearest neighbor\nrequires a sample size scaling as\n$\\widetilde{O}\\big(\\varepsilon^{-(d+4)}\\big)$, where $d$ is the dimension of\nthe state space. This is nearly optimal due to a minimax lower bound of\n$\\widetilde{\\Omega}\\big(\\varepsilon^{-(d+2)}\\big)$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 04:19:06 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 20:08:42 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 17:49:53 GMT"}, {"version": "v4", "created": "Mon, 13 Jan 2020 15:22:39 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Shah", "Devavrat", ""], ["Xie", "Qiaomin", ""], ["Xu", "Zhi", ""]]}, {"id": "1902.05312", "submitter": "Anastasia Borovykh", "authors": "Anastasia Borovykh, Cornelis W. Oosterlee, Sander M. Bohte", "title": "Generalisation in fully-connected neural networks for time series\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the generalization capabilities of fully-connected\nneural networks trained in the context of time series forecasting. Time series\ndo not satisfy the typical assumption in statistical learning theory of the\ndata being i.i.d. samples from some data-generating distribution. We use the\ninput and weight Hessians, that is the smoothness of the learned function with\nrespect to the input and the width of the minimum in weight space, to quantify\na network's ability to generalize to unseen data. While such generalization\nmetrics have been studied extensively in the i.i.d. setting of for example\nimage recognition, here we empirically validate their use in the task of time\nseries forecasting. Furthermore we discuss how one can control the\ngeneralization capability of the network by means of the training process using\nthe learning rate, batch size and the number of training iterations as\ncontrols. Using these hyperparameters one can efficiently control the\ncomplexity of the output function without imposing explicit constraints.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 11:44:01 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 01:54:02 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Borovykh", "Anastasia", ""], ["Oosterlee", "Cornelis W.", ""], ["Bohte", "Sander M.", ""]]}, {"id": "1902.05326", "submitter": "Colin Stephen", "authors": "Colin Stephen", "title": "Sinkhorn Divergence of Topological Signature Estimates for Time Series\n  Classification", "comments": "9 pages, 4 figures, 2018 17th International Conference on Machine\n  Learning and Applications", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00113", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between classes of time series sampled from dynamic systems is\na common challenge in systems and control engineering, for example in the\ncontext of health monitoring, fault detection, and quality control. The\nchallenge is increased when no underlying model of a system is known,\nmeasurement noise is present, and long signals need to be interpreted. In this\npaper we address these issues with a new non parametric classifier based on\ntopological signatures. Our model learns classes as weighted kernel density\nestimates (KDEs) over persistent homology diagrams and predicts new trajectory\nlabels using Sinkhorn divergences on the space of diagram KDEs to quantify\nproximity. We show that this approach accurately discriminates between states\nof chaotic systems that are close in parameter space, and its performance is\nrobust to noise.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 12:27:33 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Stephen", "Colin", ""]]}, {"id": "1902.05357", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Gaurav Kolhe, Setareh Rafatirad, Sai Manoj P. D., Houman\n  Homayoun, Liang Zhao, Chang-Tien Lu", "title": "Estimating the Circuit Deobfuscating Runtime based on Graph Deep\n  Learning", "comments": "Design, Automation and Test in Europe (DATE) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circuit obfuscation is a recently proposed defense mechanism to protect\ndigital integrated circuits (ICs) from reverse engineering by using camouflaged\ngates i.e., logic gates whose functionality cannot be precisely determined by\nthe attacker. There have been effective schemes such as satisfiability-checking\n(SAT)-based attacks that can potentially decrypt obfuscated circuits, called\ndeobfuscation. Deobfuscation runtime could have a large span ranging from few\nmilliseconds to thousands of years or more, depending on the number and layouts\nof the ICs and camouflaged gates. And hence accurately pre-estimating the\ndeobfuscation runtime is highly crucial for the defenders to maximize it and\noptimize their defense. However, estimating the deobfuscation runtime is a\nchallenging task due to 1) the complexity and heterogeneity of graph-structured\ncircuit, 2) the unknown and sophisticated mechanisms of the attackers for\ndeobfuscation. To address the above mentioned challenges, this work proposes\nthe first machine-learning framework that predicts the deobfuscation runtime\nbased on graph deep learning techniques. Specifically, we design a new model,\nICNet with new input and convolution layers to characterize and extract graph\nfrequencies from ICs, which are then integrated by heterogeneous deep\nfully-connected layers to obtain final output. ICNet is an end-to-end framework\nwhich can automatically extract the determinant features for deobfuscation\nruntime. Extensive experiments demonstrate its effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 13:57:11 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 13:34:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chen", "Zhiqian", ""], ["Kolhe", "Gaurav", ""], ["Rafatirad", "Setareh", ""], ["D.", "Sai Manoj P.", ""], ["Homayoun", "Houman", ""], ["Zhao", "Liang", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1902.05376", "submitter": "Guangcun Shan Prof.", "authors": "Guangcun Shan, Hongyu Wang and Wei Liang", "title": "Robust Encoder-Decoder Learning Framework towards Offline Handwritten\n  Mathematical Expression Recognition Based on Multi-Scale Deep Neural Network", "comments": "11 pages, 16 figures", "journal-ref": "Sci China Inf Sci, 2021, 64(3): 139101, doi:\n  10.1007/s11432-018-9824-9", "doi": "10.1007/s11432-018-9824-9", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline handwritten mathematical expression recognition is a challenging\ntask, because handwritten mathematical expressions mainly have two problems in\nthe process of recognition. On one hand, it is how to correctly recognize\ndifferent mathematical symbols. On the other hand, it is how to correctly\nrecognize the two-dimensional structure existing in mathematical expressions.\nInspired by recent work in deep learning, a new neural network model that\ncombines a Multi-Scale convolutional neural network (CNN) with an Attention\nrecurrent neural network (RNN) is proposed to identify two-dimensional\nhandwritten mathematical expressions as one-dimensional LaTeX sequences. As a\nresult, the model proposed in the present work has achieved a WER error of\n25.715% and ExpRate of 28.216%.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 03:29:49 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 09:29:27 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 11:06:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Shan", "Guangcun", ""], ["Wang", "Hongyu", ""], ["Liang", "Wei", ""]]}, {"id": "1902.05377", "submitter": "Yuxuan Liang", "authors": "Yuxuan Liang, Kun Ouyang, Lin Jing, Sijie Ruan, Ye Liu, Junbo Zhang,\n  David S. Rosenblum, Yu Zheng", "title": "UrbanFM: Inferring Fine-Grained Urban Flows", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330646", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban flow monitoring systems play important roles in smart city efforts\naround the world. However, the ubiquitous deployment of monitoring devices,\nsuch as CCTVs, induces a long-lasting and enormous cost for maintenance and\noperation. This suggests the need for a technology that can reduce the number\nof deployed devices, while preventing the degeneration of data accuracy and\ngranularity. In this paper, we aim to infer the real-time and fine-grained\ncrowd flows throughout a city based on coarse-grained observations. This task\nis challenging due to two reasons: the spatial correlations between coarse- and\nfine-grained urban flows, and the complexities of external impacts. To tackle\nthese issues, we develop a method entitled UrbanFM based on deep neural\nnetworks. Our model consists of two major parts: 1) an inference network to\ngenerate fine-grained flow distributions from coarse-grained inputs by using a\nfeature extraction module and a novel distributional upsampling module; 2) a\ngeneral fusion subnet to further boost the performance by considering the\ninfluences of different external factors. Extensive experiments on two\nreal-world datasets, namely TaxiBJ and HappyValley, validate the effectiveness\nand efficiency of our method compared to seven baselines, demonstrating the\nstate-of-the-art performance of our approach on the fine-grained urban flow\ninference problem.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 08:22:18 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liang", "Yuxuan", ""], ["Ouyang", "Kun", ""], ["Jing", "Lin", ""], ["Ruan", "Sijie", ""], ["Liu", "Ye", ""], ["Zhang", "Junbo", ""], ["Rosenblum", "David S.", ""], ["Zheng", "Yu", ""]]}, {"id": "1902.05378", "submitter": "Manuel Lagunas", "authors": "Manuel Lagunas, Elena Garces and Diego Gutierrez", "title": "Learning icons appearance similarity", "comments": "12 pages, 11 figures", "journal-ref": "Multimedia Tools and Applications, pages: 1-19, year: 2018,\n  publisher: Springer", "doi": "10.1007/s11042-018-6628-7", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting an optimal set of icons is a crucial step in the pipeline of visual\ndesign to structure and navigate through content. However, designing the icons\nsets is usually a difficult task for which expert knowledge is required. In\nthis work, to ease the process of icon set selection to the users, we propose a\nsimilarity metric which captures the properties of style and visual identity.\nWe train a Siamese Neural Network with an online dataset of icons organized in\nvisually coherent collections that are used to adaptively sample training data\nand optimize the training process. As the dataset contains noise, we further\ncollect human-rated information on the perception of icon's similarity which\nwill be used for evaluating and testing the proposed model. We present several\nresults and applications based on searches, kernel visualizations and optimized\nset proposals that can be helpful for designers and non-expert users while\nexploring large collections of icons.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:17:26 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Lagunas", "Manuel", ""], ["Garces", "Elena", ""], ["Gutierrez", "Diego", ""]]}, {"id": "1902.05379", "submitter": "Greg Olmschenk", "authors": "Greg Olmschenk, Hao Tang, Zhigang Zhu", "title": "Improving Dense Crowd Counting Convolutional Neural Networks using\n  Inverse k-Nearest Neighbor Maps and Multiscale Upsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gatherings of thousands to millions of people frequently occur for an\nenormous variety of events, and automated counting of these high-density crowds\nis useful for safety, management, and measuring significance of an event. In\nthis work, we show that the regularly accepted labeling scheme of crowd density\nmaps for training deep neural networks is less effective than our alternative\ninverse k-nearest neighbor (i$k$NN) maps, even when used directly in existing\nstate-of-the-art network structures. We also provide a new network architecture\nMUD-i$k$NN, which uses multi-scale upsampling via transposed convolutions to\ntake full advantage of the provided i$k$NN labeling. This upsampling combined\nwith the i$k$NN maps further improves crowd counting accuracy. Our new network\narchitecture performs favorably in comparison with the state-of-the-art.\nHowever, our labeling and upsampling techniques are generally applicable to\nexisting crowd counting architectures.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:05:47 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 21:07:05 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 20:59:03 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Olmschenk", "Greg", ""], ["Tang", "Hao", ""], ["Zhu", "Zhigang", ""]]}, {"id": "1902.05387", "submitter": "Alexander Boxer", "authors": "Seth Zuckerman, Timothy Klein, Alexander Boxer, Christopher Goldman,\n  Brian Lang", "title": "Simultaneous x, y Pixel Estimation and Feature Extraction for Multiple\n  Small Objects in a Scene: A Description of the ALIEN Network", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep-learning network that detects multiple small objects\n(hundreds to thousands) in a scene while simultaneously estimating their x,y\npixel locations together with a characteristic feature-set (for instance,\ntarget orientation and color). All estimations are performed in a single,\nforward pass which makes implementing the network fast and efficient. In this\npaper, we describe the architecture of our network --- nicknamed ALIEN --- and\ndetail its performance when applied to vehicle detection.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 16:45:32 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Zuckerman", "Seth", ""], ["Klein", "Timothy", ""], ["Boxer", "Alexander", ""], ["Goldman", "Christopher", ""], ["Lang", "Brian", ""]]}, {"id": "1902.05390", "submitter": "Akanksha Joshi", "authors": "Abhishek Gangwar, Akanksha Joshi, Padmaja Joshi, R. Raghavendra", "title": "DeepIrisNet2: Learning Deep-IrisCodes from Scratch for\n  Segmentation-Robust Visible Wavelength and Near Infrared Iris Recognition", "comments": "10 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first, introduce a deep learning based framework named as DeepIrisNet2 for\nvisible spectrum and NIR Iris representation. The framework can work without\nclassical iris normalization step or very accurate iris segmentation; allowing\nto work under non-ideal situation. The framework contains spatial transformer\nlayers to handle deformation and supervision branches after certain\nintermediate layers to mitigate overfitting. In addition, we present a dual CNN\niris segmentation pipeline comprising of a iris/pupil bounding boxes detection\nnetwork and a semantic pixel-wise segmentation network. Furthermore, to get\ncompact templates, we present a strategy to generate binary iris codes using\nDeepIrisNet2. Since, no ground truth dataset are available for CNN training for\niris segmentation, We build large scale hand labeled datasets and make them\npublic; i) iris, pupil bounding boxes, ii) labeled iris texture. The networks\nare evaluated on challenging ND-IRIS-0405, UBIRIS.v2, MICHE-I, and CASIA v4\nInterval datasets. Proposed approach significantly improves the\nstate-of-the-art and achieve outstanding performance surpassing all previous\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 08:07:37 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Gangwar", "Abhishek", ""], ["Joshi", "Akanksha", ""], ["Joshi", "Padmaja", ""], ["Raghavendra", "R.", ""]]}, {"id": "1902.05391", "submitter": "Weisi Guo", "authors": "Arya Pamuncak, Weisi Guo, Ahmed Soliman Khaled, Irwanda Laory", "title": "Deep Learning for Bridge Load Capacity Estimation in Post-Disaster and\n  -Conflict Zones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many post-disaster and -conflict regions do not have sufficient data on their\ntransportation infrastructure assets, hindering both mobility and\nreconstruction. In particular, as the number of aging and deteriorating bridges\nincrease, it is necessary to quantify their load characteristics in order to\ninform maintenance and prevent failure. The load carrying capacity and the\ndesign load are considered as the main aspects of any civil structures. Human\nexamination can be costly and slow when expertise is lacking in challenging\nscenarios. In this paper, we propose to employ deep learning as method to\nestimate the load carrying capacity from crowd sourced images. A new\nconvolutional neural network architecture is trained on data from over 6000\nbridges, which will benefit future research and applications. We tackle\nsignificant variations in the dataset (e.g. class interval, image completion,\nimage colour) and quantify their impact on the prediction accuracy, precision,\nrecall and F1 score. Finally, practical optimisation is performed by converting\nmulticlass classification into binary classification to achieve a promising\nfield use performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 23:44:17 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Pamuncak", "Arya", ""], ["Guo", "Weisi", ""], ["Khaled", "Ahmed Soliman", ""], ["Laory", "Irwanda", ""]]}, {"id": "1902.05392", "submitter": "Serhan G\\\"ul", "authors": "Talmaj Marin\\v{c}, Vignesh Srinivasan, Serhan G\\\"ul, Cornelius Hellge,\n  Wojciech Samek", "title": "Multi-Kernel Prediction Networks for Denoising of Burst Images", "comments": "5 pages, 4 figures", "journal-ref": "2019 IEEE International Conference on Image Processing (ICIP), pp.\n  2404-2408", "doi": "10.1109/ICIP.2019.8803335", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low light or short-exposure photography the image is often corrupted by\nnoise. While longer exposure helps reduce the noise, it can produce blurry\nresults due to the object and camera motion. The reconstruction of a noise-less\nimage is an ill posed problem. Recent approaches for image denoising aim to\npredict kernels which are convolved with a set of successively taken images\n(burst) to obtain a clear image. We propose a deep neural network based\napproach called Multi-Kernel Prediction Networks (MKPN) for burst image\ndenoising. MKPN predicts kernels of not just one size but of varying sizes and\nperforms fusion of these different kernels resulting in one kernel per pixel.\nThe advantages of our method are two fold: (a) the different sized kernels help\nin extracting different information from the image which results in better\nreconstruction and (b) kernel fusion assures retaining of the extracted\ninformation while maintaining computational efficiency. Experimental results\nreveal that MKPN outperforms state-of-the-art on our synthetic datasets with\ndifferent noise levels.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:29:09 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 14:57:46 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Marin\u010d", "Talmaj", ""], ["Srinivasan", "Vignesh", ""], ["G\u00fcl", "Serhan", ""], ["Hellge", "Cornelius", ""], ["Samek", "Wojciech", ""]]}, {"id": "1902.05394", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang, Haopeng Li and Fabian Wenger", "title": "Object Detection and 3D Estimation via an FMCW Radar Using a Fully\n  Convolutional Network", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers object detection and 3D estimation using an FMCW radar.\nThe state-of-the-art deep learning framework is employed instead of using\ntraditional signal processing. In preparing the radar training data, the ground\ntruth of an object orientation in 3D space is provided by conducting image\nanalysis, of which the images are obtained through a coupled camera to the\nradar device. To ensure successful training of a fully convolutional network\n(FCN), we propose a normalization method, which is found to be essential to be\napplied to the radar signal before feeding into the neural network. The system\nafter proper training is able to first detect the presence of an object in an\nenvironment. If it does, the system then further produces an estimation of its\n3D position. Experimental results show that the proposed system can be\nsuccessfully trained and employed for detecting a car and further estimating\nits 3D position in a noisy environment.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:56:20 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Li", "Haopeng", ""], ["Wenger", "Fabian", ""]]}, {"id": "1902.05395", "submitter": "Wanming Huang", "authors": "Wanming Huang, Yida Xu, Ian Oppermann", "title": "Realistic Image Generation using Region-phrase Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generative Adversarial Network (GAN) has recently been applied to\ngenerate synthetic images from text. Despite significant advances, most current\nstate-of-the-art algorithms are regular-grid region based; when attention is\nused, it is mainly applied between individual regular-grid regions and a word.\nThese approaches are sufficient to generate images that contain a single object\nin its foreground, such as a \"bird\" or \"flower\". However, natural languages\noften involve complex foreground objects and the background may also constitute\na variable portion of the generated image. Therefore, the regular-grid based\nimage attention weights may not necessarily concentrate on the intended\nforeground region(s), which in turn, results in an unnatural looking image.\nAdditionally, individual words such as \"a\", \"blue\" and \"shirt\" do not\nnecessarily provide a full visual context unless they are applied together. For\nthis reason, in our paper, we proposed a novel method in which we introduced an\nadditional set of attentions between true-grid regions and word phrases. The\ntrue-grid region is derived using a set of auxiliary bounding boxes. These\nauxiliary bounding boxes serve as superior location indicators to where the\nalignment and attention should be drawn with the word phrases. Word phrases are\nderived from analysing Part-of-Speech (POS) results. We perform experiments on\nthis novel network architecture using the Microsoft Common Objects in Context\n(MSCOCO) dataset and the model generates $256 \\times 256$ conditioned on a\nshort sentence description. Our proposed approach is capable of generating more\nrealistic images compared with the current state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 11:23:00 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Huang", "Wanming", ""], ["Xu", "Yida", ""], ["Oppermann", "Ian", ""]]}, {"id": "1902.05396", "submitter": "Krishna Chaitanya", "authors": "Krishna Chaitanya, Neerav Karani, Christian Baumgartner, Olivio\n  Donati, Anton Becker, Ender Konukoglu", "title": "Semi-Supervised and Task-Driven Data Augmentation", "comments": "13 pages, 3 figures, 1 table, This article has been accepted at the\n  26th international conference on Information Processing in Medical Imaging\n  (IPMI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep learning methods for segmentation require large amounts of\nlabelled training data, without which they are prone to overfitting, not\ngeneralizing well to unseen images. In practice, obtaining a large number of\nannotations from clinical experts is expensive and time-consuming. One way to\naddress scarcity of annotated examples is data augmentation using random\nspatial and intensity transformations. Recently, it has been proposed to use\ngenerative models to synthesize realistic training examples, complementing the\nrandom augmentation. So far, these methods have yielded limited gains over the\nrandom augmentation. However, there is potential to improve the approach by (i)\nexplicitly modeling deformation fields (non-affine spatial transformation) and\nintensity transformations and (ii) leveraging unlabelled data during the\ngenerative process. With this motivation, we propose a novel task-driven data\naugmentation method where to synthesize new training examples, a generative\nnetwork explicitly models and applies deformation fields and additive intensity\nmasks on existing labelled data, modeling shape and intensity variations,\nrespectively. Crucially, the generative model is optimized to be conducive to\nthe task, in this case segmentation, and constrained to match the distribution\nof images observed from labelled and unlabelled samples. Furthermore, explicit\nmodeling of deformation fields allow synthesizing segmentation masks and images\nin exact correspondence by simply applying the generated transformation to an\ninput image and the corresponding annotation. Our experiments on cardiac\nmagnetic resonance images (MRI) showed that, for the task of segmentation in\nsmall training data scenarios, the proposed method substantially outperforms\nconventional augmentation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 11:21:23 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 10:08:23 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chaitanya", "Krishna", ""], ["Karani", "Neerav", ""], ["Baumgartner", "Christian", ""], ["Donati", "Olivio", ""], ["Becker", "Anton", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1902.05399", "submitter": "Mohammad Tofighi", "authors": "Yuelong Li, Mohammad Tofighi, Vishal Monga and Yonina C. Eldar", "title": "An Algorithm Unrolling Approach to Deep Image Deblurring", "comments": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have achieved vastly enhanced performance over\ntraditional iterative methods in many cases, they are generally empirically\ndesigned and the underlying structures are difficult to interpret. The\nalgorithm unrolling approach has helped connect iterative algorithms to neural\nnetwork architectures. However, such connections have not been made yet for\nblind image deblurring. In this paper, we propose a neural network architecture\nthat advances this idea. We first present an iterative algorithm that may be\nconsidered a generalization of the traditional total-variation regularization\nmethod on the gradient domain, and subsequently unroll the half-quadratic\nsplitting algorithm to construct a neural network. Our proposed deep network\nachieves significant practical performance gains while enjoying\ninterpretability at the same time. Experimental results show that our approach\noutperforms many state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 21:19:11 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 18:58:12 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Li", "Yuelong", ""], ["Tofighi", "Mohammad", ""], ["Monga", "Vishal", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1902.05400", "submitter": "Shayan Jawed", "authors": "Shayan Jawed, Eya Boumaiza, Josif Grabocka, Lars Schmidt-Thieme", "title": "Data-Driven Vehicle Trajectory Forecasting", "comments": "Published in ECML KNOWMe: 2nd International Workshop on Knowledge\n  Discovery from Mobility and Transportation Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active area of research is to increase the safety of self-driving\nvehicles. Although safety cannot be guarenteed completely, the capability of a\nvehicle to predict the future trajectories of its surrounding vehicles could\nhelp ensure this notion of safety to a greater deal. We cast the trajectory\nforecast problem in a multi-time step forecasting problem and develop a\nConvolutional Neural Network based approach to learn from trajectory sequences\ngenerated from completely raw dataset in real-time. Results show improvement\nover baselines.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 12:09:48 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Jawed", "Shayan", ""], ["Boumaiza", "Eya", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1902.05401", "submitter": "Thiago Vinicius Machado De Souza", "authors": "Thiago V.M. Souza and Cleber Zanchettin", "title": "Improving Deep Image Clustering With Spatial Transformer Layers", "comments": null, "journal-ref": "Artificial Neural Networks and Machine Learning -- ICANN 2019:\n  Text and Time Series:641--654,2019", "doi": "10.1007/978-3-030-30490-4_51", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image clustering is an important but challenging task in machine learning. As\nin most image processing areas, the latest improvements came from models based\non the deep learning approach. However, classical deep learning methods have\nproblems to deal with spatial image transformations like scale and rotation. In\nthis paper, we propose the use of visual attention techniques to reduce this\nproblem in image clustering methods. We evaluate the combination of a deep\nimage clustering model called Deep Adaptive Clustering (DAC) with the Spatial\nTransformer Networks (STN). The proposed model is evaluated in the datasets\nMNIST and FashionMNIST and outperformed the baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 01:56:24 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 13:43:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Souza", "Thiago V. M.", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1902.05402", "submitter": "James Murphy", "authors": "James M. Murphy and Mauro Maggioni", "title": "Spectral-Spatial Diffusion Geometry for Hyperspectral Image Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2019.2943001", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unsupervised learning algorithm to cluster hyperspectral image (HSI) data\nis proposed that exploits spatially-regularized random walks. Markov diffusions\nare defined on the space of HSI spectra with transitions constrained to near\nspatial neighbors. The explicit incorporation of spatial regularity into the\ndiffusion construction leads to smoother random processes that are more adapted\nfor unsupervised machine learning than those based on spectra alone. The\nregularized diffusion process is subsequently used to embed the\nhigh-dimensional HSI into a lower dimensional space through diffusion\ndistances. Cluster modes are computed using density estimation and diffusion\ndistances, and all other points are labeled according to these modes. The\nproposed method has low computational complexity and performs competitively\nagainst state-of-the-art HSI clustering algorithms on real data. In particular,\nthe proposed spatial regularization confers an empirical advantage over\nnon-regularized methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 13:28:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Murphy", "James M.", ""], ["Maggioni", "Mauro", ""]]}, {"id": "1902.05408", "submitter": "Bob D. de Vos", "authors": "Bob D. de Vos, Jelmer M. Wolterink, Tim Leiner, Pim A. de Jong,\n  Nikolas Lessmann, Ivana Isgum", "title": "Direct Automatic Coronary Calcium Scoring in Cardiac and Chest CT", "comments": "IEEE Transactions on Medical Imaging (In press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular disease (CVD) is the global leading cause of death. A strong\nrisk factor for CVD events is the amount of coronary artery calcium (CAC). To\nmeet demands of the increasing interest in quantification of CAC, i.e. coronary\ncalcium scoring, especially as an unrequested finding for screening and\nresearch, automatic methods have been proposed. Current automatic calcium\nscoring methods are relatively computationally expensive and only provide\nscores for one type of CT. To address this, we propose a computationally\nefficient method that employs two ConvNets: the first performs registration to\nalign the fields of view of input CTs and the second performs direct regression\nof the calcium score, thereby circumventing time-consuming intermediate CAC\nsegmentation. Optional decision feedback provides insight in the regions that\ncontributed to the calcium score. Experiments were performed using 903 cardiac\nCT and 1,687 chest CT scans. The method predicted calcium scores in less than\n0.3 s. Intra-class correlation coefficient between predicted and manual calcium\nscores was 0.98 for both cardiac and chest CT. The method showed almost perfect\nagreement between automatic and manual CVD risk categorization in both\ndatasets, with a linearly weighted Cohen's kappa of 0.95 in cardiac CT and 0.93\nin chest CT. Performance is similar to that of state-of-the-art methods, but\nthe proposed method is hundreds of times faster. By providing visual feedback,\ninsight is given in the decision process, making it readily implementable in\nclinical and research settings.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 21:50:21 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["de Vos", "Bob D.", ""], ["Wolterink", "Jelmer M.", ""], ["Leiner", "Tim", ""], ["de Jong", "Pim A.", ""], ["Lessmann", "Nikolas", ""], ["Isgum", "Ivana", ""]]}, {"id": "1902.05411", "submitter": "Ram Krishna Pandey", "authors": "Ram Krishna Pandey, Souvik Karmakar, A G Ramakrishnan and Nabagata\n  Saha", "title": "Improving Facial Emotion Recognition Systems Using Gradient and\n  Laplacian Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we have proposed several enhancements to improve the\nperformance of any facial emotion recognition (FER) system. We believe that the\nchanges in the positions of the fiducial points and the intensities capture the\ncrucial information regarding the emotion of a face image. We propose the use\nof the gradient and the Laplacian of the input image together with the original\ninput into a convolutional neural network (CNN). These modifications help the\nnetwork learn additional information from the gradient and Laplacian of the\nimages. However, the plain CNN is not able to extract this information from the\nraw images. We have performed a number of experiments on two well known\ndatasets KDEF and FERplus. Our approach enhances the already high performance\nof state-of-the-art FER systems by 3 to 5%.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 10:00:34 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Pandey", "Ram Krishna", ""], ["Karmakar", "Souvik", ""], ["Ramakrishnan", "A G", ""], ["Saha", "Nabagata", ""]]}, {"id": "1902.05413", "submitter": "Bo Feng", "authors": "Fanbo Sun, Zhixiang Gu, Bo Feng", "title": "Yelp Food Identification via Image Feature Extraction and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Yelp has been one of the most popular local service search engine in US since\n2004. It is powered by crowd-sourced text reviews and photo reviews. Restaurant\ncustomers and business owners upload photo images to Yelp, including reviewing\nor advertising either food, drinks, or inside and outside decorations. It is\nobviously not so effective that labels for food photos rely on human editors,\nwhich is an issue should be addressed by innovative machine learning\napproaches. In this paper, we present a simple but effective approach which can\nidentify up to ten kinds of food via raw photos from the challenge dataset. We\nuse 1) image pre-processing techniques, including filtering and image\naugmentation, 2) feature extraction via convolutional neural networks (CNN),\nand 3) three ways of classification algorithms. Then, we illustrate the\nclassification accuracy by tuning parameters for augmentations, CNN, and\nclassification. Our experimental results show this simple but effective\napproach to identify up to 10 food types from images.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 19:34:34 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Sun", "Fanbo", ""], ["Gu", "Zhixiang", ""], ["Feng", "Bo", ""]]}, {"id": "1902.05414", "submitter": "Marc Aubreville", "authors": "Marc Aubreville, Christof A. Bertram, Christian Marzahl, Corinne\n  Gurtner, Martina Dettwiler, Anja Schmidt, Florian Bartenschlager, Sophie\n  Merz, Marco Fragoso, Olivia Kershaw, Robert Klopfleisch and Andreas Maier", "title": "Deep learning algorithms out-perform veterinary pathologists in\n  detecting the mitotically most active tumor region", "comments": "13 pages, 7 figures", "journal-ref": "Sci Rep. 2020 Oct 5;10(1):16447", "doi": "10.1038/s41598-020-73246-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manual count of mitotic figures, which is determined in the tumor region with\nthe highest mitotic activity, is a key parameter of most tumor grading schemes.\nIt can be, however, strongly dependent on the area selection due to uneven\nmitotic figure distribution in the tumor section.We aimed to assess the\nquestion, how significantly the area selection could impact the mitotic count,\nwhich has a known high inter-rater disagreement. On a data set of 32 whole\nslide images of H&E-stained canine cutaneous mast cell tumor, fully annotated\nfor mitotic figures, we asked eight veterinary pathologists (five\nboard-certified, three in training) to select a field of interest for the\nmitotic count. To assess the potential difference on the mitotic count, we\ncompared the mitotic count of the selected regions to the overall distribution\non the slide.Additionally, we evaluated three deep learning-based methods for\nthe assessment of highest mitotic density: In one approach, the model would\ndirectly try to predict the mitotic count for the presented image patches as a\nregression task. The second method aims at deriving a segmentation mask for\nmitotic figures, which is then used to obtain a mitotic density. Finally, we\nevaluated a two-stage object-detection pipeline based on state-of-the-art\narchitectures to identify individual mitotic figures. We found that the\npredictions by all models were, on average, better than those of the experts.\nThe two-stage object detector performed best and outperformed most of the human\npathologists on the majority of tumor cases. The correlation between the\npredicted and the ground truth mitotic count was also best for this approach\n(0.963 to 0.979). Further, we found considerable differences in position\nselection between pathologists, which could partially explain the high variance\nthat has been reported for the manual mitotic count.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:37:20 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 10:16:34 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 05:49:22 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Aubreville", "Marc", ""], ["Bertram", "Christof A.", ""], ["Marzahl", "Christian", ""], ["Gurtner", "Corinne", ""], ["Dettwiler", "Martina", ""], ["Schmidt", "Anja", ""], ["Bartenschlager", "Florian", ""], ["Merz", "Sophie", ""], ["Fragoso", "Marco", ""], ["Kershaw", "Olivia", ""], ["Klopfleisch", "Robert", ""], ["Maier", "Andreas", ""]]}, {"id": "1902.05433", "submitter": "Swetava Ganguli", "authors": "Swetava Ganguli, Jared Dunnmon, Darren Hau", "title": "Predicting Food Security Outcomes Using Convolutional Neural Networks\n  (CNNs) for Satellite Tasking", "comments": "Research performed as part of the Sustainability and Artificial\n  Intelligence Laboratory (SAIL) at Stanford University. Second revised version\n  corrects typographical errors and adds a few references", "journal-ref": null, "doi": null, "report-no": "Prepared as submission for final project of the Fall 2016 offering\n  of CS 221 Artificial Intelligence at Stanford University", "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Obtaining reliable data describing local Food Security Metrics (FSM) at a\ngranularity that is informative to policy-makers requires expensive and\nlogistically difficult surveys, particularly in the developing world. We train\na CNN on publicly available satellite data describing land cover classification\nand use both transfer learning and direct training to build a model for FSM\nprediction purely from satellite imagery data. We then propose efficient\ntasking algorithms for high resolution satellite assets via transfer learning,\nMarkovian search algorithms, and Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 02:22:12 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 19:47:36 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Ganguli", "Swetava", ""], ["Dunnmon", "Jared", ""], ["Hau", "Darren", ""]]}, {"id": "1902.05446", "submitter": "Jorge Davila-Chacon", "authors": "Jorge, Davila-Chacon and Jindong, Liu and Stefan, Wermter", "title": "Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source\n  Localization", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (Volume:\n  30, Issue: 1, Jan. 2019)", "doi": "10.1109/TNNLS.2018.2830119", "report-no": null, "categories": "cs.SD cs.HC cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the behavior of humans talking in noisy environments, we propose\nan embodied embedded cognition approach to improve automatic speech recognition\n(ASR) systems for robots in challenging environments, such as with ego noise,\nusing binaural sound source localization (SSL). The approach is verified by\nmeasuring the impact of SSL with a humanoid robot head on the performance of an\nASR system. More specifically, a robot orients itself toward the angle where\nthe signal-to-noise ratio (SNR) of speech is maximized for one microphone\nbefore doing an ASR task. First, a spiking neural network inspired by the\nmidbrain auditory system based on our previous work is applied to calculate the\nsound signal angle. Then, a feedforward neural network is used to handle high\nlevels of ego noise and reverberation in the signal. Finally, the sound signal\nis fed into an ASR system. For ASR, we use a system developed by our group and\ncompare its performance with and without the support from SSL. We test our SSL\nand ASR systems on two humanoid platforms with different structural and\nmaterial properties. With our approach we halve the sentence error rate with\nrespect to the common downmixing of both channels. Surprisingly, the ASR\nperformance is more than two times better when the angle between the humanoid\nhead and the sound source allows sound waves to be reflected most intensely\nfrom the pinna to the ear microphone, rather than when sound waves arrive\nperpendicularly to the membrane.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 14:09:11 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Jorge", "", ""], ["Davila-Chacon", "", ""], ["Jindong", "", ""], ["Liu", "", ""], ["Stefan", "", ""], ["Wermter", "", ""]]}, {"id": "1902.05454", "submitter": "Devon Graham Mr", "authors": "Robert Kleinberg, Kevin Leyton-Brown, Brendan Lucier and Devon Graham", "title": "Procrastinating with Confidence: Near-Optimal, Anytime, Adaptive\n  Algorithm Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm configuration methods optimize the performance of a parameterized\nheuristic algorithm on a given distribution of problem instances. Recent work\nintroduced an algorithm configuration procedure (\"Structured Procrastination\")\nthat provably achieves near optimal performance with high probability and with\nnearly minimal runtime in the worst case. It also offers an $\\textit{anytime}$\nproperty: it keeps tightening its optimality guarantees the longer it is run.\nUnfortunately, Structured Procrastination is not $\\textit{adaptive}$ to\ncharacteristics of the parameterized algorithm: it treats every input like the\nworst case. Follow-up work (\"LeapsAndBounds\") achieves adaptivity but trades\naway the anytime property. This paper introduces a new algorithm, \"Structured\nProcrastination with Confidence\", that preserves the near-optimality and\nanytime properties of Structured Procrastination while adding adaptivity. In\nparticular, the new algorithm will perform dramatically faster in settings\nwhere many algorithm configurations perform poorly. We show empirically both\nthat such settings arise frequently in practice and that the anytime property\nis useful for finding good configurations quickly.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 15:47:15 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 14:13:07 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 15:05:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kleinberg", "Robert", ""], ["Leyton-Brown", "Kevin", ""], ["Lucier", "Brendan", ""], ["Graham", "Devon", ""]]}, {"id": "1902.05478", "submitter": "Marcos Eduardo Valle", "authors": "Fidelis Zanetti de Castro and Marcos Eduardo Valle", "title": "A Broad Class of Discrete-Time Hypercomplex-Valued Hopfield Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.09.040", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the stability of a broad class of discrete-time\nhypercomplex-valued Hopfield-type neural networks. To ensure the neural\nnetworks belonging to this class always settle down at a stationary state, we\nintroduce novel hypercomplex number systems referred to as real-part\nassociative hypercomplex number systems. Real-part associative hypercomplex\nnumber systems generalize the well-known Cayley-Dickson algebras and real\nClifford algebras and include the systems of real numbers, complex numbers,\ndual numbers, hyperbolic numbers, quaternions, tessarines, and octonions as\nparticular instances. Apart from the novel hypercomplex number systems, we\nintroduce a family of hypercomplex-valued activation functions called\n$\\mathcal{B}$-projection functions. Broadly speaking, a\n$\\mathcal{B}$-projection function projects the activation potential onto the\nset of all possible states of a hypercomplex-valued neuron. Using the theory\npresented in this paper, we confirm the stability analysis of several\ndiscrete-time hypercomplex-valued Hopfield-type neural networks from the\nliterature. Moreover, we introduce and provide the stability analysis of a\ngeneral class of Hopfield-type neural networks on Cayley-Dickson algebras.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 16:21:49 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 11:55:45 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 12:54:32 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["de Castro", "Fidelis Zanetti", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "1902.05482", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "Classifying Treatment Responders Under Causal Effect Monotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of individual-level causal inference, we study the problem of\npredicting whether someone will respond or not to a treatment based on their\nfeatures and past examples of features, treatment indicator (e.g., drug/no\ndrug), and a binary outcome (e.g., recovery from disease). As a classification\ntask, the problem is made difficult by not knowing the example outcomes under\nthe opposite treatment indicators. We assume the effect is monotonic, as in\nadvertising's effect on a purchase or bail-setting's effect on reappearance in\ncourt: either it would have happened regardless of treatment, not happened\nregardless, or happened only depending on exposure to treatment. Predicting\nwhether the latter is latently the case is our focus. While previous work\nfocuses on conditional average treatment effect estimation, formulating the\nproblem as a classification task rather than an estimation task allows us to\ndevelop new tools more suited to this problem. By leveraging monotonicity, we\ndevelop new discriminative and generative algorithms for the\nresponder-classification problem. We explore and discuss connections to\ncorrupted data and policy learning. We provide an empirical study with both\nsynthetic and real datasets to compare these specialized algorithms to standard\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 16:32:14 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:00:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "1902.05498", "submitter": "Thomio Watanabe", "authors": "Thomio Watanabe and Denis Wolf", "title": "Instance Segmentation as Image Segmentation Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instance segmentation problem intends to precisely detect and delineate\nobjects in images. Most of the current solutions rely on deep convolutional\nneural networks but despite this fact proposed solutions are very diverse. Some\nsolutions approach the problem as a network problem, where they use several\nnetworks or specialize a single network to solve several tasks. A different\napproach tries to solve the problem as an annotation problem, where the\ninstance information is encoded in a mathematical representation. This work\nproposes a solution based in the DCME technique to solve the instance\nsegmentation with a single segmentation network. Different from others, the\nsegmentation network decoder is not specialized in a multi-task network.\nInstead, the network encoder is repurposed to classify image objects, reducing\nthe computational cost of the solution.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 10:53:25 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Watanabe", "Thomio", ""], ["Wolf", "Denis", ""]]}, {"id": "1902.05499", "submitter": "Crystal Nguyen", "authors": "Crystal T. Nguyen (1), Daniel J. Luckett (1), Anna R. Kahkoska (2),\n  Grace E. Shearrer (2), Donna Spruijt-Metz (3), Jaimie N. Davis (4), and\n  Michael R. Kosorok (1) ((1) Department of Biostatistics, University of North\n  Carolina, Chapel Hill, North Carolina, U.S.A., (2) Department of Nutrition,\n  University of North Carolina, Chapel Hill, U.S.A., (3) Center of Economic and\n  Social Research, University of Southern California, Los Angeles, California,\n  U.S.A., (4) Department of Nutrition, University of Texas, Austin, Texas,\n  U.S.A.)", "title": "Estimating Individualized Treatment Regimes from Crossover Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of precision medicine aims to tailor treatment based on\npatient-specific factors in a reproducible way. To this end, estimating an\noptimal individualized treatment regime (ITR) that recommends treatment\ndecisions based on patient characteristics to maximize the mean of a\npre-specified outcome is of particular interest. Several methods have been\nproposed for estimating an optimal ITR from clinical trial data in the parallel\ngroup setting where each subject is randomized to a single intervention.\nHowever, little work has been done in the area of estimating the optimal ITR\nfrom crossover study designs. Such designs naturally lend themselves to\nprecision medicine, because they allow for observing the response to multiple\ntreatments for each patient. In this paper, we introduce a method for\nestimating the optimal ITR using data from a 2x2 crossover study with or\nwithout carryover effects. The proposed method is similar to policy search\nmethods such as outcome weighted learning; however, we take advantage of the\ncrossover design by using the difference in responses under each treatment as\nthe observed reward. We establish Fisher and global consistency, present\nnumerical experiments, and analyze data from a feeding trial to demonstrate the\nimproved performance of the proposed method compared to standard methods for a\nparallel study design.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 02:28:33 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Nguyen", "Crystal T.", ""], ["Luckett", "Daniel J.", ""], ["Kahkoska", "Anna R.", ""], ["Shearrer", "Grace E.", ""], ["Spruijt-Metz", "Donna", ""], ["Davis", "Jaimie N.", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "1902.05522", "submitter": "Brian Cheung", "authors": "Brian Cheung, Alex Terekhov, Yubei Chen, Pulkit Agrawal, Bruno\n  Olshausen", "title": "Superposition of many models into one", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for storing multiple models within a single set of\nparameters. Models can coexist in superposition and still be retrieved\nindividually. In experiments with neural networks, we show that a surprisingly\nlarge number of models can be effectively stored within a single parameter\ninstance. Furthermore, each of these models can undergo thousands of training\nsteps without significantly interfering with other models within the\nsuperposition. This approach may be viewed as the online complement of\ncompression: rather than reducing the size of a network after training, we make\nuse of the unrealized capacity of a network during training.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 17:59:13 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 17:58:36 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Cheung", "Brian", ""], ["Terekhov", "Alex", ""], ["Chen", "Yubei", ""], ["Agrawal", "Pulkit", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1902.05542", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Gleb Shevchuk, Dorsa Sadigh, Chelsea Finn", "title": "Unsupervised Visuomotor Control through Distributional Planning Networks", "comments": "Videos available at https://sites.google.com/view/dpn-public/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning (RL) has the potential to enable robots to\nautonomously acquire a wide range of skills, in practice, RL usually requires\nmanual, per-task engineering of reward functions, especially in real world\nsettings where aspects of the environment needed to compute progress are not\ndirectly accessible. To enable robots to autonomously learn skills, we instead\nconsider the problem of reinforcement learning without access to rewards. We\naim to learn an unsupervised embedding space under which the robot can measure\nprogress towards a goal for itself. Our approach explicitly optimizes for a\nmetric space under which action sequences that reach a particular state are\noptimal when the goal is the final state reached. This enables learning\neffective and control-centric representations that lead to more autonomous\nreinforcement learning algorithms. Our experiments on three simulated\nenvironments and two real-world manipulation problems show that our method can\nlearn effective goal metrics from unlabeled interaction, and use the learned\ngoal metrics for autonomous reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 18:54:54 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Yu", "Tianhe", ""], ["Shevchuk", "Gleb", ""], ["Sadigh", "Dorsa", ""], ["Finn", "Chelsea", ""]]}, {"id": "1902.05546", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Chris Lu, Trevor Darrell, Phillip Isola, Alexei A.\n  Efros", "title": "Learning to Control Self-Assembling Morphologies: A Study of\n  Generalization via Modularity", "comments": "NeurIPS 2019 (Spotlight). Videos at\n  https://pathak22.github.io/modular-assemblies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary sensorimotor learning approaches typically start with an\nexisting complex agent (e.g., a robotic arm), which they learn to control. In\ncontrast, this paper investigates a modular co-evolution strategy: a collection\nof primitive agents learns to dynamically self-assemble into composite bodies\nwhile also learning to coordinate their behavior to control these bodies. Each\nprimitive agent consists of a limb with a motor attached at one end. Limbs may\nchoose to link up to form collectives. When a limb initiates a link-up action,\nand there is another limb nearby, the latter is magnetically connected to the\n'parent' limb's motor. This forms a new single agent, which may further link\nwith other agents. In this way, complex morphologies can emerge, controlled by\na policy whose architecture is in explicit correspondence with the morphology.\nWe evaluate the performance of these dynamic and modular agents in simulated\nenvironments. We demonstrate better generalization to test-time changes both in\nthe environment, as well as in the structure of the agent, compared to static\nand monolithic baselines. Project video and code are available at\nhttps://pathak22.github.io/modular-assemblies/\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 21:35:27 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pathak", "Deepak", ""], ["Lu", "Chris", ""], ["Darrell", "Trevor", ""], ["Isola", "Phillip", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1902.05551", "submitter": "Gang Chen", "authors": "Gang Chen and Yiming Peng", "title": "Off-Policy Actor-Critic in an Ensemble: Achieving Maximum General\n  Entropy and Effective Environment Exploration in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new policy iteration theory as an important extension of soft\npolicy iteration and Soft Actor-Critic (SAC), one of the most efficient model\nfree algorithms for deep reinforcement learning. Supported by the new theory,\narbitrary entropy measures that generalize Shannon entropy, such as Tsallis\nentropy and Renyi entropy, can be utilized to properly randomize action\nselection while fulfilling the goal of maximizing expected long-term rewards.\nOur theory gives birth to two new algorithms, i.e., Tsallis entropy\nActor-Critic (TAC) and Renyi entropy Actor-Critic (RAC). Theoretical analysis\nshows that these algorithms can be more effective than SAC. Moreover, they pave\nthe way for us to develop a new Ensemble Actor-Critic (EAC) algorithm in this\npaper that features the use of a bootstrap mechanism for deep environment\nexploration as well as a new value-function based mechanism for high-level\naction selection. Empirically we show that TAC, RAC and EAC can achieve\nstate-of-the-art performance on a range of benchmark control tasks,\noutperforming SAC and several cutting-edge learning algorithms in terms of both\nsample efficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 02:29:36 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Chen", "Gang", ""], ["Peng", "Yiming", ""]]}, {"id": "1902.05568", "submitter": "Philippe Poulin", "authors": "Philippe Poulin, Daniel J\\\"orgens, Pierre-Marc Jodoin, Maxime\n  Descoteaux", "title": "Tractography and machine learning: Current state and open challenges", "comments": null, "journal-ref": null, "doi": "10.1016/j.mri.2019.04.013", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Supervised machine learning (ML) algorithms have recently been proposed as an\nalternative to traditional tractography methods in order to address some of\ntheir weaknesses. They can be path-based and local-model-free, and easily\nincorporate anatomical priors to make contextual and non-local decisions that\nshould help the tracking process. ML-based techniques have thus shown promising\nreconstructions of larger spatial extent of existing white matter bundles,\npromising reconstructions of less false positives, and promising robustness to\nknown position and shape biases of current tractography techniques. But as of\ntoday, none of these ML-based methods have shown conclusive performances or\nhave been adopted as a de facto solution to tractography. One reason for this\nmight be the lack of well-defined and extensive frameworks to train, evaluate,\nand compare these methods.\n  In this paper, we describe several datasets and evaluation tools that contain\nuseful features for ML algorithms, along with the various methods proposed in\nthe recent years. We then discuss the strategies that are used to evaluate and\ncompare those methods, as well as their shortcomings. Finally, we describe the\nparticular needs of ML tractography methods and discuss tangible solutions for\nfuture works.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 19:12:32 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Poulin", "Philippe", ""], ["J\u00f6rgens", "Daniel", ""], ["Jodoin", "Pierre-Marc", ""], ["Descoteaux", "Maxime", ""]]}, {"id": "1902.05575", "submitter": "Jacob Anderson", "authors": "Jacob Anderson", "title": "Fully Convolutional Networks for Text Classification", "comments": "6 pages, 4 tables, 3 figures, submitted for the EVALITA 2018 workshop\n  as part of clic-it 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work I propose a new way of using fully convolutional networks for\nclassification while allowing for input of any size. I additionally propose two\nmodifications on the idea of attention and the benefits and detriments of using\nthe modifications. Finally, I show suboptimal results on the ITAmoji 2018 tweet\nto emoji task and provide a discussion about why that might be the case as well\nas a proposed fix to further improve results.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 19:30:28 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Anderson", "Jacob", ""]]}, {"id": "1902.05578", "submitter": "Ra\\'ul V. Casa\\~na-Eslava PhD", "authors": "Ra\\'ul V. Casa\\~na-Eslava, Paulo J. G. Lisboa, Sandra\n  Ortega-Martorell, Ian H. Jarman and Jos\\'e D. Mart\\'in-Guerrero", "title": "A Probabilistic framework for Quantum Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Clustering is a powerful method to detect clusters in data with mixed\ndensity. However, it is very sensitive to a length parameter that is inherent\nto the Schr\\\"odinger equation. In addition, linking data points into clusters\nrequires local estimates of covariance that are also controlled by length\nparameters. This raises the question of how to adjust the control parameters of\nthe Schr\\\"odinger equation for optimal clustering. We propose a probabilistic\nframework that provides an objective function for the goodness-of-fit to the\ndata, enabling the control parameters to be optimised within a Bayesian\nframework. This naturally yields probabilities of cluster membership and data\npartitions with specific numbers of clusters. The proposed framework is tested\non real and synthetic data sets, assessing its validity by measuring\nconcordance with known data structure by means of the Jaccard score (JS). This\nwork also proposes an objective way to measure performance in unsupervised\nlearning that correlates very well with JS.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 19:43:12 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Casa\u00f1a-Eslava", "Ra\u00fal V.", ""], ["Lisboa", "Paulo J. G.", ""], ["Ortega-Martorell", "Sandra", ""], ["Jarman", "Ian H.", ""], ["Mart\u00edn-Guerrero", "Jos\u00e9 D.", ""]]}, {"id": "1902.05581", "submitter": "Wenju Xu", "authors": "Wenju Xu and Shawn Keshmiri and Guanghui Wang", "title": "Adversarially Approximated Autoencoder for Image Generation and\n  Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized autoencoders learn the latent codes, a structure with the\nregularization under the distribution, which enables them the capability to\ninfer the latent codes given observations and generate new samples given the\ncodes. However, they are sometimes ambiguous as they tend to produce\nreconstructions that are not necessarily faithful reproduction of the inputs.\nThe main reason is to enforce the learned latent code distribution to match a\nprior distribution while the true distribution remains unknown. To improve the\nreconstruction quality and learn the latent space a manifold structure, this\nwork present a novel approach using the adversarially approximated autoencoder\n(AAAE) to investigate the latent codes with adversarial approximation. Instead\nof regularizing the latent codes by penalizing on the distance between the\ndistributions of the model and the target, AAAE learns the autoencoder flexibly\nand approximates the latent space with a simpler generator. The ratio is\nestimated using generative adversarial network (GAN) to enforce the similarity\nof the distributions. Additionally, the image space is regularized with an\nadditional adversarial regularizer. The proposed approach unifies two deep\ngenerative models for both latent space inference and diverse generation. The\nlearning scheme is realized without regularization on the latent codes, which\nalso encourages faithful reconstruction. Extensive validation experiments on\nfour real-world datasets demonstrate the superior performance of AAAE. In\ncomparison to the state-of-the-art approaches, AAAE generates samples with\nbetter quality and shares the properties of regularized autoencoder with a nice\nlatent manifold structure.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 19:54:13 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Xu", "Wenju", ""], ["Keshmiri", "Shawn", ""], ["Wang", "Guanghui", ""]]}, {"id": "1902.05586", "submitter": "Brent Lagesse", "authors": "Cody Burkard, Brent Lagesse", "title": "Can Intelligent Hyperparameter Selection Improve Resistance to\n  Adversarial Examples?", "comments": "37 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks and Deep Learning classification systems in\ngeneral have been shown to be vulnerable to attack by specially crafted data\nsamples that appear to belong to one class but are instead classified as\nanother, commonly known as adversarial examples. A variety of attack strategies\nhave been proposed to craft these samples; however, there is no standard model\nthat is used to compare the success of each type of attack. Furthermore, there\nis no literature currently available that evaluates how common hyperparameters\nand optimization strategies may impact a model's ability to resist these\nsamples. This research bridges that lack of awareness and provides a means for\nthe selection of training and model parameters in future research on evasion\nattacks against convolutional neural networks. The findings of this work\nindicate that the selection of model hyperparameters does impact the ability of\na model to resist attack, although they alone cannot prevent the existence of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 20:11:12 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Burkard", "Cody", ""], ["Lagesse", "Brent", ""]]}, {"id": "1902.05590", "submitter": "Guy Aridor", "authors": "Guy Aridor and Kevin Liu and Aleksandrs Slivkins and Zhiwei Steven Wu", "title": "The Perils of Exploration under Competition: A Computational Modeling\n  Approach", "comments": "This is a preprint of an article accepted for EC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically study the interplay between exploration and competition.\nSystems that learn from interactions with users often engage in exploration:\nmaking potentially suboptimal decisions in order to acquire new information for\nfuture decisions. However, when multiple systems are competing for the same\nmarket of users, exploration may hurt a system's reputation in the near term,\nwith adverse competitive effects. In particular, a system may enter a \"death\nspiral\", when the short-term reputation cost decreases the number of users for\nthe system to learn from, which degrades its performance relative to\ncompetition and further decreases its market share.\n  We ask whether better exploration algorithms are incentivized under\ncompetition. We run extensive numerical experiments in a stylized duopoly model\nin which two firms deploy multi-armed bandit algorithms and compete for myopic\nusers. We find that duopoly and monopoly tend to favor a primitive \"greedy\nalgorithm\" that does not explore and leads to low consumer welfare, whereas a\ntemporary monopoly (a duopoly with an early entrant) may incentivize better\nbandit algorithms and lead to higher consumer welfare. Our findings shed light\non the first-mover advantage in the digital economy by exploring the role that\ndata can play as a barrier to entry in online markets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 20:16:33 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 18:25:19 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Aridor", "Guy", ""], ["Liu", "Kevin", ""], ["Slivkins", "Aleksandrs", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1902.05601", "submitter": "Sebastian Ament", "authors": "Sebastian Ament and John Gregoire and Carla Gomes", "title": "Exponentially-Modified Gaussian Mixture Model: Applications in\n  Spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel exponentially-modified Gaussian (EMG) mixture residual\nmodel. The EMG mixture is well suited to model residuals that are contaminated\nby a distribution with positive support. This is in contrast to commonly used\nrobust residual models, like the Huber loss or $\\ell_1$, which assume a\nsymmetric contaminating distribution and are otherwise asymptotically biased.\nWe propose an expectation-maximization algorithm to optimize an arbitrary model\nwith respect to the EMG mixture. We apply the approach to linear regression and\nprobabilistic matrix factorization (PMF). We compare against other residual\nmodels, including quantile regression. Our numerical experiments demonstrate\nthe strengths of the EMG mixture on both tasks. The PMF model arises from\nconsidering spectroscopic data. In particular, we demonstrate the effectiveness\nof PMF in conjunction with the EMG mixture model on synthetic data and two\nreal-world applications: X-ray diffraction and Raman spectroscopy. We show how\nour approach is effective in inferring background signals and systematic errors\nin data arising from these experimental settings, dramatically outperforming\nexisting approaches and revealing the data's physically meaningful components.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 20:47:07 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Ament", "Sebastian", ""], ["Gregoire", "John", ""], ["Gomes", "Carla", ""]]}, {"id": "1902.05605", "submitter": "Max Argus", "authors": "Aditya Bhatt, Max Argus, Artemij Amiranashvili, Thomas Brox", "title": "CrossNorm: Normalization for Off-Policy TD Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy temporal difference (TD) methods are a powerful class of\nreinforcement learning (RL) algorithms. Intriguingly, deep off-policy TD\nalgorithms are not commonly used in combination with feature normalization\ntechniques, despite positive effects of normalization in other domains. We show\nthat naive application of existing normalization techniques is indeed not\neffective, but that well-designed normalization improves optimization stability\nand removes the necessity of target networks. In particular, we introduce a\nnormalization based on a mixture of on- and off-policy transitions, which we\ncall cross-normalization. It can be regarded as an extension of batch\nnormalization that re-centers data for two different distributions, as present\nin off-policy learning. Applied to DDPG and TD3, cross-normalization improves\nover the state of the art across a range of MuJoCo benchmark tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 21:05:50 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 15:53:02 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Bhatt", "Aditya", ""], ["Argus", "Max", ""], ["Amiranashvili", "Artemij", ""], ["Brox", "Thomas", ""]]}, {"id": "1902.05611", "submitter": "Swetava Ganguli", "authors": "Swetava Ganguli, Pedro Garzon, Noa Glaser", "title": "GeoGAN: A Conditional GAN with Reconstruction and Style Loss to Generate\n  Standard Layer of Maps from Satellite Images", "comments": "Version 2 of paper submitted incorporating minor revisions. Corrected\n  typographical errors and added some additional references", "journal-ref": null, "doi": null, "report-no": "Final report for research conducted as part of the Fall 2018\n  offering of CS 236 Deep Generative Models at Stanford University", "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatically generating maps from satellite images is an important task.\nThere is a body of literature which tries to address this challenge. We created\na more expansive survey of the task by experimenting with different models and\nadding new loss functions to improve results. We created a database of pairs of\nsatellite images and the corresponding map of the area. Our model translates\nthe satellite image to the corresponding standard layer map image using three\nmain model architectures: (i) a conditional Generative Adversarial Network\n(GAN) which compresses the images down to a learned embedding, (ii) a generator\nwhich is trained as a normalizing flow (RealNVP) model, and (iii) a conditional\nGAN where the generator translates via a series of convolutions to the standard\nlayer of a map and the discriminator input is the concatenation of the\nreal/generated map and the satellite image. Model (iii) was by far the most\npromising of three models. To improve the results we also added a\nreconstruction loss and style transfer loss in addition to the GAN losses. The\nthird model architecture produced the best quality of sampled images. In\ncontrast to the other generative model where evaluation of the model is a\nchallenging problem. since we have access to the real map for a given satellite\nimage, we are able to assign a quantitative metric to the quality of the\ngenerated images in addition to inspecting them visually. While we are\ncontinuing to work on increasing the accuracy of the model, one challenge has\nbeen the coarse resolution of the data which upper-bounds the quality of the\nresults of our model. Nevertheless, as will be seen in the results, the\ngenerated map is more accurate in the features it produces since the generator\narchitecture demands a pixel-wise image translation/pixel-wise coloring. A\nvideo presentation summarizing this paper is available at:\nhttps://youtu.be/Ur0flOX-Ji0\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 21:41:18 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 18:54:53 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Ganguli", "Swetava", ""], ["Garzon", "Pedro", ""], ["Glaser", "Noa", ""]]}, {"id": "1902.05624", "submitter": "Eoin Brophy", "authors": "Eoin Brophy, Zhengwei Wang, Tomas E. Ward", "title": "Quick and Easy Time Series Generation with Established Image-based GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years Generative Adversarial Networks (GANs) have demonstrated\nsignificant progress in generating authentic looking data. In this work we\nintroduce our simple method to exploit the advancements in well established\nimage-based GANs to synthesise single channel time series data. We implement\nWasserstein GANs (WGANs) with gradient penalty due to their stability in\ntraining to synthesise three different types of data; sinusoidal data,\nphotoplethysmograph (PPG) data and electrocardiograph (ECG) data. The length of\nthe returned time series data is limited only by the image resolution, we use\nan image size of 64x64 pixels which yields 4096 data points. We present both\nvisual and quantitative evidence that our novel method can successfully\ngenerate time series data using image-based GANs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:14:45 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 20:10:10 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 20:11:32 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Brophy", "Eoin", ""], ["Wang", "Zhengwei", ""], ["Ward", "Tomas E.", ""]]}, {"id": "1902.05625", "submitter": "Binhang Yuan", "authors": "Binhang Yuan, Chen Wang, Chen Luo, Fei Jiang, Mingsheng Long, Philip\n  S. Yu, Yuan Liu", "title": "WaveletAE: A Wavelet-enhanced Autoencoder for Wind Turbine Blade Icing\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind power, as an alternative to burning fossil fuels, is abundant and\ninexhaustible. To fully utilize wind power, wind farms are usually located in\nareas of high altitude and facing serious ice conditions, which can lead to\nserious consequences. Quick detection of blade ice accretion is crucial for the\nmaintenance of wind farms. Unlike traditional methods of installing expensive\nphysical detectors on wind blades, data-driven approaches are increasingly\npopular for inspecting the wind turbine failures. In this work, we propose a\nwavelet enhanced autoencoder model (WaveletAE) to identify wind turbine\ndysfunction by analyzing the multivariate time series monitored by the SCADA\nsystem. WaveletAE is enhanced with wavelet detail coefficients to enforce the\nautoencoder to capture information from multiple scales, and the CNN-LSTM\narchitecture is applied to learn channel-wise and temporal-wise relations. The\nempirical study shows that the proposed model outperforms other\nstate-of-the-art time series anomaly detection methods for real-world blade\nicing detection.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:20:52 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:54:13 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Yuan", "Binhang", ""], ["Wang", "Chen", ""], ["Luo", "Chen", ""], ["Jiang", "Fei", ""], ["Long", "Mingsheng", ""], ["Yu", "Philip S.", ""], ["Liu", "Yuan", ""]]}, {"id": "1902.05627", "submitter": "Henry WJ Reeve", "authors": "Henry W J Reeve and Ata Kaban", "title": "Classification with unknown class-conditional label noise on non-compact\n  feature spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of classification in the presence of unknown\nclass-conditional label noise in which the labels observed by the learner have\nbeen corrupted with some unknown class dependent probability. In order to\nobtain finite sample rates, previous approaches to classification with unknown\nclass-conditional label noise have required that the regression function is\nclose to its extrema on sets of large measure. We shall consider this problem\nin the setting of non-compact metric spaces, where the regression function need\nnot attain its extrema.\n  In this setting we determine the minimax optimal learning rates (up to\nlogarithmic factors). The rate displays interesting threshold behaviour: When\nthe regression function approaches its extrema at a sufficient rate, the\noptimal learning rates are of the same order as those obtained in the\nlabel-noise free setting. If the regression function approaches its extrema\nmore gradually then classification performance necessarily degrades. In\naddition, we present an adaptive algorithm which attains these rates without\nprior knowledge of either the distributional parameters or the local density.\nThis identifies for the first time a scenario in which finite sample rates are\nachievable in the label noise setting, but they differ from the optimal rates\nwithout label noise.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:22:49 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 07:36:03 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Reeve", "Henry W J", ""], ["Kaban", "Ata", ""]]}, {"id": "1902.05650", "submitter": "James Kostas", "authors": "James E. Kostas, Chris Nota, and Philip S. Thomas", "title": "Asynchronous Coagent Networks", "comments": "Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coagent policy gradient algorithms (CPGAs) are reinforcement learning\nalgorithms for training a class of stochastic neural networks called coagent\nnetworks. In this work, we prove that CPGAs converge to locally optimal\npolicies. Additionally, we extend prior theory to encompass asynchronous and\nrecurrent coagent networks. These extensions facilitate the straightforward\ndesign and analysis of hierarchical reinforcement learning algorithms like the\noption-critic, and eliminate the need for complex derivations of customized\nlearning rules for these algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 00:16:10 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 16:27:13 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 22:31:58 GMT"}, {"version": "v4", "created": "Mon, 10 Aug 2020 04:57:55 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kostas", "James E.", ""], ["Nota", "Chris", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1902.05653", "submitter": "Muhammad Shoaib Ahmed Siddiqui", "authors": "Muhammad Ali Chattha, Shoaib Ahmed Siddiqui, Muhammad Imran Malik,\n  Ludger van Elst, Andreas Dengel, Sheraz Ahmed", "title": "KINN: Incorporating Expert Knowledge in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The promise of ANNs to automatically discover and extract useful\nfeatures/patterns from data without dwelling on domain expertise although seems\nhighly promising but comes at the cost of high reliance on large amount of\naccurately labeled data, which is often hard to acquire and formulate\nespecially in time-series domains like anomaly detection, natural disaster\nmanagement, predictive maintenance and healthcare. As these networks completely\nrely on data and ignore a very important modality i.e. expert, they are unable\nto harvest any benefit from the expert knowledge, which in many cases is very\nuseful. In this paper, we try to bridge the gap between these data driven and\nexpert knowledge based systems by introducing a novel framework for\nincorporating expert knowledge into the network (KINN). Integrating expert\nknowledge into the network has three key advantages: (a) Reduction in the\namount of data needed to train the model, (b) provision of a lower bound on the\nperformance of the resulting classifier by obtaining the best of both worlds,\nand (c) improved convergence of model parameters (model converges in smaller\nnumber of epochs). Although experts are extremely good in solving different\ntasks, there are some trends and patterns, which are usually hidden only in the\ndata. Therefore, KINN employs a novel residual knowledge incorporation scheme,\nwhich can automatically determine the quality of the predictions made by the\nexpert and rectify it accordingly by learning the trends/patterns from data.\nSpecifically, the method tries to use information contained in one modality to\ncomplement information missed by the other. We evaluated KINN on a real world\ntraffic flow prediction problem. KINN significantly superseded performance of\nboth the expert and as well as the base network (LSTM in this case) when\nevaluated in isolation, highlighting its superiority for the task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 00:41:28 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Chattha", "Muhammad Ali", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["Malik", "Muhammad Imran", ""], ["van Elst", "Ludger", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1902.05679", "submitter": "Quoc Tran-Dinh", "authors": "Nhan H. Pham, Lam M. Nguyen, Dzung T. Phan, and Quoc Tran-Dinh", "title": "ProxSARAH: An Efficient Algorithmic Framework for Stochastic Composite\n  Nonconvex Optimization", "comments": "45 pages, 8 figures, and 2 table", "journal-ref": null, "doi": null, "report-no": "STOR-UNC-Feb14.2019", "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new stochastic first-order algorithmic framework to solve\nstochastic composite nonconvex optimization problems that covers both\nfinite-sum and expectation settings. Our algorithms rely on the SARAH estimator\nintroduced in (Nguyen et al, 2017) and consist of two steps: a proximal\ngradient and an averaging step making them different from existing nonconvex\nproximal-type algorithms. The algorithms only require an average smoothness\nassumption of the nonconvex objective term and additional bounded variance\nassumption if applied to expectation problems. They work with both constant and\nadaptive step-sizes, while allowing single sample and mini-batches. In all\nthese cases, we prove that our algorithms can achieve the best-known complexity\nbounds. One key step of our methods is new constant and adaptive step-sizes\nthat help to achieve desired complexity bounds while improving practical\nperformance. Our constant step-size is much larger than existing methods\nincluding proximal SVRG schemes in the single sample case. We also specify the\nalgorithm to the non-composite case that covers existing state-of-the-arts in\nterms of complexity bounds. Our update also allows one to trade-off between\nstep-sizes and mini-batch sizes to improve performance. We test the proposed\nalgorithms on two composite nonconvex problems and neural networks using\nseveral well-known datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 04:10:12 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 03:28:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Pham", "Nhan H.", ""], ["Nguyen", "Lam M.", ""], ["Phan", "Dzung T.", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "1902.05684", "submitter": "Sarwat Nizamani", "authors": "Sarwat Nizamani, Nasrullah Memon, Azhar Ali Shah, Sehrish Nizamani,\n  Saad Nizamani, Imdad Ali Ismaili", "title": "Crime Analysis using Open Source Information", "comments": null, "journal-ref": "Sindh University Research Journal (Science Series) Vol. 47 (4)\n  677- 682 (2015)", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a method of crime analysis from open source\ninformation. We employed un-supervised methods of data mining to explore the\nfacts regarding the crimes of an area of interest. The analysis is based on\nwell known clustering and association techniques. The results show that the\nproposed method of crime analysis is efficient and gives a broad picture of the\ncrimes of an area to analyst without much effort. The analysis is evaluated\nusing manual approach, which reveals that the results produced by the proposed\napproach are comparable to the manual analysis, while a great amount of time is\nsaved.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:12:45 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nizamani", "Sarwat", ""], ["Memon", "Nasrullah", ""], ["Shah", "Azhar Ali", ""], ["Nizamani", "Sehrish", ""], ["Nizamani", "Saad", ""], ["Ismaili", "Imdad Ali", ""]]}, {"id": "1902.05687", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Jiadong Liang, Yuxuan Song, Lantao Yu, Hongwei Wang,\n  Weinan Zhang, Yong Yu, Zhihua Zhang", "title": "Lipschitz Generative Adversarial Nets", "comments": "Published as a conference paper at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the convergence of generative adversarial networks\n(GANs) from the perspective of the informativeness of the gradient of the\noptimal discriminative function. We show that GANs without restriction on the\ndiscriminative function space commonly suffer from the problem that the\ngradient produced by the discriminator is uninformative to guide the generator.\nBy contrast, Wasserstein GAN (WGAN), where the discriminative function is\nrestricted to 1-Lipschitz, does not suffer from such a gradient\nuninformativeness problem. We further show in the paper that the model with a\ncompact dual form of Wasserstein distance, where the Lipschitz condition is\nrelaxed, may also theoretically suffer from this issue. This implies the\nimportance of Lipschitz condition and motivates us to study the general\nformulation of GANs with Lipschitz constraint, which leads to a new family of\nGANs that we call Lipschitz GANs (LGANs). We show that LGANs guarantee the\nexistence and uniqueness of the optimal discriminative function as well as the\nexistence of a unique Nash equilibrium. We prove that LGANs are generally\ncapable of eliminating the gradient uninformativeness problem. According to our\nempirical analysis, LGANs are more stable and generate consistently higher\nquality samples compared with WGAN.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:19:21 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 11:45:44 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 04:59:42 GMT"}, {"version": "v4", "created": "Mon, 24 Jun 2019 07:55:51 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Zhiming", ""], ["Liang", "Jiadong", ""], ["Song", "Yuxuan", ""], ["Yu", "Lantao", ""], ["Wang", "Hongwei", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1902.05690", "submitter": "Qian Lou", "authors": "Qian Lou and Feng Guo and Lantao Liu and Minje Kim and Lei Jiang", "title": "AutoQ: Automated Kernel-Wise Neural Network Quantization", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is one of the most hardware friendly techniques to\nenable the deployment of convolutional neural networks (CNNs) on low-power\nmobile devices. Recent network quantization techniques quantize each weight\nkernel in a convolutional layer independently for higher inference accuracy,\nsince the weight kernels in a layer exhibit different variances and hence have\ndifferent amounts of redundancy. The quantization bitwidth or bit number (QBN)\ndirectly decides the inference accuracy, latency, energy and hardware overhead.\nTo effectively reduce the redundancy and accelerate CNN inferences, various\nweight kernels should be quantized with different QBNs. However, prior works\nuse only one QBN to quantize each convolutional layer or the entire CNN,\nbecause the design space of searching a QBN for each weight kernel is too\nlarge. The hand-crafted heuristic of the kernel-wise QBN search is so\nsophisticated that domain experts can obtain only sub-optimal results. It is\ndifficult for even deep reinforcement learning (DRL) Deep Deterministic Policy\nGradient (DDPG)-based agents to find a kernel-wise QBN configuration that can\nachieve reasonable inference accuracy. In this paper, we propose a\nhierarchical-DRL-based kernel-wise network quantization technique, AutoQ, to\nautomatically search a QBN for each weight kernel, and choose another QBN for\neach activation layer. Compared to the models quantized by the state-of-the-art\nDRL-based schemes, on average, the same models quantized by AutoQ reduce the\ninference latency by 54.06\\%, and decrease the inference energy consumption by\n50.69\\%, while achieving the same inference accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:28:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 03:46:21 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 22:16:56 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lou", "Qian", ""], ["Guo", "Feng", ""], ["Liu", "Lantao", ""], ["Kim", "Minje", ""], ["Jiang", "Lei", ""]]}, {"id": "1902.05696", "submitter": "Hao Hu", "authors": "Hao Hu, Liqiang Wang and Guo-Jun Qi", "title": "Learning to Adaptively Scale Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in recurrent neural network (RNN) research have\ndemonstrated the superiority of utilizing multiscale structures in learning\ntemporal representations of time series. Currently, most of multiscale RNNs use\nfixed scales, which do not comply with the nature of dynamical temporal\npatterns among sequences. In this paper, we propose Adaptively Scaled Recurrent\nNeural Networks (ASRNN), a simple but efficient way to handle this problem.\nInstead of using predefined scales, ASRNNs are able to learn and adjust scales\nbased on different temporal contexts, making them more flexible in modeling\nmultiscale patterns. Compared with other multiscale RNNs, ASRNNs are bestowed\nupon dynamical scaling capabilities with much simpler structures, and are easy\nto be integrated with various RNN cells. The experiments on multiple sequence\nmodeling tasks indicate ASRNNs can efficiently adapt scales based on different\nsequence contexts and yield better performances than baselines without\ndynamical scaling abilities.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 06:01:24 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Hu", "Hao", ""], ["Wang", "Liqiang", ""], ["Qi", "Guo-Jun", ""]]}, {"id": "1902.05703", "submitter": "James Harrison", "authors": "Sandeep Chinchali, Apoorva Sharma, James Harrison, Amine Elhafsi,\n  Daniel Kang, Evgenya Pergament, Eyal Cidon, Sachin Katti, Marco Pavone", "title": "Network Offloading Policies for Cloud Robotics: a Learning-based\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's robotic systems are increasingly turning to computationally expensive\nmodels such as deep neural networks (DNNs) for tasks like localization,\nperception, planning, and object detection. However, resource-constrained\nrobots, like low-power drones, often have insufficient on-board compute\nresources or power reserves to scalably run the most accurate, state-of-the art\nneural network compute models. Cloud robotics allows mobile robots the benefit\nof offloading compute to centralized servers if they are uncertain locally or\nwant to run more accurate, compute-intensive models. However, cloud robotics\ncomes with a key, often understated cost: communicating with the cloud over\ncongested wireless networks may result in latency or loss of data. In fact,\nsending high data-rate video or LIDAR from multiple robots over congested\nnetworks can lead to prohibitive delay for real-time applications, which we\nmeasure experimentally. In this paper, we formulate a novel Robot Offloading\nProblem --- how and when should robots offload sensing tasks, especially if\nthey are uncertain, to improve accuracy while minimizing the cost of cloud\ncommunication? We formulate offloading as a sequential decision making problem\nfor robots, and propose a solution using deep reinforcement learning. In both\nsimulations and hardware experiments using state-of-the art vision DNNs, our\noffloading strategy improves vision task performance by between 1.3-2.6x of\nbenchmark offloading strategies, allowing robots the potential to significantly\ntranscend their on-board sensing accuracy but with limited cost of cloud\ncommunication.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 06:34:31 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Chinchali", "Sandeep", ""], ["Sharma", "Apoorva", ""], ["Harrison", "James", ""], ["Elhafsi", "Amine", ""], ["Kang", "Daniel", ""], ["Pergament", "Evgenya", ""], ["Cidon", "Eyal", ""], ["Katti", "Sachin", ""], ["Pavone", "Marco", ""]]}, {"id": "1902.05707", "submitter": "Shirin Jalali", "authors": "Shirin Jalali, Carl Nuzman, Iraj Saniee", "title": "Efficient Deep Learning of GMMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a collection of Gaussian mixture models (GMMs) in $R^{n}$ can be\noptimally classified using $O(n)$ neurons in a neural network with two hidden\nlayers (deep neural network), whereas in contrast, a neural network with a\nsingle hidden layer (shallow neural network) would require at least\n$O(\\exp(n))$ neurons or possibly exponentially large coefficients. Given the\nuniversality of the Gaussian distribution in the feature spaces of data, e.g.,\nin speech, image and text, our result sheds light on the observed efficiency of\ndeep neural networks in practical classification problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 07:10:22 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Jalali", "Shirin", ""], ["Nuzman", "Carl", ""], ["Saniee", "Iraj", ""]]}, {"id": "1902.05731", "submitter": "Jingyuan Wang", "authors": "Jingyuan Wang, Kai Feng, Junjie Wu", "title": "SVM-based Deep Stacking Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep network model, with the majority built on neural networks, has been\nproved to be a powerful framework to represent complex data for high\nperformance machine learning. In recent years, more and more studies turn to\nnonneural network approaches to build diverse deep structures, and the Deep\nStacking Network (DSN) model is one of such approaches that uses stacked\neasy-to-learn blocks to build a parameter-training-parallelizable deep network.\nIn this paper, we propose a novel SVM-based Deep Stacking Network (SVM-DSN),\nwhich uses the DSN architecture to organize linear SVM classifiers for deep\nlearning. A BP-like layer tuning scheme is also proposed to ensure holistic and\nlocal optimizations of stacked SVMs simultaneously. Some good math properties\nof SVM, such as the convex optimization, is introduced into the DSN framework\nby our model. From a global view, SVM-DSN can iteratively extract data\nrepresentations layer by layer as a deep neural network but with\nparallelizability, and from a local view, each stacked SVM can converge to its\noptimal solution and obtain the support vectors, which compared with neural\nnetworks could lead to interesting improvements in anti-saturation and\ninterpretability. Experimental results on both image and text data sets\ndemonstrate the excellent performances of SVM-DSN compared with some\ncompetitive benchmark models.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 09:24:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Wang", "Jingyuan", ""], ["Feng", "Kai", ""], ["Wu", "Junjie", ""]]}, {"id": "1902.05748", "submitter": "Isaac Fern\\'andez-Varela", "authors": "Isaac Fern\\'andez-Varela, Elena Hern\\'andez-Pereira, Diego\n  Alvarez-Estevez, Vicente Moret-Bonillo", "title": "A Convolutional Network for Sleep Stages Classification", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sleep stages classification is a crucial task in the context of sleep\nstudies. It involves the simultaneous analysis of multiple signals recorded\nduring sleep. However, it is complex and tedious, and even the trained expert\ncan spend several hours scoring a single night recording. Multiple automatic\nmethods have tried to solve these problems in the past, most of them by\nclassifying a feature vector that is engineered for a specific dataset. In this\nwork, we avoid this bias using a deep learning model that learns relevant\nfeatures without human intervention. Particularly, we propose an ensemble of 5\nconvolutional networks that achieves a kappa index of 0.83 when classifying a\ndataset of 500 sleep recordings.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 10:12:58 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Fern\u00e1ndez-Varela", "Isaac", ""], ["Hern\u00e1ndez-Pereira", "Elena", ""], ["Alvarez-Estevez", "Diego", ""], ["Moret-Bonillo", "Vicente", ""]]}, {"id": "1902.05754", "submitter": "Maxime Vono", "authors": "Maxime Vono and Nicolas Dobigeon and Pierre Chainais", "title": "Asymptotically exact data augmentation: models, properties and\n  algorithms", "comments": "63 pages", "journal-ref": null, "doi": "10.1080/10618600.2020.1826954", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation, by the introduction of auxiliary variables, has become an\nubiquitous technique to improve convergence properties, simplify the\nimplementation or reduce the computational time of inference methods such as\nMarkov chain Monte Carlo ones. Nonetheless, introducing appropriate auxiliary\nvariables while preserving the initial target probability distribution and\noffering a computationally efficient inference cannot be conducted in a\nsystematic way. To deal with such issues, this paper studies a unified\nframework, coined asymptotically exact data augmentation (AXDA), which\nencompasses both well-established and more recent approximate augmented models.\nIn a broader perspective, this paper shows that AXDA models can benefit from\ninteresting statistical properties and yield efficient inference algorithms. In\nnon-asymptotic settings, the quality of the proposed approximation is assessed\nwith several theoretical results. The latter are illustrated on standard\nstatistical problems. Supplementary materials including computer code for this\npaper are available online.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 10:29:53 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 21:11:48 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 19:27:31 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Vono", "Maxime", ""], ["Dobigeon", "Nicolas", ""], ["Chainais", "Pierre", ""]]}, {"id": "1902.05772", "submitter": "Zhengwei Bai", "authors": "Zhengwei Bai, Baigen Cai, Wei Shangguan, Linguo Chai", "title": "Deep Reinforcement Learning Based High-level Driving Behavior\n  Decision-making Model in Heterogeneous Traffic", "comments": "7 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level driving behavior decision-making is an open-challenging problem\nfor connected vehicle technology, especially in heterogeneous traffic\nscenarios. In this paper, a deep reinforcement learning based high-level\ndriving behavior decision-making approach is proposed for connected vehicle in\nheterogeneous traffic situations. The model is composed of three main parts: a\ndata preprocessor that maps hybrid data into a data format called hyper-grid\nmatrix, a two-stream deep neural network that extracts the hidden features, and\na deep reinforcement learning network that learns the optimal policy. Moreover,\na simulation environment, which includes different heterogeneous traffic\nscenarios, is built to train and test the proposed method. The results\ndemonstrate that the model has the capability to learn the optimal high-level\ndriving policy such as driving fast through heterogeneous traffic without\nunnecessary lane changes. Furthermore, two separate models are used to compare\nwith the proposed model, and the performances are analyzed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 11:25:55 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:02:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Bai", "Zhengwei", ""], ["Cai", "Baigen", ""], ["Shangguan", "Wei", ""], ["Chai", "Linguo", ""]]}, {"id": "1902.05781", "submitter": "Efi Kokiopoulou", "authors": "Efi Kokiopoulou, Anja Hauth, Luciano Sbaiz, Andrea Gesmundo, Gabor\n  Bartok, Jesse Berent", "title": "Fast Task-Aware Architecture Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has been shown to hold great promise towards the\nautomation of deep learning. However in spite of its potential, neural\narchitecture search remains quite costly. To this point, we propose a novel\ngradient-based framework for efficient architecture search by sharing\ninformation across several tasks. We start by training many model architectures\non several related (training) tasks. When a new unseen task is presented, the\nframework performs architecture inference in order to quickly identify a good\ncandidate architecture, before any model is trained on the new task. At the\ncore of our framework lies a deep value network that can predict the\nperformance of input architectures on a task by utilizing task meta-features\nand the previous model training experiments performed on related tasks. We\nadopt a continuous parametrization of the model architecture which allows for\nefficient gradient-based optimization. Given a new task, an effective\narchitecture is quickly identified by maximizing the estimated performance with\nrespect to the model architecture parameters with simple gradient ascent. It is\nkey to point out that our goal is to achieve reasonable performance at the\nlowest cost. We provide experimental results showing the effectiveness of the\nframework despite its high computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 12:00:24 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Kokiopoulou", "Efi", ""], ["Hauth", "Anja", ""], ["Sbaiz", "Luciano", ""], ["Gesmundo", "Andrea", ""], ["Bartok", "Gabor", ""], ["Berent", "Jesse", ""]]}, {"id": "1902.05795", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Xiaoyang Tan", "title": "Robust Reinforcement Learning in POMDPs with Incomplete and Noisy\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, the observation data for reinforcement learning with\ncontinuous control is commonly noisy and part of it may be dynamically missing\nover time, which violates the assumption of many current methods developed for\nthis. We addressed the issue within the framework of partially observable\nMarkov Decision Process (POMDP) using a model-based method, in which the\ntransition model is estimated from the incomplete and noisy observations using\na newly proposed surrogate loss function with local approximation, while the\npolicy and value function is learned with the help of belief imputation. For\nthe latter purpose, a generative model is constructed and is seamlessly\nincorporated into the belief updating procedure of POMDP, which enables robust\nexecution even under a significant incompleteness and noise. The effectiveness\nof the proposed method is verified on a collection of benchmark tasks, showing\nthat our approach outperforms several compared methods under various\nchallenging scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 12:47:50 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1902.05804", "submitter": "Dmitry Kobak", "authors": "Dmitry Kobak, George Linderman, Stefan Steinerberger, Yuval Kluger,\n  Philipp Berens", "title": "Heavy-tailed kernels reveal a finer cluster structure in t-SNE\n  visualisations", "comments": null, "journal-ref": "ECML PKDD 2019", "doi": "10.1007/978-3-030-46150-8_8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  T-distributed stochastic neighbour embedding (t-SNE) is a widely used data\nvisualisation technique. It differs from its predecessor SNE by the\nlow-dimensional similarity kernel: the Gaussian kernel was replaced by the\nheavy-tailed Cauchy kernel, solving the \"crowding problem\" of SNE. Here, we\ndevelop an efficient implementation of t-SNE for a $t$-distribution kernel with\nan arbitrary degree of freedom $\\nu$, with $\\nu\\to\\infty$ corresponding to SNE\nand $\\nu=1$ corresponding to the standard t-SNE. Using theoretical analysis and\ntoy examples, we show that $\\nu<1$ can further reduce the crowding problem and\nreveal finer cluster structure that is invisible in standard t-SNE. We further\ndemonstrate the striking effect of heavier-tailed kernels on large real-life\ndata sets such as MNIST, single-cell RNA-sequencing data, and the HathiTrust\nlibrary. We use domain knowledge to confirm that the revealed clusters are\nmeaningful. Overall, we argue that modifying the tail heaviness of the t-SNE\nkernel can yield additional insight into the cluster structure of the data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 13:29:33 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 11:28:50 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kobak", "Dmitry", ""], ["Linderman", "George", ""], ["Steinerberger", "Stefan", ""], ["Kluger", "Yuval", ""], ["Berens", "Philipp", ""]]}, {"id": "1902.05810", "submitter": "Ali Hirsa", "authors": "Ali Hirsa, Tugce Karatas, Amir Oskoui", "title": "Supervised Deep Neural Networks (DNNs) for Pricing/Calibration of\n  Vanilla/Exotic Options Under Various Different Processes", "comments": "17 pages, 28 figures and tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply supervised deep neural networks (DNNs) for pricing and calibration\nof both vanilla and exotic options under both diffusion and pure jump processes\nwith and without stochastic volatility. We train our neural network models\nunder different number of layers, neurons per layer, and various different\nactivation functions in order to find which combinations work better\nempirically. For training, we consider various different loss functions and\noptimization routines. We demonstrate that deep neural networks exponentially\nexpedite option pricing compared to commonly used option pricing methods which\nconsequently make calibration and parameter estimation super fast.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 13:51:45 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Hirsa", "Ali", ""], ["Karatas", "Tugce", ""], ["Oskoui", "Amir", ""]]}, {"id": "1902.05811", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Kenneth Fung, Steffen E. Petersen,\n  Nicholas Ayache", "title": "Unsupervised shape and motion analysis of 3822 cardiac 4D MRIs of UK\n  Biobank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform unsupervised analysis of image-derived shape and motion features\nextracted from 3822 cardiac 4D MRIs of the UK Biobank. First, with a feature\nextraction method previously published based on deep learning models, we\nextract from each case 9 feature values characterizing both the cardiac shape\nand motion. Second, a feature selection is performed to remove highly\ncorrelated feature pairs. Third, clustering is carried out using a Gaussian\nmixture model on the selected features. After analysis, we identify two small\nclusters which probably correspond to two pathological categories. Further\nconfirmation using a trained classification model and dimensionality reduction\ntools is carried out to support this discovery. Moreover, we examine the\ndifferences between the other large clusters and compare our measures with the\nground-truth.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 13:56:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Fung", "Kenneth", ""], ["Petersen", "Steffen E.", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1902.05826", "submitter": "Nathan Kallus", "authors": "Nathan Kallus and Angela Zhou", "title": "The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and\n  the xAUC Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where machine-learned predictive risk scores inform high-stakes decisions,\nsuch as bail and sentencing in criminal justice, fairness has been a serious\nconcern. Recent work has characterized the disparate impact that such risk\nscores can have when used for a binary classification task. This may not\naccount, however, for the more diverse downstream uses of risk scores and their\nnon-binary nature. To better account for this, in this paper, we investigate\nthe fairness of predictive risk scores from the point of view of a bipartite\nranking task, where one seeks to rank positive examples higher than negative\nones. We introduce the xAUC disparity as a metric to assess the disparate\nimpact of risk scores and define it as the difference in the probabilities of\nranking a random positive example from one protected group above a negative one\nfrom another group and vice versa. We provide a decomposition of bipartite\nranking loss into components that involve the discrepancy and components that\ninvolve pure predictive ability within each group. We use xAUC analysis to\naudit predictive risk scores for recidivism prediction, income prediction, and\ncardiac arrest prediction, where it describes disparities that are not evident\nfrom simply comparing within-group predictive performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 14:48:25 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 20:06:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "1902.05839", "submitter": "Janek Gr\\\"ohl", "authors": "Janek Gr\\\"ohl, Thomas Kirchner, Tim Adler, Lena Maier-Hein", "title": "Estimation of blood oxygenation with learned spectral decoloring for\n  quantitative photoacoustic imaging (LSD-qPAI)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main applications of photoacoustic (PA) imaging is the recovery of\nfunctional tissue properties, such as blood oxygenation (sO2). This is\ntypically achieved by linear spectral unmixing of relevant chromophores from\nmultispectral photoacoustic images. Despite the progress that has been made\ntowards quantitative PA imaging (qPAI), most sO2 estimation methods yield poor\nresults in realistic settings. In this work, we tackle the challenge by\nemploying learned spectral decoloring for quantitative photoacoustic imaging\n(LSD-qPAI) to obtain quantitative estimates for blood oxygenation. LSD-qPAI\ncomputes sO2 directly from pixel-wise initial pressure spectra Sp0, which are\nvectors comprised of the initial pressure at the same spatial location over all\nrecorded wavelengths. Initial results suggest that LSD-qPAI is able to obtain\naccurate sO2 estimates directly from multispectral photoacoustic measurements\nin silico and plausible estimates in vivo.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 15:15:11 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Gr\u00f6hl", "Janek", ""], ["Kirchner", "Thomas", ""], ["Adler", "Tim", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "1902.05876", "submitter": "Shay Moran", "authors": "Olivier Bousquet and Daniel Kane and Shay Moran", "title": "The Optimal Approximation Factor in Density Estimation", "comments": "fixed a coupkle of typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following problem: given two arbitrary densities $q_1,q_2$ and a\nsample-access to an unknown target density $p$, find which of the $q_i$'s is\ncloser to $p$ in total variation.\n  A remarkable result due to Yatracos shows that this problem is tractable in\nthe following sense: there exists an algorithm that uses $O(\\epsilon^{-2})$\nsamples from $p$ and outputs~$q_i$ such that with high probability, $TV(q_i,p)\n\\leq 3\\cdot\\mathsf{opt} + \\epsilon$, where $\\mathsf{opt}=\n\\min\\{TV(q_1,p),TV(q_2,p)\\}$. Moreover, this result extends to any finite class\nof densities $\\mathcal{Q}$: there exists an algorithm that outputs the best\ndensity in $\\mathcal{Q}$ up to a multiplicative approximation factor of 3.\n  We complement and extend this result by showing that: (i) the factor 3 can\nnot be improved if one restricts the algorithm to output a density from\n$\\mathcal{Q}$, and (ii) if one allows the algorithm to output arbitrary\ndensities (e.g.\\ a mixture of densities from $\\mathcal{Q}$), then the\napproximation factor can be reduced to 2, which is optimal. In particular this\ndemonstrates an advantage of improper learning over proper in this setup.\n  We develop two approaches to achieve the optimal approximation factor of 2:\nan adaptive one and a static one. Both approaches are based on a geometric\npoint of view of the problem and rely on estimating surrogate metrics to the\ntotal variation. Our sample complexity bounds exploit techniques from {\\it\nAdaptive Data Analysis}.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 23:15:26 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 05:06:29 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 01:05:53 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bousquet", "Olivier", ""], ["Kane", "Daniel", ""], ["Moran", "Shay", ""]]}, {"id": "1902.05888", "submitter": "Vincent Dutordoir", "authors": "Vincent Dutordoir, Mark van der Wilk, Artem Artemev and James Hensman", "title": "Bayesian Image Classification with Deep Convolutional Gaussian Processes", "comments": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020, PMLR: Volume 108", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decision-making systems, it is important to have classifiers that have\ncalibrated uncertainties, with an optimisation objective that can be used for\nautomated model selection and training. Gaussian processes (GPs) provide\nuncertainty estimates and a marginal likelihood objective, but their weak\ninductive biases lead to inferior accuracy. This has limited their\napplicability in certain tasks (e.g. image classification). We propose a\ntranslation-insensitive convolutional kernel, which relaxes the translation\ninvariance constraint imposed by previous convolutional GPs. We show how we can\nuse the marginal likelihood to learn the degree of insensitivity. We also\nreformulate GP image-to-image convolutional mappings as multi-output GPs,\nleading to deep convolutional GPs. We show experimentally that our new kernel\nimproves performance in both single-layer and deep models. We also demonstrate\nthat our fully Bayesian approach improves on dropout-based Bayesian deep\nlearning methods in terms of uncertainty and marginal likelihood estimates.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 17:07:12 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 15:04:12 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Dutordoir", "Vincent", ""], ["van der Wilk", "Mark", ""], ["Artemev", "Artem", ""], ["Hensman", "James", ""]]}, {"id": "1902.05946", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani, Marcella S. R. Martins, Myriam R. B. S. Delgado,\n  Inkyung Sung, Ricardo L\\\"uders, Markus Wagner", "title": "On resampling vs. adjusting probabilistic graphical models in estimation\n  of distribution algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian Optimisation Algorithm (BOA) is an Estimation of Distribution\nAlgorithm (EDA) that uses a Bayesian network as probabilistic graphical model\n(PGM). Determining the optimal Bayesian network structure given a solution\nsample is an NP-hard problem. This step should be completed at each iteration\nof BOA, resulting in a very time-consuming process. For this reason most\nimplementations use greedy estimation algorithms such as K2. However, we show\nin this paper that significant changes in PGM structure do not occur so\nfrequently, and can be particularly sparse at the end of evolution. A\nstatistical study of BOA is thus presented to characterise a pattern of PGM\nadjustments that can be used as a guide to reduce the frequency of PGM updates\nduring the evolutionary process. This is accomplished by proposing a new\nBOA-based optimisation approach (FBOA) whose PGM is not updated at each\niteration. This new approach avoids the computational burden usually found in\nthe standard BOA. The results compare the performances of both algorithms on an\nNK-landscape optimisation problem using the correlation between the ruggedness\nand the expected runtime over enumerated instances. The experiments show that\nFBOA presents competitive results while significantly saving computational\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:59:20 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Yafrani", "Mohamed El", ""], ["Martins", "Marcella S. R.", ""], ["Delgado", "Myriam R. B. S.", ""], ["Sung", "Inkyung", ""], ["L\u00fcders", "Ricardo", ""], ["Wagner", "Markus", ""]]}, {"id": "1902.05947", "submitter": "Fereshteh Sadeghi", "authors": "Fereshteh Sadeghi", "title": "DIViS: Domain Invariant Visual Servoing for Collision-Free Goal Reaching", "comments": "Supplementary videos: https://fsadeghi.github.io/DIViS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots should understand both semantics and physics to be functional in the\nreal world. While robot platforms provide means for interacting with the\nphysical world they cannot autonomously acquire object-level semantics without\nneeding human. In this paper, we investigate how to minimize human effort and\nintervention to teach robots perform real world tasks that incorporate\nsemantics. We study this question in the context of visual servoing of mobile\nrobots and propose DIViS, a Domain Invariant policy learning approach for\ncollision free Visual Servoing. DIViS incorporates high level semantics from\npreviously collected static human-labeled datasets and learns collision free\nservoing entirely in simulation and without any real robot data. However, DIViS\ncan directly be deployed on a real robot and is capable of servoing to the\nuser-specified object categories while avoiding collisions in the real world.\nDIViS is not constrained to be queried by the final view of goal but rather is\nrobust to servo to image goals taken from initial robot view with high\nocclusions without this impairing its ability to maintain a collision free\npath. We show the generalization capability of DIViS on real mobile robots in\nmore than 90 real world test scenarios with various unseen object goals in\nunstructured environments. DIViS is compared to prior approaches via real world\nexperiments and rigorous tests in simulation. For supplementary videos, see:\n\\href{https://fsadeghi.github.io/DIViS}{https://fsadeghi.github.io/DIViS}\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:57:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Sadeghi", "Fereshteh", ""]]}, {"id": "1902.05965", "submitter": "Xinyue Zhang", "authors": "Xinyue Zhang, Yanfang Wang, Wei Zhang, Yueqiu Sun, Siyu He, Gabriella\n  Contardo, Francisco Villaescusa-Navarro, Shirley Ho", "title": "From Dark Matter to Galaxies with Convolutional Networks", "comments": "10 pages, 11 figures, submitted for KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cosmological surveys aim at answering fundamental questions about our\nUniverse, including the nature of dark matter or the reason of unexpected\naccelerated expansion of the Universe. In order to answer these questions, two\nimportant ingredients are needed: 1) data from observations and 2) a\ntheoretical model that allows fast comparison between observation and theory.\nMost of the cosmological surveys observe galaxies, which are very difficult to\nmodel theoretically due to the complicated physics involved in their formation\nand evolution; modeling realistic galaxies over cosmological volumes requires\nrunning computationally expensive hydrodynamic simulations that can cost\nmillions of CPU hours. In this paper, we propose to use deep learning to\nestablish a mapping between the 3D galaxy distribution in hydrodynamic\nsimulations and its underlying dark matter distribution. One of the major\nchallenges in this pursuit is the very high sparsity in the predicted galaxy\ndistribution. To this end, we develop a two-phase convolutional neural network\narchitecture to generate fast galaxy catalogues, and compare our results\nagainst a standard cosmological technique. We find that our proposed approach\neither outperforms or is competitive with traditional cosmological techniques.\nCompared to the common methods used in cosmology, our approach also provides a\nnice trade-off between time-consumption (comparable to fastest benchmark in the\nliterature) and the quality and accuracy of the predicted simulation. In\ncombination with current and upcoming data from cosmological observations, our\nmethod has the potential to answer fundamental questions about our Universe\nwith the highest accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 19:01:20 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 02:33:23 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Zhang", "Xinyue", ""], ["Wang", "Yanfang", ""], ["Zhang", "Wei", ""], ["Sun", "Yueqiu", ""], ["He", "Siyu", ""], ["Contardo", "Gabriella", ""], ["Villaescusa-Navarro", "Francisco", ""], ["Ho", "Shirley", ""]]}, {"id": "1902.05967", "submitter": "Xin Wang", "authors": "Hesham Mostafa, Xin Wang", "title": "Parameter Efficient Training of Deep Convolutional Neural Networks by\n  Dynamic Sparse Reparameterization", "comments": "Proceedings of the 36th International Conference on MachineLearning,\n  Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks are typically highly overparameterized. Pruning\ntechniques are able to remove a significant fraction of network parameters with\nlittle loss in accuracy. Recently, techniques based on dynamic reallocation of\nnon-zero parameters have emerged, allowing direct training of sparse networks\nwithout having to pre-train a large dense model. Here we present a novel\ndynamic sparse reparameterization method that addresses the limitations of\nprevious techniques such as high computational cost and the need for manual\nconfiguration of the number of free parameters allocated to each layer. We\nevaluate the performance of dynamic reallocation methods in training deep\nconvolutional networks and show that our method outperforms previous static and\ndynamic reparameterization methods, yielding the best accuracy for a fixed\nparameter budget, on par with accuracies obtained by iteratively pruning a\npre-trained dense model. We further investigated the mechanisms underlying the\nsuperior generalization performance of the resultant sparse networks. We found\nthat neither the structure, nor the initialization of the non-zero parameters\nwere sufficient to explain the superior performance. Rather, effective learning\ncrucially depended on the continuous exploration of the sparse network\nstructure space during training. Our work suggests that exploring structural\ndegrees of freedom during training is more effective than adding extra\nparameters to the network.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 19:11:55 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 21:50:24 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 00:02:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mostafa", "Hesham", ""], ["Wang", "Xin", ""]]}, {"id": "1902.05974", "submitter": "Simos Gerasimou", "authors": "Hasan Ferit Eniser, Simos Gerasimou, Alper Sen", "title": "DeepFault: Fault Localization for Deep Neural Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are increasingly deployed in safety-critical\napplications including autonomous vehicles and medical diagnostics. To reduce\nthe residual risk for unexpected DNN behaviour and provide evidence for their\ntrustworthy operation, DNNs should be thoroughly tested. The DeepFault whitebox\nDNN testing approach presented in our paper addresses this challenge by\nemploying suspiciousness measures inspired by fault localization to establish\nthe hit spectrum of neurons and identify suspicious neurons whose weights have\nnot been calibrated correctly and thus are considered responsible for\ninadequate DNN performance. DeepFault also uses a suspiciousness-guided\nalgorithm to synthesize new inputs, from correctly classified inputs, that\nincrease the activation values of suspicious neurons. Our empirical evaluation\non several DNN instances trained on MNIST and CIFAR-10 datasets shows that\nDeepFault is effective in identifying suspicious neurons. Also, the inputs\nsynthesized by DeepFault closely resemble the original inputs, exercise the\nidentified suspicious neurons and are highly adversarial.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 19:42:45 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Eniser", "Hasan Ferit", ""], ["Gerasimou", "Simos", ""], ["Sen", "Alper", ""]]}, {"id": "1902.05981", "submitter": "Ehsan Kazemi", "authors": "Marko Mitrovic and Ehsan Kazemi and Moran Feldman and Andreas Krause\n  and Amin Karbasi", "title": "Adaptive Sequence Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, one needs to interactively select a\nsequence of items (e.g., recommending movies based on a user's feedback) or\nmake sequential decisions in a certain order (e.g., guiding an agent through a\nseries of states). Not only do sequences already pose a dauntingly large search\nspace, but we must also take into account past observations, as well as the\nuncertainty of future outcomes. Without further structure, finding an optimal\nsequence is notoriously challenging, if not completely intractable. In this\npaper, we view the problem of adaptive and sequential decision making through\nthe lens of submodularity and propose an adaptive greedy policy with strong\ntheoretical guarantees. Additionally, to demonstrate the practical utility of\nour results, we run experiments on Amazon product recommendation and Wikipedia\nlink prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:37:14 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 16:04:03 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Mitrovic", "Marko", ""], ["Kazemi", "Ehsan", ""], ["Feldman", "Moran", ""], ["Krause", "Andreas", ""], ["Karbasi", "Amin", ""]]}, {"id": "1902.05983", "submitter": "Ravi Mangal", "authors": "Ravi Mangal, Aditya V. Nori, Alessandro Orso", "title": "Robustness of Neural Networks: A Probabilistic and Practical Approach", "comments": "Accepted for publication at ICSE-NIER 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are becoming increasingly prevalent in software, and it is\ntherefore important to be able to verify their behavior. Because verifying the\ncorrectness of neural networks is extremely challenging, it is common to focus\non the verification of other properties of these systems. One important\nproperty, in particular, is robustness. Most existing definitions of\nrobustness, however, focus on the worst-case scenario where the inputs are\nadversarial. Such notions of robustness are too strong, and unlikely to be\nsatisfied by-and verifiable for-practical neural networks. Observing that\nreal-world inputs to neural networks are drawn from non-adversarial probability\ndistributions, we propose a novel notion of robustness: probabilistic\nrobustness, which requires the neural network to be robust with at least $(1 -\n\\epsilon)$ probability with respect to the input distribution. This\nprobabilistic approach is practical and provides a principled way of estimating\nthe robustness of a neural network. We also present an algorithm, based on\nabstract interpretation and importance sampling, for checking whether a neural\nnetwork is probabilistically robust. Our algorithm uses abstract interpretation\nto approximate the behavior of a neural network and compute an\noverapproximation of the input regions that violate robustness. It then uses\nimportance sampling to counter the effect of such overapproximation and compute\nan accurate estimate of the probability that the neural network violates the\nrobustness property.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:44:17 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mangal", "Ravi", ""], ["Nori", "Aditya V.", ""], ["Orso", "Alessandro", ""]]}, {"id": "1902.05991", "submitter": "Brandon Foggo", "authors": "Brandon Foggo, Nanpeng Yu, Jie Shi, Yuanqi Gao", "title": "Information Losses in Neural Classifiers from Sampling", "comments": "To be published in IEEE TNNLS", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2952029", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the subject of information losses arising from the\nfinite datasets used in the training of neural classifiers. It proves a\nrelationship between such losses as the product of the expected total variation\nof the estimated neural model with the information about the feature space\ncontained in the hidden representation of that model. It then bounds this\nexpected total variation as a function of the size of randomly sampled datasets\nin a fairly general setting, and without bringing in any additional dependence\non model complexity. It ultimately obtains bounds on information losses that\nare less sensitive to input compression and in general much smaller than\nexisting bounds. The paper then uses these bounds to explain some recent\nexperimental findings of information compression in neural networks which\ncannot be explained by previous work. Finally, the paper shows that not only\nare these bounds much smaller than existing ones, but that they also correspond\nwell with experiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 21:34:39 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 22:15:01 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 20:42:05 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Foggo", "Brandon", ""], ["Yu", "Nanpeng", ""], ["Shi", "Jie", ""], ["Gao", "Yuanqi", ""]]}, {"id": "1902.06007", "submitter": "Andrew Silva", "authors": "Andrew Silva, Matthew Gombolay", "title": "Neural-encoding Human Experts' Domain Knowledge to Warm Start\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successful in a variety of tasks, such\nas game playing and robotic manipulation. However, attempting to learn\n\\textit{tabula rasa} disregards the logical structure of many domains as well\nas the wealth of readily available knowledge from domain experts that could\nhelp \"warm start\" the learning process. We present a novel reinforcement\nlearning technique that allows for intelligent initialization of a neural\nnetwork weights and architecture. Our approach permits the encoding domain\nknowledge directly into a neural decision tree, and improves upon that\nknowledge with policy gradient updates. We empirically validate our approach on\ntwo OpenAI Gym tasks and two modified StarCraft 2 tasks, showing that our novel\narchitecture outperforms multilayer-perceptron and recurrent architectures. Our\nknowledge-based framework finds superior policies compared to imitation\nlearning-based and prior knowledge-based approaches. Importantly, we\ndemonstrate that our approach can be used by untrained humans to initially\nprovide >80% increase in expected reward relative to baselines prior to\ntraining (p < 0.001), which results in a >60% increase in expected reward after\npolicy optimization (p = 0.011).\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 23:28:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:23:30 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:47:06 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 22:17:29 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Silva", "Andrew", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1902.06015", "submitter": "Song Mei", "authors": "Song Mei, Theodor Misiakiewicz, Andrea Montanari", "title": "Mean-field theory of two-layers neural networks: dimension-free bounds\n  and kernel limit", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning two layer neural networks using stochastic gradient\ndescent. The mean-field description of this learning dynamics approximates the\nevolution of the network weights by an evolution in the space of probability\ndistributions in $R^D$ (where $D$ is the number of parameters associated to\neach neuron). This evolution can be defined through a partial differential\nequation or, equivalently, as the gradient flow in the Wasserstein space of\nprobability distributions. Earlier work shows that (under some regularity\nassumptions), the mean field description is accurate as soon as the number of\nhidden units is much larger than the dimension $D$. In this paper we establish\nstronger and more general approximation guarantees. First of all, we show that\nthe number of hidden units only needs to be larger than a quantity dependent on\nthe regularity properties of the data, and independent of the dimensions. Next,\nwe generalize this analysis to the case of unbounded activation functions,\nwhich was not covered by earlier bounds. We extend our results to noisy\nstochastic gradient descent.\n  Finally, we show that kernel ridge regression can be recovered as a special\nlimit of the mean field analysis.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 00:01:01 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mei", "Song", ""], ["Misiakiewicz", "Theodor", ""], ["Montanari", "Andrea", ""]]}, {"id": "1902.06021", "submitter": "Enguerrand Horel", "authors": "Enguerrand Horel, Kay Giesecke", "title": "Significance Tests for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a pivotal test to assess the statistical significance of the\nfeature variables in a single-layer feedforward neural network regression\nmodel. We propose a gradient-based test statistic and study its asymptotics\nusing nonparametric techniques. Under technical conditions, the limiting\ndistribution is given by a mixture of chi-square distributions. The tests\nenable one to discern the impact of individual variables on the prediction of a\nneural network. The test statistic can be used to rank variables according to\ntheir influence. Simulation results illustrate the computational efficiency and\nthe performance of the test. An empirical application to house price valuation\nhighlights the behavior of the test using actual data.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:28:05 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:23:02 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 21:10:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Horel", "Enguerrand", ""], ["Giesecke", "Kay", ""]]}, {"id": "1902.06034", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, John Lafferty", "title": "TopicEq: A Joint Topic and Mathematical Equation Model for Scientific\n  Texts", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific documents rely on both mathematics and text to communicate ideas.\nInspired by the topical correspondence between mathematical equations and word\ncontexts observed in scientific texts, we propose a novel topic model that\njointly generates mathematical equations and their surrounding text (TopicEq).\nUsing an extension of the correlated topic model, the context is generated from\na mixture of latent topics, and the equation is generated by an RNN that\ndepends on the latent topic activations. To experiment with this model, we\ncreate a corpus of 400K equation-context pairs extracted from a range of\nscientific articles from arXiv, and fit the model using a variational\nautoencoder approach. Experimental results show that this joint model\nsignificantly outperforms existing topic models and equation models for\nscientific texts. Moreover, we qualitatively show that the model effectively\ncaptures the relationship between topics and mathematics, enabling novel\napplications such as topic-aware equation generation, equation topic inference,\nand topic-aware alignment of mathematical symbols and words.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 03:39:51 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:55:23 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 21:24:05 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Lafferty", "John", ""]]}, {"id": "1902.06044", "submitter": "Silvija Kokalj-Filipovic", "authors": "Silvija Kokalj-Filipovic, Rob Miller", "title": "Adversarial Examples in RF Deep Learning: Detection of the Attack and\n  its Physical Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While research on adversarial examples in machine learning for images has\nbeen prolific, similar attacks on deep learning (DL) for radio frequency (RF)\nsignals and their mitigation strategies are scarcely addressed in the published\nwork, with only one recent publication in the RF domain [1]. RF adversarial\nexamples (AdExs) can cause drastic, targeted misclassification results mostly\nin spectrum sensing/ survey applications (e.g. BPSK mistaken for 8-PSK) with\nminimal waveform perturbation. It is not clear if the RF AdExs maintain their\neffects in the physical world, i.e., when AdExs are delivered over-the-air\n(OTA). Our research on deep learning AdExs and proposed defense mechanisms are\nRF-centric, and incorporate physical world, OTA effects. We here present\ndefense mechanisms based on statistical tests. One test to detect AdExs\nutilizes Peak-to- Average-Power-Ratio (PAPR) of the DL data points delivered\nOTA, while another statistical test uses the Softmax outputs of the DL\nclassifier, which corresponds to the probabilities the classifier assigns to\neach of the trained classes. The former test leverages the RF nature of the\ndata, and the latter is universally applicable to AdExs regardless of their\norigin. Both solutions are shown as viable mitigation methods to subvert\nadversarial attacks against communications and radar sensing systems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 05:12:38 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kokalj-Filipovic", "Silvija", ""], ["Miller", "Rob", ""]]}, {"id": "1902.06050", "submitter": "Khuong Vo", "authors": "Khuong Vo, Tri Nguyen, Dang Pham, Mao Nguyen, Minh Truong, Trung Mai,\n  Tho Quan", "title": "Combination of Domain Knowledge and Deep Learning for Sentiment Analysis\n  of Short and Informal Messages on Social Media", "comments": "A Preprint of an article accepted for publication by Inderscience in\n  IJCVR on September 2018", "journal-ref": "International Journal of Computational Vision and Robotics, 2019\n  Vol.9 No.5, pp.458 - 485", "doi": "10.1504/IJCVR.2019.102286", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has been emerging recently as one of the major natural\nlanguage processing (NLP) tasks in many applications. Especially, as social\nmedia channels (e.g. social networks or forums) have become significant sources\nfor brands to observe user opinions about their products, this task is thus\nincreasingly crucial. However, when applied with real data obtained from social\nmedia, we notice that there is a high volume of short and informal messages\nposted by users on those channels. This kind of data makes the existing works\nsuffer from many difficulties to handle, especially ones using deep learning\napproaches. In this paper, we propose an approach to handle this problem. This\nwork is extended from our previous work, in which we proposed to combine the\ntypical deep learning technique of Convolutional Neural Networks with domain\nknowledge. The combination is used for acquiring additional training data\naugmentation and a more reasonable loss function. In this work, we further\nimprove our architecture by various substantial enhancements, including\nnegation-based data augmentation, transfer learning for word embeddings, the\ncombination of word-level embeddings and character-level embeddings, and using\nmultitask learning technique for attaching domain knowledge rules in the\nlearning process. Those enhancements, specifically aiming to handle short and\ninformal messages, help us to enjoy significant improvement in performance once\nexperimenting on real datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 06:03:57 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 07:53:04 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Vo", "Khuong", ""], ["Nguyen", "Tri", ""], ["Pham", "Dang", ""], ["Nguyen", "Mao", ""], ["Truong", "Minh", ""], ["Mai", "Trung", ""], ["Quan", "Tho", ""]]}, {"id": "1902.06066", "submitter": "Varshaneya V", "authors": "Varshaneya V, Balasubramanian S and Darshan Gera", "title": "RES-SE-NET: Boosting Performance of Resnets by Enhancing\n  Bridge-connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One of the ways to train deep neural networks effectively is to use residual\nconnections. Residual connections can be classified as being either identity\nconnections or bridge-connections with a reshaping convolution. Empirical\nobservations on CIFAR-10 and CIFAR-100 datasets using a baseline Resnet model,\nwith bridge-connections removed, have shown a significant reduction in\naccuracy. This reduction is due to lack of contribution, in the form of feature\nmaps, by the bridge-connections. Hence bridge-connections are vital for Resnet.\nHowever, all feature maps in the bridge-connections are considered to be\nequally important. In this work, an upgraded architecture \"Res-SE-Net\" is\nproposed to further strengthen the contribution from the bridge-connections by\nquantifying the importance of each feature map and weighting them accordingly\nusing Squeeze-and-Excitation (SE) block. It is demonstrated that Res-SE-Net\ngeneralizes much better than Resnet and SE-Resnet on the benchmark CIFAR-10 and\nCIFAR-100 datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 08:25:16 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["V", "Varshaneya", ""], ["S", "Balasubramanian", ""], ["Gera", "Darshan", ""]]}, {"id": "1902.06075", "submitter": "James Goodman", "authors": "James Goodman", "title": "Re-determinizing Information Set Monte Carlo Tree Search in Hanabi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report documents the winner of the Computational Intelligence\nin Games(CIG) 2018 Hanabi competition. We introduce Re-determinizing IS-MCTS, a\nnovel extension of Information Set Monte Carlo Tree Search (IS-MCTS) that\nprevents a leakage of hidden information into opponent models that can occur in\nIS-MCTS, and is particularly severe in Hanabi. Re-determinizing IS-MCTS scores\nhigher in Hanabi for 2-4 players than previously published work at the time of\nthe competition. Given the 40ms competition time limit per move we use a\nlearned evaluation function to estimate leaf node values and avoid full\nsimulations during MCTS. For the Mixed track competition, in which the identity\nof the other players is unknown, a simple Bayesian opponent model is used that\nis updated as each game proceeds.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 09:42:41 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 18:19:19 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Goodman", "James", ""]]}, {"id": "1902.06094", "submitter": "Juan-Pablo Ortega", "authors": "Lyudmila Grigoryeva and Juan-Pablo Ortega", "title": "Differentiable reservoir computing", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much effort has been devoted in the last two decades to characterize the\nsituations in which a reservoir computing system exhibits the so-called echo\nstate (ESP) and fading memory (FMP) properties. These important features\namount, in mathematical terms, to the existence and continuity of global\nreservoir system solutions. That research is complemented in this paper with\nthe characterization of the differentiability of reservoir filters for very\ngeneral classes of discrete-time deterministic inputs. This constitutes a novel\nstrong contribution to the long line of research on the ESP and the FMP and, in\nparticular, links to existing research on the input-dependence of the ESP.\nDifferentiability has been shown in the literature to be a key feature in the\nlearning of attractors of chaotic dynamical systems. A Volterra-type series\nrepresentation for reservoir filters with semi-infinite discrete-time inputs is\nconstructed in the analytic case using Taylor's theorem and corresponding\napproximation bounds are provided. Finally, it is shown as a corollary of these\nresults that any fading memory filter can be uniformly approximated by a finite\nVolterra series with finite memory.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 11:47:04 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 12:14:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "1902.06101", "submitter": "Hanshen Xiao", "authors": "Hanshen Xiao, Yu Ye, Srinivas Devadas", "title": "Local Differential Privacy in Decentralized Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns with sensitive data are receiving increasing attention. In\nthis paper, we study local differential privacy (LDP) in interactive\ndecentralized optimization. By constructing random local aggregators, we\npropose a framework to amplify LDP by a constant. We take Alternating Direction\nMethod of Multipliers (ADMM), and decentralized gradient descent as two\nconcrete examples, where experiments support our theory. In an asymptotic view,\nwe address the following question: Under LDP, is it possible to design a\ndistributed private minimizer for arbitrary closed convex constraints with\nutility loss not explicitly dependent on dimensionality? As an affiliated\nresult, we also show that with merely linear secret sharing, information\ntheoretic privacy is achievable for bounded colluding agents.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 13:41:35 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 19:08:30 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Xiao", "Hanshen", ""], ["Ye", "Yu", ""], ["Devadas", "Srinivas", ""]]}, {"id": "1902.06125", "submitter": "Joseph Salmon", "authors": "Alain Rakotomamonjy (LITIS), Gilles Gasso (LITIS), Joseph Salmon\n  (IMAG, Univ. Montpellier)", "title": "Screening Rules for Lasso with Non-Convex Sparse Regularizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging on the convexity of the Lasso problem , screening rules help in\naccelerating solvers by discarding irrelevant variables, during the\noptimization process. However, because they provide better theoretical\nguarantees in identifying relevant variables, several non-convex regularizers\nfor the Lasso have been proposed in the literature. This work is the first that\nintroduces a screening rule strategy into a non-convex Lasso solver. The\napproach we propose is based on a iterative majorization-minimization (MM)\nstrategy that includes a screening rule in the inner solver and a condition for\npropagating screened variables between iterations of MM. In addition to improve\nefficiency of solvers, we also provide guarantees that the inner solver is able\nto identify the zeros components of its critical point in finite time. Our\nexperimental analysis illustrates the significant computational gain brought by\nthe new screening rule compared to classical coordinate-descent or proximal\ngradient descent methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 17:08:56 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 13:01:17 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Rakotomamonjy", "Alain", "", "LITIS"], ["Gasso", "Gilles", "", "LITIS"], ["Salmon", "Joseph", "", "IMAG, Univ. Montpellier"]]}, {"id": "1902.06127", "submitter": "Suvadeep Hajra", "authors": "Suvadeep Hajra", "title": "Making Convex Loss Functions Robust to Outliers using $e$-Exponentiated\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel {\\em $e$-exponentiated} transformation, $0\n\\le e<1$, for loss functions. When the transformation is applied to a convex\nloss function, the transformed loss function become more robust to outliers.\nUsing a novel generalization error bound, we have theoretically shown that the\ntransformed loss function has a tighter bound for datasets corrupted by\noutliers. Our empirical observation shows that the accuracy obtained using the\ntransformed loss function can be significantly better than the same obtained\nusing the original loss function and comparable to that obtained by some other\nstate of the art methods in the presence of label noise.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 17:16:58 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 13:13:09 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Hajra", "Suvadeep", ""]]}, {"id": "1902.06155", "submitter": "Jos van de Wolfshaar", "authors": "Jos van de Wolfshaar, Andrzej Pronobis", "title": "Deep Generalized Convolutional Sum-Product Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-Product Networks (SPNs) are hierarchical, graphical models that combine\nbenefits of deep learning and probabilistic modeling. SPNs offer unique\nadvantages to applications demanding exact probabilistic inference over\nhigh-dimensional, noisy inputs. Yet, compared to convolutional neural nets,\nthey struggle with capturing complex spatial relationships in image data. To\nalleviate this issue, we introduce Deep Generalized Convolutional Sum-Product\nNetworks (DGC-SPNs), which encode spatial features in a way similar to CNNs,\nwhile preserving the validity of the probabilistic SPN model. As opposed to\nexisting SPN-based image representations, DGC-SPNs allow for overlapping\nconvolution patches through a novel parameterization of dilations and strides,\nresulting in significantly improved feature coverage and feature resolution.\nDGC-SPNs substantially outperform other SPN architectures across several visual\ndatasets and for both generative and discriminative tasks, including image\ninpainting and classification. These contributions are reinforced by the first\nsimple, scalable, and GPU-optimized implementation of SPNs, integrated with the\nwidely used Keras/TensorFlow framework. The resulting model is fully\nprobabilistic and versatile, yet efficient and straightforward to apply in\npractical applications in place of traditional deep nets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 20:55:53 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 08:21:21 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 21:34:50 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 19:09:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["van de Wolfshaar", "Jos", ""], ["Pronobis", "Andrzej", ""]]}, {"id": "1902.06156", "submitter": "Moran Baruch", "authors": "Moran Baruch, Gilad Baruch, Yoav Goldberg", "title": "A Little Is Enough: Circumventing Defenses For Distributed Learning", "comments": null, "journal-ref": "https://papers.nips.cc/paper/2019/hash/ec1c59141046cd1866bbbcdfb6ae31d4-Abstract.html", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning is central for large-scale training of deep-learning\nmodels. However, they are exposed to a security threat in which Byzantine\nparticipants can interrupt or control the learning process. Previous attack\nmodels and their corresponding defenses assume that the rogue participants are\n(a) omniscient (know the data of all other participants), and (b) introduce\nlarge change to the parameters. We show that small but well-crafted changes are\nsufficient, leading to a novel non-omniscient attack on distributed learning\nthat go undetected by all existing defenses. We demonstrate our attack method\nworks not only for preventing convergence but also for repurposing of the model\nbehavior (backdooring). We show that 20% of corrupt workers are sufficient to\ndegrade a CIFAR10 model accuracy by 50%, as well as to introduce backdoors into\nMNIST and CIFAR10 models without hurting their accuracy\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 21:05:29 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Baruch", "Moran", ""], ["Baruch", "Gilad", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1902.06158", "submitter": "Feihu Huang", "authors": "Feihu Huang, Bin Gu, Zhouyuan Huo, Songcan Chen and Heng Huang", "title": "Faster Gradient-Free Proximal Stochastic Methods for Nonconvex Nonsmooth\n  Optimization", "comments": "AAAI-2019, 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal gradient method has been playing an important role to solve many\nmachine learning tasks, especially for the nonsmooth problems. However, in some\nmachine learning problems such as the bandit model and the black-box learning\nproblem, proximal gradient method could fail because the explicit gradients of\nthese problems are difficult or infeasible to obtain. The gradient-free\n(zeroth-order) method can address these problems because only the objective\nfunction values are required in the optimization. Recently, the first\nzeroth-order proximal stochastic algorithm was proposed to solve the nonconvex\nnonsmooth problems. However, its convergence rate is $O(\\frac{1}{\\sqrt{T}})$\nfor the nonconvex problems, which is significantly slower than the best\nconvergence rate $O(\\frac{1}{T})$ of the zeroth-order stochastic algorithm,\nwhere $T$ is the iteration number. To fill this gap, in the paper, we propose a\nclass of faster zeroth-order proximal stochastic methods with the variance\nreduction techniques of SVRG and SAGA, which are denoted as ZO-ProxSVRG and\nZO-ProxSAGA, respectively. In theoretical analysis, we address the main\nchallenge that an unbiased estimate of the true gradient does not hold in the\nzeroth-order case, which was required in previous theoretical analysis of both\nSVRG and SAGA. Moreover, we prove that both ZO-ProxSVRG and ZO-ProxSAGA\nalgorithms have $O(\\frac{1}{T})$ convergence rates. Finally, the experimental\nresults verify that our algorithms have a faster convergence rate than the\nexisting zeroth-order proximal stochastic algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 21:09:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Huang", "Feihu", ""], ["Gu", "Bin", ""], ["Huo", "Zhouyuan", ""], ["Chen", "Songcan", ""], ["Huang", "Heng", ""]]}, {"id": "1902.06160", "submitter": "Shuyu Lin", "authors": "Shuyu Lin, Ronald Clark, Robert Birke, Niki Trigoni, Stephen Roberts", "title": "WiSE-ALE: Wide Sample Estimator for Approximate Latent Embedding", "comments": "18 pages, appendix included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-encoders (VAEs) have been very successful as methods for\nforming compressed latent representations of complex, often high-dimensional,\ndata. In this paper, we derive an alternative variational lower bound from the\none common in VAEs, which aims to minimize aggregate information loss. Using\nour lower bound as the objective function for an auto-encoder enables us to\nplace a prior on the bulk statistics, corresponding to an aggregate posterior\nfor the entire dataset, as opposed to a single sample posterior as in the\noriginal VAE. This alternative form of prior constraint allows individual\nposteriors more flexibility to preserve necessary information for good\nreconstruction quality. We further derive an analytic approximation to our\nlower bound, leading to an efficient learning algorithm - WiSE-ALE. Through\nvarious examples, we demonstrate that WiSE-ALE can reach excellent\nreconstruction quality in comparison to other state-of-the-art VAE models,\nwhile still retaining the ability to learn a smooth, compact representation.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 21:20:48 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 14:40:19 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 18:24:59 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Lin", "Shuyu", ""], ["Clark", "Ronald", ""], ["Birke", "Robert", ""], ["Trigoni", "Niki", ""], ["Roberts", "Stephen", ""]]}, {"id": "1902.06199", "submitter": "Sentao Miao", "authors": "Sentao Miao, Xi Chen, Xiuli Chao, Jiaxi Liu, Yidong Zhang", "title": "Context-Based Dynamic Pricing with Online Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a context-based dynamic pricing problem of online products which\nhave low sales. Sales data from Alibaba, a major global online retailer,\nillustrate the prevalence of low-sale products. For these products, existing\nsingle-product dynamic pricing algorithms do not work well due to insufficient\ndata samples. To address this challenge, we propose pricing policies that\nconcurrently perform clustering over products and set individual pricing\ndecisions on the fly. By clustering data and identifying products that have\nsimilar demand patterns, we utilize sales data from products within the same\ncluster to improve demand estimation and allow for better pricing decisions. We\nevaluate the algorithms using the regret, and the result shows that when\nproduct demand functions come from multiple clusters, our algorithms\nsignificantly outperform traditional single-product pricing policies. Numerical\nexperiments using a real dataset from Alibaba demonstrate that the proposed\npolicies, compared with several benchmark policies, increase the revenue. The\nresults show that online clustering is an effective approach to tackling\ndynamic pricing problems associated with low-sale products. Our algorithms were\nfurther implemented in a field study at Alibaba with 40 products for 30\nconsecutive days, and compared to the products which use business-as-usual\npricing policy of Alibaba. The results from the field experiment show that the\noverall revenue increased by 10.14%.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 04:10:57 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 14:40:10 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Miao", "Sentao", ""], ["Chen", "Xi", ""], ["Chao", "Xiuli", ""], ["Liu", "Jiaxi", ""], ["Zhang", "Yidong", ""]]}, {"id": "1902.06222", "submitter": "Weize Quan", "authors": "Weize Quan, Dong-Ming Yan, Kai Wang, Xiaopeng Zhang and Denis Pellerin", "title": "Detecting Colorized Images via Convolutional Neural Networks: Toward\n  High Accuracy and Good Generalization", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image colorization achieves more and more realistic results with the\nincreasing computation power of recent deep learning techniques. It becomes\nmore difficult to identify the fake colorized images by human eyes. In this\nwork, we propose a novel forensic method to distinguish between natural images\n(NIs) and colorized images (CIs) based on convolutional neural network (CNN).\nOur method is able to achieve high classification accuracy and cope with the\nchallenging scenario of blind detection, i.e., no training sample is available\nfrom \"unknown\" colorization algorithm that we may encounter during the testing\nphase. This blind detection performance can be regarded as a generalization\nperformance. First, we design and implement a base network, which can attain\nbetter performance in terms of classification accuracy and generalization (in\nmost cases) compared with state-of-the-art methods. Furthermore, we design a\nnew branch, which analyzes smaller regions of extracted features, and insert it\ninto the above base network. Consequently, our network can not only improve the\nclassification accuracy, but also enhance the generalization in the vast\nmajority of cases. To further improve the performance of blind detection, we\npropose to automatically construct negative samples through linear\ninterpolation of paired natural and colorized images. Then, we progressively\ninsert these negative samples into the original training dataset and continue\nto train the network. Experimental results demonstrate that our method can\nachieve stable and high generalization performance when tested against\ndifferent state-of-the-art colorization algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 08:40:48 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Quan", "Weize", ""], ["Yan", "Dong-Ming", ""], ["Wang", "Kai", ""], ["Zhang", "Xiaopeng", ""], ["Pellerin", "Denis", ""]]}, {"id": "1902.06223", "submitter": "Alon Cohen", "authors": "Alon Cohen, Tomer Koren, Yishay Mansour", "title": "Learning Linear-Quadratic Regulators Efficiently with only $\\sqrt{T}$\n  Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first computationally-efficient algorithm with $\\widetilde\nO(\\sqrt{T})$ regret for learning in Linear Quadratic Control systems with\nunknown dynamics. By that, we resolve an open question of Abbasi-Yadkori and\nSzepesv\\'ari (2011) and Dean, Mania, Matni, Recht, and Tu (2018).\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 08:54:05 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 09:53:27 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cohen", "Alon", ""], ["Koren", "Tomer", ""], ["Mansour", "Yishay", ""]]}, {"id": "1902.06231", "submitter": "Aaron Tuor", "authors": "Aaron Tuor, Fnu Anubhav, Lauren Charles", "title": "Multiple Document Representations from News Alerts for Automated\n  Bio-surveillance Event Detection", "comments": "Presented at the 5th Pacific Northwest Regional NLP Workshop: NW-NLP\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to globalization, geographic boundaries no longer serve as effective\nshields for the spread of infectious diseases. In order to aid bio-surveillance\nanalysts in disease tracking, recent research has been devoted to developing\ninformation retrieval and analysis methods utilizing the vast corpora of\npublicly available documents on the internet. In this work, we present methods\nfor the automated retrieval and classification of documents related to active\npublic health events. We demonstrate classification performance on an\nauto-generated corpus, using recurrent neural network, TF-IDF, and Naive Bayes\nlog count ratio document representations. By jointly modeling the title and\ndescription of a document, we achieve 97% recall and 93.3% accuracy with our\nbest performing bio-surveillance event classification model: logistic\nregression on the combined output from a pair of bidirectional recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 09:33:24 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tuor", "Aaron", ""], ["Anubhav", "Fnu", ""], ["Charles", "Lauren", ""]]}, {"id": "1902.06239", "submitter": "Babak Badnava", "authors": "Babak Badnava and Nasser Mozayani", "title": "A new Potential-Based Reward Shaping for Reinforcement Learning Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential-based reward shaping (PBRS) is a particular category of machine\nlearning methods which aims to improve the learning speed of a reinforcement\nlearning agent by extracting and utilizing extra knowledge while performing a\ntask. There are two steps in the process of transfer learning: extracting\nknowledge from previously learned tasks and transferring that knowledge to use\nit in a target task. The latter step is well discussed in the literature with\nvarious methods being proposed for it, while the former has been explored less.\nWith this in mind, the type of knowledge that is transmitted is very important\nand can lead to considerable improvement. Among the literature of both the\ntransfer learning and the potential-based reward shaping, a subject that has\nnever been addressed is the knowledge gathered during the learning process\nitself. In this paper, we presented a novel potential-based reward shaping\nmethod that attempted to extract knowledge from the learning process. The\nproposed method extracts knowledge from episodes' cumulative rewards. The\nproposed method has been evaluated in the Arcade learning environment and the\nresults indicate an improvement in the learning process in both the single-task\nand the multi-task reinforcement learner agents.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 10:34:18 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 07:49:15 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Badnava", "Babak", ""], ["Mozayani", "Nasser", ""]]}, {"id": "1902.06267", "submitter": "Fangshu Yang", "authors": "Fangshu Yang, Jianwei Ma", "title": "Deep-learning inversion: a next generation seismic velocity-model\n  building method", "comments": "62 pages, 23 figures, 5 tables, revised version (Geophysics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seismic velocity is one of the most important parameters used in seismic\nexploration. Accurate velocity models are key prerequisites for reverse-time\nmigration and other high-resolution seismic imaging techniques. Such velocity\ninformation has traditionally been derived by tomography or full-waveform\ninversion (FWI), which are time consuming and computationally expensive, and\nthey rely heavily on human interaction and quality control. We investigate a\nnovel method based on the supervised deep fully convolutional neural network\n(FCN) for velocity-model building (VMB) directly from raw seismograms. Unlike\nthe conventional inversion method based on physical models, the supervised\ndeep-learning methods are based on big-data training rather than\nprior-knowledge assumptions. During the training stage, the network establishes\na nonlinear projection from the multi-shot seismic data to the corresponding\nvelocity models. During the prediction stage, the trained network can be used\nto estimate the velocity models from the new input seismic data. One key\ncharacteristic of the deep-learning method is that it can automatically extract\nmulti-layer useful features without the need for human-curated activities and\ninitial velocity setup. The data-driven method usually requires more time\nduring the training stage, and actual predictions take less time, with only\nseconds needed. Therefore, the computational time of geophysical inversions,\nincluding real-time inversions, can be dramatically reduced once a good\ngeneralized network is built. By using numerical experiments on synthetic\nmodels, the promising performances of our proposed method are shown in\ncomparison with conventional FWI even when the input data are in more realistic\nscenarios. Discussions on the deep-learning methods, training dataset, lack of\nlow frequencies, and advantages and disadvantages of the new method are also\nprovided.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 14:52:02 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Yang", "Fangshu", ""], ["Ma", "Jianwei", ""]]}, {"id": "1902.06278", "submitter": "Gabriele Abbati", "authors": "Philippe Wenk, Gabriele Abbati, Michael A Osborne, Bernhard\n  Sch\\\"olkopf, Andreas Krause and Stefan Bauer", "title": "ODIN: ODE-Informed Regression for Parameter and State Inference in\n  Time-Continuous Dynamical Systems", "comments": "Published at the Thirty-fourth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter inference in ordinary differential equations is an important\nproblem in many applied sciences and in engineering, especially in a\ndata-scarce setting. In this work, we introduce a novel generative modeling\napproach based on constrained Gaussian processes and leverage it to build a\ncomputationally and data efficient algorithm for state and parameter inference.\nIn an extensive set of experiments, our approach outperforms the current state\nof the art for parameter inference both in terms of accuracy and computational\ncost. It also shows promising results for the much more challenging problem of\nmodel selection.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 15:35:00 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:15:39 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 17:09:11 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Wenk", "Philippe", ""], ["Abbati", "Gabriele", ""], ["Osborne", "Michael A", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Krause", "Andreas", ""], ["Bauer", "Stefan", ""]]}, {"id": "1902.06284", "submitter": "Bilal Farooq", "authors": "Arash Kalatian and Bilal Farooq", "title": "A semi-supervised deep residual network for mode detection in Wi-Fi\n  signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their ubiquitous and pervasive nature, Wi-Fi networks have the\npotential to collect large-scale, low-cost, and disaggregate data on multimodal\ntransportation. In this study, we develop a semi-supervised deep residual\nnetwork (ResNet) framework to utilize Wi-Fi communications obtained from\nsmartphones for the purpose of transportation mode detection. This framework is\nevaluated on data collected by Wi-Fi sensors located in a congested urban area\nin downtown Toronto. To tackle the intrinsic difficulties and costs associated\nwith labelled data collection, we utilize ample amount of easily collected\nlow-cost unlabelled data by implementing the semi-supervised part of the\nframework. By incorporating a ResNet architecture as the core of the framework,\nwe take advantage of the high-level features not considered in the traditional\nmachine learning frameworks. The proposed framework shows a promising\nperformance on the collected data, with a prediction accuracy of 81.8% for\nwalking, 82.5% for biking and 86.0% for the driving mode.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 16:12:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kalatian", "Arash", ""], ["Farooq", "Bilal", ""]]}, {"id": "1902.06286", "submitter": "Nir Billfeld", "authors": "Nir Billfeld, Moshe Kim", "title": "Semiparametric correction for endogenous truncation bias with Vox Populi\n  based participation decision", "comments": "19 packages", "journal-ref": "IEEE Access, 7, 12114-12132", "doi": "10.1109/ACCESS.2018.2888575", "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We synthesize the knowledge present in various scientific disciplines for the\ndevelopment of semiparametric endogenous truncation-proof algorithm, correcting\nfor truncation bias due to endogenous self-selection. This synthesis enriches\nthe algorithm's accuracy, efficiency and applicability. Improving upon the\ncovariate shift assumption, data are intrinsically affected and largely\ngenerated by their own behavior (cognition). Refining the concept of Vox Populi\n(Wisdom of Crowd) allows data points to sort themselves out depending on their\nestimated latent reference group opinion space. Monte Carlo simulations, based\non 2,000,000 different distribution functions, practically generating 100\nmillion realizations, attest to a very high accuracy of our model.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 16:20:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Billfeld", "Nir", ""], ["Kim", "Moshe", ""]]}, {"id": "1902.06289", "submitter": "Zhen Mei", "authors": "Zhen Mei, Kui Cai, and Xingwei Zhong", "title": "Neural Network-Based Dynamic Threshold Detection for Non-Volatile\n  Memories", "comments": "A six-page version of this paper has been accepted by ICC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The memory physics induced unknown offset of the channel is a critical and\ndifficult issue to be tackled for many non-volatile memories (NVMs). In this\npaper, we first propose novel neural network (NN) detectors by using the\nmultilayer perceptron (MLP) network and the recurrent neural network (RNN),\nwhich can effectively tackle the unknown offset of the channel. However,\ncompared with the conventional threshold detector, the NN detectors will incur\na significant delay of the read latency and more power consumption. Therefore,\nwe further propose a novel dynamic threshold detector (DTD), whose detection\nthreshold can be derived based on the outputs of the proposed NN detectors. In\nthis way, the NN-based detection only needs to be invoked when the error\ncorrection code (ECC) decoder fails, or periodically when the system is in the\nidle state. Thereafter, the threshold detector will still be adopted by using\nthe adjusted detection threshold derived base on the outputs of the NN\ndetector, until a further adjustment of the detection threshold is needed.\nSimulation results demonstrate that the proposed DTD based on the RNN detection\ncan achieve the error performance of the optimum detector, without the prior\nknowledge of the channel.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 16:51:17 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mei", "Zhen", ""], ["Cai", "Kui", ""], ["Zhong", "Xingwei", ""]]}, {"id": "1902.06292", "submitter": "Sercan Arik", "authors": "Sercan O. Arik and Tomas Pfister", "title": "ProtoAttend: Attention-Based Prototypical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel inherently interpretable machine learning method that\nbases decisions on few relevant examples that we call prototypes. Our method,\nProtoAttend, can be integrated into a wide range of neural network\narchitectures including pre-trained models. It utilizes an attention mechanism\nthat relates the encoded representations to samples in order to determine\nprototypes. The resulting model outperforms state of the art in three high\nimpact problems without sacrificing accuracy of the original model: (1) it\nenables high-quality interpretability that outputs samples most relevant to the\ndecision-making (i.e. a sample-based interpretability method); (2) it achieves\nstate of the art confidence estimation by quantifying the mismatch across\nprototype labels; and (3) it obtains state of the art in distribution mismatch\ndetection. All this can be achieved with minimal additional test time and a\npractically viable training time computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 17:12:07 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 23:54:08 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 16:45:51 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 01:39:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1902.06320", "submitter": "Jasmine Sekhon", "authors": "Jasmine Sekhon, Cody Fleming", "title": "Towards Improved Testing For Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of deep neural networks in safety-critical applications makes\nit necessary to carry out adequate testing to detect and correct any incorrect\nbehavior for corner case inputs before they can be actually used. Deep neural\nnetworks lack an explicit control-flow structure, making it impossible to apply\nto them traditional software testing criteria such as code coverage. In this\npaper, we examine existing testing methods for deep neural networks, the\nopportunities for improvement and the need for a fast, scalable, generalizable\nend-to-end testing method. We also propose a coverage criterion for deep neural\nnetworks that tries to capture all possible parts of the deep neural network's\nlogic.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 20:25:02 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Sekhon", "Jasmine", ""], ["Fleming", "Cody", ""]]}, {"id": "1902.06332", "submitter": "Lin Chen", "authors": "Mingrui Zhang, Lin Chen, Aryan Mokhtari, Hamed Hassani, Amin Karbasi", "title": "Quantized Frank-Wolfe: Faster Optimization, Lower Communication, and\n  Projection Free", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently mitigate the overhead of gradient communications in\ndistributed optimization? This problem is at the heart of training scalable\nmachine learning models and has been mainly studied in the unconstrained\nsetting. In this paper, we propose Quantized-Frank-Wolfe (QFW), the first\nprojection-free and communication-efficient algorithm for solving constrained\noptimization problems at scale. We consider both convex and non-convex\nobjective functions, expressed as a finite-sum or more generally a stochastic\noptimization problem, and provide strong theoretical guarantees on the\nconvergence rate of QFW. This is accomplished by proposing novel quantization\nschemes that efficiently compress gradients while controlling the noise\nvariance introduced during this process. Finally, we empirically validate the\nefficiency of QFW in terms of communication and the quality of returned\nsolution against natural baselines.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 21:43:10 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:36:18 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 20:15:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Mingrui", ""], ["Chen", "Lin", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1902.06349", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, Armando Solar-Lezama", "title": "Learning to Infer Program Sketches", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to build systems which write code automatically from the kinds of\nspecifications humans can most easily provide, such as examples and natural\nlanguage instruction. The key idea of this work is that a flexible combination\nof pattern recognition and explicit reasoning can be used to solve these\ncomplex programming problems. We propose a method for dynamically integrating\nthese types of information. Our novel intermediate representation and training\nalgorithm allow a program synthesis system to learn, without direct\nsupervision, when to rely on pattern recognition and when to perform symbolic\nsearch. Our model matches the memorization and generalization performance of\nneural synthesis and symbolic search, respectively, and achieves\nstate-of-the-art performance on a dataset of simple English description-to-code\nprogramming problems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 23:21:34 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 21:36:48 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Nye", "Maxwell", ""], ["Hewitt", "Luke", ""], ["Tenenbaum", "Joshua", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1902.06353", "submitter": "Ilai Bistritz", "authors": "S.M. Zafaruddin, Ilai Bistritz, Amir Leshem and Dusit Niyato", "title": "Distributed Learning for Channel Allocation Over a Shared Spectrum", "comments": null, "journal-ref": "IEEE Journal on Selected Areas in Communications Year: 2019 |\n  Volume: 37, Issue: 10, Publisher: IEEE", "doi": "10.1109/JSAC.2019.2933966", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel allocation is the task of assigning channels to users such that some\nobjective (e.g., sum-rate) is maximized. In centralized networks such as\ncellular networks, this task is carried by the base station which gathers the\nchannel state information (CSI) from the users and computes the optimal\nsolution. In distributed networks such as ad-hoc and device-to-device (D2D)\nnetworks, no base station exists and conveying global CSI between users is\ncostly or simply impractical. When the CSI is time varying and unknown to the\nusers, the users face the challenge of both learning the channel statistics\nonline and converge to a good channel allocation. This introduces a multi-armed\nbandit (MAB) scenario with multiple decision makers. If two users or more\nchoose the same channel, a collision occurs and they all receive zero reward.\nWe propose a distributed channel allocation algorithm that each user runs and\nconverges to the optimal allocation while achieving an order optimal regret of\nO\\left(\\log T\\right). The algorithm is based on a carrier sensing multiple\naccess (CSMA) implementation of the distributed auction algorithm. It does not\nrequire any exchange of information between users. Users need only to observe a\nsingle channel at a time and sense if there is a transmission on that channel,\nwithout decoding the transmissions or identifying the transmitting users. We\ndemonstrate the performance of our algorithm using simulated LTE and 5G\nchannels.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 23:51:49 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 01:55:50 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zafaruddin", "S. M.", ""], ["Bistritz", "Ilai", ""], ["Leshem", "Amir", ""], ["Niyato", "Dusit", ""]]}, {"id": "1902.06361", "submitter": "Baihong Jin", "authors": "Baihong Jin, Yuxin Chen, Dan Li, Kameshwar Poolla, Alberto\n  Sangiovanni-Vincentelli", "title": "A One-Class Support Vector Machine Calibration Method for Time Series\n  Change Point Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to identify the change point of a system's health status,\nwhich usually signifies an incipient fault under development. The One-Class\nSupport Vector Machine (OC-SVM) is a popular machine learning model for anomaly\ndetection and hence could be used for identifying change points; however, it is\nsometimes difficult to obtain a good OC-SVM model that can be used on sensor\nmeasurement time series to identify the change points in system health status.\nIn this paper, we propose a novel approach for calibrating OC-SVM models. The\napproach uses a heuristic search method to find a good set of input data and\nhyperparameters that yield a well-performing model. Our results on the C-MAPSS\ndataset demonstrate that OC-SVM can also achieve satisfactory accuracy in\ndetecting change point in time series with fewer training data, compared to\nstate-of-the-art deep learning approaches. In our case study, the OC-SVM\ncalibrated by the proposed model is shown to be useful especially in scenarios\nwith limited amount of training data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 00:34:58 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Jin", "Baihong", ""], ["Chen", "Yuxin", ""], ["Li", "Dan", ""], ["Poolla", "Kameshwar", ""], ["Sangiovanni-Vincentelli", "Alberto", ""]]}, {"id": "1902.06366", "submitter": "Baihong Jin", "authors": "Baihong Jin, Dan Li, Seshadhri Srinivasan, See-Kiong Ng, Kameshwar\n  Poolla, Alberto~Sangiovanni-Vincentelli", "title": "Detecting and Diagnosing Incipient Building Faults Using Uncertainty\n  Information from Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of incipient faults is of vital importance to reducing\nmaintenance costs, saving energy, and enhancing occupant comfort in buildings.\nPopular supervised learning models such as deep neural networks are considered\npromising due to their ability to directly learn from labeled fault data;\nhowever, it is known that the performance of supervised learning approaches\nhighly relies on the availability and quality of labeled training data. In\nFault Detection and Diagnosis (FDD) applications, the lack of labeled incipient\nfault data has posed a major challenge to applying these supervised learning\ntechniques to commercial buildings. To overcome this challenge, this paper\nproposes using Monte Carlo dropout (MC-dropout) to enhance the supervised\nlearning pipeline, so that the resulting neural network is able to detect and\ndiagnose unseen incipient fault examples. We also examine the proposed\nMC-dropout method on the RP-1043 dataset to demonstrate its effectiveness in\nindicating the most likely incipient fault types.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 00:55:38 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Jin", "Baihong", ""], ["Li", "Dan", ""], ["Srinivasan", "Seshadhri", ""], ["Ng", "See-Kiong", ""], ["Poolla", "Kameshwar", ""], ["Alberto~Sangiovanni-Vincentelli", "", ""]]}, {"id": "1902.06383", "submitter": "Leslie Tiong", "authors": "Leslie Ching Ow Tiong, Andrew Beng Jin Teoh, Yunli Lee", "title": "Periocular Recognition in the Wild with Orthogonal Combination of Local\n  Binary Coded Pattern in Dual-stream Convolutional Neural Network", "comments": "Accepted in International Conference On Biometrics 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the advancements made in the periocular recognition, the dataset\nand periocular recognition in the wild remains a challenge. In this paper, we\npropose a multilayer fusion approach by means of a pair of shared parameters\n(dual-stream) convolutional neural network where each network accepts RGB data\nand a novel colour-based texture descriptor, namely Orthogonal\nCombination-Local Binary Coded Pattern (OC-LBCP) for periocular recognition in\nthe wild. Specifically, two distinct late-fusion layers are introduced in the\ndual-stream network to aggregate the RGB data and OC-LBCP. Thus, the network\nbeneficial from this new feature of the late-fusion layers for accuracy\nperformance gain. We also introduce and share a new dataset for periocular in\nthe wild, namely Ethnic-ocular dataset for benchmarking. The proposed network\nhas also been assessed on one publicly available dataset, namely UBIPr. The\nproposed network outperforms several competing approaches on these datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 03:08:04 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 05:25:05 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Tiong", "Leslie Ching Ow", ""], ["Teoh", "Andrew Beng Jin", ""], ["Lee", "Yunli", ""]]}, {"id": "1902.06415", "submitter": "Yueyao Yu", "authors": "Yueyao Yu, Pengfei Yu and Wenye Li", "title": "AuxBlocks: Defense Adversarial Example via Auxiliary Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to adversarial examples, which poses an\nindisputable threat to their applications. However, recent studies observe\ngradient-masking defenses are self-deceiving methods if an attacker can realize\nthis defense. In this paper, we propose a new defense method based on appending\ninformation. We introduce the Aux Block model to produce extra outputs as a\nself-ensemble algorithm and analytically investigate the robustness mechanism\nof Aux Block. We have empirically studied the efficiency of our method against\nadversarial examples in two types of white-box attacks, and found that even in\nthe full white-box attack where an adversary can craft malicious examples from\ndefense models, our method has a more robust performance of about 54.6%\nprecision on Cifar10 dataset and 38.7% precision on Mini-Imagenet dataset.\nAnother advantage of our method is that it is able to maintain the prediction\naccuracy of the classification model on clean images, and thereby exhibits its\nhigh potential in practical applications\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 05:52:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Yu", "Yueyao", ""], ["Yu", "Pengfei", ""], ["Li", "Wenye", ""]]}, {"id": "1902.06423", "submitter": "Florian Mai", "authors": "Florian Mai, Lukas Galke, Ansgar Scherp", "title": "CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix\n  Space Model", "comments": "Conference paper at ICLR 2019", "journal-ref": "In International Conference on Learning Representations 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Bag of Words (CBOW) is a powerful text embedding method. Due to\nits strong capabilities to encode word content, CBOW embeddings perform well on\na wide range of downstream tasks while being efficient to compute. However,\nCBOW is not capable of capturing the word order. The reason is that the\ncomputation of CBOW's word embeddings is commutative, i.e., embeddings of XYZ\nand ZYX are the same. In order to address this shortcoming, we propose a\nlearning algorithm for the Continuous Matrix Space Model, which we call\nContinual Multiplication of Words (CMOW). Our algorithm is an adaptation of\nword2vec, so that it can be trained on large quantities of unlabeled text. We\nempirically show that CMOW better captures linguistic properties, but it is\ninferior to CBOW in memorizing word content. Motivated by these findings, we\npropose a hybrid model that combines the strengths of CBOW and CMOW. Our\nresults show that the hybrid CBOW-CMOW-model retains CBOW's strong ability to\nmemorize word content while at the same time substantially improving its\nability to encode other linguistic information by 8%. As a result, the hybrid\nalso performs better on 8 out of 11 supervised downstream tasks with an average\nimprovement of 1.2%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 06:54:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Mai", "Florian", ""], ["Galke", "Lukas", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1902.06443", "submitter": "Xiaopeng Luo Dr.", "authors": "Xin Xu and Xiaopeng Luo", "title": "Sparse residual tree and forest", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse residual tree (SRT) is an adaptive exploration method for multivariate\nscattered data approximation. It leads to sparse and stable approximations in\nareas where the data is sufficient or redundant, and points out the possible\nlocal regions where data refinement is needed. Sparse residual forest (SRF) is\na combination of SRT predictors to further improve the approximation accuracy\nand stability according to the error characteristics of SRTs. The hierarchical\nparallel SRT algorithm is based on both tree decomposition and adaptive radial\nbasis function (RBF) explorations, whereby for each child a sparse and proper\nRBF refinement is added to the approximation by minimizing the norm of the\nresidual inherited from its parent. The convergence results are established for\nboth SRTs and SRFs. The worst case time complexity of SRTs is\n$\\mathcal{O}(N\\log_2N)$ for the initial work and $\\mathcal{O}(\\log_2N)$ for\neach prediction, meanwhile, the worst case storage requirement is\n$\\mathcal{O}(N\\log_2N)$, where the $N$ data points can be arbitrary\ndistributed. Numerical experiments are performed for several illustrative\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 08:03:31 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Xu", "Xin", ""], ["Luo", "Xiaopeng", ""]]}, {"id": "1902.06453", "submitter": "Raoul Heese", "authors": "Raoul Heese, Michal Walczak, Tobias Seidel, Norbert Asprion, Michael\n  Bortz", "title": "Optimized data exploration applied to the simulation of a chemical\n  process", "comments": "45 pages, 6 figures", "journal-ref": "Computers & Chemical Engineering, 2019", "doi": "10.1016/j.compchemeng.2019.01.007", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex simulation environments, certain parameter space regions may\nresult in non-convergent or unphysical outcomes. All parameters can therefore\nbe labeled with a binary class describing whether or not they lead to valid\nresults. In general, it can be very difficult to determine feasible parameter\nregions, especially without previous knowledge. We propose a novel algorithm to\nexplore such an unknown parameter space and improve its feasibility\nclassification in an iterative way. Moreover, we include an additional\noptimization target in the algorithm to guide the exploration towards regions\nof interest and to improve the classification therein. In our method we make\nuse of well-established concepts from the field of machine learning like kernel\nsupport vector machines and kernel ridge regression. From a comparison with a\nKriging-based exploration approach based on recently published results we can\nshow the advantages of our algorithm in a binary feasibility classification\nscenario with a discrete feasibility constraint violation. In this context, we\nalso propose an improvement of the Kriging-based exploration approach. We apply\nour novel method to a fully realistic, industrially relevant chemical process\nsimulation to demonstrate its practical usability and find a comparably good\napproximation of the data space topology from relatively few data points.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 08:26:10 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Heese", "Raoul", ""], ["Walczak", "Michal", ""], ["Seidel", "Tobias", ""], ["Asprion", "Norbert", ""], ["Bortz", "Michael", ""]]}, {"id": "1902.06468", "submitter": "Minsoo Rhu", "authors": "Youngeun Kwon, Minsoo Rhu", "title": "Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep\n  Learning", "comments": "Published as a conference paper at the 51st IEEE/ACM International\n  Symposium on Microarchitecture (MICRO-51), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the models and the datasets to train deep learning (DL) models scale,\nsystem architects are faced with new challenges, one of which is the memory\ncapacity bottleneck, where the limited physical memory inside the accelerator\ndevice constrains the algorithm that can be studied. We propose a\nmemory-centric deep learning system that can transparently expand the memory\ncapacity available to the accelerators while also providing fast inter-device\ncommunication for parallel training. Our proposal aggregates a pool of memory\nmodules locally within the device-side interconnect, which are decoupled from\nthe host interface and function as a vehicle for transparent memory capacity\nexpansion. Compared to conventional systems, our proposal achieves an average\n2.8x speedup on eight DL applications and increases the system-wide memory\ncapacity to tens of TBs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 09:07:07 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kwon", "Youngeun", ""], ["Rhu", "Minsoo", ""]]}, {"id": "1902.06494", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Yarin Gal", "title": "A Unifying Bayesian View of Continual Learning", "comments": "Presented at the Bayesian Deep Learning Workshop at Neural\n  Information Processing Systems December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some machine learning applications require continual learning - where data\ncomes in a sequence of datasets, each is used for training and then permanently\ndiscarded. From a Bayesian perspective, continual learning seems\nstraightforward: Given the model posterior one would simply use this as the\nprior for the next task. However, exact posterior evaluation is intractable\nwith many models, especially with Bayesian neural networks (BNNs). Instead,\nposterior approximations are often sought. Unfortunately, when posterior\napproximations are used, prior-focused approaches do not succeed in evaluations\ndesigned to capture properties of realistic continual learning use cases. As an\nalternative to prior-focused methods, we introduce a new approximate Bayesian\nderivation of the continual learning loss. Our loss does not rely on the\nposterior from earlier tasks, and instead adapts the model itself by changing\nthe likelihood term. We call these approaches likelihood-focused. We then\ncombine prior- and likelihood-focused methods into one objective, tying the two\nviews together under a single unifying framework of approximate Bayesian\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 10:22:13 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Gal", "Yarin", ""]]}, {"id": "1902.06495", "submitter": "J\\'er\\^ome Tubiana", "authors": "J\\'er\\^ome Tubiana, Simona Cocco, R\\'emi Monasson", "title": "Learning Compositional Representations of Interacting Systems with\n  Restricted Boltzmann Machines: Comparative Study of Lattice Proteins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Restricted Boltzmann Machine (RBM) is an unsupervised machine-learning\nbipartite graphical model that jointly learns a probability distribution over\ndata and extracts their relevant statistical features. As such, RBM were\nrecently proposed for characterizing the patterns of coevolution between amino\nacids in protein sequences and for designing new sequences. Here, we study how\nthe nature of the features learned by RBM changes with its defining parameters,\nsuch as the dimensionality of the representations (size of the hidden layer)\nand the sparsity of the features. We show that for adequate values of these\nparameters, RBM operate in a so-called compositional phase in which visible\nconfigurations sampled from the RBM are obtained by recombining these features.\nWe then compare the performance of RBM with other standard representation\nlearning algorithms, including Principal or Independent Component Analysis,\nautoencoders (AE), variational auto-encoders (VAE), and their sparse variants.\nWe show that RBM, due to the stochastic mapping between data configurations and\nrepresentations, better capture the underlying interactions in the system and\nare significantly more robust with respect to sample size than deterministic\nmethods such as PCA or ICA. In addition, this stochastic mapping is not\nprescribed a priori as in VAE, but learned from data, which allows RBM to show\ngood performance even with shallow architectures. All numerical results are\nillustrated on synthetic lattice-protein data, that share similar statistical\nfeatures with real protein sequences, and for which ground-truth interactions\nare known.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 10:24:19 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tubiana", "J\u00e9r\u00f4me", ""], ["Cocco", "Simona", ""], ["Monasson", "R\u00e9mi", ""]]}, {"id": "1902.06497", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Yarin Gal", "title": "Differentially Private Continual Learning", "comments": "Presented at the Privacy in Machine Learning and AI workshop at ICML\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting can be a significant problem for institutions that\nmust delete historic data for privacy reasons. For example, hospitals might not\nbe able to retain patient data permanently. But neural networks trained on\nrecent data alone will tend to forget lessons learned on old data. We present a\ndifferentially private continual learning framework based on variational\ninference. We estimate the likelihood of past data given the current model\nusing differentially private generative models of old datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 10:31:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Gal", "Yarin", ""]]}, {"id": "1902.06506", "submitter": "Youngjoo Kim", "authors": "Youngjoo Kim, Peng Wang, Lyudmila Mihaylova", "title": "Structural Recurrent Neural Network for Traffic Speed Prediction", "comments": "Accepted and revised, to be presented in International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP) on May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently demonstrated the traffic prediction\ncapability with the time series data obtained by sensors mounted on road\nsegments. However, capturing spatio-temporal features of the traffic data often\nrequires a significant number of parameters to train, increasing computational\nburden. In this work we demonstrate that embedding topological information of\nthe road network improves the process of learning traffic features. We use a\ngraph of a vehicular road network with recurrent neural networks (RNNs) to\ninfer the interaction between adjacent road segments as well as the temporal\ndynamics. The topology of the road network is converted into a spatio-temporal\ngraph to form a structural RNN (SRNN). The proposed approach is validated over\ntraffic speed data from the road network of the city of Santander in Spain. The\nexperiment shows that the graph-based method outperforms the state-of-the-art\nmethods based on spatio-temporal images, requiring much fewer parameters to\ntrain.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 10:49:04 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kim", "Youngjoo", ""], ["Wang", "Peng", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1902.06515", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "Grids versus Graphs: Partitioning Space for Improved Taxi Demand-Supply\n  Forecasts", "comments": "Submitted to IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate taxi demand-supply forecasting is a challenging application of ITS\n(Intelligent Transportation Systems), due to the complex spatial and temporal\npatterns. We investigate the impact of different spatial partitioning\ntechniques on the prediction performance of an LSTM (Long Short-Term Memory)\nnetwork, in the context of taxi demand-supply forecasting. We consider two\ntessellation schemes: (i) the variable-sized Voronoi tessellation, and (ii) the\nfixed-sized Geohash tessellation. While the widely employed ConvLSTM\n(Convolutional LSTM) can model fixed-sized Geohash partitions, the standard\nconvolutional filters cannot be applied on the variable-sized Voronoi\npartitions. To explore the Voronoi tessellation scheme, we propose the use of\nGraphLSTM (Graph-based LSTM), by representing the Voronoi spatial partitions as\nnodes on an arbitrarily structured graph. The GraphLSTM offers competitive\nperformance against ConvLSTM, at lower computational complexity, across three\nreal-world large-scale taxi demand-supply data sets, with different performance\nmetrics. To ensure superior performance across diverse settings, a HEDGE based\nensemble learning algorithm is applied over the ConvLSTM and the GraphLSTM\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:08:52 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1902.06522", "submitter": "Hung Le", "authors": "Hung Duy Le, Huynh Van Luong, Nikos Deligiannis", "title": "Designing recurrent neural networks by unfolding an l1-l1 minimization\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new deep recurrent neural network (RNN) architecture for\nsequential signal reconstruction. Our network is designed by unfolding the\niterations of the proximal gradient method that solves the l1-l1 minimization\nproblem. As such, our network leverages by design that signals have a sparse\nrepresentation and that the difference between consecutive signal\nrepresentations is also sparse. We evaluate the proposed model in the task of\nreconstructing video frames from compressive measurements and show that it\noutperforms several state-of-the-art RNN models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:34:51 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Le", "Hung Duy", ""], ["Van Luong", "Huynh", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1902.06525", "submitter": "Andrei Erofeev", "authors": "Andrei Erofeev, Denis Orlov, Alexey Ryzhov, Dmitry Koroteev", "title": "Prediction of Porosity and Permeability Alteration based on Machine\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The objective of this work is to study the applicability of various Machine\nLearning algorithms for prediction of some rock properties which geoscientists\nusually define due to special lab analysis. We demonstrate that these special\nproperties can be predicted only basing on routine core analysis (RCA) data. To\nvalidate the approach core samples from the reservoir with soluble rock matrix\ncomponents (salts) were tested within 100+ laboratory experiments. The\nchallenge of the experiments was to characterize the rate of salts in cores and\nalteration of porosity and permeability after reservoir desalination due to\ndrilling mud or water injection. For these three measured characteristics, we\ndeveloped the relevant predictive models, which were based on the results of\nRCA and data on coring depth and top and bottom depths of productive horizons.\nTo select the most accurate Machine Learning algorithm a comparative analysis\nhas been performed. It was shown that different algorithms work better in\ndifferent models. However, two hidden layers Neural network has demonstrated\nthe best predictive ability and generalizability for all three rock\ncharacteristics jointly. The other algorithms, such as Support Vector Machine\nand Linear Regression, also worked well on the dataset, but in particular\ncases. Overall, the applied approach allows predicting the alteration of\nporosity and permeability during desalination in porous rocks and also\nevaluating salt concentration without direct measurements in a laboratory. This\nwork also shows that developed approaches could be applied for prediction of\nother rock properties (residual brine and oil saturations, relative\npermeability, capillary pressure, and others), which laboratory measurements\nare time-consuming and expensive.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:37:53 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Erofeev", "Andrei", ""], ["Orlov", "Denis", ""], ["Ryzhov", "Alexey", ""], ["Koroteev", "Dmitry", ""]]}, {"id": "1902.06527", "submitter": "Woojun Kim", "authors": "Woojun Kim, Myungsik Cho, Youngchul Sung", "title": "Message-Dropout: An Efficient Training Method for Multi-Agent Deep\n  Reinforcement Learning", "comments": "The 33rd AAAI Conference on Artificial Intelligence (AAAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new learning technique named message-dropout to\nimprove the performance for multi-agent deep reinforcement learning under two\napplication scenarios: 1) classical multi-agent reinforcement learning with\ndirect message communication among agents and 2) centralized training with\ndecentralized execution. In the first application scenario of multi-agent\nsystems in which direct message communication among agents is allowed, the\nmessage-dropout technique drops out the received messages from other agents in\na block-wise manner with a certain probability in the training phase and\ncompensates for this effect by multiplying the weights of the dropped-out block\nunits with a correction probability. The applied message-dropout technique\neffectively handles the increased input dimension in multi-agent reinforcement\nlearning with communication and makes learning robust against communication\nerrors in the execution phase. In the second application scenario of\ncentralized training with decentralized execution, we particularly consider the\napplication of the proposed message-dropout to Multi-Agent Deep Deterministic\nPolicy Gradient (MADDPG), which uses a centralized critic to train a\ndecentralized actor for each agent. We evaluate the proposed message-dropout\ntechnique for several games, and numerical results show that the proposed\nmessage-dropout technique with proper dropout rate improves the reinforcement\nlearning performance significantly in terms of the training speed and the\nsteady-state performance in the execution phase.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:40:29 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kim", "Woojun", ""], ["Cho", "Myungsik", ""], ["Sung", "Youngchul", ""]]}, {"id": "1902.06542", "submitter": "Shadi Diab", "authors": "Shadi Diab", "title": "Optimizing Stochastic Gradient Descent in Text Classification Based on\n  Fine-Tuning Hyper-Parameters Approach. A Case Study on Automatic\n  Classification of Global Terrorist Attacks", "comments": "6 pages, 3 figures, 7 tables, Journal Article", "journal-ref": "International Journal of Computer Science and Information Security\n  (IJCSIS),Vol. 16, No. 12, December 2018", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this research is to enhance performance of Stochastic\nGradient Descent (SGD) algorithm in text classification. In our research, we\nproposed using SGD learning with Grid-Search approach to fine-tuning\nhyper-parameters in order to enhance the performance of SGD classification. We\nexplored different settings for representation, transformation and weighting\nfeatures from the summary description of terrorist attacks incidents obtained\nfrom the Global Terrorism Database as a pre-classification step, and validated\nSGD learning on Support Vector Machine (SVM), Logistic Regression and\nPerceptron classifiers by stratified 10-K-fold cross-validation to compare the\nperformance of different classifiers embedded in SGD algorithm. The research\nconcludes that using a grid-search to find the hyper-parameters optimize SGD\nclassification, not in the pre-classification settings only, but also in the\nperformance of the classifiers in terms of accuracy and execution time.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 12:34:27 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 06:38:32 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Diab", "Shadi", ""]]}, {"id": "1902.06550", "submitter": "Bojian Yin", "authors": "Bojian Yin, Siebren Schaafsma, Henk Corporaal, H. Steven Scholte,\n  Sander M. Bohte", "title": "LocalNorm: Robust Image Classification through Dynamically Regularized\n  Normalization", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern convolutional neural networks achieve outstanding accuracy on\nmany image classification tasks, they are, compared to humans, much more\nsensitive to image degradation. Here, we describe a variant of Batch\nNormalization, LocalNorm, that regularizes the normalization layer in the\nspirit of Dropout while dynamically adapting to the local image intensity and\ncontrast at test-time. We show that the resulting deep neural networks are much\nmore resistant to noise-induced image degradation, improving accuracy by up to\nthree times, while achieving the same or slightly better accuracy on\nnon-degraded classical benchmarks. In computational terms, LocalNorm adds\nnegligible training cost and little or no cost at inference time, and can be\napplied to already-trained networks in a straightforward manner.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 12:58:23 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 09:04:54 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 10:21:13 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yin", "Bojian", ""], ["Schaafsma", "Siebren", ""], ["Corporaal", "Henk", ""], ["Scholte", "H. Steven", ""], ["Bohte", "Sander M.", ""]]}, {"id": "1902.06562", "submitter": "Seunghyeok Back", "authors": "Hogeon Seo, Seunghyeok Back, Seongju Lee, Deokhwan Park, Tae Kim,\n  Kyoobin Lee", "title": "Intra- and Inter-epoch Temporal Context Network (IITNet) Using Sub-epoch\n  Features for Automatic Sleep Scoring on Raw Single-channel EEG", "comments": "First three authors contributed equally to this work; Accepted\n  manuscript for Biomedical Signal Processing and Control (BSPC); 12 pages, 6\n  figures;", "journal-ref": null, "doi": "10.1016/j.bspc.2020.102037", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning model, named IITNet, is proposed to learn intra- and\ninter-epoch temporal contexts from raw single-channel EEG for automatic sleep\nscoring. To classify the sleep stage from half-minute EEG, called an epoch,\nsleep experts investigate sleep-related events and consider the transition\nrules between the found events. Similarly, IITNet extracts representative\nfeatures at a sub-epoch level by a residual neural network and captures intra-\nand inter-epoch temporal contexts from the sequence of the features via\nbidirectional LSTM. The performance was investigated for three datasets as the\nsequence length (L) increased from one to ten. IITNet achieved the comparable\nperformance with other state-of-the-art results. The best accuracy, MF1, and\nCohen's kappa ($\\kappa$) were 83.9%, 77.6%, 0.78 for SleepEDF (L=10), 86.5%,\n80.7%, 0.80 for MASS (L=9), and 86.7%, 79.8%, 0.81 for SHHS (L=10),\nrespectively. Even though using four epochs, the performance was still\ncomparable. Compared to using a single epoch, on average, accuracy and MF1\nincreased by 2.48%p and 4.90%p and F1 of N1, N2, and REM increased by 16.1%p,\n1.50%p, and 6.42%p, respectively. Above four epochs, the performance\nimprovement was not significant. The results support that considering the\nlatest two-minute raw single-channel EEG can be a reasonable choice for sleep\nscoring via deep neural networks with efficiency and reliability. Furthermore,\nthe experiments with the baselines showed that introducing intra-epoch temporal\ncontext learning with a deep residual network contributes to the improvement in\nthe overall performance and has the positive synergy effect with the\ninter-epoch temporal context learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 13:32:21 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 06:38:33 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Seo", "Hogeon", ""], ["Back", "Seunghyeok", ""], ["Lee", "Seongju", ""], ["Park", "Deokhwan", ""], ["Kim", "Tae", ""], ["Lee", "Kyoobin", ""]]}, {"id": "1902.06568", "submitter": "Emre Aksan", "authors": "Emre Aksan and Otmar Hilliges", "title": "STCN: Stochastic Temporal Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional architectures have recently been shown to be competitive on\nmany sequence modelling tasks when compared to the de-facto standard of\nrecurrent neural networks (RNNs), while providing computational and modeling\nadvantages due to inherent parallelism. However, currently there remains a\nperformance gap to more expressive stochastic RNN variants, especially those\nwith several layers of dependent random variables. In this work, we propose\nstochastic temporal convolutional networks (STCNs), a novel architecture that\ncombines the computational advantages of temporal convolutional networks (TCN)\nwith the representational power and robustness of stochastic latent spaces. In\nparticular, we propose a hierarchy of stochastic latent variables that captures\ntemporal dependencies at different time-scales. The architecture is modular and\nflexible due to the decoupling of the deterministic and stochastic layers. We\nshow that the proposed architecture achieves state of the art log-likelihoods\nacross several tasks. Finally, the model is capable of predicting high-quality\nsynthetic samples over a long-range temporal horizon in modeling of handwritten\ntext.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 13:44:59 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Aksan", "Emre", ""], ["Hilliges", "Otmar", ""]]}, {"id": "1902.06579", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, Paolo Toccaceli, and Alex Gammerman", "title": "Conformal calibrators", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "23", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing examples of full conformal predictive systems, split-conformal\npredictive systems, and cross-conformal predictive systems impose severe\nrestrictions on the adaptation of predictive distributions to the test object\nat hand. In this paper we develop split-conformal and cross-conformal\npredictive systems that are fully adaptive. Our method consists in calibrating\nexisting predictive systems; the input predictive system is not supposed to\nsatisfy any properties of validity, whereas the output predictive system is\nguaranteed to be calibrated in probability. It is interesting that the method\nmay also work without the IID assumption, standard in conformal prediction.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 14:13:04 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Toccaceli", "Paolo", ""], ["Gammerman", "Alex", ""]]}, {"id": "1902.06583", "submitter": "Supratik Paul", "authors": "Supratik Paul, Vitaly Kurin, Shimon Whiteson", "title": "Fast Efficient Hyperparameter Tuning for Policy Gradients", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of policy gradient methods is sensitive to hyperparameter\nsettings that must be tuned for any new application. Widely used grid search\nmethods for tuning hyperparameters are sample inefficient and computationally\nexpensive. More advanced methods like Population Based Training that learn\noptimal schedules for hyperparameters instead of fixed settings can yield\nbetter results, but are also sample inefficient and computationally expensive.\nIn this paper, we propose Hyperparameter Optimisation on the Fly (HOOF), a\ngradient-free algorithm that requires no more than one training run to\nautomatically adapt the hyperparameter that affect the policy update directly\nthrough the gradient. The main idea is to use existing trajectories sampled by\nthe policy gradient method to optimise a one-step improvement objective,\nyielding a sample and computationally efficient algorithm that is easy to\nimplement. Our experimental results across multiple domains and algorithms show\nthat using HOOF to learn these hyperparameter schedules leads to faster\nlearning with improved performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 14:23:21 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 18:32:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Paul", "Supratik", ""], ["Kurin", "Vitaly", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1902.06615", "submitter": "Laura Anderlucci", "authors": "Cinzia Viroli and Laura Anderlucci", "title": "Deep Mixtures of Unigrams for uncovering Topics in Textual Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of Unigrams are one of the simplest and most efficient tools for\nclustering textual data, as they assume that documents related to the same\ntopic have similar distributions of terms, naturally described by Multinomials.\nWhen the classification task is particularly challenging, such as when the\ndocument-term matrix is high-dimensional and extremely sparse, a more composite\nrepresentation can provide better insight on the grouping structure. In this\nwork, we developed a deep version of mixtures of Unigrams for the unsupervised\nclassification of very short documents with a large number of terms, by\nallowing for models with further deeper latent layers; the proposal is derived\nin a Bayesian framework. The behaviour of the Deep Mixtures of Unigrams is\nempirically compared with that of other traditional and state-of-the-art\nmethods, namely $k$-means with cosine distance, $k$-means with Euclidean\ndistance on data transformed according to Semantic Analysis, Partition Around\nMedoids, Mixture of Gaussians on semantic-based transformed data, hierarchical\nclustering according to Ward's method with cosine dissimilarity, Latent\nDirichlet Allocation, Mixtures of Unigrams estimated via the EM algorithm,\nSpectral Clustering and Affinity Propagation clustering. The performance is\nevaluated in terms of both correct classification rate and Adjusted Rand Index.\nSimulation studies and real data analysis prove that going deep in clustering\nsuch data highly improves the classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 15:36:32 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 13:53:18 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Viroli", "Cinzia", ""], ["Anderlucci", "Laura", ""]]}, {"id": "1902.06660", "submitter": "Nirupam Bidikar", "authors": "Nirupam Bidikar, Kotoju Rajitha, P. Usha Supriya", "title": "A Novel Universal Solar Energy Predictor", "comments": "added additional results and discussion added new references\n  corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar energy is one of the most economical and clean sustainable energy\nsources on the planet. However, the solar energy throughput is highly\nunpredictable due to its dependency on a plethora of conditions including\nweather, seasons, and other ecological/environmental conditions. Thus, the\nsolar energy prediction is an inevitable necessity to optimize solar energy and\nalso to improve the efficiency of solar energy systems. Conventionally, the\noptimization of the solar energy is undertaken by subject matter experts using\ntheir domain knowledge; although it is impractical for even the experts to tune\nthe solar systems on a continuous basis. We strongly believe that the power of\nmachine learning can be harnessed to better optimize the solar energy\nproduction by learning the correlation between various conditions and solar\nenergy production from historical data which is typically readily available.\nFor this use, this paper predicts the daily total energy generation of an\ninstalled solar program using the Naive Bayes classifier. In the forecast\nprocedure, one year historical dataset including daily moderate temperatures,\ndaily total sunshine duration, daily total global solar radiation and daily\ntotal photovoltaic energy generation parameters are used as the categorical\nvalued features. By way of this Naive Bayes program the sensitivity and the\nprecision measures are improved for the photovoltaic energy prediction and also\nthe consequences of other solar characteristics on the solar energy production\nhave been assessed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 03:30:59 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 17:20:03 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Bidikar", "Nirupam", ""], ["Rajitha", "Kotoju", ""], ["Supriya", "P. Usha", ""]]}, {"id": "1902.06667", "submitter": "Yanqiao Zhu", "authors": "Fenyu Hu, Yanqiao Zhu, Shu Wu, Liang Wang and Tieniu Tan", "title": "Hierarchical Graph Convolutional Networks for Semi-supervised Node\n  Classification", "comments": "8 pages, 3 figures, 3 tables, accepted by International Joint\n  Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have been successfully applied in node\nclassification tasks of network mining. However, most of these models based on\nneighborhood aggregation are usually shallow and lack the \"graph pooling\"\nmechanism, which prevents the model from obtaining adequate global information.\nIn order to increase the receptive field, we propose a novel deep Hierarchical\nGraph Convolutional Network (H-GCN) for semi-supervised node classification.\nH-GCN first repeatedly aggregates structurally similar nodes to hyper-nodes and\nthen refines the coarsened graph to the original to restore the representation\nfor each node. Instead of merely aggregating one- or two-hop neighborhood\ninformation, the proposed coarsening procedure enlarges the receptive field for\neach node, hence more global information can be captured. The proposed H-GCN\nmodel shows strong empirical performance on various public benchmark graph\ndatasets, outperforming state-of-the-art methods and acquiring up to 5.9%\nperformance improvement in terms of accuracy. In addition, when only a few\nlabeled samples are provided, our model gains substantial improvements.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 09:58:44 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 10:21:00 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 15:52:05 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 08:35:03 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hu", "Fenyu", ""], ["Zhu", "Yanqiao", ""], ["Wu", "Shu", ""], ["Wang", "Liang", ""], ["Tan", "Tieniu", ""]]}, {"id": "1902.06673", "submitter": "Federico Monti", "authors": "Federico Monti, Fabrizio Frasca, Davide Eynard, Damon Mannion, Michael\n  M. Bronstein", "title": "Fake News Detection on Social Media using Geometric Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 15:21:45 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Monti", "Federico", ""], ["Frasca", "Fabrizio", ""], ["Eynard", "Davide", ""], ["Mannion", "Damon", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1902.06676", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo, M.D., M.S.(Math), M.S.(Comp. Sci.)", "title": "Generative Adversarial Networks Synthesize Realistic OCT Images of the\n  Retina", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report, to our knowledge, the first end-to-end application of Generative\nAdversarial Networks (GANs) towards the synthesis of Optical Coherence\nTomography (OCT) images of the retina. Generative models have gained recent\nattention for the increasingly realistic images they can synthesize, given a\nsampling of a data type. In this paper, we apply GANs to a sampling\ndistribution of OCTs of the retina. We observe the synthesis of realistic OCT\nimages depicting recognizable pathology such as macular holes, choroidal\nneovascular membranes, myopic degeneration, cystoid macular edema, and central\nserous retinopathy amongst others. This represents the first such report of its\nkind. Potential applications of this new technology include for surgical\nsimulation, for treatment planning, for disease prognostication, and for\naccelerating the development of new drugs and surgical procedures to treat\nretinal disease.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 17:47:53 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Odaibo", "Stephen G.", "", "Math"], ["D.", "M.", "", "Math"], ["S.", "M.", "", "Math"], ["S.", "M.", "", "Math"]]}, {"id": "1902.06679", "submitter": "Ghadeer Abuoda", "authors": "Ghadeer Abuoda, Gianmarco De Francisci Morales, Ashraf Aboulnaga", "title": "Link Prediction via Higher-Order Motif Features", "comments": "Extended version of paper that appears in ECML/PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction requires predicting which new links are likely to appear in a\ngraph. Being able to predict unseen links with good accuracy has important\napplications in several domains such as social media, security, transportation,\nand recommendation systems. A common approach is to use features based on the\ncommon neighbors of an unconnected pair of nodes to predict whether the pair\nwill form a link in the future. In this paper, we present an approach for link\nprediction that relies on higher-order analysis of the graph topology, well\nbeyond common neighbors. We treat the link prediction problem as a supervised\nclassification problem, and we propose a set of features that depend on the\npatterns or motifs that a pair of nodes occurs in. By using motifs of sizes 3,\n4, and 5, our approach captures a high level of detail about the graph topology\nwithin the neighborhood of the pair of nodes, which leads to a higher\nclassification accuracy. In addition to proposing the use of motif-based\nfeatures, we also propose two optimizations related to constructing the\nclassification dataset from the graph. First, to ensure that positive and\nnegative examples are treated equally when extracting features, we propose\nadding the negative examples to the graph as an alternative to the common\napproach of removing the positive ones. Second, we show that it is important to\ncontrol for the shortest-path distance when sampling pairs of nodes to form\nnegative examples, since the difficulty of prediction varies with the\nshortest-path distance. We experimentally demonstrate that using off-the-shelf\nclassifiers with a well constructed classification dataset results in up to 10\npercentage points increase in accuracy over prior topology-based and feature\nlearning methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 10:01:04 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 18:00:42 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Abuoda", "Ghadeer", ""], ["Morales", "Gianmarco De Francisci", ""], ["Aboulnaga", "Ashraf", ""]]}, {"id": "1902.06684", "submitter": "Guoji Fu", "authors": "Guoji Fu, Chengbin Hou and Xin Yao", "title": "Learning Topological Representation for Networks via Hierarchical\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topological information is essential for studying the relationship\nbetween nodes in a network. Recently, Network Representation Learning (NRL),\nwhich projects a network into a low-dimensional vector space, has been shown\ntheir advantages in analyzing large-scale networks. However, most existing NRL\nmethods are designed to preserve the local topology of a network, they fail to\ncapture the global topology. To tackle this issue, we propose a new NRL\nframework, named HSRL, to help existing NRL methods capture both the local and\nglobal topological information of a network. Specifically, HSRL recursively\ncompresses an input network into a series of smaller networks using a\ncommunity-awareness compressing strategy. Then, an existing NRL method is used\nto learn node embeddings for each compressed network. Finally, the node\nembeddings of the input network are obtained by concatenating the node\nembeddings from all compressed networks. Empirical studies for link prediction\non five real-world datasets demonstrate the advantages of HSRL over\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:29:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Fu", "Guoji", ""], ["Hou", "Chengbin", ""], ["Yao", "Xin", ""]]}, {"id": "1902.06687", "submitter": "Benjamin Coleman", "authors": "Benjamin Coleman, Richard G. Baraniuk, Anshumali Shrivastava", "title": "Sub-linear Memory Sketches for Near Neighbor Search on Streaming Data", "comments": "Published in ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first sublinear memory sketch that can be queried to find the\nnearest neighbors in a dataset. Our online sketching algorithm compresses an N\nelement dataset to a sketch of size $O(N^b \\log^3 N)$ in $O(N^{(b+1)} \\log^3\nN)$ time, where $b < 1$. This sketch can correctly report the nearest neighbors\nof any query that satisfies a stability condition parameterized by $b$. We\nachieve sublinear memory performance on stable queries by combining recent\nadvances in locality sensitive hash (LSH)-based estimators, online kernel\ndensity estimation, and compressed sensing. Our theoretical results shed new\nlight on the memory-accuracy tradeoff for nearest neighbor search, and our\nsketch, which consists entirely of short integer arrays, has a variety of\nattractive features in practice. We evaluate the memory-recall tradeoff of our\nmethod on a friend recommendation task in the Google Plus social media network.\nWe obtain orders of magnitude better compression than the random projection\nbased alternative while retaining the ability to report the nearest neighbors\nof practical queries.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 17:53:28 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 17:33:03 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 14:23:39 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Coleman", "Benjamin", ""], ["Baraniuk", "Richard G.", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1902.06691", "submitter": "Dennis Assenmacher", "authors": "Dennis Assenmacher, Lena Adam, Lena Frischlich, Heike Trautmann,\n  Christian Grimme", "title": "Openbots", "comments": "Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bots have recently gained attention in the context of public opinion\nmanipulation on social media platforms. While a lot of research effort has been\nput into the classification and detection of such (semi-)automated programs, it\nis still unclear how sophisticated those bots actually are, which platforms\nthey target, and where they originate from. To answer these questions, we\ngathered repository data from open source collaboration platforms to identify\nthe status-quo as well as trends of publicly available bot code. Our findings\nindicate that most of the code on collaboration platforms is of supportive\nnature and provides modules of automation instead of fully fledged social bot\nprograms. Hence, the cost (in terms of additional programming effort) for\nbuilding social bots with the goal of topic-specific manipulation is higher\nthan assumed and that methods in context of machine- or deep-learning currently\nonly play a minor role. However, our approach can be applied as multifaceted\nknowledge discovery framework to monitor trends in public bot code evolution to\ndetect new developments and streams.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 15:40:37 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 09:37:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Assenmacher", "Dennis", ""], ["Adam", "Lena", ""], ["Frischlich", "Lena", ""], ["Trautmann", "Heike", ""], ["Grimme", "Christian", ""]]}, {"id": "1902.06703", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Junichi Murata", "title": "Spectrum-Diverse Neuroevolution with Unified Neural Models", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, Volume\n  28, Issue 8, 1759-1773, 2017", "doi": "10.1109/TNNLS.2016.2551748", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms are being increasingly adopted in various applications.\nHowever, further expansion will require methods that work more automatically.\nTo enable this level of automation, a more powerful solution representation is\nneeded. However, by increasing the representation complexity a second problem\narises. The search space becomes huge and therefore an associated scalable and\nefficient searching algorithm is also required. To solve both problems, first a\npowerful representation is proposed that unifies most of the neural networks\nfeatures from the literature into one representation. Secondly, a new diversity\npreserving method called Spectrum Diversity is created based on the new concept\nof chromosome spectrum that creates a spectrum out of the characteristics and\nfrequency of alleles in a chromosome. The combination of Spectrum Diversity\nwith a unified neuron representation enables the algorithm to either surpass or\nequal NeuroEvolution of Augmenting Topologies (NEAT) on all of the five classes\nof problems tested. Ablation tests justifies the good results, showing the\nimportance of added new features in the unified neuron representation. Part of\nthe success is attributed to the novelty-focused evolution and good scalability\nwith chromosome size provided by Spectrum Diversity. Thus, this study sheds\nlight on a new representation and diversity preserving mechanism that should\nimpact algorithms and applications to come.\n  To download the code please access the following\nhttps://github.com/zweifel/Physis-Shard.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 09:58:41 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Murata", "Junichi", ""]]}, {"id": "1902.06704", "submitter": "Sarath Chandar", "authors": "Sarath Chandar, Chinnadhurai Sankar, Eugene Vorontsov, Samira Ebrahimi\n  Kahou, Yoshua Bengio", "title": "Towards Non-saturating Recurrent Units for Modelling Long-term\n  Dependencies", "comments": "In Proceedings of AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling long-term dependencies is a challenge for recurrent neural\nnetworks. This is primarily due to the fact that gradients vanish during\ntraining, as the sequence length increases. Gradients can be attenuated by\ntransition operators and are attenuated or dropped by activation functions.\nCanonical architectures like LSTM alleviate this issue by skipping information\nthrough a memory mechanism. We propose a new recurrent architecture\n(Non-saturating Recurrent Unit; NRU) that relies on a memory mechanism but\nforgoes both saturating activation functions and saturating gates, in order to\nfurther alleviate vanishing gradients. In a series of synthetic and real world\ntasks, we demonstrate that the proposed model is the only model that performs\namong the top 2 models across all tasks with and without long-term\ndependencies, when compared against a range of other architectures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:24:27 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Chandar", "Sarath", ""], ["Sankar", "Chinnadhurai", ""], ["Vorontsov", "Eugene", ""], ["Kahou", "Samira Ebrahimi", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1902.06705", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel,\n  Jonas Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, Alexey\n  Kurakin", "title": "On Evaluating Adversarial Robustness", "comments": "Living document; source available at\n  https://github.com/evaluating-adversarial-robustness/adv-eval-paper/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly evaluating defenses against adversarial examples has proven to be\nextremely difficult. Despite the significant amount of recent work attempting\nto design defenses that withstand adaptive attacks, few have succeeded; most\npapers that propose defenses are quickly shown to be incorrect.\n  We believe a large contributing factor is the difficulty of performing\nsecurity evaluations. In this paper, we discuss the methodological foundations,\nreview commonly accepted best practices, and suggest new methods for evaluating\ndefenses to adversarial examples. We hope that both researchers developing\ndefenses as well as readers and reviewers who wish to understand the\ncompleteness of an evaluation consider our advice in order to avoid common\npitfalls.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:18:27 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 17:38:32 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Carlini", "Nicholas", ""], ["Athalye", "Anish", ""], ["Papernot", "Nicolas", ""], ["Brendel", "Wieland", ""], ["Rauber", "Jonas", ""], ["Tsipras", "Dimitris", ""], ["Goodfellow", "Ian", ""], ["Madry", "Aleksander", ""], ["Kurakin", "Alexey", ""]]}, {"id": "1902.06711", "submitter": "Leonardo Enzo Brito da Silva", "authors": "Leonardo Enzo Brito da Silva, Niklas M. Melton, Donald C. Wunsch II", "title": "Incremental Cluster Validity Indices for Hard Partitions: Extensions and\n  Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validation is one of the most important aspects of clustering, but most\napproaches have been batch methods. Recently, interest has grown in providing\nincremental alternatives. This paper extends the incremental cluster validity\nindex (iCVI) family to include incremental versions of Calinski-Harabasz (iCH),\nI index and Pakhira-Bandyopadhyay-Maulik (iI and iPBM), Silhouette (iSIL),\nNegentropy Increment (iNI), Representative Cross Information Potential (irCIP)\nand Representative Cross Entropy (irH), and Conn_Index (iConn_Index).\nAdditionally, the effect of under- and over-partitioning on the behavior of\nthese six iCVIs, the Partition Separation (PS) index, as well as two other\nrecently developed iCVIs (incremental Xie-Beni (iXB) and incremental\nDavies-Bouldin (iDB)) was examined through a comparative study. Experimental\nresults using fuzzy adaptive resonance theory (ART)-based clustering methods\nshowed that while evidence of most under-partitioning cases could be inferred\nfrom the behaviors of all these iCVIs, over-partitioning was found to be a more\nchallenging scenario indicated only by the iConn_Index. The expansion of\nincremental validity indices provides significant novel opportunities for\nassessing and interpreting the results of unsupervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:27:44 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Melton", "Niklas M.", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "1902.06714", "submitter": "Milan Curcic", "authors": "Milan Curcic", "title": "A parallel Fortran framework for neural networks and deep learning", "comments": "Submitted to ACM SIGPLAN Fortran Forum. Reviewed by Arjen Markus and\n  Izaak Beekman", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes neural-fortran, a parallel Fortran framework for neural\nnetworks and deep learning. It features a simple interface to construct\nfeed-forward neural networks of arbitrary structure and size, several\nactivation functions, and stochastic gradient descent as the default\noptimization algorithm. Neural-fortran also leverages the Fortran 2018 standard\ncollective subroutines to achieve data-based parallelism on shared- or\ndistributed-memory machines. First, I describe the implementation of neural\nnetworks with Fortran derived types, whole-array arithmetic, and collective sum\nand broadcast operations to achieve parallelism. Second, I demonstrate the use\nof neural-fortran in an example of recognizing hand-written digits from images.\nFinally, I evaluate the computational performance in both serial and parallel\nmodes. Ease of use and computational performance are similar to an existing\npopular machine learning framework, making neural-fortran a viable candidate\nfor further development and use in production.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:32:30 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 14:17:05 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Curcic", "Milan", ""]]}, {"id": "1902.06720", "submitter": "Jaehoon Lee", "authors": "Jaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Roman\n  Novak, Jascha Sohl-Dickstein, Jeffrey Pennington", "title": "Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient\n  Descent", "comments": "12+16 pages; open-source code available at\n  https://github.com/google/neural-tangents; accepted to NeurIPS 2019", "journal-ref": null, "doi": "10.1088/1742-5468/abc62b", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal in deep learning research has been to precisely\ncharacterize training and generalization. However, the often complex loss\nlandscapes of neural networks have made a theory of learning dynamics elusive.\nIn this work, we show that for wide neural networks the learning dynamics\nsimplify considerably and that, in the infinite width limit, they are governed\nby a linear model obtained from the first-order Taylor expansion of the network\naround its initial parameters. Furthermore, mirroring the correspondence\nbetween wide Bayesian neural networks and Gaussian processes, gradient-based\ntraining of wide neural networks with a squared loss produces test set\npredictions drawn from a Gaussian process with a particular compositional\nkernel. While these theoretical results are only exact in the infinite width\nlimit, we nevertheless find excellent empirical agreement between the\npredictions of the original network and those of the linearized version even\nfor finite practically-sized networks. This agreement is robust across\ndifferent architectures, optimization methods, and loss functions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:37:49 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 18:30:17 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 02:18:14 GMT"}, {"version": "v4", "created": "Sun, 8 Dec 2019 06:02:33 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lee", "Jaehoon", ""], ["Xiao", "Lechao", ""], ["Schoenholz", "Samuel S.", ""], ["Bahri", "Yasaman", ""], ["Novak", "Roman", ""], ["Sohl-Dickstein", "Jascha", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "1902.06739", "submitter": "Rohil Badkundri", "authors": "Rohil Badkundri, Victor Valbuena, Srikusmanjali Pinnamareddy, Brittney\n  Cantrell, Janet Standeven", "title": "Forecasting the 2017-2018 Yemen Cholera Outbreak with Machine Learning", "comments": "Originally completed as part of the iGEM competition (see\n  http://2018.igem.org/Team:Lambert_GA/Software); 3431 words, 1 table, 2\n  manuscript figures, 2 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing Yemen cholera outbreak has been deemed one of the worst cholera\noutbreaks in history, with over a million people impacted and thousands dead.\nTriggered by a civil war, the outbreak has been shaped by various political,\nenvironmental, and epidemiological factors and continues to worsen. While\ncholera has several effective treatments, the untimely and inefficient\ndistribution of existing medicines has been the primary cause of cholera\nmortality. With the hope of facilitating resource allocation, various\nmathematical models have been created to track the Yemeni outbreak and identify\nat-risk administrative divisions, called governorates. Existing models are not\npowerful enough to accurately and consistently forecast cholera cases per\ngovernorate over multiple timeframes. To address the need for a complex,\nreliable model, we offer the Cholera Artificial Learning Model (CALM); a system\nof 4 extreme-gradient-boosting (XGBoost) machine learning models that forecast\nthe number of new cholera cases a Yemeni governorate will experience from a\ntime range of 2 weeks to 2 months. CALM provides a novel machine learning\napproach that makes use of rainfall data, past cholera cases and deaths data,\ncivil war fatalities, and inter-governorate interactions represented across\nmultiple time frames. Additionally, the use of machine learning, along with\nextensive feature engineering, allows CALM to easily learn complex non-linear\nrelations apparent in an epidemiological phenomenon. CALM is able to forecast\ncholera incidence 2 weeks to 2 months in advance within a margin of just 5\ncholera cases per 10,000 people in real-world simulation.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 05:26:07 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Badkundri", "Rohil", ""], ["Valbuena", "Victor", ""], ["Pinnamareddy", "Srikusmanjali", ""], ["Cantrell", "Brittney", ""], ["Standeven", "Janet", ""]]}, {"id": "1902.06740", "submitter": "Dhaval Adjodah", "authors": "Dhaval Adjodah, Dan Calacci, Abhimanyu Dubey, Anirudh Goyal, Peter\n  Krafft, Esteban Moro, Alex Pentland", "title": "Leveraging Communication Topologies Between Learning Agents in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.12556", "journal-ref": "AAMAS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common technique to improve learning performance in deep reinforcement\nlearning (DRL) and many other machine learning algorithms is to run multiple\nlearning agents in parallel. A neglected component in the development of these\nalgorithms has been how best to arrange the learning agents involved to improve\ndistributed search. Here we draw upon results from the networked optimization\nliteratures suggesting that arranging learning agents in communication networks\nother than fully connected topologies (the implicit way agents are commonly\narranged in) can improve learning. We explore the relative performance of four\npopular families of graphs and observe that one such family (Erdos-Renyi random\ngraphs) empirically outperforms the de facto fully-connected communication\ntopology across several DRL benchmark tasks. Additionally, we observe that 1000\nlearning agents arranged in an Erdos-Renyi graph can perform as well as 3000\nagents arranged in the standard fully-connected topology, showing the large\nlearning improvement possible when carefully designing the topology over which\nagents communicate. We complement these empirical results with a theoretical\ninvestigation of why our alternate topologies perform better. Overall, our work\nsuggests that distributed machine learning algorithms could be made more\neffective if the communication topology between learning agents was optimized.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 19:54:52 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 19:33:38 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Adjodah", "Dhaval", ""], ["Calacci", "Dan", ""], ["Dubey", "Abhimanyu", ""], ["Goyal", "Anirudh", ""], ["Krafft", "Peter", ""], ["Moro", "Esteban", ""], ["Pentland", "Alex", ""]]}, {"id": "1902.06744", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Using Machine Learning to Guide Cognitive Modeling: A Case Study in\n  Moral Reasoning", "comments": "Camera ready version for Cognitive Science Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale behavioral datasets enable researchers to use complex machine\nlearning algorithms to better predict human behavior, yet this increased\npredictive power does not always lead to a better understanding of the behavior\nin question. In this paper, we outline a data-driven, iterative procedure that\nallows cognitive scientists to use machine learning to generate models that are\nboth interpretable and accurate. We demonstrate this method in the domain of\nmoral decision-making, where standard experimental approaches often identify\nrelevant principles that influence human judgments, but fail to generalize\nthese findings to \"real world\" situations that place these principles in\nconflict. The recently released Moral Machine dataset allows us to build a\npowerful model that can predict the outcomes of these conflicts while remaining\nsimple enough to explain the basis behind human decisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:01:05 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 23:34:57 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:57:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1902.06766", "submitter": "Ilya Feige", "authors": "Christopher Frye, Ilya Feige", "title": "Parenting: Safe Reinforcement Learning from Human Input", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents trained via reinforcement learning present numerous safety\nconcerns: reward hacking, negative side effects, and unsafe exploration, among\nothers. In the context of near-future autonomous agents, operating in\nenvironments where humans understand the existing dangers, human involvement in\nthe learning process has proved a promising approach to AI Safety. Here we\ndemonstrate that a precise framework for learning from human input, loosely\ninspired by the way humans parent children, solves a broad class of safety\nproblems in this context. We show that our Parenting algorithm solves these\nproblems in the relevant AI Safety gridworlds of Leike et al. (2017), that an\nagent can learn to outperform its parent as it \"matures\", and that policies\nlearnt through Parenting are generalisable to new environments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:10:18 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Frye", "Christopher", ""], ["Feige", "Ilya", ""]]}, {"id": "1902.06778", "submitter": "Zhicheng Ding", "authors": "Zhicheng Ding, Mehmet Kerem Turkcan, Albert Boulanger", "title": "Using an Ancillary Neural Network to Capture Weekends and Holidays in an\n  Adjoint Neural Network Architecture for Intelligent Building Management", "comments": "9 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The US EIA estimated in 2017 about 39\\% of total U.S. energy consumption was\nby the residential and commercial sectors. Therefore, Intelligent Building\nManagement (IBM) solutions that minimize consumption while maintaining tenant\ncomfort are an important component in addressing climate change. A forecasting\ncapability for accurate prediction of indoor temperatures in a planning horizon\nof 24 hours is essential to IBM. It should predict the indoor temperature in\nboth short-term (e.g. 15 minutes) and long-term (e.g. 24 hours) periods\naccurately including weekends, major holidays, and minor holidays. Other\nrequirements include the ability to predict the maximum and the minimum indoor\ntemperatures precisely and provide the confidence for each prediction. To\nachieve these requirements, we propose a novel adjoint neural network\narchitecture for time series prediction that uses an ancillary neural network\nto capture weekend and holiday information. We studied four long short-term\nmemory (LSTM) based time series prediction networks within this architecture.\nWe observed that the ancillary neural network helps to improve the prediction\naccuracy, the maximum and the minimum temperature prediction and model\nreliability for all networks tested.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 18:38:28 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Ding", "Zhicheng", ""], ["Turkcan", "Mehmet Kerem", ""], ["Boulanger", "Albert", ""]]}, {"id": "1902.06787", "submitter": "Gregory Plumb", "authors": "Gregory Plumb, Maruan Al-Shedivat, Angel Alexander Cabrera, Adam\n  Perer, Eric Xing, Ameet Talwalkar", "title": "Regularizing Black-box Models for Improved Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the work on interpretable machine learning has focused on designing\neither inherently interpretable models, which typically trade-off accuracy for\ninterpretability, or post-hoc explanation systems, whose explanation quality\ncan be unpredictable. Our method, ExpO, is a hybridization of these approaches\nthat regularizes a model for explanation quality at training time. Importantly,\nthese regularizers are differentiable, model agnostic, and require no domain\nknowledge to define. We demonstrate that post-hoc explanations for\nExpO-regularized models have better explanation quality, as measured by the\ncommon fidelity and stability metrics. We verify that improving these metrics\nleads to significantly more useful explanations with a user study on a\nrealistic task.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 20:23:12 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 18:22:10 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 16:58:08 GMT"}, {"version": "v4", "created": "Wed, 18 Mar 2020 13:39:44 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 13:44:12 GMT"}, {"version": "v6", "created": "Sun, 8 Nov 2020 15:49:08 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Plumb", "Gregory", ""], ["Al-Shedivat", "Maruan", ""], ["Cabrera", "Angel Alexander", ""], ["Perer", "Adam", ""], ["Xing", "Eric", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1902.06789", "submitter": "Oscar Chang", "authors": "Oscar Chang, Hod Lipson", "title": "Seven Myths in Machine Learning Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present seven myths commonly believed to be true in machine learning\nresearch, circa Feb 2019. This is an archival copy of the blog post at\nhttps://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/\n  Myth 1: TensorFlow is a Tensor manipulation library\n  Myth 2: Image datasets are representative of real images found in the wild\n  Myth 3: Machine Learning researchers do not use the test set for validation\n  Myth 4: Every datapoint is used in training a neural network\n  Myth 5: We need (batch) normalization to train very deep residual networks\n  Myth 6: Attention $>$ Convolution\n  Myth 7: Saliency maps are robust ways to interpret neural networks\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 20:38:14 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 07:33:33 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Chang", "Oscar", ""], ["Lipson", "Hod", ""]]}, {"id": "1902.06797", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Simon Durand, Sebastian Ewert", "title": "End-to-end Lyrics Alignment for Polyphonic Music Using an\n  Audio-to-Character Recognition Model", "comments": "5 pages (1 for references), 2 figures, 2 tables. Camera-ready\n  version, accepted at the International Conference on Acoustics, Speech, and\n  Signal Processing 2019 (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-aligned lyrics can enrich the music listening experience by enabling\nkaraoke, text-based song retrieval and intra-song navigation, and other\napplications. Compared to text-to-speech alignment, lyrics alignment remains\nhighly challenging, despite many attempts to combine numerous sub-modules\nincluding vocal separation and detection in an effort to break down the\nproblem. Furthermore, training required fine-grained annotations to be\navailable in some form. Here, we present a novel system based on a modified\nWave-U-Net architecture, which predicts character probabilities directly from\nraw audio using learnt multi-scale representations of the various signal\ncomponents. There are no sub-modules whose interdependencies need to be\noptimized. Our training procedure is designed to work with weak, line-level\nannotations available in the real world. With a mean alignment error of 0.35s\non a standard dataset our system outperforms the state-of-the-art by an order\nof magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 20:53:55 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Stoller", "Daniel", ""], ["Durand", "Simon", ""], ["Ewert", "Sebastian", ""]]}, {"id": "1902.06804", "submitter": "Alexander Wong", "authors": "Raymond Bond, Ansgar Koene, Alan Dix, Jennifer Boger, Maurice D.\n  Mulvenna, Mykola Galushka, Bethany Waterhouse Bradley, Fiona Browne, Hui\n  Wang, and Alexander Wong", "title": "Democratisation of Usable Machine Learning in Computer Vision", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many industries are now investing heavily in data science and automation to\nreplace manual tasks and/or to help with decision making, especially in the\nrealm of leveraging computer vision to automate many monitoring, inspection,\nand surveillance tasks. This has resulted in the emergence of the 'data\nscientist' who is conversant in statistical thinking, machine learning (ML),\ncomputer vision, and computer programming. However, as ML becomes more\naccessible to the general public and more aspects of ML become automated,\napplications leveraging computer vision are increasingly being created by\nnon-experts with less opportunity for regulatory oversight. This points to the\noverall need for more educated responsibility for these lay-users of usable ML\ntools in order to mitigate potentially unethical ramifications. In this paper,\nwe undertake a SWOT analysis to study the strengths, weaknesses, opportunities,\nand threats of building usable ML tools for mass adoption for important areas\nleveraging ML such as computer vision. The paper proposes a set of data science\nliteracy criteria for educating and supporting lay-users in the responsible\ndevelopment and deployment of ML applications.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 21:22:45 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Bond", "Raymond", ""], ["Koene", "Ansgar", ""], ["Dix", "Alan", ""], ["Boger", "Jennifer", ""], ["Mulvenna", "Maurice D.", ""], ["Galushka", "Mykola", ""], ["Bradley", "Bethany Waterhouse", ""], ["Browne", "Fiona", ""], ["Wang", "Hui", ""], ["Wong", "Alexander", ""]]}, {"id": "1902.06818", "submitter": "Rahul Gupta", "authors": "Rahul Gupta", "title": "Data augmentation for low resource sentiment analysis using generative\n  adversarial networks", "comments": "Accepted to International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a task that may suffer from a lack of data in certain\ncases, as the datasets are often generated and annotated by humans. In cases\nwhere data is inadequate for training discriminative models, generate models\nmay aid training via data augmentation. Generative Adversarial Networks (GANs)\nare one such model that has advanced the state of the art in several tasks,\nincluding as image and text generation. In this paper, I train GAN models on\nlow resource datasets, then use them for the purpose of data augmentation\ntowards improving sentiment classifier generalization. Given the constraints of\nlimited data, I explore various techniques to train the GAN models. I also\npresent an analysis of the quality of generated GAN data as more training data\nfor the GAN is made available. In this analysis, the generated data is\nevaluated as a test set (against a model trained on real data points) as well\nas a training set to train classification models. Finally, I also conduct a\nvisual analysis by projecting the generated and the real data into a\ntwo-dimensional space using the t-Distributed Stochastic Neighbor Embedding\n(t-SNE) method.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 22:13:00 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Gupta", "Rahul", ""]]}, {"id": "1902.06822", "submitter": "Yoni Choukroun", "authors": "Yoni Choukroun, Eli Kravchik, Fan Yang, Pavel Kisilev", "title": "Low-bit Quantization of Neural Networks for Efficient Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning methods use increasingly large deep neural networks\nto achieve state of the art results in various tasks. The gains in performance\ncome at the cost of a substantial increase in computation and storage\nrequirements. This makes real-time implementations on limited resources\nhardware a challenging task. One popular approach to address this challenge is\nto perform low-bit precision computations via neural network quantization.\nHowever, aggressive quantization generally entails a severe penalty in terms of\naccuracy, and often requires retraining of the network, or resorting to higher\nbit precision quantization. In this paper, we formalize the linear quantization\ntask as a Minimum Mean Squared Error (MMSE) problem for both weights and\nactivations, allowing low-bit precision inference without the need for full\nnetwork retraining. The main contributions of our approach are the\noptimizations of the constrained MSE problem at each layer of the network, the\nhardware aware partitioning of the network parameters, and the use of multiple\nlow precision quantized tensors for poorly approximated layers. The proposed\napproach allows 4 bits integer (INT4) quantization for deployment of pretrained\nmodels on limited hardware resources. Multiple experiments on various network\narchitectures show that the suggested method yields state of the art results\nwith minimal loss of tasks accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 22:28:34 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 08:12:15 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Choukroun", "Yoni", ""], ["Kravchik", "Eli", ""], ["Yang", "Fan", ""], ["Kisilev", "Pavel", ""]]}, {"id": "1902.06836", "submitter": "Tian Xie", "authors": "Tian Xie, Arthur France-Lanord, Yanming Wang, Yang Shao-Horn, Jeffrey\n  C. Grossman", "title": "Graph Dynamical Networks for Unsupervised Learning of Atomic Scale\n  Dynamics in Materials", "comments": "25 + 7 pages, 5 + 3 figures", "journal-ref": "Nat. Commun. 10, 2667 (2019)", "doi": "10.1038/s41467-019-10663-6", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamical processes that govern the performance of\nfunctional materials is essential for the design of next generation materials\nto tackle global energy and environmental challenges. Many of these processes\ninvolve the dynamics of individual atoms or small molecules in condensed\nphases, e.g. lithium ions in electrolytes, water molecules in membranes, molten\natoms at interfaces, etc., which are difficult to understand due to the\ncomplexity of local environments. In this work, we develop graph dynamical\nnetworks, an unsupervised learning approach for understanding atomic scale\ndynamics in arbitrary phases and environments from molecular dynamics\nsimulations. We show that important dynamical information can be learned for\nvarious multi-component amorphous material systems, which is difficult to\nobtain otherwise. With the large amounts of molecular dynamics data generated\neveryday in nearly every aspect of materials design, this approach provides a\nbroadly useful, automated tool to understand atomic scale dynamics in material\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 23:17:27 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 20:58:39 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Xie", "Tian", ""], ["France-Lanord", "Arthur", ""], ["Wang", "Yanming", ""], ["Shao-Horn", "Yang", ""], ["Grossman", "Jeffrey C.", ""]]}, {"id": "1902.06841", "submitter": "Dehao Wu", "authors": "Dehao Wu, Maziar Nekovee, and Yue Wang", "title": "An Adaptive Deep Learning Algorithm Based Autoencoder for Interference\n  Channels", "comments": "6 pages, 10 figures, 2nd MLN 2019 accepted", "journal-ref": "2nd IFIP International Conference on Machine Learning for\n  Networking 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) based autoencoder has shown great potential to\nsignificantly enhance the physical layer performance. In this paper, we present\na DL based autoencoder for interference channel. Based on a characterization of\na k-user Gaussian interference channel, where the interferences are classified\nas different levels from weak to very strong interferences based on a coupling\nparameter {\\alpha}, a DL neural network (NN) based autoencoder is designed to\ntrain the data set and decode the received signals. The performance such a DL\nautoencoder for different interference scenarios are studied, with {\\alpha}\nknown or partially known, where we assume that {\\alpha} is predictable but with\na varying up to 10\\% at the training stage. The results demonstrate that DL\nbased approach has a significant capability to mitigate the effect induced by a\npoor signal-to-noise ratio (SNR) and a high interference-to-noise ratio (INR).\nHowever, the enhancement depends on the knowledge of {\\alpha} as well as the\ninterference levels. The proposed DL approach performs well with {\\alpha} up to\n10\\% offset for weak interference level. For strong and very strong\ninterference channel, the offset of {\\alpha} needs to be constrained to less\nthan 5\\% and 2\\%, respectively, to maintain similar performance as {\\alpha} is\nknown.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 23:59:17 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 16:16:43 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Wu", "Dehao", ""], ["Nekovee", "Maziar", ""], ["Wang", "Yue", ""]]}, {"id": "1902.06853", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Arnaud Doucet, Judith Rousseau", "title": "On the Impact of the Activation Function on Deep Neural Networks\n  Training", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weight initialization and the activation function of deep neural networks\nhave a crucial impact on the performance of the training procedure. An\ninappropriate selection can lead to the loss of information of the input during\nforward propagation and the exponential vanishing/exploding of gradients during\nback-propagation. Understanding the theoretical properties of untrained random\nnetworks is key to identifying which deep networks may be trained successfully\nas recently demonstrated by Samuel et al (2017) who showed that for deep\nfeedforward neural networks only a specific choice of hyperparameters known as\nthe `Edge of Chaos' can lead to good performance. While the work by Samuel et\nal (2017) discuss trainability issues, we focus here on training acceleration\nand overall performance. We give a comprehensive theoretical analysis of the\nEdge of Chaos and show that we can indeed tune the initialization parameters\nand the activation function in order to accelerate the training and improve the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 00:50:19 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 18:52:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hayou", "Soufiane", ""], ["Doucet", "Arnaud", ""], ["Rousseau", "Judith", ""]]}, {"id": "1902.06862", "submitter": "Clark Zhang", "authors": "Clark Zhang, Arbaaz Khan, Santiago Paternain, Alejandro Ribeiro", "title": "Sufficiently Accurate Model Learning", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling how a robot interacts with the environment around it is an important\nprerequisite for designing control and planning algorithms. In fact, the\nperformance of controllers and planners is highly dependent on the quality of\nthe model. One popular approach is to learn data driven models in order to\ncompensate for inaccurate physical measurements and to adapt to systems that\nevolve over time. In this paper, we investigate a method to regularize model\nlearning techniques to provide better error characteristics for traditional\ncontrol and planning algorithms. This work proposes learning \"Sufficiently\nAccurate\" models of dynamics using a primal-dual method that can explicitly\nenforce constraints on the error in pre-defined parts of the state-space. The\nresult of this method is that the error characteristics of the learned model is\nmore predictable and can be better utilized by planning and control algorithms.\nThe characteristics of Sufficiently Accurate models are analyzed through\nexperiments on a simulated ball paddle system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 02:27:41 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 04:54:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Clark", ""], ["Khan", "Arbaaz", ""], ["Paternain", "Santiago", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1902.06865", "submitter": "William Fedus", "authors": "William Fedus, Carles Gelada, Yoshua Bengio, Marc G. Bellemare, Hugo\n  Larochelle", "title": "Hyperbolic Discounting and Learning over Multiple Horizons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) typically defines a discount factor as part of\nthe Markov Decision Process. The discount factor values future rewards by an\nexponential scheme that leads to theoretical convergence guarantees of the\nBellman equation. However, evidence from psychology, economics and neuroscience\nsuggests that humans and animals instead have hyperbolic time-preferences. In\nthis work we revisit the fundamentals of discounting in RL and bridge this\ndisconnect by implementing an RL agent that acts via hyperbolic discounting. We\ndemonstrate that a simple approach approximates hyperbolic discount functions\nwhile still using familiar temporal-difference learning techniques in RL.\nAdditionally, and independent of hyperbolic discounting, we make a surprising\ndiscovery that simultaneously learning value functions over multiple\ntime-horizons is an effective auxiliary task which often improves over a strong\nvalue-based RL agent, Rainbow.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 02:36:14 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 19:00:04 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 18:32:24 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Fedus", "William", ""], ["Gelada", "Carles", ""], ["Bengio", "Yoshua", ""], ["Bellemare", "Marc G.", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1902.06876", "submitter": "Nouamane Laanait", "authors": "Nouamane Laanait and Qian He and Albina Y. Borisevich", "title": "Reconstruction of 3-D Atomic Distortions from Electron Microscopy with\n  Deep Learning", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated superb efficacy in processing imaging data,\nyet its suitability in solving challenging inverse problems in scientific\nimaging has not been fully explored. Of immense interest is the determination\nof local material properties from atomically-resolved imaging, such as electron\nmicroscopy, where such information is encoded in subtle and complex data\nsignatures, and whose recovery and interpretation necessitate intensive\nnumerical simulations subject to the requirement of near-perfect knowledge of\nthe experimental setup. We demonstrate that an end-to-end deep learning model\ncan successfully recover 3-dimensional atomic distortions of a variety of oxide\nperovskite materials from a single 2-dimensional experimental scanning\ntransmission electron (STEM) micrograph, in the process resolving a\nlongstanding question in the recovery of 3-D atomic distortions from STEM\nexperiments. Our results indicate that deep learning is a promising approach to\nefficiently address unsolved inverse problems in scientific imaging and to\nunderpin novel material investigations at atomic resolution.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 03:31:53 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Laanait", "Nouamane", ""], ["He", "Qian", ""], ["Borisevich", "Albina Y.", ""]]}, {"id": "1902.06881", "submitter": "Zac Cranko", "authors": "Zac Cranko, Robert C. Williamson, Richard Nock", "title": "Proper-Composite Loss Functions in Arbitrary Dimensions", "comments": "lots of mistakes!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of a machine learning problem is in many ways is difficult to\nseparate from the study of the loss function being used. One avenue of inquiry\nhas been to look at these loss functions in terms of their properties as\nscoring rules via the proper-composite representation, in which predictions are\nmapped to probability distributions which are then scored via a scoring rule.\nHowever, recent research so far has primarily been concerned with analysing the\n(typically) finite-dimensional conditional risk problem on the output space,\nleaving aside the larger total risk minimisation. We generalise a number of\nthese results to an infinite dimensional setting and in doing so we are able to\nexploit the familial resemblance of density and conditional density estimation\nto provide a simple characterisation of the canonical link.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 03:56:01 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 04:45:08 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cranko", "Zac", ""], ["Williamson", "Robert C.", ""], ["Nock", "Richard", ""]]}, {"id": "1902.06888", "submitter": "James Stokes", "authors": "James Stokes and John Terilla", "title": "Probabilistic Modeling with Matrix Product States", "comments": null, "journal-ref": null, "doi": "10.3390/e21121236", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the possibility that generative models based on quantum circuits\ncan provide a useful inductive bias for sequence modeling tasks, we propose an\nefficient training algorithm for a subset of classically simulable quantum\ncircuit models. The gradient-free algorithm, presented as a sequence of exactly\nsolvable effective models, is a modification of the density matrix\nrenormalization group procedure adapted for learning a probability\ndistribution. The conclusion that circuit-based models offer a useful inductive\nbias for classical datasets is supported by experimental results on the parity\nlearning problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 04:22:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Stokes", "James", ""], ["Terilla", "John", ""]]}, {"id": "1902.06894", "submitter": "Abdullah Al-Dujaili", "authors": "Abdullah Al-Dujaili and Una-May O'Reilly", "title": "There are No Bit Parts for Sign Bits in Black-Box Attacks", "comments": "Added results of Ensemble Adv Learning. ICML template", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a black-box adversarial attack algorithm which sets new\nstate-of-the-art model evasion rates for query efficiency in the $\\ell_\\infty$\nand $\\ell_2$ metrics, where only loss-oracle access to the model is available.\nOn two public black-box attack challenges, the algorithm achieves the highest\nevasion rate, surpassing all of the submitted attacks. Similar performance is\nobserved on a model that is secure against substitute-model attacks. For\nstandard models trained on the MNIST, CIFAR10, and IMAGENET datasets, averaged\nover the datasets and metrics, the algorithm is 3.8x less failure-prone, and\nspends in total 2.5x fewer queries than the current state-of-the-art attacks\ncombined given a budget of 10, 000 queries per attack attempt. Notably, it\nrequires no hyperparameter tuning or any data/time-dependent prior. The\nalgorithm exploits a new approach, namely sign-based rather than\nmagnitude-based gradient estimation. This shifts the estimation from continuous\nto binary black-box optimization. With three properties of the directional\nderivative, we examine three approaches to adversarial attacks. This yields a\nsuperior algorithm breaking a standard MNIST model using just 12 queries on\naverage!\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 05:01:23 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 15:33:04 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 23:30:06 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 15:22:51 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Al-Dujaili", "Abdullah", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1902.06913", "submitter": "Shaojie Xu", "authors": "Shaojie Xu, Sihan Zeng, Justin Romberg", "title": "Fast Compressive Sensing Recovery Using Generative Models with\n  Structured Latent Variables", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683641", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have significantly improved the visual quality and\naccuracy on compressive sensing recovery. In this paper, we propose an\nalgorithm for signal reconstruction from compressed measurements with image\npriors captured by a generative model. We search and constrain on latent\nvariable space to make the method stable when the number of compressed\nmeasurements is extremely limited. We show that, by exploiting certain\nstructures of the latent variables, the proposed method produces improved\nreconstruction accuracy and preserves realistic and non-smooth features in the\nimage. Our algorithm achieves high computation speed by projecting between the\noriginal signal space and the latent variable space in an alternating fashion.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:18:59 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 02:27:16 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 17:08:57 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 16:16:54 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Xu", "Shaojie", ""], ["Zeng", "Sihan", ""], ["Romberg", "Justin", ""]]}, {"id": "1902.06916", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler, Wasim Huleihel", "title": "Universality of Computational Lower Bounds for Submatrix Detection", "comments": "46 pages, accepted for presentation at Conference on Learning Theory\n  (COLT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the general submatrix detection problem, the task is to detect the\npresence of a small $k \\times k$ submatrix with entries sampled from a\ndistribution $\\mathcal{P}$ in an $n \\times n$ matrix of samples from\n$\\mathcal{Q}$. This formulation includes a number of well-studied problems,\nsuch as biclustering when $\\mathcal{P}$ and $\\mathcal{Q}$ are Gaussians and the\nplanted dense subgraph formulation of community detection when the submatrix is\na principal minor and $\\mathcal{P}$ and $\\mathcal{Q}$ are Bernoulli random\nvariables. These problems all seem to exhibit a universal phenomenon: there is\na statistical-computational gap depending on $\\mathcal{P}$ and $\\mathcal{Q}$\nbetween the minimum $k$ at which this task can be solved and the minimum $k$ at\nwhich it can be solved in polynomial time. Our main result is to tightly\ncharacterize this computational barrier as a tradeoff between $k$ and the KL\ndivergences between $\\mathcal{P}$ and $\\mathcal{Q}$ through average-case\nreductions from the planted clique conjecture. These computational lower bounds\nhold given mild assumptions on $\\mathcal{P}$ and $\\mathcal{Q}$ arising\nnaturally from classical binary hypothesis testing. Our results recover and\ngeneralize the planted clique lower bounds for Gaussian biclustering in Ma-Wu\n(2015) and Brennan et al. (2018) and for the sparse and general regimes of\nplanted dense subgraph in Hajek et al. (2015) and Brennan et al. (2018). This\nyields the first universality principle for computational lower bounds obtained\nthrough average-case reductions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:37:02 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 05:01:18 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 17:05:34 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Huleihel", "Wasim", ""]]}, {"id": "1902.06918", "submitter": "Seojin Bang", "authors": "Seojin Bang, Pengtao Xie, Heewook Lee, Wei Wu, and Eric Xing", "title": "Explaining a black-box using Deep Variational Information Bottleneck\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Interpretable machine learning has gained much attention recently. Briefness\nand comprehensiveness are necessary in order to provide a large amount of\ninformation concisely when explaining a black-box decision system. However,\nexisting interpretable machine learning methods fail to consider briefness and\ncomprehensiveness simultaneously, leading to redundant explanations. We propose\nthe variational information bottleneck for interpretation, VIBI, a\nsystem-agnostic interpretable method that provides a brief but comprehensive\nexplanation. VIBI adopts an information theoretic principle, information\nbottleneck principle, as a criterion for finding such explanations. For each\ninstance, VIBI selects key features that are maximally compressed about an\ninput (briefness), and informative about a decision made by a black-box system\non that input (comprehensive). We evaluate VIBI on three datasets and compare\nwith state-of-the-art interpretable machine learning methods in terms of both\ninterpretability and fidelity evaluated by human and quantitative metrics\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:42:05 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 08:24:25 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Bang", "Seojin", ""], ["Xie", "Pengtao", ""], ["Lee", "Heewook", ""], ["Wu", "Wei", ""], ["Xing", "Eric", ""]]}, {"id": "1902.06927", "submitter": "Kele Xu", "authors": "Chaojie Zhao and Peng Zhang and Jian Zhu and Chengrui Wu and Huaimin\n  Wang and Kele Xu", "title": "Predicting tongue motion in unlabeled ultrasound videos using\n  convolutional LSTM neural network", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge in speech production research is to predict future tongue\nmovements based on a short period of past tongue movements. This study tackles\nspeaker-dependent tongue motion prediction problem in unlabeled ultrasound\nvideos with convolutional long short-term memory (ConvLSTM) networks. The model\nhas been tested on two different ultrasound corpora. ConvLSTM outperforms\n3-dimensional convolutional neural network (3DCNN) in predicting the\n9\\textsuperscript{th} frames based on 8 preceding frames, and also demonstrates\ngood capacity to predict only the tongue contours in future frames. Further\ntests reveal that ConvLSTM can also learn to predict tongue movements in more\ndistant frames beyond the immediately following frames. Our codes are available\nat: https://github.com/shuiliwanwu/ConvLstm-ultrasound-videos.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 07:11:28 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Zhao", "Chaojie", ""], ["Zhang", "Peng", ""], ["Zhu", "Jian", ""], ["Wu", "Chengrui", ""], ["Wang", "Huaimin", ""], ["Xu", "Kele", ""]]}, {"id": "1902.06931", "submitter": "Erwan Scornet", "authors": "Julie Josse (CMAP, XPOP), Nicolas Prost (CMAP, XPOP, PARIETAL), Erwan\n  Scornet (X, CMAP), Ga\\\"el Varoquaux (PARIETAL)", "title": "On the consistency of supervised learning with missing values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application settings, the data have missing entries which make\nanalysis challenging. An abundant literature addresses missing values in an\ninferential framework: estimating parameters and their variance from incomplete\ntables. Here, we consider supervised-learning settings: predicting a target\nwhen missing values appear in both training and testing data. We show the\nconsistency of two approaches in prediction. A striking result is that the\nwidely-used method of imputing with a constant, such as the mean prior to\nlearning is consistent when missing values are not informative. This contrasts\nwith inferential settings where mean imputation is pointed at for distorting\nthe distribution of the data. That such a simple approach can be consistent is\nimportant in practice. We also show that a predictor suited for complete\nobservations can predict optimally on incomplete data,through multiple\nimputation.Finally, to compare imputation with learning directly with a model\nthat accounts for missing values, we analyze further decision trees. These can\nnaturally tackle empirical risk minimization with missing values, due to their\nability to handle the half-discrete nature of incomplete variables. After\ncomparing theoretically and empirically different missing values strategies in\ntrees, we recommend using the \"missing incorporated in attribute\" method as it\ncan handle both non-informative and informative missing values.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 07:27:19 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 15:26:55 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 15:12:20 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Josse", "Julie", "", "CMAP, XPOP"], ["Prost", "Nicolas", "", "CMAP, XPOP, PARIETAL"], ["Scornet", "Erwan", "", "X, CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"]]}, {"id": "1902.06937", "submitter": "Alexey Zaytsev", "authors": "Leonid Matyushin, Alexey Zaytsev, Oleg Alenkin, Andrey Ustuzhanin", "title": "Multifidelity Bayesian Optimization for Binomial Output", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key idea of Bayesian optimization is replacing an expensive target\nfunction with a cheap surrogate model. By selection of an acquisition function\nfor Bayesian optimization, we trade off between exploration and exploitation.\nThe acquisition function typically depends on the mean and the variance of the\nsurrogate model at a given point.\n  The most common Gaussian process-based surrogate model assumes that the\ntarget with fixed parameters is a realization of a Gaussian process. However,\noften the target function doesn't satisfy this approximation. Here we consider\ntarget functions that come from the binomial distribution with the parameter\nthat depends on inputs. Typically we can vary how many Bernoulli samples we\nobtain during each evaluation.\n  We propose a general Gaussian process model that takes into account Bernoulli\noutputs. To make things work we consider a simple acquisition function based on\nExpected Improvement and a heuristic strategy to choose the number of samples\nat each point thus taking into account precision of the obtained output.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 07:46:32 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Matyushin", "Leonid", ""], ["Zaytsev", "Alexey", ""], ["Alenkin", "Oleg", ""], ["Ustuzhanin", "Andrey", ""]]}, {"id": "1902.06938", "submitter": "Ce Wang", "authors": "Ce Wang, Zhangling Chen and Kun Shang", "title": "Label-Removed Generative Adversarial Networks Incorporating with K-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have achieved great success in\ngenerating realistic images. Most of these are conditional models, although\nacquisition of class labels is expensive and time-consuming in practice. To\nreduce the dependence on labeled data, we propose an un-conditional generative\nadversarial model, called K-Means-GAN (KM-GAN), which incorporates the idea of\nupdating centers in K-Means into GANs. Specifically, we redesign the framework\nof GANs by applying K-Means on the features extracted from the discriminator.\nWith obtained labels from K-Means, we propose new objective functions from the\nperspective of deep metric learning (DML). Distinct from previous works, the\ndiscriminator is treated as a feature extractor rather than a classifier in\nKM-GAN, meanwhile utilization of K-Means makes features of the discriminator\nmore representative. Experiments are conducted on various datasets, such as\nMNIST, Fashion-10, CIFAR-10 and CelebA, and show that the quality of samples\ngenerated by KM-GAN is comparable to some conditional generative adversarial\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 07:48:07 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Wang", "Ce", ""], ["Chen", "Zhangling", ""], ["Shang", "Kun", ""]]}, {"id": "1902.06958", "submitter": "Ioannis Panageas", "authors": "Sai Ganesh Nagarajan and Ioannis Panageas", "title": "On the Analysis of EM for truncated mixtures of two Gaussians", "comments": "Appeared in ALT 2020. Last version fixes statement about rates for\n  single dimensional case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a recent result of Daskalakis et al. 2018, we analyze the\npopulation version of Expectation-Maximization (EM) algorithm for the case of\n\\textit{truncated} mixtures of two Gaussians. Truncated samples from a\n$d$-dimensional mixture of two Gaussians $\\frac{1}{2} \\mathcal{N}(\\vec{\\mu},\n\\vec{\\Sigma})+ \\frac{1}{2} \\mathcal{N}(-\\vec{\\mu}, \\vec{\\Sigma})$ means that a\nsample is only revealed if it falls in some subset $S \\subset \\mathbb{R}^d$ of\npositive (Lebesgue) measure. We show that for $d=1$, EM converges almost surely\n(under random initialization) to the true mean (variance $\\sigma^2$ is known)\nfor any measurable set $S$. Moreover, for $d>1$ we show EM almost surely\nconverges to the true mean for any measurable set $S$ when the map of EM has\nonly three fixed points, namely $-\\vec{\\mu}, \\vec{0}, \\vec{\\mu}$ (covariance\nmatrix $\\vec{\\Sigma}$ is known), and prove local convergence if there are more\nthan three fixed points. We also provide convergence rates of our findings. Our\ntechniques deviate from those of Daskalakis et al. 2017, which heavily depend\non symmetry that the untruncated problem exhibits. For example, for an\narbitrary measurable set $S$, it is impossible to compute a closed form of the\nupdate rule of EM. Moreover, arbitrarily truncating the mixture, induces\nfurther correlations among the variables. We circumvent these challenges by\nusing techniques from dynamical systems, probability and statistics; implicit\nfunction theorem, stability analysis around the fixed points of the update rule\nof EM and correlation inequalities (FKG).\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 09:16:00 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 11:10:17 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 02:44:40 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 05:34:37 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 04:30:02 GMT"}, {"version": "v6", "created": "Sat, 9 May 2020 10:18:47 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Nagarajan", "Sai Ganesh", ""], ["Panageas", "Ioannis", ""]]}, {"id": "1902.06965", "submitter": "Dmitry Ivanov", "authors": "Dmitry Ivanov", "title": "DEDPUL: Difference-of-Estimated-Densities-based Positive-Unlabeled\n  Learning", "comments": "Implementation of DEDPUL and experimental data are available at\n  https://github.com/dimonenka/DEDPUL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive-Unlabeled (PU) learning is an analog to supervised binary\nclassification for the case when only the positive sample is clean, while the\nnegative sample is contaminated with latent instances of positive class and\nhence can be considered as an unlabeled mixture. The objectives are to classify\nthe unlabeled sample and train an unbiased PN classifier, which generally\nrequires to identify the mixing proportions of positives and negatives first.\nRecently, unbiased risk estimation framework has achieved state-of-the-art\nperformance in PU learning. This approach, however, exhibits two major\nbottlenecks. First, the mixing proportions are assumed to be identified, i.e.\nknown in the domain or estimated with additional methods. Second, the approach\nrelies on the classifier being a neural network. In this paper, we propose\nDEDPUL, a method that solves PU Learning without the aforementioned issues. The\nmechanism behind DEDPUL is to apply a computationally cheap post-processing\nprocedure to the predictions of any classifier trained to distinguish positive\nand unlabeled data. Instead of assuming the proportions to be identified,\nDEDPUL estimates them alongside with classifying unlabeled sample. Experiments\nshow that DEDPUL outperforms the current state-of-the-art in both proportion\nestimation and PU Classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 09:30:53 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 11:49:03 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 14:55:22 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 00:11:21 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 13:40:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ivanov", "Dmitry", ""]]}, {"id": "1902.06977", "submitter": "David Widmann", "authors": "Juozas Vaicenavicius, David Widmann, Carl Andersson, Fredrik Lindsten,\n  Jacob Roll, Thomas B. Sch\\\"on", "title": "Evaluating model calibration in classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic classifiers output a probability distribution on target classes\nrather than just a class prediction. Besides providing a clear separation of\nprediction and decision making, the main advantage of probabilistic models is\ntheir ability to represent uncertainty about predictions. In safety-critical\napplications, it is pivotal for a model to possess an adequate sense of\nuncertainty, which for probabilistic classifiers translates into outputting\nprobability distributions that are consistent with the empirical frequencies\nobserved from realized outcomes. A classifier with such a property is called\ncalibrated. In this work, we develop a general theoretical calibration\nevaluation framework grounded in probability theory, and point out subtleties\npresent in model calibration evaluation that lead to refined interpretations of\nexisting evaluation techniques. Lastly, we propose new ways to quantify and\nvisualize miscalibration in probabilistic classification, including novel\nmultidimensional reliability diagrams.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 09:59:42 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Vaicenavicius", "Juozas", ""], ["Widmann", "David", ""], ["Andersson", "Carl", ""], ["Lindsten", "Fredrik", ""], ["Roll", "Jacob", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1902.06992", "submitter": "Zebang Shen", "authors": "Hamed Hassani, Amin Karbasi, Aryan Mokhtari, Zebang Shen", "title": "Stochastic Conditional Gradient++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the general non-oblivious stochastic optimization\nwhere the underlying stochasticity may change during the optimization procedure\nand depends on the point at which the function is evaluated. We develop\nStochastic Frank-Wolfe++ ($\\text{SFW}{++} $), an efficient variant of the\nconditional gradient method for minimizing a smooth non-convex function subject\nto a convex body constraint. We show that $\\text{SFW}{++} $ converges to an\n$\\epsilon$-first order stationary point by using $O(1/\\epsilon^3)$ stochastic\ngradients. Once further structures are present, $\\text{SFW}{++}$'s theoretical\nguarantees, in terms of the convergence rate and quality of its solution,\nimprove. In particular, for minimizing a convex function, $\\text{SFW}{++} $\nachieves an $\\epsilon$-approximate optimum while using $O(1/\\epsilon^2)$\nstochastic gradients. It is known that this rate is optimal in terms of\nstochastic gradient evaluations. Similarly, for maximizing a monotone\ncontinuous DR-submodular function, a slightly different form of $\\text{SFW}{++}\n$, called Stochastic Continuous Greedy++ ($\\text{SCG}{++} $), achieves a tight\n$[(1-1/e)\\text{OPT} -\\epsilon]$ solution while using $O(1/\\epsilon^2)$\nstochastic gradients. Through an information theoretic argument, we also prove\nthat $\\text{SCG}{++} $'s convergence rate is optimal. Finally, for maximizing a\nnon-monotone continuous DR-submodular function, we can achieve a\n$[(1/e)\\text{OPT} -\\epsilon]$ solution by using $O(1/\\epsilon^2)$ stochastic\ngradients. We should highlight that our results and our novel variance\nreduction technique trivially extend to the standard and easier oblivious\nstochastic optimization settings for (non-)covex and continuous submodular\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 11:04:55 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 01:07:01 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 02:39:14 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 21:02:23 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""], ["Mokhtari", "Aryan", ""], ["Shen", "Zebang", ""]]}, {"id": "1902.07015", "submitter": "Olivier Sigaud", "authors": "Chenyang Zhao, Olivier Sigaud, Freek Stulp, Timothy M. Hospedales", "title": "Investigating Generalisation in Continuous Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has shown great success in a variety of control\ntasks. However, it is unclear how close we are to the vision of putting Deep RL\ninto practice to solve real world problems. In particular, common practice in\nthe field is to train policies on largely deterministic simulators and to\nevaluate algorithms through training performance alone, without a train/test\ndistinction to ensure models generalise and are not overfitted. Moreover, it is\nnot standard practice to check for generalisation under domain shift, although\nrobustness to such system change between training and testing would be\nnecessary for real-world Deep RL control, for example, in robotics. In this\npaper we study these issues by first characterising the sources of uncertainty\nthat provide generalisation challenges in Deep RL. We then provide a new\nbenchmark and thorough empirical evaluation of generalisation challenges for\nstate of the art Deep RL methods. In particular, we show that, if\ngeneralisation is the goal, then common practice of evaluating algorithms based\non their training performance leads to the wrong conclusions about algorithm\nchoice. Finally, we evaluate several techniques for improving generalisation\nand draw conclusions about the most robust techniques to date.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 12:20:36 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:19:07 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Zhao", "Chenyang", ""], ["Sigaud", "Olivier", ""], ["Stulp", "Freek", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1902.07068", "submitter": "Laura Anderlucci", "authors": "Laura Anderlucci, Lucia Guastadisegni, Cinzia Viroli", "title": "Classifying textual data: shallow, deep and ensemble methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a comparative evaluation of the most common and modern\nmethods for text classification, including the recent deep learning strategies\nand ensemble methods. The study is motivated by a challenging real data\nproblem, characterized by high-dimensional and extremely sparse data, deriving\nfrom incoming calls to the customer care of an Italian phone company. We will\nshow that deep learning outperforms many classical (shallow) strategies but the\ncombination of shallow and deep learning methods in a unique ensemble\nclassifier may improve the robustness and the accuracy of \"single\"\nclassification methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 15:47:35 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Anderlucci", "Laura", ""], ["Guastadisegni", "Lucia", ""], ["Viroli", "Cinzia", ""]]}, {"id": "1902.07087", "submitter": "Swetava Ganguli", "authors": "Jared Dunnmon, Swetava Ganguli, Darren Hau, Brooke Husic", "title": "Predicting US State-Level Agricultural Sentiment as a Measure of Food\n  Security with Tweets from Farming Communities", "comments": "Second revised version corrects typographical errors and adds a few\n  additional references", "journal-ref": null, "doi": null, "report-no": "Final report for research project conducted as part of the\n  Sustainability and Artificial Intelligence Laboratory (SAIL) at Stanford\n  University and the Winter 2017 offering of CS 224N Natural Language\n  Processing with Deep Learning", "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to obtain accurate food security metrics in developing areas\nwhere relevant data can be sparse is critically important for policy makers\ntasked with implementing food aid programs. As a result, a great deal of work\nhas been dedicated to predicting important food security metrics such as annual\ncrop yields using a variety of methods including simulation, remote sensing,\nweather models, and human expert input. As a complement to existing techniques\nin crop yield prediction, this work develops neural network models for\npredicting the sentiment of Twitter feeds from farming communities.\nSpecifically, we investigate the potential of both direct learning on a small\ndataset of agriculturally-relevant tweets and transfer learning from larger,\nwell-labeled sentiment datasets from other domains (e.g.~politics) to\naccurately predict agricultural sentiment, which we hope would ultimately serve\nas a useful crop yield predictor. We find that direct learning from small,\nrelevant datasets outperforms transfer learning from large, fully-labeled\ndatasets, that convolutional neural networks broadly outperform recurrent\nneural networks on Twitter sentiment classification, and that these models\nperform substantially less well on ternary sentiment problems characteristic of\npractical settings than on binary problems often found in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 20:29:00 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 20:00:59 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dunnmon", "Jared", ""], ["Ganguli", "Swetava", ""], ["Hau", "Darren", ""], ["Husic", "Brooke", ""]]}, {"id": "1902.07102", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Kimmo Karkkainen, Orpaz Goldstein, Davina\n  Zamanzadeh, and Majid Sarrafzadeh", "title": "Cost-Sensitive Diagnosis and Learning Leveraging Public Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, machine learning algorithms rely on the assumption that all\nfeatures of a given dataset are available for free. However, there are many\nconcerns such as monetary data collection costs, patient discomfort in medical\nprocedures, and privacy impacts of data collection that require careful\nconsideration in any real-world health analytics system. An efficient solution\nwould only acquire a subset of features based on the value it provides while\nconsidering acquisition costs. Moreover, datasets that provide feature costs\nare very limited, especially in healthcare. In this paper, we provide a health\ndataset as well as a method for assigning feature costs based on the total\nlevel of inconvenience asking for each feature entails. Furthermore, based on\nthe suggested dataset, we provide a comparison of recent and state-of-the-art\napproaches to cost-sensitive feature acquisition and learning. Specifically, we\nanalyze the performance of major sensitivity-based and reinforcement learning\nbased methods in the literature on three different problems in the health\ndomain, including diabetes, heart disease, and hypertension classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 15:37:13 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 22:28:15 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Goldstein", "Orpaz", ""], ["Zamanzadeh", "Davina", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1902.07104", "submitter": "Chen Xing", "authors": "Chen Xing, Negar Rostamzadeh, Boris N. Oreshkin, Pedro O. Pinheiro", "title": "Adaptive Cross-Modal Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric-based meta-learning techniques have successfully been applied to\nfew-shot classification problems. In this paper, we propose to leverage\ncross-modal information to enhance metric-based few-shot learning methods.\nVisual and semantic feature spaces have different structures by definition. For\ncertain concepts, visual features might be richer and more discriminative than\ntext ones. While for others, the inverse might be true. Moreover, when the\nsupport from visual information is limited in image classification, semantic\nrepresentations (learned from unsupervised text corpora) can provide strong\nprior knowledge and context to help learning. Based on these two intuitions, we\npropose a mechanism that can adaptively combine information from both\nmodalities according to new image categories to be learned. Through a series of\nexperiments, we show that by this adaptive combination of the two modalities,\nour model outperforms current uni-modality few-shot learning methods and\nmodality-alignment methods by a large margin on all benchmarks and few-shot\nscenarios tested. Experiments also show that our model can effectively adjust\nits focus on the two modalities. The improvement in performance is particularly\nlarge when the number of shots is very small.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 15:42:40 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 01:36:54 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 04:22:00 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xing", "Chen", ""], ["Rostamzadeh", "Negar", ""], ["Oreshkin", "Boris N.", ""], ["Pinheiro", "Pedro O.", ""]]}, {"id": "1902.07111", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu, Simon S. Du and Rachel Ward", "title": "Global Convergence of Adaptive Gradient Methods for An\n  Over-parameterized Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods like AdaGrad are widely used in optimizing neural\nnetworks. Yet, existing convergence guarantees for adaptive gradient methods\nrequire either convexity or smoothness, and, in the smooth setting, only\nguarantee convergence to a stationary point. We propose an adaptive gradient\nmethod and show that for two-layer over-parameterized neural networks -- if the\nwidth is sufficiently large (polynomially) -- then the proposed method\nconverges \\emph{to the global minimum} in polynomial time, and convergence is\nrobust, \\emph{ without the need to fine-tune hyper-parameters such as the\nstep-size schedule and with the level of over-parametrization independent of\nthe training error}. Our analysis indicates in particular that\nover-parametrization is crucial for the harnessing the full potential of\nadaptive gradient methods in the setting of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:08:55 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:07:24 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Du", "Simon S.", ""], ["Ward", "Rachel", ""]]}, {"id": "1902.07115", "submitter": "Jingyi Shi", "authors": "Jingyi Shi, Jialin Zhang, Yaorong Ge", "title": "An entropic feature selection method in perspective of Turing formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health data are generally complex in type and small in sample size. Such\ndomain-specific challenges make it difficult to capture information reliably\nand contribute further to the issue of generalization. To assist the analytics\nof healthcare datasets, we develop a feature selection method based on the\nconcept of Coverage Adjusted Standardized Mutual Information (CASMI). The main\nadvantages of the proposed method are: 1) it selects features more efficiently\nwith the help of an improved entropy estimator, particularly when the sample\nsize is small, and 2) it automatically learns the number of features to be\nselected based on the information from sample data. Additionally, the proposed\nmethod handles feature redundancy from the perspective of joint-distribution.\nThe proposed method focuses on non-ordinal data, while it works with numerical\ndata with an appropriate binning method. A simulation study comparing the\nproposed method to six widely cited feature selection methods shows that the\nproposed method performs better when measured by the Information Recovery\nRatio, particularly when the sample size is small.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:18:12 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Shi", "Jingyi", ""], ["Zhang", "Jialin", ""], ["Ge", "Yaorong", ""]]}, {"id": "1902.07119", "submitter": "Jieming Mao", "authors": "Nicole Immorlica, Jieming Mao, Aleksandrs Slivkins, Zhiwei Steven Wu", "title": "Bayesian Exploration with Heterogeneous Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common in recommendation systems that users both consume and produce\ninformation as they make strategic choices under uncertainty. While a social\nplanner would balance \"exploration\" and \"exploitation\" using a multi-armed\nbandit algorithm, users' incentives may tilt this balance in favor of\nexploitation. We consider Bayesian Exploration: a simple model in which the\nrecommendation system (the \"principal\") controls the information flow to the\nusers (the \"agents\") and strives to incentivize exploration via information\nasymmetry. A single round of this model is a version of a well-known \"Bayesian\nPersuasion game\" from [Kamenica and Gentzkow]. We allow heterogeneous users,\nrelaxing a major assumption from prior work that users have the same\npreferences from one time step to another. The goal is now to learn the best\npersonalized recommendations. One particular challenge is that it may be\nimpossible to incentivize some of the user types to take some of the actions,\nno matter what the principal does or how much time she has. We consider several\nversions of the model, depending on whether and when the user types are\nreported to the principal, and design a near-optimal \"recommendation policy\"\nfor each version. We also investigate how the model choice and the diversity of\nuser types impact the set of actions that can possibly be \"explored\" by each\ntype.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:22:43 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Immorlica", "Nicole", ""], ["Mao", "Jieming", ""], ["Slivkins", "Aleksandrs", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1902.07137", "submitter": "Stephen Vavasis", "authors": "Tao Jiang, Stephen Vavasis, Chen Wen Zhai", "title": "Recovery of a mixture of Gaussians by sum-of-norms clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-of-norms clustering is a method for assigning $n$ points in\n$\\mathbb{R}^d$ to $K$ clusters, $1\\le K\\le n$, using convex optimization.\nRecently, Panahi et al.\\ proved that sum-of-norms clustering is guaranteed to\nrecover a mixture of Gaussians under the restriction that the number of samples\nis not too large. The purpose of this note is to lift this restriction, i.e.,\nshow that sum-of-norms clustering with equal weights can recover a mixture of\nGaussians even as the number of samples tends to infinity. Our proof relies on\nan interesting characterization of clusters computed by sum-of-norms clustering\nthat was developed inside a proof of the agglomeration conjecture by Chiquet et\nal. Because we believe this theorem has independent interest, we restate and\nreprove the Chiquet et al.\\ result herein.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:49:02 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Jiang", "Tao", ""], ["Vavasis", "Stephen", ""], ["Zhai", "Chen Wen", ""]]}, {"id": "1902.07153", "submitter": "Felix Wu", "authors": "Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr., Christopher\n  Fifty, Tao Yu, Kilian Q. Weinberger", "title": "Simplifying Graph Convolutional Networks", "comments": "In ICML 2019. Code available at https://github.com/Tiiiger/SGC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) and their variants have experienced\nsignificant attention and have become the de facto methods for learning graph\nrepresentations. GCNs derive inspiration primarily from recent deep learning\napproaches, and as a result, may inherit unnecessary complexity and redundant\ncomputation. In this paper, we reduce this excess complexity through\nsuccessively removing nonlinearities and collapsing weight matrices between\nconsecutive layers. We theoretically analyze the resulting linear model and\nshow that it corresponds to a fixed low-pass filter followed by a linear\nclassifier. Notably, our experimental evaluation demonstrates that these\nsimplifications do not negatively impact accuracy in many downstream\napplications. Moreover, the resulting model scales to larger datasets, is\nnaturally interpretable, and yields up to two orders of magnitude speedup over\nFastGCN.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 17:21:15 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:22:43 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Wu", "Felix", ""], ["Zhang", "Tianyi", ""], ["Souza", "Amauri Holanda de", "Jr."], ["Fifty", "Christopher", ""], ["Yu", "Tao", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1902.07178", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Tara N. Sainath, Ron J. Weiss", "title": "A spelling correction model for end-to-end speech recognition", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models for speech recognition jointly\ntrain an acoustic model, language model (LM), and alignment mechanism using a\nsingle neural network and require only parallel audio-text pairs. Thus, the\nlanguage model component of the end-to-end model is only trained on transcribed\naudio-text pairs, which leads to performance degradation especially on rare\nwords. While there have been a variety of work that look at incorporating an\nexternal LM trained on text-only data into the end-to-end framework, none of\nthem have taken into account the characteristic error distribution made by the\nmodel. In this paper, we propose a novel approach to utilizing text-only data,\nby training a spelling correction (SC) model to explicitly correct those\nerrors. On the LibriSpeech dataset, we demonstrate that the proposed model\nresults in an 18.6% relative improvement in WER over the baseline model when\ndirectly correcting top ASR hypothesis, and a 29.0% relative improvement when\nfurther rescoring an expanded n-best list using an external LM.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:18:59 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Guo", "Jinxi", ""], ["Sainath", "Tara N.", ""], ["Weiss", "Ron J.", ""]]}, {"id": "1902.07181", "submitter": "Jacob Andreas", "authors": "Jacob Andreas", "title": "Measuring Compositionality in Representation Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning algorithms represent input data with vector embeddings\nor discrete codes. When inputs exhibit compositional structure (e.g. objects\nbuilt from parts or procedures from subroutines), it is natural to ask whether\nthis compositional structure is reflected in the the inputs' learned\nrepresentations. While the assessment of compositionality in languages has\nreceived significant attention in linguistics and adjacent fields, the machine\nlearning literature lacks general-purpose tools for producing graded\nmeasurements of compositional structure in more general (e.g. vector-valued)\nrepresentation spaces. We describe a procedure for evaluating compositionality\nby measuring how well the true representation-producing model can be\napproximated by a model that explicitly composes a collection of inferred\nrepresentational primitives. We use the procedure to provide formal and\nempirical characterizations of compositional structure in a variety of\nsettings, exploring the relationship between compositionality and learning\ndynamics, human judgments, representational similarity, and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:27:12 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 21:35:43 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Andreas", "Jacob", ""]]}, {"id": "1902.07186", "submitter": "Georgia Koppe", "authors": "Georgia Koppe, Hazem Toutounji, Peter Kirsch, Stefanie Lis, Daniel\n  Durstewitz", "title": "Identifying nonlinear dynamical systems via generative recurrent neural\n  networks with applications to fMRI", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1007263", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major tenet in theoretical neuroscience is that cognitive and behavioral\nprocesses are ultimately implemented in terms of the neural system dynamics.\nAccordingly, a major aim for the analysis of neurophysiological measurements\nshould lie in the identification of the computational dynamics underlying task\nprocessing. Here we advance a state space model (SSM) based on generative\npiecewise-linear recurrent neural networks (PLRNN) to assess dynamics from\nneuroimaging data. In contrast to many other nonlinear time series models which\nhave been proposed for reconstructing latent dynamics, our model is easily\ninterpretable in neural terms, amenable to systematic dynamical systems\nanalysis of the resulting set of equations, and can straightforwardly be\ntransformed into an equivalent continuous-time dynamical system. The major\ncontributions of this paper are the introduction of a new observation model\nsuitable for functional magnetic resonance imaging (fMRI) coupled to the latent\nPLRNN, an efficient stepwise training procedure that forces the latent model to\ncapture the 'true' underlying dynamics rather than just fitting (or predicting)\nthe observations, and of an empirical measure based on the Kullback-Leibler\ndivergence to evaluate from empirical time series how well this goal of\napproximating the underlying dynamics has been achieved. We validate and\nillustrate the power of our approach on simulated 'ground-truth' dynamical\n(benchmark) systems as well as on actual experimental fMRI time series, and\ndemonstrate that the latent dynamics harbors task-related nonlinear structure\nthat a linear dynamical model fails to capture. Given that fMRI is one of the\nmost common techniques for measuring brain activity non-invasively in human\nsubjects, this approach may provide a novel step toward analyzing aberrant\n(nonlinear) dynamics for clinical assessment or neuroscientific research.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:36:41 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 09:34:00 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Koppe", "Georgia", ""], ["Toutounji", "Hazem", ""], ["Kirsch", "Peter", ""], ["Lis", "Stefanie", ""], ["Durstewitz", "Daniel", ""]]}, {"id": "1902.07197", "submitter": "Amirhossein Taghvaei", "authors": "Amirhossein Taghvaei, Amin Jalali", "title": "2-Wasserstein Approximation via Restricted Convex Potentials with\n  Application to Improved Training for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework to approximate the 2-Wasserstein distance and the\noptimal transport map, amenable to efficient training as well as statistical\nand geometric analysis. With the quadratic cost and considering the Kantorovich\ndual form of the optimal transportation problem, the Brenier theorem states\nthat the optimal potential function is convex and the optimal transport map is\nthe gradient of the optimal potential function. Using this geometric structure,\nwe restrict the optimization problem to different parametrized classes of\nconvex functions and pay special attention to the class of input-convex neural\nnetworks. We analyze the statistical generalization and the discriminative\npower of the resulting approximate metric, and we prove a restricted\nmoment-matching property for the approximate optimal map. Finally, we discuss a\nnumerical algorithm to solve the restricted optimization problem and provide\nnumerical experiments to illustrate and compare the proposed approach with the\nestablished regularization-based approaches. We further discuss practical\nimplications of our proposal in a modular and interpretable design for GANs\nwhich connects the generator training with discriminator computations to allow\nfor learning an overall composite generator.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:49:22 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Taghvaei", "Amirhossein", ""], ["Jalali", "Amin", ""]]}, {"id": "1902.07198", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Chen Liang, Dale Schuurmans, Mohammad Norouzi", "title": "Learning to Generalize from Sparse and Underspecified Rewards", "comments": "ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:130-140, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from sparse and underspecified rewards,\nwhere an agent receives a complex input, such as a natural language\ninstruction, and needs to generate a complex response, such as an action\nsequence, while only receiving binary success-failure feedback. Such\nsuccess-failure rewards are often underspecified: they do not distinguish\nbetween purposeful and accidental success. Generalization from underspecified\nrewards hinges on discounting spurious trajectories that attain accidental\nsuccess, while learning from sparse feedback requires effective exploration. We\naddress exploration by using a mode covering direction of KL divergence to\ncollect a diverse set of successful trajectories, followed by a mode seeking KL\ndivergence to train a robust policy. We propose Meta Reward Learning (MeRL) to\nconstruct an auxiliary reward function that provides more refined feedback for\nlearning. The parameters of the auxiliary reward function are optimized with\nrespect to the validation performance of a trained policy. The MeRL approach\noutperforms our alternative reward learning technique based on Bayesian\nOptimization, and achieves the state-of-the-art on weakly-supervised semantic\nparsing. It improves previous work by 1.2% and 2.4% on WikiTableQuestions and\nWikiSQL datasets respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:51:10 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 07:21:04 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 18:21:10 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 20:54:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Liang", "Chen", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1902.07207", "submitter": "Rakshit Agrawal", "authors": "Rakshit Agrawal, Luca de Alfaro, Gabriele Ballarin, Stefano Moret,\n  Massimo Di Pierro, Eugenio Tacchini, Marco L. Della Vedova", "title": "Identifying Fake News from Twitter Sharing Data: A Large-Scale Study", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.08066", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks offer a ready channel for fake and misleading news to spread\nand exert influence. This paper examines the performance of different\nreputation algorithms when applied to a large and statistically significant\nportion of the news that are spread via Twitter. Our main result is that simple\ncrowdsourcing-based algorithms are able to identify a large portion of fake or\nmisleading news, while incurring only very low false positive rates for\nmainstream websites. We believe that these algorithms can be used as the basis\nof practical, large-scale systems for indicating to consumers which news sites\ndeserve careful scrutiny and skepticism.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 07:45:27 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Agrawal", "Rakshit", ""], ["de Alfaro", "Luca", ""], ["Ballarin", "Gabriele", ""], ["Moret", "Stefano", ""], ["Di Pierro", "Massimo", ""], ["Tacchini", "Eugenio", ""], ["Della Vedova", "Marco L.", ""]]}, {"id": "1902.07208", "submitter": "Chiyuan Zhang", "authors": "Maithra Raghu, Chiyuan Zhang, Jon Kleinberg and Samy Bengio", "title": "Transfusion: Understanding Transfer Learning for Medical Imaging", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning from natural image datasets, particularly ImageNet, using\nstandard large models and corresponding pretrained weights has become a\nde-facto method for deep learning applications to medical imaging. However,\nthere are fundamental differences in data sizes, features and task\nspecifications between natural image classification and the target medical\ntasks, and there is little understanding of the effects of transfer. In this\npaper, we explore properties of transfer learning for medical imaging. A\nperformance evaluation on two large scale medical imaging tasks shows that\nsurprisingly, transfer offers little benefit to performance, and simple,\nlightweight models can perform comparably to ImageNet architectures.\nInvestigating the learned representations and features, we find that some of\nthe differences from transfer learning are due to the over-parametrization of\nstandard models rather than sophisticated feature reuse. We isolate where\nuseful feature reuse occurs, and outline the implications for more efficient\nmodel exploration. We also explore feature independent benefits of transfer\narising from weight scalings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 01:54:53 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 00:37:48 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 20:16:30 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Raghu", "Maithra", ""], ["Zhang", "Chiyuan", ""], ["Kleinberg", "Jon", ""], ["Bengio", "Samy", ""]]}, {"id": "1902.07215", "submitter": "Sankalp Gilda", "authors": "Sankalp Gilda", "title": "Feature Selection for Better Spectral Characterization or: How I Learned\n  to Start Worrying and Love Ensembles", "comments": "4 pages, 1 figure, presented at Astronomical Data Analysis Software &\n  Systems (ADASS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.GA astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ever-looming threat to astronomical applications of machine learning is\nthe danger of over-fitting data, also known as the `curse of dimensionality.'\nThis occurs when there are fewer samples than the number of independent\nvariables. In this work, we focus on the problem of stellar parameterization\nfrom low-mid resolution spectra, with blended absorption lines. We address this\nproblem using an iterative algorithm to sequentially prune redundant features\nfrom synthetic PHOENIX spectra, and arrive at an optimal set of wavelengths\nwith the strongest correlation with each of the output variables -- T$_{\\rm\neff}$, $\\log g$, and [Fe/H]. We find that at any given resolution, most\nfeatures (i.e., absorption lines) are not only redundant, but actually act as\nnoise and decrease the accuracy of parameter retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:00:00 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 20:52:30 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gilda", "Sankalp", ""]]}, {"id": "1902.07234", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Learning Optimal Linear Regularizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for efficiently learning regularizers that improve\ngeneralization. Our approach is based on the insight that regularizers can be\nviewed as upper bounds on the generalization gap, and that reducing the slack\nin the bound can improve performance on test data. For a broad class of\nregularizers, the hyperparameters that give the best upper bound can be\ncomputed using linear programming. Under certain Bayesian assumptions, solving\nthe LP lets us \"jump\" to the optimal hyperparameters given very limited data.\nThis suggests a natural algorithm for tuning regularization hyperparameters,\nwhich we show to be effective on both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:10:17 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 22:33:46 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1902.07239", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Zheng Wen, Changyou Chen, Lawrence Carin", "title": "Scalable Thompson Sampling via Optimal Transport", "comments": "Infer to Control Workshop on Probabilistic Reinforcement Learning and\n  Structured Control at NIPS 2018; Long version accepted by AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling (TS) is a class of algorithms for sequential\ndecision-making, which requires maintaining a posterior distribution over a\nmodel. However, calculating exact posterior distributions is intractable for\nall but the simplest models. Consequently, efficient computation of an\napproximate posterior distribution is a crucial problem for scalable TS with\ncomplex models, such as neural networks. In this paper, we use distribution\noptimization techniques to approximate the posterior distribution, solved via\nWasserstein gradient flows. Based on the framework, a principled\nparticle-optimization algorithm is developed for TS to approximate the\nposterior efficiently. Our approach is scalable and does not make explicit\ndistribution assumptions on posterior approximations. Extensive experiments on\nboth synthetic data and real large-scale data demonstrate the superior\nperformance of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:15:08 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Wen", "Zheng", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1902.07243", "submitter": "Wenqi Fan", "authors": "Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, Dawei\n  Yin", "title": "Graph Neural Networks for Social Recommendation", "comments": "Accepted by WWW2019 Conference. Our code is available at\n  \\url{https://github.com/wenqifan03/GraphRec-WWW19}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Graph Neural Networks (GNNs), which can naturally integrate\nnode information and topological structure, have been demonstrated to be\npowerful in learning on graph data. These advantages of GNNs provide great\npotential to advance social recommendation since data in social recommender\nsystems can be represented as user-user social graph and user-item graph; and\nlearning latent factors of users and items is the key. However, building social\nrecommender systems based on GNNs faces challenges. For example, the user-item\ngraph encodes both interactions and their associated opinions; social relations\nhave heterogeneous strengths; users involve in two graphs (e.g., the user-user\nsocial graph and the user-item graph). To address the three aforementioned\nchallenges simultaneously, in this paper, we present a novel graph neural\nnetwork framework (GraphRec) for social recommendations. In particular, we\nprovide a principled approach to jointly capture interactions and opinions in\nthe user-item graph and propose the framework GraphRec, which coherently models\ntwo graphs and heterogeneous strengths. Extensive experiments on two real-world\ndatasets demonstrate the effectiveness of the proposed framework GraphRec. Our\ncode is available at \\url{https://github.com/wenqifan03/GraphRec-WWW19}\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:22:54 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 01:47:49 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Fan", "Wenqi", ""], ["Ma", "Yao", ""], ["Li", "Qing", ""], ["He", "Yuan", ""], ["Zhao", "Eric", ""], ["Tang", "Jiliang", ""], ["Yin", "Dawei", ""]]}, {"id": "1902.07247", "submitter": "Vicen\\c{c} Rubies-Royo", "authors": "Vicenc Rubies-Royo, Roberto Calandra, Dusan M. Stipanovic, Claire\n  Tomlin", "title": "Fast Neural Network Verification via Shadow Prices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To use neural networks in safety-critical settings it is paramount to provide\nassurances on their runtime operation. Recent work on ReLU networks has sought\nto verify whether inputs belonging to a bounded box can ever yield some\nundesirable output. Input-splitting procedures, a particular type of\nverification mechanism, do so by recursively partitioning the input set into\nsmaller sets. The efficiency of these methods is largely determined by the\nnumber of splits the box must undergo before the property can be verified. In\nthis work, we propose a new technique based on shadow prices that fully\nexploits the information of the problem yielding a more efficient generation of\nsplits than the state-of-the-art. Results on the Airborne Collision Avoidance\nSystem (ACAS) benchmark verification tasks show a considerable reduction in the\npartitions generated which substantially reduces computation times. These\nresults open the door to improved verification methods for a wide variety of\nmachine learning applications including vision and control.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:35:30 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 16:56:27 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 13:15:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Rubies-Royo", "Vicenc", ""], ["Calandra", "Roberto", ""], ["Stipanovic", "Dusan M.", ""], ["Tomlin", "Claire", ""]]}, {"id": "1902.07249", "submitter": "Seil Na", "authors": "Seil Na, Yo Joong Choe, Dong-Hyun Lee, Gunhee Kim", "title": "Discovery of Natural Language Concepts in Individual Units of CNNs", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional networks have achieved improved performance in\nmany natural language tasks, they have been treated as black boxes because they\nare difficult to interpret. Especially, little is known about how they\nrepresent language in their intermediate layers. In an attempt to understand\nthe representations of deep convolutional networks trained on language tasks,\nwe show that individual units are selectively responsive to specific morphemes,\nwords, and phrases, rather than responding to arbitrary and uninterpretable\npatterns. In order to quantitatively analyze such an intriguing phenomenon, we\npropose a concept alignment method based on how units respond to the replicated\ntext. We conduct analyses with different architectures on multiple datasets for\nclassification and translation tasks and provide new insights into how deep\nmodels understand natural language.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 06:19:14 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:05:10 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Na", "Seil", ""], ["Choe", "Yo Joong", ""], ["Lee", "Dong-Hyun", ""], ["Kim", "Gunhee", ""]]}, {"id": "1902.07257", "submitter": "Sheng Jia", "authors": "Sheng Jia, Jamie Kiros, Jimmy Ba", "title": "DOM-Q-NET: Grounded RL on Structured Language", "comments": "International Conference on Learning Representations (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building agents to interact with the web would allow for significant\nimprovements in knowledge understanding and representation learning. However,\nweb navigation tasks are difficult for current deep reinforcement learning (RL)\nmodels due to the large discrete action space and the varying number of actions\nbetween the states. In this work, we introduce DOM-Q-NET, a novel architecture\nfor RL-based web navigation to address both of these problems. It parametrizes\nQ functions with separate networks for different action categories: clicking a\nDOM element and typing a string input. Our model utilizes a graph neural\nnetwork to represent the tree-structured HTML of a standard web page. We\ndemonstrate the capabilities of our model on the MiniWoB environment where we\ncan match or outperform existing work without the use of expert demonstrations.\nFurthermore, we show 2x improvements in sample efficiency when training in the\nmulti-task setting, allowing our model to transfer learned behaviours across\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:54:15 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Jia", "Sheng", ""], ["Kiros", "Jamie", ""], ["Ba", "Jimmy", ""]]}, {"id": "1902.07275", "submitter": "Alexander Rivkind", "authors": "Doron Haviv, Alexander Rivkind and Omri Barak", "title": "Understanding and Controlling Memory in Recurrent Neural Networks", "comments": "The link to the code was changed due to technical issues with the\n  original repository. We no longer refer to the process shown in Figure 5C as\n  a bifurcation diagram, but describe it in a more precise manner. We thank an\n  anonymous reviewer for pointing this out", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be effective in sequential data processing, Recurrent Neural Networks\n(RNNs) are required to keep track of past events by creating memories. While\nthe relation between memories and the network's hidden state dynamics was\nestablished over the last decade, previous works in this direction were of a\npredominantly descriptive nature focusing mainly on locating the dynamical\nobjects of interest. In particular, it remained unclear how dynamical\nobservables affect the performance, how they form and whether they can be\nmanipulated. Here, we utilize different training protocols, datasets and\narchitectures to obtain a range of networks solving a delayed classification\ntask with similar performance, alongside substantial differences in their\nability to extrapolate for longer delays. We analyze the dynamics of the\nnetwork's hidden state, and uncover the reasons for this difference. Each\nmemory is found to be associated with a nearly steady state of the dynamics\nwhich we refer to as a 'slow point'. Slow point speeds predict extrapolation\nperformance across all datasets, protocols and architectures tested.\nFurthermore, by tracking the formation of the slow points we are able to\nunderstand the origin of differences between training protocols. Finally, we\npropose a novel regularization technique that is based on the relation between\nhidden state speeds and memory longevity. Our technique manipulates these\nspeeds, thereby leading to a dramatic improvement in memory robustness over\ntime, and could pave the way for a new class of regularization methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 20:48:38 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 17:42:06 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 14:20:15 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Haviv", "Doron", ""], ["Rivkind", "Alexander", ""], ["Barak", "Omri", ""]]}, {"id": "1902.07276", "submitter": "Tellen Bennett", "authors": "Tellen Bennett, Seth Russell, James King, Lisa Schilling, Chan Voong,\n  Nancy Rogers, Bonnie Adrian, Nicholas Bruce, Debashis Ghosh", "title": "Accuracy of the Epic Sepsis Prediction Model in a Regional Health System", "comments": "Presented at AMIA Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in an electronic health record-based computational model that can\naccurately predict a patient's risk of sepsis at a given point in time has\ngrown rapidly in the last several years. Like other EHR vendors, the Epic\nSystems Corporation has developed a proprietary sepsis prediction model (ESPM).\nEpic developed the model using data from three health systems and penalized\nlogistic regression. Demographic, comorbidity, vital sign, laboratory,\nmedication, and procedural variables contribute to the model. The objective of\nthis project was to compare the predictive performance of the ESPM with a\nregional health system's current Early Warning Score-based sepsis detection\nprogram.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 20:48:43 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Bennett", "Tellen", ""], ["Russell", "Seth", ""], ["King", "James", ""], ["Schilling", "Lisa", ""], ["Voong", "Chan", ""], ["Rogers", "Nancy", ""], ["Adrian", "Bonnie", ""], ["Bruce", "Nicholas", ""], ["Ghosh", "Debashis", ""]]}, {"id": "1902.07280", "submitter": "Chris Mesterharm", "authors": "Chris Mesterharm and Rauf Izmailov and Scott Alexander and Simon Tsang", "title": "Subspace Methods That Are Resistant to a Limited Number of Features\n  Corrupted by an Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider batch supervised learning where an adversary is\nallowed to corrupt instances with arbitrarily large noise. The adversary is\nallowed to corrupt any $l$ features in each instance and the adversary can\nchange their values in any way. This noise is introduced on test instances and\nthe algorithm receives no label feedback for these instances. We provide\nseveral subspace voting techniques that can be used to transform existing\nalgorithms and prove data-dependent performance bounds in this setting. The key\ninsight to our results is that we set our parameters so that a significant\nfraction of the voting hypotheses do not contain corrupt features and, for many\nreal world problems, these uncorrupt hypotheses are sufficient to achieve high\naccuracy. We empirically validate our approach on several datasets including\nthree new datasets that deal with side channel electromagnetic information.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 20:55:01 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 16:44:32 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mesterharm", "Chris", ""], ["Izmailov", "Rauf", ""], ["Alexander", "Scott", ""], ["Tsang", "Simon", ""]]}, {"id": "1902.07285", "submitter": "Wenqi Wang", "authors": "Wenqi Wang, Run Wang, Lina Wang, Zhibo Wang, Aoshuang Ye", "title": "Towards a Robust Deep Neural Network in Texts: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 02:42:54 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 08:25:47 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 11:26:42 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2019 09:15:28 GMT"}, {"version": "v5", "created": "Fri, 3 Jan 2020 03:12:31 GMT"}, {"version": "v6", "created": "Wed, 21 Apr 2021 10:14:36 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wang", "Wenqi", ""], ["Wang", "Run", ""], ["Wang", "Lina", ""], ["Wang", "Zhibo", ""], ["Ye", "Aoshuang", ""]]}, {"id": "1902.07286", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Jonathan Lee, Ken Goldberg, Byron Boots", "title": "Online Learning with Continuous Variations: Dynamic Regret and\n  Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning is a powerful tool for analyzing iterative algorithms.\nHowever, the classic adversarial setup sometimes fails to capture certain\nregularity in online problems in practice. Motivated by this, we establish a\nnew setup, called Continuous Online Learning (COL), where the gradient of\nonline loss function changes continuously across rounds with respect to the\nlearner's decisions. We show that COL covers and more appropriately describes\nmany interesting applications, from general equilibrium problems (EPs) to\noptimization in episodic MDPs. In particular, we show monotone EPs admits a\nreduction to achieving sublinear static regret in COL. Using this new setup, we\nrevisit the difficulty of sublinear dynamic regret. We prove a fundamental\nequivalence between achieving sublinear dynamic regret in COL and solving\ncertain EPs. With this insight, we offer conditions for efficient algorithms\nthat achieve sublinear dynamic regret, even when the losses are chosen\nadaptively without any a priori variation budget. Furthermore, we show for COL\na reduction from dynamic regret to both static regret and convergence in the\nassociated EP, allowing us to analyze the dynamic regret of many existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 21:07:10 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 20:12:19 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 04:54:36 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Cheng", "Ching-An", ""], ["Lee", "Jonathan", ""], ["Goldberg", "Ken", ""], ["Boots", "Byron", ""]]}, {"id": "1902.07292", "submitter": "Merlijn Blaauw", "authors": "Merlijn Blaauw, Jordi Bonada, Ryunosuke Daido", "title": "Data Efficient Voice Cloning for Neural Singing Synthesis", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many use cases in singing synthesis where creating voices from\nsmall amounts of data is desirable. In text-to-speech there have been several\npromising results that apply voice cloning techniques to modern deep learning\nbased models. In this work, we adapt one such technique to the case of singing\nsynthesis. By leveraging data from many speakers to first create a multispeaker\nmodel, small amounts of target data can then efficiently adapt the model to new\nunseen voices. We evaluate the system using listening tests across a number of\ndifferent use cases, languages and kinds of data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 21:31:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Blaauw", "Merlijn", ""], ["Bonada", "Jordi", ""], ["Daido", "Ryunosuke", ""]]}, {"id": "1902.07316", "submitter": "Amin Abbasloo", "authors": "Amin Abbasloo, and Alan Salari", "title": "Deep Modulation Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network has recently shown very promising applications in\ndifferent research directions and attracted the industry attention as well.\nAlthough the idea was introduced in the past but just recently the main\nlimitation of using this class of algorithms is solved by enabling parallel\ncomputing on GPU hardware. Opening the possibility of hardware prototyping with\nproven superiority of this class of algorithm, trigger several research\ndirections in communication system too. Among them cognitive radio, modulation\nrecognition, learning based receiver and transceiver are already given very\ninteresting result in simulation and real experimental evaluation implemented\non software defined radio. Specifically, modulation recognition is mostly\napproached as a classification problem which is a supervised learning\nframework. But it is here addressed as an unsupervised problem with introducing\nnew features for training, a new loss function and investigating the robustness\nof the pipeline against several mismatch conditions.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 19:37:33 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 10:21:01 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Abbasloo", "Amin", ""], ["Salari", "Alan", ""]]}, {"id": "1902.07355", "submitter": "Kirk Bansak", "authors": "Avidit Acharya, Kirk Bansak, Jens Hainmueller", "title": "Combining Outcome-Based and Preference-Based Matching: A Constrained\n  Priority Mechanism", "comments": "This manuscript has been accepted for publication by Political\n  Analysis and will appear in a revised form subject to peer review and/or\n  input from the journal's editor. End-users of this manuscript may only make\n  use of it for private research and study and may not distribute it further", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a constrained priority mechanism that combines outcome-based\nmatching from machine-learning with preference-based allocation schemes common\nin market design. Using real-world data, we illustrate how our mechanism could\nbe applied to the assignment of refugee families to host country locations, and\nkindergarteners to schools. Our mechanism allows a planner to first specify a\nthreshold $\\bar g$ for the minimum acceptable average outcome score that should\nbe achieved by the assignment. In the refugee matching context, this score\ncorresponds to the predicted probability of employment, while in the student\nassignment context it corresponds to standardized test scores. The mechanism is\na priority mechanism that considers both outcomes and preferences by assigning\nagents (refugee families, students) based on their preferences, but subject to\nmeeting the planner's specified threshold. The mechanism is both strategy-proof\nand constrained efficient in that it always generates a matching that is not\nPareto dominated by any other matching that respects the planner's threshold.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 00:17:33 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 01:41:28 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 17:22:34 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Acharya", "Avidit", ""], ["Bansak", "Kirk", ""], ["Hainmueller", "Jens", ""]]}, {"id": "1902.07358", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson, Lionel Mathelin, Zhewei Yao, Steven L. Brunton,\n  Michael W. Mahoney, J. Nathan Kutz", "title": "Shallow Neural Networks for Fluid Flow Reconstruction with Limited\n  Sensors", "comments": null, "journal-ref": "Proc. R. Soc. A476: 20200097 (2020)", "doi": "10.1098/rspa.2020.0097", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, it is important to reconstruct a fluid flow field, or\nsome other high-dimensional state, from limited measurements and limited data.\nIn this work, we propose a shallow neural network-based learning methodology\nfor such fluid flow reconstruction. Our approach learns an end-to-end mapping\nbetween the sensor measurements and the high-dimensional fluid flow field,\nwithout any heavy preprocessing on the raw data. No prior knowledge is assumed\nto be available, and the estimation method is purely data-driven. We\ndemonstrate the performance on three examples in fluid mechanics and\noceanography, showing that this modern data-driven approach outperforms\ntraditional modal approximation techniques which are commonly used for flow\nreconstruction. Not only does the proposed method show superior performance\ncharacteristics, it can also produce a comparable level of performance with\ntraditional methods in the area, using significantly fewer sensors. Thus, the\nmathematical architecture is ideal for emerging global monitoring technologies\nwhere measurement data are often limited.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 00:29:35 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 01:54:44 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Mathelin", "Lionel", ""], ["Yao", "Zhewei", ""], ["Brunton", "Steven L.", ""], ["Mahoney", "Michael W.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1902.07374", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Danwei Cai, Shen Huang and Ming Li", "title": "Utterance-level end-to-end language identification using attention-based\n  CNN-BLSTM", "comments": "Accepted for ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an end-to-end language identification framework,\nthe attention-based Convolutional Neural Network-Bidirectional Long-short Term\nMemory (CNN-BLSTM). The model is performed on the utterance level, which means\nthe utterance-level decision can be directly obtained from the output of the\nneural network. To handle speech utterances with entire arbitrary and\npotentially long duration, we combine CNN-BLSTM model with a self-attentive\npooling layer together. The front-end CNN-BLSTM module plays a role as local\npattern extractor for the variable-length inputs, and the following\nself-attentive pooling layer is built on top to get the fixed-dimensional\nutterance-level representation. We conducted experiments on NIST LRE07\nclosed-set task, and the results reveal that the proposed attention-based\nCNN-BLSTM model achieves comparable error reduction with other state-of-the-art\nutterance-level neural network approaches for all 3 seconds, 10 seconds, 30\nseconds duration tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:14:35 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Cai", "Weicheng", ""], ["Cai", "Danwei", ""], ["Huang", "Shen", ""], ["Li", "Ming", ""]]}, {"id": "1902.07376", "submitter": "Yishen Wang", "authors": "Yishen Wang, Xiao Lu, Yiran Xu, Di Shi, Zhehan Yi, Jiajun Duan, Zhiwei\n  Wang", "title": "Submodular Load Clustering with Robust Principal Component Analysis", "comments": "Accepted by 2019 IEEE PES General Meeting, Atlanta, GA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional load analysis is facing challenges with the new electricity usage\npatterns due to demand response as well as increasing deployment of distributed\ngenerations, including photovoltaics (PV), electric vehicles (EV), and energy\nstorage systems (ESS). At the transmission system, despite of irregular load\nbehaviors at different areas, highly aggregated load shapes still share similar\ncharacteristics. Load clustering is to discover such intrinsic patterns and\nprovide useful information to other load applications, such as load forecasting\nand load modeling. This paper proposes an efficient submodular load clustering\nmethod for transmission-level load areas. Robust principal component analysis\n(R-PCA) firstly decomposes the annual load profiles into low-rank components\nand sparse components to extract key features. A novel submodular cluster\ncenter selection technique is then applied to determine the optimal cluster\ncenters through constructed similarity graph. Following the selection results,\nload areas are efficiently assigned to different clusters for further load\nanalysis and applications. Numerical results obtained from PJM load demonstrate\nthe effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:23:07 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Wang", "Yishen", ""], ["Lu", "Xiao", ""], ["Xu", "Yiran", ""], ["Shi", "Di", ""], ["Yi", "Zhehan", ""], ["Duan", "Jiajun", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1902.07378", "submitter": "Martin Ingram", "authors": "Martin Ingram", "title": "Gaussian Process Priors for Dynamic Paired Comparison Modelling", "comments": "Code is available here:\n  https://github.com/martiningram/paired-comparison-gp-laplace", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic paired comparison models, such as Elo and Glicko, are frequently used\nfor sports prediction and ranking players or teams. We present an alternative\ndynamic paired comparison model which uses a Gaussian Process (GP) as a prior\nfor the time dynamics rather than the Markovian dynamics usually assumed. In\naddition, we show that the GP model can easily incorporate covariates. We\nderive an efficient approximate Bayesian inference procedure based on the\nLaplace Approximation and sparse linear algebra. We select hyperparameters by\nmaximising their marginal likelihood using Bayesian Optimisation, comparing the\nresults against random search. Finally, we fit and evaluate the model on the\n2018 season of ATP tennis matches, where it performs competitively,\noutperforming Elo and Glicko on log loss, particularly when surface covariates\nare included.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:27:55 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Ingram", "Martin", ""]]}, {"id": "1902.07379", "submitter": "Jun Shu", "authors": "Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, Deyu\n  Meng", "title": "Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current deep neural networks (DNNs) can easily overfit to biased training\ndata with corrupted labels or class imbalance. Sample re-weighting strategy is\ncommonly used to alleviate this issue by designing a weighting function mapping\nfrom training loss to sample weight, and then iterating between weight\nrecalculating and classifier updating. Current approaches, however, need\nmanually pre-specify the weighting function as well as its additional\nhyper-parameters. It makes them fairly hard to be generally applied in practice\ndue to the significant variation of proper weighting schemes relying on the\ninvestigated problem and training data. To address this issue, we propose a\nmethod capable of adaptively learning an explicit weighting function directly\nfrom data. The weighting function is an MLP with one hidden layer, constituting\na universal approximator to almost any continuous functions, making the method\nable to fit a wide range of weighting functions including those assumed in\nconventional research. Guided by a small amount of unbiased meta-data, the\nparameters of the weighting function can be finely updated simultaneously with\nthe learning process of the classifiers. Synthetic and real experiments\nsubstantiate the capability of our method for achieving proper weighting\nfunctions in class imbalance and noisy label cases, fully complying with the\ncommon settings in traditional methods, and more complicated scenarios beyond\nconventional cases. This naturally leads to its better accuracy than other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:29:55 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 15:02:28 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 04:14:01 GMT"}, {"version": "v4", "created": "Sun, 4 Aug 2019 16:20:21 GMT"}, {"version": "v5", "created": "Thu, 12 Sep 2019 09:04:15 GMT"}, {"version": "v6", "created": "Fri, 27 Sep 2019 02:48:20 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Shu", "Jun", ""], ["Xie", "Qi", ""], ["Yi", "Lixuan", ""], ["Zhao", "Qian", ""], ["Zhou", "Sanping", ""], ["Xu", "Zongben", ""], ["Meng", "Deyu", ""]]}, {"id": "1902.07380", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Optimal Average-Case Reductions to Sparse PCA: From Weak Assumptions to\n  Strong Hardness", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, sparse principal component analysis has emerged as an\narchetypal problem for illustrating statistical-computational tradeoffs. This\ntrend has largely been driven by a line of research aiming to characterize the\naverage-case complexity of sparse PCA through reductions from the planted\nclique (PC) conjecture - which conjectures that there is no polynomial-time\nalgorithm to detect a planted clique of size $K = o(N^{1/2})$ in\n$\\mathcal{G}(N, \\frac{1}{2})$. All previous reductions to sparse PCA either\nfail to show tight computational lower bounds matching existing algorithms or\nshow lower bounds for formulations of sparse PCA other than its canonical\ngenerative model, the spiked covariance model. Also, these lower bounds all\nquickly degrade with the exponent in the PC conjecture. Specifically, when only\ngiven the PC conjecture up to $K = o(N^\\alpha)$ where $\\alpha < 1/2$, there is\nno sparsity level $k$ at which these lower bounds remain tight. If $\\alpha \\le\n1/3$ these reductions fail to even show the existence of a\nstatistical-computational tradeoff at any sparsity $k$. We give a reduction\nfrom PC that yields the first full characterization of the computational\nbarrier in the spiked covariance model, providing tight lower bounds at all\nsparsities $k$. We also show the surprising result that weaker forms of the PC\nconjecture up to clique size $K = o(N^\\alpha)$ for any given $\\alpha \\in (0,\n1/2]$ imply tight computational lower bounds for sparse PCA at sparsities $k =\no(n^{\\alpha/3})$. This shows that even a mild improvement in the signal\nstrength needed by the best known polynomial-time sparse PCA algorithms would\nimply that the hardness threshold for PC is subpolynomial. This is the first\ninstance of a suboptimal hardness assumption implying optimal lower bounds for\nanother problem in unsupervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:35:39 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "1902.07399", "submitter": "Rahul Yedida", "authors": "Rahul Yedida, Snehanshu Saha and Tejas Prashanth", "title": "LipschitzLR: Using theoretically computed adaptive learning rates for\n  fast convergence", "comments": "v4; comparison studies added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing deep neural networks is largely thought to be an empirical\nprocess, requiring manual tuning of several hyper-parameters, such as learning\nrate, weight decay, and dropout rate. Arguably, the learning rate is the most\nimportant of these to tune, and this has gained more attention in recent works.\nIn this paper, we propose a novel method to compute the learning rate for\ntraining deep neural networks with stochastic gradient descent. We first derive\na theoretical framework to compute learning rates dynamically based on the\nLipschitz constant of the loss function. We then extend this framework to other\ncommonly used optimization algorithms, such as gradient descent with momentum\nand Adam. We run an extensive set of experiments that demonstrate the efficacy\nof our approach on popular architectures and datasets, and show that commonly\nused learning rates are an order of magnitude smaller than the ideal value.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 04:31:11 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 12:33:33 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 04:15:32 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 03:46:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yedida", "Rahul", ""], ["Saha", "Snehanshu", ""], ["Prashanth", "Tejas", ""]]}, {"id": "1902.07417", "submitter": "EPTCS", "authors": "Kaizaburo Chubachi, Diptarama Hendrian, Ryo Yoshinaka, Ayumi Shinohara", "title": "Query Learning Algorithm for Residual Symbolic Finite Automata", "comments": "In Proceedings GandALF 2019, arXiv:1909.05979", "journal-ref": "EPTCS 305, 2019, pp. 140-153", "doi": "10.4204/EPTCS.305.10", "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a query learning algorithm for residual symbolic finite automata\n(RSFAs). Symbolic finite automata (SFAs) are finite automata whose transitions\nare labeled by predicates over a Boolean algebra, in which a big collection of\ncharacters leading the same transition may be represented by a single\npredicate. Residual finite automata (RFAs) are a special type of\nnon-deterministic finite automata which can be exponentially smaller than the\nminimum deterministic finite automata and have a favorable property for\nlearning algorithms. RSFAs have both properties of SFAs and RFAs and can have\nmore succinct representation of transitions and fewer states than RFAs and\ndeterministic SFAs accepting the same language. The implementation of our\nalgorithm efficiently learns RSFAs over a huge alphabet and outperforms an\nexisting learning algorithm for deterministic SFAs. The result also shows that\nthe benefit of non-determinism in efficiency is even larger in learning SFAs\nthan non-symbolic automata.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:40:33 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 12:50:43 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 09:05:33 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Chubachi", "Kaizaburo", ""], ["Hendrian", "Diptarama", ""], ["Yoshinaka", "Ryo", ""], ["Shinohara", "Ayumi", ""]]}, {"id": "1902.07419", "submitter": "Fanghui Xue", "authors": "Fanghui Xue and Jack Xin", "title": "Learning Sparse Neural Networks via $\\ell_0$ and T$\\ell_1$ by a Relaxed\n  Variable Splitting Method with Application to Multi-scale Curve\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sparsification of convolutional neural networks (CNN) by a relaxed\nvariable splitting method of $\\ell_0$ and transformed-$\\ell_1$ (T$\\ell_1$)\npenalties, with application to complex curves such as texts written in\ndifferent fonts, and words written with trembling hands simulating those of\nParkinson's disease patients. The CNN contains 3 convolutional layers, each\nfollowed by a maximum pooling, and finally a fully connected layer which\ncontains the largest number of network weights. With $\\ell_0$ penalty, we\nachieved over 99 \\% test accuracy in distinguishing shaky vs. regular fonts or\nhand writings with above 86 \\% of the weights in the fully connected layer\nbeing zero. Comparable sparsity and test accuracy are also reached with a\nproper choice of T$\\ell_1$ penalty.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:47:54 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Xue", "Fanghui", ""], ["Xin", "Jack", ""]]}, {"id": "1902.07422", "submitter": "Yi-Fan Song", "authors": "Jie Wang, Yi-Fan Song and Tian-Lei Ma", "title": "Mexican Hat Wavelet Kernel ELM for Multiclass Classification", "comments": "Published by Computational Intelligence and Neuroscience, 8 pages, 1\n  figure, 13 tables", "journal-ref": "Volume 2017, 2017: 1-8", "doi": "10.1155/2017/7479140", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel extreme learning machine (KELM) is a novel feedforward neural network,\nwhich is widely used in classification problems. To some extent, it solves the\nexisting problems of the invalid nodes and the large computational complexity\nin ELM. However, the traditional KELM classifier usually has a low test\naccuracy when it faces multiclass classification problems. In order to solve\nthe above problem, a new classifier, Mexican Hat wavelet KELM classifier, is\nproposed in this paper. The proposed classifier successfully improves the\ntraining accuracy and reduces the training time in the multiclass\nclassification problems. Moreover, the validity of the Mexican Hat wavelet as a\nkernel function of ELM is rigorously proved. Experimental results on different\ndata sets show that the performance of the proposed classifier is significantly\nsuperior to the compared classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:57:58 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wang", "Jie", ""], ["Song", "Yi-Fan", ""], ["Ma", "Tian-Lei", ""]]}, {"id": "1902.07429", "submitter": "Chen Gong", "authors": "Chen Gong and Hengmin Zhang and Jian Yang and Dacheng Tao", "title": "Learning with Inadequate and Incorrect Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practically, we are often in the dilemma that the labeled data at hand are\ninadequate to train a reliable classifier, and more seriously, some of these\nlabeled data may be mistakenly labeled due to the various human factors.\nTherefore, this paper proposes a novel semi-supervised learning paradigm that\ncan handle both label insufficiency and label inaccuracy. To address label\ninsufficiency, we use a graph to bridge the data points so that the label\ninformation can be propagated from the scarce labeled examples to unlabeled\nexamples along the graph edges. To address label inaccuracy, Graph Trend\nFiltering (GTF) and Smooth Eigenbase Pursuit (SEP) are adopted to filter out\nthe initial noisy labels. GTF penalizes the l_0 norm of label difference\nbetween connected examples in the graph and exhibits better local adaptivity\nthan the traditional l_2 norm-based Laplacian smoother. SEP reconstructs the\ncorrect labels by emphasizing the leading eigenvectors of Laplacian matrix\nassociated with small eigenvalues, as these eigenvectors reflect real label\nsmoothness and carry rich class separation cues. We term our algorithm as\n`Semi-supervised learning under Inadequate and Incorrect Supervision' (SIIS).\nThorough experimental results on image classification, text categorization, and\nspeech recognition demonstrate that our SIIS is effective in label error\ncorrection, leading to superior performance to the state-of-the-art methods in\nthe presence of label noise and label scarcity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 07:19:05 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Gong", "Chen", ""], ["Zhang", "Hengmin", ""], ["Yang", "Jian", ""], ["Tao", "Dacheng", ""]]}, {"id": "1902.07436", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata and Tomoyuki Obuchi", "title": "Perfect reconstruction of sparse signals with piecewise continuous\n  nonconvex penalties and nonconvexity control", "comments": "25 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider compressed sensing formulated as a minimization problem of\nnonconvex sparse penalties, Smoothly Clipped Absolute deviation (SCAD) and\nMinimax Concave Penalty (MCP). The nonconvexity of these penalties is\ncontrolled by nonconvexity parameters, and L1 penalty is contained as a limit\nwith respect to these parameters. The analytically derived reconstruction limit\novercomes that of L1 and the algorithmic limit in the Bayes-optimal setting,\nwhen the nonconvexity parameters have suitable values. However, for small\nnonconvexity parameters, where the reconstruction of the relatively dense\nsignals is theoretically guaranteed, the corresponding approximate message\npassing (AMP) cannot achieve perfect reconstruction. We identify that the\nshrinks in the basin of attraction to the perfect reconstruction causes the\ndiscrepancy between the AMP and corresponding theory using state evolution. A\npart of the discrepancy is resolved by introducing the control of the\nnonconvexity parameters to guide the AMP trajectory to the basin of the\nattraction.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 07:38:14 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 17:44:00 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 08:11:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sakata", "Ayaka", ""], ["Obuchi", "Tomoyuki", ""]]}, {"id": "1902.07471", "submitter": "Tarun Yadav", "authors": "Tarun Yadav and Koustav Sadhukhan", "title": "Identification of Bugs and Vulnerabilities in TLS Implementation for\n  Windows Operating System Using State Machine Learning", "comments": "9 pages, 8 figures, 1 table", "journal-ref": "Security in Computing and Communications 2018, Communications in\n  Computer and Information Science, Springer", "doi": "10.1007/978-981-13-5826-5_27", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TLS protocol is an essential part of secure Internet communication. In past,\nmany attacks have been identified on the protocol. Most of these attacks are\ndue to flaws in protocol implementation. The flaws are due to improper design\nand implementation of program logic by programmers. One of the widely used\nimplementation of TLS is SChannel which is used in Windows operating system\nsince its inception. We have used protocol state fuzzing to identify vulnerable\nand undesired state transitions in the state machine of the protocol for\nvarious versions of SChannel. The client as well as server components have been\nanalyzed thoroughly using this technique and various flaws have been discovered\nin the implementation. Exploitation of these flaws under specific circumstances\nmay lead to serious attacks which could disrupt secure communication. In this\npaper, we analyze state machine models of TLS protocol implementation of\nSChannel library and describe weaknesses and design flaws in these models,\nfound using protocol state fuzzing.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 09:46:02 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Yadav", "Tarun", ""], ["Sadhukhan", "Koustav", ""]]}, {"id": "1902.07494", "submitter": "Shuai Yu", "authors": "Shuai Yu, Yongbo Wang, Min Yang, Baocheng Li, Qiang Qu and Jialie Shen", "title": "NAIRS: A Neural Attentive Interpretable Recommendation System", "comments": "This paper was published as a demonstration paper on WSDM'19. In this\n  version, we added a detailed related work section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a neural attentive interpretable recommendation\nsystem, named NAIRS. A self-attention network, as a key component of the\nsystem, is designed to assign attention weights to interacted items of a user.\nThis attention mechanism can distinguish the importance of the various\ninteracted items in contributing to a user profile. Based on the user profiles\nobtained by the self-attention network, NAIRS offers personalized high-quality\nrecommendation. Moreover, it develops visual cues to interpret recommendations.\nThis demo application with the implementation of NAIRS enables users to\ninteract with a recommendation system, and it persistently collects training\ndata to improve the system. The demonstration and experimental results show the\neffectiveness of NAIRS.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 10:40:32 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Yu", "Shuai", ""], ["Wang", "Yongbo", ""], ["Yang", "Min", ""], ["Li", "Baocheng", ""], ["Qu", "Qiang", ""], ["Shen", "Jialie", ""]]}, {"id": "1902.07500", "submitter": "Benjamin Rubinstein", "authors": "Bastian Oetomo, Malinga Perera, Renata Borovica-Gajic, Benjamin I. P.\n  Rubinstein", "title": "A Note on Bounding Regret of the C$^2$UCB Contextual Combinatorial\n  Bandit", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the proof by Qin et al. (2014) of bounded regret of the C$^2$UCB\ncontextual combinatorial bandit. We demonstrate an error in the proof of\nvolumetric expansion of the moment matrix, used in upper bounding a function of\ncontext vector norms. We prove a relaxed inequality that yields the\noriginally-stated regret bound.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 10:49:47 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Oetomo", "Bastian", ""], ["Perera", "Malinga", ""], ["Borovica-Gajic", "Renata", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "1902.07517", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi,\n  Robert Jenssen", "title": "Noisy multi-label semi-supervised dimensionality reduction", "comments": "38 pages", "journal-ref": "Pattern Recognition, Vol 90, June 2019, Pages 257-270", "doi": "10.1016/j.patcog.2019.01.033", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labeled data represent a rich source of information that often are\neasily accessible and cheap to obtain, but label noise might also have many\nnegative consequences if not accounted for. How to fully utilize noisy labels\nhas been studied extensively within the framework of standard supervised\nmachine learning over a period of several decades. However, very little\nresearch has been conducted on solving the challenge posed by noisy labels in\nnon-standard settings. This includes situations where only a fraction of the\nsamples are labeled (semi-supervised) and each high-dimensional sample is\nassociated with multiple labels. In this work, we present a novel\nsemi-supervised and multi-label dimensionality reduction method that\neffectively utilizes information from both noisy multi-labels and unlabeled\ndata. With the proposed Noisy multi-label semi-supervised dimensionality\nreduction (NMLSDR) method, the noisy multi-labels are denoised and unlabeled\ndata are labeled simultaneously via a specially designed label propagation\nalgorithm. NMLSDR then learns a projection matrix for reducing the\ndimensionality by maximizing the dependence between the enlarged and denoised\nmulti-label space and the features in the projected space. Extensive\nexperiments on synthetic data, benchmark datasets, as well as a real-world case\nstudy, demonstrate the effectiveness of the proposed algorithm and show that it\noutperforms state-of-the-art multi-label feature extraction algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:34:01 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Bianchi", "Filippo Maria", ""], ["Jenssen", "Robert", ""]]}, {"id": "1902.07528", "submitter": "Wojciech Kot{\\l}owski", "authors": "Micha{\\l} Kempka, Wojciech Kot{\\l}owski, Manfred K. Warmuth", "title": "Adaptive scale-invariant online algorithms for learning linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning with linear models, where the algorithm predicts\non sequentially revealed instances (feature vectors), and is compared against\nthe best linear function (comparator) in hindsight. Popular algorithms in this\nframework, such as Online Gradient Descent (OGD), have parameters (learning\nrates), which ideally should be tuned based on the scales of the features and\nthe optimal comparator, but these quantities only become available at the end\nof the learning process. In this paper, we resolve the tuning problem by\nproposing online algorithms making predictions which are invariant under\narbitrary rescaling of the features. The algorithms have no parameters to tune,\ndo not require any prior knowledge on the scale of the instances or the\ncomparator, and achieve regret bounds matching (up to a logarithmic factor)\nthat of OGD with optimally tuned separate learning rates per dimension, while\nretaining comparable runtime performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:58:05 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Kempka", "Micha\u0142", ""], ["Kot\u0142owski", "Wojciech", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1902.07535", "submitter": "Akira Imakura", "authors": "Akira Imakura and Tetsuya Sakurai", "title": "Data collaboration analysis for distributed datasets", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a data collaboration analysis method for\ndistributed datasets. The proposed method is a centralized machine learning\nwhile training datasets and models remain distributed over some institutions.\nRecently, data became large and distributed with decreasing costs of data\ncollection. If we can centralize these distributed datasets and analyse them as\none dataset, we expect to obtain novel insight and achieve a higher prediction\nperformance compared with individual analyses on each distributed dataset.\nHowever, it is generally difficult to centralize the original datasets due to\ntheir huge data size or regarding a privacy-preserving problem. To avoid these\ndifficulties, we propose a data collaboration analysis method for distributed\ndatasets without sharing the original datasets. The proposed method centralizes\nonly intermediate representation constructed individually instead of the\noriginal dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 12:33:39 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Imakura", "Akira", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "1902.07557", "submitter": "Filip de Roos", "authors": "Filip de Roos and Philipp Hennig", "title": "Active Probabilistic Inference on Matrices for Pre-Conditioning in\n  Stochastic Optimization", "comments": "Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-conditioning is a well-known concept that can significantly improve the\nconvergence of optimization algorithms. For noise-free problems, where good\npre-conditioners are not known a priori, iterative linear algebra methods offer\none way to efficiently construct them. For the stochastic optimization problems\nthat dominate contemporary machine learning, however, this approach is not\nreadily available. We propose an iterative algorithm inspired by classic\niterative linear solvers that uses a probabilistic model to actively infer a\npre-conditioner in situations where Hessian-projections can only be constructed\nwith strong Gaussian noise. The algorithm is empirically demonstrated to\nefficiently construct effective pre-conditioners for stochastic gradient\ndescent and its variants. Experiments on problems of comparably low\ndimensionality show improved convergence. In very high-dimensional problems,\nsuch as those encountered in deep learning, the pre-conditioner effectively\nbecomes an automatic learning-rate adaptation scheme, which we also empirically\nshow to work well.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 14:00:12 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["de Roos", "Filip", ""], ["Hennig", "Philipp", ""]]}, {"id": "1902.07565", "submitter": "Han Zhu", "authors": "Han Zhu, Daqing Chang, Ziru Xu, Pengye Zhang, Xiang Li, Jie He, Han\n  Li, Jian Xu, Kun Gai", "title": "Joint Optimization of Tree-based Index and Deep Model for Recommender\n  Systems", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale industrial recommender systems are usually confronted with\ncomputational problems due to the enormous corpus size. To retrieve and\nrecommend the most relevant items to users under response time limits,\nresorting to an efficient index structure is an effective and practical\nsolution. The previous work Tree-based Deep Model (TDM) \\cite{zhu2018learning}\ngreatly improves recommendation accuracy using tree index. By indexing items in\na tree hierarchy and training a user-node preference prediction model\nsatisfying a max-heap like property in the tree, TDM provides logarithmic\ncomputational complexity w.r.t. the corpus size, enabling the use of arbitrary\nadvanced models in candidate retrieval and recommendation.\n  In tree-based recommendation methods, the quality of both the tree index and\nthe user-node preference prediction model determines the recommendation\naccuracy for the most part. We argue that the learning of tree index and\npreference model has interdependence. Our purpose, in this paper, is to develop\na method to jointly learn the index structure and user preference prediction\nmodel. In our proposed joint optimization framework, the learning of index and\nuser preference prediction model are carried out under a unified performance\nmeasure. Besides, we come up with a novel hierarchical user preference\nrepresentation utilizing the tree index hierarchy. Experimental evaluations\nwith two large-scale real-world datasets show that the proposed method improves\nrecommendation accuracy significantly. Online A/B test results at a display\nadvertising platform also demonstrate the effectiveness of the proposed method\nin production environments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 08:52:58 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 06:55:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhu", "Han", ""], ["Chang", "Daqing", ""], ["Xu", "Ziru", ""], ["Zhang", "Pengye", ""], ["Li", "Xiang", ""], ["He", "Jie", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1902.07579", "submitter": "Marcel Binz", "authors": "Marcel Binz and Dominik Endres", "title": "Emulating Human Developmental Stages with Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the acquisition of knowledge in humans and machines. Research from\nthe field of developmental psychology indicates, that human-employed hypothesis\nare initially guided by simple rules, before evolving into more complex\ntheories. This observation is shared across many tasks and domains. We\ninvestigate whether stages of development in artificial learning systems are\nbased on the same characteristics. We operationalize developmental stages as\nthe size of the data-set, on which the artificial system is trained. For our\nanalysis we look at the developmental progress of Bayesian Neural Networks on\nthree different data-sets, including occlusion, support and quantity comparison\ntasks. We compare the results with prior research from developmental psychology\nand find agreement between the family of optimized models and pattern of\ndevelopment observed in infants and children on all three tasks, indicating\ncommon principles for the acquisition of knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 14:37:45 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Binz", "Marcel", ""], ["Endres", "Dominik", ""]]}, {"id": "1902.07580", "submitter": "Marcel Binz", "authors": "Marcel Binz and Dominik Endres", "title": "Where Do Human Heuristics Come From?", "comments": "Final version for CogSci 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-making deviates from the optimal solution, that maximizes\ncumulative rewards, in many situations. Here we approach this discrepancy from\nthe perspective of bounded rationality and our goal is to provide a\njustification for such seemingly sub-optimal strategies. More specifically we\ninvestigate the hypothesis, that humans do not know optimal decision-making\nalgorithms in advance, but instead employ a learned, resource-bounded\napproximation. The idea is formalized through combining a recently proposed\nmeta-learning model based on Recurrent Neural Networks with a resource-bounded\nobjective. The resulting approach is closely connected to variational inference\nand the Minimum Description Length principle. Empirical evidence is obtained\nfrom a two-armed bandit task. Here we observe patterns in our family of models\nthat resemble differences between individual human participants.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 14:43:28 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 08:31:43 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Binz", "Marcel", ""], ["Endres", "Dominik", ""]]}, {"id": "1902.07588", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "A Machine Learning based Robust Prediction Model for Real-life Mobile\n  Phone Data", "comments": "Journal: Internet of Things (IoT): Engineering Cyber-Physical Human\n  Systems (Elsevier). arXiv admin note: text overlap with arXiv:1710.04461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life mobile phone data may contain noisy instances, which is a\nfundamental issue for building a prediction model with many potential negative\nconsequences. The complexity of the inferred model may increase, may arise\noverfitting problem, and thereby the overall prediction accuracy of the model\nmay decrease. In this paper, we address these issues and present a robust\nprediction model for real-life mobile phone data of individual users, in order\nto improve the prediction accuracy of the model. In our robust model, we first\neffectively identify and eliminate the noisy instances from the training\ndataset by determining a dynamic noise threshold using naive Bayes classifier\nand laplace estimator, which may differ from user-to-user according to their\nunique behavioral patterns. After that, we employ the most popular rule-based\nmachine learning classification technique, i.e., decision tree, on the\nnoise-free quality dataset to build the prediction model. Experimental results\non the real-life mobile phone datasets (e.g., phone call log) of individual\nmobile phone users, show the effectiveness of our robust model in terms of\nprecision, recall and f-measure.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:29:25 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1902.07605", "submitter": "Marek Petrik", "authors": "Marek Petrik, Reazul Hasan Russell", "title": "Beyond Confidence Regions: Tight Bayesian Ambiguity Sets for Robust MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust MDPs (RMDPs) can be used to compute policies with provable worst-case\nguarantees in reinforcement learning. The quality and robustness of an RMDP\nsolution are determined by the ambiguity set---the set of plausible transition\nprobabilities---which is usually constructed as a multi-dimensional confidence\nregion. Existing methods construct ambiguity sets as confidence regions using\nconcentration inequalities which leads to overly conservative solutions. This\npaper proposes a new paradigm that can achieve better solutions with the same\nrobustness guarantees without using confidence regions as ambiguity sets. To\nincorporate prior knowledge, our algorithms optimize the size and position of\nambiguity sets using Bayesian inference. Our theoretical analysis shows the\nsafety of the proposed method, and the empirical results demonstrate its\npractical promise.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 15:46:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Petrik", "Marek", ""], ["Russell", "Reazul Hasan", ""]]}, {"id": "1902.07623", "submitter": "Gavin Weiguang Ding", "authors": "Gavin Weiguang Ding and Luyu Wang and Xiaomeng Jin", "title": "advertorch v0.1: An Adversarial Robustness Toolbox based on PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  advertorch is a toolbox for adversarial robustness research. It contains\nvarious implementations for attacks, defenses and robust training methods.\nadvertorch is built on PyTorch (Paszke et al., 2017), and leverages the\nadvantages of the dynamic computational graph to provide concise and efficient\nreference implementations. The code is licensed under the LGPL license and is\nopen sourced at https://github.com/BorealisAI/advertorch .\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 16:18:37 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Ding", "Gavin Weiguang", ""], ["Wang", "Luyu", ""], ["Jin", "Xiaomeng", ""]]}, {"id": "1902.07627", "submitter": "Aijun Zhang", "authors": "Aijun Zhang, Hengtao Zhang and Guosheng Yin", "title": "Adaptive Iterative Hessian Sketch via A-Optimal Subsampling", "comments": "To appear in Statistics and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Hessian sketch (IHS) is an effective sketching method for modeling\nlarge-scale data. It was originally proposed by Pilanci and Wainwright (2016;\nJMLR) based on randomized sketching matrices. However, it is computationally\nintensive due to the iterative sketch process. In this paper, we analyze the\nIHS algorithm under the unconstrained least squares problem setting, then\npropose a deterministic approach for improving IHS via A-optimal subsampling.\nOur contributions are three-fold: (1) a good initial estimator based on the\nA-optimal design is suggested; (2) a novel ridged preconditioner is developed\nfor repeated sketching; and (3) an exact line search method is proposed for\ndetermining the optimal step length adaptively. Extensive experimental results\ndemonstrate that our proposed A-optimal IHS algorithm outperforms the existing\naccelerated IHS methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 16:28:56 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 07:14:26 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhang", "Aijun", ""], ["Zhang", "Hengtao", ""], ["Yin", "Guosheng", ""]]}, {"id": "1902.07638", "submitter": "Liam Li", "authors": "Liam Li, Ameet Talwalkar", "title": "Random Search and Reproducibility for Neural Architecture Search", "comments": "V2 Changelog: - Modified footnote 2 for ENAS. - Expanded broad\n  reproducibility study for random search with WS for CNN to 6 sets of random\n  seeds v3 Changelog: - Added journal reference - Updated acknowledgements", "journal-ref": "Conference on Uncertainty in Artificial Intelligence (UAI), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is a promising research direction that has\nthe potential to replace expert-designed networks with learned, task-specific\narchitectures. In this work, in order to help ground the empirical results in\nthis field, we propose new NAS baselines that build off the following\nobservations: (i) NAS is a specialized hyperparameter optimization problem; and\n(ii) random search is a competitive baseline for hyperparameter optimization.\nLeveraging these observations, we evaluate both random search with\nearly-stopping and a novel random search with weight-sharing algorithm on two\nstandard NAS benchmarks---PTB and CIFAR-10. Our results show that random search\nwith early-stopping is a competitive NAS baseline, e.g., it performs at least\nas well as ENAS, a leading NAS method, on both benchmarks. Additionally, random\nsearch with weight-sharing outperforms random search with early-stopping,\nachieving a state-of-the-art NAS result on PTB and a highly competitive result\non CIFAR-10. Finally, we explore the existing reproducibility issues of\npublished NAS results. We note the lack of source material needed to exactly\nreproduce these results, and further discuss the robustness of published\nresults given the various sources of variability in NAS experimental setups.\nRelatedly, we provide all information (code, random seeds, documentation)\nneeded to exactly reproduce our results, and report our random search with\nweight-sharing results for each benchmark on multiple runs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 16:49:07 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:06:02 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 20:07:41 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Li", "Liam", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1902.07651", "submitter": "Victor Boutin", "authors": "Victor Boutin, Angelo Franciosini, Frederic Chavane, Franck Ruffier,\n  Laurent Perrinet", "title": "Sparse Deep Predictive Coding captures contour integration capabilities\n  of the early visual system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both neurophysiological and psychophysical experiments have pointed out the\ncrucial role of recurrent and feedback connections to process context-dependent\ninformation in the early visual cortex. While numerous models have accounted\nfor feedback effects at either neural or representational level, none of them\nwere able to bind those two levels of analysis. Is it possible to describe\nfeedback effects at both levels using the same model? We answer this question\nby combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical\nand convolutional framework. In this Sparse Deep Predictive Coding (SDPC)\nmodel, the SC component models the internal recurrent processing within each\nlayer, and the PC component describes the interactions between layers using\nfeedforward and feedback connections. Here, we train a 2-layered SDPC on two\ndifferent databases of images, and we interpret it as a model of the early\nvisual system (V1 & V2). We first demonstrate that once the training has\nconverged, SDPC exhibits oriented and localized receptive fields in V1 and more\ncomplex features in V2. Second, we analyze the effects of feedback on the\nneural organization beyond the classical receptive field of V1 neurons using\ninteraction maps. These maps are similar to association fields and reflect the\nGestalt principle of good continuation. We demonstrate that feedback signals\nreorganize interaction maps and modulate neural activity to promote contour\nintegration. Third, we demonstrate at the representational level that the SDPC\nfeedback connections are able to overcome noise in input images. Therefore, the\nSDPC captures the association field principle at the neural level which results\nin better disambiguation of blurred images at the representational level.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:06:00 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 07:43:28 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 15:46:21 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Boutin", "Victor", ""], ["Franciosini", "Angelo", ""], ["Chavane", "Frederic", ""], ["Ruffier", "Franck", ""], ["Perrinet", "Laurent", ""]]}, {"id": "1902.07656", "submitter": "{\\L}ukasz Maziarka", "authors": "Bartosz W\\'ojcik, {\\L}ukasz Maziarka, Jacek Tabor", "title": "LOSSGRAD: automatic learning rate in gradient descent", "comments": "TFML 2019", "journal-ref": "Schedae Informaticae, 2018, Volume 27", "doi": "10.4467/20838476SI.18.004.10409", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple, fast and easy to implement algorithm\nLOSSGRAD (locally optimal step-size in gradient descent), which automatically\nmodifies the step-size in gradient descent during neural networks training.\nGiven a function $f$, a point $x$, and the gradient $\\nabla_x f$ of $f$, we aim\nto find the step-size $h$ which is (locally) optimal, i.e. satisfies: $$\nh=arg\\,min_{t \\geq 0} f(x-t \\nabla_x f). $$ Making use of quadratic\napproximation, we show that the algorithm satisfies the above assumption. We\nexperimentally show that our method is insensitive to the choice of initial\nlearning rate while achieving results comparable to other methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:11:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["Maziarka", "\u0141ukasz", ""], ["Tabor", "Jacek", ""]]}, {"id": "1902.07662", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Jonathan Jakob, Michael Biehl, Peter Tino, Barbara\n  Hammer", "title": "Feature Relevance Bounds for Ordinal Regression", "comments": "preprint of a paper accepted for oral presentation at the 27th\n  European Symposium on Artificial Neural Networks (ESANN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing occurrence of ordinal data, mainly sociodemographic, led to a\nrenewed research interest in ordinal regression, i.e. the prediction of ordered\nclasses. Besides model accuracy, the interpretation of these models itself is\nof high relevance, and existing approaches therefore enforce e.g. model\nsparsity. For high dimensional or highly correlated data, however, this might\nbe misleading due to strong variable dependencies. In this contribution, we aim\nfor an identification of feature relevance bounds which - besides identifying\nall relevant features - explicitly differentiates between strongly and weakly\nrelevant features.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:18:48 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["Jakob", "Jonathan", ""], ["Biehl", "Michael", ""], ["Tino", "Peter", ""], ["Hammer", "Barbara", ""]]}, {"id": "1902.07698", "submitter": "Cong Ma", "authors": "Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma, Yuling Yan", "title": "Noisy Matrix Completion: Understanding Statistical Guarantees for Convex\n  Relaxation via Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies noisy low-rank matrix completion: given partial and noisy\nentries of a large low-rank matrix, the goal is to estimate the underlying\nmatrix faithfully and efficiently. Arguably one of the most popular paradigms\nto tackle this problem is convex relaxation, which achieves remarkable efficacy\nin practice. However, the theoretical support of this approach is still far\nfrom optimal in the noisy setting, falling short of explaining its empirical\nsuccess.\n  We make progress towards demystifying the practical efficacy of convex\nrelaxation vis-\\`a-vis random noise. When the rank and the condition number of\nthe unknown matrix are bounded by a constant, we demonstrate that the convex\nprogramming approach achieves near-optimal estimation errors --- in terms of\nthe Euclidean loss, the entrywise loss, and the spectral norm loss --- for a\nwide range of noise levels. All of this is enabled by bridging convex\nrelaxation with the nonconvex Burer-Monteiro approach, a seemingly distinct\nalgorithmic paradigm that is provably robust against noise. More specifically,\nwe show that an approximate critical point of the nonconvex formulation serves\nas an extremely tight approximation of the convex solution, thus allowing us to\ntransfer the desired statistical guarantees of the nonconvex approach to its\nconvex counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 18:51:50 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 14:01:40 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""], ["Yan", "Yuling", ""]]}, {"id": "1902.07742", "submitter": "Justin Fu", "authors": "Justin Fu, Anoop Korattikara, Sergey Levine, Sergio Guadarrama", "title": "From Language to Goals: Inverse Reinforcement Learning for Vision-Based\n  Instruction Following", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising framework for solving control problems,\nbut its use in practical situations is hampered by the fact that reward\nfunctions are often difficult to engineer. Specifying goals and tasks for\nautonomous machines, such as robots, is a significant challenge:\nconventionally, reward functions and goal states have been used to communicate\nobjectives. But people can communicate objectives to each other simply by\ndescribing or demonstrating them. How can we build learning algorithms that\nwill allow us to tell machines what we want them to do? In this work, we\ninvestigate the problem of grounding language commands as reward functions\nusing inverse reinforcement learning, and argue that language-conditioned\nrewards are more transferable than language-conditioned policies to new\nenvironments. We propose language-conditioned reward learning (LC-RL), which\ngrounds language commands as a reward function represented by a deep neural\nnetwork. We demonstrate that our model learns rewards that transfer to novel\ntasks and environments on realistic, high-dimensional visual environments with\nnatural language commands, whereas directly learning a language-conditioned\npolicy leads to poor performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 19:22:00 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Fu", "Justin", ""], ["Korattikara", "Anoop", ""], ["Levine", "Sergey", ""], ["Guadarrama", "Sergio", ""]]}, {"id": "1902.07762", "submitter": "Ondrej Skopek", "authors": "Lukas Jendele, Ondrej Skopek, Anton S. Becker, Ender Konukoglu", "title": "Adversarial Augmentation for Enhancing Classification of Mammography\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised deep learning relies on the assumption that enough training data\nis available, which presents a problem for its application to several fields,\nlike medical imaging. On the example of a binary image classification task\n(breast cancer recognition), we show that pretraining a generative model for\nmeaningful image augmentation helps enhance the performance of the resulting\nclassifier. By augmenting the data, performance on downstream classification\ntasks could be improved even with a relatively small training set. We show that\nthis \"adversarial augmentation\" yields promising results compared to classical\nimage augmentation on the example of breast cancer classification.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 20:13:24 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Jendele", "Lukas", ""], ["Skopek", "Ondrej", ""], ["Becker", "Anton S.", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1902.07802", "submitter": "Xiaoxiao Wang", "authors": "Xueying Guo, Xiaoxiao Wang, Xin Liu", "title": "AdaLinUCB: Opportunistic Learning for Contextual Bandits", "comments": "IJCAI. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study opportunistic contextual bandits - a\nspecial case of contextual bandits where the exploration cost varies under\ndifferent environmental conditions, such as network load or return variation in\nrecommendations. When the exploration cost is low, so is the actual regret of\npulling a sub-optimal arm (e.g., trying a suboptimal recommendation).\nTherefore, intuitively, we could explore more when the exploration cost is\nrelatively low and exploit more when the exploration cost is relatively high.\nInspired by this intuition, for opportunistic contextual bandits with Linear\npayoffs, we propose an Adaptive Upper-Confidence-Bound algorithm (AdaLinUCB) to\nadaptively balance the exploration-exploitation trade-off for opportunistic\nlearning. We prove that AdaLinUCB achieves O((log T)^2) problem-dependent\nregret upper bound, which has a smaller coefficient than that of the\ntraditional LinUCB algorithm. Moreover, based on both synthetic and real-world\ndataset, we show that AdaLinUCB significantly outperforms other contextual\nbandit algorithms, under large exploration cost fluctuations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 22:35:24 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:44:15 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Guo", "Xueying", ""], ["Wang", "Xiaoxiao", ""], ["Liu", "Xin", ""]]}, {"id": "1902.07814", "submitter": "Xiang Ren", "authors": "Hongtao Lin, Jun Yan, Meng Qu, Xiang Ren", "title": "Learning Dual Retrieval Module for Semi-supervised Relation Extraction", "comments": "10 pages, 2-page references. Accepted to The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction is an important task in structuring content of text data,\nand becomes especially challenging when learning with weak supervision---where\nonly a limited number of labeled sentences are given and a large number of\nunlabeled sentences are available. Most existing work exploits unlabeled data\nbased on the ideas of self-training (i.e., bootstrapping a model) and\nmulti-view learning (e.g., ensembling multiple model variants). However, these\nmethods either suffer from the issue of semantic drift, or do not fully capture\nthe problem characteristics of relation extraction. In this paper, we leverage\na key insight that retrieving sentences expressing a relation is a dual task of\npredicting relation label for a given sentence---two tasks are complementary to\neach other and can be optimized jointly for mutual enhancement. To model this\nintuition, we propose DualRE, a principled framework that introduces a\nretrieval module which is jointly trained with the original relation prediction\nmodule. In this way, high-quality samples selected by retrieval module from\nunlabeled data can be used to improve prediction module, and vice versa.\nExperimental results\\footnote{\\small Code and data can be found at\n\\url{https://github.com/INK-USC/DualRE}.} on two public datasets as well as\ncase studies demonstrate the effectiveness of the DualRE approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:56:21 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 20:39:43 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lin", "Hongtao", ""], ["Yan", "Jun", ""], ["Qu", "Meng", ""], ["Ren", "Xiang", ""]]}, {"id": "1902.07816", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Myle Ott, Michael Auli, Marc'Aurelio Ranzato", "title": "Mixture Models for Diverse Machine Translation: Tricks of the Trade", "comments": "ICML 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models trained via EM are among the simplest, most widely used and\nwell understood latent variable models in the machine learning literature.\nSurprisingly, these models have been hardly explored in text generation\napplications such as machine translation. In principle, they provide a latent\nvariable to control generation and produce a diverse set of hypotheses. In\npractice, however, mixture models are prone to degeneracies---often only one\ncomponent gets trained or the latent variable is simply ignored. We find that\ndisabling dropout noise in responsibility computation is critical to successful\ntraining. In addition, the design choices of parameterization, prior\ndistribution, hard versus soft EM and online versus offline assignment can\ndramatically affect model performance. We develop an evaluation protocol to\nassess both quality and diversity of generations against multiple references,\nand provide an extensive empirical study of several mixture model variants. Our\nanalysis shows that certain types of mixture models are more robust and offer\nthe best trade-off between translation quality and diversity compared to\nvariational models and diverse decoding approaches.\\footnote{Code to reproduce\nthe results in this paper is available at\n\\url{https://github.com/pytorch/fairseq}}\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:57:35 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:37:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Shen", "Tianxiao", ""], ["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1902.07823", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang and Nisheeth K. Vishnoi", "title": "Stable and Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has been a topic of intense study in machine learning,\nand several algorithms have been proposed towards this important task. However,\nin a recent study, Friedler et al. observed that fair classification algorithms\nmay not be stable with respect to variations in the training dataset -- a\ncrucial consideration in several real-world applications. Motivated by their\nwork, we study the problem of designing classification algorithms that are both\nfair and stable. We propose an extended framework based on fair classification\nalgorithms that are formulated as optimization problems, by introducing a\nstability-focused regularization term. Theoretically, we prove a stability\nguarantee, that was lacking in fair classification algorithms, and also provide\nan accuracy guarantee for our extended framework. Our accuracy guarantee can be\nused to inform the selection of the regularization parameter in our framework.\nTo the best of our knowledge, this is the first work that combines stability\nand fairness in automated decision-making tasks. We assess the benefits of our\napproach empirically by extending several fair classification algorithms that\nare shown to achieve the best balance between fairness and accuracy over the\nAdult dataset. Our empirical results show that our framework indeed improves\nthe stability at only a slight sacrifice in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 00:56:14 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:15:32 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 16:22:18 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 12:32:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Huang", "Lingxiao", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1902.07826", "submitter": "Horia Mania", "authors": "Horia Mania, Stephen Tu, Benjamin Recht", "title": "Certainty Equivalence is Efficient for Linear Quadratic Control", "comments": "In the current version we extended our analysis to the case of\n  partially observable systems, i.e. we provided a suboptimality analysis for\n  the Linear Quadratic Gaussian (LQG) setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of the certainty equivalent controller on Linear\nQuadratic (LQ) control problems with unknown transition dynamics. We show that\nfor both the fully and partially observed settings, the sub-optimality gap\nbetween the cost incurred by playing the certainty equivalent controller on the\ntrue system and the cost incurred by using the optimal LQ controller enjoys a\nfast statistical rate, scaling as the square of the parameter error. To the\nbest of our knowledge, our result is the first sub-optimality guarantee in the\npartially observed Linear Quadratic Gaussian (LQG) setting. Furthermore, in the\nfully observed Linear Quadratic Regulator (LQR), our result improves upon\nrecent work by Dean et al. (2017), who present an algorithm achieving a\nsub-optimality gap linear in the parameter error. A key part of our analysis\nrelies on perturbation bounds for discrete Riccati equations. We provide two\nnew perturbation bounds, one that expands on an existing result from\nKonstantinov et al. (1993), and another based on a new elementary proof\nstrategy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:07:32 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 16:02:02 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Mania", "Horia", ""], ["Tu", "Stephen", ""], ["Recht", "Benjamin", ""]]}, {"id": "1902.07828", "submitter": "Hsiang Hsu", "authors": "Hsiang Hsu, Salman Salamatian, Flavio P. Calmon", "title": "Correspondence Analysis Using Neural Networks", "comments": "Accepted to AISTATS 2019. Overlaps with arXiv:1806.08449", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correspondence analysis (CA) is a multivariate statistical tool used to\nvisualize and interpret data dependencies. CA has found applications in fields\nranging from epidemiology to social sciences. However, current methods used to\nperform CA do not scale to large, high-dimensional datasets. By re-interpreting\nthe objective in CA using an information-theoretic tool called the principal\ninertia components, we demonstrate that performing CA is equivalent to solving\na functional optimization problem over the space of finite variance functions\nof two random variable. We show that this optimization problem, in turn, can be\nefficiently approximated by neural networks. The resulting formulation, called\nthe correspondence analysis neural network (CA-NN), enables CA to be performed\nat an unprecedented scale. We validate the CA-NN on synthetic data, and\ndemonstrate how it can be used to perform CA on a variety of datasets,\nincluding food recipes, wine compositions, and images. Our results outperform\ntraditional methods used in CA, indicating that CA-NN can serve as a new,\nscalable tool for interpretability and visualization of complex dependencies\nbetween random variables.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:09:30 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Hsu", "Hsiang", ""], ["Salamatian", "Salman", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "1902.07839", "submitter": "Xinsong Du", "authors": "Xinsong Du, Jae Min, Mattia Prosperi, Rohit Bishnoi, Dominick J.\n  Lemas, Chintan P. Shah", "title": "Inference of a Multi-Domain Machine Learning Model to Predict Mortality\n  in Hospital Stays for Patients with Cancer upon Febrile Neutropenia Onset", "comments": "This paper is under development, the authors think the paper contains\n  no innovation and do not want to reveal some of the current results included\n  in the paper for now", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Febrile neutropenia (FN) has been associated with high mortality, especially\namong adults with cancer. Understanding the patient and provider level\nheterogeneity in FN hospital admissions has potential to inform personalized\ninterventions focused on increasing survival of individuals with FN. We\nleverage machine learning techniques to disentangling the complex interactions\namong multi domain risk factors in a population with FN. Data from the\nHealthcare Cost and Utilization Project (HCUP) National Inpatient Sample and\nNationwide Inpatient Sample (NIS) were used to build machine learning based\nmodels of mortality for adult cancer patients who were diagnosed with FN during\na hospital admission. In particular, the importance of risk factors from\ndifferent domains (including demographic, clinical, and hospital associated\ninformation) was studied. A set of more interpretable (decision tree, logistic\nregression) as well as more black box (random forest, gradient boosting, neural\nnetworks) models were analyzed and compared via multiple cross validation. Our\nresults demonstrate that a linear prediction score of FN mortality among adults\nwith cancer, based on admission information is effective in classifying high\nrisk patients; clinical diagnoses is the domain with the highest predictive\npower. A number of the risk variables (e.g. sepsis, kidney failure, etc.)\nidentified in this study are clinically actionable and may inform future\nstudies looking at the patients prior medical history are warranted.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:52:12 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 20:09:50 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 14:27:12 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Du", "Xinsong", ""], ["Min", "Jae", ""], ["Prosperi", "Mattia", ""], ["Bishnoi", "Rohit", ""], ["Lemas", "Dominick J.", ""], ["Shah", "Chintan P.", ""]]}, {"id": "1902.07846", "submitter": "Alistair Shilton", "authors": "Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh, Majid\n  Abdolshah, Dang Nguyen", "title": "Stable Bayesian Optimisation via Direct Stability Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of finding stable maxima of expensive\n(to evaluate) functions. We are motivated by the optimisation of physical and\nindustrial processes where, for some input ranges, small and unavoidable\nvariations in inputs lead to unacceptably large variation in outputs. Our\napproach uses multiple gradient Gaussian Process models to estimate the\nprobability that worst-case output variation for specified input perturbation\nexceeded the desired maxima, and these probabilities are then used to (a) guide\nthe optimisation process toward solutions satisfying our stability criteria and\n(b) post-filter results to find the best stable solution. We exhibit our\nalgorithm on synthetic and real-world problems and demonstrate that it is able\nto effectively find stable maxima.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 02:36:16 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Shilton", "Alistair", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""], ["Abdolshah", "Majid", ""], ["Nguyen", "Dang", ""]]}, {"id": "1902.07848", "submitter": "Chengjie Li", "authors": "Chengjie Li, Ruixuan Li, Haozhao Wang, Yuhua Li, Pan Zhou, Song Guo,\n  Keqin Li", "title": "Gradient Scheduling with Global Momentum for Non-IID Data Distributed\n  Asynchronous Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed asynchronous offline training has received widespread attention\nin recent years because of its high performance on large-scale data and complex\nmodels. As data are distributed from cloud-centric to edge nodes, a big\nchallenge for distributed machine learning systems is how to handle native and\nnatural non-independent and identically distributed (non-IID) data for\ntraining. Previous asynchronous training methods do not have a satisfying\nperformance on non-IID data because it would result in that the training\nprocess fluctuates greatly which leads to an abnormal convergence. We propose a\ngradient scheduling algorithm with partly averaged gradients and global\nmomentum (GSGM) for non-IID data distributed asynchronous training. Our key\nidea is to apply global momentum and local average to the biased gradient after\nscheduling, in order to make the training process steady. Experimental results\nshow that for non-IID data training under the same experimental conditions,\nGSGM on popular optimization algorithms can achieve a 20% increase in training\nstability with a slight improvement in accuracy on Fashion-Mnist and CIFAR-10\ndatasets. Meanwhile, when expanding distributed scale on CIFAR-100 dataset that\nresults in sparse data distribution, GSGM can perform a 37% improvement on\ntraining stability. Moreover, only GSGM can converge well when the number of\ncomputing nodes grows to 30, compared to the state-of-the-art distributed\nasynchronous algorithms. At the same time, GSGM is robust to different degrees\nof non-IID data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 02:39:07 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 06:42:27 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 09:05:44 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Li", "Chengjie", ""], ["Li", "Ruixuan", ""], ["Wang", "Haozhao", ""], ["Li", "Yuhua", ""], ["Zhou", "Pan", ""], ["Guo", "Song", ""], ["Li", "Keqin", ""]]}, {"id": "1902.07849", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Ailing Piao, Wenjun Jiang, Yiran Zhao, Huajie Shao,\n  Shengzhong Liu, Dongxin Liu, Jinyang Li, Tianshi Wang, Shaohan Hu, Lu Su,\n  Jiawei Han, Tarek Abdelzaher", "title": "STFNets: Learning Sensing Signals from the Time-Frequency Perspective\n  with Short-Time Fourier Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3308558.3313426", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep learning motivate the use of deep neural networks in\nInternet-of-Things (IoT) applications. These networks are modelled after signal\nprocessing in the human brain, thereby leading to significant advantages at\nperceptual tasks such as vision and speech recognition. IoT applications,\nhowever, often measure physical phenomena, where the underlying physics (such\nas inertia, wireless signal propagation, or the natural frequency of\noscillation) are fundamentally a function of signal frequencies, offering\nbetter features in the frequency domain. This observation leads to a\nfundamental question: For IoT applications, can one develop a new brand of\nneural network structures that synthesize features inspired not only by the\nbiology of human perception but also by the fundamental nature of physics?\nHence, in this paper, instead of using conventional building blocks (e.g.,\nconvolutional and recurrent layers), we propose a new foundational neural\nnetwork building block, the Short-Time Fourier Neural Network (STFNet). It\nintegrates a widely-used time-frequency analysis method, the Short-Time Fourier\nTransform, into data processing to learn features directly in the frequency\ndomain, where the physics of underlying phenomena leave better foot-prints.\nSTFNets bring additional flexibility to time-frequency analysis by offering\nnovel nonlinear learnable operations that are spectral-compatible. Moreover,\nSTFNets show that transforming signals to a domain that is more connected to\nthe underlying physics greatly simplifies the learning process. We demonstrate\nthe effectiveness of STFNets with extensive experiments. STFNets significantly\noutperform the state-of-the-art deep learning models in all experiments. A\nSTFNet, therefore, demonstrates superior capability as the fundamental building\nblock of deep neural networks for IoT applications for various sensor inputs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 02:44:41 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Yao", "Shuochao", ""], ["Piao", "Ailing", ""], ["Jiang", "Wenjun", ""], ["Zhao", "Yiran", ""], ["Shao", "Huajie", ""], ["Liu", "Shengzhong", ""], ["Liu", "Dongxin", ""], ["Li", "Jinyang", ""], ["Wang", "Tianshi", ""], ["Hu", "Shaohan", ""], ["Su", "Lu", ""], ["Han", "Jiawei", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1902.07855", "submitter": "Avinash Barnwal", "authors": "Avinash Barnwal, Hari Pad Bharti, Aasim Ali, and Vishal Singh", "title": "Stacking with Neural network for Cryptocurrency investment", "comments": "20 pages,7 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the direction of assets have been an active area of study and a\ndifficult task. Machine learning models have been used to build robust models\nto model the above task. Ensemble methods is one of them showing results better\nthan a single supervised method. In this paper, we have used generative and\ndiscriminative classifiers to create the stack, particularly 3 generative and 6\ndiscriminative classifiers and optimized over one-layer Neural Network to model\nthe direction of price cryptocurrencies. Features used are technical indicators\nused are not limited to trend, momentum, volume, volatility indicators, and\nsentiment analysis has also been used to gain useful insight combined with the\nabove features. For Cross-validation, Purged Walk forward cross-validation has\nbeen used. In terms of accuracy, we have done a comparative analysis of the\nperformance of Ensemble method with Stacking and Ensemble method with blending.\nWe have also developed a methodology for combined features importance for the\nstacked model. Important indicators are also identified based on feature\nimportance.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 03:36:50 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 05:47:21 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Barnwal", "Avinash", ""], ["Bharti", "Hari Pad", ""], ["Ali", "Aasim", ""], ["Singh", "Vishal", ""]]}, {"id": "1902.07864", "submitter": "Ramakrishna Vedantam", "authors": "Ramakrishna Vedantam, Karan Desai, Stefan Lee, Marcus Rohrbach, Dhruv\n  Batra, Devi Parikh", "title": "Probabilistic Neural-symbolic Models for Interpretable Visual Question\n  Answering", "comments": "ICML 2019 Camera Ready + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of probabilistic neural-symbolic models, that have\nsymbolic functional programs as a latent, stochastic variable. Instantiated in\nthe context of visual question answering, our probabilistic formulation offers\ntwo key conceptual advantages over prior neural-symbolic models for VQA.\nFirstly, the programs generated by our model are more understandable while\nrequiring lesser number of teaching examples. Secondly, we show that one can\npose counterfactual scenarios to the model, to probe its beliefs on the\nprograms that could lead to a specified answer given an image. Our results on\nthe CLEVR and SHAPES datasets verify our hypotheses, showing that the model\ngets better program (and answer) prediction accuracy even in the low data\nregime, and allows one to probe the coherence and consistency of reasoning\nperformed.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 04:55:56 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 22:12:00 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Vedantam", "Ramakrishna", ""], ["Desai", "Karan", ""], ["Lee", "Stefan", ""], ["Rohrbach", "Marcus", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1902.07867", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Chunyan Miao", "title": "ntuer at SemEval-2019 Task 3: Emotion Classification with Word and\n  Sentence Representations in RCNN", "comments": "SemEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our model on the task of emotion detection in\ntextual conversations in SemEval-2019. Our model extends the Recurrent\nConvolutional Neural Network (RCNN) by using external fine-tuned word\nrepresentations and DeepMoji sentence representations. We also explored several\nother competitive pre-trained word and sentence representations including ELMo,\nBERT and InferSent but found inferior performance. In addition, we conducted\nextensive sensitivity analysis, which empirically shows that our model is\nrelatively robust to hyper-parameters. Our model requires no handcrafted\nfeatures or emotion lexicons but achieved good performance with a micro-F1\nscore of 0.7463.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 05:16:45 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 02:29:57 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhong", "Peixiang", ""], ["Miao", "Chunyan", ""]]}, {"id": "1902.07881", "submitter": "Keisuke Kinoshita", "authors": "Thilo von Neumann, Keisuke Kinoshita, Marc Delcroix, Shoko Araki,\n  Tomohiro Nakatani, Reinhold Haeb-Umbach", "title": "All-neural online source separation, counting, and diarization for\n  meeting analysis", "comments": "5 pages, to appear in ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic meeting analysis comprises the tasks of speaker counting, speaker\ndiarization, and the separation of overlapped speech, followed by automatic\nspeech recognition. This all has to be carried out on arbitrarily long sessions\nand, ideally, in an online or block-online manner. While significant progress\nhas been made on individual tasks, this paper presents for the first time an\nall-neural approach to simultaneous speaker counting, diarization and source\nseparation. The NN-based estimator operates in a block-online fashion and\ntracks speakers even if they remain silent for a number of time blocks, thus\nlearning a stable output order for the separated sources. The neural network is\nrecurrent over time as well as over the number of sources. The simulation\nexperiments show that state of the art separation performance is achieved,\nwhile at the same time delivering good diarization and source counting results.\nIt even generalizes well to an unseen large number of blocks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 06:32:21 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["von Neumann", "Thilo", ""], ["Kinoshita", "Keisuke", ""], ["Delcroix", "Marc", ""], ["Araki", "Shoko", ""], ["Nakatani", "Tomohiro", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1902.07892", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Deep Adaptive Input Normalization for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) models can be used to tackle time series analysis tasks\nwith great success. However, the performance of DL models can degenerate\nrapidly if the data are not appropriately normalized. This issue is even more\napparent when DL is used for financial time series forecasting tasks, where the\nnon-stationary and multimodal nature of the data pose significant challenges\nand severely affect the performance of DL models. In this work, a simple, yet\neffective, neural layer, that is capable of adaptively normalizing the input\ntime series, while taking into account the distribution of the data, is\nproposed. The proposed layer is trained in an end-to-end fashion using\nback-propagation and leads to significant performance improvements compared to\nother evaluated normalization schemes. The proposed method differs from\ntraditional normalization methods since it learns how to perform normalization\nfor a given task instead of using a fixed normalization scheme. At the same\ntime, it can be directly applied to any new time series without requiring\nre-training. The effectiveness of the proposed method is demonstrated using a\nlarge-scale limit order book dataset, as well as a load forecasting dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 07:17:26 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 07:56:58 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1902.07896", "submitter": "Philipp Petersen", "authors": "Ingo G\\\"uhring, Gitta Kutyniok, Philipp Petersen", "title": "Error bounds for approximations with deep ReLU neural networks in\n  $W^{s,p}$ norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze approximation rates of deep ReLU neural networks for\nSobolev-regular functions with respect to weaker Sobolev norms. First, we\nconstruct, based on a calculus of ReLU networks, artificial neural networks\nwith ReLU activation functions that achieve certain approximation rates.\nSecond, we establish lower bounds for the approximation by ReLU neural networks\nfor classes of Sobolev-regular functions. Our results extend recent advances in\nthe approximation theory of ReLU networks to the regime that is most relevant\nfor applications in the numerical analysis of partial differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 07:45:40 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["G\u00fchring", "Ingo", ""], ["Kutyniok", "Gitta", ""], ["Petersen", "Philipp", ""]]}, {"id": "1902.07901", "submitter": "Anastasios Gounaris", "authors": "Theodoros Toliopoulos, Anastasios Gounaris, Kostas Tsichlas, Apostolos\n  Papadopoulos, Sandra Sampaio", "title": "Continuous Outlier Mining of Streaming Data in Flink", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on distance-based outliers in a metric space, where\nthe status of an entity as to whether it is an outlier is based on the number\nof other entities in its neighborhood. In recent years, several solutions have\ntackled the problem of distance-based outliers in data streams, where outliers\nmust be mined continuously as new elements become available. An interesting\nresearch problem is to combine the streaming environment with massively\nparallel systems to provide scalable streambased algorithms. However, none of\nthe previously proposed techniques refer to a massively parallel setting. Our\nproposal fills this gap and investigates the challenges in transferring\nstate-of-the-art techniques to Apache Flink, a modern platform for intensive\nstreaming analytics. We thoroughly present the technical challenges encountered\nand the alternatives that may be applied. We show speed-ups of up to 117 (resp.\n2076) times over a naive parallel (resp. non-parallel) solution in Flink, by\nusing just an ordinary four-core machine and a real-world dataset. When moving\nto a three-machine cluster, due to less contention, we manage to achieve both\nbetter scalability in terms of the window slide size and the data\ndimensionality, and even higher speed-ups, e.g., by a factor of 510. Overall,\nour results demonstrate that oulier mining can be achieved in an efficient and\nscalable manner. The resulting techniques have been made publicly available as\nopen-source software.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 07:51:51 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Toliopoulos", "Theodoros", ""], ["Gounaris", "Anastasios", ""], ["Tsichlas", "Kostas", ""], ["Papadopoulos", "Apostolos", ""], ["Sampaio", "Sandra", ""]]}, {"id": "1902.07903", "submitter": "Yujiao Lu", "authors": "Yujiao Lu, Hancheng Lu, Liangliang Cao, Feng Wu, Daren Zhu", "title": "Learning Deterministic Policy with Target for Power Control in Wireless\n  Networks", "comments": "7 pages, 7 figures, GlobeCom2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-Cell Interference Coordination (ICIC) is a promising way to improve\nenergy efficiency in wireless networks, especially where small base stations\nare densely deployed. However, traditional optimization based ICIC schemes\nsuffer from severe performance degradation with complex interference pattern.\nTo address this issue, we propose a Deep Reinforcement Learning with\nDeterministic Policy and Target (DRL-DPT) framework for ICIC in wireless\nnetworks. DRL-DPT overcomes the main obstacles in applying reinforcement\nlearning and deep learning in wireless networks, i.e. continuous state space,\ncontinuous action space and convergence. Firstly, a Deep Neural Network (DNN)\nis involved as the actor to obtain deterministic power control actions in\ncontinuous space. Then, to guarantee the convergence, an online training\nprocess is presented, which makes use of a dedicated reward function as the\ntarget rule and a policy gradient descent algorithm to adjust DNN weights.\nExperimental results show that the proposed DRL-DPT framework consistently\noutperforms existing schemes in terms of energy efficiency and throughput under\ndifferent wireless interference scenarios. More specifically, it improves up to\n15% of energy efficiency with faster convergence rate.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 07:57:18 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Lu", "Yujiao", ""], ["Lu", "Hancheng", ""], ["Cao", "Liangliang", ""], ["Wu", "Feng", ""], ["Zhu", "Daren", ""]]}, {"id": "1902.07906", "submitter": "Eric Wong", "authors": "Eric Wong, Frank R. Schmidt, J. Zico Kolter", "title": "Wasserstein Adversarial Examples via Projected Sinkhorn Iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rapidly growing area of work has studied the existence of adversarial\nexamples, datapoints which have been perturbed to fool a classifier, but the\nvast majority of these works have focused primarily on threat models defined by\n$\\ell_p$ norm-bounded perturbations. In this paper, we propose a new threat\nmodel for adversarial attacks based on the Wasserstein distance. In the image\nclassification setting, such distances measure the cost of moving pixel mass,\nwhich naturally cover \"standard\" image manipulations such as scaling, rotation,\ntranslation, and distortion (and can potentially be applied to other settings\nas well). To generate Wasserstein adversarial examples, we develop a procedure\nfor projecting onto the Wasserstein ball, based upon a modified version of the\nSinkhorn iteration. The resulting algorithm can successfully attack image\nclassification models, bringing traditional CIFAR10 models down to 3% accuracy\nwithin a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1\npixel), and we demonstrate that PGD-based adversarial training can improve this\nadversarial accuracy to 76%. In total, this work opens up a new direction of\nstudy in adversarial robustness, more formally considering convex metrics that\naccurately capture the invariances that we typically believe should exist in\nclassifiers. Code for all experiments in the paper is available at\nhttps://github.com/locuslab/projected_sinkhorn.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 08:07:45 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 23:42:39 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wong", "Eric", ""], ["Schmidt", "Frank R.", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1902.07908", "submitter": "Rafael Dos Santos De Oliveira", "authors": "Rafael Oliveira, Lionel Ott and Fabio Ramos", "title": "Bayesian optimisation under uncertain inputs", "comments": "Preprint of paper to appear in the proceedings of the 22nd\n  International Conference on Artificial Intelligence and Statistics (AISTATS)\n  2019, Naha, Okinawa, Japan. PMLR: Volume 89", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation (BO) has been a successful approach to optimise\nfunctions which are expensive to evaluate and whose observations are noisy.\nClassical BO algorithms, however, do not account for errors about the location\nwhere observations are taken, which is a common issue in problems with physical\ncomponents. In these cases, the estimation of the actual query location is also\nsubject to uncertainty. In this context, we propose an upper confidence bound\n(UCB) algorithm for BO problems where both the outcome of a query and the true\nquery location are uncertain. The algorithm employs a Gaussian process model\nthat takes probability distributions as inputs. Theoretical results are\nprovided for both the proposed algorithm and a conventional UCB approach within\nthe uncertain-inputs setting. Finally, we evaluate each method's performance\nexperimentally, comparing them to other input noise aware BO approaches on\nsimulated scenarios involving synthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 08:15:10 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Oliveira", "Rafael", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "1902.07958", "submitter": "Mateus Espadoto", "authors": "Mateus Espadoto, Nina S. T. Hirata, Alexandru C. Telea", "title": "Deep Learning Multidimensional Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction methods, also known as projections, are frequently\nused for exploring multidimensional data in machine learning, data science, and\ninformation visualization. Among these, t-SNE and its variants have become very\npopular for their ability to visually separate distinct data clusters. However,\nsuch methods are computationally expensive for large datasets, suffer from\nstability problems, and cannot directly handle out-of-sample data. We propose a\nlearning approach to construct such projections. We train a deep neural network\nbased on a collection of samples from a given data universe, and their\ncorresponding projections, and next use the network to infer projections of\ndata from the same, or similar, universes. Our approach generates projections\nwith similar characteristics as the learned ones, is computationally two to\nthree orders of magnitude faster than SNE-class methods, has no complex-to-set\nuser parameters, handles out-of-sample data in a stable manner, and can be used\nto learn any projection technique. We demonstrate our proposal on several\nreal-world high dimensional datasets from machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 10:50:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Espadoto", "Mateus", ""], ["Hirata", "Nina S. T.", ""], ["Telea", "Alexandru C.", ""]]}, {"id": "1902.07967", "submitter": "Jun Li", "authors": "Jun Li, Daoyu Lin, Yang Wang, Guangluan Xu, Chibiao Ding", "title": "Deep Discriminative Representation Learning with Attention Map for Scene\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning powerful discriminative features for remote sensing image scene\nclassification is a challenging computer vision problem. In the past, most\nclassification approaches were based on handcrafted features. However, most\nrecent approaches to remote sensing scene classification are based on\nConvolutional Neural Networks (CNNs). The de facto practice when learning these\nCNN models is only to use original RGB patches as input with training performed\non large amounts of labeled data (ImageNet). In this paper, we show class\nactivation map (CAM) encoded CNN models, codenamed DDRL-AM, trained using\noriginal RGB patches and attention map based class information provide\ncomplementary information to the standard RGB deep models. To the best of our\nknowledge, we are the first to investigate attention information encoded CNNs.\nAdditionally, to enhance the discriminability, we further employ a recently\ndeveloped object function called \"center loss,\" which has proved to be very\nuseful in face recognition. Finally, our framework provides attention guidance\nto the model in an end-to-end fashion. Extensive experiments on two benchmark\ndatasets show that our approach matches or exceeds the performance of other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 11:09:18 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Li", "Jun", ""], ["Lin", "Daoyu", ""], ["Wang", "Yang", ""], ["Xu", "Guangluan", ""], ["Ding", "Chibiao", ""]]}, {"id": "1902.08009", "submitter": "Zekun Li", "authors": "Zeyu Cui, Zekun Li, Shu Wu, Xiaoyu Zhang, Liang Wang", "title": "Dressing as a Whole: Outfit Compatibility Learning Based on Node-wise\n  Graph Neural Networks", "comments": "11 pages, accepted by the 2019 World Wide Web Conference (WWW-2019)", "journal-ref": null, "doi": "10.1145/3308558.3313444", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the rapid development of fashion market, the customers' demands of\ncustomers for fashion recommendation are rising. In this paper, we aim to\ninvestigate a practical problem of fashion recommendation by answering the\nquestion \"which item should we select to match with the given fashion items and\nform a compatible outfit\". The key to this problem is to estimate the outfit\ncompatibility. Previous works which focus on the compatibility of two items or\nrepresent an outfit as a sequence fail to make full use of the complex\nrelations among items in an outfit. To remedy this, we propose to represent an\noutfit as a graph. In particular, we construct a Fashion Graph, where each node\nrepresents a category and each edge represents interaction between two\ncategories. Accordingly, each outfit can be represented as a subgraph by\nputting items into their corresponding category nodes. To infer the outfit\ncompatibility from such a graph, we propose Node-wise Graph Neural Networks\n(NGNN) which can better model node interactions and learn better node\nrepresentations. In NGNN, the node interaction on each edge is different, which\nis determined by parameters correlated to the two connected nodes. An attention\nmechanism is utilized to calculate the outfit compatibility score with learned\nnode representations. NGNN can not only be used to model outfit compatibility\nfrom visual or textual modality but also from multiple modalities. We conduct\nexperiments on two tasks: (1) Fill-in-the-blank: suggesting an item that\nmatches with existing components of outfit; (2) Compatibility prediction:\npredicting the compatibility scores of given outfits. Experimental results\ndemonstrate the great superiority of our proposed method over others.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 12:50:01 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Cui", "Zeyu", ""], ["Li", "Zekun", ""], ["Wu", "Shu", ""], ["Zhang", "Xiaoyu", ""], ["Wang", "Liang", ""]]}, {"id": "1902.08028", "submitter": "Francisco Benita", "authors": "Francisco Benita, Garvit Bansal, Georgios Piliouras and Bige\n  Tun\\c{c}er", "title": "Short-distance commuters in the smart city", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study models and examines commuter's preferences for short-distance\ntransportation modes, namely: walking, taking a bus or riding a metro. It is\nused a unique dataset from a large-scale field experiment in Singapore that\nprovides rich information about tens of thousands of commuters' behavior. In\ncontrast to the standard approach, this work does not relay on survey data.\nConversely, the chosen transportation modes are identified by processing raw\ndata (latitude, longitude, timestamp). The approach of this work exploits the\ninformation generated by the smart transportation system in the city that make\nsuitable the task of obtaining granular and nearly real-time data. Novel\nalgorithms are proposed with the intention to generate proxies for walkability\nand public transport attributes. The empirical results of the case study\nsuggest that commuters do no differentiate between public transport choices\n(bus and metro), therefore possible nested structures for the public transport\nmodes are rejected.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 07:46:09 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Benita", "Francisco", ""], ["Bansal", "Garvit", ""], ["Piliouras", "Georgios", ""], ["Tun\u00e7er", "Bige", ""]]}, {"id": "1902.08034", "submitter": "Silvija Kokalj-Filipovic", "authors": "Silvija Kokalj-Filipovic, Rob Miller, Nicholas Chang, Chi Leung Lau", "title": "Mitigation of Adversarial Examples in RF Deep Classifiers Utilizing\n  AutoEncoder Pre-training", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.06044", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples in machine learning for images are widely publicized and\nexplored. Illustrations of misclassifications caused by slightly perturbed\ninputs are abundant and commonly known (e.g., a picture of panda imperceptibly\nperturbed to fool the classifier into incorrectly labeling it as a gibbon).\nSimilar attacks on deep learning (DL) for radio frequency (RF) signals and\ntheir mitigation strategies are scarcely addressed in the published work. Yet,\nRF adversarial examples (AdExs) with minimal waveform perturbations can cause\ndrastic, targeted misclassification results, particularly against spectrum\nsensing/survey applications (e.g. BPSK is mistaken for 8-PSK). Our research on\ndeep learning AdExs and proposed defense mechanisms are RF-centric, and\nincorporate physical world, over-the-air (OTA) effects. We herein present\ndefense mechanisms based on pre-training the target classifier using an\nautoencoder. Our results validate this approach as a viable mitigation method\nto subvert adversarial attacks against deep learning-based communications and\nradar sensing systems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 06:04:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Kokalj-Filipovic", "Silvija", ""], ["Miller", "Rob", ""], ["Chang", "Nicholas", ""], ["Lau", "Chi Leung", ""]]}, {"id": "1902.08036", "submitter": "Kfir Levy Yehuda", "authors": "Pragnya Alatur, Kfir Y. Levy, Andreas Krause", "title": "Multi-Player Bandits: The Adversarial Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting where multiple players sequentially choose among a\ncommon set of actions (arms). Motivated by a cognitive radio networks\napplication, we assume that players incur a loss upon colliding, and that\ncommunication between players is not possible. Existing approaches assume that\nthe system is stationary. Yet this assumption is often violated in practice,\ne.g., due to signal strength fluctuations. In this work, we design the first\nMulti-player Bandit algorithm that provably works in arbitrarily changing\nenvironments, where the losses of the arms may even be chosen by an adversary.\nThis resolves an open problem posed by Rosenski, Shamir, and Szlak (2016).\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:30:14 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Alatur", "Pragnya", ""], ["Levy", "Kfir Y.", ""], ["Krause", "Andreas", ""]]}, {"id": "1902.08039", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Curiosity-Driven Experience Prioritization via Density Estimation", "comments": "Accepted by NIPS Deep RL Workshop, 2018, link:\n  https://sites.google.com/view/deep-rl-workshop-nips-2018 . arXiv admin note:\n  substantial text overlap with arXiv:1810.01363 and text overlap with\n  arXiv:1905.08786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reinforcement Learning (RL), an agent explores the environment and\ncollects trajectories into the memory buffer for later learning. However, the\ncollected trajectories can easily be imbalanced with respect to the achieved\ngoal states. The problem of learning from imbalanced data is a well-known\nproblem in supervised learning, but has not yet been thoroughly researched in\nRL. To address this problem, we propose a novel Curiosity-Driven Prioritization\n(CDP) framework to encourage the agent to over-sample those trajectories that\nhave rare achieved goal states. The CDP framework mimics the human learning\nprocess and focuses more on relatively uncommon events. We evaluate our methods\nusing the robotic environment provided by OpenAI Gym. The environment contains\nsix robot manipulation tasks. In our experiments, we combined CDP with Deep\nDeterministic Policy Gradient (DDPG) with or without Hindsight Experience\nReplay (HER). The experimental results show that CDP improves both performance\nand sample-efficiency of reinforcement learning agents, compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 12:31:23 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 11:38:48 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:15:29 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1902.08043", "submitter": "Hai-Jun Zhou", "authors": "Hai-Jun Zhou", "title": "Active online learning in the binary perceptron problem", "comments": "10 pages", "journal-ref": null, "doi": "10.1088/0253-6102/71/2/243", "report-no": null, "categories": "cs.LG cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary perceptron is the simplest artificial neural network formed by $N$\ninput units and one output unit, with the neural states and the synaptic\nweights all restricted to $\\pm 1$ values. The task in the teacher--student\nscenario is to infer the hidden weight vector by training on a set of labeled\npatterns. Previous efforts on the passive learning mode have shown that\nlearning from independent random patterns is quite inefficient. Here we\nconsider the active online learning mode in which the student designs every new\nIsing training pattern. We demonstrate that it is mathematically possible to\nachieve perfect (error-free) inference using only $N$ designed training\npatterns, but this is computationally unfeasible for large systems. We then\ninvestigate two Bayesian statistical designing protocols, which require $2.3 N$\nand $1.9 N$ training patterns, respectively, to achieve error-free inference.\nIf the training patterns are instead designed through deductive reasoning,\nperfect inference is achieved using $N\\!+\\!\\log_{2}\\!N$ samples. The\nperformance gap between Bayesian and deductive designing strategies may be\nshortened in future work by taking into account the possibility of ergodicity\nbreaking in the version space of the binary perceptron.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:35:16 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Zhou", "Hai-Jun", ""]]}, {"id": "1902.08068", "submitter": "Yu Guan", "authors": "Yan Gao, Yang Long, Yu Guan, Anna Basu, Jessica Baggaley, Thomas\n  Ploetz", "title": "Towards Reliable, Automated General Movement Assessment for Perinatal\n  Stroke Screening in Infants Using Wearable Accelerometers", "comments": "Gao and Long share equal contributions; This work has been accepted\n  for publication in ACM IMWUT (Ubicomp) 2019;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perinatal stroke (PS) is a serious condition that, if undetected and thus\nuntreated, often leads to life-long disability, in particular Cerebral Palsy\n(CP). In clinical settings, Prechtl's General Movement Assessment (GMA) can be\nused to classify infant movements using a Gestalt approach, identifying infants\nat high risk of developing PS. Training and maintenance of assessment skills\nare essential and expensive for the correct use of GMA, yet many practitioners\nlack these skills, preventing larger-scale screening and leading to significant\nrisks of missing opportunities for early detection and intervention for\naffected infants. We present an automated approach to GMA, based on body-worn\naccelerometers and a novel sensor data analysis method-Discriminative Pattern\nDiscovery (DPD)-that is designed to cope with scenarios where only coarse\nannotations of data are available for model training. We demonstrate the\neffectiveness of our approach in a study with 34 newborns (21 typically\ndeveloping infants and 13 PS infants with abnormal movements). Our method is\nable to correctly recognise the trials with abnormal movements with at least\nthe accuracy that is required by newly trained human annotators (75%), which is\nencouraging towards our ultimate goal of an automated PS screening system that\ncan be used population-wide.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:30:59 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Gao", "Yan", ""], ["Long", "Yang", ""], ["Guan", "Yu", ""], ["Basu", "Anna", ""], ["Baggaley", "Jessica", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1902.08077", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Sylvain Gelly, Gary B\\'ecigneul, Aliaksei\n  Severyn", "title": "Breaking the Softmax Bottleneck via Learnable Monotonic Pointwise\n  Non-linearities", "comments": null, "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Softmax function on top of a final linear layer is the de facto method to\noutput probability distributions in neural networks. In many applications such\nas language models or text generation, this model has to produce distributions\nover large output vocabularies. Recently, this has been shown to have limited\nrepresentational capacity due to its connection with the rank bottleneck in\nmatrix factorization. However, little is known about the limitations of\nLinear-Softmax for quantities of practical interest such as cross entropy or\nmode estimation, a direction that we explore here. As an efficient and\neffective solution to alleviate this issue, we propose to learn parametric\nmonotonic functions on top of the logits. We theoretically investigate the rank\nincreasing capabilities of such monotonic functions. Empirically, our method\nimproves in two different quality metrics over the traditional Linear-Softmax\nlayer in synthetic and real language model experiments, adding little time or\nmemory overhead, while being comparable to the more computationally expensive\nmixture of Softmaxes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 14:44:59 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 22:29:18 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["Gelly", "Sylvain", ""], ["B\u00e9cigneul", "Gary", ""], ["Severyn", "Aliaksei", ""]]}, {"id": "1902.08093", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Unsupervised Grounding of Plannable First-Order Logic Representation\n  from Images", "comments": "Accepted in 29th International Conference of Automated Planning and\n  Scheduling (ICAPS-2019), Planning and Learning track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is an increasing interest in obtaining the relational\nstructures of the environment in the Reinforcement Learning community. However,\nthe resulting \"relations\" are not the discrete, logical predicates compatible\nto the symbolic reasoning such as classical planning or goal recognition.\nMeanwhile, Latplan (Asai and Fukunaga 2018) bridged the gap between\ndeep-learning perceptual systems and symbolic classical planners. One key\ncomponent of the system is a Neural Network called State AutoEncoder (SAE),\nwhich encodes an image-based input into a propositional representation\ncompatible to classical planning. To get the best of both worlds, we propose\nFirst-Order State AutoEncoder, an unsupervised architecture for grounding the\nfirst-order logic predicates and facts. Each predicate models a relationship\nbetween objects by taking the interpretable arguments and returning a\npropositional value. In the experiment using 8-Puzzle and a photo-realistic\nBlocksworld environment, we show that (1) the resulting predicates capture the\ninterpretable relations (e.g. spatial), (2) they help obtaining the compact,\nabstract model of the environment, and finally, (3) the resulting model is\ncompatible to symbolic classical planning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 15:16:38 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 05:57:02 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 05:25:15 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 07:10:38 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1902.08102", "submitter": "Mark Rowland", "authors": "Mark Rowland, Robert Dadashi, Saurabh Kumar, R\\'emi Munos, Marc G.\n  Bellemare, Will Dabney", "title": "Statistics and Samples in Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unifying framework for designing and analysing distributional\nreinforcement learning (DRL) algorithms in terms of recursively estimating\nstatistics of the return distribution. Our key insight is that DRL algorithms\ncan be decomposed as the combination of some statistical estimator and a method\nfor imputing a return distribution consistent with that set of statistics. With\nthis new understanding, we are able to provide improved analyses of existing\nDRL algorithms as well as construct a new algorithm (EDRL) based upon\nestimation of the expectiles of the return distribution. We compare EDRL with\nexisting methods on a variety of MDPs to illustrate concrete aspects of our\nanalysis, and develop a deep RL variant of the algorithm, ER-DQN, which we\nevaluate on the Atari-57 suite of games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 15:37:49 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Rowland", "Mark", ""], ["Dadashi", "Robert", ""], ["Kumar", "Saurabh", ""], ["Munos", "R\u00e9mi", ""], ["Bellemare", "Marc G.", ""], ["Dabney", "Will", ""]]}, {"id": "1902.08129", "submitter": "Greg Yang", "authors": "Greg Yang, Jeffrey Pennington, Vinay Rao, Jascha Sohl-Dickstein, and\n  Samuel S. Schoenholz", "title": "A Mean Field Theory of Batch Normalization", "comments": "To appear in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a mean field theory for batch normalization in fully-connected\nfeedforward neural networks. In so doing, we provide a precise characterization\nof signal propagation and gradient backpropagation in wide batch-normalized\nnetworks at initialization. Our theory shows that gradient signals grow\nexponentially in depth and that these exploding gradients cannot be eliminated\nby tuning the initial weight variances or by adjusting the nonlinear activation\nfunction. Indeed, batch normalization itself is the cause of gradient\nexplosion. As a result, vanilla batch-normalized networks without skip\nconnections are not trainable at large depths for common initialization\nschemes, a prediction that we verify with a variety of empirical simulations.\nWhile gradient explosion cannot be eliminated, it can be reduced by tuning the\nnetwork close to the linear regime, which improves the trainability of deep\nbatch-normalized networks without residual connections. Finally, we investigate\nthe learning dynamics of batch-normalized networks and observe that after a\nsingle step of optimization the networks achieve a relatively stable\nequilibrium in which gradients have dramatically smaller dynamic range. Our\ntheory leverages Laplace, Fourier, and Gegenbauer transforms and we derive new\nidentities that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 16:36:13 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 21:42:13 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Yang", "Greg", ""], ["Pennington", "Jeffrey", ""], ["Rao", "Vinay", ""], ["Sohl-Dickstein", "Jascha", ""], ["Schoenholz", "Samuel S.", ""]]}, {"id": "1902.08134", "submitter": "Csaba Botos", "authors": "Botos Csaba, Adnane Boukhayma, Viveka Kulharia, Andr\\'as Horv\\'ath,\n  Philip H. S. Torr", "title": "Domain Partitioning Network", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard adversarial training involves two agents, namely a generator and a\ndiscriminator, playing a mini-max game. However, even if the players converge\nto an equilibrium, the generator may only recover a part of the target data\ndistribution, in a situation commonly referred to as mode collapse. In this\nwork, we present the Domain Partitioning Network (DoPaNet), a new approach to\ndeal with mode collapse in generative adversarial learning. We employ multiple\ndiscriminators, each encouraging the generator to cover a different part of the\ntarget distribution. To ensure these parts do not overlap and collapse into the\nsame mode, we add a classifier as a third agent in the game. The classifier\ndecides which discriminator the generator is trained against for each sample.\nThrough experiments on toy examples and real images, we show the merits of\nDoPaNet in covering the real distribution and its superiority with respect to\nthe competing methods. Besides, we also show that we can control the modes from\nwhich samples are generated using DoPaNet.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 16:45:20 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Csaba", "Botos", ""], ["Boukhayma", "Adnane", ""], ["Kulharia", "Viveka", ""], ["Horv\u00e1th", "Andr\u00e1s", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1902.08137", "submitter": "Jochen Laubrock", "authors": "David Dubray and Jochen Laubrock", "title": "Deep CNN-based Speech Balloon Detection and Segmentation for Comic Books", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for the automated detection and segmentation of speech\nballoons in comic books, including their carrier and tails. Our method is based\non a deep convolutional neural network that was trained on annotated pages of\nthe Graphic Narrative Corpus. More precisely, we are using a fully\nconvolutional network approach inspired by the U-Net architecture, combined\nwith a VGG-16 based encoder. The trained model delivers state-of-the-art\nperformance with an F1-score of over 0.94. Qualitative results suggest that\nwiggly tails, curved corners, and even illusory contours do not pose a major\nproblem. Furthermore, the model has learned to distinguish speech balloons from\ncaptions. We compare our model to earlier results and discuss some possible\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 16:49:12 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Dubray", "David", ""], ["Laubrock", "Jochen", ""]]}, {"id": "1902.08138", "submitter": "Elham Azizi", "authors": "Cassandra Burdziak, Elham Azizi, Sandhya Prabhakaran, Dana Pe'er", "title": "A Nonparametric Multi-view Model for Estimating Cell Type-Specific Gene\n  Regulatory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN q-bio.MN q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Bayesian hierarchical multi-view mixture model termed Symphony\nthat simultaneously learns clusters of cells representing cell types and their\nunderlying gene regulatory networks by integrating data from two views:\nsingle-cell gene expression data and paired epigenetic data, which is\ninformative of gene-gene interactions. This model improves interpretation of\nclusters as cell types with similar expression patterns as well as regulatory\nnetworks driving expression, by explaining gene-gene covariances with the\nbiological machinery regulating gene expression. We show the theoretical\nadvantages of the multi-view learning approach and present a Variational EM\ninference procedure. We demonstrate superior performance on both synthetic data\nand real genomic data with subtypes of peripheral blood cells compared to other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 16:55:28 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Burdziak", "Cassandra", ""], ["Azizi", "Elham", ""], ["Prabhakaran", "Sandhya", ""], ["Pe'er", "Dana", ""]]}, {"id": "1902.08142", "submitter": "Kaicheng Yu", "authors": "Kaicheng Yu, Christian Sciuto, Martin Jaggi, Claudiu Musat, Mathieu\n  Salzmann", "title": "Evaluating the Search Phase of Neural Architecture Search", "comments": "We find that random policy in NAS works amazingly well and propose an\n  evaluation framework to have a fair comparison. Adding additional results on\n  standard CNN search space used for weight sharing and NASBench-101. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Architecture Search (NAS) aims to facilitate the design of deep\nnetworks for new tasks. Existing techniques rely on two stages: searching over\nthe architecture space and validating the best architecture. NAS algorithms are\ncurrently compared solely based on their results on the downstream task. While\nintuitive, this fails to explicitly evaluate the effectiveness of their search\nstrategies. In this paper, we propose to evaluate the NAS search phase. To this\nend, we compare the quality of the solutions obtained by NAS search policies\nwith that of random architecture selection. We find that: (i) On average, the\nstate-of-the-art NAS algorithms perform similarly to the random policy; (ii)\nthe widely-used weight sharing strategy degrades the ranking of the NAS\ncandidates to the point of not reflecting their true performance, thus reducing\nthe effectiveness of the search process. We believe that our evaluation\nframework will be key to designing NAS strategies that consistently discover\narchitectures superior to random ones.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 17:11:56 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 11:42:39 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 17:07:59 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Yu", "Kaicheng", ""], ["Sciuto", "Christian", ""], ["Jaggi", "Martin", ""], ["Musat", "Claudiu", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "1902.08153", "submitter": "Steven Esser", "authors": "Steven K. Esser, Jeffrey L. McKinstry, Deepika Bablani, Rathinakumar\n  Appuswamy, Dharmendra S. Modha", "title": "Learned Step Size Quantization", "comments": "International Conference on Learning Representations (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks run with low precision operations at inference time offer power\nand space advantages over high precision alternatives, but need to overcome the\nchallenge of maintaining high accuracy as precision decreases. Here, we present\na method for training such networks, Learned Step Size Quantization, that\nachieves the highest accuracy to date on the ImageNet dataset when using\nmodels, from a variety of architectures, with weights and activations quantized\nto 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach\nfull precision baseline accuracy. Our approach builds upon existing methods for\nlearning weights in quantized networks by improving how the quantizer itself is\nconfigured. Specifically, we introduce a novel means to estimate and scale the\ntask loss gradient at each weight and activation layer's quantizer step size,\nsuch that it can be learned in conjunction with other network parameters. This\napproach works using different levels of precision as needed for a given system\nand requires only a simple modification of existing training code.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 17:31:32 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 21:18:07 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 03:30:49 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Esser", "Steven K.", ""], ["McKinstry", "Jeffrey L.", ""], ["Bablani", "Deepika", ""], ["Appuswamy", "Rathinakumar", ""], ["Modha", "Dharmendra S.", ""]]}, {"id": "1902.08160", "submitter": "Maxime Gabella", "authors": "Maxime Gabella", "title": "Topology of Learning in Artificial Neural Networks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3015790", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how neural networks learn remains one of the central challenges\nin machine learning research. From random at the start of training, the weights\nof a neural network evolve in such a way as to be able to perform a variety of\ntasks, like classifying images. Here we study the emergence of structure in the\nweights by applying methods from topological data analysis. We train simple\nfeedforward neural networks on the MNIST dataset and monitor the evolution of\nthe weights. When initialized to zero, the weights follow trajectories that\nbranch off recurrently, thus generating trees that describe the growth of the\neffective capacity of each layer. When initialized to tiny random values, the\nweights evolve smoothly along two-dimensional surfaces. We show that natural\ncoordinates on these learning surfaces correspond to important factors of\nvariation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 17:48:45 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 07:51:42 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 08:16:12 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 11:54:59 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Gabella", "Maxime", ""]]}, {"id": "1902.08171", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Xingguo Li and Jarvis Haupt", "title": "A Dictionary Based Generalization of Robust PCA", "comments": "5 pages; Index terms -- Low-rank, Dictionary sparse, Matrix Demixing,\n  and Generalized Robust PCA", "journal-ref": "2016 IEEE Global Conference on Signal and Information Processing\n  (GlobalSIP)", "doi": "10.1109/GlobalSIP.2016.7906054", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the decomposition of a data matrix, assumed to be a superposition\nof a low-rank component and a component which is sparse in a known dictionary,\nusing a convex demixing method. We provide a unified analysis, encompassing\nboth undercomplete and overcomplete dictionary cases, and show that the\nconstituent components can be successfully recovered under some relatively mild\nassumptions up to a certain $\\textit{global}$ sparsity level. Further, we\ncorroborate our theoretical results by presenting empirical evaluations in\nterms of phase transitions in rank and sparsity for various dictionary sizes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 18:16:18 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Li", "Xingguo", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.08179", "submitter": "Holden Lee", "authors": "Holden Lee, Oren Mangoubi, Nisheeth K. Vishnoi", "title": "Online Sampling from Log-Concave Distributions", "comments": "42 pages", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of convex functions $f_0, f_1, \\ldots, f_T$, we study the\nproblem of sampling from the Gibbs distribution $\\pi_t \\propto\ne^{-\\sum_{k=0}^tf_k}$ for each epoch $t$ in an online manner. Interest in this\nproblem derives from applications in machine learning, Bayesian statistics, and\noptimization where, rather than obtaining all the observations at once, one\nconstantly acquires new data, and must continuously update the distribution.\nOur main result is an algorithm that generates roughly independent samples from\n$\\pi_t$ for every epoch $t$ and, under mild assumptions, makes\n$\\mathrm{polylog}(T)$ gradient evaluations per epoch. All previous results\nimply a bound on the number of gradient or function evaluations which is at\nleast linear in $T$. Motivated by real-world applications, we assume that\nfunctions are smooth, their associated distributions have a bounded second\nmoment, and their minimizer drifts in a bounded manner, but do not assume they\nare strongly convex. In particular, our assumptions hold for online Bayesian\nlogistic regression, when the data satisfy natural regularity properties,\ngiving a sampling algorithm with updates that are poly-logarithmic in $T$. In\nsimulations, our algorithm achieves accuracy comparable to an algorithm\nspecialized to logistic regression. Key to our algorithm is a novel stochastic\ngradient Langevin dynamics Markov chain with a carefully designed variance\nreduction step and constant batch size. Technically, lack of strong convexity\nis a significant barrier to analysis and, here, our main contribution is a\nmartingale exit time argument that shows our Markov chain remains in a ball of\nradius roughly poly-logarithmic in $T$ for enough time to reach within\n$\\varepsilon$ of $\\pi_t$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 18:42:14 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 01:25:58 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 15:50:02 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 23:52:58 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lee", "Holden", ""], ["Mangoubi", "Oren", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1902.08192", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Jointly Sparse Convolutional Neural Networks in Dual Spatial-Winograd\n  Domains", "comments": "IEEE ICASSP 2019. arXiv admin note: substantial text overlap with\n  arXiv:1805.08303", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization of deep convolutional neural networks (CNNs)\nsuch that they provide good performance while having reduced complexity if\ndeployed on either conventional systems with spatial-domain convolution or\nlower-complexity systems designed for Winograd convolution. The proposed\nframework produces one compressed model whose convolutional filters can be made\nsparse either in the spatial domain or in the Winograd domain. Hence, the\ncompressed model can be deployed universally on any platform, without need for\nre-training on the deployed platform. To get a better compression ratio, the\nsparse model is compressed in the spatial domain that has a fewer number of\nparameters. From our experiments, we obtain $24.2\\times$ and $47.7\\times$\ncompressed models for ResNet-18 and AlexNet trained on the ImageNet dataset,\nwhile their computational cost is also reduced by $4.5\\times$ and $5.1\\times$,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:03:04 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1902.08213", "submitter": "David Harwath", "authors": "David Harwath and James Glass", "title": "Towards Visually Grounded Sub-Word Speech Unit Discovery", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the manner in which interpretable sub-word\nspeech units emerge within a convolutional neural network model trained to\nassociate raw speech waveforms with semantically related natural image scenes.\nWe show how diphone boundaries can be superficially extracted from the\nactivation patterns of intermediate layers of the model, suggesting that the\nmodel may be leveraging these events for the purpose of word recognition. We\npresent a series of experiments investigating the information encoded by these\nevents.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 19:00:30 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Harwath", "David", ""], ["Glass", "James", ""]]}, {"id": "1902.08226", "submitter": "Fuli Feng", "authors": "Fuli Feng, Xiangnan He, Jie Tang, Tat-Seng Chua", "title": "Graph Adversarial Training: Dynamically Regularizing Based on Graph\n  Structure", "comments": "Accepted by TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts show that neural networks are vulnerable to small but\nintentional perturbations on input features in visual classification tasks. Due\nto the additional consideration of connections between examples (\\eg articles\nwith citation link tend to be in the same class), graph neural networks could\nbe more sensitive to the perturbations, since the perturbations from connected\nexamples exacerbate the impact on a target example. Adversarial Training (AT),\na dynamic regularization technique, can resist the worst-case perturbations on\ninput features and is a promising choice to improve model robustness and\ngeneralization. However, existing AT methods focus on standard classification,\nbeing less effective when training models on graph since it does not model the\nimpact from connected examples.\n  In this work, we explore adversarial training on graph, aiming to improve the\nrobustness and generalization of models learned on graph. We propose Graph\nAdversarial Training (GraphAT), which takes the impact from connected examples\ninto account when learning to construct and resist perturbations. We give a\ngeneral formulation of GraphAT, which can be seen as a dynamic regularization\nscheme based on the graph structure. To demonstrate the utility of GraphAT, we\nemploy it on a state-of-the-art graph neural network model --- Graph\nConvolutional Network (GCN). We conduct experiments on two citation graphs\n(Citeseer and Cora) and a knowledge graph (NELL), verifying the effectiveness\nof GraphAT which outperforms normal training on GCN by 4.51% in node\nclassification accuracy. Codes are available via:\nhttps://github.com/fulifeng/GraphAT.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:18:01 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 04:14:27 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Tang", "Jie", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1902.08232", "submitter": "Yassine Benyahia", "authors": "Yassine Benyahia, Kaicheng Yu, Kamil Bennani-Smires, Martin Jaggi,\n  Anthony Davison, Mathieu Salzmann, Claudiu Musat", "title": "Overcoming Multi-Model Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a phenomenon, which we refer to as multi-model forgetting, that\noccurs when sequentially training multiple deep networks with partially-shared\nparameters; the performance of previously-trained models degrades as one\noptimizes a subsequent one, due to the overwriting of shared parameters. To\novercome this, we introduce a statistically-justified weight plasticity loss\nthat regularizes the learning of a model's shared parameters according to their\nimportance for the previous models, and demonstrate its effectiveness when\ntraining two models sequentially and for neural architecture search. Adding\nweight plasticity in neural architecture search preserves the best models to\nthe end of the search and yields improved results in both natural language\nprocessing and computer vision tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 19:51:35 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 18:59:39 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Benyahia", "Yassine", ""], ["Yu", "Kaicheng", ""], ["Bennani-Smires", "Kamil", ""], ["Jaggi", "Martin", ""], ["Davison", "Anthony", ""], ["Salzmann", "Mathieu", ""], ["Musat", "Claudiu", ""]]}, {"id": "1902.08234", "submitter": "Yeming Wen", "authors": "Yeming Wen, Kevin Luk, Maxime Gazeau, Guodong Zhang, Harris Chan,\n  Jimmy Ba", "title": "An Empirical Study of Large-Batch Stochastic Gradient Descent with\n  Structured Covariance Noise", "comments": null, "journal-ref": "The 23rd International Conference on Artificial Intelligence and\n  Statistics, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of batch-size in a stochastic optimization algorithm plays a\nsubstantial role for both optimization and generalization. Increasing the\nbatch-size used typically improves optimization but degrades generalization. To\naddress the problem of improving generalization while maintaining optimal\nconvergence in large-batch training, we propose to add covariance noise to the\ngradients. We demonstrate that the learning performance of our method is more\naccurately captured by the structure of the covariance matrix of the noise\nrather than by the variance of gradients. Moreover, over the convex-quadratic,\nwe prove in theory that it can be characterized by the Frobenius norm of the\nnoise matrix. Our empirical studies with standard deep learning\nmodel-architectures and datasets shows that our method not only improves\ngeneralization performance in large-batch training, but furthermore, does so in\na way where the optimization performance remains desirable and the training\nduration is not elongated.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 19:57:15 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 03:22:48 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 01:45:13 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 19:53:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wen", "Yeming", ""], ["Luk", "Kevin", ""], ["Gazeau", "Maxime", ""], ["Zhang", "Guodong", ""], ["Chan", "Harris", ""], ["Ba", "Jimmy", ""]]}, {"id": "1902.08261", "submitter": "Yingtao Tian", "authors": "Yingtao Tian, Jesse Engel", "title": "Latent Translation: Crossing Modalities by Bridging Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end optimization has achieved state-of-the-art performance on many\nspecific problems, but there is no straight-forward way to combine pretrained\nmodels for new problems. Here, we explore improving modularity by learning a\npost-hoc interface between two existing models to solve a new task.\nSpecifically, we take inspiration from neural machine translation, and cast the\nchallenging problem of cross-modal domain transfer as unsupervised translation\nbetween the latent spaces of pretrained deep generative models. By abstracting\naway the data representation, we demonstrate that it is possible to transfer\nacross different modalities (e.g., image-to-audio) and even different types of\ngenerative models (e.g., VAE-to-GAN). We compare to state-of-the-art techniques\nand find that a straight-forward variational autoencoder is able to best bridge\nthe two generative models through learning a shared latent space. We can\nfurther impose supervised alignment of attributes in both domains with a\nclassifier in the shared latent space. Through qualitative and quantitative\nevaluations, we demonstrate that locality and semantic alignment are preserved\nthrough the transfer process, as indicated by high transfer accuracies and\nsmooth interpolations within a class. Finally, we show this modular structure\nspeeds up training of new interface models by several orders of magnitude by\ndecoupling it from expensive retraining of base generative models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 20:54:51 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Tian", "Yingtao", ""], ["Engel", "Jesse", ""]]}, {"id": "1902.08265", "submitter": "Matt Jordan", "authors": "Matt Jordan, Naren Manoj, Surbhi Goel, Alexandros G. Dimakis", "title": "Quantifying Perceptual Distortion of Adversarial Examples", "comments": "18 pages, codebase/framework available at\n  https://github.com/revbucket/mister_ed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that additive threat models, which only permit the\naddition of bounded noise to the pixels of an image, are insufficient for fully\ncapturing the space of imperceivable adversarial examples. For example, small\nrotations and spatial transformations can fool classifiers, remain\nimperceivable to humans, but have large additive distance from the original\nimages. In this work, we leverage quantitative perceptual metrics like LPIPS\nand SSIM to define a novel threat model for adversarial attacks.\n  To demonstrate the value of quantifying the perceptual distortion of\nadversarial examples, we present and employ a unifying framework fusing\ndifferent attack styles. We first prove that our framework results in images\nthat are unattainable by attack styles in isolation. We then perform\nadversarial training using attacks generated by our framework to demonstrate\nthat networks are only robust to classes of adversarial perturbations they have\nbeen trained against, and combination attacks are stronger than any of their\nindividual components. Finally, we experimentally demonstrate that our combined\nattacks retain the same perceptual distortion but induce far higher\nmisclassification rates when compared against individual attacks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:02:58 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Jordan", "Matt", ""], ["Manoj", "Naren", ""], ["Goel", "Surbhi", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1902.08267", "submitter": "Il Yong Chun", "authors": "Il Yong Chun, David Hong, Ben Adcock, Jeffrey A. Fessler", "title": "Convolutional Analysis Operator Learning: Dependence on Training Data", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": "10.1109/LSP.2019.2921446", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional analysis operator learning (CAOL) enables the unsupervised\ntraining of (hierarchical) convolutional sparsifying operators or autoencoders\nfrom large datasets. One can use many training images for CAOL, but a precise\nunderstanding of the impact of doing so has remained an open question. This\npaper presents a series of results that lend insight into the impact of dataset\nsize on the filter update in CAOL. The first result is a general deterministic\nbound on errors in the estimated filters, and is followed by a bound on the\nexpected errors as the number of training samples increases. The second result\nprovides a high probability analogue. The bounds depend on properties of the\ntraining data, and we investigate their empirical values with real data. Taken\ntogether, these results provide evidence for the potential benefit of using\nmore training data in CAOL.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:06:13 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 01:26:09 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 03:13:41 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 22:15:49 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chun", "Il Yong", ""], ["Hong", "David", ""], ["Adcock", "Ben", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1902.08274", "submitter": "Abhishek Dubey", "authors": "Ayan Mukhopadhyay and Geoffrey Pettet and Chinmaya Samal and Abhishek\n  Dubey and Yevgeniy Vorobeychik", "title": "An Online Decision-Theoretic Pipeline for Responder Dispatch", "comments": "Appeared in ICCPS 2019", "journal-ref": null, "doi": "10.1145/3302509.3311055", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of dispatching emergency responders to service traffic accidents,\nfire, distress calls and crimes plagues urban areas across the globe. While\nsuch problems have been extensively looked at, most approaches are offline.\nSuch methodologies fail to capture the dynamically changing environments under\nwhich critical emergency response occurs, and therefore, fail to be implemented\nin practice. Any holistic approach towards creating a pipeline for effective\nemergency response must also look at other challenges that it subsumes -\npredicting when and where incidents happen and understanding the changing\nenvironmental dynamics. We describe a system that collectively deals with all\nthese problems in an online manner, meaning that the models get updated with\nstreaming data sources. We highlight why such an approach is crucial to the\neffectiveness of emergency response, and present an algorithmic framework that\ncan compute promising actions for a given decision-theoretic model for\nresponder dispatch. We argue that carefully crafted heuristic measures can\nbalance the trade-off between computational time and the quality of solutions\nachieved and highlight why such an approach is more scalable and tractable than\ntraditional approaches. We also present an online mechanism for incident\nprediction, as well as an approach based on recurrent neural networks for\nlearning and predicting environmental features that affect responder dispatch.\nWe compare our methodology with prior state-of-the-art and existing dispatch\nstrategies in the field, which show that our approach results in a reduction in\nresponse time with a drastic reduction in computational time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:27:43 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Mukhopadhyay", "Ayan", ""], ["Pettet", "Geoffrey", ""], ["Samal", "Chinmaya", ""], ["Dubey", "Abhishek", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1902.08276", "submitter": "Michael Andrews", "authors": "Michael Andrews, John Alison, Sitong An, Patrick Bryant, Bjorn Burkle,\n  Sergei Gleyzer, Meenakshi Narain, Manfred Paulini, Barnabas Poczos, Emanuele\n  Usai", "title": "End-to-End Jet Classification of Quarks and Gluons with the CMS Open\n  Data", "comments": "10 pages, 5 figures, 7 tables; v2: published version", "journal-ref": "Nucl. Instrum. Methods Phys. Res. A 977, 164304 (2020)", "doi": "10.1016/j.nima.2020.164304", "report-no": null, "categories": "hep-ex cs.CV cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the construction of end-to-end jet image classifiers based on\nsimulated low-level detector data to discriminate quark- vs. gluon-initiated\njets with high-fidelity simulated CMS Open Data. We highlight the importance of\nprecise spatial information and demonstrate competitive performance to existing\nstate-of-the-art jet classifiers. We further generalize the end-to-end approach\nto event-level classification of quark vs. gluon di-jet QCD events. We compare\nthe fully end-to-end approach to using hand-engineered features and demonstrate\nthat the end-to-end algorithm is robust against the effects of underlying event\nand pile-up.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:43:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 23:42:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Andrews", "Michael", ""], ["Alison", "John", ""], ["An", "Sitong", ""], ["Bryant", "Patrick", ""], ["Burkle", "Bjorn", ""], ["Gleyzer", "Sergei", ""], ["Narain", "Meenakshi", ""], ["Paulini", "Manfred", ""], ["Poczos", "Barnabas", ""], ["Usai", "Emanuele", ""]]}, {"id": "1902.08285", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Bayes Optimal Early Stopping Policies for Black-Box Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an optimal policy for adaptively restarting a randomized algorithm,\nbased on observed features of the run-so-far, so as to minimize the expected\ntime required for the algorithm to successfully terminate. Given a suitable\nBayesian prior, this result can be used to select the optimal black-box\noptimization algorithm from among a large family of algorithms that includes\nrandom search, Successive Halving, and Hyperband. On CIFAR-10 and ImageNet\nhyperparameter tuning problems, the proposed policies offer up to a factor of\n13 improvement over random search in terms of expected time to reach a given\ntarget accuracy, and up to a factor of 3 improvement over a baseline adaptive\npolicy that terminates a run whenever its accuracy is below-median.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 22:15:31 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1902.08295", "submitter": "Jonathan Shen", "authors": "Jonathan Shen, Patrick Nguyen, Yonghui Wu, Zhifeng Chen, Mia X. Chen,\n  Ye Jia, Anjuli Kannan, Tara Sainath, Yuan Cao, Chung-Cheng Chiu, Yanzhang He,\n  Jan Chorowski, Smit Hinsu, Stella Laurenzo, James Qin, Orhan Firat, Wolfgang\n  Macherey, Suyog Gupta, Ankur Bapna, Shuyuan Zhang, Ruoming Pang, Ron J.\n  Weiss, Rohit Prabhavalkar, Qiao Liang, Benoit Jacob, Bowen Liang, HyoukJoong\n  Lee, Ciprian Chelba, S\\'ebastien Jean, Bo Li, Melvin Johnson, Rohan Anil,\n  Rajat Tibrewal, Xiaobing Liu, Akiko Eriguchi, Navdeep Jaitly, Naveen Ari,\n  Colin Cherry, Parisa Haghani, Otavio Good, Youlong Cheng, Raziel Alvarez,\n  Isaac Caswell, Wei-Ning Hsu, Zongheng Yang, Kuan-Chieh Wang, Ekaterina\n  Gonina, Katrin Tomanek, Ben Vanik, Zelin Wu, Llion Jones, Mike Schuster,\n  Yanping Huang, Dehao Chen, Kazuki Irie, George Foster, John Richardson, Klaus\n  Macherey, Antoine Bruguier, Heiga Zen, Colin Raffel, Shankar Kumar, Kanishka\n  Rao, David Rybach, Matthew Murray, Vijayaditya Peddinti, Maxim Krikun,\n  Michiel A. U. Bacchiani, Thomas B. Jablin, Rob Suderman, Ian Williams,\n  Benjamin Lee, Deepti Bhatia, Justin Carlson, Semih Yavuz, Yu Zhang, Ian\n  McGraw, Max Galkin, Qi Ge, Golan Pundak, Chad Whipkey, Todd Wang, Uri Alon,\n  Dmitry Lepikhin, Ye Tian, Sara Sabour, William Chan, Shubham Toshniwal,\n  Baohua Liao, Michael Nirschl, Pat Rondon", "title": "Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lingvo is a Tensorflow framework offering a complete solution for\ncollaborative deep learning research, with a particular focus towards\nsequence-to-sequence models. Lingvo models are composed of modular building\nblocks that are flexible and easily extensible, and experiment configurations\nare centralized and highly customizable. Distributed training and quantized\ninference are supported directly within the framework, and it contains existing\nimplementations of a large number of utilities, helper functions, and the\nnewest research ideas. Lingvo has been used in collaboration by dozens of\nresearchers in more than 20 papers over the last two years. This document\noutlines the underlying design of Lingvo and serves as an introduction to the\nvarious pieces of the framework, while also offering examples of advanced\nfeatures that showcase the capabilities of the framework.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 22:55:09 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Shen", "Jonathan", ""], ["Nguyen", "Patrick", ""], ["Wu", "Yonghui", ""], ["Chen", "Zhifeng", ""], ["Chen", "Mia X.", ""], ["Jia", "Ye", ""], ["Kannan", "Anjuli", ""], ["Sainath", "Tara", ""], ["Cao", "Yuan", ""], ["Chiu", "Chung-Cheng", ""], ["He", "Yanzhang", ""], ["Chorowski", "Jan", ""], ["Hinsu", "Smit", ""], ["Laurenzo", "Stella", ""], ["Qin", "James", ""], ["Firat", "Orhan", ""], ["Macherey", "Wolfgang", ""], ["Gupta", "Suyog", ""], ["Bapna", "Ankur", ""], ["Zhang", "Shuyuan", ""], ["Pang", "Ruoming", ""], ["Weiss", "Ron J.", ""], ["Prabhavalkar", "Rohit", ""], ["Liang", "Qiao", ""], ["Jacob", "Benoit", ""], ["Liang", "Bowen", ""], ["Lee", "HyoukJoong", ""], ["Chelba", "Ciprian", ""], ["Jean", "S\u00e9bastien", ""], ["Li", "Bo", ""], ["Johnson", "Melvin", ""], ["Anil", "Rohan", ""], ["Tibrewal", "Rajat", ""], ["Liu", "Xiaobing", ""], ["Eriguchi", "Akiko", ""], ["Jaitly", "Navdeep", ""], ["Ari", "Naveen", ""], ["Cherry", "Colin", ""], ["Haghani", "Parisa", ""], ["Good", "Otavio", ""], ["Cheng", "Youlong", ""], ["Alvarez", "Raziel", ""], ["Caswell", "Isaac", ""], ["Hsu", "Wei-Ning", ""], ["Yang", "Zongheng", ""], ["Wang", "Kuan-Chieh", ""], ["Gonina", "Ekaterina", ""], ["Tomanek", "Katrin", ""], ["Vanik", "Ben", ""], ["Wu", "Zelin", ""], ["Jones", "Llion", ""], ["Schuster", "Mike", ""], ["Huang", "Yanping", ""], ["Chen", "Dehao", ""], ["Irie", "Kazuki", ""], ["Foster", "George", ""], ["Richardson", "John", ""], ["Macherey", "Klaus", ""], ["Bruguier", "Antoine", ""], ["Zen", "Heiga", ""], ["Raffel", "Colin", ""], ["Kumar", "Shankar", ""], ["Rao", "Kanishka", ""], ["Rybach", "David", ""], ["Murray", "Matthew", ""], ["Peddinti", "Vijayaditya", ""], ["Krikun", "Maxim", ""], ["Bacchiani", "Michiel A. U.", ""], ["Jablin", "Thomas B.", ""], ["Suderman", "Rob", ""], ["Williams", "Ian", ""], ["Lee", "Benjamin", ""], ["Bhatia", "Deepti", ""], ["Carlson", "Justin", ""], ["Yavuz", "Semih", ""], ["Zhang", "Yu", ""], ["McGraw", "Ian", ""], ["Galkin", "Max", ""], ["Ge", "Qi", ""], ["Pundak", "Golan", ""], ["Whipkey", "Chad", ""], ["Wang", "Todd", ""], ["Alon", "Uri", ""], ["Lepikhin", "Dmitry", ""], ["Tian", "Ye", ""], ["Sabour", "Sara", ""], ["Chan", "William", ""], ["Toshniwal", "Shubham", ""], ["Liao", "Baohua", ""], ["Nirschl", "Michael", ""], ["Rondon", "Pat", ""]]}, {"id": "1902.08297", "submitter": "Maher Nouiehed", "authors": "Maher Nouiehed, Maziar Sanjabi, Tianjian Huang, Jason D. Lee, Meisam\n  Razaviyayn", "title": "Solving a Class of Non-Convex Min-Max Games Using Iterative First Order\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications that arise in machine learning have surged significant\ninterest in solving min-max saddle point games. This problem has been\nextensively studied in the convex-concave regime for which a global equilibrium\nsolution can be computed efficiently. In this paper, we study the problem in\nthe non-convex regime and show that an \\varepsilon--first order stationary\npoint of the game can be computed when one of the player's objective can be\noptimized to global optimality efficiently. In particular, we first consider\nthe case where the objective of one of the players satisfies the\nPolyak-{\\L}ojasiewicz (PL) condition. For such a game, we show that a simple\nmulti-step gradient descent-ascent algorithm finds an \\varepsilon--first order\nstationary point of the problem in \\widetilde{\\mathcal{O}}(\\varepsilon^{-2})\niterations. Then we show that our framework can also be applied to the case\nwhere the objective of the \"max-player\" is concave. In this case, we propose a\nmulti-step gradient descent-ascent algorithm that finds an \\varepsilon--first\norder stationary point of the game in \\widetilde{\\cal O}(\\varepsilon^{-3.5})\niterations, which is the best known rate in the literature. We applied our\nalgorithm to a fair classification problem of Fashion-MNIST dataset and\nobserved that the proposed algorithm results in smoother training and better\ngeneralization.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 23:02:38 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 23:02:06 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 03:24:41 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Nouiehed", "Maher", ""], ["Sanjabi", "Maziar", ""], ["Huang", "Tianjian", ""], ["Lee", "Jason D.", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "1902.08304", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Xingguo Li, Jineng Ren, and Jarvis Haupt", "title": "A Dictionary-Based Generalization of Robust PCA with Applications to\n  Target Localization in Hyperspectral Imaging", "comments": "21 Pages; Index terms - Low-rank, Matrix Demixing, Dictionary Sparse,\n  Target Localization, and Robust PCA", "journal-ref": "IEEE Transactions on Signal Processing ( March 2020, Volume: 68,\n  Pages 1760 - 1775)", "doi": "10.1109/TSP.2020.2977458", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the decomposition of a data matrix assumed to be a superposition\nof a low-rank matrix and a component which is sparse in a known dictionary,\nusing a convex demixing method. We consider two sparsity structures for the\nsparse factor of the dictionary sparse component, namely entry-wise and\ncolumn-wise sparsity, and provide a unified analysis, encompassing both\nundercomplete and the overcomplete dictionary cases, to show that the\nconstituent matrices can be successfully recovered under some relatively mild\nconditions on incoherence, sparsity, and rank. We leverage these results to\nlocalize targets of interest in a hyperspectral (HS) image based on their\nspectral signature(s) using the a priori known characteristic spectral\nresponses of the target. We corroborate our theoretical results and analyze\ntarget localization performance of our approach via experimental evaluations\nand comparisons to related techniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 23:26:35 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 01:23:47 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 00:01:37 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Li", "Xingguo", ""], ["Ren", "Jineng", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.08313", "submitter": "Yinjie Huang", "authors": "YInjie Huang and Cong Li and Michael Georgiopoulos and Georgios C.\n  Anagnostopoulos", "title": "Reduced-Rank Local Distance Metric Learning for k-NN Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for local distance metric learning based on sample\nsimilarity as side information. These local metrics, which utilize conical\ncombinations of metric weight matrices, are learned from the pooled spatial\ncharacteristics of the data, as well as the similarity profiles between the\npairs of samples, whose distances are measured. The main objective of our\nframework is to yield metrics, such that the resulting distances between\nsimilar samples are small and distances between dissimilar samples are above a\ncertain threshold. For learning and inference purposes, we describe a\ntransductive, as well as an inductive algorithm; the former approach naturally\nbefits our framework, while the latter one is provided in the interest of\nfaster learning. Experimental results on a collection of classification\nproblems imply that the new methods may exhibit notable performance advantages\nover alternative metric learning approaches that have recently appeared in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 23:46:37 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Huang", "YInjie", ""], ["Li", "Cong", ""], ["Georgiopoulos", "Michael", ""], ["Anagnostopoulos", "Georgios C.", ""]]}, {"id": "1902.08314", "submitter": "Ivo Trowitzsch", "authors": "Ivo Trowitzsch, Jalil Taghia, Youssef Kashef, Klaus Obermayer", "title": "The NIGENS General Sound Events Database", "comments": "update to v4: added classification rate table, corrections, updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational auditory scene analysis is gaining interest in the last years.\nTrailing behind the more mature field of speech recognition, it is particularly\ngeneral sound event detection that is attracting increasing attention. Crucial\nfor training and testing reasonable models is having available enough suitable\ndata -- until recently, general sound event databases were hardly found. We\nrelease and present a database with 714 wav files containing isolated high\nquality sound events of 14 different types, plus 303 `general' wav files of\nanything else but these 14 types. All sound events are strongly labeled with\nperceptual on- and offset times, paying attention to omitting in-between\nsilences. The amount of isolated sound events, the quality of annotations, and\nthe particular general sound class distinguish NIGENS from other databases.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 23:51:59 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 10:51:31 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 19:53:34 GMT"}, {"version": "v4", "created": "Wed, 1 Jan 2020 23:22:00 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Trowitzsch", "Ivo", ""], ["Taghia", "Jalil", ""], ["Kashef", "Youssef", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1902.08321", "submitter": "Christopher Wikle", "authors": "Christopher K. Wikle", "title": "Comparison of Deep Neural Networks and Deep Hierarchical Models for\n  Spatio-Temporal Data", "comments": "26 pages, including 6 figures and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal data are ubiquitous in the agricultural, ecological, and\nenvironmental sciences, and their study is important for understanding and\npredicting a wide variety of processes. One of the difficulties with modeling\nspatial processes that change in time is the complexity of the dependence\nstructures that must describe how such a process varies, and the presence of\nhigh-dimensional complex data sets and large prediction domains. It is\nparticularly challenging to specify parameterizations for nonlinear dynamic\nspatio-temporal models (DSTMs) that are simultaneously useful scientifically\nand efficient computationally. Statisticians have developed deep hierarchical\nmodels that can accommodate process complexity as well as the uncertainties in\nthe predictions and inference. However, these models can be expensive and are\ntypically application specific. On the other hand, the machine learning\ncommunity has developed alternative \"deep learning\" approaches for nonlinear\nspatio-temporal modeling. These models are flexible yet are typically not\nimplemented in a probabilistic framework. The two paradigms have many things in\ncommon and suggest hybrid approaches that can benefit from elements of each\nframework. This overview paper presents a brief introduction to the deep\nhierarchical DSTM (DH-DSTM) framework, and deep models in machine learning,\nculminating with the deep neural DSTM (DN-DSTM). Recent approaches that combine\nelements from DH-DSTMs and echo state network DN-DSTMs are presented as\nillustrations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 00:47:15 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Wikle", "Christopher K.", ""]]}, {"id": "1902.08329", "submitter": "Jian Zhang", "authors": "Jinyin Chen, Jian Zhang, Xuanheng Xu, Chengbo Fu, Dan Zhang, Qingpeng\n  Zhang, Qi Xuan", "title": "E-LSTM-D: A Deep Learning Framework for Dynamic Network Link Prediction", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the potential relations between nodes in networks, known as link\nprediction, has long been a challenge in network science. However, most studies\njust focused on link prediction of static network, while real-world networks\nalways evolve over time with the occurrence and vanishing of nodes and links.\nDynamic network link prediction thus has been attracting more and more\nattention since it can better capture the evolution nature of networks, but\nstill most algorithms fail to achieve satisfied prediction accuracy. Motivated\nby the excellent performance of Long Short-Term Memory (LSTM) in processing\ntime series, in this paper, we propose a novel Encoder-LSTM-Decoder (E-LSTM-D)\ndeep learning model to predict dynamic links end to end. It could handle long\nterm prediction problems, and suits the networks of different scales with\nfine-tuned structure. To the best of our knowledge, it is the first time that\nLSTM, together with an encoder-decoder architecture, is applied to link\nprediction in dynamic networks. This new model is able to automatically learn\nstructural and temporal features in a unified framework, which can predict the\nlinks that never appear in the network before. The extensive experiments show\nthat our E-LSTM-D model significantly outperforms newly proposed dynamic\nnetwork link prediction methods and obtain the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 01:40:51 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Jian", ""], ["Xu", "Xuanheng", ""], ["Fu", "Chengbo", ""], ["Zhang", "Dan", ""], ["Zhang", "Qingpeng", ""], ["Xuan", "Qi", ""]]}, {"id": "1902.08336", "submitter": "Gavin Weiguang Ding", "authors": "Gavin Weiguang Ding, Kry Yik Chau Lui, Xiaomeng Jin, Luyu Wang,\n  Ruitong Huang", "title": "On the Sensitivity of Adversarial Robustness to Input Data Distributions", "comments": "ICLR 2019, Seventh International Conference on Learning\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to small adversarial perturbations. Existing\nliterature largely focused on understanding and mitigating the vulnerability of\nlearned models. In this paper, we demonstrate an intriguing phenomenon about\nthe most popular robust training method in the literature, adversarial\ntraining: Adversarial robustness, unlike clean accuracy, is sensitive to the\ninput data distribution. Even a semantics-preserving transformations on the\ninput data distribution can cause a significantly different robustness for the\nadversarial trained model that is both trained and evaluated on the new\ndistribution. Our discovery of such sensitivity on data distribution is based\non a study which disentangles the behaviors of clean accuracy and robust\naccuracy of the Bayes classifier. Empirical investigations further confirm our\nfinding. We construct semantically-identical variants for MNIST and CIFAR10\nrespectively, and show that standardly trained models achieve comparable clean\naccuracies on them, but adversarially trained models achieve significantly\ndifferent robustness accuracies. This counter-intuitive phenomenon indicates\nthat input data distribution alone can affect the adversarial robustness of\ntrained neural networks, not necessarily the tasks themselves. Lastly, we\ndiscuss the practical implications on evaluating adversarial robustness, and\nmake initial attempts to understand this complex phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:03:17 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Ding", "Gavin Weiguang", ""], ["Lui", "Kry Yik Chau", ""], ["Jin", "Xiaomeng", ""], ["Wang", "Luyu", ""], ["Huang", "Ruitong", ""]]}, {"id": "1902.08341", "submitter": "Masanori Yamada", "authors": "Masanori Yamada, Heecheol Kim, Kosuke Miyoshi, Hiroshi Yamakawa", "title": "FAVAE: Sequence Disentanglement using Information Bottleneck Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the factorized action variational autoencoder (FAVAE), a\nstate-of-the-art generative model for learning disentangled and interpretable\nrepresentations from sequential data via the information bottleneck without\nsupervision. The purpose of disentangled representation learning is to obtain\ninterpretable and transferable representations from data. We focused on the\ndisentangled representation of sequential data since there is a wide range of\npotential applications if disentanglement representation is extended to\nsequential data such as video, speech, and stock market. Sequential data are\ncharacterized by dynamic and static factors: dynamic factors are time\ndependent, and static factors are independent of time. Previous models\ndisentangle static and dynamic factors by explicitly modeling the priors of\nlatent variables to distinguish between these factors. However, these models\ncannot disentangle representations between dynamic factors, such as\ndisentangling \"picking up\" and \"throwing\" in robotic tasks. FAVAE can\ndisentangle multiple dynamic factors. Since it does not require modeling\npriors, it can disentangle \"between\" dynamic factors. We conducted experiments\nto show that FAVAE can extract disentangled dynamic factors.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:30:41 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 05:27:44 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Yamada", "Masanori", ""], ["Kim", "Heecheol", ""], ["Miyoshi", "Kosuke", ""], ["Yamakawa", "Hiroshi", ""]]}, {"id": "1902.08349", "submitter": "Sek Chai", "authors": "Aswin Raghavan, Jesse Hostetler, Sek Chai", "title": "Generative Memory for Lifelong Reinforcement Learning", "comments": "Abstract NICE 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research is focused on understanding and applying biological memory\ntransfers to new AI systems that can fundamentally improve their performance,\nthroughout their fielded lifetime experience. We leverage current understanding\nof biological memory transfer to arrive at AI algorithms for memory\nconsolidation and replay. In this paper, we propose the use of generative\nmemory that can be recalled in batch samples to train a multi-task agent in a\npseudo-rehearsal manner. We show results motivating the need for task-agnostic\nseparation of latent space for the generative memory to address issues of\ncatastrophic forgetting in lifelong learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:58:50 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Raghavan", "Aswin", ""], ["Hostetler", "Jesse", ""], ["Chai", "Sek", ""]]}, {"id": "1902.08355", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Tong Gao, Sohee Yang, Jaejun Yoo, Jung-Woo Ha", "title": "Large-Scale Answerer in Questioner's Mind for Visual Dialog Question\n  Generation", "comments": "Accepted for ICLR 2019. Camera ready version. Our code is publically\n  available: https://github.com/naver/aqm-plus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answerer in Questioner's Mind (AQM) is an information-theoretic framework\nthat has been recently proposed for task-oriented dialog systems. AQM benefits\nfrom asking a question that would maximize the information gain when it is\nasked. However, due to its intrinsic nature of explicitly calculating the\ninformation gain, AQM has a limitation when the solution space is very large.\nTo address this, we propose AQM+ that can deal with a large-scale problem and\nask a question that is more coherent to the current context of the dialog. We\nevaluate our method on GuessWhich, a challenging task-oriented visual dialog\nproblem, where the number of candidate classes is near 10K. Our experimental\nresults and ablation studies show that AQM+ outperforms the state-of-the-art\nmodels by a remarkable margin with a reasonable approximation. In particular,\nthe proposed AQM+ reduces more than 60% of error as the dialog proceeds, while\nthe comparative algorithms diminish the error by less than 6%. Based on our\nresults, we argue that AQM+ is a general task-oriented dialog algorithm that\ncan be applied for non-yes-or-no responses.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 03:46:53 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Gao", "Tong", ""], ["Yang", "Sohee", ""], ["Yoo", "Jaejun", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1902.08373", "submitter": "Bishan Yang", "authors": "Igor Labutov, Bishan Yang, Tom Mitchell", "title": "Learning to Learn Semantic Parsers from Natural Language Supervision", "comments": "published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans, we often rely on language to learn language. For example, when\ncorrected in a conversation, we may learn from that correction, over time\nimproving our language fluency. Inspired by this observation, we propose a\nlearning algorithm for training semantic parsers from supervision (feedback)\nexpressed in natural language. Our algorithm learns a semantic parser from\nusers' corrections such as \"no, what I really meant was before his job, not\nafter\", by also simultaneously learning to parse this natural language feedback\nin order to leverage it as a form of supervision. Unlike supervision with\ngold-standard logical forms, our method does not require the user to be\nfamiliar with the underlying logical formalism, and unlike supervision from\ndenotation, it does not require the user to know the correct answer to their\nquery. This makes our learning algorithm naturally scalable in settings where\nexisting conversational logs are available and can be leveraged as training\ndata. We construct a novel dataset of natural language feedback in a\nconversational setting, and show that our method is effective at learning a\nsemantic parser from such natural language supervision.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 06:28:36 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Labutov", "Igor", ""], ["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1902.08380", "submitter": "Yu Wang", "authors": "Yu Wang, Siqi Wu, Bin Yu", "title": "Unique Sharp Local Minimum in $\\ell_1$-minimization Complete Dictionary\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of globally recovering a dictionary from a set of\nsignals via $\\ell_1$-minimization. We assume that the signals are generated as\ni.i.d. random linear combinations of the $K$ atoms from a complete reference\ndictionary $D^*\\in \\mathbb R^{K\\times K}$, where the linear combination\ncoefficients are from either a Bernoulli type model or exact sparse model.\nFirst, we obtain a necessary and sufficient norm condition for the reference\ndictionary $D^*$ to be a sharp local minimum of the expected $\\ell_1$ objective\nfunction. Our result substantially extends that of Wu and Yu (2015) and allows\nthe combination coefficient to be non-negative. Secondly, we obtain an explicit\nbound on the region within which the objective value of the reference\ndictionary is minimal. Thirdly, we show that the reference dictionary is the\nunique sharp local minimum, thus establishing the first known global property\nof $\\ell_1$-minimization dictionary learning. Motivated by the theoretical\nresults, we introduce a perturbation-based test to determine whether a\ndictionary is a sharp local minimum of the objective function. In addition, we\nalso propose a new dictionary learning algorithm based on Block Coordinate\nDescent, called DL-BCD, which is guaranteed to have monotonic convergence.\nSimulation studies show that DL-BCD has competitive performance in terms of\nrecovery rate compared to many state-of-the-art dictionary learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 06:57:21 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Wang", "Yu", ""], ["Wu", "Siqi", ""], ["Yu", "Bin", ""]]}, {"id": "1902.08391", "submitter": "Meysam Sadeghi", "authors": "Meysam Sadeghi and Erik G. Larsson", "title": "Physical Adversarial Attacks Against End-to-End Autoencoder\n  Communication Systems", "comments": "to appear at IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that end-to-end learning of communication systems through deep neural\nnetwork (DNN) autoencoders can be extremely vulnerable to physical adversarial\nattacks. Specifically, we elaborate how an attacker can craft effective\nphysical black-box adversarial attacks. Due to the openness (broadcast nature)\nof the wireless channel, an adversary transmitter can increase the\nblock-error-rate of a communication system by orders of magnitude by\ntransmitting a well-designed perturbation signal over the channel. We reveal\nthat the adversarial attacks are more destructive than jamming attacks. We also\nshow that classical coding schemes are more robust than autoencoders against\nboth adversarial and jamming attacks. The codes are available at [1].\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 08:16:59 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Sadeghi", "Meysam", ""], ["Larsson", "Erik G.", ""]]}, {"id": "1902.08394", "submitter": "Xianbin Wang", "authors": "Xianbin Wang and Huazi Zhang and Rong Li and Lingchen Huang and\n  Shengchen Dai and Yourui Huangfu and Jun Wang", "title": "Learning to Flip Successive Cancellation Decoding of Polar Codes with\n  LSTM Networks", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to successive cancellation (SC) flip decoding of polar codes is to\naccurately identify the first error bit. The optimal flipping strategy is\nconsidered difficult due to lack of an analytical solution. Alternatively, we\npropose a deep learning aided SC flip algorithm. Specifically, before each SC\ndecoding attempt, a long short-term memory (LSTM) network is exploited to\neither (i) locate the first error bit, or (ii) undo a previous `wrong' flip. In\neach SC attempt, the sequence of log likelihood ratios (LLRs) derived in the\nprevious SC attempt is exploited to decide which action to take. Accordingly, a\ntwo-stage training method of the LSTM network is proposed, i.e., learn to\nlocate first error bits in the first stage, and then to undo `wrong' flips in\nthe second stage. Simulation results show that the proposed approach identifies\nerror bits more accurately and achieves better performance than the\nstate-of-the-art SC flip algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 08:26:29 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 01:50:55 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Wang", "Xianbin", ""], ["Zhang", "Huazi", ""], ["Li", "Rong", ""], ["Huang", "Lingchen", ""], ["Dai", "Shengchen", ""], ["Huangfu", "Yourui", ""], ["Wang", "Jun", ""]]}, {"id": "1902.08399", "submitter": "Marcelo Daniel Gutierrez Mallea", "authors": "Marcelo Daniel Gutierrez Mallea, Peter Meltzer and Peter J Bentley", "title": "Capsule Neural Networks for Graph Classification using Explicit\n  Tensorial Graph Representations", "comments": "This work has been submitted to the International Joint Conference on\n  Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a significant problem in many scientific domains. It\naddresses tasks such as the classification of proteins and chemical compounds\ninto categories according to their functions, or chemical and structural\nproperties. In a supervised setting, this problem can be framed as learning the\nstructure, features and relationships between features within a set of labelled\ngraphs and being able to correctly predict the labels or categories of unseen\ngraphs.\n  A significant difficulty in this task arises when attempting to apply\nestablished classification algorithms due to the requirement for fixed size\nmatrix or tensor representations of the graphs which may vary greatly in their\nnumbers of nodes and edges. Building on prior work combining explicit tensor\nrepresentations with a standard image-based classifier, we propose a model to\nperform graph classification by extracting fixed size tensorial information\nfrom each graph in a given set, and using a Capsule Network to perform\nclassification.\n  The graphs we consider here are undirected and with categorical features on\nthe nodes. Using standard benchmarking chemical and protein datasets, we\ndemonstrate that our graph Capsule Network classification model using an\nexplicit tensorial representation of the graphs is competitive with current\nstate of the art graph kernels and graph neural network models despite only\nlimited hyper-parameter searching.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 08:39:18 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Mallea", "Marcelo Daniel Gutierrez", ""], ["Meltzer", "Peter", ""], ["Bentley", "Peter J", ""]]}, {"id": "1902.08401", "submitter": "Mohamed Ishmael Belghazi", "authors": "Mohamed Ishmael Belghazi, Maxime Oquab, Yann LeCun, David Lopez-Paz", "title": "Learning about an exponential amount of conditional distributions", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Neural Conditioner (NC), a self-supervised machine able to\nlearn about all the conditional distributions of a random vector $X$. The NC is\na function $NC(x \\cdot a, a, r)$ that leverages adversarial training to match\neach conditional distribution $P(X_r|X_a=x_a)$. After training, the NC\ngeneralizes to sample from conditional distributions never seen, including the\njoint distribution. The NC is also able to auto-encode examples, providing data\nrepresentations useful for downstream classification tasks. In sum, the NC\nintegrates different self-supervised tasks (each being the estimation of a\nconditional distribution) and levels of supervision (partially observed data)\nseamlessly into a single learning experience.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 08:45:01 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Belghazi", "Mohamed Ishmael", ""], ["Oquab", "Maxime", ""], ["LeCun", "Yann", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1902.08411", "submitter": "Zhaofei Yu", "authors": "Yajing Zheng, Shanshan Jia, Zhaofei Yu, Tiejun Huang, Jian K. Liu, and\n  Yonghong Tian", "title": "Probabilistic Inference of Binary Markov Random Fields in Spiking Neural\n  Networks through Mean-field Approximation", "comments": "Accepted in Neural Networks", "journal-ref": null, "doi": "10.1016/j.neunet.2020.03.003", "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies have suggested that the cognitive process of the human brain\nis realized as probabilistic inference and can be further modeled by\nprobabilistic graphical models like Markov random fields. Nevertheless, it\nremains unclear how probabilistic inference can be implemented by a network of\nspiking neurons in the brain. Previous studies have tried to relate the\ninference equation of binary Markov random fields to the dynamic equation of\nspiking neural networks through belief propagation algorithm and\nreparameterization, but they are valid only for Markov random fields with\nlimited network structure. In this paper, we propose a spiking neural network\nmodel that can implement inference of arbitrary binary Markov random fields.\nSpecifically, we design a spiking recurrent neural network and prove that its\nneuronal dynamics are mathematically equivalent to the inference process of\nMarkov random fields by adopting mean-field theory. Furthermore, our mean-field\napproach unifies previous works. Theoretical analysis and experimental results,\ntogether with the application to image denoising, demonstrate that our proposed\nspiking neural network can get comparable results to that of mean-field\ninference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 09:18:51 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:10:41 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 10:38:00 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zheng", "Yajing", ""], ["Jia", "Shanshan", ""], ["Yu", "Zhaofei", ""], ["Huang", "Tiejun", ""], ["Liu", "Jian K.", ""], ["Tian", "Yonghong", ""]]}, {"id": "1902.08412", "submitter": "Daniel Z\\\"ugner", "authors": "Daniel Z\\\"ugner, Stephan G\\\"unnemann", "title": "Adversarial Attacks on Graph Neural Networks via Meta Learning", "comments": "ICLR submission", "journal-ref": "International Conference on Learning Representations (ICLR), New\n  Orleans, LA, USA, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for graphs have advanced the state of the art on many\ntasks. Despite their recent success, little is known about their robustness. We\ninvestigate training time attacks on graph neural networks for node\nclassification that perturb the discrete graph structure. Our core principle is\nto use meta-gradients to solve the bilevel problem underlying training-time\nattacks, essentially treating the graph as a hyperparameter to optimize. Our\nexperiments show that small graph perturbations consistently lead to a strong\ndecrease in performance for graph convolutional networks, and even transfer to\nunsupervised embeddings. Remarkably, the perturbations created by our algorithm\ncan misguide the graph neural networks such that they perform worse than a\nsimple baseline that ignores all relational information. Our attacks do not\nassume any knowledge about or access to the target classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 09:20:05 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1902.08431", "submitter": "Vanderson Martins do Rosario", "authors": "Vanderson Martins do Rosario, Edson Borin, Mauricio Breternitz Jr", "title": "The Multi-Lane Capsule Network (MLCN)", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2915661", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Multi-Lane Capsule Networks (MLCN), which are a separable and\nresource efficient organization of Capsule Networks (CapsNet) that allows\nparallel processing, while achieving high accuracy at reduced cost. A MLCN is\ncomposed of a number of (distinct) parallel lanes, each contributing to a\ndimension of the result, trained using the routing-by-agreement organization of\nCapsNet. Our results indicate similar accuracy with a much reduced cost in\nnumber of parameters for the Fashion-MNIST and Cifar10 datsets. They also\nindicate that the MLCN outperforms the original CapsNet when using a proposed\nnovel configuration for the lanes. MLCN also has faster training and inference\ntimes, being more than two-fold faster than the original CapsNet in the same\naccelerator.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:44:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Rosario", "Vanderson Martins do", ""], ["Borin", "Edson", ""], ["Breternitz", "Mauricio", "Jr"]]}, {"id": "1902.08438", "submitter": "Aravind Rajeswaran", "authors": "Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey Levine", "title": "Online Meta-Learning", "comments": "ICML 2019. The first two authors contributed equally. Expanded\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central capability of intelligent systems is the ability to continuously\nbuild upon previous experiences to speed up and enhance learning of new tasks.\nTwo distinct research paradigms have studied this question. Meta-learning views\nthis problem as learning a prior over model parameters that is amenable for\nfast adaptation on a new task, but typically assumes the set of tasks are\navailable together as a batch. In contrast, online (regret based) learning\nconsiders a sequential setting in which problems are revealed one after the\nother, but conventionally train only a single model without any task-specific\nadaptation. This work introduces an online meta-learning setting, which merges\nideas from both the aforementioned paradigms to better capture the spirit and\npractice of continual lifelong learning. We propose the follow the meta leader\nalgorithm which extends the MAML algorithm to this setting. Theoretically, this\nwork provides an $\\mathcal{O}(\\log T)$ regret guarantee with only one\nadditional higher order smoothness assumption in comparison to the standard\nonline setting. Our experimental evaluation on three different large-scale\ntasks suggest that the proposed algorithm significantly outperforms\nalternatives based on traditional online learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 11:20:42 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 19:25:58 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 01:02:06 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 20:50:53 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Finn", "Chelsea", ""], ["Rajeswaran", "Aravind", ""], ["Kakade", "Sham", ""], ["Levine", "Sergey", ""]]}, {"id": "1902.08440", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "Robust Graph Embedding with Noisy Link Weights", "comments": "14 pages (with Supplementary Material), 3 figures, AISTATS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\beta$-graph embedding for robustly learning feature vectors from\ndata vectors and noisy link weights. A newly introduced empirical moment\n$\\beta$-score reduces the influence of contamination and robustly measures the\ndifference between the underlying correct expected weights of links and the\nspecified generative model. The proposed method is computationally tractable;\nwe employ a minibatch-based efficient stochastic algorithm and prove that this\nalgorithm locally minimizes the empirical moment $\\beta$-score. We conduct\nnumerical experiments on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 11:21:34 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1902.08452", "submitter": "Oren Mangoubi", "authors": "Oren Mangoubi and Nisheeth K. Vishnoi", "title": "Nonconvex sampling with the Metropolis-adjusted Langevin algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Langevin Markov chain algorithms are widely deployed methods to sample\nfrom distributions in challenging high-dimensional and non-convex statistics\nand machine learning applications. Despite this, current bounds for the\nLangevin algorithms are slower than those of competing algorithms in many\nimportant situations, for instance when sampling from weakly log-concave\ndistributions, or when sampling or optimizing non-convex log-densities. In this\npaper, we obtain improved bounds in many of these situations, showing that the\nMetropolis-adjusted Langevin algorithm (MALA) is faster than the best bounds\nfor its competitor algorithms when the target distribution satisfies weak\nthird- and fourth- order regularity properties associated with the input data.\nIn many settings, our regularity conditions are weaker than the usual Euclidean\noperator norm regularity properties, allowing us to show faster bounds for a\nmuch larger class of distributions than would be possible with the usual\nEuclidean operator norm approach, including in statistics and machine learning\napplications where the data satisfy a certain incoherence condition. In\nparticular, we show that using our regularity conditions one can obtain faster\nbounds for applications which include sampling problems in Bayesian logistic\nregression with weakly convex priors, and the nonconvex optimization problem of\nlearning linear classifiers with zero-one loss functions.\n  Our main technical contribution in this paper is our analysis of the\nMetropolis acceptance probability of MALA in terms of its \"energy-conservation\nerror,\" and our bound for this error in terms of third- and fourth- order\nregularity conditions. Our combination of this higher-order analysis of the\nenergy conservation error with the conductance method is key to obtaining\nbounds which have a sub-linear dependence on the dimension $d$ in the\nnon-strongly logconcave setting.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:05:58 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 16:40:25 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Mangoubi", "Oren", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1902.08455", "submitter": "Juho Lauri", "authors": "Juho Lauri and Sourav Dutta", "title": "Fine-grained Search Space Classification for Hard Enumeration Variants\n  of Subset Problems", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, powerful, and flexible machine learning framework for\n(i) reducing the search space of computationally difficult enumeration variants\nof subset problems and (ii) augmenting existing state-of-the-art solvers with\ninformative cues arising from the input distribution. We instantiate our\nframework for the problem of listing all maximum cliques in a graph, a central\nproblem in network analysis, data mining, and computational biology. We\ndemonstrate the practicality of our approach on real-world networks with\nmillions of vertices and edges by not only retaining all optimal solutions, but\nalso aggressively pruning the input instance size resulting in several fold\nspeedups of state-of-the-art algorithms. Finally, we explore the limits of\nscalability and robustness of our proposed framework, suggesting that\nsupervised learning is viable for tackling NP-hard problems in practice.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:11:33 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Lauri", "Juho", ""], ["Dutta", "Sourav", ""]]}, {"id": "1902.08466", "submitter": "Mohamed Souhayel Abassi", "authors": "Mohamed Souhayel Abassi", "title": "Diversity of Ensembles for Data Stream Classification", "comments": "9 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When constructing a classifier ensemble, diversity among the base classifiers\nis one of the important characteristics. Several studies have been made in the\ncontext of standard static data, in particular, when analyzing the relationship\nbetween a high ensemble predictive performance and the diversity of its\ncomponents. Besides, ensembles of learning machines have been performed to\nlearn in the presence of concept drift and adapt to it. However, diversity\nmeasures have not received much research interest in evolving data streams.\nOnly a few researchers directly consider promoting diversity while constructing\nan ensemble or rebuilding them in the moment of detecting drifts. In this\npaper, we present a theoretical analysis of different diversity measures and\nrelate them to the success of ensemble learning algorithms for streaming data.\nThe analysis provides a deeper understanding of the concept of diversity and\nits impact on online ensemble Learning in the presence of concept drift. More\nprecisely, we are interested in answering the following research question;\nWhich commonly used diversity measures are used in the context of static-data\nensembles and how far are they applicable in the context of streaming data\nensembles?\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:32:57 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Abassi", "Mohamed Souhayel", ""]]}, {"id": "1902.08472", "submitter": "Bernd Taschler", "authors": "Bernd Taschler, Frank Dondelinger, Sach Mukherjee", "title": "Model-based clustering in very high dimensions via adaptive projections", "comments": "25 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture models are a standard approach to dealing with heterogeneous data\nwith non-i.i.d. structure. However, when the dimension $p$ is large relative to\nsample size $n$ and where either or both of means and covariances/graphical\nmodels may differ between the latent groups, mixture models face statistical\nand computational difficulties and currently available methods cannot\nrealistically go beyond $p \\! \\sim \\! 10^4$ or so. We propose an approach\ncalled Model-based Clustering via Adaptive Projections (MCAP). Instead of\nestimating mixtures in the original space, we work with a low-dimensional\nrepresentation obtained by linear projection. The projection dimension itself\nplays an important role and governs a type of bias-variance tradeoff with\nrespect to recovery of the relevant signals. MCAP sets the projection dimension\nautomatically in a data-adaptive manner, using a proxy for the assignment risk.\nCombining a full covariance formulation with the adaptive projection allows\ndetection of both mean and covariance signals in very high dimensional\nproblems. We show real-data examples in which covariance signals are reliably\ndetected in problems with $p \\! \\sim \\! 10^4$ or more, and simulations going up\nto $p = 10^6$. In some examples, MCAP performs well even when the mean signal\nis entirely removed, leaving differential covariance structure in the\nhigh-dimensional space as the only signal. Across a number of regimes, MCAP\nperforms as well or better than a range of existing methods, including a\nrecently-proposed $\\ell_1$-penalized approach; and performance remains broadly\nstable with increasing dimension. MCAP can be run \"out of the box\" and is fast\nenough for interactive use on large-$p$ problems using standard desktop\ncomputing resources.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:46:45 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Taschler", "Bernd", ""], ["Dondelinger", "Frank", ""], ["Mukherjee", "Sach", ""]]}, {"id": "1902.08480", "submitter": "Gabriele Abbati", "authors": "Gabriele Abbati, Philippe Wenk, Michael A Osborne, Andreas Krause,\n  Bernhard Sch\\\"olkopf and Stefan Bauer", "title": "AReS and MaRS - Adversarial and MMD-Minimizing Regression for SDEs", "comments": "Published at the Thirty-sixth International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic differential equations are an important modeling class in many\ndisciplines. Consequently, there exist many methods relying on various\ndiscretization and numerical integration schemes. In this paper, we propose a\nnovel, probabilistic model for estimating the drift and diffusion given noisy\nobservations of the underlying stochastic system. Using state-of-the-art\nadversarial and moment matching inference techniques, we avoid the\ndiscretization schemes of classical approaches. This leads to significant\nimprovements in parameter accuracy and robustness given random initial guesses.\nOn four established benchmark systems, we compare the performance of our\nalgorithms to state-of-the-art solutions based on extended Kalman filtering and\nGaussian processes.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 13:03:04 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 15:34:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Abbati", "Gabriele", ""], ["Wenk", "Philippe", ""], ["Osborne", "Michael A", ""], ["Krause", "Andreas", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "1902.08495", "submitter": "Yury Maximov", "authors": "Alexandra Burashnikova, Yury Maximov and Massih-Reza Amini", "title": "Sequential Learning over Implicit Feedback for Robust Large-Scale\n  Recommender Systems", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a robust sequential learning strategy for training\nlarge-scale Recommender Systems (RS) over implicit feedback mainly in the form\nof clicks. Our approach relies on the minimization of a pairwise ranking loss\nover blocks of consecutive items constituted by a sequence of non-clicked items\nfollowed by a clicked one for each user. Parameter updates are discarded if for\na given user the number of sequential blocks is below or above some given\nthresholds estimated over the distribution of the number of blocks in the\ntraining set. This is to prevent from an abnormal number of clicks over some\ntargeted items, mainly due to bots; or very few user interactions. Both\nscenarios affect the decision of RS and imply a shift over the distribution of\nitems that are shown to the users. We provide a theoretical analysis showing\nthat in the case where the ranking loss is convex, the deviation between the\nloss with respect to the sequence of weights found by the proposed algorithm\nand its minimum is bounded. Furthermore, experimental results on five\nlarge-scale collections demonstrate the efficiency of the proposed algorithm\nwith respect to the state-of-the-art approaches, both regarding different\nranking measures and computation time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 02:46:39 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Burashnikova", "Alexandra", ""], ["Maximov", "Yury", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1902.08496", "submitter": "Ashadullah Shawon", "authors": "Ashadullah Shawon, Syed Tauhid Zuhori, Firoz Mahmud, Md. Jamil-Ur\n  Rahman", "title": "Web Links Prediction And Category-Wise Recommendation Based On Browser\n  History", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A web browser should not be only for browsing web pages but also help users\nto find out their target websites and recommend similar type websites based on\ntheir behavior. Throughout this paper, we propose two methods to make a web\nbrowser more intelligent about link prediction which works during typing on\naddress-bar and recommendation of websites according to several categories. Our\nproposed link prediction system is actually frecency prediction which is\npredicted based on the first visit, last visit and URL counts. But recommend\nsystem is the most challenging as it is needed to classify web URLs according\nto names without visiting web pages. So we use existing model for URL\nclassification. The only existing approach gives unsatisfactory results and low\naccuracy. So we add hyperparameter optimization with an existing approach that\nfinds the best parameters for existing URL classification model and gives\nbetter accuracy. In this paper, we propose a category wise recommendation\nsystem using frecency value and the total visit of individual URL category.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 07:23:55 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Shawon", "Ashadullah", ""], ["Zuhori", "Syed Tauhid", ""], ["Mahmud", "Firoz", ""], ["Rahman", "Md. Jamil-Ur", ""]]}, {"id": "1902.08498", "submitter": "Cun Mu", "authors": "Cun Mu, Jun Zhao, Guang Yang, Binwei Yang, Zheng Yan", "title": "Fast and Exact Nearest Neighbor Search in Hamming Space on Full-Text\n  Search Engines", "comments": "A shorter version of the paper is accepted by SISAP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing interest has been witnessed recently from both academia and\nindustry in building nearest neighbor search (NNS) solutions on top of\nfull-text search engines. Compared with other NNS systems, such solutions are\ncapable of effectively reducing main memory consumption, coherently supporting\nmulti-model search and being immediately ready for production deployment. In\nthis paper, we continue the journey to explore specifically how to empower\nfull-text search engines with fast and exact NNS in Hamming space (i.e., the\nset of binary codes). By revisiting three techniques (bit operation, subs-code\nfiltering and data preprocessing with permutation) in information retrieval\nliterature, we develop a novel engineering solution for full-text search\nengines to efficiently accomplish this special but important NNS task. In the\nexperiment, we show that our proposed approach enables full-text search engines\nto achieve significant speed-ups over its state-of-the-art term match approach\nfor NNS within binary codes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 19:31:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 00:38:09 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mu", "Cun", ""], ["Zhao", "Jun", ""], ["Yang", "Guang", ""], ["Yang", "Binwei", ""], ["Yan", "Zheng", ""]]}, {"id": "1902.08527", "submitter": "Xiaoxiao He", "authors": "Xiaoxiao He, Chaowei Tan, Yuting Qiao, Virak Tan, Dimitris Metaxas,\n  Kang Li", "title": "Effective 3D Humerus and Scapula Extraction using Low-contrast and\n  High-shape-variability MR Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For the initial shoulder preoperative diagnosis, it is essential to obtain a\nthree-dimensional (3D) bone mask from medical images, e.g., magnetic resonance\n(MR). However, obtaining high-resolution and dense medical scans is both costly\nand time-consuming. In addition, the imaging parameters for each 3D scan may\nvary from time to time and thus increase the variance between images.\nTherefore, it is practical to consider the bone extraction on low-resolution\ndata which may influence imaging contrast and make the segmentation work\ndifficult. In this paper, we present a joint segmentation for the humerus and\nscapula bones on a small dataset with low-contrast and high-shape-variability\n3D MR images. The proposed network has a deep end-to-end architecture to obtain\nthe initial 3D bone masks. Because the existing scarce and inaccurate\nhuman-labeled ground truth, we design a self-reinforced learning strategy to\nincrease performance. By comparing with the non-reinforced segmentation and a\nclassical multi-atlas method with joint label fusion, the proposed approach\nobtains better results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 15:16:25 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["He", "Xiaoxiao", ""], ["Tan", "Chaowei", ""], ["Qiao", "Yuting", ""], ["Tan", "Virak", ""], ["Metaxas", "Dimitris", ""], ["Li", "Kang", ""]]}, {"id": "1902.08538", "submitter": "Mohammad Salahuddin", "authors": "Abbas Abou Daya, Mohammad A. Salahuddin, Noura Limam, and Raouf\n  Boutaba", "title": "A Graph-Based Machine Learning Approach for Bot Detection", "comments": "IFIP/IEEE International Symposium on Integrated Network\n  Management,Washington DC, USA, April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bot detection using machine learning (ML), with network flow-level features,\nhas been extensively studied in the literature. However, existing flow-based\napproaches typically incur a high computational overhead and do not completely\ncapture the network communication patterns, which can expose additional aspects\nof malicious hosts. Recently, bot detection systems which leverage\ncommunication graph analysis using ML have gained attention to overcome these\nlimitations. A graph-based approach is rather intuitive, as graphs are true\nrepresentations of network communications. In this paper, we propose a\ntwo-phased, graph-based bot detection system which leverages both unsupervised\nand supervised ML. The first phase prunes presumable benign hosts, while the\nsecond phase achieves bot detection with high precision. Our system detects\nmultiple types of bots and is robust to zero-day attacks. It also accommodates\ndifferent network topologies and is suitable for large-scale data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 15:54:28 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Daya", "Abbas Abou", ""], ["Salahuddin", "Mohammad A.", ""], ["Limam", "Noura", ""], ["Boutaba", "Raouf", ""]]}, {"id": "1902.08552", "submitter": "Ziqi Yang", "authors": "Ziqi Yang, Ee-Chien Chang, Zhenkai Liang", "title": "Adversarial Neural Network Inversion via Auxiliary Knowledge Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of deep learning technique has raised new privacy concerns about the\ntraining data and test data. In this work, we investigate the model inversion\nproblem in the adversarial settings, where the adversary aims at inferring\ninformation about the target model's training data and test data from the\nmodel's prediction values. We develop a solution to train a second neural\nnetwork that acts as the inverse of the target model to perform the inversion.\nThe inversion model can be trained with black-box accesses to the target model.\nWe propose two main techniques towards training the inversion model in the\nadversarial settings. First, we leverage the adversary's background knowledge\nto compose an auxiliary set to train the inversion model, which does not\nrequire access to the original training data. Second, we design a\ntruncation-based technique to align the inversion model to enable effective\ninversion of the target model from partial predictions that the adversary\nobtains on victim user's data. We systematically evaluate our inversion\napproach in various machine learning tasks and model architectures on multiple\nimage datasets. Our experimental results show that even with no full knowledge\nabout the target model's training data, and with only partial prediction\nvalues, our inversion approach is still able to perform accurate inversion of\nthe target model, and outperform previous approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 16:38:29 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Yang", "Ziqi", ""], ["Chang", "Ee-Chien", ""], ["Liang", "Zhenkai", ""]]}, {"id": "1902.08571", "submitter": "Stephen L. France", "authors": "Stephen L. France and Ulas Akkucuk", "title": "A Review, Framework and R toolkit for Exploring, Evaluating, and\n  Comparing Visualizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a review and synthesis of methods of evaluating\ndimensionality reduction techniques. Particular attention is paid to rank-order\nneighborhood evaluation metrics. A framework is created for exploring\ndimensionality reduction quality through visualization. An associated toolkit\nis implemented in R. The toolkit includes scatter plots, heat maps, loess\nsmoothing, and performance lift diagrams. The overall rationale is to help\nresearchers compare dimensionality reduction techniques and use visual insights\nto help select and improve techniques. Examples are given for dimensionality\nreduction of manifolds and for the dimensionality reduction applied to a\nconsumer survey dataset.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 17:32:25 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["France", "Stephen L.", ""], ["Akkucuk", "Ulas", ""]]}, {"id": "1902.08572", "submitter": "Jonathan Donier", "authors": "Jonathan Donier", "title": "Capacity allocation through neural network layers", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capacity analysis has been recently introduced as a way to analyze how linear\nmodels distribute their modelling capacity across the input space. In this\npaper, we extend the notion of capacity allocation to the case of neural\nnetworks with non-linear layers. We show that under some hypotheses the problem\nis equivalent to linear capacity allocation, within some extended input space\nthat factors in the non-linearities. We introduce the notion of layer\ndecoupling, which quantifies the degree to which a non-linear activation\ndecouples its outputs, and show that it plays a central role in capacity\nallocation through layers. In the highly non-linear limit where decoupling is\ntotal, we show that the propagation of capacity throughout the layers follows a\nsimple markovian rule, which turns into a diffusion PDE in the limit of deep\nnetworks with residual layers. This allows us to recover some known results\nabout deep neural networks, such as the size of the effective receptive field,\nor why ResNets avoid the shattering problem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 17:36:33 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:07:06 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Donier", "Jonathan", ""]]}, {"id": "1902.08588", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Francois Belletti, Sagar Jain, Minmin Chen, Alex Beutel,\n  Can Xu, Ed H. Chi", "title": "Towards Neural Mixture Recommender for Long Range Dependent User\n  Sequences", "comments": "Accepted at WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313650", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding temporal dynamics has proved to be highly valuable for accurate\nrecommendation. Sequential recommenders have been successful in modeling the\ndynamics of users and items over time. However, while different model\narchitectures excel at capturing various temporal ranges or dynamics, distinct\napplication contexts require adapting to diverse behaviors. In this paper we\nexamine how to build a model that can make use of different temporal ranges and\ndynamics depending on the request context. We begin with the analysis of an\nanonymized Youtube dataset comprising millions of user sequences. We quantify\nthe degree of long-range dependence in these sequences and demonstrate that\nboth short-term and long-term dependent behavioral patterns co-exist. We then\npropose a neural Multi-temporal-range Mixture Model (M3) as a tailored solution\nto deal with both short-term and long-term dependencies. Our approach employs a\nmixture of models, each with a different temporal range. These models are\ncombined by a learned gating mechanism capable of exerting different model\ncombinations given different contextual information. In empirical evaluations\non a public dataset and our own anonymized YouTube dataset, M3 consistently\noutperforms state-of-the-art sequential recommendation methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 18:12:37 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Tang", "Jiaxi", ""], ["Belletti", "Francois", ""], ["Jain", "Sagar", ""], ["Chen", "Minmin", ""], ["Beutel", "Alex", ""], ["Xu", "Can", ""], ["Chi", "Ed H.", ""]]}, {"id": "1902.08593", "submitter": "Joshua Reid", "authors": "Larkin Liu, Richard Downe and Joshua Reid", "title": "Multi-Armed Bandit Strategies for Non-Stationary Reward Distributions\n  and Delayed Feedback Processes", "comments": "13 pages, manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A survey is performed of various Multi-Armed Bandit (MAB) strategies in order\nto examine their performance in circumstances exhibiting non-stationary\nstochastic reward functions in conjunction with delayed feedback. We run\nseveral MAB simulations to simulate an online eCommerce platform for grocery\npick up, optimizing for product availability. In this work, we evaluate several\npopular MAB strategies, such as $\\epsilon$-greedy, UCB1, and Thompson Sampling.\nWe compare the respective performances of each MAB strategy in the context of\nregret minimization. We run the analysis in the scenario where the reward\nfunction is non-stationary. Furthermore, the process experiences delayed\nfeedback, where the reward function is not immediately responsive to the arm\nplayed. We devise a new adaptive technique (AG1) tailored for non-stationary\nreward functions in the delayed feedback scenario. The results of the\nsimulation show show superior performance in the context of regret minimization\ncompared to traditional MAB strategies.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 18:19:17 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:50:34 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 18:16:49 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Liu", "Larkin", ""], ["Downe", "Richard", ""], ["Reid", "Joshua", ""]]}, {"id": "1902.08594", "submitter": "Roel Dobbe", "authors": "Oscar Sondermeijer, Roel Dobbe, Daniel Arnold, Claire Tomlin, Tam\\'as\n  Keviczky", "title": "Regression-based Inverter Control for Decentralized Optimal Power Flow\n  and Voltage Regulation", "comments": "Cite as: Oscar Sondermeijer, Roel Dobbe, Daniel Arnold, Claire Tomlin\n  and Tam\\'as Keviczky, \"Regression-based Inverter Control for Decentralized\n  Optimal Power Flow and Voltage Regulation\", IEEE Power & Energy Society\n  General Meeting, Boston, July 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic power inverters are capable of quickly delivering reactive power\nto maintain customer voltages within operating tolerances and to reduce system\nlosses in distribution grids. This paper proposes a systematic and data-driven\napproach to determine reactive power inverter output as a function of local\nmeasurements in a manner that obtains near optimal results. First, we use a\nnetwork model and historic load and generation data and do optimal power flow\nto compute globally optimal reactive power injections for all controllable\ninverters in the network. Subsequently, we use regression to find a function\nfor each inverter that maps its local historical data to an approximation of\nits optimal reactive power injection. The resulting functions then serve as\ndecentralized controllers in the participating inverters to predict the optimal\ninjection based on a new local measurements. The method achieves near-optimal\nresults when performing voltage- and capacity-constrained loss minimization and\nvoltage flattening, and allows for an efficient volt-VAR optimization (VVO)\nscheme in which legacy control equipment collaborates with existing inverters\nto facilitate safe operation of distribution networks with higher levels of\ndistributed generation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 23:20:52 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Sondermeijer", "Oscar", ""], ["Dobbe", "Roel", ""], ["Arnold", "Daniel", ""], ["Tomlin", "Claire", ""], ["Keviczky", "Tam\u00e1s", ""]]}, {"id": "1902.08605", "submitter": "Gabriel Huang", "authors": "Gabriel Huang, Hugo Larochelle, Simon Lacoste-Julien", "title": "Are Few-Shot Learning Benchmarks too Simple ? Solving them without Task\n  Supervision at Test-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that several popular few-shot learning benchmarks can be solved with\nvarying degrees of success without using support set Labels at Test-time (LT).\nTo this end, we introduce a new baseline called Centroid Networks, a\nmodification of Prototypical Networks in which the support set labels are\nhidden from the method at test-time and have to be recovered through\nclustering. A benchmark that can be solved perfectly without LT does not\nrequire proper task adaptation and is therefore inadequate for evaluating\nfew-shot methods. In practice, most benchmarks cannot be solved perfectly\nwithout LT, but running our baseline on any new combinations of architectures\nand datasets gives insights on the baseline performance to be expected from\nleveraging a good representation, before any adaptation to the test-time\nlabels.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 18:46:06 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:11:28 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 21:51:53 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Huang", "Gabriel", ""], ["Larochelle", "Hugo", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1902.08627", "submitter": "Ethan Roberts", "authors": "Ethan Roberts, Bruce A. Bassett, Michelle Lochner", "title": "Bayesian Anomaly Detection and Classification", "comments": "29 pages, 13 figures, Demo available:\n  https://github.com/ethyroberts/BADAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical uncertainties are rarely incorporated in machine learning\nalgorithms, especially for anomaly detection. Here we present the Bayesian\nAnomaly Detection And Classification (BADAC) formalism, which provides a\nunified statistical approach to classification and anomaly detection within a\nhierarchical Bayesian framework. BADAC deals with uncertainties by\nmarginalising over the unknown, true, value of the data. Using simulated data\nwith Gaussian noise, BADAC is shown to be superior to standard algorithms in\nboth classification and anomaly detection performance in the presence of\nuncertainties, though with significantly increased computational cost.\nAdditionally, BADAC provides well-calibrated classification probabilities,\nvaluable for use in scientific pipelines. We show that BADAC can work in online\nmode and is fairly robust to model errors, which can be diagnosed through\nmodel-selection methods. In addition it can perform unsupervised new class\ndetection and can naturally be extended to search for anomalous subsets of\ndata. BADAC is therefore ideal where computational cost is not a limiting\nfactor and statistical rigour is important. We discuss approximations to speed\nup BADAC, such as the use of Gaussian processes, and finally introduce a new\nmetric, the Rank-Weighted Score (RWS), that is particularly suited to\nevaluating the ability of algorithms to detect anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:00:06 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Roberts", "Ethan", ""], ["Bassett", "Bruce A.", ""], ["Lochner", "Michelle", ""]]}, {"id": "1902.08638", "submitter": "Sindhu Ghanta", "authors": "Sindhu Ghanta, Sriram Subramanian, Lior Khermosh, Harshil Shah, Yakov\n  Goldberg, Swaminathan Sundararaman, Drew Roselli, Nisha Talagala", "title": "MPP: Model Performance Predictor", "comments": "submitted to OpML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operations is a key challenge in the domain of machine learning pipeline\ndeployments involving monitoring and management of real-time prediction\nquality. Typically, metrics like accuracy, RMSE etc., are used to track the\nperformance of models in deployment. However, these metrics cannot be\ncalculated in production due to the absence of labels. We propose using an ML\nalgorithm, Model Performance Predictor (MPP), to track the performance of the\nmodels in deployment. We argue that an ensemble of such metrics can be used to\ncreate a score representing the prediction quality in production. This in turn\nfacilitates formulation and customization of ML alerts, that can be escalated\nby an operations team to the data science team. Such a score automates\nmonitoring and enables ML deployments at scale.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:16:32 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ghanta", "Sindhu", ""], ["Subramanian", "Sriram", ""], ["Khermosh", "Lior", ""], ["Shah", "Harshil", ""], ["Goldberg", "Yakov", ""], ["Sundararaman", "Swaminathan", ""], ["Roselli", "Drew", ""], ["Talagala", "Nisha", ""]]}, {"id": "1902.08639", "submitter": "Yinjie Huang", "authors": "Yinjie Huang and Michael Georgiopoulos and Georgios C. Anagnostopoulos", "title": "Learning Hash Function through Codewords", "comments": "arXiv admin note: substantial text overlap with arXiv:1508.03285", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel hash learning approach that has the\nfollowing main distinguishing features, when compared to past frameworks.\nFirst, the codewords are utilized in the Hamming space as ancillary techniques\nto accomplish its hash learning task. These codewords, which are inferred from\nthe data, attempt to capture grouping aspects of the data's hash codes.\nFurthermore, the proposed framework is capable of addressing supervised,\nunsupervised and, even, semi-supervised hash learning scenarios. Additionally,\nthe framework adopts a regularization term over the codewords, which\nautomatically chooses the codewords for the problem. To efficiently solve the\nproblem, one Block Coordinate Descent algorithm is showcased in the paper. We\nalso show that one step of the algorithms can be casted into several Support\nVector Machine problems which enables our algorithms to utilize efficient\nsoftware package. For the regularization term, a closed form solution of the\nproximal operator is provided in the paper. A series of comparative experiments\nfocused on content-based image retrieval highlights its performance advantages.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:18:02 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Huang", "Yinjie", ""], ["Georgiopoulos", "Michael", ""], ["Anagnostopoulos", "Georgios C.", ""]]}, {"id": "1902.08646", "submitter": "Fabio Kepler", "authors": "F\\'abio Kepler, Jonay Tr\\'enous, Marcos Treviso, Miguel Vera, Andr\\'e\n  F. T. Martins", "title": "OpenKiwi: An Open Source Framework for Quality Estimation", "comments": "Published at the Annual Meeting of the Association for Computational\n  Linguistics (ACL) 2019: System Demonstrations\n  (https://aclweb.org/anthology/papers/P/P19/P19-3020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce OpenKiwi, a PyTorch-based open source framework for translation\nquality estimation. OpenKiwi supports training and testing of word-level and\nsentence-level quality estimation systems, implementing the winning systems of\nthe WMT 2015-18 quality estimation campaigns. We benchmark OpenKiwi on two\ndatasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art\nperformance on the word-level tasks and near state-of-the-art in the\nsentence-level tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:27:45 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 15:07:52 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kepler", "F\u00e1bio", ""], ["Tr\u00e9nous", "Jonay", ""], ["Treviso", "Marcos", ""], ["Vera", "Miguel", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1902.08647", "submitter": "Tomer Koren", "authors": "Anupam Gupta, Tomer Koren, Kunal Talwar", "title": "Better Algorithms for Stochastic Bandits with Adversarial Corruptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic multi-armed bandits problem in the presence of\nadversarial corruption. We present a new algorithm for this problem whose\nregret is nearly optimal, substantially improving upon previous work. Our\nalgorithm is agnostic to the level of adversarial contamination and can\ntolerate a significant amount of corruption with virtually no degradation in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:28:06 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 05:42:35 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Gupta", "Anupam", ""], ["Koren", "Tomer", ""], ["Talwar", "Kunal", ""]]}, {"id": "1902.08648", "submitter": "Benjamin Chamberlain", "authors": "Benjamin Paul Chamberlain, Stephen R. Hardwick, David R. Wardrope,\n  Fabon Dzogang, Fabio Daolio, Sa\\'ul Vargas", "title": "Scalable Hyperbolic Recommender Systems", "comments": "11 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large scale hyperbolic recommender system. We discuss why\nhyperbolic geometry is a more suitable underlying geometry for many\nrecommendation systems and cover the fundamental milestones and insights that\nwe have gained from its development. In doing so, we demonstrate the viability\nof hyperbolic geometry for recommender systems, showing that they significantly\noutperform Euclidean models on datasets with the properties of complex\nnetworks. Key to the success of our approach are the novel choice of underlying\nhyperbolic model and the use of the Einstein midpoint to define an asymmetric\nrecommender system in hyperbolic space. These choices allow us to scale to\nmillions of users and hundreds of thousands of items.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:32:28 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chamberlain", "Benjamin Paul", ""], ["Hardwick", "Stephen R.", ""], ["Wardrope", "David R.", ""], ["Dzogang", "Fabon", ""], ["Daolio", "Fabio", ""], ["Vargas", "Sa\u00fal", ""]]}, {"id": "1902.08649", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli", "title": "Saliency Learning: Teaching the Model Where to Pay Attention", "comments": "Accepted as a short paper at NAACL 2019. 10 pages, 2 figures, 6\n  tables", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a compelling solution to many NLP tasks with\nremarkable performances. However, due to their opacity, such models are hard to\ninterpret and trust. Recent work on explaining deep models has introduced\napproaches to provide insights toward the model's behaviour and predictions,\nwhich are helpful for assessing the reliability of the model's predictions.\nHowever, such methods do not improve the model's reliability. In this paper, we\naim to teach the model to make the right prediction for the right reason by\nproviding explanation training and ensuring the alignment of the model's\nexplanation with the ground truth explanation. Our experimental results on\nmultiple tasks and datasets demonstrate the effectiveness of the proposed\nmethod, which produces more reliable predictions while delivering better\nresults compared to traditionally trained models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:38:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 00:01:28 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 04:42:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Shahbazi", "Hamed", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1902.08661", "submitter": "Tristan Bepler", "authors": "Tristan Bepler and Bonnie Berger", "title": "Learning protein sequence embeddings using information from structure", "comments": "17 pages, 3 figures, 8 tables, proceedings of ICLR 2019", "journal-ref": "International Conference on Learning Representations, 2019", "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the structural properties of a protein from its amino acid sequence\nis a challenging yet important problem in biology. Structures are not known for\nthe vast majority of protein sequences, but structure is critical for\nunderstanding function. Existing approaches for detecting structural similarity\nbetween proteins from sequence are unable to recognize and exploit structural\npatterns when sequences have diverged too far, limiting our ability to transfer\nknowledge between structurally related proteins. We newly approach this problem\nthrough the lens of representation learning. We introduce a framework that maps\nany protein sequence to a sequence of vector embeddings --- one per amino acid\nposition --- that encode structural information. We train bidirectional long\nshort-term memory (LSTM) models on protein sequences with a two-part feedback\nmechanism that incorporates information from (i) global structural similarity\nbetween proteins and (ii) pairwise residue contact maps for individual\nproteins. To enable learning from structural similarity information, we define\na novel similarity measure between arbitrary-length sequences of vector\nembeddings based on a soft symmetric alignment (SSA) between them. Our method\nis able to learn useful position-specific embeddings despite lacking direct\nobservations of position-level correspondence between sequences. We show\nempirically that our multi-task framework outperforms other sequence-based\nmethods and even a top-performing structure-based alignment method when\npredicting structural similarity, our goal. Finally, we demonstrate that our\nlearned embeddings can be transferred to other protein sequence problems,\nimproving the state-of-the-art in transmembrane domain prediction.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 20:17:52 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 17:09:32 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Bepler", "Tristan", ""], ["Berger", "Bonnie", ""]]}, {"id": "1902.08666", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "From open learners to open games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categories of open learners (due to Fong, Spivak and Tuy\\'eras) and open\ngames (due to the present author, Ghani, Winschel and Zahn) bear a very\nstriking and unexpected similarity. The purpose of this short note is to prove\nthat there is a faithful symmetric monoidal functor from the former to the\nlatter, which means that any supervised neural network (without feedback or\nother complicating features) can be seen as an open game in a canonical way.\nRoughly, each parameter is controlled by a different player, and the game's\nbest response relation encodes the dynamics of gradient descent. We suggest\npaths for further work exploiting the link.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 20:57:33 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1902.08668", "submitter": "Nicole M\\\"ucke", "authors": "Nicole M\\\"ucke, Gergely Neu and Lorenzo Rosasco", "title": "Beating SGD Saturation with Tail-Averaging and Minibatching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While stochastic gradient descent (SGD) is one of the major workhorses in\nmachine learning, the learning properties of many practically used variants are\npoorly understood. In this paper, we consider least squares learning in a\nnonparametric setting and contribute to filling this gap by focusing on the\neffect and interplay of multiple passes, mini-batching and averaging, and in\nparticular tail averaging. Our results show how these different variants of SGD\ncan be combined to achieve optimal learning errors, hence providing practical\ninsights. In particular, we show for the first time in the literature that tail\naveraging allows faster convergence rates than uniform averaging in the\nnonparametric setting. Finally, we show that a combination of tail-averaging\nand minibatching allows more aggressive step-size choices than using any one of\nsaid components.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:07:17 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 09:55:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["M\u00fccke", "Nicole", ""], ["Neu", "Gergely", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1902.08670", "submitter": "Xingyu Li", "authors": "Xingyu Li, Marko Radulovic, Ksenija Kanjer, Konstantinos N.\n  Plataniotis", "title": "Discriminative Pattern Mining for Breast Cancer Histopathology Image\n  Classification via Fully Convolutional Autoencoder", "comments": null, "journal-ref": "IEEE Access, vol. 7, 2019", "doi": "10.1109/ACCESS.2019.2904245", "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate diagnosis of breast cancer in histopathology images is challenging\ndue to the heterogeneity of cancer cell growth as well as of a variety of\nbenign breast tissue proliferative lesions. In this paper, we propose a\npractical and self-interpretable invasive cancer diagnosis solution. With\nminimum annotation information, the proposed method mines contrast patterns\nbetween normal and malignant images in unsupervised manner and generates a\nprobability map of abnormalities to verify its reasoning. Particularly, a fully\nconvolutional autoencoder is used to learn the dominant structural patterns\namong normal image patches. Patches that do not share the characteristics of\nthis normal population are detected and analyzed by one-class support vector\nmachine and 1-layer neural network. We apply the proposed method to a public\nbreast cancer image set. Our results, in consultation with a senior\npathologist, demonstrate that the proposed method outperforms existing methods.\nThe obtained probability map could benefit the pathology practice by providing\nvisualized verification data and potentially leads to a better understanding of\ndata-driven diagnosis solutions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:22:52 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 17:43:11 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 15:35:08 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Xingyu", ""], ["Radulovic", "Marko", ""], ["Kanjer", "Ksenija", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "1902.08673", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad and Shahrokh Valaee", "title": "Ising-Dropout: A Regularization Method for Training and Compression of\n  Deep Neural Networks", "comments": "This paper is accepted at 44th IEEE International Conference on\n  Acoustics, Speech and Signal Processing (IEEE ICASSP), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting is a major problem in training machine learning models,\nspecifically deep neural networks. This problem may be caused by imbalanced\ndatasets and initialization of the model parameters, which conforms the model\ntoo closely to the training data and negatively affects the generalization\nperformance of the model for unseen data. The original dropout is a\nregularization technique to drop hidden units randomly during training. In this\npaper, we propose an adaptive technique to wisely drop the visible and hidden\nunits in a deep neural network using Ising energy of the network. The\npreliminary results show that the proposed approach can keep the classification\nperformance competitive to the original network while eliminating optimization\nof unnecessary network parameters in each training cycle. The dropout state of\nunits can also be applied to the trained (inference) model. This technique\ncould compress the network in terms of number of parameters up to 41.18% and\n55.86% for the classification task on the MNIST and Fashion-MNIST datasets,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 02:21:40 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1902.08675", "submitter": "Wen-Hao Chiang", "authors": "Wen-Hao Chiang, Li Shen, Lang Li and Xia Ning", "title": "Drug-drug interaction prediction based on co-medication patterns and\n  graph matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The problem of predicting whether a drug combination of arbitrary\norders is likely to induce adverse drug reactions is considered in this\nmanuscript. Methods: Novel kernels over drug combinations of arbitrary orders\nare developed within support vector machines for the prediction. Graph matching\nmethods are used in the novel kernels to measure the similarities among drug\ncombinations, in which drug co-medication patterns are leveraged to measure\nsingle drug similarities. Results: The experimental results on a real-world\ndataset demonstrated that the new kernels achieve an area under the curve (AUC)\nvalue 0.912 for the prediction problem. Conclusions: The new methods with drug\nco-medication based single drug similarities can accurately predict whether a\ndrug combination is likely to induce adverse drug reactions of interest.\n  Keywords: drug-drug interaction prediction; drug combination similarity;\nco-medication; graph matching\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:30:40 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chiang", "Wen-Hao", ""], ["Shen", "Li", ""], ["Li", "Lang", ""], ["Ning", "Xia", ""]]}, {"id": "1902.08679", "submitter": "Philip Milton", "authors": "Philip Milton, Emanuele Giorgi, Samir Bhatt", "title": "Spatial Analysis Made Easy with Linear Regression and Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are an incredibly popular technique for extending linear\nmodels to non-linear problems via a mapping to an implicit, high-dimensional\nfeature space. While kernel methods are computationally cheaper than an\nexplicit feature mapping, they are still subject to cubic cost on the number of\npoints. Given only a few thousand locations, this computational cost rapidly\noutstrips the currently available computational power. This paper aims to\nprovide an overview of kernel methods from first-principals (with a focus on\nridge regression), before progressing to a review of random Fourier features\n(RFF), a set of methods that enable the scaling of kernel methods to big\ndatasets. At each stage, the associated R code is provided. We begin by\nillustrating how the dual representation of ridge regression relies solely on\ninner products and permits the use of kernels to map the data into\nhigh-dimensional spaces. We progress to RFFs, showing how only a few lines of\ncode provides a significant computational speed-up for a negligible cost to\naccuracy. We provide an example of the implementation of RFFs on a simulated\nspatial data set to illustrate these properties. Lastly, we summarise the main\nissues with RFFs and highlight some of the advanced techniques aimed at\nalleviating them.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:39:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Milton", "Philip", ""], ["Giorgi", "Emanuele", ""], ["Bhatt", "Samir", ""]]}, {"id": "1902.08692", "submitter": "Rafael Boloix-Tortosa", "authors": "Rafael Boloix-Tortosa, Juan Jos\\'e Murillo-Fuentes, Sotirios A.\n  Tsaftaris", "title": "The Generalized Complex Kernel Least-Mean-Square Algorithm", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2019.2937289", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive kernel based regression method for complex-valued\nsignals: the generalized complex-valued kernel least-mean-square (gCKLMS). We\nborrow from the new results on widely linear reproducing kernel Hilbert space\n(WL-RKHS) for nonlinear regression and complex-valued signals, recently\nproposed by the authors. This paper shows that in the adaptive version of the\nkernel regression for complex-valued signals we need to include another kernel\nterm, the so-called pseudo-kernel. This new solution is endowed with better\nrepresentation capabilities in complex-valued fields, since it can efficiently\ndecouple the learning of the real and the imaginary part. Also, we review\nprevious realizations of the complex KLMS algorithm and its augmented version\nto prove that they can be rewritten as particular cases of the gCKLMS.\nFurthermore, important conclusions on the kernels design are drawn that help to\ngreatly improve the convergence of the algorithms. In the experiments, we\nrevisit the nonlinear channel equalization problem to highlight the better\nconvergence of the gCKLMS compared to previous solutions. Also, the flexibility\nof the proposed generalized approach is tested in a second experiment with\nnon-independent real and imaginary parts. The results illustrate the\nsignificant performance improvements of the gCKLMS approach when the\ncomplex-valued signals have different properties for the real and imaginary\nparts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 22:31:23 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Boloix-Tortosa", "Rafael", ""], ["Murillo-Fuentes", "Juan Jos\u00e9", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "1902.08697", "submitter": "Avinash Parnandi", "authors": "Avinash Parnandi, Jasim Uddin, Dawn M. Nilsen, Heidi Schambra", "title": "Pragmatic classification of movement primitives for stroke\n  rehabilitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rehabilitation training is the primary intervention to improve motor recovery\nafter stroke, but a tool to measure functional training does not currently\nexist. To bridge this gap, we previously developed an approach to classify\nfunctional movement primitives using wearable sensors and a machine learning\n(ML) algorithm. We found that this approach had encouraging classification\nperformance but had computational and practical limitations, such as training\ntime, sensor cost, and magnetic drift. Here, we sought to refine this approach\nand determine the algorithm, sensor configurations, and data requirements\nneeded to maximize computational and practical performance.\n  Motion data had been previously collected from 6 stroke patients wearing 11\ninertial measurement units (IMUs) as they moved objects on a target array. To\nidentify optimal ML performance, we evaluated 4 algorithms that are commonly\nused in activity recognition (linear discriminant analysis (LDA), na\\\"ive\nBayes, support vector machine, and k-nearest neighbors). We compared their\nclassification accuracy, computational complexity, and tuning requirements. To\nidentify optimal sensor configuration, we progressively sampled fewer sensors\nand compared classification accuracy. To identify optimal data requirements, we\ncompared accuracy using data from IMUs versus accelerometers.\n  We found that LDA had the highest classification accuracy (92%) of the\nalgorithms tested. It also was the most pragmatic, with low training and\ntesting times and modest tuning requirements. We found that 7 sensors on the\nparetic arm and back resulted in the best accuracy. Using this array,\naccelerometers had a lower accuracy (84%).\n  We refined strategies to accurately and pragmatically quantify functional\nmovement primitives in stroke patients. We propose that this optimized\nML-sensor approach could be a means to quantify training dose after stroke.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 23:09:38 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:15:46 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 14:32:07 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Parnandi", "Avinash", ""], ["Uddin", "Jasim", ""], ["Nilsen", "Dawn M.", ""], ["Schambra", "Heidi", ""]]}, {"id": "1902.08705", "submitter": "Jayesh Gupta", "authors": "Jayesh K. Gupta, Kunal Menda, Zachary Manchester and Mykel J.\n  Kochenderfer", "title": "A General Framework for Structured Learning of Mechanical Systems", "comments": "10 pages, 7 figures. First two authors contributed equally. Submitted\n  to IROS/RA-L. Code at https://github.com/sisl/mechamodlearn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning accurate dynamics models is necessary for optimal, compliant control\nof robotic systems. Current approaches to white-box modeling using analytic\nparameterizations, or black-box modeling using neural networks, can suffer from\nhigh bias or high variance. We address the need for a flexible, gray-box model\nof mechanical systems that can seamlessly incorporate prior knowledge where it\nis available, and train expressive function approximators where it is not. We\npropose to parameterize a mechanical system using neural networks to model its\nLagrangian and the generalized forces that act on it. We test our method on a\nsimulated, actuated double pendulum. We show that our method outperforms a\nnaive, black-box model in terms of data-efficiency, as well as performance in\nmodel-based reinforcement learning. We also conduct a systematic study of our\nmethod's ability to incorporate available prior knowledge about the system to\nimprove data efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 23:45:40 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:11:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Gupta", "Jayesh K.", ""], ["Menda", "Kunal", ""], ["Manchester", "Zachary", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1902.08708", "submitter": "Elena Smirnova", "authors": "Elena Smirnova, Elvis Dohmatob, J\\'er\\'emie Mary", "title": "Distributionally Robust Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications require RL algorithms to act safely. During learning\nprocess, it is likely that the agent executes sub-optimal actions that may lead\nto unsafe/poor states of the system. Exploration is particularly brittle in\nhigh-dimensional state/action space due to increased number of low-performing\nactions. In this work, we consider risk-averse exploration in approximate RL\nsetting. To ensure safety during learning, we propose the distributionally\nrobust policy iteration scheme that provides lower bound guarantee on\nstate-values. Our approach induces a dynamic level of risk to prevent poor\ndecisions and yet preserves the convergence to the optimal policy. Our\nformulation results in a efficient algorithm that accounts for a simple\nre-weighting of policy actions in the standard policy iteration scheme. We\nextend our approach to continuous state/action space and present a practical\nalgorithm, distributionally robust soft actor-critic, that implements a\ndifferent exploration strategy: it acts conservatively at short-term and it\nexplores optimistically in a long-run. We provide promising experimental\nresults on continuous control tasks.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 00:13:42 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 04:58:55 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Smirnova", "Elena", ""], ["Dohmatob", "Elvis", ""], ["Mary", "J\u00e9r\u00e9mie", ""]]}, {"id": "1902.08710", "submitter": "Jesse Engel", "authors": "Jesse Engel, Kumar Krishna Agrawal, Shuo Chen, Ishaan Gulrajani, Chris\n  Donahue, Adam Roberts", "title": "GANSynth: Adversarial Neural Audio Synthesis", "comments": "Colab Notebook: http://goo.gl/magenta/gansynth-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient audio synthesis is an inherently difficult machine learning task,\nas human perception is sensitive to both global structure and fine-scale\nwaveform coherence. Autoregressive models, such as WaveNet, model local\nstructure at the expense of global latent structure and slow iterative\nsampling, while Generative Adversarial Networks (GANs), have global latent\nconditioning and efficient parallel sampling, but struggle to generate\nlocally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact\ngenerate high-fidelity and locally-coherent audio by modeling log magnitudes\nand instantaneous frequencies with sufficient frequency resolution in the\nspectral domain. Through extensive empirical investigations on the NSynth\ndataset, we demonstrate that GANs are able to outperform strong WaveNet\nbaselines on automated and human evaluation metrics, and efficiently generate\naudio several orders of magnitude faster than their autoregressive\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 00:55:16 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 01:37:13 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Engel", "Jesse", ""], ["Agrawal", "Kumar Krishna", ""], ["Chen", "Shuo", ""], ["Gulrajani", "Ishaan", ""], ["Donahue", "Chris", ""], ["Roberts", "Adam", ""]]}, {"id": "1902.08721", "submitter": "Karan Singh", "authors": "Naman Agarwal, Brian Bullins, Elad Hazan, Sham M. Kakade, Karan Singh", "title": "Online Control with Adversarial Disturbances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the control of a linear dynamical system with adversarial\ndisturbances (as opposed to statistical noise). The objective we consider is\none of regret: we desire an online control procedure that can do nearly as well\nas that of a procedure that has full knowledge of the disturbances in\nhindsight. Our main result is an efficient algorithm that provides nearly tight\nregret bounds for this problem. From a technical standpoint, this work\ngeneralizes upon previous work in two main aspects: our model allows for\nadversarial noise in the dynamics, and allows for general convex costs.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 03:00:22 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Agarwal", "Naman", ""], ["Bullins", "Brian", ""], ["Hazan", "Elad", ""], ["Kakade", "Sham M.", ""], ["Singh", "Karan", ""]]}, {"id": "1902.08722", "submitter": "Hadi Salman", "authors": "Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang", "title": "A Convex Relaxation Barrier to Tight Robustness Verification of Neural\n  Networks", "comments": "Poster at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of neural networks enables us to gauge their robustness against\nadversarial attacks. Verification algorithms fall into two categories: exact\nverifiers that run in exponential time and relaxed verifiers that are efficient\nbut incomplete. In this paper, we unify all existing LP-relaxed verifiers, to\nthe best of our knowledge, under a general convex relaxation framework. This\nframework works for neural networks with diverse architectures and\nnonlinearities and covers both primal and dual views of robustness\nverification. We further prove strong duality between the primal and dual\nproblems under very mild conditions. Next, we perform large-scale experiments,\namounting to more than 22 CPU-years, to obtain exact solution to the\nconvex-relaxed problem that is optimal within our framework for ReLU networks.\nWe find the exact solution does not significantly improve upon the gap between\nPGD and existing relaxed verifiers for various networks trained normally or\nrobustly on MNIST and CIFAR datasets. Our results suggest there is an inherent\nbarrier to tight verification for the large class of methods captured by our\nframework. We discuss possible causes of this barrier and potential future\ndirections for bypassing it. Our code and trained models are available at\nhttp://github.com/Hadisalman/robust-verify-benchmark .\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 03:01:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 18:53:39 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 02:17:14 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 09:31:37 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 00:20:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Salman", "Hadi", ""], ["Yang", "Greg", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""], ["Zhang", "Pengchuan", ""]]}, {"id": "1902.08727", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Pritish Sahu, Behnam Gholami, Vladimir Pavlovic", "title": "Unsupervised Visual Domain Adaptation: A Deep Max-Margin Gaussian\n  Process Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised domain adaptation, it is widely known that the target domain\nerror can be provably reduced by having a shared input representation that\nmakes the source and target domains indistinguishable from each other. Very\nrecently it has been studied that not just matching the marginal input\ndistributions, but the alignment of output (class) distributions is also\ncritical. The latter can be achieved by minimizing the maximum discrepancy of\npredictors (classifiers). In this paper, we adopt this principle, but propose a\nmore systematic and effective way to achieve hypothesis consistency via\nGaussian processes (GP). The GP allows us to define/induce a hypothesis space\nof the classifiers from the posterior distribution of the latent random\nfunctions, turning the learning into a simple large-margin posterior separation\nproblem, far easier to solve than previous approaches based on adversarial\nminimax optimization. We formulate a learning objective that effectively pushes\nthe posterior to minimize the maximum discrepancy. This is further shown to be\nequivalent to maximizing margins and minimizing uncertainty of the class\npredictions in the target domain, a well-established principle in classical\n(semi-)supervised learning. Empirical results demonstrate that our approach is\ncomparable or superior to the existing methods on several benchmark domain\nadaptation datasets.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 03:40:14 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kim", "Minyoung", ""], ["Sahu", "Pritish", ""], ["Gholami", "Behnam", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1902.08740", "submitter": "Julian Theis", "authors": "Julian Theis and Houshang Darabi", "title": "Behavioral Petri Net Mining and Automated Analysis for Human-Computer\n  Interaction Recommendations in Multi-Application Environments", "comments": "Fixed typos, updated event ordering in traces and PN marking\n  definition", "journal-ref": null, "doi": "10.1145/3331155", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process Mining is a famous technique which is frequently applied to Software\nDevelopment Processes, while being neglected in Human-Computer Interaction\n(HCI) recommendation applications. Organizations usually train employees to\ninteract with required IT systems. Often, employees, or users in general,\ndevelop their own strategies for solving repetitive tasks and processes.\nHowever, organizations find it hard to detect whether employees interact\nefficiently with IT systems or not. Hence, we have developed a method which\ndetects inefficient behavior assuming that at least one optimal HCI strategy is\nknown. This method provides recommendations to gradually adapt users' behavior\ntowards the optimal way of interaction considering satisfaction of users. Based\non users' behavior logs tracked by a Java application suitable for\nmulti-application and multi-instance environments, we demonstrate the\napplicability for a specific task in a common Windows environment utilizing\nrealistic simulated behaviors of users.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 05:55:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:37:48 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Theis", "Julian", ""], ["Darabi", "Houshang", ""]]}, {"id": "1902.08753", "submitter": "Matthias Claudius Caro", "authors": "Matthias C. Caro", "title": "Quantum Learning Boolean Linear Functions w.r.t. Product Distributions", "comments": "27 pages main text, 12 pages Appendix; 2 figures; improved and\n  extended presentation containing a strengthened quantum sample complexity\n  lower bound; accepted for publication in Quantum Information Processing", "journal-ref": "Quantum Inf Process 19, 172 (2020)", "doi": "10.1007/s11128-020-02661-1", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning Boolean linear functions from quantum examples w.r.t.\nthe uniform distribution can be solved on a quantum computer using the\nBernstein-Vazirani algorithm. A similar strategy can be applied in the case of\nnoisy quantum training data, as was observed in arXiv:1702.08255v2 [quant-ph].\nHowever, extensions of these learning algorithms beyond the uniform\ndistribution have not yet been studied. We employ the biased quantum Fourier\ntransform introduced in arXiv:1802.05690v2 [quant-ph] to develop efficient\nquantum algorithms for learning Boolean linear functions on $n$ bits from\nquantum examples w.r.t. a biased product distribution. Our first procedure is\napplicable to any (except full) bias and requires $\\mathcal{O}(\\ln (n))$\nquantum examples. The number of quantum examples used by our second algorithm\nis independent of $n$, but the strategy is applicable only for small bias.\nMoreover, we show that the second procedure is stable w.r.t. noisy training\ndata and w.r.t. faulty quantum gates. This also enables us to solve a version\nof the learning problem in which the underlying distribution is not known in\nadvance. Finally, we prove lower bounds on the classical and quantum sample\ncomplexities of the learning problem. Whereas classically, $\\Omega (n)$\nexamples are necessary independently of the bias, we are able to establish a\nquantum sample complexity lower bound of $\\Omega (\\ln (n))$ only under an\nassumption of large bias. Nevertheless, this allows for a discussion of the\nperformance of our suggested learning algorithms w.r.t. sample complexity. With\nour analysis we contribute to a more quantitative understanding of the power\nand limitations of quantum training data for learning classical functions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 08:20:09 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 17:59:59 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Caro", "Matthias C.", ""]]}, {"id": "1902.08792", "submitter": "Zhongyi Hu", "authors": "Zhongyi Hu, Raymond Chiong, Ilung Pranata, Willy Susilo, Yukun Bao", "title": "Identifying Malicious Web Domains Using Machine Learning Techniques with\n  Online Credibility and Performance Data", "comments": "10 pages, conference", "journal-ref": "2016 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC.2016.7748347", "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious web domains represent a big threat to web users' privacy and\nsecurity. With so much freely available data on the Internet about web domains'\npopularity and performance, this study investigated the performance of\nwell-known machine learning techniques used in conjunction with this type of\nonline data to identify malicious web domains. Two datasets consisting of\nmalware and phishing domains were collected to build and evaluate the machine\nlearning classifiers. Five single classifiers and four ensemble classifiers\nwere applied to distinguish malicious domains from benign ones. In addition, a\nbinary particle swarm optimisation (BPSO) based feature selection method was\nused to improve the performance of single classifiers. Experimental results\nshow that, based on the web domains' popularity and performance data features,\nthe examined machine learning techniques can accurately identify malicious\ndomains in different ways. Furthermore, the BPSO-based feature selection\nprocedure is shown to be an effective way to improve the performance of\nclassifiers.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 14:10:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hu", "Zhongyi", ""], ["Chiong", "Raymond", ""], ["Pranata", "Ilung", ""], ["Susilo", "Willy", ""], ["Bao", "Yukun", ""]]}, {"id": "1902.08810", "submitter": "Hadi Zare", "authors": "Soheila Molaei, Hadi Zare, Hadi Veisi", "title": "Deep Learning Approach on Information Diffusion in Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2019.105153", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many real-world knowledge based networked systems with multi-type\ninteracting entities that can be regarded as heterogeneous networks including\nhuman connections and biological evolutions. One of the main issues in such\nnetworks is to predict information diffusion such as shape, growth and size of\nsocial events and evolutions in the future. While there exist a variety of\nworks on this topic mainly using a threshold-based approach, they suffer from\nthe local viewpoint on the network and sensitivity to the threshold parameters.\nIn this paper, information diffusion is considered through a latent\nrepresentation learning of the heterogeneous networks to encode in a deep\nlearning model. To this end, we propose a novel meta-path representation\nlearning approach, Heterogeneous Deep Diffusion(HDD), to exploit meta-paths as\nmain entities in networks. At first, the functional heterogeneous structures of\nthe network are learned by a continuous latent representation through\ntraversing meta-paths with the aim of global end-to-end viewpoint. Then, the\nwell-known deep learning architectures are employed on our generated features\nto predict diffusion processes in the network. The proposed approach enables us\nto apply it on different information diffusion tasks such as topic diffusion\nand cascade prediction. We demonstrate the proposed approach on benchmark\nnetwork datasets through the well-known evaluation measures. The experimental\nresults show that our approach outperforms the earlier state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 16:31:04 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 13:28:20 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Molaei", "Soheila", ""], ["Zare", "Hadi", ""], ["Veisi", "Hadi", ""]]}, {"id": "1902.08813", "submitter": "Guillaume Salha", "authors": "Guillaume Salha, Romain Hennequin, Viet Anh Tran, Michalis\n  Vazirgiannis", "title": "A Degeneracy Framework for Scalable Graph Autoencoders", "comments": "International Joint Conference on Artificial Intelligence (IJCAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general framework to scale graph autoencoders\n(AE) and graph variational autoencoders (VAE). This framework leverages graph\ndegeneracy concepts to train models only from a dense subset of nodes instead\nof using the entire graph. Together with a simple yet effective propagation\nmechanism, our approach significantly improves scalability and training speed\nwhile preserving performance. We evaluate and discuss our method on several\nvariants of existing graph AE and VAE, providing the first application of these\nmodels to large graphs with up to millions of nodes and edges. We achieve\nempirically competitive results w.r.t. several popular scalable node embedding\nmethods, which emphasizes the relevance of pursuing further research towards\nmore scalable graph AE and VAE.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 16:45:13 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 16:54:03 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Tran", "Viet Anh", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1902.08835", "submitter": "Mingjun Zhong", "authors": "Michele DIncecco and Stefano Squartini and Mingjun Zhong", "title": "Transfer Learning for Non-Intrusive Load Monitoring", "comments": "10 pages, 12 Figures", "journal-ref": "IEEE Transactions on Smart Grid, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring (NILM) is a technique to recover source\nappliances from only the recorded mains in a household. NILM is unidentifiable\nand thus a challenge problem because the inferred power value of an appliance\ngiven only the mains could not be unique. To mitigate the unidentifiable\nproblem, various methods incorporating domain knowledge into NILM have been\nproposed and shown effective experimentally. Recently, among these methods,\ndeep neural networks are shown performing best. Arguably, the recently proposed\nsequence-to-point (seq2point) learning is promising for NILM. However, the\nresults were only carried out on the same data domain. It is not clear if the\nmethod could be generalised or transferred to different domains, e.g., the test\ndata were drawn from a different country comparing to the training data. We\naddress this issue in the paper, and two transfer learning schemes are\nproposed, i.e., appliance transfer learning (ATL) and cross-domain transfer\nlearning (CTL). For ATL, our results show that the latent features learnt by a\n`complex' appliance, e.g., washing machine, can be transferred to a `simple'\nappliance, e.g., kettle. For CTL, our conclusion is that the seq2point learning\nis transferable. Precisely, when the training and test data are in a similar\ndomain, seq2point learning can be directly applied to the test data without\nfine tuning; when the training and test data are in different domains,\nseq2point learning needs fine tuning before applying to the test data.\nInterestingly, we show that only the fully connected layers need fine tuning\nfor transfer learning. Source code can be found at\nhttps://github.com/MingjunZhong/transferNILM.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 19:31:46 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 11:37:06 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 10:22:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["DIncecco", "Michele", ""], ["Squartini", "Stefano", ""], ["Zhong", "Mingjun", ""]]}, {"id": "1902.08869", "submitter": "Mohammad Aminisharifabad", "authors": "Mohammad Aminisharifabad, Qingyu Yang", "title": "Statistical Method to Model the Quality Inconsistencies of the Welding\n  Process", "comments": "IISE Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistance Spot Welding (RSW) is an important manufacturing process that\nattracts increasing attention in automotive industry. However, due to the\ncomplexity of the manufacturing process, the corresponding product quality\nshows significant inconsistencies even under the same process setup. This paper\ndevelops a statistical method to capture the inconsistence of welding quality\nmeasurements (e.g., nugget width) based on process parameters to efficiently\nmonitor product quality. The proposed method provides engineering efficiency\nand cost saving benefit through reduction of physical testing required for\nweldability and verification. The developed method is applied to the real-world\nwelding process.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 01:12:21 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Aminisharifabad", "Mohammad", ""], ["Yang", "Qingyu", ""]]}, {"id": "1902.08874", "submitter": "Bargav Jayaraman", "authors": "Bargav Jayaraman and David Evans", "title": "Evaluating Differentially Private Machine Learning in Practice", "comments": "Revised version of a paper in USENIX Security 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a strong notion for privacy that can be used to prove\nformal guarantees, in terms of a privacy budget, $\\epsilon$, about how much\ninformation is leaked by a mechanism. However, implementations of\nprivacy-preserving machine learning often select large values of $\\epsilon$ in\norder to get acceptable utility of the model, with little understanding of the\nimpact of such choices on meaningful privacy. Moreover, in scenarios where\niterative learning procedures are used, differential privacy variants that\noffer tighter analyses are used which appear to reduce the needed privacy\nbudget but present poorly understood trade-offs between privacy and utility. In\nthis paper, we quantify the impact of these choices on privacy in experiments\nwith logistic regression and neural network models. Our main finding is that\nthere is a huge gap between the upper bounds on privacy loss that can be\nguaranteed, even with advanced mechanisms, and the effective privacy loss that\ncan be measured using current inference attacks. Current mechanisms for\ndifferentially private machine learning rarely offer acceptable utility-privacy\ntrade-offs with guarantees for complex learning tasks: settings that provide\nlimited accuracy loss provide meaningless privacy guarantees, and settings that\nprovide strong privacy guarantees result in useless models. Code for the\nexperiments can be found here: https://github.com/bargavj/EvaluatingDPML\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 01:48:53 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 22:16:03 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 17:16:24 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 23:18:20 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Jayaraman", "Bargav", ""], ["Evans", "David", ""]]}, {"id": "1902.08888", "submitter": "Gholamreza Haffari", "authors": "Faik Aydin and Maggie Zhang and Michelle Ananda-Rajah and Gholamreza\n  Haffari", "title": "Medical Multimodal Classifiers Under Scarce Data Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is one of the essential ingredients to power deep learning research.\nSmall datasets, especially specific to medical institutes, bring challenges to\ndeep learning training stage. This work aims to develop a practical deep\nmultimodal that can classify patients into abnormal and normal categories\naccurately as well as assist radiologists to detect visual and textual\nanomalies by locating areas of interest. The detection of the anomalies is\nachieved through a novel technique which extends the integrated gradients\nmethodology with an unsupervised clustering algorithm. This technique also\nintroduces a tuning parameter which trades off true positive signals to denoise\nfalse positive signals in the detection process. To overcome the challenges of\nthe small training dataset which only has 3K frontal X-ray images and medical\nreports in pairs, we have adopted transfer learning for the multimodal which\nconcatenates the layers of image and text submodels. The image submodel was\ntrained on the vast ChestX-ray14 dataset, while the text submodel transferred a\npertained word embedding layer from a hospital-specific corpus. Experimental\nresults show that our multimodal improves the accuracy of the classification by\n4% and 7% on average of 50 epochs, compared to the individual text and image\nmodel, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 03:38:41 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Aydin", "Faik", ""], ["Zhang", "Maggie", ""], ["Ananda-Rajah", "Michelle", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1902.08918", "submitter": "Benjamin Rubinstein", "authors": "Yuan Li, Benjamin I. P. Rubinstein, Trevor Cohn", "title": "Truth Inference at Scale: A Bayesian Model for Adjudicating Highly\n  Redundant Crowd Annotations", "comments": "Accepted at the Web Conference/WWW 2019 (camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd-sourcing is a cheap and popular means of creating training and\nevaluation datasets for machine learning, however it poses the problem of\n`truth inference', as individual workers cannot be wholly trusted to provide\nreliable annotations. Research into models of annotation aggregation attempts\nto infer a latent `true' annotation, which has been shown to improve the\nutility of crowd-sourced data. However, existing techniques beat simple\nbaselines only in low redundancy settings, where the number of annotations per\ninstance is low ($\\le 3$), or in situations where workers are unreliable and\nproduce low quality annotations (e.g., through spamming, random, or adversarial\nbehaviours.) As we show, datasets produced by crowd-sourcing are often not of\nthis type: the data is highly redundantly annotated ($\\ge 5$ annotations per\ninstance), and the vast majority of workers produce high quality outputs. In\nthese settings, the majority vote heuristic performs very well, and most truth\ninference models underperform this simple baseline. We propose a novel\ntechnique, based on a Bayesian graphical model with conjugate priors, and\nsimple iterative expectation-maximisation inference. Our technique produces\ncompetitive performance to the state-of-the-art benchmark methods, and is the\nonly method that significantly outperforms the majority vote heuristic at\none-sided level 0.025, shown by significance tests. Moreover, our technique is\nsimple, is implemented in only 50 lines of code, and trains in seconds.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 10:48:25 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Li", "Yuan", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Cohn", "Trevor", ""]]}, {"id": "1902.08921", "submitter": "Hongjoon Ahn", "authors": "Hongjoon Ahn, Taesup Moon", "title": "Iterative Channel Estimation for Discrete Denoising under Channel\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel iterative channel estimation (ICE) algorithm that\nessentially removes the critical known noisy channel assumption for universal\ndiscrete denoising problem. Our algorithm is based on Neural DUDE (N-DUDE), a\nrecently proposed neural network-based discrete denoiser, and it estimates the\nchannel transition matrix as well as the neural network parameters in an\nalternating manner until convergence. While we do not make any probabilistic\nassumption on the underlying clean data, our ICE resembles\nExpectation-Maximization (EM) with variational approximation, and it takes\nadvantage of the property of N-DUDE being locally robust around the true\nchannel. With extensive experiments on several radically different types of\ndata, we show that the ICE equipped N-DUDE (dubbed as ICE-N-DUDE) can perform\n\\emph{universally} well regardless of the uncertainties in both the channel and\nthe clean source. Moreover, we show ICE-N-DUDE becomes extremely robust to its\nhyperparameters and significantly outperforms the strong baseline that can deal\nwith the channel uncertainties for denoising, the widely used Baum-Welch (BW)\nalgorithm for hidden Markov models (HMM).\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 10:58:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 04:10:38 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ahn", "Hongjoon", ""], ["Moon", "Taesup", ""]]}, {"id": "1902.08934", "submitter": "Sina Shaham", "authors": "Sina Shaham, Ming Ding, Bo Liu, Shuping Dang, Zihuai Lin, and Jun Li", "title": "Privacy Preserving Location Data Publishing: A Machine Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Publishing datasets plays an essential role in open data research and\npromoting transparency of government agencies. However, such data publication\nmight reveal users' private information. One of the most sensitive sources of\ndata is spatiotemporal trajectory datasets. Unfortunately, merely removing\nunique identifiers cannot preserve the privacy of users. Adversaries may know\nparts of the trajectories or be able to link the published dataset to other\nsources for the purpose of user identification. Therefore, it is crucial to\napply privacy preserving techniques before the publication of spatiotemporal\ntrajectory datasets. In this paper, we propose a robust framework for the\nanonymization of spatiotemporal trajectory datasets termed as machine learning\nbased anonymization (MLA). By introducing a new formulation of the problem, we\nare able to apply machine learning algorithms for clustering the trajectories\nand propose to use $k$-means algorithm for this purpose. A variation of\n$k$-means algorithm is also proposed to preserve the privacy in overly\nsensitive datasets. Moreover, we improve the alignment process by considering\nmultiple sequence alignment as part of the MLA. The framework and all the\nproposed algorithms are applied to TDrive and Geolife location datasets. The\nexperimental results indicate a significantly higher utility of datasets by\nanonymization based on MLA framework.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 12:19:58 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:09:57 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shaham", "Sina", ""], ["Ding", "Ming", ""], ["Liu", "Bo", ""], ["Dang", "Shuping", ""], ["Lin", "Zihuai", ""], ["Li", "Jun", ""]]}, {"id": "1902.08949", "submitter": "Wei Peng", "authors": "Wei Peng, Yuhong Dai, Hui Zhang, Lizhi Cheng", "title": "Training GANs with Centripetal Acceleration", "comments": null, "journal-ref": null, "doi": "10.1080/10556788.2020.1754414", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative adversarial networks (GANs) often suffers from cyclic\nbehaviors of iterates. Based on a simple intuition that the direction of\ncentripetal acceleration of an object moving in uniform circular motion is\ntoward the center of the circle, we present the Simultaneous Centripetal\nAcceleration (SCA) method and the Alternating Centripetal Acceleration (ACA)\nmethod to alleviate the cyclic behaviors. Under suitable conditions, gradient\ndescent methods with either SCA or ACA are shown to be linearly convergent for\nbilinear games. Numerical experiments are conducted by applying ACA to existing\ngradient-based algorithms in a GAN setup scenario, which demonstrate the\nsuperiority of ACA.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 14:03:21 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Peng", "Wei", ""], ["Dai", "Yuhong", ""], ["Zhang", "Hui", ""], ["Cheng", "Lizhi", ""]]}, {"id": "1902.08955", "submitter": "Jiajun Zhang", "authors": "Jiajun Zhang, Long Zhou, Yang Zhao, Chengqing Zong", "title": "Synchronous Bidirectional Inference for Neural Sequence Generation", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence to sequence generation tasks (e.g. machine translation and\nabstractive summarization), inference is generally performed in a left-to-right\nmanner to produce the result token by token. The neural approaches, such as\nLSTM and self-attention networks, are now able to make full use of all the\npredicted history hypotheses from left side during inference, but cannot\nmeanwhile access any future (right side) information and usually generate\nunbalanced outputs in which left parts are much more accurate than right ones.\nIn this work, we propose a synchronous bidirectional inference model to\ngenerate outputs using both left-to-right and right-to-left decoding\nsimultaneously and interactively. First, we introduce a novel beam search\nalgorithm that facilitates synchronous bidirectional decoding. Then, we present\nthe core approach which enables left-to-right and right-to-left decoding to\ninteract with each other, so as to utilize both the history and future\npredictions simultaneously during inference. We apply the proposed model to\nboth LSTM and self-attention networks. In addition, we propose two strategies\nfor parameter optimization. The extensive experiments on machine translation\nand abstractive summarization demonstrate that our synchronous bidirectional\ninference model can achieve remarkable improvements over the strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 14:44:07 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Jiajun", ""], ["Zhou", "Long", ""], ["Zhao", "Yang", ""], ["Zong", "Chengqing", ""]]}, {"id": "1902.08959", "submitter": "Anton Mallasto", "authors": "Anton Mallasto, Tom Dela Haije, Aasa Feragen", "title": "A Formalization of The Natural Gradient Method for General Similarity\n  Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In optimization, the natural gradient method is well-known for likelihood\nmaximization. The method uses the Kullback-Leibler divergence, corresponding\ninfinitesimally to the Fisher-Rao metric, which is pulled back to the parameter\nspace of a family of probability distributions. This way, gradients with\nrespect to the parameters respect the Fisher-Rao geometry of the space of\ndistributions, which might differ vastly from the standard Euclidean geometry\nof the parameter space, often leading to faster convergence. However, when\nminimizing an arbitrary similarity measure between distributions, it is\ngenerally unclear which metric to use. We provide a general framework that,\ngiven a similarity measure, derives a metric for the natural gradient. We then\ndiscuss connections between the natural gradient method and multiple other\noptimization techniques in the literature. Finally, we provide computations of\nthe formal natural gradient to show overlap with well-known cases and to\ncompute natural gradients in novel frameworks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 15:07:31 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mallasto", "Anton", ""], ["Haije", "Tom Dela", ""], ["Feragen", "Aasa", ""]]}, {"id": "1902.08967", "submitter": "Nolan Wagener", "authors": "Nolan Wagener, Ching-An Cheng, Jacob Sacks, Byron Boots", "title": "An Online Learning Approach to Model Predictive Control", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Model predictive control (MPC) is a powerful technique for solving dynamic\ncontrol tasks. In this paper, we show that there exists a close connection\nbetween MPC and online learning, an abstract theoretical framework for\nanalyzing online decision making in the optimization literature. This new\nperspective provides a foundation for leveraging powerful online learning\nalgorithms to design MPC algorithms. Specifically, we propose a new algorithm\nbased on dynamic mirror descent (DMD), an online learning algorithm that is\ndesigned for non-stationary setups. Our algorithm, Dynamic Mirror Descent Model\nPredictive Control (DMD-MPC), represents a general family of MPC algorithms\nthat includes many existing techniques as special instances. DMD-MPC also\nprovides a fresh perspective on previous heuristics used in MPC and suggests a\nprincipled way to design new MPC algorithms. In the experimental section of\nthis paper, we demonstrate the flexibility of DMD-MPC, presenting a set of new\nMPC algorithms on a simple simulated cartpole and a simulated and real-world\naggressive driving task. Videos of the real-world experiments can be found at\nhttps://youtu.be/vZST3v0_S9w and https://youtu.be/MhuqiHo2t98.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 15:52:09 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 18:00:05 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 13:54:45 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wagener", "Nolan", ""], ["Cheng", "Ching-An", ""], ["Sacks", "Jacob", ""], ["Boots", "Byron", ""]]}, {"id": "1902.08990", "submitter": "Chongyang Wang", "authors": "Chongyang Wang, Temitayo A. Olugbade, Akhil Mathur, Amanda C. De C.\n  Williams, Nicholas D. Lane, Nadia Bianchi-Berthouze", "title": "Chronic-Pain Protective Behavior Detection with Deep Learning", "comments": "24 pages, 12 figures, 7 tables. Accepted by ACM Transactions on\n  Computing for Healthcare", "journal-ref": null, "doi": "10.1145/3449068", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In chronic pain rehabilitation, physiotherapists adapt physical activity to\npatients' performance based on their expression of protective behavior,\ngradually exposing them to feared but harmless and essential everyday\nactivities. As rehabilitation moves outside the clinic, technology should\nautomatically detect such behavior to provide similar support. Previous works\nhave shown the feasibility of automatic protective behavior detection (PBD)\nwithin a specific activity. In this paper, we investigate the use of deep\nlearning for PBD across activity types, using wearable motion capture and\nsurface electromyography data collected from healthy participants and people\nwith chronic pain. We approach the problem by continuously detecting protective\nbehavior within an activity rather than estimating its overall presence. The\nbest performance reaches mean F1 score of 0.82 with leave-one-subject-out cross\nvalidation. When protective behavior is modelled per activity type, performance\nis mean F1 score of 0.77 for bend-down, 0.81 for one-leg-stand, 0.72 for\nsit-to-stand, 0.83 for stand-to-sit, and 0.67 for reach-forward. This\nperformance reaches excellent level of agreement with the average experts'\nrating performance suggesting potential for personalized chronic pain\nmanagement at home. We analyze various parameters characterizing our approach\nto understand how the results could generalize to other PBD datasets and\ndifferent levels of ground truth granularity.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 17:50:44 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 18:48:08 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 01:03:12 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 06:10:35 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Chongyang", ""], ["Olugbade", "Temitayo A.", ""], ["Mathur", "Akhil", ""], ["Williams", "Amanda C. De C.", ""], ["Lane", "Nicholas D.", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "1902.08999", "submitter": "Xudong Sun", "authors": "Xudong Sun, Andrea Bommert, Florian Pfisterer, J\\\"org Rahnenf\\\"uhrer,\n  Michel Lang, Bernd Bischl", "title": "High Dimensional Restrictive Federated Model Selection with\n  multi-objective Bayesian Optimization over shifted distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel machine learning optimization process coined Restrictive Federated\nModel Selection (RFMS) is proposed under the scenario, for example, when data\nfrom healthcare units can not leave the site it is situated on and it is\nforbidden to carry out training algorithms on remote data sites due to either\ntechnical or privacy and trust concerns. To carry out a clinical research under\nthis scenario, an analyst could train a machine learning model only on local\ndata site, but it is still possible to execute a statistical query at a certain\ncost in the form of sending a machine learning model to some of the remote data\nsites and get the performance measures as feedback, maybe due to prediction\nbeing usually much cheaper. Compared to federated learning, which is optimizing\nthe model parameters directly by carrying out training across all data sites,\nRFMS trains model parameters only on one local data site but optimizes\nhyper-parameters across other data sites jointly since hyper-parameters play an\nimportant role in machine learning performance. The aim is to get a Pareto\noptimal model with respective to both local and remote unseen prediction\nlosses, which could generalize well across data sites. In this work, we\nspecifically consider high dimensional data with shifted distributions over\ndata sites. As an initial investigation, Bayesian Optimization especially\nmulti-objective Bayesian Optimization is used to guide an adaptive\nhyper-parameter optimization process to select models under the RFMS scenario.\nEmpirical results show that solely using the local data site to tune\nhyper-parameters generalizes poorly across data sites, compared to methods that\nutilize the local and remote performances. Furthermore, in terms of dominated\nhypervolumes, multi-objective Bayesian Optimization algorithms show increased\nperformance across multiple data sites among other candidates.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 19:48:30 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 21:21:46 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Sun", "Xudong", ""], ["Bommert", "Andrea", ""], ["Pfisterer", "Florian", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""], ["Lang", "Michel", ""], ["Bischl", "Bernd", ""]]}, {"id": "1902.09003", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Combining Online Learning Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to take any two parameter-free online learning algorithms with\ndifferent regret guarantees and obtain a single algorithm whose regret is the\nminimum of the two base algorithms. Our method is embarrassingly simple: just\nadd the iterates. This trick can generate efficient algorithms that adapt to\nmany norms simultaneously, as well as providing diagonal-style algorithms that\nstill maintain dimension-free guarantees. We then proceed to show how a variant\non this idea yields a black-box procedure for generating optimistic online\nlearning algorithms. This yields the first optimistic regret guarantees in the\nunconstrained setting and generically increases adaptivity. Further, our\noptimistic algorithms are guaranteed to do no worse than their non-optimistic\ncounterparts regardless of the quality of the optimistic estimates provided to\nthe algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 19:57:48 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "1902.09006", "submitter": "Catherine Chen", "authors": "Catherine Chen, Qihong Lu, Andre Beukers, Christopher Baldassano, and\n  Kenneth A. Norman", "title": "Learning to Perform Role-Filler Binding with Schematic Knowledge", "comments": null, "journal-ref": "PeerJ 9:e11046 (2021)", "doi": "10.7717/peerj.11046", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through specific experiences, humans learn relationships underlying the\nstructure of events in the world. Schema theory suggests that we organize this\ninformation in mental frameworks called \"schemata,\" which represent our\nknowledge of the structure of the world. Generalizing knowledge of structural\nrelationships to new situations requires role-filler binding, the ability to\nassociate specific \"fillers\" with abstract \"roles.\" For instance, when we hear\nthe sentence \"Alice ordered a tea from Bob,\" the role-filler bindings\n\"Alice:customer,\" \"tea:drink,\" and \"Bob:barista\" allow us to understand and\nmake inferences about the sentence. We can perform these bindings for arbitrary\nfillers -- we understand this sentence even if we have never heard the names\n\"Alice,\" \"tea,\" or \"Bob\" before. In this work, we define a model as capable of\nperforming role-filler binding if it can recall arbitrary fillers corresponding\nto a specified role, even when these pairings violate correlations seen during\ntraining. Previous work found that models can learn this ability when\nexplicitly told what the roles and fillers are, or when given fillers seen\nduring training. We show that networks with external memory can learn these\nrelationships with fillers not seen during training and without explicitly\nlabeled role-filler bindings, and show that analyses inspired by neural\ndecoding can provide a means of understanding what the networks have learned.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 20:05:07 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 00:21:08 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 00:48:54 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chen", "Catherine", ""], ["Lu", "Qihong", ""], ["Beukers", "Andre", ""], ["Baldassano", "Christopher", ""], ["Norman", "Kenneth A.", ""]]}, {"id": "1902.09009", "submitter": "Lydia Zakynthinou", "authors": "Huy L. Nguyen, Jonathan Ullman, Lydia Zakynthinou", "title": "Efficient Private Algorithms for Learning Large-Margin Halfspaces", "comments": "changed title, added references and remarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new differentially private algorithms for learning a large-margin\nhalfspace. In contrast to previous algorithms, which are based on either\ndifferentially private simulations of the statistical query model or on private\nconvex optimization, the sample complexity of our algorithms depends only on\nthe margin of the data, and not on the dimension. We complement our results\nwith a lower bound, showing that the dependence of our upper bounds on the\nmargin is optimal.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 20:14:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 02:50:55 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Nguyen", "Huy L.", ""], ["Ullman", "Jonathan", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "1902.09013", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Artificial Constraints and Lipschitz Hints for Unconstrained Online\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide algorithms that guarantee regret $R_T(u)\\le \\tilde O(G\\|u\\|^3 +\nG(\\|u\\|+1)\\sqrt{T})$ or $R_T(u)\\le \\tilde O(G\\|u\\|^3T^{1/3} + GT^{1/3}+\nG\\|u\\|\\sqrt{T})$ for online convex optimization with $G$-Lipschitz losses for\nany comparison point $u$ without prior knowledge of either $G$ or $\\|u\\|$.\nPrevious algorithms dispense with the $O(\\|u\\|^3)$ term at the expense of\nknowledge of one or both of these parameters, while a lower bound shows that\nsome additional penalty term over $G\\|u\\|\\sqrt{T}$ is necessary. Previous\npenalties were exponential while our bounds are polynomial in all quantities.\nFurther, given a known bound $\\|u\\|\\le D$, our same techniques allow us to\ndesign algorithms that adapt optimally to the unknown value of $\\|u\\|$ without\nrequiring knowledge of $G$.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 20:30:59 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "1902.09024", "submitter": "Timo Klock", "authors": "Zeljko Kereta, Timo Klock, Valeriya Naumova", "title": "Nonlinear generalization of the monotone single index model", "comments": "37 pages, 23 figures, 4 table", "journal-ref": "Information and Inference: A Journal of the IMA (2020)", "doi": "10.1093/imaiai/iaaa013", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single index model is a powerful yet simple model, widely used in statistics,\nmachine learning, and other scientific fields. It models the regression\nfunction as $g(<a,x>)$, where a is an unknown index vector and x are the\nfeatures. This paper deals with a nonlinear generalization of this framework to\nallow for a regressor that uses multiple index vectors, adapting to local\nchanges in the responses. To do so we exploit the conditional distribution over\nfunction-driven partitions, and use linear regression to locally estimate index\nvectors. We then regress by applying a kNN type estimator that uses a localized\nproxy of the geodesic metric. We present theoretical guarantees for estimation\nof local index vectors and out-of-sample prediction, and demonstrate the\nperformance of our method with experiments on synthetic and real-world data\nsets, comparing it with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 22:13:33 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 18:23:04 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kereta", "Zeljko", ""], ["Klock", "Timo", ""], ["Naumova", "Valeriya", ""]]}, {"id": "1902.09025", "submitter": "Patrick Johnstone", "authors": "Patrick R. Johnstone and Jonathan Eckstein", "title": "Single-Forward-Step Projective Splitting: Exploiting Cocoercivity", "comments": "Updated Numerical Experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a new variant of projective splitting for solving maximal\nmonotone inclusions and complicated convex optimization problems. In the new\nversion, cocoercive operators can be processed with a single forward step per\niteration. In the convex optimization context, cocoercivity is equivalent to\nLipschitz differentiability. Prior forward-step versions of projective\nsplitting did not fully exploit cocoercivity and required two forward steps per\niteration for such operators. Our new single-forward-step method establishes a\nsymmetry between projective splitting algorithms, the classical\nforward-backward splitting method (FB), and Tseng's forward-backward-forward\nmethod (FBF). The new procedure allows for larger stepsizes for cocoercive\noperators: the stepsize bound is $2\\beta$ for a $\\beta$-cocoercive operator,\nthe same bound as has been established for FB. We show that FB corresponds to\nan unattainable boundary case of the parameters in the new procedure. Unlike\nFB, the new method allows for a backtracking procedure when the cocoercivity\nconstant is unknown. Proving convergence of the algorithm requires some\ndepartures from the prior proof framework for projective splitting. We close\nwith some computational tests establishing competitive performance for the\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 22:14:28 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 18:07:18 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 19:50:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Johnstone", "Patrick R.", ""], ["Eckstein", "Jonathan", ""]]}, {"id": "1902.09030", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang and Kenta Niwa and W. Bastiaan Kleijn", "title": "Rapidly Adapting Moment Estimation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods such as Adam have been shown to be very effective\nfor training deep neural networks (DNNs) by tracking the second moment of\ngradients to compute the individual learning rates. Differently from existing\nmethods, we make use of the most recent first moment of gradients to compute\nthe individual learning rates per iteration. The motivation behind it is that\nthe dynamic variation of the first moment of gradients may provide useful\ninformation to obtain the learning rates. We refer to the new method as the\nrapidly adapting moment estimation (RAME). The theoretical convergence of\ndeterministic RAME is studied by using an analysis similar to the one used in\n[1] for Adam. Experimental results for training a number of DNNs show promising\nperformance of RAME w.r.t. the convergence speed and generalization performance\ncompared to the stochastic heavy-ball (SHB) method, Adam, and RMSprop.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 22:43:40 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Niwa", "Kenta", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1902.09037", "submitter": "Ivan Chelombiev", "authors": "Ivan Chelombiev, Conor Houghton, Cian O'Donnell", "title": "Adaptive Estimators Show Information Compression in Deep Neural Networks", "comments": "Accepted as a poster presentation at ICLR 2019 and reviewed on\n  OpenReview (available at https://openreview.net/forum?id=SkeZisA5t7). Pages:\n  11. Figures: 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve how neural networks function it is crucial to understand their\nlearning process. The information bottleneck theory of deep learning proposes\nthat neural networks achieve good generalization by compressing their\nrepresentations to disregard information that is not relevant to the task.\nHowever, empirical evidence for this theory is conflicting, as compression was\nonly observed when networks used saturating activation functions. In contrast,\nnetworks with non-saturating activation functions achieved comparable levels of\ntask performance but did not show compression. In this paper we developed more\nrobust mutual information estimation techniques, that adapt to hidden activity\nof neural networks and produce more sensitive measurements of activations from\nall functions, especially unbounded functions. Using these adaptive estimation\ntechniques, we explored compression in networks with a range of different\nactivation functions. With two improved methods of estimation, firstly, we show\nthat saturation of the activation function is not required for compression, and\nthe amount of compression varies between different activation functions. We\nalso find that there is a large amount of variation in compression between\ndifferent network initializations. Secondary, we see that L2 regularization\nleads to significantly increased compression, while preventing overfitting.\nFinally, we show that only compression of the last layer is positively\ncorrelated with generalization.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 23:41:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chelombiev", "Ivan", ""], ["Houghton", "Conor", ""], ["O'Donnell", "Cian", ""]]}, {"id": "1902.09062", "submitter": "Yi Han", "authors": "Yi Han, David Hubczenko, Paul Montague, Olivier De Vel, Tamas Abraham,\n  Benjamin I.P. Rubinstein, Christopher Leckie, Tansu Alpcan, Sarah Erfani", "title": "Adversarial Reinforcement Learning under Partial Observability in\n  Autonomous Computer Network Defence", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that reinforcement learning (RL) agents are\nsusceptible to adversarial manipulation, similar to vulnerabilities previously\ndemonstrated in the supervised learning setting. While most existing work\nstudies the problem in the context of computer vision or console games, this\npaper focuses on reinforcement learning in autonomous cyber defence under\npartial observability. We demonstrate that under the black-box setting, where\nthe attacker has no direct access to the target RL model, causative\nattacks---attacks that target the training process---can poison RL agents even\nif the attacker only has partial observability of the environment. In addition,\nwe propose an inversion defence method that aims to apply the opposite\nperturbation to that which an attacker might use to generate their adversarial\nsamples. Our experimental results illustrate that the countermeasure can\neffectively reduce the impact of the causative attack, while not significantly\naffecting the training process in non-attack scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 02:22:25 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:01:18 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 01:09:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Han", "Yi", ""], ["Hubczenko", "David", ""], ["Montague", "Paul", ""], ["De Vel", "Olivier", ""], ["Abraham", "Tamas", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Leckie", "Christopher", ""], ["Alpcan", "Tansu", ""], ["Erfani", "Sarah", ""]]}, {"id": "1902.09068", "submitter": "Shiwen Liu", "authors": "Shiwen Liu, Kan Zheng, Long Zhao, Pingzhi Fan", "title": "A Driving Intention Prediction Method Based on Hidden Markov Model for\n  Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a mixed-traffic scenario where both autonomous vehicles and human-driving\nvehicles exist, a timely prediction of driving intentions of nearby\nhuman-driving vehicles is essential for the safe and efficient driving of an\nautonomous vehicle. In this paper, a driving intention prediction method based\non Hidden Markov Model (HMM) is proposed for autonomous vehicles. HMMs\nrepresenting different driving intentions are trained and tested with field\ncollected data from a flyover. When training the models, either discrete or\ncontinuous characterization of the mobility features of vehicles is applied.\nExperimental results show that the HMMs trained with the continuous\ncharacterization of mobility features can give a higher prediction accuracy\nwhen they are used for predicting driving intentions. Moreover, when the\nsurrounding traffic of the vehicle is taken into account, the performances of\nthe proposed prediction method are further improved.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 02:46:44 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Liu", "Shiwen", ""], ["Zheng", "Kan", ""], ["Zhao", "Long", ""], ["Fan", "Pingzhi", ""]]}, {"id": "1902.09069", "submitter": "Johan Bjorck", "authors": "Johan Bjorck, Brendan H. Rappazzo, Di Chen, Richard Bernstein, Peter\n  H. Wrege and Carla P. Gomes", "title": "Automatic Detection and Compression for Passive Acoustic Monitoring of\n  the African Forest Elephant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider applying machine learning to the analysis and\ncompression of audio signals in the context of monitoring elephants in\nsub-Saharan Africa. Earth's biodiversity is increasingly under threat by\nsources of anthropogenic change (e.g. resource extraction, land use change, and\nclimate change) and surveying animal populations is critical for developing\nconservation strategies. However, manually monitoring tropical forests or deep\noceans is intractable. For species that communicate acoustically, researchers\nhave argued for placing audio recorders in the habitats as a cost-effective and\nnon-invasive method, a strategy known as passive acoustic monitoring (PAM). In\ncollaboration with conservation efforts, we construct a large labeled dataset\nof passive acoustic recordings of the African Forest Elephant via\ncrowdsourcing, compromising thousands of hours of recordings in the wild. Using\nstate-of-the-art techniques in artificial intelligence we improve upon\npreviously proposed methods for passive acoustic monitoring for classification\nand segmentation. In real-time detection of elephant calls, network bandwidth\nquickly becomes a bottleneck and efficient ways to compress the data are\nneeded. Most audio compression schemes are aimed at human listeners and are\nunsuitable for low-frequency elephant calls. To remedy this, we provide a novel\nend-to-end differentiable method for compression of audio signals that can be\nadapted to acoustic monitoring of any species and dramatically improves over\nnaive coding strategies.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 02:48:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Bjorck", "Johan", ""], ["Rappazzo", "Brendan H.", ""], ["Chen", "Di", ""], ["Bernstein", "Richard", ""], ["Wrege", "Peter H.", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1902.09073", "submitter": "Jaewoong Cho", "authors": "Jaewoong Cho and Changho Suh", "title": "Wasserstein GAN Can Perform PCA", "comments": "7 pages, 5 figures. Accepted to the 2019 57th Annual Allerton\n  Conference on Communication, Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become a powerful framework to\nlearn generative models that arise across a wide variety of domains. While\nthere has been a recent surge in the development of numerous GAN architectures\nwith distinct optimization metrics, we are still lacking in our understanding\non how far away such GANs are from optimality. In this paper, we make progress\non a theoretical understanding of the GANs under a simple linear-generator\nGaussian-data setting where the optimal maximum-likelihood generator is known\nto perform Principal Component Analysis (PCA). We find that the original GAN by\nGoodfellow et. al. fails to recover the optimal PCA solution. On the other\nhand, we show that Wasserstein GAN can approach the PCA solution in the limit\nof sample size, and hence it may serve as a basis for an optimal GAN\narchitecture that yields the optimal generator for a wide range of data\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 03:23:39 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 01:28:29 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Cho", "Jaewoong", ""], ["Suh", "Changho", ""]]}, {"id": "1902.09091", "submitter": "Bishan Yang", "authors": "Bishan Yang, Tom Mitchell", "title": "Leveraging Knowledge Bases in LSTMs for Improving Machine Reading", "comments": "published at ACL 2017", "journal-ref": "ACL 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on how to take advantage of external knowledge bases (KBs)\nto improve recurrent neural networks for machine reading. Traditional methods\nthat exploit knowledge from KBs encode knowledge as discrete indicator\nfeatures. Not only do these features generalize poorly, but they require\ntask-specific feature engineering to achieve good performance. We propose\nKBLSTM, a novel neural model that leverages continuous representations of KBs\nto enhance the learning of recurrent neural networks for machine reading. To\neffectively integrate background knowledge with information from the currently\nprocessed text, our model employs an attention mechanism with a sentinel to\nadaptively decide whether to attend to background knowledge and which\ninformation from KBs is useful. Experimental results show that our model\nachieves accuracies that surpass the previous state-of-the-art results for both\nentity extraction and event extraction on the widely used ACE2005 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1902.09096", "submitter": "Li Zhang", "authors": "Li Zhang, Weichen Shen, Shijian Li, Gang Pan", "title": "Field-aware Neural Factorization Machine for Click-Through Rate\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems and computing advertisements have gradually entered\nthe field of academic research from the field of commercial applications.\nClick-through rate prediction is one of the core research issues because the\nprediction accuracy affects the user experience and the revenue of merchants\nand platforms. Feature engineering is very important to improve click-through\nrate prediction. Traditional feature engineering heavily relies on people's\nexperience, and is difficult to construct a feature combination that can\ndescribe the complex patterns implied in the data. This paper combines\ntraditional feature combination methods and deep neural networks to automate\nfeature combinations to improve the accuracy of click-through rate prediction.\nWe propose a mechannism named 'Field-aware Neural Factorization Machine'\n(FNFM). This model can have strong second order feature interactive learning\nability like Field-aware Factorization Machine, on this basis, deep neural\nnetwork is used for higher-order feature combination learning. Experiments show\nthat the model has stronger expression ability than current deep learning\nfeature combination models like the DeepFM, DCN and NFM.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:34:15 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Li", ""], ["Shen", "Weichen", ""], ["Li", "Shijian", ""], ["Pan", "Gang", ""]]}, {"id": "1902.09097", "submitter": "Joe Booth", "authors": "Joe Booth, Jackson Booth", "title": "Marathon Environments: Multi-Agent Continuous Control Benchmarks in a\n  Modern Video Game Engine", "comments": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "journal-ref": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning in the paradigm of locomotion\nusing continuous control have raised the interest of game makers for the\npotential of digital actors using active ragdoll. Currently, the available\noptions to develop these ideas are either researchers' limited codebase or\nproprietary closed systems. We present Marathon Environments, a suite of open\nsource, continuous control benchmarks implemented on the Unity game engine,\nusing the Unity ML- Agents Toolkit. We demonstrate through these benchmarks\nthat continuous control research is transferable to a commercial game engine.\nFurthermore, we exhibit the robustness of these environments by reproducing\nadvanced continuous control research, such as learning to walk, run and\nbackflip from motion capture data; learning to navigate complex terrains; and\nby implementing a video game input control system. We show further robustness\nby training with alternative algorithms found in OpenAI.Baselines. Finally, we\nshare strategies for significantly reducing the training time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:56:35 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Booth", "Joe", ""], ["Booth", "Jackson", ""]]}, {"id": "1902.09122", "submitter": "Uri Alon", "authors": "Yaniv David, Uri Alon, Eran Yahav", "title": "Neural Reverse Engineering of Stripped Binaries using Augmented Control\n  Flow Graphs", "comments": null, "journal-ref": null, "doi": "10.1145/3428293", "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of reverse engineering of stripped executables, which\ncontain no debug information. This is a challenging problem because of the low\namount of syntactic information available in stripped executables, and the\ndiverse assembly code patterns arising from compiler optimizations.\n  We present a novel approach for predicting procedure names in stripped\nexecutables. Our approach combines static analysis with neural models. The main\nidea is to use static analysis to obtain augmented representations of call\nsites; encode the structure of these call sites using the control-flow graph\n(CFG) and finally, generate a target name while attending to these call sites.\nWe use our representation to drive graph-based, LSTM-based and\nTransformer-based architectures.\n  Our evaluation shows that our models produce predictions that are difficult\nand time consuming for humans, while improving on existing methods by 28% and\nby 100% over state-of-the-art neural textual models that do not use any static\nanalysis. Code and data for this evaluation are available at\nhttps://github.com/tech-srl/Nero .\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 07:30:39 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 08:21:53 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 07:22:27 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 08:42:40 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["David", "Yaniv", ""], ["Alon", "Uri", ""], ["Yahav", "Eran", ""]]}, {"id": "1902.09154", "submitter": "Zhihui Ji", "authors": "Qi Wang, Zhihui Ji, Huasheng Liu, Binqiang Zhao", "title": "Deep Bayesian Multi-Target Learning for Recommender Systems", "comments": "7 pages, Deep Learning, Probabilistic Machine Learning, Recommender\n  System, Multi-task Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing variety of services that e-commerce platforms provide,\ncriteria for evaluating their success become also increasingly multi-targeting.\nThis work introduces a multi-target optimization framework with Bayesian\nmodeling of the target events, called Deep Bayesian Multi-Target Learning\n(DBMTL). In this framework, target events are modeled as forming a Bayesian\nnetwork, in which directed links are parameterized by hidden layers, and\nlearned from training samples. The structure of Bayesian network is determined\nby model selection. We applied the framework to Taobao live-streaming\nrecommendation, to simultaneously optimize (and strike a balance) on targets\nincluding click-through rate, user stay time in live room, purchasing behaviors\nand interactions. Significant improvement has been observed for the proposed\nmethod over other MTL frameworks and the non-MTL model. Our practice shows that\nwith an integrated causality structure, we can effectively make the learning of\na target benefit from other targets, creating significant synergy effects that\nimprove all targets. The neural network construction guided by DBMTL fits in\nwith the general probabilistic model connecting features and multiple targets,\ntaking weaker assumption than the other methods discussed in this paper. This\ntheoretical generality brings about practical generalization power over various\ntargets distributions, including sparse targets and continuous-value ones.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 09:11:53 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Wang", "Qi", ""], ["Ji", "Zhihui", ""], ["Liu", "Huasheng", ""], ["Zhao", "Binqiang", ""]]}, {"id": "1902.09162", "submitter": "Shuai Li", "authors": "Shuai Li, Wei Chen, Shuai Li, Kwong-Sak Leung", "title": "Improved Algorithm on Online Clustering of Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the setting of online clustering of bandits by allowing\nnon-uniform distribution over user frequencies. A more efficient algorithm is\nproposed with simple set structures to represent clusters. We prove a regret\nbound for the new algorithm which is free of the minimal frequency over users.\nThe experiments on both synthetic and real datasets consistently show the\nadvantage of the new algorithm over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 09:31:15 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 08:43:49 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Shuai", ""], ["Chen", "Wei", ""], ["Li", "Shuai", ""], ["Leung", "Kwong-Sak", ""]]}, {"id": "1902.09173", "submitter": "Feng Ji", "authors": "Feng Ji, Jielong Yang, Qiang Zhang, and Wee Peng Tay", "title": "GFCN: A New Graph Convolutional Network Based on Parallel Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In view of the huge success of convolution neural networks (CNN) for image\nclassification and object recognition, there have been attempts to generalize\nthe method to general graph-structured data. One major direction is based on\nspectral graph theory and graph signal processing. In this paper, we study the\nproblem from a completely different perspective, by introducing parallel flow\ndecomposition of graphs. The essential idea is to decompose a graph into\nfamilies of non-intersecting one dimensional (1D) paths, after which, we may\napply a 1D CNN along each family of paths. We demonstrate that the our method,\nwhich we call GraphFlow, is able to transfer CNN architectures to general\ngraphs. To show the effectiveness of our approach, we test our method on the\nclassical MNIST dataset, synthetic datasets on network information propagation\nand a news article classification dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:06:15 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:06:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 09:50:59 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 09:50:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Ji", "Feng", ""], ["Yang", "Jielong", ""], ["Zhang", "Qiang", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1902.09191", "submitter": "Shaojie Jiang", "authors": "Shaojie Jiang, Pengjie Ren, Christof Monz, Maarten de Rijke", "title": "Improving Neural Response Diversity with Frequency-Aware Cross-Entropy\n  Loss", "comments": "Will appear at The Web Conference 2019", "journal-ref": null, "doi": "10.1145/3308558.3313415", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-Sequence (Seq2Seq) models have achieved encouraging performance\non the dialogue response generation task. However, existing Seq2Seq-based\nresponse generation methods suffer from a low-diversity problem: they\nfrequently generate generic responses, which make the conversation less\ninteresting. In this paper, we address the low-diversity problem by\ninvestigating its connection with model over-confidence reflected in predicted\ndistributions. Specifically, we first analyze the influence of the commonly\nused Cross-Entropy (CE) loss function, and find that the CE loss function\nprefers high-frequency tokens, which results in low-diversity responses. We\nthen propose a Frequency-Aware Cross-Entropy (FACE) loss function that improves\nover the CE loss function by incorporating a weighting mechanism conditioned on\ntoken frequency. Extensive experiments on benchmark datasets show that the FACE\nloss function is able to substantially improve the diversity of existing\nstate-of-the-art Seq2Seq response generation methods, in terms of both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:53:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jiang", "Shaojie", ""], ["Ren", "Pengjie", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1902.09192", "submitter": "Zhijie Deng", "authors": "Zhijie Deng and Yinpeng Dong and Jun Zhu", "title": "Batch Virtual Adversarial Training for Graph Convolutional Networks", "comments": "ICML 2019 Workshop on Learning and Reasoning with Graph-Structured\n  Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present batch virtual adversarial training (BVAT), a novel regularization\nmethod for graph convolutional networks (GCNs). BVAT addresses the shortcoming\nof GCNs that do not consider the smoothness of the model's output distribution\nagainst local perturbations around the input. We propose two algorithms,\nsample-based BVAT and optimization-based BVAT, which are suitable to promote\nthe smoothness of the model for graph-structured data by either finding virtual\nadversarial perturbations for a subset of nodes far from each other or\ngenerating virtual adversarial perturbations for all nodes with an optimization\nprocess. Extensive experiments on three citation network datasets Cora,\nCiteseer and Pubmed and a knowledge graph dataset Nell validate the\neffectiveness of the proposed method, which establishes state-of-the-art\nresults in the semi-supervised node classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:57:43 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 02:05:30 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Deng", "Zhijie", ""], ["Dong", "Yinpeng", ""], ["Zhu", "Jun", ""]]}, {"id": "1902.09216", "submitter": "Aleksey Fedorov", "authors": "Y.A. Kharkov, V.E. Sotskov, A.A. Karazeev, E.O. Kiktenko, and A.K.\n  Fedorov", "title": "Revealing quantum chaos with machine learning", "comments": "12 pages, 12 figures", "journal-ref": "Phys. Rev. B 101, 064406 (2020)", "doi": "10.1103/PhysRevB.101.064406", "report-no": null, "categories": "quant-ph cond-mat.quant-gas cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding properties of quantum matter is an outstanding challenge in\nscience. In this paper, we demonstrate how machine-learning methods can be\nsuccessfully applied for the classification of various regimes in\nsingle-particle and many-body systems. We realize neural network algorithms\nthat perform a classification between regular and chaotic behavior in quantum\nbilliard models with remarkably high accuracy. We use the variational\nautoencoder for autosupervised classification of regular/chaotic wave\nfunctions, as well as demonstrating that variational autoencoders could be used\nas a tool for detection of anomalous quantum states, such as quantum scars. By\ntaking this method further, we show that machine learning techniques allow us\nto pin down the transition from integrability to many-body quantum chaos in\nHeisenberg XXZ spin chains. For both cases, we confirm the existence of\nuniversal W shapes that characterize the transition. Our results pave the way\nfor exploring the power of machine learning tools for revealing exotic\nphenomena in quantum many-body systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:01:55 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:36:32 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Kharkov", "Y. A.", ""], ["Sotskov", "V. E.", ""], ["Karazeev", "A. A.", ""], ["Kiktenko", "E. O.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "1902.09225", "submitter": "Soochan Lee", "authors": "Soochan Lee, Junsoo Ha, Gunhee Kim", "title": "Harmonizing Maximum Likelihood with GANs for Multimodal Conditional\n  Generation", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in conditional image generation tasks, such as image-to-image\ntranslation and image inpainting, are largely accounted to the success of\nconditional GAN models, which are often optimized by the joint use of the GAN\nloss with the reconstruction loss. However, we reveal that this training recipe\nshared by almost all existing methods causes one critical side effect: lack of\ndiversity in output samples. In order to accomplish both training stability and\nmultimodal output generation, we propose novel training schemes with a new set\nof losses named moment reconstruction losses that simply replace the\nreconstruction loss. We show that our approach is applicable to any conditional\ngeneration tasks by performing thorough experiments on image-to-image\ntranslation, super-resolution and image inpainting using Cityscapes and CelebA\ndataset. Quantitative evaluations also confirm that our methods achieve a great\ndiversity in outputs while retaining or even improving the visual fidelity of\ngenerated samples.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:22:28 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lee", "Soochan", ""], ["Ha", "Junsoo", ""], ["Kim", "Gunhee", ""]]}, {"id": "1902.09229", "submitter": "Nikunj Saunshi", "authors": "Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis\n  Plevrakis, Nikunj Saunshi", "title": "A Theoretical Analysis of Contrastive Unsupervised Representation\n  Learning", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent empirical works have successfully used unlabeled data to learn feature\nrepresentations that are broadly useful in downstream classification tasks.\nSeveral of these methods are reminiscent of the well-known word2vec embedding\nalgorithm: leveraging availability of pairs of semantically \"similar\" data\npoints and \"negative samples,\" the learner forces the inner product of\nrepresentations of similar pairs with each other to be higher on average than\nwith negative samples. The current paper uses the term contrastive learning for\nsuch algorithms and presents a theoretical framework for analyzing them by\nintroducing latent classes and hypothesizing that semantically similar points\nare sampled from the same latent class. This framework allows us to show\nprovable guarantees on the performance of the learned representations on the\naverage classification task that is comprised of a subset of the same set of\nlatent classes. Our generalization bound also shows that learned\nrepresentations can reduce (labeled) sample complexity on downstream tasks. We\nconduct controlled experiments in both the text and image domains to support\nthe theory.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:32:15 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Arora", "Sanjeev", ""], ["Khandeparkar", "Hrishikesh", ""], ["Khodak", "Mikhail", ""], ["Plevrakis", "Orestis", ""], ["Saunshi", "Nikunj", ""]]}, {"id": "1902.09238", "submitter": "Ruihan Hu", "authors": "Ruihan Hu, Qijun Huang, Sheng Chang, Hao Wang and Jin He", "title": "The MBPEP: a deep ensemble pruning algorithm providing high quality\n  uncertainty prediction", "comments": "20 pages, 7 figures", "journal-ref": "Applied Intelligence(2019)", "doi": "10.1007/s10489-019-01421-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been effectively applied into various real\nworld tasks. However, it is difficult to provide high-quality machine learning\nsolutions to accommodate an unknown distribution of input datasets; this\ndifficulty is called the uncertainty prediction problems. In this paper, a\nmargin-based Pareto deep ensemble pruning (MBPEP) model is proposed. It\nachieves the high-quality uncertainty estimation with a small value of the\nprediction interval width (MPIW) and a high confidence of prediction interval\ncoverage probability (PICP) by using deep ensemble networks. In addition to\nthese networks, unique loss functions are proposed, and these functions make\nthe sub-learners available for standard gradient descent learning. Furthermore,\nthe margin criterion fine-tuning-based Pareto pruning method is introduced to\noptimize the ensembles. Several experiments including predicting uncertainties\nof classification and regression are conducted to analyze the performance of\nMBPEP. The experimental results show that MBPEP achieves a small interval width\nand a low learning error with an optimal number of ensembles. For the\nreal-world problems, MBPEP performs well on input datasets with unknown\ndistributions datasets incomings and improves learning performance on a multi\ntask problem when compared to that of each single model.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:52:29 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hu", "Ruihan", ""], ["Huang", "Qijun", ""], ["Chang", "Sheng", ""], ["Wang", "Hao", ""], ["He", "Jin", ""]]}, {"id": "1902.09240", "submitter": "David Castillo Bolado", "authors": "David Castillo-Bolado, Cayetano Guerra-Artal, Mario Hernandez-Tejera", "title": "Modularity as a Means for Complexity Management in Neural Networks\n  Learning", "comments": "Full-paper submited to the AAAI-MAKE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a Neural Network (NN) with lots of parameters or intricate\narchitectures creates undesired phenomena that complicate the optimization\nprocess. To address this issue we propose a first modular approach to NN\ndesign, wherein the NN is decomposed into a control module and several\nfunctional modules, implementing primitive operations. We illustrate the\nmodular concept by comparing performances between a monolithic and a modular NN\non a list sorting problem and show the benefits in terms of training speed,\ntraining stability and maintainability. We also discuss some questions that\narise in modular NNs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:57:58 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Castillo-Bolado", "David", ""], ["Guerra-Artal", "Cayetano", ""], ["Hernandez-Tejera", "Mario", ""]]}, {"id": "1902.09255", "submitter": "Xianfeng Tang", "authors": "Xianfeng Tang, Boqing Gong, Yanwei Yu, Huaxiu Yao, Yandong Li, Haiyong\n  Xie, Xiaoyu Wang", "title": "Joint Modeling of Dense and Incomplete Trajectories for Citywide Traffic\n  Volume Inference", "comments": "Accepted by The Web Conference (WWW) 2019", "journal-ref": null, "doi": "10.1145/3308558.3313621", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time traffic volume inference is key to an intelligent city. It is a\nchallenging task because accurate traffic volumes on the roads can only be\nmeasured at certain locations where sensors are installed. Moreover, the\ntraffic evolves over time due to the influences of weather, events, holidays,\netc. Existing solutions to the traffic volume inference problem often rely on\ndense GPS trajectories, which inevitably fail to account for the vehicles which\ncarry no GPS devices or have them turned off. Consequently, the results are\nbiased to taxicabs because they are almost always online for GPS tracking. In\nthis paper, we propose a novel framework for the citywide traffic volume\ninference using both dense GPS trajectories and incomplete trajectories\ncaptured by camera surveillance systems. Our approach employs a high-fidelity\ntraffic simulator and deep reinforcement learning to recover full vehicle\nmovements from the incomplete trajectories. In order to jointly model the\nrecovered trajectories and dense GPS trajectories, we construct spatiotemporal\ngraphs and use multi-view graph embedding to encode the multi-hop correlations\nbetween road segments into real-valued vectors. Finally, we infer the citywide\ntraffic volumes by propagating the traffic values of monitored road segments to\nthe unmonitored ones through masked pairwise similarities. Extensive\nexperiments with two big regions in a provincial capital city in China verify\nthe effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:27:17 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Tang", "Xianfeng", ""], ["Gong", "Boqing", ""], ["Yu", "Yanwei", ""], ["Yao", "Huaxiu", ""], ["Li", "Yandong", ""], ["Xie", "Haiyong", ""], ["Wang", "Xiaoyu", ""]]}, {"id": "1902.09278", "submitter": "Weitian Li", "authors": "Weitian Li, Haiguang Xu, Zhixian Ma, Ruimin Zhu, Dan Hu, Zhenghao Zhu,\n  Junhua Gu, Chenxi Shan, Jie Zhu, Xiang-Ping Wu", "title": "Separating the EoR Signal with a Convolutional Denoising Autoencoder: A\n  Deep-learning-based Method", "comments": "10 pages, 9 figures; minor text updates to match the MNRAS published\n  version", "journal-ref": "2019, MNRAS, 485, 2628", "doi": "10.1093/mnras/stz582", "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying the foreground removal methods to uncover the faint\ncosmological signal from the epoch of reionization (EoR), the foreground\nspectra are assumed to be smooth. However, this assumption can be seriously\nviolated in practice since the unresolved or mis-subtracted foreground sources,\nwhich are further complicated by the frequency-dependent beam effects of\ninterferometers, will generate significant fluctuations along the frequency\ndimension. To address this issue, we propose a novel deep-learning-based method\nthat uses a 9-layer convolutional denoising autoencoder (CDAE) to separate the\nEoR signal. After being trained on the SKA images simulated with realistic beam\neffects, the CDAE achieves excellent performance as the mean correlation\ncoefficient ($\\bar{\\rho}$) between the reconstructed and input EoR signals\nreaches $0.929 \\pm 0.045$. In comparison, the two representative traditional\nmethods, namely the polynomial fitting method and the continuous wavelet\ntransform method, both have difficulties in modelling and removing the\nforeground emission complicated with the beam effects, yielding only\n$\\bar{\\rho}_{\\text{poly}} = 0.296 \\pm 0.121$ and $\\bar{\\rho}_{\\text{cwt}} =\n0.198 \\pm 0.160$, respectively. We conclude that, by hierarchically learning\nsophisticated features through multiple convolutional layers, the CDAE is a\npowerful tool that can be used to overcome the complicated beam effects and\naccurately separate the EoR signal. Our results also exhibit the great\npotential of deep-learning-based methods in future EoR experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:13:09 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 16:53:34 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Li", "Weitian", ""], ["Xu", "Haiguang", ""], ["Ma", "Zhixian", ""], ["Zhu", "Ruimin", ""], ["Hu", "Dan", ""], ["Zhu", "Zhenghao", ""], ["Gu", "Junhua", ""], ["Shan", "Chenxi", ""], ["Zhu", "Jie", ""], ["Wu", "Xiang-Ping", ""]]}, {"id": "1902.09286", "submitter": "Jan Philip G\\\"opfert", "authors": "Jan Philip G\\\"opfert and Andr\\'e Artelt and Heiko Wersing and Barbara\n  Hammer", "title": "Adversarial attacks hidden in plain sight", "comments": null, "journal-ref": "Advances in Intelligent Data Analysis XVIII (2020) Pages 235-247", "doi": "10.1007/978-3-030-44584-3_19", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been used to achieve a string of successes\nduring recent years, but their lack of interpretability remains a serious\nissue. Adversarial examples are designed to deliberately fool neural networks\ninto making any desired incorrect classification, potentially with very high\ncertainty. Several defensive approaches increase robustness against adversarial\nattacks, demanding attacks of greater magnitude, which lead to visible\nartifacts. By considering human visual perception, we compose a technique that\nallows to hide such adversarial attacks in regions of high complexity, such\nthat they are imperceptible even to an astute observer. We carry out a user\nstudy on classifying adversarially modified images to validate the perceptual\nquality of our approach and find significant evidence for its concealment with\nregards to human visual perception.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:27:05 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 20:48:37 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 13:45:21 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["G\u00f6pfert", "Jan Philip", ""], ["Artelt", "Andr\u00e9", ""], ["Wersing", "Heiko", ""], ["Hammer", "Barbara", ""]]}, {"id": "1902.09294", "submitter": "Ahmed Rashed", "authors": "Ahmed Rashed, Josif Grabocka, Lars Schmidt-Thieme", "title": "Multi-Label Network Classification via Weighted Personalized\n  Factorizations", "comments": "Accepted in ICAART 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label network classification is a well-known task that is being used in\na wide variety of web-based and non-web-based domains. It can be formalized as\na multi-relational learning task for predicting nodes labels based on their\nrelations within the network. In sparse networks, this prediction task can be\nvery challenging when only implicit feedback information is available such as\nin predicting user interests in social networks. Current approaches rely on\nlearning per-node latent representations by utilizing the network structure,\nhowever, implicit feedback relations are naturally sparse and contain only\npositive observed feedbacks which mean that these approaches will treat all\nobserved relations as equally important. This is not necessarily the case in\nreal-world scenarios as implicit relations might have semantic weights which\nreflect the strength of those relations. If those weights can be approximated,\nthe models can be trained to differentiate between strong and weak relations.\nIn this paper, we propose a weighted personalized two-stage multi-relational\nmatrix factorization model with Bayesian personalized ranking loss for network\nclassification that utilizes basic transitive node similarity function for\nweighting implicit feedback relations. Experiments show that the proposed model\nsignificantly outperforms the state-of-art models on three different real-world\nweb-based datasets and a biology-based dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:35:31 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Rashed", "Ahmed", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1902.09323", "submitter": "Yuling Jiao", "authors": "Shunkang Zhang, Yuan Gao, Yuling Jiao, Jin Liu, Yang Wang and Can Yang", "title": "Wasserstein-Wasserstein Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the challenges in learning deep generative models (e.g.,the\nblurriness of variational auto-encoder and the instability of training\ngenerative adversarial networks, we propose a novel deep generative model,\nnamed Wasserstein-Wasserstein auto-encoders (WWAE). We formulate WWAE as\nminimization of the penalized optimal transport between the target distribution\nand the generated distribution. By noticing that both the prior $P_Z$ and the\naggregated posterior $Q_Z$ of the latent code Z can be well captured by\nGaussians, the proposed WWAE utilizes the closed-form of the squared\nWasserstein-2 distance for two Gaussians in the optimization process. As a\nresult, WWAE does not suffer from the sampling burden and it is computationally\nefficient by leveraging the reparameterization trick. Numerical results\nevaluated on multiple benchmark datasets including MNIST, fashion- MNIST and\nCelebA show that WWAE learns better latent structures than VAEs and generates\nsamples of better visual quality and higher FID scores than VAEs and GANs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:57:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Shunkang", ""], ["Gao", "Yuan", ""], ["Jiao", "Yuling", ""], ["Liu", "Jin", ""], ["Wang", "Yang", ""], ["Yang", "Can", ""]]}, {"id": "1902.09328", "submitter": "Megumi Nakao", "authors": "Megumi Nakao, Mitsuki Morita, Tetsuya Matsuda", "title": "Sparse Elasticity Reconstruction and Clustering using Local Displacement\n  Fields", "comments": "Elasticity reconstruction, Sparse modeling, Online clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an elasticity reconstruction method based on local\ndisplacement observations of elastic bodies. Sparse reconstruction theory is\napplied to formulate the underdetermined inverse problems of elasticity\nreconstruction including unobserved areas. An online local clustering scheme\ncalled a superelement is proposed to reduce the number of dimensions of the\noptimization parameters. Alternating the optimization of element boundaries and\nelasticity parameters enables the elasticity distribution to be estimated with\na higher spatial resolution. The simulation experiments show that elasticity\ndistribution is reconstructed based on observations of approximately 10% of the\ntotal body. The estimation error was improved when considering the sparseness\nof the elasticity distribution.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 11:44:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Nakao", "Megumi", ""], ["Morita", "Mitsuki", ""], ["Matsuda", "Tetsuya", ""]]}, {"id": "1902.09347", "submitter": "Huiru Xiao", "authors": "Huiru Xiao, Xin Liu, Yangqiu Song", "title": "Efficient Path Prediction for Semi-Supervised and Weakly Supervised\n  Hierarchical Text Classification", "comments": "Aceepted by 2019 World Wide Web Conference (WWW19)", "journal-ref": null, "doi": "10.1145/3308558.3313658", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical text classification has many real-world applications. However,\nlabeling a large number of documents is costly. In practice, we can use\nsemi-supervised learning or weakly supervised learning (e.g., dataless\nclassification) to reduce the labeling cost. In this paper, we propose a path\ncost-sensitive learning algorithm to utilize the structural information and\nfurther make use of unlabeled and weakly-labeled data. We use a generative\nmodel to leverage the large amount of unlabeled data and introduce path\nconstraints into the learning algorithm to incorporate the structural\ninformation of the class hierarchy. The posterior probabilities of both\nunlabeled and weakly labeled data can be incorporated with path-dependent\nscores. Since we put a structure-sensitive cost to the learning algorithm to\nconstrain the classification consistent with the class hierarchy and do not\nneed to reconstruct the feature vectors for different structures, we can\nsignificantly reduce the computational cost compared to structural output\nlearning. Experimental results on two hierarchical text classification\nbenchmarks show that our approach is not only effective but also efficient to\nhandle the semi-supervised and weakly supervised hierarchical text\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:11:44 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Xiao", "Huiru", ""], ["Liu", "Xin", ""], ["Song", "Yangqiu", ""]]}, {"id": "1902.09357", "submitter": "Mikel Elkano", "authors": "Mikel Elkano and Jose Sanz and Edurne Barrenechea and Humberto\n  Bustince and Mikel Galar", "title": "CFM-BD: a distributed rule induction algorithm for building Compact\n  Fuzzy Models in Big Data classification problems", "comments": "Appears in IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2019.2900856", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has always been a major concern for fuzzy rule-based\nclassifiers. The usage of human-readable models allows them to explain the\nreasoning behind their predictions and decisions. However, when it comes to Big\nData classification problems, fuzzy rule-based classifiers have not been able\nto maintain the good trade-off between accuracy and interpretability that has\ncharacterized these techniques in non-Big Data environments. The most accurate\nmethods build too complex models composed of a large number of rules and fuzzy\nsets, while those approaches focusing on interpretability do not provide\nstate-of-the-art discrimination capabilities. In this paper, we propose a new\ndistributed learning algorithm named CFM-BD to construct accurate and compact\nfuzzy rule-based classification systems for Big Data. This method has been\nspecifically designed from scratch for Big Data problems and does not adapt or\nextend any existing algorithm. The proposed learning process consists of three\nstages: 1) pre-processing based on the probability integral transform theorem;\n2) rule induction inspired by CHI-BD and Apriori algorithms; 3) rule selection\nby means of a global evolutionary optimization. We conducted a complete\nempirical study to test the performance of our approach in terms of accuracy,\ncomplexity, and runtime. The results obtained were compared and contrasted with\nfour state-of-the-art fuzzy classifiers for Big Data (FBDT, FMDT, Chi-Spark-RS,\nand CHI-BD). According to this study, CFM-BD is able to provide competitive\ndiscrimination capabilities using significantly simpler models composed of a\nfew rules of less than 3 antecedents, employing 5 linguistic labels for all\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:22:04 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Elkano", "Mikel", ""], ["Sanz", "Jose", ""], ["Barrenechea", "Edurne", ""], ["Bustince", "Humberto", ""], ["Galar", "Mikel", ""]]}, {"id": "1902.09393", "submitter": "Serhii Havrylov", "authors": "Serhii Havrylov, Germ\\'an Kruszewski, Armand Joulin", "title": "Cooperative Learning of Disjoint Syntax and Semantics", "comments": "The paper was accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable attention devoted to models that learn to jointly\ninfer an expression's syntactic structure and its semantics. Yet,\n\\citet{NangiaB18} has recently shown that the current best systems fail to\nlearn the correct parsing strategy on mathematical expressions generated from a\nsimple context-free grammar. In this work, we present a recursive model\ninspired by \\newcite{ChoiYL18} that reaches near perfect accuracy on this task.\nOur model is composed of two separated modules for syntax and semantics. They\nare cooperatively trained with standard continuous and discrete optimization\nschemes. Our model does not require any linguistic structure for supervision\nand its recursive nature allows for out-of-domain generalization with little\nloss in performance. Additionally, our approach performs competitively on\nseveral natural language tasks, such as Natural Language Inference or Sentiment\nAnalysis.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:56:34 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:42:17 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Havrylov", "Serhii", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Joulin", "Armand", ""]]}, {"id": "1902.09426", "submitter": "Shun Takeuchi Ph.D.", "authors": "Shun Takeuchi, Takuya Nishino, Takahiro Saito, Isamu Watanabe", "title": "Semi-supervised Approach to Soft Sensor Modeling for Fault Detection in\n  Industrial Systems with Multiple Operation Modes", "comments": "7 pages, 1 figure", "journal-ref": "International Conference on Advanced Intelligent Systems and\n  Informatics 2017", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial systems, certain process variables that need to be monitored\nfor detecting faults are often difficult or impossible to measure. Soft sensor\ntechniques are widely used to estimate such difficult-to-measure process\nvariables from easy-to-measure ones. Soft sensor modeling requires training\ndatasets including the information of various states such as operation modes,\nbut the fault dataset with the target variable is insufficient as the training\ndataset. This paper describes a semi-supervised approach to soft sensor\nmodeling to incorporate an incomplete dataset without the target variable in\nthe training dataset. To incorporate the incomplete dataset, we consider the\nproperties of processes at transition points between operation modes in the\nsystem. The regression coefficients of the operation modes are estimated under\nconstraint conditions obtained from the information on the mode transitions. In\na case study, this constrained soft sensor modeling was used to predict\nrefrigerant leaks in air-conditioning systems with heating and cooling\noperation modes. The results show that this modeling method is promising for\nsoft sensors in a system with multiple operation modes.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 14:12:28 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Takeuchi", "Shun", ""], ["Nishino", "Takuya", ""], ["Saito", "Takahiro", ""], ["Watanabe", "Isamu", ""]]}, {"id": "1902.09427", "submitter": "Shun Takeuchi Ph.D.", "authors": "Shun Takeuchi, Takahiro Saito", "title": "Fault Diagnosis Method Based on Scaling Law for On-line Refrigerant Leak\n  Detection", "comments": "8 pages, 6 figures", "journal-ref": "2018 17th IEEE International Conference on Machine Learning and\n  Applications (ICMLA)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early fault detection using instrumented sensor data is one of the promising\napplication areas of machine learning in industrial facilities. However, it is\ndifficult to improve the generalization performance of the trained\nfault-detection model because of the complex system configuration in the target\ndiagnostic system and insufficient fault data. It is not trivial to apply the\ntrained model to other systems. Here we propose a fault diagnosis method for\nrefrigerant leak detection considering the physical modeling and control\nmechanism of an air-conditioning system. We derive a useful scaling law related\nto refrigerant leak. If the control mechanism is the same, the model can be\napplied to other air-conditioning systems irrespective of the system\nconfiguration. Small-scale off-line fault test data obtained in a laboratory\nare applied to estimate the scaling exponent. We evaluate the proposed scaling\nlaw by using real-world data. Based on a statistical hypothesis test of the\ninteraction between two groups, we show that the scaling exponents of different\nair-conditioning systems are equivalent. In addition, we estimated the time\nseries of the degree of leakage of real process data based on the scaling law\nand confirmed that the proposed method is promising for early leak detection\nthrough comparison with assessment by experts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 15:30:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Takeuchi", "Shun", ""], ["Saito", "Takahiro", ""]]}, {"id": "1902.09432", "submitter": "Jaehong Yoon", "authors": "Jaehong Yoon, Saehoon Kim, Eunho Yang, Sung Ju Hwang", "title": "Scalable and Order-robust Continual Learning with Additive Parameter\n  Decomposition", "comments": "Published in \"International Conference on Learning Representation\n  (ICLR)\" 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent continual learning methods largely alleviate the catastrophic\nproblem on toy-sized datasets, some issues remain to be tackled to apply them\nto real-world problem domains. First, a continual learning model should\neffectively handle catastrophic forgetting and be efficient to train even with\na large number of tasks. Secondly, it needs to tackle the problem of\norder-sensitivity, where the performance of the tasks largely varies based on\nthe order of the task arrival sequence, as it may cause serious problems where\nfairness plays a critical role (e.g. medical diagnosis). To tackle these\npractical challenges, we propose a novel continual learning method that is\nscalable as well as order-robust, which instead of learning a completely shared\nset of weights, represents the parameters for each task as a sum of task-shared\nand sparse task-adaptive parameters. With our Additive Parameter Decomposition\n(APD), the task-adaptive parameters for earlier tasks remain mostly unaffected,\nwhere we update them only to reflect the changes made to the task-shared\nparameters. This decomposition of parameters effectively prevents catastrophic\nforgetting and order-sensitivity, while being computation- and\nmemory-efficient. Further, we can achieve even better scalability with APD\nusing hierarchical knowledge consolidation, which clusters the task-adaptive\nparameters to obtain hierarchically shared parameters. We validate our network\nwith APD, APD-Net, on multiple benchmark datasets against state-of-the-art\ncontinual learning methods, which it largely outperforms in accuracy,\nscalability, and order-robustness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 16:49:52 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 19:44:15 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 14:13:27 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yoon", "Jaehong", ""], ["Kim", "Saehoon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1902.09434", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "S-TRIGGER: Continual State Representation Learning via Self-Triggered\n  Generative Replay", "comments": "Accepted to IJCNN 2021. arXiv admin note: text overlap with\n  arXiv:1810.03880", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of building a state representation model for control,\nin a continual learning setting. As the environment changes, the aim is to\nefficiently compress the sensory state's information without losing past\nknowledge, and then use Reinforcement Learning on the resulting features for\nefficient policy learning. To this end, we propose S-TRIGGER, a general method\nfor Continual State Representation Learning applicable to Variational\nAuto-Encoders and its many variants. The method is based on Generative Replay,\ni.e. the use of generated samples to maintain past knowledge. It comes along\nwith a statistically sound method for environment change detection, which\nself-triggers the Generative Replay. Our experiments on VAEs show that\nS-TRIGGER learns state representations that allows fast and high-performing\nReinforcement Learning, while avoiding catastrophic forgetting. The resulting\nsystem is capable of autonomously learning new information without using past\ndata and with a bounded system size. Code for our experiments is attached in\nAppendix.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 16:52:49 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 13:25:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "1902.09458", "submitter": "Aleksandra Faust", "authors": "Anthony Francis and Aleksandra Faust and Hao-Tien Lewis Chiang and\n  Jasmine Hsu and J. Chase Kew and Marek Fiser and Tsang-Wei Edward Lee", "title": "Long-Range Indoor Navigation with PRM-RL", "comments": "Accepted to T-RO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range indoor navigation requires guiding robots with noisy sensors and\ncontrols through cluttered environments along paths that span a variety of\nbuildings. We achieve this with PRM-RL, a hierarchical robot navigation method\nin which reinforcement learning agents that map noisy sensors to robot controls\nlearn to solve short-range obstacle avoidance tasks, and then sampling-based\nplanners map where these agents can reliably navigate in simulation; these\nroadmaps and agents are then deployed on robots, guiding them along the\nshortest path where the agents are likely to succeed. Here we use Probabilistic\nRoadmaps (PRMs) as the sampling-based planner, and AutoRL as the reinforcement\nlearning method in the indoor navigation context. We evaluate the method in\nsimulation for kinematic differential drive and kinodynamic car-like robots in\nseveral environments, and on differential-drive robots at three physical sites.\nOur results show PRM-RL with AutoRL is more successful than several baselines,\nis robust to noise, and can guide robots over hundreds of meters in the face of\nnoise and obstacles in both simulation and on robots, including over 5.8\nkilometers of physical robot navigation. Video: https://youtu.be/xN-OWX5gKvQ\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:20:06 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 20:27:22 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Francis", "Anthony", ""], ["Faust", "Aleksandra", ""], ["Chiang", "Hao-Tien Lewis", ""], ["Hsu", "Jasmine", ""], ["Kew", "J. Chase", ""], ["Fiser", "Marek", ""], ["Lee", "Tsang-Wei Edward", ""]]}, {"id": "1902.09465", "submitter": "Daniel LeJeune", "authors": "Daniel LeJeune, Richard G. Baraniuk, Reinhard Heckel", "title": "Adaptive Estimation for Approximate k-Nearest-Neighbor Computations", "comments": "11 pages, 2 figures. To appear in AISTATS 2019", "journal-ref": "Proceedings of Machine Learning Research 89 (2019):3099-3107", "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms often carry out equally many computations for \"easy\" and \"hard\"\nproblem instances. In particular, algorithms for finding nearest neighbors\ntypically have the same running time regardless of the particular problem\ninstance. In this paper, we consider the approximate k-nearest-neighbor\nproblem, which is the problem of finding a subset of O(k) points in a given set\nof points that contains the set of k nearest neighbors of a given query point.\nWe propose an algorithm based on adaptively estimating the distances, and show\nthat it is essentially optimal out of algorithms that are only allowed to\nadaptively estimate distances. We then demonstrate both theoretically and\nexperimentally that the algorithm can achieve significant speedups relative to\nthe naive method.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:30:07 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["LeJeune", "Daniel", ""], ["Baraniuk", "Richard G.", ""], ["Heckel", "Reinhard", ""]]}, {"id": "1902.09476", "submitter": "Sunil Mohan", "authors": "Sunil Mohan and Donghui Li", "title": "MedMentions: A Large Biomedical Corpus Annotated with UMLS Concepts", "comments": "To appear in AKBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the formal release of MedMentions, a new manually\nannotated resource for the recognition of biomedical concepts. What\ndistinguishes MedMentions from other annotated biomedical corpora is its size\n(over 4,000 abstracts and over 350,000 linked mentions), as well as the size of\nthe concept ontology (over 3 million concepts from UMLS 2017) and its broad\ncoverage of biomedical disciplines. In addition to the full corpus, a\nsub-corpus of MedMentions is also presented, comprising annotations for a\nsubset of UMLS 2017 targeted towards document retrieval. To encourage research\nin Biomedical Named Entity Recognition and Linking, data splits for training\nand testing are included in the release, and a baseline model and its metrics\nfor entity linking are also described.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:53:20 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mohan", "Sunil", ""], ["Li", "Donghui", ""]]}, {"id": "1902.09487", "submitter": "R\\'emi Cad\\`ene", "authors": "Remi Cadene and Hedi Ben-younes and Matthieu Cord and Nicolas Thome", "title": "MUREL: Multimodal Relational Reasoning for Visual Question Answering", "comments": "CVPR2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal attentional networks are currently state-of-the-art models for\nVisual Question Answering (VQA) tasks involving real images. Although attention\nallows to focus on the visual content relevant to the question, this simple\nmechanism is arguably insufficient to model complex reasoning features required\nfor VQA or other high-level tasks.\n  In this paper, we propose MuRel, a multimodal relational network which is\nlearned end-to-end to reason over real images. Our first contribution is the\nintroduction of the MuRel cell, an atomic reasoning primitive representing\ninteractions between question and image regions by a rich vectorial\nrepresentation, and modeling region relations with pairwise combinations.\nSecondly, we incorporate the cell into a full MuRel network, which\nprogressively refines visual and question interactions, and can be leveraged to\ndefine visualization schemes finer than mere attention maps.\n  We validate the relevance of our approach with various ablation studies, and\nshow its superiority to attention-based methods on three datasets: VQA 2.0,\nVQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms\nstate-of-the-art results in this challenging context.\n  Our code is available: https://github.com/Cadene/murel.bootstrap.pytorch\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:04:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cadene", "Remi", ""], ["Ben-younes", "Hedi", ""], ["Cord", "Matthieu", ""], ["Thome", "Nicolas", ""]]}, {"id": "1902.09492", "submitter": "Tal Schuster", "authors": "Tal Schuster, Ori Ram, Regina Barzilay, Amir Globerson", "title": "Cross-Lingual Alignment of Contextual Word Embeddings, with Applications\n  to Zero-shot Dependency Parsing", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method for multilingual transfer that utilizes deep\ncontextual embeddings, pretrained in an unsupervised fashion. While contextual\nembeddings have been shown to yield richer representations of meaning compared\nto their static counterparts, aligning them poses a challenge due to their\ndynamic nature. To this end, we construct context-independent variants of the\noriginal monolingual spaces and utilize their mapping to derive an alignment\nfor the context-dependent spaces. This mapping readily supports processing of a\ntarget language, improving transfer by context-aware embeddings. Our\nexperimental results demonstrate the effectiveness of this approach for\nzero-shot and few-shot learning of dependency parsing. Specifically, our method\nconsistently outperforms the previous state-of-the-art on 6 tested languages,\nyielding an improvement of 6.8 LAS points on average.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:14:11 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 02:53:24 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Schuster", "Tal", ""], ["Ram", "Ori", ""], ["Barzilay", "Regina", ""], ["Globerson", "Amir", ""]]}, {"id": "1902.09499", "submitter": "Matthias H\\\"user", "authors": "Matthias H\\\"user, Adrian K\\\"undig, Walter Karlen, Valeria De Luca,\n  Martin Jaggi", "title": "Forecasting intracranial hypertension using multi-scale waveform metrics", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1088/1361-6579/ab6360", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Acute intracranial hypertension is an important risk factor of\nsecondary brain damage after traumatic brain injury. Hypertensive episodes are\noften diagnosed reactively, leading to late detection and lost time for\nintervention planning. A pro-active approach that predicts critical events\nseveral hours ahead of time could assist in directing attention to patients at\nrisk. Approach: We developed a prediction framework that forecasts onsets of\nacute intracranial hypertension in the next 8 hours. It jointly uses cerebral\nauto-regulation indices, spectral energies and morphological pulse metrics to\ndescribe the neurological state of the patient. One-minute base windows were\ncompressed by computing signal metrics, and then stored in a multi-scale\nhistory, from which physiological features were derived. Main results: Our\nmodel predicted events up to 8 hours in advance with alarm recall rates of 90%\nat a precision of 30.3% in the MIMIC-III waveform database, improving upon two\nbaselines from the literature. We found that features derived from\nhigh-frequency waveforms substantially improved the prediction performance over\nsimple statistical summaries of low-frequency time series, and each of the\nthree feature classes contributed to the performance gain. The inclusion of\nlong-term history up to 8 hours was especially important. Significance: Our\nresults highlight the importance of information contained in high-frequency\nwaveforms in the neurological intensive care unit. They could motivate future\nstudies on pre-hypertensive patterns and the design of new alarm algorithms for\ncritical events in the injured brain.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:21:37 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 23:25:17 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 21:39:19 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["H\u00fcser", "Matthias", ""], ["K\u00fcndig", "Adrian", ""], ["Karlen", "Walter", ""], ["De Luca", "Valeria", ""], ["Jaggi", "Martin", ""]]}, {"id": "1902.09506", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional\n  Question Answering", "comments": "Published as a conference paper at CVPR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce GQA, a new dataset for real-world visual reasoning and\ncompositional question answering, seeking to address key shortcomings of\nprevious VQA datasets. We have developed a strong and robust question engine\nthat leverages scene graph structures to create 22M diverse reasoning\nquestions, all come with functional programs that represent their semantics. We\nuse the programs to gain tight control over the answer distribution and present\na new tunable smoothing technique to mitigate question biases. Accompanying the\ndataset is a suite of new metrics that evaluate essential qualities such as\nconsistency, grounding and plausibility. An extensive analysis is performed for\nbaselines as well as state-of-the-art models, providing fine-grained results\nfor different question types and topologies. Whereas a blind LSTM obtains mere\n42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%,\noffering ample opportunity for new research to explore. We strongly hope GQA\nwill provide an enabling resource for the next generation of models with\nenhanced robustness, improved consistency, and deeper semantic understanding\nfor images and language.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:37:49 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 09:10:11 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:24:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1902.09508", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav Vaibhav, Sumeet Singh, Craig Stewart, Graham Neubig", "title": "Improving Robustness of Machine Translation with Synthetic Noise", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern Machine Translation (MT) systems perform consistently well on clean,\nin-domain text. However most human generated text, particularly in the realm of\nsocial media, is full of typos, slang, dialect, idiolect and other noise which\ncan have a disastrous impact on the accuracy of output translation. In this\npaper we leverage the Machine Translation of Noisy Text (MTNT) dataset to\nenhance the robustness of MT systems by emulating naturally occurring noise in\notherwise clean data. Synthesizing noise in this manner we are ultimately able\nto make a vanilla MT system resilient to naturally occurring noise and\npartially mitigate loss in accuracy resulting therefrom.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:39:42 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 20:53:49 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Vaibhav", "Vaibhav", ""], ["Singh", "Sumeet", ""], ["Stewart", "Craig", ""], ["Neubig", "Graham", ""]]}, {"id": "1902.09566", "submitter": "Jagdish Ramakrishnan", "authors": "Jagdish Ramakrishnan, Elham Shaabani, Chao Li and M\\'aty\\'as A. Sustik", "title": "Anomaly Detection for an E-commerce Pricing System", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online retailers execute a very large number of price updates when compared\nto brick-and-mortar stores. Even a few mis-priced items can have a significant\nbusiness impact and result in a loss of customer trust. Early detection of\nanomalies in an automated real-time fashion is an important part of such a\npricing system. In this paper, we describe unsupervised and supervised anomaly\ndetection approaches we developed and deployed for a large-scale online pricing\nsystem at Walmart. Our system detects anomalies both in batch and real-time\nstreaming settings, and the items flagged are reviewed and actioned based on\npriority and business impact. We found that having the right architecture\ndesign was critical to facilitate model performance at scale, and business\nimpact and speed were important factors influencing model selection, parameter\nchoice, and prioritization in a production environment for a large-scale\nsystem. We conducted analyses on the performance of various approaches on a\ntest set using real-world retail data and fully deployed our approach into\nproduction. We found that our approach was able to detect the most important\nanomalies with high precision.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:03:30 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 18:39:06 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 22:24:48 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 17:21:31 GMT"}, {"version": "v5", "created": "Sat, 1 Jun 2019 18:57:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ramakrishnan", "Jagdish", ""], ["Shaabani", "Elham", ""], ["Li", "Chao", ""], ["Sustik", "M\u00e1ty\u00e1s A.", ""]]}, {"id": "1902.09574", "submitter": "Trevor Gale", "authors": "Trevor Gale, Erich Elsen, Sara Hooker", "title": "The State of Sparsity in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We rigorously evaluate three state-of-the-art techniques for inducing\nsparsity in deep neural networks on two large-scale learning tasks: Transformer\ntrained on WMT 2014 English-to-German, and ResNet-50 trained on ImageNet.\nAcross thousands of experiments, we demonstrate that complex techniques\n(Molchanov et al., 2017; Louizos et al., 2017b) shown to yield high compression\nrates on smaller datasets perform inconsistently, and that simple magnitude\npruning approaches achieve comparable or better results. Additionally, we\nreplicate the experiments performed by (Frankle & Carbin, 2018) and (Liu et\nal., 2018) at scale and show that unstructured sparse architectures learned\nthrough pruning cannot be trained from scratch to the same test set performance\nas a model trained with joint sparsification and optimization. Together, these\nresults highlight the need for large-scale benchmarks in the field of model\ncompression. We open-source our code, top performing model checkpoints, and\nresults of all hyperparameter configurations to establish rigorous baselines\nfor future work on compression and sparsification.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:18:40 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gale", "Trevor", ""], ["Elsen", "Erich", ""], ["Hooker", "Sara", ""]]}, {"id": "1902.09592", "submitter": "Chongli Qin", "authors": "Chongli Qin, Krishnamurthy (Dj) Dvijotham, Brendan O'Donoghue, Rudy\n  Bunel, Robert Stanforth, Sven Gowal, Jonathan Uesato, Grzegorz Swirszcz,\n  Pushmeet Kohli", "title": "Verification of Non-Linear Specifications for Neural Networks", "comments": "ICLR conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on neural network verification has focused on specifications that\nare linear functions of the output of the network, e.g., invariance of the\nclassifier output under adversarial perturbations of the input. In this paper,\nwe extend verification algorithms to be able to certify richer properties of\nneural networks. To do this we introduce the class of convex-relaxable\nspecifications, which constitute nonlinear specifications that can be verified\nusing a convex relaxation. We show that a number of important properties of\ninterest can be modeled within this class, including conservation of energy in\na learned dynamics model of a physical system; semantic consistency of a\nclassifier's output labels under adversarial perturbations and bounding errors\nin a system that predicts the summation of handwritten digits. Our experimental\nevaluation shows that our method is able to effectively verify these\nspecifications. Moreover, our evaluation exposes the failure modes in models\nwhich cannot be verified to satisfy these specifications. Thus, emphasizing the\nimportance of training models not just to fit training data but also to be\nconsistent with specifications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:04:13 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Qin", "Chongli", "", "Dj"], ["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["O'Donoghue", "Brendan", ""], ["Bunel", "Rudy", ""], ["Stanforth", "Robert", ""], ["Gowal", "Sven", ""], ["Uesato", "Jonathan", ""], ["Swirszcz", "Grzegorz", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1902.09599", "submitter": "Steve Li", "authors": "Steven Cheng-Xian Li, Bo Jiang, Benjamin Marlin", "title": "MisGAN: Learning from Incomplete Data with Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GANs) have been shown to provide an\neffective way to model complex distributions and have obtained impressive\nresults on various challenging tasks. However, typical GANs require\nfully-observed data during training. In this paper, we present a GAN-based\nframework for learning from complex, high-dimensional incomplete data. The\nproposed framework learns a complete data generator along with a mask generator\nthat models the missing data distribution. We further demonstrate how to impute\nmissing data by equipping our framework with an adversarially trained imputer.\nWe evaluate the proposed framework using a series of experiments with several\ntypes of missing data processes under the missing completely at random\nassumption.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:24:35 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Li", "Steven Cheng-Xian", ""], ["Jiang", "Bo", ""], ["Marlin", "Benjamin", ""]]}, {"id": "1902.09601", "submitter": "Lingyi Han", "authors": "Lingyi Han, Kan Zheng, Long Zhao, Xianbin Wang, and Xuemin Shen", "title": "Short-term Road Traffic Prediction based on Deep Cluster at Large-scale\n  Networks", "comments": "12 pages, 15 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term road traffic prediction (STTP) is one of the most important\nmodules in Intelligent Transportation Systems (ITS). However, network-level\nSTTP still remains challenging due to the difficulties both in modeling the\ndiverse traffic patterns and tacking high-dimensional time series with low\nlatency. Therefore, a framework combining with a deep clustering (DeepCluster)\nmodule is developed for STTP at largescale networks in this paper. The\nDeepCluster module is proposed to supervise the representation learning in a\nvisualized way from the large unlabeled dataset. More specifically, to fully\nexploit the traffic periodicity, the raw series is first split into a number of\nsub-series for triplets generation. The convolutional neural networks (CNNs)\nwith triplet loss are utilized to extract the features of shape by transferring\nthe series into visual images. The shape-based representations are then used\nfor road segments clustering. Thereafter, motivated by the fact that the road\nsegments in a group have similar patterns, a model sharing strategy is further\nproposed to build recurrent NNs (RNNs)-based predictions through a group-based\nmodel (GM), instead of individual-based model (IM) in which one model are built\nfor one road exclusively. Our framework can not only significantly reduce the\nnumber of models and cost, but also increase the number of training data and\nthe diversity of samples. In the end, we evaluate the proposed framework over\nthe network of Liuli Bridge in Beijing. Experimental results show that the\nDeepCluster can effectively cluster the road segments and GM can achieve\ncomparable performance against the IM with less number of models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:37:59 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Han", "Lingyi", ""], ["Zheng", "Kan", ""], ["Zhao", "Long", ""], ["Wang", "Xianbin", ""], ["Shen", "Xuemin", ""]]}, {"id": "1902.09602", "submitter": "Brandon Foggo", "authors": "Brandon Foggo and Nanpeng Yu", "title": "Analyzing Data Selection Techniques with Tools from the Theory of\n  Information Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present and illustrate some new tools for rigorously\nanalyzing training data selection methods. These tools focus on the information\ntheoretic losses that occur when sampling data. We use this framework to prove\nthat two methods, Facility Location Selection and Transductive Experimental\nDesign, reduce these losses. These are meant to act as generalizable\ntheoretical examples of applying the field of Information Theoretic Deep\nLearning Theory to the fields of data selection and active learning. Both\nanalyses yield insight into their respective methods and increase their\ninterpretability. In the case of Transductive Experimental Design, the provided\nanalysis greatly increases the method's scope as well.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:43:28 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 06:48:43 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 19:44:16 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Foggo", "Brandon", ""], ["Yu", "Nanpeng", ""]]}, {"id": "1902.09626", "submitter": "Fan Fei", "authors": "Fan Fei, Zhan Tu, Jian Zhang, Xinyan Deng", "title": "Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots", "comments": "6 pages, accepted at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological studies show that hummingbirds can perform extreme aerobatic\nmaneuvers during fast escape. Given a sudden looming visual stimulus at hover,\na hummingbird initiates a fast backward translation coupled with a 180-degree\nyaw turn, which is followed by instant posture stabilization in just under 10\nwingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is\ncarried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal\nperformance during such extreme maneuvers, we developed a flight control\nstrategy and experimentally demonstrated that such maneuverability can be\nachieved by an at-scale 12-gram hummingbird robot equipped with just two\nactuators. The proposed hybrid control policy combines model-based nonlinear\ncontrol with model-free reinforcement learning. We use model-based nonlinear\ncontrol for nominal flight control, as the dynamic model is relatively accurate\nfor these conditions. However, during extreme maneuver, the modeling error\nbecomes unmanageable. A model-free reinforcement learning policy trained in\nsimulation was optimized to 'destabilize' the system and maximize the\nperformance during maneuvering. The hybrid policy manifests a maneuver that is\nclose to that observed in hummingbirds. Direct simulation-to-real transfer is\nachieved, demonstrating the hummingbird-like fast evasive maneuvers on the\nat-scale hummingbird robot.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:27:57 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Fei", "Fan", ""], ["Tu", "Zhan", ""], ["Zhang", "Jian", ""], ["Deng", "Xinyan", ""]]}, {"id": "1902.09628", "submitter": "Fan Fei", "authors": "Fan Fei, Zhan Tu, Yilun Yang, Jian Zhang, Xinyan Deng", "title": "Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing\n  Robots and Animals", "comments": "The code is available at\n  (https://github.com/purdue-biorobotics/flappy). 6 pages, 10 figure, accepted\n  at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insects and hummingbirds exhibit extraordinary flight capabilities and can\nsimultaneously master seemingly conflicting goals: stable hovering and\naggressive maneuvering, unmatched by small scale man-made vehicles. Flapping\nWing Micro Air Vehicles (FWMAVs) hold great promise for closing this\nperformance gap. However, design and control of such systems remain challenging\ndue to various constraints. Here, we present an open source high fidelity\ndynamic simulation for FWMAVs to serve as a testbed for the design,\noptimization and flight control of FWMAVs. For simulation validation, we\nrecreated the hummingbird-scale robot developed in our lab in the simulation.\nSystem identification was performed to obtain the model parameters. The force\ngeneration, open-loop and closed-loop dynamic response between simulated and\nexperimental flights were compared and validated. The unsteady aerodynamics and\nthe highly nonlinear flight dynamics present challenging control problems for\nconventional and learning control algorithms such as Reinforcement Learning.\nThe interface of the simulation is fully compatible with OpenAI Gym\nenvironment. As a benchmark study, we present a linear controller for hovering\nstabilization and a Deep Reinforcement Learning control policy for\ngoal-directed maneuvering. Finally, we demonstrate direct simulation-to-real\ntransfer of both control policies onto the physical robot, further\ndemonstrating the fidelity of the simulation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Fei", "Fan", ""], ["Tu", "Zhan", ""], ["Yang", "Yilun", ""], ["Zhang", "Jian", ""], ["Deng", "Xinyan", ""]]}, {"id": "1902.09630", "submitter": "Nathan Tsoi", "authors": "Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian\n  Reid, Silvio Savarese", "title": "Generalized Intersection over Union: A Metric and A Loss for Bounding\n  Box Regression", "comments": "accepted in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intersection over Union (IoU) is the most popular evaluation metric used in\nthe object detection benchmarks. However, there is a gap between optimizing the\ncommonly used distance losses for regressing the parameters of a bounding box\nand maximizing this metric value. The optimal objective for a metric is the\nmetric itself. In the case of axis-aligned 2D bounding boxes, it can be shown\nthat $IoU$ can be directly used as a regression loss. However, $IoU$ has a\nplateau making it infeasible to optimize in the case of non-overlapping\nbounding boxes. In this paper, we address the weaknesses of $IoU$ by\nintroducing a generalized version as both a new loss and a new metric. By\nincorporating this generalized $IoU$ ($GIoU$) as a loss into the state-of-the\nart object detection frameworks, we show a consistent improvement on their\nperformance using both the standard, $IoU$ based, and new, $GIoU$ based,\nperformance measures on popular object detection benchmarks such as PASCAL VOC\nand MS COCO.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:47:33 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 03:18:03 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Rezatofighi", "Hamid", ""], ["Tsoi", "Nathan", ""], ["Gwak", "JunYoung", ""], ["Sadeghian", "Amir", ""], ["Reid", "Ian", ""], ["Savarese", "Silvio", ""]]}, {"id": "1902.09635", "submitter": "Chris Ying", "authors": "Chris Ying, Aaron Klein, Esteban Real, Eric Christiansen, Kevin\n  Murphy, Frank Hutter", "title": "NAS-Bench-101: Towards Reproducible Neural Architecture Search", "comments": "Published in the Proceedings of the 36th International Conference on\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in neural architecture search (NAS) demand tremendous\ncomputational resources, which makes it difficult to reproduce experiments and\nimposes a barrier-to-entry to researchers without access to large-scale\ncomputation. We aim to ameliorate these problems by introducing NAS-Bench-101,\nthe first public architecture dataset for NAS research. To build NAS-Bench-101,\nwe carefully constructed a compact, yet expressive, search space, exploiting\ngraph isomorphisms to identify 423k unique convolutional architectures. We\ntrained and evaluated all of these architectures multiple times on CIFAR-10 and\ncompiled the results into a large dataset of over 5 million trained models.\nThis allows researchers to evaluate the quality of a diverse range of models in\nmilliseconds by querying the pre-computed dataset. We demonstrate its utility\nby analyzing the dataset as a whole and by benchmarking a range of architecture\noptimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:56:54 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 05:33:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ying", "Chris", ""], ["Klein", "Aaron", ""], ["Real", "Esteban", ""], ["Christiansen", "Eric", ""], ["Murphy", "Kevin", ""], ["Hutter", "Frank", ""]]}, {"id": "1902.09641", "submitter": "Chen Sun", "authors": "Chen Sun and Per Karlsson and Jiajun Wu and Joshua B Tenenbaum and\n  Kevin Murphy", "title": "Stochastic Prediction of Multi-Agent Interactions from Partial\n  Observations", "comments": "ICLR 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method that learns to integrate temporal information, from a\nlearned dynamics model, with ambiguous visual information, from a learned\nvision model, in the context of interacting agents. Our method is based on a\ngraph-structured variational recurrent neural network (Graph-VRNN), which is\ntrained end-to-end to infer the current state of the (partially observed)\nworld, as well as to forecast future states. We show that our method\noutperforms various baselines on two sports datasets, one based on real\nbasketball trajectories, and one generated by a soccer game engine.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 22:17:34 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Sun", "Chen", ""], ["Karlsson", "Per", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B", ""], ["Murphy", "Kevin", ""]]}, {"id": "1902.09682", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Tara Javidi", "title": "Multiscale Gaussian Process Level Set Estimation", "comments": "15 pages", "journal-ref": "AISTATS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of estimating the level set of a black-box\nfunction from noisy and expensive evaluation queries is considered. A new\nalgorithm for this problem in the Bayesian framework with a Gaussian Process\n(GP) prior is proposed. The proposed algorithm employs a hierarchical sequence\nof partitions to explore different regions of the search space at varying\nlevels of detail depending upon their proximity to the level set boundary. It\nis shown that this approach results in the algorithm having a low complexity\nimplementation whose computational cost is significantly smaller than the\nexisting algorithms for higher dimensional search space $\\X$. Furthermore, high\nprobability bounds on a measure of discrepancy between the estimated level set\nand the true level set for the the proposed algorithm are obtained, which are\nshown to be strictly better than the existing guarantees for a large class of\nGPs. In the process, a tighter characterization of the information gain of the\nproposed algorithm is obtained which takes into account the structured nature\nof the evaluation points. This approach improves upon the existing technique of\nbounding the information gain with maximum information gain.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 00:59:14 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Javidi", "Tara", ""]]}, {"id": "1902.09689", "submitter": "Bo Chang", "authors": "Bo Chang, Minmin Chen, Eldad Haber, Ed H. Chi", "title": "AntisymmetricRNN: A Dynamical System View on Recurrent Neural Networks", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recurrent neural networks have gained widespread use in modeling sequential\ndata. Learning long-term dependencies using these models remains difficult\nthough, due to exploding or vanishing gradients. In this paper, we draw\nconnections between recurrent networks and ordinary differential equations. A\nspecial form of recurrent networks called the AntisymmetricRNN is proposed\nunder this theoretical framework, which is able to capture long-term\ndependencies thanks to the stability property of its underlying differential\nequation. Existing approaches to improving RNN trainability often incur\nsignificant computation overhead. In comparison, AntisymmetricRNN achieves the\nsame goal by design. We showcase the advantage of this new architecture through\nextensive simulations and experiments. AntisymmetricRNN exhibits much more\npredictable dynamics. It outperforms regular LSTM models on tasks requiring\nlong-term memory and matches the performance on tasks where short-term\ndependencies dominate despite being much simpler.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:18:46 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Chang", "Bo", ""], ["Chen", "Minmin", ""], ["Haber", "Eldad", ""], ["Chi", "Ed H.", ""]]}, {"id": "1902.09694", "submitter": "Shahin Boluki", "authors": "Shahin Boluki, Siamak Zamani Dadaneh, Xiaoning Qian, Edward R.\n  Dougherty", "title": "Optimal Clustering with Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing values frequently arise in modern biomedical studies due to various\nreasons, including missing tests or complex profiling technologies for\ndifferent omics measurements. Missing values can complicate the application of\nclustering algorithms, whose goals are to group points based on some similarity\ncriterion. A common practice for dealing with missing values in the context of\nclustering is to first impute the missing values, and then apply the clustering\nalgorithm on the completed data.\n  We consider missing values in the context of optimal clustering, which finds\nan optimal clustering operator with reference to an underlying random labeled\npoint process (RLPP). We show how the missing-value problem fits neatly into\nthe overall framework of optimal clustering by incorporating the missing value\nmechanism into the random labeled point process and then marginalizing out the\nmissing-value process. In particular, we demonstrate the proposed framework for\nthe Gaussian model with arbitrary covariance structures. Comprehensive\nexperimental studies on both synthetic and real-world RNA-seq data show the\nsuperior performance of the proposed optimal clustering with missing values\nwhen compared to various clustering approaches. Optimal clustering with missing\nvalues obviates the need for imputation-based pre-processing of the data, while\nat the same time possessing smaller clustering errors.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:40:13 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Boluki", "Shahin", ""], ["Dadaneh", "Siamak Zamani", ""], ["Qian", "Xiaoning", ""], ["Dougherty", "Edward R.", ""]]}, {"id": "1902.09698", "submitter": "Yuqi Li", "authors": "Ankit Raj, Yuqi Li, Yoram Bresler", "title": "GAN-based Projector for Faster Recovery with Convergence Guarantees in\n  Linear Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Generative Adversarial Network (GAN) with generator $G$ trained to model\nthe prior of images has been shown to perform better than sparsity-based\nregularizers in ill-posed inverse problems. Here, we propose a new method of\ndeploying a GAN-based prior to solve linear inverse problems using projected\ngradient descent (PGD). Our method learns a network-based projector for use in\nthe PGD algorithm, eliminating expensive computation of the Jacobian of $G$.\nExperiments show that our approach provides a speed-up of $60\\text{-}80\\times$\nover earlier GAN-based recovery methods along with better accuracy. Our main\ntheoretical result is that if the measurement matrix is moderately conditioned\non the manifold range($G$) and the projector is $\\delta$-approximate, then the\nalgorithm is guaranteed to reach $O(\\delta)$ reconstruction error in\n$O(log(1/\\delta))$ steps in the low noise regime. Additionally, we propose a\nfast method to design such measurement matrices for a given $G$. Extensive\nexperiments demonstrate the efficacy of this method by requiring\n$5\\text{-}10\\times$ fewer measurements than random Gaussian measurement\nmatrices for comparable recovery performance. Because the learning of the GAN\nand projector is decoupled from the measurement operator, our GAN-based\nprojector and recovery algorithm are applicable without retraining to all\nlinear inverse problems, as confirmed by experiments on compressed sensing,\nsuper-resolution, and inpainting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:50:21 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 22:51:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Raj", "Ankit", ""], ["Li", "Yuqi", ""], ["Bresler", "Yoram", ""]]}, {"id": "1902.09700", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Learning to Sample Hard Instances for Graph Algorithms", "comments": "16 pages, 4 figures, accepted by ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard instances, which require a long time for a specific algorithm to solve,\nhelp (1) analyze the algorithm for accelerating it and (2) build a good\nbenchmark for evaluating the performance of algorithms. There exist several\nefforts for automatic generation of hard instances. For example, evolutionary\nalgorithms have been utilized to generate hard instances. However, they\ngenerate only finite number of hard instances. The merit of such methods is\nlimited because it is difficult to extract meaningful patterns from small\nnumber of instances. We seek for a probabilistic generator of hard instances.\nOnce the generative distribution of hard instances is obtained, we can sample a\nvariety of hard instances to build a benchmark, and we can extract meaningful\npatterns of hard instances from sampled instances. The existing methods for\nmodeling the hard instance distribution rely on parameters or rules that are\nfound by domain experts; however, they are specific to the problem. Hence, it\nis challenging to model the distribution for general cases. In this paper, we\nfocus on graph problems. We propose HiSampler, the hard instance sampler, to\nmodel the hard instance distribution of graph algorithms. HiSampler makes it\npossible to obtain the distribution of hard instances without hand-engineered\nfeatures. To the best of our knowledge, this is the first method to learn the\ndistribution of hard instances using machine learning. Through experiments, we\ndemonstrate that our proposed method can generate instances that are a few to\nseveral orders of magnitude harder than the random-based approach in many\nsettings. In particular, our method outperforms rule-based algorithms in the\n3-coloring problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:01:26 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 12:40:45 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1902.09701", "submitter": "Pedro Savarese", "authors": "Pedro Savarese, Michael Maire", "title": "Learning Implicitly Recurrent CNNs Through Parameter Sharing", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parameter sharing scheme, in which different layers of a\nconvolutional neural network (CNN) are defined by a learned linear combination\nof parameter tensors from a global bank of templates. Restricting the number of\ntemplates yields a flexible hybridization of traditional CNNs and recurrent\nnetworks. Compared to traditional CNNs, we demonstrate substantial parameter\nsavings on standard image classification tasks, while maintaining accuracy.\n  Our simple parameter sharing scheme, though defined via soft weights, in\npractice often yields trained networks with near strict recurrent structure;\nwith negligible side effects, they convert into networks with actual loops.\nTraining these networks thus implicitly involves discovery of suitable\nrecurrent architectures. Though considering only the design aspect of recurrent\nlinks, our trained networks achieve accuracy competitive with those built using\nstate-of-the-art neural architecture search (NAS) procedures.\n  Our hybridization of recurrent and convolutional networks may also represent\na beneficial architectural bias. Specifically, on synthetic tasks which are\nalgorithmic in nature, our hybrid networks both train faster and extrapolate\nbetter to test examples outside the span of the training set.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:02:09 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 19:36:06 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Savarese", "Pedro", ""], ["Maire", "Michael", ""]]}, {"id": "1902.09705", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Lorenzo Jamone, Alexandre Bernardino, Giampiero\n  Salvi", "title": "Beyond the Self: Using Grounded Affordances to Interpret and Describe\n  Others' Actions", "comments": "code available at https://github.com/gsaponaro/tcds-gestures, IEEE\n  Transactions on Cognitive and Developmental Systems", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, vol. 12,\n  no. 2, pp. 209-221, June 2020", "doi": "10.1109/TCDS.2018.2882140", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a developmental approach that allows a robot to interpret and\ndescribe the actions of human agents by reusing previous experience. The robot\nfirst learns the association between words and object affordances by\nmanipulating the objects in its environment. It then uses this information to\nlearn a mapping between its own actions and those performed by a human in a\nshared environment. It finally fuses the information from these two models to\ninterpret and describe human actions in light of its own experience. In our\nexperiments, we show that the model can be used flexibly to do inference on\ndifferent aspects of the scene. We can predict the effects of an action on the\nbasis of object properties. We can revise the belief that a certain action\noccurred, given the observed effects of the human action. In an early action\nrecognition fashion, we can anticipate the effects when the action has only\nbeen partially observed. By estimating the probability of words given the\nevidence and feeding them into a pre-defined grammar, we can generate relevant\ndescriptions of the scene. We believe that this is a step towards providing\nrobots with the fundamental skills to engage in social collaboration with\nhumans.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:14:10 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1902.09713", "submitter": "Khalil Mrini", "authors": "Khalil Mrini, Claudiu Musat, Michael Baeriswyl, Martin Jaggi", "title": "Interpretable Structure-aware Document Encoders with Hierarchical\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to create document representations that reflect their\ninternal structure. We modify Tree-LSTMs to hierarchically merge basic elements\nsuch as words and sentences into blocks of increasing complexity. Our Structure\nTree-LSTM implements a hierarchical attention mechanism over individual\ncomponents and combinations thereof. We thus emphasize the usefulness of\nTree-LSTMs for texts larger than a sentence. We show that structure-aware\nencoders can be used to improve the performance of document classification. We\ndemonstrate that our method is resilient to changes to the basic building\nblocks, as it performs well with both sentence and word embeddings. The\nStructure Tree-LSTM outperforms all the baselines on two datasets by leveraging\nstructural clues. We show our model's interpretability by visualizing how our\nmodel distributes attention inside a document. On a third dataset from the\nmedical domain, our model achieves competitive performance with the state of\nthe art. This result shows the Structure Tree-LSTM can leverage dependency\nrelations other than text structure, such as a set of reports on the same\npatient.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:54:03 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 05:45:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Mrini", "Khalil", ""], ["Musat", "Claudiu", ""], ["Baeriswyl", "Michael", ""], ["Jaggi", "Martin", ""]]}, {"id": "1902.09722", "submitter": "Tatsuya Shiraishi", "authors": "Tatsuya Shiraishi, Tam Le, Hisashi Kashima, Makoto Yamada", "title": "Topological Bayesian Optimization with Persistence Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an optimal parameter of a black-box function is important for\nsearching stable material structures and finding optimal neural network\nstructures, and Bayesian optimization algorithms are widely used for the\npurpose. However, most of existing Bayesian optimization algorithms can only\nhandle vector data and cannot handle complex structured data. In this paper, we\npropose the topological Bayesian optimization, which can efficiently find an\noptimal solution from structured data using \\emph{topological information}.\nMore specifically, in order to apply Bayesian optimization to structured data,\nwe extract useful topological information from a structure and measure the\nproper similarity between structures. To this end, we utilize persistent\nhomology, which is a topological data analysis method that was recently applied\nin machine learning. Moreover, we propose the Bayesian optimization algorithm\nthat can handle multiple types of topological information by using a linear\ncombination of kernels for persistence diagrams. Through experiments, we show\nthat topological information extracted by persistent homology contributes to a\nmore efficient search for optimal structures compared to the random search\nbaseline and the graph Bayesian optimization algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:13:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Shiraishi", "Tatsuya", ""], ["Le", "Tam", ""], ["Kashima", "Hisashi", ""], ["Yamada", "Makoto", ""]]}, {"id": "1902.09723", "submitter": "Fereshteh Jafariakinabad", "authors": "Fereshteh Jafariakinabad, Sansiri Tarnpradab, Kien A. Hua", "title": "Syntactic Recurrent Neural Network for Authorship Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing style is a combination of consistent decisions at different levels of\nlanguage production including lexical, syntactic, and structural associated to\na specific author (or author groups). While lexical-based models have been\nwidely explored in style-based text classification, relying on content makes\nthe model less scalable when dealing with heterogeneous data comprised of\nvarious topics. On the other hand, syntactic models which are\ncontent-independent, are more robust against topic variance. In this paper, we\nintroduce a syntactic recurrent neural network to encode the syntactic patterns\nof a document in a hierarchical structure. The model first learns the syntactic\nrepresentation of sentences from the sequence of part-of-speech tags. For this\npurpose, we exploit both convolutional filters and long short-term memories to\ninvestigate the short-term and long-term dependencies of part-of-speech tags in\nthe sentences. Subsequently, the syntactic representations of sentences are\naggregated into document representation using recurrent neural networks. Our\nexperimental results on PAN 2012 dataset for authorship attribution task shows\nthat syntactic recurrent neural network outperforms the lexical model with the\nidentical architecture by approximately 14% in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:32:42 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 02:54:33 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Jafariakinabad", "Fereshteh", ""], ["Tarnpradab", "Sansiri", ""], ["Hua", "Kien A.", ""]]}, {"id": "1902.09724", "submitter": "Henry Chai", "authors": "Henry Chai, Jean-Francois Ton, Roman Garnett and Michael A. Osborne", "title": "Automated Model Selection with Bayesian Quadrature", "comments": "10 pages, 5 figures. Currently in submission to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique for tailoring Bayesian quadrature (BQ) to model\nselection. The state-of-the-art for comparing the evidence of multiple models\nrelies on Monte Carlo methods, which converge slowly and are unreliable for\ncomputationally expensive models. Previous research has shown that BQ offers\nsample efficiency superior to Monte Carlo in computing the evidence of an\nindividual model. However, applying BQ directly to model comparison may waste\ncomputation producing an overly-accurate estimate for the evidence of a clearly\npoor model. We propose an automated and efficient algorithm for computing the\nmost-relevant quantity for model selection: the posterior probability of a\nmodel. Our technique maximizes the mutual information between this quantity and\nobservations of the models' likelihoods, yielding efficient acquisition of\nsamples across disparate model spaces when likelihood observations are limited.\nOur method produces more-accurate model posterior estimates using fewer model\nlikelihood evaluations than standard Bayesian quadrature and Monte Carlo\nestimators, as we demonstrate on synthetic and real-world examples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:38:39 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 04:09:36 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 16:17:08 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Chai", "Henry", ""], ["Ton", "Jean-Francois", ""], ["Garnett", "Roman", ""], ["Osborne", "Michael A.", ""]]}, {"id": "1902.09737", "submitter": "Guang-He Lee", "authors": "Guang-He Lee, Wengong Jin, David Alvarez-Melis, Tommi S. Jaakkola", "title": "Functional Transparency for Structured Data: a Game-Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new approach to training neural models to exhibit transparency\nin a well-defined, functional manner. Our approach naturally operates over\nstructured data and tailors the predictor, functionally, towards a chosen\nfamily of (local) witnesses. The estimation problem is setup as a co-operative\ngame between an unrestricted predictor such as a neural network, and a set of\nwitnesses chosen from the desired transparent family. The goal of the witnesses\nis to highlight, locally, how well the predictor conforms to the chosen family\nof functions, while the predictor is trained to minimize the highlighted\ndiscrepancy. We emphasize that the predictor remains globally powerful as it is\nonly encouraged to agree locally with locally adapted witnesses. We analyze the\neffect of the proposed approach, provide example formulations in the context of\ndeep graph and sequence models, and empirically illustrate the idea in chemical\nproperty prediction, temporal modeling, and molecule representation learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 05:17:18 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Lee", "Guang-He", ""], ["Jin", "Wengong", ""], ["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1902.09742", "submitter": "Jeremy Morton", "authors": "Jeremy Morton, Freddie D Witherden, Mykel J Kochenderfer", "title": "Deep Variational Koopman Models: Inferring Koopman Observations for\n  Uncertainty-Aware Dynamics Modeling and Control", "comments": "Accepted to the 2019 International Joint Conference on Artificial\n  Intelligence (IJCAI). 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koopman theory asserts that a nonlinear dynamical system can be mapped to a\nlinear system, where the Koopman operator advances observations of the state\nforward in time. However, the observable functions that map states to\nobservations are generally unknown. We introduce the Deep Variational Koopman\n(DVK) model, a method for inferring distributions over observations that can be\npropagated linearly in time. By sampling from the inferred distributions, we\nobtain a distribution over dynamical models, which in turn provides a\ndistribution over possible outcomes as a modeled system advances in time.\nExperiments show that the DVK model is effective at long-term prediction for a\nvariety of dynamical systems. Furthermore, we describe how to incorporate the\nlearned models into a control framework, and demonstrate that accounting for\nthe uncertainty present in the distribution over dynamical models enables more\neffective control.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 05:40:16 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 20:50:08 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 17:42:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Morton", "Jeremy", ""], ["Witherden", "Freddie D", ""], ["Kochenderfer", "Mykel J", ""]]}, {"id": "1902.09745", "submitter": "Inon Peled", "authors": "Inon Peled, Kelvin Lee, Yu Jiang, Justin Dauwels, Francisco C. Pereira", "title": "Online Predictive Optimization Framework for Stochastic\n  Demand-Responsive Transit Services", "comments": "34 pages, 12 figures, 5 tables", "journal-ref": "2019 IEEE Intelligent Transportation Systems Conference (ITSC),\n  Auckland, New Zealand, 2019, pp. 3043-3048", "doi": "10.1109/ITSC.2019.8916878", "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops an online predictive optimization framework for\ndynamically operating a transit service in an area of crowd movements. The\nproposed framework integrates demand prediction and supply optimization to\nperiodically redesign the service routes based on recently observed demand. To\npredict demand for the service, we use Quantile Regression to estimate the\nmarginal distribution of movement counts between each pair of serviced\nlocations. The framework then combines these marginals into a joint demand\ndistribution by constructing a Gaussian copula, which captures the structure of\ncorrelation between the marginals. For supply optimization, we devise a linear\nprogramming model, which simultaneously determines the route structure and the\nservice frequency according to the predicted demand. Importantly, our framework\nboth preserves the uncertainty structure of future demand and leverages this\nfor robust route optimization, while keeping both components decoupled. We\nevaluate our framework using a real-world case study of autonomous mobility in\na university campus in Denmark. The results show that our framework often\nobtains the ground truth optimal solution, and can outperform conventional\nmethods for route optimization, which do not leverage full predictive\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 05:56:05 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 10:27:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Peled", "Inon", ""], ["Lee", "Kelvin", ""], ["Jiang", "Yu", ""], ["Dauwels", "Justin", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "1902.09754", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Tongzheng Ren, Jun Zhu, Bo Zhang", "title": "Function Space Particle Optimization for Bayesian Neural Networks", "comments": "Extended version of the ICLR'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Bayesian neural networks (BNNs) have drawn increasing attention, their\nposterior inference remains challenging, due to the high-dimensional and\nover-parameterized nature. To address this issue, several highly flexible and\nscalable variational inference procedures based on the idea of particle\noptimization have been proposed. These methods directly optimize a set of\nparticles to approximate the target posterior. However, their application to\nBNNs often yields sub-optimal performance, as such methods have a particular\nfailure mode on over-parameterized models. In this paper, we propose to solve\nthis issue by performing particle optimization directly in the space of\nregression functions. We demonstrate through extensive experiments that our\nmethod successfully overcomes this issue, and outperforms strong baselines in a\nvariety of tasks including prediction, defense against adversarial examples,\nand reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 06:39:42 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 20:02:26 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wang", "Ziyu", ""], ["Ren", "Tongzheng", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1902.09757", "submitter": "Fuxing Hong", "authors": "Fuxing Hong, Dongbo Huang, Ge Chen", "title": "Interaction-aware Factorization Machines for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization Machine (FM) is a widely used supervised learning approach by\neffectively modeling of feature interactions. Despite the successful\napplication of FM and its many deep learning variants, treating every feature\ninteraction fairly may degrade the performance. For example, the interactions\nof a useless feature may introduce noises; the importance of a feature may also\ndiffer when interacting with different features. In this work, we propose a\nnovel model named \\emph{Interaction-aware Factorization Machine} (IFM) by\nintroducing Interaction-Aware Mechanism (IAM), which comprises the\n\\emph{feature aspect} and the \\emph{field aspect}, to learn flexible\ninteractions on two levels. The feature aspect learns feature interaction\nimportance via an attention network while the field aspect learns the feature\ninteraction effect as a parametric similarity of the feature interaction vector\nand the corresponding field interaction prototype. IFM introduces more\nstructured control and learns feature interaction importance in a stratified\nmanner, which allows for more leverage in tweaking the interactions on both\nfeature-wise and field-wise levels. Besides, we give a more generalized\narchitecture and propose Interaction-aware Neural Network (INN) and DeepIFM to\ncapture higher-order interactions. To further improve both the performance and\nefficiency of IFM, a sampling scheme is developed to select interactions based\non the field aspect importance. The experimental results from two well-known\ndatasets show the superiority of the proposed models over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 06:47:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Hong", "Fuxing", ""], ["Huang", "Dongbo", ""], ["Chen", "Ge", ""]]}, {"id": "1902.09765", "submitter": "Anshul Thakur", "authors": "Anshul Thakur and Padmanabhan Rajan", "title": "Directional Embedding Based Semi-supervised Framework For Bird\n  Vocalization Segmentation", "comments": "Accepted for publication in Applied Acoustics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a data-efficient, semi-supervised, two-pass framework for\nsegmenting bird vocalizations. The framework utilizes a binary classification\nmodel to categorize frames of an input audio recording into the background or\nbird vocalization. The first pass of the framework automatically generates\ntraining labels from the input recording itself, while model training and\nclassification is done during the second pass. The proposed framework utilizes\na reference directional model for obtaining a feature representation called\ndirectional embeddings (DE). This reference directional model acts as an\nacoustic model for bird vocalizations and is obtained using the mixtures of\nVon-Mises Fisher distribution (moVMF). The proposed DE space only contains\ninformation about bird vocalizations, while no information about the background\ndisturbances is reflected. The framework employs supervised information only\nfor obtaining the reference directional model and avoids the background\nmodeling. Hence, it can be regarded as semi-supervised in nature. The proposed\nframework is tested on approximately 79000 vocalizations of seven different\nbird species. The performance of the framework is also analyzed in the presence\nof noise at different SNRs. Experimental results convey that the proposed\nframework performs better than the existing bird vocalization segmentation\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 07:08:31 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Thakur", "Anshul", ""], ["Rajan", "Padmanabhan", ""]]}, {"id": "1902.09803", "submitter": "Joseph De Vilmarest", "authors": "Joseph De Vilmarest (LPSM UMR 8001), Olivier Wintenberger (LPSM UMR\n  8001)", "title": "Logarithmic Regret for parameter-free Online Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online optimization procedures in the context of logistic\nregression, focusing on the Extended Kalman Filter (EKF). We introduce a\nsecond-order algorithm close to the EKF, named Semi-Online Step (SOS), for\nwhich we prove a O(log(n)) regret in the adversarial setting, paving the way to\nsimilar results for the EKF. This regret bound on SOS is the first for such\nparameter-free algorithm in the adversarial logistic regression. We prove for\nthe EKF in constant dynamics a O(log(n)) regret in expectation and in the\nwell-specified logistic regression model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 08:51:45 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["De Vilmarest", "Joseph", "", "LPSM UMR 8001"], ["Wintenberger", "Olivier", "", "LPSM UMR\n  8001"]]}, {"id": "1902.09817", "submitter": "Ziyao Li", "authors": "Ziyao Li, Liang Zhang, Guojie Song", "title": "GCN-LASE: Towards Adequately Incorporating Link Attributes in Graph\n  Convolutional Networks", "comments": "IJCAI2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have proved to be a most powerful\narchitecture in aggregating local neighborhood information for individual graph\nnodes. Low-rank proximities and node features are successfully leveraged in\nexisting GCNs, however, attributes that graph links may carry are commonly\nignored, as almost all of these models simplify graph links into binary or\nscalar values describing node connectedness. In our paper instead, links are\nreverted to hypostatic relationships between entities with descriptional\nattributes. We propose GCN-LASE (GCN with Link Attributes and Sampling\nEstimation), a novel GCN model taking both node and link attributes as inputs.\nTo adequately captures the interactions between link and node attributes, their\ntensor product is used as neighbor features, based on which we define several\ngraph kernels and further develop according architectures for LASE. Besides, to\naccelerate the training process, the sum of features in entire neighborhoods\nare estimated through Monte Carlo method, with novel sampling strategies\ndesigned for LASE to minimize the estimation variance. Our experiments show\nthat LASE outperforms strong baselines over various graph datasets, and further\nexperiments corroborate the informativeness of link attributes and our model's\nability of adequately leveraging them.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 09:21:27 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 15:27:56 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Li", "Ziyao", ""], ["Zhang", "Liang", ""], ["Song", "Guojie", ""]]}, {"id": "1902.09820", "submitter": "Michele Tonutti", "authors": "Michele Tonutti, Emanuele Ruffaldi, Alessandro Cattaneo, Carlo Alberto\n  Avizzano", "title": "Robust and Subject-Independent Driving Manoeuvre Anticipation through\n  Domain-Adversarial Recurrent Neural Networks", "comments": "40 pages, 4 figures. Published online in Robotics and Autonomous\n  Systems", "journal-ref": "Robot.Auton.Syst. 115 (2019) 162-173", "doi": "10.1016/j.robot.2019.02.007", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through deep learning and computer vision techniques, driving manoeuvres can\nbe predicted accurately a few seconds in advance. Even though adapting a\nlearned model to new drivers and different vehicles is key for robust\ndriver-assistance systems, this problem has received little attention so far.\nThis work proposes to tackle this challenge through domain adaptation, a\ntechnique closely related to transfer learning. A proof of concept for the\napplication of a Domain-Adversarial Recurrent Neural Network (DA-RNN) to\nmulti-modal time series driving data is presented, in which domain-invariant\nfeatures are learned by maximizing the loss of an auxiliary domain classifier.\nOur implementation is evaluated using a leave-one-driver-out approach on\nindividual drivers from the Brain4Cars dataset, as well as using a new dataset\nacquired through driving simulations, yielding an average increase in\nperformance of 30% and 114% respectively compared to no adaptation. We also\nshow the importance of fine-tuning sections of the network to optimise the\nextraction of domain-independent features. The results demonstrate the\napplicability of the approach to driver-assistance systems as well as training\nand simulation environments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 09:32:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tonutti", "Michele", ""], ["Ruffaldi", "Emanuele", ""], ["Cattaneo", "Alessandro", ""], ["Avizzano", "Carlo Alberto", ""]]}, {"id": "1902.09834", "submitter": "Homayun Afrabandpey", "authors": "Homayun Afrabandpey, Tomi Peltola, Samuel Kaski", "title": "Human-in-the-loop Active Covariance Learning for Improving Prediction in\n  Small Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning predictive models from small high-dimensional data sets is a key\nproblem in high-dimensional statistics. Expert knowledge elicitation can help,\nand a strong line of work focuses on directly eliciting informative prior\ndistributions for parameters. This either requires considerable statistical\nexpertise or is laborious, as the emphasis has been on accuracy and not on\nefficiency of the process. Another line of work queries about importance of\nfeatures one at a time, assuming them to be independent and hence missing\ncovariance information. In contrast, we propose eliciting expert knowledge\nabout pairwise feature similarities, to borrow statistical strength in the\npredictions, and using sequential decision making techniques to minimize the\neffort of the expert. Empirical results demonstrate improvement in predictive\nperformance on both simulated and real data, in high-dimensional linear\nregression tasks, where we learn the covariance structure with a Gaussian\nprocess, based on sequential elicitation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:03:18 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 14:57:35 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Afrabandpey", "Homayun", ""], ["Peltola", "Tomi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1902.09835", "submitter": "C\\'eline Hocquette", "authors": "C\\'eline Hocquette and Stephen H. Muggleton", "title": "Can Meta-Interpretive Learning outperform Deep Reinforcement Learning of\n  Evaluable Game strategies?", "comments": "7 pages 5 figures 3 tables 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  World-class human players have been outperformed in a number of complex two\nperson games (Go, Chess, Checkers) by Deep Reinforcement Learning systems.\nHowever, owing to tractability considerations minimax regret of a learning\nsystem cannot be evaluated in such games. In this paper we consider simple\ngames (Noughts-and-Crosses and Hexapawn) in which minimax regret can be\nefficiently evaluated. We use these games to compare Cumulative Minimax Regret\nfor variants of both standard and deep reinforcement learning against two\nvariants of a new Meta-Interpretive Learning system called MIGO. In our\nexperiments all tested variants of both normal and deep reinforcement learning\nhave worse performance (higher cumulative minimax regret) than both variants of\nMIGO on Noughts-and-Crosses and Hexapawn. Additionally, MIGO's learned rules\nare relatively easy to comprehend, and are demonstrated to achieve significant\ntransfer learning in both directions between Noughts-and-Crosses and Hexapawn.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:04:19 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Hocquette", "C\u00e9line", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "1902.09843", "submitter": "Liangchen Luo", "authors": "Liangchen Luo, Yuanhao Xiong, Yan Liu, Xu Sun", "title": "Adaptive Gradient Methods with Dynamic Bound of Learning Rate", "comments": "Accepted to ICLR 2019. arXiv admin note: text overlap with\n  arXiv:1904.09237 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimization methods such as AdaGrad, RMSprop and Adam have been\nproposed to achieve a rapid training process with an element-wise scaling term\non learning rates. Though prevailing, they are observed to generalize poorly\ncompared with SGD or even fail to converge due to unstable and extreme learning\nrates. Recent work has put forward some algorithms such as AMSGrad to tackle\nthis issue but they failed to achieve considerable improvement over existing\nmethods. In our paper, we demonstrate that extreme learning rates can lead to\npoor performance. We provide new variants of Adam and AMSGrad, called AdaBound\nand AMSBound respectively, which employ dynamic bounds on learning rates to\nachieve a gradual and smooth transition from adaptive methods to SGD and give a\ntheoretical proof of convergence. We further conduct experiments on various\npopular tasks and models, which is often insufficient in previous work.\nExperimental results show that new variants can eliminate the generalization\ngap between adaptive methods and SGD and maintain higher learning speed early\nin training at the same time. Moreover, they can bring significant improvement\nover their prototypes, especially on complex deep networks. The implementation\nof the algorithm can be found at https://github.com/Luolc/AdaBound .\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:22:48 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Luo", "Liangchen", ""], ["Xiong", "Yuanhao", ""], ["Liu", "Yan", ""], ["Sun", "Xu", ""]]}, {"id": "1902.09849", "submitter": "Chaoyue He", "authors": "Chaoyue He, Yong Liu, Qingyu Guo and Chunyan Miao", "title": "Multi-Scale Quasi-RNN for Next Item Recommendation", "comments": "7 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to better utilize sequential information has been extensively studied in\nthe setting of recommender systems. To this end, architectural inductive biases\nsuch as Markov-Chains, Recurrent models, Convolutional networks and many others\nhave demonstrated reasonable success on this task. This paper proposes a new\nneural architecture, multi-scale Quasi-RNN for next item Recommendation\n(QR-Rec) task. Our model provides the best of both worlds by exploiting\nmulti-scale convolutional features as the compositional gating functions of a\nrecurrent cell. The model is implemented in a multi-scale fashion, i.e.,\nconvolutional filters of various widths are implemented to capture different\nunion-level features of input sequences which influence the compositional\nencoder. The key idea aims to capture the recurrent relations between different\nkinds of local features, which has never been studied previously in the context\nof recommendation. Through extensive experiments, we demonstrate that our model\nachieves state-of-the-art performance on 15 well-established datasets,\noutperforming strong competitors such as FPMC, Fossil and Caser absolutely by\n0.57%-7.16% and relatively by 1.44%-17.65% in terms of MAP, Recall@10 and\nNDCG@10.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:33:00 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["He", "Chaoyue", ""], ["Liu", "Yong", ""], ["Guo", "Qingyu", ""], ["Miao", "Chunyan", ""]]}, {"id": "1902.09855", "submitter": "Wouter Van Heeswijk PhD", "authors": "Wouter van Heeswijk, Han La Poutr\\'e", "title": "Approximate Dynamic Programming with Neural Networks in Linear Discrete\n  Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems of operations research are typically high-dimensional and\ncombinatorial. Linear programs are generally used to formulate and efficiently\nsolve these large decision problems. However, in multi-period decision\nproblems, we must often compute expected downstream values corresponding to\ncurrent decisions. When applying stochastic methods to approximate these\nvalues, linear programs become restrictive for designing value function\napproximations (VFAs). In particular, the manual design of a polynomial VFA is\nchallenging.\n  This paper presents an integrated approach for complex optimization problems,\nfocusing on applications in the domain of operations research. It develops a\nhybrid solution method that combines linear programming and neural networks as\npart of approximate dynamic programming.\n  Our proposed solution method embeds neural network VFAs into linear decision\nproblems, combining the nonlinear expressive power of neural networks with the\nefficiency of solving linear programs. As a proof of concept, we perform\nnumerical experiments on a transportation problem. The neural network VFAs\nconsistently outperform polynomial VFAs, with limited design and tuning effort.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:45:58 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["van Heeswijk", "Wouter", ""], ["La Poutr\u00e9", "Han", ""]]}, {"id": "1902.09856", "submitter": "Changhee Han", "authors": "Changhee Han, Kohei Murao, Tomoyuki Noguchi, Yusuke Kawata, Fumiya\n  Uchiyama, Leonardo Rundo, Hideki Nakayama, Shin'ichi Satoh", "title": "Learning More with Less: Conditional PGGAN-based Data Augmentation for\n  Brain Metastases Detection Using Highly-Rough Annotation on MR Images", "comments": "9 pages, 7 figures, accepted to CIKM 2019 (acceptance rate: 19%)", "journal-ref": null, "doi": "10.1145/3357384.3357890", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate Computer-Assisted Diagnosis, associated with proper data wrangling,\ncan alleviate the risk of overlooking the diagnosis in a clinical environment.\nTowards this, as a Data Augmentation (DA) technique, Generative Adversarial\nNetworks (GANs) can synthesize additional training data to handle the\nsmall/fragmented medical imaging datasets collected from various scanners;\nthose images are realistic but completely different from the original ones,\nfilling the data lack in the real image distribution. However, we cannot easily\nuse them to locate disease areas, considering expert physicians' expensive\nannotation cost. Therefore, this paper proposes Conditional Progressive Growing\nof GANs (CPGGANs), incorporating highly-rough bounding box conditions\nincrementally into PGGANs to place brain metastases at desired positions/sizes\non 256 X 256 Magnetic Resonance (MR) images, for Convolutional Neural\nNetwork-based tumor detection; this first GAN-based medical DA using automatic\nbounding box annotation improves the training robustness. The results show that\nCPGGAN-based DA can boost 10% sensitivity in diagnosis with clinically\nacceptable additional False Positives. Surprisingly, further tumor realism,\nachieved with additional normal brain MR images for CPGGAN training, does not\ncontribute to detection performance, while even three physicians cannot\naccurately distinguish them from the real ones in Visual Turing Test.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:46:53 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 15:33:12 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 15:05:36 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 12:44:45 GMT"}, {"version": "v5", "created": "Thu, 22 Aug 2019 11:01:29 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Han", "Changhee", ""], ["Murao", "Kohei", ""], ["Noguchi", "Tomoyuki", ""], ["Kawata", "Yusuke", ""], ["Uchiyama", "Fumiya", ""], ["Rundo", "Leonardo", ""], ["Nakayama", "Hideki", ""], ["Satoh", "Shin'ichi", ""]]}, {"id": "1902.09859", "submitter": "Zhenisbek Assylbekov", "authors": "Zhenisbek Assylbekov and Rustem Takhanov", "title": "Context Vectors are Reflections of Word Vectors in Half the Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper takes a step towards theoretical analysis of the relationship\nbetween word embeddings and context embeddings in models such as word2vec. We\nstart from basic probabilistic assumptions on the nature of word vectors,\ncontext vectors, and text generation. These assumptions are well supported\neither empirically or theoretically by the existing literature. Next, we show\nthat under these assumptions the widely-used word-word PMI matrix is\napproximately a random symmetric Gaussian ensemble. This, in turn, implies that\ncontext vectors are reflections of word vectors in approximately half the\ndimensions. As a direct application of our result, we suggest a theoretically\ngrounded way of tying weights in the SGNS model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:09:29 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Assylbekov", "Zhenisbek", ""], ["Takhanov", "Rustem", ""]]}, {"id": "1902.09866", "submitter": "Jianlin Li", "authors": "Jianlin Li, Pengfei Yang, Jiangchao Liu, Liqian Chen, Xiaowei Huang\n  and Lijun Zhang", "title": "Analyzing Deep Neural Networks with Symbolic Propagation: Towards Higher\n  Precision and Faster Verification", "comments": "SAS 2019: 26th Static Analysis Symposium, Porto, Portugal, October\n  8-11, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32304-2_15", "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been shown lack of robustness for the\nvulnerability of their classification to small perturbations on the inputs.\nThis has led to safety concerns of applying DNNs to safety-critical domains.\nSeveral verification approaches have been developed to automatically prove or\ndisprove safety properties of DNNs. However, these approaches suffer from\neither the scalability problem, i.e., only small DNNs can be handled, or the\nprecision problem, i.e., the obtained bounds are loose. This paper improves on\na recent proposal of analyzing DNNs through the classic abstract interpretation\ntechnique, by a novel symbolic propagation technique. More specifically, the\nvalues of neurons are represented symbolically and propagated forwardly from\nthe input layer to the output layer, on top of abstract domains. We show that\nour approach can achieve significantly higher precision and thus can prove more\nproperties than using only abstract domains. Moreover, we show that the bounds\nderived from our approach on the hidden neurons, when applied to a\nstate-of-the-art SMT based verification tool, can improve its performance. We\nimplement our approach into a software tool and validate it over a few DNNs\ntrained on benchmark datasets such as MNIST, etc.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 11:23:00 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 15:38:49 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Li", "Jianlin", ""], ["Yang", "Pengfei", ""], ["Liu", "Jiangchao", ""], ["Chen", "Liqian", ""], ["Huang", "Xiaowei", ""], ["Zhang", "Lijun", ""]]}, {"id": "1902.09884", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Amos Storkey", "title": "Assume, Augment and Learn: Unsupervised Few-Shot Meta-Learning via\n  Random Labels and Data Augmentation", "comments": "Work in Progress - Under Review in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of few-shot learning has been laboriously explored in the\nsupervised setting, where per-class labels are available. On the other hand,\nthe unsupervised few-shot learning setting, where no labels of any kind are\nrequired, has seen little investigation. We propose a method, named Assume,\nAugment and Learn or AAL, for generating few-shot tasks using unlabeled data.\nWe randomly label a random subset of images from an unlabeled dataset to\ngenerate a support set. Then by applying data augmentation on the support set's\nimages, and reusing the support set's labels, we obtain a target set. The\nresulting few-shot tasks can be used to train any standard meta-learning\nframework. Once trained, such a model, can be directly applied on small\nreal-labeled datasets without any changes or fine-tuning required. In our\nexperiments, the learned models achieve good generalization performance in a\nvariety of established few-shot learning tasks on Omniglot and Mini-Imagenet.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 12:16:10 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 10:09:00 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 23:09:17 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Antoniou", "Antreas", ""], ["Storkey", "Amos", ""]]}, {"id": "1902.09913", "submitter": "Uiwon Hwang", "authors": "Uiwon Hwang, Dahuin Jung, Sungroh Yoon", "title": "HexaGAN: Generative Adversarial Nets for Real World Classification", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning classification studies assume clean data. However, when\ndealing with the real world data, we encounter three problems such as 1)\nmissing data, 2) class imbalance, and 3) missing label problems. These problems\nundermine the performance of a classifier. Various preprocessing techniques\nhave been proposed to mitigate one of these problems, but an algorithm that\nassumes and resolves all three problems together has not been proposed yet. In\nthis paper, we propose HexaGAN, a generative adversarial network framework that\nshows promising classification performance for all three problems. We interpret\nthe three problems from a single perspective to solve them jointly. To enable\nthis, the framework consists of six components, which interact with each other.\nWe also devise novel loss functions corresponding to the architecture. The\ndesigned loss functions allow us to achieve state-of-the-art imputation\nperformance, with up to a 14% improvement, and to generate high-quality\nclass-conditional data. We evaluate the classification performance (F1-score)\nof the proposed method with 20% missingness and confirm up to a 5% improvement\nin comparison with the performance of combinations of state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 13:12:56 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 20:35:50 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Hwang", "Uiwon", ""], ["Jung", "Dahuin", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1902.09917", "submitter": "Remi Jezequel", "authors": "R\\'emi J\\'ez\\'equel (SIERRA), Pierre Gaillard (SIERRA), Alessandro\n  Rudi (SIERRA)", "title": "Efficient online learning with kernels for adversarial large scale\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in a framework of online learning with kernels for\nlow-dimensional but large-scale and potentially adversarial datasets. We study\nthe computational and theoretical performance of online variations of kernel\nRidge regression. Despite its simplicity, the algorithm we study is the first\nto achieve the optimal regret for a wide range of kernels with a per-round\ncomplexity of order $n^\\alpha$ with $\\alpha < 2$. The algorithm we consider is\nbased on approximating the kernel with the linear span of basis functions. Our\ncontributions is two-fold: 1) For the Gaussian kernel, we propose to build the\nbasis beforehand (independently of the data) through Taylor expansion. For\n$d$-dimensional inputs, we provide a (close to) optimal regret of order\n$O((\\log n)^{d+1})$ with per-round time complexity and space complexity\n$O((\\log n)^{2d})$. This makes the algorithm a suitable choice as soon as $n\n\\gg e^d$ which is likely to happen in a scenario with small dimensional and\nlarge-scale dataset; 2) For general kernels with low effective dimension, the\nbasis functions are updated sequentially in a data-adaptive fashion by sampling\nNystr{\\\"o}m points. In this case, our algorithm improves the computational\ntrade-off known for online kernel regression.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 13:17:11 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:57:43 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["J\u00e9z\u00e9quel", "R\u00e9mi", "", "SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"], ["Rudi", "Alessandro", "", "SIERRA"]]}, {"id": "1902.09934", "submitter": "Jiahang Xu", "authors": "Jiahang Xu, Fangyang Jiao, Yechong Huang, Xinzhe Luo, Qian Xu, Ling\n  Li, Xueling Liu, Chuantao Zuo, Ping Wu and Xiahai Zhuang", "title": "A Fully-Automatic Framework for Parkinson's Disease Diagnosis by\n  Multi-Modality Images", "comments": "16 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: Parkinson's disease (PD) is a prevalent long-term\nneurodegenerative disease. Though the diagnostic criteria of PD are relatively\nwell defined, the current medical imaging diagnostic procedures are\nexpertise-demanding, and thus call for a higher-integrated AI-based diagnostic\nalgorithm. Methods: In this paper, we proposed an automatic, end-to-end,\nmulti-modality diagnosis framework, including segmentation, registration,\nfeature generation and machine learning, to process the information of the\nstriatum for the diagnosis of PD. Multiple modalities, including T1- weighted\nMRI and 11C-CFT PET, were used in the proposed framework. The reliability of\nthis framework was then validated on a dataset from the PET center of Huashan\nHospital, as the dataset contains paired T1-MRI and CFT-PET images of 18 Normal\n(NL) subjects and 49 PD subjects. Results: We obtained an accuracy of 100% for\nthe PD/NL classification task, besides, we conducted several comparative\nexperiments to validate the diagnosis ability of our framework. Conclusion:\nThrough experiment we illustrate that (1) automatic segmentation has the same\nclassification effect as the manual segmentation, (2) the multi-modality images\ngenerates a better prediction than single modality images, and (3) volume\nfeature is shown to be irrelevant to PD diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 13:52:41 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Xu", "Jiahang", ""], ["Jiao", "Fangyang", ""], ["Huang", "Yechong", ""], ["Luo", "Xinzhe", ""], ["Xu", "Qian", ""], ["Li", "Ling", ""], ["Liu", "Xueling", ""], ["Zuo", "Chuantao", ""], ["Wu", "Ping", ""], ["Zhuang", "Xiahai", ""]]}, {"id": "1902.09936", "submitter": "Lu Bai", "authors": "Lu Bai, Lixin Cui, Shu Wu, Yuhang Jiao, Edwin R. Hancock", "title": "Learning Vertex Convolutional Networks for Graph Classification", "comments": "arXiv admin note: text overlap with arXiv:1809.01090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new aligned vertex convolutional network model to\nlearn multi-scale local-level vertex features for graph classification. Our\nidea is to transform the graphs of arbitrary sizes into fixed-sized aligned\nvertex grid structures, and define a new vertex convolution operation by\nadopting a set of fixed-sized one-dimensional convolution filters on the grid\nstructure. We show that the proposed model not only integrates the precise\nstructural correspondence information between graphs but also minimises the\nloss of structural information residing on local-level vertices. Experiments on\nstandard graph datasets demonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 13:58:37 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Wu", "Shu", ""], ["Jiao", "Yuhang", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1902.09938", "submitter": "Hamid Usefi", "authors": "Javad Rahimipour Anaraki and Hamid Usefi", "title": "A Feature Selection Based on Perturbation Theory", "comments": null, "journal-ref": "Expert Systems With Applications, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a supervised dataset $D=[A\\mid \\textbf{b}]$, where $\\textbf{b}$ is\nthe outcome column, rows of $D$ correspond to observations, and columns of $A$\nare the features of the dataset. A central problem in machine learning and\npattern recognition is to select the most important features from $D$ to be\nable to predict the outcome. In this paper, we provide a new feature selection\nmethod where we use perturbation theory to detect correlations between\nfeatures. We solve $AX=\\textbf{b}$ using the method of least squares and\nsingular value decomposition of $A$. In practical applications, such as in\nbioinformatics, the number of rows of $A$ (observations) are much less than the\nnumber of columns of $A$ (features). So we are dealing with singular matrices\nwith big condition numbers. Although it is known that the solutions of least\nsquare problems in singular case are very sensitive to perturbations in $A$,\nour novel approach in this paper is to prove that the correlations between\nfeatures can be detected by applying perturbations to $A$. The effectiveness of\nour method is verified by performing a series of comparisons with conventional\nand novel feature selection methods in the literature. It is demonstrated that\nin most situations, our method chooses considerably less number of features\nwhile attaining or exceeding the accuracy of the other methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:02:21 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Usefi", "Hamid", ""]]}, {"id": "1902.09947", "submitter": "Lu Bai", "authors": "Lu Bai, Lixin Cui, Yue Wang, Philip S. Yu, Edwin R. Hancock", "title": "Fused Lasso for Feature Selection using Structural Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection has been proven a powerful preprocessing step for\nhigh-dimensional data analysis. However, most state-of-the-art methods tend to\noverlook the structural correlation information between pairwise samples, which\nmay encapsulate useful information for refining the performance of feature\nselection. Moreover, they usually consider candidate feature relevancy\nequivalent to selected feature relevancy, and some less relevant features may\nbe misinterpreted as salient features. To overcome these issues, we propose a\nnew feature selection method using structural correlation between pairwise\nsamples. Our idea is based on converting the original vectorial features into\nstructure-based feature graph representations to incorporate structural\nrelationship between samples, and defining a new evaluation measure to compute\nthe joint significance of pairwise feature combinations in relation to the\ntarget feature graph. Furthermore, we formulate the corresponding feature\nsubset selection problem into a least square regression model associated with a\nfused lasso regularizer to simultaneously maximize the joint relevancy and\nminimize the redundancy of the selected features. To effectively solve the\noptimization problem, an iterative algorithm is developed to identify the most\ndiscriminative features. Experiments demonstrate the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:17:06 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:52:23 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 19:30:14 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Wang", "Yue", ""], ["Yu", "Philip S.", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1902.09962", "submitter": "Md Mursalin", "authors": "Md Mursalin, Syed Shamsul Islam, Md Kislu Noman and Adel Ali\n  Al-Jumaily", "title": "Epileptic seizure classification using statistical sampling and a novel\n  feature selection algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a well-known neuronal disorder that can be identified by\ninterpretation of the electroencephalogram (EEG) signal. Usually, the length of\nan EEG signal is quite long which is challenging to interpret manually. In this\nwork, we propose an automated epileptic seizure detection method by applying a\ntwo-step minimization technique: first, we reduce the data points using a\nstatistical sampling technique and then, we minimize the number of features\nusing our novel feature selection algorithm. We then apply different machine\nlearning algorithms for performance measurement of the proposed feature\nselection algorithm. The experimental results outperform some of the\nstate-of-the-art methods for seizure detection using the reduced data points\nand the least number of features.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 16:45:24 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 02:34:06 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Mursalin", "Md", ""], ["Islam", "Syed Shamsul", ""], ["Noman", "Md Kislu", ""], ["Al-Jumaily", "Adel Ali", ""]]}, {"id": "1902.09964", "submitter": "Ihab Mohamed", "authors": "Ihab S. Mohamed, Stefano Rovetta, Ton Duc Do, Tomislav Dragicevic,\n  Ahmed A. Zaki Diab", "title": "A Neural-Network-Based Model Predictive Control of Three-Phase Inverter\n  With an Output LC Filter", "comments": "13 pages, 15 figures, 3 tables. This article has been submitted to\n  IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2938220", "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model predictive control (MPC) has become one of the well-established modern\ncontrol methods for three-phase inverters with an output LC filter, where a\nhigh-quality voltage with low total harmonic distortion (THD) is needed.\nAlthough it is an intuitive controller, easy to understand and implement, it\nhas the significant disadvantage of requiring a large number of online\ncalculations for solving the optimization problem. On the other hand, the\napplication of model-free approaches such as those based on artificial neural\nnetworks approaches is currently growing rapidly in the area of power\nelectronics and drives. This paper presents a new control scheme for a\ntwo-level converter based on combining MPC and feed-forward ANN, with the aim\nof getting lower THD and improving the steady and dynamic performance of the\nsystem for different types of loads. First, MPC is used, as an expert, in the\ntraining phase to generate data required for training the proposed neural\nnetwork. Then, once the neural network is fine-tuned, it can be successfully\nused online for voltage tracking purpose, without the need of using MPC. The\nproposed ANN-based control strategy is validated through simulation, using\nMATLAB/Simulink tools, taking into account different loads conditions.\nMoreover, the performance of the ANN-based controller is evaluated, on several\nsamples of linear and non-linear loads under various operating conditions, and\ncompared to that of MPC, demonstrating the excellent steady-state and dynamic\nperformance of the proposed ANN-based control strategy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:51:57 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 10:41:22 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 20:43:07 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Mohamed", "Ihab S.", ""], ["Rovetta", "Stefano", ""], ["Do", "Ton Duc", ""], ["Dragicevic", "Tomislav", ""], ["Diab", "Ahmed A. Zaki", ""]]}, {"id": "1902.09969", "submitter": "Ashutosh Mishra", "authors": "Ashutosh Mishra, Marcus Liwicki", "title": "Using Deep Object Features for Image Descriptions", "comments": "arXiv admin note: text overlap with arXiv:1411.2539, arXiv:1609.06647\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent advances in leveraging multiple modalities in machine\ntranslation, we introduce an encoder-decoder pipeline that uses (1) specific\nobjects within an image and their object labels, (2) a language model for\ndecoding joint embedding of object features and the object labels. Our pipeline\nmerges prior detected objects from the image and their object labels and then\nlearns the sequences of captions describing the particular image. The decoder\nmodel learns to extract descriptions for the image from scratch by decoding the\njoint representation of the object visual features and their object classes\nconditioned by the encoder component. The idea of the model is to concentrate\nonly on the specific objects of the image and their labels for generating\ndescriptions of the image rather than visual feature of the entire image. The\nmodel needs to be calibrated more by adjusting the parameters and settings to\nresult in better accuracy and performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:40:25 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Mishra", "Ashutosh", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1902.09972", "submitter": "Nurali Virani", "authors": "Zhaoyuan Yang, Naresh Iyer, Johan Reimann, Nurali Virani", "title": "Design of intentional backdoors in sequential models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated robust mechanisms by which attacks can be\norchestrated on machine learning models. In contrast to adversarial examples,\nbackdoor or trojan attacks embed surgically modified samples with targeted\nlabels in the model training process to cause the targeted model to learn to\nmisclassify chosen samples in the presence of specific triggers, while keeping\nthe model performance stable across other nominal samples. However, current\npublished research on trojan attacks mainly focuses on classification problems,\nwhich ignores sequential dependency between inputs. In this paper, we propose\nmethods to discreetly introduce and exploit novel backdoor attacks within a\nsequential decision-making agent, such as a reinforcement learning agent, by\ntraining multiple benign and malicious policies within a single long short-term\nmemory (LSTM) network. We demonstrate the effectiveness as well as the damaging\nimpact of such attacks through initial outcomes generated from our approach,\nemployed on grid-world environments. We also provide evidence as well as\nintuition on how the trojan trigger and malicious policy is activated.\nChallenges with network size and unintentional triggers are identified and\nanalogies with adversarial examples are also discussed. In the end, we propose\npotential approaches to defend against or serve as early detection for such\nattacks. Results of our work can also be extended to many applications of LSTM\nand recurrent networks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:43:14 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Yang", "Zhaoyuan", ""], ["Iyer", "Naresh", ""], ["Reimann", "Johan", ""], ["Virani", "Nurali", ""]]}, {"id": "1902.09980", "submitter": "Tom Everitt", "authors": "Tom Everitt, Pedro A. Ortega, Elizabeth Barnes, Shane Legg", "title": "Understanding Agent Incentives using Causal Influence Diagrams. Part I:\n  Single Action Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents are systems that optimize an objective function in an environment.\nTogether, the goal and the environment induce secondary objectives, incentives.\nModeling the agent-environment interaction using causal influence diagrams, we\ncan answer two fundamental questions about an agent's incentives directly from\nthe graph: (1) which nodes can the agent have an incentivize to observe, and\n(2) which nodes can the agent have an incentivize to control? The answers tell\nus which information and influence points need extra protection. For example,\nwe may want a classifier for job applications to not use the ethnicity of the\ncandidate, and a reinforcement learning agent not to take direct control of its\nreward mechanism. Different algorithms and training paradigms can lead to\ndifferent causal influence diagrams, so our method can be used to identify\nalgorithms with problematic incentives and help in designing algorithms with\nbetter incentives.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:54:09 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 12:20:42 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 10:31:00 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 09:57:41 GMT"}, {"version": "v5", "created": "Thu, 1 Aug 2019 16:16:14 GMT"}, {"version": "v6", "created": "Fri, 6 Sep 2019 16:38:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Everitt", "Tom", ""], ["Ortega", "Pedro A.", ""], ["Barnes", "Elizabeth", ""], ["Legg", "Shane", ""]]}, {"id": "1902.09992", "submitter": "Ruben Martinez-Cantin", "authors": "Javier Garcia-Barcos, Ruben Martinez-Cantin", "title": "Fully Distributed Bayesian Optimization with Stochastic Policies", "comments": null, "journal-ref": "Proceedings of the International Joint Conference on Artificial\n  Intelligence (IJCAI-19), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a popular method for high-throughput\ncomputing, like the design of computer experiments or hyperparameter tuning of\nexpensive models, where sample efficiency is mandatory. In these applications,\ndistributed and scalable architectures are a necessity. However, Bayesian\noptimization is mostly sequential. Even parallel variants require certain\ncomputations between samples, limiting the parallelization bandwidth. Thompson\nsampling has been previously applied for distributed Bayesian optimization.\nBut, when compared with other acquisition functions in the sequential setting,\nThompson sampling is known to perform suboptimally. In this paper, we present a\nnew method for fully distributed Bayesian optimization, which can be combined\nwith any acquisition function. Our approach considers Bayesian optimization as\na partially observable Markov decision process. In this context, stochastic\npolicies, such as the Boltzmann policy, have some interesting properties which\ncan also be studied for Bayesian optimization. Furthermore, the Boltzmann\npolicy trivially allows a distributed Bayesian optimization implementation with\nhigh level of parallelism and scalability. We present results in several\nbenchmarks and applications that shows the performance of our method.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:13:17 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 17:52:55 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Garcia-Barcos", "Javier", ""], ["Martinez-Cantin", "Ruben", ""]]}, {"id": "1902.09996", "submitter": "Anna Harutyunyan", "authors": "Anna Harutyunyan, Will Dabney, Diana Borsa, Nicolas Heess, Remi Munos,\n  Doina Precup", "title": "The Termination Critic", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of autonomously discovering behavioral\nabstractions, or options, for reinforcement learning agents. We propose an\nalgorithm that focuses on the termination condition, as opposed to -- as is\ncommon -- the policy. The termination condition is usually trained to optimize\na control objective: an option ought to terminate if another has better value.\nWe offer a different, information-theoretic perspective, and propose that\nterminations should focus instead on the compressibility of the option's\nencoding -- arguably a key reason for using abstractions. To achieve this\nalgorithmically, we leverage the classical options framework, and learn the\noption transition model as a \"critic\" for the termination condition. Using this\nmodel, we derive gradients that optimize the desired criteria. We show that the\nresulting options are non-trivial, intuitively meaningful, and useful for\nlearning and planning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:26:10 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Harutyunyan", "Anna", ""], ["Dabney", "Will", ""], ["Borsa", "Diana", ""], ["Heess", "Nicolas", ""], ["Munos", "Remi", ""], ["Precup", "Doina", ""]]}, {"id": "1902.10027", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi and Sudipta Chattopadhyay", "title": "Grammar Based Directed Testing of Machine Learning Systems", "comments": "Accepted to appear in the IEEE Transactions on Software Engineering\n  (TSE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The massive progress of machine learning has seen its application over a\nvariety of domains in the past decade. But how do we develop a systematic,\nscalable and modular strategy to validate machine-learning systems? We present,\nto the best of our knowledge, the first approach, which provides a systematic\ntest framework for machine-learning systems that accepts grammar-based inputs.\nOur OGMA approach automatically discovers erroneous behaviours in classifiers\nand leverages these erroneous behaviours to improve the respective models. OGMA\nleverages inherent robustness properties present in any well trained\nmachine-learning model to direct test generation and thus, implementing a\nscalable test generation methodology. To evaluate our OGMA approach, we have\ntested it on three real world natural language processing (NLP) classifiers. We\nhave found thousands of erroneous behaviours in these systems. We also compare\nOGMA with a random test generation approach and observe that OGMA is more\neffective than such random test generation by up to 489%.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:12:45 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 03:40:34 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 07:15:26 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1902.10028", "submitter": "Iqbal H. Sarker", "authors": "Md. Faisal Faruque, Asaduzzaman, Iqbal H. Sarker", "title": "Performance Analysis of Machine Learning Techniques to Predict Diabetes\n  Mellitus", "comments": "IEEE International Conference on Electrical, Computer and\n  Communication Engineering (ECCE 2019), Cox's Bazar, Bangladesh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes mellitus is a common disease of human body caused by a group of\nmetabolic disorders where the sugar levels over a prolonged period is very\nhigh. It affects different organs of the human body which thus harm a large\nnumber of the body's system, in particular the blood veins and nerves. Early\nprediction in such disease can be controlled and save human life. To achieve\nthe goal, this research work mainly explores various risk factors related to\nthis disease using machine learning techniques. Machine learning techniques\nprovide efficient result to extract knowledge by constructing predicting models\nfrom diagnostic medical datasets collected from the diabetic patients.\nExtracting knowledge from such data can be useful to predict diabetic patients.\nIn this work, we employ four popular machine learning algorithms, namely\nSupport Vector Machine (SVM), Naive Bayes (NB), K-Nearest Neighbor (KNN) and\nC4.5 Decision Tree, on adult population data to predict diabetic mellitus. Our\nexperimental results show that C4.5 decision tree achieved higher accuracy\ncompared to other machine learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 14:53:27 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Faruque", "Md. Faisal", ""], ["Asaduzzaman", "", ""], ["Sarker", "Iqbal H.", ""]]}, {"id": "1902.10031", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Cassie Gregson, Robert Hernandez, Goran Nenadic", "title": "A framework for information extraction from tables in biomedical\n  literature", "comments": "24 pages", "journal-ref": "2019, International Journal on Document Analysis and Recognition\n  (IJDAR)", "doi": "10.1007/s10032-019-00317-0", "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scientific literature is growing exponentially, and professionals are no\nmore able to cope with the current amount of publications. Text mining provided\nin the past methods to retrieve and extract information from text; however,\nmost of these approaches ignored tables and figures. The research done in\nmining table data still does not have an integrated approach for mining that\nwould consider all complexities and challenges of a table. Our research is\nexamining the methods for extracting numerical (number of patients, age, gender\ndistribution) and textual (adverse reactions) information from tables in the\nclinical literature. We present a requirement analysis template and an integral\nmethodology for information extraction from tables in clinical domain that\ncontains 7 steps: (1) table detection, (2) functional processing, (3)\nstructural processing, (4) semantic tagging, (5) pragmatic processing, (6) cell\nselection and (7) syntactic processing and extraction. Our approach performed\nwith the F-measure ranged between 82 and 92%, depending on the variable, task\nand its complexity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:22:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Milosevic", "Nikola", ""], ["Gregson", "Cassie", ""], ["Hernandez", "Robert", ""], ["Nenadic", "Goran", ""]]}, {"id": "1902.10042", "submitter": "Andrew Carr", "authors": "Andrew Carr and David Wingate", "title": "Graph Neural Processes: Towards Bayesian Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Graph Neural Processes (GNP), inspired by the recent work in\nconditional and latent neural processes. A Graph Neural Process is defined as a\nConditional Neural Process that operates on arbitrary graph data. It takes\nfeatures of sparsely observed context points as input, and outputs a\ndistribution over target points. We demonstrate graph neural processes in edge\nimputation and discuss benefits and drawbacks of the method for other\napplication areas. One major benefit of GNPs is the ability to quantify\nuncertainty in deep learning on graph structures. An additional benefit of this\nmethod is the ability to extend graph neural networks to inputs of dynamic\nsized graphs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:39:42 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 21:13:48 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Carr", "Andrew", ""], ["Wingate", "David", ""]]}, {"id": "1902.10061", "submitter": "Benedikt Zacher", "authors": "Benedikt Zacher and Irina Czogiel", "title": "Supervised learning improves disease outbreak detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early detection of infectious disease outbreaks is a crucial task to\nprotect population health. To this end, public health surveillance systems have\nbeen established to systematically collect and analyse infectious disease data.\nA variety of statistical tools are available, which detect potential outbreaks\nas abberations from an expected endemic level using these data. Here, we\ndevelop the first supervised learning approach based on hidden Markov models\nfor disease outbreak detection, which leverages data that is routinely\ncollected within a public health surveillance system. We evaluate our model\nusing real Salmonella and Campylobacter data, as well as simulations. In\ncomparison to a state-of-the-art approach, which is applied in multiple\nEuropean countries including Germany, our proposed model reduces the false\npositive rate by up to 50% while retaining the same sensitivity. We see our\nsupervised learning approach as a significant step to further develop machine\nlearning applications for disease outbreak detection, which will be\ninstrumental to improve public health surveillance systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 13:45:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Zacher", "Benedikt", ""], ["Czogiel", "Irina", ""]]}, {"id": "1902.10078", "submitter": "Nicolas Durrande", "authors": "Nicolas Durrande, Vincent Adam, Lucas Bordeaux, Stefanos\n  Eleftheriadis, James Hensman", "title": "Banded Matrix Operators for Gaussian Markov Models in the Automatic\n  Differentiation Era", "comments": null, "journal-ref": "Proceedings of the 22 nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR:\n  Volume 89", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banded matrices can be used as precision matrices in several models including\nlinear state-space models, some Gaussian processes, and Gaussian Markov random\nfields. The aim of the paper is to make modern inference methods (such as\nvariational inference or gradient-based sampling) available for Gaussian models\nwith banded precision. We show that this can efficiently be achieved by\nequipping an automatic differentiation framework, such as TensorFlow or\nPyTorch, with some linear algebra operators dedicated to banded matrices. This\npaper studies the algorithmic aspects of the required operators, details their\nreverse-mode derivatives, and show that their complexity is linear in the\nnumber of observations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 17:36:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Durrande", "Nicolas", ""], ["Adam", "Vincent", ""], ["Bordeaux", "Lucas", ""], ["Eleftheriadis", "Stefanos", ""], ["Hensman", "James", ""]]}, {"id": "1902.10089", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Csaba Szepesvari, Mohammad Ghavamzadeh, and Craig\n  Boutilier", "title": "Perturbed-History Exploration in Stochastic Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online algorithm for cumulative regret minimization in a\nstochastic multi-armed bandit. The algorithm adds $O(t)$ i.i.d. pseudo-rewards\nto its history in round $t$ and then pulls the arm with the highest average\nreward in its perturbed history. Therefore, we call it perturbed-history\nexploration (PHE). The pseudo-rewards are carefully designed to offset\npotentially underestimated mean rewards of arms with a high probability. We\nderive near-optimal gap-dependent and gap-free bounds on the $n$-round regret\nof PHE. The key step in our analysis is a novel argument that shows that\nrandomized Bernoulli rewards lead to optimism. Finally, we empirically evaluate\nPHE and show that it is competitive with state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:04:58 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:27:37 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "1902.10107", "submitter": "Weidi Xie", "authors": "Weidi Xie, Arsha Nagrani, Joon Son Chung, Andrew Zisserman", "title": "Utterance-level Aggregation For Speaker Recognition In The Wild", "comments": "To appear in: International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2019. (Oral Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this paper is speaker recognition \"in the wild\"-where\nutterances may be of variable length and also contain irrelevant signals.\nCrucial elements in the design of deep networks for this task are the type of\ntrunk (frame level) network, and the method of temporal aggregation. We propose\na powerful speaker recognition deep network, using a \"thin-ResNet\" trunk\narchitecture, and a dictionary-based NetVLAD or GhostVLAD layer to aggregate\nfeatures across time, that can be trained end-to-end. We show that our network\nachieves state of the art performance by a significant margin on the VoxCeleb1\ntest set for speaker recognition, whilst requiring fewer parameters than\nprevious methods. We also investigate the effect of utterance length on\nperformance, and conclude that for \"in the wild\" data, a longer length is\nbeneficial.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:34:05 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 19:13:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Xie", "Weidi", ""], ["Nagrani", "Arsha", ""], ["Chung", "Joon Son", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1902.10119", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Pooyan Jamshidi, Marco Valtorta", "title": "Transfer Learning for Performance Modeling of Configurable Systems: A\n  Causal Analysis", "comments": "Accepted for presentation at the First AAAI Spring Symposium: Beyond\n  Curve Fitting: Causation, Counterfactuals, and Imagination-based AI, 2019\n  Stanford, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern systems (e.g., deep neural networks, big data analytics, and\ncompilers) are highly configurable, which means they expose different\nperformance behavior under different configurations. The fundamental challenge\nis that one cannot simply measure all configurations due to the sheer size of\nthe configuration space. Transfer learning has been used to reduce the\nmeasurement efforts by transferring knowledge about performance behavior of\nsystems across environments. Previously, research has shown that statistical\nmodels are indeed transferable across environments. In this work, we\ninvestigate identifiability and transportability of causal effects and\nstatistical relations in highly-configurable systems. Our causal analysis\nagrees with previous exploratory analysis \\cite{Jamshidi17} and confirms that\nthe causal effects of configuration options can be carried over across\nenvironments with high confidence. We expect that the ability to carry over\ncausal relations will enable effective performance analysis of\nhighly-configurable systems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:53:38 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Jamshidi", "Pooyan", ""], ["Valtorta", "Marco", ""]]}, {"id": "1902.10126", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Luk\\'a\\v{s} Burget, Pavel Smrz", "title": "BUT-FIT at SemEval-2019 Task 7: Determining the Rumour Stance with\n  Pre-Trained Deep Bidirectional Transformers", "comments": "This work has been submitted to NAACL SemEval workshop. Work in\n  progress", "journal-ref": "Proceedings of the 13th International Workshop on Semantic\n  Evaluation 13 (2019) 1097-1104", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system submitted to SemEval 2019 Task 7: RumourEval\n2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell\net al., 2019). The challenge focused on classifying whether posts from Twitter\nand Reddit support, deny, query, or comment a hidden rumour, truthfulness of\nwhich is the topic of an underlying discussion thread. We formulate the problem\nas a stance classification, determining the rumour stance of a post with\nrespect to the previous thread post and the source thread post. The recent BERT\narchitecture was employed to build an end-to-end system which has reached the\nF1 score of 61.67% on the provided test data. It finished at the 2nd place in\nthe competition, without any hand-crafted features, only 0.2% behind the\nwinner.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:53:01 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 08:43:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Fajcik", "Martin", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Smrz", "Pavel", ""]]}, {"id": "1902.10127", "submitter": "Maryam Gholizadeh-Ansari", "authors": "Maryam Gholizadeh-Ansari, Javad Alirezaie and Paul Babyn", "title": "Deep Learning for Low-Dose CT Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dose CT denoising is a challenging task that has been studied by many\nresearchers. Some studies have used deep neural networks to improve the quality\nof low-dose CT images and achieved fruitful results. In this paper, we propose\na deep neural network that uses dilated convolutions with different dilation\nrates instead of standard convolution helping to capture more contextual\ninformation in fewer layers. Also, we have employed residual learning by\ncreating shortcut connections to transmit image information from the early\nlayers to later ones. To further improve the performance of the network, we\nhave introduced a non-trainable edge detection layer that extracts edges in\nhorizontal, vertical, and diagonal directions. Finally, we demonstrate that\noptimizing the network by a combination of mean-square error loss and\nperceptual loss preserves many structural details in the CT image. This\nobjective function does not suffer from over smoothing and blurring effects\ncaused by per-pixel loss and grid-like artifacts resulting from perceptual\nloss. The experiments show that each modification to the network improves the\noutcome while only minimally changing the complexity of the network.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:14:45 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Gholizadeh-Ansari", "Maryam", ""], ["Alirezaie", "Javad", ""], ["Babyn", "Paul", ""]]}, {"id": "1902.10132", "submitter": "Pan Li", "authors": "Pan Li, Niao He, Olgica Milenkovic", "title": "Quadratic Decomposable Submodular Function Minimization: Theory and\n  Practice (Computation and Analysis of PageRank over Hypergraphs)", "comments": "A part of the work appeared in NeurIPS 2018. The current version is\n  to appear in JMLR (Revise some typos). arXiv admin note: substantial text\n  overlap with arXiv:1806.09842", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new convex optimization problem, termed quadratic decomposable\nsubmodular function minimization (QDSFM), which allows to model a number of\nlearning tasks on graphs and hypergraphs. The problem exhibits close ties to\ndecomposable submodular function minimization (DSFM), yet is much more\nchallenging to solve. We approach the problem via a new dual strategy and\nformulate an objective that can be optimized through a number of double-loop\nalgorithms. The outer-loop uses either random coordinate descent (RCD) or\nalternative projection (AP) methods, for both of which we prove linear\nconvergence rates. The inner-loop computes projections onto cones generated by\nbase polytopes of the submodular functions, via the modified min-norm-point or\nFrank-Wolfe algorithm. We also describe two new applications of QDSFM:\nhypergraph-adapted PageRank and semi-supervised learning. The proposed\nhypergraph-based PageRank algorithm can be used for local hypergraph\npartitioning, and comes with provable performance guarantees. For\nhypergraph-adapted semi-supervised learning, we provide numerical experiments\ndemonstrating the efficiency of our QDSFM solvers and their significant\nimprovements on prediction accuracy when compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 08:08:40 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 09:23:38 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 00:10:29 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 15:33:50 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Pan", ""], ["He", "Niao", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1902.10139", "submitter": "Christopher Iliffe Sprague", "authors": "Christopher Iliffe Sprague, Dario Izzo, Petter \\\"Ogren", "title": "Learning Dynamic-Objective Policies from a Class of Optimal Trajectories", "comments": "Accepted to the 59th IEEE Conference on Decision and Control (CDC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal state-feedback controllers, capable of changing between different\nobjective functions, are advantageous to systems in which unexpected situations\nmay arise. However, synthesising such controllers, even for a single objective,\nis a demanding process. In this paper, we present a novel and straightforward\napproach to synthesising these policies through a combination of trajectory\noptimisation, homotopy continuation, and imitation learning. We use numerical\ncontinuation to efficiently generate optimal demonstrations across several\nobjectives and boundary conditions, and use these to train our policies.\nAdditionally, we demonstrate the ability of our policies to effectively learn\nfamilies of optimal state-feedback controllers, which can be used to change\nobjective functions online. We illustrate this approach across two trajectory\noptimisation problems, an inverted pendulum swingup and a spacecraft orbit\ntransfer, and show that the synthesised policies, when evaluated in simulation,\nproduce trajectories that are near-optimal. These results indicate the benefit\nof trajectory optimisation and homotopy continuation to the synthesis of\ncontrollers in dynamic-objective contexts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:04:17 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 11:13:33 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 08:19:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sprague", "Christopher Iliffe", ""], ["Izzo", "Dario", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1902.10140", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour", "title": "Planning in Hierarchical Reinforcement Learning: Guarantees for Using\n  Local Policies", "comments": "Extends previous paper (arXiv:1803.04674) by the same authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a settings of hierarchical reinforcement learning, in which the\nreward is a sum of components. For each component we are given a policy that\nmaximizes it and our goal is to assemble a policy from the individual policies\nthat maximizes the sum of the components. We provide theoretical guarantees for\nassembling such policies in deterministic MDPs with collectible rewards. Our\napproach builds on formulating this problem as a traveling salesman problem\nwith discounted reward. We focus on local solutions, i.e., policies that only\nuse information from the current state; thus, they are easy to implement and do\nnot require substantial computational resources. We propose three local\nstochastic policies and prove that they guarantee better performance than any\ndeterministic local policy in the worst case; experimental results suggest that\nthey also perform better on average.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:04:18 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 15:59:35 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zahavy", "Tom", ""], ["Hasidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1902.10142", "submitter": "Feras Saad", "authors": "Feras A. Saad, Cameron E. Freer, Nathanael L. Ackerman, Vikash K.\n  Mansinghka", "title": "A Family of Exact Goodness-of-Fit Tests for High-Dimensional Discrete\n  Distributions", "comments": "20 pages, 6 figures. Appearing in AISTATS 2019", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics, PMLR 89:1640-1649, 2019", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of goodness-of-fit testing is to assess whether a dataset of\nobservations is likely to have been drawn from a candidate probability\ndistribution. This paper presents a rank-based family of goodness-of-fit tests\nthat is specialized to discrete distributions on high-dimensional domains. The\ntest is readily implemented using a simulation-based, linear-time procedure.\nThe testing procedure can be customized by the practitioner using knowledge of\nthe underlying data domain. Unlike most existing test statistics, the proposed\ntest statistic is distribution-free and its exact (non-asymptotic) sampling\ndistribution is known in closed form. We establish consistency of the test\nagainst all alternatives by showing that the test statistic is distributed as a\ndiscrete uniform if and only if the samples were drawn from the candidate\ndistribution. We illustrate its efficacy for assessing the sample quality of\napproximate sampling algorithms over combinatorially large spaces with\nintractable probabilities, including random partitions in Dirichlet process\nmixture models and random lattices in Ising models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:45:34 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Saad", "Feras A.", ""], ["Freer", "Cameron E.", ""], ["Ackerman", "Nathanael L.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1902.10162", "submitter": "Jiayi Huang", "authors": "Jiayi Huang, Mostofa Patwary, Gregory Diamos", "title": "Coloring Big Graphs with AlphaGoZero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that recent innovations in deep reinforcement learning can\neffectively color very large graphs -- a well-known NP-hard problem with clear\ncommercial applications. Because the Monte Carlo Tree Search with Upper\nConfidence Bound algorithm used in AlphaGoZero can improve the performance of a\ngiven heuristic, our approach allows deep neural networks trained using high\nperformance computing (HPC) technologies to transform computation into improved\nheuristics with zero prior knowledge. Key to our approach is the introduction\nof a novel deep neural network architecture (FastColorNet) that has access to\nthe full graph context and requires $O(V)$ time and space to color a graph with\n$V$ vertices, which enables scaling to very large graphs that arise in real\napplications like parallel computing, compilers, numerical solvers, and design\nautomation, among others. As a result, we are able to learn new state of the\nart heuristics for graph coloring.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:05:30 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 23:53:29 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 17:24:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Jiayi", ""], ["Patwary", "Mostofa", ""], ["Diamos", "Gregory", ""]]}, {"id": "1902.10170", "submitter": "Shijun Zhang", "authors": "Zuowei Shen and Haizhao Yang and Shijun Zhang", "title": "Nonlinear Approximation via Compositions", "comments": null, "journal-ref": "Neural Networks, Volume 119, November 2019, Pages 74-84", "doi": "10.1016/j.neunet.2019.07.011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a function dictionary $\\cal D$ and an approximation budget\n$N\\in\\mathbb{N}^+$, nonlinear approximation seeks the linear combination of the\nbest $N$ terms $\\{T_n\\}_{1\\le n\\le N}\\subseteq{\\cal D}$ to approximate a given\nfunction $f$ with the minimum approximation\nerror\\[\\varepsilon_{L,f}:=\\min_{\\{g_n\\}\\subseteq{\\mathbb{R}},\\{T_n\\}\\subseteq{\\cal\nD}}\\|f(x)-\\sum_{n=1}^N g_n T_n(x)\\|.\\]Motivated by recent success of deep\nlearning, we propose dictionaries with functions in a form of compositions,\ni.e.,\\[T(x)=T^{(L)}\\circ T^{(L-1)}\\circ\\cdots\\circ T^{(1)}(x)\\]for all\n$T\\in\\cal D$, and implement $T$ using ReLU feed-forward neural networks (FNNs)\nwith $L$ hidden layers. We further quantify the improvement of the best\n$N$-term approximation rate in terms of $N$ when $L$ is increased from $1$ to\n$2$ or $3$ to show the power of compositions. In the case when $L>3$, our\nanalysis shows that increasing $L$ cannot improve the approximation rate in\nterms of $N$.\n  In particular, for any function $f$ on $[0,1]$, regardless of its smoothness\nand even the continuity, if $f$ can be approximated using a dictionary when\n$L=1$ with the best $N$-term approximation rate $\\varepsilon_{L,f}={\\cal\nO}(N^{-\\eta})$, we show that dictionaries with $L=2$ can improve the best\n$N$-term approximation rate to $\\varepsilon_{L,f}={\\cal O}(N^{-2\\eta})$. We\nalso show that for H\\\"older continuous functions of order $\\alpha$ on\n$[0,1]^d$, the application of a dictionary with $L=3$ in nonlinear\napproximation can achieve an essentially tight best $N$-term approximation rate\n$\\varepsilon_{L,f}={\\cal O}(N^{-2\\alpha/d})$. Finally, we show that\ndictionaries consisting of wide FNNs with a few hidden layers are more\nattractive in terms of computational efficiency than dictionaries with narrow\nand very deep FNNs for approximating H\\\"older continuous functions if the\nnumber of computer cores is larger than $N$ in parallel computing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:10:58 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 08:45:42 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 11:54:00 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 18:43:26 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 15:55:14 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "1902.10172", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer and Jeff Bilmes", "title": "Near Optimal Algorithms for Hard Submodular Programs with Discounted\n  Cooperative Costs", "comments": "To Appear in Proc. AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a class of submodular problems which in general\nare very hard. These include minimizing a submodular cost function under\ncombinatorial constraints, which include cuts, matchings, paths, etc.,\noptimizing a submodular function under submodular cover and submodular knapsack\nconstraints, and minimizing a ratio of submodular functions. All these problems\nappear in several real world problems but have hardness factors of\n$\\Omega(\\sqrt{n})$ for general submodular cost functions. We show how we can\nachieve constant approximation factors when we restrict the cost functions to\nlow rank sums of concave over modular functions. A wide variety of machine\nlearning applications are very naturally modeled via this subclass of\nsubmodular functions. Our work therefore provides a tighter connection between\ntheory and practice by enabling theoretically satisfying guarantees for a rich\nclass of expressible, natural, and useful submodular cost models. We\nempirically demonstrate the utility of our models on real world problems of\ncooperative image matching and sensor placement with cooperative costs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:16:24 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Iyer", "Rishabh", ""], ["Bilmes", "Jeff", ""]]}, {"id": "1902.10173", "submitter": "Vladimir V'yugin", "authors": "Vladimir V'yugin and Vladimir Trunov", "title": "Online Learning with Continuous Ranked Probability Score", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic forecasts in the form of probability distributions over future\nevents have become popular in several fields of statistical science. The\ndissimilarity between a probability forecast and an outcome is measured by a\nloss function (scoring rule). Popular example of scoring rule for continuous\noutcomes is the continuous ranked probability score (CRPS). We consider the\ncase where several competing methods produce online predictions in the form of\nprobability distribution functions. In this paper, the problem of combining\nprobabilistic forecasts is considered in the prediction with expert advice\nframework. We show that CRPS is a mixable loss function and then the time\nindependent upper bound for the regret of the Vovk's aggregating algorithm\nusing CRPS as a loss function can be obtained. We present the results of\nnumerical experiments illustrating the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:16:57 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 22:03:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["V'yugin", "Vladimir", ""], ["Trunov", "Vladimir", ""]]}, {"id": "1902.10176", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer and Jeff Bilmes", "title": "A Memoization Framework for Scaling Submodular Optimization to Large\n  Scale Problems", "comments": "To Appear in Proc. AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are motivated by large scale submodular optimization problems, where\nstandard algorithms that treat the submodular functions in the \\emph{value\noracle model} do not scale. In this paper, we present a model called the\n\\emph{precomputational complexity model}, along with a unifying memoization\nbased framework, which looks at the specific form of the given submodular\nfunction. A key ingredient in this framework is the notion of a\n\\emph{precomputed statistic}, which is maintained in the course of the\nalgorithms. We show that we can easily integrate this idea into a large class\nof submodular optimization problems including constrained and unconstrained\nsubmodular maximization, minimization, difference of submodular optimization,\noptimization with submodular constraints and several other related optimization\nproblems. Moreover, memoization can be integrated in both discrete and\ncontinuous relaxation flavors of algorithms for these problems. We demonstrate\nthis idea for several commonly occurring submodular functions, and show how the\nprecomputational model provides significant speedups compared to the value\noracle model. Finally, we empirically demonstrate this for large scale machine\nlearning problems of data subset selection and summarization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:22:57 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Iyer", "Rishabh", ""], ["Bilmes", "Jeff", ""]]}, {"id": "1902.10178", "submitter": "Wojciech Samek", "authors": "Sebastian Lapuschkin, Stephan W\\\"aldchen, Alexander Binder, Gr\\'egoire\n  Montavon, Wojciech Samek, Klaus-Robert M\\\"uller", "title": "Unmasking Clever Hans Predictors and Assessing What Machines Really\n  Learn", "comments": "Accepted for publication in Nature Communications", "journal-ref": null, "doi": "10.1038/s41467-019-08987-4", "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current learning machines have successfully solved hard application problems,\nreaching high accuracy and displaying seemingly \"intelligent\" behavior. Here we\napply recent techniques for explaining decisions of state-of-the-art learning\nmachines and analyze various tasks from computer vision and arcade games. This\nshowcases a spectrum of problem-solving behaviors ranging from naive and\nshort-sighted, to well-informed and strategic. We observe that standard\nperformance evaluation metrics can be oblivious to distinguishing these diverse\nproblem solving behaviors. Furthermore, we propose our semi-automated Spectral\nRelevance Analysis that provides a practically effective way of characterizing\nand validating the behavior of nonlinear learning machines. This helps to\nassess whether a learned model indeed delivers reliably for the problem that it\nwas conceived for. Furthermore, our work intends to add a voice of caution to\nthe ongoing excitement about machine intelligence and pledges to evaluate and\njudge some of these recent successes in a more nuanced manner.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:25:11 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Lapuschkin", "Sebastian", ""], ["W\u00e4ldchen", "Stephan", ""], ["Binder", "Alexander", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1902.10189", "submitter": "Jan Steinbrener", "authors": "Konstantin Posch, Jan Steinbrener, J\\\"urgen Pilz", "title": "Variational Inference to Measure Model Uncertainty in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for training deep neural networks in a Bayesian\nway. Classical, i.e. non-Bayesian, deep learning has two major drawbacks both\noriginating from the fact that network parameters are considered to be\ndeterministic. First, model uncertainty cannot be measured thus limiting the\nuse of deep learning in many fields of application and second, training of deep\nneural networks is often hampered by overfitting. The proposed approach uses\nvariational inference to approximate the intractable a posteriori distribution\non basis of a normal prior. The variational density is designed in such a way\nthat the a posteriori uncertainty of the network parameters is represented per\nnetwork layer and depending on the estimated parameter expectation values. This\nway, only a few additional parameters need to be optimized compared to a\nnon-Bayesian network. We apply this Bayesian approach to train and test the\nLeNet architecture on the MNIST dataset. Compared to classical deep learning,\nthe test error is reduced by 15%. In addition, the trained model contains\ninformation about the parameter uncertainty in each layer. We show that this\ninformation can be used to calculate credible intervals for the prediction and\nto optimize the network architecture for a given training data set.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:04:15 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 10:55:19 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Posch", "Konstantin", ""], ["Steinbrener", "Jan", ""], ["Pilz", "J\u00fcrgen", ""]]}, {"id": "1902.10191", "submitter": "Jie Chen", "authors": "Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro\n  Suzumura, Hiroki Kanezashi, Tim Kaler, Tao B. Schardl, Charles E. Leiserson", "title": "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs", "comments": "AAAI 2020. The code is available at https://github.com/IBM/EvolveGCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning resurges as a trending research subject owing\nto the widespread use of deep learning for Euclidean data, which inspire\nvarious creative designs of neural networks in the non-Euclidean domain,\nparticularly graphs. With the success of these graph neural networks (GNN) in\nthe static setting, we approach further practical scenarios where the graph\ndynamically evolves. Existing approaches typically resort to node embeddings\nand use a recurrent neural network (RNN, broadly speaking) to regulate the\nembeddings and learn the temporal dynamics. These methods require the knowledge\nof a node in the full time span (including both training and testing) and are\nless applicable to the frequent change of the node set. In some extreme\nscenarios, the node sets at different time steps may completely differ. To\nresolve this challenge, we propose EvolveGCN, which adapts the graph\nconvolutional network (GCN) model along the temporal dimension without\nresorting to node embeddings. The proposed approach captures the dynamism of\nthe graph sequence through using an RNN to evolve the GCN parameters. Two\narchitectures are considered for the parameter evolution. We evaluate the\nproposed approach on tasks including link prediction, edge classification, and\nnode classification. The experimental results indicate a generally higher\nperformance of EvolveGCN compared with related approaches. The code is\navailable at \\url{https://github.com/IBM/EvolveGCN}.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:07:34 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 03:33:46 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 18:42:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pareja", "Aldo", ""], ["Domeniconi", "Giacomo", ""], ["Chen", "Jie", ""], ["Ma", "Tengfei", ""], ["Suzumura", "Toyotaro", ""], ["Kanezashi", "Hiroki", ""], ["Kaler", "Tim", ""], ["Schardl", "Tao B.", ""], ["Leiserson", "Charles E.", ""]]}, {"id": "1902.10194", "submitter": "Georgi Tinchev", "authors": "Georgi Tinchev, Adrian Penate-Sanchez and Maurice Fallon", "title": "Learning to See the Wood for the Trees: Deep Laser Localization in Urban\n  and Natural Environments on a CPU", "comments": "Accepted for publication at RA-L/ICRA 2019. More info:\n  https://ori.ox.ac.uk/esm-localization", "journal-ref": null, "doi": "10.1109/LRA.2019.2895264", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization in challenging, natural environments such as forests or\nwoodlands is an important capability for many applications from guiding a robot\nnavigating along a forest trail to monitoring vegetation growth with handheld\nsensors. In this work we explore laser-based localization in both urban and\nnatural environments, which is suitable for online applications. We propose a\ndeep learning approach capable of learning meaningful descriptors directly from\n3D point clouds by comparing triplets (anchor, positive and negative examples).\nThe approach learns a feature space representation for a set of segmented point\nclouds that are matched between a current and previous observations. Our\nlearning method is tailored towards loop closure detection resulting in a small\nmodel which can be deployed using only a CPU. The proposed learning method\nwould allow the full pipeline to run on robots with limited computational\npayload such as drones, quadrupeds or UGVs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:13:14 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Tinchev", "Georgi", ""], ["Penate-Sanchez", "Adrian", ""], ["Fallon", "Maurice", ""]]}, {"id": "1902.10197", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, Jian Tang", "title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex\n  Space", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning representations of entities and relations in\nknowledge graphs for predicting missing links. The success of such a task\nheavily relies on the ability of modeling and inferring the patterns of (or\nbetween) the relations. In this paper, we present a new approach for knowledge\ngraph embedding called RotatE, which is able to model and infer various\nrelation patterns including: symmetry/antisymmetry, inversion, and composition.\nSpecifically, the RotatE model defines each relation as a rotation from the\nsource entity to the target entity in the complex vector space. In addition, we\npropose a novel self-adversarial negative sampling technique for efficiently\nand effectively training the RotatE model. Experimental results on multiple\nbenchmark knowledge graphs show that the proposed RotatE model is not only\nscalable, but also able to infer and model various relation patterns and\nsignificantly outperform existing state-of-the-art models for link prediction.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:15:09 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""], ["Nie", "Jian-Yun", ""], ["Tang", "Jian", ""]]}, {"id": "1902.10214", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Wei-Cheng Chang, Youssef Mroueh, Yiming Yang,\n  Barnab\\'as P\\'oczos", "title": "Implicit Kernel Learning", "comments": "In the Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernels are powerful and versatile tools in machine learning and statistics.\nAlthough the notion of universal kernels and characteristic kernels has been\nstudied, kernel selection still greatly influences the empirical performance.\nWhile learning the kernel in a data driven way has been investigated, in this\npaper we explore learning the spectral distribution of kernel via implicit\ngenerative models parametrized by deep neural networks. We called our method\nImplicit Kernel Learning (IKL). The proposed framework is simple to train and\ninference is performed via sampling random Fourier features. We investigate two\napplications of the proposed IKL as examples, including generative adversarial\nnetworks with MMD (MMD GAN) and standard supervised learning. Empirically, MMD\nGAN with IKL outperforms vanilla predefined kernels on both image and text\ngeneration benchmarks; using IKL with Random Kitchen Sinks also leads to\nsubstantial improvement over existing state-of-the-art kernel learning\nalgorithms on popular supervised learning benchmarks. Theory and conditions for\nusing IKL in both applications are also studied as well as connections to\nprevious state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:47:56 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Li", "Chun-Liang", ""], ["Chang", "Wei-Cheng", ""], ["Mroueh", "Youssef", ""], ["Yang", "Yiming", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1902.10222", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad\n  Shafique", "title": "ROMANet: Fine-Grained Reuse-Driven Off-Chip Memory Access Management and\n  Data Organization for Deep Neural Network Accelerators", "comments": "Submitted to the IEEE-TVLSI journal, 14 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling high energy efficiency is crucial for embedded implementations of\ndeep learning. Several studies have shown that the DRAM-based off-chip memory\naccesses are one of the most energy-consuming operations in deep neural network\n(DNN) accelerators, and thereby limit the designs from achieving efficiency\ngains at the full potential. DRAM access energy varies depending upon the\nnumber of accesses required as well as the energy consumed per-access.\nTherefore, searching for a solution towards the minimum DRAM access energy is\nan important optimization problem. Towards this, we propose the ROMANet\nmethodology that aims at reducing the number of memory accesses, by searching\nfor the appropriate data partitioning and scheduling for each layer of a\nnetwork using a design space exploration, based on the knowledge of the\navailable on-chip memory and the data reuse factors. Moreover, ROMANet also\ntargets decreasing the number of DRAM row buffer conflicts and misses, by\nexploiting the DRAM multi-bank burst feature to improve the energy-per-access.\nBesides providing the energy benefits, our proposed DRAM data mapping also\nresults in an increased effective DRAM throughput, which is useful for\nlatency-constraint scenarios. Our experimental results show that the ROMANet\nsaves DRAM access energy by 12% for the AlexNet, by 36% for the VGG-16, and by\n46% for the MobileNet, while also improving the DRAM throughput by 10%, as\ncompared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 20:04:37 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 11:40:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1902.10226", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Nikos D. Sidiropoulos, and Jarvis Haupt", "title": "TensorMap: Lidar-Based Topological Mapping and Localization via Tensor\n  Decompositions", "comments": "5 pages; Index Terms - Topological maps, Lidar, Localization of\n  Autonomous Vehicles, Orthogonal Tucker Decomposition, and Scan-matching", "journal-ref": "2018 IEEE Global Conference on Signal and Information Processing\n  (GlobalSIP)", "doi": "10.1109/GlobalSIP.2018.8646665", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique to develop (and localize in) topological maps from\nlight detection and ranging (Lidar) data. Localizing an autonomous vehicle with\nrespect to a reference map in real-time is crucial for its safe operation.\nOwing to the rich information provided by Lidar sensors, these are emerging as\na promising choice for this task. However, since a Lidar outputs a large amount\nof data every fraction of a second, it is progressively harder to process the\ninformation in real-time. Consequently, current systems have migrated towards\nfaster alternatives at the expense of accuracy. To overcome this inherent\ntrade-off between latency and accuracy, we propose a technique to develop\ntopological maps from Lidar data using the orthogonal Tucker3 tensor\ndecomposition. Our experimental evaluations demonstrate that in addition to\nachieving a high compression ratio as compared to full data, the proposed\ntechnique, $\\textit{TensorMap}$, also accurately detects the position of the\nvehicle in a graph-based representation of a map. We also analyze the\nrobustness of the proposed technique to Gaussian and translational noise, thus\ninitiating explorations into potential applications of tensor decompositions in\nLidar data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 21:46:20 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Sidiropoulos", "Nikos D.", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.10228", "submitter": "Rohit Kate", "authors": "Rohit J. Kate, Noah Pearce, Debesh Mazumdar, Vani Nilakantan", "title": "Continual Prediction from EHR Data for Inpatient Acute Kidney Injury", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute kidney injury (AKI) commonly occurs in hospitalized patients and can\nlead to serious medical complications. In order to optimally predict AKI before\nit develops at any time during a hospital stay, we present a novel framework in\nwhich AKI is continually predicted automatically from EHR data over the entire\nhospital stay instead of at only one particular time. The continual model\npredicts AKI every time a patients AKI-relevant variable changes in the EHR.\nThus the model is not only independent of a particular time for making\npredictions, but it can also leverage the latest values of all the AKI-relevant\npatient variables for making predictions. Using data of 44,691 hospital stays\nof duration longer than 24 hours we evaluated our continual prediction model\nand compared it with the traditional one-time prediction models. Excluding\nhospitals stays in which AKI occurred within 24 hours from admission, the\none-time prediction model predicting at 24 hours from admission obtained area\nunder ROC curve (AUC) of 0.653 while the continual prediction model obtained\nAUC of 0.724. The one-time prediction model that predicts at 24 hours obviously\ncannot predict AKI incidences that occur within 24 hours of admission which\nwhen included in the evaluation reduced its AUC to 0.57. In comparison, the\ncontinual prediction model had AUC of 0.709. The continual prediction model\nalso did better than all other one-time prediction models predicting at other\nfixed times. By being able to take into account the latest values of\nAKI-relevant patient variables and by not being limited to a particular time of\nprediction, the continual prediction model out-performed one-time prediction\nmodels in predicting AKI.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 21:16:24 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Kate", "Rohit J.", ""], ["Pearce", "Noah", ""], ["Mazumdar", "Debesh", ""], ["Nilakantan", "Vani", ""]]}, {"id": "1902.10238", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Xingguo Li, Jineng Ren and Jarvis Haupt", "title": "A Dictionary-Based Generalization of Robust PCA Part II: Applications to\n  Hyperspectral Demixing", "comments": "13 pages; Index Terms - Hyperspectral imaging, Robust-PCA, Dictionary\n  Sparse, Matrix Demixing, Target Localization, and Remote Sensing", "journal-ref": null, "doi": "10.1109/TSP.2020.2977458", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of localizing targets of interest in a hyperspectral\n(HS) image based on their spectral signature(s), by posing the problem as two\ndistinct convex demixing task(s). With applications ranging from remote sensing\nto surveillance, this task of target detection leverages the fact that each\nmaterial/object possesses its own characteristic spectral response, depending\nupon its composition. However, since $\\textit{signatures}$ of different\nmaterials are often correlated, matched filtering-based approaches may not be\napply here. To this end, we model a HS image as a superposition of a low-rank\ncomponent and a dictionary sparse component, wherein the dictionary consists of\nthe $\\textit{a priori}$ known characteristic spectral responses of the target\nwe wish to localize, and develop techniques for two different sparsity\nstructures, resulting from different model assumptions. We also present the\ncorresponding recovery guarantees, leveraging our recent theoretical results\nfrom a companion paper. Finally, we analyze the performance of the proposed\napproach via experimental evaluations on real HS datasets for a classification\ntask, and compare its performance with related techniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 21:42:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Li", "Xingguo", ""], ["Ren", "Jineng", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.10245", "submitter": "Yiren Wang", "authors": "Yiren Wang, Fei Tian, Di He, Tao Qin, ChengXiang Zhai, Tie-Yan Liu", "title": "Non-Autoregressive Machine Translation with Auxiliary Regularization", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new neural machine translation approach, Non-Autoregressive machine\nTranslation (NAT) has attracted attention recently due to its high efficiency\nin inference. However, the high efficiency has come at the cost of not\ncapturing the sequential dependency on the target side of translation, which\ncauses NAT to suffer from two kinds of translation errors: 1) repeated\ntranslations (due to indistinguishable adjacent decoder hidden states), and 2)\nincomplete translations (due to incomplete transfer of source side information\nvia the decoder hidden states).\n  In this paper, we propose to address these two problems by improving the\nquality of decoder hidden representations via two auxiliary regularization\nterms in the training process of an NAT model. First, to make the hidden states\nmore distinguishable, we regularize the similarity between consecutive hidden\nstates based on the corresponding target tokens. Second, to force the hidden\nstates to contain all the information in the source sentence, we leverage the\ndual nature of translation tasks (e.g., English to German and German to\nEnglish) and minimize a backward reconstruction error to ensure that the hidden\nstates of the NAT decoder are able to recover the source side sentence.\nExtensive experiments conducted on several benchmark datasets show that both\nregularization strategies are effective and can alleviate the issues of\nrepeated translations and incomplete translations in NAT models. The accuracy\nof NAT models is therefore improved significantly over the state-of-the-art NAT\nmodels with even better efficiency for inference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:37:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Wang", "Yiren", ""], ["Tian", "Fei", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Zhai", "ChengXiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1902.10246", "submitter": "Xi Zhu", "authors": "Xi Zhu, Mingbin Xu, Hui Jiang", "title": "Fixed-Size Ordinally Forgetting Encoding Based Word Sense Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our method of using fixed-size ordinally forgetting\nencoding (FOFE) to solve the word sense disambiguation (WSD) problem. FOFE\nenables us to encode variable-length sequence of words into a theoretically\nunique fixed-size representation that can be fed into a feed forward neural\nnetwork (FFNN), while keeping the positional information between words. In our\nmethod, a FOFE-based FFNN is used to train a pseudo language model over\nunlabelled corpus, then the pre-trained language model is capable of\nabstracting the surrounding context of polyseme instances in labelled corpus\ninto context embeddings. Next, we take advantage of these context embeddings\ntowards WSD classification. We conducted experiments on several WSD data sets,\nwhich demonstrates that our proposed method can achieve comparable performance\nto that of the state-of-the-art approach at the expense of much lower\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 00:22:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhu", "Xi", ""], ["Xu", "Mingbin", ""], ["Jiang", "Hui", ""]]}, {"id": "1902.10247", "submitter": "Hadi Zare", "authors": "Kayvan Bijari, Hadi Zare, Emad Kebriaei, Hadi Veisi", "title": "Leveraging Deep Graph-Based Text Representation for Sentiment Polarity\n  Applications", "comments": "33 pages, 6 figures, 6 Tables, Accepted for publication in Expert\n  Systems With Applications Journal", "journal-ref": "Expert Systems with Applications Volume 144, 15 April 2020, 113090", "doi": "10.1016/j.eswa.2019.113090", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, machine learning over graph structures has\nmanifested a significant enhancement in text mining applications such as event\ndetection, opinion mining, and news recommendation. One of the primary\nchallenges in this regard is structuring a graph that encodes and encompasses\nthe features of textual data for the effective machine learning algorithm.\nBesides, exploration and exploiting of semantic relations is regarded as a\nprincipal step in text mining applications. However, most of the traditional\ntext mining methods perform somewhat poor in terms of employing such relations.\nIn this paper, we propose a sentence-level graph-based text representation\nwhich includes stop words to consider semantic and term relations. Then, we\nemploy a representation learning approach on the combined graphs of sentences\nto extract the latent and continuous features of the documents. Eventually, the\nlearned features of the documents are fed into a deep neural network for the\nsentiment classification task. The experimental results demonstrate that the\nproposed method substantially outperforms the related sentiment analysis\napproaches based on several benchmark datasets. Furthermore, our method can be\ngeneralized on different datasets without any dependency on pre-trained word\nembeddings.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 16:38:35 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:25:14 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 07:45:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bijari", "Kayvan", ""], ["Zare", "Hadi", ""], ["Kebriaei", "Emad", ""], ["Veisi", "Hadi", ""]]}, {"id": "1902.10248", "submitter": "Daniel Greenfeld", "authors": "Daniel Greenfeld, Meirav Galun, Ron Kimmel, Irad Yavneh, Ronen Basri", "title": "Learning to Optimize Multigrid PDE Solvers", "comments": "Proceedings of the 36th International Conference on Machine Learning\n  (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing fast numerical solvers for partial differential equations (PDEs)\nis crucial for many scientific disciplines. A leading technique for solving\nlarge-scale PDEs is using multigrid methods. At the core of a multigrid solver\nis the prolongation matrix, which relates between different scales of the\nproblem. This matrix is strongly problem-dependent, and its optimal\nconstruction is critical to the efficiency of the solver. In practice, however,\ndevising multigrid algorithms for new problems often poses formidable\nchallenges. In this paper we propose a framework for learning multigrid\nsolvers. Our method learns a (single) mapping from a family of parameterized\nPDEs to prolongation operators. We train a neural network once for the entire\nclass of PDEs, using an efficient and unsupervised loss function. Experiments\non a broad class of 2D diffusion problems demonstrate improved convergence\nrates compared to the widely used Black-Box multigrid scheme, suggesting that\nour method successfully learned rules for constructing prolongation matrices.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 09:12:54 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:30:54 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 21:49:12 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Greenfeld", "Daniel", ""], ["Galun", "Meirav", ""], ["Kimmel", "Ron", ""], ["Yavneh", "Irad", ""], ["Basri", "Ronen", ""]]}, {"id": "1902.10250", "submitter": "Justin Fu", "authors": "Justin Fu, Aviral Kumar, Matthew Soh, Sergey Levine", "title": "Diagnosing Bottlenecks in Deep Q-learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning methods represent a commonly used class of algorithms in\nreinforcement learning: they are generally efficient and simple, and can be\ncombined readily with function approximators for deep reinforcement learning\n(RL). However, the behavior of Q-learning methods with function approximation\nis poorly understood, both theoretically and empirically. In this work, we aim\nto experimentally investigate potential issues in Q-learning, by means of a\n\"unit testing\" framework where we can utilize oracles to disentangle sources of\nerror. Specifically, we investigate questions related to function\napproximation, sampling error and nonstationarity, and where available, verify\nif trends found in oracle settings hold true with modern deep RL methods. We\nfind that large neural network architectures have many benefits with regards to\nlearning stability; offer several practical compensations for overfitting; and\ndevelop a novel sampling method based on explicitly compensating for function\napproximation error that yields fair improvement on high-dimensional continuous\ncontrol domains.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 22:17:47 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Fu", "Justin", ""], ["Kumar", "Aviral", ""], ["Soh", "Matthew", ""], ["Levine", "Sergey", ""]]}, {"id": "1902.10275", "submitter": "Ruoxi Jia", "authors": "Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nick Hynes,\n  Nezihe Merve Gurel, Bo Li, Ce Zhang, Dawn Song, Costas Spanos", "title": "Towards Efficient Data Valuation Based on the Shapley Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"How much is my data worth?\" is an increasingly common question posed by\norganizations and individuals alike. An answer to this question could allow,\nfor instance, fairly distributing profits among multiple data contributors and\ndetermining prospective compensation when data breaches happen. In this paper,\nwe study the problem of data valuation by utilizing the Shapley value, a\npopular notion of value which originated in coopoerative game theory. The\nShapley value defines a unique payoff scheme that satisfies many desiderata for\nthe notion of data value. However, the Shapley value often requires exponential\ntime to compute. To meet this challenge, we propose a repertoire of efficient\nalgorithms for approximating the Shapley value. We also demonstrate the value\nof each training instance for various benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:22:43 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 22:24:37 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 01:39:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jia", "Ruoxi", ""], ["Dao", "David", ""], ["Wang", "Boxin", ""], ["Hubis", "Frances Ann", ""], ["Hynes", "Nick", ""], ["Gurel", "Nezihe Merve", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""], ["Song", "Dawn", ""], ["Spanos", "Costas", ""]]}, {"id": "1902.10284", "submitter": "Qingna Li", "authors": "Panpan Yu and Qingna Li", "title": "Ordinal Distance Metric Learning with MDS for Image Ranking", "comments": null, "journal-ref": "Asia-Pacific Journal of Operational Research 35 (2018)", "doi": "10.1142/S0217595918500070", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image ranking is to rank images based on some known ranked images. In this\npaper, we propose an improved linear ordinal distance metric learning approach\nbased on the linear distance metric learning model. By decomposing the distance\nmetric $A$ as $L^TL$, the problem can be cast as looking for a linear map\nbetween two sets of points in different spaces, meanwhile maintaining some data\nstructures. The ordinal relation of the labels can be maintained via classical\nmultidimensional scaling, a popular tool for dimension reduction in statistics.\nA least squares fitting term is then introduced to the cost function, which can\nalso maintain the local data structure. The resulting model is an unconstrained\nproblem, and can better fit the data structure. Extensive numerical results\ndemonstrate the improvement of the new approach over the linear distance metric\nlearning model both in speed and ranking performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:53:22 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Yu", "Panpan", ""], ["Li", "Qingna", ""]]}, {"id": "1902.10286", "submitter": "Alexander D'Amour", "authors": "Alexander D'Amour", "title": "On Multi-Cause Causal Inference with Unobserved Confounding:\n  Counterexamples, Impossibility, and Alternatives", "comments": "Accepted to AISTATS 2019. Since last revision: corrected constant\n  factors in linear gaussian example; fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unobserved confounding is a central barrier to drawing causal inferences from\nobservational data. Several authors have recently proposed that this barrier\ncan be overcome in the case where one attempts to infer the effects of several\nvariables simultaneously. In this paper, we present two simple, analytical\ncounterexamples that challenge the general claims that are central to these\napproaches. In addition, we show that nonparametric identification is\nimpossible in this setting. We discuss practical implications, and suggest\nalternatives to the methods that have been proposed so far in this line of\nwork: using proxy variables and shifting focus to sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 00:55:13 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 16:04:44 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 16:29:52 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 17:48:23 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["D'Amour", "Alexander", ""]]}, {"id": "1902.10294", "submitter": "Rui Shu", "authors": "Rui Shu, Hung H. Bui, Jay Whang, Stefano Ermon", "title": "Training Variational Autoencoders with Buffered Stochastic Variational\n  Inference", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition network in deep latent variable models such as variational\nautoencoders (VAEs) relies on amortized inference for efficient posterior\napproximation that can scale up to large datasets. However, this technique has\nalso been demonstrated to select suboptimal variational parameters, often\nresulting in considerable additional error called the amortization gap. To\nclose the amortization gap and improve the training of the generative model,\nrecent works have introduced an additional refinement step that applies\nstochastic variational inference (SVI) to improve upon the variational\nparameters returned by the amortized inference model. In this paper, we propose\nthe Buffered Stochastic Variational Inference (BSVI), a new refinement\nprocedure that makes use of SVI's sequence of intermediate variational proposal\ndistributions and their corresponding importance weights to construct a new\ngeneralized importance-weighted lower bound. We demonstrate empirically that\ntraining the variational autoencoders with BSVI consistently out-performs SVI,\nyielding an improved training procedure for VAEs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 01:34:57 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Shu", "Rui", ""], ["Bui", "Hung H.", ""], ["Whang", "Jay", ""], ["Ermon", "Stefano", ""]]}, {"id": "1902.10297", "submitter": "Joshua Michalenko", "authors": "Joshua J. Michalenko, Ameesh Shah, Abhinav Verma, Richard G. Baraniuk,\n  Swarat Chaudhuri, Ankit B. Patel", "title": "Representing Formal Languages: A Comparison Between Finite Automata and\n  Recurrent Neural Networks", "comments": "15 Pages, 13 Figures, Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the internal representations that a recurrent neural network\n(RNN) uses while learning to recognize a regular formal language. Specifically,\nwe train a RNN on positive and negative examples from a regular language, and\nask if there is a simple decoding function that maps states of this RNN to\nstates of the minimal deterministic finite automaton (MDFA) for the language.\nOur experiments show that such a decoding function indeed exists, and that it\nmaps states of the RNN not to MDFA states, but to states of an {\\em\nabstraction} obtained by clustering small sets of MDFA states into\n\"superstates\". A qualitative analysis reveals that the abstraction often has a\nsimple interpretation. Overall, the results suggest a strong structural\nrelationship between internal representations used by RNNs and finite automata,\nand explain the well-known ability of RNNs to recognize formal grammatical\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 01:45:01 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Michalenko", "Joshua J.", ""], ["Shah", "Ameesh", ""], ["Verma", "Abhinav", ""], ["Baraniuk", "Richard G.", ""], ["Chaudhuri", "Swarat", ""], ["Patel", "Ankit B.", ""]]}, {"id": "1902.10298", "submitter": "Amir Gholami", "authors": "Amir Gholami and Kurt Keutzer and George Biros", "title": "ANODE: Unconditionally Accurate Memory-Efficient Gradients for Neural\n  ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual neural networks can be viewed as the forward Euler discretization of\nan Ordinary Differential Equation (ODE) with a unit time step. This has\nrecently motivated researchers to explore other discretization approaches and\ntrain ODE based networks. However, an important challenge of neural ODEs is\ntheir prohibitive memory cost during gradient backpropogation. Recently a\nmethod proposed in [8], claimed that this memory overhead can be reduced from\nO(LN_t), where N_t is the number of time steps, down to O(L) by solving forward\nODE backwards in time, where L is the depth of the network. However, we will\nshow that this approach may lead to several problems: (i) it may be numerically\nunstable for ReLU/non-ReLU activations and general convolution operators, and\n(ii) the proposed optimize-then-discretize approach may lead to divergent\ntraining due to inconsistent gradients for small time step sizes. We discuss\nthe underlying problems, and to address them we propose ANODE, an Adjoint based\nNeural ODE framework which avoids the numerical instability related problems\nnoted above, and provides unconditionally accurate gradients. ANODE has a\nmemory footprint of O(L) + O(N_t), with the same computational cost as\nreversing ODE solve. We furthermore, discuss a memory efficient algorithm which\ncan further reduce this footprint with a trade-off of additional computational\ncost. We show results on Cifar-10/100 datasets using ResNet and SqueezeNext\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 01:48:32 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 06:25:32 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 17:54:01 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gholami", "Amir", ""], ["Keutzer", "Kurt", ""], ["Biros", "George", ""]]}, {"id": "1902.10301", "submitter": "Alireza Sadeghi", "authors": "Alireza Sadeghi, Gang Wang, Georgios B. Giannakis", "title": "Deep Reinforcement Learning for Adaptive Caching in Hierarchical Content\n  Delivery Networks", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching is envisioned to play a critical role in next-generation content\ndelivery infrastructure, cellular networks, and Internet architectures. By\nsmartly storing the most popular contents at the storage-enabled network\nentities during off-peak demand instances, caching can benefit both network\ninfrastructure as well as end users, during on-peak periods. In this context,\ndistributing the limited storage capacity across network entities calls for\ndecentralized caching schemes. Many practical caching systems involve a parent\ncaching node connected to multiple leaf nodes to serve user file requests. To\nmodel the two-way interactive influence between caching decisions at the parent\nand leaf nodes, a reinforcement learning framework is put forth. To handle the\nlarge continuous state space, a scalable deep reinforcement learning approach\nis pursued. The novel approach relies on a deep Q-network to learn the\nQ-function, and thus the optimal caching policy, in an online fashion.\nReinforcing the parent node with ability to learn-and-adapt to unknown policies\nof leaf nodes as well as spatio-temporal dynamic evolution of file requests,\nresults in remarkable caching performance, as corroborated through numerical\ntests.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 01:58:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 00:11:28 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sadeghi", "Alireza", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1902.10307", "submitter": "Tyler Derr", "authors": "Tyler Derr, Hamid Karimi, Xiaorui Liu, Jiejun Xu, Jiliang Tang", "title": "Deep Adversarial Network Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network alignment, in general, seeks to discover the hidden underlying\ncorrespondence between nodes across two (or more) networks when given their\nnetwork structure. However, most existing network alignment methods have added\nassumptions of additional constraints to guide the alignment, such as having a\nset of seed node-node correspondences across the networks or the existence of\nside-information. Instead, we seek to develop a general network alignment\nalgorithm that makes no additional assumptions. Recently, network embedding has\nproven effective in many network analysis tasks, but embeddings of different\nnetworks are not aligned. Thus, we present our Deep Adversarial Network\nAlignment (DANA) framework that first uses deep adversarial learning to\ndiscover complex mappings for aligning the embedding distributions of the two\nnetworks. Then, using our learned mapping functions, DANA performs an efficient\nnearest neighbor node alignment. We perform experiments on real world datasets\nto show the effectiveness of our framework for first aligning the graph\nembedding distributions and then discovering node alignments that outperform\nexisting methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 02:14:42 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Derr", "Tyler", ""], ["Karimi", "Hamid", ""], ["Liu", "Xiaorui", ""], ["Xu", "Jiejun", ""], ["Tang", "Jiliang", ""]]}, {"id": "1902.10319", "submitter": "Eric Liang", "authors": "Eric Liang, Hang Zhu, Xin Jin, Ion Stoica", "title": "Neural Packet Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet classification is a fundamental problem in computer networking. This\nproblem exposes a hard tradeoff between the computation and state complexity,\nwhich makes it particularly challenging. To navigate this tradeoff, existing\nsolutions rely on complex hand-tuned heuristics, which are brittle and hard to\noptimize. In this paper, we propose a deep reinforcement learning (RL) approach\nto solve the packet classification problem. There are several characteristics\nthat make this problem a good fit for Deep RL. First, many of the existing\nsolutions are iteratively building a decision tree by splitting nodes in the\ntree. Second, the effects of these actions (e.g., splitting nodes) can only be\nevaluated once we are done with building the tree. These two characteristics\nare naturally captured by the ability of RL to take actions that have sparse\nand delayed rewards. Third, it is computationally efficient to generate data\ntraces and evaluate decision trees, which alleviate the notoriously high sample\ncomplexity problem of Deep RL algorithms. Our solution, NeuroCuts, uses\nsuccinct representations to encode state and action space, and efficiently\nexplore candidate decision trees to optimize for a global objective. It\nproduces compact decision trees optimized for a specific set of rules and a\ngiven performance metric, such as classification time, memory footprint, or a\ncombination of the two. Evaluation on ClassBench shows that NeuroCuts\noutperforms existing hand-crafted algorithms in classification time by 18% at\nthe median, and reduces both time and memory footprint by up to 3x.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 03:24:40 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Liang", "Eric", ""], ["Zhu", "Hang", ""], ["Jin", "Xin", ""], ["Stoica", "Ion", ""]]}, {"id": "1902.10327", "submitter": "Aleksey Buzmakov", "authors": "Aleksey Buzmakov", "title": "Machine learning for subgroup discovery under treatment effect", "comments": "32 pages, in Russian, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical tasks it is needed to estimate an effect of treatment on\nindividual level. For example, in medicine it is essential to determine the\npatients that would benefit from a certain medicament. In marketing, knowing\nthe persons that are likely to buy a new product would reduce the amount of\nspam. In this chapter, we review the methods to estimate an individual\ntreatment effect from a randomized trial, i.e., an experiment when a part of\nindividuals receives a new treatment, while the others do not. Finally, it is\nshown that new efficient methods are needed in this domain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 04:41:34 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Buzmakov", "Aleksey", ""]]}, {"id": "1902.10336", "submitter": "Richeng Jin", "authors": "Richeng Jin, Xiaofan He and Huaiyu Dai", "title": "Distributed Byzantine Tolerant Stochastic Gradient Descent in the Era of\n  Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in sensor technologies and smart devices enable the\ncollaborative collection of a sheer volume of data from multiple information\nsources. As a promising tool to efficiently extract useful information from\nsuch big data, machine learning has been pushed to the forefront and seen great\nsuccess in a wide range of relevant areas such as computer vision, health care,\nand financial market analysis. To accommodate the large volume of data, there\nis a surge of interest in the design of distributed machine learning, among\nwhich stochastic gradient descent (SGD) is one of the mostly adopted methods.\nNonetheless, distributed machine learning methods may be vulnerable to\nByzantine attack, in which the adversary can deliberately share falsified\ninformation to disrupt the intended machine learning procedures. Therefore, two\nasynchronous Byzantine tolerant SGD algorithms are proposed in this work, in\nwhich the honest collaborative workers are assumed to store the model\nparameters derived from their own local data and use them as the ground truth.\nThe proposed algorithms can deal with an arbitrary number of Byzantine\nattackers and are provably convergent. Simulation results based on a real-world\ndataset are presented to verify the theoretical results and demonstrate the\neffectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 05:39:06 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 06:15:13 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 19:48:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Jin", "Richeng", ""], ["He", "Xiaofan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "1902.10339", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Wang", "title": "How Large a Vocabulary Does Text Classification Need? A Variational\n  Approach to Vocabulary Selection", "comments": "Accepted to NAACL 2019, 11 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development in deep learning, deep neural networks have been\nwidely adopted in many real-life natural language applications. Under deep\nneural networks, a pre-defined vocabulary is required to vectorize text inputs.\nThe canonical approach to select pre-defined vocabulary is based on the word\nfrequency, where a threshold is selected to cut off the long tail distribution.\nHowever, we observed that such simple approach could easily lead to under-sized\nvocabulary or over-sized vocabulary issues. Therefore, we are interested in\nunderstanding how the end-task classification accuracy is related to the\nvocabulary size and what is the minimum required vocabulary size to achieve a\nspecific performance. In this paper, we provide a more sophisticated\nvariational vocabulary dropout (VVD) based on variational dropout to perform\nvocabulary selection, which can intelligently select the subset of the\nvocabulary to achieve the required performance. To evaluate different\nalgorithms on the newly proposed vocabulary selection problem, we propose two\nnew metrics: Area Under Accuracy-Vocab Curve and Vocab Size under X\\% Accuracy\nDrop. Through extensive experiments on various NLP classification tasks, our\nvariational framework is shown to significantly outperform the frequency-based\nand other selection baselines on these metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 05:57:13 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 19:42:22 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 19:59:53 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 20:07:26 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Chen", "Wenhu", ""], ["Su", "Yu", ""], ["Shen", "Yilin", ""], ["Chen", "Zhiyu", ""], ["Yan", "Xifeng", ""], ["Wang", "William", ""]]}, {"id": "1902.10350", "submitter": "Evgenii Tsymbalov", "authors": "Evgenii Tsymbalov, Sergei Makarychev, Alexander Shapeev, Maxim Panov", "title": "Deeper Connections between Neural Networks and Gaussian Processes\n  Speed-up Active Learning", "comments": null, "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence {IJCAI-19}, 2019", "doi": "10.24963/ijcai.2019/499", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning methods for neural networks are usually based on greedy\ncriteria which ultimately give a single new design point for the evaluation.\nSuch an approach requires either some heuristics to sample a batch of design\npoints at one active learning iteration, or retraining the neural network after\nadding each data point, which is computationally inefficient. Moreover,\nuncertainty estimates for neural networks sometimes are overconfident for the\npoints lying far from the training sample. In this work we propose to\napproximate Bayesian neural networks (BNN) by Gaussian processes, which allows\nus to update the uncertainty estimates of predictions efficiently without\nretraining the neural network, while avoiding overconfident uncertainty\nprediction for out-of-sample points. In a series of experiments on real-world\ndata including large-scale problems of chemical and physical modeling, we show\nsuperiority of the proposed approach over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 06:22:28 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Tsymbalov", "Evgenii", ""], ["Makarychev", "Sergei", ""], ["Shapeev", "Alexander", ""], ["Panov", "Maxim", ""]]}, {"id": "1902.10365", "submitter": "Masoud Badiei Khuzani", "authors": "Masoud Badiei Khuzani, Hongyi Ren, Md Tauhidul Islam, Lei Xing", "title": "A Distributionally Robust Optimization Method for Adversarial Multiple\n  Kernel Learning", "comments": "Major revision. The title and abstract have been updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data-driven method to learn a mixture of multiple kernels\nwith random features that is certifiabaly robust against adverserial inputs.\nSpecifically, we consider a distributionally robust optimization of the\nkernel-target alignment with respect to the distribution of training samples\nover a distributional ball defined by the Kullback-Leibler (KL) divergence. The\ndistributionally robust optimization problem can be recast as a min-max\noptimization whose objective function includes a log-sum term. We develop a\nmini-batch biased stochastic primal-dual proximal method to solve the min-max\noptimization. To debias the minibatch algorithm, we use the Gumbel perturbation\ntechnique to estimate the log-sum term. We establish theoretical guarantees for\nthe performance of the proposed multiple kernel learning method. In particular,\nwe prove the consistency, asymptotic normality, stochastic equicontinuity, and\nthe minimax rate of the empirical estimators. In addition, based on the notion\nof Rademacher and Gaussian complexities, we establish distributionally robust\ngeneralization bounds that are tighter than previous known bounds. More\nspecifically, we leverage matrix concentration inequalities to establish\ndistributionally robust generalization bounds. We validate our kernel learning\napproach for classification with the kernel SVMs on synthetic dataset generated\nby sampling multvariate Gaussian distributions with differernt variance\nstructures. We also apply our kernel learning approach to the MNIST data-set\nand evaluate its robustness to perturbation of input images under different\nadversarial models. More specifically, we examine the robustness of the\nproposed kernel model selection technique against FGSM, PGM, C\\&W, and DDN\nadversarial perturbations, and compare its performance with alternative\nstate-of-the-art multiple kernel learning paradigms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:24:03 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 23:13:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Khuzani", "Masoud Badiei", ""], ["Ren", "Hongyi", ""], ["Islam", "Md Tauhidul", ""], ["Xing", "Lei", ""]]}, {"id": "1902.10375", "submitter": "Tomoyuki Obuchi", "authors": "Tomoyuki Obuchi and Ayaka Sakata", "title": "Cross validation in sparse linear regression with piecewise continuous\n  nonconvex penalties and its acceleration", "comments": "33 pages, 18 figures. MATLAB codes implementing the proposed method\n  are distributed in\n  https://github.com/T-Obuchi/SLRpackage_AcceleratedCV_matlab", "journal-ref": null, "doi": "10.1088/1751-8121/ab3e89", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the signal reconstruction performance of sparse linear\nregression in the presence of noise when piecewise continuous nonconvex\npenalties are used. Among such penalties, we focus on the SCAD penalty. The\ncontributions of this study are three-fold: We first present a theoretical\nanalysis of a typical reconstruction performance, using the replica method,\nunder the assumption that each component of the design matrix is given as an\nindependent and identically distributed (i.i.d.) Gaussian variable. This\nclarifies the superiority of the SCAD estimator compared with $\\ell_1$ in a\nwide parameter range, although the nonconvex nature of the penalty tends to\nlead to solution multiplicity in certain regions. This multiplicity is shown to\nbe connected to replica symmetry breaking in the spin-glass theory. We also\nshow that the global minimum of the mean square error between the estimator and\nthe true signal is located in the replica symmetric phase. Second, we develop\nan approximate formula efficiently computing the cross-validation error without\nactually conducting the cross-validation, which is also applicable to the\nnon-i.i.d. design matrices. It is shown that this formula is only applicable to\nthe unique solution region and tends to be unstable in the multiple solution\nregion. We implement instability detection procedures, which allows the\napproximate formula to stand alone and resultantly enables us to draw phase\ndiagrams for any specific dataset. Third, we propose an annealing procedure,\ncalled nonconvexity annealing, to obtain the solution path efficiently.\nNumerical simulations are conducted on simulated datasets to examine these\nresults to verify the theoretical results consistency and the approximate\nformula efficiency. Another numerical experiment on a real-world dataset is\nconducted; its results are consistent with those of earlier studies using the\n$\\ell_0$ formulation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:04:52 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 05:48:10 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Obuchi", "Tomoyuki", ""], ["Sakata", "Ayaka", ""]]}, {"id": "1902.10379", "submitter": "Hao Zhang", "authors": "Hao Zhang, Xiuyan Yang and Jianwei Ma", "title": "Can learning from natural image denoising be used for seismic data\n  interpolation?", "comments": "26 pages, 7 figures, 2 tables", "journal-ref": "Geophysics 85(4): WA115-WA136, 2020", "doi": "10.1190/GEO2019-0243.1", "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convolutional neural network (CNN) denoising based method for\nseismic data interpolation. It provides a simple and efficient way to break\nthough the lack problem of geophysical training labels that are often required\nby deep learning methods. The new method consists of two steps: (1) Train a set\nof CNN denoisers from natural image clean-noisy pairs to learn denoising; (2)\nIntegrate the trained CNN denoisers into project onto convex set (POCS)\nframework to perform seismic data interpolation. The method alleviates the\ndemanding of seismic big data with similar features as applications of\nend-to-end deep learning on seismic data interpolation. Additionally, the\nproposed method is flexible for many cases of traces missing because missing\ncases are not involved in the training step, and thus it is of plug-and-play\nnature. These indicate the high generalizability of our approach and the\nreduction of the need of the problem-specific training. Primary results on\nsynthetic and field data show promising interpolation performances of the\npresented CNN-POCS method in terms of signal-to-noise ratio, de-aliasing and\nweak-feature reconstruction, in comparison with traditional $f$-$x$ prediction\nfiltering and curvelet transform based POCS methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:16:50 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 21:06:12 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 03:12:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Hao", ""], ["Yang", "Xiuyan", ""], ["Ma", "Jianwei", ""]]}, {"id": "1902.10385", "submitter": "Sebastiaan Koning", "authors": "Sebastiaan Koning, Caspar Greeven and Eric Postma", "title": "Reducing Artificial Neural Network Complexity: A Case Study on Exoplanet\n  Detection", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their successes in the field of self-learning AI, Convolutional\nNeural Networks (CNNs) suffer from having too many trainable parameters,\nimpacting computational performance. Several approaches have been proposed to\nreduce the number of parameters in the visual domain, the Inception\narchitecture [Szegedy et al., 2016] being a prominent example. This raises the\nquestion whether the number of trainable parameters in CNNs can also be reduced\nfor 1D inputs, such as time-series data, without incurring a substantial loss\nin classification performance. We propose and examine two methods for\ncomplexity reduction in AstroNet [Shallue & Vanderburg, 2018], a CNN for\nautomatic classification of time-varying brightness data of stars to detect\nexoplanets. The first method makes only a tactical reduction of layers in\nAstroNet while the second method also modifies the original input data by means\nof a Gaussian pyramid. We conducted our experiments with various degrees of\ndropout regularization. Our results show only a non-substantial loss in\naccuracy compared to the original AstroNet, while reducing training time up to\n85 percent. These results show potential for similar reductions in other CNN\napplications while largely retaining accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 08:34:45 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Koning", "Sebastiaan", ""], ["Greeven", "Caspar", ""], ["Postma", "Eric", ""]]}, {"id": "1902.10402", "submitter": "Bilal Abu-Salih", "authors": "Bilal Abu-Salih, Bushra Bremie, Pornpit Wongthongtham, Kevin Duan,\n  Tomayess Issa, Kit Yan Chan, Mohammad Alhabashneh, Teshreen Albtoush,\n  Sulaiman Alqahtani, Abdullah Alqahtani, Muteeb Alahmari, Naser Alshareef,\n  Abdulaziz Albahlal", "title": "Social Credibility Incorporating Semantic Analysis and Machine Learning:\n  A Survey of the State-of-the-Art and Future Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wealth of Social Big Data (SBD) represents a unique opportunity for\norganisations to obtain the excessive use of such data abundance to increase\ntheir revenues. Hence, there is an imperative need to capture, load, store,\nprocess, analyse, transform, interpret, and visualise such manifold social\ndatasets to develop meaningful insights that are specific to an application\ndomain. This paper lays the theoretical background by introducing the\nstate-of-the-art literature review of the research topic. This is associated\nwith a critical evaluation of the current approaches, and fortified with\ncertain recommendations indicated to bridge the research gap.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:10:11 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Abu-Salih", "Bilal", ""], ["Bremie", "Bushra", ""], ["Wongthongtham", "Pornpit", ""], ["Duan", "Kevin", ""], ["Issa", "Tomayess", ""], ["Chan", "Kit Yan", ""], ["Alhabashneh", "Mohammad", ""], ["Albtoush", "Teshreen", ""], ["Alqahtani", "Sulaiman", ""], ["Alqahtani", "Abdullah", ""], ["Alahmari", "Muteeb", ""], ["Alshareef", "Naser", ""], ["Albahlal", "Abdulaziz", ""]]}, {"id": "1902.10404", "submitter": "{\\L}ukasz Maziarka", "authors": "Sylwester Klocek, {\\L}ukasz Maziarka, Maciej Wo{\\l}czyk, Jacek Tabor,\n  Jakub Nowak, Marek \\'Smieja", "title": "Hypernetwork functional image representation", "comments": null, "journal-ref": "Artificial Neural Networks and Machine Learning -- ICANN 2019:\n  Workshop and Special Sessions", "doi": "10.1007/978-3-030-30493-5_48", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the human way of memorizing images we introduce their functional\nrepresentation, where an image is represented by a neural network. For this\npurpose, we construct a hypernetwork which takes an image and returns weights\nto the target network, which maps point from the plane (representing positions\nof the pixel) into its corresponding color in the image. Since the obtained\nrepresentation is continuous, one can easily inspect the image at various\nresolutions and perform on it arbitrary continuous operations. Moreover, by\ninspecting interpolations we show that such representation has some properties\ncharacteristic to generative models. To evaluate the proposed mechanism\nexperimentally, we apply it to image super-resolution problem. Despite using a\nsingle model for various scaling factors, we obtained results comparable to\nexisting super-resolution methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:12:29 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 21:44:12 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 13:11:41 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Klocek", "Sylwester", ""], ["Maziarka", "\u0141ukasz", ""], ["Wo\u0142czyk", "Maciej", ""], ["Tabor", "Jacek", ""], ["Nowak", "Jakub", ""], ["\u015amieja", "Marek", ""]]}, {"id": "1902.10407", "submitter": "Ibrahim Jubran", "authors": "Ibrahim Jubran, David Cohn, Dan Feldman", "title": "Provable Approximations for Constrained $\\ell_p$ Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\ell_p$ linear regression problem is to minimize $f(x)=||Ax-b||_p$ over\n$x\\in\\mathbb{R}^d$, where $A\\in\\mathbb{R}^{n\\times d}$, $b\\in \\mathbb{R}^n$,\nand $p>0$. To avoid overfitting and bound $||x||_2$, the constrained $\\ell_p$\nregression minimizes $f(x)$ over every unit vector $x\\in\\mathbb{R}^d$. This\nmakes the problem non-convex even for the simplest case $d=p=2$. Instead, ridge\nregression is used to minimize the Lagrange form $f(x)+\\lambda ||x||_2$ over\n$x\\in\\mathbb{R}^d$, which yields a convex problem in the price of calibrating\nthe regularization parameter $\\lambda>0$. We provide the first provable\nconstant factor approximation algorithm that solves the constrained $\\ell_p$\nregression directly, for every constant $p,d\\geq 1$. Using core-sets, its\nrunning time is $O(n \\log n)$ including extensions for streaming and\ndistributed (big) data. In polynomial time, it can handle outliers, $p\\in\n(0,1)$ and minimize $f(x)$ over every $x$ and permutation of rows in $A$.\nExperimental results are also provided, including open source and comparison to\nexisting software.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:24:25 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Jubran", "Ibrahim", ""], ["Cohn", "David", ""], ["Feldman", "Dan", ""]]}, {"id": "1902.10409", "submitter": "Geewook Kim", "authors": "Geewook Kim and Akifumi Okuno and Kazuki Fukui and Hidetoshi\n  Shimodaira", "title": "Representation Learning with Weighted Inner Product for Universal\n  Approximation of General Similarities", "comments": "8 pages, 2 figures, IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\textit{weighted inner product similarity}$ (WIPS) for neural\nnetwork-based graph embedding. In addition to the parameters of neural\nnetworks, we optimize the weights of the inner product by allowing positive and\nnegative values. Despite its simplicity, WIPS can approximate arbitrary general\nsimilarities including positive definite, conditionally positive definite, and\nindefinite kernels. WIPS is free from similarity model selection, since it can\nlearn any similarity models such as cosine similarity, negative Poincar\\'e\ndistance and negative Wasserstein distance. Our experiments show that the\nproposed method can learn high-quality distributed representations of nodes\nfrom real datasets, leading to an accurate approximation of similarities as\nwell as high performance in inductive tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:39:18 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 06:25:01 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kim", "Geewook", ""], ["Okuno", "Akifumi", ""], ["Fukui", "Kazuki", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1902.10416", "submitter": "Pierre Stock", "authors": "Pierre Stock, Benjamin Graham, R\\'emi Gribonval and Herv\\'e J\\'egou", "title": "Equi-normalization of Neural Networks", "comments": "ICLR 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are over-parametrized. In particular, each rectified\nlinear hidden unit can be modified by a multiplicative factor by adjusting\ninput and output weights, without changing the rest of the network. Inspired by\nthe Sinkhorn-Knopp algorithm, we introduce a fast iterative method for\nminimizing the L2 norm of the weights, equivalently the weight decay\nregularizer. It provably converges to a unique solution. Interleaving our\nalgorithm with SGD during training improves the test accuracy. For small\nbatches, our approach offers an alternative to batch-and group-normalization on\nCIFAR-10 and ImageNet with a ResNet-18.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:52:43 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Stock", "Pierre", ""], ["Graham", "Benjamin", ""], ["Gribonval", "R\u00e9mi", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1902.10424", "submitter": "Gabriel Eilertsen", "authors": "Gabriel Eilertsen, Rafa{\\l} K. Mantiuk, Jonas Unger", "title": "Single-frame Regularization for Temporally Stable CNNs", "comments": "Project web: http://hdrv.org/hdrcnn/cvpr2019/", "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2019", "doi": "10.1109/CVPR.2019.01143", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) can model complicated non-linear\nrelations between images. However, they are notoriously sensitive to small\nchanges in the input. Most CNNs trained to describe image-to-image mappings\ngenerate temporally unstable results when applied to video sequences, leading\nto flickering artifacts and other inconsistencies over time. In order to use\nCNNs for video material, previous methods have relied on estimating dense\nframe-to-frame motion information (optical flow) in the training and/or the\ninference phase, or by exploring recurrent learning structures. We take a\ndifferent approach to the problem, posing temporal stability as a\nregularization of the cost function. The regularization is formulated to\naccount for different types of motion that can occur between frames, so that\ntemporally stable CNNs can be trained without the need for video material or\nexpensive motion estimation. The training can be performed as a fine-tuning\noperation, without architectural modifications of the CNN. Our evaluation shows\nthat the training strategy leads to large improvements in temporal smoothness.\nMoreover, for small datasets the regularization can help in boosting the\ngeneralization performance to a much larger extent than what is possible with\nna\\\"ive augmentation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 10:01:49 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 05:39:31 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Eilertsen", "Gabriel", ""], ["Mantiuk", "Rafa\u0142 K.", ""], ["Unger", "Jonas", ""]]}, {"id": "1902.10433", "submitter": "Alexander Korotin", "authors": "Alexander Korotin and Vladimir V'yugin and Evgeny Burnaev", "title": "Adaptive Hedging under Delayed Feedback", "comments": "38 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article is devoted to investigating the application of hedging strategies\nto online expert weight allocation under delayed feedback. As the main result,\nwe develop the General Hedging algorithm $\\mathcal{G}$ based on the exponential\nreweighing of experts' losses. We build the artificial probabilistic framework\nand use it to prove the adversarial loss bounds for the algorithm $\\mathcal{G}$\nin the delayed feedback setting. The designed algorithm $\\mathcal{G}$ can be\napplied to both countable and continuous sets of experts. We also show how\nalgorithm $\\mathcal{G}$ extends classical Hedge (Multiplicative Weights) and\nadaptive Fixed Share algorithms to the delayed feedback and derive their regret\nbounds for the delayed setting by using our main result.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 10:18:06 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 14:25:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Korotin", "Alexander", ""], ["V'yugin", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1902.10445", "submitter": "Kerstin Beer", "authors": "Kerstin Beer and Dmytro Bondarenko and Terry Farrelly and Tobias J.\n  Osborne and Robert Salzmann and Ramona Wolf", "title": "Efficient Learning for Deep Quantum Neural Networks", "comments": null, "journal-ref": "Nat. Commun. 11, 808 (2020)", "doi": "10.1038/s41467-020-14454-2", "report-no": null, "categories": "quant-ph cs.GT cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks enjoy widespread success in both research and industry and,\nwith the imminent advent of quantum technology, it is now a crucial challenge\nto design quantum neural networks for fully quantum learning tasks. Here we\npropose the use of quantum neurons as a building block for quantum feed-forward\nneural networks capable of universal quantum computation. We describe the\nefficient training of these networks using the fidelity as a cost function and\nprovide both classical and efficient quantum implementations. Our method allows\nfor fast optimisation with reduced memory requirements: the number of qudits\nrequired scales with only the width, allowing the optimisation of deep\nnetworks. We benchmark our proposal for the quantum task of learning an unknown\nunitary and find remarkable generalisation behaviour and a striking robustness\nto noisy training data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 10:39:25 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Beer", "Kerstin", ""], ["Bondarenko", "Dmytro", ""], ["Farrelly", "Terry", ""], ["Osborne", "Tobias J.", ""], ["Salzmann", "Robert", ""], ["Wolf", "Ramona", ""]]}, {"id": "1902.10448", "submitter": "Sarod Yatawatta", "authors": "Sarod Yatawatta", "title": "Statistical Performance of Radio Interferometric Calibration", "comments": "MNRAS Accepted 2019 April 30. Received 2019 April 9; in original form\n  2018 December 6", "journal-ref": null, "doi": "10.1093/mnras/stz1222", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration is an essential step in radio interferometric data processing\nthat corrects the data for systematic errors and in addition, subtracts bright\nforeground interference to reveal weak signals hidden in the residual. These\nweak and unknown signals are much sought after to reach many science goals but\nthe effect of calibration on such signals is an ever present concern. The main\nreason for this is the incompleteness of the model used in calibration.\nDistributed calibration based on consensus optimization has been shown to\nmitigate the effect due to model incompleteness by calibrating data covering a\nwide bandwidth in a computationally efficient manner. In this paper, we study\nthe statistical performance of direction dependent distributed calibration,\ni.e., the distortion caused by calibration on the residual statistics. In order\nto study this, we consider the mapping between the input uncalibrated data and\nthe output residual data. We derive an analytical relationship for the\ninfluence of the input on the residual and use this to find the relationship\nbetween the input and output probability density functions. Using simulations\nwe show that the smallest eigenvalue of the Jacobian of this mapping is a\nreliable indicator of the statistical performance of calibration. The analysis\ndeveloped in this paper can also be applied to other data processing steps in\nradio interferometry such as imaging and foreground subtraction as well as to\nmany other machine learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 10:45:01 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 14:07:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Yatawatta", "Sarod", ""]]}, {"id": "1902.10459", "submitter": "Michele Allegra", "authors": "Michele Allegra, Elena Facco, Francesco Denti, Alessandro Laio,\n  Antonietta Mira", "title": "Data segmentation based on the local intrinsic dimension", "comments": "11 pages, 6 figures + 9 pages Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the founding paradigms of machine learning is that a small number of\nvariables is often sufficient to describe high-dimensional data. The minimum\nnumber of variables required is called the intrinsic dimension (ID) of the\ndata. Contrary to common intuition, there are cases where the ID varies within\nthe same data set. This fact has been highlighted in technical discussions, but\nseldom exploited to analyze large data sets and obtain insight into their\nstructure. Here we develop a robust approach to discriminate regions with\ndifferent local IDs and segment the points accordingly. Our approach is\ncomputationally efficient and can be proficiently used even on large data sets.\nWe find that many real-world data sets contain regions with widely\nheterogeneous dimensions. These regions host points differing in core\nproperties: folded vs unfolded configurations in a protein molecular dynamics\ntrajectory, active vs non-active regions in brain imaging data, and firms with\ndifferent financial risk in company balance sheets. A simple topological\nfeature, the local ID, is thus sufficient to achieve an unsupervised\nsegmentation of high-dimensional data, complementary to the one given by\nclustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 11:11:17 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 15:18:02 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 12:28:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Allegra", "Michele", ""], ["Facco", "Elena", ""], ["Denti", "Francesco", ""], ["Laio", "Alessandro", ""], ["Mira", "Antonietta", ""]]}, {"id": "1902.10486", "submitter": "Arslan Chaudhry", "authors": "Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam\n  Ajanthan, Puneet K. Dokania, Philip H. S. Torr, Marc'Aurelio Ranzato", "title": "On Tiny Episodic Memories in Continual Learning", "comments": "Making the main point of the paper more clear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In continual learning (CL), an agent learns from a stream of tasks leveraging\nprior experience to transfer knowledge to future tasks. It is an ideal\nframework to decrease the amount of supervision in the existing learning\nalgorithms. But for a successful knowledge transfer, the learner needs to\nremember how to perform previous tasks. One way to endow the learner the\nability to perform tasks seen in the past is to store a small memory, dubbed\nepisodic memory, that stores few examples from previous tasks and then to\nreplay these examples when training for future tasks. In this work, we\nempirically analyze the effectiveness of a very small episodic memory in a CL\nsetup where each training example is only seen once. Surprisingly, across four\nrather different supervised learning benchmarks adapted to CL, a very simple\nbaseline, that jointly trains on both examples from the current task as well as\nexamples stored in the episodic memory, significantly outperforms specifically\ndesigned CL approaches with and without episodic memory. Interestingly, we find\nthat repetitive training on even tiny memories of past tasks does not harm\ngeneralization, on the contrary, it improves it, with gains between 7\\% and\n17\\% when the memory is populated with a single example per class.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 12:34:19 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:02:13 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 13:10:32 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 07:59:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chaudhry", "Arslan", ""], ["Rohrbach", "Marcus", ""], ["Elhoseiny", "Mohamed", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Dokania", "Puneet K.", ""], ["Torr", "Philip H. S.", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1902.10501", "submitter": "S{\\o}ren Ager Meldgaard", "authors": "Mathias S. J{\\o}rgensen, Henrik L. Mortensen, S{\\o}ren A. Meldgaard,\n  Esben L. Kolsbjerg, Thomas L. Jacobsen, Knud H. S{\\o}rensen, and Bj{\\o}rk\n  Hammer", "title": "Atomistic structure learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5108871", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One endeavour of modern physical chemistry is to use bottom-up approaches to\ndesign materials and drugs with desired properties. Here we introduce an\natomistic structure learning algorithm (ASLA) that utilizes a convolutional\nneural network to build 2D compounds and layered structures atom by atom. The\nalgorithm takes no prior data or knowledge on atomic interactions but inquires\na first-principles quantum mechanical program for physical properties. Using\nreinforcement learning, the algorithm accumulates knowledge of chemical\ncompound space for a given number and type of atoms and stores this in the\nneural network, ultimately learning the blueprint for the optimal structural\narrangement of the atoms for a given target property. ASLA is demonstrated to\nwork on diverse problems, including grain boundaries in graphene sheets,\norganic compound formation and a surface oxide structure. This approach to\nstructure prediction is a first step toward direct manipulation of atoms with\nartificially intelligent first principles computer codes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:05:10 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["J\u00f8rgensen", "Mathias S.", ""], ["Mortensen", "Henrik L.", ""], ["Meldgaard", "S\u00f8ren A.", ""], ["Kolsbjerg", "Esben L.", ""], ["Jacobsen", "Thomas L.", ""], ["S\u00f8rensen", "Knud H.", ""], ["Hammer", "Bj\u00f8rk", ""]]}, {"id": "1902.10505", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Michalina Strzyz, David Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Viable Dependency Parsing as Sequence Labeling", "comments": "Camera-ready version to appear at NAACL 2019 (final peer-reviewed\n  manuscript). 8 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recast dependency parsing as a sequence labeling problem, exploring\nseveral encodings of dependency trees as labels. While dependency parsing by\nmeans of sequence labeling had been attempted in existing work, results\nsuggested that the technique was impractical. We show instead that with a\nconventional BiLSTM-based model it is possible to obtain fast and accurate\nparsers. These parsers are conceptually simple, not needing traditional parsing\nalgorithms or auxiliary structures. However, experiments on the PTB and a\nsample of UD treebanks show that they provide a good speed-accuracy tradeoff,\nwith results competitive with more complex approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:08:27 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 17:25:11 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1902.10525", "submitter": "Thomas Deselaers", "authors": "Victor Carbune and Pedro Gonnet and Thomas Deselaers and Henry A.\n  Rowley and Alexander Daryin and Marcos Calvo and Li-Lun Wang and Daniel\n  Keysers and Sandro Feuz and Philippe Gervais", "title": "Fast Multi-language LSTM-based Online Handwriting Recognition", "comments": "accepted to IJDAR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe an online handwriting system that is able to support 102\nlanguages using a deep neural network architecture. This new system has\ncompletely replaced our previous Segment-and-Decode-based system and reduced\nthe error rate by 20%-40% relative for most languages. Further, we report new\nstate-of-the-art results on IAM-OnDB for both the open and closed dataset\nsetting. The system combines methods from sequence recognition with a new input\nencoding using B\\'ezier curves. This leads to up to 10x faster recognition\ntimes compared to our previous system. Through a series of experiments we\ndetermine the optimal configuration of our models and report the results of our\nsetup on a number of additional public datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 12:33:38 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 09:52:41 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Carbune", "Victor", ""], ["Gonnet", "Pedro", ""], ["Deselaers", "Thomas", ""], ["Rowley", "Henry A.", ""], ["Daryin", "Alexander", ""], ["Calvo", "Marcos", ""], ["Wang", "Li-Lun", ""], ["Keysers", "Daniel", ""], ["Feuz", "Sandro", ""], ["Gervais", "Philippe", ""]]}, {"id": "1902.10547", "submitter": "Alexandra Chronopoulou", "authors": "Alexandra Chronopoulou, Christos Baziotis, Alexandros Potamianos", "title": "An Embarrassingly Simple Approach for Transfer Learning from Pretrained\n  Language Models", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of state-of-the-art transfer learning methods employ\nlanguage models pretrained on large generic corpora. In this paper we present a\nconceptually simple and effective transfer learning approach that addresses the\nproblem of catastrophic forgetting. Specifically, we combine the task-specific\noptimization function with an auxiliary language model objective, which is\nadjusted during the training process. This preserves language regularities\ncaptured by language models, while enabling sufficient adaptation for solving\nthe target task. Our method does not require pretraining or finetuning separate\ncomponents of the network and we train our models end-to-end in a single step.\nWe present results on a variety of challenging affective and text\nclassification tasks, surpassing well established transfer learning methods\nwith greater level of complexity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 14:17:12 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 14:41:05 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 12:53:15 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chronopoulou", "Alexandra", ""], ["Baziotis", "Christos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1902.10565", "submitter": "David Wu", "authors": "David J. Wu", "title": "Accelerating Self-Play Learning in Go", "comments": "28 pages including appendices, 8 figures, 7 tables. Presented at\n  AAAI20-RLG workshop. (this version: updated an email address)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By introducing several improvements to the AlphaZero process and\narchitecture, we greatly accelerate self-play learning in Go, achieving a 50x\nreduction in computation over comparable methods. Like AlphaZero and\nreplications such as ELF OpenGo and Leela Zero, our bot KataGo only learns from\nneural-net-guided Monte Carlo tree search self-play. But whereas AlphaZero\nrequired thousands of TPUs over several days and ELF required thousands of GPUs\nover two weeks, KataGo surpasses ELF's final model after only 19 days on fewer\nthan 30 GPUs. Much of the speedup involves non-domain-specific improvements\nthat might directly transfer to other problems. Further gains from\ndomain-specific techniques reveal the remaining efficiency gap between the best\nmethods and purely general methods such as AlphaZero. Our work is a step\ntowards making learning in state spaces as large as Go possible without\nlarge-scale computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 14:51:51 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 17:45:10 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 00:40:26 GMT"}, {"version": "v4", "created": "Thu, 6 Feb 2020 15:30:15 GMT"}, {"version": "v5", "created": "Mon, 9 Nov 2020 18:17:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wu", "David J.", ""]]}, {"id": "1902.10569", "submitter": "Gaelle Loosli", "authors": "Ga\\\"elle Loosli (LIMOS)", "title": "TrIK-SVM : an alternative decomposition for kernel methods in Krein\n  spaces", "comments": "ESANN - European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning, Apr 2019, Bruges, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proposed work aims at proposing a alternative kernel decomposition in the\ncontext of kernel machines with indefinite kernels. The original paper of KSVM\n(SVM in Kre\\v{i}n spaces) uses the eigen-decomposition, our proposition avoids\nthis decompostion. We explain how it can help in designing an algorithm that\nwon't require to compute the full kernel matrix. Finally we illustrate the good\nbehavior of the proposed method compared to KSVM.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:01:05 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Loosli", "Ga\u00eblle", "", "LIMOS"]]}, {"id": "1902.10574", "submitter": "Yanxiang Jiang", "authors": "Liuyang Lu, Yanxiang Jiang, Mehdi Bennis, Zhiguo Ding, Fu-Chun Zheng,\n  and Xiaohu You", "title": "Distributed Edge Caching via Reinforcement Learning in Fog Radio Access\n  Networks", "comments": "6 pages, 6 figures, this work has been accepted by IEEE VTC 2019\n  Spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the distributed edge caching problem in fog radio access\nnetworks (F-RANs) is investigated. By considering the unknown spatio-temporal\ncontent popularity and user preference, a user request model based on hidden\nMarkov process is proposed to characterize the fluctuant spatio-temporal\ntraffic demands in F-RANs. Then, the Q-learning method based on the\nreinforcement learning (RL) framework is put forth to seek the optimal caching\npolicy in a distributed manner, which enables fog access points (F-APs) to\nlearn and track the potential dynamic process without extra communications\ncost. Furthermore, we propose a more efficient Q-learning method with value\nfunction approximation (Q-VFA-learning) to reduce complexity and accelerate\nconvergence. Simulation results show that the performance of our proposed\nmethod is superior to those of the traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:10:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Lu", "Liuyang", ""], ["Jiang", "Yanxiang", ""], ["Bennis", "Mehdi", ""], ["Ding", "Zhiguo", ""], ["Zheng", "Fu-Chun", ""], ["You", "Xiaohu", ""]]}, {"id": "1902.10582", "submitter": "Yuko Kuroki", "authors": "Yuko Kuroki, Liyuan Xu, Atsushi Miyauchi, Junya Honda, Masashi\n  Sugiyama", "title": "Polynomial-time Algorithms for Multiple-arm Identification with\n  Full-bandit Feedback", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of stochastic combinatorial pure exploration (CPE),\nwhere an agent sequentially pulls a set of single arms (a.k.a. a super arm) and\ntries to find the best super arm. Among a variety of problem settings of the\nCPE, we focus on the full-bandit setting, where we cannot observe the reward of\neach single arm, but only the sum of the rewards. Although we can regard the\nCPE with full-bandit feedback as a special case of pure exploration in linear\nbandits, an approach based on linear bandits is not computationally feasible\nsince the number of super arms may be exponential. In this paper, we first\npropose a polynomial-time bandit algorithm for the CPE under general\ncombinatorial constraints and provide an upper bound of the sample complexity.\nSecond, we design an approximation algorithm for the 0-1 quadratic maximization\nproblem, which arises in many bandit algorithms with confidence ellipsoids.\nBased on our approximation algorithm, we propose novel bandit algorithms for\nthe top-k selection problem, and prove that our algorithms run in polynomial\ntime. Finally, we conduct experiments on synthetic and real-world datasets, and\nconfirm the validity of our theoretical analysis in terms of both the\ncomputation time and the sample complexity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:20:09 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 12:45:35 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kuroki", "Yuko", ""], ["Xu", "Liyuan", ""], ["Miyauchi", "Atsushi", ""], ["Honda", "Junya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1902.10590", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Dhiraj Gulati, Rongjie Yan", "title": "Architecting Dependable Learning-enabled Autonomous Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a summary over architectural approaches that can be used to\nconstruct dependable learning-enabled autonomous systems, with a focus on\nautomated driving. We consider three technology pillars for architecting\ndependable autonomy, namely diverse redundancy, information fusion, and runtime\nmonitoring. For learning-enabled components, we additionally summarize recent\narchitectural approaches to increase the dependability beyond standard\nconvolutional neural networks. We conclude the study with a list of promising\nresearch directions addressing the challenges of existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:31:34 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Gulati", "Dhiraj", ""], ["Yan", "Rongjie", ""]]}, {"id": "1902.10630", "submitter": "Fangxin Shang", "authors": "Fangxin Shang, Hao Zhang", "title": "Alternating Synthetic and Real Gradients for Neural Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks (RNNs) with backpropagation through time\n(BPTT) has known drawbacks such as being difficult to capture longterm\ndependencies in sequences. Successful alternatives to BPTT have not yet been\ndiscovered. Recently, BP with synthetic gradients by a decoupled neural\ninterface module has been proposed to replace BPTT for training RNNs. On the\nother hand, it has been shown that the representations learned with synthetic\nand real gradients are different though they are functionally identical. In\nthis project, we explore ways of combining synthetic and real gradients with\napplication to neural language modeling tasks. Empirically, we demonstrate the\neffectiveness of alternating training with synthetic and real gradients after\nperiodic warm restarts on language modeling tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 16:48:20 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Shang", "Fangxin", ""], ["Zhang", "Hao", ""]]}, {"id": "1902.10644", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Provable Guarantees for Gradient-Based Meta-Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of meta-learning through the lens of online convex\noptimization, developing a meta-algorithm bridging the gap between popular\ngradient-based meta-learning and classical regularization-based multi-task\ntransfer methods. Our method is the first to simultaneously satisfy good sample\nefficiency guarantees in the convex setting, with generalization bounds that\nimprove with task-similarity, while also being computationally scalable to\nmodern deep learning architectures and the many-task setting. Despite its\nsimplicity, the algorithm matches, up to a constant factor, a lower bound on\nthe performance of any such parameter-transfer method under natural task\nsimilarity assumptions. We use experiments in both convex and deep learning\nsettings to verify and demonstrate the applicability of our theory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:24:38 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:27:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1902.10657", "submitter": "Michael Burke Dr", "authors": "Michael Burke, Svetlin Penkov, Subramanian Ramamoorthy", "title": "From explanation to synthesis: Compositional program induction for\n  learning from demonstration", "comments": null, "journal-ref": "Proceedings of Robotics: Science and Systems (2019)", "doi": "10.15607/RSS.2019.XV.015", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid systems are a compact and natural mechanism with which to address\nproblems in robotics. This work introduces an approach to learning hybrid\nsystems from demonstrations, with an emphasis on extracting models that are\nexplicitly verifiable and easily interpreted by robot operators. We fit a\nsequence of controllers using sequential importance sampling under a generative\nswitching proportional controller task model. Here, we parameterise controllers\nusing a proportional gain and a visually verifiable joint angle goal. Inference\nunder this model is challenging, but we address this by introducing an\nattribution prior extracted from a neural end-to-end visuomotor control model.\nGiven the sequence of controllers comprising a task, we simplify the trace\nusing grammar parsing strategies, taking advantage of the sequence\ncompositionality, before grounding the controllers by training perception\nnetworks to predict goals given images. Using this approach, we are\nsuccessfully able to induce a program for a visuomotor reaching task involving\nloops and conditionals from a single demonstration and a neural end-to-end\nmodel. In addition, we are able to discover the program used for a tower\nbuilding task. We argue that computer program-like control systems are more\ninterpretable than alternative end-to-end learning approaches, and that hybrid\nsystems inherently allow for better generalisation across task configurations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:43:30 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:04:56 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Burke", "Michael", ""], ["Penkov", "Svetlin", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1902.10658", "submitter": "Baihan Lin", "authors": "Baihan Lin", "title": "Constraining Implicit Space with Minimum Description Length: An\n  Unsupervised Attention Mechanism across Neural Network Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the adaptation phenomenon of neuronal firing, we propose the\nregularity normalization (RN) as an unsupervised attention mechanism (UAM)\nwhich computes the statistical regularity in the implicit space of neural\nnetworks under the Minimum Description Length (MDL) principle. Treating the\nneural network optimization process as a partially observable model selection\nproblem, UAM constrains the implicit space by a normalization factor, the\nuniversal code length. We compute this universal code incrementally across\nneural network layers and demonstrated the flexibility to include data priors\nsuch as top-down attention and other oracle information. Empirically, our\napproach outperforms existing normalization methods in tackling limited,\nimbalanced and non-stationary input distribution in image classification,\nclassic control, procedurally-generated reinforcement learning, generative\nmodeling, handwriting generation and question answering tasks with various\nneural network architectures. Lastly, UAM tracks dependency and critical\nlearning stages across layers and recurrent time steps of deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:44:50 GMT"}, {"version": "v10", "created": "Tue, 26 May 2020 01:07:00 GMT"}, {"version": "v11", "created": "Fri, 5 Jun 2020 21:49:26 GMT"}, {"version": "v12", "created": "Thu, 10 Sep 2020 08:58:16 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 04:30:58 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 13:06:31 GMT"}, {"version": "v4", "created": "Sat, 30 Mar 2019 21:55:07 GMT"}, {"version": "v5", "created": "Wed, 1 May 2019 18:42:40 GMT"}, {"version": "v6", "created": "Thu, 25 Jul 2019 21:47:10 GMT"}, {"version": "v7", "created": "Wed, 31 Jul 2019 15:01:28 GMT"}, {"version": "v8", "created": "Mon, 25 Nov 2019 17:03:43 GMT"}, {"version": "v9", "created": "Fri, 21 Feb 2020 20:25:26 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Lin", "Baihan", ""]]}, {"id": "1902.10660", "submitter": "Hongge Chen", "authors": "Hongge Chen, Huan Zhang, Duane Boning, Cho-Jui Hsieh", "title": "Robust Decision Trees Against Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although adversarial examples and model robustness have been extensively\nstudied in the context of linear models and neural networks, research on this\nissue in tree-based models and how to make tree-based models robust against\nadversarial examples is still limited. In this paper, we show that tree based\nmodels are also vulnerable to adversarial examples and develop a novel\nalgorithm to learn robust trees. At its core, our method aims to optimize the\nperformance under the worst-case perturbation of input features, which leads to\na max-min saddle point problem. Incorporating this saddle point objective into\nthe decision tree building procedure is non-trivial due to the discrete nature\nof trees --- a naive approach to finding the best split according to this\nsaddle point objective will take exponential time. To make our approach\npractical and scalable, we propose efficient tree building algorithms by\napproximating the inner minimizer in this saddle point problem, and present\nefficient implementations for classical information gain based trees as well as\nstate-of-the-art tree boosting models such as XGBoost. Experimental results on\nreal world datasets demonstrate that the proposed algorithms can substantially\nimprove the robustness of tree-based models against adversarial examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:48:29 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 08:55:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Chen", "Hongge", ""], ["Zhang", "Huan", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1902.10664", "submitter": "Danny Panknin", "authors": "Danny Panknin, Shinichi Nakajima, Thanh Binh Bui, Klaus-Robert\n  M\\\"uller", "title": "Estimating Local Function Complexity via Mixture of Gaussian Processes", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world data often exhibit inhomogeneity, e.g., the noise level, the\nsampling distribution or the complexity of the target function may change over\nthe input space. In this paper, we try to isolate local function complexity in\na practical, robust way. This is achieved by first estimating the locally\noptimal kernel bandwidth as a functional relationship. Specifically, we propose\nSpatially Adaptive Bandwidth Estimation in Regression (SABER), which employs\nthe mixture of experts consisting of multinomial kernel logistic regression as\na gate and Gaussian process regression models as experts. Using the locally\noptimal kernel bandwidths, we deduce an estimate to the local function\ncomplexity by drawing parallels to the theory of locally linear smoothing. We\ndemonstrate the usefulness of local function complexity for model\ninterpretation and active learning in quantum chemistry experiments and fluid\ndynamics simulations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:55:06 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 10:03:33 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 11:17:20 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Panknin", "Danny", ""], ["Nakajima", "Shinichi", ""], ["Bui", "Thanh Binh", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1902.10666", "submitter": "Ramiro Camino", "authors": "Ramiro D. Camino, Christian A. Hammerschmidt, Radu State", "title": "Improving Missing Data Imputation with Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets with missing values are very common on industry applications, and\nthey can have a negative impact on machine learning models. Recent studies\nintroduced solutions to the problem of imputing missing values based on deep\ngenerative models. Previous experiments with Generative Adversarial Networks\nand Variational Autoencoders showed interesting results in this domain, but it\nis not clear which method is preferable for different use cases. The goal of\nthis work is twofold: we present a comparison between missing data imputation\nsolutions based on deep generative models, and we propose improvements over\nthose methodologies. We run our experiments using known real life datasets with\ndifferent characteristics, removing values at random and reconstructing them\nwith several imputation techniques. Our results show that the presence or\nabsence of categorical variables can alter the selection of the best model, and\nthat some models are more stable than others after similar runs with different\nrandom number generator seeds.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:01:06 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Camino", "Ramiro D.", ""], ["Hammerschmidt", "Christian A.", ""], ["State", "Radu", ""]]}, {"id": "1902.10674", "submitter": "Muhammad Zaid Hameed", "authors": "Muhammad Zaid Hameed, Andras Gyorgy, and Deniz Gunduz", "title": "The Best Defense Is a Good Offense: Adversarial Attacks to Avoid\n  Modulation Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a communication scenario, in which an intruder tries to determine\nthe modulation scheme of the intercepted signal. Our aim is to minimize the\naccuracy of the intruder, while guaranteeing that the intended receiver can\nstill recover the underlying message with the highest reliability. This is\nachieved by perturbing channel input symbols at the encoder, similarly to\nadversarial attacks against classifiers in machine learning. In image\nclassification, the perturbation is limited to be imperceptible to a human\nobserver, while in our case the perturbation is constrained so that the message\ncan still be reliably decoded by the legitimate receiver, which is oblivious to\nthe perturbation. Simulation results demonstrate the viability of our approach\nto make wireless communication secure against state-of-the-art intruders (using\ndeep learning or decision trees) with minimal sacrifice in the communication\nperformance. On the other hand, we also demonstrate that using diverse training\ndata and curriculum learning can significantly boost the accuracy of the\nintruder.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:22:28 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 18:17:07 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Hameed", "Muhammad Zaid", ""], ["Gyorgy", "Andras", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1902.10675", "submitter": "Riccardo Moriconi", "authors": "Riccardo Moriconi, Marc P. Deisenroth, K. S. Sesh Kumar", "title": "High-dimensional Bayesian optimization using low-dimensional feature\n  spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a powerful approach for seeking the global\noptimum of expensive black-box functions and has proven successful for fine\ntuning hyper-parameters of machine learning models. However, BO is practically\nlimited to optimizing 10--20 parameters. To scale BO to high dimensions, we\nusually make structural assumptions on the decomposition of the objective\nand\\slash or exploit the intrinsic lower dimensionality of the problem, e.g. by\nusing linear projections. We could achieve a higher compression rate with\nnonlinear projections, but learning these nonlinear embeddings typically\nrequires much data. This contradicts the BO objective of a relatively small\nevaluation budget. To address this challenge, we propose to learn a\nlow-dimensional feature space jointly with (a) the response surface and (b) a\nreconstruction mapping. Our approach allows for optimization of BO's\nacquisition function in the lower-dimensional subspace, which significantly\nsimplifies the optimization problem. We reconstruct the original parameter\nspace from the lower-dimensional subspace for evaluating the black-box\nfunction. For meaningful exploration, we solve a constrained optimization\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:23:42 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 16:13:05 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 20:24:25 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 13:58:40 GMT"}, {"version": "v5", "created": "Thu, 9 Apr 2020 15:34:10 GMT"}, {"version": "v6", "created": "Wed, 15 Apr 2020 16:13:56 GMT"}, {"version": "v7", "created": "Fri, 25 Sep 2020 11:04:59 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Moriconi", "Riccardo", ""], ["Deisenroth", "Marc P.", ""], ["Kumar", "K. S. Sesh", ""]]}, {"id": "1902.10697", "submitter": "Renee Obringer", "authors": "Renee Obringer, Rohini Kumar, Roshanak Nateghi", "title": "Integrated analysis of the urban water-electricity demand nexus in the\n  Midwestern United States", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.apenergy.2019.113466", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the interdependencies between water and electricity use is\ncritical for ensuring conservation measures are successful in lowering the net\nwater and electricity use in a city. This water-electricity demand nexus will\nbecome even more important as cities continue to grow, causing water and\nelectricity utilities additional stress, especially given the likely impacts of\nfuture global climatic and socioeconomic changes. Here, we propose a modeling\nframework based in statistical learning theory for predicting the\nclimate-sensitive portion of the coupled water-electricity demand nexus. The\npredictive models were built and tested on six Midwestern cities. The results\nshowed that water use was better predicted than electricity use, indicating\nthat water use is slightly more sensitive to climate than electricity use.\nAdditionally, the results demonstrated the importance of the variability in the\nEl Nino/Southern Oscillation index, which explained the majority of the\ncovariance in the water-electricity nexus. Our modeling results suggest that\nstronger El Ninos lead to an overall increase in water and electricity use in\nthese cities. The integrated modeling framework presented here can be used to\ncharacterize the climate-related sensitivity of the water-electricity demand\nnexus, accounting for the coupled water and electricity use rather than\nmodeling them separately, as independent variables.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:36:59 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Obringer", "Renee", ""], ["Kumar", "Rohini", ""], ["Nateghi", "Roshanak", ""]]}, {"id": "1902.10700", "submitter": "Imon Banerjee", "authors": "Imon Banerjee, Luis de Sisternes, Joelle Hallak, Theodore Leng, Aaron\n  Osborne, Mary Durbin, Daniel Rubin", "title": "A Deep-learning Approach for Prognosis of Age-Related Macular\n  Degeneration Disease using SD-OCT Imaging Biomarkers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid sequential deep learning model to predict the risk of AMD\nprogression in non-exudative AMD eyes at multiple timepoints, starting from\nshort-term progression (3-months) up to long-term progression (21-months).\nProposed model combines radiomics and deep learning to handle challenges\nrelated to imperfect ratio of OCT scan dimension and training cohort size. We\nconsidered a retrospective clinical trial dataset that includes 671 fellow eyes\nwith 13,954 dry AMD observations for training and validating the machine\nlearning models on a 10-fold cross validation setting. The proposed RNN model\nachieved high accuracy (0.96 AUCROC) for the prediction of both short term and\nlong-term AMD progression, and outperformed the traditional random forest model\ntrained. High accuracy achieved by the RNN establishes the ability to identify\nAMD patients at risk of progressing to advanced AMD at an early stage which\ncould have a high clinical impact as it allows for optimal clinical follow-up,\nwith more frequent screening and potential earlier treatment for those patients\nat high risk.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 06:16:12 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Banerjee", "Imon", ""], ["de Sisternes", "Luis", ""], ["Hallak", "Joelle", ""], ["Leng", "Theodore", ""], ["Osborne", "Aaron", ""], ["Durbin", "Mary", ""], ["Rubin", "Daniel", ""]]}, {"id": "1902.10704", "submitter": "Yanzhi Chen", "authors": "Yanzhi Chen, Michael U. Gutmann", "title": "Adaptive Gaussian Copula ABC", "comments": "8 pages, 5 figures, accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation (ABC) is a set of techniques for Bayesian\ninference when the likelihood is intractable but sampling from the model is\npossible. This work presents a simple yet effective ABC algorithm based on the\ncombination of two classical ABC approaches --- regression ABC and sequential\nABC. The key idea is that rather than learning the posterior directly, we first\ntarget another auxiliary distribution that can be learned accurately by\nexisting methods, through which we then subsequently learn the desired\nposterior with the help of a Gaussian copula. During this process, the\ncomplexity of the model changes adaptively according to the data at hand.\nExperiments on a synthetic dataset as well as three real-world inference tasks\ndemonstrates that the proposed method is fast, accurate, and easy to use.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 12:28:14 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chen", "Yanzhi", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "1902.10709", "submitter": "L.A. Prashanth", "authors": "Prashanth L.A. and Sanjay P. Bhat", "title": "Concentration of risk measures: A Wasserstein distance approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a unified approach based on Wasserstein distance to\nderive concentration bounds for empirical estimates for a broad class of risk\nmeasures. The results cover two broad classes of risk measures which are\ndefined in the paper. The classes of risk measures introduced include include\nas special cases well known risk measures from the finance literature such as\nconditional value at risk (CVaR), spectral risk measures, utility-based\nshortfall risk, cumulative prospect theory (CPT) value, and rank dependent\nexpected utility. Two estimation schemes are considered, one for each class of\nrisk measures. One estimation scheme involves applying the risk measure to the\nempirical distribution function formed from a collection of i.i.d. samples of\nthe random variable (r.v.), while the second scheme involves applying the same\nprocedure to a truncated sample. The bounds provided apply to three popular\nclasses of distributions, namely sub-Gaussian, sub-exponential and heavy-tailed\ndistributions. The bounds are derived by first relating the estimation error to\nthe Wasserstein distance between the true and empirical distributions, and then\nusing recent concentration bounds for the latter. Previous concentration bounds\nare available only for specific risk measures such as CVaR and CPT-value. The\nbounds derived in this paper are shown to either match or improve upon previous\nbounds in cases where they are available. The usefulness of the bounds is\nillustrated through an algorithm and the corresponding regret bound for a\nstochastic bandit problem involving a general risk measure from either of the\ntwo classes introduced in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:41:35 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 05:52:06 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 11:37:31 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["A.", "Prashanth L.", ""], ["Bhat", "Sanjay P.", ""]]}, {"id": "1902.10710", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Jan Vondrak", "title": "High probability generalization bounds for uniformly stable algorithms\n  with nearly optimal rate", "comments": "this is a follow-up to and has minor text overlap with\n  arXiv:1812.09859; v2: minor revision following acceptance for presentation at\n  COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic stability is a classical approach to understanding and analysis\nof the generalization error of learning algorithms. A notable weakness of most\nstability-based generalization bounds is that they hold only in expectation.\nGeneralization with high probability has been established in a landmark paper\nof Bousquet and Elisseeff (2002) albeit at the expense of an additional\n$\\sqrt{n}$ factor in the bound. Specifically, their bound on the estimation\nerror of any $\\gamma$-uniformly stable learning algorithm on $n$ samples and\nrange in $[0,1]$ is $O(\\gamma \\sqrt{n \\log(1/\\delta)} +\n\\sqrt{\\log(1/\\delta)/n})$ with probability $\\geq 1-\\delta$. The $\\sqrt{n}$\noverhead makes the bound vacuous in the common settings where $\\gamma \\geq\n1/\\sqrt{n}$. A stronger bound was recently proved by the authors (Feldman and\nVondrak, 2018) that reduces the overhead to at most $O(n^{1/4})$. Still, both\nof these results give optimal generalization bounds only when $\\gamma =\nO(1/n)$.\n  We prove a nearly tight bound of $O(\\gamma \\log(n)\\log(n/\\delta) +\n\\sqrt{\\log(1/\\delta)/n})$ on the estimation error of any $\\gamma$-uniformly\nstable algorithm. It implies that for algorithms that are uniformly stable with\n$\\gamma = O(1/\\sqrt{n})$, estimation error is essentially the same as the\nsampling error. Our result leads to the first high-probability generalization\nbounds for multi-pass stochastic gradient descent and regularized ERM for\nstochastic convex problems with nearly optimal rate --- resolving open problems\nin prior work. Our proof technique is new and we introduce several analysis\ntools that might find additional applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:50:28 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 05:48:35 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Feldman", "Vitaly", ""], ["Vondrak", "Jan", ""]]}, {"id": "1902.10730", "submitter": "Ray Jiang", "authors": "Ray Jiang, Silvia Chiappa, Tor Lattimore, Andr\\'as Gy\\\"orgy, Pushmeet\n  Kohli", "title": "Degenerate Feedback Loops in Recommender Systems", "comments": null, "journal-ref": "Proceedings of AAAI/ACM Conference on AI, Ethics, and Society,\n  Honolulu, HI, USA, January 27-28, 2019 (AIES '19)", "doi": "10.1145/3306618.3314288", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used extensively in recommender systems deployed in\nproducts. The decisions made by these systems can influence user beliefs and\npreferences which in turn affect the feedback the learning system receives -\nthus creating a feedback loop. This phenomenon can give rise to the so-called\n\"echo chambers\" or \"filter bubbles\" that have user and societal implications.\nIn this paper, we provide a novel theoretical analysis that examines both the\nrole of user dynamics and the behavior of recommender systems, disentangling\nthe echo chamber from the filter bubble effect. In addition, we offer practical\nsolutions to slow down system degeneracy. Our study contributes toward\nunderstanding and developing solutions to commonly cited issues in the complex\ntemporal scenario, an area that is still largely unexplored.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:02:45 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 21:14:00 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 11:30:57 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Jiang", "Ray", ""], ["Chiappa", "Silvia", ""], ["Lattimore", "Tor", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1902.10731", "submitter": "Shay Moran", "authors": "Amos Beimel and Shay Moran and Kobbi Nissim and Uri Stemmer", "title": "Private Center Points and Learning of Halfspaces", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a private learner for halfspaces over an arbitrary finite domain\n$X\\subset \\mathbb{R}^d$ with sample complexity $mathrm{poly}(d,2^{\\log^*|X|})$.\nThe building block for this learner is a differentially private algorithm for\nlocating an approximate center point of $m>\\mathrm{poly}(d,2^{\\log^*|X|})$\npoints -- a high dimensional generalization of the median function. Our\nconstruction establishes a relationship between these two problems that is\nreminiscent of the relation between the median and learning one-dimensional\nthresholds [Bun et al.\\ FOCS '15]. This relationship suggests that the problem\nof privately locating a center point may have further applications in the\ndesign of differentially private algorithms.\n  We also provide a lower bound on the sample complexity for privately finding\na point in the convex hull. For approximate differential privacy, we show a\nlower bound of $m=\\Omega(d+\\log^*|X|)$, whereas for pure differential privacy\n$m=\\Omega(d\\log|X|)$.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:06:12 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Beimel", "Amos", ""], ["Moran", "Shay", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1902.10733", "submitter": "Panagiotis Agrafiotis", "authors": "Panagiotis Agrafiotis, Dimitrios Skarlatos, Andreas Georgopoulos and\n  Konstantinos Karantzalos", "title": "Shallow Water Bathymetry Mapping from UAV Imagery based on Machine\n  Learning", "comments": "8 pages, 9 figures", "journal-ref": "Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W10,\n  9-16, 2019", "doi": "10.5194/isprs-archives-XLII-2-W10-9-2019", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The determination of accurate bathymetric information is a key element for\nnear offshore activities, hydrological studies such as coastal engineering\napplications, sedimentary processes, hydrographic surveying as well as\narchaeological mapping and biological research. UAV imagery processed with\nStructure from Motion (SfM) and Multi View Stereo (MVS) techniques can provide\na low-cost alternative to established shallow seabed mapping techniques\noffering as well the important visual information. Nevertheless, water\nrefraction poses significant challenges on depth determination. Till now, this\nproblem has been addressed through customized image-based refraction correction\nalgorithms or by modifying the collinearity equation. In this paper, in order\nto overcome the water refraction errors, we employ machine learning tools that\nare able to learn the systematic underestimation of the estimated depths. In\nthe proposed approach, based on known depth observations from bathymetric LiDAR\nsurveys, an SVR model was developed able to estimate more accurately the real\ndepths of point clouds derived from SfM-MVS procedures. Experimental results\nover two test sites along with the performed quantitative validation indicated\nthe high potential of the developed approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:09:13 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 09:17:04 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 15:13:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Agrafiotis", "Panagiotis", ""], ["Skarlatos", "Dimitrios", ""], ["Georgopoulos", "Andreas", ""], ["Karantzalos", "Konstantinos", ""]]}, {"id": "1902.10747", "submitter": "Mikael Brudfors", "authors": "Mikael Brudfors, Ya\\\"el Balbastre, John Ashburner", "title": "Nonlinear Markov Random Fields Learned via Backpropagation", "comments": "Accepted for the international conference on Information Processing\n  in Medical Imaging (IPMI) 2019, camera ready version", "journal-ref": null, "doi": "10.1007/978-3-030-20351-1_63", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although convolutional neural networks (CNNs) currently dominate competitions\non image segmentation, for neuroimaging analysis tasks, more classical\ngenerative approaches based on mixture models are still used in practice to\nparcellate brains. To bridge the gap between the two, in this paper we propose\na marriage between a probabilistic generative model, which has been shown to be\nrobust to variability among magnetic resonance (MR) images acquired via\ndifferent imaging protocols, and a CNN. The link is in the prior distribution\nover the unknown tissue classes, which are classically modelled using a Markov\nrandom field. In this work we model the interactions among neighbouring pixels\nby a type of recurrent CNN, which can encode more complex spatial interactions.\nWe validate our proposed model on publicly available MR data, from different\ncentres, and show that it generalises across imaging protocols. This result\ndemonstrates a successful and principled inclusion of a CNN in a generative\nmodel, which in turn could be adapted by any probabilistic generative approach\nfor image segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:34:22 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 12:34:18 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Brudfors", "Mikael", ""], ["Balbastre", "Ya\u00ebl", ""], ["Ashburner", "John", ""]]}, {"id": "1902.10754", "submitter": "Michael Warren", "authors": "Chris R. Serrano and Michael A. Warren", "title": "Introspection Learning", "comments": "8 pages. Submitted to 2019 AAAI Spring Symposium on Verification of\n  Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional reinforcement learning agents learn from experience, past or\npresent, gained through interaction with their environment. Our approach\nsynthesizes experience, without requiring an agent to interact with their\nenvironment, by asking the policy directly \"Are there situations X, Y, and Z,\nsuch that in these situations you would select actions A, B, and C?\" In this\npaper we present Introspection Learning, an algorithm that allows for the\nasking of these types of questions of neural network policies. Introspection\nLearning is reinforcement learning algorithm agnostic and the states returned\nmay be used as an indicator of the health of the policy or to shape the policy\nin a myriad of ways. We demonstrate the usefulness of this algorithm both in\nthe context of speeding up training and improving robustness with respect to\nsafety constraints.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:53:01 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Serrano", "Chris R.", ""], ["Warren", "Michael A.", ""]]}, {"id": "1902.10755", "submitter": "Fazle Karim", "authors": "Fazle Karim, Somshubra Majumdar, and Houshang Darabi", "title": "Adversarial Attacks on Time Series", "comments": "13 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification models have been garnering significant importance\nin the research community. However, not much research has been done on\ngenerating adversarial samples for these models. These adversarial samples can\nbecome a security concern. In this paper, we propose utilizing an adversarial\ntransformation network (ATN) on a distilled model to attack various time series\nclassification models. The proposed attack on the classification model utilizes\na distilled model as a surrogate that mimics the behavior of the attacked\nclassical time series classification models. Our proposed methodology is\napplied onto 1-Nearest Neighbor Dynamic Time Warping (1-NN ) DTW, a Fully\nConnected Network and a Fully Convolutional Network (FCN), all of which are\ntrained on 42 University of California Riverside (UCR) datasets. In this paper,\nwe show both models were susceptible to attacks on all 42 datasets. To the best\nof our knowledge, such an attack on time series classification models has never\nbeen done before. Finally, we recommend future researchers that develop time\nseries classification models to incorporating adversarial data samples into\ntheir training data sets to improve resilience on adversarial samples and to\nconsider model robustness as an evaluative metric.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:55:44 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 01:07:12 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Karim", "Fazle", ""], ["Majumdar", "Somshubra", ""], ["Darabi", "Houshang", ""]]}, {"id": "1902.10756", "submitter": "Fazle Karim", "authors": "Fazle Karim, Somshubra Majumdar, Houshang Darabi", "title": "Insights into LSTM Fully Convolutional Networks for Time Series\n  Classification", "comments": "8 pages, 4 tables, 1 figure", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2916828", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short Term Memory Fully Convolutional Neural Networks (LSTM-FCN) and\nAttention LSTM-FCN (ALSTM-FCN) have shown to achieve state-of-the-art\nperformance on the task of classifying time series signals on the old\nUniversity of California-Riverside (UCR) time series repository. However, there\nhas been no study on why LSTM-FCN and ALSTM-FCN perform well. In this paper, we\nperform a series of ablation tests (3627 experiments) on LSTM-FCN and ALSTM-FCN\nto provide a better understanding of the model and each of its sub-module.\nResults from the ablation tests on ALSTM-FCN and LSTM-FCN show that the LSTM\nand the FCN blocks perform better when applied in a conjoined manner. Two\nz-normalizing techniques, z-normalizing each sample independently and\nz-normalizing the whole dataset, are compared using a Wilcoxson signed-rank\ntest to show a statistical difference in performance. In addition, we provide\nan understanding of the impact dimension shuffle has on LSTM-FCN by comparing\nits performance with LSTM-FCN when no dimension shuffle is applied. Finally, we\ndemonstrate the performance of the LSTM-FCN when the LSTM block is replaced by\na GRU, basic RNN, and Dense Block.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:55:54 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:49:12 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 23:59:03 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Karim", "Fazle", ""], ["Majumdar", "Somshubra", ""], ["Darabi", "Houshang", ""]]}, {"id": "1902.10758", "submitter": "Arinbj\\\"orn Kolbeinsson", "authors": "Arinbj\\\"orn Kolbeinsson, Jean Kossaifi, Yannis Panagakis, Adrian\n  Bulat, Anima Anandkumar, Ioanna Tzoulaki, Paul Matthews", "title": "Tensor Dropout for Robust Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNNs achieve remarkable performance by leveraging deep, over-parametrized\narchitectures, trained on large datasets. However, they have limited\ngeneralization ability to data outside the training domain, and a lack of\nrobustness to noise and adversarial attacks. By building better inductive\nbiases, we can improve robustness and also obtain smaller networks that are\nmore memory and computationally efficient. While standard CNNs use matrix\ncomputations, we study tensor layers that involve higher-order computations and\nprovide better inductive bias. Specifically, we impose low-rank tensor\nstructures on the weights of tensor regression layers to obtain compact\nnetworks, and propose tensor dropout, a randomization in the tensor rank for\nrobustness. We show that our approach outperforms other methods for large-scale\nimage classification on ImageNet and CIFAR-100. We establish a new\nstate-of-the-art accuracy for phenotypic trait prediction on the largest\ndataset of brain MRI, the UK Biobank brain MRI dataset, where multi-linear\nstructure is paramount. In all cases, we demonstrate superior performance and\nsignificantly improved robustness, both to noisy inputs and to adversarial\nattacks. We rigorously validate the theoretical validity of our approach by\nestablishing the link between our randomized decomposition and non-linear\ndropout.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:56:34 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 17:50:05 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 17:46:52 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 18:44:04 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Kossaifi", "Jean", ""], ["Panagakis", "Yannis", ""], ["Bulat", "Adrian", ""], ["Anandkumar", "Anima", ""], ["Tzoulaki", "Ioanna", ""], ["Matthews", "Paul", ""]]}, {"id": "1902.10768", "submitter": "Bilal Farooq", "authors": "Ali Yazdizadeh and Zachary Patterson and Bilal Farooq", "title": "Semi-supervised GANs to Infer Travel Modes in GPS Trajectories", "comments": null, "journal-ref": "Journal of Big Data Analytics in Transportation, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised Generative Adversarial Networks (GANs) are developed in the\ncontext of travel mode inference with uni-dimensional smartphone trajectory\ndata. We use data from a large-scale smartphone travel survey in Montreal,\nCanada. We convert GPS trajectories into fixed-sized segments with five\nchannels (variables). We develop different GANs architectures and compare their\nprediction results with Convolutional Neural Networks (CNNs). The best\nsemi-supervised GANs model led to a prediction accuracy of 83.4%, while the\nbest CNN model was able to achieve the prediction accuracy of 81.3%. The\nresults compare favorably with previous studies, especially when taking the\nlarge-scale real-world nature of the dataset into account.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 20:29:02 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 17:58:29 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Yazdizadeh", "Ali", ""], ["Patterson", "Zachary", ""], ["Farooq", "Bilal", ""]]}, {"id": "1902.10797", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi, Wouter M. Koolen, Tim van Erven", "title": "Lipschitz Adaptivity with Multiple Learning Rates in Online Learning", "comments": "22 pages. To appear in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to design adaptive online learning algorithms that take advantage of\nany special structure that might be present in the learning task at hand, with\nas little manual tuning by the user as possible. A fundamental obstacle that\ncomes up in the design of such adaptive algorithms is to calibrate a so-called\nstep-size or learning rate hyperparameter depending on variance, gradient\nnorms, etc. A recent technique promises to overcome this difficulty by\nmaintaining multiple learning rates in parallel. This technique has been\napplied in the MetaGrad algorithm for online convex optimization and the Squint\nalgorithm for prediction with expert advice. However, in both cases the user\nstill has to provide in advance a Lipschitz hyperparameter that bounds the norm\nof the gradients. Although this hyperparameter is typically not available in\nadvance, tuning it correctly is crucial: if it is set too small, the methods\nmay fail completely; but if it is taken too large, performance deteriorates\nsignificantly. In the present work we remove this Lipschitz hyperparameter by\ndesigning new versions of MetaGrad and Squint that adapt to its optimal value\nautomatically. We achieve this by dynamically updating the set of active\nlearning rates. For MetaGrad, we further improve the computational efficiency\nof handling constraints on the domain of prediction, and we remove the need to\nspecify the number of rounds in advance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 21:42:32 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 07:41:43 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Koolen", "Wouter M.", ""], ["van Erven", "Tim", ""]]}, {"id": "1902.10798", "submitter": "Yitao Liang", "authors": "Yitao Liang and Guy Van den Broeck", "title": "Learning Logistic Circuits", "comments": "Published in the Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (AAAI19)", "journal-ref": "@proceedings{liang2019logistic, title = {Proceedings of the\n  Thirty-Third {AAAI} Conference on Artificial Intelligence (AAAI-19)},\n  publisher = {{AAAI} Press}, year = {2019} }", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new classification model called logistic circuits. On\nMNIST and Fashion datasets, our learning algorithm outperforms neural networks\nthat have an order of magnitude more parameters. Yet, logistic circuits have a\ndistinct origin in symbolic AI, forming a discriminative counterpart to\nprobabilistic-logical circuits such as ACs, SPNs, and PSDDs. We show that\nparameter learning for logistic circuits is convex optimization, and that a\nsimple local search algorithm can induce strong model structures from data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 21:49:29 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1902.10807", "submitter": "Vojtech Mrazek", "authors": "Vojtech Mrazek and Muhammad Abdullah Hanif and Zdenek Vasicek and\n  Lukas Sekanina and Muhammad Shafique", "title": "autoAx: An Automatic Design Space Exploration and Circuit Building\n  Methodology utilizing Libraries of Approximate Components", "comments": "Accepted for publication at the Design Automation Conference 2019\n  (DAC'19), Las Vegas, Nevada, USA", "journal-ref": null, "doi": "10.1145/3316781.3317781", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate computing is an emerging paradigm for developing highly\nenergy-efficient computing systems such as various accelerators. In the\nliterature, many libraries of elementary approximate circuits have already been\nproposed to simplify the design process of approximate accelerators. Because\nthese libraries contain from tens to thousands of approximate implementations\nfor a single arithmetic operation it is intractable to find an optimal\ncombination of approximate circuits in the library even for an application\nconsisting of a few operations. An open problem is \"how to effectively combine\ncircuits from these libraries to construct complex approximate accelerators\".\nThis paper proposes a novel methodology for searching, selecting and combining\nthe most suitable approximate circuits from a set of available libraries to\ngenerate an approximate accelerator for a given application. To enable fast\ndesign space generation and exploration, the methodology utilizes machine\nlearning techniques to create computational models estimating the overall\nquality of processing and hardware cost without performing full synthesis at\nthe accelerator level. Using the methodology, we construct hundreds of\napproximate accelerators (for a Sobel edge detector) showing different but\nrelevant tradeoffs between the quality of processing and hardware cost and\nidentify a corresponding Pareto-frontier. Furthermore, when searching for\napproximate implementations of a generic Gaussian filter consisting of 17\narithmetic operations, the proposed approach allows us to identify\napproximately $10^3$ highly important implementations from $10^{23}$ possible\nsolutions in a few hours, while the exhaustive search would take four months on\na high-end processor.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 08:35:03 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 09:11:44 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mrazek", "Vojtech", ""], ["Hanif", "Muhammad Abdullah", ""], ["Vasicek", "Zdenek", ""], ["Sekanina", "Lukas", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1902.10811", "submitter": "Ludwig Schmidt", "authors": "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar", "title": "Do ImageNet Classifiers Generalize to ImageNet?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build new test sets for the CIFAR-10 and ImageNet datasets. Both\nbenchmarks have been the focus of intense research for almost a decade, raising\nthe danger of overfitting to excessively re-used test sets. By closely\nfollowing the original dataset creation processes, we test to what extent\ncurrent classification models generalize to new data. We evaluate a broad range\nof models and find accuracy drops of 3% - 15% on CIFAR-10 and 11% - 14% on\nImageNet. However, accuracy gains on the original test sets translate to larger\ngains on the new test sets. Our results suggest that the accuracy drops are not\ncaused by adaptivity, but by the models' inability to generalize to slightly\n\"harder\" images than those found in the original test sets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 20:35:44 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 17:42:33 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Recht", "Benjamin", ""], ["Roelofs", "Rebecca", ""], ["Schmidt", "Ludwig", ""], ["Shankar", "Vaishaal", ""]]}, {"id": "1902.10814", "submitter": "Chun-Ta Lu", "authors": "Da-Cheng Juan, Chun-Ta Lu, Zhen Li, Futang Peng, Aleksei Timofeev,\n  Yi-Ting Chen, Yaxi Gao, Tom Duerig, Andrew Tomkins, Sujith Ravi", "title": "Graph-RISE: Graph-Regularized Image Semantic Embedding", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning image representations to capture fine-grained semantics has been a\nchallenging and important task enabling many applications such as image search\nand clustering. In this paper, we present Graph-Regularized Image Semantic\nEmbedding (Graph-RISE), a large-scale neural graph learning framework that\nallows us to train embeddings to discriminate an unprecedented O(40M)\nultra-fine-grained semantic labels. Graph-RISE outperforms state-of-the-art\nimage embedding algorithms on several evaluation tasks, including image\nclassification and triplet ranking. We provide case studies to demonstrate\nthat, qualitatively, image retrieval based on Graph-RISE effectively captures\nsemantics and, compared to the state-of-the-art, differentiates nuances at\nlevels that are closer to human-perception.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 04:55:28 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Juan", "Da-Cheng", ""], ["Lu", "Chun-Ta", ""], ["Li", "Zhen", ""], ["Peng", "Futang", ""], ["Timofeev", "Aleksei", ""], ["Chen", "Yi-Ting", ""], ["Gao", "Yaxi", ""], ["Duerig", "Tom", ""], ["Tomkins", "Andrew", ""], ["Ravi", "Sujith", ""]]}, {"id": "1902.10848", "submitter": "Sara Mousavi", "authors": "Sara Mousavi, Ramin Nabati, Megan Kleeschulte, Audris Mockus", "title": "Machine-assisted annotation of forensic imagery", "comments": "Submitted to ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image collections, if critical aspects of image content are exposed, can spur\nresearch and practical applications in many domains. Supervised machine\nlearning may be the only feasible way to annotate very large collections, but\nleading approaches rely on large samples of completely and accurately annotated\nimages. In the case of a large forensic collection, we are aiming to annotate,\nneither the complete annotation nor the large training samples can be feasibly\nproduced. We, therefore, investigate ways to assist manual annotation efforts\ndone by forensic experts. We present a method that can propose both images and\nareas within an image likely to contain desired classes. Evaluation of the\nmethod with human annotators showed highly accurate classification that was\nstrongly helped by transfer learning. The segmentation precision (mAP) was\nimproved by adding a separate class capturing background, but that did not\naffect the recall (mAR). Further work is needed to both increase the accuracy\nof segmentation and enhances prediction with additional covariates affecting\ndecomposition. We hope this effort to be of help in other domains that require\nweak segmentation and have limited availability of qualified annotators.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 00:39:53 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Mousavi", "Sara", ""], ["Nabati", "Ramin", ""], ["Kleeschulte", "Megan", ""], ["Mockus", "Audris", ""]]}, {"id": "1902.10849", "submitter": "Elizabeth Fons", "authors": "Elizabeth Fons, Paula Dawson, Jeffrey Yau, Xiao-jun Zeng and John\n  Keane", "title": "A novel dynamic asset allocation system using Feature Saliency Hidden\n  Markov models for smart beta investing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial crisis of 2008 generated interest in more transparent,\nrules-based strategies for portfolio construction, with Smart beta strategies\nemerging as a trend among institutional investors. While they perform well in\nthe long run, these strategies often suffer from severe short-term drawdown\n(peak-to-trough decline) with fluctuating performance across cycles. To address\ncyclicality and underperformance, we build a dynamic asset allocation system\nusing Hidden Markov Models (HMMs). We test our system across multiple\ncombinations of smart beta strategies and the resulting portfolios show an\nimprovement in risk-adjusted returns, especially on more return oriented\nportfolios (up to 50$\\%$ in excess of market annually). In addition, we propose\na novel smart beta allocation system based on the Feature Saliency HMM (FSHMM)\nalgorithm that performs feature selection simultaneously with the training of\nthe HMM, to improve regime identification. We evaluate our systematic trading\nsystem with real life assets using MSCI indices; further, the results (up to\n60$\\%$ in excess of market annually) show model performance improvement with\nrespect to portfolios built using full feature HMMs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 00:40:17 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Fons", "Elizabeth", ""], ["Dawson", "Paula", ""], ["Yau", "Jeffrey", ""], ["Zeng", "Xiao-jun", ""], ["Keane", "John", ""]]}, {"id": "1902.10877", "submitter": "Sangyeon Kim", "authors": "Sangyeon Kim, Myungjoo Kang", "title": "Financial series prediction using Attention LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time series prediction, especially with machine learning\ntechniques, is an extensive field of study. In recent times, deep learning\nmethods (especially time series analysis) have performed outstandingly for\nvarious industrial problems, with better prediction than machine learning\nmethods. Moreover, many researchers have used deep learning methods to predict\nfinancial time series with various models in recent years. In this paper, we\nwill compare various deep learning models, such as multilayer perceptron (MLP),\none-dimensional convolutional neural networks (1D CNN), stacked long short-term\nmemory (stacked LSTM), attention networks, and weighted attention networks for\nfinancial time series prediction. In particular, attention LSTM is not only\nused for prediction, but also for visualizing intermediate outputs to analyze\nthe reason of prediction; therefore, we will show an example for understanding\nthe model prediction intuitively with attention vectors. In addition, we focus\non time and factors, which lead to an easy understanding of why certain trends\nare predicted when accessing a given time series table. We also modify the loss\nfunctions of the attention models with weighted categorical cross entropy; our\nproposed model produces a 0.76 hit ratio, which is superior to those of other\nmethods for predicting the trends of the KOSPI 200.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 03:09:25 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Kim", "Sangyeon", ""], ["Kang", "Myungjoo", ""]]}, {"id": "1902.10885", "submitter": "Hemalatha M", "authors": "Anubha Pearline.S and Hemalatha.M", "title": "Face Recognition Under Varying Blur, Illumination and Expression in an\n  Unconstrained Environment", "comments": null, "journal-ref": "Special Issue International Journal of Computer Science and\n  Information Security (IJCSIS) 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition system is one of the esteemed research areas in pattern\nrecognition and computer vision as long as its major challenges. A few\nchallenges in recognizing faces are blur, illumination, and varied expressions.\nBlur is natural while taking photographs using cameras, mobile phones, etc.\nBlur can be uniform and non-uniform. Usually non-uniform blur happens in images\ntaken using handheld image devices. Distinguishing or handling a blurred image\nin a face recognition system is generally tough. Under varying lighting\nconditions, it is challenging to identify the person correctly. Diversified\nfacial expressions such as happiness, sad, surprise, fear, anger changes or\ndeforms the faces from normal images. Identifying faces with facial expressions\nis also a challenging task, due to the deformation caused by the facial\nexpressions. To solve these issues, a pre-processing step was carried out after\nwhich Blur and Illumination-Robust Face recognition (BIRFR) algorithm was\nperformed. The test image and training images with facial expression are\ntransformed to neutral face using Facial expression removal (FER) peration.\nEvery training image is transformed based on the optimal Transformation Spread\nFunction (TSF), and illumination coefficients. Local Binary Pattern (LBP)\nfeatures extracted from test image and transformed training image is used for\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 04:18:28 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["S", "Anubha Pearline.", ""], ["M", "Hemalatha.", ""]]}, {"id": "1902.10887", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Bo Han, Laura Wynter, Kian Hsiang Low, and Mohan\n  Kankanhalli", "title": "Towards Robust ResNet: A Small Step but A Giant Leap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet principled approach to boosting the\nrobustness of the residual network (ResNet) that is motivated by the dynamical\nsystem perspective. Namely, a deep neural network can be interpreted using a\npartial differential equation, which naturally inspires us to characterize\nResNet by an explicit Euler method. Our analytical studies reveal that the step\nfactor h in the Euler method is able to control the robustness of ResNet in\nboth its training and generalization. Specifically, we prove that a small step\nfactor h can benefit the training robustness for back-propagation; from the\nview of forward-propagation, a small h can aid in the robustness of the model\ngeneralization. A comprehensive empirical evaluation on both vision CIFAR-10\nand text AG-NEWS datasets confirms that a small h aids both the training and\ngeneralization robustness.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 04:24:46 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 01:17:30 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 03:02:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Han", "Bo", ""], ["Wynter", "Laura", ""], ["Low", "Kian Hsiang", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1902.10890", "submitter": "Daoud Burghal", "authors": "Daoud Burghal and Rui Wang and Andreas F. Molisch", "title": "Deep Learning and Gaussian Process based Band Assignment in Dual Band\n  Systems", "comments": "30 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the band assignment (BA) problem in dual-band systems, where the\nbasestation (BS) chooses one of the two available frequency bands\n(centimeter-wave and millimeter-wave bands) to communicate with the user\nequipment (UE). While the millimeter-wave band might offer higher data rate,\nthere is a significant probability of outage during which the communication\nshould be carried on the (more reliable) centimeter-wave band. We consider two\nvariations of the BA problem, one-shot and sequential BA. For the former the BS\nuses only the currently observed information to decide whether to switch to the\nother frequency band, for the sequential BA, the BS uses a window of previously\nobserved information to predict the best band for a future time step. We\nprovide two approaches to solve the BA problem, (i) a deep learning approach\nthat is based on Long Short Term Memory and/or multi-layer Neural Networks, and\n(ii) a Gaussian Process based approach, which relies on the assumption that the\nchannel states are jointly Gaussian. We compare the achieved performances to\nseveral benchmarks in two environments: (i) a stochastic environment, and (ii)\nmicrocellular outdoor channels obtained by ray-tracing. In general, the deep\nlearning solution shows superior performance in both environments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 04:55:53 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Burghal", "Daoud", ""], ["Wang", "Rui", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "1902.10899", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Qiang Zhang, Rongyao Fang, Bingbing Ni, Jinxian Liu,\n  Qi Tian", "title": "Adversarial Attack and Defense on Point Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emergence of the utility of 3D point cloud data in safety-critical vision\ntasks (e.g., ADAS) urges researchers to pay more attention to the robustness of\n3D representations and deep networks. To this end, we develop an attack and\ndefense scheme, dedicated to 3D point cloud data, for preventing 3D point\nclouds from manipulated as well as pursuing noise-tolerable 3D representation.\nA set of novel 3D point cloud attack operations are proposed via pointwise\ngradient perturbation and adversarial point attachment / detachment. We then\ndevelop a flexible perturbation-measurement scheme for 3D point cloud data to\ndetect potential attack data or noisy sensing data. Notably, the proposed\ndefense methods are even effective to detect the adversarial point clouds\ngenerated by a proof-of-concept attack directly targeting the defense.\nTransferability of adversarial attacks between several point cloud networks is\naddressed, and we propose an momentum-enhanced pointwise gradient to improve\nthe attack transferability. We further analyze the transferability from\nadversarial point clouds to grid CNNs and the inverse. Extensive experimental\nresults on common point cloud benchmarks demonstrate the validity of the\nproposed 3D attack and defense framework.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 05:27:40 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 16:31:38 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:13:03 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 16:03:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yang", "Jiancheng", ""], ["Zhang", "Qiang", ""], ["Fang", "Rongyao", ""], ["Ni", "Bingbing", ""], ["Liu", "Jinxian", ""], ["Tian", "Qi", ""]]}, {"id": "1902.10918", "submitter": "Ruihao Zhu", "authors": "Hamsa Bastani and David Simchi-Levi and Ruihao Zhu", "title": "Meta Dynamic Pricing: Transfer Learning Across Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning shared structure \\emph{across} a sequence of\ndynamic pricing experiments for related products. We consider a practical\nformulation where the unknown demand parameters for each product come from an\nunknown distribution (prior) that is shared across products. We then propose a\nmeta dynamic pricing algorithm that learns this prior online while solving a\nsequence of Thompson sampling pricing experiments (each with horizon $T$) for\n$N$ different products. Our algorithm addresses two challenges: (i) balancing\nthe need to learn the prior (\\emph{meta-exploration}) with the need to leverage\nthe estimated prior to achieve good performance (\\emph{meta-exploitation}), and\n(ii) accounting for uncertainty in the estimated prior by appropriately\n\"widening\" the estimated prior as a function of its estimation error. We\nintroduce a novel prior alignment technique to analyze the regret of Thompson\nsampling with a mis-specified prior, which may be of independent interest.\nUnlike prior-independent approaches, our algorithm's meta regret grows\nsublinearly in $N$, demonstrating that the price of an unknown prior in\nThompson sampling can be negligible in experiment-rich environments (large\n$N$). Numerical experiments on synthetic and real auto loan data demonstrate\nthat our algorithm significantly speeds up learning compared to\nprior-independent algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 06:25:06 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 21:28:40 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:58:02 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 02:00:52 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Bastani", "Hamsa", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1902.10920", "submitter": "Anish Agarwal", "authors": "Anish Agarwal, Devavrat Shah, Dennis Shen and Dogyoon Song", "title": "On Robustness of Principal Component Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component regression (PCR) is a simple, but powerful and\nubiquitously utilized method. Its effectiveness is well established when the\ncovariates exhibit low-rank structure. However, its ability to handle settings\nwith noisy, missing, and mixed-valued, i.e., discrete and continuous,\ncovariates is not understood and remains an important open challenge. As the\nmain contribution of this work we establish the robustness of PCR, without any\nchange, in this respect and provide meaningful finite-sample analysis. To do\nso, we establish that PCR is equivalent to performing linear regression after\npre-processing the covariate matrix via hard singular value thresholding\n(HSVT). As a result, in the context of counterfactual analysis using\nobservational data, we show PCR is equivalent to the recently proposed robust\nvariant of the synthetic control method, known as robust synthetic control\n(RSC). As an immediate consequence, we obtain finite-sample analysis of the RSC\nestimator that was previously absent. As an important contribution to the\nsynthetic controls literature, we establish that an (approximate) linear\nsynthetic control exists in the setting of a generalized factor model or latent\nvariable model; traditionally in the literature, the existence of a synthetic\ncontrol needs to be assumed to exist as an axiom. We further discuss a\nsurprising implication of the robustness property of PCR with respect to noise,\ni.e., PCR can learn a good predictive model even if the covariates are\ntactfully transformed to preserve differential privacy. Finally, this work\nadvances the state-of-the-art analysis for HSVT by establishing stronger\nguarantees with respect to the $\\ell_{2, \\infty}$-norm rather than the\nFrobenius norm as is commonly done in the matrix estimation literature, which\nmay be of interest in its own right.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 06:34:52 GMT"}, {"version": "v10", "created": "Wed, 19 May 2021 14:40:43 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 22:58:13 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 04:04:35 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 02:25:01 GMT"}, {"version": "v5", "created": "Wed, 12 Jun 2019 16:41:24 GMT"}, {"version": "v6", "created": "Mon, 13 Jan 2020 19:33:57 GMT"}, {"version": "v7", "created": "Mon, 20 Jan 2020 04:49:20 GMT"}, {"version": "v8", "created": "Mon, 10 Aug 2020 15:25:12 GMT"}, {"version": "v9", "created": "Sat, 12 Dec 2020 16:56:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Agarwal", "Anish", ""], ["Shah", "Devavrat", ""], ["Shen", "Dennis", ""], ["Song", "Dogyoon", ""]]}, {"id": "1902.10940", "submitter": "R\\'emi Domingues", "authors": "R\\'emi Domingues, Pietro Michiardi, J\\'er\\'emie Barlet, Maurizio\n  Filippone", "title": "A comparative evaluation of novelty detection algorithms for discrete\n  sequences", "comments": "Submitted to Artificial Intelligence Review journal; 24 pages, 4\n  tables, 11 figures", "journal-ref": "Artificial Intelligence Review (2019)", "doi": "10.1007/s10462-019-09779-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of anomalies in temporal data is a core component of\nnumerous research areas such as intrusion detection, fault prevention, genomics\nand fraud detection. This article provides an experimental comparison of the\nnovelty detection problem applied to discrete sequences. The objective of this\nstudy is to identify which state-of-the-art methods are efficient and\nappropriate candidates for a given use case. These recommendations rely on\nextensive novelty detection experiments based on a variety of public datasets\nin addition to novel industrial datasets. We also perform thorough scalability\nand memory usage tests resulting in new supplementary insights of the methods'\nperformance, key selection criterion to solve problems relying on large volumes\nof data and to meet the expectations of applications subject to strict response\ntime constraints.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:56:46 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 13:48:26 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Domingues", "R\u00e9mi", ""], ["Michiardi", "Pietro", ""], ["Barlet", "J\u00e9r\u00e9mie", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1902.10952", "submitter": "Clement Abi Nader", "authors": "Clement Abi Nader, Nicholas Ayache, Philippe Robert, Marco Lorenzi", "title": "Monotonic Gaussian Process for Spatio-Temporal Disease Progression\n  Modeling in Brain Imaging Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic generative model for disentangling\nspatio-temporal disease trajectories from series of high-dimensional brain\nimages. The model is based on spatio-temporal matrix factorization, where\ninference on the sources is constrained by anatomically plausible statistical\npriors. To model realistic trajectories, the temporal sources are defined as\nmonotonic and time-reparametrized Gaussian Processes. To account for the\nnon-stationarity of brain images, we model the spatial sources as sparse codes\nconvolved at multiple scales. The method was tested on synthetic data\nfavourably comparing with standard blind source separation approaches. The\napplication on large-scale imaging data from a clinical study allows to\ndisentangle differential temporal progression patterns mapping brain regions\nkey to neurodegeneration, while revealing a disease-specific time scale\nassociated to the clinical diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 08:59:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 12:16:27 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 08:19:02 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Nader", "Clement Abi", ""], ["Ayache", "Nicholas", ""], ["Robert", "Philippe", ""], ["Lorenzi", "Marco", ""]]}, {"id": "1902.10966", "submitter": "Amer Krivo\\v{s}ija", "authors": "Amer Krivo\\v{s}ija and Alexander Munteanu", "title": "Probabilistic smallest enclosing ball in high dimensions via subgradient\n  sampling", "comments": "20 pages; SoCG 2019 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the median problem for a collection of point sets in\nhigh dimensions. This generalizes the geometric median as well as the\n(probabilistic) smallest enclosing ball (pSEB) problems. Our main objective and\nmotivation is to improve the previously best algorithm for the pSEB problem by\nreducing its exponential dependence on the dimension to linear. This is\nachieved via a novel combination of sampling techniques for clustering problems\nin metric spaces with the framework of stochastic subgradient descent. As a\nresult, the algorithm becomes applicable to shape fitting problems in Hilbert\nspaces of unbounded dimension via kernel functions. We present an exemplary\napplication by extending the support vector data description (SVDD) shape\nfitting method to the probabilistic case. This is done by simulating the pSEB\nalgorithm implicitly in the feature space induced by the kernel function.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:22:46 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Krivo\u0161ija", "Amer", ""], ["Munteanu", "Alexander", ""]]}, {"id": "1902.10974", "submitter": "Andr\\'es Felipe L\\'opez-Lopera", "authors": "Andr\\'es F. L\\'opez-Lopera and ST John and Nicolas Durrande", "title": "Gaussian Process Modulated Cox Processes under Linear Inequality\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) modulated Cox processes are widely used to model point\npatterns. Existing approaches require a mapping (link function) between the\nunconstrained GP and the positive intensity function. This commonly yields\nsolutions that do not have a closed form or that are restricted to specific\ncovariance functions. We introduce a novel finite approximation of GP-modulated\nCox processes where positiveness conditions can be imposed directly on the GP,\nwith no restrictions on the covariance function. Our approach can also ensure\nother types of inequality constraints (e.g. monotonicity, convexity), resulting\nin more versatile models that can be used for other classes of point processes\n(e.g. renewal processes). We demonstrate on both synthetic and real-world data\nthat our framework accurately infers the intensity functions. Where\nmonotonicity is a feature of the process, our ability to include this in the\ninference improves results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:39:02 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["L\u00f3pez-Lopera", "Andr\u00e9s F.", ""], ["John", "ST", ""], ["Durrande", "Nicolas", ""]]}, {"id": "1902.11004", "submitter": "Adrien Guille", "authors": "Robin Brochier, Adrien Guille, Julien Velcin", "title": "Global Vectors for Node Representations", "comments": "2019 ACM World Wide Web Conference (WWW 19)", "journal-ref": null, "doi": "10.1145/3308558.3313595", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network embedding algorithms consist in measuring co-occurrences of\nnodes via random walks then learning the embeddings using Skip-Gram with\nNegative Sampling. While it has proven to be a relevant choice, there are\nalternatives, such as GloVe, which has not been investigated yet for network\nembedding. Even though SGNS better handles non co-occurrence than GloVe, it has\na worse time-complexity. In this paper, we propose a matrix factorization\napproach for network embedding, inspired by GloVe, that better handles non\nco-occurrence with a competitive time-complexity. We also show how to extend\nthis model to deal with networks where nodes are documents, by simultaneously\nlearning word, node and document representations. Quantitative evaluations show\nthat our model achieves state-of-the-art performance, while not being so\nsensitive to the choice of hyper-parameters. Qualitatively speaking, we show\nhow our model helps exploring a network of documents by generating\ncomplementary network-oriented and content-oriented keywords.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 10:46:54 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "1902.11019", "submitter": "Ke Sun", "authors": "Ke Sun, Zhanxing Zhu, Zhouchen Lin", "title": "Towards Understanding Adversarial Examples Systematically: Exploring\n  Data Size, Task and Model Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous works usually explained adversarial examples from several\nspecific perspectives, lacking relatively integral comprehension about this\nproblem. In this paper, we present a systematic study on adversarial examples\nfrom three aspects: the amount of training data, task-dependent and\nmodel-specific factors. Particularly, we show that adversarial generalization\n(i.e. test accuracy on adversarial examples) for standard training requires\nmore data than standard generalization (i.e. test accuracy on clean examples);\nand uncover the global relationship between generalization and robustness with\nrespect to the data size especially when data is augmented by generative\nmodels. This reveals the trade-off correlation between standard generalization\nand robustness in limited training data regime and their consistency when data\nsize is large enough. Furthermore, we explore how different task-dependent and\nmodel-specific factors influence the vulnerability of deep neural networks by\nextensive empirical analysis. Relevant recommendations on defense against\nadversarial attacks are provided as well. Our results outline a potential path\ntowards the luminous and systematic understanding of adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 11:14:45 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Sun", "Ke", ""], ["Zhu", "Zhanxing", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1902.11029", "submitter": "Ke Sun", "authors": "Ke Sun, Zhanxing Zhu, Zhouchen Lin", "title": "Enhancing the Robustness of Deep Neural Networks by Boundary Conditional\n  GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been widely deployed in various machine learning\ntasks. However, recent works have demonstrated that they are vulnerable to\nadversarial examples: carefully crafted small perturbations to cause\nmisclassification by the network. In this work, we propose a novel defense\nmechanism called Boundary Conditional GAN to enhance the robustness of deep\nneural networks against adversarial examples. Boundary Conditional GAN, a\nmodified version of Conditional GAN, can generate boundary samples with true\nlabels near the decision boundary of a pre-trained classifier. These boundary\nsamples are fed to the pre-trained classifier as data augmentation to make the\ndecision boundary more robust. We empirically show that the model improved by\nour approach consistently defenses against various types of adversarial attacks\nsuccessfully. Further quantitative investigations about the improvement of\nrobustness and visualization of decision boundaries are also provided to\njustify the effectiveness of our strategy. This new defense mechanism that uses\nboundary samples to enhance the robustness of networks opens up a new way to\ndefense adversarial attacks consistently.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 11:53:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Sun", "Ke", ""], ["Zhu", "Zhanxing", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1902.11035", "submitter": "Przemyslaw Biecek", "authors": "Alicja Gosiewska, Aleksandra Gacek, Piotr Lubon, Przemyslaw Biecek", "title": "SAFE ML: Surrogate Assisted Feature Extraction for Model Learning", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex black-box predictive models may have high accuracy, but opacity\ncauses problems like lack of trust, lack of stability, sensitivity to concept\ndrift. On the other hand, interpretable models require more work related to\nfeature engineering, which is very time consuming. Can we train interpretable\nand accurate models, without timeless feature engineering? In this article, we\nshow a method that uses elastic black-boxes as surrogate models to create a\nsimpler, less opaque, yet still accurate and interpretable glass-box models.\nNew models are created on newly engineered features extracted/learned with the\nhelp of a surrogate model. We show applications of this method for model level\nexplanations and possible extensions for instance level explanations. We also\npresent an example implementation in Python and benchmark this method on a\nnumber of tabular data sets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:00:51 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Gacek", "Aleksandra", ""], ["Lubon", "Piotr", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1902.11036", "submitter": "Moti Freiman", "authors": "Moti Freiman, Ravindra Manjeshwar, and Liran Goshen", "title": "Unsupervised Abnormality Detection through Mixed Structure\n  Regularization (MSR) in Deep Sparse Autoencoders", "comments": "Accepted for publication in the journal: \"Medical Physics\" (2019)", "journal-ref": null, "doi": "10.1002/mp.13464", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep sparse auto-encoders with mixed structure regularization (MSR) in\naddition to explicit sparsity regularization term and stochastic corruption of\nthe input data with Gaussian noise have the potential to improve unsupervised\nabnormality detection. Unsupervised abnormality detection based on identifying\noutliers using deep sparse auto-encoders is a very appealing approach for\nmedical computer aided detection systems as it requires only healthy data for\ntraining rather than expert annotated abnormality. In the task of detecting\ncoronary artery disease from Coronary Computed Tomography Angiography (CCTA),\nour results suggests that the MSR has the potential to improve overall\nperformance by 20-30% compared to deep sparse and denoising auto-encoders.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:01:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Freiman", "Moti", ""], ["Manjeshwar", "Ravindra", ""], ["Goshen", "Liran", ""]]}, {"id": "1902.11038", "submitter": "Ke Sun", "authors": "Ke Sun, Zhouchen Lin, Zhanxing Zhu", "title": "Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on\n  Graphs with Few Labels", "comments": "AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks(GCNs) play a crucial role in graph learning\ntasks, however, learning graph embedding with few supervised signals is still a\ndifficult problem. In this paper, we propose a novel training algorithm for\nGraph Convolutional Network, called Multi-Stage Self-Supervised(M3S) Training\nAlgorithm, combined with self-supervised learning approach, focusing on\nimproving the generalization performance of GCNs on graphs with few labeled\nnodes. Firstly, a Multi-Stage Training Framework is provided as the basis of\nM3S training method. Then we leverage DeepCluster technique, a popular form of\nself-supervised learning, and design corresponding aligning mechanism on the\nembedding space to refine the Multi-Stage Training Framework, resulting in M3S\nTraining Algorithm. Finally, extensive experimental results verify the superior\nperformance of our algorithm on graphs with few labeled nodes under different\nlabel rates compared with other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:06:35 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:31:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sun", "Ke", ""], ["Lin", "Zhouchen", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1902.11045", "submitter": "Ke Sun", "authors": "Ke Sun, Zhouchen Lin, Hantao Guo, Zhanxing Zhu", "title": "Virtual Adversarial Training on Graph Convolutional Networks in Node\n  Classification", "comments": "Chinese Conference on Pattern Recognition and Computer Vision(PRCV)\n  2019 Oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Graph Convolutional Networks (GCNs) has been\ndemonstrated in a wide range of graph-based machine learning tasks. However,\nthe update of parameters in GCNs is only from labeled nodes, lacking the\nutilization of unlabeled data. In this paper, we apply Virtual Adversarial\nTraining (VAT), an adversarial regularization method based on both labeled and\nunlabeled data, on the supervised loss of GCN to enhance its generalization\nperformance. By imposing virtually adversarial smoothness on the posterior\ndistribution in semi-supervised learning, VAT yields improvement on the\nSymmetrical Laplacian Smoothness of GCNs. In addition, due to the difference of\nproperty in features, we perturb virtual adversarial perturbations on sparse\nand dense features, resulting in GCN Sparse VAT (GCNSVAT) and GCN Dense VAT\n(GCNDVAT) algorithms, respectively. Extensive experiments verify the\neffectiveness of our two methods across different training sizes. Our work\npaves the way towards better understanding the direction of improvement on GCNs\nin the future.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:23:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 15:59:52 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sun", "Ke", ""], ["Lin", "Zhouchen", ""], ["Guo", "Hantao", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1902.11054", "submitter": "Robin Brochier", "authors": "Robin Brochier and Adrien Guille and Julien Velcin", "title": "Link Prediction with Mutual Attention for Text-Attributed Networks", "comments": "Added missing reference", "journal-ref": null, "doi": "10.1145/3308560.3316587", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this extended abstract, we present an algorithm that learns a similarity\nmeasure between documents from the network topology of a structured corpus. We\nleverage the Scaled Dot-Product Attention, a recently proposed attention\nmechanism, to design a mutual attention mechanism between pairs of documents.\nTo train its parameters, we use the network links as supervision. We provide\npreliminary experiment results with a citation dataset on two prediction tasks,\ndemonstrating the capacity of our model to learn a meaningful textual\nsimilarity.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 12:45:42 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 09:20:53 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "1902.11074", "submitter": "Ning Gui Prof. dr.", "authors": "Ning Gui, Danni Ge, Ziyin Hu", "title": "AFS: An Attention-based mechanism for Supervised Feature Selection", "comments": "9 pages, 5 figures, published in the AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective data preprocessing step, feature selection has shown its\neffectiveness to prepare high-dimensional data for many machine learning tasks.\nThe proliferation of high di-mension and huge volume big data, however, has\nbrought major challenges, e.g. computation complexity and stability on noisy\ndata, upon existing feature-selection techniques. This paper introduces a novel\nneural network-based feature selection architecture, dubbed Attention-based\nFeature Selec-tion (AFS). AFS consists of two detachable modules: an at-tention\nmodule for feature weight generation and a learning module for the problem\nmodeling. The attention module for-mulates correlation problem among features\nand supervision target into a binary classification problem, supported by a\nshallow attention net for each feature. Feature weights are generated based on\nthe distribution of respective feature se-lection patterns adjusted by\nbackpropagation during the train-ing process. The detachable structure allows\nexisting off-the-shelf models to be directly reused, which allows for much less\ntraining time, demands for the training data and requirements for expertise. A\nhybrid initialization method is also intro-duced to boost the selection\naccuracy for datasets without enough samples for feature weight generation.\nExperimental results show that AFS achieves the best accuracy and stability in\ncomparison to several state-of-art feature selection algo-rithms upon both\nMNIST, noisy MNIST and several datasets with small samples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 13:34:11 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gui", "Ning", ""], ["Ge", "Danni", ""], ["Hu", "Ziyin", ""]]}, {"id": "1902.11088", "submitter": "Anton Osokin", "authors": "Aleksandr Shevchenko and Anton Osokin", "title": "Scaling Matters in Deep Structured-Prediction Models", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep structured-prediction energy-based models combine the expressive power\nof learned representations and the ability of embedding knowledge about the\ntask at hand into the system. A common way to learn parameters of such models\nconsists in a multistage procedure where different combinations of components\nare trained at different stages. The joint end-to-end training of the whole\nsystem is then done as the last fine-tuning stage. This multistage approach is\ntime-consuming and cumbersome as it requires multiple runs until convergence\nand multiple rounds of hyperparameter tuning. From this point of view, it is\nbeneficial to start the joint training procedure from the beginning. However,\nsuch approaches often unexpectedly fail and deliver results worse than the\nmultistage ones. In this paper, we hypothesize that one reason for joint\ntraining of deep energy-based models to fail is the incorrect relative\nnormalization of different components in the energy function. We propose online\nand offline scaling algorithms that fix the joint training and demonstrate\ntheir efficacy on three different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:05:35 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Shevchenko", "Aleksandr", ""], ["Osokin", "Anton", ""]]}, {"id": "1902.11097", "submitter": "Jamie Morgenstern", "authors": "Benjamin Wilson and Judy Hoffman and Jamie Morgenstern", "title": "Predictive Inequity in Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate whether state-of-the-art object detection\nsystems have equitable predictive performance on pedestrians with different\nskin tones. This work is motivated by many recent examples of ML and vision\nsystems displaying higher error rates for certain demographic groups than\nothers. We annotate an existing large scale dataset which contains pedestrians,\nBDD100K, with Fitzpatrick skin tones in ranges [1-3] or [4-6]. We then provide\nan in-depth comparative analysis of performance between these two skin tone\ngroupings, finding that neither time of day nor occlusion explain this\nbehavior, suggesting this disparity is not merely the result of pedestrians in\nthe 4-6 range appearing in more difficult scenes for detection. We investigate\nto what extent time of day, occlusion, and reweighting the supervised loss\nduring training affect this predictive bias.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:11:16 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Wilson", "Benjamin", ""], ["Hoffman", "Judy", ""], ["Morgenstern", "Jamie", ""]]}, {"id": "1902.11102", "submitter": "Vidit Saxena", "authors": "Vidit Saxena, Joseph E. Gonzalez, Ion Stoica, Hugo Tullberg, and\n  Joakim Jald\\'en", "title": "Constrained Thompson Sampling for Wireless Link Optimization", "comments": "11 pages, 2 figures. Revised version containing theoretical\n  performance bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Wireless communication systems operate in complex time-varying environments.\nTherefore, selecting the optimal configuration parameters in these systems is a\nchallenging problem. For wireless links, \\emph{rate selection} is used to\nselect the optimal data transmission rate that maximizes the link throughput\nsubject to an application-defined latency constraint. We model rate selection\nas a stochastic multi-armed bandit (MAB) problem, where a finite set of\ntransmission rates are modeled as independent bandit arms. For this setup, we\npropose Con-TS, a novel constrained version of the Thompson sampling algorithm,\nwhere the latency requirement is modeled by a high-probability linear\nconstraint. We show that for Con-TS, the expected number of constraint\nviolations over T transmission intervals is upper bounded by O(\\sqrt{KT}),\nwhere K is the number of available rates. Further, the expected loss in\ncumulative throughput compared to the optimal rate selection scheme (i.e., the\negret is also upper bounded by O(\\sqrt{KT \\log K}). Through numerical\nsimulations, we demonstrate that Con-TS significantly outperforms\nstate-of-the-art bandit schemes for rate selection.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:36:28 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 23:05:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Saxena", "Vidit", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""], ["Tullberg", "Hugo", ""], ["Jald\u00e9n", "Joakim", ""]]}, {"id": "1902.11104", "submitter": "No\u00e9mie Jaquier", "authors": "No\\'emie Jaquier, Robert Haschke, Sylvain Calinon", "title": "Tensor-variate Mixture of Experts for Proportional Myographic Control of\n  a Robotic Hand", "comments": "Accepted for publication in Robotics and Autonomous Systems (RAS).\n  Code and video available at:\n  https://sites.google.com/view/tensor-mixture-of-experts/ . 14 pages, 10\n  figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data are organized in matrices or arrays of higher dimensions (tensors),\nclassical regression methods first transform these data into vectors, therefore\nignoring the underlying structure of the data and increasing the dimensionality\nof the problem. This flattening operation typically leads to overfitting when\nonly few training data is available. In this paper, we present a\nmixture-of-experts model that exploits tensorial representations for regression\nof tensor-valued data. The proposed formulation takes into account the\nunderlying structure of the data and remains efficient when few training data\nare available. Evaluation on artificially generated data, as well as offline\nand real-time experiments recognizing hand movements from tactile myography\nprove the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:38:31 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 08:15:59 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 16:28:46 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Jaquier", "No\u00e9mie", ""], ["Haschke", "Robert", ""], ["Calinon", "Sylvain", ""]]}, {"id": "1902.11106", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Turker Ince, Alexandros Iosifidis and Moncef Gabbouj", "title": "Operational Neural Networks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward, fully-connected Artificial Neural Networks (ANNs) or the\nso-called Multi-Layer Perceptrons (MLPs) are well-known universal\napproximators. However, their learning performance varies significantly\ndepending on the function or the solution space that they attempt to\napproximate. This is mainly because of their homogenous configuration based\nsolely on the linear neuron model. Therefore, while they learn very well those\nproblems with a monotonous, relatively simple and linearly separable solution\nspace, they may entirely fail to do so when the solution space is highly\nnonlinear and complex. Sharing the same linear neuron model with two additional\nconstraints (local connections and weight sharing), this is also true for the\nconventional Convolutional Neural Networks (CNNs) and, it is, therefore, not\nsurprising that in many challenging problems only the deep CNNs with a massive\ncomplexity and depth can achieve the required diversity and the learning\nperformance. In order to address this drawback and also to accomplish a more\ngeneralized model over the convolutional neurons, this study proposes a novel\nnetwork model, called Operational Neural Networks (ONNs), which can be\nheterogeneous and encapsulate neurons with any set of operators to boost\ndiversity and to learn highly complex and multi-modal functions or spaces with\nminimal network complexity and training data. Finally, a novel training method\nis formulated to back-propagate the error through the operational layers of\nONNs. Experimental results over highly challenging problems demonstrate the\nsuperior learning capabilities of ONNs even with few neurons and hidden layers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:13:51 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 11:19:56 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1902.11108", "submitter": "Rahul Bhalley", "authors": "Rahul Bhalley and Jianlin Su", "title": "Artist Style Transfer Via Quadratic Potential", "comments": "8 pages, 3 figures, uses nips_2018.sty, renamed the network to\n  CycleGAN-QP for maintaining consistency with work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we address the problem of artist style transfer where the\npainting style of a given artist is applied on a real world photograph. We\ntrain our neural networks in adversarial setting via recently introduced\nquadratic potential divergence for stable learning process. To further improve\nthe quality of generated artist stylized images we also integrate some of the\nrecently introduced deep learning techniques in our method. To our best\nknowledge this is the first attempt towards artist style transfer via quadratic\npotential divergence. We provide some stylized image samples in the\nsupplementary material. The source code for experimentation was written in\nPyTorch and is available online in my GitHub repository.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 12:09:13 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 05:09:17 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bhalley", "Rahul", ""], ["Su", "Jianlin", ""]]}, {"id": "1902.11110", "submitter": "Swetava Ganguli", "authors": "Anthony Perez, Swetava Ganguli, Stefano Ermon, George Azzari, Marshall\n  Burke, David Lobell", "title": "Semi-Supervised Multitask Learning on Multispectral Satellite Images\n  Using Wasserstein Generative Adversarial Networks (GANs) for Predicting\n  Poverty", "comments": "This project was recognized as the best two-person project during the\n  Spring 2017 offering of CS 231N Convolutional Neural Networks for Visual\n  Recognition. Second revised version corrects typographical errors and adds a\n  few additional references", "journal-ref": null, "doi": null, "report-no": "Final report of research project conducted by the authors as part of\n  the Sustainability and Artificial Intelligence Laboratory (SAIL) at Stanford\n  University and as part of the Spring 2017 offering of CS 231N", "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Obtaining reliable data describing local poverty metrics at a granularity\nthat is informative to policy-makers requires expensive and logistically\ndifficult surveys, particularly in the developing world. Not surprisingly, the\npoverty stricken regions are also the ones which have a high probability of\nbeing a war zone, have poor infrastructure and sometimes have governments that\ndo not cooperate with internationally funded development efforts. We train a\nCNN on free and publicly available daytime satellite images of the African\ncontinent from Landsat 7 to build a model for predicting local economic\nlivelihoods. Only 5% of the satellite images can be associated with labels\n(which are obtained from DHS Surveys) and thus a semi-supervised approach using\na GAN (similar to the approach of Salimans, et al. (2016)), albeit with a more\nstable-to-train flavor of GANs called the Wasserstein GAN regularized with\ngradient penalty(Gulrajani, et al. (2017)) is used. The method of multitask\nlearning is employed to regularize the network and also create an end-to-end\nmodel for the prediction of multiple poverty metrics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 21:52:17 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 19:27:01 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Perez", "Anthony", ""], ["Ganguli", "Swetava", ""], ["Ermon", "Stefano", ""], ["Azzari", "George", ""], ["Burke", "Marshall", ""], ["Lobell", "David", ""]]}, {"id": "1902.11111", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Xingguo Li, and Jarvis Haupt", "title": "Target-based Hyperspectral Demixing via Generalized Robust PCA", "comments": "5 Pages; Index Terms - Hyperspectral imaging, Robust-PCA, Dictionary\n  Sparse, Matrix Demixing, Target Localization, and Remote Sensing. arXiv admin\n  note: substantial text overlap with arXiv:1902.10238", "journal-ref": "2017 51st Asilomar Conference on Signals, Systems, and Computers", "doi": "10.1109/ACSSC.2017.8335372", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localizing targets of interest in a given hyperspectral (HS) image has\napplications ranging from remote sensing to surveillance. This task of target\ndetection leverages the fact that each material/object possesses its own\ncharacteristic spectral response, depending upon its composition. As\n$\\textit{signatures}$ of different materials are often correlated, matched\nfiltering based approaches may not be appropriate in this case. In this work,\nwe present a technique to localize targets of interest based on their spectral\nsignatures. We also present the corresponding recovery guarantees, leveraging\nour recent theoretical results. To this end, we model a HS image as a\nsuperposition of a low-rank component and a dictionary sparse component,\nwherein the dictionary consists of the $\\textit{a priori}$ known characteristic\nspectral responses of the target we wish to localize. Finally, we analyze the\nperformance of the proposed approach via experimental validation on real HS\ndata for a classification task, and compare it with related techniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 21:43:51 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Li", "Xingguo", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.11113", "submitter": "Dahuin Jung", "authors": "Dahuin Jung, Ho Bae, Hyun-Soo Choi, and Sungroh Yoon", "title": "PixelSteganalysis: Destroying Hidden Information with a Low Degree of\n  Visual Degradation", "comments": "The updated version of this paper is uploaded in arXiv:1902.10905 as\n  a revised title. Sorry for inconvenience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography is the science of unnoticeably concealing a secret message\nwithin a certain image, called a cover image. The cover image with the secret\nmessage is called a stego image. Steganography is commonly used for illegal\npurposes such as terrorist activities and pornography. To thwart covert\ncommunications and transactions, attacking algorithms against steganography,\ncalled steganalysis, exist. Currently, there are many studies implementing deep\nlearning to the steganography algorithm. However, conventional steganalysis is\nno longer effective for deep learning based steganography algorithms. Our\nframework is the first one to disturb covert communications and transactions\nvia the recent deep learning-based steganography algorithms. We first extract a\nsophisticated pixel distribution of the potential stego image from the\nauto-regressive model induced by deep learning. Using the extracted pixel\ndistributions, we detect whether an image is the stego or not at the pixel\nlevel. Each pixel value is adjusted as required and the adjustment induces an\neffective removal of the secret image. Because the decoding method of deep\nlearning-based steganography algorithms is approximate (lossy), which is\ndifferent from the conventional steganography, we propose a new quantitative\nmetric that is more suitable for measuring the accurate effect. We evaluate our\nmethod using three public benchmarks in comparison with a conventional\nsteganalysis method and show up to a 20% improvement in terms of decoding rate.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:16:09 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 00:52:14 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Jung", "Dahuin", ""], ["Bae", "Ho", ""], ["Choi", "Hyun-Soo", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1902.11119", "submitter": "Behnam Dezfouli", "authors": "Salma Abdel Magid, Francesco Petrini, and Behnam Dezfouli", "title": "Image Classification on IoT Edge Devices: Profiling and Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": "SIOTLAB-TECHREP-OCT2018", "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of powerful, low-cost IoT systems, processing data closer to\nwhere the data originates, known as edge computing, has become an increasingly\nviable option. In addition to lowering the cost of networking infrastructures,\nedge computing reduces edge-cloud delay, which is essential for\nmission-critical applications. In this paper, we show the feasibility and study\nthe performance of image classification using IoT devices. Specifically, we\nexplore the relationships between various factors of image classification\nalgorithms that may affect energy consumption such as dataset size, image\nresolution, algorithm type, algorithm phase, and device hardware. Our\nexperiments show a strong, positive linear relationship between three predictor\nvariables, namely model complexity, image resolution, and dataset size, with\nrespect to energy consumption. In addition, in order to provide a means of\npredicting the energy consumption of an edge device performing image\nclassification, we investigate the usage of three machine learning algorithms\nusing the data generated from our experiments. The performance as well as the\ntrade offs for using linear regression, Gaussian process, and random forests\nare discussed and validated. Our results indicate that the random forest model\noutperforms the two former algorithms, with an R-squared value of 0.95 and 0.79\nfor two different validation datasets.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 06:41:29 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 05:28:16 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Magid", "Salma Abdel", ""], ["Petrini", "Francesco", ""], ["Dezfouli", "Behnam", ""]]}, {"id": "1902.11121", "submitter": "Weiliang Zhang", "authors": "Yunxuan Zhang and Weiliang Zhang and Qinyan Zhang and Jijiang Yang and\n  Xiuyu Chen and Shihua Zhao", "title": "CMR motion artifact correction using generative adversarial nets", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular Magnetic Resonance (CMR) plays an important role in the\ndiagnoses and treatment of cardiovascular diseases while motion artifacts which\nare formed during the scanning process of CMR seriously affects doctors to find\nthe exact focus. The current correction methods mainly focus on the K-space\nwhich is a grid of raw data obtained from the MR signal directly and then\ntransfer to CMR image by inverse Fourier transform. They are neither effective\nnor efficient and can not be utilized in clinic. In this paper, we propose a\nnovel approach for CMR motion artifact correction using deep learning.\nSpecially, we use deep residual network (ResNet) as net framework and train our\nmodel in adversarial manner. Our approach is motivated by the connection\nbetween image motion blur and CMR motion artifact, so we can transfer methods\nfrom motion-deblur where deep learning has made great progress to CMR\nmotion-correction successfully. To evaluate motion artifact correction methods,\nwe propose a novel algorithm on how edge detection results are improved by\ndeblurred algorithm. Boosted by deep learning and adversarial training\nalgorithm, our model is trainable in an end-to-end manner, can be tested in\nreal-time and achieves the state-of-art results for CMR correction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 12:39:23 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Zhang", "Yunxuan", ""], ["Zhang", "Weiliang", ""], ["Zhang", "Qinyan", ""], ["Yang", "Jijiang", ""], ["Chen", "Xiuyu", ""], ["Zhao", "Shihua", ""]]}, {"id": "1902.11122", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos and Dimitrios Koutsouris", "title": "Deep Learning in Cardiology", "comments": "27 pages, 2 figures, 10 tables", "journal-ref": "IEEE Reviews in Biomedical Engineering 12 (2019): 168-193", "doi": "10.1109/RBME.2018.2885714", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical field is creating large amount of data that physicians are unable\nto decipher and use efficiently. Moreover, rule-based expert systems are\ninefficient in solving complicated medical tasks or for creating insights using\nbig data. Deep learning has emerged as a more accurate and effective technology\nin a wide range of medical problems such as diagnosis, prediction and\nintervention. Deep learning is a representation learning method that consists\nof layers that transform the data non-linearly, thus, revealing hierarchical\nrelationships and structures. In this review we survey deep learning\napplication papers that use structured data, signal and imaging modalities from\ncardiology. We discuss the advantages and limitations of applying deep learning\nin cardiology that also apply in medicine in general, while proposing certain\ndirections as the most viable for clinical use.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:09:11 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 21:22:09 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:43:32 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""], ["Koutsouris", "Dimitrios", ""]]}, {"id": "1902.11123", "submitter": "Mennatullah Siam M.S.", "authors": "Mennatullah Siam, Boris Oreshkin, Martin Jagersand", "title": "Adaptive Masked Proxies for Few-Shot Segmentation", "comments": "Accepted to ICCV'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has thrived by training on large-scale datasets. However, in\nrobotics applications sample efficiency is critical. We propose a novel\nadaptive masked proxies method that constructs the final segmentation layer\nweights from few labelled samples. It utilizes multi-resolution average pooling\non base embeddings masked with the label to act as a positive proxy for the new\nclass, while fusing it with the previously learned class signatures. Our method\nis evaluated on PASCAL-$5^i$ dataset and outperforms the state-of-the-art in\nthe few-shot semantic segmentation. Unlike previous methods, our approach does\nnot require a second branch to estimate parameters or prototypes, which enables\nit to be used with 2-stream motion and appearance based segmentation networks.\nWe further propose a novel setup for evaluating continual learning of object\nsegmentation which we name incremental PASCAL (iPASCAL) where our method\noutperforms the baseline method. Our code is publicly available at\nhttps://github.com/MSiam/AdaptiveMaskedProxies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 22:28:02 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 22:31:32 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 15:16:40 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 04:04:44 GMT"}, {"version": "v5", "created": "Mon, 14 Oct 2019 19:56:53 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Siam", "Mennatullah", ""], ["Oreshkin", "Boris", ""], ["Jagersand", "Martin", ""]]}, {"id": "1902.11124", "submitter": "Mingpan Guo", "authors": "Mingpan Guo, Stefan Matthes, Jiaojiao Ye, Hao Shen", "title": "A Generative Map for Image-based Camera Localization", "comments": "typo fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image-based camera localization systems, information about the environment\nis usually stored in some representation, which can be referred to as a map.\nConventionally, most maps are built upon hand-crafted features. Recently,\nneural networks have attracted attention as a data-driven map representation,\nand have shown promising results in visual localization. However, these neural\nnetwork maps are generally hard to interpret by human. A readable map is not\nonly accessible to humans, but also provides a way to be verified when the\nground truth pose is unavailable. To tackle this problem, we propose Generative\nMap, a new framework for learning human-readable neural network maps, by\ncombining a generative model with the Kalman filter, which also allows it to\nincorporate additional sensor information such as stereo visual odometry. For\nevaluation, we use real world images from the 7-Scenes and Oxford RobotCar\ndatasets. We demonstrate that our Generative Map can be queried with a pose of\ninterest from the test sequence to predict an image, which closely resembles\nthe true scene. For localization, we show that Generative Map achieves\ncomparable performance with current regression models. Moreover, our framework\nis trained completely from scratch, unlike regression models which rely on\nlarge ImageNet pretrained networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 13:18:36 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 13:13:46 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 11:08:38 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 15:59:29 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Guo", "Mingpan", ""], ["Matthes", "Stefan", ""], ["Ye", "Jiaojiao", ""], ["Shen", "Hao", ""]]}, {"id": "1902.11128", "submitter": "Chuteng Zhou", "authors": "Paul N. Whatmough, Chuteng Zhou, Patrick Hansen, Shreyas Kolala\n  Venkataramanaiah, Jae-sun Seo, Matthew Mattina", "title": "FixyNN: Efficient Hardware for Mobile Computer Vision via Transfer\n  Learning", "comments": "10 pages, 8 figures, paper accepted at SysML2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational demands of computer vision tasks based on state-of-the-art\nConvolutional Neural Network (CNN) image classification far exceed the energy\nbudgets of mobile devices. This paper proposes FixyNN, which consists of a\nfixed-weight feature extractor that generates ubiquitous CNN features, and a\nconventional programmable CNN accelerator which processes a dataset-specific\nCNN. Image classification models for FixyNN are trained end-to-end via transfer\nlearning, with the common feature extractor representing the transfered part,\nand the programmable part being learnt on the target dataset. Experimental\nresults demonstrate FixyNN hardware can achieve very high energy efficiencies\nup to 26.6 TOPS/W ($4.81 \\times$ better than iso-area programmable\naccelerator). Over a suite of six datasets we trained models via transfer\nlearning with an accuracy loss of $<1\\%$ resulting in up to 11.2 TOPS/W -\nnearly $2 \\times$ more efficient than a conventional programmable CNN\naccelerator of the same area.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 02:42:33 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Whatmough", "Paul N.", ""], ["Zhou", "Chuteng", ""], ["Hansen", "Patrick", ""], ["Venkataramanaiah", "Shreyas Kolala", ""], ["Seo", "Jae-sun", ""], ["Mattina", "Matthew", ""]]}, {"id": "1902.11132", "submitter": "M. Salman Asif", "authors": "Rakib Hyder and M. Salman Asif", "title": "Generative Models for Low-Rank Video Representation and Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2977256", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding compact representation of videos is an essential component in almost\nevery problem related to video processing or understanding. In this paper, we\npropose a generative model to learn compact latent codes that can efficiently\nrepresent and reconstruct a video sequence from its missing or under-sampled\nmeasurements. We use a generative network that is trained to map a compact code\ninto an image. We first demonstrate that if a video sequence belongs to the\nrange of the pretrained generative network, then we can recover it by\nestimating the underlying compact latent codes. Then we demonstrate that even\nif the video sequence does not belong to the range of a pretrained network, we\ncan still recover the true video sequence by jointly updating the latent codes\nand the weights of the generative network. To avoid overfitting in our model,\nwe regularize the recovery problem by imposing low-rank and similarity\nconstraints on the latent codes of the neighboring frames in the video\nsequence. We use our methods to recover a variety of videos from compressive\nmeasurements at different compression rates. We also demonstrate that we can\ngenerate missing frames in a video sequence by interpolating the latent codes\nof the observed frames in the low-dimensional space.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:48:23 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hyder", "Rakib", ""], ["Asif", "M. Salman", ""]]}, {"id": "1902.11133", "submitter": "Debayan Ganguly", "authors": "Swagato Chatterjee, Rwik Kumar Dutta, Debayan Ganguly, Kingshuk\n  Chatterjee and Sudipta Roy", "title": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:52:53 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chatterjee", "Swagato", ""], ["Dutta", "Rwik Kumar", ""], ["Ganguly", "Debayan", ""], ["Chatterjee", "Kingshuk", ""], ["Roy", "Sudipta", ""]]}, {"id": "1902.11134", "submitter": "Zhenyu Duan", "authors": "Zhenyu Duan, Martin Renqiang Min, Li Erran Li, Mingbo Cai, Yi Xu,\n  Bingbing Ni", "title": "Disentangled Deep Autoencoding Regularization for Robust Image\n  Classification", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of achieving revolutionary successes in machine learning, deep\nconvolutional neural networks have been recently found to be vulnerable to\nadversarial attacks and difficult to generalize to novel test images with\nreasonably large geometric transformations. Inspired by a recent neuroscience\ndiscovery revealing that primate brain employs disentangled shape and\nappearance representations for object recognition, we propose a general\ndisentangled deep autoencoding regularization framework that can be easily\napplied to any deep embedding based classification model for improving the\nrobustness of deep neural networks. Our framework effectively learns\ndisentangled appearance code and geometric code for robust image\nclassification, which is the first disentangling based method defending against\nadversarial attacks and complementary to standard defense methods. Extensive\nexperiments on several benchmark datasets show that, our proposed\nregularization framework leveraging disentangled embedding significantly\noutperforms traditional unregularized convolutional neural networks for image\nclassification on robustness against adversarial attacks and generalization to\nnovel test data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 04:49:57 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Duan", "Zhenyu", ""], ["Min", "Martin Renqiang", ""], ["Li", "Li Erran", ""], ["Cai", "Mingbo", ""], ["Xu", "Yi", ""], ["Ni", "Bingbing", ""]]}, {"id": "1902.11136", "submitter": "Emmanuel De B\\'ezenac", "authors": "Ibrahim Ayed, Emmanuel de B\\'ezenac, Arthur Pajot, Julien Brajard,\n  Patrick Gallinari", "title": "Learning Dynamical Systems from Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.DS physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of forecasting complex, nonlinear space-time\nprocesses when observations provide only partial information of on the system's\nstate. We propose a natural data-driven framework, where the system's dynamics\nare modelled by an unknown time-varying differential equation, and the\nevolution term is estimated from the data, using a neural network. Any future\nstate can then be computed by placing the associated differential equation in\nan ODE solver. We first evaluate our approach on shallow water and Euler\nsimulations. We find that our method not only demonstrates high quality\nlong-term forecasts, but also learns to produce hidden states closely\nresembling the true states of the system, without direct supervision on the\nlatter. Additional experiments conducted on challenging, state of the art ocean\nsimulations further validate our findings, while exhibiting notable\nimprovements over classical baselines.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 12:50:49 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Pajot", "Arthur", ""], ["Brajard", "Julien", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1902.11153", "submitter": "Xinsheng Xuan", "authors": "Xinsheng Xuan, Bo Peng, Wei Wang and Jing Dong", "title": "On the generalization of GAN image forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the GAN generated face images are more and more realistic with\nhigh-quality, even hard for human eyes to detect. On the other hand, the\nforensics community keeps on developing methods to detect these generated fake\nimages and try to guarantee the credibility of visual contents. Although\nresearchers have developed some methods to detect generated images, few of them\nexplore the important problem of generalization ability of forensics model. As\nnew types of GANs are emerging fast, the generalization ability of forensics\nmodels to detect new types of GAN images is absolutely an essential research\ntopic. In this paper, we explore this problem and propose to use preprocessed\nimages to train a forensic CNN model. By applying similar image level\npreprocessing to both real and fake training images, the forensics model is\nforced to learn more intrinsic features to classify the generated and real face\nimages. Our experimental results also prove the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 07:05:38 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 08:19:47 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Xuan", "Xinsheng", ""], ["Peng", "Bo", ""], ["Wang", "Wei", ""], ["Dong", "Jing", ""]]}, {"id": "1902.11156", "submitter": "Dominik St\\\"oger", "authors": "Felix Krahmer, Dominik St\\\"oger", "title": "On the convex geometry of blind deconvolution and matrix completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix recovery from structured measurements has been a topic of\nintense study in the last decade and many important problems like matrix\ncompletion and blind deconvolution have been formulated in this framework. An\nimportant benchmark method to solve these problems is to minimize the nuclear\nnorm, a convex proxy for the rank. A common approach to establish recovery\nguarantees for this convex program relies on the construction of a so-called\napproximate dual certificate. However, this approach provides only limited\ninsight in various respects. Most prominently, the noise bounds exhibit\nseemingly suboptimal dimension factors. In this paper we take a novel, more\ngeometric viewpoint to analyze both the matrix completion and the blind\ndeconvolution scenario. We find that for both these applications the dimension\nfactors in the noise bounds are not an artifact of the proof, but the problems\nare intrinsically badly conditioned. We show, however, that bad conditioning\nonly arises for very small noise levels: Under mild assumptions that include\nmany realistic noise levels we derive near-optimal error estimates for blind\ndeconvolution under adversarial noise.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:30:41 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 16:29:10 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 20:02:52 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Krahmer", "Felix", ""], ["St\u00f6ger", "Dominik", ""]]}, {"id": "1902.11163", "submitter": "Sindri Magn\\'usson Mr.", "authors": "Sindri Magn\\'usson, Hossein Shokri-Ghadikolaei, and Na Li", "title": "On Maintaining Linear Convergence of Distributed Learning and\n  Optimization under Limited Communication", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3031073", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed optimization and machine learning, multiple nodes coordinate\nto solve large problems. To do this, the nodes need to compress important\nalgorithm information to bits so that it can be communicated over a digital\nchannel. The communication time of these algorithms follows a complex interplay\nbetween a) the algorithm's convergence properties, b) the compression scheme,\nand c) the transmission rate offered by the digital channel. We explore these\nrelationships for a general class of linearly convergent distributed\nalgorithms. In particular, we illustrate how to design quantizers for these\nalgorithms that compress the communicated information to a few bits while still\npreserving the linear convergence. Moreover, we characterize the communication\ntime of these algorithms as a function of the available transmission rate. We\nillustrate our results on learning algorithms using different communication\nstructures, such as decentralized algorithms where a single master coordinates\ninformation from many workers and fully distributed algorithms where only\nneighbours in a communication graph can communicate. We conclude that a\nco-design of machine learning and communication protocols are mandatory to\nflourish machine learning over networks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 03:00:55 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 19:40:21 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 20:59:33 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 09:37:33 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Magn\u00fasson", "Sindri", ""], ["Shokri-Ghadikolaei", "Hossein", ""], ["Li", "Na", ""]]}, {"id": "1902.11175", "submitter": "Neel Guha", "authors": "Neel Guha, Ameet Talwalkar, Virginia Smith", "title": "One-Shot Federated Learning", "comments": "5 pages, 3 figures, 1 table. 2nd Workshop on Machine Learning on the\n  Phone and other Consumer Devices, NeurIPs 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present one-shot federated learning, where a central server learns a\nglobal model over a network of federated devices in a single round of\ncommunication. Our approach - drawing on ensemble learning and knowledge\naggregation - achieves an average relative gain of 51.5% in AUC over local\nbaselines and comes within 90.1% of the (unattainable) global ideal. We discuss\nthese methods and identify several promising directions of future work.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:55:18 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 20:33:39 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Guha", "Neel", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "1902.11189", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist and Dexter Kozen", "title": "Semantics of higher-order probabilistic programs with conditioning", "comments": "17 pages, proofs in the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a denotational semantics for higher-order probabilistic programs\nin terms of linear operators between Banach spaces. Our semantics is rooted in\nthe classical theory of Banach spaces and their tensor products, but bears\nsimilarities with the well-known Scott semantics of higher-order programs\nthrough the use ordered Banach spaces which allow definitions in terms of fixed\npoints. Being based on a monoidal rather than cartesian closed structure, our\nsemantics effectively treats randomness as a resource.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:17:33 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Kozen", "Dexter", ""]]}, {"id": "1902.11199", "submitter": "Jean Tarbouriech", "authors": "Jean Tarbouriech, Alessandro Lazaric", "title": "Active Exploration in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the active exploration problem in Markov decision processes\n(MDPs). Each state of the MDP is characterized by a random value and the\nlearner should gather samples to estimate the mean value of each state as\naccurately as possible. Similarly to active exploration in multi-armed bandit\n(MAB), states may have different levels of noise, so that the higher the noise,\nthe more samples are needed. As the noise level is initially unknown, we need\nto trade off the exploration of the environment to estimate the noise and the\nexploitation of these estimates to compute a policy maximizing the accuracy of\nthe mean predictions. We introduce a novel learning algorithm to solve this\nproblem showing that active exploration in MDPs may be significantly more\ndifficult than in MAB. We also derive a heuristic procedure to mitigate the\nnegative effect of slowly mixing policies. Finally, we validate our findings on\nsimple numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:38:28 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Tarbouriech", "Jean", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1902.11208", "submitter": "Gideon Maillette De Buy Wenniger", "authors": "Gideon Maillette de Buy Wenniger, Lambert Schomaker, Andy Way", "title": "No Padding Please: Efficient Neural Handwriting Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/ICDAR.2019.00064", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural handwriting recognition (NHR) is the recognition of handwritten text\nwith deep learning models, such as multi-dimensional long short-term memory\n(MDLSTM) recurrent neural networks. Models with MDLSTM layers have achieved\nstate-of-the art results on handwritten text recognition tasks. While\nmulti-directional MDLSTM-layers have an unbeaten ability to capture the\ncomplete context in all directions, this strength limits the possibilities for\nparallelization, and therefore comes at a high computational cost. In this work\nwe develop methods to create efficient MDLSTM-based models for NHR,\nparticularly a method aimed at eliminating computation waste that results from\npadding. This proposed method, called example-packing, replaces wasteful\nstacking of padded examples with efficient tiling in a 2-dimensional grid. For\nword-based NHR this yields a speed improvement of factor 6.6 over an already\nefficient baseline of minimal padding for each batch separately. For line-based\nNHR the savings are more modest, but still significant. In addition to\nexample-packing, we propose: 1) a technique to optimize parallelization for\ndynamic graph definition frameworks including PyTorch, using convolutions with\ngrouping, 2) a method for parallelization across GPUs for variable-length\nexample batches. All our techniques are thoroughly tested on our own PyTorch\nre-implementation of MDLSTM-based NHR models. A thorough evaluation on the IAM\ndataset shows that our models are performing similar to earlier implementations\nof state-of-the-art models. Our efficient NHR model and some of the reusable\ntechniques discussed with it offer ways to realize relatively efficient models\nfor the omnipresent scenario of variable-length inputs in deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:46:43 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Wenniger", "Gideon Maillette de Buy", ""], ["Schomaker", "Lambert", ""], ["Way", "Andy", ""]]}, {"id": "1902.11216", "submitter": "Bernd Huber", "authors": "Bernd Huber, Hijung Valentina Shin, Bryan Russell, Oliver Wang,\n  Gautham J. Mysore", "title": "B-Script: Transcript-based B-roll Video Editing with Recommendations", "comments": "11 pages, 10 figures, CHI 2019", "journal-ref": null, "doi": "10.1145/3290605.3300311", "report-no": null, "categories": "cs.HC cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In video production, inserting B-roll is a widely used technique to enrich\nthe story and make a video more engaging. However, determining the right\ncontent and positions of B-roll and actually inserting it within the main\nfootage can be challenging, and novice producers often struggle to get both\ntiming and content right. We present B-Script, a system that supports B-roll\nvideo editing via interactive transcripts. B-Script has a built-in\nrecommendation system trained on expert-annotated data, recommending users\nB-roll position and content. To evaluate the system, we conducted a\nwithin-subject user study with 110 participants, and compared three interface\nvariations: a timeline-based editor, a transcript-based editor, and a\ntranscript-based editor with recommendations. Users found it easier and were\nfaster to insert B-roll using the transcript-based interface, and they created\nmore engaging videos when recommendations were provided.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 17:01:29 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Huber", "Bernd", ""], ["Shin", "Hijung Valentina", ""], ["Russell", "Bryan", ""], ["Wang", "Oliver", ""], ["Mysore", "Gautham J.", ""]]}, {"id": "1902.11237", "submitter": "Kassem Kallas", "authors": "Mauro Barni, Kassem Kallas, Benedetta Tondi", "title": "A new Backdoor Attack in CNNs by training set corruption without label\n  poisoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks against CNNs represent a new threat against deep learning\nsystems, due to the possibility of corrupting the training set so to induce an\nincorrect behaviour at test time. To avoid that the trainer recognises the\npresence of the corrupted samples, the corruption of the training set must be\nas stealthy as possible. Previous works have focused on the stealthiness of the\nperturbation injected into the training samples, however they all assume that\nthe labels of the corrupted samples are also poisoned. This greatly reduces the\nstealthiness of the attack, since samples whose content does not agree with the\nlabel can be identified by visual inspection of the training set or by running\na pre-classification step. In this paper we present a new backdoor attack\nwithout label poisoning Since the attack works by corrupting only samples of\nthe target class, it has the additional advantage that it does not need to\nidentify beforehand the class of the samples to be attacked at test time.\nResults obtained on the MNIST digits recognition task and the traffic signs\nclassification task show that backdoor attacks without label poisoning are\nindeed possible, thus raising a new alarm regarding the use of deep learning in\nsecurity-critical applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 16:27:41 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Barni", "Mauro", ""], ["Kallas", "Kassem", ""], ["Tondi", "Benedetta", ""]]}, {"id": "1902.11245", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin and Mohammad Ali Zamani and Cornelius Weber and Sven\n  Magg and Stefan Wermter", "title": "Incorporating End-to-End Speech Recognition Models for Sentiment\n  Analysis", "comments": "Accepted at the 2019 International Conference on Robotics and\n  Automation (ICRA) will be held on May 20-24, 2019 in Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on emotion recognition demonstrated a synergistic effect of\ncombining several modalities such as auditory, visual, and transcribed text to\nestimate the affective state of a speaker. Among these, the linguistic modality\nis crucial for the evaluation of an expressed emotion. However, manually\ntranscribed spoken text cannot be given as input to a system practically. We\nargue that using ground-truth transcriptions during training and evaluation\nphases leads to a significant discrepancy in performance compared to real-world\nconditions, as the spoken text has to be recognized on the fly and can contain\nspeech recognition mistakes. In this paper, we propose a method of integrating\nan automatic speech recognition (ASR) output with a character-level recurrent\nneural network for sentiment recognition. In addition, we conduct several\nexperiments investigating sentiment recognition for human-robot interaction in\na noise-realistic scenario which is challenging for the ASR systems. We\nquantify the improvement compared to using only the acoustic modality in\nsentiment recognition. We demonstrate the effectiveness of this approach on the\nMultimodal Corpus of Sentiment Intensity (MOSI) by achieving 73,6% accuracy in\na binary sentiment classification task, exceeding previously reported results\nthat use only acoustic input. In addition, we set a new state-of-the-art\nperformance on the MOSI dataset (80.4% accuracy, 2% absolute improvement).\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 17:48:20 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Lakomkin", "Egor", ""], ["Zamani", "Mohammad Ali", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1902.11259", "submitter": "Dylan Foster", "authors": "Jayadev Acharya and Christopher De Sa and Dylan J. Foster and Karthik\n  Sridharan", "title": "Distributed Learning with Sublinear Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed statistical learning, $N$ samples are split across $m$\nmachines and a learner wishes to use minimal communication to learn as well as\nif the examples were on a single machine. This model has received substantial\ninterest in machine learning due to its scalability and potential for parallel\nspeedup. However, in high-dimensional settings, where the number examples is\nsmaller than the number of features (\"dimension\"), the speedup afforded by\ndistributed learning may be overshadowed by the cost of communicating a single\nexample. This paper investigates the following question: When is it possible to\nlearn a $d$-dimensional model in the distributed setting with total\ncommunication sublinear in $d$?\n  Starting with a negative result, we show that for learning $\\ell_1$-bounded\nor sparse linear models, no algorithm can obtain optimal error until\ncommunication is linear in dimension. Our main result is that that by slightly\nrelaxing the standard boundedness assumptions for linear models, we can obtain\ndistributed algorithms that enjoy optimal error with communication logarithmic\nin dimension. This result is based on a family of algorithms that combine\nmirror descent with randomized sparsification/quantization of iterates, and\nextends to the general stochastic convex optimization model.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:05:12 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 00:23:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Acharya", "Jayadev", ""], ["De Sa", "Christopher", ""], ["Foster", "Dylan J.", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1902.11261", "submitter": "Sirisha Rambhatla", "authors": "Sirisha Rambhatla, Xingguo Li, and Jarvis Haupt", "title": "NOODL: Provable Online Dictionary Learning and Sparse Coding", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2019; 42 Pages with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dictionary learning problem, where the aim is to model the\ngiven data as a linear combination of a few columns of a matrix known as a\ndictionary, where the sparse weights forming the linear combination are known\nas coefficients. Since the dictionary and coefficients, parameterizing the\nlinear model are unknown, the corresponding optimization is inherently\nnon-convex. This was a major challenge until recently, when provable algorithms\nfor dictionary learning were proposed. Yet, these provide guarantees only on\nthe recovery of the dictionary, without explicit recovery guarantees on the\ncoefficients. Moreover, any estimation error in the dictionary adversely\nimpacts the ability to successfully localize and estimate the coefficients.\nThis potentially limits the utility of existing provable dictionary learning\nmethods in applications where coefficient recovery is of interest. To this end,\nwe develop NOODL: a simple Neurally plausible alternating Optimization-based\nOnline Dictionary Learning algorithm, which recovers both the dictionary and\ncoefficients exactly at a geometric rate, when initialized appropriately. Our\nalgorithm, NOODL, is also scalable and amenable for large scale distributed\nimplementations in neural architectures, by which we mean that it only involves\nsimple linear and non-linear operations. Finally, we corroborate these\ntheoretical results via experimental evaluation of the proposed algorithm with\nthe current state-of-the-art techniques.\n  Keywords: dictionary learning, provable dictionary learning, online\ndictionary learning, non-convex, sparse coding, support recovery, iterative\nhard thresholding, matrix factorization, neural architectures, neural networks,\nnoodl, sparse representations, sparse signal processing.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:08:01 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 18:46:33 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 17:23:39 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 19:58:36 GMT"}, {"version": "v5", "created": "Tue, 27 Aug 2019 21:54:27 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Rambhatla", "Sirisha", ""], ["Li", "Xingguo", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1902.11269", "submitter": "Liunian Harold Li", "authors": "Liunian Harold Li, Patrick H. Chen, Cho-Jui Hsieh, Kai-Wei Chang", "title": "Efficient Contextual Representation Learning Without Softmax Layer", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual representation models have achieved great success in improving\nvarious downstream tasks. However, these language-model-based encoders are\ndifficult to train due to the large parameter sizes and high computational\ncomplexity. By carefully examining the training procedure, we find that the\nsoftmax layer (the output layer) causes significant inefficiency due to the\nlarge vocabulary size. Therefore, we redesign the learning objective and\npropose an efficient framework for training contextual representation models.\nSpecifically, the proposed approach bypasses the softmax layer by performing\nlanguage modeling with dimension reduction, and allows the models to leverage\npre-trained word embeddings. Our framework reduces the time spent on the output\nlayer to a negligible level, eliminates almost all the trainable parameters of\nthe softmax layer and performs language modeling without truncating the\nvocabulary. When applied to ELMo, our method achieves a 4 times speedup and\neliminates 80% trainable parameters while achieving competitive performance on\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:19:14 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Li", "Liunian Harold", ""], ["Chen", "Patrick H.", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1902.11280", "submitter": "Jerome Abdelnour", "authors": "Jerome Abdelnour, Giampiero Salvi, Jean Rouat", "title": "From Visual to Acoustic Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the new task of Acoustic Question Answering (AQA) to promote\nresearch in acoustic reasoning. The AQA task consists of analyzing an acoustic\nscene composed by a combination of elementary sounds and answering questions\nthat relate the position and properties of these sounds. The kind of relational\nquestions asked, require that the models perform non-trivial reasoning in order\nto answer correctly. Although similar problems have been extensively studied in\nthe domain of visual reasoning, we are not aware of any previous studies\naddressing the problem in the acoustic domain. We propose a method for\ngenerating the acoustic scenes from elementary sounds and a number of relevant\nquestions for each scene using templates. We also present preliminary results\nobtained with two models (FiLM and MAC) that have been shown to work for visual\nreasoning.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:35:45 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Abdelnour", "Jerome", ""], ["Salvi", "Giampiero", ""], ["Rouat", "Jean", ""]]}, {"id": "1902.11281", "submitter": "Uthaipon Tantipongpipat", "authors": "Uthaipon Tantipongpipat, Samira Samadi, Mohit Singh, Jamie\n  Morgenstern, Santosh Vempala", "title": "Multi-Criteria Dimensionality Reduction with Applications to Fairness", "comments": "The preliminary version appeared in NeurIPS2019. This version\n  combines the motivation from \"The Price of Fair PCA: One Extra Dimension\"\n  (NeurIPS 2018) by the same set of author, adds new a motivation, and\n  introduces new heuristics and more experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is a classical technique widely used for data\nanalysis. One foundational instantiation is Principal Component Analysis (PCA),\nwhich minimizes the average reconstruction error. In this paper, we introduce\nthe \"multi-criteria dimensionality reduction\" problem where we are given\nmultiple objectives that need to be optimized simultaneously. As an\napplication, our model captures several fairness criteria for dimensionality\nreduction such as our novel Fair-PCA problem and the Nash Social Welfare (NSW)\nproblem. In Fair-PCA, the input data is divided into $k$ groups, and the goal\nis to find a single $d$-dimensional representation for all groups for which the\nminimum variance of any one group is maximized. In NSW, the goal is to maximize\nthe product of the individual variances of the groups achieved by the common\nlow-dimensional space.\n  Our main result is an exact polynomial-time algorithm for the two-criterion\ndimensionality reduction problem when the two criteria are increasing concave\nfunctions. As an application of this result, we obtain a polynomial time\nalgorithm for Fair-PCA for $k=2$ groups and a polynomial time algorithm for NSW\nobjective for $k=2$ groups. We also give approximation algorithms for $k>2$.\nOur technical contribution in the above results is to prove new low-rank\nproperties of extreme point solutions to semi-definite programs. We conclude\nwith experiments indicating the effectiveness of algorithms based on extreme\npoint solutions of semi-definite programs on several real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:37:18 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 17:36:00 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 13:40:52 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Tantipongpipat", "Uthaipon", ""], ["Samadi", "Samira", ""], ["Singh", "Mohit", ""], ["Morgenstern", "Jamie", ""], ["Vempala", "Santosh", ""]]}, {"id": "1902.11294", "submitter": "Vincent Corlay", "authors": "Vincent Corlay, Joseph J. Boutros, Philippe Ciblat, Loic Brunel", "title": "A lattice-based approach to the expressivity of deep ReLU neural\n  networks", "comments": "arXiv admin note: text overlap with arXiv:1902.05146", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new families of continuous piecewise linear (CPWL) functions in Rn\nhaving a number of affine pieces growing exponentially in $n$. We show that\nthese functions can be seen as the high-dimensional generalization of the\ntriangle wave function used by Telgarsky in 2016. We prove that they can be\ncomputed by ReLU networks with quadratic depth and linear width in the space\ndimension. We also investigate the approximation error of one of these\nfunctions by shallower networks and prove a separation result. The main\ndifference between our functions and other constructions is their practical\ninterest: they arise in the scope of channel coding. Hence, computing such\nfunctions amounts to performing a decoding operation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:52:35 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 10:55:35 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Corlay", "Vincent", ""], ["Boutros", "Joseph J.", ""], ["Ciblat", "Philippe", ""], ["Brunel", "Loic", ""]]}]