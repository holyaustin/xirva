[{"id": "1710.00018", "submitter": "Vladimir Pavlovic", "authors": "Cuong D. Tran and Ognjen Rudovic and Vladimir Pavlovic", "title": "Unsupervised Domain Adaptation with Copula Models", "comments": "IEEE International Workshop On Machine Learning for Signal Processing\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of unsupervised domain adaptation, where no labeled data\nfrom the target domain is provided during training time. To deal with the\npotential discrepancy between the source and target distributions, both in\nfeatures and labels, we exploit a copula-based regression framework. The\nbenefits of this approach are two-fold: (a) it allows us to model a broader\nrange of conditional predictive densities beyond the common exponential family,\n(b) we show how to leverage Sklar's theorem, the essence of the copula\nformulation relating the joint density to the copula dependency functions, to\nfind effective feature mappings that mitigate the domain mismatch. By\ntransforming the data to a copula domain, we show on a number of benchmark\ndatasets (including human emotion estimation), and using different regression\nmodels for prediction, that we can achieve a more robust and accurate\nestimation of target labels, compared to recently proposed feature\ntransformation (adaptation) methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 18:14:55 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Tran", "Cuong D.", ""], ["Rudovic", "Ognjen", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1710.00032", "submitter": "Saurav Talukdar", "authors": "Saurav Talukdar, Deepjyoti Deka, Sandeep Attree, Donatello Materassi\n  and Murti V. Salapaka", "title": "Learning the Exact Topology of Undirected Consensus Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a method to learn the interaction topology of a\nnetwork of agents undergoing linear consensus updates in a non invasive manner.\nOur approach is based on multivariate Wiener filtering, which is known to\nrecover spurious edges apart from the true edges in the topology. The main\ncontribution of this work is to show that in the case of undirected consensus\nnetworks, all spurious links obtained using Wiener filtering can be identified\nusing frequency response of the Wiener filters. Thus, the exact interaction\ntopology of the agents is unveiled. The method presented requires time series\nmeasurements of the state of the agents and does not require any knowledge of\nlink weights. To the best of our knowledge this is the first approach that\nprovably reconstructs the structure of undirected consensus networks with\ncorrelated noise. We illustrate the effectiveness of the method developed\nthrough numerical simulations as well as experiments on a five node network of\nRaspberry Pis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 18:57:39 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Talukdar", "Saurav", ""], ["Deka", "Deepjyoti", ""], ["Attree", "Sandeep", ""], ["Materassi", "Donatello", ""], ["Salapaka", "Murti V.", ""]]}, {"id": "1710.00085", "submitter": "Niko Br\\\"ummer", "authors": "Niko Br\\\"ummer and Albert Swart", "title": "Language-depedent I-Vectors for LRE15", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard recipe for spoken language recognition is to apply a Gaussian\nback-end to i-vectors. This ignores the uncertainty in the i-vector extraction,\nwhich could be important especially for short utterances. A recent paper by\nCumani, Plchot and Fer proposes a solution to propagate that uncertainty into\nthe backend. We propose an alternative method of propagating the uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 20:43:24 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Br\u00fcmmer", "Niko", ""], ["Swart", "Albert", ""]]}, {"id": "1710.00095", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Avetik G. Karagulyan", "title": "User-friendly guarantees for the Langevin Monte Carlo with inaccurate\n  gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from a given probability\ndensity function that is known to be smooth and strongly log-concave. We\nanalyze several methods of approximate sampling based on discretizations of the\n(highly overdamped) Langevin diffusion and establish guarantees on its error\nmeasured in the Wasserstein-2 distance. Our guarantees improve or extend the\nstate-of-the-art results in three directions. First, we provide an upper bound\non the error of the first-order Langevin Monte Carlo (LMC) algorithm with\noptimized varying step-size. This result has the advantage of being horizon\nfree (we do not need to know in advance the target precision) and to improve by\na logarithmic factor the corresponding result for the constant step-size.\nSecond, we study the case where accurate evaluations of the gradient of the\nlog-density are unavailable, but one can have access to approximations of the\naforementioned gradient. In such a situation, we consider both deterministic\nand stochastic approximations of the gradient and provide an upper bound on the\nsampling error of the first-order LMC that quantifies the impact of the\ngradient evaluation inaccuracies. Third, we establish upper bounds for two\nversions of the second-order LMC, which leverage the Hessian of the\nlog-density. We nonasymptotic guarantees on the sampling error of these\nsecond-order LMCs. These guarantees reveal that the second-order LMC algorithms\nimprove on the first-order LMC in ill-conditioned settings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 21:15:03 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 21:01:23 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 11:46:52 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Karagulyan", "Avetik G.", ""]]}, {"id": "1710.00112", "submitter": "Sayed Hadi Hashemi", "authors": "Faraz Faghri, Sayed Hadi Hashemi, Mohammad Babaeizadeh, Mike A. Nalls,\n  Saurabh Sinha, Roy H. Campbell", "title": "Toward Scalable Machine Learning and Data Mining: the Bioinformatics\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to overcome the data deluge in computational biology and\nbioinformatics and to facilitate bioinformatics research in the era of big\ndata, we identify some of the most influential algorithms that have been widely\nused in the bioinformatics community. These top data mining and machine\nlearning algorithms cover classification, clustering, regression, graphical\nmodel-based learning, and dimensionality reduction. The goal of this study is\nto guide the focus of scalable computing experts in the endeavor of applying\nnew storage and scalable computation designs to bioinformatics algorithms that\nmerit their attention most, following the engineering maxim of \"optimize the\ncommon case\".\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 22:29:19 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Faghri", "Faraz", ""], ["Hashemi", "Sayed Hadi", ""], ["Babaeizadeh", "Mohammad", ""], ["Nalls", "Mike A.", ""], ["Sinha", "Saurabh", ""], ["Campbell", "Roy H.", ""]]}, {"id": "1710.00209", "submitter": "Gal Hyams", "authors": "Gal Hyams, Daniel Greenfeld, Dor Bank", "title": "Improved Training for Self-Training by Confidence Assessments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that for some tasks, labeled data sets may be hard to\ngather. Therefore, we wished to tackle here the problem of having insufficient\ntraining data. We examined learning methods from unlabeled data after an\ninitial training on a limited labeled data set. The suggested approach can be\nused as an online learning method on the unlabeled test set. In the general\nclassification task, whenever we predict a label with high enough confidence,\nwe treat it as a true label and train the data accordingly. For the semantic\nsegmentation task, a classic example for an expensive data labeling process, we\ndo so pixel-wise. Our suggested approaches were applied on the MNIST data-set\nas a proof of concept for a vision classification task and on the ADE20K\ndata-set in order to tackle the semi-supervised semantic segmentation problem.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 14:47:06 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 14:42:52 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Hyams", "Gal", ""], ["Greenfeld", "Daniel", ""], ["Bank", "Dor", ""]]}, {"id": "1710.00211", "submitter": "Bing Yu", "authors": "Weinan E, Bing Yu", "title": "The Deep Ritz method: A deep learning-based numerical algorithm for\n  solving variational problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning based method, the Deep Ritz Method, for\nnumerically solving variational problems, particularly the ones that arise from\npartial differential equations. The Deep Ritz method is naturally nonlinear,\nnaturally adaptive and has the potential to work in rather high dimensions. The\nframework is quite simple and fits well with the stochastic gradient descent\nmethod used in deep learning. We illustrate the method on several problems\nincluding some eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 15:06:14 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["E", "Weinan", ""], ["Yu", "Bing", ""]]}, {"id": "1710.00264", "submitter": "Samuel Hopkins", "authors": "Samuel B. Hopkins and David Steurer", "title": "Bayesian estimation from few samples: community detection and related\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient meta-algorithm for Bayesian estimation problems that\nis based on low-degree polynomials, semidefinite programming, and tensor\ndecomposition. The algorithm is inspired by recent lower bound constructions\nfor sum-of-squares and related to the method of moments. Our focus is on sample\ncomplexity bounds that are as tight as possible (up to additive lower-order\nterms) and often achieve statistical thresholds or conjectured computational\nthresholds.\n  Our algorithm recovers the best known bounds for community detection in the\nsparse stochastic block model, a widely-studied class of estimation problems\nfor community detection in graphs. We obtain the first recovery guarantees for\nthe mixed-membership stochastic block model (Airoldi et el.) in constant\naverage degree graphs---up to what we conjecture to be the computational\nthreshold for this model. We show that our algorithm exhibits a sharp\ncomputational threshold for the stochastic block model with multiple\ncommunities beyond the Kesten--Stigum bound---giving evidence that this task\nmay require exponential time.\n  The basic strategy of our algorithm is strikingly simple: we compute the\nbest-possible low-degree approximation for the moments of the posterior\ndistribution of the parameters and use a robust tensor decomposition algorithm\nto recover the parameters from these approximate posterior moments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 21:58:34 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Hopkins", "Samuel B.", ""], ["Steurer", "David", ""]]}, {"id": "1710.00283", "submitter": "Ding Zhao", "authors": "Zhiyuan Huang, Yaohui Guo, Henry Lam, Ding Zhao", "title": "A Versatile Approach to Evaluating and Testing Automated Vehicles based\n  on Kernel Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation and validation of complicated control systems are crucial to\nguarantee usability and safety. Usually, failure happens in some very rarely\nencountered situations, but once triggered, the consequence is disastrous.\nAccelerated Evaluation is a methodology that efficiently tests those\nrarely-occurring yet critical failures via smartly-sampled test cases. The\ndistribution used in sampling is pivotal to the performance of the method, but\nbuilding a suitable distribution requires case-by-case analysis. This paper\nproposes a versatile approach for constructing sampling distribution using\nkernel method. The approach uses statistical learning tools to approximate the\ncritical event sets and constructs distributions based on the unique properties\nof Gaussian distributions. We applied the method to evaluate the automated\nvehicles. Numerical experiments show proposed approach can robustly identify\nthe rare failures and significantly reduce the evaluation time.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 03:36:21 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Huang", "Zhiyuan", ""], ["Guo", "Yaohui", ""], ["Lam", "Henry", ""], ["Zhao", "Ding", ""]]}, {"id": "1710.00379", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Shao-Chuan Lee, Yu-An Chung, Tung-En Wu, Si-An Chen,\n  Hsuan-Tien Lin", "title": "libact: Pool-based Active Learning in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  libact is a Python package designed to make active learning easier for\ngeneral users. The package not only implements several popular active learning\nstrategies, but also features the active-learning-by-learning meta-algorithm\nthat assists the users to automatically select the best strategy on the fly.\nFurthermore, the package provides a unified interface for implementing more\nstrategies, models and application-specific labelers. The package is\nopen-source on Github, and can be easily installed from Python Package Index\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 17:18:03 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Lee", "Shao-Chuan", ""], ["Chung", "Yu-An", ""], ["Wu", "Tung-En", ""], ["Chen", "Si-An", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1710.00447", "submitter": "Hao Wang", "authors": "Hao Wang, Lisa Vo, Flavio P. Calmon, Muriel M\\'edard, Ken R. Duffy,\n  Mayank Varia", "title": "Privacy with Estimation Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the central problem in data privacy: how to share data with an\nanalyst while providing both privacy and utility guarantees to the user that\nowns the data. In this setting, we present an estimation-theoretic analysis of\nthe privacy-utility trade-off (PUT). Here, an analyst is allowed to reconstruct\n(in a mean-squared error sense) certain functions of the data (utility), while\nother private functions should not be reconstructed with distortion below a\ncertain threshold (privacy). We demonstrate how chi-square information captures\nthe fundamental PUT in this case and provide bounds for the best PUT. We\npropose a convex program to compute privacy-assuring mappings when the\nfunctions to be disclosed and hidden are known a priori and the data\ndistribution is known. We derive lower bounds on the minimum mean-squared error\nof estimating a target function from the disclosed data and evaluate the\nrobustness of our approach when an empirical distribution is used to compute\nthe privacy-assuring mappings instead of the true data distribution. We\nillustrate the proposed approach through two numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 01:14:10 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 03:03:17 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 15:25:29 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 20:51:37 GMT"}, {"version": "v5", "created": "Fri, 20 Mar 2020 14:12:00 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Wang", "Hao", ""], ["Vo", "Lisa", ""], ["Calmon", "Flavio P.", ""], ["M\u00e9dard", "Muriel", ""], ["Duffy", "Ken R.", ""], ["Varia", "Mayank", ""]]}, {"id": "1710.00450", "submitter": "D. H. S. Maithripala", "authors": "T. W. U. Madhushani, D. H. S. Maithripala and N. E. Leonard", "title": "Asymptotic Allocation Rules for a Class of Dynamic Multi-armed Bandit\n  Problems", "comments": "Pre-print submitted to 2018 American Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a class of Dynamic Multi-Armed Bandit problems where the\nreward can be modeled as the noisy output of a time varying linear stochastic\ndynamic system that satisfies some boundedness constraints. The class allows\nmany seemingly different problems with time varying option characteristics to\nbe considered in a single framework. It also opens up the possibility of\nconsidering many new problems of practical importance. For instance it affords\nthe simultaneous consideration of temporal option unavailabilities and the\ndepen- dencies between options with time varying option characteristics in a\nseamless manner. We show that, for this class of problems, the combination of\nany Upper Confidence Bound type algorithm with any efficient reward estimator\nfor the expected reward ensures the logarithmic bounding of the expected\ncumulative regret. We demonstrate the versatility of the approach by the\nexplicit consideration of a new example of practical interest.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 01:30:21 GMT"}, {"version": "v2", "created": "Sat, 7 Oct 2017 16:18:30 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Madhushani", "T. W. U.", ""], ["Maithripala", "D. H. S.", ""], ["Leonard", "N. E.", ""]]}, {"id": "1710.00459", "submitter": "Melrose Roderick", "authors": "Melrose Roderick, Christopher Grimm, Stefanie Tellex", "title": "Deep Abstract Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of learning and planning on high-dimensional domains\nwith long horizons and sparse rewards. Recent approaches have shown great\nsuccesses in many Atari 2600 domains. However, domains with long horizons and\nsparse rewards, such as Montezuma's Revenge and Venture, remain challenging for\nexisting methods. Methods using abstraction (Dietterich 2000; Sutton, Precup,\nand Singh 1999) have shown to be useful in tackling long-horizon problems. We\ncombine recent techniques of deep reinforcement learning with existing\nmodel-based approaches using an expert-provided state abstraction. We construct\ntoy domains that elucidate the problem of long horizons, sparse rewards and\nhigh-dimensional inputs, and show that our algorithm significantly outperforms\nprevious methods on these domains. Our abstraction-based approach outperforms\nDeep Q-Networks (Mnih et al. 2015) on Montezuma's Revenge and Venture, and\nexhibits backtracking behavior that is absent from previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 02:17:09 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 18:29:32 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Roderick", "Melrose", ""], ["Grimm", "Christopher", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1710.00482", "submitter": "Hung-Hsuan Chen", "authors": "Hung-Hsuan Chen", "title": "Weighted-SVD: Matrix Factorization with Weights on the Latent Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Matrix Factorization models, sometimes called the latent factor models,\nare a family of methods in the recommender system research area to (1) generate\nthe latent factors for the users and the items and (2) predict users' ratings\non items based on their latent factors. However, current Matrix Factorization\nmodels presume that all the latent factors are equally weighted, which may not\nalways be a reasonable assumption in practice. In this paper, we propose a new\nmodel, called Weighted-SVD, to integrate the linear regression model with the\nSVD model such that each latent factor accompanies with a corresponding weight\nparameter. This mechanism allows the latent factors have different weights to\ninfluence the final ratings. The complexity of the Weighted-SVD model is\nslightly larger than the SVD model but much smaller than the SVD++ model. We\ncompared the Weighted-SVD model with several latent factor models on five\npublic datasets based on the Root-Mean-Squared-Errors (RMSEs). The results show\nthat the Weighted-SVD model outperforms the baseline methods in all the\nexperimental datasets under almost all settings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 04:56:09 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chen", "Hung-Hsuan", ""]]}, {"id": "1710.00486", "submitter": "Divya Gopinath", "authors": "Divya Gopinath, Guy Katz, Corina S. Pasareanu, Clark Barrett", "title": "DeepSafe: A Data-driven Approach for Checking Adversarial Robustness in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become widely used, obtaining remarkable results in\ndomains such as computer vision, speech recognition, natural language\nprocessing, audio recognition, social network filtering, machine translation,\nand bio-informatics, where they have produced results comparable to human\nexperts. However, these networks can be easily fooled by adversarial\nperturbations: minimal changes to correctly-classified inputs, that cause the\nnetwork to mis-classify them. This phenomenon represents a concern for both\nsafety and security, but it is currently unclear how to measure a network's\nrobustness against such perturbations. Existing techniques are limited to\nchecking robustness around a few individual input points, providing only very\nlimited guarantees. We propose a novel approach for automatically identifying\nsafe regions of the input space, within which the network is robust against\nadversarial perturbations. The approach is data-guided, relying on clustering\nto identify well-defined geometric regions as candidate safe regions. We then\nutilize verification techniques to confirm that these regions are safe or to\nprovide counter-examples showing that they are not safe. We also introduce the\nnotion of targeted robustness which, for a given target label and region,\nensures that a NN does not map any input in the region to the target label. We\nevaluated our technique on the MNIST dataset and on a neural network\nimplementation of a controller for the next-generation Airborne Collision\nAvoidance System for unmanned aircraft (ACAS Xu). For these networks, our\napproach identified multiple regions which were completely safe as well as some\nwhich were only safe for specific labels. It also discovered several\nadversarial perturbations of interest.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 05:09:52 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:29:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Gopinath", "Divya", ""], ["Katz", "Guy", ""], ["Pasareanu", "Corina S.", ""], ["Barrett", "Clark", ""]]}, {"id": "1710.00499", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Fanny Yang, Martin J. Wainwright, Michael I. Jordan", "title": "Online control of the false discovery rate with decaying memory", "comments": "20 pages, 4 figures. Published in the proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online multiple testing problem, p-values corresponding to different\nnull hypotheses are observed one by one, and the decision of whether or not to\nreject the current hypothesis must be made immediately, after which the next\np-value is observed. Alpha-investing algorithms to control the false discovery\nrate (FDR), formulated by Foster and Stine, have been generalized and applied\nto many settings, including quality-preserving databases in science and\nmultiple A/B or multi-armed bandit tests for internet commerce. This paper\nimproves the class of generalized alpha-investing algorithms (GAI) in four\nways: (a) we show how to uniformly improve the power of the entire class of\nmonotone GAI procedures by awarding more alpha-wealth for each rejection,\ngiving a win-win resolution to a recent dilemma raised by Javanmard and\nMontanari, (b) we demonstrate how to incorporate prior weights to indicate\ndomain knowledge of which hypotheses are likely to be non-null, (c) we allow\nfor differing penalties for false discoveries to indicate that some hypotheses\nmay be more important than others, (d) we define a new quantity called the\ndecaying memory false discovery rate (mem-FDR) that may be more meaningful for\ntruly temporal applications, and which alleviates problems that we describe and\nrefer to as \"piggybacking\" and \"alpha-death\". Our GAI++ algorithms incorporate\nall four generalizations simultaneously, and reduce to more powerful variants\nof earlier algorithms when the weights and decay are all set to unity. Finally,\nwe also describe a simple method to derive new online FDR rules based on an\nestimated false discovery proportion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 06:13:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Yang", "Fanny", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1710.00575", "submitter": "Pablo Morales-\\'Alvarez", "authors": "Pablo Morales-Alvarez and Adrian Perez-Suay and Rafael Molina and\n  Gustau Camps-Valls", "title": "Remote Sensing Image Classification with Large Scale Gaussian Processes", "comments": "11 pages, 6 figures, Accepted for publication in IEEE Transactions on\n  Geoscience and Remote Sensing; added the IEEE copyright statement", "journal-ref": null, "doi": "10.1109/TGRS.2017.2758922", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current remote sensing image classification problems have to deal with an\nunprecedented amount of heterogeneous and complex data sources. Upcoming\nmissions will soon provide large data streams that will make land cover/use\nclassification difficult. Machine learning classifiers can help at this, and\nmany methods are currently available. A popular kernel classifier is the\nGaussian process classifier (GPC), since it approaches the classification\nproblem with a solid probabilistic treatment, thus yielding confidence\nintervals for the predictions as well as very competitive results to\nstate-of-the-art neural networks and support vector machines. However, its\ncomputational cost is prohibitive for large scale applications, and constitutes\nthe main obstacle precluding wide adoption. This paper tackles this problem by\nintroducing two novel efficient methodologies for Gaussian Process (GP)\nclassification. We first include the standard random Fourier features\napproximation into GPC, which largely decreases its computational cost and\npermits large scale remote sensing image classification. In addition, we\npropose a model which avoids randomly sampling a number of Fourier frequencies,\nand alternatively learns the optimal ones within a variational Bayes approach.\nThe performance of the proposed methods is illustrated in complex problems of\ncloud detection from multispectral imagery and infrared sounding data.\nExcellent empirical results support the proposal in both computational cost and\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 10:51:47 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 10:40:11 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Morales-Alvarez", "Pablo", ""], ["Perez-Suay", "Adrian", ""], ["Molina", "Rafael", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1710.00641", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "Improving speech recognition by revising gated recurrent units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition is largely taking advantage of deep learning, showing that\nsubstantial benefits can be obtained by modern Recurrent Neural Networks\n(RNNs). The most popular RNNs are Long Short-Term Memory (LSTMs), which\ntypically reach state-of-the-art performance in many tasks thanks to their\nability to learn long-term dependencies and robustness to vanishing gradients.\nNevertheless, LSTMs have a rather complex design with three multiplicative\ngates, that might impair their efficient implementation. An attempt to simplify\nLSTMs has recently led to Gated Recurrent Units (GRUs), which are based on just\ntwo multiplicative gates.\n  This paper builds on these efforts by further revising GRUs and proposing a\nsimplified architecture potentially more suitable for speech recognition. The\ncontribution of this work is two-fold. First, we suggest to remove the reset\ngate in the GRU design, resulting in a more efficient single-gate architecture.\nSecond, we propose to replace tanh with ReLU activations in the state update\nequations. Results show that, in our implementation, the revised architecture\nreduces the per-epoch training time with more than 30% and consistently\nimproves recognition performance across different tasks, input features, and\nnoisy conditions when compared to a standard GRU.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 12:40:50 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.00760", "submitter": "Majdi Khalid", "authors": "Majdi Khalid, Indrakshi Ray, and Hamidreza Chitsaz", "title": "Scalable Nonlinear AUC Maximization Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area under the ROC curve (AUC) is a measure of interest in various\nmachine learning and data mining applications. It has been widely used to\nevaluate classification performance on heavily imbalanced data. The kernelized\nAUC maximization machines have established a superior generalization ability\ncompared to linear AUC machines because of their capability in modeling the\ncomplex nonlinear structure underlying most real-world data. However, the high\ntraining complexity renders the kernelized AUC machines infeasible for\nlarge-scale data. In this paper, we present two nonlinear AUC maximization\nalgorithms that optimize pairwise linear classifiers over a finite-dimensional\nfeature space constructed via the k-means Nystr\\\"{o}m method. Our first\nalgorithm maximize the AUC metric by optimizing a pairwise squared hinge loss\nfunction using the truncated Newton method. However, the second-order batch AUC\nmaximization method becomes expensive to optimize for extremely massive\ndatasets. This motivate us to develop a first-order stochastic AUC maximization\nalgorithm that incorporates a scheduled regularization update and scheduled\naveraging techniques to accelerate the convergence of the classifier.\nExperiments on several benchmark datasets demonstrate that the proposed AUC\nclassifiers are more efficient than kernelized AUC machines while they are able\nto surpass or at least match the AUC performance of the kernelized AUC\nmachines. The experiments also show that the proposed stochastic AUC classifier\noutperforms the state-of-the-art online AUC maximization methods in terms of\nAUC classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 16:28:35 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 19:24:33 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2018 00:30:18 GMT"}, {"version": "v4", "created": "Mon, 29 Apr 2019 05:26:04 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Khalid", "Majdi", ""], ["Ray", "Indrakshi", ""], ["Chitsaz", "Hamidreza", ""]]}, {"id": "1710.00811", "submitter": "Aaron Tuor", "authors": "Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, Sean\n  Robinson", "title": "Deep Learning for Unsupervised Insider Threat Detection in Structured\n  Cybersecurity Data Streams", "comments": "Proceedings of AI for Cyber Security Workshop at AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of an organization's computer network activity is a key component of\nearly detection and mitigation of insider threat, a growing concern for many\norganizations. Raw system logs are a prototypical example of streaming data\nthat can quickly scale beyond the cognitive power of a human analyst. As a\nprospective filter for the human analyst, we present an online unsupervised\ndeep learning approach to detect anomalous network activity from system logs in\nreal time. Our models decompose anomaly scores into the contributions of\nindividual user behavior features for increased interpretability to aid\nanalysts reviewing potential cases of insider threat. Using the CERT Insider\nThreat Dataset v6.2 and threat detection recall as our performance metric, our\nnovel deep and recurrent neural network models outperform Principal Component\nAnalysis, Support Vector Machine and Isolation Forest based anomaly detection\nbaselines. For our best model, the events labeled as insider threat activity in\nour dataset had an average anomaly score in the 95.53 percentile, demonstrating\nour approach's potential to greatly reduce analyst workloads.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 17:54:28 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 20:53:03 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Tuor", "Aaron", ""], ["Kaplan", "Samuel", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""], ["Robinson", "Sean", ""]]}, {"id": "1710.00814", "submitter": "Jia-Bin Huang", "authors": "Yen-Chen Lin, Ming-Yu Liu, Min Sun, Jia-Bin Huang", "title": "Detecting Adversarial Attacks on Neural Network Policies with Visual\n  Foresight", "comments": "Project page: http://yclin.me/RL_attack_detection/ Code:\n  https://github.com/yenchenlin/rl-attack-detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has shown promising results in learning control\npolicies for complex sequential decision-making tasks. However, these neural\nnetwork-based policies are known to be vulnerable to adversarial examples. This\nvulnerability poses a potentially serious threat to safety-critical systems\nsuch as autonomous vehicles. In this paper, we propose a defense mechanism to\ndefend reinforcement learning agents from adversarial attacks by leveraging an\naction-conditioned frame prediction module. Our core idea is that the\nadversarial examples targeting at a neural network-based policy are not\neffective for the frame prediction model. By comparing the action distribution\nproduced by a policy from processing the current observed frame to the action\ndistribution produced by the same policy from processing the predicted frame\nfrom the action-conditioned frame prediction module, we can detect the presence\nof adversarial examples. Beyond detecting the presence of adversarial examples,\nour method allows the agent to continue performing the task using the predicted\nframe when the agent is under attack. We evaluate the performance of our\nalgorithm using five games in Atari 2600. Our results demonstrate that the\nproposed defense mechanism achieves favorable performance against baseline\nalgorithms in detecting adversarial examples and in earning rewards when the\nagents are under attack.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 17:56:26 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Lin", "Yen-Chen", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Min", ""], ["Huang", "Jia-Bin", ""]]}, {"id": "1710.00818", "submitter": "Sina Sajadmanesh", "authors": "Sina Sajadmanesh, Sogol Bazargani, Jiawei Zhang and Hamid R. Rabiee", "title": "Continuous-Time Relationship Prediction in Dynamic Heterogeneous\n  Information Networks", "comments": "To appear in ACM Transactions on Knowledge Discovery from Data", "journal-ref": "ACM Transactions on Knowledge Discovery from Data, July 2019", "doi": "10.1145/3333028", "report-no": "44", "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks, World Wide Web, media and technological networks, and\nother types of so-called information networks are ubiquitous nowadays. These\ninformation networks are inherently heterogeneous and dynamic. They are\nheterogeneous as they consist of multi-typed objects and relations, and they\nare dynamic as they are constantly evolving over time. One of the challenging\nissues in such heterogeneous and dynamic environments is to forecast those\nrelationships in the network that will appear in the future. In this paper, we\ntry to solve the problem of continuous-time relationship prediction in dynamic\nand heterogeneous information networks. This implies predicting the time it\ntakes for a relationship to appear in the future, given its features that have\nbeen extracted by considering both heterogeneity and temporal dynamics of the\nunderlying network. To this end, we first introduce a feature extraction\nframework that combines the power of meta-path-based modeling and recurrent\nneural networks to effectively extract features suitable for relationship\nprediction regarding heterogeneity and dynamicity of the networks. Next, we\npropose a supervised non-parametric approach, called Non-Parametric Generalized\nLinear Model (NP-GLM), which infers the hidden underlying probability\ndistribution of the relationship building time given its features. We then\npresent a learning algorithm to train NP-GLM and an inference method to answer\ntime-related queries. Extensive experiments conducted on synthetic data and\nthree real-world datasets, namely Delicious, MovieLens, and DBLP, demonstrate\nthe effectiveness of NP-GLM in solving continuous-time relationship prediction\nproblem vis-a-vis competitive baselines\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 09:05:27 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 18:13:51 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 15:11:58 GMT"}, {"version": "v4", "created": "Sun, 19 May 2019 07:35:29 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Sajadmanesh", "Sina", ""], ["Bazargani", "Sogol", ""], ["Zhang", "Jiawei", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1710.00892", "submitter": "Joseph Geumlek", "authors": "Joseph Geumlek, Shuang Song, Kamalika Chaudhuri", "title": "R\\'enyi Differential Privacy Mechanisms for Posterior Sampling", "comments": "to be published in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a recently proposed privacy definition of R\\'enyi Differential Privacy\n(RDP), we re-examine the inherent privacy of releasing a single sample from a\nposterior distribution. We exploit the impact of the prior distribution in\nmitigating the influence of individual data points. In particular, we focus on\nsampling from an exponential family and specific generalized linear models,\nsuch as logistic regression. We propose novel RDP mechanisms as well as\noffering a new RDP analysis for an existing method in order to add value to the\nRDP framework. Each method is capable of achieving arbitrary RDP privacy\nguarantees, and we offer experimental results of their efficacy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 20:15:43 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Geumlek", "Joseph", ""], ["Song", "Shuang", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1710.00904", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Liang Zhao, Arnold P. Boedihardjo, Chang-Tien Lu", "title": "Online and Distributed Robust Regressions under Adversarial Data\n  Corruption", "comments": "Accepted by ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's era of big data, robust least-squares regression becomes a more\nchallenging problem when considering the adversarial corruption along with\nexplosive growth of datasets. Traditional robust methods can handle the noise\nbut suffer from several challenges when applied in huge dataset including 1)\ncomputational infeasibility of handling an entire dataset at once, 2) existence\nof heterogeneously distributed corruption, and 3) difficulty in corruption\nestimation when data cannot be entirely loaded. This paper proposes online and\ndistributed robust regression approaches, both of which can concurrently\naddress all the above challenges. Specifically, the distributed algorithm\noptimizes the regression coefficients of each data block via heuristic hard\nthresholding and combines all the estimates in a distributed robust\nconsolidation. Furthermore, an online version of the distributed algorithm is\nproposed to incrementally update the existing estimates with new incoming data.\nWe also prove that our algorithms benefit from strong robustness guarantees in\nterms of regression coefficient recovery with a constant upper bound on the\nerror of state-of-the-art batch methods. Extensive experiments on synthetic and\nreal datasets demonstrate that our approaches are superior to those of existing\nmethods in effectiveness, with competitive efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 20:55:39 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhang", "Xuchao", ""], ["Zhao", "Liang", ""], ["Boedihardjo", "Arnold P.", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1710.00977", "submitter": "Naimish Agarwal", "authors": "Naimish Agarwal, Artus Krohn-Grimberghe, Ranjana Vyas", "title": "Facial Key Points Detection using Deep Convolutional Neural Network -\n  NaimishNet", "comments": "7 pages, 21 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Key Points (FKPs) Detection is an important and challenging problem in\nthe fields of computer vision and machine learning. It involves predicting the\nco-ordinates of the FKPs, e.g. nose tip, center of eyes, etc, for a given face.\nIn this paper, we propose a LeNet adapted Deep CNN model - NaimishNet, to\noperate on facial key points data and compare our model's performance against\nexisting state of the art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 04:23:08 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Agarwal", "Naimish", ""], ["Krohn-Grimberghe", "Artus", ""], ["Vyas", "Ranjana", ""]]}, {"id": "1710.01013", "submitter": "Emanuele Sansone", "authors": "Emanuele Sansone, Francesco G.B. De Natale", "title": "Training Feedforward Neural Networks with Standard Logistic Activations\n  is Feasible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training feedforward neural networks with standard logistic activations is\nconsidered difficult because of the intrinsic properties of these sigmoidal\nfunctions. This work aims at showing that these networks can be trained to\nachieve generalization performance comparable to those based on hyperbolic\ntangent activations. The solution consists on applying a set of conditions in\nparameter initialization, which have been derived from the study of the\nproperties of a single neuron from an information-theoretic perspective. The\nproposed initialization is validated through an extensive experimental\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 07:21:03 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Sansone", "Emanuele", ""], ["De Natale", "Francesco G. B.", ""]]}, {"id": "1710.01020", "submitter": "Sifei Liu", "authors": "Sifei Liu, Shalini De Mello, Jinwei Gu, Guangyu Zhong, Ming-Hsuan\n  Yang, Jan Kautz", "title": "Learning Affinity via Spatial Propagation Networks", "comments": "A long version of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose spatial propagation networks for learning the\naffinity matrix for vision tasks. We show that by constructing a row/column\nlinear propagation model, the spatially varying transformation matrix exactly\nconstitutes an affinity matrix that models dense, global pairwise relationships\nof an image. Specifically, we develop a three-way connection for the linear\npropagation model, which (a) formulates a sparse transformation matrix, where\nall elements can be the output from a deep CNN, but (b) results in a dense\naffinity matrix that effectively models any task-specific pairwise similarity\nmatrix. Instead of designing the similarity kernels according to image features\nof two points, we can directly output all the similarities in a purely\ndata-driven manner. The spatial propagation network is a generic framework that\ncan be applied to many affinity-related tasks, including but not limited to\nimage matting, segmentation and colorization, to name a few. Essentially, the\nmodel can learn semantically-aware affinity values for high-level vision tasks\ndue to the powerful learning capability of the deep neural network classifier.\nWe validate the framework on the task of refinement for image segmentation\nboundaries. Experiments on the HELEN face parsing and PASCAL VOC-2012 semantic\nsegmentation tasks show that the spatial propagation network provides a\ngeneral, effective and efficient solution for generating high-quality\nsegmentation results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 08:00:15 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Liu", "Sifei", ""], ["De Mello", "Shalini", ""], ["Gu", "Jinwei", ""], ["Zhong", "Guangyu", ""], ["Yang", "Ming-Hsuan", ""], ["Kautz", "Jan", ""]]}, {"id": "1710.01408", "submitter": "Mohammed Yousefhussien", "authors": "Mohammed Yousefhussien, David J. Kelbe, Emmett J. Ientilucci and Carl\n  Salvaggio", "title": "A Fully Convolutional Network for Semantic Labeling of 3D Point Clouds", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing, 2018", "doi": "10.1016/j.isprsjprs.2018.03.018", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When classifying point clouds, a large amount of time is devoted to the\nprocess of engineering a reliable set of features which are then passed to a\nclassifier of choice. Generally, such features - usually derived from the\n3D-covariance matrix - are computed using the surrounding neighborhood of\npoints. While these features capture local information, the process is usually\ntime-consuming, and requires the application at multiple scales combined with\ncontextual methods in order to adequately describe the diversity of objects\nwithin a scene. In this paper we present a 1D-fully convolutional network that\nconsumes terrain-normalized points directly with the corresponding spectral\ndata,if available, to generate point-wise labeling while implicitly learning\ncontextual features in an end-to-end fashion. Our method uses only the\n3D-coordinates and three corresponding spectral features for each point.\nSpectral features may either be extracted from 2D-georeferenced images, as\nshown here for Light Detection and Ranging (LiDAR) point clouds, or extracted\ndirectly for passive-derived point clouds,i.e. from muliple-view imagery. We\ntrain our network by splitting the data into square regions, and use a pooling\nlayer that respects the permutation-invariance of the input points. Evaluated\nusing the ISPRS 3D Semantic Labeling Contest, our method scored second place\nwith an overall accuracy of 81.6%. We ranked third place with a mean F1-score\nof 63.32%, surpassing the F1-score of the method with highest accuracy by\n1.69%. In addition to labeling 3D-point clouds, we also show that our method\ncan be easily extended to 2D-semantic segmentation tasks, with promising\ninitial results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:35:25 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Yousefhussien", "Mohammed", ""], ["Kelbe", "David J.", ""], ["Ientilucci", "Emmett J.", ""], ["Salvaggio", "Carl", ""]]}, {"id": "1710.01420", "submitter": "Jose Picado", "authors": "Jose Picado, Arash Termehchy, Sudhanshu Pathak, Alan Fern, Praveen\n  Ilango, Yunqiao Cai", "title": "Usable & Scalable Learning Over Relational Data With Automatic Language\n  Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational databases are valuable resources for learning novel and\ninteresting relations and concepts. In order to constraint the search through\nthe large space of candidate definitions, users must tune the algorithm by\nspecifying a language bias. Unfortunately, specifying the language bias is done\nvia trial and error and is guided by the expert's intuitions. We propose\nAutoBias, a system that leverages information in the schema and content of the\ndatabase to automatically induce the language bias used by popular relational\nlearning systems. We show that AutoBias delivers the same accuracy as using\nmanually-written language bias by imposing only a slight overhead on the\nrunning time of the learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 23:36:31 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:56:51 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Picado", "Jose", ""], ["Termehchy", "Arash", ""], ["Pathak", "Sudhanshu", ""], ["Fern", "Alan", ""], ["Ilango", "Praveen", ""], ["Cai", "Yunqiao", ""]]}, {"id": "1710.01467", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Mechanisms of dimensionality reduction and decorrelation in deep neural\n  networks", "comments": "11 pages, 5 figures, a physics explanation of decorrelation and\n  dimensionality reduction is added; to be published by Phys Rev E (2018)", "journal-ref": "Phys. Rev. E 98, 062313 (2018)", "doi": "10.1103/PhysRevE.98.062313", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used in various domains. However, the nature\nof computations at each layer of the deep networks is far from being well\nunderstood. Increasing the interpretability of deep neural networks is thus\nimportant. Here, we construct a mean-field framework to understand how compact\nrepresentations are developed across layers, not only in deterministic deep\nnetworks with random weights but also in generative deep networks where an\nunsupervised learning is carried out. Our theory shows that the deep\ncomputation implements a dimensionality reduction while maintaining a finite\nlevel of weak correlations between neurons for possible feature extraction.\nMechanisms of dimensionality reduction and decorrelation are unified in the\nsame framework. This work may pave the way for understanding how a sensory\nhierarchy works.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 05:38:50 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 04:59:06 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 02:52:24 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1710.01493", "submitter": "Ruben H\\\"uhnerbein", "authors": "Ruben H\\\"uhnerbein, Fabrizio Savarino, Freddie \\r{A}str\\\"om, Christoph\n  Schn\\\"orr", "title": "Image Labeling Based on Graphical Models Using Wasserstein Messages and\n  Geometric Assignment", "comments": null, "journal-ref": null, "doi": "10.1137/17M1150669", "report-no": null, "categories": "cs.LG cs.CV cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to Maximum A Posteriori inference based on\ndiscrete graphical models. By utilizing local Wasserstein distances for\ncoupling assignment measures across edges of the underlying graph, a given\ndiscrete objective function is smoothly approximated and restricted to the\nassignment manifold. A corresponding multiplicative update scheme combines in a\nsingle process (i) geometric integration of the resulting Riemannian gradient\nflow and (ii) rounding to integral solutions that represent valid labelings.\nThroughout this process, local marginalization constraints known from the\nestablished LP relaxation are satisfied, whereas the smooth geometric setting\nresults in rapidly converging iterations that can be carried out in parallel\nfor every edge.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 08:00:50 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 08:54:37 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["H\u00fchnerbein", "Ruben", ""], ["Savarino", "Fabrizio", ""], ["\u00c5str\u00f6m", "Freddie", ""], ["Schn\u00f6rr", "Christoph", ""]]}, {"id": "1710.01614", "submitter": "Zhiguo Zhou", "authors": "Zhiguo Zhou, Zhi-Jie Zhou, Hongxia Hao, Shulong Li, Xi Chen, You\n  Zhang, Michael Folkert, and Jing Wang", "title": "Constructing multi-modality and multi-classifier radiomics predictive\n  models through reliable classifier fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiomics aims to extract and analyze large numbers of quantitative features\nfrom medical images and is highly promising in staging, diagnosing, and\npredicting outcomes of cancer treatments. Nevertheless, several challenges need\nto be addressed to construct an optimal radiomics predictive model. First, the\npredictive performance of the model may be reduced when features extracted from\nan individual imaging modality are blindly combined into a single predictive\nmodel. Second, because many different types of classifiers are available to\nconstruct a predictive model, selecting an optimal classifier for a particular\napplication is still challenging. In this work, we developed multi-modality and\nmulti-classifier radiomics predictive models that address the aforementioned\nissues in currently available models. Specifically, a new reliable classifier\nfusion strategy was proposed to optimally combine output from different\nmodalities and classifiers. In this strategy, modality-specific classifiers\nwere first trained, and an analytic evidential reasoning (ER) rule was\ndeveloped to fuse the output score from each modality to construct an optimal\npredictive model. One public data set and two clinical case studies were\nperformed to validate model performance. The experimental results indicated\nthat the proposed ER rule based radiomics models outperformed the traditional\nmodels that rely on a single classifier or simply use combined features from\ndifferent modalities.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 14:23:04 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 20:52:35 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Zhou", "Zhiguo", ""], ["Zhou", "Zhi-Jie", ""], ["Hao", "Hongxia", ""], ["Li", "Shulong", ""], ["Chen", "Xi", ""], ["Zhang", "You", ""], ["Folkert", "Michael", ""], ["Wang", "Jing", ""]]}, {"id": "1710.01688", "submitter": "Stephen Tu", "authors": "Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht and Stephen Tu", "title": "On the Sample Complexity of the Linear Quadratic Regulator", "comments": "Contains a new analysis of finite-dimensional truncation, a new\n  data-dependent estimation bound, and an expanded exposition on necessary\n  background in control theory and System Level Synthesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the optimal control problem known as the Linear\nQuadratic Regulator in the case when the dynamics are unknown. We propose a\nmulti-stage procedure, called Coarse-ID control, that estimates a model from a\nfew experimental trials, estimates the error in that model with respect to the\ntruth, and then designs a controller using both the model and uncertainty\nestimate. Our technique uses contemporary tools from random matrix theory to\nbound the error in the estimation procedure. We also employ a recently\ndeveloped approach to control synthesis called System Level Synthesis that\nenables robust control design by solving a convex optimization problem. We\nprovide end-to-end bounds on the relative error in control cost that are nearly\noptimal in the number of parameters and that highlight salient properties of\nthe system to be controlled such as closed-loop sensitivity and optimal control\nmagnitude. We show experimentally that the Coarse-ID approach enables efficient\ncomputation of a stabilizing controller in regimes where simple control schemes\nthat do not take the model uncertainty into account fail to stabilize the true\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 16:46:38 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 08:39:54 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 20:38:30 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Dean", "Sarah", ""], ["Mania", "Horia", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""], ["Tu", "Stephen", ""]]}, {"id": "1710.01691", "submitter": "Kun Ho Kim", "authors": "Kun Ho Kim, Oisin Mac Aodha, Pietro Perona", "title": "Context Embedding Networks", "comments": "CVPR 2018 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:46:40 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 22:47:50 GMT"}, {"version": "v3", "created": "Thu, 29 Mar 2018 16:32:35 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kim", "Kun Ho", ""], ["Mac Aodha", "Oisin", ""], ["Perona", "Pietro", ""]]}, {"id": "1710.01692", "submitter": "Dokhyam Hoshen", "authors": "Dokhyam Hoshen, Michael Werman", "title": "IQ of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IQ tests are an accepted method for assessing human intelligence. The tests\nconsist of several parts that must be solved under a time constraint. Of all\nthe tested abilities, pattern recognition has been found to have the highest\ncorrelation with general intelligence. This is primarily because pattern\nrecognition is the ability to find order in a noisy environment, a necessary\nskill for intelligent agents. In this paper, we propose a convolutional neural\nnetwork (CNN) model for solving geometric pattern recognition problems. The CNN\nreceives as input multiple ordered input images and outputs the next image\naccording to the pattern. Our CNN is able to solve problems involving rotation,\nreflection, color, size and shape patterns and score within the top 5% of human\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 11:48:58 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Hoshen", "Dokhyam", ""], ["Werman", "Michael", ""]]}, {"id": "1710.01693", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo", "title": "Model-free prediction of noisy chaotic time series by deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep neural network for a model-free prediction of a chaotic\ndynamical system from noisy observations. The proposed deep learning model aims\nto predict the conditional probability distribution of a state variable. The\nLong Short-Term Memory network (LSTM) is employed to model the nonlinear\ndynamics and a softmax layer is used to approximate a probability distribution.\nThe LSTM model is trained by minimizing a regularized cross-entropy function.\nThe LSTM model is validated against delay-time chaotic dynamical systems,\nMackey-Glass and Ikeda equations. It is shown that the present LSTM makes a\ngood prediction of the nonlinear dynamics by effectively filtering out the\nnoise. It is found that the prediction uncertainty of a multiple-step forecast\nof the LSTM model is not a monotonic function of time; the predicted standard\ndeviation may increase or decrease dynamically in time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 20:36:02 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Yeo", "Kyongmin", ""]]}, {"id": "1710.01695", "submitter": "Yuanfang Chen", "authors": "Yuanfang Chen, Falin Chen, Yizhi Ren, Ting Wu, Ye Yao", "title": "DeepTFP: Mobile Time Series Data Analytics based Traffic Flow Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow prediction is an important research issue to avoid traffic\ncongestion in transportation systems. Traffic congestion avoiding can be\nachieved by knowing traffic flow and then conducting transportation planning.\nAchieving traffic flow prediction is challenging as the prediction is affected\nby many complex factors such as inter-region traffic, vehicles' relations, and\nsudden events. However, as the mobile data of vehicles has been widely\ncollected by sensor-embedded devices in transportation systems, it is possible\nto predict the traffic flow by analysing mobile data. This study proposes a\ndeep learning based prediction algorithm, DeepTFP, to collectively predict the\ntraffic flow on each and every traffic road of a city. This algorithm uses\nthree deep residual neural networks to model temporal closeness, period, and\ntrend properties of traffic flow. Each residual neural network consists of a\nbranch of residual convolutional units. DeepTFP aggregates the outputs of the\nthree residual neural networks to optimize the parameters of a time series\nprediction model. Contrast experiments on mobile time series data from the\ntransportation system of England demonstrate that the proposed DeepTFP\noutperforms the Long Short-Term Memory (LSTM) architecture based method in\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 23:28:33 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Chen", "Yuanfang", ""], ["Chen", "Falin", ""], ["Ren", "Yizhi", ""], ["Wu", "Ting", ""], ["Yao", "Ye", ""]]}, {"id": "1710.01719", "submitter": "Enoch Yeung Ph.D.", "authors": "Zhiyuan Liu, Soumya Kundu, Lijun Chen, and Enoch Yeung", "title": "Decomposition of Nonlinear Dynamical Systems Using Koopman Gramians", "comments": "8 pages, submitted to IEEE 2018 ACC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new Koopman operator approach to the decomposition\nof nonlinear dynamical systems using Koopman Gramians. We introduce the notion\nof an input-Koopman operator, and show how input-Koopman operators can be used\nto cast a nonlinear system into the classical state-space form, and identify\nconditions under which input and state observable functions are well separated.\nWe then extend an existing method of dynamic mode decomposition for learning\nKoopman operators from data known as deep dynamic mode decomposition to systems\nwith controls or disturbances. We illustrate the accuracy of the method in\nlearning an input-state separable Koopman operator for an example system, even\nwhen the underlying system exhibits mixed state-input terms. We next introduce\na nonlinear decomposition algorithm, based on Koopman Gramians, that maximizes\ninternal subsystem observability and disturbance rejection from unwanted noise\nfrom other subsystems. We derive a relaxation based on Koopman Gramians and\nmulti-way partitioning for the resulting NP-hard decomposition problem. We\nlastly illustrate the proposed algorithm with the swing dynamics for an IEEE\n39-bus system.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 17:47:39 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Liu", "Zhiyuan", ""], ["Kundu", "Soumya", ""], ["Chen", "Lijun", ""], ["Yeung", "Enoch", ""]]}, {"id": "1710.01813", "submitter": "Danfei Xu", "authors": "Danfei Xu, Suraj Nair, Yuke Zhu, Julian Gao, Animesh Garg, Li Fei-Fei,\n  Silvio Savarese", "title": "Neural Task Programming: Learning to Generalize Across Hierarchical\n  Tasks", "comments": "ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel robot learning framework called Neural Task\nProgramming (NTP), which bridges the idea of few-shot learning from\ndemonstration and neural program induction. NTP takes as input a task\nspecification (e.g., video demonstration of a task) and recursively decomposes\nit into finer sub-task specifications. These specifications are fed to a\nhierarchical neural program, where bottom-level programs are callable\nsubroutines that interact with the environment. We validate our method in three\nrobot manipulation tasks. NTP achieves strong generalization across sequential\ntasks that exhibit hierarchal and compositional structures. The experimental\nresults show that NTP learns to generalize well to- wards unseen tasks with\nincreasing lengths, variable topologies, and changing objectives.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 21:31:49 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 22:04:25 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Xu", "Danfei", ""], ["Nair", "Suraj", ""], ["Zhu", "Yuke", ""], ["Gao", "Julian", ""], ["Garg", "Animesh", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "1710.01878", "submitter": "Michael Zhu", "authors": "Michael Zhu, Suyog Gupta", "title": "To prune, or not to prune: exploring the efficacy of pruning for model\n  compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model pruning seeks to induce sparsity in a deep neural network's various\nconnection matrices, thereby reducing the number of nonzero-valued parameters\nin the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep\nnetworks at the cost of only a marginal loss in accuracy and achieve a sizable\nreduction in model size. This hints at the possibility that the baseline models\nin these experiments are perhaps severely over-parameterized at the outset and\na viable alternative for model compression might be to simply reduce the number\nof hidden units while maintaining the model's dense connection structure,\nexposing a similar trade-off in model size and accuracy. We investigate these\ntwo distinct paths for model compression within the context of energy-efficient\ninference in resource-constrained environments and propose a new gradual\npruning technique that is simple and straightforward to apply across a variety\nof models/datasets with minimal tuning and can be seamlessly incorporated\nwithin the training process. We compare the accuracy of large, but pruned\nmodels (large-sparse) and their smaller, but dense (small-dense) counterparts\nwith identical memory footprint. Across a broad range of neural network\narchitectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find\nlarge-sparse models to consistently outperform small-dense models and achieve\nup to 10x reduction in number of non-zero parameters with minimal loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 04:26:49 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 18:40:16 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Zhu", "Michael", ""], ["Gupta", "Suyog", ""]]}, {"id": "1710.01927", "submitter": "Esben Jannik Bjerrum", "authors": "Esben Jannik Bjerrum, Mads Glahder, Thomas Skov", "title": "Data Augmentation of Spectral Data for Convolutional Neural Network\n  (CNN) Based Deep Chemometrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are used on spectroscopic data to predict drug content\nin tablets from near infrared (NIR) spectra. Using convolutional neural\nnetworks (CNNs), features are ex- tracted from the spectroscopic data. Extended\nmultiplicative scatter correction (EMSC) and a novel spectral data augmentation\nmethod are benchmarked as preprocessing steps. The learned models perform\nbetter or on par with hypothetical optimal partial least squares (PLS) models\nfor all combinations of preprocessing. Data augmentation with subsequent EMSC\nin combination gave the best results. The deep learning model CNNs also\noutperform the PLS models in an extrapolation chal- lenge created using data\nfrom a second instrument and from an analyte concentration not covered by the\ntraining data. Qualitative investigations of the CNNs kernel activations show\ntheir resemblance to wellknown data processing methods such as smoothing,\nslope/derivative, thresholds and spectral region selection.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 09:11:11 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Bjerrum", "Esben Jannik", ""], ["Glahder", "Mads", ""], ["Skov", "Thomas", ""]]}, {"id": "1710.02004", "submitter": "Paris Giampouras", "authors": "Paris V. Giampouras, Athanasios A. Rontogiannis and Konstantinos D.\n  Koutroumbas", "title": "Alternating Iteratively Reweighted Minimization Algorithms for Low-Rank\n  Matrix Factorization", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the availability of large-scale data in disparate application\ndomains urges the deployment of sophisticated tools for extracting valuable\nknowledge out of this huge bulk of information. In that vein, low-rank\nrepresentations (LRRs) which seek low-dimensional embeddings of data have\nnaturally appeared. In an effort to reduce computational complexity and improve\nestimation performance, LRR has been viewed via a matrix factorization (MF)\nperspective. Recently, low-rank MF (LRMF) approaches have been proposed for\ntackling the inherent weakness of MF i.e., the unawareness of the dimension of\nthe low-dimensional space where data reside. Herein, inspired by the merits of\niterative reweighted schemes for rank minimization, we come up with a generic\nlow-rank promoting regularization function. Then, focusing on a specific\ninstance of it, we propose a regularizer that imposes column-sparsity jointly\non the two matrix factors that result from MF, thus promoting low-rankness on\nthe optimization problem. The problems of denoising, matrix completion and\nnon-negative matrix factorization (NMF) are redefined according to the new LRMF\nformulation and solved via efficient Newton-type algorithms with proven\ntheoretical guarantees as to their convergence and rates of convergence to\nstationary points. The effectiveness of the proposed algorithms is verified in\ndiverse simulated and real data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 13:26:32 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Giampouras", "Paris V.", ""], ["Rontogiannis", "Athanasios A.", ""], ["Koutroumbas", "Konstantinos D.", ""]]}, {"id": "1710.02030", "submitter": "Ali Pesaranghader", "authors": "Ali Pesaranghader, Herna Viktor, Eric Paquet", "title": "McDiarmid Drift Detection Methods for Evolving Data Streams", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, Internet of Things (IoT) domains, such as sensor networks,\nsmart cities, and social networks, generate vast amounts of data. Such data are\nnot only unbounded and rapidly evolving. Rather, the content thereof\ndynamically evolves over time, often in unforeseen ways. These variations are\ndue to so-called concept drifts, caused by changes in the underlying data\ngeneration mechanisms. In a classification setting, concept drift causes the\npreviously learned models to become inaccurate, unsafe and even unusable.\nAccordingly, concept drifts need to be detected, and handled, as soon as\npossible. In medical applications and emergency response settings, for example,\nchange in behaviours should be detected in near real-time, to avoid potential\nloss of life. To this end, we introduce the McDiarmid Drift Detection Method\n(MDDM), which utilizes McDiarmid's inequality in order to detect concept drift.\nThe MDDM approach proceeds by sliding a window over prediction results, and\nassociate window entries with weights. Higher weights are assigned to the most\nrecent entries, in order to emphasize their importance. As instances are\nprocessed, the detection algorithm compares a weighted mean of elements inside\nthe sliding window with the maximum weighted mean observed so far. A\nsignificant difference between the two weighted means, upper-bounded by the\nMcDiarmid inequality, implies a concept drift. Our extensive experimentation\nagainst synthetic and real-world data streams show that our novel method\noutperforms the state-of-the-art. Specifically, MDDM yields shorter detection\ndelays as well as lower false negative rates, while maintaining high\nclassification accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 14:02:28 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 19:03:06 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Pesaranghader", "Ali", ""], ["Viktor", "Herna", ""], ["Paquet", "Eric", ""]]}, {"id": "1710.02101", "submitter": "Amir Najafi", "authors": "Amir Najafi, Abolfazl Motahari, Hamid R. Rabiee", "title": "Reliable Clustering of Bernoulli Mixture Models", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bernoulli Mixture Model (BMM) is a finite mixture of random binary vectors\nwith independent dimensions. The problem of clustering BMM data arises in a\nvariety of real-world applications, ranging from population genetics to\nactivity analysis in social networks. In this paper, we analyze the\nclusterability of BMMs from a theoretical perspective, when the number of\nclusters is unknown. In particular, we stipulate a set of conditions on the\nsample complexity and dimension of the model in order to guarantee the Probably\nApproximately Correct (PAC)-clusterability of a dataset. To the best of our\nknowledge, these findings are the first non-asymptotic bounds on the sample\ncomplexity of learning or clustering BMMs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:22:27 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 19:35:33 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2019 04:55:27 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Najafi", "Amir", ""], ["Motahari", "Abolfazl", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1710.02103", "submitter": "Yu Zhang", "authors": "Yu Zhang, Srikanta Tirthapura, Graham Cormode", "title": "Learning Graphical Models from a Distributed Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current challenge for data management systems is to support the\nconstruction and maintenance of machine learning models over data that is\nlarge, multi-dimensional, and evolving. While systems that could support these\ntasks are emerging, the need to scale to distributed, streaming data requires\nnew models and algorithms. In this setting, as well as computational\nscalability and model accuracy, we also need to minimize the amount of\ncommunication between distributed processors, which is the chief component of\nlatency. We study Bayesian networks, the workhorse of graphical models, and\npresent a communication-efficient method for continuously learning and\nmaintaining a Bayesian network model over data that is arriving as a\ndistributed stream partitioned across multiple processors. We show a strategy\nfor maintaining model parameters that leads to an exponential reduction in\ncommunication when compared with baseline approaches to maintain the exact MLE\n(maximum likelihood estimation). Meanwhile, our strategy provides similar\nprediction errors for the target distribution and for classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:30:33 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Zhang", "Yu", ""], ["Tirthapura", "Srikanta", ""], ["Cormode", "Graham", ""]]}, {"id": "1710.02174", "submitter": "Qiang Ha", "authors": "Qiang Ha", "title": "A study of Thompson Sampling with Parameter h", "comments": "12 pages,0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling algorithm is a well known Bayesian algorithm for solving\nstochastic multi-armed bandit. At each time step the algorithm chooses each arm\nwith probability proportional to it being the current best arm. We modify the\nstrategy by introducing a paramter h which alters the importance of the\nprobability of an arm being the current best arm. We show that the optimality\nof Thompson sampling is robust to this perturbation within a range of parameter\nvalues for two arm bandits.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 18:29:10 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ha", "Qiang", ""]]}, {"id": "1710.02196", "submitter": "Soheil Feizi", "authors": "Soheil Feizi, Hamid Javadi, Jesse Zhang and David Tse", "title": "Porcupine Neural Networks: (Almost) All Local Optima are Global", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been used prominently in several machine learning and\nstatistics applications. In general, the underlying optimization of neural\nnetworks is non-convex which makes their performance analysis challenging. In\nthis paper, we take a novel approach to this problem by asking whether one can\nconstrain neural network weights to make its optimization landscape have good\ntheoretical properties while at the same time, be a good approximation for the\nunconstrained one. For two-layer neural networks, we provide affirmative\nanswers to these questions by introducing Porcupine Neural Networks (PNNs)\nwhose weight vectors are constrained to lie over a finite set of lines. We show\nthat most local optima of PNN optimizations are global while we have a\ncharacterization of regions where bad local optimizers may exist. Moreover, our\ntheoretical and empirical results suggest that an unconstrained neural network\ncan be approximated using a polynomially-large PNN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 20:04:10 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Feizi", "Soheil", ""], ["Javadi", "Hamid", ""], ["Zhang", "Jesse", ""], ["Tse", "David", ""]]}, {"id": "1710.02221", "submitter": "Ondrej Kuzelka", "authors": "Gustav Sourek, Martin Svatos, Filip Zelezny, Steven Schockaert, Ondrej\n  Kuzelka", "title": "Stacked Structure Learning for Lifted Relational Neural Networks", "comments": "Presented at ILP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted Relational Neural Networks (LRNNs) describe relational domains using\nweighted first-order rules which act as templates for constructing feed-forward\nneural networks. While previous work has shown that using LRNNs can lead to\nstate-of-the-art results in various ILP tasks, these results depended on\nhand-crafted rules. In this paper, we extend the framework of LRNNs with\nstructure learning, thus enabling a fully automated learning process. Similarly\nto many ILP methods, our structure learning algorithm proceeds in an iterative\nfashion by top-down searching through the hypothesis space of all possible Horn\nclauses, considering the predicates that occur in the training examples as well\nas invented soft concepts entailed by the best weighted rules found so far. In\nthe experiments, we demonstrate the ability to automatically induce useful\nhierarchical soft concepts leading to deep LRNNs with a competitive predictive\npower.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 21:15:45 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Sourek", "Gustav", ""], ["Svatos", "Martin", ""], ["Zelezny", "Filip", ""], ["Schockaert", "Steven", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "1710.02224", "submitter": "Shiyu Chang", "authors": "Shiyu Chang, Yang Zhang, Wei Han, Mo Yu, Xiaoxiao Guo, Wei Tan,\n  Xiaodong Cui, Michael Witbrock, Mark Hasegawa-Johnson, Thomas S. Huang", "title": "Dilated Recurrent Neural Networks", "comments": "Accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with recurrent neural networks (RNNs) on long sequences is a\nnotoriously difficult task. There are three major challenges: 1) complex\ndependencies, 2) vanishing and exploding gradients, and 3) efficient\nparallelization. In this paper, we introduce a simple yet effective RNN\nconnection structure, the DilatedRNN, which simultaneously tackles all of these\nchallenges. The proposed architecture is characterized by multi-resolution\ndilated recurrent skip connections and can be combined flexibly with diverse\nRNN cells. Moreover, the DilatedRNN reduces the number of parameters needed and\nenhances training efficiency significantly, while matching state-of-the-art\nperformance (even with standard RNN cells) in tasks involving very long-term\ndependencies. To provide a theory-based quantification of the architecture's\nadvantages, we introduce a memory capacity measure, the mean recurrent length,\nwhich is more suitable for RNNs with long skip connections than existing\nmeasures. We rigorously prove the advantages of the DilatedRNN over other\nrecurrent neural architectures. The code for our method is publicly available\nat https://github.com/code-terminator/DilatedRNN\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 21:28:01 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 15:46:44 GMT"}, {"version": "v3", "created": "Thu, 2 Nov 2017 01:24:16 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Han", "Wei", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Tan", "Wei", ""], ["Cui", "Xiaodong", ""], ["Witbrock", "Michael", ""], ["Hasegawa-Johnson", "Mark", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1710.02238", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas,\n  Nathan Baker", "title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?", "comments": "In Proceedings of 2018 IEEE Winter Conference on Applications of\n  Computer Vision (WACV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 23:53:59 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 14:03:12 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Goh", "Garrett B.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Hodas", "Nathan O.", ""], ["Baker", "Nathan", ""]]}, {"id": "1710.02242", "submitter": "Tobias Hagge", "authors": "Tobias Hagge, Panos Stinis, Enoch Yeung and Alexandre M. Tartakovsky", "title": "Solving differential equations with unknown constitutive relations as\n  recurrent neural networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve a system of ordinary differential equations with an unknown\nfunctional form of a sink (reaction rate) term. We assume that the measurements\n(time series) of state variables are partially available, and we use recurrent\nneural network to \"learn\" the reaction rate from this data. This is achieved by\nincluding a discretized ordinary differential equations as part of a recurrent\nneural network training problem. We extend TensorFlow's recurrent neural\nnetwork architecture to create a simple but scalable and effective solver for\nthe unknown functions, and apply it to a fedbatch bioreactor simulation\nproblem. Use of techniques from recent deep learning literature enables\ntraining of functions with behavior manifesting over thousands of time steps.\nOur networks are structurally similar to recurrent neural networks, but\ndifferences in design and function require modifications to the conventional\nwisdom about training such networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 00:14:52 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Hagge", "Tobias", ""], ["Stinis", "Panos", ""], ["Yeung", "Enoch", ""], ["Tartakovsky", "Alexandre M.", ""]]}, {"id": "1710.02245", "submitter": "Son Tran", "authors": "Son N. Tran, Srikanth Cherla, Artur Garcez, Tillman Weyde", "title": "Linear-Time Sequence Classification using Restricted Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Classification of sequence data is the topic of interest for dynamic Bayesian\nmodels and Recurrent Neural Networks (RNNs). While the former can explicitly\nmodel the temporal dependencies between class variables, the latter have a\ncapability of learning representations. Several attempts have been made to\nimprove performance by combining these two approaches or increasing the\nprocessing capability of the hidden units in RNNs. This often results in\ncomplex models with a large number of learning parameters. In this paper, a\ncompact model is proposed which offers both representation learning and\ntemporal inference of class variables by rolling Restricted Boltzmann Machines\n(RBMs) and class variables over time. We address the key issue of\nintractability in this variant of RBMs by optimising a conditional\ndistribution, instead of a joint distribution. Experiments reported in the\npaper on melody modelling and optical character recognition show that the\nproposed model can outperform the state-of-the-art. Also, the experimental\nresults on optical character recognition, part-of-speech tagging and text\nchunking demonstrate that our model is comparable to recurrent neural networks\nwith complex memory gates while requiring far fewer parameters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 00:29:30 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 22:38:07 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 23:55:15 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Tran", "Son N.", ""], ["Cherla", "Srikanth", ""], ["Garcez", "Artur", ""], ["Weyde", "Tillman", ""]]}, {"id": "1710.02248", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Ahmed Touati, Laurent Dinh, Michal Drozdzal, Mohammad\n  Havaei, Laurent Charlin, Aaron Courville", "title": "Learnable Explicit Density for Continuous Latent Space and Variational\n  Inference", "comments": "2 figures, 5 pages, submitted to ICML Principled Approaches to Deep\n  Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two aspects of the variational autoencoder (VAE): the\nprior distribution over the latent variables and its corresponding posterior.\nFirst, we decompose the learning of VAEs into layerwise density estimation, and\nargue that having a flexible prior is beneficial to both sample generation and\ninference. Second, we analyze the family of inverse autoregressive flows\n(inverse AF) and show that with further improvement, inverse AF could be used\nas universal approximation to any complicated posterior. Our analysis results\nin a unified approach to parameterizing a VAE, without the need to restrict\nourselves to use factorial Gaussians in the latent real space.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 00:51:03 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Touati", "Ahmed", ""], ["Dinh", "Laurent", ""], ["Drozdzal", "Michal", ""], ["Havaei", "Mohammad", ""], ["Charlin", "Laurent", ""], ["Courville", "Aaron", ""]]}, {"id": "1710.02254", "submitter": "Chaitanya Ahuja", "authors": "Chaitanya Ahuja and Louis-Philippe Morency", "title": "Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency\n  for Sequence Modeling", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have shown remarkable success in modeling\nsequences. However low resource situations still adversely affect the\ngeneralizability of these models. We introduce a new family of models, called\nLattice Recurrent Units (LRU), to address the challenge of learning deep\nmulti-layer recurrent models with limited resources. LRU models achieve this\ngoal by creating distinct (but coupled) flow of information inside the units: a\nfirst flow along time dimension and a second flow along depth dimension. It\nalso offers a symmetry in how information can flow horizontally and vertically.\nWe analyze the effects of decoupling three different components of our LRU\nmodel: Reset Gate, Update Gate and Projected State. We evaluate this family on\nnew LRU models on computational convergence rates and statistical efficiency.\nOur experiments are performed on four publicly-available datasets, comparing\nwith Grid-LSTM and Recurrent Highway networks. Our results show that LRU has\nbetter empirical computational convergence rates and statistical efficiency\nvalues, along with learning more accurate language models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 01:52:14 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 05:11:17 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Ahuja", "Chaitanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1710.02268", "submitter": "Anna Guitart Atienza", "authors": "Alain Saas, Anna Guitart and \\'Africa Peri\\'a\\~nez", "title": "Discovering Playing Patterns: Time Series Clustering of Free-To-Play\n  Game Data", "comments": null, "journal-ref": "IEEE Conference on Computational Intelligence and Games (CIG),\n  20-23, 2016", "doi": "10.1109/CIG.2016.7860442", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of time series data is a challenge common to all\ndata-driven fields. However, there is no agreement about which are the most\nefficient techniques to group unlabeled time-ordered data. This is because a\nsuccessful classification of time series patterns depends on the goal and the\ndomain of interest, i.e. it is application-dependent.\n  In this article, we study free-to-play game data. In this domain, clustering\nsimilar time series information is increasingly important due to the large\namount of data collected by current mobile and web applications. We evaluate\nwhich methods cluster accurately time series of mobile games, focusing on\nplayer behavior data. We identify and validate several aspects of the\nclustering: the similarity measures and the representation techniques to reduce\nthe high dimensionality of time series. As a robustness test, we compare\nvarious temporal datasets of player activity from two free-to-play video-games.\n  With these techniques we extract temporal patterns of player behavior\nrelevant for the evaluation of game events and game-business diagnosis. Our\nexperiments provide intuitive visualizations to validate the results of the\nclustering and to determine the optimal number of clusters. Additionally, we\nassess the common characteristics of the players belonging to the same group.\nThis study allows us to improve the understanding of player dynamics and churn\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 03:39:33 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Saas", "Alain", ""], ["Guitart", "Anna", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1710.02277", "submitter": "Donghyun Yoo", "authors": "Donghyun Yoo, Haoqi Fan, Vishnu Naresh Boddeti, Kris M. Kitani", "title": "Efficient K-Shot Learning with Regularized Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature representations from pre-trained deep neural networks have been known\nto exhibit excellent generalization and utility across a variety of related\ntasks. Fine-tuning is by far the simplest and most widely used approach that\nseeks to exploit and adapt these feature representations to novel tasks with\nlimited data. Despite the effectiveness of fine-tuning, itis often sub-optimal\nand requires very careful optimization to prevent severe over-fitting to small\ndatasets. The problem of sub-optimality and over-fitting, is due in part to the\nlarge number of parameters used in a typical deep convolutional neural network.\nTo address these problems, we propose a simple yet effective regularization\nmethod for fine-tuning pre-trained deep networks for the task of k-shot\nlearning. To prevent overfitting, our key strategy is to cluster the model\nparameters while ensuring intra-cluster similarity and inter-cluster diversity\nof the parameters, effectively regularizing the dimensionality of the parameter\nsearch space. In particular, we identify groups of neurons within each layer of\na deep network that shares similar activation patterns. When the network is to\nbe fine-tuned for a classification task using only k examples, we propagate a\nsingle gradient to all of the neuron parameters that belong to the same group.\nThe grouping of neurons is non-trivial as neuron activations depend on the\ndistribution of the input data. To efficiently search for optimal groupings\nconditioned on the input data, we propose a reinforcement learning search\nstrategy using recurrent networks to learn the optimal group assignments for\neach network layer. Experimental results show that our method can be easily\napplied to several popular convolutional neural networks and improve upon other\nstate-of-the-art fine-tuning based k-shot learning strategies by more than10%\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 05:07:28 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Yoo", "Donghyun", ""], ["Fan", "Haoqi", ""], ["Boddeti", "Vishnu Naresh", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1710.02286", "submitter": "Lars Hertel", "authors": "Lars Hertel, Erhardt Barth, Thomas K\\\"aster, Thomas Martinetz", "title": "Deep Convolutional Neural Networks as Generic Feature Extractors", "comments": "4 pages, accepted version for publication in Proceedings of the IEEE\n  International Joint Conference on Neural Networks (IJCNN), July 2015,\n  Killarney, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing objects in natural images is an intricate problem involving\nmultiple conflicting objectives. Deep convolutional neural networks, trained on\nlarge datasets, achieve convincing results and are currently the\nstate-of-the-art approach for this task. However, the long time needed to train\nsuch deep networks is a major drawback. We tackled this problem by reusing a\npreviously trained network. For this purpose, we first trained a deep\nconvolutional network on the ILSVRC2012 dataset. We then maintained the learned\nconvolution kernels and only retrained the classification part on different\ndatasets. Using this approach, we achieved an accuracy of 67.68 % on CIFAR-100,\ncompared to the previous state-of-the-art result of 65.43 %. Furthermore, our\nfindings indicate that convolutional networks are able to learn generic feature\nextractors that can be used for different tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 06:42:11 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Hertel", "Lars", ""], ["Barth", "Erhardt", ""], ["K\u00e4ster", "Thomas", ""], ["Martinetz", "Thomas", ""]]}, {"id": "1710.02298", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg\n  Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, David Silver", "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning", "comments": "Under review as a conference paper at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep reinforcement learning community has made several independent\nimprovements to the DQN algorithm. However, it is unclear which of these\nextensions are complementary and can be fruitfully combined. This paper\nexamines six extensions to the DQN algorithm and empirically studies their\ncombination. Our experiments show that the combination provides\nstate-of-the-art performance on the Atari 2600 benchmark, both in terms of data\nefficiency and final performance. We also provide results from a detailed\nablation study that shows the contribution of each component to overall\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 07:45:46 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Hessel", "Matteo", ""], ["Modayil", "Joseph", ""], ["van Hasselt", "Hado", ""], ["Schaul", "Tom", ""], ["Ostrovski", "Georg", ""], ["Dabney", "Will", ""], ["Horgan", "Dan", ""], ["Piot", "Bilal", ""], ["Azar", "Mohammad", ""], ["Silver", "David", ""]]}, {"id": "1710.02338", "submitter": "Lei Huang", "authors": "Lei Huang, Xianglong Liu, Bo Lang and Bo Li", "title": "Projection Based Weight Normalization for Deep Neural Networks", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing deep neural networks (DNNs) often suffers from the ill-conditioned\nproblem. We observe that the scaling-based weight space symmetry property in\nrectified nonlinear network will cause this negative effect. Therefore, we\npropose to constrain the incoming weights of each neuron to be unit-norm, which\nis formulated as an optimization problem over Oblique manifold. A simple yet\nefficient method referred to as projection based weight normalization (PBWN) is\nalso developed to solve this problem. PBWN executes standard gradient updates,\nfollowed by projecting the updated weight back to Oblique manifold. This\nproposed method has the property of regularization and collaborates well with\nthe commonly used batch normalization technique. We conduct comprehensive\nexperiments on several widely-used image datasets including CIFAR-10,\nCIFAR-100, SVHN and ImageNet for supervised learning over the state-of-the-art\nconvolutional neural networks, such as Inception, VGG and residual networks.\nThe results show that our method is able to improve the performance of DNNs\nwith different architectures consistently. We also apply our method to Ladder\nnetwork for semi-supervised learning on permutation invariant MNIST dataset,\nand our method outperforms the state-of-the-art methods: we obtain test errors\nas 2.52%, 1.06%, and 0.91% with only 20, 50, and 100 labeled samples,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 10:24:38 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Huang", "Lei", ""], ["Liu", "Xianglong", ""], ["Lang", "Bo", ""], ["Li", "Bo", ""]]}, {"id": "1710.02368", "submitter": "Joeri Hermans", "authors": "Joeri Hermans, Gerasimos Spanakis and Rico M\\\"ockel", "title": "Accumulated Gradient Normalization", "comments": "16 pages, 12 figures, ACML2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work addresses the instability in asynchronous data parallel\noptimization. It does so by introducing a novel distributed optimizer which is\nable to efficiently optimize a centralized model under communication\nconstraints. The optimizer achieves this by pushing a normalized sequence of\nfirst-order gradients to a parameter server. This implies that the magnitude of\na worker delta is smaller compared to an accumulated gradient, and provides a\nbetter direction towards a minimum compared to first-order gradients, which in\nturn also forces possible implicit momentum fluctuations to be more aligned\nsince we make the assumption that all workers contribute towards a single\nminima. As a result, our approach mitigates the parameter staleness problem\nmore effectively since staleness in asynchrony induces (implicit) momentum, and\nachieves a better convergence rate compared to other optimizers such as\nasynchronous EASGD and DynSGD, which we show empirically.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 12:32:16 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Hermans", "Joeri", ""], ["Spanakis", "Gerasimos", ""], ["M\u00f6ckel", "Rico", ""]]}, {"id": "1710.02410", "submitter": "Matthias M\\\"uller", "authors": "Felipe Codevilla, Matthias M\\\"uller, Antonio L\\'opez, Vladlen Koltun,\n  Alexey Dosovitskiy", "title": "End-to-end Driving via Conditional Imitation Learning", "comments": "Published at the International Conference on Robotics and Automation\n  (ICRA), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks trained on demonstrations of human driving have learned to\nfollow roads and avoid obstacles. However, driving policies trained via\nimitation learning cannot be controlled at test time. A vehicle trained\nend-to-end to imitate an expert cannot be guided to take a specific turn at an\nupcoming intersection. This limits the utility of such systems. We propose to\ncondition imitation learning on high-level command input. At test time, the\nlearned driving policy functions as a chauffeur that handles sensorimotor\ncoordination but continues to respond to navigational commands. We evaluate\ndifferent architectures for conditional imitation learning in vision-based\ndriving. We conduct experiments in realistic three-dimensional simulations of\nurban driving and on a 1/5 scale robotic truck that is trained to drive in a\nresidential area. Both systems drive based on visual input yet remain\nresponsive to high-level navigational commands. The supplementary video can be\nviewed at https://youtu.be/cFtnflNe5fM\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 14:00:31 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 16:43:34 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Codevilla", "Felipe", ""], ["M\u00fcller", "Matthias", ""], ["L\u00f3pez", "Antonio", ""], ["Koltun", "Vladlen", ""], ["Dosovitskiy", "Alexey", ""]]}, {"id": "1710.02458", "submitter": "Daniel B. Neill", "authors": "Daniel B. Neill (1), William Herlands (1) ((1) Carnegie Mellon\n  University)", "title": "Machine Learning for Drug Overdose Surveillance", "comments": "Presented at the Data For Good Exchange 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two recently proposed machine learning approaches for discovering\nemerging trends in fatal accidental drug overdoses. The Gaussian Process Subset\nScan enables early detection of emerging patterns in spatio-temporal data,\naccounting for both the non-iid nature of the data and the fact that detecting\nsubtle patterns requires integration of information across multiple spatial\nareas and multiple time steps. We apply this approach to 17 years of\ncounty-aggregated data for monthly opioid overdose deaths in the New York City\nmetropolitan area, showing clear advantages in the utility of discovered\npatterns as compared to typical anomaly detection approaches.\n  To detect and characterize emerging overdose patterns that differentially\naffect a subpopulation of the data, including geographic, demographic, and\nbehavioral patterns (e.g., which combinations of drugs are involved), we apply\nthe Multidimensional Tensor Scan to 8 years of case-level overdose data from\nAllegheny County, PA. We discover previously unidentified overdose patterns\nwhich reveal unusual demographic clusters, show impacts of drug legislation,\nand demonstrate potential for early detection and targeted intervention. These\napproaches to early detection of overdose patterns can inform prevention and\nresponse efforts, as well as understanding the effects of policy changes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 15:43:44 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Neill", "Daniel B.", ""], ["Herlands", "William", ""]]}, {"id": "1710.02543", "submitter": "Lei Tai", "authors": "Lei Tai and Jingwei Zhang and Ming Liu and Wolfram Burgard", "title": "Socially Compliant Navigation through Raw Depth Inputs with Generative\n  Adversarial Imitation Learning", "comments": "ICRA 2018 camera-ready version. 7 pages, video link:\n  https://www.youtube.com/watch?v=0hw0GD3lkA8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for mobile robots to learn to navigate in dynamic\nenvironments with pedestrians via raw depth inputs, in a socially compliant\nmanner. To achieve this, we adopt a generative adversarial imitation learning\n(GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our\napproach overcomes the disadvantages of previous methods, as they heavily\ndepend on the full knowledge of the location and velocity information of nearby\npedestrians, which not only requires specific sensors, but also the extraction\nof such state information from raw sensory input could consume much computation\ntime. In this paper, our proposed GAIL-based model performs directly on raw\ndepth inputs and plans in real-time. Experiments show that our GAIL-based\napproach greatly improves the safety and efficiency of the behavior of mobile\nrobots from pure behavior cloning. The real-world deployment also shows that\nour method is capable of guiding autonomous vehicles to navigate in a socially\ncompliant manner directly through raw depth inputs. In addition, we release a\nsimulation plugin for modeling pedestrian behaviors based on the social force\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 18:29:44 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 05:56:54 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Tai", "Lei", ""], ["Zhang", "Jingwei", ""], ["Liu", "Ming", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1710.02546", "submitter": "Xuemei Xie", "authors": "Xuemei Xie, Chenye Wang, Shu Chen, Guangming Shi, Zhifu Zhao", "title": "Real-Time Illegal Parking Detection System Based on Deep Learning", "comments": "5pages,6figures", "journal-ref": null, "doi": "10.1145/3094243.3094261", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing illegal parking has become more and more serious. Nowadays the\nmethods of detecting illegally parked vehicles are based on background\nsegmentation. However, this method is weakly robust and sensitive to\nenvironment. Benefitting from deep learning, this paper proposes a novel\nillegal vehicle parking detection system. Illegal vehicles captured by camera\nare firstly located and classified by the famous Single Shot MultiBox Detector\n(SSD) algorithm. To improve the performance, we propose to optimize SSD by\nadjusting the aspect ratio of default box to accommodate with our dataset\nbetter. After that, a tracking and analysis of movement is adopted to judge the\nillegal vehicles in the region of interest (ROI). Experiments show that the\nsystem can achieve a 99% accuracy and real-time (25FPS) detection with strong\nrobustness in complex environments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 07:57:29 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Xie", "Xuemei", ""], ["Wang", "Chenye", ""], ["Chen", "Shu", ""], ["Shi", "Guangming", ""], ["Zhao", "Zhifu", ""]]}, {"id": "1710.02572", "submitter": "Chaofan Chen", "authors": "Chaofan Chen, Cynthia Rudin", "title": "An Optimization Approach to Learning Falling Rule Lists", "comments": "Accepted at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A falling rule list is a probabilistic decision list for binary\nclassification, consisting of a series of if-then rules with antecedents in the\nif clauses and probabilities of the desired outcome (\"1\") in the then clauses.\nJust as in a regular decision list, the order of rules in a falling rule list\nis important -- each example is classified by the first rule whose antecedent\nit satisfies. Unlike a regular decision list, a falling rule list requires the\nprobabilities of the desired outcome (\"1\") to be monotonically decreasing down\nthe list. We propose an optimization approach to learning falling rule lists\nand \"softly\" falling rule lists, along with Monte-Carlo search algorithms that\nuse bounds on the optimal solution to prune the search space.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 20:16:54 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 21:16:40 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 17:06:31 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Chen", "Chaofan", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1710.02619", "submitter": "Yijie Peng", "authors": "Yijie Peng, Edwin K. P. Chong, Chun-Hung Chen and Michael C. Fu", "title": "Ranking and Selection as Stochastic Control", "comments": "15 pages, 8 figures, to appear in IEEE Transactions on Automatic\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a Bayesian framework, we formulate the fully sequential sampling and\nselection decision in statistical ranking and selection as a stochastic control\nproblem, and derive the associated Bellman equation. Using value function\napproximation, we derive an approximately optimal allocation policy. We show\nthat this policy is not only computationally efficient but also possesses both\none-step-ahead and asymptotic optimality for independent normal sampling\ndistributions. Moreover, the proposed allocation policy is easily generalizable\nin the approximate dynamic programming paradigm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 01:53:54 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Peng", "Yijie", ""], ["Chong", "Edwin K. P.", ""], ["Chen", "Chun-Hung", ""], ["Fu", "Michael C.", ""]]}, {"id": "1710.02650", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Topic Modeling based on Keywords and Context", "comments": "SIAM International Conference on Data Mining (SDM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current topic models often suffer from discovering topics not matching human\nintuition, unnatural switching of topics within documents and high\ncomputational demands. We address these concerns by proposing a topic model and\nan inference algorithm based on automatically identifying characteristic\nkeywords for topics. Keywords influence topic-assignments of nearby words. Our\nalgorithm learns (key)word-topic scores and it self-regulates the number of\ntopics. Inference is simple and easily parallelizable. Qualitative analysis\nyields comparable results to state-of-the-art models (eg. LDA), but with\ndifferent strengths and weaknesses. Quantitative analysis using 9 datasets\nshows gains in terms of classification accuracy, PMI score, computational\nperformance and consistency of topic assignments within documents, while most\noften using less topics.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 08:18:12 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 23:36:54 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "1710.02736", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Andrej Risteski", "title": "Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal\n  Distributions using Simulated Tempering Langevin Monte Carlo", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key task in Bayesian statistics is sampling from distributions that are\nonly specified up to a partition function (i.e., constant of proportionality).\nHowever, without any assumptions, sampling (even approximately) can be #P-hard,\nand few works have provided \"beyond worst-case\" guarantees for such settings.\n  For log-concave distributions, classical results going back to Bakry and\n\\'Emery (1985) show that natural continuous-time Markov chains called Langevin\ndiffusions mix in polynomial time. The most salient feature of log-concavity\nviolated in practice is uni-modality: commonly, the distributions we wish to\nsample from are multi-modal. In the presence of multiple deep and\nwell-separated modes, Langevin diffusion suffers from torpid mixing.\n  We address this problem by combining Langevin diffusion with simulated\ntempering. The result is a Markov chain that mixes more rapidly by\ntransitioning between different temperatures of the distribution. We analyze\nthis Markov chain for the canonical multi-modal distribution: a mixture of\ngaussians (of equal variance). The algorithm based on our Markov chain provably\nsamples from distributions that are close to mixtures of gaussians, given\naccess to the gradient of the log-pdf. For the analysis, we use a spectral\ndecomposition theorem for graphs (Gharan and Trevisan, 2014) and a Markov chain\ndecomposition technique (Madras and Randall, 2002).\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 19:55:51 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 01:49:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Risteski", "Andrej", ""]]}, {"id": "1710.02756", "submitter": "William Casper", "authors": "W.R. Casper and Balu Nadiga", "title": "A New Spectral Clustering Algorithm", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new clustering algorithm that is based on searching for natural\ngaps in the components of the lowest energy eigenvectors of the Laplacian of a\ngraph. In comparing the performance of the proposed method with a set of other\npopular methods (KMEANS, spectral-KMEANS, and an agglomerative method) in the\ncontext of the Lancichinetti-Fortunato-Radicchi (LFR) Benchmark for undirected\nweighted overlapping networks, we find that the new method outperforms the\nother spectral methods considered in certain parameter regimes. Finally, in an\napplication to climate data involving one of the most important modes of\ninterannual climate variability, the El Nino Southern Oscillation phenomenon,\nwe demonstrate the ability of the new algorithm to readily identify different\nflavors of the phenomenon.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 22:59:13 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Casper", "W. R.", ""], ["Nadiga", "Balu", ""]]}, {"id": "1710.02765", "submitter": "Ngoc Hieu Tran", "authors": "Ngoc Hieu Tran, Zachariah Levine, Lei Xin, Baozhen Shan, Ming Li", "title": "Protein identification with deep learning: from abc to xyz", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proteins are the main workhorses of biological functions in a cell, a tissue,\nor an organism. Identification and quantification of proteins in a given\nsample, e.g. a cell type under normal/disease conditions, are fundamental tasks\nfor the understanding of human health and disease. In this paper, we present\nDeepNovo, a deep learning-based tool to address the problem of protein\nidentification from tandem mass spectrometry data. The idea was first proposed\nin the context of de novo peptide sequencing [1] in which convolutional neural\nnetworks and recurrent neural networks were applied to predict the amino acid\nsequence of a peptide from its spectrum, a similar task to generating a caption\nfrom an image. We further develop DeepNovo to perform sequence database search,\nthe main technique for peptide identification that greatly benefits from\nnumerous existing protein databases. We combine two modules de novo sequencing\nand database search into a single deep learning framework for peptide\nidentification, and integrate de Bruijn graph assembly technique to offer a\ncomplete solution to reconstruct protein sequences from tandem mass\nspectrometry data. This paper describes a comprehensive protocol of DeepNovo\nfor protein identification, including training neural network models, dynamic\nprogramming search, database querying, estimation of false discovery rate, and\nde Bruijn graph assembly. Training and testing data, model implementations, and\ncomprehensive tutorials in form of IPython notebooks are available in our\nGitHub repository (https://github.com/nh2tran/DeepNovo).\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 01:23:18 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Tran", "Ngoc Hieu", ""], ["Levine", "Zachariah", ""], ["Xin", "Lei", ""], ["Shan", "Baozhen", ""], ["Li", "Ming", ""]]}, {"id": "1710.02766", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Bayesian Alignments of Warped Multi-Output Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian approach to modelling nonlinear alignments of\ntime series based on latent shared information. We apply the method to the\nreal-world problem of finding common structure in the sensor data of wind\nturbines introduced by the underlying latent and turbulent wind field. The\nproposed model allows for both arbitrary alignments of the inputs and\nnon-parametric output warpings to transform the observations. This gives rise\nto multiple deep Gaussian process models connected via latent generating\nprocesses. We present an efficient variational approximation based on nested\nvariational compression and show how the model can be used to extract shared\ninformation between dependent time series, recovering an interpretable\nfunctional decomposition of the learning problem. We show results for an\nartificial data set and real-world data of two wind turbines.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 01:42:39 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 12:04:08 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 13:07:53 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1710.02823", "submitter": "Markku Hinkka", "authors": "Markku Hinkka, Teemu Lehto, Keijo Heljanko, Alexander Jung", "title": "Structural Feature Selection for Event Logs", "comments": "Extended version of a paper published in the proceedings of the BPM\n  2017 workshops", "journal-ref": null, "doi": "10.1007/978-3-319-74030-0_2", "report-no": null, "categories": "cs.LG cs.DB cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classifying business process instances based on\nstructural features derived from event logs. The main motivation is to provide\nmachine learning based techniques with quick response times for interactive\ncomputer assisted root cause analysis. In particular, we create structural\nfeatures from process mining such as activity and transition occurrence counts,\nand ordering of activities to be evaluated as potential features for\nclassification. We show that adding such structural features increases the\namount of information thus potentially increasing classification accuracy.\nHowever, there is an inherent trade-off as using too many features leads to too\nlong run-times for machine learning classification models. One way to improve\nthe machine learning algorithms' run-time is to only select a small number of\nfeatures by a feature selection algorithm. However, the run-time required by\nthe feature selection algorithm must also be taken into account. Also, the\nclassification accuracy should not suffer too much from the feature selection.\nThe main contributions of this paper are as follows: First, we propose and\ncompare six different feature selection algorithms by means of an experimental\nsetup comparing their classification accuracy and achievable response times.\nSecond, we discuss the potential use of feature selection results for computer\nassisted root cause analysis as well as the properties of different types of\nstructural features in the context of feature selection.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 11:38:37 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 08:54:22 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Hinkka", "Markku", ""], ["Lehto", "Teemu", ""], ["Heljanko", "Keijo", ""], ["Jung", "Alexander", ""]]}, {"id": "1710.02836", "submitter": "Jiajun Liu", "authors": "Yanlei Yu, Zhiwu Lu, Jiajun Liu, Guoping Zhao, Ji-Rong Wen, Kai Zheng", "title": "RUM: network Representation learning throUgh Multi-level structural\n  information preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have witnessed the discovery of many techniques for network representation\nlearning in recent years, ranging from encoding the context in random walks to\nembedding the lower order connections, to finding latent space representations\nwith auto-encoders. However, existing techniques are looking mostly into the\nlocal structures in a network, while higher-level properties such as global\ncommunity structures are often neglected. We propose a novel network\nrepresentations learning model framework called RUM (network Representation\nlearning throUgh Multi-level structural information preservation). In RUM, we\nincorporate three essential aspects of a node that capture a network's\ncharacteristics in multiple levels: a node's affiliated local triads, its\nneighborhood relationships, and its global community affiliations. Therefore\nthe framework explicitly and comprehensively preserves the structural\ninformation of a network, extending the encoding process both to the local end\nof the structural information spectrum and to the global end. The framework is\nalso flexible enough to take various community discovery algorithms as its\npreprocessor. Empirical results show that the representations learned by RUM\nhave demonstrated substantial performance advantages in real-life tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 14:23:30 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Yu", "Yanlei", ""], ["Lu", "Zhiwu", ""], ["Liu", "Jiajun", ""], ["Zhao", "Guoping", ""], ["Wen", "Ji-Rong", ""], ["Zheng", "Kai", ""]]}, {"id": "1710.02844", "submitter": "Zeng Yu", "authors": "Zeng Yu, Tianrui Li, Ning Yu, Yi Pan, Hongmei Chen, Bing Liu", "title": "Reconstruction of Hidden Representation for Robust Feature Extraction", "comments": "This article has been accepted for publication in a future issue of\n  ACM Transactions on Intelligent Systems and Technology", "journal-ref": null, "doi": "10.1145/3284174", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to develop a new and robust approach to feature\nrepresentation. Motivated by the success of Auto-Encoders, we first theoretical\nsummarize the general properties of all algorithms that are based on\ntraditional Auto-Encoders: 1) The reconstruction error of the input can not be\nlower than a lower bound, which can be viewed as a guiding principle for\nreconstructing the input. Additionally, when the input is corrupted with\nnoises, the reconstruction error of the corrupted input also can not be lower\nthan a lower bound. 2) The reconstruction of a hidden representation achieving\nits ideal situation is the necessary condition for the reconstruction of the\ninput to reach the ideal state. 3) Minimizing the Frobenius norm of the\nJacobian matrix of the hidden representation has a deficiency and may result in\na much worse local optimum value. We believe that minimizing the reconstruction\nerror of the hidden representation is more robust than minimizing the Frobenius\nnorm of the Jacobian matrix of the hidden representation. Based on the above\nanalysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs),\nwhich uses corruption and reconstruction on both the input and the hidden\nrepresentation. We demonstrate that the proposed model is highly flexible and\nextensible and has a potentially better capability to learn invariant and\nrobust feature representations. We also show that our model is more robust than\nDenoising Auto-Encoders (DAEs) for dealing with noises or inessential features.\nFurthermore, we detail how to train DDAEs with two different pre-training\nmethods by optimizing the objective function in a combined and separate manner,\nrespectively. Comparative experiments illustrate that the proposed model is\nsignificantly better for representation learning than the state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 15:48:37 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 15:51:57 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Yu", "Zeng", ""], ["Li", "Tianrui", ""], ["Yu", "Ning", ""], ["Pan", "Yi", ""], ["Chen", "Hongmei", ""], ["Liu", "Bing", ""]]}, {"id": "1710.02869", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge, Jose C. Principe", "title": "An Analysis of the Value of Information when Exploring Stochastic,\n  Discrete Multi-Armed Bandits", "comments": "Entropy", "journal-ref": null, "doi": "10.3390/e20030155", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an information-theoretic exploration strategy for\nstochastic, discrete multi-armed bandits that achieves optimal regret. Our\nstrategy is based on the value of information criterion. This criterion\nmeasures the trade-off between policy information and obtainable rewards. High\namounts of policy information are associated with exploration-dominant searches\nof the space and yield high rewards. Low amounts of policy information favor\nthe exploitation of existing knowledge. Information, in this criterion, is\nquantified by a parameter that can be varied during search. We demonstrate that\na simulated-annealing-like update of this parameter, with a sufficiently fast\ncooling schedule, leads to an optimal regret that is logarithmic with respect\nto the number of episodes.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 18:48:48 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 21:01:57 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1710.02896", "submitter": "Doo Re Song", "authors": "Doo Re Song, Chuanyu Yang, Christopher McGreavy, Zhibin Li", "title": "Recurrent Deterministic Policy Gradient Method for Bipedal Locomotion on\n  Rough Terrain Challenge", "comments": "Published in IEEE proceedings: 2018 15th International Conference on\n  Control, Automation, Robotics and Vision (IEEE-ICARCV)", "journal-ref": "The Institute of Electrical and Electronics Engineers 2018 15th\n  International Conference on Control, Automation, Robotics and Vision\n  (IEEE-ICARCV)", "doi": "10.1109/ICARCV.2018.8581309", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep learning framework that is capable of solving\npartially observable locomotion tasks based on our novel interpretation of\nRecurrent Deterministic Policy Gradient (RDPG). We study on bias of sampled\nerror measure and its variance induced by the partial observability of\nenvironment and subtrajectory sampling, respectively. Three major improvements\nare introduced in our RDPG based learning framework: tail-step bootstrap of\ninterpolated temporal difference, initialisation of hidden state using past\ntrajectory scanning, and injection of external experiences learned by other\nagents. The proposed learning framework was implemented to solve the\nBipedal-Walker challenge in OpenAI's gym simulation environment where only\npartial state information is available. Our simulation study shows that the\nautonomous behaviors generated by the RDPG agent are highly adaptive to a\nvariety of obstacles and enables the agent to effectively traverse rugged\nterrains for long distance with higher success rate than leading contenders.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 22:38:34 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 10:12:48 GMT"}, {"version": "v3", "created": "Sun, 6 May 2018 16:54:06 GMT"}, {"version": "v4", "created": "Sat, 11 Aug 2018 09:55:39 GMT"}, {"version": "v5", "created": "Thu, 13 Sep 2018 08:40:02 GMT"}, {"version": "v6", "created": "Sun, 15 Dec 2019 11:03:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Song", "Doo Re", ""], ["Yang", "Chuanyu", ""], ["McGreavy", "Christopher", ""], ["Li", "Zhibin", ""]]}, {"id": "1710.02924", "submitter": "Chuanhou Gao", "authors": "Shaohan Chen, Chuanhou Gao, and Ping Zhang", "title": "Enhancing Interpretability of Black-box Soft-margin SVM by Integrating\n  Data-based Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability often makes black-box models difficult to be\napplied to many practical domains. For this reason, the current work, from the\nblack-box model input port, proposes to incorporate data-based prior\ninformation into the black-box soft-margin SVM model to enhance its\ninterpretability. The concept and incorporation mechanism of data-based prior\ninformation are successively developed, based on which the interpretable or\npartly interpretable SVM optimization model is designed and then solved through\nhandily rewriting the optimization problem as a nonlinear quadratic programming\nproblem. An algorithm for mining data-based linear prior information from data\nset is also proposed, which generates a linear expression with respect to two\nappropriate inputs identified from all inputs of system. At last, the proposed\ninterpretability enhancement strategy is applied to eight benchmark examples\nfor effectiveness exhibition.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 03:06:32 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 13:53:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chen", "Shaohan", ""], ["Gao", "Chuanhou", ""], ["Zhang", "Ping", ""]]}, {"id": "1710.02971", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, Jie Tang", "title": "Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE,\n  and node2vec", "comments": "9 pages, published in WSDM 2018 proceedings", "journal-ref": null, "doi": "10.1145/3159652.3159706", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the invention of word2vec, the skip-gram model has significantly\nadvanced the research of network embedding, such as the recent emergence of the\nDeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of\nthe aforementioned models with negative sampling can be unified into the matrix\nfactorization framework with closed forms. Our analysis and proofs reveal that:\n(1) DeepWalk empirically produces a low-rank transformation of a network's\nnormalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk\nwhen the size of vertices' context is set to one; (3) As an extension of LINE,\nPTE can be viewed as the joint factorization of multiple networks' Laplacians;\n(4) node2vec is factorizing a matrix related to the stationary distribution and\ntransition probability tensor of a 2nd-order random walk. We further provide\nthe theoretical connections between skip-gram based network embedding\nalgorithms and the theory of graph Laplacian. Finally, we present the NetMF\nmethod as well as its approximation algorithm for computing network embedding.\nOur method offers significant improvements over DeepWalk and LINE for\nconventional network mining tasks. This work lays the theoretical foundation\nfor skip-gram based network embedding methods, leading to a better\nunderstanding of latent network representation learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 07:28:46 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 02:38:00 GMT"}, {"version": "v3", "created": "Tue, 12 Dec 2017 06:33:35 GMT"}, {"version": "v4", "created": "Thu, 8 Feb 2018 09:51:03 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Dong", "Yuxiao", ""], ["Ma", "Hao", ""], ["Li", "Jian", ""], ["Wang", "Kuansan", ""], ["Tang", "Jie", ""]]}, {"id": "1710.03029", "submitter": "Martim Brand\\~ao", "authors": "Martim Brandao, Kenji Hashimoto, Atsuo Takanishi", "title": "SGD for robot motion? The effectiveness of stochastic optimization on a\n  new benchmark for biped locomotion tasks", "comments": "To appear in IEEE-RAS International Conference on Humanoid Robots\n  (Humanoids) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory optimization and posture generation are hard problems in robot\nlocomotion, which can be non-convex and have multiple local optima. Progress on\nthese problems is further hindered by a lack of open benchmarks, since\ncomparisons of different solutions are difficult to make. In this paper we\nintroduce a new benchmark for trajectory optimization and posture generation of\nlegged robots, using a pre-defined scenario, robot and constraints, as well as\nevaluation criteria. We evaluate state-of-the-art trajectory optimization\nalgorithms based on sequential quadratic programming (SQP) on the benchmark, as\nwell as new stochastic and incremental optimization methods borrowed from the\nlarge-scale machine learning literature. Interestingly we show that some of\nthese stochastic and incremental methods, which are based on stochastic\ngradient descent (SGD), achieve higher success rates than SQP on tough\ninitializations. Inspired by this observation we also propose a new incremental\nvariant of SQP which updates only a random subset of the costs and constraints\nat each iteration. The algorithm is the best performing in both success rate\nand convergence speed, improving over SQP by up to 30% in both criteria. The\nbenchmark's resources and a solution evaluation script are made openly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 11:02:29 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Brandao", "Martim", ""], ["Hashimoto", "Kenji", ""], ["Takanishi", "Atsuo", ""]]}, {"id": "1710.03035", "submitter": "Wenzhe Li", "authors": "Wenzhe Li, Dong Guo, Greg Ver Steeg, Aram Galstyan", "title": "Unifying Local and Global Change Detection in Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world networks are complex dynamical systems, where both local\n(e.g., changing node attributes) and global (e.g., changing network topology)\nprocesses unfold over time. Local dynamics may provoke global changes in the\nnetwork, and the ability to detect such effects could have profound\nimplications for a number of real-world problems. Most existing techniques\nfocus individually on either local or global aspects of the problem or treat\nthe two in isolation from each other. In this paper we propose a novel network\nmodel that simultaneously accounts for both local and global dynamics. To the\nbest of our knowledge, this is the first attempt at modeling and detecting\nlocal and global change points on dynamic networks via a unified generative\nframework. Our model is built upon the popular mixed membership stochastic\nblockmodels (MMSB) with sparse co-evolving patterns. We derive an efficient\nstochastic gradient Langevin dynamics (SGLD) sampler for our proposed model,\nwhich allows it to scale to potentially very large networks. Finally, we\nvalidate our model on both synthetic and real-world data and demonstrate its\nsuperiority over several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 11:34:29 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Li", "Wenzhe", ""], ["Guo", "Dong", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1710.03059", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garcia-Duran and Mathias Niepert", "title": "Learning Graph Representations with Embedding Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Embedding Propagation (EP), an unsupervised learning framework for\ngraph-structured data. EP learns vector representations of graphs by passing\ntwo types of messages between neighboring nodes. Forward messages consist of\nlabel representations such as representations of words and other attributes\nassociated with the nodes. Backward messages consist of gradients that result\nfrom aggregating the label representations and applying a reconstruction loss.\nNode representations are finally computed from the representation of their\nlabels. With significantly fewer parameters and hyperparameters an instance of\nEP is competitive with and often outperforms state of the art unsupervised and\nsemi-supervised learning methods on a range of benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 12:43:56 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Garcia-Duran", "Alberto", ""], ["Niepert", "Mathias", ""]]}, {"id": "1710.03070", "submitter": "Brian DePasquale", "authors": "Brian DePasquale, Christopher J. Cueva, Kanaka Rajan, G. Sean Escola,\n  L.F. Abbott", "title": "full-FORCE: A Target-Based Method for Training Recurrent Networks", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0191527", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained recurrent networks are powerful tools for modeling dynamic neural\ncomputations. We present a target-based method for modifying the full\nconnectivity matrix of a recurrent network to train it to perform tasks\ninvolving temporally complex input/output transformations. The method\nintroduces a second network during training to provide suitable \"target\"\ndynamics useful for performing the task. Because it exploits the full recurrent\nconnectivity, the method produces networks that perform tasks with fewer\nneurons and greater noise robustness than traditional least-squares (FORCE)\napproaches. In addition, we show how introducing additional input signals into\nthe target-generating network, which act as task hints, greatly extends the\nrange of tasks that can be learned and provides control over the complexity and\nnature of the dynamics of the trained, task-performing network.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 13:00:08 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["DePasquale", "Brian", ""], ["Cueva", "Christopher J.", ""], ["Rajan", "Kanaka", ""], ["Escola", "G. Sean", ""], ["Abbott", "L. F.", ""]]}, {"id": "1710.03107", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Georg N\\\"uhrenberg, Chung-Hao Huang, Harald Ruess", "title": "Verification of Binarized Neural Networks via Inter-Neuron Factoring", "comments": "Version 2: add proofs for hardness of PTAS approximability, remove\n  experiments on randomized examples and some not-so-important optimizations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of formal verification of Binarized Neural Networks\n(BNN), which have recently been proposed as a energy-efficient alternative to\ntraditional learning networks. The verification of BNNs, using the reduction to\nhardware verification, can be even more scalable by factoring computations\namong neurons within the same layer. By proving the NP-hardness of finding\noptimal factoring as well as the hardness of PTAS approximability, we design\npolynomial-time search heuristics to generate factoring solutions. The overall\nframework allows applying verification techniques to moderately-sized BNNs for\nembedded devices with thousands of neurons and inputs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 14:11:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 10:30:08 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["N\u00fchrenberg", "Georg", ""], ["Huang", "Chung-Hao", ""], ["Ruess", "Harald", ""]]}, {"id": "1710.03113", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Jian-Huang Lai, Chee-Keong Kwoh", "title": "Toward Multi-Diversified Ensemble Clustering of High-Dimensional Data:\n  From Subspaces to Metrics and Beyond", "comments": "Accepted by IEEE Transactions on Cybernetics. The MATLAB source code\n  is available at https://github.com/huangdonghere/MDEC", "journal-ref": null, "doi": "10.1109/TCYB.2021.3049633", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid emergence of high-dimensional data in various areas has brought new\nchallenges to current ensemble clustering research. To deal with the curse of\ndimensionality, recently considerable efforts in ensemble clustering have been\nmade by means of different subspace-based techniques. However, besides the\nemphasis on subspaces, rather limited attention has been paid to the potential\ndiversity in similarity/dissimilarity metrics. It remains a surprisingly open\nproblem in ensemble clustering how to create and aggregate a large population\nof diversified metrics, and furthermore, how to jointly investigate the\nmulti-level diversity in the large populations of metrics, subspaces, and\nclusters in a unified framework. To tackle this problem, this paper proposes a\nnovel multi-diversified ensemble clustering approach. In particular, we create\na large number of diversified metrics by randomizing a scaled exponential\nsimilarity kernel, which are then coupled with random subspaces to form a large\nset of metric-subspace pairs. Based on the similarity matrices derived from\nthese metric-subspace pairs, an ensemble of diversified base clusterings can\nthereby be constructed. Further, an entropy-based criterion is utilized to\nexplore the cluster-wise diversity in ensembles, based on which three specific\nensemble clustering algorithms are presented by incorporating three types of\nconsensus functions. Extensive experiments are conducted on 30 high-dimensional\ndatasets, including 18 cancer gene expression datasets and 12 image/speech\ndatasets, which demonstrate the superiority of our algorithms over the\nstate-of-the-art. The source code is available at\nhttps://github.com/huangdonghere/MDEC.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 14:19:04 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 08:06:15 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 17:33:00 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 01:49:43 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Lai", "Jian-Huang", ""], ["Kwoh", "Chee-Keong", ""]]}, {"id": "1710.03163", "submitter": "Mahmoud Nabil", "authors": "Mahmoud Nabil", "title": "Random Projection and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Projection is a foundational research topic that connects a bunch of\nmachine learning algorithms under a similar mathematical basis. It is used to\nreduce the dimensionality of the dataset by projecting the data points\nefficiently to a smaller dimensions while preserving the original relative\ndistance between the data points. In this paper, we are intended to explain\nrandom projection method, by explaining its mathematical background and\nfoundation, the applications that are currently adopting it, and an overview on\nits current research perspective.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 15:57:45 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Nabil", "Mahmoud", ""]]}, {"id": "1710.03184", "submitter": "Pratik Gajane", "authors": "Pratik Gajane and Mykola Pechenizkiy", "title": "On Formalizing Fairness in Prediction with Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms for prediction are increasingly being used in\ncritical decisions affecting human lives. Various fairness formalizations, with\nno firm consensus yet, are employed to prevent such algorithms from\nsystematically discriminating against people based on certain attributes\nprotected by law. The aim of this article is to survey how fairness is\nformalized in the machine learning literature for the task of prediction and\npresent these formalizations with their corresponding notions of distributive\njustice from the social sciences literature. We provide theoretical as well as\nempirical critiques of these notions from the social sciences literature and\nexplain how these critiques limit the suitability of the corresponding fairness\nformalizations to certain domains. We also suggest two notions of distributive\njustice which address some of these critiques and discuss avenues for\nprospective fairness formalizations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 16:39:31 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 10:12:23 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 08:22:01 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Gajane", "Pratik", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1710.03222", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir, Slawek Smyl", "title": "Forecasting Across Time Series Databases using Recurrent Neural Networks\n  on Groups of Similar Series: A Clustering Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Big Data, nowadays in many applications databases\ncontaining large quantities of similar time series are available. Forecasting\ntime series in these domains with traditional univariate forecasting procedures\nleaves great potentials for producing accurate forecasts untapped. Recurrent\nneural networks (RNNs), and in particular Long Short-Term Memory (LSTM)\nnetworks, have proven recently that they are able to outperform\nstate-of-the-art univariate time series forecasting methods in this context\nwhen trained across all available time series. However, if the time series\ndatabase is heterogeneous, accuracy may degenerate, so that on the way towards\nfully automatic forecasting methods in this space, a notion of similarity\nbetween the time series needs to be built into the methods. To this end, we\npresent a prediction model that can be used with different types of RNN models\non subgroups of similar time series, which are identified by time series\nclustering techniques. We assess our proposed methodology using LSTM networks,\na widely popular RNN variant. Our method achieves competitive results on\nbenchmarking datasets under competition evaluation procedures. In particular,\nin terms of mean sMAPE accuracy, it consistently outperforms the baseline LSTM\nmodel and outperforms all other methods on the CIF2016 forecasting competition\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 04:08:15 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 08:03:34 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Smyl", "Slawek", ""]]}, {"id": "1710.03263", "submitter": "Oren Elisha", "authors": "Oren Elisha and Shai Dekel", "title": "Function space analysis of deep learning representation layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a function space approach to Representation Learning\nand the analysis of the representation layers in deep learning architectures.\nWe show how to compute a weak-type Besov smoothness index that quantifies the\ngeometry of the clustering in the feature space. This approach was already\napplied successfully to improve the performance of machine learning algorithms\nsuch as the Random Forest and tree-based Gradient Boosting. Our experiments\ndemonstrate that in well-known and well-performing trained networks, the Besov\nsmoothness of the training set, measured in the corresponding hidden layer\nfeature map representation, increases from layer to layer. We also contribute\nto the understanding of generalization by showing how the Besov smoothness of\nthe representations, decreases as we add more mis-labeling to the training\ndata. We hope this approach will contribute to the de-mystification of some\naspects of deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 18:52:42 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Elisha", "Oren", ""], ["Dekel", "Shai", ""]]}, {"id": "1710.03282", "submitter": "Hugh Chen", "authors": "Hugh Chen and Scott Lundberg and Su-In Lee", "title": "Checkpoint Ensembles: Ensemble Methods from a Single Training Process", "comments": "7 pages, 4 figures, under review AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the checkpoint ensembles method that can learn ensemble models on\na single training process. Although checkpoint ensembles can be applied to any\nparametric iterative learning technique, here we focus on neural networks.\nNeural networks' composable and simple neurons make it possible to capture many\nindividual and interaction effects among features. However, small sample sizes\nand sampling noise may result in patterns in the training data that are not\nrepresentative of the true relationship between the features and the outcome.\nAs a solution, regularization during training is often used (e.g. dropout).\nHowever, regularization is no panacea -- it does not perfectly address\noverfitting. Even with methods like dropout, two methodologies are commonly\nused in practice. First is to utilize a validation set independent to the\ntraining set as a way to decide when to stop training. Second is to use\nensemble methods to further reduce overfitting and take advantage of local\noptima (i.e. averaging over the predictions of several models). In this paper,\nwe explore checkpoint ensembles -- a simple technique that combines these two\nideas in one training process. Checkpoint ensembles improve performance by\naveraging the predictions from \"checkpoints\" of the best models within single\ntraining process. We use three real-world data sets -- text, image, and\nelectronic health record data -- using three prediction models: a vanilla\nneural network, a convolutional neural network, and a long short term memory\nnetwork to show that checkpoint ensembles outperform existing methods: a method\nthat selects a model by minimum validation score, and two methods that average\nmodels by weights. Our results also show that checkpoint ensembles capture a\nportion of the performance gains that traditional ensembles provide.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:38:26 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "1710.03285", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Alexander Munteanu, Kristian Kersting", "title": "Coresets for Dependency Networks", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications infer the structure of a probabilistic graphical model from\ndata to elucidate the relationships between variables. But how can we train\ngraphical models on a massive data set? In this paper, we show how to construct\ncoresets -compressed data sets which can be used as proxy for the original data\nand have provably bounded worst case error- for Gaussian dependency networks\n(DNs), i.e., cyclic directed graphical models over Gaussians, where the parents\nof each variable are its Markov blanket. Specifically, we prove that Gaussian\nDNs admit coresets of size independent of the size of the data set.\nUnfortunately, this does not extend to DNs over members of the exponential\nfamily in general. As we will prove, Poisson DNs do not admit small coresets.\nDespite this worst-case result, we will provide an argument why our coreset\nconstruction for DNs can still work well in practice on count data. To\ncorroborate our theoretical results, we empirically evaluated the resulting\nCore DNs on real data sets. The results\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:49:11 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 08:45:43 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Molina", "Alejandro", ""], ["Munteanu", "Alexander", ""], ["Kersting", "Kristian", ""]]}, {"id": "1710.03297", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Antonio Vergari, Nicola Di Mauro, Sriraam Natarajan,\n  Floriana Esposito, Kristian Kersting", "title": "Sum-Product Networks for Hybrid Domains", "comments": "16 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While all kinds of mixed data -from personal data, over panel and scientific\ndata, to public and commercial data- are collected and stored, building\nprobabilistic graphical models for these hybrid domains becomes more difficult.\nUsers spend significant amounts of time in identifying the parametric form of\nthe random variables (Gaussian, Poisson, Logit, etc.) involved and learning the\nmixed models. To make this difficult task easier, we propose the first\ntrainable probabilistic deep architecture for hybrid domains that features\ntractable queries. It is based on Sum-Product Networks (SPNs) with piecewise\npolynomial leave distributions together with novel nonparametric decomposition\nand conditioning steps using the Hirschfeld-Gebelein-R\\'enyi Maximum\nCorrelation Coefficient. This relieves the user from deciding a-priori the\nparametric form of the random variables but is still expressive enough to\neffectively approximate any continuous distribution and permits efficient\nlearning and inference. Our empirical evidence shows that the architecture,\ncalled Mixed SPNs, can indeed capture complex distributions across a wide range\nof hybrid domains.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 20:13:21 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 08:40:57 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 09:39:01 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Molina", "Alejandro", ""], ["Vergari", "Antonio", ""], ["Di Mauro", "Nicola", ""], ["Natarajan", "Sriraam", ""], ["Esposito", "Floriana", ""], ["Kersting", "Kristian", ""]]}, {"id": "1710.03323", "submitter": "Gerasimos Spanakis", "authors": "Tom Rolandus Hagedoorn, Gerasimos Spanakis", "title": "Massive Open Online Courses Temporal Profiling for Dropout Prediction", "comments": "8 pages, ICTAI17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Courses (MOOCs) are attracting the attention of people\nall over the world. Regardless the platform, numbers of registrants for online\ncourses are impressive but in the same time, completion rates are\ndisappointing. Understanding the mechanisms of dropping out based on the\nlearner profile arises as a crucial task in MOOCs, since it will allow\nintervening at the right moment in order to assist the learner in completing\nthe course. In this paper, the dropout behaviour of learners in a MOOC is\nthoroughly studied by first extracting features that describe the behavior of\nlearners within the course and then by comparing three classifiers (Logistic\nRegression, Random Forest and AdaBoost) in two tasks: predicting which users\nwill have dropped out by a certain week and predicting which users will drop\nout on a specific week. The former has showed to be considerably easier, with\nall three classifiers performing equally well. However, the accuracy for the\nsecond task is lower, and Logistic Regression tends to perform slightly better\nthan the other two algorithms. We found that features that reflect an active\nattitude of the user towards the MOOC, such as submitting their assignment,\nposting on the Forum and filling their Profile, are strong indicators of\npersistence.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 21:31:44 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Hagedoorn", "Tom Rolandus", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1710.03368", "submitter": "Yang Liu", "authors": "Jiaqi Guan, Yang Liu, Qiang Liu, Jian Peng", "title": "Energy-efficient Amortized Inference with Cascaded Deep Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have been remarkable successful in various AI tasks but\noften cast high computation and energy cost for energy-constrained applications\nsuch as mobile sensing. We address this problem by proposing a novel framework\nthat optimizes the prediction accuracy and energy cost simultaneously, thus\nenabling effective cost-accuracy trade-off at test time. In our framework, each\ndata instance is pushed into a cascade of deep neural networks with increasing\nsizes, and a selection module is used to sequentially determine when a\nsufficiently accurate classifier can be used for this data instance. The\ncascade of neural networks and the selection module are jointly trained in an\nend-to-end fashion by the REINFORCE algorithm to optimize a trade-off between\nthe computational cost and the predictive accuracy. Our method is able to\nsimultaneously improve the accuracy and efficiency by learning to assign easy\ninstances to fast yet sufficiently accurate classifiers to save computation and\nenergy cost, while assigning harder instances to deeper and more powerful\nclassifiers to ensure satisfiable accuracy. With extensive experiments on\nseveral image classification datasets using cascaded ResNet classifiers, we\ndemonstrate that our method outperforms the standard well-trained ResNets in\naccuracy but only requires less than 20% and 50% FLOPs cost on the CIFAR-10/100\ndatasets and 66% on the ImageNet dataset, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 01:14:54 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Guan", "Jiaqi", ""], ["Liu", "Yang", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1710.03442", "submitter": "Ryo Iwaki", "authors": "Ryo Iwaki and Minoru Asada", "title": "On- and Off-Policy Monotonic Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic policy improvement and off-policy learning are two main desirable\nproperties for reinforcement learning algorithms. In this paper, by lower\nbounding the performance difference of two policies, we show that the monotonic\npolicy improvement is guaranteed from on- and off-policy mixture samples. An\noptimization procedure which applies the proposed bound can be regarded as an\noff-policy natural policy gradient method. In order to support the theoretical\nresult, we provide a trust region policy optimization method using experience\nreplay as a naive application of our bound, and evaluate its performance in two\nclassical benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 08:18:24 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 08:37:34 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Iwaki", "Ryo", ""], ["Asada", "Minoru", ""]]}, {"id": "1710.03444", "submitter": "Martin Trapp", "authors": "Martin Trapp, Tamas Madl, Robert Peharz, Franz Pernkopf, Robert Trappl", "title": "Safe Semi-Supervised Learning of Sum-Product Networks", "comments": "Conference on Uncertainty in Artificial Intelligence (UAI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several domains obtaining class annotations is expensive while at the same\ntime unlabelled data are abundant. While most semi-supervised approaches\nenforce restrictive assumptions on the data distribution, recent work has\nmanaged to learn semi-supervised models in a non-restrictive regime. However,\nso far such approaches have only been proposed for linear models. In this work,\nwe introduce semi-supervised parameter learning for Sum-Product Networks\n(SPNs). SPNs are deep probabilistic models admitting inference in linear time\nin number of network edges. Our approach has several advantages, as it (1)\nallows generative and discriminative semi-supervised learning, (2) guarantees\nthat adding unlabelled data can increase, but not degrade, the performance\n(safe), and (3) is computationally efficient and does not enforce restrictive\nassumptions on the data distribution. We show on a variety of data sets that\nsafe semi-supervised learning with SPNs is competitive compared to\nstate-of-the-art and can lead to a better generative and discriminative\nobjective value than a purely supervised approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 08:27:42 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Trapp", "Martin", ""], ["Madl", "Tamas", ""], ["Peharz", "Robert", ""], ["Pernkopf", "Franz", ""], ["Trappl", "Robert", ""]]}, {"id": "1710.03463", "submitter": "Da Li", "authors": "Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M. Hospedales", "title": "Learning to Generalize: Meta-Learning for Domain Generalization", "comments": "8 pages, 2 figures, under review of AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain shift refers to the well known problem that a model trained in one\nsource domain performs poorly when applied to a target domain with different\nstatistics. {Domain Generalization} (DG) techniques attempt to alleviate this\nissue by producing models which by design generalize well to novel testing\ndomains. We propose a novel {meta-learning} method for domain generalization.\nRather than designing a specific model that is robust to domain shift as in\nmost previous DG work, we propose a model agnostic training procedure for DG.\nOur algorithm simulates train/test domain shift during training by synthesizing\nvirtual testing domains within each mini-batch. The meta-optimization objective\nrequires that steps to improve training domain performance should also improve\ntesting domain performance. This meta-learning procedure trains models with\ngood generalization ability to novel domains. We evaluate our method and\nachieve state of the art results on a recent cross-domain image classification\nbenchmark, as well demonstrating its potential on two classic reinforcement\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 09:15:16 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Li", "Da", ""], ["Yang", "Yongxin", ""], ["Song", "Yi-Zhe", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1710.03487", "submitter": "Jacopo Cavazza", "authors": "Jacopo Cavazza, Connor Lane, Benjamin D. Haeffele, Vittorio Murino,\n  Ren\\'e Vidal", "title": "An Analysis of Dropout for Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a simple yet effective algorithm for regularizing neural networks\nby randomly dropping out units through Bernoulli multiplicative noise, and for\nsome restricted problem classes, such as linear or logistic regression, several\ntheoretical studies have demonstrated the equivalence between dropout and a\nfully deterministic optimization problem with data-dependent Tikhonov\nregularization. This work presents a theoretical analysis of dropout for matrix\nfactorization, where Bernoulli random variables are used to drop a factor,\nthereby attempting to control the size of the factorization. While recent work\nhas demonstrated the empirical effectiveness of dropout for matrix\nfactorization, a theoretical understanding of the regularization properties of\ndropout in this context remains elusive. This work demonstrates the equivalence\nbetween dropout and a fully deterministic model for matrix factorization in\nwhich the factors are regularized by the sum of the product of the norms of the\ncolumns. While the resulting regularizer is closely related to a variational\nform of the nuclear norm, suggesting that dropout may limit the size of the\nfactorization, we show that it is possible to trivially lower the objective\nvalue by doubling the size of the factorization. We show that this problem is\ncaused by the use of a fixed dropout rate, which motivates the use of a rate\nthat increases with the size of the factorization. Synthetic experiments\nvalidate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 10:03:43 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Cavazza", "Jacopo", ""], ["Lane", "Connor", ""], ["Haeffele", "Benjamin D.", ""], ["Murino", "Vittorio", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1710.03522", "submitter": "Xiao-Long Ren", "authors": "Xiao-Long Ren, Niels Gleinig, Dijana Tolic, Nino Antulov-Fantulin", "title": "Underestimated cost of targeted attacks on complex networks", "comments": "14 pages, 7 figures", "journal-ref": "Complexity (2018)", "doi": "10.1155/2018/9826243", "report-no": "vol. 2018, Article ID 9826243, 15 pages", "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of complex networks under targeted attacks is deeply connected\nto the resilience of complex systems, i.e., the ability to make appropriate\nresponses to the attacks. In this article, we investigated the state-of-the-art\ntargeted node attack algorithms and demonstrate that they become very\ninefficient when the cost of the attack is taken into consideration. In this\npaper, we made explicit assumption that the cost of removing a node is\nproportional to the number of adjacent links that are removed, i.e., higher\ndegree nodes have higher cost. Finally, for the case when it is possible to\nattack links, we propose a simple and efficient edge removal strategy named\nHierarchical Power Iterative Normalized cut (HPI-Ncut).The results on real and\nartificial networks show that the HPI-Ncut algorithm outperforms all the node\nremoval and link removal attack algorithms when the cost of the attack is taken\ninto consideration. In addition, we show that on sparse networks, the\ncomplexity of this hierarchical power iteration edge removal algorithm is only\n$O(n\\log^{2+\\epsilon}(n))$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 11:38:15 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Ren", "Xiao-Long", ""], ["Gleinig", "Niels", ""], ["Tolic", "Dijana", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1710.03600", "submitter": "Zheng-Chu Guo", "authors": "Zheng-Chu Guo and Lei Shi", "title": "Fast and Strong Convergence of Online Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the online learning algorithm without explicit\nregularization terms. This algorithm is essentially a stochastic gradient\ndescent scheme in a reproducing kernel Hilbert space (RKHS). The polynomially\ndecaying step size in each iteration can play a role of regularization to\nensure the generalization ability of online learning algorithm. We develop a\nnovel capacity dependent analysis on the performance of the last iterate of\nonline learning algorithm. The contribution of this paper is two-fold. First,\nour nice analysis can lead to the convergence rate in the standard mean square\ndistance which is the best so far. Second, we establish, for the first time,\nthe strong convergence of the last iterate with polynomially decaying step\nsizes in the RKHS norm. We demonstrate that the theoretical analysis\nestablished in this paper fully exploits the fine structure of the underlying\nRKHS, and thus can lead to sharp error estimates of online learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 13:53:45 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Guo", "Zheng-Chu", ""], ["Shi", "Lei", ""]]}, {"id": "1710.03608", "submitter": "Jungwoo Lee", "authors": "Jungwoo Lee, Dongjin Choi, and Lee Sael", "title": "CTD: Fast, Accurate, and Interpretable Method for Static and Dynamic\n  Tensor Decompositions", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0200579", "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we find patterns and anomalies in a tensor, or multi-dimensional\narray, in an efficient and directly interpretable way? How can we do this in an\nonline environment, where a new tensor arrives each time step? Finding patterns\nand anomalies in a tensor is a crucial problem with many applications,\nincluding building safety monitoring, patient health monitoring, cyber\nsecurity, terrorist detection, and fake user detection in social networks.\nStandard PARAFAC and Tucker decomposition results are not directly\ninterpretable. Although a few sampling-based methods have previously been\nproposed towards better interpretability, they need to be made faster, more\nmemory efficient, and more accurate.\n  In this paper, we propose CTD, a fast, accurate, and directly interpretable\ntensor decomposition method based on sampling. CTD-S, the static version of\nCTD, provably guarantees a high accuracy that is 17 ~ 83x more accurate than\nthat of the state-of-the-art method. Also, CTD-S is made 5 ~ 86x faster, and 7\n~ 12x more memory-efficient than the state-of-the-art method by removing\nredundancy. CTD-D, the dynamic version of CTD, is the first interpretable\ndynamic tensor decomposition method ever proposed. Also, it is made 2 ~ 3x\nfaster than already fast CTD-S by exploiting factors at previous time step and\nby reordering operations. With CTD, we demonstrate how the results can be\neffectively interpreted in the online distributed denial of service (DDoS)\nattack detection.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 09:44:41 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Lee", "Jungwoo", ""], ["Choi", "Dongjin", ""], ["Sael", "Lee", ""]]}, {"id": "1710.03634", "submitter": "Laurent De Vito", "authors": "Laurent de Vito", "title": "LinXGBoost: Extension of XGBoost to Generalized Local Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XGBoost is often presented as the algorithm that wins every ML competition.\nSurprisingly, this is true even though predictions are piecewise constant. This\nmight be justified in high dimensional input spaces, but when the number of\nfeatures is low, a piecewise linear model is likely to perform better. XGBoost\nwas extended into LinXGBoost that stores at each leaf a linear model. This\nextension, equivalent to piecewise regularized least-squares, is particularly\nattractive for regression of functions that exhibits jumps or discontinuities.\nThose functions are notoriously hard to regress. Our extension is compared to\nthe vanilla XGBoost and Random Forest in experiments on both synthetic and\nreal-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 14:52:47 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["de Vito", "Laurent", ""]]}, {"id": "1710.03641", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Trapit Bansal, Yuri Burda, Ilya Sutskever, Igor\n  Mordatch, Pieter Abbeel", "title": "Continuous Adaptation via Meta-Learning in Nonstationary and Competitive\n  Environments", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability to continuously learn and adapt from limited experience in\nnonstationary environments is an important milestone on the path towards\ngeneral intelligence. In this paper, we cast the problem of continuous\nadaptation into the learning-to-learn framework. We develop a simple\ngradient-based meta-learning algorithm suitable for adaptation in dynamically\nchanging and adversarial scenarios. Additionally, we design a new multi-agent\ncompetitive environment, RoboSumo, and define iterated adaptation games for\ntesting various aspects of continuous adaptation strategies. We demonstrate\nthat meta-learning enables significantly more efficient adaptation than\nreactive baselines in the few-shot regime. Our experiments with a population of\nagents that learn and compete suggest that meta-learners are the fittest.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 15:00:37 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 17:27:36 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Bansal", "Trapit", ""], ["Burda", "Yuri", ""], ["Sutskever", "Ilya", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1710.03667", "submitter": "Madhu Advani", "authors": "Madhu S. Advani, Andrew M. Saxe", "title": "High-dimensional dynamics of generalization error in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an average case analysis of the generalization dynamics of large\nneural networks trained using gradient descent. We study the\npractically-relevant \"high-dimensional\" regime where the number of free\nparameters in the network is on the order of or even larger than the number of\nexamples in the dataset. Using random matrix theory and exact solutions in\nlinear models, we derive the generalization error and training error dynamics\nof learning and analyze how they depend on the dimensionality of data and\nsignal to noise ratio of the learning problem. We find that the dynamics of\ngradient descent learning naturally protect against overtraining and\noverfitting in large networks. Overtraining is worst at intermediate network\nsizes, when the effective number of free parameters equals the number of\nsamples, and thus can be reduced by making a network smaller or larger.\nAdditionally, in the high-dimensional regime, low generalization error requires\nstarting with small initial weights. We then turn to non-linear neural\nnetworks, and show that making networks very large does not harm their\ngeneralization performance. On the contrary, it can in fact reduce\novertraining, even without early stopping or regularization of any sort. We\nidentify two novel phenomena underlying this behavior in overcomplete models:\nfirst, there is a frozen subspace of the weights in which no learning occurs\nunder gradient descent; and second, the statistical properties of the\nhigh-dimensional regime yield better-conditioned input correlations which\nprotect against overtraining. We demonstrate that naive application of\nworst-case theories such as Rademacher complexity are inaccurate in predicting\nthe generalization performance of deep neural networks, and derive an\nalternative bound which incorporates the frozen subspace and conditioning\neffects and qualitatively matches the behavior observed in simulation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 15:48:12 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Advani", "Madhu S.", ""], ["Saxe", "Andrew M.", ""]]}, {"id": "1710.03695", "submitter": "Majid Jahani", "authors": "Majid Jahani, Naga Venkata C. Gudapati, Chenxin Ma, Rachael Tappenden,\n  Martin Tak\\'a\\v{c}", "title": "Fast and Safe: Accelerated gradient methods with optimality certificates\n  and underestimate sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the concept of an Underestimate Sequence (UES),\nwhich is motivated by Nesterov's estimate sequence. Our definition of a UES\nutilizes three sequences, one of which is a lower bound (or under-estimator) of\nthe objective function. The question of how to construct an appropriate\nsequence of lower bounds is addressed, and we present lower bounds for strongly\nconvex smooth functions and for strongly convex composite functions, which\nadhere to the UES framework. Further, we propose several first order methods\nfor minimizing strongly convex functions in both the smooth and composite\ncases. The algorithms, based on efficiently updating lower bounds on the\nobjective functions, have natural stopping conditions that provide the user\nwith a certificate of optimality. Convergence of all algorithms is guaranteed\nthrough the UES framework, and we show that all presented algorithms converge\nlinearly, with the accelerated variants enjoying the optimal linear rate of\nconvergence.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 16:10:55 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 23:47:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jahani", "Majid", ""], ["Gudapati", "Naga Venkata C.", ""], ["Ma", "Chenxin", ""], ["Tappenden", "Rachael", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1710.03740", "submitter": "Sharan Narang", "authors": "Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos,\n  Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev,\n  Ganesh Venkatesh, Hao Wu", "title": "Mixed Precision Training", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have enabled progress in a wide variety of applications.\nGrowing the size of the neural network typically results in improved accuracy.\nAs model sizes grow, the memory and compute requirements for training these\nmodels also increases. We introduce a technique to train deep neural networks\nusing half precision floating point numbers. In our technique, weights,\nactivations and gradients are stored in IEEE half-precision format.\nHalf-precision floating numbers have limited numerical range compared to\nsingle-precision numbers. We propose two techniques to handle this loss of\ninformation. Firstly, we recommend maintaining a single-precision copy of the\nweights that accumulates the gradients after each optimizer step. This\nsingle-precision copy is rounded to half-precision format during training.\nSecondly, we propose scaling the loss appropriately to handle the loss of\ninformation with half-precision gradients. We demonstrate that this approach\nworks for a wide variety of models including convolution neural networks,\nrecurrent neural networks and generative adversarial networks. This technique\nworks for large scale models with more than 100 million parameters trained on\nlarge datasets. Using this approach, we can reduce the memory consumption of\ndeep learning models by nearly 2x. In future processors, we can also expect a\nsignificant computation speedup using half-precision hardware units.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 17:42:04 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 19:09:05 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 20:04:02 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Micikevicius", "Paulius", ""], ["Narang", "Sharan", ""], ["Alben", "Jonah", ""], ["Diamos", "Gregory", ""], ["Elsen", "Erich", ""], ["Garcia", "David", ""], ["Ginsburg", "Boris", ""], ["Houston", "Michael", ""], ["Kuchaiev", "Oleksii", ""], ["Venkatesh", "Ganesh", ""], ["Wu", "Hao", ""]]}, {"id": "1710.03804", "submitter": "Hesham Mohamed Eraqi", "authors": "Hesham M. Eraqi, Mohamed N. Moustafa, Jens Honer", "title": "End-to-End Deep Learning for Steering Autonomous Vehicles Considering\n  Temporal Dependencies", "comments": "31st Conference on Neural Information Processing Systems (NIPS),\n  Machine Learning for Intelligent Transportation Systems Workshop, Long Beach,\n  CA, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steering a car through traffic is a complex task that is difficult to cast\ninto algorithms. Therefore, researchers turn to training artificial neural\nnetworks from front-facing camera data stream along with the associated\nsteering angles. Nevertheless, most existing solutions consider only the visual\ncamera frames as input, thus ignoring the temporal relationship between frames.\nIn this work, we propose a Convolutional Long Short-Term Memory Recurrent\nNeural Network (C-LSTM), that is end-to-end trainable, to learn both visual and\ndynamic temporal dependencies of driving. Additionally, We introduce posing the\nsteering angle regression problem as classification while imposing a spatial\nrelationship between the output layer neurons. Such method is based on learning\na sinusoidal function that encodes steering angles. To train and validate our\nproposed methods, we used the publicly available Comma.ai dataset. Our solution\nimproved steering root mean square error by 35% over recent methods, and led to\na more stable steering by 87%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 20:10:25 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 18:11:30 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 13:03:45 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Eraqi", "Hesham M.", ""], ["Moustafa", "Mohamed N.", ""], ["Honer", "Jens", ""]]}, {"id": "1710.03830", "submitter": "Vasilis Syrgkanis", "authors": "Vasilis Syrgkanis, Elie Tamer, Juba Ziani", "title": "Inference on Auctions with Weak Assumptions on Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.GT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sample of bids from independent auctions, this paper examines the\nquestion of inference on auction fundamentals (e.g. valuation distributions,\nwelfare measures) under weak assumptions on information structure. The question\nis important as it allows us to learn about the valuation distribution in a\nrobust way, i.e., without assuming that a particular information structure\nholds across observations. We leverage the recent contributions of\n\\cite{Bergemann2013} in the robust mechanism design literature that exploit the\nlink between Bayesian Correlated Equilibria and Bayesian Nash Equilibria in\nincomplete information games to construct an econometrics framework for\nlearning about auction fundamentals using observed data on bids. We showcase\nour construction of identified sets in private value and common value auctions.\nOur approach for constructing these sets inherits the computational simplicity\nof solving for correlated equilibria: checking whether a particular valuation\ndistribution belongs to the identified set is as simple as determining whether\na {\\it linear} program is feasible. A similar linear program can be used to\nconstruct the identified set on various welfare measures and counterfactual\nobjects. For inference and to summarize statistical uncertainty, we propose\nnovel finite sample methods using tail inequalities that are used to construct\nconfidence regions on sets. We also highlight methods based on Bayesian\nbootstrap and subsampling. A set of Monte Carlo experiments show adequate\nfinite sample properties of our inference procedures. We illustrate our methods\nusing data from OCS auctions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 21:46:47 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 14:22:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Syrgkanis", "Vasilis", ""], ["Tamer", "Elie", ""], ["Ziani", "Juba", ""]]}, {"id": "1710.03839", "submitter": "Rob Brekelmans", "authors": "Greg Ver Steeg, Rob Brekelmans, Hrayr Harutyunyan, and Aram Galstyan", "title": "Disentangled Representations via Synergy Minimization", "comments": "8 pages, 4 figures, 55th Annual Allerton Conference on Communication,\n  Control, and Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists often seek simplified representations of complex systems to\nfacilitate prediction and understanding. If the factors comprising a\nrepresentation allow us to make accurate predictions about our system, but\nobscuring any subset of the factors destroys our ability to make predictions,\nwe say that the representation exhibits informational synergy. We argue that\nsynergy is an undesirable feature in learned representations and that\nexplicitly minimizing synergy can help disentangle the true factors of\nvariation underlying data. We explore different ways of quantifying synergy,\nderiving new closed-form expressions in some cases, and then show how to modify\nlearning to produce representations that are minimally synergistic. We\nintroduce a benchmark task to disentangle separate characters from images of\nwords. We demonstrate that Minimally Synergistic (MinSyn) representations\ncorrectly disentangle characters while methods relying on statistical\nindependence fail.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 22:16:43 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Steeg", "Greg Ver", ""], ["Brekelmans", "Rob", ""], ["Harutyunyan", "Hrayr", ""], ["Galstyan", "Aram", ""]]}, {"id": "1710.03850", "submitter": "David Isele", "authors": "David Isele, Mohammad Rostami, Eric Eaton", "title": "Using Task Descriptions in Lifelong Machine Learning for Improved\n  Performance and Zero-Shot Transfer", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge transfer between tasks can improve the performance of learned\nmodels, but requires an accurate estimate of the inter-task relationships to\nidentify the relevant knowledge to transfer. These inter-task relationships are\ntypically estimated based on training data for each task, which is inefficient\nin lifelong learning settings where the goal is to learn each consecutive task\nrapidly from as little data as possible. To reduce this burden, we develop a\nlifelong learning method based on coupled dictionary learning that utilizes\nhigh-level task descriptions to model the inter-task relationships. We show\nthat using task descriptors improves the performance of the learned task\npolicies, providing both theoretical justification for the benefit and\nempirical demonstration of the improvement across a variety of learning\nproblems. Given only the descriptor for a new task, the lifelong learner is\nalso able to accurately predict a model for the new task through zero-shot\nlearning using the coupled dictionary, eliminating the need to gather training\ndata before addressing the task.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 22:57:43 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Isele", "David", ""], ["Rostami", "Mohammad", ""], ["Eaton", "Eric", ""]]}, {"id": "1710.03863", "submitter": "Yanjun Han", "authors": "Yanjun Han, Jiantao Jiao, Rajarshi Mukherjee", "title": "On Estimation of $L_{r}$-Norms in Gaussian White Noise Models", "comments": "This version (v6) fixed an error in the proof of Lemma 5.6, and\n  corrected some typos", "journal-ref": "Published in Probability Theory and Related Fields, vol. 177, no.\n  3-4, pp. 1243-1294, 2020", "doi": "10.1007/s00440-020-00982-x", "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complete picture of asymptotically minimax estimation of\n$L_r$-norms (for any $r\\ge 1$) of the mean in Gaussian white noise model over\nNikolskii-Besov spaces. In this regard, we complement the work of Lepski,\nNemirovski and Spokoiny (1999), who considered the cases of $r=1$ (with\npoly-logarithmic gap between upper and lower bounds) and $r$ even (with\nasymptotically sharp upper and lower bounds) over H\\\"{o}lder spaces. We\nadditionally consider the case of asymptotically adaptive minimax estimation\nand demonstrate a difference between even and non-even $r$ in terms of an\ninvestigator's ability to produce asymptotically adaptive minimax estimators\nwithout paying a penalty.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 00:22:03 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 06:45:30 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 04:47:50 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 02:59:15 GMT"}, {"version": "v5", "created": "Thu, 9 Jul 2020 05:46:24 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 06:31:53 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Han", "Yanjun", ""], ["Jiao", "Jiantao", ""], ["Mukherjee", "Rajarshi", ""]]}, {"id": "1710.03875", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Susmit Jha, Ashish Tiwari, Mark K. Ho,\n  Sanjit A. Seshia", "title": "Learning Task Specifications from Demonstrations", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world applications often naturally decompose into several sub-tasks. In\nmany settings (e.g., robotics) demonstrations provide a natural way to specify\nthe sub-tasks. However, most methods for learning from demonstrations either do\nnot provide guarantees that the artifacts learned for the sub-tasks can be\nsafely recombined or limit the types of composition available. Motivated by\nthis deficit, we consider the problem of inferring Boolean non-Markovian\nrewards (also known as logical trace properties or specifications) from\ndemonstrations provided by an agent operating in an uncertain, stochastic\nenvironment. Crucially, specifications admit well-defined composition rules\nthat are typically easy to interpret. In this paper, we formulate the\nspecification inference task as a maximum a posteriori (MAP) probability\ninference problem, apply the principle of maximum entropy to derive an analytic\ndemonstration likelihood model and give an efficient approach to search for the\nmost likely specification in a large candidate pool of specifications. In our\nexperiments, we demonstrate how learning specifications can help avoid common\nproblems that often arise due to ad-hoc reward composition.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 01:31:14 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 06:03:22 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 00:32:09 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 03:32:12 GMT"}, {"version": "v5", "created": "Sat, 27 Oct 2018 16:49:13 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Jha", "Susmit", ""], ["Tiwari", "Ashish", ""], ["Ho", "Mark K.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1710.03937", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust, Oscar Ramirez, Marek Fiser, Kenneth Oslund, Anthony\n  Francis, James Davidson, and Lydia Tapia", "title": "PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement\n  Learning and Sampling-based Planning", "comments": "9 pages, 7 figures", "journal-ref": "IEEE International Conference on Robotics and Automation (ICRA),\n  2018", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PRM-RL, a hierarchical method for long-range navigation task\ncompletion that combines sampling based path planning with reinforcement\nlearning (RL). The RL agents learn short-range, point-to-point navigation\npolicies that capture robot dynamics and task constraints without knowledge of\nthe large-scale topology. Next, the sampling-based planners provide roadmaps\nwhich connect robot configurations that can be successfully navigated by the RL\nagent. The same RL agents are used to control the robot under the direction of\nthe planning, enabling long-range navigation. We use the Probabilistic Roadmaps\n(PRMs) for the sampling-based planner. The RL agents are constructed using\nfeature-based and deep neural net policies in continuous state and action\nspaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation\ntasks with non-trivial robot dynamics: end-to-end differential drive indoor\nnavigation in office environments, and aerial cargo delivery in urban\nenvironments with load displacement constraints. Our results show improvement\nin task completion over both RL agents on their own and traditional\nsampling-based planners. In the indoor navigation task, PRM-RL successfully\ncompletes up to 215 m long trajectories under noisy sensor conditions, and the\naerial cargo delivery completes flights over 1000 m without violating the task\nconstraints in an environment 63 million times larger than used in training.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 07:19:17 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 07:05:43 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Faust", "Aleksandra", ""], ["Ramirez", "Oscar", ""], ["Fiser", "Marek", ""], ["Oslund", "Kenneth", ""], ["Francis", "Anthony", ""], ["Davidson", "James", ""], ["Tapia", "Lydia", ""]]}, {"id": "1710.03942", "submitter": "Nguyen Tran Quang", "authors": "Nguyen Tran, Saeed Basirian, Alexander Jung", "title": "When is Network Lasso Accurate: The Vector Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed learning algorithm for massive network-structured data\nsets (big data over networks) is the network Lasso (nLasso), which extends the\nwell- known Lasso estimator from sparse models to network-structured datasets.\nEfficient implementations of the nLasso have been presented using modern convex\noptimization methods. In this paper, we provide sufficient conditions on the\nnetwork structure and available label information such that nLasso accurately\nlearns a vector-valued graph signal (representing label information) from the\ninformation provided by the labels of a few data points.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 07:28:04 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Tran", "Nguyen", ""], ["Basirian", "Saeed", ""], ["Jung", "Alexander", ""]]}, {"id": "1710.03971", "submitter": "Markus Grasmair", "authors": "Markus Grasmair, Timo Klock, and Valeriya Naumova", "title": "Adaptive multi-penalty regularization based on a generalized Lasso path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many algorithms, parameter tuning remains a challenging and critical\ntask, which becomes tedious and infeasible in a multi-parameter setting.\nMulti-penalty regularization, successfully used for solving undetermined sparse\nregression of problems of unmixing type where signal and noise are additively\nmixed, is one of such examples. In this paper, we propose a novel algorithmic\nframework for an adaptive parameter choice in multi-penalty regularization with\na focus on the correct support recovery. Building upon the theory of\nregularization paths and algorithms for single-penalty functionals, we extend\nthese ideas to a multi-penalty framework by providing an efficient procedure\nfor the construction of regions containing structurally similar solutions,\ni.e., solutions with the same sparsity and sign pattern, over the whole range\nof parameters. Combining this with a model selection criterion, we can choose\nregularization parameters in a data-adaptive manner. Another advantage of our\nalgorithm is that it provides an overview on the solution stability over the\nwhole range of parameters. This can be further exploited to obtain additional\ninsights into the problem of interest. We provide a numerical analysis of our\nmethod and compare it to the state-of-the-art single-penalty algorithms for\ncompressed sensing problems in order to demonstrate the robustness and power of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 09:12:45 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Grasmair", "Markus", ""], ["Klock", "Timo", ""], ["Naumova", "Valeriya", ""]]}, {"id": "1710.04019", "submitter": "Bertrand Michel", "authors": "Fr\\'ed\\'eric Chazal (1), Bertrand Michel (2) ((1) DATASHAPE, (2) LSTA)", "title": "An introduction to Topological Data Analysis: fundamental and practical\n  aspects for data scientists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.AT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis is a recent and fast growing field providing a set\nof new topological and geometric tools to infer relevant features for possibly\ncomplex data. This paper is a brief introduction, through a few selected\ntopics, to basic fundamental and practical aspects of \\tda\\ for non experts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:53:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 08:31:59 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Michel", "Bertrand", "", "LSTA"]]}, {"id": "1710.04062", "submitter": "Alec Koppel", "authors": "Alec Koppel, Santiago Paternain, Cedric Richard, Alejandro Ribeiro", "title": "Decentralized Online Learning with Kernels", "comments": "Submitted to IEEE TSP. Partial results appear in 2017 IEEE GlobalSIP.\n  arXiv admin note: text overlap with arXiv:1612.04111", "journal-ref": null, "doi": "10.1109/TSP.2018.2830299", "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-agent stochastic optimization problems over reproducing\nkernel Hilbert spaces (RKHS). In this setting, a network of interconnected\nagents aims to learn decision functions, i.e., nonlinear statistical models,\nthat are optimal in terms of a global convex functional that aggregates data\nacross the network, with only access to locally and sequentially observed\nsamples. We propose solving this problem by allowing each agent to learn a\nlocal regression function while enforcing consensus constraints. We use a\npenalized variant of functional stochastic gradient descent operating\nsimultaneously with low-dimensional subspace projections. These subspaces are\nconstructed greedily by applying orthogonal matching pursuit to the sequence of\nkernel dictionaries and weights. By tuning the projection-induced bias, we\npropose an algorithm that allows for each individual agent to learn, based upon\nits locally observed data stream and message passing with its neighbors only, a\nregression function that is close to the globally optimal regression function.\nThat is, we establish that with constant step-size selections agents' functions\nconverge to a neighborhood of the globally optimal one while satisfying the\nconsensus constraints as the penalty parameter is increased. Moreover, the\ncomplexity of the learned regression functions is guaranteed to remain finite.\nOn both multi-class kernel logistic regression and multi-class kernel support\nvector classification with data generated from class-dependent Gaussian mixture\nmodels, we observe stable function estimation and state of the art performance\nfor distributed online multi-class classification. Experiments on the Brodatz\ntextures further substantiate the empirical validity of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 13:49:28 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Koppel", "Alec", ""], ["Paternain", "Santiago", ""], ["Richard", "Cedric", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1710.04089", "submitter": "Badong Chen", "authors": "Badong Chen, Lei Xing, Nanning Zheng, Jose C. Pr\\'incipe", "title": "Quantized Minimum Error Entropy Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing with traditional learning criteria, such as mean square error\n(MSE), the minimum error entropy (MEE) criterion is superior in nonlinear and\nnon-Gaussian signal processing and machine learning. The argument of the\nlogarithm in Renyis entropy estimator, called information potential (IP), is a\npopular MEE cost in information theoretic learning (ITL). The computational\ncomplexity of IP is however quadratic in terms of sample number due to double\nsummation. This creates computational bottlenecks especially for large-scale\ndatasets. To address this problem, in this work we propose an efficient\nquantization approach to reduce the computational burden of IP, which decreases\nthe complexity from O(N*N) to O (MN) with M << N. The new learning criterion is\ncalled the quantized MEE (QMEE). Some basic properties of QMEE are presented.\nIllustrative examples are provided to verify the excellent performance of QMEE.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:30:29 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 09:15:41 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Chen", "Badong", ""], ["Xing", "Lei", ""], ["Zheng", "Nanning", ""], ["Pr\u00edncipe", "Jose C.", ""]]}, {"id": "1710.04099", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen", "title": "Wembedder: Wikidata entity embedding web service", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I present a web service for querying an embedding of entities in the Wikidata\nknowledge graph. The embedding is trained on the Wikidata dump using Gensim's\nWord2Vec implementation and a simple graph walk. A REST API is implemented.\nTogether with the Wikidata API the web service exposes a multilingual resource\nfor over 600'000 Wikidata items and properties.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:56:27 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""]]}, {"id": "1710.04102", "submitter": "Alina Kloss", "authors": "Alina Kloss, Stefan Schaal and Jeannette Bohg", "title": "Combining Learned and Analytical Models for Predicting Action Effects\n  from Sensory Data", "comments": "The International Journal of Robotics Research (2020)", "journal-ref": null, "doi": "10.1177/0278364920954896", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most basic skills a robot should possess is predicting the effect\nof physical interactions with objects in the environment. This enables optimal\naction selection to reach a certain goal state. Traditionally, dynamics are\napproximated by physics-based analytical models. These models rely on specific\nstate representations that may be hard to obtain from raw sensory data,\nespecially if no knowledge of the object shape is assumed. More recently, we\nhave seen learning approaches that can predict the effect of complex physical\ninteractions directly from sensory input. It is however an open question how\nfar these models generalize beyond their training data. In this work, we\ninvestigate the advantages and limitations of neural network based learning\napproaches for predicting the effects of actions based on sensory input and\nshow how analytical and learned models can be combined to leverage the best of\nboth worlds. As physical interaction task, we use planar pushing, for which\nthere exists a well-known analytical model and a large real-world dataset. We\npropose to use a convolutional neural network to convert raw depth images or\norganized point clouds into a suitable representation for the analytical model\nand compare this approach to using neural networks for both, perception and\nprediction. A systematic evaluation of the proposed approach on a very large\nreal-world dataset shows two main advantages of the hybrid architecture.\nCompared to a pure neural network, it significantly (i) reduces required\ntraining data and (ii) improves generalization to novel physical interaction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 15:05:01 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 10:34:48 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 14:48:35 GMT"}, {"version": "v4", "created": "Mon, 12 Oct 2020 07:39:34 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kloss", "Alina", ""], ["Schaal", "Stefan", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1710.04110", "submitter": "Michael Mozer", "authors": "Michael C. Mozer, Denis Kazakov, Robert V. Lindsey", "title": "Discrete Event, Continuous Time RNNs", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate recurrent neural network architectures for event-sequence\nprocessing. Event sequences, characterized by discrete observations stamped\nwith continuous-valued times of occurrence, are challenging due to the\npotentially wide dynamic range of relevant time scales as well as interactions\nbetween time scales. We describe four forms of inductive bias that should\nbenefit architectures for event sequences: temporal locality, position and\nscale homogeneity, and scale interdependence. We extend the popular gated\nrecurrent unit (GRU) architecture to incorporate these biases via intrinsic\ntemporal dynamics, obtaining a continuous-time GRU. The CT-GRU arises by\ninterpreting the gates of a GRU as selecting a time scale of memory, and the\nCT-GRU generalizes the GRU by incorporating multiple time scales of memory and\nperforming context-dependent selection of time scales for information storage\nand retrieval. Event time-stamps drive decay dynamics of the CT-GRU, whereas\nthey serve as generic additional inputs to the GRU. Despite the very different\nmanner in which the two models consider time, their performance on eleven data\nsets we examined is essentially identical. Our surprising results point both to\nthe robustness of GRU and LSTM architectures for handling continuous time, and\nto the potency of incorporating continuous dynamics into neural architectures.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 15:20:51 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Mozer", "Michael C.", ""], ["Kazakov", "Denis", ""], ["Lindsey", "Robert V.", ""]]}, {"id": "1710.04133", "submitter": "Emanuele Massaro Ph.D.", "authors": "Umberto Fugiglando, Emanuele Massaro, Paolo Santi, Sebastiano Milardo,\n  Kacem Abida, Rainer Stahlmann, Florian Netter, Carlo Ratti", "title": "Driving Behavior Analysis through CAN Bus Data in an Uncontrolled\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cars can nowadays record several thousands of signals through the CAN bus\ntechnology and potentially provide real-time information on the car, the driver\nand the surrounding environment. This paper proposes a new method for the\nanalysis and classification of driver behavior using a selected subset of CAN\nbus signals, specifically gas pedal position, brake pedal pressure, steering\nwheel angle, steering wheel momentum, velocity, RPM, frontal and lateral\nacceleration. Data has been collected in a completely uncontrolled experiment,\nwhere 64 people drove 10 cars for or a total of over 2000 driving trips without\nany type of pre-determined driving instruction on a wide variety of road\nscenarios. We propose an unsupervised learning technique that clusters drivers\nin different groups, and offers a validation method to test the robustness of\nclustering in a wide range of experimental settings. The minimal amount of data\nneeded to preserve robust driver clustering is also computed. The presented\nstudy provides a new methodology for near-real-time classification of driver\nbehavior in uncontrolled environments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 09:58:23 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Fugiglando", "Umberto", ""], ["Massaro", "Emanuele", ""], ["Santi", "Paolo", ""], ["Milardo", "Sebastiano", ""], ["Abida", "Kacem", ""], ["Stahlmann", "Rainer", ""], ["Netter", "Florian", ""], ["Ratti", "Carlo", ""]]}, {"id": "1710.04162", "submitter": "Adam Stooke", "authors": "Adam Stooke and Pieter Abbeel", "title": "Synkhronos: a Multi-GPU Theano Extension for Data Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Synkhronos, an extension to Theano for multi-GPU computations\nleveraging data parallelism. Our framework provides automated execution and\nsynchronization across devices, allowing users to continue to write serial\nprograms without risk of race conditions. The NVIDIA Collective Communication\nLibrary is used for high-bandwidth inter-GPU communication. Further\nenhancements to the Theano function interface include input slicing (with\naggregation) and input indexing, which perform common data-parallel computation\npatterns efficiently. One example use case is synchronous SGD, which has\nrecently been shown to scale well for a growing set of deep learning problems.\nWhen training ResNet-50, we achieve a near-linear speedup of 7.5x on an NVIDIA\nDGX-1 using 8 GPUs, relative to Theano-only code running a single GPU in\nisolation. Yet Synkhronos remains general to any data-parallel computation\nprogrammable in Theano. By implementing parallelism at the level of individual\nTheano functions, our framework uniquely addresses a niche between manual\nmulti-device programming and prescribed multi-GPU training routines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 16:38:58 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Stooke", "Adam", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1710.04170", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath", "title": "Concentration of Multilinear Functions of the Ising Model with\n  Applications to Network Data", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math-ph math.MP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove near-tight concentration of measure for polynomial functions of the\nIsing model under high temperature. For any degree $d$, we show that a\ndegree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that\nscale as $\\exp(-r^{2/d})$ at radius $r=\\tilde{\\Omega}_d(n^{d/2})$. Our\nconcentration radius is optimal up to logarithmic factors for constant $d$,\nimproving known results by polynomial factors in the number of spins. We\ndemonstrate the efficacy of polynomial functions as statistics for testing the\nstrength of interactions in social networks in both synthetic and real world\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 16:55:14 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Kamath", "Gautam", ""]]}, {"id": "1710.04211", "submitter": "Biswa Sengupta", "authors": "Alessandro Bay, Biswa Sengupta", "title": "StackSeq2Seq: Dual Encoder Seq2Seq Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely studied non-deterministic polynomial time (NP) hard problem lies in\nfinding a route between the two nodes of a graph. Often meta-heuristics\nalgorithms such as $A^{*}$ are employed on graphs with a large number of nodes.\nHere, we propose a deep recurrent neural network architecture based on the\nSequence-2-Sequence (Seq2Seq) model, widely used, for instance in text\ntranslation. Particularly, we illustrate that utilising a context vector that\nhas been learned from two different recurrent networks enables increased\naccuracies in learning the shortest route of a graph. Additionally, we show\nthat one can boost the performance of the Seq2Seq network by smoothing the loss\nfunction using a homotopy continuation of the decoder's loss function.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:22:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 21:47:46 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Bay", "Alessandro", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1710.04234", "submitter": "Alexandre Drouin", "authors": "Alexandre Drouin, Toby Dylan Hocking, Fran\\c{c}ois Laviolette", "title": "Maximum Margin Interval Trees", "comments": "Accepted for presentation at the 31st Conference on Neural\n  Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a regression function using censored or interval-valued output data\nis an important problem in fields such as genomics and medicine. The goal is to\nlearn a real-valued prediction function, and the training output labels\nindicate an interval of possible values. Whereas most existing algorithms for\nthis task are linear models, in this paper we investigate learning nonlinear\ntree models. We propose to learn a tree by minimizing a margin-based\ndiscriminative objective function, and we provide a dynamic programming\nalgorithm for computing the optimal solution in log-linear time. We show\nempirically that this algorithm achieves state-of-the-art speed and prediction\naccuracy in a benchmark of several data sets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:02:38 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 16:48:57 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Drouin", "Alexandre", ""], ["Hocking", "Toby Dylan", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "1710.04238", "submitter": "Mark Tygert", "authors": "Mark Tygert", "title": "Regression-aware decompositions", "comments": "19 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear least-squares regression with a \"design\" matrix A approximates a given\nmatrix B via minimization of the spectral- or Frobenius-norm discrepancy\n||AX-B|| over every conformingly sized matrix X. Another popular approximation\nis low-rank approximation via principal component analysis (PCA) -- which is\nessentially singular value decomposition (SVD) -- or interpolative\ndecomposition (ID). Classically, PCA/SVD and ID operate solely with the matrix\nB being approximated, not supervised by any auxiliary matrix A. However, linear\nleast-squares regression models can inform the ID, yielding regression-aware\nID. As a bonus, this provides an interpretation as regression-aware PCA for a\nkind of canonical correlation analysis between A and B. The regression-aware\ndecompositions effectively enable supervision to inform classical\ndimensionality reduction, which classically has been totally unsupervised. The\nregression-aware decompositions reveal the structure inherent in B that is\nrelevant to regression against A.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:06:25 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 22:11:18 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tygert", "Mark", ""]]}, {"id": "1710.04248", "submitter": "Christian Grussler", "authors": "Christian Grussler and Pontus Giselsson", "title": "Local Convergence of Proximal Splitting Methods for Rank Constrained\n  Problems", "comments": "To be presented at the 56th IEEE Conference on Decision and Control,\n  Melbourne, Dec 2017", "journal-ref": null, "doi": "10.1109/CDC.2017.8263743", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the local convergence of proximal splitting algorithms to solve\noptimization problems that are convex besides a rank constraint. For this, we\nshow conditions under which the proximal operator of a function involving the\nrank constraint is locally identical to the proximal operator of its convex\nenvelope, hence implying local convergence. The conditions imply that the\nnon-convex algorithms locally converge to a solution whenever a convex\nrelaxation involving the convex envelope can be expected to solve the\nnon-convex problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:35:21 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Grussler", "Christian", ""], ["Giselsson", "Pontus", ""]]}, {"id": "1710.04325", "submitter": "Wai Ming Tai", "authors": "Jeff M. Phillips, Wai Ming Tai", "title": "Improved Coresets for Kernel Density Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the construction of coresets for kernel density estimates. That is\nwe show how to approximate the kernel density estimate described by a large\npoint set with another kernel density estimate with a much smaller point set.\nFor characteristic kernels (including Gaussian and Laplace kernels), our\napproximation preserves the $L_\\infty$ error between kernel density estimates\nwithin error $\\epsilon$, with coreset size $2/\\epsilon^2$, but no other aspects\nof the data, including the dimension, the diameter of the point set, or the\nbandwidth of the kernel common to other approximations. When the dimension is\nunrestricted, we show this bound is tight for these kernels as well as a much\nbroader set.\n  This work provides a careful analysis of the iterative Frank-Wolfe algorithm\nadapted to this context, an algorithm called \\emph{kernel herding}. This\nanalysis unites a broad line of work that spans statistics, machine learning,\nand geometry.\n  When the dimension $d$ is constant, we demonstrate much tighter bounds on the\nsize of the coreset specifically for Gaussian kernels, showing that it is\nbounded by the size of the coreset for axis-aligned rectangles. Currently the\nbest known constructive bound is $O(\\frac{1}{\\epsilon} \\log^d\n\\frac{1}{\\epsilon})$, and non-constructively, this can be improved by\n$\\sqrt{\\log \\frac{1}{\\epsilon}}$. This improves the best constant dimension\nbounds polynomially for $d \\geq 3$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 22:35:29 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1710.04329", "submitter": "Youzuo Lin", "authors": "Youzuo Lin, Shusen Wang, Jayaraman Thiagarajan, George Guthrie, David\n  Coblentz", "title": "Efficient Data-Driven Geologic Feature Detection from Pre-stack Seismic\n  Measurements using Randomized Machine-Learning Algorithm", "comments": null, "journal-ref": null, "doi": "10.1093/gji/ggy385", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional seismic techniques for detecting the subsurface geologic\nfeatures are challenged by limited data coverage, computational inefficiency,\nand subjective human factors. We developed a novel data-driven geological\nfeature detection approach based on pre-stack seismic measurements. Our\ndetection method employs an efficient and accurate machine-learning detection\napproach to extract useful subsurface geologic features automatically.\nSpecifically, our method is based on kernel ridge regression model. The\nconventional kernel ridge regression can be computationally prohibited because\nof the large volume of seismic measurements. We employ a data reduction\ntechnique in combination with the conventional kernel ridge regression method\nto improve the computational efficiency and reduce memory usage. In particular,\nwe utilize a randomized numerical linear algebra technique, named Nystr\\\"om\nmethod, to effectively reduce the dimensionality of the feature space without\ncompromising the information content required for accurate detection. We\nprovide thorough computational cost analysis to show efficiency of our new\ngeological feature detection methods. We further validate the performance of\nour new subsurface geologic feature detection method using synthetic surface\nseismic data for 2D acoustic and elastic velocity models. Our numerical\nexamples demonstrate that our new detection method significantly improves the\ncomputational efficiency while maintaining comparable accuracy. Interestingly,\nwe show that our method yields a speed-up ratio on the order of $\\sim10^2$ to\n$\\sim 10^3$ in a multi-core computational environment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 23:04:49 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lin", "Youzuo", ""], ["Wang", "Shusen", ""], ["Thiagarajan", "Jayaraman", ""], ["Guthrie", "George", ""], ["Coblentz", "David", ""]]}, {"id": "1710.04340", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi, Yoshinobu Kawahara, Takehisa Yairi", "title": "Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition", "comments": "18 pages, 7 figures, presented in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral decomposition of the Koopman operator is attracting attention as a\ntool for the analysis of nonlinear dynamical systems. Dynamic mode\ndecomposition is a popular numerical algorithm for Koopman spectral analysis;\nhowever, we often need to prepare nonlinear observables manually according to\nthe underlying dynamics, which is not always possible since we may not have any\na priori knowledge about them. In this paper, we propose a fully data-driven\nmethod for Koopman spectral analysis based on the principle of learning Koopman\ninvariant subspaces from observed data. To this end, we propose minimization of\nthe residual sum of squares of linear least-squares regression to estimate a\nset of functions that transforms data into a form in which the linear\nregression fits well. We introduce an implementation with neural networks and\nevaluate performance empirically using nonlinear dynamical systems and\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 01:37:46 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 08:06:25 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""], ["Yairi", "Takehisa", ""]]}, {"id": "1710.04350", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Tony (Zhiwei) Qin, Xuewen Chen, Matthew Nokleby and\n  Jieping Ye", "title": "A Unified Neural Network Approach for Estimating Travel Time and\n  Distance for a Taxi Trip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In building intelligent transportation systems such as taxi or rideshare\nservices, accurate prediction of travel time and distance is crucial for\ncustomer experience and resource management. Using the NYC taxi dataset, which\ncontains taxi trips data collected from GPS-enabled taxis [23], this paper\ninvestigates the use of deep neural networks to jointly predict taxi trip time\nand distance. We propose a model, called ST-NN (Spatio-Temporal Neural\nNetwork), which first predicts the travel distance between an origin and a\ndestination GPS coordinate, then combines this prediction with the time of day\nto predict the travel time. The beauty of ST-NN is that it uses only the raw\ntrips data without requiring further feature engineering and provides a joint\nestimate of travel time and distance. We compare the performance of ST-NN to\nthat of state-of-the-art travel time estimation methods, and we observe that\nthe proposed approach generalizes better than state-of-the-art methods. We show\nthat ST-NN approach significantly reduces the mean absolute error for both\npredicted travel time and distance, about 17% for travel time prediction. We\nalso observe that the proposed approach is more robust to outliers present in\nthe dataset by testing the performance of ST-NN on the datasets with and\nwithout outliers.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 03:21:16 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Jindal", "Ishan", "", "Zhiwei"], ["Tony", "", "", "Zhiwei"], ["Qin", "", ""], ["Chen", "Xuewen", ""], ["Nokleby", "Matthew", ""], ["Ye", "Jieping", ""]]}, {"id": "1710.04373", "submitter": "Chuanyun Zang", "authors": "Chuanyun Zang", "title": "Deep Learning in Multiple Multistep Time Series Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project aims to research on combining deep learning specifically\nLong-Short Memory (LSTM) and basic statistics in multiple multistep time series\nprediction. LSTM can dive into all the pages and learn the general trends of\nvariation in a large scope, while the well selected medians for each page can\nkeep the special seasonality of different pages so that the future trend will\nnot fluctuate too much from the reality. A recent Kaggle competition on 145K\nWeb Traffic Time Series Forecasting [1] is used to thoroughly illustrate and\ntest this idea.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 05:28:05 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Zang", "Chuanyun", ""]]}, {"id": "1710.04380", "submitter": "Tsuyoshi Kato", "authors": "Tsuyoshi Kato, Misato Kobayashi, Daisuke Sano", "title": "Sign-Constrained Regularized Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical analysis, domain knowledge about analysis target has often been\naccumulated, although, typically, such knowledge has been discarded in the\nstatistical analysis stage, and the statistical tool has been applied as a\nblack box. In this paper, we introduce sign constraints that are a handy and\nsimple representation for non-experts in generic learning problems. We have\ndeveloped two new optimization algorithms for the sign-constrained regularized\nloss minimization, called the sign-constrained Pegasos (SC-Pega) and the\nsign-constrained SDCA (SC-SDCA), by simply inserting the sign correction step\ninto the original Pegasos and SDCA, respectively. We present theoretical\nanalyses that guarantee that insertion of the sign correction step does not\ndegrade the convergence rate for both algorithms. Two applications, where the\nsign-constrained learning is effective, are presented. The one is exploitation\nof prior information about correlation between explanatory variables and a\ntarget variable. The other is introduction of the sign-constrained to\nSVM-Pairwise method. Experimental results demonstrate significant improvement\nof generalization performance by introducing sign constraints in both\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 06:34:54 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Kato", "Tsuyoshi", ""], ["Kobayashi", "Misato", ""], ["Sano", "Daisuke", ""]]}, {"id": "1710.04394", "submitter": "Daniel McNamara", "authors": "Daniel McNamara, Cheng Soon Ong, Robert C. Williamson", "title": "Provably Fair Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are increasingly used to make decisions about\npeople's lives, such as whether to give someone a loan or whether to interview\nsomeone for a job. This has led to considerable interest in making such machine\nlearning systems fair. One approach is to transform the input data used by the\nalgorithm. This can be achieved by passing each input data point through a\nrepresentation function prior to its use in training or testing. Techniques for\nlearning such representation functions from data have been successful\nempirically, but typically lack theoretical fairness guarantees. We show that\nit is possible to prove that a representation function is fair according to\ncommon measures of both group and individual fairness, as well as useful with\nrespect to a target task. These provable properties can be used in a governance\nmodel involving a data producer, a data user and a data regulator, where there\nis a separation of concerns between fairness and target task utility to ensure\ntransparency and prevent perverse incentives. We formally define the 'cost of\nmistrust' of using this model compared to the setting where there is a single\ntrusted party, and provide bounds on this cost in particular cases. We present\na practical approach to learning fair representation functions and apply it to\nfinancial and criminal justice datasets. We evaluate the fairness and utility\nof these representation functions using measures motivated by our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 07:37:52 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["McNamara", "Daniel", ""], ["Ong", "Cheng Soon", ""], ["Williamson", "Robert C.", ""]]}, {"id": "1710.04404", "submitter": "Or Sharir", "authors": "Or Sharir and Amnon Shashua", "title": "Sum-Product-Quotient Networks", "comments": "Published as a conference paper at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel tractable generative model that extends Sum-Product\nNetworks (SPNs) and significantly boosts their power. We call it\nSum-Product-Quotient Networks (SPQNs), whose core concept is to incorporate\nconditional distributions into the model by direct computation using quotient\nnodes, e.g. $P(A|B) = \\frac{P(A,B)}{P(B)}$. We provide sufficient conditions\nfor the tractability of SPQNs that generalize and relax the decomposable and\ncomplete tractability conditions of SPNs. These relaxed conditions give rise to\nan exponential boost to the expressive efficiency of our model, i.e. we prove\nthat there are distributions which SPQNs can compute efficiently but require\nSPNs to be of exponential size. Thus, we narrow the gap in expressivity between\ntractable graphical models and other Neural Network-based generative models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 08:18:07 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 16:11:53 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 23:34:53 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1710.04423", "submitter": "Youngchul Sung", "authors": "Seungyul Han and Youngchul Sung", "title": "AMBER: Adaptive Multi-Batch Experience Replay for Continuous Action\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new adaptive multi-batch experience replay scheme is\nproposed for proximal policy optimization (PPO) for continuous action control.\nOn the contrary to original PPO, the proposed scheme uses the batch samples of\npast policies as well as the current policy for the update for the next policy,\nwhere the number of the used past batches is adaptively determined based on the\noldness of the past batches measured by the average importance sampling (IS)\nweight. The new algorithm constructed by combining PPO with the proposed\nmulti-batch experience replay scheme maintains the advantages of original PPO\nsuch as random mini-batch sampling and small bias due to low IS weights by\nstoring the pre-computed advantages and values and adaptively determining the\nmini-batch size. Numerical results show that the proposed method significantly\nincreases the speed and stability of convergence on various continuous control\ntasks compared to original PPO.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 09:42:47 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 08:42:45 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "1710.04450", "submitter": "Parvin Razzaghi", "authors": "Parvin Razzaghi", "title": "Self-Taught Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new approach for classification of target task using limited\nlabeled target data as well as enormous unlabeled source data is proposed which\nis called self-taught learning. The target and source data can be drawn from\ndifferent distributions. In the previous approaches, covariate shift assumption\nis considered where the marginal distributions p(x) change over domains and the\nconditional distributions p(y|x) remain the same. In our approach, we propose a\nnew objective function which simultaneously learns a common space T(.) where\nthe conditional distributions over domains p(T(x)|y) remain the same and learns\nrobust SVM classifiers for target task using both source and target data in the\nnew representation. Hence, in the proposed objective function, the hidden label\nof the source data is also incorporated. We applied the proposed approach on\nCaltech-256, MSRC+LMO datasets and compared the performance of our algorithm to\nthe available competing methods. Our method has a superior performance to the\nsuccessful existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 11:12:30 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Razzaghi", "Parvin", ""]]}, {"id": "1710.04461", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Muhammad Ashad Kabir, Alan Colman, Jun Han", "title": "An Improved Naive Bayes Classifier-based Noise Detection Technique for\n  Classifying User Phone Call Behavior", "comments": "The 15th Australasian Data Mining Conference (AusDM 2017), Melbourne,\n  Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of noisy instances in mobile phone data is a fundamental issue\nfor classifying user phone call behavior (i.e., accept, reject, missed and\noutgoing), with many potential negative consequences. The classification\naccuracy may decrease and the complexity of the classifiers may increase due to\nthe number of redundant training samples. To detect such noisy instances from a\ntraining dataset, researchers use naive Bayes classifier (NBC) as it identifies\nmisclassified instances by taking into account independence assumption and\nconditional probabilities of the attributes. However, some of these\nmisclassified instances might indicate usages behavioral patterns of individual\nmobile phone users. Existing naive Bayes classifier based noise detection\ntechniques have not considered this issue and, thus, are lacking in\nclassification accuracy. In this paper, we propose an improved noise detection\ntechnique based on naive Bayes classifier for effectively classifying users'\nphone call behaviors. In order to improve the classification accuracy, we\neffectively identify noisy instances from the training dataset by analyzing the\nbehavioral patterns of individuals. We dynamically determine a noise threshold\naccording to individual's unique behavioral patterns by using both the naive\nBayes classifier and Laplace estimator. We use this noise threshold to identify\nnoisy instances. To measure the effectiveness of our technique in classifying\nuser phone call behavior, we employ the most popular classification algorithm\n(e.g., decision tree). Experimental results on the real phone call log dataset\nshow that our proposed technique more accurately identifies the noisy instances\nfrom the training datasets that leads to better classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 11:37:21 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 01:19:03 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Kabir", "Muhammad Ashad", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""]]}, {"id": "1710.04580", "submitter": "Galen Reeves", "authors": "Galen Reeves", "title": "Additivity of Information in Multilayer Networks via Additive Gaussian\n  Noise Transforms", "comments": "Presented at the 55th Annual Allerton Conference on Communication,\n  Control, and Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer (or deep) networks are powerful probabilistic models based on\nmultiple stages of a linear transform followed by a non-linear (possibly\nrandom) function. In general, the linear transforms are defined by matrices and\nthe non-linear functions are defined by information channels. These models have\ngained great popularity due to their ability to characterize complex\nprobabilistic relationships arising in a wide variety of inference problems.\nThe contribution of this paper is a new method for analyzing the fundamental\nlimits of statistical inference in settings where the model is known. The\nvalidity of our method can be established in a number of settings and is\nconjectured to hold more generally. A key assumption made throughout is that\nthe matrices are drawn randomly from orthogonally invariant distributions.\n  Our method yields explicit formulas for 1) the mutual information; 2) the\nminimum mean-squared error (MMSE); 3) the existence and locations of certain\nphase-transitions with respect to the problem parameters; and 4) the stationary\npoints for the state evolution of approximate message passing algorithms. When\napplied to the special case of models with multivariate Gaussian channels our\nmethod is rigorous and has close connections to free probability theory for\nrandom matrices. When applied to the general case of non-Gaussian channels, our\nmethod provides a simple alternative to the replica method from statistical\nphysics. A key observation is that the combined effects of the individual\ncomponents in the model (namely the matrices and the channels) are additive\nwhen viewed in a certain transform domain.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:02:19 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Reeves", "Galen", ""]]}, {"id": "1710.04582", "submitter": "Eleni Vasilaki D.Phil.", "authors": "Eleni Vasilaki", "title": "Is Epicurus the father of Reinforcement Learning?", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Epicurean Philosophy is commonly thought as simplistic and hedonistic.\nHere I discuss how this is a misconception and explore its link to\nReinforcement Learning. Based on the letters of Epicurus, I construct an\nobjective function for hedonism which turns out to be equivalent of the\nReinforcement Learning objective function when omitting the discount factor. I\nthen discuss how Plato and Aristotle 's views that can be also loosely linked\nto Reinforcement Learning, as well as their weaknesses in relationship to it.\nFinally, I emphasise the close affinity of the Epicurean views and the Bellman\nequation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:07:18 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Vasilaki", "Eleni", ""]]}, {"id": "1710.04584", "submitter": "Yongyu Wang", "authors": "Yongyu Wang, Zhuo Feng", "title": "Towards Scalable Spectral Clustering via Spectrum-Preserving\n  Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is\nthe main computational bottleneck in spectral clustering. In this work, we\nintroduce a highly-scalable, spectrum-preserving graph sparsification algorithm\nthat enables to build ultra-sparse NN (u-NN) graphs with guaranteed\npreservation of the original graph spectrums, such as the first few\neigenvectors of the original graph Laplacian. Our approach can immediately lead\nto scalable spectral clustering of large data networks without sacrificing\nsolution quality. The proposed method starts from constructing low-stretch\nspanning trees (LSSTs) from the original graphs, which is followed by\niteratively recovering small portions of \"spectrally critical\" off-tree edges\nto the LSSTs by leveraging a spectral off-tree embedding scheme. To determine\nthe suitable amount of off-tree edges to be recovered to the LSSTs, an\neigenvalue stability checking scheme is proposed, which enables to robustly\npreserve the first few Laplacian eigenvectors within the sparsified graph.\nAdditionally, an incremental graph densification scheme is proposed for\nidentifying extra edges that have been missing in the original NN graphs but\ncan still play important roles in spectral clustering tasks. Our experimental\nresults for a variety of well-known data sets show that the proposed method can\ndramatically reduce the complexity of NN graphs, leading to significant\nspeedups in spectral clustering.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:09:29 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 00:51:54 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 01:04:10 GMT"}, {"version": "v4", "created": "Thu, 11 Oct 2018 17:59:49 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Wang", "Yongyu", ""], ["Feng", "Zhuo", ""]]}, {"id": "1710.04615", "submitter": "Tianhao Zhang", "authors": "Tianhao Zhang, Zoe McCarthy, Owen Jow, Dennis Lee, Xi Chen, Ken\n  Goldberg, Pieter Abbeel", "title": "Deep Imitation Learning for Complex Manipulation Tasks from Virtual\n  Reality Teleoperation", "comments": "First two authors contributed equally. Video available at\n  https://sites.google.com/view/vrlfd/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a powerful paradigm for robot skill acquisition.\nHowever, obtaining demonstrations suitable for learning a policy that maps from\nraw pixels to actions can be challenging. In this paper we describe how\nconsumer-grade Virtual Reality headsets and hand tracking hardware can be used\nto naturally teleoperate robots to perform complex tasks. We also describe how\nimitation learning can learn deep neural network policies (mapping from pixels\nto actions) that can acquire the demonstrated skills. Our experiments showcase\nthe effectiveness of our approach for learning visuomotor skills.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 17:02:31 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 19:00:40 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Zhang", "Tianhao", ""], ["McCarthy", "Zoe", ""], ["Jow", "Owen", ""], ["Lee", "Dennis", ""], ["Chen", "Xi", ""], ["Goldberg", "Ken", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1710.04689", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, Katharina Muelling and Jean Oh", "title": "Social Attention: Modeling Attention in Human Crowds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that navigate through human crowds need to be able to plan safe,\nefficient, and human predictable trajectories. This is a particularly\nchallenging problem as it requires the robot to predict future human\ntrajectories within a crowd where everyone implicitly cooperates with each\nother to avoid collisions. Previous approaches to human trajectory prediction\nhave modeled the interactions between humans as a function of proximity.\nHowever, that is not necessarily true as some people in our immediate vicinity\nmoving in the same direction might not be as important as other people that are\nfurther away, but that might collide with us in the future. In this work, we\npropose Social Attention, a novel trajectory prediction model that captures the\nrelative importance of each person when navigating in the crowd, irrespective\nof their proximity. We demonstrate the performance of our method against a\nstate-of-the-art approach on two publicly available crowd datasets and analyze\nthe trained attention model to gain a better understanding of which surrounding\nagents humans attend to, when navigating in a crowd.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 19:01:43 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 18:13:55 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Vemula", "Anirudh", ""], ["Muelling", "Katharina", ""], ["Oh", "Jean", ""]]}, {"id": "1710.04725", "submitter": "Jan N. Van Rijn PhD", "authors": "J. N. van Rijn and F. Hutter", "title": "Hyperparameter Importance Across Datasets", "comments": "\\c{opyright} 2018. Copyright is held by the owner/author(s).\n  Publication rights licensed to ACM. This is the author's version of the work.\n  It is posted here for your personal use, not for redistribution. The\n  definitive Version of Record was published in Proceedings of the 24th ACM\n  SIGKDD International Conference on Knowledge Discovery & Data Mining", "journal-ref": null, "doi": "10.1145/3219819.3220058", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of automated machine learning, automated hyperparameter\noptimization methods are by now routinely used in data mining. However, this\nprogress is not yet matched by equal progress on automatic analyses that yield\ninformation beyond performance-optimizing hyperparameter settings. In this\nwork, we aim to answer the following two questions: Given an algorithm, what\nare generally its most important hyperparameters, and what are typically good\nvalues for these? We present methodology and a framework to answer these\nquestions based on meta-learning across many datasets. We apply this\nmethodology using the experimental meta-data available on OpenML to determine\nthe most important hyperparameters of support vector machines, random forests\nand Adaboost, and to infer priors for all their hyperparameters. The results,\nobtained fully automatically, provide a quantitative basis to focus efforts in\nboth manual algorithm design and in automated hyperparameter optimization. The\nconducted experiments confirm that the hyperparameters selected by the proposed\nmethod are indeed the most important ones and that the obtained priors also\nlead to statistically significant improvements in hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 21:27:38 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:43:53 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["van Rijn", "J. N.", ""], ["Hutter", "F.", ""]]}, {"id": "1710.04735", "submitter": "Dhruv Choudhary", "authors": "Dhruv Choudhary, Arun Kejariwal, Francois Orsini", "title": "On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for\n  Real-Time Streaming Data", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever growing volume and velocity of data coupled with decreasing attention\nspan of end users underscore the critical need for real-time analytics. In this\nregard, anomaly detection plays a key role as an application as well as a means\nto verify data fidelity. Although the subject of anomaly detection has been\nresearched for over 100 years in a multitude of disciplines such as, but not\nlimited to, astronomy, statistics, manufacturing, econometrics, marketing, most\nof the existing techniques cannot be used as is on real-time data streams.\nFurther, the lack of characterization of performance -- both with respect to\nreal-timeliness and accuracy -- on production data sets makes model selection\nvery challenging. To this end, we present an in-depth analysis, geared towards\nreal-time streaming data, of anomaly detection techniques. Given the\nrequirements with respect to real-timeliness and accuracy, the analysis\npresented in this paper should serve as a guide for selection of the \"best\"\nanomaly detection technique. To the best of our knowledge, this is the first\ncharacterization of anomaly detection techniques proposed in very diverse set\nof fields, using production data sets corresponding to a wide set of\napplication domains.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 21:57:55 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Choudhary", "Dhruv", ""], ["Kejariwal", "Arun", ""], ["Orsini", "Francois", ""]]}, {"id": "1710.04759", "submitter": "David Krueger", "authors": "David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre\n  Lacoste, Aaron Courville", "title": "Bayesian Hypernetworks", "comments": "David Krueger and Chin-Wei Huang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Bayesian hypernetworks: a framework for approximate Bayesian\ninference in neural networks. A Bayesian hypernetwork $\\h$ is a neural network\nwhich learns to transform a simple noise distribution, $p(\\vec\\epsilon) =\n\\N(\\vec 0,\\mat I)$, to a distribution $q(\\pp) := q(h(\\vec\\epsilon))$ over the\nparameters $\\pp$ of another neural network (the \"primary network\")\\@. We train\n$q$ with variational inference, using an invertible $\\h$ to enable efficient\nestimation of the variational lower bound on the posterior $p(\\pp | \\D)$ via\nsampling. In contrast to most methods for Bayesian deep learning, Bayesian\nhypernets can represent a complex multimodal approximate posterior with\ncorrelations between parameters, while enabling cheap iid sampling of~$q(\\pp)$.\nIn practice, Bayesian hypernets can provide a better defense against\nadversarial examples than dropout, and also exhibit competitive performance on\na suite of tasks which evaluate model uncertainty, including regularization,\nactive learning, and anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 00:27:57 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 20:36:16 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Krueger", "David", ""], ["Huang", "Chin-Wei", ""], ["Islam", "Riashat", ""], ["Turner", "Ryan", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1710.04792", "submitter": "Shihua Zhang", "authors": "Wenwen Min, Juan Liu and Shihua Zhang", "title": "Sparse Weighted Canonical Correlation Analysis", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two data matrices $X$ and $Y$, sparse canonical correlation analysis\n(SCCA) is to seek two sparse canonical vectors $u$ and $v$ to maximize the\ncorrelation between $Xu$ and $Yv$. However, classical and sparse CCA models\nconsider the contribution of all the samples of data matrices and thus cannot\nidentify an underlying specific subset of samples. To this end, we propose a\nnovel sparse weighted canonical correlation analysis (SWCCA), where weights are\nused for regularizing different samples. We solve the $L_0$-regularized SWCCA\n($L_0$-SWCCA) using an alternating iterative algorithm. We apply $L_0$-SWCCA to\nsynthetic data and real-world data to demonstrate its effectiveness and\nsuperiority compared to related methods. Lastly, we consider also SWCCA with\ndifferent penalties like LASSO (Least absolute shrinkage and selection\noperator) and Group LASSO, and extend it for integrating more than three data\nmatrices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 03:42:39 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Min", "Wenwen", ""], ["Liu", "Juan", ""], ["Zhang", "Shihua", ""]]}, {"id": "1710.04806", "submitter": "Oscar Li", "authors": "Oscar Li, Hao Liu, Chaofan Chen, and Cynthia Rudin", "title": "Deep Learning for Case-Based Reasoning through Prototypes: A Neural\n  Network that Explains Its Predictions", "comments": "The first two authors contributed equally, 8 pages, accepted in AAAI\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used for classification. These deep models\noften suffer from a lack of interpretability -- they are particularly difficult\nto understand because of their non-linear nature. As a result, neural networks\nare often treated as \"black box\" models, and in the past, have been trained\npurely to optimize the accuracy of predictions. In this work, we create a novel\nnetwork architecture for deep learning that naturally explains its own\nreasoning for each prediction. This architecture contains an autoencoder and a\nspecial prototype layer, where each unit of that layer stores a weight vector\nthat resembles an encoded training input. The encoder of the autoencoder allows\nus to do comparisons within the latent space, while the decoder allows us to\nvisualize the learned prototypes. The training objective has four terms: an\naccuracy term, a term that encourages every prototype to be similar to at least\none encoded input, a term that encourages every encoded input to be close to at\nleast one prototype, and a term that encourages faithful reconstruction by the\nautoencoder. The distances computed in the prototype layer are used as part of\nthe classification process. Since the prototypes are learned during training,\nthe learned network naturally comes with explanations for each prediction, and\nthe explanations are loyal to what the network actually computes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 05:12:03 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 06:43:01 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Li", "Oscar", ""], ["Liu", "Hao", ""], ["Chen", "Chaofan", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1710.04809", "submitter": "Siqi Nie", "authors": "Siqi Nie, Meng Zheng, Qiang Ji", "title": "Deep Regression Bayesian Network and Its Applications", "comments": "Accepted to IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep directed generative models have attracted much attention recently due to\ntheir generative modeling nature and powerful data representation ability. In\nthis paper, we review different structures of deep directed generative models\nand the learning and inference algorithms associated with the structures. We\nfocus on a specific structure that consists of layers of Bayesian Networks due\nto the property of capturing inherent and rich dependencies among latent\nvariables. The major difficulty of learning and inference with deep directed\nmodels with many latent variables is the intractable inference due to the\ndependencies among the latent variables and the exponential number of latent\nvariable configurations. Current solutions use variational methods often\nthrough an auxiliary network to approximate the posterior probability\ninference. In contrast, inference can also be performed directly without using\nany auxiliary network to maximally preserve the dependencies among the latent\nvariables. Specifically, by exploiting the sparse representation with the\nlatent space, max-max instead of max-sum operation can be used to overcome the\nexponential number of latent configurations. Furthermore, the max-max operation\nand augmented coordinate ascent are applied to both supervised and unsupervised\nlearning as well as to various inference. Quantitative evaluations on benchmark\ndatasets of different models are given for both data representation and feature\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 05:25:56 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Nie", "Siqi", ""], ["Zheng", "Meng", ""], ["Ji", "Qiang", ""]]}, {"id": "1710.04837", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Tao Xiang, Yu-Gang Jiang, Xiangyang Xue, Leonid Sigal, and\n  Shaogang Gong", "title": "Recent Advances in Zero-shot Recognition", "comments": "accepted by IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent renaissance of deep convolution neural networks, encouraging\nbreakthroughs have been achieved on the supervised recognition tasks, where\neach class has sufficient training data and fully annotated training data.\nHowever, to scale the recognition to a large number of classes with few or now\ntraining samples for each class remains an unsolved problem. One approach to\nscaling up the recognition is to develop models capable of recognizing unseen\ncategories without any training instances, or zero-shot recognition/ learning.\nThis article provides a comprehensive review of existing zero-shot recognition\ntechniques covering various aspects ranging from representations of models, and\nfrom datasets and evaluation settings. We also overview related recognition\ntasks including one-shot and open set recognition which can be used as natural\nextensions of zero-shot recognition when limited number of class samples become\navailable or when zero-shot recognition is implemented in a real-world setting.\nImportantly, we highlight the limitations of existing approaches and point out\nfuture research directions in this existing new research area.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 08:29:29 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Fu", "Yanwei", ""], ["Xiang", "Tao", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""], ["Sigal", "Leonid", ""], ["Gong", "Shaogang", ""]]}, {"id": "1710.04843", "submitter": "Biju Issac", "authors": "Syed Ali Raza Shah and Biju Issac", "title": "Performance Comparison of Intrusion Detection Systems and Application of\n  Machine Learning to Snort System", "comments": "25 pages", "journal-ref": "S.A.R. Shah, B. Issac, (2018). Performance Comparison of Intrusion\n  Detection Systems and Application of Machine Learning to Snort System, Future\n  Generation Computer Systems, Elsevier, ISSN 0167-739X, Vol. 80, 157-170", "doi": "10.1016/j.future.2017.10.016", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study investigates the performance of two open source intrusion\ndetection systems (IDSs) namely Snort and Suricata for accurately detecting the\nmalicious traffic on computer networks. Snort and Suricata were installed on\ntwo different but identical computers and the performance was evaluated at 10\nGbps network speed. It was noted that Suricata could process a higher speed of\nnetwork traffic than Snort with lower packet drop rate but it consumed higher\ncomputational resources. Snort had higher detection accuracy and was thus\nselected for further experiments. It was observed that the Snort triggered a\nhigh rate of false positive alarms. To solve this problem a Snort adaptive\nplug-in was developed. To select the best performing algorithm for Snort\nadaptive plug-in, an empirical study was carried out with different learning\nalgorithms and Support Vector Machine (SVM) was selected. A hybrid version of\nSVM and Fuzzy logic produced a better detection accuracy. But the best result\nwas achieved using an optimised SVM with firefly algorithm with FPR (false\npositive rate) as 8.6% and FNR (false negative rate) as 2.2%, which is a good\nresult. The novelty of this work is the performance comparison of two IDSs at\n10 Gbps and the application of hybrid and optimised machine learning algorithms\nto Snort.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 08:49:10 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 09:54:03 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Shah", "Syed Ali Raza", ""], ["Issac", "Biju", ""]]}, {"id": "1710.04872", "submitter": "Abhishake Rastogi", "authors": "Abhishake Rastogi and Sivananthan Sampath", "title": "Manifold regularization based on Nystr{\\\"o}m type subsampling", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2018.12.002", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Nystr{\\\"o}m type subsampling for large scale\nkernel methods to reduce the computational complexities of big data. We discuss\nthe multi-penalty regularization scheme based on Nystr{\\\"o}m type subsampling\nwhich is motivated from well-studied manifold regularization schemes. We\ndevelop a theoretical analysis of multi-penalty least-square regularization\nscheme under the general source condition in vector-valued function setting,\ntherefore the results can also be applied to multi-task learning problems. We\nachieve the optimal minimax convergence rates of multi-penalty regularization\nusing the concept of effective dimension for the appropriate subsampling size.\nWe discuss an aggregation approach based on linear function strategy to combine\nvarious Nystr{\\\"o}m approximants. Finally, we demonstrate the performance of\nmulti-penalty regularization based on Nystr{\\\"o}m type subsampling on\nCaltech-101 data set for multi-class image classification and NSL-KDD benchmark\ndata set for intrusion detection problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:13:38 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Rastogi", "Abhishake", ""], ["Sampath", "Sivananthan", ""]]}, {"id": "1710.04874", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "A Method of Generating Random Weights and Biases in Feedforward Neural\n  Networks with Random Hidden Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with random hidden nodes have gained increasing interest from\nresearchers and practical applications. This is due to their unique features\nsuch as very fast training and universal approximation property. In these\nnetworks the weights and biases of hidden nodes determining the nonlinear\nfeature mapping are set randomly and are not learned. Appropriate selection of\nthe intervals from which weights and biases are selected is extremely\nimportant. This topic has not yet been sufficiently explored in the literature.\nIn this work a method of generating random weights and biases is proposed. This\nmethod generates the parameters of the hidden nodes in such a way that\nnonlinear fragments of the activation functions are located in the input space\nregions with data and can be used to construct the surface approximating a\nnonlinear target function. The weights and biases are dependent on the input\ndata range and activation function type. The proposed methods allows us to\ncontrol the generalization degree of the model. These all lead to improvement\nin approximation performance of the network. Several experiments show very\npromising results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:23:18 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1710.04881", "submitter": "Pedram Daee", "authors": "Pedram Daee, Tomi Peltola, Aki Vehtari, Samuel Kaski", "title": "User Modelling for Avoiding Overfitting in Interactive Knowledge\n  Elicitation for Prediction", "comments": "9 pages, 2 figures. The paper is published in the proceedings of IUI\n  2018. Codes and data available at\n  https://github.com/HIIT/human-overfitting-in-IML", "journal-ref": null, "doi": "10.1145/3172944.3172989", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human-in-the-loop machine learning, the user provides information beyond\nthat in the training data. Many algorithms and user interfaces have been\ndesigned to optimize and facilitate this human--machine interaction; however,\nfewer studies have addressed the potential defects the designs can cause.\nEffective interaction often requires exposing the user to the training data or\nits statistics. The design of the system is then critical, as this can lead to\ndouble use of data and overfitting, if the user reinforces noisy patterns in\nthe data. We propose a user modelling methodology, by assuming simple rational\nbehaviour, to correct the problem. We show, in a user study with 48\nparticipants, that the method improves predictive performance in a sparse\nlinear regression sentiment analysis task, where graded user knowledge on\nfeature relevance is elicited. We believe that the key idea of inferring user\nknowledge with probabilistic user models has general applicability in guarding\nagainst overfitting and improving interactive machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:52:19 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 02:06:27 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Daee", "Pedram", ""], ["Peltola", "Tomi", ""], ["Vehtari", "Aki", ""], ["Kaski", "Samuel", ""]]}, {"id": "1710.04908", "submitter": "Meihao Chen", "authors": "Meihao Chen, Zhuoru Lin, Kyunghyun Cho", "title": "Graph Convolutional Networks for Classification with a Structured Label\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a usual practice to ignore any structural information underlying\nclasses in multi-class classification. In this paper, we propose a graph\nconvolutional network (GCN) augmented neural network classifier to exploit a\nknown, underlying graph structure of labels. The proposed approach resembles an\n(approximate) inference procedure in, for instance, a conditional random field\n(CRF). We evaluate the proposed approach on document classification and object\nrecognition and report both accuracies and graph-theoretic metrics that\ncorrespond to the consistency of the model's prediction. The experiment results\nreveal that the proposed model outperforms a baseline method which ignores the\ngraph structures of a label space in terms of graph-theoretic metrics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 02:39:18 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 07:21:29 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Chen", "Meihao", ""], ["Lin", "Zhuoru", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1710.04924", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama and Hajime Shimao", "title": "Two-stage Algorithm for Fairness-aware Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic decision making process now affects many aspects of our lives.\nStandard tools for machine learning, such as classification and regression, are\nsubject to the bias in data, and thus direct application of such off-the-shelf\ntools could lead to a specific group being unfairly discriminated. Removing\nsensitive attributes of data does not solve this problem because a\n\\textit{disparate impact} can arise when non-sensitive attributes and sensitive\nattributes are correlated. Here, we study a fair machine learning algorithm\nthat avoids such a disparate impact when making a decision. Inspired by the\ntwo-stage least squares method that is widely used in the field of economics,\nwe propose a two-stage algorithm that removes bias in the training data. The\nproposed algorithm is conceptually simple. Unlike most of existing fair\nalgorithms that are designed for classification tasks, the proposed method is\nable to (i) deal with regression tasks, (ii) combine explanatory attributes to\nremove reverse discrimination, and (iii) deal with numerical sensitive\nattributes. The performance and fairness of the proposed algorithm are\nevaluated in simulations with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 13:58:42 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Komiyama", "Junpei", ""], ["Shimao", "Hajime", ""]]}, {"id": "1710.04975", "submitter": "Fethiye Irmak Do\\u{g}an", "authors": "Fethiye Irmak Do\\u{g}an, Hande \\c{C}elikkanat, and Sinan Kalkan", "title": "A Deep Incremental Boltzmann Machine for Modeling Context in Robots", "comments": "6 pages, 5 figures, International Conference on Robotics and\n  Automation (ICRA 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Context is an essential capability for robots that are to be as adaptive as\npossible in challenging environments. Although there are many context modeling\nefforts, they assume a fixed structure and number of contexts. In this paper,\nwe propose an incremental deep model that extends Restricted Boltzmann\nMachines. Our model gets one scene at a time, and gradually extends the\ncontextual model when necessary, either by adding a new context or a new\ncontext layer to form a hierarchy. We show on a scene classification benchmark\nthat our method converges to a good estimate of the contexts of the scenes, and\nperforms better or on-par on several tasks compared to other incremental models\nor non-incremental models.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 15:49:28 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 13:56:19 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 16:32:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Do\u011fan", "Fethiye Irmak", ""], ["\u00c7elikkanat", "Hande", ""], ["Kalkan", "Sinan", ""]]}, {"id": "1710.04981", "submitter": "Fethiye Irmak Do\\u{g}an", "authors": "Fethiye Irmak Do\\u{g}an, \\.Ilker Bozcan, Mehmet \\c{C}elik, Sinan\n  Kalkan", "title": "CINet: A Learning Based Approach to Incremental Context Modeling in\n  Robots", "comments": "The first two authors have contributed equally, 6 pages, 8 figures,\n  International Conference on Intelligent Robots (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There have been several attempts at modeling context in robots. However,\neither these attempts assume a fixed number of contexts or use a rule-based\napproach to determine when to increment the number of contexts. In this paper,\nwe pose the task of when to increment as a learning problem, which we solve\nusing a Recurrent Neural Network. We show that the network successfully (with\n98\\% testing accuracy) learns to predict when to increment, and demonstrate, in\na scene modeling problem (where the correct number of contexts is not known),\nthat the robot increments the number of contexts in an expected manner (i.e.,\nthe entropy of the system is reduced). We also present how the incremental\nmodel can be used for various scene reasoning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 16:06:18 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 17:44:16 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2018 15:59:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Do\u011fan", "Fethiye Irmak", ""], ["Bozcan", "\u0130lker", ""], ["\u00c7elik", "Mehmet", ""], ["Kalkan", "Sinan", ""]]}, {"id": "1710.05012", "submitter": "Sreeram Kannan", "authors": "Arman Rahimzamani and Sreeram Kannan", "title": "Potential Conditional Mutual Information: Estimators, Properties and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional mutual information I(X;Y|Z) measures the average information\nthat X and Y contain about each other given Z. This is an important primitive\nin many learning problems including conditional independence testing, graphical\nmodel inference, causal strength estimation and time-series problems. In\nseveral applications, it is desirable to have a functional purely of the\nconditional distribution p_{Y|X,Z} rather than of the joint distribution\np_{X,Y,Z}. We define the potential conditional mutual information as the\nconditional mutual information calculated with a modified joint distribution\np_{Y|X,Z} q_{X,Z}, where q_{X,Z} is a potential distribution, fixed airport. We\ndevelop K nearest neighbor based estimators for this functional, employing\nimportance sampling, and a coupling trick, and prove the finite k consistency\nof such an estimator. We demonstrate that the estimator has excellent practical\nperformance and show an application in dynamical system inference.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 17:26:18 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Rahimzamani", "Arman", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1710.05053", "submitter": "Trevor Campbell", "authors": "Trevor Campbell, Tamara Broderick", "title": "Automated Scalable Bayesian Inference via Hilbert Coresets", "comments": null, "journal-ref": "Journal of Machine Learning Research 20(15):1-38, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of posterior inference in Bayesian data analysis has enabled\nexperts and nonexperts alike to use more sophisticated models, engage in faster\nexploratory modeling and analysis, and ensure experimental reproducibility.\nHowever, standard automated posterior inference algorithms are not tractable at\nthe scale of massive modern datasets, and modifications to make them so are\ntypically model-specific, require expert tuning, and can break theoretical\nguarantees on inferential quality. Building on the Bayesian coresets framework,\nthis work instead takes advantage of data redundancy to shrink the dataset\nitself as a preprocessing step, providing fully-automated, scalable Bayesian\ninference with theoretical guarantees. We begin with an intuitive reformulation\nof Bayesian coreset construction as sparse vector sum approximation, and\ndemonstrate that its automation and performance-based shortcomings arise from\nthe use of the supremum norm. To address these shortcomings we develop Hilbert\ncoresets, i.e., Bayesian coresets constructed under a norm induced by an\ninner-product on the log-likelihood function space. We propose two Hilbert\ncoreset construction algorithms---one based on importance sampling, and one\nbased on the Frank-Wolfe algorithm---along with theoretical guarantees on\napproximation quality as a function of coreset size. Since the exact\ncomputation of the proposed inner-products is model-specific, we automate the\nconstruction with a random finite-dimensional projection of the log-likelihood\nfunctions. The resulting automated coreset construction algorithm is simple to\nimplement, and experiments on a variety of models with real and synthetic\ndatasets show that it provides high-quality posterior approximations and a\nsignificant reduction in the computational cost of inference.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 19:13:40 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 08:59:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Campbell", "Trevor", ""], ["Broderick", "Tamara", ""]]}, {"id": "1710.05086", "submitter": "Romain Lopez", "authors": "Romain Lopez, Jeffrey Regier, Michael Cole, Michael Jordan and Nir\n  Yosef", "title": "A deep generative model for single-cell RNA sequencing with application\n  to detecting differentially expressed genes", "comments": "Updated a previous submission instead. See arXiv:1709.02082", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for interpreting gene expression levels that\nare observed through single-cell RNA sequencing. In the model, each cell has a\nlow-dimensional latent representation. Additional latent variables account for\ntechnical effects that may erroneously set some observations of gene expression\nlevels to zero. Conditional distributions are specified by neural networks,\ngiving the proposed model enough flexibility to fit the data well. We use\nvariational inference and stochastic optimization to approximate the posterior\ndistribution. The inference procedure scales to over one million cells, whereas\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\nproposed procedure outperforms state-of-the-art methods like ZIFA and\nZINB-WaVE. We also extend our framework to take into account batch effects and\nother confounding factors and propose a natural Bayesian hypothesis framework\nfor differential expression that outperforms tradition DESeq2.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 21:47:48 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 01:42:35 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Lopez", "Romain", ""], ["Regier", "Jeffrey", ""], ["Cole", "Michael", ""], ["Jordan", "Michael", ""], ["Yosef", "Nir", ""]]}, {"id": "1710.05090", "submitter": "Alex Kuefler", "authors": "Alex Kuefler, Mykel J. Kochenderfer", "title": "Burn-In Demonstrations for Multi-Modal Imitation Learning", "comments": "1st Conference on Robotic Learning, Non-archival Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on imitation learning has generated policies that reproduce\nexpert behavior from multi-modal data. However, past approaches have focused\nonly on recreating a small number of distinct, expert maneuvers, or have relied\non supervised learning techniques that produce unstable policies. This work\nextends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce\nbehavior over an extended period of time. Our approach involves reformulating\nthe typical imitation learning setting to include \"burn-in demonstrations\" upon\nwhich policies are conditioned at test time. We demonstrate that our approach\noutperforms standard InfoGAIL in maximizing the mutual information between\npredicted and unseen style labels in road scene simulations, and we show that\nour method leads to policies that imitate expert autonomous driving systems\nover long time horizons.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:29:51 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Kuefler", "Alex", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1710.05091", "submitter": "Gourab Mitra", "authors": "Gourab Mitra, Shashidhar Sundareisan and Bikash Kanti Sarkar", "title": "A simple data discretizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data discretization is an important step in the process of machine learning,\nsince it is easier for classifiers to deal with discrete attributes rather than\ncontinuous attributes. Over the years, several methods of performing\ndiscretization such as Boolean Reasoning, Equal Frequency Binning, Entropy have\nbeen proposed, explored, and implemented. In this article, a simple supervised\ndiscretization approach is introduced. The prime goal of MIL is to maximize\nclassification accuracy of classifier, minimizing loss of information while\ndiscretization of continuous attributes. The performance of the suggested\napproach is compared with the supervised discretization algorithm Minimum\nInformation Loss (MIL), using the state-of-the-art rule inductive algorithms-\nJ48 (Java implementation of C4.5 classifier). The presented approach is,\nindeed, the modified version of MIL. The empirical results show that the\nmodified approach performs better in several cases in comparison to the\noriginal MIL algorithm and Minimum Description Length Principle (MDLP) .\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:45:11 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Mitra", "Gourab", ""], ["Sundareisan", "Shashidhar", ""], ["Sarkar", "Bikash Kanti", ""]]}, {"id": "1710.05092", "submitter": "Jacopo Cavazza", "authors": "Jacopo Cavazza, Pietro Morerio, Benjamin Haeffele, Connor Lane,\n  Vittorio Murino, Rene Vidal", "title": "Dropout as a Low-Rank Regularizer for Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization for matrix factorization (MF) and approximation problems has\nbeen carried out in many different ways. Due to its popularity in deep\nlearning, dropout has been applied also for this class of problems. Despite its\nsolid empirical performance, the theoretical properties of dropout as a\nregularizer remain quite elusive for this class of problems. In this paper, we\npresent a theoretical analysis of dropout for MF, where Bernoulli random\nvariables are used to drop columns of the factors. We demonstrate the\nequivalence between dropout and a fully deterministic model for MF in which the\nfactors are regularized by the sum of the product of squared Euclidean norms of\nthe columns. Additionally, we inspect the case of a variable sized\nfactorization and we prove that dropout achieves the global minimum of a convex\napproximation problem with (squared) nuclear norm regularization. As a result,\nwe conclude that dropout can be used as a low-rank regularizer with data\ndependent singular-value thresholding.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:47:19 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Cavazza", "Jacopo", ""], ["Morerio", "Pietro", ""], ["Haeffele", "Benjamin", ""], ["Lane", "Connor", ""], ["Murino", "Vittorio", ""], ["Vidal", "Rene", ""]]}, {"id": "1710.05106", "submitter": "Yuxin Peng", "authors": "Yuxin Peng, Jinwei Qi and Yuxin Yuan", "title": "CM-GANs: Cross-modal Generative Adversarial Networks for Common\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the inconsistent distribution and representation of\ndifferent modalities, such as image and text, cause the heterogeneity gap that\nmakes it challenging to correlate such heterogeneous data. Generative\nadversarial networks (GANs) have shown its strong ability of modeling data\ndistribution and learning discriminative representation, existing GANs-based\nworks mainly focus on generative problem to generate new data. We have\ndifferent goal, aim to correlate heterogeneous data, by utilizing the power of\nGANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs\nto learn discriminative common representation for bridging heterogeneity gap.\nThe main contributions are: (1) Cross-modal GANs architecture is proposed to\nmodel joint distribution over data of different modalities. The inter-modality\nand intra-modality correlation can be explored simultaneously in generative and\ndiscriminative models. Both of them beat each other to promote cross-modal\ncorrelation learning. (2) Cross-modal convolutional autoencoders with\nweight-sharing constraint are proposed to form generative model. They can not\nonly exploit cross-modal correlation for learning common representation, but\nalso preserve reconstruction information for capturing semantic consistency\nwithin each modality. (3) Cross-modal adversarial mechanism is proposed, which\nutilizes two kinds of discriminative models to simultaneously conduct\nintra-modality and inter-modality discrimination. They can mutually boost to\nmake common representation more discriminative by adversarial training process.\nTo the best of our knowledge, our proposed CM-GANs approach is the first to\nutilize GANs to perform cross-modal common representation learning. Experiments\nare conducted to verify the performance of our proposed approach on cross-modal\nretrieval paradigm, compared with 10 methods on 3 cross-modal datasets.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 00:15:56 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 16:38:56 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Peng", "Yuxin", ""], ["Qi", "Jinwei", ""], ["Yuan", "Yuxin", ""]]}, {"id": "1710.05110", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth", "title": "Subsampling for Ridge Regression via Regularized Volume Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ vectors $\\mathbf{x}_i\\in \\mathbb{R}^d$, we want to fit a linear\nregression model for noisy labels $y_i\\in\\mathbb{R}$. The ridge estimator is a\nclassical solution to this problem. However, when labels are expensive, we are\nforced to select only a small subset of vectors $\\mathbf{x}_i$ for which we\nobtain the labels $y_i$. We propose a new procedure for selecting the subset of\nvectors, such that the ridge estimator obtained from that subset offers strong\nstatistical guarantees in terms of the mean squared prediction error over the\nentire dataset of $n$ labeled vectors. The number of labels needed is\nproportional to the statistical dimension of the problem which is often much\nsmaller than $d$. Our method is an extension of a joint subsampling procedure\ncalled volume sampling. A second major contribution is that we speed up volume\nsampling so that it is essentially as efficient as leverage scores, which is\nthe main i.i.d. subsampling procedure for this task. Finally, we show\ntheoretically and experimentally that volume sampling has a clear advantage\nover any i.i.d. sampling when labels are expensive.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 00:37:59 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 18:23:52 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1710.05128", "submitter": "Hongyu Guo", "authors": "Martin Renqiang Min and Hongyu Guo and Dinghan Shen", "title": "Parametric t-Distributed Stochastic Exemplar-centered Embedding", "comments": "fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric embedding methods such as parametric t-SNE (pt-SNE) have been\nwidely adopted for data visualization and out-of-sample data embedding without\nfurther computationally expensive optimization or approximation. However, the\nperformance of pt-SNE is highly sensitive to the hyper-parameter batch size due\nto conflicting optimization goals, and often produces dramatically different\nembeddings with different choices of user-defined perplexities. To effectively\nsolve these issues, we present parametric t-distributed stochastic\nexemplar-centered embedding methods. Our strategy learns embedding parameters\nby comparing given data only with precomputed exemplars, resulting in a cost\nfunction with linear computational and memory complexity, which is further\nreduced by noise contrastive samples. Moreover, we propose a shallow embedding\nnetwork with high-order feature interactions for data visualization, which is\nmuch easier to tune but produces comparable performance in contrast to a deep\nneural network employed by pt-SNE. We empirically demonstrate, using several\nbenchmark datasets, that our proposed methods significantly outperform pt-SNE\nin terms of robustness, visual effects, and quantitative evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 03:19:27 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 15:14:53 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 19:23:42 GMT"}, {"version": "v4", "created": "Thu, 8 Mar 2018 19:20:50 GMT"}, {"version": "v5", "created": "Fri, 20 Apr 2018 19:29:27 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Min", "Martin Renqiang", ""], ["Guo", "Hongyu", ""], ["Shen", "Dinghan", ""]]}, {"id": "1710.05135", "submitter": "Lin Wu", "authors": "Tong Chen, Lin Wu, Yang Wang, Jun Zhang, Hongxu Chen, Xue Li", "title": "When Point Process Meets RNNs: Predicting Fine-Grained User Interests\n  with Mutual Behavioral Infectivity", "comments": "Several existing references are missing and not discussed explicitly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting fine-grained interests of users with temporal behavior is\nimportant to personalization and information filtering applications. However,\nexisting interest prediction methods are incapable of capturing the subtle\ndegreed user interests towards particular items, and the internal time-varying\ndrifting attention of individuals is not studied yet. Moreover, the prediction\nprocess can also be affected by inter-personal influence, known as behavioral\nmutual infectivity. Inspired by point process in modeling temporal point\nprocess, in this paper we present a deep prediction method based on two\nrecurrent neural networks (RNNs) to jointly model each user's continuous\nbrowsing history and asynchronous event sequences in the context of inter-user\nbehavioral mutual infectivity. Our model is able to predict the fine-grained\ninterest from a user regarding a particular item and corresponding timestamps\nwhen an occurrence of event takes place. The proposed approach is more flexible\nto capture the dynamic characteristic of event sequences by using the temporal\npoint process to model event data and timely update its intensity function by\nRNNs. Furthermore, to improve the interpretability of the model, the attention\nmechanism is introduced to emphasize both intra-personal and inter-personal\nbehavior influence over time. Experiments on real datasets demonstrate that our\nmodel outperforms the state-of-the-art methods in fine-grained user interest\nprediction.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 05:37:55 GMT"}, {"version": "v2", "created": "Sun, 22 Oct 2017 00:12:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chen", "Tong", ""], ["Wu", "Lin", ""], ["Wang", "Yang", ""], ["Zhang", "Jun", ""], ["Chen", "Hongxu", ""], ["Li", "Xue", ""]]}, {"id": "1710.05179", "submitter": "Hyeonwoo Noh", "authors": "Hyeonwoo Noh, Tackgeun You, Jonghwan Mun, Bohyung Han", "title": "Regularizing Deep Neural Networks by Noise: Its Interpretation and\n  Optimization", "comments": "NIPS 2017 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting is one of the most critical challenges in deep neural networks,\nand there are various types of regularization methods to improve generalization\nperformance. Injecting noises to hidden units during training, e.g., dropout,\nis known as a successful regularizer, but it is still not clear enough why such\ntraining techniques work well in practice and how we can maximize their benefit\nin the presence of two conflicting objectives---optimizing to true data\ndistribution and preventing overfitting by regularization. This paper addresses\nthe above issues by 1) interpreting that the conventional training methods with\nregularization by noise injection optimize the lower bound of the true\nobjective and 2) proposing a technique to achieve a tighter lower bound using\nmultiple noise samples per training example in a stochastic gradient descent\niteration. We demonstrate the effectiveness of our idea in several computer\nvision applications.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 13:10:59 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 13:50:43 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Noh", "Hyeonwoo", ""], ["You", "Tackgeun", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1710.05199", "submitter": "Mohammad Mehdi Keikha", "authors": "Mohammad Mehdi Keikha, Maseud Rahgozar, Masoud Asadpour", "title": "Community Aware Random Walk for Network Embedding", "comments": "17 pages, 3 figures, 4 Tables", "journal-ref": "Knowledge-Based Systems Volume 148, 15 May 2018, Pages 47-54", "doi": "10.1016/j.knosys.2018.02.028", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network analysis provides meaningful information about behavior of\nnetwork members that can be used for diverse applications such as\nclassification, link prediction. However, network analysis is computationally\nexpensive because of feature learning for different applications. In recent\nyears, many researches have focused on feature learning methods in social\nnetworks. Network embedding represents the network in a lower dimensional\nrepresentation space with the same properties which presents a compressed\nrepresentation of the network. In this paper, we introduce a novel algorithm\nnamed \"CARE\" for network embedding that can be used for different types of\nnetworks including weighted, directed and complex. Current methods try to\npreserve local neighborhood information of nodes, whereas the proposed method\nutilizes local neighborhood and community information of network nodes to cover\nboth local and global structure of social networks. CARE builds customized\npaths, which are consisted of local and global structure of network nodes, as a\nbasis for network embedding and uses the Skip-gram model to learn\nrepresentation vector of nodes. Subsequently, stochastic gradient descent is\napplied to optimize our objective function and learn the final representation\nof nodes. Our method can be scalable when new nodes are appended to network\nwithout information loss. Parallelize generation of customized random walks is\nalso used for speeding up CARE. We evaluate the performance of CARE on multi\nlabel classification and link prediction tasks. Experimental results on various\nnetworks indicate that the proposed method outperforms others in both Micro and\nMacro-f1 measures for different size of training data.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 15:37:07 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 15:57:36 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Keikha", "Mohammad Mehdi", ""], ["Rahgozar", "Maseud", ""], ["Asadpour", "Masoud", ""]]}, {"id": "1710.05209", "submitter": "Abbas Mehrabian", "authors": "Hassan Ashtiani and Shai Ben-David and Nick Harvey and Christopher\n  Liaw and Abbas Mehrabian and Yaniv Plan", "title": "Near-optimal Sample Complexity Bounds for Robust Learning of Gaussians\n  Mixtures via Compression Schemes", "comments": "To appear in Journal of the ACM. 46 pages. An extended abstract\n  appeared in NeurIPS 2018. This version contains all the proofs, generalizes\n  the results to agnostic learning, and improves the bounds by logarithmic\n  factors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that $\\tilde{\\Theta}(k d^2 / \\varepsilon^2)$ samples are necessary\nand sufficient for learning a mixture of $k$ Gaussians in $\\mathbb{R}^d$, up to\nerror $\\varepsilon$ in total variation distance. This improves both the known\nupper bounds and lower bounds for this problem. For mixtures of axis-aligned\nGaussians, we show that $\\tilde{O}(k d / \\varepsilon^2)$ samples suffice,\nmatching a known lower bound. Moreover, these results hold in the\nagnostic-learning/robust-estimation setting as well, where the target\ndistribution is only approximately a mixture of Gaussians.\n  The upper bound is shown using a novel technique for distribution learning\nbased on a notion of `compression.' Any class of distributions that allows such\na compression scheme can also be learned with few samples. Moreover, if a class\nof distributions has such a compression scheme, then so do the classes of\nproducts and mixtures of those distributions. The core of our main result is\nshowing that the class of Gaussians in $\\mathbb{R}^d$ admits a small-sized\ncompression scheme.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 16:39:24 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 18:40:00 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 07:59:54 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 16:25:31 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 19:48:26 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Ashtiani", "Hassan", ""], ["Ben-David", "Shai", ""], ["Harvey", "Nick", ""], ["Liaw", "Christopher", ""], ["Mehrabian", "Abbas", ""], ["Plan", "Yaniv", ""]]}, {"id": "1710.05219", "submitter": "Jian-Qiao Zhu", "authors": "Jian-Qiao Zhu, Adam N. Sanborn, Nick Chater", "title": "Mental Sampling in Multimodal Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both resources in the natural environment and concepts in a semantic space\nare distributed \"patchily\", with large gaps in between the patches. To describe\npeople's internal and external foraging behavior, various random walk models\nhave been proposed. In particular, internal foraging has been modeled as\nsampling: in order to gather relevant information for making a decision, people\ndraw samples from a mental representation using random-walk algorithms such as\nMarkov chain Monte Carlo (MCMC). However, two common empirical observations\nargue against simple sampling algorithms such as MCMC. First, the spatial\nstructure is often best described by a L\\'evy flight distribution: the\nprobability of the distance between two successive locations follows a\npower-law on the distances. Second, the temporal structure of the sampling that\nhumans and other animals produce have long-range, slowly decaying serial\ncorrelations characterized as $1/f$-like fluctuations. We propose that mental\nsampling is not done by simple MCMC, but is instead adapted to multimodal\nrepresentations and is implemented by Metropolis-coupled Markov chain Monte\nCarlo (MC$^3$), one of the first algorithms developed for sampling from\nmultimodal distributions. MC$^3$ involves running multiple Markov chains in\nparallel but with target distributions of different temperatures, and it swaps\nthe states of the chains whenever a better location is found. Heated chains\nmore readily traverse valleys in the probability landscape to propose moves to\nfar-away peaks, while the colder chains make the local steps that explore the\ncurrent peak or patch. We show that MC$^3$ generates distances between\nsuccessive samples that follow a L\\'evy flight distribution and $1/f$-like\nserial correlations, providing a single mechanistic account of these two\npuzzling empirical phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 18:17:30 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhu", "Jian-Qiao", ""], ["Sanborn", "Adam N.", ""], ["Chater", "Nick", ""]]}, {"id": "1710.05233", "submitter": "Jonathan Shafer", "authors": "Raef Bassily, Shay Moran, Ido Nachum, Jonathan Shafer, Amir Yehudayoff", "title": "Learners that Use Little Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning algorithms that are restricted to using a small amount of\ninformation from their input sample. We introduce a category of learning\nalgorithms we term $d$-bit information learners, which are algorithms whose\noutput conveys at most $d$ bits of information of their input. A central theme\nin this work is that such algorithms generalize.\n  We focus on the learning capacity of these algorithms, and prove sample\ncomplexity bounds with tight dependencies on the confidence and error\nparameters. We also observe connections with well studied notions such as\nsample compression schemes, Occam's razor, PAC-Bayes and differential privacy.\n  We discuss an approach that allows us to prove upper bounds on the amount of\ninformation that algorithms reveal about their inputs, and also provide a lower\nbound by showing a simple concept class for which every (possibly randomized)\nempirical risk minimizer must reveal a lot of information. On the other hand,\nwe show that in the distribution-dependent setting every VC class has empirical\nrisk minimizers that do not reveal a lot of information.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 20:40:46 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 10:51:35 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 03:14:32 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Bassily", "Raef", ""], ["Moran", "Shay", ""], ["Nachum", "Ido", ""], ["Shafer", "Jonathan", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1710.05241", "submitter": "Qunwei Li", "authors": "Qunwei Li, Bhavya Kailkhura, Ryan Goldhahn, Priyadip Ray, Pramod K.\n  Varshney", "title": "Robust Decentralized Learning Using ADMM with Unreliable Agents", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be formulated as consensus optimization\nproblems which can be solved efficiently via a cooperative multi-agent system.\nHowever, the agents in the system can be unreliable due to a variety of\nreasons: noise, faults and attacks. Providing erroneous updates leads the\noptimization process in a wrong direction, and degrades the performance of\ndistributed machine learning algorithms. This paper considers the problem of\ndecentralized learning using ADMM in the presence of unreliable agents. First,\nwe rigorously analyze the effect of erroneous updates (in ADMM learning\niterations) on the convergence behavior of multi-agent system. We show that the\nalgorithm linearly converges to a neighborhood of the optimal solution under\ncertain conditions and characterize the neighborhood size analytically. Next,\nwe provide guidelines for network design to achieve a faster convergence. We\nalso provide conditions on the erroneous updates for exact convergence to the\noptimal solution. Finally, to mitigate the influence of unreliable agents, we\npropose \\textsf{ROAD}, a robust variant of ADMM, and show its resilience to\nunreliable agents with an exact convergence to the optimum.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 21:44:32 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 21:08:41 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 19:10:13 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Li", "Qunwei", ""], ["Kailkhura", "Bhavya", ""], ["Goldhahn", "Ryan", ""], ["Ray", "Priyadip", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1710.05268", "submitter": "Frederik Ebert", "authors": "Frederik Ebert, Chelsea Finn, Alex X. Lee, Sergey Levine", "title": "Self-Supervised Visual Planning with Temporal Skip Connections", "comments": "accepted at the Conference on Robot Learning (CoRL) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to autonomously learn wide repertoires of complex skills, robots\nmust be able to learn from their own autonomously collected data, without human\nsupervision. One learning signal that is always available for autonomously\ncollected data is prediction: if a robot can learn to predict the future, it\ncan use this predictive model to take actions to produce desired outcomes, such\nas moving an object to a particular location. However, in complex open-world\nscenarios, designing a representation for prediction is difficult. In this\nwork, we instead aim to enable self-supervised robotic learning through direct\nvideo prediction: instead of attempting to design a good representation, we\ndirectly predict what the robot will see next, and then use this model to\nachieve desired goals. A key challenge in video prediction for robotic\nmanipulation is handling complex spatial arrangements such as occlusions. To\nthat end, we introduce a video prediction model that can keep track of objects\nthrough occlusion by incorporating temporal skip-connections. Together with a\nnovel planning criterion and action space formulation, we demonstrate that this\nmodel substantially outperforms prior work on video prediction-based control.\nOur results show manipulation of objects not seen during training, handling\nmultiple objects, and pushing objects around obstructions. These results\nrepresent a significant advance in the range and complexity of skills that can\nbe performed entirely with self-supervised robotic learning.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 02:58:20 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Ebert", "Frederik", ""], ["Finn", "Chelsea", ""], ["Lee", "Alex X.", ""], ["Levine", "Sergey", ""]]}, {"id": "1710.05270", "submitter": "Wei Ping", "authors": "Wei Ping, Qiang Liu, Alexander Ihler", "title": "Learning Infinite RBMs with Frank-Wolfe", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an infinite restricted Boltzmann machine~(RBM),\nwhose maximum likelihood estimation~(MLE) corresponds to a constrained convex\noptimization. We consider the Frank-Wolfe algorithm to solve the program, which\nprovides a sparse solution that can be interpreted as inserting a hidden unit\nat each iteration, so that the optimization process takes the form of a\nsequence of finite models of increasing complexity. As a side benefit, this can\nbe used to easily and efficiently identify an appropriate number of hidden\nunits during the optimization. The resulting model can also be used as an\ninitialization for typical state-of-the-art RBM training algorithms such as\ncontrastive divergence, leading to models with consistently higher test\nlikelihood than random initialization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 03:38:32 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ping", "Wei", ""], ["Liu", "Qiang", ""], ["Ihler", "Alexander", ""]]}, {"id": "1710.05279", "submitter": "Shenghao Shi", "authors": "Shenghao Shi", "title": "Facial Keypoints Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Detect facial keypoints is a critical element in face recognition. However,\nthere is difficulty to catch keypoints on the face due to complex influences\nfrom original images, and there is no guidance to suitable algorithms. In this\npaper, we study different algorithms that can be applied to locate keyponits.\nSpecifically: our framework (1)prepare the data for further investigation\n(2)Using PCA and LBP to process the data (3) Apply different algorithms to\nanalysis data, including linear regression models, tree based model, neural\nnetwork and convolutional neural network, etc. Finally we will give our\nconclusion and further research topic. A comprehensive set of experiments on\ndataset demonstrates the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 05:38:16 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Shi", "Shenghao", ""]]}, {"id": "1710.05285", "submitter": "Haipeng Zeng", "authors": "Haipeng Zeng, Hammad Haleem, Xavier Plantaz, Nan Cao, Huamin Qu", "title": "CNNComparator: Comparative Analytics of Convolutional Neural Networks", "comments": "5 pages. This paper has been accepted by VADL 2017: Workshop on\n  Visual Analytics for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are widely used in many image\nrecognition tasks due to their extraordinary performance. However, training a\ngood CNN model can still be a challenging task. In a training process, a CNN\nmodel typically learns a large number of parameters over time, which usually\nresults in different performance. Often, it is difficult to explore the\nrelationships between the learned parameters and the model performance due to a\nlarge number of parameters and different random initializations. In this paper,\nwe present a visual analytics approach to compare two different snapshots of a\ntrained CNN model taken after different numbers of epochs, so as to provide\nsome insight into the design or the training of a better CNN model. Our system\ncompares snapshots by exploring the differences in operation parameters and the\ncorresponding blob data at different levels. A case study has been conducted to\ndemonstrate the effectiveness of our system.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 06:43:29 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zeng", "Haipeng", ""], ["Haleem", "Hammad", ""], ["Plantaz", "Xavier", ""], ["Cao", "Nan", ""], ["Qu", "Huamin", ""]]}, {"id": "1710.05298", "submitter": "Hyemin Ahn", "authors": "Hyemin Ahn, Timothy Ha, Yunho Choi, Hwiyeon Yoo, and Songhwai Oh", "title": "Text2Action: Generative Adversarial Synthesis from Language to Action", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generative model which learns the relationship\nbetween language and human action in order to generate a human action sequence\ngiven a sentence describing human behavior. The proposed generative model is a\ngenerative adversarial network (GAN), which is based on the sequence to\nsequence (SEQ2SEQ) model. Using the proposed generative network, we can\nsynthesize various actions for a robot or a virtual agent using a text encoder\nrecurrent neural network (RNN) and an action decoder RNN. The proposed\ngenerative network is trained from 29,770 pairs of actions and sentence\nannotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video\ndataset. We demonstrate that the network can generate human-like actions which\ncan be transferred to a Baxter robot, such that the robot performs an action\nbased on a provided sentence. Results show that the proposed generative network\ncorrectly models the relationship between language and action and can generate\na diverse set of actions from the same sentence.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 07:51:01 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 06:32:52 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Ahn", "Hyemin", ""], ["Ha", "Timothy", ""], ["Choi", "Yunho", ""], ["Yoo", "Hwiyeon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1710.05338", "submitter": "Tsz Kit Lau", "authors": "Tsz Kit Lau and Yuan Yao", "title": "Accelerated Block Coordinate Proximal Gradients with Applications in\n  High Dimensional Statistics", "comments": "10th NIPS Workshop on Optimization for Machine Learning (NIPS 2017).\n  8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex optimization problems arise in different research fields and arouse\nlots of attention in signal processing, statistics and machine learning. In\nthis work, we explore the accelerated proximal gradient method and some of its\nvariants which have been shown to converge under nonconvex context recently. We\nshow that a novel variant proposed here, which exploits adaptive momentum and\nblock coordinate update with specific update rules, further improves the\nperformance of a broad class of nonconvex problems. In applications to sparse\nlinear regression with regularizations like Lasso, grouped Lasso, capped\n$\\ell_1$ and SCAP, the proposed scheme enjoys provable local linear\nconvergence, with experimental justification.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 14:07:32 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 11:21:32 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 06:31:38 GMT"}, {"version": "v4", "created": "Mon, 30 Oct 2017 15:16:24 GMT"}, {"version": "v5", "created": "Tue, 31 Oct 2017 11:40:24 GMT"}, {"version": "v6", "created": "Sat, 18 Nov 2017 09:26:25 GMT"}, {"version": "v7", "created": "Sun, 3 Dec 2017 11:21:03 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Lau", "Tsz Kit", ""], ["Yao", "Yuan", ""]]}, {"id": "1710.05359", "submitter": "Tomoya Sakai", "authors": "Tomoya Sakai and Gang Niu and Masashi Sugiyama", "title": "Information-Theoretic Representation Learning for Positive-Unlabeled\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in weakly supervised classification allow us to train a\nclassifier only from positive and unlabeled (PU) data. However, existing PU\nclassification methods typically require an accurate estimate of the\nclass-prior probability, which is a critical bottleneck particularly for\nhigh-dimensional data. This problem has been commonly addressed by applying\nprincipal component analysis in advance, but such unsupervised dimension\nreduction can collapse underlying class structure. In this paper, we propose a\nnovel representation learning method from PU data based on the\ninformation-maximization principle. Our method does not require class-prior\nestimation and thus can be used as a preprocessing method for PU\nclassification. Through experiments, we demonstrate that our method combined\nwith deep neural networks highly improves the accuracy of PU class-prior\nestimation, leading to state-of-the-art PU classification performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 16:19:37 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 10:50:54 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 06:45:53 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Sakai", "Tomoya", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.05373", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Rui Shu, Mohammad Ghavamzadeh, Hung Bui, Ali Ghodsi", "title": "Robust Locally-Linear Controllable Embedding", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embed-to-control (E2C) is a model for solving high-dimensional optimal\ncontrol problems by combining variational auto-encoders with locally-optimal\ncontrollers. However, the E2C model suffers from two major drawbacks: 1) its\nobjective function does not correspond to the likelihood of the data sequence\nand 2) the variational encoder used for embedding typically has large\nvariational approximation error, especially when there is noise in the system\ndynamics. In this paper, we present a new model for learning robust\nlocally-linear controllable embedding (RCE). Our model directly estimates the\npredictive conditional density of the future observation given the current one,\nwhile introducing the bottleneck between the current and future observations.\nAlthough the bottleneck provides a natural embedding candidate for control, our\nRCE model introduces additional specific structures in the generative graphical\nmodel so that the model dynamics can be robustly linearized. We also propose a\nprincipled variational approximation of the embedding posterior that takes the\nfuture observation into account, and thus, makes the variational approximation\nmore robust against the noise. Experimental results show that RCE outperforms\nthe E2C model, and does so significantly when the underlying dynamics is noisy.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 18:22:44 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 22:57:57 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Banijamali", "Ershad", ""], ["Shu", "Rui", ""], ["Ghavamzadeh", "Mohammad", ""], ["Bui", "Hung", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1710.05381", "submitter": "Mateusz Buda", "authors": "Mateusz Buda, Atsuto Maki, Maciej A. Mazurowski", "title": "A systematic study of the class imbalance problem in convolutional\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2018.07.011", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we systematically investigate the impact of class imbalance on\nclassification performance of convolutional neural networks (CNNs) and compare\nfrequently used methods to address the issue. Class imbalance is a common\nproblem that has been comprehensively studied in classical machine learning,\nyet very limited systematic research is available in the context of deep\nlearning. In our study, we use three benchmark datasets of increasing\ncomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of\nimbalance on classification and perform an extensive comparison of several\nmethods to address the issue: oversampling, undersampling, two-phase training,\nand thresholding that compensates for prior class probabilities. Our main\nevaluation metric is area under the receiver operating characteristic curve\n(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is\nassociated with notable difficulties in the context of imbalanced data. Based\non results from our experiments we conclude that (i) the effect of class\nimbalance on classification performance is detrimental; (ii) the method of\naddressing class imbalance that emerged as dominant in almost all analyzed\nscenarios was oversampling; (iii) oversampling should be applied to the level\nthat completely eliminates the imbalance, whereas the optimal undersampling\nratio depends on the extent of imbalance; (iv) as opposed to some classical\nmachine learning models, oversampling does not cause overfitting of CNNs; (v)\nthresholding should be applied to compensate for prior class probabilities when\noverall number of properly classified cases is of interest.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:01:43 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 02:02:17 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Buda", "Mateusz", ""], ["Maki", "Atsuto", ""], ["Mazurowski", "Maciej A.", ""]]}, {"id": "1710.05384", "submitter": "Chuang Wang", "authors": "Chuang Wang and Yue M. Lu", "title": "The Scaling Limit of High-Dimensional Online Independent Component\n  Analysis", "comments": "10 pages, 3 figures, 31st Conference on Neural Information Processing\n  Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the dynamics of an online algorithm for independent component\nanalysis in the high-dimensional scaling limit. As the ambient dimension tends\nto infinity, and with proper time scaling, we show that the time-varying joint\nempirical measure of the target feature vector and the estimates provided by\nthe algorithm will converge weakly to a deterministic measured-valued process\nthat can be characterized as the unique solution of a nonlinear PDE. Numerical\nsolutions of this PDE, which involves two spatial variables and one time\nvariable, can be efficiently obtained. These solutions provide detailed\ninformation about the performance of the ICA algorithm, as many practical\nperformance metrics are functionals of the joint empirical measures. Numerical\nsimulations show that our asymptotic analysis is accurate even for moderate\ndimensions. In addition to providing a tool for understanding the performance\nof the algorithm, our PDE analysis also provides useful insight. In particular,\nin the high-dimensional limit, the original coupled dynamics associated with\nthe algorithm will be asymptotically \"decoupled\", with each coordinate\nindependently solving a 1-D effective minimization problem via stochastic\ngradient descent. Exploiting this insight to design new algorithms for\nachieving optimal trade-offs between computational and statistical efficiency\nmay prove an interesting line of future research.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:14:26 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 02:48:03 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Wang", "Chuang", ""], ["Lu", "Yue M.", ""]]}, {"id": "1710.05387", "submitter": "Xinyan Yan", "authors": "Xinyan Yan, Krzysztof Choromanski, Byron Boots, Vikas Sindhwani", "title": "Manifold Regularization for Kernelized LSTD", "comments": "6 pages, CoRL 2017 non-archival track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation or value function or Q-function approximation is a key\nprocedure in reinforcement learning (RL). It is a necessary component of policy\niteration and can be used for variance reduction in policy gradient methods.\nTherefore its quality has a significant impact on most RL algorithms. Motivated\nby manifold regularized learning, we propose a novel kernelized policy\nevaluation method that takes advantage of the intrinsic geometry of the state\nspace learned from data, in order to achieve better sample efficiency and\nhigher accuracy in Q-function approximation. Applying the proposed method in\nthe Least-Squares Policy Iteration (LSPI) framework, we observe superior\nperformance compared to widely used parametric basis functions on two standard\nbenchmarks in terms of policy quality.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:59:13 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Yan", "Xinyan", ""], ["Choromanski", "Krzysztof", ""], ["Boots", "Byron", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1710.05420", "submitter": "Ermao Cai", "authors": "Ermao Cai, Da-Cheng Juan, Dimitrios Stamoulis, Diana Marculescu", "title": "NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural\n  Networks", "comments": "Accepted as a conference paper at ACML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"How much energy is consumed for an inference made by a convolutional neural\nnetwork (CNN)?\" With the increased popularity of CNNs deployed on the\nwide-spectrum of platforms (from mobile devices to workstations), the answer to\nthis question has drawn significant attention. From lengthening battery life of\nmobile devices to reducing the energy bill of a datacenter, it is important to\nunderstand the energy efficiency of CNNs during serving for making an\ninference, before actually training the model. In this work, we propose\nNeuralPower: a layer-wise predictive framework based on sparse polynomial\nregression, for predicting the serving energy consumption of a CNN deployed on\nany GPU platform. Given the architecture of a CNN, NeuralPower provides an\naccurate prediction and breakdown for power and runtime across all layers in\nthe whole network, helping machine learners quickly identify the power,\nruntime, or energy bottlenecks. We also propose the \"energy-precision ratio\"\n(EPR) metric to guide machine learners in selecting an energy-efficient CNN\narchitecture that better trades off the energy consumption and prediction\naccuracy. The experimental results show that the prediction accuracy of the\nproposed NeuralPower outperforms the best published model to date, yielding an\nimprovement in accuracy of up to 68.5%. We also assess the accuracy of\npredictions at the network level, by predicting the runtime, power, and energy\nof state-of-the-art CNN architectures, achieving an average accuracy of 88.24%\nin runtime, 88.34% in power, and 97.21% in energy. We comprehensively\ncorroborate the effectiveness of NeuralPower as a powerful framework for\nmachine learners by testing it on different GPU platforms and Deep Learning\nsoftware tools.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 23:39:29 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Cai", "Ermao", ""], ["Juan", "Da-Cheng", ""], ["Stamoulis", "Dimitrios", ""], ["Marculescu", "Diana", ""]]}, {"id": "1710.05422", "submitter": "Ehsan Emamjomeh-Zadeh", "authors": "Ehsan Emamjomeh-Zadeh, David Kempe", "title": "A General Framework for Robust Interactive Learning", "comments": "In NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for interactively learning models, such as\n(binary or non-binary) classifiers, orderings/rankings of items, or clusterings\nof data points. Our framework is based on a generalization of Angluin's\nequivalence query model and Littlestone's online learning model: in each\niteration, the algorithm proposes a model, and the user either accepts it or\nreveals a specific mistake in the proposal. The feedback is correct only with\nprobability $p > 1/2$ (and adversarially incorrect with probability $1 - p$),\ni.e., the algorithm must be able to learn in the presence of arbitrary noise.\nThe algorithm's goal is to learn the ground truth model using few iterations.\n  Our general framework is based on a graph representation of the models and\nuser feedback. To be able to learn efficiently, it is sufficient that there be\na graph $G$ whose nodes are the models and (weighted) edges capture the user\nfeedback, with the property that if $s, s^*$ are the proposed and target\nmodels, respectively, then any (correct) user feedback $s'$ must lie on a\nshortest $s$-$s^*$ path in $G$. Under this one assumption, there is a natural\nalgorithm reminiscent of the Multiplicative Weights Update algorithm, which\nwill efficiently learn $s^*$ even in the presence of noise in the user's\nfeedback.\n  From this general result, we rederive with barely any extra effort classic\nresults on learning of classifiers and a recent result on interactive\nclustering; in addition, we easily obtain new interactive learning algorithms\nfor ordering/ranking.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 00:13:20 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Emamjomeh-Zadeh", "Ehsan", ""], ["Kempe", "David", ""]]}, {"id": "1710.05468", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Leslie Pack Kaelbling, Yoshua Bengio", "title": "Generalization in Deep Learning", "comments": "To appear in Mathematics of Deep Learning, Cambridge University\n  Press. All previous results remain unchanged", "journal-ref": null, "doi": null, "report-no": "Massachusetts Institute of Technology (MIT), MIT-CSAIL-TR-2018-014", "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides theoretical insights into why and how deep learning can\ngeneralize well, despite its large capacity, complexity, possible algorithmic\ninstability, nonrobustness, and sharp minima, responding to an open question in\nthe literature. We also discuss approaches to provide non-vacuous\ngeneralization guarantees for deep learning. Based on theoretical observations,\nwe propose new open problems and discuss the limitations of our results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 02:21:24 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 19:44:43 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 23:39:50 GMT"}, {"version": "v4", "created": "Tue, 1 Jan 2019 00:07:45 GMT"}, {"version": "v5", "created": "Fri, 10 May 2019 18:41:13 GMT"}, {"version": "v6", "created": "Mon, 27 Jul 2020 23:01:04 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Kaelbling", "Leslie Pack", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.05472", "submitter": "Li Wang", "authors": "Li Wang, Evangelos A. Theodorou, and Magnus Egerstedt", "title": "Safe Learning of Quadrotor Dynamics Using Barrier Certificates", "comments": "Submitted to ICRA 2018, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively control complex dynamical systems, accurate nonlinear models\nare typically needed. However, these models are not always known. In this\npaper, we present a data-driven approach based on Gaussian processes that\nlearns models of quadrotors operating in partially unknown environments. What\nmakes this challenging is that if the learning process is not carefully\ncontrolled, the system will go unstable, i.e., the quadcopter will crash. To\nthis end, barrier certificates are employed for safe learning. The barrier\ncertificates establish a non-conservative forward invariant safe region, in\nwhich high probability safety guarantees are provided based on the statistics\nof the Gaussian Process. A learning controller is designed to efficiently\nexplore those uncertain states and expand the barrier certified safe region\nbased on an adaptive sampling scheme. In addition, a recursive Gaussian Process\nprediction method is developed to learn the complex quadrotor dynamics in\nreal-time. Simulation results are provided to demonstrate the effectiveness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 02:37:26 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Wang", "Li", ""], ["Theodorou", "Evangelos A.", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "1710.05476", "submitter": "Haozhen Wu", "authors": "Haozhen Wu", "title": "Calibrated Boosting-Forest", "comments": "9 pages, 3 figures, 4 tables, NIPS 2017 Workshop on Machine Learning\n  for Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excellent ranking power along with well calibrated probability estimates are\nneeded in many classification tasks. In this paper, we introduce a technique,\nCalibrated Boosting-Forest that captures both. This novel technique is an\nensemble of gradient boosting machines that can support both continuous and\nbinary labels. While offering superior ranking power over any individual\nregression or classification model, Calibrated Boosting-Forest is able to\npreserve well calibrated posterior probabilities. Along with these benefits, we\nprovide an alternative to the tedious step of tuning gradient boosting\nmachines. We demonstrate that tuning Calibrated Boosting-Forest can be reduced\nto a simple hyper-parameter selection. We further establish that increasing\nthis hyper-parameter improves the ranking performance under a diminishing\nreturn. We examine the effectiveness of Calibrated Boosting-Forest on\nligand-based virtual screening where both continuous and binary labels are\navailable and compare the performance of Calibrated Boosting-Forest with\nlogistic regression, gradient boosting machine and deep learning. Calibrated\nBoosting-Forest achieved an approximately 48% improvement compared to a\nstate-of-art deep learning model. Moreover, it achieved around 95% improvement\non probability quality measurement compared to the best individual gradient\nboosting machine. Calibrated Boosting-Forest offers a benchmark demonstration\nthat in the field of ligand-based virtual screening, deep learning is not the\nuniversally dominant machine learning model and good calibrated probabilities\ncan better facilitate virtual screening process.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 02:49:07 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 02:45:46 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 19:01:55 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Wu", "Haozhen", ""]]}, {"id": "1710.05488", "submitter": "Na Lei", "authors": "Na Lei, Kehua Su, Li Cui, Shing-Tung Yau, David Xianfeng Gu", "title": "A Geometric View of Optimal Transportation and Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show the intrinsic relations between optimal transportation\nand convex geometry, especially the variational approach to solve Alexandrov\nproblem: constructing a convex polytope with prescribed face normals and\nvolumes. This leads to a geometric interpretation to generative models, and\nleads to a novel framework for generative models. By using the optimal\ntransportation view of GAN model, we show that the discriminator computes the\nKantorovich potential, the generator calculates the transportation map. For a\nlarge class of transportation costs, the Kantorovich potential can give the\noptimal transportation map by a close-form formula. Therefore, it is sufficient\nto solely optimize the discriminator. This shows the adversarial competition\ncan be avoided, and the computational architecture can be simplified.\nPreliminary experimental results show the geometric method outperforms WGAN for\napproximating probability measures with multiple clusters in low dimensional\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 03:30:09 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 04:28:31 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Lei", "Na", ""], ["Su", "Kehua", ""], ["Cui", "Li", ""], ["Yau", "Shing-Tung", ""], ["Gu", "David Xianfeng", ""]]}, {"id": "1710.05512", "submitter": "Roberto Calandra", "authors": "Roberto Calandra, Andrew Owens, Manu Upadhyaya, Wenzhen Yuan, Justin\n  Lin, Edward H. Adelson, Sergey Levine", "title": "The Feeling of Success: Does Touch Sensing Help Predict Grasp Outcomes?", "comments": "10 pages, accepted at the 1st Annual Conference on Robot Learning\n  (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A successful grasp requires careful balancing of the contact forces. Deducing\nwhether a particular grasp will be successful from indirect measurements, such\nas vision, is therefore quite challenging, and direct sensing of contacts\nthrough touch sensing provides an appealing avenue toward more successful and\nconsistent robotic grasping. However, in order to fully evaluate the value of\ntouch sensing for grasp outcome prediction, we must understand how touch\nsensing can influence outcome prediction accuracy when combined with other\nmodalities. Doing so using conventional model-based techniques is exceptionally\ndifficult. In this work, we investigate the question of whether touch sensing\naids in predicting grasp outcomes within a multimodal sensing framework that\ncombines vision and touch. To that end, we collected more than 9,000 grasping\ntrials using a two-finger gripper equipped with GelSight high-resolution\ntactile sensors on each finger, and evaluated visuo-tactile deep neural network\nmodels to directly predict grasp outcomes from either modality individually,\nand from both modalities together. Our experimental results indicate that\nincorporating tactile readings substantially improve grasping performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 05:32:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Calandra", "Roberto", ""], ["Owens", "Andrew", ""], ["Upadhyaya", "Manu", ""], ["Yuan", "Wenzhen", ""], ["Lin", "Justin", ""], ["Adelson", "Edward H.", ""], ["Levine", "Sergey", ""]]}, {"id": "1710.05520", "submitter": "Ya-Hui Zhang", "authors": "Ya-Hui Zhang", "title": "Entanglement Entropy of Target Functions for Image Classification and\n  Convolutional Neural Network", "comments": "9pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.str-el cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep convolutional neural network (CNN) in computer vision\nespecially image classification problems requests a new information theory for\nfunction of image, instead of image itself. In this article, after establishing\na deep mathematical connection between image classification problem and quantum\nspin model, we propose to use entanglement entropy, a generalization of\nclassical Boltzmann-Shannon entropy, as a powerful tool to characterize the\ninformation needed for representation of general function of image. We prove\nthat there is a sub-volume-law bound for entanglement entropy of target\nfunctions of reasonable image classification problems. Therefore target\nfunctions of image classification only occupy a small subspace of the whole\nHilbert space. As a result, a neural network with polynomial number of\nparameters is efficient for representation of such target functions of image.\nThe concept of entanglement entropy can also be useful to characterize the\nexpressive power of different neural networks. For example, we show that to\nmaintain the same expressive power, number of channels $D$ in a convolutional\nneural network should scale with the number of convolution layers $n_c$ as\n$D\\sim D_0^{\\frac{1}{n_c}}$. Therefore, deeper CNN with large $n_c$ is more\nefficient than shallow ones.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 05:54:38 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhang", "Ya-Hui", ""]]}, {"id": "1710.05613", "submitter": "Nino Antulov-Fantulin", "authors": "Vaibhav Krishna and Tian Guo and Nino Antulov-Fantulin", "title": "Is Simple Better? Revisiting Non-linear Matrix Factorization for\n  Learning Incomplete Ratings", "comments": "version 3", "journal-ref": null, "doi": "10.1109/ICDMW.2018.00183", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization techniques have been widely used as a method for\ncollaborative filtering for recommender systems. In recent times, different\nvariants of deep learning algorithms have been explored in this setting to\nimprove the task of making a personalized recommendation with user-item\ninteraction data. The idea that the mapping between the latent user or item\nfactors and the original features is highly nonlinear suggest that classical\nmatrix factorization techniques are no longer sufficient. In this paper, we\npropose a multilayer nonlinear semi-nonnegative matrix factorization method,\nwith the motivation that user-item interactions can be modeled more accurately\nusing a linear combination of non-linear item features. Firstly, we learn\nlatent factors for representations of users and items from the designed\nmultilayer nonlinear Semi-NMF approach using explicit ratings. Secondly, the\narchitecture built is compared with deep-learning algorithms like Restricted\nBoltzmann Machine and state-of-the-art Deep Matrix factorization techniques. By\nusing both supervised rate prediction task and unsupervised clustering in\nlatent item space, we demonstrate that our proposed approach achieves better\ngeneralization ability in prediction as well as comparable representation\nability as deep matrix factorization in the clustering task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 10:46:41 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 12:58:31 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2018 09:36:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Krishna", "Vaibhav", ""], ["Guo", "Tian", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1710.05654", "submitter": "Nathanael Perraudin N. P.", "authors": "Vassilis Kalofolias, Nathana\\\"el Perraudin", "title": "Large Scale Graph Learning from Smooth Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a prevalent tool in data science, as they model the inherent\nstructure of the data. They have been used successfully in unsupervised and\nsemi-supervised learning. Typically they are constructed either by connecting\nnearest samples, or by learning them from data, solving an optimization\nproblem. While graph learning does achieve a better quality, it also comes with\na higher computational cost. In particular, the current state-of-the-art model\ncost is $\\mathcal{O}(n^2)$ for $n$ samples. In this paper, we show how to scale\nit, obtaining an approximation with leading cost of $\\mathcal{O}(n\\log(n))$,\nwith quality that approaches the exact graph learning model. Our algorithm uses\nknown approximate nearest neighbor techniques to reduce the number of\nvariables, and automatically selects the correct parameters of the model,\nrequiring a single intuitive input: the desired edge density.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 12:42:15 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 12:30:44 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Kalofolias", "Vassilis", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "1710.05711", "submitter": "Sanping Zhou", "authors": "Sanping Zhou, Jinjun Wang, Deyu Meng, Xiaomeng Xin, Yubing Li, Yihong\n  Gong, Nanning Zheng", "title": "Deep Self-Paced Learning for Person Re-Identification", "comments": "Accepted by Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (Re-ID) usually suffers from noisy samples with\nbackground clutter and mutual occlusion, which makes it extremely difficult to\ndistinguish different individuals across the disjoint camera views. In this\npaper, we propose a novel deep self-paced learning (DSPL) algorithm to\nalleviate this problem, in which we apply a self-paced constraint and symmetric\nregularization to help the relative distance metric training the deep neural\nnetwork, so as to learn the stable and discriminative features for person\nRe-ID. Firstly, we propose a soft polynomial regularizer term which can derive\nthe adaptive weights to samples based on both the training loss and model age.\nAs a result, the high-confidence fidelity samples will be emphasized and the\nlow-confidence noisy samples will be suppressed at early stage of the whole\ntraining process. Such a learning regime is naturally implemented under a\nself-paced learning (SPL) framework, in which samples weights are adaptively\nupdated based on both model age and sample loss using an alternative\noptimization method. Secondly, we introduce a symmetric regularizer term to\nrevise the asymmetric gradient back-propagation derived by the relative\ndistance metric, so as to simultaneously minimize the intra-class distance and\nmaximize the inter-class distance in each triplet unit. Finally, we build a\npart-based deep neural network, in which the features of different body parts\nare first discriminately learned in the lower convolutional layers and then\nfused in the higher fully connected layers. Experiments on several benchmark\ndatasets have demonstrated the superior performance of our method as compared\nwith the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 01:32:38 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhou", "Sanping", ""], ["Wang", "Jinjun", ""], ["Meng", "Deyu", ""], ["Xin", "Xiaomeng", ""], ["Li", "Yubing", ""], ["Gong", "Yihong", ""], ["Zheng", "Nanning", ""]]}, {"id": "1710.05719", "submitter": "Hien Nguyen", "authors": "Aryan Mobiny, Supratik Moulik, Hien Van Nguyen", "title": "Lung Cancer Screening Using Adaptive Memory-Augmented Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the effectiveness of deep learning techniques\nfor lung nodule classification in computed tomography scans. Using less than\n10,000 training examples, our deep networks perform two times better than a\nstandard radiology software. Visualization of the networks' neurons reveals\nsemantically meaningful features that are consistent with the clinical\nknowledge and radiologists' perception. Our paper also proposes a novel\nframework for rapidly adapting deep networks to the radiologists' feedback, or\nchange in the data due to the shift in sensor's resolution or patient\npopulation. The classification accuracy of our approach remains above 80% while\npopular deep networks' accuracy is around chance. Finally, we provide in-depth\nanalysis of our framework by asking a radiologist to examine important\nnetworks' features and perform blind re-labeling of networks' mistakes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:54:04 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:41:56 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Mobiny", "Aryan", ""], ["Moulik", "Supratik", ""], ["Van Nguyen", "Hien", ""]]}, {"id": "1710.05739", "submitter": "Gergely Neu", "authors": "G\\'abor Lugosi, Mihalis G. Markakis, Gergely Neu", "title": "On the Hardness of Inventory Management with Censored Demand Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a repeated newsvendor problem where the inventory manager has no\nprior information about the demand, and can access only censored/sales data. In\nanalogy to multi-armed bandit problems, the manager needs to simultaneously\n\"explore\" and \"exploit\" with her inventory decisions, in order to minimize the\ncumulative cost. We make no probabilistic assumptions---importantly,\nindependence or time stationarity---regarding the mechanism that creates the\ndemand sequence. Our goal is to shed light on the hardness of the problem, and\nto develop policies that perform well with respect to the regret criterion,\nthat is, the difference between the cumulative cost of a policy and that of the\nbest fixed action/static inventory decision in hindsight, uniformly over all\nfeasible demand sequences. We show that a simple randomized policy, termed the\nExponentially Weighted Forecaster, combined with a carefully designed cost\nestimator, achieves optimal scaling of the expected regret (up to logarithmic\nfactors) with respect to all three key primitives: the number of time periods,\nthe number of inventory decisions available, and the demand support. Through\nthis result, we derive an important insight: the benefit from \"information\nstalking\" as well as the cost of censoring are both negligible in this dynamic\nlearning problem, at least with respect to the regret criterion. Furthermore,\nwe modify the proposed policy in order to perform well in terms of the tracking\nregret, that is, using as benchmark the best sequence of inventory decisions\nthat switches a limited number of times. Numerical experiments suggest that the\nproposed approach outperforms existing ones (that are tailored to, or\nfacilitated by, time stationarity) on nonstationary demand models. Finally, we\nextend the proposed approach and its analysis to a \"combinatorial\" version of\nthe repeated newsvendor problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:33:59 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Markakis", "Mihalis G.", ""], ["Neu", "Gergely", ""]]}, {"id": "1710.05741", "submitter": "Marco Fraccaro", "authors": "Marco Fraccaro, Simon Kamronn, Ulrich Paquet, Ole Winther", "title": "A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised\n  Learning", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes a step towards temporal reasoning in a dynamically changing\nvideo, not in the pixel space that constitutes its frames, but in a latent\nspace that describes the non-linear dynamics of the objects in its world. We\nintroduce the Kalman variational auto-encoder, a framework for unsupervised\nlearning of sequential data that disentangles two latent representations: an\nobject's representation, coming from a recognition model, and a latent state\ndescribing its dynamics. As a result, the evolution of the world can be\nimagined and missing data imputed, both without the need to generate high\ndimensional frames at each time step. The model is trained end-to-end on videos\nof a variety of simulated physical systems, and outperforms competing methods\nin generative and missing data imputation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:34:24 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 09:34:32 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Fraccaro", "Marco", ""], ["Kamronn", "Simon", ""], ["Paquet", "Ulrich", ""], ["Winther", "Ole", ""]]}, {"id": "1710.05758", "submitter": "Dominik Marek Loroch", "authors": "Dominik Marek Loroch, Norbert Wehn, Franz-Josef Pfreundt, Janis Keuper", "title": "TensorQuant - A Simulation Toolbox for Deep Neural Network Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research implies that training and inference of deep neural networks\n(DNN) can be computed with low precision numerical representations of the\ntraining/test data, weights and gradients without a general loss in accuracy.\nThe benefit of such compact representations is twofold: they allow a\nsignificant reduction of the communication bottleneck in distributed DNN\ntraining and faster neural network implementations on hardware accelerators\nlike FPGAs. Several quantization methods have been proposed to map the original\n32-bit floating point problem to low-bit representations. While most related\npublications validate the proposed approach on a single DNN topology, it\nappears to be evident, that the optimal choice of the quantization method and\nnumber of coding bits is topology dependent. To this end, there is no general\ntheory available, which would allow users to derive the optimal quantization\nduring the design of a DNN topology. In this paper, we present a quantization\ntool box for the TensorFlow framework. TensorQuant allows a transparent\nquantization simulation of existing DNN topologies during training and\ninference. TensorQuant supports generic quantization methods and allows\nexperimental evaluation of the impact of the quantization on single layers as\nwell as on the full topology. In a first series of experiments with\nTensorQuant, we show an analysis of fix-point quantizations of popular CNN\ntopologies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 10:15:27 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Loroch", "Dominik Marek", ""], ["Wehn", "Norbert", ""], ["Pfreundt", "Franz-Josef", ""], ["Keuper", "Janis", ""]]}, {"id": "1710.05888", "submitter": "Nir Rosenfeld", "authors": "Nir Rosenfeld, Yishay Mansour, Elad Yom-Tov", "title": "Discriminative Learning of Prediction Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the task of constructing prediction intervals in an\ninductive batch setting. We present a discriminative learning framework which\noptimizes the expected error rate under a budget constraint on the interval\nsizes. Most current methods for constructing prediction intervals offer\nguarantees for a single new test point. Applying these methods to multiple test\npoints can result in a high computational overhead and degraded statistical\nguarantees. By focusing on expected errors, our method allows for variability\nin the per-example conditional error rates. As we demonstrate both analytically\nand empirically, this flexibility can increase the overall accuracy, or\nalternatively, reduce the average interval size.\n  While the problem we consider is of a regressive flavor, the loss we use is\ncombinatorial. This allows us to provide PAC-style, finite-sample guarantees.\nComputationally, we show that our original objective is NP-hard, and suggest a\ntractable convex surrogate. We conclude with a series of experimental\nevaluations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 17:42:28 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 14:43:19 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Rosenfeld", "Nir", ""], ["Mansour", "Yishay", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1710.05895", "submitter": "Anil Aswani", "authors": "Matt Olfat, Anil Aswani", "title": "Spectral Algorithms for Computing Fair Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers and rating scores are prone to implicitly codifying biases, which\nmay be present in the training data, against protected classes (i.e., age,\ngender, or race). So it is important to understand how to design classifiers\nand scores that prevent discrimination in predictions. This paper develops\ncomputationally tractable algorithms for designing accurate but fair support\nvector machines (SVM's). Our approach imposes a constraint on the covariance\nmatrices conditioned on each protected class, which leads to a nonconvex\nquadratic constraint in the SVM formulation. We develop iterative algorithms to\ncompute fair linear and kernel SVM's, which solve a sequence of relaxations\nconstructed using a spectral decomposition of the nonconvex constraint. Its\neffectiveness in achieving high prediction accuracy while ensuring fairness is\nshown through numerical experiments on several data sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 17:48:23 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Olfat", "Matt", ""], ["Aswani", "Anil", ""]]}, {"id": "1710.05941", "submitter": "Prajit Ramachandran", "authors": "Prajit Ramachandran, Barret Zoph, Quoc V. Le", "title": "Searching for Activation Functions", "comments": "Updated version of \"Swish: a Self-Gated Activation Function\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation functions in deep networks has a significant effect\non the training dynamics and task performance. Currently, the most successful\nand widely-used activation function is the Rectified Linear Unit (ReLU).\nAlthough various hand-designed alternatives to ReLU have been proposed, none\nhave managed to replace it due to inconsistent gains. In this work, we propose\nto leverage automatic search techniques to discover new activation functions.\nUsing a combination of exhaustive and reinforcement learning-based search, we\ndiscover multiple novel activation functions. We verify the effectiveness of\nthe searches by conducting an empirical evaluation with the best discovered\nactivation function. Our experiments show that the best discovered activation\nfunction, $f(x) = x \\cdot \\text{sigmoid}(\\beta x)$, which we name Swish, tends\nto work better than ReLU on deeper models across a number of challenging\ndatasets. For example, simply replacing ReLUs with Swish units improves top-1\nclassification accuracy on ImageNet by 0.9\\% for Mobile NASNet-A and 0.6\\% for\nInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it\neasy for practitioners to replace ReLUs with Swish units in any neural network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 18:05:45 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 17:45:21 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Ramachandran", "Prajit", ""], ["Zoph", "Barret", ""], ["Le", "Quoc V.", ""]]}, {"id": "1710.05958", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Anna Rohrbach, Trevor Darrell", "title": "Gradient-free Policy Architecture Search and Adaptation", "comments": "Accepted in Conference on Robot Learning, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for policy architecture search and adaptation via\ngradient-free optimization which can learn to perform autonomous driving tasks.\nBy learning from both demonstration and environmental reward we develop a model\nthat can learn with relatively few early catastrophic failures. We first learn\nan architecture of appropriate complexity to perceive aspects of world state\nrelevant to the expert demonstration, and then mitigate the effect of\ndomain-shift during deployment by adapting a policy demonstrated in a source\ndomain to rewards obtained in a target environment. We show that our approach\nallows safer learning than baseline methods, offering a reduced cumulative\ncrash metric over the agent's lifetime as it learns to drive in a realistic\nsimulated environment.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 18:47:35 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Rohrbach", "Anna", ""], ["Darrell", "Trevor", ""]]}, {"id": "1710.05982", "submitter": "Lorenzo Alvino", "authors": "Lorenzo Alvino", "title": "Pushing the envelope in deep visual recognition for mobile platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification is the task of assigning to an input image a label from\na fixed set of categories. One of its most important applicative fields is that\nof robotics, in particular the needing of a robot to be aware of what's around\nand the consequent exploitation of that information as a benefit for its tasks.\nIn this work we consider the problem of a robot that enters a new environment\nand wants to understand visual data coming from its camera, so to extract\nknowledge from them. As main novelty we want to overcome the needing of a\nphysical robot, as it could be expensive and unhandy, so to hopefully enhance,\nspeed up and ease the research in this field. That's why we propose to develop\nan application for a mobile platform that wraps several deep visual recognition\ntasks. First we deal with a simple Image classification, testing a model\nobtained from an AlexNet trained on the ILSVRC 2012 dataset. Several photo\nsettings are considered to better understand which factors affect most the\nquality of classification. For the same purpose we are interested to integrate\nthe classification task with an extra module dealing with segmentation of the\nobject inside the image. In particular we propose a technique for extracting\nthe object shape and moving out all the background, so to focus the\nclassification only on the region occupied by the object. Another significant\ntask that is included is that of object discovery. Its purpose is to simulate\nthe situation in which the robot needs a certain object to complete one of its\nactivities. It starts searching for what it needs by looking around and trying\nto understand the location of the object by scanning the surrounding\nenvironment. Finally we provide a tool for dealing with the creation of\ncustomized task-specific databases, meant to better suit to one's needing in a\nparticular vision task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 20:11:23 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 11:37:48 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Alvino", "Lorenzo", ""]]}, {"id": "1710.06034", "submitter": "Tianbing Xu", "authors": "Tianbing Xu, Qiang Liu, Jian Peng", "title": "Stochastic Variance Reduction for Policy Gradient Estimation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in policy gradient methods and deep learning have\ndemonstrated their applicability for complex reinforcement learning problems.\nHowever, the variance of the performance gradient estimates obtained from the\nsimulation is often excessive, leading to poor sample efficiency. In this\npaper, we apply the stochastic variance reduced gradient descent (SVRG) to\nmodel-free policy gradient to significantly improve the sample-efficiency. The\nSVRG estimation is incorporated into a trust-region Newton conjugate gradient\nframework for the policy optimization. On several Mujoco tasks, our method\nachieves significantly better performance compared to the state-of-the-art\nmodel-free policy gradient methods in robotic continuous control such as trust\nregion policy optimization (TRPO)\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 00:05:06 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 21:09:55 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 00:33:08 GMT"}, {"version": "v4", "created": "Thu, 29 Mar 2018 17:51:14 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Xu", "Tianbing", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1710.06081", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin\n  Hu, Jianguo Li", "title": "Boosting Adversarial Attacks with Momentum", "comments": "CVPR 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which poses\nsecurity concerns on these algorithms due to the potentially severe\nconsequences. Adversarial attacks serve as an important surrogate to evaluate\nthe robustness of deep learning models before they are deployed. However, most\nof existing adversarial attacks can only fool a black-box model with a low\nsuccess rate. To address this issue, we propose a broad class of momentum-based\niterative algorithms to boost adversarial attacks. By integrating the momentum\nterm into the iterative process for attacks, our methods can stabilize update\ndirections and escape from poor local maxima during the iterations, resulting\nin more transferable adversarial examples. To further improve the success rates\nfor black-box attacks, we apply momentum iterative algorithms to an ensemble of\nmodels, and show that the adversarially trained models with a strong defense\nability are also vulnerable to our black-box attacks. We hope that the proposed\nmethods will serve as a benchmark for evaluating the robustness of various deep\nmodels and defense methods. With this method, we won the first places in NIPS\n2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack\ncompetitions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 04:03:04 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 06:53:07 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 12:46:44 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Dong", "Yinpeng", ""], ["Liao", "Fangzhou", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""], ["Hu", "Xiaolin", ""], ["Li", "Jianguo", ""]]}, {"id": "1710.06085", "submitter": "Rahul Gopal Krishnan", "authors": "Rahul G. Krishnan, Dawen Liang, Matthew Hoffman", "title": "On the challenges of learning with inference networks on sparse,\n  high-dimensional data", "comments": "14 pages, 3 tables, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parameter estimation in Nonlinear Factor Analysis (NFA) where the\ngenerative model is parameterized by a deep neural network. Recent work has\nfocused on learning such models using inference (or recognition) networks; we\nidentify a crucial problem when modeling large, sparse, high-dimensional\ndatasets -- underfitting. We study the extent of underfitting, highlighting\nthat its severity increases with the sparsity of the data. We propose methods\nto tackle it via iterative optimization inspired by stochastic variational\ninference \\citep{hoffman2013stochastic} and improvements in the sparse data\nrepresentation used for inference. The proposed techniques drastically improve\nthe ability of these powerful models to fit sparse data, achieving\nstate-of-the-art results on a benchmark text-count dataset and excellent\nresults on the task of top-N recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 04:17:07 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Krishnan", "Rahul G.", ""], ["Liang", "Dawen", ""], ["Hoffman", "Matthew", ""]]}, {"id": "1710.06096", "submitter": "Ricky Fok", "authors": "Ricky Fok, Aijun An, and Xiaogang Wang", "title": "Spontaneous Symmetry Breaking in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to understand the unprecedented performance and\nrobustness of deep neural networks using field theory. Correlations between the\nweights within the same layer can be described by symmetries in that layer, and\nnetworks generalize better if such symmetries are broken to reduce the\nredundancies of the weights. Using a two parameter field theory, we find that\nthe network can break such symmetries itself towards the end of training in a\nprocess commonly known in physics as spontaneous symmetry breaking. This\ncorresponds to a network generalizing itself without any user input layers to\nbreak the symmetry, but by communication with adjacent layers. In the layer\ndecoupling limit applicable to residual networks (He et al., 2015), we show\nthat the remnant symmetries that survive the non-linear layers are\nspontaneously broken. The Lagrangian for the non-linear and weight layers\ntogether has striking similarities with the one in quantum field theory of a\nscalar. Using results from quantum field theory we show that our framework is\nable to explain many experimentally observed phenomena,such as training on\nrandom labels with zero error (Zhang et al., 2017), the information bottleneck,\nthe phase transition out of it and gradient variance explosion (Shwartz-Ziv &\nTishby, 2017), shattered gradients (Balduzzi et al., 2017), and many more.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 04:55:14 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Fok", "Ricky", ""], ["An", "Aijun", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1710.06100", "submitter": "Mengdi Wang", "authors": "Mengdi Wang", "title": "Primal-Dual $\\pi$ Learning: Sample Complexity and Sublinear Run Time for\n  Ergodic Markov Decision Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of approximating the optimal policy of a Markov decision\nprocess (MDP) by sampling state transitions. In contrast to existing\nreinforcement learning methods that are based on successive approximations to\nthe nonlinear Bellman equation, we propose a Primal-Dual $\\pi$ Learning method\nin light of the linear duality between the value and policy. The $\\pi$ learning\nmethod is model-free and makes primal-dual updates to the policy and value\nvectors as new data are revealed. For infinite-horizon undiscounted Markov\ndecision process with finite state space $S$ and finite action space $A$, the\n$\\pi$ learning method finds an $\\epsilon$-optimal policy using the following\nnumber of sample transitions $$ \\tilde{O}( \\frac{(\\tau\\cdot t^*_{mix})^2 |S|\n|A| }{\\epsilon^2} ),$$ where $t^*_{mix}$ is an upper bound of mixing times\nacross all policies and $\\tau$ is a parameter characterizing the range of\nstationary distributions across policies. The $\\pi$ learning method also\napplies to the computational problem of MDP where the transition probabilities\nand rewards are explicitly given as the input. In the case where each state\ntransition can be sampled in $\\tilde{O}(1)$ time, the $\\pi$ learning method\ngives a sublinear-time algorithm for solving the averaged-reward MDP.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 05:03:19 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Wang", "Mengdi", ""]]}, {"id": "1710.06117", "submitter": "Ayaka Kume", "authors": "Ayaka Kume, Eiichi Matsumoto, Kuniyuki Takahashi, Wilson Ko and Jethro\n  Tan", "title": "Map-based Multi-Policy Reinforcement Learning: Enhancing Adaptability of\n  Robots by Deep Reinforcement Learning", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for robots to perform mission-critical tasks, it is essential that\nthey are able to quickly adapt to changes in their environment as well as to\ninjuries and or other bodily changes. Deep reinforcement learning has been\nshown to be successful in training robot control policies for operation in\ncomplex environments. However, existing methods typically employ only a single\npolicy. This can limit the adaptability since a large environmental\nmodification might require a completely different behavior compared to the\nlearning environment. To solve this problem, we propose Map-based Multi-Policy\nReinforcement Learning (MMPRL), which aims to search and store multiple\npolicies that encode different behavioral features while maximizing the\nexpected reward in advance of the environment change. Thanks to these policies,\nwhich are stored into a multi-dimensional discrete map according to its\nbehavioral feature, adaptation can be performed within reasonable time without\nretraining the robot. An appropriate pre-trained policy from the map can be\nrecalled using Bayesian optimization. Our experiments show that MMPRL enables\nrobots to quickly adapt to large changes without requiring any prior knowledge\non the type of injuries that could occur. A highlight of the learned behaviors\ncan be found here: https://youtu.be/QwInbilXNOE .\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 06:26:44 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 04:54:31 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Kume", "Ayaka", ""], ["Matsumoto", "Eiichi", ""], ["Takahashi", "Kuniyuki", ""], ["Ko", "Wilson", ""], ["Tan", "Jethro", ""]]}, {"id": "1710.06122", "submitter": "Michael Tschannen", "authors": "Martin Zihlmann, Dmytro Perekrestenko, Michael Tschannen", "title": "Convolutional Recurrent Neural Networks for Electrocardiogram\n  Classification", "comments": "4 pages, in Computing in Cardiology (CinC) 2017, PhysioNet/CinC\n  Challenge 2017 submission. Code available at\n  https://github.com/yruffiner/ecg-classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two deep neural network architectures for classification of\narbitrary-length electrocardiogram (ECG) recordings and evaluate them on the\natrial fibrillation (AF) classification data set provided by the PhysioNet/CinC\nChallenge 2017. The first architecture is a deep convolutional neural network\n(CNN) with averaging-based feature aggregation across time. The second\narchitecture combines convolutional layers for feature extraction with\nlong-short term memory (LSTM) layers for temporal aggregation of features. As a\nkey ingredient of our training procedure we introduce a simple data\naugmentation scheme for ECG data and demonstrate its effectiveness in the AF\nclassification task at hand. The second architecture was found to outperform\nthe first one, obtaining an $F_1$ score of $82.1$% on the hidden challenge\ntesting set.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 06:50:58 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 14:01:38 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Zihlmann", "Martin", ""], ["Perekrestenko", "Dmytro", ""], ["Tschannen", "Michael", ""]]}, {"id": "1710.06134", "submitter": "Davy Geysen", "authors": "Davy Geysen and Oscar De Somer and Christian Johansson and Jens Brage\n  and Dirk Vanhoudt", "title": "Operational thermal load forecasting in district heating networks using\n  machine learning and expert advice", "comments": "29 pages, 4 figures, submitted Energies and Buildings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting thermal load is a key component for the majority of optimization\nsolutions for controlling district heating and cooling systems. Recent studies\nhave analysed the results of a number of data-driven methods applied to thermal\nload forecasting, this paper presents the results of combining a collection of\nthese individual methods in an expert system. The expert system will combine\nmultiple thermal load forecasts in a way that it always tracks the best expert\nin the system. This solution is tested and validated using a thermal load\ndataset of 27 months obtained from 10 residential buildings located in Rottne,\nSweden together with outdoor temperature information received from a weather\nforecast service. The expert system is composed of the following data-driven\nmethods: linear regression, extremely randomized trees regression, feed-forward\nneural network and support vector machine. The results of the proposed solution\nare compared with the results of the individual methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 07:33:10 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Geysen", "Davy", ""], ["De Somer", "Oscar", ""], ["Johansson", "Christian", ""], ["Brage", "Jens", ""], ["Vanhoudt", "Dirk", ""]]}, {"id": "1710.06159", "submitter": "Nghi Bui", "authors": "Nghi D. Q. Bui, Lingxiao Jiang, Yijun Yu", "title": "Cross-Language Learning for Program Classification using Bilateral\n  Tree-Based Convolutional Neural Networks", "comments": "Accepted at NL4SE Workshop, AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards the vision of translating code that implements an algorithm from one\nprogramming language into another, this paper proposes an approach for\nautomated program classification using bilateral tree-based convolutional\nneural networks (BiTBCNNs). It is layered on top of two tree-based\nconvolutional neural networks (TBCNNs), each of which recognizes the algorithm\nof code written in an individual programming language. The combination layer of\nthe networks recognizes the similarities and differences among code in\ndifferent programming languages. The BiTBCNNs are trained using the source code\nin different languages but known to implement the same algorithms and/or\nfunctionalities. For a preliminary evaluation, we use 3591 Java and 3534 C++\ncode snippets from 6 algorithms we crawled systematically from GitHub. We\nobtained over 90% accuracy in the cross-language binary classification task to\ntell whether any given two code snippets implement the same algorithm. Also,\nfor the algorithm classification task, i.e., to predict which one of the six\nalgorithm labels is implemented by an arbitrary C++ code snippet, we achieved\nover 80% precision.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 08:37:44 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 20:47:26 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Jiang", "Lingxiao", ""], ["Yu", "Yijun", ""]]}, {"id": "1710.06169", "submitter": "Sarah Tan", "authors": "Sarah Tan, Rich Caruana, Giles Hooker, Yin Lou", "title": "Distill-and-Compare: Auditing Black-Box Models Using Transparent Model\n  Distillation", "comments": "Camera-ready version for AAAI/ACM AIES 2018. Data and pseudocode at\n  https://github.com/shftan/auditblackbox. Previously titled \"Detecting Bias in\n  Black-Box Models Using Transparent Model Distillation\". A short version was\n  presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": "10.1145/3278721.3278725", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box risk scoring models permeate our lives, yet are typically\nproprietary or opaque. We propose Distill-and-Compare, a model distillation and\ncomparison approach to audit such models. To gain insight into black-box\nmodels, we treat them as teachers, training transparent student models to mimic\nthe risk scores assigned by black-box models. We compare the student model\ntrained with distillation to a second un-distilled transparent model trained on\nground-truth outcomes, and use differences between the two models to gain\ninsight into the black-box model. Our approach can be applied in a realistic\nsetting, without probing the black-box model API. We demonstrate the approach\non four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending\nClub. We also propose a statistical test to determine if a data set is missing\nkey features used to train the black-box model. Our test finds that the\nProPublica data is likely missing key feature(s) used in COMPAS.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 08:58:59 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 07:54:17 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 05:25:51 GMT"}, {"version": "v4", "created": "Thu, 11 Oct 2018 07:33:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Tan", "Sarah", ""], ["Caruana", "Rich", ""], ["Hooker", "Giles", ""], ["Lou", "Yin", ""]]}, {"id": "1710.06202", "submitter": "Kevin Cremanns", "authors": "Kevin Cremanns and Dirk Roos", "title": "Deep Gaussian Covariance Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlation length-scale next to the noise variance are the most used\nhyperparameters for the Gaussian processes. Typically, stationary covariance\nfunctions are used, which are only dependent on the distances between input\npoints and thus invariant to the translations in the input space. The\noptimization of the hyperparameters is commonly done by maximizing the log\nmarginal likelihood. This works quite well, if the distances are uniform\ndistributed. In the case of a locally adapted or even sparse input space, the\nprediction of a test point can be worse dependent of its position. A possible\nsolution to this, is the usage of a non-stationary covariance function, where\nthe hyperparameters are calculated by a deep neural network. So that the\ncorrelation length scales and possibly the noise variance are dependent on the\ntest point. Furthermore, different types of covariance functions are trained\nsimultaneously, so that the Gaussian process prediction is an additive overlay\nof different covariance matrices. The right covariance functions combination\nand its hyperparameters are learned by the deep neural network. Additional, the\nGaussian process will be able to be trained by batches or online and so it can\nhandle arbitrarily large data sets. We call this framework Deep Gaussian\nCovariance Network (DGCP). There are also further extensions to this framework\npossible, for example sequentially dependent problems like time series or the\nlocal mixture of experts. The basic framework and some extension possibilities\nwill be presented in this work. Moreover, a comparison to some recent state of\nthe art surrogate model methods will be performed, also for a time dependent\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 10:57:21 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 13:30:35 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Cremanns", "Kevin", ""], ["Roos", "Dirk", ""]]}, {"id": "1710.06219", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Saehoon Kim, Seungjin Choi", "title": "Learning to Warm-Start Bayesian Hyperparameter Optimization", "comments": "14 pages, a preliminary version was presented at NIPS 2017 workshop\n  on Bayesian optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization aims to find the optimal hyperparameter\nconfiguration of a machine learning model, which provides the best performance\non a validation dataset. Manual search usually leads to get stuck in a local\nhyperparameter configuration, and heavily depends on human intuition and\nexperience. A simple alternative of manual search is random/grid search on a\nspace of hyperparameters, which still undergoes extensive evaluations of\nvalidation errors in order to find its best configuration. Bayesian\noptimization that is a global optimization method for black-box functions is\nnow popular for hyperparameter optimization, since it greatly reduces the\nnumber of validation error evaluations required, compared to random/grid\nsearch. Bayesian optimization generally finds the best hyperparameter\nconfiguration from random initialization without any prior knowledge. This\nmotivates us to let Bayesian optimization start from the configurations that\nwere successful on similar datasets, which are able to remarkably minimize the\nnumber of evaluations. In this paper, we propose deep metric learning to learn\nmeta-features over datasets such that the similarity over them is effectively\nmeasured by Euclidean distance between their associated meta-features. To this\nend, we introduce a Siamese network composed of deep feature and meta-feature\nextractors, where deep feature extractor provides a semantic representation of\neach instance in a dataset and meta-feature extractor aggregates a set of deep\nfeatures to encode a single representation over a dataset. Then, our learned\nmeta-features are used to select a few datasets similar to the new dataset, so\nthat hyperparameters in similar datasets are adopted as initializations to\nwarm-start Bayesian hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 11:34:32 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 12:31:26 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 14:37:01 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Kim", "Jungtaek", ""], ["Kim", "Saehoon", ""], ["Choi", "Seungjin", ""]]}, {"id": "1710.06273", "submitter": "Marwa El Halabi", "authors": "Marwa El Halabi, Francis Bach, and Volkan Cevher", "title": "Combinatorial Penalties: Which structures are preserved by convex\n  relaxations?", "comments": null, "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the homogeneous and the non-homogeneous convex relaxations for\ncombinatorial penalty functions defined on support sets. Our study identifies\nkey differences in the tightness of the resulting relaxations through the\nnotion of the lower combinatorial envelope of a set-function along with new\nnecessary conditions for support identification. We then propose a general\nadaptive estimator for convex monotone regularizers, and derive new sufficient\nconditions for support recovery in the asymptotic setting.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:41:21 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 18:02:14 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Halabi", "Marwa El", ""], ["Bach", "Francis", ""], ["Cevher", "Volkan", ""]]}, {"id": "1710.06276", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Vivien Seguy, Antoine Rolet", "title": "Smooth and Sparse Optimal Transport", "comments": "Accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropic regularization is quickly emerging as a new standard in optimal\ntransport (OT). It enables to cast the OT computation as a differentiable and\nunconstrained convex optimization problem, which can be efficiently solved\nusing the Sinkhorn algorithm. However, entropy keeps the transportation plan\nstrictly positive and therefore completely dense, unlike unregularized OT. This\nlack of sparsity can be problematic in applications where the transportation\nplan itself is of interest. In this paper, we explore regularizing the primal\nand dual OT formulations with a strongly convex term, which corresponds to\nrelaxing the dual and primal constraints with smooth approximations. We show\nhow to incorporate squared $2$-norm and group lasso regularizations within that\nframework, leading to sparse and group-sparse transportation plans. On the\ntheoretical side, we bound the approximation error introduced by regularizing\nthe primal and dual formulations. Our results suggest that, for the regularized\nprimal, the approximation error can often be smaller with squared $2$-norm than\nwith entropic regularization. We showcase our proposed framework on the task of\ncolor transfer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:42:37 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 05:51:02 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Blondel", "Mathieu", ""], ["Seguy", "Vivien", ""], ["Rolet", "Antoine", ""]]}, {"id": "1710.06319", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Gaetano Scebba, Jia Zhang, Marco Delai, Walter Karlen", "title": "Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural\n  Networks", "comments": "Accepted at Computing in Cardiology (CinC) 2017", "journal-ref": null, "doi": "10.22489/CinC.2017.363-223", "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With tens of thousands of electrocardiogram (ECG) records processed by mobile\ncardiac event recorders every day, heart rhythm classification algorithms are\nan important tool for the continuous monitoring of patients at risk. We utilise\nan annotated dataset of 12,186 single-lead ECG recordings to build a diverse\nensemble of recurrent neural networks (RNNs) that is able to distinguish\nbetween normal sinus rhythms, atrial fibrillation, other types of arrhythmia\nand signals that are too noisy to interpret. In order to ease learning over the\ntemporal dimension, we introduce a novel task formulation that harnesses the\nnatural segmentation of ECG signals into heartbeats to drastically reduce the\nnumber of time steps per sequence. Additionally, we extend our RNNs with an\nattention mechanism that enables us to reason about which heartbeats our RNNs\nfocus on to make their decisions. Through the use of attention, our model\nmaintains a high degree of interpretability, while also achieving\nstate-of-the-art classification performance with an average F1 score of 0.79 on\nan unseen test set (n=3,658).\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 14:39:17 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 09:51:04 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Schwab", "Patrick", ""], ["Scebba", "Gaetano", ""], ["Zhang", "Jia", ""], ["Delai", "Marco", ""], ["Karlen", "Walter", ""]]}, {"id": "1710.06382", "submitter": "Jerry Chee", "authors": "Jerry Chee and Panos Toulis", "title": "Convergence diagnostics for stochastic gradient descent with constant\n  step size", "comments": "Accepted to Artificial Intelligence and Statistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many iterative procedures in stochastic optimization exhibit a transient\nphase followed by a stationary phase. During the transient phase the procedure\nconverges towards a region of interest, and during the stationary phase the\nprocedure oscillates in that region, commonly around a single point. In this\npaper, we develop a statistical diagnostic test to detect such phase transition\nin the context of stochastic gradient descent with constant learning rate. We\npresent theory and experiments suggesting that the region where the proposed\ndiagnostic is activated coincides with the convergence region. For a class of\nloss functions, we derive a closed-form solution describing such region.\nFinally, we suggest an application to speed up convergence of stochastic\ngradient descent by halving the learning rate each time stationarity is\ndetected. This leads to a new variant of stochastic gradient descent, which in\nmany settings is comparable to state-of-art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:51:16 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 04:31:07 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Chee", "Jerry", ""], ["Toulis", "Panos", ""]]}, {"id": "1710.06390", "submitter": "Maria Glenski", "authors": "Maria Glenski, Ellyn Ayton, Dustin Arendt, and Svitlana Volkova", "title": "Fishing for Clickbaits in Social Images and Texts with\n  Linguistically-Infused Neural Network Models", "comments": "Pineapplefish Clickbait Detector, Clickbait Challenge 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results and conclusions of our participation in the\nClickbait Challenge 2017 on automatic clickbait detection in social media. We\nfirst describe linguistically-infused neural network models and identify\ninformative representations to predict the level of clickbaiting present in\nTwitter posts. Our models allow to answer the question not only whether a post\nis a clickbait or not, but to what extent it is a clickbait post e.g., not at\nall, slightly, considerably, or heavily clickbaity using a score ranging from 0\nto 1. We evaluate the predictive power of models trained on varied text and\nimage representations extracted from tweets. Our best performing model that\nrelies on the tweet text and linguistic markers of biased language extracted\nfrom the tweet and the corresponding page yields mean squared error (MSE) of\n0.04, mean absolute error (MAE) of 0.16 and R2 of 0.43 on the held-out test\ndata. For the binary classification setup (clickbait vs. non-clickbait), our\nmodel achieved F1 score of 0.69. We have not found that image representations\ncombined with text yield significant performance improvement yet. Nevertheless,\nthis work is the first to present preliminary analysis of objects extracted\nusing Google Tensorflow object detection API from images in clickbait vs.\nnon-clickbait Twitter posts. Finally, we outline several steps to improve model\nperformance as a part of the future work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:00:59 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Glenski", "Maria", ""], ["Ayton", "Ellyn", ""], ["Arendt", "Dustin", ""], ["Volkova", "Svitlana", ""]]}, {"id": "1710.06422", "submitter": "Kuan Fang", "authors": "Kuan Fang, Yunfei Bai, Stefan Hinterstoisser, Silvio Savarese, Mrinal\n  Kalakrishnan", "title": "Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from\n  Simulation", "comments": "ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches to robotic manipulation are limited by the\nscalability of data collection and accessibility of labels. In this paper, we\npresent a multi-task domain adaptation framework for instance grasping in\ncluttered scenes by utilizing simulated robot experiments. Our neural network\ntakes monocular RGB images and the instance segmentation mask of a specified\ntarget object as inputs, and predicts the probability of successfully grasping\nthe specified object for each candidate motor command. The proposed transfer\nlearning framework trains a model for instance grasping in simulation and uses\na domain-adversarial loss to transfer the trained model to real robots using\nindiscriminate grasping data, which is available both in simulation and the\nreal world. We evaluate our model in real-world robot experiments, comparing it\nwith alternative model architectures as well as an indiscriminate grasping\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:54:50 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 04:08:58 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Fang", "Kuan", ""], ["Bai", "Yunfei", ""], ["Hinterstoisser", "Stefan", ""], ["Savarese", "Silvio", ""], ["Kalakrishnan", "Mrinal", ""]]}, {"id": "1710.06425", "submitter": "Joshua Tobin", "authors": "Joshua Tobin, Lukas Biewald, Rocky Duan, Marcin Andrychowicz, Ankur\n  Handa, Vikash Kumar, Bob McGrew, Jonas Schneider, Peter Welinder, Wojciech\n  Zaremba, Pieter Abbeel", "title": "Domain Randomization and Generative Models for Robotic Grasping", "comments": "8 pages, 11 figures. Submitted to 2018 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based robotic grasping has made significant progress thanks to\nalgorithmic improvements and increased data availability. However,\nstate-of-the-art models are often trained on as few as hundreds or thousands of\nunique object instances, and as a result generalization can be a challenge.\n  In this work, we explore a novel data generation pipeline for training a deep\nneural network to perform grasp planning that applies the idea of domain\nrandomization to object synthesis. We generate millions of unique, unrealistic\nprocedurally generated objects, and train a deep neural network to perform\ngrasp planning on these objects.\n  Since the distribution of successful grasps for a given object can be highly\nmultimodal, we propose an autoregressive grasp planning model that maps sensor\ninputs of a scene to a probability distribution over possible grasps. This\nmodel allows us to sample grasps efficiently at test time (or avoid sampling\nentirely).\n  We evaluate our model architecture and data generation pipeline in simulation\nand the real world. We find we can achieve a $>$90% success rate on previously\nunseen realistic objects at test time in simulation despite having only been\ntrained on random objects. We also demonstrate an 80% success rate on\nreal-world grasp attempts despite having only been trained on random simulated\nobjects.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 17:56:53 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 05:03:46 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Tobin", "Joshua", ""], ["Biewald", "Lukas", ""], ["Duan", "Rocky", ""], ["Andrychowicz", "Marcin", ""], ["Handa", "Ankur", ""], ["Kumar", "Vikash", ""], ["McGrew", "Bob", ""], ["Schneider", "Jonas", ""], ["Welinder", "Peter", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1710.06451", "submitter": "Samuel L. Smith", "authors": "Samuel L. Smith and Quoc V. Le", "title": "A Bayesian Perspective on Generalization and Stochastic Gradient Descent", "comments": "13 pages, 9 figures. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two questions at the heart of machine learning; how can we\npredict if a minimum will generalize to the test set, and why does stochastic\ngradient descent find minima that generalize well? Our work responds to Zhang\net al. (2016), who showed deep neural networks can easily memorize randomly\nlabeled training data, despite generalizing well on real labels of the same\ninputs. We show that the same phenomenon occurs in small linear models. These\nobservations are explained by the Bayesian evidence, which penalizes sharp\nminima but is invariant to model parameterization. We also demonstrate that,\nwhen one holds the learning rate fixed, there is an optimum batch size which\nmaximizes the test set accuracy. We propose that the noise introduced by small\nmini-batches drives the parameters towards minima whose evidence is large.\nInterpreting stochastic gradient descent as a stochastic differential equation,\nwe identify the \"noise scale\" $g = \\epsilon (\\frac{N}{B} - 1) \\approx \\epsilon\nN/B$, where $\\epsilon$ is the learning rate, $N$ the training set size and $B$\nthe batch size. Consequently the optimum batch size is proportional to both the\nlearning rate and the size of the training set, $B_{opt} \\propto \\epsilon N$.\nWe verify these predictions empirically.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:08:04 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 22:07:53 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 19:42:20 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Smith", "Samuel L.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1710.06462", "submitter": "Suchismit Mahapatra", "authors": "Suchismit Mahapatra, Varun Chandola", "title": "S-Isomap++: Multi Manifold Learning from Streaming Data", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2017.8257987", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning based methods have been widely used for non-linear\ndimensionality reduction (NLDR). However, in many practical settings, the need\nto process streaming data is a challenge for such methods, owing to the high\ncomputational complexity involved. Moreover, most methods operate under the\nassumption that the input data is sampled from a single manifold, embedded in a\nhigh dimensional space. We propose a method for streaming NLDR when the\nobserved data is either sampled from multiple manifolds or irregularly sampled\nfrom a single manifold. We show that existing NLDR methods, such as Isomap,\nfail in such situations, primarily because they rely on smoothness and\ncontinuity of the underlying manifold, which is violated in the scenarios\nexplored in this paper. However, the proposed algorithm is able to learn\neffectively in presence of multiple, and potentially intersecting, manifolds,\nwhile allowing for the input data to arrive as a massive stream.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:30:57 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 01:08:19 GMT"}, {"version": "v3", "created": "Sat, 17 Mar 2018 23:20:39 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mahapatra", "Suchismit", ""], ["Chandola", "Varun", ""]]}, {"id": "1710.06463", "submitter": "Rania Rayyes", "authors": "Rania Rayyes, Daniel Kubus, Carsten Hartmann and Jochen Steil", "title": "Learning Inverse Statics Models Efficiently", "comments": null, "journal-ref": null, "doi": "10.3389/fnbot.2018.00068", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Goal Babbling and Direction Sampling are recently proposed methods for\ndirect learning of inverse kinematics mappings from scratch even in\nhigh-dimensional sensorimotor spaces following the paradigm of \"learning while\nbehaving\". To learn inverse statics mappings - primarily for gravity\ncompensation - from scratch and without using any closed-loop controller, we\nmodify and enhance the Online Goal Babbling and Direction Sampling schemes.\nMoreover, we exploit symmetries in the inverse statics mappings to drastically\nreduce the number of samples required for learning inverse statics models.\nResults for a 2R planar robot, a 3R simplified human arm, and a 4R humanoid\nrobot arm clearly demonstrate that their inverse statics mappings can be\nlearned successfully with our modified online Goal Babbling scheme.\nFurthermore, we show that the number of samples required for the 2R and 3R arms\ncan be reduced by a factor of at least 8 and 16 resp. -depending on the number\nof discovered symmetries.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:35:29 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Rayyes", "Rania", ""], ["Kubus", "Daniel", ""], ["Hartmann", "Carsten", ""], ["Steil", "Jochen", ""]]}, {"id": "1710.06471", "submitter": "Qian Yu", "authors": "Qian Yu, Mohammad Ali Maddah-Ali, and A. Salman Avestimehr", "title": "Coded Fourier Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the Fourier transform of\nhigh-dimensional vectors, distributedly over a cluster of machines consisting\nof a master node and multiple worker nodes, where the worker nodes can only\nstore and process a fraction of the inputs. We show that by exploiting the\nalgebraic structure of the Fourier transform operation and leveraging concepts\nfrom coding theory, one can efficiently deal with the straggler effects. In\nparticular, we propose a computation strategy, named as coded FFT, which\nachieves the optimal recovery threshold, defined as the minimum number of\nworkers that the master node needs to wait for in order to compute the output.\nThis is the first code that achieves the optimum robustness in terms of\ntolerating stragglers or failures for computing Fourier transforms.\nFurthermore, the reconstruction process for coded FFT can be mapped to MDS\ndecoding, which can be solved efficiently. Moreover, we extend coded FFT to\nsettings including computing general $n$-dimensional Fourier transforms, and\nprovide the optimal computing strategy for those settings.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:57:52 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Yu", "Qian", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1710.06514", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw and Jesse H. Krijthe and Marco Loog", "title": "Robust importance-weighted cross-validation under sample selection bias", "comments": "6 pages, 8 figures, Accepted to the IEEE International Workshop on\n  Machine Learning for Signal Processing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation under sample selection bias can, in principle, be done by\nimportance-weighting the empirical risk. However, the importance-weighted risk\nestimator produces sub-optimal hyperparameter estimates in problem settings\nwhere large weights arise with high probability. We study its sampling variance\nas a function of the training data distribution and introduce a control variate\nto increase its robustness to problematically large weights.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 22:10:07 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 14:27:57 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 10:56:45 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Krijthe", "Jesse H.", ""], ["Loog", "Marco", ""]]}, {"id": "1710.06520", "submitter": "Evgeniy Faerman", "authors": "Evgeniy Faerman, Felix Borutta, Kimon Fountoulakis, Michael W. Mahoney", "title": "LASAGNE: Locality And Structure Aware Graph Node Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose Lasagne, a methodology to learn locality and\nstructure aware graph node embeddings in an unsupervised way. In particular, we\nshow that the performance of existing random-walk based approaches depends\nstrongly on the structural properties of the graph, e.g., the size of the\ngraph, whether the graph has a flat or upward-sloping Network Community Profile\n(NCP), whether the graph is expander-like, whether the classes of interest are\nmore k-core-like or more peripheral, etc. For larger graphs with flat NCPs that\nare strongly expander-like, existing methods lead to random walks that expand\nrapidly, touching many dissimilar nodes, thereby leading to lower-quality\nvector representations that are less useful for downstream tasks. Rather than\nrelying on global random walks or neighbors within fixed hop distances, Lasagne\nexploits strongly local Approximate Personalized PageRank stationary\ndistributions to more precisely engineer local information into node\nembeddings. This leads, in particular, to more meaningful and more useful\nvector representations of nodes in poorly-structured graphs. We show that\nLasagne leads to significant improvement in downstream multi-label\nclassification for larger graphs with flat NCPs, that it is comparable for\nsmaller graphs with upward-sloping NCPs, and that is comparable to existing\nmethods for link prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 22:44:18 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Faerman", "Evgeniy", ""], ["Borutta", "Felix", ""], ["Fountoulakis", "Kimon", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1710.06542", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, Marcin Andrychowicz, Peter Welinder, Wojciech Zaremba,\n  Pieter Abbeel", "title": "Asymmetric Actor Critic for Image-Based Robot Learning", "comments": "Videos of experiments can be found at http://www.goo.gl/b57WTs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has proven a powerful technique in many\nsequential decision making domains. However, Robotics poses many challenges for\nRL, most notably training on a physical system can be expensive and dangerous,\nwhich has sparked significant interest in learning control policies using a\nphysics simulator. While several recent works have shown promising results in\ntransferring policies trained in simulation to the real world, they often do\nnot fully utilize the advantage of working with a simulator. In this work, we\nexploit the full state observability in the simulator to train better policies\nwhich take as input only partial observations (RGBD images). We do this by\nemploying an actor-critic training algorithm in which the critic is trained on\nfull states while the actor (or policy) gets rendered images as input. We show\nexperimentally on a range of simulated tasks that using these asymmetric inputs\nsignificantly improves performance. Finally, we combine this method with domain\nrandomization and show real robot experiments for several tasks like picking,\npushing, and moving a block. We achieve this simulation to real world transfer\nwithout training on any real world data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 01:10:37 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Pinto", "Lerrel", ""], ["Andrychowicz", "Marcin", ""], ["Welinder", "Peter", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1710.06564", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Hamed Haddadi", "title": "Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data\n  Analysis", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": "10.1109/IoTDI.2018.00025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of sensors on mobile, Internet of things (IoT), and\nwearable devices generate time-series measurements of physical activities.\nThough access to the sensory data is critical to the success of many beneficial\napplications such as health monitoring or activity recognition, a wide range of\npotentially sensitive information about the individuals can also be discovered\nthrough access to sensory data and this cannot easily be protected using\ntraditional privacy approaches.\n  In this paper, we propose a privacy-preserving sensing framework for managing\naccess to time-series data in order to provide utility while protecting\nindividuals' privacy. We introduce Replacement AutoEncoder, a novel algorithm\nwhich learns how to transform discriminative features of data that correspond\nto sensitive inferences, into some features that have been more observed in\nnon-sensitive inferences, to protect users' privacy. This efficiency is\nachieved by defining a user-customized objective function for deep\nautoencoders. Our replacement method will not only eliminate the possibility of\nrecognizing sensitive inferences, it also eliminates the possibility of\ndetecting the occurrence of them. That is the main weakness of other approaches\nsuch as filtering or randomization. We evaluate the efficacy of the algorithm\nwith an activity recognition task in a multi-sensing environment using\nextensive experiments on three benchmark datasets. We show that it can retain\nthe recognition accuracy of state-of-the-art techniques while simultaneously\npreserving the privacy of sensitive information. Finally, we utilize the GANs\nfor detecting the occurrence of replacement, after releasing data, and show\nthat this can be done only if the adversarial network is trained on the users'\noriginal data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 02:45:44 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 14:09:05 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 12:45:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1710.06570", "submitter": "Samuel Schoenholz", "authors": "Samuel S. Schoenholz, Jeffrey Pennington and Jascha Sohl-Dickstein", "title": "A Correspondence Between Random Neural Networks and Statistical Field\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent papers have provided evidence that practical design\nquestions about neural networks may be tackled theoretically by studying the\nbehavior of random networks. However, until now the tools available for\nanalyzing random neural networks have been relatively ad-hoc. In this work, we\nshow that the distribution of pre-activations in random neural networks can be\nexactly mapped onto lattice models in statistical physics. We argue that\nseveral previous investigations of stochastic networks actually studied a\nparticular factorial approximation to the full lattice model. For random linear\nnetworks and random rectified linear networks we show that the corresponding\nlattice models in the wide network limit may be systematically approximated by\na Gaussian distribution with covariance between the layers of the network. In\neach case, the approximate distribution can be diagonalized by Fourier\ntransformation. We show that this approximation accurately describes the\nresults of numerical simulations of wide random neural networks. Finally, we\ndemonstrate that in each case the large scale behavior of the random networks\ncan be approximated by an effective field theory.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 03:05:47 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Schoenholz", "Samuel S.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1710.06574", "submitter": "Ruishan Liu", "authors": "Ruishan Liu, James Zou", "title": "The Effects of Memory Replay in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is a key technique behind many recent advances in deep\nreinforcement learning. Allowing the agent to learn from earlier memories can\nspeed up learning and break undesirable temporal correlations. Despite its\nwide-spread application, very little is understood about the properties of\nexperience replay. How does the amount of memory kept affect learning dynamics?\nDoes it help to prioritize certain experiences? In this paper, we address these\nquestions by formulating a dynamical systems ODE model of Q-learning with\nexperience replay. We derive analytic solutions of the ODE for a simple\nsetting. We show that even in this very simple setting, the amount of memory\nkept can substantially affect the agent's performance. Too much or too little\nmemory both slow down learning. Moreover, we characterize regimes where\nprioritized replay harms the agent's learning. We show that our analytic\nsolutions have excellent agreement with experiments. Finally, we propose a\nsimple algorithm for adaptively changing the memory buffer size which achieves\nconsistently good empirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 03:19:55 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Liu", "Ruishan", ""], ["Zou", "James", ""]]}, {"id": "1710.06582", "submitter": "Xiaoming Zhang", "authors": "Feiran Huang, Xiaoming Zhang, Zhoujun Li, Tao Mei, Yueying He,\n  Zhonghua Zhao", "title": "Learning Social Image Embedding with Deep Multimodal Attention Networks", "comments": null, "journal-ref": "Proceedings of Thematic Workshops of the 25th ACM Multimedia 2017", "doi": "10.1145/3126686.3126720", "report-no": null, "categories": "cs.MM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning social media data embedding by deep models has attracted extensive\nresearch interest as well as boomed a lot of applications, such as link\nprediction, classification, and cross-modal search. However, for social images\nwhich contain both link information and multimodal contents (e.g., text\ndescription, and visual content), simply employing the embedding learnt from\nnetwork structure or data content results in sub-optimal social image\nrepresentation. In this paper, we propose a novel social image embedding\napproach called Deep Multimodal Attention Networks (DMAN), which employs a deep\nmodel to jointly embed multimodal contents and link information. Specifically,\nto effectively capture the correlations between multimodal contents, we propose\na multimodal attention network to encode the fine-granularity relation between\nimage regions and textual words. To leverage the network structure for\nembedding learning, a novel Siamese-Triplet neural network is proposed to model\nthe links among images. With the joint deep model, the learnt embedding can\ncapture both the multimodal contents and the nonlinear network information.\nExtensive experiments are conducted to investigate the effectiveness of our\napproach in the applications of multi-label classification and cross-modal\nsearch. Compared to state-of-the-art image embeddings, our proposed DMAN\nachieves significant improvement in the tasks of multi-label classification and\ncross-modal search.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 04:28:20 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Huang", "Feiran", ""], ["Zhang", "Xiaoming", ""], ["Li", "Zhoujun", ""], ["Mei", "Tao", ""], ["He", "Yueying", ""], ["Zhao", "Zhonghua", ""]]}, {"id": "1710.06703", "submitter": "Amal Rannen Triki", "authors": "Amal Rannen Triki, Maxim Berman and Matthew B. Blaschko", "title": "Function Norms and Regularization in Deep Networks", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become increasingly important due to their\nexcellent empirical performance on a wide range of problems. However,\nregularization is generally achieved by indirect means, largely due to the\ncomplex set of functions defined by a network and the difficulty in measuring\nfunction complexity. There exists no method in the literature for additive\nregularization based on a norm of the function, as is classically considered in\nstatistical learning theory. In this work, we propose sampling-based\napproximations to weighted function norms as regularizers for deep neural\nnetworks. We provide, to the best of our knowledge, the first proof in the\nliterature of the NP-hardness of computing function norms of DNNs, motivating\nthe necessity of an approximate approach. We then derive a generalization bound\nfor functions trained with weighted norms and prove that a natural stochastic\noptimization strategy minimizes the bound. Finally, we empirically validate the\nimproved performance of the proposed regularization strategies for both convex\nfunction sets as well as DNNs on real-world classification and image\nsegmentation tasks demonstrating improved performance over weight decay,\ndropout, and batch normalization. Source code will be released at the time of\npublication.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 12:43:01 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 23:21:55 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Triki", "Amal Rannen", ""], ["Berman", "Maxim", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "1710.06763", "submitter": "Debasish Chatterjee", "authors": "Mohammed Rayyan Sheriff and Debasish Chatterjee", "title": "A complete characterization of optimal dictionaries for least squares\n  representation", "comments": "36 pages", "journal-ref": "Journal of Machine Learning Research, Vol 18, Paper No. 107,\n  1--28, 2017", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionaries are collections of vectors used for representations of elements\nin Euclidean spaces. While recent research on optimal dictionaries is focussed\non providing sparse (i.e., $\\ell_0$-optimal,) representations, here we consider\nthe problem of finding optimal dictionaries such that representations of\nsamples of a random vector are optimal in an $\\ell_2$-sense. For us, optimality\nof representation is equivalent to minimization of the average $\\ell_2$-norm of\nthe coefficients used to represent the random vector, with the lengths of the\ndictionary vectors being specified a priori. With the help of recent results on\nrank-$1$ decompositions of symmetric positive semidefinite matrices and the\ntheory of majorization, we provide a complete characterization of\n$\\ell_2$-optimal dictionaries. Our results are accompanied by polynomial time\nalgorithms that construct $\\ell_2$-optimal dictionaries from given data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 14:59:58 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Sheriff", "Mohammed Rayyan", ""], ["Chatterjee", "Debasish", ""]]}, {"id": "1710.06766", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett and Volkan Cevher", "title": "Phase Transitions in the Pooled Data Problem", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the pooled data problem of identifying the labels\nassociated with a large collection of items, based on a sequence of pooled\ntests revealing the counts of each label within the pool. In the noiseless\nsetting, we identify an exact asymptotic threshold on the required number of\ntests with optimal decoding, and prove a phase transition between complete\nsuccess and complete failure. In addition, we present a novel noisy variation\nof the problem, and provide an information-theoretic framework for\ncharacterizing the required number of tests for general random noise models.\nOur results reveal that noise can make the problem considerably more difficult,\nwith strict increases in the scaling laws even at low noise levels. Finally, we\ndemonstrate similar behavior in an approximate recovery setting, where a given\nnumber of errors is allowed in the decoded labels.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 15:04:48 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1710.06798", "submitter": "Sael Lee", "authors": "Jaya Thomas, Sonia Thomas, Lee Sael", "title": "Feature versus Raw Sequence: Deep Learning Comparative Study on\n  Predicting Pre-miRNA", "comments": "12 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1704.03834", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Should we input known genome sequence features or input sequence itself in\ndeep learning framework? As deep learning more popular in various applications,\nresearchers often come to question whether to generate features or use raw\nsequences for deep learning. To answer this question, we study the prediction\naccuracy of precursor miRNA prediction of feature-based deep belief network and\nsequence-based convolution neural network. Tested on a variant of six-layer\nconvolution neural net and three-layer deep belief network, we find the raw\nsequence input based convolution neural network model performs similar or\nslightly better than feature based deep belief networks with best accuracy\nvalues of 0.995 and 0.990, respectively. Both the models outperform existing\nbenchmarks models. The results shows us that if provided large enough data,\nwell devised raw sequence based deep learning models can replace feature based\ndeep learning models. However, construction of well behaved deep learning model\ncan be very challenging. In cased features can be easily extracted,\nfeature-based deep learning models may be a better alternative.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 14:09:00 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Thomas", "Jaya", ""], ["Thomas", "Sonia", ""], ["Sael", "Lee", ""]]}, {"id": "1710.06815", "submitter": "Mohammad Raji", "authors": "Mohammad Raji, Alok Hota, Robert Sisneros, Peter Messmer, Jian Huang", "title": "Photo-Guided Exploration of Volume Data Features", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we pose the question of whether, by considering qualitative\ninformation such as a sample target image as input, one can produce a rendered\nimage of scientific data that is similar to the target. The algorithm resulting\nfrom our research allows one to ask the question of whether features like those\nin the target image exists in a given dataset. In that way, our method is one\nof imagery query or reverse engineering, as opposed to manual parameter\ntweaking of the full visualization pipeline. For target images, we can use\nreal-world photographs of physical phenomena. Our method leverages deep neural\nnetworks and evolutionary optimization. Using a trained similarity function\nthat measures the difference between renderings of a phenomenon and real-world\nphotographs, our method optimizes rendering parameters. We demonstrate the\nefficacy of our method using a superstorm simulation dataset and images found\nonline. We also discuss a parallel implementation of our method, which was run\non NCSA's Blue Waters.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 16:28:08 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Raji", "Mohammad", ""], ["Hota", "Alok", ""], ["Sisneros", "Robert", ""], ["Messmer", "Peter", ""], ["Huang", "Jian", ""]]}, {"id": "1710.06832", "submitter": "James P. Crutchfield", "authors": "James P. Crutchfield", "title": "The Origins of Computational Mechanics: A Brief Intellectual History and\n  Several Clarifications", "comments": "11 pages, 123 citations;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/cmr.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT cs.LG math.IT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle goal of computational mechanics is to define pattern and\nstructure so that the organization of complex systems can be detected and\nquantified. Computational mechanics developed from efforts in the 1970s and\nearly 1980s to identify strange attractors as the mechanism driving weak fluid\nturbulence via the method of reconstructing attractor geometry from measurement\ntime series and in the mid-1980s to estimate equations of motion directly from\ncomplex time series. In providing a mathematical and operational definition of\nstructure it addressed weaknesses of these early approaches to discovering\npatterns in natural systems.\n  Since then, computational mechanics has led to a range of results from\ntheoretical physics and nonlinear mathematics to diverse applications---from\nclosed-form analysis of Markov and non-Markov stochastic processes that are\nergodic or nonergodic and their measures of information and intrinsic\ncomputation to complex materials and deterministic chaos and intelligence in\nMaxwellian demons to quantum compression of classical processes and the\nevolution of computation and language.\n  This brief review clarifies several misunderstandings and addresses concerns\nrecently raised regarding early works in the field (1980s). We show that\nmisguided evaluations of the contributions of computational mechanics are\ngroundless and stem from a lack of familiarity with its basic goals and from a\nfailure to consider its historical context. For all practical purposes, its\nmodern methods and results largely supersede the early works. This not only\nrenders recent criticism moot and shows the solid ground on which computational\nmechanics stands but, most importantly, shows the significant progress achieved\nover three decades and points to the many intriguing and outstanding challenges\nin understanding the computational nature of complex dynamic systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 17:21:20 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Crutchfield", "James P.", ""]]}, {"id": "1710.06835", "submitter": "Jorge Silva", "authors": "Jorge F. Silva", "title": "Shannon Entropy Estimation in $\\infty$-Alphabets from Convergence\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Shannon entropy estimation in countable infinite alphabets is\naddressed from the study and use of convergence results of the entropy\nfunctional, which is known to be discontinuous with respect to the total\nvariation distance in $\\infty$-alphabets. Sufficient conditions for the\nconvergence of the entropy are used, including scenarios with both finitely and\ninfinitely supported assumptions on the distributions. From this new\nperspective, four plug-in histogram-based estimators are studied showing that\nconvergence results are instrumental to derive new strong consistency and rate\nof convergences results. Different scenarios and conditions are used on both\nthe estimators and the underlying distribution, considering for example finite\nand unknown supported assumptions and summable tail bounded conditions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 19:54:18 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 17:07:00 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Silva", "Jorge F.", ""]]}, {"id": "1710.06900", "submitter": "Feras Saad", "authors": "Feras A. Saad, Vikash K. Mansinghka", "title": "Temporally-Reweighted Chinese Restaurant Process Mixtures for\n  Clustering, Imputing, and Forecasting Multivariate Time Series", "comments": "19 pages, 10 figures, 2 tables. Appearing in AISTATS 2018", "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics, PMLR 84:755-764, 2018", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a Bayesian nonparametric method for forecasting,\nimputation, and clustering in sparsely observed, multivariate time series data.\nThe method is appropriate for jointly modeling hundreds of time series with\nwidely varying, non-stationary dynamics. Given a collection of $N$ time series,\nthe Bayesian model first partitions them into independent clusters using a\nChinese restaurant process prior. Within a cluster, all time series are modeled\njointly using a novel \"temporally-reweighted\" extension of the Chinese\nrestaurant process mixture. Markov chain Monte Carlo techniques are used to\nobtain samples from the posterior distribution, which are then used to form\npredictive inferences. We apply the technique to challenging forecasting and\nimputation tasks using seasonal flu data from the US Center for Disease Control\nand Prevention, demonstrating superior forecasting accuracy and competitive\nimputation accuracy as compared to multiple widely used baselines. We further\nshow that the model discovers interpretable clusters in datasets with hundreds\nof time series, using macroeconomic data from the Gapminder Foundation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 19:17:43 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 21:13:18 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Saad", "Feras A.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1710.06910", "submitter": "Yi Zhou", "authors": "Yi Zhou and Yingbin Liang", "title": "Characterization of Gradient Dominance and Regularity Conditions for\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has witnessed a successful application of deep learning to\nsolving many challenging problems in machine learning and artificial\nintelligence. However, the loss functions of deep neural networks (especially\nnonlinear networks) are still far from being well understood from a theoretical\naspect. In this paper, we enrich the current understanding of the landscape of\nthe square loss functions for three types of neural networks. Specifically,\nwhen the parameter matrices are square, we provide an explicit characterization\nof the global minimizers for linear networks, linear residual networks, and\nnonlinear networks with one hidden layer. Then, we establish two quadratic\ntypes of landscape properties for the square loss of these neural networks,\ni.e., the gradient dominance condition within the neighborhood of their full\nrank global minimizers, and the regularity condition along certain directions\nand within the neighborhood of their global minimizers. These two landscape\nproperties are desirable for the optimization around the global minimizers of\nthe loss function for these neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 19:53:57 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 14:49:30 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1710.06940", "submitter": "Yunwen Xu", "authors": "Yunwen Xu, Rui Xu, Weizhong Yan, Paul Ardis", "title": "Concept Drift Learning with Alternating Learners", "comments": null, "journal-ref": "Y. Xu, R. Xu, W. Yan and P. Ardis, \"Concept drift learning with\n  alternating learners,\" 2017 International Joint Conference on Neural Networks\n  (IJCNN), Anchorage, AK, 2017, pp. 2104-2111", "doi": "10.1109/IJCNN.2017.7966108", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven predictive analytics are in use today across a number of\nindustrial applications, but further integration is hindered by the requirement\nof similarity among model training and test data distributions. This paper\naddresses the need of learning from possibly nonstationary data streams, or\nunder concept drift, a commonly seen phenomenon in practical applications. A\nsimple dual-learner ensemble strategy, alternating learners framework, is\nproposed. A long-memory model learns stable concepts from a long relevant time\nwindow, while a short-memory model learns transient concepts from a small\nrecent window. The difference in prediction performance of these two models is\nmonitored and induces an alternating policy to select, update and reset the two\nmodels. The method features an online updating mechanism to maintain the\nensemble accuracy, and a concept-dependent trigger to focus on relevant data.\nThrough empirical studies the method demonstrates effective tracking and\nprediction when the steaming data carry abrupt and/or gradual changes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 21:13:36 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Xu", "Yunwen", ""], ["Xu", "Rui", ""], ["Yan", "Weizhong", ""], ["Ardis", "Paul", ""]]}, {"id": "1710.06943", "submitter": "Andrew Feit", "authors": "Andrew Feit and Berenice Mettler", "title": "First-Person Perceptual Guidance Behavior Decomposition using Active\n  Constraint Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans exhibit a wide range of adaptive and robust dynamic motion behavior\nthat is yet unmatched by autonomous control systems. These capabilities are\nessential for real-time behavior generation in cluttered environments. Recent\nwork suggests that human capabilities rely on task structure learning and\nembedded or ecological cognition in the form of perceptual guidance. This paper\ndescribes the experimental investigation of the functional elements of human\nmotion guidance, focusing on the control and perceptual mechanisms. The motion,\ncontrol, and perceptual data from first-person guidance experiments is\ndecomposed into elemental segments based on invariants. These elements are then\nanalyzed to determine their functional characteristics. The resulting model\nexplains the structure of the agent-environment interaction and provides lawful\ndescriptions of specific perceptual guidance and control mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 21:26:41 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Feit", "Andrew", ""], ["Mettler", "Berenice", ""]]}, {"id": "1710.06952", "submitter": "Xiangru Lian", "authors": "Xiangru Lian, Wei Zhang, Ce Zhang, Ji Liu", "title": "Asynchronous Decentralized Parallel Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most commonly used distributed machine learning systems are either\nsynchronous or centralized asynchronous. Synchronous algorithms like\nAllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous\nalgorithms using a parameter server suffer from 1) communication bottleneck at\nparameter servers when workers are many, and 2) significantly worse convergence\nwhen the traffic to parameter server is congested. Can we design an algorithm\nthat is robust in a heterogeneous environment, while being communication\nefficient and maintaining the best-possible convergence rate? In this paper, we\npropose an asynchronous decentralized stochastic gradient decent algorithm\n(AD-PSGD) satisfying all above expectations. Our theoretical analysis shows\nAD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear\nspeedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of\ndecentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and\nstandard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a\nheterogeneous environment. When training ResNet-50 on ImageNet with up to 128\nGPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each\nepoch can be up to 4-8X faster than its synchronous counterparts in a\nnetwork-sharing HPC environment. To the best of our knowledge, AD-PSGD is the\nfirst asynchronous algorithm that achieves a similar epoch-wise convergence\nrate as AllReduce-SGD, at an over 100-GPU scale.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 22:44:03 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 00:39:36 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2018 00:25:58 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lian", "Xiangru", ""], ["Zhang", "Wei", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1710.06963", "submitter": "Hugh Brendan McMahan", "authors": "H. Brendan McMahan, Daniel Ramage, Kunal Talwar, Li Zhang", "title": "Learning Differentially Private Recurrent Language Models", "comments": "Camera-ready ICLR 2018 version, minor edits from previous", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that it is possible to train large recurrent language models\nwith user-level differential privacy guarantees with only a negligible cost in\npredictive accuracy. Our work builds on recent advances in the training of deep\nnetworks on user-partitioned data and privacy accounting for stochastic\ngradient descent. In particular, we add user-level privacy protection to the\nfederated averaging algorithm, which makes \"large step\" updates from user-level\ndata. Our work demonstrates that given a dataset with a sufficiently large\nnumber of users (a requirement easily met by even small internet-scale\ndatasets), achieving differential privacy comes at the cost of increased\ncomputation, rather than in decreased utility as in most prior work. We find\nthat our private LSTM language models are quantitatively and qualitatively\nsimilar to un-noised models when trained on a large dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 23:46:57 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 17:47:52 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 00:40:30 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["McMahan", "H. Brendan", ""], ["Ramage", "Daniel", ""], ["Talwar", "Kunal", ""], ["Zhang", "Li", ""]]}, {"id": "1710.07016", "submitter": "Renzhi Cao", "authors": "Renzhi Cao, Colton Freitas, Leong Chan, Miao Sun, Haiqing Jiang,\n  Zhangxin Chen", "title": "ProLanGO: Protein Function Prediction Using Neural~Machine Translation\n  Based on a Recurrent Neural Network", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the development of next generation sequencing techniques, it is fast and\ncheap to determine protein sequences but relatively slow and expensive to\nextract useful information from protein sequences because of limitations of\ntraditional biological experimental techniques. Protein function prediction has\nbeen a long standing challenge to fill the gap between the huge amount of\nprotein sequences and the known function. In this paper, we propose a novel\nmethod to convert the protein function problem into a language translation\nproblem by the new proposed protein sequence language \"ProLan\" to the protein\nfunction language \"GOLan\", and build a neural machine translation model based\non recurrent neural networks to translate \"ProLan\" language to \"GOLan\"\nlanguage. We blindly tested our method by attending the latest third Critical\nAssessment of Function Annotation (CAFA 3) in 2016, and also evaluate the\nperformance of our methods on selected proteins whose function was released\nafter CAFA competition. The good performance on the training and testing\ndatasets demonstrates that our new proposed method is a promising direction for\nprotein function prediction. In summary, we first time propose a method which\nconverts the protein function prediction problem to a language translation\nproblem and applies a neural machine translation model for protein function\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 06:48:38 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Cao", "Renzhi", ""], ["Freitas", "Colton", ""], ["Chan", "Leong", ""], ["Sun", "Miao", ""], ["Jiang", "Haiqing", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1710.07110", "submitter": "Dawit Mureja Argaw", "authors": "Dawit Mureja, Hyunsin Park, Chang D. Yoo", "title": "Meta-Learning via Feature-Label Memory Network", "comments": "https://github.com/Dawitmu/Meta-Learning-via-Feature-Label-Memory-Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning typically requires training a very capable architecture using\nlarge datasets. However, many important learning problems demand an ability to\ndraw valid inferences from small size datasets, and such problems pose a\nparticular challenge for deep learning. In this regard, various researches on\n\"meta-learning\" are being actively conducted. Recent work has suggested a\nMemory Augmented Neural Network (MANN) for meta-learning. MANN is an\nimplementation of a Neural Turing Machine (NTM) with the ability to rapidly\nassimilate new data in its memory, and use this data to make accurate\npredictions. In models such as MANN, the input data samples and their\nappropriate labels from previous step are bound together in the same memory\nlocations. This often leads to memory interference when performing a task as\nthese models have to retrieve a feature of an input from a certain memory\nlocation and read only the label information bound to that location. In this\npaper, we tried to address this issue by presenting a more robust MANN. We\nrevisited the idea of meta-learning and proposed a new memory augmented neural\nnetwork by explicitly splitting the external memory into feature and label\nmemories. The feature memory is used to store the features of input data\nsamples and the label memory stores their labels. Hence, when predicting the\nlabel of a given input, our model uses its feature memory unit as a reference\nto extract the stored feature of the input, and based on that feature, it\nretrieves the label information of the input from the label memory unit. In\norder for the network to function in this framework, a new memory-writingmodule\nto encode label information into the label memory in accordance with the\nmeta-learning task structure is designed. Here, we demonstrate that our model\noutperforms MANN by a large margin in supervised one-shot classification tasks\nusing Omniglot and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 12:08:59 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Mureja", "Dawit", ""], ["Park", "Hyunsin", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1710.07138", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Gang Niu, Masashi Sugiyama", "title": "Binary Classification from Positive-Confidence Data", "comments": "NeurIPS 2018 camera-ready version (this paper was selected for\n  spotlight presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we learn a binary classifier from only positive data, without any\nnegative data or unlabeled data? We show that if one can equip positive data\nwith confidence (positive-confidence), one can successfully learn a binary\nclassifier, which we name positive-confidence (Pconf) classification. Our work\nis related to one-class classification which is aimed at \"describing\" the\npositive class by clustering-related methods, but one-class classification does\nnot have the ability to tune hyper-parameters and their aim is not on\n\"discriminating\" positive and negative classes. For the Pconf classification\nproblem, we provide a simple empirical risk minimization framework that is\nmodel-independent and optimization-independent. We theoretically establish the\nconsistency and an estimation error bound, and demonstrate the usefulness of\nthe proposed method for training deep neural networks through experiments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 13:36:54 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 09:20:15 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:11:12 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Ishida", "Takashi", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.07264", "submitter": "Artem Artemov", "authors": "Artem Artemov, Eugeny Lutsenko, Edward Ayunts, Ivan Bolokhov", "title": "Informational Neurobayesian Approach to Neural Networks Training.\n  Opportunities and Prospects", "comments": "9 pages, 5 figures, 2 tables; corrected typos, mistake in a formula", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A study of the classification problem in context of information theory is\npresented in the paper. Current research in that field is focused on\noptimisation and bayesian approach. Although that gives satisfying results,\nthey require a vast amount of data and computations to train on. Authors\npropose a new concept named Informational Neurobayesian Approach (INA), which\nallows to solve the same problems, but requires significantly less training\ndata as well as computational power. Experiments were conducted to compare its\nperformance with the traditional one and the results showed that capacity of\nthe INA is quite promising.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 17:43:06 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 18:17:42 GMT"}, {"version": "v3", "created": "Sun, 3 Dec 2017 19:06:28 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Artemov", "Artem", ""], ["Lutsenko", "Eugeny", ""], ["Ayunts", "Edward", ""], ["Bolokhov", "Ivan", ""]]}, {"id": "1710.07276", "submitter": "Paul Rozdeba", "authors": "H. D. I. Abarbanel, P. J. Rozdeba, S. Shirman", "title": "Machine Learning as Statistical Data Assimilation", "comments": "arXiv admin note: text overlap with arXiv:1707.01415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a strong equivalence between neural network based machine\nlearning (ML) methods and the formulation of statistical data assimilation\n(DA), known to be a problem in statistical physics. DA, as used widely in\nphysical and biological sciences, systematically transfers information in\nobservations to a model of the processes producing the observations. The\ncorrespondence is that layer label in the ML setting is the analog of time in\nthe data assimilation setting. Utilizing aspects of this equivalence we discuss\nhow to establish the global minimum of the cost functions in the ML context,\nusing a variational annealing method from DA. This provides a design method for\noptimal networks for ML applications and may serve as the basis for\nunderstanding the success of \"deep learning\". Results from an ML example are\npresented.\n  When the layer label is taken to be continuous, the Euler-Lagrange equation\nfor the ML optimization problem is an ordinary differential equation, and we\nsee that the problem being solved is a two point boundary value problem. The\nuse of continuous layers is denoted \"deepest learning\". The Hamiltonian version\nprovides a direct rationale for back propagation as a solution method for the\ncanonical momentum; however, it suggests other solution methods are to be\npreferred.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 06:05:23 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Abarbanel", "H. D. I.", ""], ["Rozdeba", "P. J.", ""], ["Shirman", "S.", ""]]}, {"id": "1710.07283", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Jos\\'e Miguel Hern\\'andez-Lobato, Finale Doshi-Velez,\n  Steffen Udluft", "title": "Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and\n  Risk-sensitive Learning", "comments": "This paper supersedes arXiv:1706.08495", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks with latent variables are scalable and flexible\nprobabilistic models: They account for uncertainty in the estimation of the\nnetwork weights and, by making use of latent variables, can capture complex\nnoise patterns in the data. We show how to extract and decompose uncertainty\ninto epistemic and aleatoric components for decision-making purposes. This\nallows us to successfully identify informative points for active learning of\nfunctions with heteroscedastic and bimodal noise. Using the decomposition we\nfurther define a novel risk-sensitive criterion for reinforcement learning to\nidentify policies that balance expected cost, model-bias and noise aversion.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 16:21:10 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 19:09:45 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 00:13:06 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 21:56:12 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Depeweg", "Stefan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Doshi-Velez", "Finale", ""], ["Udluft", "Steffen", ""]]}, {"id": "1710.07314", "submitter": "Yunwen Xu", "authors": "Rui Xu, Yunwen Xu, Weizhong Yan", "title": "Power Plant Performance Modeling with Concept Drift", "comments": null, "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN),\n  Anchorage, AK, 2017, pp. 2096-2103", "doi": "10.1109/IJCNN.2017.7966108", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power plant is a complex and nonstationary system for which the traditional\nmachine learning modeling approaches fall short of expectations. The\nensemble-based online learning methods provide an effective way to continuously\nlearn from the dynamic environment and autonomously update models to respond to\nenvironmental changes. This paper proposes such an online ensemble regression\napproach to model power plant performance, which is critically important for\noperation optimization. The experimental results on both simulated and real\ndata show that the proposed method can achieve performance with less than 1%\nmean average percentage error, which meets the general expectations in field\noperations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 18:44:05 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Xu", "Rui", ""], ["Xu", "Yunwen", ""], ["Yan", "Weizhong", ""]]}, {"id": "1710.07319", "submitter": "Elyas Sabeti", "authors": "Elyas Sabeti, Anders H{\\o}st-Madsen", "title": "Atypicality for Heart Rate Variability Using a Pattern-Tree Weighting\n  Method", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart rate variability (HRV) is a vital measure of the autonomic nervous\nsystem functionality and a key indicator of cardiovascular condition. This\npaper proposes a novel method, called pattern tree which is an extension of\nWillem's context tree to real-valued data, to investigate HRV via an\natypicality framework. In a previous paper atypicality was developed as method\nfor mining and discovery in \"Big Data,\" which requires a universal approach.\nUsing the proposed pattern tree as a universal source coder in this framework\nled to discovery of arrhythmias and unknown patterns in HRV Holter Monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 01:52:44 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Sabeti", "Elyas", ""], ["H\u00f8st-Madsen", "Anders", ""]]}, {"id": "1710.07322", "submitter": "Bruno Schneider", "authors": "Bruno Schneider, Dominik J\\\"ackle, Florian Stoffel, Alexandra Diehl,\n  Johannes Fuchs and Daniel Keim", "title": "Visual Integration of Data and Model Space in Ensemble Learning", "comments": "8 pages, 7 pictures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of classifier models typically deliver superior performance and can\noutperform single classifier models given a dataset and classification task at\nhand. However, the gain in performance comes together with the lack in\ncomprehensibility, posing a challenge to understand how each model affects the\nclassification outputs and where the errors come from. We propose a tight\nvisual integration of the data and the model space for exploring and combining\nclassifier models. We introduce a workflow that builds upon the visual\nintegration and enables the effective exploration of classification outputs and\nmodels. We then present a use case in which we start with an ensemble\nautomatically selected by a standard ensemble selection algorithm, and show how\nwe can manipulate models and alternative combinations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 19:10:16 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Schneider", "Bruno", ""], ["J\u00e4ckle", "Dominik", ""], ["Stoffel", "Florian", ""], ["Diehl", "Alexandra", ""], ["Fuchs", "Johannes", ""], ["Keim", "Daniel", ""]]}, {"id": "1710.07324", "submitter": "Alexander Novikov", "authors": "Pavel Izmailov, Alexander Novikov, Dmitry Kropotov", "title": "Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor\n  Train Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method (TT-GP) for approximate inference in Gaussian Process\n(GP) models. We build on previous scalable GP research including stochastic\nvariational inference based on inducing inputs, kernel interpolation, and\nstructure exploiting algebra. The key idea of our method is to use Tensor Train\ndecomposition for variational parameters, which allows us to train GPs with\nbillions of inducing inputs and achieve state-of-the-art results on several\nbenchmarks. Further, our approach allows for training kernels based on deep\nneural networks without any modifications to the underlying GP model. A neural\nnetwork learns a multidimensional embedding for the data, which is used by the\nGP to make the final prediction. We train GP and neural network parameters\nend-to-end without pretraining, through maximization of GP marginal likelihood.\nWe show the efficiency of the proposed approach on several regression and\nclassification benchmark datasets including MNIST, CIFAR-10, and Airline.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 19:13:26 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 11:11:12 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Izmailov", "Pavel", ""], ["Novikov", "Alexander", ""], ["Kropotov", "Dmitry", ""]]}, {"id": "1710.07328", "submitter": "Ian Gemp", "authors": "Ian Gemp, Sridhar Mahadevan", "title": "Online Monotone Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic game theory (AGT) focuses on the design and analysis of\nalgorithms for interacting agents, with interactions rigorously formalized\nwithin the framework of games. Results from AGT find applications in domains\nsuch as online bidding auctions for web advertisements and network routing\nprotocols. Monotone games are games where agent strategies naturally converge\nto an equilibrium state. Previous results in AGT have been obtained for convex,\nsocially-convex, or smooth games, but not monotone games. Our primary\ntheoretical contributions are defining the monotone game setting and its\nextension to the online setting, a new notion of regret for this setting, and\naccompanying algorithms that achieve sub-linear regret. We demonstrate the\nutility of online monotone game theory on a variety of problem domains\nincluding variational inequalities, reinforcement learning, and generative\nadversarial networks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 19:31:56 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Gemp", "Ian", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1710.07400", "submitter": "David Koes", "authors": "Matthew Ragoza, Lillian Turner and David Ryan Koes", "title": "Ligand Pose Optimization with Atomic Grid-Based Convolutional Neural\n  Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Docking is an important tool in computational drug discovery that aims to\npredict the binding pose of a ligand to a target protein through a combination\nof pose scoring and optimization. A scoring function that is differentiable\nwith respect to atom positions can be used for both scoring and gradient-based\noptimization of poses for docking. Using a differentiable grid-based atomic\nrepresentation as input, we demonstrate that a scoring function learned by\ntraining a convolutional neural network (CNN) to identify binding poses can\nalso be applied to pose optimization. We also show that an iteratively-trained\nCNN that includes poses optimized by the first CNN in its training set performs\neven better at optimizing randomly initialized poses than either the first CNN\nscoring function or AutoDock Vina.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 02:37:39 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Ragoza", "Matthew", ""], ["Turner", "Lillian", ""], ["Koes", "David Ryan", ""]]}, {"id": "1710.07406", "submitter": "Ioannis Panageas", "authors": "Jason D. Lee, Ioannis Panageas, Georgios Piliouras, Max Simchowitz,\n  Michael I. Jordan and Benjamin Recht", "title": "First-order Methods Almost Always Avoid Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish that first-order methods avoid saddle points for almost all\ninitializations. Our results apply to a wide variety of first-order methods,\nincluding gradient descent, block coordinate descent, mirror descent and\nvariants thereof. The connecting thread is that such algorithms can be studied\nfrom a dynamical systems perspective in which appropriate instantiations of the\nStable Manifold Theorem allow for a global stability analysis. Thus, neither\naccess to second-order derivative information nor randomness beyond\ninitialization is necessary to provably avoid saddle points.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 03:34:56 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Lee", "Jason D.", ""], ["Panageas", "Ioannis", ""], ["Piliouras", "Georgios", ""], ["Simchowitz", "Max", ""], ["Jordan", "Michael I.", ""], ["Recht", "Benjamin", ""]]}, {"id": "1710.07425", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Quang Khai Tran, Jun Sakuma", "title": "Differentially Private Empirical Risk Minimization with Input\n  Perturbation", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for the differentially private ERM, input\nperturbation. Existing differentially private ERM implicitly assumed that the\ndata contributors submit their private data to a database expecting that the\ndatabase invokes a differentially private mechanism for publication of the\nlearned model. In input perturbation, each data contributor independently\nrandomizes her/his data by itself and submits the perturbed data to the\ndatabase. We show that the input perturbation framework theoretically\nguarantees that the model learned with the randomized data eventually satisfies\ndifferential privacy with the prescribed privacy parameters. At the same time,\ninput perturbation guarantees that local differential privacy is guaranteed to\nthe server. We also show that the excess risk bound of the model learned with\ninput perturbation is $O(1/n)$ under a certain condition, where $n$ is the\nsample size. This is the same as the excess risk bound of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 06:24:31 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Tran", "Quang Khai", ""], ["Sakuma", "Jun", ""]]}, {"id": "1710.07435", "submitter": "Arash Shahriari", "authors": "Arash Shahriari, Fatih Porikli", "title": "Multipartite Pooling for Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel pooling strategy that learns how to adaptively rank deep\nconvolutional features for selecting more informative representations. To this\nend, we exploit discriminative analysis to project the features onto a space\nspanned by the number of classes in the dataset under study. This maps the\nnotion of labels in the feature space into instances in the projected space. We\nemploy these projected distances as a measure to rank the existing features\nwith respect to their specific discriminant power for each individual class. We\nthen apply multipartite ranking to score the separability of the instances and\naggregate one-versus-all scores to compute an overall distinction score for\neach feature. For the pooling, we pick features with the highest scores in a\npooling window instead of maximum, average or stochastic random assignments.\nOur experiments on various benchmarks confirm that the proposed strategy of\nmultipartite pooling is highly beneficial to consistently improve the\nperformance of deep convolutional networks via better generalization of the\ntrained models for the test-time data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:19:32 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Shahriari", "Arash", ""], ["Porikli", "Fatih", ""]]}, {"id": "1710.07437", "submitter": "Arash Shahriari", "authors": "Arash Shahriari", "title": "Distributed Deep Transfer Learning by Basic Probability Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a popular practice in deep neural networks, but\nfine-tuning of large number of parameters is a hard task due to the complex\nwiring of neurons between splitting layers and imbalance distributions of data\nin pretrained and transferred domains. The reconstruction of the original\nwiring for the target domain is a heavy burden due to the size of\ninterconnections across neurons. We propose a distributed scheme that tunes the\nconvolutional filters individually while backpropagates them jointly by means\nof basic probability assignment. Some of the most recent advances in evidence\ntheory show that in a vast variety of the imbalanced regimes, optimizing of\nsome proper objective functions derived from contingency matrices prevents\nbiases towards high-prior class distributions. Therefore, the original filters\nget gradually transferred based on individual contributions to overall\nperformance of the target domain. This largely reduces the expected complexity\nof transfer learning whilst highly improves precision. Our experiments on\nstandard benchmarks and scenarios confirm the consistent improvement of our\ndistributed deep transfer learning strategy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:26:11 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Shahriari", "Arash", ""]]}, {"id": "1710.07438", "submitter": "Arash Shahriari", "authors": "Arash Shahriari", "title": "Unified Backpropagation for Multi-Objective Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common practice in most of deep convolutional neural architectures is to\nemploy fully-connected layers followed by Softmax activation to minimize\ncross-entropy loss for the sake of classification. Recent studies show that\nsubstitution or addition of the Softmax objective to the cost functions of\nsupport vector machines or linear discriminant analysis is highly beneficial to\nimprove the classification performance in hybrid neural networks. We propose a\nnovel paradigm to link the optimization of several hybrid objectives through\nunified backpropagation. This highly alleviates the burden of extensive\nboosting for independent objective functions or complex formulation of\nmultiobjective gradients. Hybrid loss functions are linked by basic probability\nassignment from evidence theory. We conduct our experiments for a variety of\nscenarios and standard datasets to evaluate the advantage of our proposed\nunification approach to deliver consistent improvements into the classification\nperformance of deep convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:31:12 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Shahriari", "Arash", ""]]}, {"id": "1710.07453", "submitter": "Andr\\'es Felipe L\\'opez-Lopera", "authors": "Andr\\'es F. L\\'opez-Lopera, Fran\\c{c}ois Bachoc, Nicolas Durrande, and\n  Olivier Roustant", "title": "Finite-dimensional Gaussian approximation with linear inequality\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing inequality constraints in Gaussian process (GP) models can lead\nto more realistic uncertainties in learning a great variety of real-world\nproblems. We consider the finite-dimensional Gaussian approach from Maatouk and\nBay (2017) which can satisfy inequality conditions everywhere (either\nboundedness, monotonicity or convexity). Our contributions are threefold.\nFirst, we extend their approach in order to deal with general sets of linear\ninequalities. Second, we explore several Markov Chain Monte Carlo (MCMC)\ntechniques to approximate the posterior distribution. Third, we investigate\ntheoretical and numerical properties of the constrained likelihood for\ncovariance parameter estimation. According to experiments on both artificial\nand real data, our full framework together with a Hamiltonian Monte Carlo-based\nsampler provides efficient results on both data fitting and uncertainty\nquantification.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 08:39:49 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["L\u00f3pez-Lopera", "Andr\u00e9s F.", ""], ["Bachoc", "Fran\u00e7ois", ""], ["Durrande", "Nicolas", ""], ["Roustant", "Olivier", ""]]}, {"id": "1710.07457", "submitter": "Remi Flamary", "authors": "Nicolas Courty, R\\'emi Flamary, M\\'elanie Ducoffe", "title": "Learning Wasserstein Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance received a lot of attention recently in the\ncommunity of machine learning, especially for its principled way of comparing\ndistributions. It has found numerous applications in several hard problems,\nsuch as domain adaptation, dimensionality reduction or generative models.\nHowever, its use is still limited by a heavy computational cost. Our goal is to\nalleviate this problem by providing an approximation mechanism that allows to\nbreak its inherent complexity. It relies on the search of an embedding where\nthe Euclidean distance mimics the Wasserstein distance. We show that such an\nembedding can be found with a siamese architecture associated with a decoder\nnetwork that allows to move from the embedding space back to the original input\nspace. Once this embedding has been found, computing optimization problems in\nthe Wasserstein space (e.g. barycenters, principal directions or even\narchetypes) can be conducted extremely fast. Numerical experiments supporting\nthis idea are conducted on image datasets, and show the wide potential benefits\nof our method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 09:09:34 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Courty", "Nicolas", ""], ["Flamary", "R\u00e9mi", ""], ["Ducoffe", "M\u00e9lanie", ""]]}, {"id": "1710.07462", "submitter": "Robert M. Gower", "authors": "Robert M. Gower, Nicolas Le Roux and Francis Bach", "title": "Tracking the gradients using the Hessian: A new look at variance\n  reducing stochastic methods", "comments": "17 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to improve variance reducing stochastic methods through better\ncontrol variates. We first propose a modification of SVRG which uses the\nHessian to track gradients over time, rather than to recondition, increasing\nthe correlation of the control variates and leading to faster theoretical\nconvergence close to the optimum. We then propose accurate and computationally\nefficient approximations to the Hessian, both using a diagonal and a low-rank\nmatrix. Finally, we demonstrate the effectiveness of our method on a wide range\nof problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 09:31:06 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 22:15:22 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 19:14:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Gower", "Robert M.", ""], ["Roux", "Nicolas Le", ""], ["Bach", "Francis", ""]]}, {"id": "1710.07480", "submitter": "Gabriel Eilertsen", "authors": "Gabriel Eilertsen, Joel Kronander, Gyorgy Denes, Rafa{\\l} K. Mantiuk,\n  Jonas Unger", "title": "HDR image reconstruction from a single exposure using deep CNNs", "comments": "15 pages, 19 figures, Siggraph Asia 2017. Project webpage located at\n  http://hdrv.org/hdrcnn/ where paper with high quality images is available, as\n  well as supplementary material (document, images, video and source code)", "journal-ref": "ACM Trans. Graph. 36, 6, Article 178 (2017)", "doi": "10.1145/3130800.3130816", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera sensors can only capture a limited range of luminance simultaneously,\nand in order to create high dynamic range (HDR) images a set of different\nexposures are typically combined. In this paper we address the problem of\npredicting information that have been lost in saturated image areas, in order\nto enable HDR reconstruction from a single exposure. We show that this problem\nis well-suited for deep learning algorithms, and propose a deep convolutional\nneural network (CNN) that is specifically designed taking into account the\nchallenges in predicting HDR values. To train the CNN we gather a large dataset\nof HDR images, which we augment by simulating sensor saturation for a range of\ncameras. To further boost robustness, we pre-train the CNN on a simulated HDR\ndataset created from a subset of the MIT Places database. We demonstrate that\nour approach can reconstruct high-resolution visually convincing HDR results in\na wide range of situations, and that it generalizes well to reconstruction of\nimages captured with arbitrary and low-end cameras that use unknown camera\nresponse functions and post-processing. Furthermore, we compare to existing\nmethods for HDR expansion, and show high quality results also for image based\nlighting. Finally, we evaluate the results in a subjective experiment performed\non an HDR display. This shows that the reconstructed HDR images are visually\nconvincing, with large improvements as compared to existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 10:48:22 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Eilertsen", "Gabriel", ""], ["Kronander", "Joel", ""], ["Denes", "Gyorgy", ""], ["Mantiuk", "Rafa\u0142 K.", ""], ["Unger", "Jonas", ""]]}, {"id": "1710.07491", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "Dynamic classifier chains for multi-label learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33676-9_40", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the task of building a dynamic ensemble of chain\nclassifiers for multi-label classification. To do so, we proposed two concepts\nof classifier chains algorithms that are able to change label order of the\nchain without rebuilding the entire model. Such modes allows anticipating the\ninstance-specific chain order without a significant increase in computational\nburden. The proposed chain models are built using the Naive Bayes classifier\nand nearest neighbour approach as a base single-label classifiers. To take the\nbenefits of the proposed algorithms, we developed a simple heuristic that\nallows the system to find relatively good label order. The heuristic sort\nlabels according to the label-specific classification quality gained during the\nvalidation phase. The heuristic tries to minimise the phenomenon of error\npropagation in the chain. The experimental results showed that the proposed\nmodel based on Naive Bayes classifier the above-mentioned heuristic is an\nefficient tool for building dynamic chain classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 11:26:41 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 16:11:39 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.07535", "submitter": "Raphael Gontijo Lopes", "authors": "Raphael Gontijo Lopes, Stefano Fenu, Thad Starner", "title": "Data-Free Knowledge Distillation for Deep Neural Networks", "comments": "Accepted to NIPS 2017 Workshop on Learning with Limited Data. Under\n  review at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in model compression have provided procedures for compressing\nlarge neural networks to a fraction of their original size while retaining most\nif not all of their accuracy. However, all of these approaches rely on access\nto the original training set, which might not always be possible if the network\nto be compressed was trained on a very large dataset, or on a dataset whose\nrelease poses privacy or safety concerns as may be the case for biometrics\ntasks. We present a method for data-free knowledge distillation, which is able\nto compress deep neural networks trained on large-scale datasets to a fraction\nof their size leveraging only some extra metadata to be provided with a\npretrained model release. We also explore different kinds of metadata that can\nbe used with our method, and discuss tradeoffs involved in using each of them.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 16:04:05 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 16:28:48 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Lopes", "Raphael Gontijo", ""], ["Fenu", "Stefano", ""], ["Starner", "Thad", ""]]}, {"id": "1710.07547", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Karl {\\O}yvind Mikalsen and Robert Jenssen", "title": "Learning compressed representations of blood samples time series with\n  missing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical measurements collected over time are naturally represented as\nmultivariate time series (MTS), which often contain missing data. An\nautoencoder can learn low dimensional vectorial representations of MTS that\npreserve important data characteristics, but cannot deal explicitly with\nmissing data. In this work, we propose a new framework that combines an\nautoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts\nfor missingness patterns in MTS. Via kernel alignment, we incorporate TCK in\nthe autoencoder to improve the learned representations in presence of missing\ndata. We consider a classification problem of MTS with missing values,\nrepresenting blood samples of patients with surgical site infection. With our\napproach, rather than with a standard autoencoder, we learn representations in\nlow dimensions that can be classified better.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 14:29:52 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Mikalsen", "Karl \u00d8yvind", ""], ["Jenssen", "Robert", ""]]}, {"id": "1710.07654", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan,\n  Sharan Narang, Jonathan Raiman, John Miller", "title": "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence\n  Learning", "comments": "Published as a conference paper at ICLR 2018. (v3 changed paper\n  title)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Voice 3, a fully-convolutional attention-based neural\ntext-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural\nspeech synthesis systems in naturalness while training ten times faster. We\nscale Deep Voice 3 to data set sizes unprecedented for TTS, training on more\nthan eight hundred hours of audio from over two thousand speakers. In addition,\nwe identify common error modes of attention-based speech synthesis networks,\ndemonstrate how to mitigate them, and compare several different waveform\nsynthesis methods. We also describe how to scale inference to ten million\nqueries per day on one single-GPU server.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 18:17:23 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 02:50:28 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 06:23:45 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Gibiansky", "Andrew", ""], ["Arik", "Sercan O.", ""], ["Kannan", "Ajay", ""], ["Narang", "Sharan", ""], ["Raiman", "Jonathan", ""], ["Miller", "John", ""]]}, {"id": "1710.07702", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Zachary Kaplan, Thabo Samakhoana, Daniel\n  Sanz-Alonso", "title": "On the Consistency of Graph-based Bayesian Learning and the Scalability\n  of Sampling Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to semi-supervised learning proceeds by endowing the input\ndata with a graph structure in order to extract geometric information and\nincorporate it into a Bayesian framework. We introduce new theory that gives\nappropriate scalings of graph parameters that provably lead to a well-defined\nlimiting posterior as the size of the unlabeled data set grows. Furthermore, we\nshow that these consistency results have profound algorithmic implications.\nWhen consistency holds, carefully designed graph-based Markov chain Monte Carlo\nalgorithms are proved to have a uniform spectral gap, independent of the number\nof unlabeled inputs. Several numerical experiments corroborate both the\nstatistical consistency and the algorithmic scalability established by the\ntheory.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 20:57:14 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 16:26:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Kaplan", "Zachary", ""], ["Samakhoana", "Thabo", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1710.07706", "submitter": "Supriya Kapur", "authors": "Supriya Kapur, Asit Mishra, and Debbie Marr", "title": "Low Precision RNNs: Quantizing RNNs Without Losing Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar to convolution neural networks, recurrent neural networks (RNNs)\ntypically suffer from over-parameterization. Quantizing bit-widths of weights\nand activations results in runtime efficiency on hardware, yet it often comes\nat the cost of reduced accuracy. This paper proposes a quantization approach\nthat increases model size with bit-width reduction. This approach will allow\nnetworks to perform at their baseline accuracy while still maintaining the\nbenefits of reduced precision and overall model size reduction.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 21:12:30 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Kapur", "Supriya", ""], ["Mishra", "Asit", ""], ["Marr", "Debbie", ""]]}, {"id": "1710.07732", "submitter": "Nishant Mehta", "authors": "Peter D. Gr\\\"unwald and Nishant A. Mehta", "title": "A Tight Excess Risk Bound via a Unified\n  PAC-Bayesian-Rademacher-Shtarkov-MDL Complexity", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel notion of complexity that interpolates between and\ngeneralizes some classic existing complexity notions in learning theory: for\nestimators like empirical risk minimization (ERM) with arbitrary bounded\nlosses, it is upper bounded in terms of data-independent Rademacher complexity;\nfor generalized Bayesian estimators, it is upper bounded by the data-dependent\ninformation complexity (also known as stochastic or PAC-Bayesian,\n$\\mathrm{KL}(\\text{posterior} \\operatorname{\\|} \\text{prior})$ complexity. For\n(penalized) ERM, the new complexity reduces to (generalized) normalized maximum\nlikelihood (NML) complexity, i.e. a minimax log-loss individual-sequence\nregret. Our first main result bounds excess risk in terms of the new\ncomplexity. Our second main result links the new complexity via Rademacher\ncomplexity to $L_2(P)$ entropy, thereby generalizing earlier results of Opper,\nHaussler, Lugosi, and Cesa-Bianchi who did the log-loss case with $L_\\infty$.\nTogether, these results recover optimal bounds for VC- and large (polynomial\nentropy) classes, replacing localized Rademacher complexity by a simpler\nanalysis which almost completely separates the two aspects that determine the\nachievable rates: 'easiness' (Bernstein) conditions and model complexity.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 00:28:39 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Gr\u00fcnwald", "Peter D.", ""], ["Mehta", "Nishant A.", ""]]}, {"id": "1710.07739", "submitter": "Oran Shayer", "authors": "Oran Shayer, Dan Levi and Ethan Fetaya", "title": "Learning Discrete Weights Using the Local Reparameterization Trick", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in computer vision make use of large deep neural\nnetworks, utilizing the substantial speedup offered by GPUs. For applications\nrunning on limited hardware, however, high precision real-time processing can\nstill be a challenge. One approach to solving this problem is training networks\nwith binary or ternary weights, thus removing the need to calculate\nmultiplications and significantly reducing memory size. In this work, we\nintroduce LR-nets (Local reparameterization networks), a new method for\ntraining neural networks with discrete weights using stochastic parameters. We\nshow how a simple modification to the local reparameterization trick,\npreviously used to train Gaussian distributed weights, enables the training of\ndiscrete weights. Using the proposed training we test both binary and ternary\nmodels on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art\nresults on most experiments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 02:06:09 GMT"}, {"version": "v2", "created": "Sat, 28 Oct 2017 00:48:21 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 12:20:03 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Shayer", "Oran", ""], ["Levi", "Dan", ""], ["Fetaya", "Ethan", ""]]}, {"id": "1710.07742", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Bo Dai, Xingguo Li, Zhen Liu, James M. Rehg, Le Song", "title": "Towards Black-box Iterative Machine Teaching", "comments": "Published in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make an important step towards the black-box machine\nteaching by considering the cross-space machine teaching, where the teacher and\nthe learner use different feature representations and the teacher can not fully\nobserve the learner's model. In such scenario, we study how the teacher is\nstill able to teach the learner to achieve faster convergence rate than the\ntraditional passive learning. We propose an active teacher model that can\nactively query the learner (i.e., make the learner take exams) for estimating\nthe learner's status and provably guide the learner to achieve faster\nconvergence. The sample complexities for both teaching and query are provided.\nIn the experiments, we compare the proposed active teacher with the omniscient\nteacher and verify the effectiveness of the active teacher model.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 02:36:08 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 22:37:51 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 21:56:44 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Liu", "Weiyang", ""], ["Dai", "Bo", ""], ["Li", "Xingguo", ""], ["Liu", "Zhen", ""], ["Rehg", "James M.", ""], ["Song", "Le", ""]]}, {"id": "1710.07746", "submitter": "Penghang Yin", "authors": "Penghang Yin, Minh Pham, Adam Oberman, Stanley Osher", "title": "Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for\n  $k$-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an implicit gradient descent algorithm for the\nclassic $k$-means problem. The implicit gradient step or backward Euler is\nsolved via stochastic fixed-point iteration, in which we randomly sample a\nmini-batch gradient in every iteration. It is the average of the fixed-point\ntrajectory that is carried over to the next gradient step. We draw connections\nbetween the proposed stochastic backward Euler and the recent entropy\nstochastic gradient descent (Entropy-SGD) for improving the training of deep\nneural networks. Numerical experiments on various synthetic and real datasets\nshow that the proposed algorithm provides better clustering results compared to\n$k$-means algorithms in the sense that it decreased the objective function (the\ncluster) and is much more robust to initialization.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 03:02:29 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 18:32:15 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 19:18:23 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Yin", "Penghang", ""], ["Pham", "Minh", ""], ["Oberman", "Adam", ""], ["Osher", "Stanley", ""]]}, {"id": "1710.07783", "submitter": "Aixiang Chen", "authors": "Aixiang Chen, Bingchuan Chen, Xiaolong Chai, Rui Bian, Hengguang Li", "title": "A Novel Stochastic Stratified Average Gradient Method: Convergence Rate\n  and Its Complexity", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SGD (Stochastic Gradient Descent) is a popular algorithm for large scale\noptimization problems due to its low iterative cost. However, SGD can not\nachieve linear convergence rate as FGD (Full Gradient Descent) because of the\ninherent gradient variance. To attack the problem, mini-batch SGD was proposed\nto get a trade-off in terms of convergence rate and iteration cost. In this\npaper, a general CVI (Convergence-Variance Inequality) equation is presented to\nstate formally the interaction of convergence rate and gradient variance. Then\na novel algorithm named SSAG (Stochastic Stratified Average Gradient) is\nintroduced to reduce gradient variance based on two techniques, stratified\nsampling and averaging over iterations that is a key idea in SAG (Stochastic\nAverage Gradient). Furthermore, SSAG can achieve linear convergence rate of\n$\\mathcal {O}((1-\\frac{\\mu}{8CL})^k)$ at smaller storage and iterative costs,\nwhere $C\\geq 2$ is the category number of training data. This convergence rate\ndepends mainly on the variance between classes, but not on the variance within\nthe classes. In the case of $C\\ll N$ ($N$ is the training data size), SSAG's\nconvergence rate is much better than SAG's convergence rate of $\\mathcal\n{O}((1-\\frac{\\mu}{8NL})^k)$. Our experimental results show SSAG outperforms SAG\nand many other algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 10:45:13 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 08:13:34 GMT"}, {"version": "v3", "created": "Sun, 3 Dec 2017 23:13:26 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Chen", "Aixiang", ""], ["Chen", "Bingchuan", ""], ["Chai", "Xiaolong", ""], ["Bian", "Rui", ""], ["Li", "Hengguang", ""]]}, {"id": "1710.07797", "submitter": "Junhong Lin", "authors": "Junhong Lin and Lorenzo Rosasco", "title": "Optimal Rates for Learning with Nystr\\\"om Stochastic Gradient Methods", "comments": "41pages, 6figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of nonparametric regression, we propose and study a\ncombination of stochastic gradient methods with Nystr\\\"om subsampling, allowing\nmultiple passes over the data and mini-batches. Generalization error bounds for\nthe studied algorithm are provided. Particularly, optimal learning rates are\nderived considering different possible choices of the step-size, the mini-batch\nsize, the number of iterations/passes, and the subsampling level. In comparison\nwith state-of-the-art algorithms such as the classic stochastic gradient\nmethods and kernel ridge regression with Nystr\\\"om, the studied algorithm has\nadvantages on the computational complexity, while achieving the same optimal\nlearning rates. Moreover, our results indicate that using mini-batches can\nreduce the total computational cost while achieving the same optimal\nstatistical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 12:36:39 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Lin", "Junhong", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1710.07804", "submitter": "Sijia Liu", "authors": "Sijia Liu and Jie Chen and Pin-Yu Chen and Alfred O. Hero", "title": "Zeroth-Order Online Alternating Direction Method of Multipliers:\n  Convergence Analysis and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and analyze a new zeroth-order online algorithm,\nnamely, the zeroth-order online alternating direction method of multipliers\n(ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and\nemploying the ADMM to accommodate complex structured regularizers. Compared to\nthe first-order gradient-based online algorithm, we show that ZOO-ADMM requires\n$\\sqrt{m}$ times more iterations, leading to a convergence rate of\n$O(\\sqrt{m}/\\sqrt{T})$, where $m$ is the number of optimization variables, and\n$T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two\nminibatch strategies: gradient sample averaging and observation averaging,\nresulting in an improved convergence rate of $O(\\sqrt{1+q^{-1}m}/\\sqrt{T})$,\nwhere $q$ is the minibatch size. In addition to convergence analysis, we also\ndemonstrate ZOO-ADMM to applications in signal processing, statistics, and\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 13:59:16 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 03:19:07 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Sijia", ""], ["Chen", "Jie", ""], ["Chen", "Pin-Yu", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1710.07818", "submitter": "Yue Zhao", "authors": "Yue Zhao, Jianshu Chen, H. Vincent Poor", "title": "A Learning-to-Infer Method for Real-Time Power Grid Multi-Line Outage\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying a potentially large number of simultaneous line outages in power\ntransmission networks in real time is a computationally hard problem. This is\nbecause the number of hypotheses grows exponentially with the network size. A\nnew \"Learning-to-Infer\" method is developed for efficient inference of every\nline status in the network. Optimizing the line outage detector is transformed\nto and solved as a discriminative learning problem based on Monte Carlo samples\ngenerated with power flow simulations. A major advantage of the developed\nLearning-to-Infer method is that the labeled data used for training can be\ngenerated in an arbitrarily large amount rapidly and at very little cost. As a\nresult, the power of offline training is fully exploited to learn very complex\nclassifiers for effective real-time multi-line outage identification. The\nproposed methods are evaluated in the IEEE 30, 118 and 300 bus systems.\nExcellent performance in identifying multi-line outages in real time is\nachieved with a reasonably small amount of data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 15:58:46 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:45:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhao", "Yue", ""], ["Chen", "Jianshu", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1710.07830", "submitter": "Surat Teerapittayanon", "authors": "Bradley McDanel, Surat Teerapittayanon and H.T. Kung", "title": "Incomplete Dot Products for Dynamic Computation Scaling in Neural\n  Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of incomplete dot products (IDP) to dynamically adjust the\nnumber of input channels used in each layer of a convolutional neural network\nduring feedforward inference. IDP adds monotonically non-increasing\ncoefficients, referred to as a \"profile\", to the channels during training. The\nprofile orders the contribution of each channel in non-increasing order. At\ninference time, the number of channels used can be dynamically adjusted to\ntrade off accuracy for lowered power consumption and reduced latency by\nselecting only a beginning subset of channels. This approach allows for a\nsingle network to dynamically scale over a computation range, as opposed to\ntraining and deploying multiple networks to support different levels of\ncomputation scaling. Additionally, we extend the notion to multiple profiles,\neach optimized for some specific range of computation scaling. We present\nexperiments on the computation and accuracy trade-offs of IDP for popular image\nclassification models and datasets. We demonstrate that, for MNIST and\nCIFAR-10, IDP reduces computation significantly, e.g., by 75%, without\nsignificantly compromising accuracy. We argue that IDP provides a convenient\nand effective means for devices to lower computation costs dynamically to\nreflect the current computation budget of the system. For example, VGG-16 with\n50% IDP (using only the first 50% of channels) achieves 70% in accuracy on the\nCIFAR-10 dataset compared to the standard network which achieves only 35%\naccuracy when using the reduced channel set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 17:37:11 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["McDanel", "Bradley", ""], ["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1710.07831", "submitter": "Siqi Nie", "authors": "Siqi Nie, Ziheng Wang, Qiang Ji", "title": "A Generative Restricted Boltzmann Machine Based Method for\n  High-Dimensional Motion Data Modeling", "comments": null, "journal-ref": "Computer Vision and Image Understanding 136 (2015): 14-22", "doi": "10.1016/j.cviu.2014.12.005", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision applications involve modeling complex spatio-temporal\npatterns in high-dimensional motion data. Recently, restricted Boltzmann\nmachines (RBMs) have been widely used to capture and represent spatial patterns\nin a single image or temporal patterns in several time slices. To model global\ndynamics and local spatial interactions, we propose to theoretically extend the\nconventional RBMs by introducing another term in the energy function to\nexplicitly model the local spatial interactions in the input data. A learning\nmethod is then proposed to perform efficient learning for the proposed model.\nWe further introduce a new method for multi-class classification that can\neffectively estimate the infeasible partition functions of different RBMs such\nthat RBM is treated as a generative model for classification purpose. The\nimproved RBM model is evaluated on two computer vision applications: facial\nexpression recognition and human action recognition. Experimental results on\nbenchmark databases demonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 17:40:12 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Nie", "Siqi", ""], ["Wang", "Ziheng", ""], ["Ji", "Qiang", ""]]}, {"id": "1710.07850", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan, Nina Narodytska, Hongxia Jin", "title": "Deep Neural Network Approximation using Tensor Sketching", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are powerful learning models that achieve\nstate-of-the-art performance on many computer vision, speech, and language\nprocessing tasks. In this paper, we study a fundamental question that arises\nwhen designing deep network architectures: Given a target network architecture\ncan we design a smaller network architecture that approximates the operation of\nthe target network? The question is, in part, motivated by the challenge of\nparameter reduction (compression) in modern deep neural networks, as the ever\nincreasing storage and memory requirements of these networks pose a problem in\nresource constrained environments.\n  In this work, we focus on deep convolutional neural network architectures,\nand propose a novel randomized tensor sketching technique that we utilize to\ndevelop a unified framework for approximating the operation of both the\nconvolutional and fully connected layers. By applying the sketching technique\nalong different tensor dimensions, we design changes to the convolutional and\nfully connected layers that substantially reduce the number of effective\nparameters in a network. We show that the resulting smaller network can be\ntrained directly, and has a classification accuracy that is comparable to the\noriginal network.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 20:14:00 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Narodytska", "Nina", ""], ["Jin", "Hongxia", ""]]}, {"id": "1710.07868", "submitter": "Mohit Yadav", "authors": "Mohit Yadav and Vivek Tyagi", "title": "Deep Triphone Embedding Improves Phoneme Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel Deep Triphone Embedding (DTE)\nrepresentation derived from Deep Neural Network (DNN) to encapsulate the\ndiscriminative information present in the adjoining speech frames. DTEs are\ngenerated using a four hidden layer DNN with 3000 nodes in each hidden layer at\nthe first-stage. This DNN is trained with the tied-triphone classification\naccuracy as an optimization criterion. Thereafter, we retain the activation\nvectors (3000) of the last hidden layer, for each speech MFCC frame, and\nperform dimension reduction to further obtain a 300 dimensional representation,\nwhich we termed as DTE. DTEs along with MFCC features are fed into a\nsecond-stage four hidden layer DNN, which is subsequently trained for the task\nof tied-triphone classification. Both DNNs are trained using tri-phone labels\ngenerated from a tied-state triphone HMM-GMM system, by performing a\nforced-alignment between the transcriptions and MFCC feature frames. We conduct\nthe experiments on publicly available TED-LIUM speech corpus. The results show\nthat the proposed DTE method provides an improvement of absolute 2.11% in\nphoneme recognition, when compared with a competitive hybrid tied-state\ntriphone HMM-DNN system.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 01:06:23 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 14:59:30 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Yadav", "Mohit", ""], ["Tyagi", "Vivek", ""]]}, {"id": "1710.07887", "submitter": "Jinshuo Dong", "authors": "Jinshuo Dong, Aaron Roth, Zachary Schutzman, Bo Waggoner, Zhiwei\n  Steven Wu", "title": "Strategic Classification from Revealed Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online linear classification problem, in which the data is\ngenerated by strategic agents who manipulate their features in an effort to\nchange the classification outcome. In rounds, the learner deploys a classifier,\nand an adversarially chosen agent arrives, possibly manipulating her features\nto optimally respond to the learner. The learner has no knowledge of the\nagents' utility functions or \"real\" features, which may vary widely across\nagents. Instead, the learner is only able to observe their \"revealed\npreferences\" --- i.e. the actual manipulated feature vectors they provide. For\na broad family of agent cost functions, we give a computationally efficient\nlearning algorithm that is able to obtain diminishing \"Stackelberg regret\" ---\na form of policy regret that guarantees that the learner is obtaining loss\nnearly as small as that of the best classifier in hindsight, even allowing for\nthe fact that agents will best-respond differently to the optimal classifier.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 04:29:32 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Dong", "Jinshuo", ""], ["Roth", "Aaron", ""], ["Schutzman", "Zachary", ""], ["Waggoner", "Bo", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1710.07954", "submitter": "Freweyni Kidane Teklehaymanot", "authors": "Freweyni K. Teklehaymanot, Michael Muma, and Abdelhak M. Zoubir", "title": "Bayesian Cluster Enumeration Criterion for Unsupervised Learning", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2866385", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new Bayesian Information Criterion (BIC) by formulating the\nproblem of estimating the number of clusters in an observed data set as\nmaximization of the posterior probability of the candidate models. Given that\nsome mild assumptions are satisfied, we provide a general BIC expression for a\nbroad class of data distributions. This serves as a starting point when\nderiving the BIC for specific distributions. Along this line, we provide a\nclosed-form BIC expression for multivariate Gaussian distributed variables. We\nshow that incorporating the data structure of the clustering problem into the\nderivation of the BIC results in an expression whose penalty term is different\nfrom that of the original BIC. We propose a two-step cluster enumeration\nalgorithm. First, a model-based unsupervised learning algorithm partitions the\ndata according to a given set of candidate models. Subsequently, the number of\nclusters is determined as the one associated with the model for which the\nproposed BIC is maximal. The performance of the proposed two-step algorithm is\ntested using synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 14:59:08 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 17:31:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 13:53:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Teklehaymanot", "Freweyni K.", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1710.07991", "submitter": "Mrinal Haloi", "authors": "Mrinal Haloi", "title": "Rethinking Convolutional Semantic Segmentation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional semantic segmentation (DCSS) learning doesn't converge to\nan optimal local minimum with random parameters initializations; a pre-trained\nmodel on the same domain becomes necessary to achieve convergence.In this work,\nwe propose a joint cooperative end-to-end learning method for DCSS. It\naddresses many drawbacks with existing deep semantic segmentation learning; the\nproposed approach simultaneously learn both segmentation and classification;\ntaking away the essential need of the pre-trained model for learning\nconvergence. We present an improved inception based architecture with partial\nattention gating (PAG) over encoder information. The PAG also adds to achieve\nfaster convergence and better accuracy for segmentation task. We will show the\neffectiveness of this learning on a diabetic retinopathy classification and\nsegmentation dataset.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 18:13:24 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Haloi", "Mrinal", ""]]}, {"id": "1710.08005", "submitter": "Adam Elmachtoub", "authors": "Adam N. Elmachtoub, Paul Grigas", "title": "Smart \"Predict, then Optimize\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world analytics problems involve two significant challenges:\nprediction and optimization. Due to the typically complex nature of each\nchallenge, the standard paradigm is predict-then-optimize. By and large,\nmachine learning tools are intended to minimize prediction error and do not\naccount for how the predictions will be used in the downstream optimization\nproblem. In contrast, we propose a new and very general framework, called Smart\n\"Predict, then Optimize\" (SPO), which directly leverages the optimization\nproblem structure, i.e., its objective and constraints, for designing better\nprediction models. A key component of our framework is the SPO loss function\nwhich measures the decision error induced by a prediction.\n  Training a prediction model with respect to the SPO loss is computationally\nchallenging, and thus we derive, using duality theory, a convex surrogate loss\nfunction which we call the SPO+ loss. Most importantly, we prove that the SPO+\nloss is statistically consistent with respect to the SPO loss under mild\nconditions. Our SPO+ loss function can tractably handle any polyhedral, convex,\nor even mixed-integer optimization problem with a linear objective. Numerical\nexperiments on shortest path and portfolio optimization problems show that the\nSPO framework can lead to significant improvement under the\npredict-then-optimize paradigm, in particular when the prediction model being\ntrained is misspecified. We find that linear models trained using SPO+ loss\ntend to dominate random forest algorithms, even when the ground truth is highly\nnonlinear.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 19:44:46 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 04:45:54 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 22:35:21 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 23:53:39 GMT"}, {"version": "v5", "created": "Thu, 19 Nov 2020 23:45:01 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Elmachtoub", "Adam N.", ""], ["Grigas", "Paul", ""]]}, {"id": "1710.08012", "submitter": "Maryam Hashemzadeh", "authors": "Maryam Hashemzadeh, Reshad Hosseini and Majid Nili Ahmadabadi", "title": "Exploiting generalization in the subspaces for faster model-based\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the lack of enough generalization in the state-space, common methods\nin Reinforcement Learning (RL) suffer from slow learning speed especially in\nthe early learning trials. This paper introduces a model-based method in\ndiscrete state-spaces for increasing learning speed in terms of required\nexperience (but not required computational time) by exploiting generalization\nin the experiences of the subspaces. A subspace is formed by choosing a subset\nof features in the original state representation (full-space). Generalization\nand faster learning in a subspace are due to many-to-one mapping of experiences\nfrom the full-space to each state in the subspace. Nevertheless, due to\ninherent perceptual aliasing in the subspaces, the policy suggested by each\nsubspace does not generally converge to the optimal policy. Our approach,\ncalled Model Based Learning with Subspaces (MoBLeS), calculates confidence\nintervals of the estimated Q-values in the full-space and in the subspaces.\nThese confidence intervals are used in the decision making, such that the agent\nbenefits the most from the possible generalization while avoiding from\ndetriment of the perceptual aliasing in the subspaces. Convergence of MoBLeS to\nthe optimal policy is theoretically investigated. Additionally, we show through\nseveral experiments that MoBLeS improves the learning speed in the early\ntrials.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 20:50:52 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 11:51:13 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Hashemzadeh", "Maryam", ""], ["Hosseini", "Reshad", ""], ["Ahmadabadi", "Majid Nili", ""]]}, {"id": "1710.08045", "submitter": "Annie Marsden", "authors": "Annie Marsden, Sergio Bacallado", "title": "Sequential Matrix Completion", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for sequential matrix completion in a\nrecommender system setting, where the $(i,j)$th entry of the matrix corresponds\nto a user $i$'s rating of product $j$. The objective of the algorithm is to\nprovide a sequential policy for user-product pair recommendation which will\nyield the highest possible ratings after a finite time horizon. The algorithm\nuses a Gamma process factor model with two posterior-focused bandit policies,\nThompson Sampling and Information-Directed Sampling. While Thompson Sampling\nshows competitive performance in simulations, state-of-the-art performance is\nobtained from Information-Directed Sampling, which makes its recommendations\nbased off a ratio between the expected reward and a measure of information\ngain. To our knowledge, this is the first implementation of Information\nDirected Sampling on large real datasets.\n  This approach contributes to a recent line of research on bandit approaches\nto collaborative filtering including Kawale et al. (2015), Li et al. (2010),\nBresler et al. (2014), Li et al. (2016), Deshpande & Montanari (2012), and Zhao\net al. (2013). The setting of this paper, as has been noted in Kawale et al.\n(2015) and Zhao et al. (2013), presents significant challenges to bounding\nregret after finite horizons. We discuss these challenges in relation to\nsimpler models for bandits with side information, such as linear or gaussian\nprocess bandits, and hope the experiments presented here motivate further\nresearch toward theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 00:20:32 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Marsden", "Annie", ""], ["Bacallado", "Sergio", ""]]}, {"id": "1710.08070", "submitter": "Kailasam Lakshmanan", "authors": "K. Lakshmanan", "title": "Accelerated Reinforcement Learning", "comments": "The proof is not complete as it has to be shown the algorithm tracks\n  the ODE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are widely used in reinforcement learning algorithms\nto search for better policies in the parameterized policy space. They do\ngradient search in the policy space and are known to converge very slowly.\nNesterov developed an accelerated gradient search algorithm for convex\noptimization problems. This has been recently extended for non-convex and also\nstochastic optimization. We use Nesterov's acceleration for policy gradient\nsearch in the well-known actor-critic algorithm and show the convergence using\nODE method. We tested this algorithm on a scheduling problem. Here an incoming\njob is scheduled into one of the four queues based on the queue lengths. We see\nfrom experimental results that algorithm using Nesterov's acceleration has\nsignificantly better performance compared to algorithm which do not use\nacceleration. To the best of our knowledge this is the first time Nesterov's\nacceleration has been used with actor-critic algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 02:45:31 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 23:55:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Lakshmanan", "K.", ""]]}, {"id": "1710.08079", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Ambuj Tewari", "title": "Online Boosting Algorithms for Multi-label Ranking", "comments": "12pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-label ranking approach to multi-label learning.\nBoosting is a natural method for multi-label ranking as it aggregates weak\npredictions through majority votes, which can be directly used as scores to\nproduce a ranking of the labels. We design online boosting algorithms with\nprovable loss bounds for multi-label ranking. We show that our first algorithm\nis optimal in terms of the number of learners required to attain a desired\naccuracy, but it requires knowledge of the edge of the weak learners. We also\ndesign an adaptive algorithm that does not require this knowledge and is hence\nmore practical. Experimental results on real data sets demonstrate that our\nalgorithms are at least as good as existing batch boosting algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 03:19:58 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 01:12:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1710.08114", "submitter": "Yuri Kalnishkan", "authors": "Dmitry Adamskiy, Tony Bellotti, Raisa Dzhamtyrova, Yuri Kalnishkan", "title": "Aggregating Algorithm for Prediction of Packs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates the protocol for prediction of packs, which a special\ncase of prediction under delayed feedback. Under this protocol, the learner\nmust make a few predictions without seeing the outcomes and then the outcomes\nare revealed. We develop the theory of prediction with expert advice for packs.\nBy applying Vovk's Aggregating Algorithm to this problem we obtain a number of\nalgorithms with tight upper bounds. We carry out empirical experiments on\nhousing data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 07:05:51 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Adamskiy", "Dmitry", ""], ["Bellotti", "Tony", ""], ["Dzhamtyrova", "Raisa", ""], ["Kalnishkan", "Yuri", ""]]}, {"id": "1710.08167", "submitter": "Jefrey Lijffijt", "authors": "Kai Puolam\\\"aki, Emilia Oikarinen, Bo Kang, Jefrey Lijffijt, Tijl De\n  Bie", "title": "Interactive Visual Data Exploration with Subjective Feedback: An\n  Information-Theoretic Approach", "comments": "12 pages, 9 figures, 2 tables, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual exploration of high-dimensional real-valued datasets is a fundamental\ntask in exploratory data analysis (EDA). Existing methods use predefined\ncriteria to choose the representation of data. There is a lack of methods that\n(i) elicit from the user what she has learned from the data and (ii) show\npatterns that she does not know yet. We construct a theoretical model where\nidentified patterns can be input as knowledge to the system. The knowledge\nsyntax here is intuitive, such as \"this set of points forms a cluster\", and\nrequires no knowledge of maths. This background knowledge is used to find a\nMaximum Entropy distribution of the data, after which the system provides the\nuser data projections in which the data and the Maximum Entropy distribution\ndiffer the most, hence showing the user aspects of the data that are maximally\ninformative given the user's current knowledge. We provide an open source EDA\nsystem with tailored interactive visualizations to demonstrate these concepts.\nWe study the performance of the system and present use cases on both synthetic\nand real data. We find that the model and the prototype system allow the user\nto learn information efficiently from various data sources and the system works\nsufficiently fast in practice. We conclude that the information theoretic\napproach to exploratory data analysis where patterns observed by a user are\nformalized as constraints provides a principled, intuitive, and efficient basis\nfor constructing an EDA system.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 09:44:35 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Puolam\u00e4ki", "Kai", ""], ["Oikarinen", "Emilia", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "1710.08177", "submitter": "Saikat  Chatterjee", "authors": "Saikat Chatterjee, Alireza M. Javid, Mostafa Sadeghi, Partha P. Mitra,\n  Mikael Skoglund", "title": "Progressive Learning for Systematic Design of Large Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for systematic design of a large artificial neural\nnetwork using a progression property. We find that some non-linear functions,\nsuch as the rectifier linear unit and its derivatives, hold the property. The\nsystematic design addresses the choice of network size and regularization of\nparameters. The number of nodes and layers in network increases in progression\nwith the objective of consistently reducing an appropriate cost. Each layer is\noptimized at a time, where appropriate parameters are learned using convex\noptimization. Regularization parameters for convex optimization do not need a\nsignificant manual effort for tuning. We also use random instances for some\nweight matrices, and that helps to reduce the number of parameters we learn.\nThe developed network is expected to show good generalization power due to\nappropriate regularization and use of random weights in the layers. This\nexpectation is verified by extensive experiments for classification and\nregression problems, using standard databases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 10:06:15 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chatterjee", "Saikat", ""], ["Javid", "Alireza M.", ""], ["Sadeghi", "Mostafa", ""], ["Mitra", "Partha P.", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1710.08247", "submitter": "Tilman Wekel", "authors": "Amir R. Zamir, Tilman Wekel, Pulkit Argrawal, Colin Weil, Jitendra\n  Malik, Silvio Savarese", "title": "Generic 3D Representation via Pose Estimation and Matching", "comments": "Published in ECCV16. See the project website\n  http://3drepresentation.stanford.edu/ and dataset website\n  https://github.com/amir32002/3D_Street_View", "journal-ref": "ECCV 2016 535-553", "doi": "10.1007/978-3-319-46487-9_33", "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though a large body of computer vision research has investigated developing\ngeneric semantic representations, efforts towards developing a similar\nrepresentation for 3D has been limited. In this paper, we learn a generic 3D\nrepresentation through solving a set of foundational proxy 3D tasks:\nobject-centric camera pose estimation and wide baseline feature matching. Our\nmethod is based upon the premise that by providing supervision over a set of\ncarefully selected foundational tasks, generalization to novel tasks and\nabstraction capabilities can be achieved. We empirically show that the internal\nrepresentation of a multi-task ConvNet trained to solve the above core problems\ngeneralizes to novel 3D tasks (e.g., scene layout estimation, object pose\nestimation, surface normal estimation) without the need for fine-tuning and\nshows traits of abstraction abilities (e.g., cross-modality pose estimation).\nIn the context of the core supervised tasks, we demonstrate our representation\nachieves state-of-the-art wide baseline feature matching results without\nrequiring apriori rectification (unlike SIFT and the majority of learned\nfeatures). We also show 6DOF camera pose estimation given a pair local image\npatches. The accuracy of both supervised tasks come comparable to humans.\nFinally, we contribute a large-scale dataset composed of object-centric street\nview scenes along with point correspondences and camera pose information, and\nconclude with a discussion on the learned representation and open research\nquestions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 13:01:05 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Zamir", "Amir R.", ""], ["Wekel", "Tilman", ""], ["Argrawal", "Pulkit", ""], ["Weil", "Colin", ""], ["Malik", "Jitendra", ""], ["Savarese", "Silvio", ""]]}, {"id": "1710.08266", "submitter": "Jean-Michel Loubes", "authors": "Thomas Epelbaum (IPHT), Fabrice Gamboa (IMT), Jean-Michel Loubes\n  (IMT), Jessica Martin", "title": "Deep Learning applied to Road Traffic Speed forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep learning architectures (FNN, CNN and LSTM) to\nforecast a regression model for time dependent data. These algorithm's are\ndesigned to handle Floating Car Data (FCD) historic speeds to predict road\ntraffic data. For this we aggregate the speeds into the network inputs in an\ninnovative way. We compare the RMSE thus obtained with the results of a simpler\nphysical model, and show that the latter achieves better RMSE accuracy. We also\npropose a new indicator, which evaluates the algorithms improvement when\ncompared to a benchmark prediction. We conclude by questioning the interest of\nusing deep learning methods for this specific regression task.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 14:27:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Epelbaum", "Thomas", "", "IPHT"], ["Gamboa", "Fabrice", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Martin", "Jessica", ""]]}, {"id": "1710.08306", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu and Dario Pompili and Saman Zonouz and Vincent\n  Sritapan", "title": "CollabLoc: Privacy-Preserving Multi-Modal Localization via Collaborative\n  Information Fusion", "comments": "9 pages, 26th International Conference on Computer Communication and\n  Networks (ICCCN), Vancouver, BC, Canada, 2017, pp. 1-9", "journal-ref": null, "doi": "10.1109/ICCCN.2017.8038390", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones provide an excellent opportunity for building context-aware\napplications. In particular, location-based services are important\ncontext-aware services that are more and more used for enforcing security\npolicies, for supporting indoor room navigation, and for providing personalized\nassistance. However, a major problem still remains unaddressed---the lack of\nsolutions that work across buildings while not using additional infrastructure\nand also accounting for privacy and reliability needs. In this paper, a\nprivacy-preserving, multi-modal, cross-building, collaborative localization\nplatform is proposed based on Wi-Fi RSSI (existing infrastructure), Cellular\nRSSI, sound and light levels, that enables room-level localization as main\napplication (though sub room level granularity is possible). The privacy is\ninherently built into the solution based on onion routing, and\nperturbation/randomization techniques, and exploits the idea of weighted\ncollaboration to increase the reliability as well as to limit the effect of\nnoisy devices (due to sensor noise/privacy). The proposed solution has been\nanalyzed in terms of privacy, accuracy, optimum parameters, and other overheads\non location data collected at multiple indoor and outdoor locations using an\nAndroid app.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 23:05:19 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Pompili", "Dario", ""], ["Zonouz", "Saman", ""], ["Sritapan", "Vincent", ""]]}, {"id": "1710.08310", "submitter": "Kai Han", "authors": "Kai Han, Yunhe Wang, Chao Zhang, Chao Li, Chao Xu", "title": "AutoEncoder Inspired Unsupervised Feature Selection", "comments": "accepted by ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data in many areas such as computer vision and machine\nlearning tasks brings in computational and analytical difficulty. Feature\nselection which selects a subset from observed features is a widely used\napproach for improving performance and effectiveness of machine learning models\nwith high-dimensional data. In this paper, we propose a novel AutoEncoder\nFeature Selector (AEFS) for unsupervised feature selection which combines\nautoencoder regression and group lasso tasks. Compared to traditional feature\nselection methods, AEFS can select the most important features by excavating\nboth linear and nonlinear information among features, which is more flexible\nthan the conventional self-representation method for unsupervised feature\nselection with only linear assumptions. Experimental results on benchmark\ndataset show that the proposed method is superior to the state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 14:44:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 01:19:12 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 13:54:48 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Han", "Kai", ""], ["Wang", "Yunhe", ""], ["Zhang", "Chao", ""], ["Li", "Chao", ""], ["Xu", "Chao", ""]]}, {"id": "1710.08335", "submitter": "Anestis Tsakmalis", "authors": "Anestis Tsakmalis, Symeon Chatzinotas, Bj\\\"orn Ottersten", "title": "Constrained Bayesian Active Learning of Interference Channels in\n  Cognitive Radio Networks", "comments": "14 pages, 6 figures, submitted to IEEE JSTSP Special Issue on Machine\n  Learning for Cognition in Radio Communications and Radar", "journal-ref": null, "doi": "10.1109/JSTSP.2017.2785826", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a sequential probing method for interference constraint\nlearning is proposed to allow a centralized Cognitive Radio Network (CRN)\naccessing the frequency band of a Primary User (PU) in an underlay cognitive\nscenario with a designed PU protection specification. The main idea is that the\nCRN probes the PU and subsequently eavesdrops the reverse PU link to acquire\nthe binary ACK/NACK packet. This feedback indicates whether the probing-induced\ninterference is harmful or not and can be used to learn the PU interference\nconstraint. The cognitive part of this sequential probing process is the\nselection of the power levels of the Secondary Users (SUs) which aims to learn\nthe PU interference constraint with a minimum number of probing attempts while\nsetting a limit on the number of harmful probing-induced interference events or\nequivalently of NACK packet observations over a time window. This constrained\ndesign problem is studied within the Active Learning (AL) framework and an\noptimal solution is derived and implemented with a sophisticated, accurate and\nfast Bayesian Learning method, the Expectation Propagation (EP). The\nperformance of this solution is also demonstrated through numerical simulations\nand compared with modified versions of AL techniques we developed in earlier\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 15:31:32 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Tsakmalis", "Anestis", ""], ["Chatzinotas", "Symeon", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "1710.08347", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Ruslan Salakhutdinov", "title": "Improving One-Shot Learning through Fusing Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) often struggle with one-shot learning where we\nhave only one or a few labeled training examples per category. In this paper,\nwe argue that by using side information, we may compensate the missing\ninformation across classes. We introduce two statistical approaches for fusing\nside information into data representation learning to improve one-shot\nlearning. First, we propose to enforce the statistical dependency between data\nrepresentations and multiple types of side information. Second, we introduce an\nattention mechanism to efficiently treat examples belonging to the\n'lots-of-examples' classes as quasi-samples (additional training samples) for\n'one-example' classes. We empirically show that our learning architecture\nimproves over traditional softmax regression networks as well as\nstate-of-the-art attentional regression networks on one-shot recognition tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 15:50:20 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 04:27:47 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1710.08402", "submitter": "Zachary Charles", "authors": "Zachary Charles, Dimitris Papailiopoulos", "title": "Stability and Generalization of Learning Algorithms that Converge to\n  Global Optima", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish novel generalization bounds for learning algorithms that\nconverge to global minima. We do so by deriving black-box stability results\nthat only depend on the convergence of a learning algorithm and the geometry\naround the minimizers of the loss function. The results are shown for nonconvex\nloss functions satisfying the Polyak-{\\L}ojasiewicz (PL) and the quadratic\ngrowth (QG) conditions. We further show that these conditions arise for some\nneural networks with linear activations. We use our black-box results to\nestablish the stability of optimization algorithms such as stochastic gradient\ndescent (SGD), gradient descent (GD), randomized coordinate descent (RCD), and\nthe stochastic variance reduced gradient method (SVRG), in both the PL and the\nstrongly convex setting. Our results match or improve state-of-the-art\ngeneralization bounds and can easily be extended to similar optimization\nalgorithms. Finally, we show that although our results imply comparable\nstability for SGD and GD in the PL setting, there exist simple neural networks\nwith multiple local minima where SGD is stable but GD is not.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 17:42:30 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1710.08446", "submitter": "Mihaela Rosca", "authors": "William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew M. Dai,\n  Shakir Mohamed, Ian Goodfellow", "title": "Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At\n  Every Step", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a family of generative models that\ndo not minimize a single training criterion. Unlike other generative models,\nthe data distribution is learned via a game between a generator (the generative\nmodel) and a discriminator (a teacher providing training signal) that each\nminimize their own cost. GANs are designed to reach a Nash equilibrium at which\neach player cannot reduce their cost without changing the other players'\nparameters. One useful approach for the theory of GANs is to show that a\ndivergence between the training distribution and the model distribution obtains\nits minimum value at equilibrium. Several recent research directions have been\nmotivated by the idea that this divergence is the primary guide for the\nlearning process and that every step of learning should decrease the\ndivergence. We show that this view is overly restrictive. During GAN training,\nthe discriminator provides learning signal in situations where the gradients of\nthe divergences between distributions would not be useful. We provide empirical\ncounterexamples to the view of GAN training as divergence minimization.\nSpecifically, we demonstrate that GANs are able to learn distributions in\nsituations where the divergence minimization point of view predicts they would\nfail. We also show that gradient penalties motivated from the divergence\nminimization perspective are equally helpful when applied in other contexts in\nwhich the divergence minimization perspective does not predict they would be\nhelpful. This contributes to a growing body of evidence that GAN training may\nbe more usefully viewed as approaching Nash equilibria via trajectories that do\nnot necessarily minimize a specific divergence at each step.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 18:30:56 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 09:02:49 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 22:10:33 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Fedus", "William", ""], ["Rosca", "Mihaela", ""], ["Lakshminarayanan", "Balaji", ""], ["Dai", "Andrew M.", ""], ["Mohamed", "Shakir", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1710.08464", "submitter": "Benjamin Baron", "authors": "Benjamin Baron and Mirco Musolesi", "title": "Interpretable Machine Learning for Privacy-Preserving Pervasive Systems", "comments": null, "journal-ref": "IEEE Pervasive Computing, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our everyday interactions with pervasive systems generate traces that capture\nvarious aspects of human behavior and enable machine learning algorithms to\nextract latent information about users. In this paper, we propose a machine\nlearning interpretability framework that enables users to understand how these\ngenerated traces violate their privacy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 19:19:55 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 17:02:19 GMT"}, {"version": "v3", "created": "Wed, 29 Nov 2017 16:45:31 GMT"}, {"version": "v4", "created": "Tue, 9 Jan 2018 14:46:02 GMT"}, {"version": "v5", "created": "Wed, 13 Jun 2018 17:38:07 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2019 21:17:51 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Baron", "Benjamin", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1710.08473", "submitter": "Christopher Xie", "authors": "Christopher Xie, Alex Tank, Alec Greaves-Tunnell, Emily Fox", "title": "A Unified Framework for Long Range and Cold Start Forecasting of\n  Seasonal Profiles in Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing long-range forecasts is a fundamental challenge in time series\nmodeling, which is only compounded by the challenge of having to form such\nforecasts when a time series has never previously been observed. The latter\nchallenge is the time series version of the cold-start problem seen in\nrecommender systems which, to our knowledge, has not been addressed in previous\nwork. A similar problem occurs when a long range forecast is required after\nonly observing a small number of time points --- a warm start forecast. With\nthese aims in mind, we focus on forecasting seasonal profiles---or baseline\ndemand---for periods on the order of a year in three cases: the long range case\nwith multiple previously observed seasonal profiles, the cold start case with\nno previous observed seasonal profiles, and the warm start case with only a\nsingle partially observed profile. Classical time series approaches that\nperform iterated step-ahead forecasts based on previous observations struggle\nto provide accurate long range predictions; in settings with little to no\nobserved data, such approaches are simply not applicable. Instead, we present a\nstraightforward framework which combines ideas from high-dimensional regression\nand matrix factorization on a carefully constructed data matrix. Key to our\nformulation and resulting performance is leveraging (1) repeated patterns over\nfixed periods of time and across series, and (2) metadata associated with the\nindividual series; without this additional data, the cold-start/warm-start\nproblems are nearly impossible to solve. We demonstrate that our framework can\naccurately forecast an array of seasonal profiles on multiple large scale\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 19:37:00 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 19:48:07 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Xie", "Christopher", ""], ["Tank", "Alex", ""], ["Greaves-Tunnell", "Alec", ""], ["Fox", "Emily", ""]]}, {"id": "1710.08496", "submitter": "Haishan Ye", "authors": "Haishan Ye, Zhihua Zhang", "title": "Nesterov's Acceleration For Approximate Newton", "comments": "supercedes arXiv:1705.07171", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Optimization plays a key role in machine learning. Recently, stochastic\nsecond-order methods have attracted much attention due to their low\ncomputational cost in each iteration. However, these algorithms might perform\npoorly especially if it is hard to approximate the Hessian well and\nefficiently. As far as we know, there is no effective way to handle this\nproblem. In this paper, we resort to Nesterov's acceleration technique to\nimprove the convergence performance of a class of second-order methods called\napproximate Newton. We give a theoretical analysis that Nesterov's acceleration\ntechnique can improve the convergence performance for approximate Newton just\nlike for first-order methods. We accordingly propose an accelerated regularized\nsub-sampled Newton. Our accelerated algorithm performs much better than the\noriginal regularized sub-sampled Newton in experiments, which validates our\ntheory empirically. Besides, the accelerated regularized sub-sampled Newton has\ngood performance comparable to or even better than classical algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 06:18:24 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Ye", "Haishan", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1710.08502", "submitter": "Feipeng Zhao", "authors": "Feipeng Zhao and Martin Renqiang Min and Chen Shen and Amit\n  Chakraborty", "title": "Convolutional Neural Knowledge Graph Learning", "comments": "evaluation mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous models for learning entity and relationship embeddings of knowledge\ngraphs such as TransE, TransH, and TransR aim to explore new links based on\nlearned representations. However, these models interpret relationships as\nsimple translations on entity embeddings. In this paper, we try to learn more\ncomplex connections between entities and relationships. In particular, we use a\nConvolutional Neural Network (CNN) to learn entity and relationship\nrepresentations in knowledge graphs. In our model, we treat entities and\nrelationships as one-dimensional numerical sequences with the same length.\nAfter that, we combine each triplet of head, relationship, and tail together as\na matrix with height 3. CNN is applied to the triplets to get confidence\nscores. Positive and manually corrupted negative triplets are used to train the\nembeddings and the CNN model simultaneously. Experimental results on public\nbenchmark datasets show that the proposed model outperforms state-of-the-art\nmodels on exploring unseen relationships, which proves that CNN is effective to\nlearn complex interactive patterns between entities and relationships.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 20:39:40 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 19:58:14 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Zhao", "Feipeng", ""], ["Min", "Martin Renqiang", ""], ["Shen", "Chen", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1710.08530", "submitter": "Ali Heydari", "authors": "Ali Heydari", "title": "Stability Analysis of Optimal Adaptive Control using Value Iteration\n  with Approximation Errors", "comments": "A part of this paper is based on preliminary results presented in\n  arXiv:1412.5675", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimal control using value iteration initiated from a stabilizing\ncontrol policy is theoretically analyzed in terms of stability of the system\nduring the learning stage without ignoring the effects of approximation errors.\nThis analysis includes the system operated using any single/constant resulting\ncontrol policy and also using an evolving/time-varying control policy. A\nfeature of the presented results is providing estimations of the \\textit{region\nof attraction} so that if the initial condition is within the region, the whole\ntrajectory will remain inside it and hence, the function approximation results\nremain valid.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 22:20:22 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Heydari", "Ali", ""]]}, {"id": "1710.08531", "submitter": "Zhengping Che", "authors": "Sanjay Purushotham, Chuizheng Meng, Zhengping Che, Yan Liu", "title": "Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets", "comments": "Submitted to Journal of Biomedical Informatics (JBI). First two\n  authors have equal contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models (aka Deep Neural Networks) have revolutionized many\nfields including computer vision, natural language processing, speech\nrecognition, and is being increasingly used in clinical healthcare\napplications. However, few works exist which have benchmarked the performance\nof the deep learning models with respect to the state-of-the-art machine\nlearning models and prognostic scoring systems on publicly available healthcare\ndatasets. In this paper, we present the benchmarking results for several\nclinical prediction tasks such as mortality prediction, length of stay\nprediction, and ICD-9 code group prediction using Deep Learning models,\nensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA\nscores. We used the Medical Information Mart for Intensive Care III (MIMIC-III)\n(v1.4) publicly available dataset, which includes all patients admitted to an\nICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the\nbenchmarking tasks. Our results show that deep learning models consistently\noutperform all the other approaches especially when the `raw' clinical time\nseries data is used as input features to the models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 22:23:34 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Purushotham", "Sanjay", ""], ["Meng", "Chuizheng", ""], ["Che", "Zhengping", ""], ["Liu", "Yan", ""]]}, {"id": "1710.08543", "submitter": "Sungbin Lim", "authors": "Hyungjoo Cho, Sungbin Lim, Gunho Choi, Hyunseok Min", "title": "Neural Stain-Style Transfer Learning using GAN for Histopathological\n  Images", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of data-driven network for tumor classification varies with\nstain-style of histopathological images. This article proposes the stain-style\ntransfer (SST) model based on conditional generative adversarial networks\n(GANs) which is to learn not only the certain color distribution but also the\ncorresponding histopathological pattern. Our model considers feature-preserving\nloss in addition to well-known GAN loss. Consequently our model does not only\ntransfers initial stain-styles to the desired one but also prevent the\ndegradation of tumor classifier on transferred images. The model is examined\nusing the CAMELYON16 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 23:02:25 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 11:15:25 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Cho", "Hyungjoo", ""], ["Lim", "Sungbin", ""], ["Choi", "Gunho", ""], ["Min", "Hyunseok", ""]]}, {"id": "1710.08585", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Ashwin A. Kannan, Gautam Arakalgud, Marios Savvides", "title": "Max-Margin Invariant Features from Transformed Unlabeled Data", "comments": "Accepted at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of representations invariant to common transformations of the data\nis important to learning. Most techniques have focused on local approximate\ninvariance implemented within expensive optimization frameworks lacking\nexplicit theoretical guarantees. In this paper, we study kernels that are\ninvariant to a unitary group while having theoretical guarantees in addressing\nthe important practical issue of unavailability of transformed versions of\nlabelled data. A problem we call the Unlabeled Transformation Problem which is\na special form of semi-supervised learning and one-shot learning. We present a\ntheoretically motivated alternate approach to the invariant kernel SVM based on\nwhich we propose Max-Margin Invariant Features (MMIF) to solve this problem. As\nan illustration, we design an framework for face recognition and demonstrate\nthe efficacy of our approach on a large scale semi-synthetic dataset with\n153,000 images and a new challenging protocol on Labelled Faces in the Wild\n(LFW) while out-performing strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 02:57:37 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Pal", "Dipan K.", ""], ["Kannan", "Ashwin A.", ""], ["Arakalgud", "Gautam", ""], ["Savvides", "Marios", ""]]}, {"id": "1710.08619", "submitter": "Sambuddha Ghosal", "authors": "Sambuddha Ghosal, David Blystone, Asheesh K. Singh, Baskar\n  Ganapathysubramanian, Arti Singh and Soumik Sarkar", "title": "Interpretable Deep Learning applied to Plant Stress Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Availability of an explainable deep learning model that can be applied to\npractical real world scenarios and in turn, can consistently, rapidly and\naccurately identify specific and minute traits in applicable fields of\nbiological sciences, is scarce. Here we consider one such real world example\nviz., accurate identification, classification and quantification of biotic and\nabiotic stresses in crop research and production. Up until now, this has been\npredominantly done manually by visual inspection and require specialized\ntraining. However, such techniques are hindered by subjectivity resulting from\ninter- and intra-rater cognitive variability. Here, we demonstrate the ability\nof a machine learning framework to identify and classify a diverse set of\nfoliar stresses in the soybean plant with remarkable accuracy. We also present\nan explanation mechanism using gradient-weighted class activation mapping that\nisolates the visual symptoms used by the model to make predictions. This\nunsupervised identification of unique visual symptoms for each stress provides\na quantitative measure of stress severity, allowing for identification,\nclassification and quantification in one framework. The learnt model appears to\nbe agnostic to species and make good predictions for other (non-soybean)\nspecies, demonstrating an ability of transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 06:49:03 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 21:33:19 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 22:10:09 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Ghosal", "Sambuddha", ""], ["Blystone", "David", ""], ["Singh", "Asheesh K.", ""], ["Ganapathysubramanian", "Baskar", ""], ["Singh", "Arti", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1710.08637", "submitter": "Vincent Gripon", "authors": "Vincent Gripon and Ghouthi B. Hacene and Matthias L\\\"owe and Franck\n  Vermet", "title": "Improving Accuracy of Nonparametric Transfer Learning via Vector\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning using deep neural networks as feature extractors has become\nincreasingly popular over the past few years. It allows to obtain\nstate-of-the-art accuracy on datasets too small to train a deep neural network\non its own, and it provides cutting edge descriptors that, combined with\nnonparametric learning methods, allow rapid and flexible deployment of\nperforming solutions in computationally restricted settings. In this paper, we\nare interested in showing that the features extracted using deep neural\nnetworks have specific properties which can be used to improve accuracy of\ndownstream nonparametric learning methods. Namely, we demonstrate that for some\ndistributions where information is embedded in a few coordinates, segmenting\nfeature vectors can lead to better accuracy. We show how this model can be\napplied to real datasets by performing experiments using three mainstream deep\nneural network feature extractors and four databases, in vision and audio.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 07:46:57 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Gripon", "Vincent", ""], ["Hacene", "Ghouthi B.", ""], ["L\u00f6we", "Matthias", ""], ["Vermet", "Franck", ""]]}, {"id": "1710.08717", "submitter": "Zhenwen Dai", "authors": "Matthias Seeger, Asmus Hetzel, Zhenwen Dai, Eric Meissner, Neil D.\n  Lawrence", "title": "Auto-Differentiating Linear Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development systems for deep learning (DL), such as Theano, Torch,\nTensorFlow, or MXNet, are easy-to-use tools for creating complex neural network\nmodels. Since gradient computations are automatically baked in, and execution\nis mapped to high performance hardware, these models can be trained end-to-end\non large amounts of data. However, it is currently not easy to implement many\nbasic machine learning primitives in these systems (such as Gaussian processes,\nleast squares estimation, principal components analysis, Kalman smoothing),\nmainly because they lack efficient support of linear algebra primitives as\ndifferentiable operators. We detail how a number of matrix decompositions\n(Cholesky, LQ, symmetric eigen) can be implemented as differentiable operators.\nWe have implemented these primitives in MXNet, running on CPU and GPU in single\nand double precision. We sketch use cases of these new operators, learning\nGaussian process and Bayesian linear regression models, where we demonstrate\nvery substantial reductions in implementation complexity and running time\ncompared to previous codes. Our MXNet extension allows end-to-end learning of\nhybrid models, which combine deep neural networks (DNNs) with Bayesian\nconcepts, with applications in advanced Gaussian process models, scalable\nBayesian optimization, and Bayesian active learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 11:58:45 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 15:13:38 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 13:48:27 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 09:40:13 GMT"}, {"version": "v5", "created": "Wed, 14 Aug 2019 13:08:25 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Seeger", "Matthias", ""], ["Hetzel", "Asmus", ""], ["Dai", "Zhenwen", ""], ["Meissner", "Eric", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1710.08729", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "A Correction Method of a Binary Classifier Applied to Multi-label\n  Pairwise Models", "comments": null, "journal-ref": null, "doi": "10.1142/s0129065717500629", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we addressed the issue of applying a stochastic classifier and\na local, fuzzy confusion matrix under the framework of multi-label\nclassification. We proposed a novel solution to the problem of correcting label\npairwise ensembles. The main step of the correction procedure is to compute\nclassifier- specific competence and cross-competence measures, which estimates\nerror pattern of the underlying classifier. We considered two improvements of\nthe method of obtaining confusion matrices. The first one is aimed to deal with\nimbalanced labels. The other utilizes double labelled instances which are\nusually removed during the pairwise transformation. The proposed methods were\nevaluated using 29 benchmark datasets. In order to assess the efficiency of the\nintroduced models, they were compared against 1 state-of-the-art approach and\nthe correction scheme based on the original method of confusion matrix\nestimation. The comparison was performed using four different multi-label\nevaluation measures: macro and micro-averaged F1 loss, zero-one loss and\nHamming loss. Additionally, we investigated relations between classification\nquality, which is expressed in terms of different quality criteria, and\ncharacteristics of multi-label datasets such as average imbalance ratio or\nlabel density. The experimental study reveals that the correction approaches\nsignificantly outperforms the reference method only in terms of zero-one loss.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 12:23:22 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.08846", "submitter": "Yunchuan Kong", "authors": "Yunchuan Kong and Xiaodan Fan", "title": "A Bayesian Method for Joint Clustering of Vectorial Data and Network\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based integrative method for clustering objects given\nboth vectorial data, which describes the feature of each object, and network\ndata, which indicates the similarity of connected objects. The proposed general\nmodel is able to cluster the two types of data simultaneously within one\nintegrative probabilistic model, while traditional methods can only handle one\ndata type or depend on transforming one data type to another. Bayesian\ninference of the clustering is conducted based on a Markov chain Monte Carlo\nalgorithm. A special case of the general model combining the Gaussian mixture\nmodel and the stochastic block model is extensively studied. We used both\nsynthetic data and real data to evaluate this new method and compare it with\nalternative methods. The results show that our simultaneous clustering method\nperforms much better. This improvement is due to the power of the model-based\nprobabilistic approach for efficiently integrating information.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 15:26:46 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Kong", "Yunchuan", ""], ["Fan", "Xiaodan", ""]]}, {"id": "1710.08864", "submitter": "Jiawei Su", "authors": "Jiawei Su, Danilo Vasconcellos Vargas and Sakurai Kouichi", "title": "One pixel attack for fooling deep neural networks", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation}, Vol.23 , Issue.5 ,\n  pp. 828--841. Publisher: IEEE. 2019", "doi": "10.1109/TEVC.2019.2890858", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has revealed that the output of Deep Neural Networks (DNN)\ncan be easily altered by adding relatively small perturbations to the input\nvector. In this paper, we analyze an attack in an extremely limited scenario\nwhere only one pixel can be modified. For that we propose a novel method for\ngenerating one-pixel adversarial perturbations based on differential evolution\n(DE). It requires less adversarial information (a black-box attack) and can\nfool more types of networks due to the inherent features of DE. The results\nshow that 67.97% of the natural images in Kaggle CIFAR-10 test dataset and\n16.04% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least\none target class by modifying just one pixel with 74.03% and 22.91% confidence\non average. We also show the same vulnerability on the original CIFAR-10\ndataset. Thus, the proposed attack explores a different take on adversarial\nmachine learning in an extreme limited scenario, showing that current DNNs are\nalso vulnerable to such low dimension attacks. Besides, we also illustrate an\nimportant application of DE (or broadly speaking, evolutionary computation) in\nthe domain of adversarial machine learning: creating tools that can effectively\ngenerate low-cost adversarial attacks against neural networks for evaluating\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:02:19 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 07:58:35 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 08:53:44 GMT"}, {"version": "v4", "created": "Thu, 22 Feb 2018 09:18:34 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 04:39:30 GMT"}, {"version": "v6", "created": "Fri, 3 May 2019 08:32:24 GMT"}, {"version": "v7", "created": "Thu, 17 Oct 2019 07:46:53 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Su", "Jiawei", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Kouichi", "Sakurai", ""]]}, {"id": "1710.08878", "submitter": "Andreas Haupt", "authors": "Andreas Haupt, Mohammad Khatami, Thomas Schultz, Ngoc Mai Tran", "title": "Classification on Large Networks: A Quantitative Bound via Motifs and\n  Graphons", "comments": "17 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When each data point is a large graph, graph statistics such as densities of\ncertain subgraphs (motifs) can be used as feature vectors for machine learning.\nWhile intuitive, motif counts are expensive to compute and difficult to work\nwith theoretically. Via graphon theory, we give an explicit quantitative bound\nfor the ability of motif homomorphisms to distinguish large networks under both\ngenerative and sampling noise. Furthermore, we give similar bounds for the\ngraph spectrum and connect it to homomorphism densities of cycles. This results\nin an easily computable classifier on graph data with theoretical performance\nguarantee. Our method yields competitive results on classification tasks for\nthe autoimmune disease Lupus Erythematosus.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:34:37 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Haupt", "Andreas", ""], ["Khatami", "Mohammad", ""], ["Schultz", "Thomas", ""], ["Tran", "Ngoc Mai", ""]]}, {"id": "1710.08883", "submitter": "Saeed Soori", "authors": "Saeed Soori, Aditya Devarakonda, James Demmel, Mert Gurbuzbalaban,\n  Maryam Mehri Dehnavi", "title": "Avoiding Communication in Proximal Methods for Convex Optimization\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast iterative soft thresholding algorithm (FISTA) is used to solve\nconvex regularized optimization problems in machine learning. Distributed\nimplementations of the algorithm have become popular since they enable the\nanalysis of large datasets. However, existing formulations of FISTA communicate\ndata at every iteration which reduces its performance on modern distributed\narchitectures. The communication costs of FISTA, including bandwidth and\nlatency costs, is closely tied to the mathematical formulation of the\nalgorithm. This work reformulates FISTA to communicate data at every k\niterations and reduce data communication when operating on large data sets. We\nformulate the algorithm for two different optimization methods on the Lasso\nproblem and show that the latency cost is reduced by a factor of k while\nbandwidth and floating-point operation costs remain the same. The convergence\nrates and stability properties of the reformulated algorithms are similar to\nthe standard formulations. The performance of communication-avoiding FISTA and\nProximal Newton methods is evaluated on 1 to 1024 nodes for multiple benchmarks\nand demonstrate average speedups of 3-10x with scaling properties that\noutperform the classical algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:47:23 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Soori", "Saeed", ""], ["Devarakonda", "Aditya", ""], ["Demmel", "James", ""], ["Gurbuzbalaban", "Mert", ""], ["Dehnavi", "Maryam Mehri", ""]]}, {"id": "1710.08893", "submitter": "Shaojun Zhu", "authors": "Shaojun Zhu, Andrew Kimmel, Kostas E. Bekris and Abdeslam Boularias", "title": "Fast Model Identification via Physics Engines for Data-Efficient Policy\n  Search", "comments": "IJCAI 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for identifying mechanical parameters of robots\nor objects, such as their mass and friction coefficients. Key features are the\nuse of off-the-shelf physics engines and the adaptation of a Bayesian\noptimization technique towards minimizing the number of real-world experiments\nneeded for model-based reinforcement learning. The proposed framework\nreproduces in a physics engine experiments performed on a real robot and\noptimizes the model's mechanical parameters so as to match real-world\ntrajectories. The optimized model is then used for learning a policy in\nsimulation, before real-world deployment. It is well understood, however, that\nit is hard to exactly reproduce real trajectories in simulation. Moreover, a\nnear-optimal policy can be frequently found with an imperfect model. Therefore,\nthis work proposes a strategy for identifying a model that is just good enough\nto approximate the value of a locally optimal policy with a certain confidence,\ninstead of wasting effort on identifying the most accurate model. Evaluations,\nperformed both in simulation and on a real robotic manipulation task, indicate\nthat the proposed strategy results in an overall time-efficient, integrated\nmodel identification and learning solution, which significantly improves the\ndata-efficiency of existing policy search algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 17:08:20 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 19:45:10 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 13:03:41 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Zhu", "Shaojun", ""], ["Kimmel", "Andrew", ""], ["Bekris", "Kostas E.", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "1710.08894", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ilia Nouretdinov, Valery Manokhin, and Alex Gammerman", "title": "Conformal predictive distributions with kernels", "comments": "20 pages, 3 figures, prepared for the Proceedings of the Braverman\n  Readings (Boston, 28-30 April 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the checkered history of predictive distributions in\nstatistics and discusses two developments, one from recent literature and the\nother new. The first development is bringing predictive distributions into\nmachine learning, whose early development was so deeply influenced by two\nremarkable groups at the Institute of Automation and Remote Control. The second\ndevelopment is combining predictive distributions with kernel methods, which\nwere originated by one of those groups, including Emmanuel Braverman.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 17:10:49 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Vovk", "Vladimir", ""], ["Nouretdinov", "Ilia", ""], ["Manokhin", "Valery", ""], ["Gammerman", "Alex", ""]]}, {"id": "1710.08936", "submitter": "Hoi-To Wai", "authors": "Hoi-To Wai, Wei Shi, Angelia Nedic and Anna Scaglione", "title": "Curvature-aided Incremental Aggregated Gradient Method", "comments": "Final version submitted to Allerton Conference 2017 on Oct 8, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new algorithm for finite sum optimization which we call the\ncurvature-aided incremental aggregated gradient (CIAG) method. Motivated by the\nproblem of training a classifier for a d-dimensional problem, where the number\nof training data is $m$ and $m \\gg d \\gg 1$, the CIAG method seeks to\naccelerate incremental aggregated gradient (IAG) methods using aids from the\ncurvature (or Hessian) information, while avoiding the evaluation of matrix\ninverses required by the incremental Newton (IN) method. Specifically, our idea\nis to exploit the incrementally aggregated Hessian matrix to trace the full\ngradient vector at every incremental step, therefore achieving an improved\nlinear convergence rate over the state-of-the-art IAG methods. For strongly\nconvex problems, the fast linear convergence rate requires the objective\nfunction to be close to quadratic, or the initial point to be close to optimal\nsolution. Importantly, we show that running one iteration of the CIAG method\nyields the same improvement to the optimality gap as running one iteration of\nthe full gradient method, while the complexity is $O(d^2)$ for CIAG and $O(md)$\nfor the full gradient. Overall, the CIAG method strikes a balance between the\nhigh computation complexity incremental Newton-type methods and the slow IAG\nmethod. Our numerical results support the theoretical findings and show that\nthe CIAG method often converges with much fewer iterations than IAG, and\nrequires much shorter running time than IN when the problem dimension is high.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 18:12:33 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Wai", "Hoi-To", ""], ["Shi", "Wei", ""], ["Nedic", "Angelia", ""], ["Scaglione", "Anna", ""]]}, {"id": "1710.08937", "submitter": "Vincent Froese", "authors": "Markus Brill, Till Fluschnik, Vincent Froese, Brijnesh Jain, Rolf\n  Niedermeier, David Schultz", "title": "Exact Mean Computation in Dynamic Time Warping Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic time warping constitutes a major tool for analyzing time series. In\nparticular, computing a mean series of a given sample of series in dynamic time\nwarping spaces (by minimizing the Fr\\'echet function) is a challenging\ncomputational problem, so far solved by several heuristic and inexact\nstrategies. We spot some inaccuracies in the literature on exact mean\ncomputation in dynamic time warping spaces. Our contributions comprise an exact\ndynamic program computing a mean (useful for benchmarking and evaluating known\nheuristics). Based on this dynamic program, we empirically study properties\nlike uniqueness and length of a mean. Moreover, experimental evaluations reveal\nsubstantial deficits of state-of-the-art heuristics in terms of their output\nquality. We also give an exact polynomial-time algorithm for the special case\nof binary time series.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 18:12:35 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 19:13:55 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 12:16:00 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Brill", "Markus", ""], ["Fluschnik", "Till", ""], ["Froese", "Vincent", ""], ["Jain", "Brijnesh", ""], ["Niedermeier", "Rolf", ""], ["Schultz", "David", ""]]}, {"id": "1710.08961", "submitter": "Milad Makkie", "authors": "Milad Makkie, Heng Huang, Yu Zhao, Athanasios V. Vasilakos, Tianming\n  Liu", "title": "Fast and Scalable Distributed Deep Convolutional Autoencoder for fMRI\n  Big Data Analytics", "comments": "This work is submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, analyzing task-based fMRI (tfMRI) data has become an\nessential tool for understanding brain function and networks. However, due to\nthe sheer size of tfMRI data, its intrinsic complex structure, and lack of\nground truth of underlying neural activities, modeling tfMRI data is hard and\nchallenging. Previously proposed data-modeling methods including Independent\nComponent Analysis (ICA) and Sparse Dictionary Learning only provided a weakly\nestablished model based on blind source separation under the strong assumption\nthat original fMRI signals could be linearly decomposed into time series\ncomponents with corresponding spatial maps. Meanwhile, analyzing and learning a\nlarge amount of tfMRI data from a variety of subjects has been shown to be very\ndemanding but yet challenging even with technological advances in computational\nhardware. Given the Convolutional Neural Network (CNN), a robust method for\nlearning high-level abstractions from low-level data such as tfMRI time series,\nin this work we propose a fast and scalable novel framework for distributed\ndeep Convolutional Autoencoder model. This model aims to both learn the complex\nhierarchical structure of the tfMRI data and to leverage the processing power\nof multiple GPUs in a distributed fashion. To implement such a model, we have\ncreated an enhanced processing pipeline on the top of Apache Spark and\nTensorflow library, leveraging from a very large cluster of GPU machines.\nExperimental data from applying the model on the Human Connectome Project (HCP)\nshow that the proposed model is efficient and scalable toward tfMRI big data\nanalytics, thus enabling data-driven extraction of hierarchical neuroscientific\ninformation from massive fMRI big data in the future.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:35:51 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 07:46:58 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2018 21:31:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Makkie", "Milad", ""], ["Huang", "Heng", ""], ["Zhao", "Yu", ""], ["Vasilakos", "Athanasios V.", ""], ["Liu", "Tianming", ""]]}, {"id": "1710.08963", "submitter": "Patrick Perry", "authors": "Patrick O. Perry and Kenneth Benoit", "title": "Scaling Text with the Class Affinity Model", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic methods for classifying text form a rich tradition in machine\nlearning and natural language processing. For many important problems, however,\nclass prediction is uninteresting because the class is known, and instead the\nfocus shifts to estimating latent quantities related to the text, such as\naffect or ideology. We focus on one such problem of interest, estimating the\nideological positions of 55 Irish legislators in the 1991 D\\'ail confidence\nvote. To solve the D\\'ail scaling problem and others like it, we develop a text\nmodeling framework that allows actors to take latent positions on a \"gray\"\nspectrum between \"black\" and \"white\" polar opposites. We are able to validate\nresults from this model by measuring the influences exhibited by individual\nwords, and we are able to quantify the uncertainty in the scaling estimates by\nusing a sentence-level block bootstrap. Applying our method to the D\\'ail\ndebate, we are able to scale the legislators between extreme pro-government and\npro-opposition in a way that reveals nuances in their speeches not captured by\ntheir votes or party affiliations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:38:20 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Perry", "Patrick O.", ""], ["Benoit", "Kenneth", ""]]}, {"id": "1710.08969", "submitter": "Hideyuki Tachibana", "authors": "Hideyuki Tachibana, Katsuya Uenoyama, Shunsuke Aihara", "title": "Efficiently Trainable Text-to-Speech System Based on Deep Convolutional\n  Networks with Guided Attention", "comments": "5 pages, 3figures, IEEE ICASSP 2018", "journal-ref": "Proc. ICASSP (2018) 4784-4788", "doi": "10.1109/ICASSP.2018.8461829", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel text-to-speech (TTS) technique based on deep\nconvolutional neural networks (CNN), without use of any recurrent units.\nRecurrent neural networks (RNN) have become a standard technique to model\nsequential data recently, and this technique has been used in some cutting-edge\nneural TTS techniques. However, training RNN components often requires a very\npowerful computer, or a very long time, typically several days or weeks. Recent\nother studies, on the other hand, have shown that CNN-based sequence synthesis\ncan be much faster than RNN-based techniques, because of high\nparallelizability. The objective of this paper is to show that an alternative\nneural TTS based only on CNN alleviate these economic costs of training. In our\nexperiment, the proposed Deep Convolutional TTS was sufficiently trained\novernight (15 hours), using an ordinary gaming PC equipped with two GPUs, while\nthe quality of the synthesized speech was almost acceptable.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:56:32 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 05:41:53 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tachibana", "Hideyuki", ""], ["Uenoyama", "Katsuya", ""], ["Aihara", "Shunsuke", ""]]}, {"id": "1710.08997", "submitter": "Tomer Koren", "authors": "Tomer Koren, Roi Livni, Yishay Mansour", "title": "Multi-Armed Bandits with Metric Movement Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the non-stochastic Multi-Armed Bandit problem in a setting where\nthere is a fixed and known metric on the action space that determines a cost\nfor switching between any pair of actions. The loss of the online learner has\ntwo components: the first is the usual loss of the selected actions, and the\nsecond is an additional loss due to switching between actions. Our main\ncontribution gives a tight characterization of the expected minimax regret in\nthis setting, in terms of a complexity measure $\\mathcal{C}$ of the underlying\nmetric which depends on its covering numbers. In finite metric spaces with $k$\nactions, we give an efficient algorithm that achieves regret of the form\n$\\widetilde{O}(\\max\\{\\mathcal{C}^{1/3}T^{2/3},\\sqrt{kT}\\})$, and show that this\nis the best possible. Our regret bound generalizes previous known regret bounds\nfor some special cases: (i) the unit-switching cost regret\n$\\widetilde{\\Theta}(\\max\\{k^{1/3}T^{2/3},\\sqrt{kT}\\})$ where\n$\\mathcal{C}=\\Theta(k)$, and (ii) the interval metric with regret\n$\\widetilde{\\Theta}(\\max\\{T^{2/3},\\sqrt{kT}\\})$ where $\\mathcal{C}=\\Theta(1)$.\nFor infinite metrics spaces with Lipschitz loss functions, we derive a tight\nregret bound of $\\widetilde{\\Theta}(T^{\\frac{d+1}{d+2}})$ where $d \\ge 1$ is\nthe Minkowski dimension of the space, which is known to be tight even when\nthere are no switching costs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 21:34:31 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Koren", "Tomer", ""], ["Livni", "Roi", ""], ["Mansour", "Yishay", ""]]}, {"id": "1710.09001", "submitter": "Jingge Zhu", "authors": "Jingge Zhu, Ye Pu, Vipul Gupta, Claire Tomlin, Kannan Ramchandran", "title": "A Sequential Approximation Framework for Coded Distributed Optimization", "comments": "presented in 55th Annual Allerton Conference on Communication,\n  Control, and Computing, Oct. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the previous work of Lee et al. and Ferdinand et al. on coded\ncomputation, we propose a sequential approximation framework for solving\noptimization problems in a distributed manner. In a distributed computation\nsystem, latency caused by individual processors (\"stragglers\") usually causes a\nsignificant delay in the overall process. The proposed method is powered by a\nsequential computation scheme, which is designed specifically for systems with\nstragglers. This scheme has the desirable property that the user is guaranteed\nto receive useful (approximate) computation results whenever a processor\nfinishes its subtask, even in the presence of uncertain latency. In this paper,\nwe give a coding theorem for sequentially computing matrix-vector\nmultiplications, and the optimality of this coding scheme is also established.\nAs an application of the results, we demonstrate solving optimization problems\nusing a sequential approximation approach, which accelerates the algorithm in a\ndistributed system with stragglers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 21:53:21 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Zhu", "Jingge", ""], ["Pu", "Ye", ""], ["Gupta", "Vipul", ""], ["Tomlin", "Claire", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1710.09026", "submitter": "Markus Kliegl", "authors": "Markus Kliegl, Siddharth Goyal, Kexin Zhao, Kavya Srinet, Mohammad\n  Shoeybi", "title": "Trace norm regularization and faster inference for embedded speech\n  recognition RNNs", "comments": "Our optimized inference kernels are available at:\n  https://github.com/PaddlePaddle/farm (Note: This paper was submitted to, but\n  rejected from, ICLR 2018. We believe it may still be of value to others.\n  Please see the discussion here: https://openreview.net/forum?id=B1tC-LT6W)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate new techniques for compressing and speeding up dense\nmatrix multiplications as found in the fully connected and recurrent layers of\nneural networks for embedded large vocabulary continuous speech recognition\n(LVCSR). For compression, we introduce and study a trace norm regularization\ntechnique for training low rank factored versions of matrix multiplications.\nCompared to standard low rank training, we show that our method leads to good\naccuracy versus number of parameter trade-offs and can be used to speed up\ntraining of large models. For speedup, we enable faster inference on ARM\nprocessors through new open sourced kernels optimized for small batch sizes,\nresulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond\nLVCSR, we expect our techniques and kernels to be more generally applicable to\nembedded neural networks with large fully connected or recurrent layers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 00:20:55 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:00:10 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kliegl", "Markus", ""], ["Goyal", "Siddharth", ""], ["Zhao", "Kexin", ""], ["Srinet", "Kavya", ""], ["Shoeybi", "Mohammad", ""]]}, {"id": "1710.09027", "submitter": "Jianxin Zhao", "authors": "Jianxin Zhao, Richard Mortier, Jon Crowcroft, Liang Wang", "title": "User-centric Composable Services: A New Generation of Personal Data\n  Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques, such as Neural Network, are widely used in\ntoday's applications. However, there is still a big gap between the current ML\nsystems and users' requirements. ML systems focus on improving the performance\nof models in training, while individual users cares more about response time\nand expressiveness of the tool. Many existing research and product begin to\nmove computation towards edge devices. Based on the numerical computing system\nOwl, we propose to build the Zoo system to support construction, compose, and\ndeployment of ML models on edge and local devices.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 00:21:21 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 17:16:51 GMT"}, {"version": "v3", "created": "Sun, 26 Nov 2017 19:37:49 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Zhao", "Jianxin", ""], ["Mortier", "Richard", ""], ["Crowcroft", "Jon", ""], ["Wang", "Liang", ""]]}, {"id": "1710.09052", "submitter": "Jiechao Cheng", "authors": "Jiechao Cheng, Rui Ren, Lei Wang and Jianfeng Zhan", "title": "Deep Convolutional Neural Networks for Anomaly Event Classification on\n  Distributed Systems", "comments": "There was an error in the Results and Discussion parts of Experiments\n  section, figure 7 and table VII have some number confusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of server usage has brought a plenty of anomaly log\nevents, which have threatened a vast collection of machines. Recognizing and\ncategorizing the anomalous events thereby is a much salient work for our\nsystems, especially the ones generate the massive amount of data and harness it\nfor technology value creation and business development. To assist in focusing\non the classification and the prediction of anomaly events, and gaining\ncritical insights from system event records, we propose a novel log\npreprocessing method which is very effective to filter abundant information and\nretain critical characteristics. Additionally, a competitive approach for\nautomated classification of anomalous events detected from the distributed\nsystem logs with the state-of-the-art deep (Convolutional Neural Network)\narchitectures is proposed in this paper. We measure a series of deep CNN\nalgorithms with varied hyper-parameter combinations by using standard\nevaluation metrics, the results of our study reveals the advantages and\npotential capabilities of the proposed deep CNN models for anomaly event\nclassification tasks on real-world systems. The optimal classification\nprecision of our approach is 98.14%, which surpasses the popular traditional\nmachine learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 02:10:34 GMT"}, {"version": "v2", "created": "Sat, 30 Dec 2017 01:48:22 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Cheng", "Jiechao", ""], ["Ren", "Rui", ""], ["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1710.09064", "submitter": "Srihari Kankanahalli", "authors": "Srihari Kankanahalli", "title": "End-to-End Optimized Speech Coding with Deep Neural Networks", "comments": "Accepted and presented at ICASSP 2018. Samples available here:\n  http://srik.tk/speech-coding/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern compression algorithms are often the result of laborious\ndomain-specific research; industry standards such as MP3, JPEG, and AMR-WB took\nyears to develop and were largely hand-designed. We present a deep neural\nnetwork model which optimizes all the steps of a wideband speech coding\npipeline (compression, quantization, entropy coding, and decompression)\nend-to-end directly from raw speech data -- no manual feature engineering\nnecessary, and it trains in hours. In testing, our DNN-based coder performs on\npar with the AMR-WB standard at a variety of bitrates (~9kbps up to ~24kbps).\nIt also runs in realtime on a 3.8GhZ Intel CPU.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 03:21:44 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 05:17:03 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 15:43:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kankanahalli", "Srihari", ""]]}, {"id": "1710.09139", "submitter": "Martin V\\\"olker", "authors": "Martin V\\\"olker, Robin T. Schirrmeister, Lukas D. J. Fiederer, Wolfram\n  Burgard, Tonio Ball", "title": "Deep Transfer Learning for Error Decoding from Non-Invasive EEG", "comments": "6 pages, 9 figures, The 6th International Winter Conference on\n  Brain-Computer Interface 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recorded high-density EEG in a flanker task experiment (31 subjects) and\nan online BCI control paradigm (4 subjects). On these datasets, we evaluated\nthe use of transfer learning for error decoding with deep convolutional neural\nnetworks (deep ConvNets). In comparison with a regularized linear discriminant\nanalysis (rLDA) classifier, ConvNets were significantly better in both intra-\nand inter-subject decoding, achieving an average accuracy of 84.1 % within\nsubject and 81.7 % on unknown subjects (flanker task). Neither method was,\nhowever, able to generalize reliably between paradigms. Visualization of\nfeatures the ConvNets learned from the data showed plausible patterns of brain\nactivity, revealing both similarities and differences between the different\nkinds of errors. Our findings indicate that deep learning techniques are useful\nto infer information about the correctness of action in BCI applications,\nparticularly for the transfer of pre-trained classifiers to new recording\nsessions or subjects.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 09:47:04 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 16:46:48 GMT"}, {"version": "v3", "created": "Wed, 10 Jan 2018 09:13:24 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["V\u00f6lker", "Martin", ""], ["Schirrmeister", "Robin T.", ""], ["Fiederer", "Lukas D. J.", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1710.09207", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Ali Hassan Mirza, Suleyman Serdar Kozat", "title": "Unsupervised and Semi-supervised Anomaly Detection with LSTM Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2935975", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate anomaly detection in an unsupervised framework and introduce\nLong Short Term Memory (LSTM) neural network based algorithms. In particular,\ngiven variable length data sequences, we first pass these sequences through our\nLSTM based structure and obtain fixed length sequences. We then find a decision\nfunction for our anomaly detectors based on the One Class Support Vector\nMachines (OC-SVM) and Support Vector Data Description (SVDD) algorithms. As the\nfirst time in the literature, we jointly train and optimize the parameters of\nthe LSTM architecture and the OC-SVM (or SVDD) algorithm using highly effective\ngradient and quadratic programming based training methods. To apply the\ngradient based training method, we modify the original objective criteria of\nthe OC-SVM and SVDD algorithms, where we prove the convergence of the modified\nobjective criteria to the original criteria. We also provide extensions of our\nunsupervised formulation to the semi-supervised and fully supervised\nframeworks. Thus, we obtain anomaly detection algorithms that can process\nvariable length data sequences while providing high performance, especially for\ntime series data. Our approach is generic so that we also apply this approach\nto the Gated Recurrent Unit (GRU) architecture by directly replacing our LSTM\nbased structure with the GRU based structure. In our experiments, we illustrate\nsignificant performance gains achieved by our algorithms with respect to the\nconventional methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 12:57:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ergen", "Tolga", ""], ["Mirza", "Ali Hassan", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "1710.09220", "submitter": "Anthony Bagnall Dr", "authors": "James Large, Jason Lines and Anthony Bagnall", "title": "The Heterogeneous Ensembles of Standard Classification Algorithms\n  (HESCA): the Whole is Greater than the Sum of its Parts", "comments": null, "journal-ref": "Data Min Knowl Disc 33, 1674-1709 (2019)", "doi": "10.1007/s10618-019-00638-y", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building classification models is an intrinsically practical exercise that\nrequires many design decisions prior to deployment. We aim to provide some\nguidance in this decision making process. Specifically, given a classification\nproblem with real valued attributes, we consider which classifier or family of\nclassifiers should one use. Strong contenders are tree based homogeneous\nensembles, support vector machines or deep neural networks. All three families\nof model could claim to be state-of-the-art, and yet it is not clear when one\nis preferable to the others. Our extensive experiments with over 200 data sets\nfrom two distinct archives demonstrate that, rather than choose a single family\nand expend computing resources on optimising that model, it is significantly\nbetter to build simpler versions of classifiers from each family and ensemble.\nWe show that the Heterogeneous Ensembles of Standard Classification Algorithms\n(HESCA), which ensembles based on error estimates formed on the train data, is\nsignificantly better (in terms of error, balanced error, negative log\nlikelihood and area under the ROC curve) than its individual components,\npicking the component that is best on train data, and a support vector machine\ntuned over 1089 different parameter configurations. We demonstrate HESCA+,\nwhich contains a deep neural network, a support vector machine and two decision\ntree forests, is significantly better than its components, picking the best\ncomponent, and HESCA. We analyse the results further and find that HESCA and\nHESCA+ are of particular value when the train set size is relatively small and\nthe problem has multiple classes. HESCA is a fast approach that is, on average,\nas good as state-of-the-art classifiers, whereas HESCA+ is significantly better\nthan average and represents a strong benchmark for future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 13:19:18 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Large", "James", ""], ["Lines", "Jason", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1710.09230", "submitter": "Marco Loog", "authors": "Marco Loog", "title": "Supervised Classification: Quite a Brief Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original problem of supervised classification considers the task of\nautomatically assigning objects to their respective classes on the basis of\nnumerical measurements derived from these objects. Classifiers are the tools\nthat implement the actual functional mapping from these measurements---also\ncalled features or inputs---to the so-called class label---or output. The\nfields of pattern recognition and machine learning study ways of constructing\nsuch classifiers. The main idea behind supervised methods is that of learning\nfrom examples: given a number of example input-output relations, to what extent\ncan the general mapping be learned that takes any new and unseen feature vector\nto its correct class? This chapter provides a basic introduction to the\nunderlying ideas of how to come to a supervised classification problem. In\naddition, it provides an overview of some specific classification techniques,\ndelves into the issues of object representation and classifier evaluation, and\n(very) briefly covers some variations on the basic supervised classification\ntask that may also be of interest to the practitioner.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 13:42:40 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Loog", "Marco", ""]]}, {"id": "1710.09259", "submitter": "Bijit Kumar Das", "authors": "B. K. Das, S. Mukhopadhyay, and M. Chakraborty", "title": "Convergence Analysis of l0-RLS Adaptive Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents first and second order convergence analysis of the\nsparsity aware l0-RLS adaptive filter. The theorems 1 and 2 state the steady\nstate value of mean and mean square deviation of the adaptive filter weight\nvector.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 09:06:41 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Das", "B. K.", ""], ["Mukhopadhyay", "S.", ""], ["Chakraborty", "M.", ""]]}, {"id": "1710.09282", "submitter": "Yu Cheng", "authors": "Yu Cheng, Duo Wang, Pan Zhou, Tao Zhang", "title": "A Survey of Model Compression and Acceleration for Deep Neural Networks", "comments": "Published in IEEE Signal Processing Magazine, updated version\n  including more recent works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently achieved great success in many\nvisual recognition tasks. However, existing deep neural network models are\ncomputationally expensive and memory intensive, hindering their deployment in\ndevices with low memory resources or in applications with strict latency\nrequirements. Therefore, a natural thought is to perform model compression and\nacceleration in deep networks without significantly decreasing the model\nperformance. During the past five years, tremendous progress has been made in\nthis area. In this paper, we review the recent techniques for compacting and\naccelerating DNN models. In general, these techniques are divided into four\ncategories: parameter pruning and quantization, low-rank factorization,\ntransferred/compact convolutional filters, and knowledge distillation. Methods\nof parameter pruning and quantization are described first, after that the other\ntechniques are introduced. For each category, we also provide insightful\nanalysis about the performance, related applications, advantages, and\ndrawbacks. Then we go through some very recent successful methods, for example,\ndynamic capacity networks and stochastic depths networks. After that, we survey\nthe evaluation matrices, the main datasets used for evaluating the model\nperformance, and recent benchmark efforts. Finally, we conclude this paper,\ndiscuss remaining the challenges and possible directions for future work.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 20:16:55 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 01:22:14 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 00:12:34 GMT"}, {"version": "v4", "created": "Sat, 18 Nov 2017 07:54:57 GMT"}, {"version": "v5", "created": "Wed, 13 Dec 2017 21:10:49 GMT"}, {"version": "v6", "created": "Mon, 21 Jan 2019 23:34:25 GMT"}, {"version": "v7", "created": "Thu, 7 Feb 2019 05:07:15 GMT"}, {"version": "v8", "created": "Sun, 8 Sep 2019 16:30:38 GMT"}, {"version": "v9", "created": "Sun, 14 Jun 2020 19:10:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Cheng", "Yu", ""], ["Wang", "Duo", ""], ["Zhou", "Pan", ""], ["Zhang", "Tao", ""]]}, {"id": "1710.09288", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Xiang Xiang, Trac D. Tran, Gregory D. Hager, Xiaohui Xie", "title": "Adversarial Deep Structured Nets for Mass Segmentation from Mammograms", "comments": "Accepted by ISBI2018. arXiv admin note: substantial text overlap with\n  arXiv:1612.05970", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mass segmentation provides effective morphological features which are\nimportant for mass diagnosis. In this work, we propose a novel end-to-end\nnetwork for mammographic mass segmentation which employs a fully convolutional\nnetwork (FCN) to model a potential function, followed by a CRF to perform\nstructured learning. Because the mass distribution varies greatly with pixel\nposition, the FCN is combined with a position priori. Further, we employ\nadversarial training to eliminate over-fitting due to the small sizes of\nmammogram datasets. Multi-scale FCN is employed to improve the segmentation\nperformance. Experimental results on two public datasets, INbreast and\nDDSM-BCRP, demonstrate that our end-to-end network achieves better performance\nthan state-of-the-art approaches.\n\\footnote{https://github.com/wentaozhu/adversarial-deep-structural-networks.git}\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 06:54:43 GMT"}, {"version": "v2", "created": "Mon, 25 Dec 2017 07:50:09 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Zhu", "Wentao", ""], ["Xiang", "Xiang", ""], ["Tran", "Trac D.", ""], ["Hager", "Gregory D.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1710.09300", "submitter": "Filipe Alves Neto Verri", "authors": "Filipe Alves Neto Verri, Renato Tin\\'os, Liang Zhao", "title": "Feature learning in feature-sample networks using multi-objective\n  optimization", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": "10.1109/CEC.2018.8477891", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data and knowledge representation are fundamental concepts in machine\nlearning. The quality of the representation impacts the performance of the\nlearning model directly. Feature learning transforms or enhances raw data to\nstructures that are effectively exploited by those models. In recent years,\nseveral works have been using complex networks for data representation and\nanalysis. However, no feature learning method has been proposed for such\ncategory of techniques. Here, we present an unsupervised feature learning\nmechanism that works on datasets with binary features. First, the dataset is\nmapped into a feature--sample network. Then, a multi-objective optimization\nprocess selects a set of new vertices to produce an enhanced version of the\nnetwork. The new features depend on a nonlinear function of a combination of\npreexisting features. Effectively, the process projects the input data into a\nhigher-dimensional space. To solve the optimization problem, we design two\nmetaheuristics based on the lexicographic genetic algorithm and the improved\nstrength Pareto evolutionary algorithm (SPEA2). We show that the enhanced\nnetwork contains more information and can be exploited to improve the\nperformance of machine learning methods. The advantages and disadvantages of\neach optimization strategy are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 15:18:27 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Verri", "Filipe Alves Neto", ""], ["Tin\u00f3s", "Renato", ""], ["Zhao", "Liang", ""]]}, {"id": "1710.09302", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Richard Baraniuk", "title": "Deep Neural Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are universal function approximators providing\nstate-of- the-art solutions on wide range of applications. Common perceptual\ntasks such as speech recognition, image classification, and object tracking are\nnow commonly tackled via DNNs. Some fundamental problems remain: (1) the lack\nof a mathematical framework providing an explicit and interpretable\ninput-output formula for any topology, (2) quantification of DNNs stability\nregarding adversarial examples (i.e. modified inputs fooling DNN predictions\nwhilst undetectable to humans), (3) absence of generalization guarantees and\ncontrollable behaviors for ambiguous patterns, (4) leverage unlabeled data to\napply DNNs to domains where expert labeling is scarce as in the medical field.\nAnswering those points would provide theoretical perspectives for further\ndevelopments based on a common ground. Furthermore, DNNs are now deployed in\ntremendous societal applications, pushing the need to fill this theoretical gap\nto ensure control, reliability, and interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 15:23:01 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 20:32:56 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 21:49:49 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1710.09303", "submitter": "Ramviyas Parasuraman", "authors": "Sergio Caccamo, Ramviyas Parasuraman, Luigi Freda, Mario Gianni,\n  Petter \\\"Ogren", "title": "RCAMP: A Resilient Communication-Aware Motion Planner for Mobile Robots\n  with Autonomous Repair of Wireless Connectivity", "comments": "IROS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robots, be it autonomous or teleoperated, require stable communication\nwith the base station to exchange valuable information. Given the stochastic\nelements in radio signal propagation, such as shadowing and fading, and the\npossibilities of unpredictable events or hardware failures, communication loss\noften presents a significant mission risk, both in terms of probability and\nimpact, especially in Urban Search and Rescue (USAR) operations. Depending on\nthe circumstances, disconnected robots are either abandoned or attempt to\nautonomously back-trace their way to the base station. Although recent results\nin Communication-Aware Motion Planning can be used to effectively manage\nconnectivity with robots, there are no results focusing on autonomously\nre-establishing the wireless connectivity of a mobile robot without\nback-tracking or using detailed a priori information of the network.\n  In this paper, we present a robust and online radio signal mapping method\nusing Gaussian Random Fields and propose a Resilient Communication-Aware Motion\nPlanner (RCAMP) that integrates the above signal mapping framework with a\nmotion planner. RCAMP considers both the environment and the physical\nconstraints of the robot, based on the available sensory information. We also\npropose a self-repair strategy using RCMAP, that takes both connectivity and\nthe goal position into account when driving to a connection-safe position in\nthe event of a communication loss. We demonstrate the proposed planner in a set\nof realistic simulations of an exploration task in single or multi-channel\ncommunication scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 22:13:04 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Caccamo", "Sergio", ""], ["Parasuraman", "Ramviyas", ""], ["Freda", "Luigi", ""], ["Gianni", "Mario", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1710.09323", "submitter": "Maikel Leemans", "authors": "Maikel Leemans, Wil M. P. van der Aalst, Mark G. J. van den Brand", "title": "Recursion Aware Modeling and Discovery For Hierarchical Software Event\n  Log Analysis (Extended)", "comments": "Extended version (14 pages total) of the paper Recursion Aware\n  Modeling and Discovery For Hierarchical Software Event Log Analysis. This\n  Technical Report version includes the guarantee proofs for the proposed\n  discovery algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended paper presents 1) a novel hierarchy and recursion extension to\nthe process tree model; and 2) the first, recursion aware process model\ndiscovery technique that leverages hierarchical information in event logs,\ntypically available for software systems. This technique allows us to analyze\nthe operational processes of software systems under real-life conditions at\nmultiple levels of granularity. The work can be positioned in-between reverse\nengineering and process mining. An implementation of the proposed approach is\navailable as a ProM plugin. Experimental results based on real-life (software)\nevent logs demonstrate the feasibility and usefulness of the approach and show\nthe huge potential to speed up discovery by exploiting the available hierarchy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 08:56:50 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Leemans", "Maikel", ""], ["van der Aalst", "Wil M. P.", ""], ["Brand", "Mark G. J. van den", ""]]}, {"id": "1710.09334", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Licheng Yu, Mark Davenport, Hongyuan Zha", "title": "A unified framework for manifold landmarking", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2869116", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of semi-supervised manifold learning is highly dependent on the\nquality of the labeled samples. Active manifold learning aims to select and\nlabel representative landmarks on a manifold from a given set of samples to\nimprove semi-supervised manifold learning. In this paper, we propose a novel\nactive manifold learning method based on a unified framework of manifold\nlandmarking. In particular, our method combines geometric manifold landmarking\nmethods with algebraic ones. We achieve this by using the Gershgorin circle\ntheorem to construct an upper bound on the learning error that depends on the\nlandmarks and the manifold's alignment matrix in a way that captures both the\ngeometric and algebraic criteria. We then attempt to select landmarks so as to\nminimize this bound by iteratively deleting the Gershgorin circles\ncorresponding to the selected landmarks. We also analyze the complexity,\nscalability, and robustness of our method through simulations, and demonstrate\nits superiority compared to existing methods. Experiments in regression and\nclassification further verify that our method performs better than its\ncompetitors.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 16:41:00 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 15:12:07 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Xu", "Hongteng", ""], ["Yu", "Licheng", ""], ["Davenport", "Mark", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1710.09363", "submitter": "Biswa Sengupta", "authors": "Alessandro Bay and Biswa Sengupta", "title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fisher information metric is an important foundation of information\ngeometry, wherein it allows us to approximate the local geometry of a\nprobability distribution. Recurrent neural networks such as the\nSequence-to-Sequence (Seq2Seq) networks that have lately been used to yield\nstate-of-the-art performance on speech translation or image captioning have so\nfar ignored the geometry of the latent embedding, that they iteratively learn.\nWe propose the information geometric Seq2Seq (GeoSeq2Seq) network which\nabridges the gap between deep recurrent neural networks and information\ngeometry. Specifically, the latent embedding offered by a recurrent network is\nencoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism\ncommon in computer vision. We utilise such a network to predict the shortest\nroutes between two nodes of a graph by learning the adjacency matrix using the\nGeoSeq2Seq formalism; our results show that for such a problem the\nprobabilistic representation of the latent embedding supersedes the\nnon-probabilistic embedding by 10-15\\%.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 17:52:14 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 20:08:06 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Bay", "Alessandro", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1710.09412", "submitter": "Hongyi Zhang", "authors": "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz", "title": "mixup: Beyond Empirical Risk Minimization", "comments": "ICLR camera ready version. Changes vs V1: fix repo URL; add ablation\n  studies; add mixup + dropout etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep neural networks are powerful, but exhibit undesirable behaviors\nsuch as memorization and sensitivity to adversarial examples. In this work, we\npropose mixup, a simple learning principle to alleviate these issues. In\nessence, mixup trains a neural network on convex combinations of pairs of\nexamples and their labels. By doing so, mixup regularizes the neural network to\nfavor simple linear behavior in-between training examples. Our experiments on\nthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show\nthat mixup improves the generalization of state-of-the-art neural network\narchitectures. We also find that mixup reduces the memorization of corrupt\nlabels, increases the robustness to adversarial examples, and stabilizes the\ntraining of generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 18:30:49 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 21:39:25 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhang", "Hongyi", ""], ["Cisse", "Moustapha", ""], ["Dauphin", "Yann N.", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1710.09429", "submitter": "Gang Wang", "authors": "Gang Wang and Jia Chen and Georgios B. Giannakis", "title": "DPCA: Dimensionality Reduction for Discriminative Analytics of Multiple\n  Large-Scale Datasets", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) has well-documented merits for data\nextraction and dimensionality reduction. PCA deals with a single dataset at a\ntime, and it is challenged when it comes to analyzing multiple datasets. Yet in\ncertain setups, one wishes to extract the most significant information of one\ndataset relative to other datasets. Specifically, the interest may be on\nidentifying, namely extracting features that are specific to a single target\ndataset but not the others. This paper develops a novel approach for such\nso-termed discriminative data analysis, and establishes its optimality in the\nleast-squares (LS) sense under suitable data modeling assumptions. The\ncriterion reveals linear combinations of variables by maximizing the ratio of\nthe variance of the target data to that of the remainders. The novel approach\nsolves a generalized eigenvalue problem by performing SVD just once. Numerical\ntests using synthetic and real datasets showcase the merits of the proposed\napproach relative to its competing alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:24:37 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Wang", "Gang", ""], ["Chen", "Jia", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1710.09430", "submitter": "Venkata Krishna Pillutla", "authors": "Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli,\n  Venkata Krishna Pillutla, Aaron Sidford", "title": "A Markov Chain Theory Approach to Characterizing the Minimax Optimality\n  of Stochastic Gradient Descent (for Least Squares)", "comments": "Lemma 1 has been updated in v2", "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2017.2", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a simplified proof of the statistical minimax optimality\nof (iterate averaged) stochastic gradient descent (SGD), for the special case\nof least squares. This result is obtained by analyzing SGD as a stochastic\nprocess and by sharply characterizing the stationary covariance matrix of this\nprocess. The finite rate optimality characterization captures the constant\nfactors and addresses model mis-specification.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:28:13 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 21:13:33 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Jain", "Prateek", ""], ["Kakade", "Sham M.", ""], ["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""], ["Pillutla", "Venkata Krishna", ""], ["Sidford", "Aaron", ""]]}, {"id": "1710.09431", "submitter": "Yoav Levine", "authors": "Yoav Levine, Or Sharir, Alon Ziv and Amnon Shashua", "title": "On the Long-Term Memory of Deep Recurrent Networks", "comments": "An earlier version of this paper was accepted to the workshop track\n  of the 6th International Conference on Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key attribute that drives the unprecedented success of modern Recurrent\nNeural Networks (RNNs) on learning tasks which involve sequential data, is\ntheir ability to model intricate long-term temporal dependencies. However, a\nwell established measure of RNNs long-term memory capacity is lacking, and thus\nformal understanding of the effect of depth on their ability to correlate data\nthroughout time is limited. Specifically, existing depth efficiency results on\nconvolutional networks do not suffice in order to account for the success of\ndeep RNNs on data of varying lengths. In order to address this, we introduce a\nmeasure of the network's ability to support information flow across time,\nreferred to as the Start-End separation rank, which reflects the distance of\nthe function realized by the recurrent network from modeling no dependency\nbetween the beginning and end of the input sequence. We prove that deep\nrecurrent networks support Start-End separation ranks which are combinatorially\nhigher than those supported by their shallow counterparts. Thus, we establish\nthat depth brings forth an overwhelming advantage in the ability of recurrent\nnetworks to model long-term dependencies, and provide an exemplar of\nquantifying this key attribute which may be readily extended to other RNN\narchitectures of interest, e.g. variants of LSTM networks. We obtain our\nresults by considering a class of recurrent networks referred to as Recurrent\nArithmetic Circuits, which merge the hidden state with the input via the\nMultiplicative Integration operation, and empirically demonstrate the discussed\nphenomena on common RNNs. Finally, we employ the tool of quantum Tensor\nNetworks to gain additional graphic insight regarding the complexity brought\nforth by depth in recurrent networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:34:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 13:33:04 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Levine", "Yoav", ""], ["Sharir", "Or", ""], ["Ziv", "Alon", ""], ["Shashua", "Amnon", ""]]}, {"id": "1710.09435", "submitter": "Edward Raff", "authors": "Edward Raff, Jon Barker, Jared Sylvester, Robert Brandon, Bryan\n  Catanzaro, Charles Nicholas", "title": "Malware Detection by Eating a Whole EXE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce malware detection from raw byte sequences as a\nfruitful research area to the larger machine learning community. Building a\nneural network for such a problem presents a number of interesting challenges\nthat have not occurred in tasks such as image processing or NLP. In particular,\nwe note that detection from raw bytes presents a sequence problem with over two\nmillion time steps and a problem where batch normalization appear to hinder the\nlearning process. We present our initial work in building a solution to tackle\nthis problem, which has linear complexity dependence on the sequence length,\nand allows for interpretable sub-regions of the binary to be identified. In\ndoing so we will discuss the many challenges in building a neural network to\nprocess data at this scale, and the methods we used to work around them.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:48:54 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Raff", "Edward", ""], ["Barker", "Jon", ""], ["Sylvester", "Jared", ""], ["Brandon", "Robert", ""], ["Catanzaro", "Bryan", ""], ["Nicholas", "Charles", ""]]}, {"id": "1710.09447", "submitter": "Tianbao Yang", "authors": "Mingrui Liu, Tianbao Yang", "title": "Stochastic Non-convex Optimization with Strong High Probability\n  Second-order Convergence", "comments": "This short paper will appear at NIPS 2017 Optimization of Machine\n  Learning Workshop. Partial results are presented in arXiv:1709.08571. The\n  second version corrects a statement regarding previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study stochastic non-convex optimization with non-convex\nrandom functions. Recent studies on non-convex optimization revolve around\nestablishing second-order convergence, i.e., converging to a nearly\nsecond-order optimal stationary points. However, existing results on stochastic\nnon-convex optimization are limited, especially with a high probability\nsecond-order convergence. We propose a novel updating step (named NCG-S) by\nleveraging a stochastic gradient and a noisy negative curvature of a stochastic\nHessian, where the stochastic gradient and Hessian are based on a proper\nmini-batch of random functions. Building on this step, we develop two\nalgorithms and establish their high probability second-order convergence. To\nthe best of our knowledge, the proposed stochastic algorithms are the first\nwith a second-order convergence in {\\it high probability} and a time complexity\nthat is {\\it almost linear} in the problem's dimensionality.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 20:26:33 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 04:56:31 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Liu", "Mingrui", ""], ["Yang", "Tianbao", ""]]}, {"id": "1710.09471", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Ryan A. Rossi, Rong Zhou, John Boaz Lee, Xiangnan\n  Kong, Theodore L. Willke and Hoda Eldardiry", "title": "Inductive Representation Learning in Large Attributed Graphs", "comments": "NIPS WiML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs (networks) are ubiquitous and allow us to model entities (nodes) and\nthe dependencies (edges) between them. Learning a useful feature representation\nfrom graph data lies at the heart and success of many machine learning tasks\nsuch as classification, anomaly detection, link prediction, among many others.\nMany existing techniques use random walks as a basis for learning features or\nestimating the parameters of a graph model for a downstream prediction task.\nExamples include recent node embedding methods such as DeepWalk, node2vec, as\nwell as graph-based deep learning algorithms. However, the simple random walk\nused by these methods is fundamentally tied to the identity of the node. This\nhas three main disadvantages. First, these approaches are inherently\ntransductive and do not generalize to unseen nodes and other graphs. Second,\nthey are not space-efficient as a feature vector is learned for each node which\nis impractical for large graphs. Third, most of these approaches lack support\nfor attributed graphs.\n  To make these methods more generally applicable, we propose a framework for\ninductive network representation learning based on the notion of attributed\nrandom walk that is not tied to node identity and is instead based on learning\na function $\\Phi : \\mathrm{\\rm \\bf x} \\rightarrow w$ that maps a node attribute\nvector $\\mathrm{\\rm \\bf x}$ to a type $w$. This framework serves as a basis for\ngeneralizing existing methods such as DeepWalk, node2vec, and many other\nprevious methods that leverage traditional random walks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 21:40:57 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 23:51:39 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan A.", ""], ["Zhou", "Rong", ""], ["Lee", "John Boaz", ""], ["Kong", "Xiangnan", ""], ["Willke", "Theodore L.", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "1710.09483", "submitter": "Edward Schmerling", "authors": "Edward Schmerling and Karen Leung and Wolf Vollprecht and Marco Pavone", "title": "Multimodal Probabilistic Model-Based Planning for Human-Robot\n  Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for constructing human-robot interaction\npolicies in settings where multimodality, i.e., the possibility of multiple\nhighly distinct futures, plays a critical role in decision making. We are\nmotivated in this work by the example of traffic weaving, e.g., at highway\non-ramps/off-ramps, where entering and exiting cars must swap lanes in a short\ndistance---a challenging negotiation even for experienced drivers due to the\ninherent multimodal uncertainty of who will pass whom. Our approach is to learn\nmultimodal probability distributions over future human actions from a dataset\nof human-human exemplars and perform real-time robot policy construction in the\nresulting environment model through massively parallel sampling of human\nresponses to candidate robot action sequences. Direct learning of these\ndistributions is made possible by recent advances in the theory of conditional\nvariational autoencoders (CVAEs), whereby we learn action distributions\nsimultaneously conditioned on the present interaction history, as well as\ncandidate future robot actions in order to take into account response dynamics.\nWe demonstrate the efficacy of this approach with a human-in-the-loop\nsimulation of a traffic weaving scenario.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 22:25:09 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Schmerling", "Edward", ""], ["Leung", "Karen", ""], ["Vollprecht", "Wolf", ""], ["Pavone", "Marco", ""]]}, {"id": "1710.09511", "submitter": "Shane Barratt", "authors": "Shane Barratt", "title": "InterpNET: Neural Introspection for Interpretable Deep Learning", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to explain their reasoning. On the contrary, deep neural\nnetworks are not. This paper attempts to bridge this gap by introducing a new\nway to design interpretable neural networks for classification, inspired by\nphysiological evidence of the human visual system's inner-workings. This paper\nproposes a neural network design paradigm, termed InterpNET, which can be\ncombined with any existing classification architecture to generate natural\nlanguage explanations of the classifications. The success of the module relies\non the assumption that the network's computation and reasoning is represented\nin its internal layer activations. While in principle InterpNET could be\napplied to any existing classification architecture, it is evaluated via an\nimage classification and explanation task. Experiments on a CUB bird\nclassification and explanation dataset show qualitatively and quantitatively\nthat the model is able to generate high-quality explanations. While the current\nstate-of-the-art METEOR score on this dataset is 29.2, InterpNET achieves a\nmuch higher METEOR score of 37.9.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 02:01:12 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 21:25:25 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Barratt", "Shane", ""]]}, {"id": "1710.09513", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Long Chen, Cheng Tai, Weinan E", "title": "Maximum Principle Based Algorithms for Deep Learning", "comments": "Published version", "journal-ref": "Journal of Machine Learning Research 18 (2018) 1-29", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous dynamical system approach to deep learning is explored in\norder to devise alternative frameworks for training algorithms. Training is\nrecast as a control problem and this allows us to formulate necessary\noptimality conditions in continuous time using the Pontryagin's maximum\nprinciple (PMP). A modification of the method of successive approximations is\nthen used to solve the PMP, giving rise to an alternative training algorithm\nfor deep learning. This approach has the advantage that rigorous error\nestimates and convergence results can be established. We also show that it may\navoid some pitfalls of gradient-based methods, such as slow convergence on flat\nlandscapes near saddle points. Furthermore, we demonstrate that it obtains\nfavorable initial convergence rate per-iteration, provided Hamiltonian\nmaximization can be efficiently carried out - a step which is still in need of\nimprovement. Overall, the approach opens up new avenues to attack problems\nassociated with deep learning, such as trapping in slow manifolds and\ninapplicability of gradient-based methods for discrete trainable variables.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 02:04:33 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 01:17:39 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 12:55:37 GMT"}, {"version": "v4", "created": "Sat, 2 Jun 2018 08:50:02 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Li", "Qianxiao", ""], ["Chen", "Long", ""], ["Tai", "Cheng", ""], ["E", "Weinan", ""]]}, {"id": "1710.09515", "submitter": "Hsuan-Tien Lin", "authors": "Te-Kang Jan, Da-Wei Wang, Chi-Hung Lin, Hsuan-Tien Lin", "title": "Soft Methodology for Cost-and-error Sensitive Classification", "comments": "A shorter version appeared in KDD '12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world data mining applications need varying cost for different\ntypes of classification errors and thus call for cost-sensitive classification\nalgorithms. Existing algorithms for cost-sensitive classification are\nsuccessful in terms of minimizing the cost, but can result in a high error rate\nas the trade-off. The high error rate holds back the practical use of those\nalgorithms. In this paper, we propose a novel cost-sensitive classification\nmethodology that takes both the cost and the error rate into account. The\nmethodology, called soft cost-sensitive classification, is established from a\nmulticriteria optimization problem of the cost and the error rate, and can be\nviewed as regularizing cost-sensitive classification with the error rate. The\nsimple methodology allows immediate improvements of existing cost-sensitive\nclassification algorithms. Experiments on the benchmark and the real-world data\nsets show that our proposed methodology indeed achieves lower test error rates\nand similar (sometimes lower) test costs than existing cost-sensitive\nclassification algorithms. We also demonstrate that the methodology can be\nextended for considering the weighted error rate instead of the original error\nrate. This extension is useful for tackling unbalanced classification problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 02:39:29 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Jan", "Te-Kang", ""], ["Wang", "Da-Wei", ""], ["Lin", "Chi-Hung", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1710.09537", "submitter": "Li Jing", "authors": "Rumen Dangovski and Li Jing and Marin Soljacic", "title": "Rotational Unit of Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of unitary evolution matrices and associative memory have\nboosted the field of Recurrent Neural Networks (RNN) to state-of-the-art\nperformance in a variety of sequential tasks. However, RNN still have a limited\ncapacity to manipulate long-term memory. To bypass this weakness the most\nsuccessful applications of RNN use external techniques such as attention\nmechanisms. In this paper we propose a novel RNN model that unifies the\nstate-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM\nis its rotational operation, which is, naturally, a unitary matrix, providing\narchitectures with the power to learn long-term dependencies by overcoming the\nvanishing and exploding gradients problem. Moreover, the rotational unit also\nserves as associative memory. We evaluate our model on synthetic memorization,\nquestion answering and language modeling tasks. RUM learns the Copying Memory\ntask completely and improves the state-of-the-art result in the Recall task.\nRUM's performance in the bAbI Question Answering task is comparable to that of\nmodels with attention mechanism. We also improve the state-of-the-art result to\n1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB)\ntask, which is to signify the applications of RUM to real-world sequential\ndata. The universality of our construction, at the core of RNN, establishes RUM\nas a promising approach to language modeling, speech recognition and machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 04:36:35 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Dangovski", "Rumen", ""], ["Jing", "Li", ""], ["Soljacic", "Marin", ""]]}, {"id": "1710.09549", "submitter": "Chong Huang", "authors": "Chong Huang, Peter Kairouz, Xiao Chen, Lalitha Sankar, and Ram\n  Rajagopal", "title": "Context-Aware Generative Adversarial Privacy", "comments": "Improved version of a paper accepted by Entropy Journal, Special\n  Issue on Information Theory in Machine Learning and Data Science", "journal-ref": null, "doi": "10.3390/e19120656", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.GT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving the utility of published datasets while simultaneously providing\nprovable privacy guarantees is a well-known challenge. On the one hand,\ncontext-free privacy solutions, such as differential privacy, provide strong\nprivacy guarantees, but often lead to a significant reduction in utility. On\nthe other hand, context-aware privacy solutions, such as information theoretic\nprivacy, achieve an improved privacy-utility tradeoff, but assume that the data\nholder has access to dataset statistics. We circumvent these limitations by\nintroducing a novel context-aware privacy framework called generative\nadversarial privacy (GAP). GAP leverages recent advancements in generative\nadversarial networks (GANs) to allow the data holder to learn privatization\nschemes from the dataset itself. Under GAP, learning the privacy mechanism is\nformulated as a constrained minimax game between two players: a privatizer that\nsanitizes the dataset in a way that limits the risk of inference attacks on the\nindividuals' private variables, and an adversary that tries to infer the\nprivate variables from the sanitized dataset. To evaluate GAP's performance, we\ninvestigate two simple (yet canonical) statistical dataset models: (a) the\nbinary data model, and (b) the binary Gaussian mixture model. For both models,\nwe derive game-theoretically optimal minimax privacy mechanisms, and show that\nthe privacy mechanisms learned from data (in a generative adversarial fashion)\nmatch the theoretically optimal ones. This demonstrates that our framework can\nbe easily applied in practice, even in the absence of dataset statistics.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 05:36:35 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 16:40:45 GMT"}, {"version": "v3", "created": "Sun, 3 Dec 2017 00:17:37 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Huang", "Chong", ""], ["Kairouz", "Peter", ""], ["Chen", "Xiao", ""], ["Sankar", "Lalitha", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1710.09553", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Rethinking generalization requires revisiting old ideas: statistical\n  mechanics approaches and complex learning behavior", "comments": "31 pages; added brief discussion of recent papers that use/extend\n  these ideas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to understand the peculiar and counterintuitive\ngeneralization properties of deep neural networks. The approach involves going\nbeyond worst-case theoretical capacity control frameworks that have been\npopular in machine learning in recent years to revisit old ideas in the\nstatistical mechanics of neural networks. Within this approach, we present a\nprototypical Very Simple Deep Learning (VSDL) model, whose behavior is\ncontrolled by two control parameters, one describing an effective amount of\ndata, or load, on the network (that decreases when noise is added to the\ninput), and one with an effective temperature interpretation (that increases\nwhen algorithms are early stopped). Using this model, we describe how a very\nsimple application of ideas from the statistical mechanics theory of\ngeneralization provides a strong qualitative description of recently-observed\nempirical results regarding the inability of deep neural networks not to\noverfit training data, discontinuous learning and sharp transitions in the\ngeneralization properties of learning algorithms, etc.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 06:08:39 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 05:57:09 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1710.09567", "submitter": "Rajiv Sambasivan", "authors": "Rajiv Sambasivan, Sourish Das", "title": "Big Data Classification Using Augmented Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for classification tasks on big data. Experiments\nconducted as part of this study indicate that the algorithm can be as accurate\nas ensemble methods such as random forests or gradient boosted trees. Unlike\nensemble methods, the models produced by the algorithm can be easily\ninterpreted. The algorithm is based on a divide and conquer strategy and\nconsists of two steps. The first step consists of using a decision tree to\nsegment the large dataset. By construction, decision trees attempt to create\nhomogeneous class distributions in their leaf nodes. However, non-homogeneous\nleaf nodes are usually produced. The second step of the algorithm consists of\nusing a suitable classifier to determine the class labels for the\nnon-homogeneous leaf nodes. The decision tree segment provides a coarse segment\nprofile while the leaf level classifier can provide information about the\nattributes that affect the label within a segment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 07:33:40 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Sambasivan", "Rajiv", ""], ["Das", "Sourish", ""]]}, {"id": "1710.09574", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Biologically Inspired Feedforward Supervised Learning for Deep\n  Self-Organizing Map Networks", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437)", "journal-ref": null, "doi": null, "report-no": "MLINI/2016/05", "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel deep neural network and its supervised\nlearning method that uses a feedforward supervisory signal. The method is\ninspired by the human visual system and performs human-like association-based\nlearning without any backward error propagation. The feedforward supervisory\nsignal that produces the correct result is preceded by the target signal and\nassociates its confirmed label with the classification result of the target\nsignal. It effectively uses a large amount of information from the feedforward\nsignal, and forms a continuous and rich learning representation. The method is\nvalidated using visual recognition tasks on the MNIST handwritten dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 07:56:16 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "1710.09599", "submitter": "Sami Abu-El-Haija", "authors": "Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, Alex Alemi", "title": "Watch Your Step: Learning Node Embeddings via Graph Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph embedding methods represent nodes in a continuous vector space,\npreserving information from the graph (e.g. by sampling random walks). There\nare many hyper-parameters to these methods (such as random walk length) which\nhave to be manually tuned for every graph. In this paper, we replace random\nwalk hyper-parameters with trainable parameters that we automatically learn via\nbackpropagation. In particular, we learn a novel attention model on the power\nseries of the transition matrix, which guides the random walk to optimize an\nupstream objective. Unlike previous approaches to attention models, the method\nthat we propose utilizes attention parameters exclusively on the data (e.g. on\nthe random walk), and not used by the model for inference. We experiment on\nlink prediction tasks, as we aim to produce embeddings that best-preserve the\ngraph structure, generalizing to unseen information. We improve\nstate-of-the-art on a comprehensive suite of real world datasets including\nsocial, collaboration, and biological networks. Adding attention to random\nwalks can reduce the error by 20% to 45% on datasets we attempted. Further, our\nlearned attention parameters are different for every graph, and our\nautomatically-found values agree with the optimal choice of hyper-parameter if\nwe manually tune existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 09:10:01 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 16:34:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["Al-Rfou", "Rami", ""], ["Alemi", "Alex", ""]]}, {"id": "1710.09657", "submitter": "Alireza Ahrabian", "authors": "Alireza Ahrabian and Shirin Enshaeifar and Clive Cheong-Took and Payam\n  Barnaghi", "title": "Segment Parameter Labelling in MCMC Mean-Shift Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of segmentation in time series data with\nrespect to a statistical parameter of interest in Bayesian models. It is common\nto assume that the parameters are distinct within each segment. As such, many\nBayesian change point detection models do not exploit the segment parameter\npatterns, which can improve performance. This work proposes a Bayesian\nmean-shift change point detection algorithm that makes use of repetition in\nsegment parameters, by introducing segment class labels that utilise a\nDirichlet process prior. The performance of the proposed approach was assessed\non both synthetic and real world data, highlighting the enhanced performance\nwhen using parameter labelling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 12:02:45 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Ahrabian", "Alireza", ""], ["Enshaeifar", "Shirin", ""], ["Cheong-Took", "Clive", ""], ["Barnaghi", "Payam", ""]]}, {"id": "1710.09668", "submitter": "Bin Dong Dr.", "authors": "Zichao Long, Yiping Lu, Xianzhong Ma, Bin Dong", "title": "PDE-Net: Learning PDEs from Data", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an initial attempt to learn evolution PDEs from\ndata. Inspired by the latest development of neural network designs in deep\nlearning, we propose a new feed-forward deep network, called PDE-Net, to\nfulfill two objectives at the same time: to accurately predict dynamics of\ncomplex systems and to uncover the underlying hidden PDE models. The basic idea\nof the proposed PDE-Net is to learn differential operators by learning\nconvolution kernels (filters), and apply neural networks or other machine\nlearning methods to approximate the unknown nonlinear responses. Comparing with\nexisting approaches, which either assume the form of the nonlinear response is\nknown or fix certain finite difference approximations of differential\noperators, our approach has the most flexibility by learning both differential\noperators and the nonlinear responses. A special feature of the proposed\nPDE-Net is that all filters are properly constrained, which enables us to\neasily identify the governing PDE models while still maintaining the expressive\nand predictive power of the network. These constrains are carefully designed by\nfully exploiting the relation between the orders of differential operators and\nthe orders of sum rules of filters (an important concept originated from\nwavelet theory). We also discuss relations of the PDE-Net with some existing\nnetworks in computer vision such as Network-In-Network (NIN) and Residual\nNeural Network (ResNet). Numerical experiments show that the PDE-Net has the\npotential to uncover the hidden PDE of the observed dynamics, and predict the\ndynamical behavior for a relatively long time, even in a noisy environment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 12:50:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 07:22:36 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Long", "Zichao", ""], ["Lu", "Yiping", ""], ["Ma", "Xianzhong", ""], ["Dong", "Bin", ""]]}, {"id": "1710.09691", "submitter": "Santosh Devasia", "authors": "Nathan Banka, W. Tony Piaskowy, Joseph Garbini, Santosh Devasia", "title": "Iterative Machine Learning for Precision Trajectory Tracking with Series\n  Elastic Actuators", "comments": "9 pages, 16 figure. Submitted to AMC Workshop", "journal-ref": "2018 IEEE 15th International Workshop on Advanced Motion Control\n  (AMC), Tokyo, 2018, pp. 234-239", "doi": "10.1109/AMC.2019.8371094", "report-no": null, "categories": "cs.SY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When robots operate in unknown environments small errors in postions can lead\nto large variations in the contact forces, especially with typical\nhigh-impedance designs. This can potentially damage the surroundings and/or the\nrobot. Series elastic actuators (SEAs) are a popular way to reduce the output\nimpedance of a robotic arm to improve control authority over the force exerted\non the environment. However this increased control over forces with lower\nimpedance comes at the cost of lower positioning precision and bandwidth. This\narticle examines the use of an iteratively-learned feedforward command to\nimprove position tracking when using SEAs. Over each iteration, the output\nresponses of the system to the quantized inputs are used to estimate a\nlinearized local system models. These estimated models are obtained using a\ncomplex-valued Gaussian Process Regression (cGPR) technique and then, used to\ngenerate a new feedforward input command based on the previous iteration's\nerror. This article illustrates this iterative machine learning (IML) technique\nfor a two degree of freedom (2-DOF) robotic arm, and demonstrates successful\nconvergence of the IML approach to reduce the tracking error.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 19:39:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Banka", "Nathan", ""], ["Piaskowy", "W. Tony", ""], ["Garbini", "Joseph", ""], ["Devasia", "Santosh", ""]]}, {"id": "1710.09710", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "Weighting Scheme for a Pairwise Multi-label Classifier Based on the\n  Fuzzy Confusion Matrix", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.08729", "journal-ref": null, "doi": "10.1016/j.patrec.2018.01.012", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we addressed the issue of applying a stochastic classifier and a\nlocal, fuzzy confusion matrix under the framework of multi-label\nclassification. We proposed a novel solution to the problem of correcting label\npairwise ensembles. The main step of the correction procedure is to compute\nclassifier-specific competence and cross-competence measures, which estimates\nerror pattern of the underlying classifier. At the fusion phase we employed two\nweighting approaches based on information theory. The classifier weights\npromote base classifiers which are the most susceptible to the correction based\non the fuzzy confusion matrix. During the experimental study, the proposed\napproach was compared against two reference methods. The comparison was made in\nterms of six different quality criteria. The conducted experiments reveals that\nthe proposed approach eliminates one of main drawbacks of the original\nFCM-based approach i.e. the original approach is vulnerable to the imbalanced\nclass/label distribution. What is more, the obtained results shows that the\nintroduced method achieves satisfying classification quality under all\nconsidered quality criteria. Additionally, the impact of fluctuations of data\nset characteristics is reduced.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 02:30:39 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 07:47:27 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.09718", "submitter": "Yuhang Song", "authors": "Yuhang Song, Christopher Grimm, Xianming Wang, Michael L. Littman", "title": "Learning Approximate Stochastic Transition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of learning mappings from state to state, suitable for\nuse in a model-based reinforcement-learning setting, that simultaneously\ngeneralize to novel states and can capture stochastic transitions. We show that\ncurrently popular generative adversarial networks struggle to learn these\nstochastic transition models but a modification to their loss functions results\nin a powerful learning algorithm for this class of problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 14:06:52 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Song", "Yuhang", ""], ["Grimm", "Christopher", ""], ["Wang", "Xianming", ""], ["Littman", "Michael L.", ""]]}, {"id": "1710.09762", "submitter": "Sarfaraz Hussein", "authors": "Maria J. M. Chuquicusma, Sarfaraz Hussein, Jeremy Burt, and Ulas Bagci", "title": "How to Fool Radiologists with Generative Adversarial Networks? A Visual\n  Turing Test for Lung Cancer Diagnosis", "comments": "Accepted for publication in IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating lung nodules as malignant or benign is still an underlying\nchallenge. To address this challenge, radiologists need computer aided\ndiagnosis (CAD) systems which can assist in learning discriminative imaging\nfeatures corresponding to malignant and benign nodules. However, learning\nhighly discriminative imaging features is an open problem. In this paper, our\naim is to learn the most discriminative features pertaining to lung nodules by\nusing an adversarial learning methodology. Specifically, we propose to use\nunsupervised learning with Deep Convolutional-Generative Adversarial Networks\n(DC-GANs) to generate lung nodule samples realistically. We hypothesize that\nimaging features of lung nodules will be discriminative if it is hard to\ndifferentiate them (fake) from real (true) nodules. To test this hypothesis, we\npresent Visual Turing tests to two radiologists in order to evaluate the\nquality of the generated (fake) nodules. Extensive comparisons are performed in\ndiscerning real, generated, benign, and malignant nodules. This experimental\nset up allows us to validate the overall quality of the generated nodules,\nwhich can then be used to (1) improve diagnostic decisions by mining highly\ndiscriminative imaging features, (2) train radiologists for educational\npurposes, and (3) generate realistic samples to train deep networks with big\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 15:38:50 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 04:31:54 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Chuquicusma", "Maria J. M.", ""], ["Hussein", "Sarfaraz", ""], ["Burt", "Jeremy", ""], ["Bagci", "Ulas", ""]]}, {"id": "1710.09767", "submitter": "John Schulman", "authors": "Kevin Frans, Jonathan Ho, Xi Chen, Pieter Abbeel, John Schulman", "title": "Meta Learning Shared Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a metalearning approach for learning hierarchically structured\npolicies, improving sample efficiency on unseen tasks through the use of shared\nprimitives---policies that are executed for large numbers of timesteps.\nSpecifically, a set of primitives are shared within a distribution of tasks,\nand are switched between by task-specific policies. We provide a concrete\nmetric for measuring the strength of such hierarchies, leading to an\noptimization problem for quickly reaching high reward on unseen tasks. We then\npresent an algorithm to solve this problem end-to-end through the use of any\noff-the-shelf reinforcement learning method, by repeatedly sampling new tasks\nand resetting task-specific policies. We successfully discover meaningful motor\nprimitives for the directional movement of four-legged robots, solely by\ninteracting with distributions of mazes. We also demonstrate the\ntransferability of primitives to solve long-timescale sparse-reward obstacle\ncourses, and we enable 3D humanoid robots to robustly walk and crawl with the\nsame policy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 15:43:33 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Frans", "Kevin", ""], ["Ho", "Jonathan", ""], ["Chen", "Xi", ""], ["Abbeel", "Pieter", ""], ["Schulman", "John", ""]]}, {"id": "1710.09779", "submitter": "Sarfaraz Hussein", "authors": "Sarfaraz Hussein, Pujan Kandel, Juan E. Corral, Candice W. Bolan,\n  Michael B. Wallace and Ulas Bagci", "title": "Deep Multi-Modal Classification of Intraductal Papillary Mucinous\n  Neoplasms (IPMN) with Canonical Correlation Analysis", "comments": "Accepted for publication in IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pancreatic cancer has the poorest prognosis among all cancer types.\nIntraductal Papillary Mucinous Neoplasms (IPMNs) are radiographically\nidentifiable precursors to pancreatic cancer; hence, early detection and\nprecise risk assessment of IPMN are vital. In this work, we propose a\nConvolutional Neural Network (CNN) based computer aided diagnosis (CAD) system\nto perform IPMN diagnosis and risk assessment by utilizing multi-modal MRI. In\nour proposed approach, we use minimum and maximum intensity projections to ease\nthe annotation variations among different slices and type of MRIs. Then, we\npresent a CNN to obtain deep feature representation corresponding to each MRI\nmodality (T1-weighted and T2-weighted). At the final step, we employ canonical\ncorrelation analysis (CCA) to perform a fusion operation at the feature level,\nleading to discriminative canonical correlation features. Extracted features\nare used for classification. Our results indicate significant improvements over\nother potential approaches to solve this important problem. The proposed\napproach doesn't require explicit sample balancing in cases of imbalance\nbetween positive and negative examples. To the best of our knowledge, our study\nis the first to automatically diagnose IPMN using multi-modal MRI.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:01:31 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 04:27:29 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 16:47:53 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Hussein", "Sarfaraz", ""], ["Kandel", "Pujan", ""], ["Corral", "Juan E.", ""], ["Bolan", "Candice W.", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1710.09787", "submitter": "Danny Barash", "authors": "Danny Barash and Matan Gavish", "title": "Optimal Shrinkage of Singular Values Under Random Data Contamination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A low rank matrix X has been contaminated by uniformly distributed noise,\nmissing values, outliers and corrupt entries. Reconstruction of X from the\nsingular values and singular vectors of the contaminated matrix Y is a key\nproblem in machine learning, computer vision and data science. In this paper we\nshow that common contamination models (including arbitrary combinations of\nuniform noise,missing values, outliers and corrupt entries) can be described\nefficiently using a single framework. We develop an asymptotically optimal\nalgorithm that estimates X by manipulation of the singular values of Y , which\napplies to any of the contamination models considered. Finally, we find an\nexplicit signal-to-noise cutoff, below which estimation of X from the singular\nvalue decomposition of Y must fail, in a well-defined sense.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:17:36 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 21:07:43 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Barash", "Danny", ""], ["Gavish", "Matan", ""]]}, {"id": "1710.09805", "submitter": "Weinan Zhang", "authors": "Long Chen, Fajie Yuan, Joemon M. Jose, Weinan Zhang", "title": "Improving Negative Sampling for Word Representation using Self-embedded\n  Features", "comments": "Accepted in WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the word-popularity based negative sampler has shown superb\nperformance in the skip-gram model, the theoretical motivation behind\noversampling popular (non-observed) words as negative samples is still not well\nunderstood. In this paper, we start from an investigation of the gradient\nvanishing issue in the skipgram model without a proper negative sampler. By\nperforming an insightful analysis from the stochastic gradient descent (SGD)\nlearning perspective, we demonstrate that, both theoretically and intuitively,\nnegative samples with larger inner product scores are more informative than\nthose with lower scores for the SGD learner in terms of both convergence rate\nand accuracy. Understanding this, we propose an alternative sampling algorithm\nthat dynamically selects informative negative samples during each SGD update.\nMore importantly, the proposed sampler accounts for multi-dimensional\nself-embedded features during the sampling process, which essentially makes it\nmore effective than the original popularity-based (one-dimensional) sampler.\nEmpirical experiments further verify our observations, and show that our\nfine-grained samplers gain significant improvement over the existing ones\nwithout increasing computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:54:13 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:40:22 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 07:32:18 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Long", ""], ["Yuan", "Fajie", ""], ["Jose", "Joemon M.", ""], ["Zhang", "Weinan", ""]]}, {"id": "1710.09809", "submitter": "Cedric Herzet", "authors": "C. Herzet and A. Dr\\'emeau", "title": "Joint Screening Tests for LASSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focusses on \"safe\" screening techniques for the LASSO problem.\nMotivated by the need for low-complexity algorithms, we propose a new approach,\ndubbed \"joint\" screening test, allowing to screen a set of atoms by carrying\nout one single test. The approach is particularized to two different sets of\natoms, respectively expressed as sphere and dome regions. After presenting the\nmathematical derivations of the tests, we elaborate on their relative\neffectiveness and discuss the practical use of such procedures.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 17:04:10 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 10:27:11 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Herzet", "C.", ""], ["Dr\u00e9meau", "A.", ""]]}, {"id": "1710.09813", "submitter": "Don Towsley", "authors": "James Atwood, Siddharth Pal, Don Towsley, Ananthram Swami", "title": "Sparse Diffusion-Convolutional Neural Networks", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive power and overall computational efficiency of\nDiffusion-convolutional neural networks make them an attractive choice for node\nclassification tasks. However, a naive dense-tensor-based implementation of\nDCNNs leads to $\\mathcal{O}(N^2)$ memory complexity which is prohibitive for\nlarge graphs. In this paper, we introduce a simple method for thresholding\ninput graphs that provably reduces memory requirements of DCNNs to O(N) (i.e.\nlinear in the number of nodes in the input) without significantly affecting\npredictive performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 17:16:14 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Atwood", "James", ""], ["Pal", "Siddharth", ""], ["Towsley", "Don", ""], ["Swami", "Ananthram", ""]]}, {"id": "1710.09825", "submitter": "Carlo Lucibello", "authors": "Carlo Baldassi, Federica Gerace, Hilbert J. Kappen, Carlo Lucibello,\n  Luca Saglietti, Enzo Tartaglione, Riccardo Zecchina", "title": "On the role of synaptic stochasticity in training low-precision neural\n  networks", "comments": "7 pages + 14 pages of supplementary material", "journal-ref": "Phys. Rev. Lett. 120, 268103 (2018)", "doi": "10.1103/PhysRevLett.120.268103", "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochasticity and limited precision of synaptic weights in neural network\nmodels are key aspects of both biological and hardware modeling of learning\nprocesses. Here we show that a neural network model with stochastic binary\nweights naturally gives prominence to exponentially rare dense regions of\nsolutions with a number of desirable properties such as robustness and good\ngeneralization performance, while typical solutions are isolated and hard to\nfind. Binary solutions of the standard perceptron problem are obtained from a\nsimple gradient descent procedure on a set of real values parametrizing a\nprobability distribution over the binary synapses. Both analytical and\nnumerical results are presented. An algorithmic extension aimed at training\ndiscrete deep neural networks is also investigated.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 17:42:23 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 03:17:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Baldassi", "Carlo", ""], ["Gerace", "Federica", ""], ["Kappen", "Hilbert J.", ""], ["Lucibello", "Carlo", ""], ["Saglietti", "Luca", ""], ["Tartaglione", "Enzo", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1710.09854", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Jialei Wang, Ji Liu, Tong Zhang", "title": "Gradient Sparsification for Communication-Efficient Distributed\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large scale machine learning applications require stochastic\noptimization algorithms to be implemented on distributed computational\narchitectures. A key bottleneck is the communication overhead for exchanging\ninformation such as stochastic gradients among different workers. In this\npaper, to reduce the communication cost we propose a convex optimization\nformulation to minimize the coding length of stochastic gradients. To solve the\noptimal sparsification efficiently, several simple and fast algorithms are\nproposed for approximate solution, with theoretical guaranteed for sparseness.\nExperiments on $\\ell_2$ regularized logistic regression, support vector\nmachines, and convolutional neural networks validate our sparsification\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:26:43 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Wang", "Jialei", ""], ["Liu", "Ji", ""], ["Zhang", "Tong", ""]]}, {"id": "1710.09859", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Maria L. Rizzo, Joshua T. Vogelstein", "title": "Kernel k-Groups via Hartigan's Method", "comments": "several improvements; connections with community detection and\n  stochastic block model. Matches published version", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.2998120", "report-no": null, "categories": "stat.ML cs.CV cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy statistics was proposed by Sz\\' ekely in the 80's inspired by Newton's\ngravitational potential in classical mechanics and it provides a model-free\nhypothesis test for equality of distributions. In its original form, energy\nstatistics was formulated in Euclidean spaces. More recently, it was\ngeneralized to metric spaces of negative type. In this paper, we consider a\nformulation for the clustering problem using a weighted version of energy\nstatistics in spaces of negative type. We show that this approach leads to a\nquadratically constrained quadratic program in the associated kernel space,\nestablishing connections with graph partitioning problems and kernel methods in\nmachine learning. To find local solutions of such an optimization problem, we\npropose kernel k-groups, which is an extension of Hartigan's method to kernel\nspaces. Kernel k-groups is cheaper than spectral clustering and has the same\ncomputational cost as kernel k-means (which is based on Lloyd's heuristic) but\nour numerical results show an improved performance, especially in higher\ndimensions. Moreover, we verify the efficiency of kernel k-groups in community\ndetection in sparse stochastic block models which has fascinating applications\nin several areas of science.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 14:02:55 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:29:58 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 19:57:09 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Rizzo", "Maria L.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1710.09953", "submitter": "Yu-Jun Li", "authors": "Jean Honorio, Yu-Jun Li", "title": "The Error Probability of Random Fourier Features is Dimensionality\n  Independent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the error probability of reconstructing kernel matrices from\nRandom Fourier Features for the Gaussian kernel function is at most\n$\\mathcal{O}(R^{2/3} \\exp(-D))$, where $D$ is the number of random features and\n$R$ is the diameter of the data domain. We also provide an\ninformation-theoretic method-independent lower bound of $\\Omega((1-\\exp(-R^2))\n\\exp(-D))$. Compared to prior work, we are the first to show that the error\nprobability for random Fourier features is independent of the dimensionality of\ndata points. As applications of our theory, we obtain dimension-independent\nbounds for kernel ridge regression and support vector machines.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 00:19:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 00:42:59 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 20:03:07 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 23:41:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Honorio", "Jean", ""], ["Li", "Yu-Jun", ""]]}, {"id": "1710.09967", "submitter": "Brad Carlile", "authors": "Brad Carlile, Guy Delamarter, Paul Kinney, Akiko Marti, Brian Whitney", "title": "Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs)", "comments": "8 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \"inverse square root linear unit\" (ISRLU) to speed up\nlearning in deep neural networks. ISRLU has better performance than ELU but has\nmany of the same benefits. ISRLU and ELU have similar curves and\ncharacteristics. Both have negative values, allowing them to push mean unit\nactivation closer to zero, and bring the normal gradient closer to the unit\nnatural gradient, ensuring a noise-robust deactivation state, lessening the\nover fitting risk. The significant performance advantage of ISRLU on\ntraditional CPUs also carry over to more efficient HW implementations on HW/SW\ncodesign for CNNs/RNNs. In experiments with TensorFlow, ISRLU leads to faster\nlearning and better generalization than ReLU on CNNs. This work also suggests a\ncomputationally efficient variant called the \"inverse square root unit\" (ISRU)\nwhich can be used for RNNs. Many RNNs use either long short-term memory (LSTM)\nand gated recurrent units (GRU) which are implemented with tanh and sigmoid\nactivation functions. ISRU has less com- putational complexity but still has a\nsimilar curve to tanh and sigmoid.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 02:01:28 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 21:59:39 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Carlile", "Brad", ""], ["Delamarter", "Guy", ""], ["Kinney", "Paul", ""], ["Marti", "Akiko", ""], ["Whitney", "Brian", ""]]}, {"id": "1710.09979", "submitter": "Xiao-Bo Jin", "authors": "Xiao-Bo Jin, Xu-Yao Zhang, Kaizhu Huang and Guang-Gang Geng", "title": "Stochastic Conjugate Gradient Algorithm with Variance Reduction", "comments": "10 pages, 4 figures, appeared in IEEE TRANSACTIONS ON NEURAL NETWORKS\n  AND LEARNING SYSTEMS, CGVR algorithm is available on github:\n  https://github.com/xbjin/cgvr", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems,2018", "doi": "10.1109/TNNLS.2018.2868835", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjugate gradient (CG) methods are a class of important methods for solving\nlinear equations and nonlinear optimization problems. In this paper, we propose\na new stochastic CG algorithm with variance reduction and we prove its linear\nconvergence with the Fletcher and Reeves method for strongly convex and smooth\nfunctions. We experimentally demonstrate that the CG with variance reduction\nalgorithm converges faster than its counterparts for four learning models,\nwhich may be convex, nonconvex or nonsmooth. In addition, its area under the\ncurve performance on six large-scale data sets is comparable to that of the\nLIBLINEAR solver for the L2-regularized L2-loss but with a significant\nimprovement in computational efficiency\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 03:47:41 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 11:33:01 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Jin", "Xiao-Bo", ""], ["Zhang", "Xu-Yao", ""], ["Huang", "Kaizhu", ""], ["Geng", "Guang-Gang", ""]]}, {"id": "1710.09988", "submitter": "Xian Wu", "authors": "Aaron Sidford, Mengdi Wang, Xian Wu, Yinyu Ye", "title": "Variance Reduced Value Iteration and Faster Algorithms for Solving\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide faster algorithms for approximately solving\ndiscounted Markov Decision Processes in multiple parameter regimes. Given a\ndiscounted Markov Decision Process (DMDP) with $|S|$ states, $|A|$ actions,\ndiscount factor $\\gamma\\in(0,1)$, and rewards in the range $[-M, M]$, we show\nhow to compute an $\\epsilon$-optimal policy, with probability $1 - \\delta$ in\ntime \\[ \\tilde{O}\\left( \\left(|S|^2 |A| + \\frac{|S| |A|}{(1 - \\gamma)^3}\n\\right)\n  \\log\\left( \\frac{M}{\\epsilon} \\right) \\log\\left( \\frac{1}{\\delta} \\right)\n\\right) ~ . \\] This contribution reflects the first nearly linear time, nearly\nlinearly convergent algorithm for solving DMDPs for intermediate values of\n$\\gamma$.\n  We also show how to obtain improved sublinear time algorithms provided we can\nsample from the transition function in $O(1)$ time. Under this assumption we\nprovide an algorithm which computes an $\\epsilon$-optimal policy with\nprobability $1 - \\delta$ in time \\[ \\tilde{O} \\left(\\frac{|S| |A| M^2}{(1 -\n\\gamma)^4 \\epsilon^2} \\log \\left(\\frac{1}{\\delta}\\right) \\right) ~. \\]\n  Lastly, we extend both these algorithms to solve finite horizon MDPs. Our\nalgorithms improve upon the previous best for approximately computing optimal\npolicies for fixed-horizon MDPs in multiple parameter regimes.\n  Interestingly, we obtain our results by a careful modification of approximate\nvalue iteration. We show how to combine classic approximate value iteration\nanalysis with new techniques in variance reduction. Our fastest algorithms\nleverage further insights to ensure that our algorithms make monotonic progress\ntowards the optimal value. This paper is one of few instances in using sampling\nto obtain a linearly convergent linear programming algorithm and we hope that\nthe analysis may be useful more broadly.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 04:44:24 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 13:59:02 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 05:24:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Sidford", "Aaron", ""], ["Wang", "Mengdi", ""], ["Wu", "Xian", ""], ["Ye", "Yinyu", ""]]}, {"id": "1710.10002", "submitter": "Ken-ichiro Moridomi", "authors": "Ken-ichiro Moridomi, Kohei Hatano, Eiji Takimoto", "title": "Online linear optimization with the log-determinant regularizer", "comments": "18 pages", "journal-ref": null, "doi": "10.1587/transinf.2017EDP7317", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online linear optimization over symmetric positive semi-definite\nmatrices, which has various applications including the online collaborative\nfiltering. The problem is formulated as a repeated game between the algorithm\nand the adversary, where in each round t the algorithm and the adversary choose\nmatrices X_t and L_t, respectively, and then the algorithm suffers a loss given\nby the Frobenius inner product of X_t and L_t. The goal of the algorithm is to\nminimize the cumulative loss. We can employ a standard framework called Follow\nthe Regularized Leader (FTRL) for designing algorithms, where we need to choose\nan appropriate regularization function to obtain a good performance guarantee.\nWe show that the log-determinant regularization works better than other popular\nregularization functions in the case where the loss matrices L_t are all\nsparse. Using this property, we show that our algorithm achieves an optimal\nperformance guarantee for the online collaborative filtering. The technical\ncontribution of the paper is to develop a new technique of deriving performance\nbounds by exploiting the property of strong convexity of the log-determinant\nwith respect to the loss matrices, while in the previous analysis the strong\nconvexity is defined with respect to a norm. Intuitively, skipping the norm\nanalysis results in the improved bound. Moreover, we apply our method to online\nlinear optimization over vectors and show that the FTRL with the Burg entropy\nregularizer, which is the analogue of the log-determinant regularizer in the\nvector case, works well.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 06:38:11 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Moridomi", "Ken-ichiro", ""], ["Hatano", "Kohei", ""], ["Takimoto", "Eiji", ""]]}, {"id": "1710.10006", "submitter": "Jong Chul Ye", "authors": "Yeo Hun Yoon and Jong Chul Ye", "title": "Deep Learning for Accelerated Ultrasound Imaging", "comments": "Invited paper for ICASSP 2018 Special Session for \"Machine Learning\n  in Medical Imaging: from Measurement to Diagnosis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In portable, 3-D, or ultra-fast ultrasound (US) imaging systems, there is an\nincreasing demand to reconstruct high quality images from limited number of\ndata. However, the existing solutions require either hardware changes or\ncomputationally expansive algorithms. To overcome these limitations, here we\npropose a novel deep learning approach that interpolates the missing RF data by\nutilizing the sparsity of the RF data in the Fourier domain. Extensive\nexperimental results from sub-sampled RF data from a real US system confirmed\nthat the proposed method can effectively reduce the data rate without\nsacrificing the image quality.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 06:49:37 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Yoon", "Yeo Hun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1710.10016", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Soroosh Shafieezadeh-Abadeh, Daniel Kuhn, Peyman Mohajerin Esfahani", "title": "Regularization via Mass Transportation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of regression and classification methods in supervised learning is\nto minimize the empirical risk, that is, the expectation of some loss function\nquantifying the prediction error under the empirical distribution. When facing\nscarce training data, overfitting is typically mitigated by adding\nregularization terms to the objective that penalize hypothesis complexity. In\nthis paper we introduce new regularization techniques using ideas from\ndistributionally robust optimization, and we give new probabilistic\ninterpretations to existing techniques. Specifically, we propose to minimize\nthe worst-case expected loss, where the worst case is taken over the ball of\nall (continuous or discrete) distributions that have a bounded transportation\ndistance from the (discrete) empirical distribution. By choosing the radius of\nthis ball judiciously, we can guarantee that the worst-case expected loss\nprovides an upper confidence bound on the loss on test data, thus offering new\ngeneralization bounds. We prove that the resulting regularized learning\nproblems are tractable and can be tractably kernelized for many popular loss\nfunctions. We validate our theoretical out-of-sample guarantees through\nsimulated and empirical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 07:52:45 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 08:48:21 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 08:14:21 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Shafieezadeh-Abadeh", "Soroosh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1710.10036", "submitter": "Yuhang Song", "authors": "Yuhang Song, Main Xu, Songyang Zhang, Liangyu Huo", "title": "Generalization Tower Network: A Novel Deep Neural Network Architecture\n  for Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) advances state-of-the-art reinforcement learning (RL), by\nincorporating deep neural networks in learning representations from the input\nto RL. However, the conventional deep neural network architecture is limited in\nlearning representations for multi-task RL (MT-RL), as multiple tasks can refer\nto different kinds of representations. In this paper, we thus propose a novel\ndeep neural network architecture, namely generalization tower network (GTN),\nwhich can achieve MT-RL within a single learned model. Specifically, the\narchitecture of GTN is composed of both horizontal and vertical streams. In our\nGTN architecture, horizontal streams are used to learn representation shared in\nsimilar tasks. In contrast, the vertical streams are introduced to be more\nsuitable for handling diverse tasks, which encodes hierarchical shared\nknowledge of these tasks. The effectiveness of the introduced vertical stream\nis validated by experimental results. Experimental results further verify that\nour GTN architecture is able to advance the state-of-the-art MT-RL, via being\ntested on 51 Atari games.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 09:11:26 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:44:17 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 01:06:10 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Song", "Yuhang", ""], ["Xu", "Main", ""], ["Zhang", "Songyang", ""], ["Huo", "Liangyu", ""]]}, {"id": "1710.10044", "submitter": "Will Dabney", "authors": "Will Dabney, Mark Rowland, Marc G. Bellemare, R\\'emi Munos", "title": "Distributional Reinforcement Learning with Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning an agent interacts with the environment by taking\nactions and observing the next state and reward. When sampled\nprobabilistically, these state transitions, rewards, and actions can all induce\nrandomness in the observed long-term return. Traditionally, reinforcement\nlearning algorithms average over this randomness to estimate the value\nfunction. In this paper, we build on recent work advocating a distributional\napproach to reinforcement learning in which the distribution over returns is\nmodeled explicitly instead of only estimating the mean. That is, we examine\nmethods of learning the value distribution instead of the value function. We\ngive results that close a number of gaps between the theoretical and\nalgorithmic results given by Bellemare, Dabney, and Munos (2017). First, we\nextend existing results to the approximate distribution setting. Second, we\npresent a novel distributional reinforcement learning algorithm consistent with\nour theoretical formulation. Finally, we evaluate this new algorithm on the\nAtari 2600 games, observing that it significantly outperforms many of the\nrecent improvements on DQN, including the related distributional algorithm C51.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 09:35:26 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Dabney", "Will", ""], ["Rowland", "Mark", ""], ["Bellemare", "Marc G.", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1710.10059", "submitter": "Sharath Adavanne", "authors": "Sharath Adavanne, Archontis Politis and Tuomas Virtanen", "title": "Direction of arrival estimation for multiple sound sources using\n  convolutional recurrent neural network", "comments": "EUSIPCO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a deep neural network for estimating the directions of\narrival (DOA) of multiple sound sources. The proposed stacked convolutional and\nrecurrent neural network (DOAnet) generates a spatial pseudo-spectrum (SPS)\nalong with the DOA estimates in both azimuth and elevation. We avoid any\nexplicit feature extraction step by using the magnitudes and phases of the\nspectrograms of all the channels as input to the network. The proposed DOAnet\nis evaluated by estimating the DOAs of multiple concurrently present sources in\nanechoic, matched and unmatched reverberant conditions. The results show that\nthe proposed DOAnet is capable of estimating the number of sources and their\nrespective DOAs with good precision and generate SPS with high signal-to-noise\nratio.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 10:24:00 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 19:54:58 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Adavanne", "Sharath", ""], ["Politis", "Archontis", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1710.10060", "submitter": "Nadia Figueroa", "authors": "Nadia Figueroa and Aude Billard", "title": "Transform-Invariant Non-Parametric Clustering of Covariance Matrices and\n  its Application to Unsupervised Joint Segmentation and Action Discovery", "comments": "51 pages, 20 figures. Submitted to Journal of Machine Learning\n  Research, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we tackle the problem of transform-invariant unsupervised\nlearning in the space of Covariance matrices and applications thereof. We begin\nby introducing the Spectral Polytope Covariance Matrix (SPCM) Similarity\nfunction; a similarity function for Covariance matrices, invariant to any type\nof transformation. We then derive the SPCM-CRP mixture model, a\ntransform-invariant non-parametric clustering approach for Covariance matrices\nthat leverages the proposed similarity function, spectral embedding and the\ndistance-dependent Chinese Restaurant Process (dd-CRP) (Blei and Frazier,\n2011). The scalability and applicability of these two contributions is\nextensively validated on real-world Covariance matrix datasets from diverse\nresearch fields. Finally, we couple the SPCM-CRP mixture model with the\nBayesian non-parametric Indian Buffet Process (IBP) - Hidden Markov Model (HMM)\n(Fox et al., 2009), to jointly segment and discover transform-invariant action\nprimitives from complex sequential data. Resulting in a topic-modeling inspired\nhierarchical model for unsupervised time-series data analysis which we call\nICSC-HMM (IBP Coupled SPCM-CRP Hidden Markov Model). The ICSC-HMM is validated\non kinesthetic demonstrations of uni-manual and bi-manual cooking tasks;\nachieving unsupervised human-level decomposition of complex sequential tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 10:25:35 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Figueroa", "Nadia", ""], ["Billard", "Aude", ""]]}, {"id": "1710.10116", "submitter": "Prashant Doshi", "authors": "Shervin Shahryari and Prashant Doshi", "title": "Inverse Reinforcement Learning Under Noisy Observations", "comments": "Full version of the extended abstract published in AAMAS 2017\n  conference, pages 1733 - 1735", "journal-ref": "In Proceedings of the 16th Conference on Autonomous Agents and\n  MultiAgent Systems (AAMAS '17). International Foundation for Autonomous\n  Agents and Multiagent Systems, Richland, SC, 1733-1735, 2017", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing inverse reinforcement learning when the\ntrajectory of the expert is not perfectly observed by the learner. Instead, a\nnoisy continuous-time observation of the trajectory is provided to the learner.\nThis problem exhibits wide-ranging applications and the specific application we\nconsider here is the scenario in which the learner seeks to penetrate a\nperimeter patrolled by a robot. The learner's field of view is limited due to\nwhich it cannot observe the patroller's complete trajectory. Instead, we allow\nthe learner to listen to the expert's movement sound, which it can also use to\nestimate the expert's state and action using an observation model. We treat the\nexpert's state and action as hidden data and present an algorithm based on\nexpectation maximization and maximum entropy principle to solve the non-linear,\nnon-convex problem. Related work considers discrete-time observations and an\nobservation model that does not include actions. In contrast, our technique\ntakes expectations over both state and action of the expert, enabling learning\neven in the presence of extreme noise and broader applications.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 13:10:26 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Shahryari", "Shervin", ""], ["Doshi", "Prashant", ""]]}, {"id": "1710.10121", "submitter": "Yiping Lu", "authors": "Yiping Lu, Aoxiao Zhong, Quanzheng Li, Bin Dong", "title": "Beyond Finite Layer Neural Networks: Bridging Deep Architectures and\n  Numerical Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our work, we bridge deep neural network design with numerical differential\nequations. We show that many effective networks, such as ResNet, PolyNet,\nFractalNet and RevNet, can be interpreted as different numerical\ndiscretizations of differential equations. This finding brings us a brand new\nperspective on the design of effective deep architectures. We can take\nadvantage of the rich knowledge in numerical analysis to guide us in designing\nnew and potentially more effective deep networks. As an example, we propose a\nlinear multi-step architecture (LM-architecture) which is inspired by the\nlinear multi-step method solving ordinary differential equations. The\nLM-architecture is an effective structure that can be used on any ResNet-like\nnetworks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the\nnetworks obtained by applying the LM-architecture on ResNet and ResNeXt\nrespectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on\nboth CIFAR and ImageNet with comparable numbers of trainable parameters. In\nparticular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly\ncompress ($>50$\\%) the original networks while maintaining a similar\nperformance. This can be explained mathematically using the concept of modified\nequation from numerical analysis. Last but not least, we also establish a\nconnection between stochastic control and noise injection in the training\nprocess which helps to improve generalization of the networks. Furthermore, by\nrelating stochastic training strategy with stochastic dynamic system, we can\neasily apply stochastic training to the networks with the LM-architecture. As\nan example, we introduced stochastic depth to LM-ResNet and achieve significant\nimprovement over the original LM-ResNet on CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 13:19:59 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 09:19:19 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 04:20:58 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Lu", "Yiping", ""], ["Zhong", "Aoxiao", ""], ["Li", "Quanzheng", ""], ["Dong", "Bin", ""]]}, {"id": "1710.10174", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson, Eran Malach and Shai Shalev-Shwartz", "title": "SGD Learns Over-parameterized Networks that Provably Generalize on\n  Linearly Separable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks exhibit good generalization behavior in the\nover-parameterized regime, where the number of network parameters exceeds the\nnumber of observations. Nonetheless, current generalization bounds for neural\nnetworks fail to explain this phenomenon. In an attempt to bridge this gap, we\nstudy the problem of learning a two-layer over-parameterized neural network,\nwhen the data is generated by a linearly separable function. In the case where\nthe network has Leaky ReLU activations, we provide both optimization and\ngeneralization guarantees for over-parameterized networks. Specifically, we\nprove convergence rates of SGD to a global minimum and provide generalization\nguarantees for this global minimum that are independent of the network size.\nTherefore, our result clearly shows that the use of SGD for optimization both\nfinds a global minimum, and avoids overfitting despite the high capacity of the\nmodel. This is the first theoretical demonstration that SGD can avoid\noverfitting, when learning over-specified neural network classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 14:42:09 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""], ["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1710.10196", "submitter": "Samuli Laine", "authors": "Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen", "title": "Progressive Growing of GANs for Improved Quality, Stability, and\n  Variation", "comments": "Final ICLR 2018 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new training methodology for generative adversarial networks.\nThe key idea is to grow both the generator and discriminator progressively:\nstarting from a low resolution, we add new layers that model increasingly fine\ndetails as training progresses. This both speeds the training up and greatly\nstabilizes it, allowing us to produce images of unprecedented quality, e.g.,\nCelebA images at 1024^2. We also propose a simple way to increase the variation\nin generated images, and achieve a record inception score of 8.80 in\nunsupervised CIFAR10. Additionally, we describe several implementation details\nthat are important for discouraging unhealthy competition between the generator\nand discriminator. Finally, we suggest a new metric for evaluating GAN results,\nboth in terms of image quality and variation. As an additional contribution, we\nconstruct a higher-quality version of the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:28:35 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 14:39:27 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 15:33:34 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Karras", "Tero", ""], ["Aila", "Timo", ""], ["Laine", "Samuli", ""], ["Lehtinen", "Jaakko", ""]]}, {"id": "1710.10197", "submitter": "Fei Tao", "authors": "Fei Tao and Gang Liu", "title": "Advanced LSTM: A Study about Better Time Dependency Modeling in Emotion\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) is normally used in recurrent neural network\n(RNN) as basic recurrent unit. However,conventional LSTM assumes that the state\nat current time step depends on previous time step. This assumption constraints\nthe time dependency modeling capability. In this study, we propose a new\nvariation of LSTM, advanced LSTM (A-LSTM), for better temporal context\nmodeling. We employ A-LSTM in weighted pooling RNN for emotion recognition. The\nA-LSTM outperforms the conventional LSTM by 5.5% relatively. The A-LSTM based\nweighted pooling RNN can also complement the state-of-the-art emotion\nclassification framework. This shows the advantage of A-LSTM.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:29:09 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Tao", "Fei", ""], ["Liu", "Gang", ""]]}, {"id": "1710.10230", "submitter": "Cyril Zhang", "authors": "Brian Bullins, Cyril Zhang, Yi Zhang", "title": "Not-So-Random Features", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principled method for kernel learning, which relies on a\nFourier-analytic characterization of translation-invariant or\nrotation-invariant kernels. Our method produces a sequence of feature maps,\niteratively refining the SVM margin. We provide rigorous guarantees for\noptimality and generalization, interpreting our algorithm as online\nequilibrium-finding dynamics in a certain two-player min-max game. Evaluations\non synthetic and real-world datasets demonstrate scalability and consistent\nimprovements over related random features-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 16:28:06 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 00:50:27 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Bullins", "Brian", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1710.10248", "submitter": "Vasily Pestun", "authors": "Vasily Pestun, Yiannis Vlassopoulos", "title": "Tensor network language model", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new statistical model suitable for machine learning of systems\nwith long distance correlations such as natural languages. The model is based\non directed acyclic graph decorated by multi-linear tensor maps in the vertices\nand vector spaces in the edges, called tensor network. Such tensor networks\nhave been previously employed for effective numerical computation of the\nrenormalization group flow on the space of effective quantum field theories and\nlattice models of statistical mechanics. We provide explicit algebro-geometric\nanalysis of the parameter moduli space for tree graphs, discuss model\nproperties and applications such as statistical translation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 17:26:57 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 16:03:48 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Pestun", "Vasily", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "1710.10280", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, James L. McClelland", "title": "One-shot and few-shot learning of word embeddings", "comments": "15 pages, 7 figures, under review as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 18:05:22 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 16:53:05 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "1710.10313", "submitter": "Alan Do-Omri", "authors": "Alan Do-Omri, Dalei Wu and Xiaohua Liu", "title": "A Self-Training Method for Semi-Supervised GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the creation of Generative Adversarial Networks (GANs), much work has\nbeen done to improve their training stability, their generated image quality,\ntheir range of application but nearly none of them explored their self-training\npotential. Self-training has been used before the advent of deep learning in\norder to allow training on limited labelled training data and has shown\nimpressive results in semi-supervised learning. In this work, we combine these\ntwo ideas and make GANs self-trainable for semi-supervised learning tasks by\nexploiting their infinite data generation potential. Results show that using\neven the simplest form of self-training yields an improvement. We also show\nresults for a more complex self-training scheme that performs at least as well\nas the basic self-training scheme but with significantly less data\naugmentation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 19:43:21 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Do-Omri", "Alan", ""], ["Wu", "Dalei", ""], ["Liu", "Xiaohua", ""]]}, {"id": "1710.10321", "submitter": "Claire Donnat", "authors": "Claire Donnat, Marinka Zitnik, David Hallac, Jure Leskovec", "title": "Learning Structural Node Embeddings Via Diffusion Wavelets", "comments": "The 24th ACM SIGKDD International Conference on Knowledge Discovery &\n  Data Mining, August 19--23, 2018, London, United Kingdom", "journal-ref": null, "doi": "10.1145/3219819.3220025", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes residing in different parts of a graph can have similar structural\nroles within their local network topology. The identification of such roles\nprovides key insight into the organization of networks and can be used for a\nvariety of machine learning tasks. However, learning structural representations\nof nodes is a challenging problem, and it has typically involved manually\nspecifying and tailoring topological features for each node. In this paper, we\ndevelop GraphWave, a method that represents each node's network neighborhood\nvia a low-dimensional embedding by leveraging heat wavelet diffusion patterns.\nInstead of training on hand-selected features, GraphWave learns these\nembeddings in an unsupervised way. We mathematically prove that nodes with\nsimilar network neighborhoods will have similar GraphWave embeddings even\nthough these nodes may reside in very different parts of the network, and our\nmethod scales linearly with the number of edges. Experiments in a variety of\ndifferent settings demonstrate GraphWave's real-world potential for capturing\nstructural roles in networks, and our approach outperforms existing\nstate-of-the-art baselines in every experiment, by as much as 137%.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:07:38 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 16:33:36 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 05:18:36 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 17:05:35 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Donnat", "Claire", ""], ["Zitnik", "Marinka", ""], ["Hallac", "David", ""], ["Leskovec", "Jure", ""]]}, {"id": "1710.10328", "submitter": "Lixin Fan", "authors": "Lixin Fan", "title": "Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU\n  with Generalized Hamming Network", "comments": "10 pages, 5 figures, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit fuzzy neural network with a cornerstone notion of generalized\nhamming distance, which provides a novel and theoretically justified framework\nto re-interpret many useful neural network techniques in terms of fuzzy logic.\nIn particular, we conjecture and empirically illustrate that, the celebrated\nbatch normalization (BN) technique actually adapts the normalized bias such\nthat it approximates the rightful bias induced by the generalized hamming\ndistance. Once the due bias is enforced analytically, neither the optimization\nof bias terms nor the sophisticated batch normalization is needed. Also in the\nlight of generalized hamming distance, the popular rectified linear units\n(ReLU) can be treated as setting a minimal hamming distance threshold between\nnetwork inputs and weights. This thresholding scheme, on the one hand, can be\nimproved by introducing double thresholding on both extremes of neuron outputs.\nOn the other hand, ReLUs turn out to be non-essential and can be removed from\nnetworks trained for simple tasks like MNIST classification. The proposed\ngeneralized hamming network (GHN) as such not only lends itself to rigorous\nanalysis and interpretation within the fuzzy logic theory but also demonstrates\nfast learning speed, well-controlled behaviour and state-of-the-art\nperformances on a variety of learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:48:57 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Fan", "Lixin", ""]]}, {"id": "1710.10329", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Elad Hazan", "title": "Lower Bounds for Higher-Order Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods in convex and non-convex optimization employ\nhigher-order derivative information, either implicitly or explicitly. We\nexplore the limitations of higher-order optimization and prove that even for\nconvex optimization, a polynomial dependence on the approximation guarantee and\nhigher-order smoothness parameters is necessary. As a special case, we show\nNesterov's accelerated cubic regularization method to be nearly tight.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:52:33 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Agarwal", "Naman", ""], ["Hazan", "Elad", ""]]}, {"id": "1710.10335", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Nesreen K. Ahmed, Hoda Eldardiry, and Rong Zhou", "title": "Similarity-based Multi-label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is an important learning problem with many\napplications. In this work, we propose a principled similarity-based approach\nfor multi-label learning called SML. We also introduce a similarity-based\napproach for predicting the label set size. The experimental results\ndemonstrate the effectiveness of SML for multi-label classification where it is\nshown to compare favorably with a wide variety of existing algorithms across a\nrange of evaluation criterion.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 21:20:31 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""], ["Eldardiry", "Hoda", ""], ["Zhou", "Rong", ""]]}, {"id": "1710.10345", "submitter": "Daniel Soudry", "authors": "Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar,\n  Nathan Srebro", "title": "The Implicit Bias of Gradient Descent on Separable Data", "comments": "Final JMLR version, with improved discussions over v3. Main\n  improvements in journal version over conference version (v2 appeared in\n  ICLR): We proved the measure zero case for main theorem (with implications\n  for the rates), and the multi-class case", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine gradient descent on unregularized logistic regression problems,\nwith homogeneous linear predictors on linearly separable datasets. We show the\npredictor converges to the direction of the max-margin (hard margin SVM)\nsolution. The result also generalizes to other monotone decreasing loss\nfunctions with an infimum at infinity, to multi-class problems, and to training\na weight layer in a deep network in a certain restricted setting. Furthermore,\nwe show this convergence is very slow, and only logarithmic in the convergence\nof the loss itself. This can help explain the benefit of continuing to optimize\nthe logistic or cross-entropy loss even after the training error is zero and\nthe training loss is extremely small, and, as we show, even if the validation\nloss increases. Our methodology can also aid in understanding implicit\nregularization n more complex models and with other optimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 21:47:58 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 21:12:01 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 17:53:26 GMT"}, {"version": "v4", "created": "Fri, 28 Dec 2018 10:51:36 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Soudry", "Daniel", ""], ["Hoffer", "Elad", ""], ["Nacson", "Mor Shpigel", ""], ["Gunasekar", "Suriya", ""], ["Srebro", "Nathan", ""]]}, {"id": "1710.10355", "submitter": "Fernando Gama", "authors": "Fernando Gama, Geert Leus, Antonio G. Marques, Alejandro Ribeiro", "title": "Convolutional Neural Networks Via Node-Varying Graph Filters", "comments": "Submitted to DSW 2018 (IEEE Data Science Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are being applied to an increasing\nnumber of problems and fields due to their superior performance in\nclassification and regression tasks. Since two of the key operations that CNNs\nimplement are convolution and pooling, this type of networks is implicitly\ndesigned to act on data described by regular structures such as images.\nMotivated by the recent interest in processing signals defined in irregular\ndomains, we advocate a CNN architecture that operates on signals supported on\ngraphs. The proposed design replaces the classical convolution not with a\nnode-invariant graph filter (GF), which is the natural generalization of\nconvolution to graph domains, but with a node-varying GF. This filter extracts\ndifferent local features without increasing the output dimension of each layer\nand, as a result, bypasses the need for a pooling stage while involving only\nlocal operations. A second contribution is to replace the node-varying GF with\na hybrid node-varying GF, which is a new type of GF introduced in this paper.\nWhile the alternative architecture can still be run locally without requiring a\npooling stage, the number of trainable parameters is smaller and can be\nrendered independent of the data dimension. Tests are run on a synthetic source\nlocalization problem and on the 20NEWS dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 23:53:13 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 20:00:07 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gama", "Fernando", ""], ["Leus", "Geert", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1710.10363", "submitter": "Sergio Valcarcel Macua", "authors": "Sergio Valcarcel Macua and Aleksi Tukiainen and Daniel\n  Garc\\'ia-Oca\\~na Hern\\'andez and David Baldazo and Enrique Munoz de Cote and\n  Santiago Zazo", "title": "Diff-DAC: Distributed Actor-Critic for Average Multitask Deep\n  Reinforcement Learning", "comments": null, "journal-ref": "Presented at Adaptive Learning Agents workshop (ALA2018), July\n  14th, 2018, Stockholm, Sweden", "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fully distributed actor-critic algorithm approximated by deep\nneural networks, named \\textit{Diff-DAC}, with application to single-task and\nto average multitask reinforcement learning (MRL). Each agent has access to\ndata from its local task only, but it aims to learn a policy that performs well\non average for the whole set of tasks. During the learning process, agents\ncommunicate their value-policy parameters to their neighbors, diffusing the\ninformation across the network, so that they converge to a common policy, with\nno need for a central node. The method is scalable, since the computational and\ncommunication costs per agent grow with its number of neighbors. We derive\nDiff-DAC's from duality theory and provide novel insights into the standard\nactor-critic framework, showing that it is actually an instance of the dual\nascent method that approximates the solution of a linear program. Experiments\nsuggest that Diff-DAC can outperform the single previous distributed MRL\napproach (i.e., Dist-MTLPS) and even the centralized architecture.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 00:55:01 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 18:10:08 GMT"}, {"version": "v3", "created": "Wed, 29 Nov 2017 16:21:47 GMT"}, {"version": "v4", "created": "Sun, 22 Apr 2018 10:34:09 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 08:03:01 GMT"}, {"version": "v6", "created": "Sun, 25 Oct 2020 14:41:10 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Macua", "Sergio Valcarcel", ""], ["Tukiainen", "Aleksi", ""], ["Hern\u00e1ndez", "Daniel Garc\u00eda-Oca\u00f1a", ""], ["Baldazo", "David", ""], ["de Cote", "Enrique Munoz", ""], ["Zazo", "Santiago", ""]]}, {"id": "1710.10364", "submitter": "Jeff Calder", "authors": "Jeff Calder", "title": "Consistency of Lipschitz learning with infinite unlabeled data and\n  finite labeled data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the consistency of Lipschitz learning on graphs in the limit of\ninfinite unlabeled data and finite labeled data. Previous work has conjectured\nthat Lipschitz learning is well-posed in this limit, but is insensitive to the\ndistribution of the unlabeled data, which is undesirable for semi-supervised\nlearning. We first prove that this conjecture is true in the special case of a\nrandom geometric graph model with kernel-based weights. Then we go on to show\nthat on a random geometric graph with self-tuning weights, Lipschitz learning\nis in fact highly sensitive to the distribution of the unlabeled data, and we\nshow how the degree of sensitivity can be adjusted by tuning the weights. In\nboth cases, our results follow from showing that the sequence of learned\nfunctions converges to the viscosity solution of an $\\infty$-Laplace type\nequation, and studying the structure of the limiting equation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 00:56:14 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 03:42:25 GMT"}, {"version": "v3", "created": "Sat, 17 Aug 2019 02:29:10 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Calder", "Jeff", ""]]}, {"id": "1710.10366", "submitter": "Aditya Gangrade", "authors": "Aditya Gangrade, Bobak Nazer and Venkatesh Saligrama", "title": "Lower Bounds for Two-Sample Structural Change Detection in Ising and\n  Gaussian Models", "comments": "Presented at the 55th Annual Allerton Conference on Communication,\n  Control, and Computing, Oct. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The change detection problem is to determine if the Markov network structures\nof two Markov random fields differ from one another given two sets of samples\ndrawn from the respective underlying distributions. We study the trade-off\nbetween the sample sizes and the reliability of change detection, measured as a\nminimax risk, for the important cases of the Ising models and the Gaussian\nMarkov random fields restricted to the models which have network structures\nwith $p$ nodes and degree at most $d$, and obtain information-theoretic lower\nbounds for reliable change detection over these models. We show that for the\nIsing model, $\\Omega\\left(\\frac{d^2}{(\\log d)^2}\\log p\\right)$ samples are\nrequired from each dataset to detect even the sparsest possible changes, and\nthat for the Gaussian, $\\Omega\\left( \\gamma^{-2} \\log(p)\\right)$ samples are\nrequired from each dataset to detect change, where $\\gamma$ is the smallest\nratio of off-diagonal to diagonal terms in the precision matrices of the\ndistributions. These bounds are compared to the corresponding results in\nstructure learning, and closely match them under mild conditions on the model\nparameters. Thus, our change detection bounds inherit partial tightness from\nthe structure learning schemes in previous literature, demonstrating that in\ncertain parameter regimes, the naive structure learning based approach to\nchange detection is minimax optimal up to constant factors.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 01:13:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Gangrade", "Aditya", ""], ["Nazer", "Bobak", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1710.10368", "submitter": "Nitin Kamra", "authors": "Nitin Kamra, Umang Gupta, Yan Liu", "title": "Deep Generative Dual Memory Network for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advances in deep learning, neural networks can only learn multiple\ntasks when trained on them jointly. When tasks arrive sequentially, they lose\nperformance on previously learnt tasks. This phenomenon called catastrophic\nforgetting is a fundamental challenge to overcome before neural networks can\nlearn continually from incoming data. In this work, we derive inspiration from\nhuman memory to develop an architecture capable of learning continuously from\nsequentially incoming tasks, while averting catastrophic forgetting.\nSpecifically, our contributions are: (i) a dual memory architecture emulating\nthe complementary learning systems (hippocampus and the neocortex) in the human\nbrain, (ii) memory consolidation via generative replay of past experiences,\n(iii) demonstrating advantages of generative replay and dual memories via\nexperiments, and (iv) improved performance retention on challenging tasks even\nfor low capacity models. Our architecture displays many characteristics of the\nmammalian memory and provides insights on the connection between sleep and\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 01:45:43 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 21:58:08 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Kamra", "Nitin", ""], ["Gupta", "Umang", ""], ["Liu", "Yan", ""]]}, {"id": "1710.10370", "submitter": "Jian Du", "authors": "Jian Du, Shanghang Zhang, Guanhang Wu, Jose M. F. Moura, Soummya Kar", "title": "Topology Adaptive Graph Convolutional Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral graph convolutional neural networks (CNNs) require approximation to\nthe convolution to alleviate the computational complexity, resulting in\nperformance loss. This paper proposes the topology adaptive graph convolutional\nnetwork (TAGCN), a novel graph convolutional network defined in the vertex\ndomain. We provide a systematic way to design a set of fixed-size learnable\nfilters to perform convolutions on graphs. The topologies of these filters are\nadaptive to the topology of the graph when they scan the graph to perform\nconvolution. The TAGCN not only inherits the properties of convolutions in CNN\nfor grid-structured data, but it is also consistent with convolution as defined\nin graph signal processing. Since no approximation to the convolution is\nneeded, TAGCN exhibits better performance than existing spectral CNNs on a\nnumber of data sets and is also computationally simpler than other recent\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 02:12:51 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 14:02:52 GMT"}, {"version": "v3", "created": "Fri, 17 Nov 2017 01:58:56 GMT"}, {"version": "v4", "created": "Sun, 31 Dec 2017 22:19:33 GMT"}, {"version": "v5", "created": "Sun, 11 Feb 2018 20:53:09 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Du", "Jian", ""], ["Zhang", "Shanghang", ""], ["Wu", "Guanhang", ""], ["Moura", "Jose M. F.", ""], ["Kar", "Soummya", ""]]}, {"id": "1710.10380", "submitter": "Shuai Tang", "authors": "Shuai Tang, Hailin Jin, Chen Fang, Zhaowen Wang, Virginia R. de Sa", "title": "Speeding up Context-based Sentence Representation Learning with\n  Non-autoregressive Convolutional Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays an important role in human language understanding, thus it may\nalso be useful for machines learning vector representations of language. In\nthis paper, we explore an asymmetric encoder-decoder structure for unsupervised\ncontext-based sentence representation learning. We carefully designed\nexperiments to show that neither an autoregressive decoder nor an RNN decoder\nis required. After that, we designed a model which still keeps an RNN as the\nencoder, while using a non-autoregressive convolutional decoder. We further\ncombine a suite of effective designs to significantly improve model efficiency\nwhile also achieving better performance. Our model is trained on two different\nlarge unlabelled corpora, and in both cases the transferability is evaluated on\na set of downstream NLP tasks. We empirically show that our model is simple and\nfast while producing rich sentence representations that excel in downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 03:18:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 00:12:18 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 01:05:28 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tang", "Shuai", ""], ["Jin", "Hailin", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1710.10381", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Jose C. Principe", "title": "Partitioning Relational Matrices of Similarities or Dissimilarities\n  using the Value of Information", "comments": "Submitted to the IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an approach to clustering relational matrices whose\nentries correspond to either similarities or dissimilarities between objects.\nOur approach is based on the value of information, a parameterized,\ninformation-theoretic criterion that measures the change in costs associated\nwith changes in information. Optimizing the value of information yields a\ndeterministic annealing style of clustering with many benefits. For instance,\ninvestigators avoid needing to a priori specify the number of clusters, as the\npartitions naturally undergo phase changes, during the annealing process,\nwhereby the number of clusters changes in a data-driven fashion. The\nglobal-best partition can also often be identified.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 03:21:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1710.10388", "submitter": "Cheng Mao", "authors": "Cheng Mao, Jonathan Weed and Philippe Rigollet", "title": "Minimax Rates and Efficient Algorithms for Noisy Sorting", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in studying permutation-based\nmodels for ranking from pairwise comparison data. Despite being structurally\nricher and more robust than parametric ranking models, permutation-based models\nare less well understood statistically and generally lack efficient learning\nalgorithms. In this work, we study a prototype of permutation-based ranking\nmodels, namely, the noisy sorting model. We establish the optimal rates of\nlearning the model under two sampling procedures. Furthermore, we provide a\nfast algorithm to achieve near-optimal rates if the observations are sampled\nindependently. Along the way, we discover properties of the symmetric group\nwhich are of theoretical interest.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 04:45:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Mao", "Cheng", ""], ["Weed", "Jonathan", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1710.10393", "submitter": "Xu Sun", "authors": "Xu Sun, Bingzhen Wei, Xuancheng Ren, Shuming Ma", "title": "Label Embedding Network: Learning Label Representation for Soft Training\n  of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method, called Label Embedding Network, which can learn label\nrepresentation (label embedding) during the training process of deep networks.\nWith the proposed method, the label embedding is adaptively and automatically\nlearned through back propagation. The original one-hot represented loss\nfunction is converted into a new loss function with soft distributions, such\nthat the originally unrelated labels have continuous interactions with each\nother during the training process. As a result, the trained model can achieve\nsubstantially higher accuracy and with faster convergence speed. Experimental\nresults based on competitive tasks demonstrate the effectiveness of the\nproposed method, and the learned label embedding is reasonable and\ninterpretable. The proposed method achieves comparable or even better results\nthan the state-of-the-art systems. The source code is available at\n\\url{https://github.com/lancopku/LabelEmb}.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 05:42:19 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Sun", "Xu", ""], ["Wei", "Bingzhen", ""], ["Ren", "Xuancheng", ""], ["Ma", "Shuming", ""]]}, {"id": "1710.10403", "submitter": "Cheng-Hao Cai", "authors": "Cheng-Hao Cai, Yanyan Xu, Dengfeng Ke, Kaile Su, Jing Sun", "title": "Trainable back-propagated functional transfer matrices", "comments": "39 pages, 4 figures, submitted as a journal article", "journal-ref": "Appl. Intell. (2018)", "doi": "10.1007/s10489-018-1266-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between nodes of fully connected neural networks are usually\nrepresented by weight matrices. In this article, functional transfer matrices\nare introduced as alternatives to the weight matrices: Instead of using real\nweights, a functional transfer matrix uses real functions with trainable\nparameters to represent connections between nodes. Multiple functional transfer\nmatrices are then stacked together with bias vectors and activations to form\ndeep functional transfer neural networks. These neural networks can be trained\nwithin the framework of back-propagation, based on a revision of the delta\nrules and the error transmission rule for functional connections. In\nexperiments, it is demonstrated that the revised rules can be used to train a\nrange of functional connections: 20 different functions are applied to neural\nnetworks with up to 10 hidden layers, and most of them gain high test\naccuracies on the MNIST database. It is also demonstrated that a functional\ntransfer matrix with a memory function can roughly memorise a non-cyclical\nsequence of 400 digits.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 06:59:18 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cai", "Cheng-Hao", ""], ["Xu", "Yanyan", ""], ["Ke", "Dengfeng", ""], ["Su", "Kaile", ""], ["Sun", "Jing", ""]]}, {"id": "1710.10404", "submitter": "Jinglin Chen", "authors": "Jinglin Chen, Jian Peng, Qiang Liu", "title": "Efficient Localized Inference for Large Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new localized inference algorithm for answering marginalization\nqueries in large graphical models with the correlation decay property. Given a\nquery variable and a large graphical model, we define a much smaller model in a\nlocal region around the query variable in the target model so that the marginal\ndistribution of the query variable can be accurately approximated. We introduce\ntwo approximation error bounds based on the Dobrushin's comparison theorem and\napply our bounds to derive a greedy expansion algorithm that efficiently guides\nthe selection of neighbor nodes for localized inference. We verify our\ntheoretical bounds on various datasets and demonstrate that our localized\ninference algorithm can provide fast and accurate approximation for large\ngraphical models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 07:02:07 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Chen", "Jinglin", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "1710.10451", "submitter": "Taejun Kim", "authors": "Taejun Kim, Jongpil Lee, Juhan Nam", "title": "Sample-level CNN Architectures for Music Auto-tagging Using Raw\n  Waveforms", "comments": "Accepted for publication at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the end-to-end approach using convolutional neural\nnetwork (CNN) is effective in various types of machine learning tasks. For\naudio signals, the approach takes raw waveforms as input using an 1-D\nconvolution layer. In this paper, we improve the 1-D CNN architecture for music\nauto-tagging by adopting building blocks from state-of-the-art image\nclassification models, ResNets and SENets, and adding multi-level feature\naggregation to it. We compare different combinations of the modules in building\nCNN architectures. The results show that they achieve significant improvements\nover previous state-of-the-art models on the MagnaTagATune dataset and\ncomparable results on Million Song Dataset. Furthermore, we analyze and\nvisualize our model to show how the 1-D CNN operates.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 11:55:50 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 04:39:50 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Kim", "Taejun", ""], ["Lee", "Jongpil", ""], ["Nam", "Juhan", ""]]}, {"id": "1710.10457", "submitter": "Wenzheng Li", "authors": "Shichuan Deng, Wenzheng Li, Xuan Wu", "title": "Wasserstein Identity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniformity testing and the more general identity testing are well studied\nproblems in distributional property testing. Most previous work focuses on\ntesting under $L_1$-distance. However, when the support is very large or even\ncontinuous, testing under $L_1$-distance may require a huge (even infinite)\nnumber of samples. Motivated by such issues, we consider the identity testing\nin Wasserstein distance (a.k.a. transportation distance and earthmover\ndistance) on a metric space (discrete or continuous).\n  In this paper, we propose the Wasserstein identity testing problem (Identity\nTesting in Wasserstein distance). We obtain nearly optimal worst-case sample\ncomplexity for the problem. Moreover, for a large class of probability\ndistributions satisfying the so-called \"Doubling Condition\", we provide nearly\ninstance-optimal sample complexity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 12:39:40 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Deng", "Shichuan", ""], ["Li", "Wenzheng", ""], ["Wu", "Xuan", ""]]}, {"id": "1710.10467", "submitter": "Quan Wang", "authors": "Li Wan, Quan Wang, Alan Papir, Ignacio Lopez Moreno", "title": "Generalized End-to-End Loss for Speaker Verification", "comments": "Published at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new loss function called generalized end-to-end\n(GE2E) loss, which makes the training of speaker verification models more\nefficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\nTE2E, the GE2E loss function updates the network in a way that emphasizes\nexamples that are difficult to verify at each step of the training process.\nAdditionally, the GE2E loss does not require an initial stage of example\nselection. With these properties, our model with the new loss function\ndecreases speaker verification EER by more than 10%, while reducing the\ntraining time by 60% at the same time. We also introduce the MultiReader\ntechnique, which allows us to do domain adaptation - training a more accurate\nmodel that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\nwell as multiple dialects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 13:51:51 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 22:11:24 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 21:29:09 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 19:13:25 GMT"}, {"version": "v5", "created": "Mon, 9 Nov 2020 17:02:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wan", "Li", ""], ["Wang", "Quan", ""], ["Papir", "Alan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1710.10468", "submitter": "Quan Wang", "authors": "Quan Wang, Carlton Downey, Li Wan, Philip Andrew Mansfield, Ignacio\n  Lopez Moreno", "title": "Speaker Diarization with LSTM", "comments": "Published at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, i-vector based audio embedding techniques were the dominant\napproach for speaker verification and speaker diarization applications.\nHowever, mirroring the rise of deep learning in various domains, neural network\nbased audio embeddings, also known as d-vectors, have consistently demonstrated\nsuperior speaker verification performance. In this paper, we build on the\nsuccess of d-vector based speaker verification systems to develop a new\nd-vector based approach to speaker diarization. Specifically, we combine\nLSTM-based d-vector audio embeddings with recent work in non-parametric\nclustering to obtain a state-of-the-art speaker diarization system. Our system\nis evaluated on three standard public datasets, suggesting that d-vector based\ndiarization systems offer significant advantages over traditional i-vector\nbased systems. We achieved a 12.0% diarization error rate on NIST SRE 2000\nCALLHOME, while our model is trained with out-of-domain data from voice search\nlogs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 13:59:17 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 15:58:07 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 14:53:16 GMT"}, {"version": "v4", "created": "Thu, 16 Nov 2017 16:17:58 GMT"}, {"version": "v5", "created": "Wed, 31 Jan 2018 17:19:05 GMT"}, {"version": "v6", "created": "Fri, 14 Dec 2018 21:23:33 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wang", "Quan", ""], ["Downey", "Carlton", ""], ["Wan", "Li", ""], ["Mansfield", "Philip Andrew", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1710.10470", "submitter": "Quan Wang", "authors": "F A Rezaur Rahman Chowdhury, Quan Wang, Ignacio Lopez Moreno, Li Wan", "title": "Attention-Based Models for Text-Dependent Speaker Verification", "comments": "Submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have recently shown great performance on a range of\ntasks, such as speech recognition, machine translation, and image captioning\ndue to their ability to summarize relevant information that expands through the\nentire length of an input sequence. In this paper, we analyze the usage of\nattention mechanisms to the problem of sequence summarization in our end-to-end\ntext-dependent speaker recognition system. We explore different topologies and\ntheir variants of the attention layer, and compare different pooling methods on\nthe attention weights. Ultimately, we show that attention-based models can\nimproves the Equal Error Rate (EER) of our speaker verification system by\nrelatively 14% compared to our non-attention LSTM baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 14:12:29 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 15:48:14 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 20:58:17 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Chowdhury", "F A Rezaur Rahman", ""], ["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""], ["Wan", "Li", ""]]}, {"id": "1710.10513", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Yao Xie", "title": "Crime incidents embedding using restricted Boltzmann machines", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for detecting related crime series, by unsupervised\nlearning of the latent feature embeddings from narratives of crime record via\nthe Gaussian-Bernoulli Restricted Boltzmann Machines (RBM). This is a\ndrastically different approach from prior work on crime analysis, which\ntypically considers only time and location and at most category information.\nAfter the embedding, related cases are closer to each other in the Euclidean\nfeature space, and the unrelated cases are far apart, which is a good property\ncan enable subsequent analysis such as detection and clustering of related\ncases. Experiments over several series of related crime incidents hand labeled\nby the Atlanta Police Department reveal the promise of our embedding methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 18:42:11 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 18:07:38 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 02:23:01 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Zhu", "Shixiang", ""], ["Xie", "Yao", ""]]}, {"id": "1710.10532", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Matthias Scheutz", "title": "Interpretable Apprenticeship Learning with Temporal Logic Specifications", "comments": "Accepted to the 56th IEEE Conference on Decision and Control (CDC\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has addressed using formulas in linear temporal logic (LTL) as\nspecifications for agents planning in Markov Decision Processes (MDPs). We\nconsider the inverse problem: inferring an LTL specification from demonstrated\nbehavior trajectories in MDPs. We formulate this as a multiobjective\noptimization problem, and describe state-based (\"what actually happened\") and\naction-based (\"what the agent expected to happen\") objective functions based on\na notion of \"violation cost\". We demonstrate the efficacy of the approach by\nemploying genetic programming to solve this problem in two simple domains.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 22:01:55 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1710.10547", "submitter": "Abubakar Abid", "authors": "Amirata Ghorbani, Abubakar Abid, James Zou", "title": "Interpretation of Neural Networks is Fragile", "comments": "Published as a conference paper at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for machine learning to be deployed and trusted in many\napplications, it is crucial to be able to reliably explain why the machine\nlearning algorithm makes certain predictions. For example, if an algorithm\nclassifies a given pathology image to be a malignant tumor, then the doctor may\nneed to know which parts of the image led the algorithm to this classification.\nHow to interpret black-box predictors is thus an important and active area of\nresearch. A fundamental question is: how much can we trust the interpretation\nitself? In this paper, we show that interpretation of deep learning predictions\nis extremely fragile in the following sense: two perceptively indistinguishable\ninputs with the same predicted label can be assigned very different\ninterpretations. We systematically characterize the fragility of several\nwidely-used feature-importance interpretation methods (saliency maps, relevance\npropagation, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that\neven small random perturbation can change the feature importance and new\nsystematic perturbations can lead to dramatically different interpretations\nwithout changing the label. We extend these results to show that\ninterpretations based on exemplars (e.g. influence functions) are similarly\nfragile. Our analysis of the geometry of the Hessian matrix gives insight on\nwhy fragility could be a fundamental challenge to the current interpretation\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 01:02:12 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 05:26:44 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1710.10551", "submitter": "Yining Wang", "authors": "Yining Wang, Simon Du, Sivaraman Balakrishnan, Aarti Singh", "title": "Stochastic Zeroth-order Optimization in High Dimensions", "comments": "Camera-ready version at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a high-dimensional convex function\nusing stochastic zeroth-order queries. Under sparsity assumptions on the\ngradients or function values, we present two algorithms: a successive\ncomponent/feature selection algorithm and a noisy mirror descent algorithm\nusing Lasso gradient estimates, and show that both algorithms have convergence\nrates that de- pend only logarithmically on the ambient dimension of the\nproblem. Empirical results confirm our theoretical findings and show that the\nalgorithms we design outperform classical zeroth-order optimization methods in\nthe high-dimensional setting.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 02:11:48 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 02:26:27 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wang", "Yining", ""], ["Du", "Simon", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1710.10555", "submitter": "Wenying Ji", "authors": "Wenying Ji, Simaan M. AbouRizk, Osmar R. Zaiane, Yitong Li", "title": "Complexity Analysis Approach for Prefabricated Construction Products\n  Using Uncertain Data Clustering", "comments": null, "journal-ref": null, "doi": "10.1061/(ASCE)CO.1943-7862.0001520", "report-no": null, "categories": "cs.DB cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an uncertain data clustering approach to quantitatively\nanalyze the complexity of prefabricated construction components through the\nintegration of quality performance-based measures with associated engineering\ndesign information. The proposed model is constructed in three steps, which (1)\nmeasure prefabricated construction product complexity (hereafter referred to as\nproduct complexity) by introducing a Bayesian-based nonconforming quality\nperformance indicator; (2) score each type of product complexity by developing\na Hellinger distance-based distribution similarity measurement; and (3) cluster\nproducts into homogeneous complexity groups by using the agglomerative\nhierarchical clustering technique. An illustrative example is provided to\ndemonstrate the proposed approach, and a case study of an industrial company in\nEdmonton, Canada, is conducted to validate the feasibility and applicability of\nthe proposed model. This research inventively defines and investigates product\ncomplexity from the perspective of product quality performance with design\ninformation associated. The research outcomes provide simplified,\ninterpretable, and informative insights for practitioners to better analyze and\nmanage product complexity. In addition to this practical contribution, a novel\nhierarchical clustering technique is devised. This technique is capable of\nclustering uncertain data (i.e., beta distributions) with lower computational\ncomplexity and has the potential to be generalized to cluster all types of\nuncertain data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 03:30:36 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 17:45:03 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Ji", "Wenying", ""], ["AbouRizk", "Simaan M.", ""], ["Zaiane", "Osmar R.", ""], ["Li", "Yitong", ""]]}, {"id": "1710.10556", "submitter": "Alon Gonen", "authors": "Ran Gilad-Bachrach, Alon Gonen", "title": "Smooth Sensitivity Based Approach for Differentially Private Principal\n  Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently known methods for this task either employ the computationally\nintensive \\emph{exponential mechanism} or require an access to the covariance\nmatrix, and therefore fail to utilize potential sparsity of the data. The\nproblem of designing simpler and more efficient methods for this task has been\nraised as an open problem in \\cite{kapralov2013differentially}.\n  In this paper we address this problem by employing the output perturbation\nmechanism. Despite being arguably the simplest and most straightforward\ntechnique, it has been overlooked due to the large \\emph{global sensitivity}\nassociated with publishing the leading eigenvector. We tackle this issue by\nadopting a \\emph{smooth sensitivity} based approach, which allows us to\nestablish differential privacy (in a worst-case manner) and near-optimal sample\ncomplexity results under eigengap assumption. We consider both the pure and the\napproximate notions of differential privacy, and demonstrate a tradeoff between\nprivacy level and sample complexity. We conclude by suggesting how our results\ncan be extended to related problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 03:35:10 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 03:23:11 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 02:07:14 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 08:52:42 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gilad-Bachrach", "Ran", ""], ["Gonen", "Alon", ""]]}, {"id": "1710.10564", "submitter": "Trung Pham", "authors": "Toan Tran, Trung Pham, Gustavo Carneiro, Lyle Palmer and Ian Reid", "title": "A Bayesian Data Augmentation Approach for Learning Deep Models", "comments": "Accepted to NISP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is an essential part of the training process applied to\ndeep learning models. The motivation is that a robust training process for deep\nlearning models depends on large annotated datasets, which are expensive to be\nacquired, stored and processed. Therefore a reasonable alternative is to be\nable to automatically generate new annotated training samples using a process\nknown as data augmentation. The dominant data augmentation approach in the\nfield assumes that new training samples can be obtained via random geometric or\nappearance transformations applied to annotated training samples, but this is a\nstrong assumption because it is unclear if this is a reliable generative model\nfor producing new training samples. In this paper, we provide a novel Bayesian\nformulation to data augmentation, where new annotated training points are\ntreated as missing variables and generated based on the distribution learned\nfrom the training set. For learning, we introduce a theoretically sound\nalgorithm --- generalised Monte Carlo expectation maximisation, and demonstrate\none possible implementation via an extension of the Generative Adversarial\nNetwork (GAN). Classification results on MNIST, CIFAR-10 and CIFAR-100 show the\nbetter performance of our proposed method compared to the current dominant data\naugmentation approach mentioned above --- the results also show that our\napproach produces better classification results than similar GAN models.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 05:02:14 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Tran", "Toan", ""], ["Pham", "Trung", ""], ["Carneiro", "Gustavo", ""], ["Palmer", "Lyle", ""], ["Reid", "Ian", ""]]}, {"id": "1710.10568", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Jun Zhu and Le Song", "title": "Stochastic Training of Graph Convolutional Networks with Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are powerful deep neural networks for\ngraph-structured data. However, GCN computes the representation of a node\nrecursively from its neighbors, making the receptive field size grow\nexponentially with the number of layers. Previous attempts on reducing the\nreceptive field size by subsampling neighbors do not have a convergence\nguarantee, and their receptive field size per node is still in the order of\nhundreds. In this paper, we develop control variate based algorithms which\nallow sampling an arbitrarily small neighbor size. Furthermore, we prove new\ntheoretical guarantee for our algorithms to converge to a local optimum of GCN.\nEmpirical results show that our algorithms enjoy a similar convergence with the\nexact algorithm using only two neighbors per node. The runtime of our\nalgorithms on a large Reddit dataset is only one seventh of previous neighbor\nsampling algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 06:14:00 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 12:55:08 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 15:23:22 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Song", "Le", ""]]}, {"id": "1710.10570", "submitter": "Saiprasad Koturwar", "authors": "Saiprasad Koturwar, Shabbir Merchant", "title": "Weight Initialization of Deep Neural Networks(DNNs) using Data\n  Statistics", "comments": "The work is currently under progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) form the backbone of almost every\nstate-of-the-art technique in the fields such as computer vision, speech\nprocessing, and text analysis. The recent advances in computational technology\nhave made the use of DNNs more practical. Despite the overwhelming performances\nby DNN and the advances in computational technology, it is seen that very few\nresearchers try to train their models from the scratch. Training of DNNs still\nremains a difficult and tedious job. The main challenges that researchers face\nduring training of DNNs are the vanishing/exploding gradient problem and the\nhighly non-convex nature of the objective function which has up to million\nvariables. The approaches suggested in He and Xavier solve the vanishing\ngradient problem by providing a sophisticated initialization technique. These\napproaches have been quite effective and have achieved good results on standard\ndatasets, but these same approaches do not work very well on more practical\ndatasets. We think the reason for this is not making use of data statistics for\ninitializing the network weights. Optimizing such a high dimensional loss\nfunction requires careful initialization of network weights. In this work, we\npropose a data dependent initialization and analyze its performance against the\nstandard initialization techniques such as He and Xavier. We performed our\nexperiments on some practical datasets and the results show our algorithm's\nsuperior classification accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 07:23:19 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 08:25:20 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Koturwar", "Saiprasad", ""], ["Merchant", "Shabbir", ""]]}, {"id": "1710.10571", "submitter": "Aman Sinha", "authors": "Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi", "title": "Certifying Some Distributional Robustness with Principled Adversarial\n  Training", "comments": "ICLR 2018: https://openreview.net/forum?id=Hk6kPgZA-", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples and researchers have\nproposed many heuristic attack and defense mechanisms. We address this problem\nthrough the principled lens of distributionally robust optimization, which\nguarantees performance under adversarial input perturbations. By considering a\nLagrangian penalty formulation of perturbing the underlying data distribution\nin a Wasserstein ball, we provide a training procedure that augments model\nparameter updates with worst-case perturbations of training data. For smooth\nlosses, our procedure provably achieves moderate levels of robustness with\nlittle computational or statistical cost relative to empirical risk\nminimization. Furthermore, our statistical guarantees allow us to efficiently\ncertify robustness for the population loss. For imperceptible perturbations,\nour method matches or outperforms heuristic approaches.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 07:27:57 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 18:01:49 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 20:20:25 GMT"}, {"version": "v4", "created": "Tue, 1 May 2018 05:52:13 GMT"}, {"version": "v5", "created": "Fri, 1 May 2020 07:29:34 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sinha", "Aman", ""], ["Namkoong", "Hongseok", ""], ["Volpi", "Riccardo", ""], ["Duchi", "John", ""]]}, {"id": "1710.10600", "submitter": "Daniel Lopez Martinez", "authors": "Daniel Lopez-Martinez", "title": "Regularization approaches for support vector machines with applications\n  to biomedical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) is a widely used machine learning tool for\nclassification based on statistical learning theory. Given a set of training\ndata, the SVM finds a hyperplane that separates two different classes of data\npoints by the largest distance. While the standard form of SVM uses L2-norm\nregularization, other regularization approaches are particularly attractive for\nbiomedical datasets where, for example, sparsity and interpretability of the\nclassifier's coefficient values are highly desired features. Therefore, in this\npaper we consider different types of regularization approaches for SVMs, and\nexplore them in both synthetic and real biomedical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 12:17:19 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lopez-Martinez", "Daniel", ""]]}, {"id": "1710.10628", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, Richard E. Turner", "title": "Variational Continual Learning", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops variational continual learning (VCL), a simple but\ngeneral framework for continual learning that fuses online variational\ninference (VI) and recent advances in Monte Carlo VI for neural networks. The\nframework can successfully train both deep discriminative models and deep\ngenerative models in complex continual learning settings where existing tasks\nevolve over time and entirely new tasks emerge. Experimental results show that\nVCL outperforms state-of-the-art continual learning methods on a variety of\ntasks, avoiding catastrophic forgetting in a fully automatic way.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 15:30:58 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 11:40:11 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 14:51:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Li", "Yingzhen", ""], ["Bui", "Thang D.", ""], ["Turner", "Richard E.", ""]]}, {"id": "1710.10629", "submitter": "Stefan Doerr", "authors": "Stefan Doerr, Igor Ariz-Extreme, Matthew J. Harvey, Gianni De\n  Fabritiis", "title": "Dimensionality reduction methods for molecular simulations", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular simulations produce very high-dimensional data-sets with millions\nof data points. As analysis methods are often unable to cope with so many\ndimensions, it is common to use dimensionality reduction and clustering methods\nto reach a reduced representation of the data. Yet these methods often fail to\ncapture the most important features necessary for the construction of a Markov\nmodel. Here we demonstrate the results of various dimensionality reduction\nmethods on two simulation data-sets, one of protein folding and another of\nprotein-ligand binding. The methods tested include a k-means clustering\nvariant, a non-linear auto encoder, principal component analysis and tICA. The\ndimension-reduced data is then used to estimate the implied timescales of the\nslowest process by a Markov state model analysis to assess the quality of the\nprojection. The projected dimensions learned from the data are visualized to\ndemonstrate which conformations the various methods choose to represent the\nmolecular process.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 15:33:42 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 10:00:57 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Doerr", "Stefan", ""], ["Ariz-Extreme", "Igor", ""], ["Harvey", "Matthew J.", ""], ["De Fabritiis", "Gianni", ""]]}, {"id": "1710.10646", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang", "title": "On the Consistency of Quick Shift", "comments": "Proceedings of 31st Conference on Neural Information Processing\n  Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quick Shift is a popular mode-seeking and clustering algorithm. We present\nfinite sample statistical consistency guarantees for Quick Shift on mode and\ncluster recovery under mild distributional assumptions. We then apply our\nresults to construct a consistent modal regression algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 16:49:38 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 07:28:02 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jiang", "Heinrich", ""]]}, {"id": "1710.10657", "submitter": "Giulia DeSalvo", "authors": "Corinna Cortes, Giulia DeSalvo, Vitaly Kuznetsov, Mehryar Mohri, and\n  Scott Yang", "title": "Discrepancy-Based Algorithms for Non-Stationary Rested Bandits", "comments": "Unfinished work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-armed bandit problem where the rewards are realizations of\ngeneral non-stationary stochastic processes, a setting that generalizes many\nexisting lines of work and analyses. In particular, we present a theoretical\nanalysis and derive regret guarantees for rested bandits in which the reward\ndistribution of each arm changes only when we pull that arm. Remarkably, our\nregret bounds are logarithmic in the number of rounds under several natural\nconditions. We introduce a new algorithm based on classical UCB ideas combined\nwith the notion of weighted discrepancy, a useful tool for measuring the\nnon-stationarity of a stochastic process. We show that the notion of\ndiscrepancy can be used to design very general algorithms and a unified\nframework for the analysis of multi-armed rested bandit problems with\nnon-stationary rewards. In particular, we show that we can recover the regret\nguarantees of many specific instances of bandit problems with non-stationary\nrewards that have been studied in the literature. We also provide experiments\ndemonstrating that our algorithms can enjoy a significant improvement in\npractice compared to standard benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 17:59:19 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 23:16:33 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:48:29 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Cortes", "Corinna", ""], ["DeSalvo", "Giulia", ""], ["Kuznetsov", "Vitaly", ""], ["Mohri", "Mehryar", ""], ["Yang", "Scott", ""]]}, {"id": "1710.10686", "submitter": "Vladimir Golkov", "authors": "Jan Kuka\\v{c}ka, Vladimir Golkov, Daniel Cremers", "title": "Regularization for Deep Learning: A Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 20:27:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Kuka\u010dka", "Jan", ""], ["Golkov", "Vladimir", ""], ["Cremers", "Daniel", ""]]}, {"id": "1710.10689", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos, Polykarpos Meladianos, Antoine Jean-Pierre\n  Tixier, Konstantinos Skianis, Michalis Vazirgiannis", "title": "Kernel Graph Convolutional Neural Networks", "comments": "Accepted at ICANN '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels have been successfully applied to many graph classification\nproblems. Typically, a kernel is first designed, and then an SVM classifier is\ntrained based on the features defined implicitly by this kernel. This two-stage\napproach decouples data representation from learning, which is suboptimal. On\nthe other hand, Convolutional Neural Networks (CNNs) have the capability to\nlearn their own features directly from the raw data during training.\nUnfortunately, they cannot handle irregular data such as graphs. We address\nthis challenge by using graph kernels to embed meaningful local neighborhoods\nof the graphs in a continuous vector space. A set of filters is then convolved\nwith these patches, pooled, and the output is then passed to a feedforward\nnetwork. With limited parameter tuning, our approach outperforms strong\nbaselines on 7 out of 10 benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 20:53:40 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 19:41:23 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Meladianos", "Polykarpos", ""], ["Tixier", "Antoine Jean-Pierre", ""], ["Skianis", "Konstantinos", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1710.10704", "submitter": "Alireza Bagheri", "authors": "Alireza Bagheri, Osvaldo Simeone, Bipin Rajendran", "title": "Training Probabilistic Spiking Neural Networks with First-to-spike\n  Decoding", "comments": "A shorter version will be published on Proc. IEEE ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at\nharnessing the energy efficiency of spike-domain processing by building on\ncomputing elements that operate on, and exchange, spikes. In this paper, the\nproblem of training a two-layer SNN is studied for the purpose of\nclassification, under a Generalized Linear Model (GLM) probabilistic neural\nmodel that was previously considered within the computational neuroscience\nliterature. Conventional classification rules for SNNs operate offline based on\nthe number of output spikes at each output neuron. In contrast, a novel\ntraining method is proposed here for a first-to-spike decoding rule, whereby\nthe SNN can perform an early classification decision once spike firing is\ndetected at an output neuron. Numerical results bring insights into the optimal\nparameter selection for the GLM neuron and on the accuracy-complexity trade-off\nperformance of conventional and first-to-spike decoding.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 22:13:53 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 07:41:15 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 04:49:44 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Bagheri", "Alireza", ""], ["Simeone", "Osvaldo", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1710.10728", "submitter": "Chengyu Liu", "authors": "Chengyu Liu, Wei Wang", "title": "Contextual Regression: An Accurate and Conveniently Interpretable\n  Nonlinear Model for Mining Discovery from Scientific Data", "comments": "18 pages of Main Article, 30 pages of Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms such as linear regression, SVM and neural network\nhave played an increasingly important role in the process of scientific\ndiscovery. However, none of them is both interpretable and accurate on\nnonlinear datasets. Here we present contextual regression, a method that joins\nthese two desirable properties together using a hybrid architecture of neural\nnetwork embedding and dot product layer. We demonstrate its high prediction\naccuracy and sensitivity through the task of predictive feature selection on a\nsimulated dataset and the application of predicting open chromatin sites in the\nhuman genome. On the simulated data, our method achieved high fidelity recovery\nof feature contributions under random noise levels up to 200%. On the open\nchromatin dataset, the application of our method not only outperformed the\nstate of the art method in terms of accuracy, but also unveiled two previously\nunfound open chromatin related histone marks. Our method can fill the blank of\naccurate and interpretable nonlinear modeling in scientific data mining tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 00:39:47 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Liu", "Chengyu", ""], ["Wang", "Wei", ""]]}, {"id": "1710.10733", "submitter": "Yash Sharma", "authors": "Yash Sharma, Pin-Yu Chen", "title": "Attacking the Madry Defense Model with $L_1$-based Adversarial Examples", "comments": "Accepted to ICLR 2018 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Madry Lab recently hosted a competition designed to test the robustness\nof their adversarially trained MNIST model. Attacks were constrained to perturb\neach pixel of the input image by a scaled maximal $L_\\infty$ distortion\n$\\epsilon$ = 0.3. This discourages the use of attacks which are not optimized\non the $L_\\infty$ distortion metric. Our experimental results demonstrate that\nby relaxing the $L_\\infty$ constraint of the competition, the elastic-net\nattack to deep neural networks (EAD) can generate transferable adversarial\nexamples which, despite their high average $L_\\infty$ distortion, have minimal\nvisual distortion. These results call into question the use of $L_\\infty$ as a\nsole measure for visual distortion, and further demonstrate the power of EAD at\ngenerating robust adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 00:57:34 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 07:31:59 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 03:28:21 GMT"}, {"version": "v4", "created": "Fri, 27 Jul 2018 22:01:59 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Sharma", "Yash", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "1710.10737", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Linearly convergent stochastic heavy ball method for minimizing\n  generalization error", "comments": "NIPS 2017, Workshop on Optimization for Machine Learning (camera\n  ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we establish the first linear convergence result for the\nstochastic heavy ball method. The method performs SGD steps with a fixed\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\nminimizing the expected loss and not on finite-sum minimization, which is\ntypically a much harder problem. While in the analysis we constrain ourselves\nto quadratic loss, the overall objective is not necessarily strongly convex.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 01:49:34 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 02:18:06 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1710.10742", "submitter": "Dustin Tran", "authors": "Dustin Tran, David M. Blei", "title": "Implicit Causal Models for Genome-wide Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in probabilistic generative models has accelerated, developing\nricher models with neural architectures, implicit densities, and with scalable\nalgorithms for their Bayesian inference. However, there has been limited\nprogress in models that capture causal relationships, for example, how\nindividual genetic factors cause major human diseases. In this work, we focus\non two challenges in particular: How do we build richer causal models, which\ncan capture highly nonlinear relationships and interactions between multiple\ncauses? How do we adjust for latent confounders, which are variables\ninfluencing both cause and effect and which prevent learning of causal\nrelationships? To address these challenges, we synthesize ideas from causality\nand modern probabilistic modeling. For the first, we describe implicit causal\nmodels, a class of causal models that leverages neural architectures with an\nimplicit density. For the second, we describe an implicit causal model that\nadjusts for confounders by sharing strength across examples. In experiments, we\nscale Bayesian inference on up to a billion genetic measurements. We achieve\nstate of the art accuracy for identifying causal factors: we significantly\noutperform existing genetics methods by an absolute difference of 15-45.3%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 02:05:10 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Tran", "Dustin", ""], ["Blei", "David M.", ""]]}, {"id": "1710.10755", "submitter": "Jianyi Wang", "authors": "Yuhang Song, Mai Xu, Jianyi Wang, Minglang Qiao, Liangyu Huo, Zulin\n  Wang", "title": "Predicting Head Movement in Panoramic Video: A Deep Reinforcement\n  Learning Approach", "comments": "15 pages, 10 figures, published on TPAMI 2018", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence.\n  2018 Jul 24", "doi": "10.1109/TPAMI.2018.2858783", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Panoramic video provides immersive and interactive experience by enabling\nhumans to control the field of view (FoV) through head movement (HM). Thus, HM\nplays a key role in modeling human attention on panoramic video. This paper\nestablishes a database collecting subjects' HM in panoramic video sequences.\nFrom this database, we find that the HM data are highly consistent across\nsubjects. Furthermore, we find that deep reinforcement learning (DRL) can be\napplied to predict HM positions, via maximizing the reward of imitating human\nHM scanpaths through the agent's actions. Based on our findings, we propose a\nDRL-based HM prediction (DHP) approach with offline and online versions, called\noffline-DHP and online-DHP. In offline-DHP, multiple DRL workflows are run to\ndetermine potential HM positions at each panoramic frame. Then, a heat map of\nthe potential HM positions, named the HM map, is generated as the output of\noffline-DHP. In online-DHP, the next HM position of one subject is estimated\ngiven the currently observed HM position, which is achieved by developing a DRL\nalgorithm upon the learned offline-DHP model. Finally, the experiments validate\nthat our approach is effective in both offline and online prediction of HM\npositions for panoramic video, and that the learned offline-DHP model can\nimprove the performance of online-DHP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 03:32:22 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:39:17 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 01:04:53 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2018 01:51:30 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 09:33:09 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Song", "Yuhang", ""], ["Xu", "Mai", ""], ["Wang", "Jianyi", ""], ["Qiao", "Minglang", ""], ["Huo", "Liangyu", ""], ["Wang", "Zulin", ""]]}, {"id": "1710.10766", "submitter": "Yang Song", "authors": "Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, Nate Kushman", "title": "PixelDefend: Leveraging Generative Models to Understand and Defend\n  against Adversarial Examples", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbations of normal images are usually imperceptible to\nhumans, but they can seriously confuse state-of-the-art machine learning\nmodels. What makes them so special in the eyes of image classifiers? In this\npaper, we show empirically that adversarial examples mainly lie in the low\nprobability regions of the training distribution, regardless of attack types\nand targeted models. Using statistical hypothesis testing, we find that modern\nneural density models are surprisingly good at detecting imperceptible image\nperturbations. Based on this discovery, we devised PixelDefend, a new approach\nthat purifies a maliciously perturbed image by moving it back towards the\ndistribution seen in the training data. The purified image is then run through\nan unmodified classifier, making our method agnostic to both the classifier and\nthe attacking method. As a result, PixelDefend can be used to protect already\ndeployed models and be combined with other model-specific defenses. Experiments\nshow that our method greatly improves resilience across a wide variety of\nstate-of-the-art attacking methods, increasing accuracy on the strongest attack\nfrom 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 04:21:23 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 06:03:37 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 05:26:01 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Song", "Yang", ""], ["Kim", "Taesup", ""], ["Nowozin", "Sebastian", ""], ["Ermon", "Stefano", ""], ["Kushman", "Nate", ""]]}, {"id": "1710.10769", "submitter": "Penporn Koanantakool", "authors": "Penporn Koanantakool, Alnur Ali, Ariful Azad, Aydin Buluc, Dmitriy\n  Morozov, Leonid Oliker, Katherine Yelick, Sang-Yun Oh", "title": "Communication-Avoiding Optimization Methods for Distributed\n  Massive-Scale Sparse Inverse Covariance Estimation", "comments": "Main paper: 15 pages, appendix: 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across a variety of scientific disciplines, sparse inverse covariance\nestimation is a popular tool for capturing the underlying dependency\nrelationships in multivariate data. Unfortunately, most estimators are not\nscalable enough to handle the sizes of modern high-dimensional data sets (often\non the order of terabytes), and assume Gaussian samples. To address these\ndeficiencies, we introduce HP-CONCORD, a highly scalable optimization method\nfor estimating a sparse inverse covariance matrix based on a regularized\npseudolikelihood framework, without assuming Gaussianity. Our parallel proximal\ngradient method uses a novel communication-avoiding linear algebra algorithm\nand runs across a multi-node cluster with up to 1k nodes (24k cores), achieving\nparallel scalability on problems with up to ~819 billion parameters (1.28\nmillion dimensions); even on a single node, HP-CONCORD demonstrates\nscalability, outperforming a state-of-the-art method. We also use HP-CONCORD to\nestimate the underlying dependency structure of the brain from fMRI data, and\nuse the result to identify functional regions automatically. The results show\ngood agreement with a clustering from the neuroscience literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 04:32:41 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 16:06:51 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Koanantakool", "Penporn", ""], ["Ali", "Alnur", ""], ["Azad", "Ariful", ""], ["Buluc", "Aydin", ""], ["Morozov", "Dmitriy", ""], ["Oliker", "Leonid", ""], ["Yelick", "Katherine", ""], ["Oh", "Sang-Yun", ""]]}, {"id": "1710.10770", "submitter": "Melanie Weber", "authors": "Melanie Weber and Suvrit Sra", "title": "Riemannian Optimization via Frank-Wolfe Methods", "comments": "Under Review. Largely revised version, including an extended\n  experimental section and an application to the special orthogonal group and\n  the Procrustes problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study projection-free methods for constrained Riemannian optimization. In\nparticular, we propose the Riemannian Frank-Wolfe (RFW) method. We analyze\nnon-asymptotic convergence rates of RFW to an optimum for (geodesically) convex\nproblems, and to a critical point for nonconvex objectives. We also present a\npractical setting under which RFW can attain a linear convergence rate. As a\nconcrete example, we specialize Rfw to the manifold of positive definite\nmatrices and apply it to two tasks: (i) computing the matrix geometric mean\n(Riemannian centroid); and (ii) computing the Bures-Wasserstein barycenter.\nBoth tasks involve geodesically convex interval constraints, for which we show\nthat the Riemannian \"linear oracle\" required by RFW admits a closed-form\nsolution; this result may be of independent interest. We further specialize RFW\nto the special orthogonal group and show that here too, the Riemannian \"linear\noracle\" can be solved in closed form. Here, we describe an application to the\nsynchronization of data matrices (Procrustes problem). We complement our\ntheoretical results with an empirical comparison of Rfw against\nstate-of-the-art Riemannian optimization methods and observe that RFW performs\ncompetitively on the task of computing Riemannian centroids.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 04:34:21 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 21:37:55 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 15:44:39 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Weber", "Melanie", ""], ["Sra", "Suvrit", ""]]}, {"id": "1710.10772", "submitter": "Xingwei Cao", "authors": "Xingwei Cao, Xuyang Zhao, Qibin Zhao", "title": "Tensorizing Generative Adversarial Nets", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) and its variants exhibit\nstate-of-the-art performance in the class of generative models. To capture\nhigher-dimensional distributions, the common learning procedure requires high\ncomputational complexity and a large number of parameters. The problem of\nemploying such massive framework arises when deploying it on a platform with\nlimited computational power such as mobile phones. In this paper, we present a\nnew generative adversarial framework by representing each layer as a tensor\nstructure connected by multilinear operations, aiming to reduce the number of\nmodel parameters by a large factor while preserving the generative performance\nand sample quality. To learn the model, we employ an efficient algorithm which\nalternatively optimizes both discriminator and generator. Experimental outcomes\ndemonstrate that our model can achieve high compression rate for model\nparameters up to $35$ times when compared to the original GAN for MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:05:02 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 03:23:03 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Cao", "Xingwei", ""], ["Zhao", "Xuyang", ""], ["Zhao", "Qibin", ""]]}, {"id": "1710.10774", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Sequence-to-Sequence ASR Optimization via Reinforcement Learning", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of sequence-to-sequence approaches in automatic speech\nrecognition (ASR) systems, the models still suffer from several problems,\nmainly due to the mismatch between the training and inference conditions. In\nthe sequence-to-sequence architecture, the model is trained to predict the\ngrapheme of the current time-step given the input of speech signal and the\nground-truth grapheme history of the previous time-steps. However, it remains\nunclear how well the model approximates real-world speech during inference.\nThus, generating the whole transcription from scratch based on previous\npredictions is complicated and errors can propagate over time. Furthermore, the\nmodel is optimized to maximize the likelihood of training data instead of error\nrate evaluation metrics that actually quantify recognition quality. This paper\npresents an alternative strategy for training sequence-to-sequence ASR models\nby adopting the idea of reinforcement learning (RL). Unlike the standard\ntraining scheme with maximum likelihood estimation, our proposed approach\nutilizes the policy gradient algorithm. We can (1) sample the whole\ntranscription based on the model's prediction in the training process and (2)\ndirectly optimize the model with negative Levenshtein distance as the reward.\nExperimental results demonstrate that we significantly improved the performance\ncompared to a model trained only with maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:09:36 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 13:44:38 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1710.10776", "submitter": "Catherine Wong", "authors": "Catherine Wong and Andrea Gesmundo", "title": "Transfer Learning to Learn with Multitask Neural Model Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models require extensive architecture design exploration and\nhyperparameter optimization to perform well on a given task. The exploration of\nthe model design space is often made by a human expert, and optimized using a\ncombination of grid search and search heuristics over a large space of possible\nchoices. Neural Architecture Search (NAS) is a Reinforcement Learning approach\nthat has been proposed to automate architecture design. NAS has been\nsuccessfully applied to generate Neural Networks that rival the best\nhuman-designed architectures. However, NAS requires sampling, constructing, and\ntraining hundreds to thousands of models to achieve well-performing\narchitectures. This procedure needs to be executed from scratch for each new\ntask. The application of NAS to a wide set of tasks currently lacks a way to\ntransfer generalizable knowledge across tasks. In this paper, we present the\nMultitask Neural Model Search (MNMS) controller. Our goal is to learn a\ngeneralizable framework that can condition model construction on successful\nmodel searches for previously seen tasks, thus significantly speeding up the\nsearch for new tasks. We demonstrate that MNMS can conduct an automated\narchitecture search for multiple tasks simultaneously while still learning\nwell-performing, specialized models for each task. We then show that\npre-trained MNMS controllers can transfer learning to new tasks. By leveraging\nknowledge from previous searches, we find that pre-trained MNMS models start\nfrom a better location in the search space and reduce search time on unseen\ntasks, while still discovering models that outperform published human-designed\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:32:50 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wong", "Catherine", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1710.10779", "submitter": "Cem Subakan", "authors": "Cem Subakan and Paris Smaragdis", "title": "Generative Adversarial Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative source separation methods such as non-negative matrix\nfactorization (NMF) or auto-encoders, rely on the assumption of an output\nprobability density. Generative Adversarial Networks (GANs) can learn data\ndistributions without needing a parametric assumption on the output density. We\nshow on a speech source separation experiment that, a multi-layer perceptron\ntrained with a Wasserstein-GAN formulation outperforms NMF, auto-encoders\ntrained with maximum likelihood, and variational auto-encoders in terms of\nsource to distortion ratio.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:42:25 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Subakan", "Cem", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1710.10781", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai", "title": "Stochastic variance reduced multiplicative update for nonnegative matrix\n  factorization", "comments": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF), a dimensionality reduction and factor\nanalysis method, is a special case in which factor matrices have low-rank\nnonnegative constraints. Considering the stochastic learning in NMF, we\nspecifically address the multiplicative update (MU) rule, which is the most\npopular, but which has slow convergence property. This present paper introduces\non the stochastic MU rule a variance-reduced technique of stochastic gradient.\nNumerical comparisons suggest that our proposed algorithms robustly outperform\nstate-of-the-art algorithms across different synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 06:14:17 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 21:45:46 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Kasai", "Hiroyuki", ""]]}, {"id": "1710.10784", "submitter": "Xiao Dong", "authors": "Xiao Dong, Jiasong Wu, Ling Zhou", "title": "How deep learning works --The geometry of deep learning", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Why and how that deep learning works well on different tasks remains a\nmystery from a theoretical perspective. In this paper we draw a geometric\npicture of the deep learning system by finding its analogies with two existing\ngeometric structures, the geometry of quantum computations and the geometry of\nthe diffeomorphic template matching. In this framework, we give the geometric\nstructures of different deep learning systems including convolutional neural\nnetworks, residual networks, recursive neural networks, recurrent neural\nnetworks and the equilibrium prapagation framework. We can also analysis the\nrelationship between the geometrical structures and their performance of\ndifferent networks in an algorithmic level so that the geometric framework may\nguide the design of the structures and algorithms of deep learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 06:42:23 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Dong", "Xiao", ""], ["Wu", "Jiasong", ""], ["Zhou", "Ling", ""]]}, {"id": "1710.10793", "submitter": "Soheil Feizi", "authors": "Soheil Feizi, Farzan Farnia, Tony Ginart and David Tse", "title": "Understanding GANs: the LQG Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become a popular method to learn\na probability model from data. In this paper, we aim to provide an\nunderstanding of some of the basic issues surrounding GANs including their\nformulation, generalization and stability on a simple benchmark where the data\nhas a high-dimensional Gaussian distribution. Even in this simple benchmark,\nthe GAN problem has not been well-understood as we observe that existing\nstate-of-the-art GAN architectures may fail to learn a proper generative\ndistribution owing to (1) stability issues (i.e., convergence to bad local\nsolutions or not converging at all), (2) approximation issues (i.e., having\nimproper global GAN optimizers caused by inappropriate GAN's loss functions),\nand (3) generalizability issues (i.e., requiring large number of samples for\ntraining). In this setup, we propose a GAN architecture which recovers the\nmaximum-likelihood solution and demonstrates fast generalization. Moreover, we\nanalyze global stability of different computational approaches for the proposed\nGAN optimization and highlight their pros and cons. Finally, we outline an\nextension of our model-based approach to design GANs in more complex setups\nthan the considered Gaussian benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 07:20:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 13:42:23 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Feizi", "Soheil", ""], ["Farnia", "Farzan", ""], ["Ginart", "Tony", ""], ["Tse", "David", ""]]}, {"id": "1710.10824", "submitter": "Shuliang Xu", "authors": "Lin Feng, Shuliang Xu, Feilong Wang, Shenglan Liu", "title": "Rough extreme learning machine: a new classification method based on\n  uncertainty measure", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extreme learning machine (ELM) is a new single hidden layer feedback neural\nnetwork. The weights of the input layer and the biases of neurons in hidden\nlayer are randomly generated, the weights of the output layer can be\nanalytically determined. ELM has been achieved good results for a large number\nof classification tasks. In this paper, a new extreme learning machine called\nrough extreme learning machine (RELM) was proposed. RELM uses rough set to\ndivide data into upper approximation set and lower approximation set, and the\ntwo approximation sets are utilized to train upper approximation neurons and\nlower approximation neurons. In addition, an attribute reduction is executed in\nthis algorithm to remove redundant attributes. The experimental results showed,\ncomparing with the comparison algorithms, RELM can get a better accuracy and\nrepeatability in most cases, RELM can not only maintain the advantages of fast\nspeed, but also effectively cope with the classification task for\nhigh-dimensional data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 09:37:20 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 09:03:36 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Feng", "Lin", ""], ["Xu", "Shuliang", ""], ["Wang", "Feilong", ""], ["Liu", "Shenglan", ""]]}, {"id": "1710.10866", "submitter": "Tadashi Kozuno", "authors": "Tadashi Kozuno, Eiji Uchibe, Kenji Doya", "title": "Unifying Value Iteration, Advantage Learning, and Dynamic Policy\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate dynamic programming algorithms, such as approximate value\niteration, have been successfully applied to many complex reinforcement\nlearning tasks, and a better approximate dynamic programming algorithm is\nexpected to further extend the applicability of reinforcement learning to\nvarious tasks. In this paper we propose a new, robust dynamic programming\nalgorithm that unifies value iteration, advantage learning, and dynamic policy\nprogramming. We call it generalized value iteration (GVI) and its approximated\nversion, approximate GVI (AGVI). We show AGVI's performance guarantee, which\nincludes performance guarantees for existing algorithms, as special cases. We\ndiscuss theoretical weaknesses of existing algorithms, and explain the\nadvantages of AGVI. Numerical experiments in a simple environment support\ntheoretical arguments, and suggest that AGVI is a promising alternative to\nprevious algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:05:32 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Kozuno", "Tadashi", ""], ["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "1710.10881", "submitter": "Armand Joulin", "authors": "Armand Joulin, Edouard Grave, Piotr Bojanowski, Maximilian Nickel,\n  Tomas Mikolov", "title": "Fast Linear Model for Knowledge Graph Embeddings", "comments": "Submitted AKBC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that a simple baseline based on a Bag-of-Words (BoW)\nrepresentation learns surprisingly good knowledge graph embeddings. By casting\nknowledge base completion and question answering as supervised classification\nproblems, we observe that modeling co-occurences of entities and relations\nleads to state-of-the-art performance with a training time of a few minutes\nusing the open sourced library fastText.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:46:23 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Joulin", "Armand", ""], ["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Nickel", "Maximilian", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1710.10903", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Guillem Cucurull, Arantxa Casanova, Adriana\n  Romero, Pietro Li\\`o, Yoshua Bengio", "title": "Graph Attention Networks", "comments": "To appear at ICLR 2018. 12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present graph attention networks (GATs), novel neural network\narchitectures that operate on graph-structured data, leveraging masked\nself-attentional layers to address the shortcomings of prior methods based on\ngraph convolutions or their approximations. By stacking layers in which nodes\nare able to attend over their neighborhoods' features, we enable (implicitly)\nspecifying different weights to different nodes in a neighborhood, without\nrequiring any kind of costly matrix operation (such as inversion) or depending\non knowing the graph structure upfront. In this way, we address several key\nchallenges of spectral-based graph neural networks simultaneously, and make our\nmodel readily applicable to inductive as well as transductive problems. Our GAT\nmodels have achieved or matched state-of-the-art results across four\nestablished transductive and inductive graph benchmarks: the Cora, Citeseer and\nPubmed citation network datasets, as well as a protein-protein interaction\ndataset (wherein test graphs remain unseen during training).\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 12:41:12 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 11:18:15 GMT"}, {"version": "v3", "created": "Sun, 4 Feb 2018 19:13:29 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Cucurull", "Guillem", ""], ["Casanova", "Arantxa", ""], ["Romero", "Adriana", ""], ["Li\u00f2", "Pietro", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.10928", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen and Matthias Hein", "title": "Optimization Landscape and Expressivity of Deep CNNs", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the loss landscape and expressiveness of practical deep\nconvolutional neural networks (CNNs) with shared weights and max pooling\nlayers. We show that such CNNs produce linearly independent features at a\n\"wide\" layer which has more neurons than the number of training samples. This\ncondition holds e.g. for the VGG network. Furthermore, we provide for such wide\nCNNs necessary and sufficient conditions for global minima with zero training\nerror. For the case where the wide layer is followed by a fully connected layer\nwe show that almost every critical point of the empirical loss is a global\nminimum with zero training error. Our analysis suggests that both depth and\nwidth are very important in deep learning. While depth brings more\nrepresentational power and allows the network to learn high level features,\nwidth smoothes the optimization landscape of the loss function in the sense\nthat a sufficiently wide network has a well-behaved loss surface with almost no\nbad local minima.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:24:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 12:49:58 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Nguyen", "Quynh", ""], ["Hein", "Matthias", ""]]}, {"id": "1710.10944", "submitter": "Yuan Zeng", "authors": "Yuan Zeng, Kevin Devincentis, Yao Xiao, Zubayer Ibne Ferdous, Xiaochen\n  Guo, Zhiyuan Yan, Yevgeny Berdichevsky", "title": "A Supervised STDP-based Training Algorithm for Living Neural Networks", "comments": "5 pages, 3 figures, Accepted by ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have shown great potential in many applications like speech\nrecognition, drug discovery, image classification, and object detection. Neural\nnetwork models are inspired by biological neural networks, but they are\noptimized to perform machine learning tasks on digital computers. The proposed\nwork explores the possibilities of using living neural networks in vitro as\nbasic computational elements for machine learning applications. A new\nsupervised STDP-based learning algorithm is proposed in this work, which\nconsiders neuron engineering constrains. A 74.7% accuracy is achieved on the\nMNIST benchmark for handwritten digit recognition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:55:59 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 18:50:59 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 18:21:55 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zeng", "Yuan", ""], ["Devincentis", "Kevin", ""], ["Xiao", "Yao", ""], ["Ferdous", "Zubayer Ibne", ""], ["Guo", "Xiaochen", ""], ["Yan", "Zhiyuan", ""], ["Berdichevsky", "Yevgeny", ""]]}, {"id": "1710.10967", "submitter": "Mitsuru Igami", "authors": "Mitsuru Igami", "title": "Artificial Intelligence as Structural Estimation: Economic\n  Interpretations of Deep Blue, Bonanza, and AlphaGo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has achieved superhuman performance in a growing\nnumber of tasks, but understanding and explaining AI remain challenging. This\npaper clarifies the connections between machine-learning algorithms to develop\nAIs and the econometrics of dynamic structural models through the case studies\nof three famous game AIs. Chess-playing Deep Blue is a calibrated value\nfunction, whereas shogi-playing Bonanza is an estimated value function via\nRust's (1987) nested fixed-point method. AlphaGo's \"supervised-learning policy\nnetwork\" is a deep neural network implementation of Hotz and Miller's (1993)\nconditional choice probability estimation; its \"reinforcement-learning value\nnetwork\" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional\nchoice simulation method. Relaxing these AIs' implicit econometric assumptions\nwould improve their structural interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 14:25:39 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 22:48:17 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 20:52:33 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Igami", "Mitsuru", ""]]}, {"id": "1710.11004", "submitter": "Akisato Kimura", "authors": "Masaya Hibino, Akisato Kimura, Takayoshi Yamashita, Yuji Yamauchi,\n  Hironobu Fujiyoshi", "title": "Denoising random forests", "comments": "20 pages, 10 figures, submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel type of random forests called a denoising random\nforests that are robust against noises contained in test samples. Such\nnoise-corrupted samples cause serious damage to the estimation performances of\nrandom forests, since unexpected child nodes are often selected and the leaf\nnodes that the input sample reaches are sometimes far from those for a clean\nsample. Our main idea for tackling this problem originates from a binary\nindicator vector that encodes a traversal path of a sample in the forest. Our\nproposed method effectively employs this vector by introducing denoising\nautoencoders into random forests. A denoising autoencoder can be trained with\nindicator vectors produced from clean and noisy input samples, and non-leaf\nnodes where incorrect decisions are made can be identified by comparing the\ninput and output of the trained denoising autoencoder. Multiple traversal paths\nwith respect to the nodes with incorrect decisions caused by the noises can\nthen be considered for the estimation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 15:16:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hibino", "Masaya", ""], ["Kimura", "Akisato", ""], ["Yamashita", "Takayoshi", ""], ["Yamauchi", "Yuji", ""], ["Fujiyoshi", "Hironobu", ""]]}, {"id": "1710.11029", "submitter": "Pratik Chaudhari", "authors": "Pratik Chaudhari, Stefano Soatto", "title": "Stochastic gradient descent performs variational inference, converges to\n  limit cycles for deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is widely believed to perform implicit\nregularization when used to train deep neural networks, but the precise manner\nin which this occurs has thus far been elusive. We prove that SGD minimizes an\naverage potential over the posterior distribution of weights along with an\nentropic regularization term. This potential is however not the original loss\nfunction in general. So SGD does perform variational inference, but for a\ndifferent loss than the one used to compute the gradients. Even more\nsurprisingly, SGD does not even converge in the classical sense: we show that\nthe most likely trajectories of SGD for deep networks do not behave like\nBrownian motion around critical points. Instead, they resemble closed loops\nwith deterministic components. We prove that such \"out-of-equilibrium\" behavior\nis a consequence of highly non-isotropic gradient noise in SGD; the covariance\nmatrix of mini-batch gradients for deep networks has a rank as small as 1% of\nits dimension. We provide extensive empirical validation of these claims,\nproven in the appendix.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 15:58:18 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 08:04:21 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Chaudhari", "Pratik", ""], ["Soatto", "Stefano", ""]]}, {"id": "1710.11041", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre, Kyunghyun Cho", "title": "Unsupervised Neural Machine Translation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the recent success of neural machine translation (NMT) in\nstandard benchmarks, the lack of large parallel corpora poses a major practical\nproblem for many language pairs. There have been several proposals to alleviate\nthis issue with, for instance, triangulation and semi-supervised learning\ntechniques, but they still require a strong cross-lingual signal. In this work,\nwe completely remove the need of parallel data and propose a novel method to\ntrain an NMT system in a completely unsupervised manner, relying on nothing but\nmonolingual corpora. Our model builds upon the recent work on unsupervised\nembedding mappings, and consists of a slightly modified attentional\nencoder-decoder model that can be trained on monolingual corpora alone using a\ncombination of denoising and backtranslation. Despite the simplicity of the\napproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014\nFrench-to-English and German-to-English translation. The model can also profit\nfrom small parallel corpora, and attains 21.81 and 15.24 points when combined\nwith 100,000 parallel sentences, respectively. Our implementation is released\nas an open source project.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 16:17:34 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:54:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1710.11052", "submitter": "Dmitrij Schlesinger", "authors": "Dmitrij Schlesinger", "title": "A Connection between Feed-Forward Neural Networks and Probabilistic\n  Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two of the most popular modelling paradigms in computer vision are\nfeed-forward neural networks (FFNs) and probabilistic graphical models (GMs).\nVarious connections between the two have been studied in recent works, such as\ne.g. expressing mean-field based inference in a GM as an FFN. This paper\nestablishes a new connection between FFNs and GMs. Our key observation is that\nany FFN implements a certain approximation of a corresponding Bayesian network\n(BN). We characterize various benefits of having this connection. In\nparticular, it results in a new learning algorithm for BNs. We validate the\nproposed methods for a classification problem on CIFAR-10 dataset and for\nbinary image segmentation on Weizmann Horse dataset. We show that statistically\nlearned BNs improve performance, having at the same time essentially better\ngeneralization capability, than their FFN counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 16:31:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Schlesinger", "Dmitrij", ""]]}, {"id": "1710.11070", "submitter": "Yining Wang", "authors": "Yining Wang", "title": "Convergence Rates of Latent Topic Models Under Relaxed Identifiability\n  Conditions", "comments": "26 pages, 1 table. Added significantly more expositions, and a\n  numerical procedure to check the order of degeneracy. Proofs slightly altered\n  with explicit constants given at various places", "journal-ref": "Electronic Journal of Statistics, 13(1):37-66, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the frequentist convergence rate for the Latent\nDirichlet Allocation (Blei et al., 2003) topic models. We show that the maximum\nlikelihood estimator converges to one of the finitely many equivalent\nparameters in Wasserstein's distance metric at a rate of $n^{-1/4}$ without\nassuming separability or non-degeneracy of the underlying topics and/or the\nexistence of more than three words per document, thus generalizing the previous\nworks of Anandkumar et al. (2012, 2014) from an information-theoretical\nperspective. We also show that the $n^{-1/4}$ convergence rate is optimal in\nthe worst case.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 17:05:28 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 21:35:57 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Wang", "Yining", ""]]}, {"id": "1710.11089", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado, Clemens Rosenbaum, Xiaoxiao Guo, Miao Liu, Gerald\n  Tesauro, Murray Campbell", "title": "Eigenoption Discovery through the Deep Successor Representation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Options in reinforcement learning allow agents to hierarchically decompose a\ntask into subtasks, having the potential to speed up learning and planning.\nHowever, autonomously learning effective sets of options is still a major\nchallenge in the field. In this paper we focus on the recently introduced idea\nof using representation learning methods to guide the option discovery process.\nSpecifically, we look at eigenoptions, options obtained from representations\nthat encode diffusive information flow in the environment. We extend the\nexisting algorithms for eigenoption discovery to settings with stochastic\ntransitions and in which handcrafted features are not available. We propose an\nalgorithm that discovers eigenoptions while learning non-linear state\nrepresentations from raw pixels. It exploits recent successes in the deep\nreinforcement learning literature and the equivalence between proto-value\nfunctions and the successor representation. We use traditional tabular domains\nto provide intuition about our approach and Atari 2600 games to demonstrate its\npotential.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 17:36:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 01:48:36 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 21:55:05 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Machado", "Marlos C.", ""], ["Rosenbaum", "Clemens", ""], ["Guo", "Xiaoxiao", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1710.11118", "submitter": "Chen Zheng", "authors": "Chen Zheng, Clara Grzegorz Kasprowicz, Carol Saunders", "title": "Customized Routing Optimization Based on Gradient Boost Regressor Model", "comments": "6 pages, 7 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discussed limitation of current\nelectronic-design-automoation (EDA) tool and proposed a machine learning\nframework to overcome the limitations and achieve better design quality. We\nexplored how to efficiently extract relevant features and leverage gradient\nboost regressor (GBR) model to predict underestimated risky net (URN).\nCustomized routing optimizations are applied to the URNs and results show clear\ntiming improvement and trend to converge toward timing closure.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 06:24:42 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Zheng", "Chen", ""], ["Kasprowicz", "Clara Grzegorz", ""], ["Saunders", "Carol", ""]]}, {"id": "1710.11122", "submitter": "William Falcon", "authors": "William Falcon, Henning Schulzrinne", "title": "Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone\n  Sensor Data", "comments": "International Conference on Learning Representations (ICLR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cities with tall buildings, emergency responders need an accurate floor\nlevel location to find 911 callers quickly. We introduce a system to estimate a\nvictim's floor level via their mobile device's sensor data in a two-step\nprocess. First, we train a neural network to determine when a smartphone enters\nor exits a building via GPS signal changes. Second, we use a barometer equipped\nsmartphone to measure the change in barometric pressure from the entrance of\nthe building to the victim's indoor location. Unlike impractical previous\napproaches, our system is the first that does not require the use of beacons,\nprior knowledge of the building infrastructure, or knowledge of user behavior.\nWe demonstrate real-world feasibility through 63 experiments across five\ndifferent tall buildings throughout New York City where our system predicted\nthe correct floor level with 100% accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 02:04:31 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 13:38:17 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 15:44:32 GMT"}, {"version": "v4", "created": "Sat, 15 Sep 2018 23:37:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Falcon", "William", ""], ["Schulzrinne", "Henning", ""]]}, {"id": "1710.11153", "submitter": "Curtis Hawthorne", "authors": "Curtis Hawthorne, Erich Elsen, Jialin Song, Adam Roberts, Ian Simon,\n  Colin Raffel, Jesse Engel, Sageev Oore, Douglas Eck", "title": "Onsets and Frames: Dual-Objective Piano Transcription", "comments": "Examples available at https://goo.gl/magenta/onsets-frames-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We advance the state of the art in polyphonic piano music transcription by\nusing a deep convolutional and recurrent neural network which is trained to\njointly predict onsets and frames. Our model predicts pitch onset events and\nthen uses those predictions to condition framewise pitch predictions. During\ninference, we restrict the predictions from the framewise detector by not\nallowing a new note to start unless the onset detector also agrees that an\nonset for that pitch is present in the frame. We focus on improving onsets and\noffsets together instead of either in isolation as we believe this correlates\nbetter with human musical perception. Our approach results in over a 100%\nrelative improvement in note F1 score (with offsets) on the MAPS dataset.\nFurthermore, we extend the model to predict relative velocities of normalized\naudio which results in more natural-sounding transcriptions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:05:49 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:20:28 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Hawthorne", "Curtis", ""], ["Elsen", "Erich", ""], ["Song", "Jialin", ""], ["Roberts", "Adam", ""], ["Simon", "Ian", ""], ["Raffel", "Colin", ""], ["Engel", "Jesse", ""], ["Oore", "Sageev", ""], ["Eck", "Douglas", ""]]}, {"id": "1710.11176", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Nishant Vishwamitra, Hongxin Hu, Feng Luo", "title": "CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new deep convolutional neural network, CrescendoNet, by\nstacking simple building blocks without residual connections. Each Crescendo\nblock contains independent convolution paths with increased depths. The numbers\nof convolution layers and parameters are only increased linearly in Crescendo\nblocks. In experiments, CrescendoNet with only 15 layers outperforms almost all\nnetworks without residual connections on benchmark datasets, CIFAR10, CIFAR100,\nand SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with\n15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250\nlayers and 15.3M parameters. CrescendoNet provides a new way to construct high\nperformance deep convolutional neural networks without residual connections.\nMoreover, through investigating the behavior and performance of subnetworks in\nCrescendoNet, we note that the high performance of CrescendoNet may come from\nits implicit ensemble behavior, which differs from the FractalNet that is also\na deep convolutional neural network without residual connections. Furthermore,\nthe independence between paths in CrescendoNet allows us to introduce a new\npath-wise training procedure, which can reduce the memory needed for training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:35:01 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 17:01:21 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Zhang", "Xiang", ""], ["Vishwamitra", "Nishant", ""], ["Hu", "Hongxin", ""], ["Luo", "Feng", ""]]}, {"id": "1710.11198", "submitter": "Yihao Feng", "authors": "Hao Liu, Yihao Feng, Yi Mao, Dengyong Zhou, Jian Peng, Qiang Liu", "title": "Action-depedent Control Variates for Policy Optimization via Stein's\n  Identity", "comments": "The first two authors contributed equally. Author ordering determined\n  by coin flip over a Google Hangout. Accepted by ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have achieved remarkable successes in solving\nchallenging reinforcement learning problems. However, it still often suffers\nfrom the large variance issue on policy gradient estimation, which leads to\npoor sample efficiency during training. In this work, we propose a control\nvariate method to effectively reduce variance for policy gradient methods.\nMotivated by the Stein's identity, our method extends the previous control\nvariate methods used in REINFORCE and advantage actor-critic by introducing\nmore general action-dependent baseline functions. Empirical studies show that\nour method significantly improves the sample efficiency of the state-of-the-art\npolicy gradient approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:03:48 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 21:33:17 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 04:06:07 GMT"}, {"version": "v4", "created": "Fri, 23 Feb 2018 07:10:10 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Liu", "Hao", ""], ["Feng", "Yihao", ""], ["Mao", "Yi", ""], ["Zhou", "Dengyong", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "1710.11205", "submitter": "Yi Zhou", "authors": "Yi Zhou and Yingbin Liang", "title": "Critical Points of Neural Networks: Analytical Forms and Landscape\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the success of deep learning to solving a variety of challenging\nmachine learning tasks, there is a rising interest in understanding loss\nfunctions for training neural networks from a theoretical aspect. Particularly,\nthe properties of critical points and the landscape around them are of\nimportance to determine the convergence performance of optimization algorithms.\nIn this paper, we provide full (necessary and sufficient) characterization of\nthe analytical forms for the critical points (as well as global minimizers) of\nthe square loss functions for various neural networks. We show that the\nanalytical forms of the critical points characterize the values of the\ncorresponding loss functions as well as the necessary and sufficient conditions\nto achieve global minimum. Furthermore, we exploit the analytical forms of the\ncritical points to characterize the landscape properties for the loss functions\nof these neural networks. One particular conclusion is that: The loss function\nof linear networks has no spurious local minimum, while the loss function of\none-hidden-layer nonlinear networks with ReLU activation function does have\nlocal minimum that is not global minimum.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:18:43 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1710.11214", "submitter": "Allison Chaney", "authors": "Allison J.B. Chaney, Brandon M. Stewart, Barbara E. Engelhardt", "title": "How Algorithmic Confounding in Recommendation Systems Increases\n  Homogeneity and Decreases Utility", "comments": null, "journal-ref": null, "doi": "10.1145/3240323.3240370", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are ubiquitous and impact many domains; they have the\npotential to influence product consumption, individuals' perceptions of the\nworld, and life-altering decisions. These systems are often evaluated or\ntrained with data from users already exposed to algorithmic recommendations;\nthis creates a pernicious feedback loop. Using simulations, we demonstrate how\nusing data confounded in this way homogenizes user behavior without increasing\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:42:02 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 01:58:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Chaney", "Allison J. B.", ""], ["Stewart", "Brandon M.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1710.11223", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang and Arshdeep Sekhon and Yanjun Qi", "title": "Fast and Scalable Learning of Sparse Changes in High-Dimensional\n  Gaussian Graphical Model Structure", "comments": "20pages, 6 figures, 10 tables; at AISTAT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of estimating the change in the dependency structures\nof two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for\nsparse change estimation in GGMs involve expensive and difficult non-smooth\noptimization. We propose a novel method, DIFFEE for estimating DIFFerential\nnetworks via an Elementary Estimator under a high-dimensional situation. DIFFEE\nis solved through a faster and closed form solution that enables it to work in\nlarge-scale settings. We conduct a rigorous statistical analysis showing that\nsurprisingly DIFFEE achieves the same asymptotic convergence rates as the\nstate-of-the-art estimators that are much more difficult to compute. Our\nexperimental results on multiple synthetic datasets and one real-world data\nabout brain connectivity show strong performance improvements over baselines,\nas well as significant computational benefits.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 20:15:20 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 16:14:25 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 17:57:26 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Wang", "Beilun", ""], ["Sekhon", "Arshdeep", ""], ["Qi", "Yanjun", ""]]}, {"id": "1710.11238", "submitter": "Yanjun  Qi Dr.", "authors": "Jack Lanchantin, Arshdeep Sekhon, Ritambhara Singh, Yanjun Qi", "title": "Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence\n  Classification", "comments": "15 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental tasks in understanding genomics is the problem of\npredicting Transcription Factor Binding Sites (TFBSs). With more than hundreds\nof Transcription Factors (TFs) as labels, genomic-sequence based TFBS\nprediction is a challenging multi-label classification task. There are two\nmajor biological mechanisms for TF binding: (1) sequence-specific binding\npatterns on genomes known as \"motifs\" and (2) interactions among TFs known as\nco-binding effects. In this paper, we propose a novel deep architecture, the\nPrototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN\nmodel automatically extracts prototypes (\"motif\"-like features) for each TF\nthrough a novel prototype-matching loss. Borrowing ideas from few-shot matching\nmodels, we use the notion of support set of prototypes and an LSTM to learn how\nTFs interact and bind to genomic sequences. On a reference TFBS dataset with\n$2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and\nvalidates our design choices empirically. To our knowledge, this is the first\ndeep learning architecture that introduces prototype learning and considers\nTF-TF interactions for large-scale TFBS prediction. Not only is the proposed\narchitecture accurate, but it also models the underlying biology.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:04:49 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 16:47:26 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Lanchantin", "Jack", ""], ["Sekhon", "Arshdeep", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1710.11239", "submitter": "Christoph Wehmeyer", "authors": "Christoph Wehmeyer and Frank No\\'e", "title": "Time-lagged autoencoders: Deep learning of slow collective variables for\n  molecular kinetics", "comments": null, "journal-ref": null, "doi": "10.1063/1.5011399", "report-no": null, "categories": "stat.ML cs.LG physics.bio-ph physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of deep learning techniques in the physical and\nchemical sciences, we apply a modification of an autoencoder type deep neural\nnetwork to the task of dimension reduction of molecular dynamics data. We can\nshow that our time-lagged autoencoder reliably finds low-dimensional embeddings\nfor high-dimensional feature spaces which capture the slow dynamics of the\nunderlying stochastic processes - beyond the capabilities of linear dimension\nreduction techniques.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:06:11 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wehmeyer", "Christoph", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1710.11241", "submitter": "Digvijay Boob", "authors": "Digvijay Boob and Guanghui Lan", "title": "Theoretical properties of the global optimizer of two layer neural\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of optimizing a two-layer artificial\nneural network that best fits a training dataset. We look at this problem in\nthe setting where the number of parameters is greater than the number of\nsampled points. We show that for a wide class of differentiable activation\nfunctions (this class involves \"almost\" all functions which are not piecewise\nlinear), we have that first-order optimal solutions satisfy global optimality\nprovided the hidden layer is non-singular. Our results are easily extended to\nhidden layers given by a flat matrix from that of a square matrix. Results are\napplicable even if network has more than one hidden layer provided all hidden\nlayers satisfy non-singularity, all activations are from the given \"good\" class\nof differentiable functions and optimization is only with respect to the last\nhidden layer. We also study the smoothness properties of the objective function\nand show that it is actually Lipschitz smooth, i.e., its gradients do not\nchange sharply. We use smoothness properties to guarantee asymptotic\nconvergence of O(1/number of iterations) to a first-order optimal solution. We\nalso show that our algorithm will maintain non-singularity of hidden layer for\nany finite number of iterations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:10:17 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Boob", "Digvijay", ""], ["Lan", "Guanghui", ""]]}, {"id": "1710.11248", "submitter": "Justin Fu", "authors": "Justin Fu, Katie Luo, Sergey Levine", "title": "Learning Robust Rewards with Adversarial Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides a powerful and general framework for decision\nmaking and control, but its application in practice is often hindered by the\nneed for extensive feature and reward engineering. Deep reinforcement learning\nmethods can remove the need for explicit engineering of policy or value\nfeatures, but still require a manually specified reward function. Inverse\nreinforcement learning holds the promise of automatic reward acquisition, but\nhas proven exceptionally difficult to apply to large, high-dimensional problems\nwith unknown dynamics. In this work, we propose adverserial inverse\nreinforcement learning (AIRL), a practical and scalable inverse reinforcement\nlearning algorithm based on an adversarial reward learning formulation. We\ndemonstrate that AIRL is able to recover reward functions that are robust to\nchanges in dynamics, enabling us to learn policies even under significant\nvariation in the environment seen during training. Our experiments show that\nAIRL greatly outperforms prior methods in these transfer settings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:22:28 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 18:33:24 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Fu", "Justin", ""], ["Luo", "Katie", ""], ["Levine", "Sergey", ""]]}, {"id": "1710.11253", "submitter": "Pavel Kolev", "authors": "Karl Bringmann, Pavel Kolev, David P. Woodruff", "title": "Approximation Algorithms for $\\ell_0$-Low Rank Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $\\ell_0$-Low Rank Approximation Problem, where the goal is,\ngiven an $m \\times n$ matrix $A$, to output a rank-$k$ matrix $A'$ for which\n$\\|A'-A\\|_0$ is minimized. Here, for a matrix $B$, $\\|B\\|_0$ denotes the number\nof its non-zero entries. This NP-hard variant of low rank approximation is\nnatural for problems with no underlying metric, and its goal is to minimize the\nnumber of disagreeing data positions. We provide approximation algorithms which\nsignificantly improve the running time and approximation factor of previous\nwork. For $k > 1$, we show how to find, in poly$(mn)$ time for every $k$, a\nrank $O(k \\log(n/k))$ matrix $A'$ for which $\\|A'-A\\|_0 \\leq O(k^2 \\log(n/k))\n\\mathrm{OPT}$. To the best of our knowledge, this is the first algorithm with\nprovable guarantees for the $\\ell_0$-Low Rank Approximation Problem for $k >\n1$, even for bicriteria algorithms. For the well-studied case when $k = 1$, we\ngive a $(2+\\epsilon)$-approximation in {\\it sublinear time}, which is\nimpossible for other variants of low rank approximation such as for the\nFrobenius norm. We strengthen this for the well-studied case of binary matrices\nto obtain a $(1+O(\\psi))$-approximation in sublinear time, where $\\psi =\n\\mathrm{OPT}/\\lVert A\\rVert_0$. For small $\\psi$, our approximation factor is\n$1+o(1)$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:49:48 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 15:06:01 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bringmann", "Karl", ""], ["Kolev", "Pavel", ""], ["Woodruff", "David P.", ""]]}, {"id": "1710.11272", "submitter": "Giovanni Alcantara", "authors": "Giovanni Alcantara", "title": "Empirical analysis of non-linear activation functions for Deep Neural\n  Networks in classification tasks", "comments": "7 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of several non-linear activation functions in a neural\nnetwork architecture that have proven successful in many machine learning\napplications. We conduct an empirical analysis on the effectiveness of using\nthese function on the MNIST classification task, with the aim of clarifying\nwhich functions produce the best results overall. Based on this first set of\nresults, we examine the effects of building deeper architectures with an\nincreasing number of hidden layers. We also survey the impact of using, on the\nsame task, different initialisation schemes for the weights of our neural\nnetwork. Using these sets of experiments as a base, we conclude by providing a\noptimal neural network architecture that yields impressive results in accuracy\non the MNIST classification task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 23:45:57 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Alcantara", "Giovanni", ""]]}, {"id": "1710.11277", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Yun-Nung Chen and Kam-Fai Wong", "title": "Adversarial Advantage Actor-Critic Model for Task-Completion Dialogue\n  Policy Learning", "comments": "5 pages, 3 figures, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method --- adversarial advantage actor-critic\n(Adversarial A2C), which significantly improves the efficiency of dialogue\npolicy learning in task-completion dialogue systems. Inspired by generative\nadversarial networks (GAN), we train a discriminator to differentiate\nresponses/actions generated by dialogue agents from responses/actions by\nexperts. Then, we incorporate the discriminator as another critic into the\nadvantage actor-critic (A2C) framework, to encourage the dialogue agent to\nexplore state-action within the regions where the agent takes actions similar\nto those of the experts. Experimental results in a movie-ticket booking domain\nshow that the proposed Adversarial A2C can accelerate policy exploration\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:25:03 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 18:41:05 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Chen", "Yun-Nung", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "1710.11278", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mark Sellke", "title": "Approximating Continuous Functions by ReLU Nets of Minimal Width", "comments": "v2. 13p. Extended main result to higher dimensional output. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the expressive power of depth in deep feed-forward\nneural nets with ReLU activations. Specifically, we answer the following\nquestion: for a fixed $d_{in}\\geq 1,$ what is the minimal width $w$ so that\nneural nets with ReLU activations, input dimension $d_{in}$, hidden layer\nwidths at most $w,$ and arbitrary depth can approximate any continuous,\nreal-valued function of $d_{in}$ variables arbitrarily well? It turns out that\nthis minimal width is exactly equal to $d_{in}+1.$ That is, if all the hidden\nlayer widths are bounded by $d_{in}$, then even in the infinite depth limit,\nReLU nets can only express a very limited class of functions, and, on the other\nhand, any continuous function on the $d_{in}$-dimensional unit cube can be\napproximated to arbitrary precision by ReLU nets in which all hidden layers\nhave width exactly $d_{in}+1.$ Our construction in fact shows that any\ncontinuous function $f:[0,1]^{d_{in}}\\to\\mathbb R^{d_{out}}$ can be\napproximated by a net of width $d_{in}+d_{out}$. We obtain quantitative depth\nestimates for such an approximation in terms of the modulus of continuity of\n$f$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:26:56 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 21:47:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Hanin", "Boris", ""], ["Sellke", "Mark", ""]]}, {"id": "1710.11303", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Frank Stephan", "title": "Algorithmic learning of probability distributions from random data in\n  the limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying a probability distribution for some given\nrandomly sampled data in the limit, in the context of algorithmic learning\ntheory as proposed recently by Vinanyi and Chater. We show that there exists a\ncomputable partial learner for the computable probability measures, while by\nBienvenu, Monin and Shen it is known that there is no computable learner for\nthe computable probability measures. Our main result is the characterization of\nthe oracles that compute explanatory learners for the computable (continuous)\nprobability measures as the high oracles. This provides an analogue of a\nwell-known result of Adleman and Blum in the context of learning computable\nprobability distributions. We also discuss related learning notions such as\nbehaviorally correct learning and orther variations of explanatory learning, in\nthe context of learning probability distributions from data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 02:35:04 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 10:17:12 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 05:35:10 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Barmpalias", "George", ""], ["Stephan", "Frank", ""]]}, {"id": "1710.11306", "submitter": "Panos P. Markopoulos", "authors": "Panos P. Markopoulos, Dimitris G. Chachlakis, and Evangelos E.\n  Papalexakis", "title": "The Exact Solution to Rank-1 L1-norm TUCKER2 Decomposition", "comments": "This is a preprint; An edited/finalized version of this manuscript\n  has been submitted for publication to IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2018.2790901", "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rank-1 {L1-norm-based TUCKER2} (L1-TUCKER2) decomposition of 3-way\ntensors, treated as a collection of $N$ $D \\times M$ matrices that are to be\njointly decomposed. Our contributions are as follows. i) We prove that the\nproblem is equivalent to combinatorial optimization over $N$ antipodal-binary\nvariables. ii) We derive the first two algorithms in the literature for its\nexact solution. The first algorithm has cost exponential in $N$; the second one\nhas cost polynomial in $N$ (under a mild assumption). Our algorithms are\naccompanied by formal complexity analysis. iii) We conduct numerical studies to\ncompare the performance of exact L1-TUCKER2 (proposed) with standard HOSVD,\nHOOI, GLRAM, PCA, L1-PCA, and TPCA-L1. Our studies show that L1-TUCKER2\noutperforms (in tensor approximation) all the above counterparts when the\nprocessed data are outlier corrupted.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 03:01:35 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Markopoulos", "Panos P.", ""], ["Chachlakis", "Dimitris G.", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1710.11311", "submitter": "Alexander Lambert", "authors": "Alexander Lambert, Amirreza Shaban, Amit Raj, Zhen Liu and Byron Boots", "title": "Deep Forward and Inverse Perceptual Models for Tracking and Prediction", "comments": "8 pages, International Conference on Robotics and Automation (ICRA)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of learning forward models that map state to\nhigh-dimensional images and inverse models that map high-dimensional images to\nstate in robotics. Specifically, we present a perceptual model for generating\nvideo frames from state with deep networks, and provide a framework for its use\nin tracking and prediction tasks. We show that our proposed model greatly\noutperforms standard deconvolutional methods and GANs for image generation,\nproducing clear, photo-realistic images. We also develop a convolutional neural\nnetwork model for state estimation and compare the result to an Extended Kalman\nFilter to estimate robot trajectories. We validate all models on a real robotic\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 03:35:03 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 02:30:14 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Lambert", "Alexander", ""], ["Shaban", "Amirreza", ""], ["Raj", "Amit", ""], ["Liu", "Zhen", ""], ["Boots", "Byron", ""]]}, {"id": "1710.11324", "submitter": "Junghyo Jo", "authors": "Juyong Song, Matteo Marsili, Junghyo Jo", "title": "Resolution and Relevance Trade-offs in Deep Learning", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been successfully applied to various tasks, but its\nunderlying mechanism remains unclear. Neural networks associate similar inputs\nin the visible layer to the same state of hidden variables in deep layers. The\nfraction of inputs that are associated to the same state is a natural measure\nof similarity and is simply related to the cost in bits required to represent\nthese inputs. The degeneracy of states with the same information cost provides\ninstead a natural measure of noise and is simply related the entropy of the\nfrequency of states, that we call relevance. Representations with minimal\nnoise, at a given level of similarity (resolution), are those that maximise the\nrelevance. A signature of such efficient representations is that frequency\ndistributions follow power laws. We show, in extensive numerical experiments,\nthat deep neural networks extract a hierarchy of efficient representations from\ndata, because they i) achieve low levels of noise (i.e. high relevance) and ii)\nexhibit power law distributions. We also find that the layer that is most\nefficient to reliably generate patterns of training data is the one for which\nrelevance and resolution are traded at the same price, which implies that\nfrequency distribution follows Zipf's law.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 04:33:56 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 01:23:24 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Song", "Juyong", ""], ["Marsili", "Matteo", ""], ["Jo", "Junghyo", ""]]}, {"id": "1710.11342", "submitter": "Zhengli Zhao", "authors": "Zhengli Zhao, Dheeru Dua, Sameer Singh", "title": "Generating Natural Adversarial Examples", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their complex nature, it is hard to characterize the ways in which\nmachine learning models can misbehave or be exploited when deployed. Recent\nwork on adversarial examples, i.e. inputs with minor perturbations that result\nin substantially different model predictions, is helpful in evaluating the\nrobustness of these models by exposing the adversarial scenarios where they\nfail. However, these malicious perturbations are often unnatural, not\nsemantically meaningful, and not applicable to complicated domains such as\nlanguage. In this paper, we propose a framework to generate natural and legible\nadversarial examples that lie on the data manifold, by searching in semantic\nspace of dense and continuous data representation, utilizing the recent\nadvances in generative adversarial networks. We present generated adversaries\nto demonstrate the potential of the proposed approach for black-box classifiers\nfor a wide range of applications such as image classification, textual\nentailment, and machine translation. We include experiments to show that the\ngenerated adversaries are natural, legible to humans, and useful in evaluating\nand analyzing black-box classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 06:22:26 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 23:28:31 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhao", "Zhengli", ""], ["Dua", "Dheeru", ""], ["Singh", "Sameer", ""]]}, {"id": "1710.11345", "submitter": "Rose Yu", "authors": "Rose Yu, Guangyu Li, Yan Liu", "title": "Tensor Regression Meets Gaussian Processes", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor regression, a new model class that learns high-order\ncorrelation from data, has recently received considerable attention. At the\nsame time, Gaussian processes (GP) are well-studied machine learning models for\nstructure learning. In this paper, we demonstrate interesting connections\nbetween the two, especially for multi-way data analysis. We show that low-rank\ntensor regression is essentially learning a multi-linear kernel in Gaussian\nprocesses, and the low-rank assumption translates to the constrained Bayesian\ninference problem. We prove the oracle inequality and derive the average case\nlearning curve for the equivalent GP model. Our finding implies that low-rank\ntensor regression, though empirically successful, is highly dependent on the\neigenvalues of covariance functions as well as variable correlations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 06:44:59 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Yu", "Rose", ""], ["Li", "Guangyu", ""], ["Liu", "Yan", ""]]}, {"id": "1710.11351", "submitter": "Keisuke Fukuda", "authors": "Takuya Akiba and Keisuke Fukuda and Shuji Suzuki", "title": "ChainerMN: Scalable Distributed Deep Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the keys for deep learning to have made a breakthrough in various\nfields was to utilize high computing powers centering around GPUs. Enabling the\nuse of further computing abilities by distributed processing is essential not\nonly to make the deep learning bigger and faster but also to tackle unsolved\nchallenges. We present the design, implementation, and evaluation of ChainerMN,\nthe distributed deep learning framework we have developed. We demonstrate that\nChainerMN can scale the learning process of the ResNet-50 model to the ImageNet\ndataset up to 128 GPUs with the parallel efficiency of 90%.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 07:13:29 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Akiba", "Takuya", ""], ["Fukuda", "Keisuke", ""], ["Suzuki", "Shuji", ""]]}, {"id": "1710.11381", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Aurelien Lucchi, Thomas Hofmann", "title": "Semantic Interpolation in Implicit Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In implicit models, one often interpolates between sampled points in latent\nspace. As we show in this paper, care needs to be taken to match-up the\ndistributional assumptions on code vectors with the geometry of the\ninterpolating paths. Otherwise, typical assumptions about the quality and\nsemantics of in-between points may not be justified. Based on our analysis we\npropose to modify the prior code distribution to put significantly more\nprobability mass closer to the origin. As a result, linear interpolation paths\nare not only shortest paths, but they are also guaranteed to pass through\nhigh-density regions, irrespective of the dimensionality of the latent space.\nExperiments on standard benchmark image datasets demonstrate clear visual\nimprovements in the quality of the generated samples and exhibit more\nmeaningful interpolation paths.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:11:17 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 08:56:11 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 09:56:08 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Kilcher", "Yannic", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11383", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Aurelien Lucchi, Thomas Hofmann", "title": "Flexible Prior Distributions for Deep Generative Models", "comments": "arXiv admin note: text overlap with arXiv:1707.09241", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training generative models with deep neural\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\ndominant paradigm combines simple priors over codes with complex deterministic\nmodels, we argue that it might be advantageous to use more flexible code\ndistributions. We demonstrate how these distributions can be induced directly\nfrom the data. The benefits include: more powerful generative models, better\nmodeling of latent structure and explicit control of the degree of\ngeneralization.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:16:09 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 09:13:41 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Kilcher", "Yannic", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11386", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Gary Becigneul, Thomas Hofmann", "title": "Parametrizing filters of a CNN with a GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly agreed that the use of relevant invariances as a good\nstatistical bias is important in machine-learning. However, most approaches\nthat explicitly incorporate invariances into a model architecture only make use\nof very simple transformations, such as translations and rotations. Hence,\nthere is a need for methods to model and extract richer transformations that\ncapture much higher-level invariances. To that end, we introduce a tool\nallowing to parametrize the set of filters of a trained convolutional neural\nnetwork with the latent space of a generative adversarial network. We then show\nthat the method can capture highly non-linear invariances of the data by\nvisualizing their effect in the data space.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:24:39 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Kilcher", "Yannic", ""], ["Becigneul", "Gary", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11417", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Tim Rockt\\\"aschel, Maximilian Igl, Shimon Whiteson", "title": "TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 11:54:35 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 17:30:48 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Farquhar", "Gregory", ""], ["Rockt\u00e4schel", "Tim", ""], ["Igl", "Maximilian", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1710.11424", "submitter": "Peter Jin", "authors": "Peter Jin, Kurt Keutzer, Sergey Levine", "title": "Regret Minimization for Partially Observable Deep Reinforcement Learning", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning algorithms that estimate state and state-action\nvalue functions have been shown to be effective in a variety of challenging\ndomains, including learning control strategies from raw image pixels. However,\nalgorithms that estimate state and state-action value functions typically\nassume a fully observed state and must compensate for partial observations by\nusing finite length observation histories or recurrent networks. In this work,\nwe propose a new deep reinforcement learning algorithm based on counterfactual\nregret minimization that iteratively updates an approximation to an\nadvantage-like function and is robust to partially observed state. We\ndemonstrate that this new algorithm can substantially outperform strong\nbaseline methods on several partially observed reinforcement learning tasks:\nlearning first-person 3D navigation in Doom and Minecraft, and acting in the\npresence of partially observed objects in Doom and Pong.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:15:38 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 00:58:42 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Jin", "Peter", ""], ["Keutzer", "Kurt", ""], ["Levine", "Sergey", ""]]}, {"id": "1710.11428", "submitter": "Zhe Cheng Fan", "authors": "Zhe-Cheng Fan, Yen-Lin Lai, Jyh-Shing Roger Jang", "title": "SVSGAN: Singing Voice Separation via Generative Adversarial Network", "comments": "5 pages, 4 figures, 1 table. Demo website:\n  http://mirlab.org/demo/svsgan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating two sources from an audio mixture is an important task with many\napplications. It is a challenging problem since only one signal channel is\navailable for analysis. In this paper, we propose a novel framework for singing\nvoice separation using the generative adversarial network (GAN) with a\ntime-frequency masking function. The mixture spectra is considered to be a\ndistribution and is mapped to the clean spectra which is also considered a\ndistribtution. The approximation of distributions between mixture spectra and\nclean spectra is performed during the adversarial training process. In contrast\nwith current deep learning approaches for source separation, the parameters of\nthe proposed framework are first initialized in a supervised setting and then\noptimized by the training procedure of GAN in an unsupervised setting.\nExperimental results on three datasets (MIR-1K, iKala and DSD100) show that\nperformance can be improved by the proposed framework consisting of\nconventional networks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:19:23 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 13:29:58 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Fan", "Zhe-Cheng", ""], ["Lai", "Yen-Lin", ""], ["Jang", "Jyh-Shing Roger", ""]]}, {"id": "1710.11431", "submitter": "Anuj Karpatne", "authors": "Anuj Karpatne, William Watkins, Jordan Read, and Vipin Kumar", "title": "Physics-guided Neural Networks (PGNN): An Application in Lake\n  Temperature Modeling", "comments": "submitted to ACM SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel framework for combining scientific knowledge of\nphysics-based models with neural networks to advance scientific discovery. This\nframework, termed as physics-guided neural network (PGNN), leverages the output\nof physics-based model simulations along with observational features to\ngenerate predictions using a neural network architecture. Further, this paper\npresents a novel framework for using physics-based loss functions in the\nlearning objective of neural networks, to ensure that the model predictions not\nonly show lower errors on the training set but are also scientifically\nconsistent with the known physics on the unlabeled set. We illustrate the\neffectiveness of PGNN for the problem of lake temperature modeling, where\nphysical relationships between the temperature, density, and depth of water are\nused to design a physics-based loss function. By using scientific knowledge to\nguide the construction and learning of neural networks, we are able to show\nthat the proposed framework ensures better generalizability as well as\nscientific consistency of results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:24:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 17:33:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Karpatne", "Anuj", ""], ["Watkins", "William", ""], ["Read", "Jordan", ""], ["Kumar", "Vipin", ""]]}, {"id": "1710.11438", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (PARIETAL, NEUROSPIN), Julien Mairal (Thoth, LJK),\n  Danilo Bzdok, Bertrand Thirion (PARIETAL, NEUROSPIN), Ga\\\"el Varoquaux\n  (PARIETAL, NEUROSPIN)", "title": "Learning Neural Representations of Human Cognition across Many fMRI\n  Studies", "comments": "Advances in Neural Information Processing Systems, Dec 2017, Long\n  Beach, United States. 2017", "journal-ref": "Advances in Neural Information Processing Systems, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive neuroscience is enjoying rapid increase in extensive public\nbrain-imaging datasets. It opens the door to large-scale statistical models.\nFinding a unified perspective for all available data calls for scalable and\nautomated solutions to an old challenge: how to aggregate heterogeneous\ninformation on brain function into a universal cognitive system that relates\nmental operations/cognitive processes/psychological tasks to brain networks? We\ncast this challenge in a machine-learning approach to predict conditions from\nstatistical brain maps across different studies. For this, we leverage\nmulti-task learning and multi-scale dimension reduction to learn\nlow-dimensional representations of brain images that carry cognitive\ninformation and can be robustly associated with psychological stimuli. Our\nmulti-dataset classification model achieves the best prediction performance on\nseveral large reference datasets, compared to models without cognitive-aware\nlow-dimension representations, it brings a substantial performance boost to the\nanalysis of small datasets, and can be introspected to identify universal\ntemplate cognitive concepts.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:51:36 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 03:16:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mensch", "Arthur", "", "PARIETAL, NEUROSPIN"], ["Mairal", "Julien", "", "Thoth, LJK"], ["Bzdok", "Danilo", "", "PARIETAL, NEUROSPIN"], ["Thirion", "Bertrand", "", "PARIETAL, NEUROSPIN"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, NEUROSPIN"]]}, {"id": "1710.11439", "submitter": "Yoshiaki Bando", "authors": "Yoshiaki Bando, Masato Mimura, Katsutoshi Itoyama, Kazuyoshi Yoshii,\n  Tatsuya Kawahara", "title": "Statistical Speech Enhancement Based on Probabilistic Integration of\n  Variational Autoencoder and Non-Negative Matrix Factorization", "comments": "5 pages, 3 figures, version that Eqs. (9), (19), and (20) in v2\n  (submitted to ICASSP 2018) are corrected. Samples available here:\n  http://sap.ist.i.kyoto-u.ac.jp/members/yoshiaki/demo/vae-nmf/", "journal-ref": null, "doi": "10.1109/ICASSP.2018.8461530", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a statistical method of single-channel speech enhancement\nthat uses a variational autoencoder (VAE) as a prior distribution on clean\nspeech. A standard approach to speech enhancement is to train a deep neural\nnetwork (DNN) to take noisy speech as input and output clean speech. Although\nthis supervised approach requires a very large amount of pair data for\ntraining, it is not robust against unknown environments. Another approach is to\nuse non-negative matrix factorization (NMF) based on basis spectra trained on\nclean speech in advance and those adapted to noise on the fly. This\nsemi-supervised approach, however, causes considerable signal distortion in\nenhanced speech due to the unrealistic assumption that speech spectrograms are\nlinear combinations of the basis spectra. Replacing the poor linear generative\nmodel of clean speech in NMF with a VAE---a powerful nonlinear deep generative\nmodel---trained on clean speech, we formulate a unified probabilistic\ngenerative model of noisy speech. Given noisy speech as observed data, we can\nsample clean speech from its posterior distribution. The proposed method\noutperformed the conventional DNN-based method in unseen noisy environments.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:52:09 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 04:58:48 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 11:57:51 GMT"}, {"version": "v4", "created": "Mon, 19 Mar 2018 07:04:46 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Bando", "Yoshiaki", ""], ["Mimura", "Masato", ""], ["Itoyama", "Katsutoshi", ""], ["Yoshii", "Kazuyoshi", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1710.11469", "submitter": "Christina Heinze-Deml", "authors": "Christina Heinze-Deml and Nicolai Meinshausen", "title": "Conditional Variance Penalties and Domain Shift Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a deep neural network for image classification, one can broadly\ndistinguish between two types of latent features of images that will drive the\nclassification. We can divide latent features into (i) \"core\" or \"conditionally\ninvariant\" features $X^\\text{core}$ whose distribution $X^\\text{core}\\vert Y$,\nconditional on the class $Y$, does not change substantially across domains and\n(ii) \"style\" features $X^{\\text{style}}$ whose distribution $X^{\\text{style}}\n\\vert Y$ can change substantially across domains. Examples for style features\ninclude position, rotation, image quality or brightness but also more complex\nones like hair color, image quality or posture for images of persons. Our goal\nis to minimize a loss that is robust under changes in the distribution of these\nstyle features. In contrast to previous work, we assume that the domain itself\nis not observed and hence a latent variable.\n  We do assume that we can sometimes observe a typically discrete identifier or\n\"$\\mathrm{ID}$ variable\". In some applications we know, for example, that two\nimages show the same person, and $\\mathrm{ID}$ then refers to the identity of\nthe person. The proposed method requires only a small fraction of images to\nhave $\\mathrm{ID}$ information. We group observations if they share the same\nclass and identifier $(Y,\\mathrm{ID})=(y,\\mathrm{id})$ and penalize the\nconditional variance of the prediction or the loss if we condition on\n$(Y,\\mathrm{ID})$. Using a causal framework, this conditional variance\nregularization (CoRe) is shown to protect asymptotically against shifts in the\ndistribution of the style variables. Empirically, we show that the CoRe penalty\nimproves predictive accuracy substantially in settings where domain changes\noccur in terms of image quality, brightness and color while we also look at\nmore complex changes such as changes in movement and posture.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 13:52:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 13:30:15 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 20:43:04 GMT"}, {"version": "v4", "created": "Tue, 8 May 2018 11:37:22 GMT"}, {"version": "v5", "created": "Sat, 13 Apr 2019 12:39:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1710.11473", "submitter": "Emad Grais", "authors": "Emad M. Grais, Hagen Wierstorf, Dominic Ward, Mark D. Plumbley", "title": "Multi-Resolution Fully Convolutional Neural Networks for Monaural Audio\n  Source Separation", "comments": "arXiv admin note: text overlap with arXiv:1703.08019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural networks with convolutional layers, each layer typically has\nfixed-size/single-resolution receptive field (RF). Convolutional layers with a\nlarge RF capture global information from the input features, while layers with\nsmall RF size capture local details with high resolution from the input\nfeatures. In this work, we introduce novel deep multi-resolution fully\nconvolutional neural networks (MR-FCNN), where each layer has different RF\nsizes to extract multi-resolution features that capture the global and local\ndetails information from its input features. The proposed MR-FCNN is applied to\nseparate a target audio source from a mixture of many audio sources.\nExperimental results show that using MR-FCNN improves the performance compared\nto feedforward deep neural networks (DNNs) and single resolution deep fully\nconvolutional neural networks (FCNNs) on the audio source separation problem.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 22:12:08 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Grais", "Emad M.", ""], ["Wierstorf", "Hagen", ""], ["Ward", "Dominic", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1710.11478", "submitter": "Andri Mirzal", "authors": "Andri Mirzal", "title": "A Convergent Algorithm for Bi-orthogonal Nonnegative Matrix\n  Tri-Factorization", "comments": "arXiv admin note: substantial text overlap with arXiv:1010.5290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A convergent algorithm for nonnegative matrix factorization with\northogonality constraints imposed on both factors is proposed in this paper.\nThis factorization concept was first introduced by Ding et al. with intent to\nfurther improve clustering capability of NMF. However, as the original\nalgorithm was developed based on multiplicative update rules, the convergence\nof the algorithm cannot be guaranteed. In this paper, we utilize the technique\npresented in our previous work to develop the algorithm and prove that it\nconverges to a stationary point inside the solution space.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 12:26:14 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 08:29:21 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Mirzal", "Andri", ""]]}, {"id": "1710.11547", "submitter": "Natalia Ponomareva", "authors": "Natalia Ponomareva, Thomas Colthurst, Gilbert Hendry, Salem Haykal,\n  Soroush Radpour", "title": "Compact Multi-Class Boosted Trees", "comments": "Accepted for publication in IEEE Big Data 2017\n  http://cci.drexel.edu/bigdata/bigdata2017/AcceptedPapers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted decision trees are a popular machine learning technique, in\npart because of their ability to give good accuracy with small models. We\ndescribe two extensions to the standard tree boosting algorithm designed to\nincrease this advantage. The first improvement extends the boosting formalism\nfrom scalar-valued trees to vector-valued trees. This allows individual trees\nto be used as multiclass classifiers, rather than requiring one tree per class,\nand drastically reduces the model size required for multiclass problems. We\nalso show that some other popular vector-valued gradient boosted trees\nmodifications fit into this formulation and can be easily obtained in our\nimplementation. The second extension, layer-by-layer boosting, takes smaller\nsteps in function space, which is empirically shown to lead to a faster\nconvergence and to a more compact ensemble. We have added both improvements to\nthe open-source TensorFlow Boosted trees (TFBT) package, and we demonstrate\ntheir efficacy on a variety of multiclass datasets. We expect these extensions\nwill be of particular interest to boosted tree applications that require small\nmodels, such as embedded devices, applications requiring fast inference, or\napplications desiring more interpretable models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:02:00 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Ponomareva", "Natalia", ""], ["Colthurst", "Thomas", ""], ["Hendry", "Gilbert", ""], ["Haykal", "Salem", ""], ["Radpour", "Soroush", ""]]}, {"id": "1710.11555", "submitter": "Natalia Ponomareva", "authors": "Natalia Ponomareva, Soroush Radpour, Gilbert Hendry, Salem Haykal,\n  Thomas Colthurst, Petr Mitrichev, Alexander Grushetsky", "title": "TF Boosted Trees: A scalable TensorFlow based framework for gradient\n  boosting", "comments": "European Conference on Machine Learning and Principles and Practice\n  of Knowledge Discovery in Databases (ECML PKDD 2017). The final publication\n  will be available at link.springer.com and is available on ECML website\n  http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TF Boosted Trees (TFBT) is a new open-sourced frame-work for the distributed\ntraining of gradient boosted trees. It is based on TensorFlow, and its\ndistinguishing features include a novel architecture, automatic loss\ndifferentiation, layer-by-layer boosting that results in smaller ensembles and\nfaster prediction, principled multi-class handling, and a number of\nregularization techniques to prevent overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:12:27 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Ponomareva", "Natalia", ""], ["Radpour", "Soroush", ""], ["Hendry", "Gilbert", ""], ["Haykal", "Salem", ""], ["Colthurst", "Thomas", ""], ["Mitrichev", "Petr", ""], ["Grushetsky", "Alexander", ""]]}, {"id": "1710.11573", "submitter": "Abram Friesen", "authors": "Abram L. Friesen and Pedro Domingos", "title": "Deep Learning as a Mixed Convex-Combinatorial Optimization Problem", "comments": "14 pages (9 body, 5 pages of references and appendices)", "journal-ref": "In Proceedings of the International Conference on Learning\n  Representations (ICLR) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks grow deeper and wider, learning networks with\nhard-threshold activations is becoming increasingly important, both for network\nquantization, which can drastically reduce time and energy requirements, and\nfor creating large integrated systems of deep networks, which may have\nnon-differentiable components and must avoid vanishing and exploding gradients\nfor effective learning. However, since gradient descent is not applicable to\nhard-threshold functions, it is not clear how to learn networks of them in a\nprincipled way. We address this problem by observing that setting targets for\nhard-threshold hidden units in order to minimize loss is a discrete\noptimization problem, and can be solved as such. The discrete optimization goal\nis to find a set of targets such that each unit, including the output, has a\nlinearly separable problem to solve. Given these targets, the network\ndecomposes into individual perceptrons, which can then be learned with standard\nconvex approaches. Based on this, we develop a recursive mini-batch algorithm\nfor learning deep hard-threshold networks that includes the popular but poorly\njustified straight-through estimator as a special case. Empirically, we show\nthat our algorithm improves classification accuracy in a number of settings,\nincluding for AlexNet and ResNet-18 on ImageNet, when compared to the\nstraight-through estimator.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:42:44 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 17:58:16 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 20:46:14 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Friesen", "Abram L.", ""], ["Domingos", "Pedro", ""]]}, {"id": "1710.11577", "submitter": "Guokun Lai", "authors": "Guokun Lai, Hanxiao Liu, Yiming Yang", "title": "Learning Depthwise Separable Graph Convolution from Data Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Network (CNN) has gained tremendous success in computer\nvision tasks with its outstanding ability to capture the local latent features.\nRecently, there has been an increasing interest in extending convolution\noperations to the non-Euclidean geometry. Although various types of convolution\noperations have been proposed for graphs or manifolds, their connections with\ntraditional convolution over grid-structured data are not well-understood. In\nthis paper, we show that depthwise separable convolution can be successfully\ngeneralized for the unification of both graph-based and grid-based convolution\nmethods. Based on this insight we propose a novel Depthwise Separable Graph\nConvolution (DSGC) approach which is compatible with the tradition convolution\nnetwork and subsumes existing convolution methods as special cases. It is\nequipped with the combined strengths in model expressiveness, compatibility\n(relatively small number of parameters), modularity and computational\nefficiency in training. Extensive experiments show the outstanding performance\nof DSGC in comparison with strong baselines on multi-domain benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:48:12 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:32:25 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 05:58:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Lai", "Guokun", ""], ["Liu", "Hanxiao", ""], ["Yang", "Yiming", ""]]}, {"id": "1710.11592", "submitter": "Aravindan Vijayaraghavan", "authors": "Oded Regev and Aravindan Vijayaraghavan", "title": "On Learning Mixtures of Well-Separated Gaussians", "comments": "Appeared in FOCS 2017. 55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficiently learning mixtures of a large number of\nspherical Gaussians, when the components of the mixture are well separated. In\nthe most basic form of this problem, we are given samples from a uniform\nmixture of $k$ standard spherical Gaussians, and the goal is to estimate the\nmeans up to accuracy $\\delta$ using $poly(k,d, 1/\\delta)$ samples.\n  In this work, we study the following question: what is the minimum separation\nneeded between the means for solving this task? The best known algorithm due to\nVempala and Wang [JCSS 2004] requires a separation of roughly\n$\\min\\{k,d\\}^{1/4}$. On the other hand, Moitra and Valiant [FOCS 2010] showed\nthat with separation $o(1)$, exponentially many samples are required. We\naddress the significant gap between these two bounds, by showing the following\nresults.\n  1. We show that with separation $o(\\sqrt{\\log k})$, super-polynomially many\nsamples are required. In fact, this holds even when the $k$ means of the\nGaussians are picked at random in $d=O(\\log k)$ dimensions.\n  2. We show that with separation $\\Omega(\\sqrt{\\log k})$, $poly(k,d,1/\\delta)$\nsamples suffice. Note that the bound on the separation is independent of\n$\\delta$. This result is based on a new and efficient \"accuracy boosting\"\nalgorithm that takes as input coarse estimates of the true means and in time\n$poly(k,d, 1/\\delta)$ outputs estimates of the means up to arbitrary accuracy\n$\\delta$ assuming the separation between the means is $\\Omega(\\min\\{\\sqrt{\\log\nk},\\sqrt{d}\\})$ (independently of $\\delta$).\n  We also present a computationally efficient algorithm in $d=O(1)$ dimensions\nwith only $\\Omega(\\sqrt{d})$ separation. These results together essentially\ncharacterize the optimal order of separation between components that is needed\nto learn a mixture of $k$ spherical Gaussians with polynomial samples.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:10:21 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Regev", "Oded", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1710.11595", "submitter": "Casey Kneale", "authors": "Casey Kneale, Steven D. Brown", "title": "Small Moving Window Calibration Models for Soft Sensing Processes with\n  Limited History", "comments": "Fixed many errors and improved clarity", "journal-ref": null, "doi": "10.1016/j.chemolab.2018.10.007", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Five simple soft sensor methodologies with two update conditions were\ncompared on two experimentally-obtained datasets and one simulated dataset. The\nsoft sensors investigated were moving window partial least squares regression\n(and a recursive variant), moving window random forest regression, the mean\nmoving window of $y$, and a novel random forest partial least squares\nregression ensemble (RF-PLS), all of which can be used with small sample sizes\nso that they can be rapidly placed online. It was found that, on two of the\ndatasets studied, small window sizes led to the lowest prediction errors for\nall of the moving window methods studied. On the majority of datasets studied,\nthe RF-PLS calibration method offered the lowest one-step-ahead prediction\nerrors compared to those of the other methods, and it demonstrated greater\npredictive stability at larger time delays than moving window PLS alone. It was\nfound that both the random forest and RF-PLS methods most adequately modeled\nthe datasets that did not feature purely monotonic increases in property\nvalues, but that both methods performed more poorly than moving window PLS\nmodels on one dataset with purely monotonic property values. Other data\ndependent findings are presented and discussed.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:15:37 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 22:45:10 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 16:52:15 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kneale", "Casey", ""], ["Brown", "Steven D.", ""]]}, {"id": "1710.11622", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Sergey Levine", "title": "Meta-Learning and Universality: Deep Representations and Gradient\n  Descent can Approximate any Learning Algorithm", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to learn is a powerful paradigm for enabling models to learn from\ndata more effectively and efficiently. A popular approach to meta-learning is\nto train a recurrent model to read in a training dataset as input and output\nthe parameters of a learned model, or output predictions for new test inputs.\nAlternatively, a more recent approach to meta-learning aims to acquire deep\nrepresentations that can be effectively fine-tuned, via standard gradient\ndescent, to new tasks. In this paper, we consider the meta-learning problem\nfrom the perspective of universality, formalizing the notion of learning\nalgorithm approximation and comparing the expressive power of the\naforementioned recurrent models to the more recent approaches that embed\ngradient descent into the meta-learner. In particular, we seek to answer the\nfollowing question: does deep representation combined with standard gradient\ndescent have sufficient capacity to approximate any learning algorithm? We find\nthat this is indeed true, and further find, in our experiments, that\ngradient-based meta-learning consistently leads to learning strategies that\ngeneralize more widely compared to those represented by recurrent models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:55:42 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 01:38:51 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 19:16:20 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}]