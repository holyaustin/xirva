[{"id": "1911.00110", "submitter": "Andrew Weinert", "authors": "Andrew Weinert", "title": "Method to Characterize Potential UAS Encounters Using Open Source Data", "comments": "15 pages, 7 figures, 4 tables, 19 references", "journal-ref": "Aerospace 2020, 7, 158", "doi": "10.3390/aerospace7110158", "report-no": null, "categories": "cs.RO cs.ET cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As unmanned aerial systems (UASs) increasingly integrate into the US national\nairspace system, there is an increasing need to characterize how commercial and\nrecreational UASs may encounter each other. To inform the development and\nevaluation of safety critical technologies, we demonstrate a methodology to\nanalytically calculate all potential relative geometries between different UAS\noperations performing inspection missions. This method is based on a previously\ndemonstrated technique that leverages open source geospatial information to\ngenerate representative unmanned aircraft trajectories. Using open source data\nand parallel processing techniques, we performed trillions of calculations to\nestimate the relative horizontal distance between geospatial points across\nsixteen locations.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:11:24 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 18:05:18 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 19:14:56 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Weinert", "Andrew", ""]]}, {"id": "1911.00142", "submitter": "Xinyu Huang", "authors": "Xinyu Huang, Yuting Fang, Adam Noel, Nan Yang", "title": "Channel Characterization for 1D Molecular Communication with Two\n  Absorbing Receivers", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1109/LCOMM.2020.2981609", "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter develops a one-dimensional (1D) diffusion-based molecular\ncommunication system to analyze channel responses between a single transmitter\n(TX) and two fully-absorbing receivers (RXs). Incorporating molecular\ndegradation in the environment, rigorous analytical formulas for i) the\nfraction of molecules absorbed, ii) the corresponding hitting rate, and iii)\nthe asymptotic fraction of absorbed molecules as time approaches infinity at\neach RX are derived when an impulse of molecules are released at the TX. By\nusing particle-based simulations, the derived analytical expressions are\nvalidated. Simulations also present the distance ranges of two RXs that do not\nimpact molecular absorption of each other, and demonstrate that the mutual\nimfluence of two active RXs reduces with the increase in the degradation rate.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:49:52 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 04:40:05 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Huang", "Xinyu", ""], ["Fang", "Yuting", ""], ["Noel", "Adam", ""], ["Yang", "Nan", ""]]}, {"id": "1911.00548", "submitter": "Anup Das", "authors": "Adarsha Balaji, Shihao Song, Anup Das, Nikil Dutt, Jeff Krichmar,\n  Nagarajan Kandasamy, Francky Catthoor", "title": "A Framework to Explore Workload-Specific Performance and Lifetime\n  Trade-offs in Neuromorphic Computing", "comments": "4 pages, 5 figures, 13 references, accepted for publication at IEEE\n  Computer Architecture Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuromorphic hardware with non-volatile memory (NVM) can implement machine\nlearning workload in an energy-efficient manner. Unfortunately, certain NVMs\nsuch as phase change memory (PCM) require high voltages for correct operation.\nThese voltages are supplied from an on-chip charge pump. If the charge pump is\nactivated too frequently, its internal CMOS devices do not recover from stress,\naccelerating their aging and leading to negative bias temperature instability\n(NBTI) generated defects. Forcefully discharging the stressed charge pump can\nlower the aging rate of its CMOS devices, but makes the neuromorphic hardware\nunavailable to perform computations while its charge pump is being discharged.\nThis negatively impacts performance such as latency and accuracy of the machine\nlearning workload being executed. In this paper, we propose a novel framework\nto exploit workload-specific performance and lifetime trade-offs in\nneuromorphic computing. Our framework first extracts the precise times at which\na charge pump in the hardware is activated to support neural computations\nwithin a workload. This timing information is then used with a characterized\nNBTI reliability model to estimate the charge pump's aging during the workload\nexecution. We use our framework to evaluate workload-specific performance and\nreliability impacts of using 1) different SNN mapping strategies and 2)\ndifferent charge pump discharge strategies. We show that our framework can be\nused by system designers to explore performance and reliability trade-offs\nearly in the design of neuromorphic hardware such that appropriate\nreliability-oriented design margins can be set.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:45:20 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Balaji", "Adarsha", ""], ["Song", "Shihao", ""], ["Das", "Anup", ""], ["Dutt", "Nikil", ""], ["Krichmar", "Jeff", ""], ["Kandasamy", "Nagarajan", ""], ["Catthoor", "Francky", ""]]}, {"id": "1911.01117", "submitter": "Jonas Landman", "authors": "Iordanis Kerenidis, Jonas Landman, Anupam Prakash", "title": "Quantum Algorithms for Deep Convolutional Neural Networks", "comments": null, "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a new computational paradigm that promises applications\nin several fields, including machine learning. In the last decade, deep\nlearning, and in particular Convolutional neural networks (CNN), have become\nessential for applications in signal processing and image recognition. Quantum\ndeep learning, however remains a challenging problem, as it is difficult to\nimplement non linearities with quantum unitaries. In this paper we propose a\nquantum algorithm for applying and training deep convolutional neural networks\nwith a potential speedup. The quantum CNN (QCNN) is a shallow circuit,\nreproducing completely the classical CNN, by allowing non linearities and\npooling operations. The QCNN is particularly interesting for deep networks and\ncould allow new frontiers in image recognition, by using more or larger\nconvolution kernels, larger or deeper inputs. We introduce a new quantum\ntomography algorithm with $\\ell_{\\infty}$ norm guarantees, and new applications\nof probabilistic sampling in the context of information processing. We also\npresent numerical simulations for the classification of the MNIST dataset to\nprovide practical evidence for the efficiency of the QCNN.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 10:34:46 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Landman", "Jonas", ""], ["Prakash", "Anupam", ""]]}, {"id": "1911.01968", "submitter": "Todd Hylton", "authors": "Tom Conte, Erik DeBenedictis, Natesh Ganesh, Todd Hylton, John Paul\n  Strachan, R. Stanley Williams, Alexander Alemi, Lee Altenberg, Gavin Crooks,\n  James Crutchfield, Lidia del Rio, Josh Deutsch, Michael DeWeese, Khari\n  Douglas, Massimiliano Esposito, Michael Frank, Robert Fry, Peter Harsha, Mark\n  Hill, Christopher Kello, Jeff Krichmar, Suhas Kumar, Shih-Chii Liu, Seth\n  Lloyd, Matteo Marsili, Ilya Nemenman, Alex Nugent, Norman Packard, Dana\n  Randall, Peter Sadowski, Narayana Santhanam, Robert Shaw, Adam Stieg, Elan\n  Stopnitzky, Christof Teuscher, Chris Watkins, David Wolpert, Joshua Yang, and\n  Yan Yufik", "title": "Thermodynamic Computing", "comments": "A Computing Community Consortium (CCC) workshop report, 36 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_6", "categories": "cs.CY cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardware and software foundations laid in the first half of the 20th\nCentury enabled the computing technologies that have transformed the world, but\nthese foundations are now under siege. The current computing paradigm, which is\nthe foundation of much of the current standards of living that we now enjoy,\nfaces fundamental limitations that are evident from several perspectives. In\nterms of hardware, devices have become so small that we are struggling to\neliminate the effects of thermodynamic fluctuations, which are unavoidable at\nthe nanometer scale. In terms of software, our ability to imagine and program\neffective computational abstractions and implementations are clearly challenged\nin complex domains. In terms of systems, currently five percent of the power\ngenerated in the US is used to run computing systems - this astonishing figure\nis neither ecologically sustainable nor economically scalable. Economically,\nthe cost of building next-generation semiconductor fabrication plants has\nsoared past $10 billion. All of these difficulties - device scaling, software\ncomplexity, adaptability, energy consumption, and fabrication economics -\nindicate that the current computing paradigm has matured and that continued\nimprovements along this path will be limited. If technological progress is to\ncontinue and corresponding social and economic benefits are to continue to\naccrue, computing must become much more capable, energy efficient, and\naffordable. We propose that progress in computing can continue under a united,\nphysically grounded, computational paradigm centered on thermodynamics. Herein\nwe propose a research agenda to extend these thermodynamic foundations into\ncomplex, non-equilibrium, self-organizing systems and apply them holistically\nto future computing systems that will harness nature's innate computational\ncapacity. We call this type of computing \"Thermodynamic Computing\" or TC.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:48:35 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 15:12:35 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Conte", "Tom", ""], ["DeBenedictis", "Erik", ""], ["Ganesh", "Natesh", ""], ["Hylton", "Todd", ""], ["Strachan", "John Paul", ""], ["Williams", "R. Stanley", ""], ["Alemi", "Alexander", ""], ["Altenberg", "Lee", ""], ["Crooks", "Gavin", ""], ["Crutchfield", "James", ""], ["del Rio", "Lidia", ""], ["Deutsch", "Josh", ""], ["DeWeese", "Michael", ""], ["Douglas", "Khari", ""], ["Esposito", "Massimiliano", ""], ["Frank", "Michael", ""], ["Fry", "Robert", ""], ["Harsha", "Peter", ""], ["Hill", "Mark", ""], ["Kello", "Christopher", ""], ["Krichmar", "Jeff", ""], ["Kumar", "Suhas", ""], ["Liu", "Shih-Chii", ""], ["Lloyd", "Seth", ""], ["Marsili", "Matteo", ""], ["Nemenman", "Ilya", ""], ["Nugent", "Alex", ""], ["Packard", "Norman", ""], ["Randall", "Dana", ""], ["Sadowski", "Peter", ""], ["Santhanam", "Narayana", ""], ["Shaw", "Robert", ""], ["Stieg", "Adam", ""], ["Stopnitzky", "Elan", ""], ["Teuscher", "Christof", ""], ["Watkins", "Chris", ""], ["Wolpert", "David", ""], ["Yang", "Joshua", ""], ["Yufik", "Yan", ""]]}, {"id": "1911.02385", "submitter": "Christian Mayr", "authors": "Christian Mayr and Sebastian Hoeppner and Steve Furber", "title": "SpiNNaker 2: A 10 Million Core Processor System for Brain Simulation and\n  Machine Learning", "comments": null, "journal-ref": "Communication Process Architectures 2018", "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SpiNNaker is an ARM-based processor platform optimized for the simulation of\nspiking neural networks. This brief describes the roadmap in going from the\ncurrent SPINNaker1 system, a 1 Million core machine in 130nm CMOS, to\nSpiNNaker2, a 10 Million core machine in 22nm FDSOI. Apart from pure scaling,\nwe will take advantage of specific technology features, such as runtime\nadaptive body biasing, to deliver cutting-edge power consumption. Power\nmanagement of the cores allows a wide range of workload adaptivity, i.e.\nprocessor power scales with the complexity and activity of the spiking network.\nAdditional numerical accelerators will enhance the utility of SpiNNaker2 for\nsimulation of spiking neural networks as well as for executing conventional\ndeep neural networks. These measures should increase the simulation capacity of\nthe machine by a factor $>$50. The interplay between the two domains, i.e.\nspiking and rate based, will provide an interesting field for algorithm\nexploration on SpiNNaker2. Apart from the platforms' traditional usage as a\nneuroscience exploration tool, the extended functionality opens up new\napplication areas such as automotive AI, tactile internet, industry 4.0 and\nbiomedical processing.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:47:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Mayr", "Christian", ""], ["Hoeppner", "Sebastian", ""], ["Furber", "Steve", ""]]}, {"id": "1911.02547", "submitter": "Andrei Velichko", "authors": "A. A. Velichko, M. A. Belyaev, D. V. Ryabokon and S. D. Khanin", "title": "The non-capacitor model of leaky integrate-and-fire $VO_2$ neuron with\n  the thermal mechanism of the membrane potential", "comments": null, "journal-ref": "J. Phys.: Conf. Ser. 1399 022046 (2019)", "doi": "10.1088/1742-6596/1399/2/022046", "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents a numerical model of leaky integrate-and-fire neuron\ncreated on the basis of $VO_2$ switch. The analogue of the membrane potential\nin the model is the temperature of the switch channel, and the action potential\nfrom neighbouring neurons propagates along the substrate in the form of thermal\npulses. We simulated the operation of three neurons and demonstrated that the\ntotal effect happens due to interference of thermal waves in the region of the\nneuron switching channel. The thermal mechanism of the threshold function\noperates due to the effect of electrical switching, and the magnitude\n(temperature) of the threshold can vary by external voltage. The neuron circuit\ndoes not contain capacitor, making it possible to produce a network with a high\ndensity of components, and has the potential for 3D integration due to the\nthermal mechanism of neurons interaction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:19:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Velichko", "A. A.", ""], ["Belyaev", "M. A.", ""], ["Ryabokon", "D. V.", ""], ["Khanin", "S. D.", ""]]}, {"id": "1911.02923", "submitter": "Dario Ballarini", "authors": "D. Ballarini, A. Gianfrate, R. Panico, A. Opala, S. Ghosh, L.\n  Dominici, V. Ardizzone, M. De Giorgi, G. Lerario, G. Gigli, T.C.H. Liew, M.\n  Matuszewski, D. Sanvitto", "title": "Polaritonic neuromorphic computing outperforms linear classifiers", "comments": null, "journal-ref": null, "doi": "10.1021/acs.nanolett.0c00435", "report-no": null, "categories": "cs.ET cond-mat.dis-nn cond-mat.quant-gas", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning software applications are nowadays ubiquitous in many fields\nof science and society for their outstanding capability of solving\ncomputationally vast problems like the recognition of patterns and regularities\nin big datasets. One of the main goals of research is the realization of a\nphysical neural network able to perform data processing in a much faster and\nenergy-efficient way than the state-of-the-art technology. Here we show that\nlattices of exciton-polariton condensates accomplish neuromorphic computing\nusing fast optical nonlinearities and with lower error rate than any previous\nhardware implementation. We demonstrate that our neural network significantly\nincreases the recognition efficiency compared to the linear classification\nalgorithms on one of the most widely used benchmarks, the MNIST problem,\nshowing a concrete advantage from the integration of optical systems in\nreservoir computing architectures.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:17:29 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ballarini", "D.", ""], ["Gianfrate", "A.", ""], ["Panico", "R.", ""], ["Opala", "A.", ""], ["Ghosh", "S.", ""], ["Dominici", "L.", ""], ["Ardizzone", "V.", ""], ["De Giorgi", "M.", ""], ["Lerario", "G.", ""], ["Gigli", "G.", ""], ["Liew", "T. C. H.", ""], ["Matuszewski", "M.", ""], ["Sanvitto", "D.", ""]]}, {"id": "1911.03446", "submitter": "Andrew King", "authors": "Andrew D. King, Jack Raymond, Trevor Lanting, Sergei V. Isakov, Masoud\n  Mohseni, Gabriel Poulin-Lamarre, Sara Ejtemaee, William Bernoudy, Isil\n  Ozfidan, Anatoly Yu. Smirnov, Mauricio Reis, Fabio Altomare, Michael Babcock,\n  Catia Baron, Andrew J. Berkley, Kelly Boothby, Paul I. Bunyk, Holly\n  Christiani, Colin Enderud, Bram Evert, Richard Harris, Emile Hoskinson,\n  Shuiyuan Huang, Kais Jooya, Ali Khodabandelou, Nicolas Ladizinsky, Ryan Li,\n  P. Aaron Lott, Allison J. R. MacDonald, Danica Marsden, Gaelen Marsden,\n  Teresa Medina, Reza Molavi, Richard Neufeld, Mana Norouzpour, Travis Oh, Igor\n  Pavlov, Ilya Perminov, Thomas Prescott, Chris Rich, Yuki Sato, Benjamin\n  Sheldan, George Sterling, Loren J. Swenson, Nicholas Tsai, Mark H. Volkmann,\n  Jed D. Whittaker, Warren Wilkinson, Jason Yao, Hartmut Neven, Jeremy P.\n  Hilton, Eric Ladizinsky, Mark W. Johnson, Mohammad H. Amin", "title": "Scaling advantage in quantum simulation of geometrically frustrated\n  magnets", "comments": "7 pages, 4 figures, 22 pages of supplemental material with 18 figures", "journal-ref": null, "doi": "10.1038/s41467-021-20901-5", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of quantum computing lies in harnessing programmable quantum\ndevices for practical applications such as efficient simulation of quantum\nmaterials and condensed matter systems. One important task is the simulation of\ngeometrically frustrated magnets in which topological phenomena can emerge from\ncompetition between quantum and thermal fluctuations. Here we report on\nexperimental observations of relaxation in such simulations, measured on up to\n1440 qubits with microsecond resolution. By initializing the system in a state\nwith topological obstruction, we observe quantum annealing (QA) relaxation\ntimescales in excess of one microsecond. Measurements indicate a dynamical\nadvantage in the quantum simulation over the classical approach of\npath-integral Monte Carlo (PIMC) fixed-Hamiltonian relaxation with multiqubit\ncluster updates. The advantage increases with both system size and inverse\ntemperature, exceeding a million-fold speedup over a CPU. This is an important\npiece of experimental evidence that in general, PIMC does not mimic QA dynamics\nfor stoquastic Hamiltonians. The observed scaling advantage, for simulation of\nfrustrated magnetism in quantum condensed matter, demonstrates that near-term\nquantum devices can be used to accelerate computational tasks of practical\nrelevance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:55:01 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["King", "Andrew D.", ""], ["Raymond", "Jack", ""], ["Lanting", "Trevor", ""], ["Isakov", "Sergei V.", ""], ["Mohseni", "Masoud", ""], ["Poulin-Lamarre", "Gabriel", ""], ["Ejtemaee", "Sara", ""], ["Bernoudy", "William", ""], ["Ozfidan", "Isil", ""], ["Smirnov", "Anatoly Yu.", ""], ["Reis", "Mauricio", ""], ["Altomare", "Fabio", ""], ["Babcock", "Michael", ""], ["Baron", "Catia", ""], ["Berkley", "Andrew J.", ""], ["Boothby", "Kelly", ""], ["Bunyk", "Paul I.", ""], ["Christiani", "Holly", ""], ["Enderud", "Colin", ""], ["Evert", "Bram", ""], ["Harris", "Richard", ""], ["Hoskinson", "Emile", ""], ["Huang", "Shuiyuan", ""], ["Jooya", "Kais", ""], ["Khodabandelou", "Ali", ""], ["Ladizinsky", "Nicolas", ""], ["Li", "Ryan", ""], ["Lott", "P. Aaron", ""], ["MacDonald", "Allison J. R.", ""], ["Marsden", "Danica", ""], ["Marsden", "Gaelen", ""], ["Medina", "Teresa", ""], ["Molavi", "Reza", ""], ["Neufeld", "Richard", ""], ["Norouzpour", "Mana", ""], ["Oh", "Travis", ""], ["Pavlov", "Igor", ""], ["Perminov", "Ilya", ""], ["Prescott", "Thomas", ""], ["Rich", "Chris", ""], ["Sato", "Yuki", ""], ["Sheldan", "Benjamin", ""], ["Sterling", "George", ""], ["Swenson", "Loren J.", ""], ["Tsai", "Nicholas", ""], ["Volkmann", "Mark H.", ""], ["Whittaker", "Jed D.", ""], ["Wilkinson", "Warren", ""], ["Yao", "Jason", ""], ["Neven", "Hartmut", ""], ["Hilton", "Jeremy P.", ""], ["Ladizinsky", "Eric", ""], ["Johnson", "Mark W.", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1911.05828", "submitter": "Abhronil Sengupta", "authors": "Kezhou Yang, Akul Malhotra, Sen Lu, Abhronil Sengupta", "title": "All-Spin Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TED.2020.2968223", "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic machine learning enabled by the Bayesian formulation has\nrecently gained significant attention in the domain of automated reasoning and\ndecision-making. While impressive strides have been made recently to scale up\nthe performance of deep Bayesian neural networks, they have been primarily\nstandalone software efforts without any regard to the underlying hardware\nimplementation. In this paper, we propose an \"All-Spin\" Bayesian Neural Network\nwhere the underlying spintronic hardware provides a better match to the\nBayesian computing models. To the best of our knowledge, this is the first\nexploration of a Bayesian neural hardware accelerator enabled by emerging\npost-CMOS technologies. We develop an experimentally calibrated\ndevice-circuit-algorithm co-simulation framework and demonstrate $24\\times$\nreduction in energy consumption against an iso-network CMOS baseline\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:51:18 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 18:05:34 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 05:26:20 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 15:49:40 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yang", "Kezhou", ""], ["Malhotra", "Akul", ""], ["Lu", "Sen", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "1911.06438", "submitter": "Harun Siljak", "authors": "Harun Siljak, Julien de Rosny and Mathias Fink", "title": "Reversible Hardware for Acoustic Communications", "comments": "Accepted for publication in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET eess.SP physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible computation has been recognised as a potential solution to the\ntechnological bottleneck in the future of computing machinery. Rolf Landauer\ndetermined the lower limit for power dissipation in computation and noted that\ndissipation happens when information is lost, i.e., when a bit is erased. This\nmeant that reversible computation, conserving information conserves energy as\nwell, and as such can operate on arbitrarily small power. There were only a few\napplications and use cases of reversible computing hardware. Here we present a\nnovel reversible computation architecture for time reversal of waves, with an\napplication to sound wave communications. This energy efficient design is also\na natural one, and it allows the use of the same hardware for transmission and\nreception at the time reversal mirror.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 01:10:52 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Siljak", "Harun", ""], ["de Rosny", "Julien", ""], ["Fink", "Mathias", ""]]}, {"id": "1911.06983", "submitter": "Andrei Velichko", "authors": "M. A. Belyaev, A. A. Velichko", "title": "Capacitorless Model of a VO2 Oscillator", "comments": "7 pages, 5 figures", "journal-ref": "IOP Conf. Ser.: Mater. Sci. Eng. 734 012151 (2020)", "doi": "10.1088/1757-899X/734/1/012151", "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a capacitorless model of a VO2 oscillator by introducing into\nthe circuit of a field-effect transistor and a VO2 thermal sensor, which\nprovide negative current feedback with a time delay. We compare the dynamics of\ncurrent and voltage oscillations on a switch in a circuit with a capacitor and\nwithout a capacitor. The oscillation period in the capacitorless model is\ncontrolled in a narrow range by changing the distance between the switch and\nthe sensor. The capacitorless model provides the possibility of significant\nminiaturization of the oscillator circuit, and it is important for the\nimplementation of large arrays of oscillators in oscillatory neural networks to\nsolve the problem of classification and pattern recognition.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:44:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Belyaev", "M. A.", ""], ["Velichko", "A. A.", ""]]}, {"id": "1911.07110", "submitter": "Keshab Parhi", "authors": "Xingyi Liu and Keshab K. Parhi", "title": "Training DNA Perceptrons via Fractional Coding", "comments": "Proc. 2019 Asilomar Conference on Signals, Systems and Computers", "journal-ref": null, "doi": "10.1109/IEEECONF44664.2019.9048931", "report-no": null, "categories": "cs.ET q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach to synthesize molecular reactions to\ntrain a perceptron, i.e., a single-layered neural network, with sigmoidal\nactivation function. The approach is based on fractional coding where a\nvariable is represented by two molecules. The synergy between fractional coding\nin molecular computing and stochastic logic implementations in electronic\ncomputing is key to translating known stochastic logic circuits to molecular\ncomputing. In prior work, a DNA perceptron with bipolar inputs and unipolar\noutput was proposed for inference. The focus of this paper is on synthesis of\nmolecular reactions for training of the DNA perceptron. A new molecular scaler\nthat performs multiplication by a factor greater than 1 is proposed based on\nfractional coding. The training of the perceptron proposed in this paper is\nbased on a modified backpropagation equation as the exact equation cannot be\neasily mapped to molecular reactions using fractional coding.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 22:48:28 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 23:06:02 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Liu", "Xingyi", ""], ["Parhi", "Keshab K.", ""]]}, {"id": "1911.07153", "submitter": "Abhronil Sengupta", "authors": "Kezhou Yang, Abhronil Sengupta", "title": "Stochastic Magnetoelectric Neuron for Temporal Information Encoding", "comments": null, "journal-ref": null, "doi": "10.1063/1.5138951", "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emulating various facets of computing principles of the brain can potentially\nlead to the development of neuro-computers that are able to exhibit brain-like\ncognitive capabilities. In this letter, we propose a magnetoelectronic neuron\nthat utilizes noise as a computing resource and is able to encode information\nover time through the independent control of external voltage signals. We\nextensively characterize the device operation using simulations and demonstrate\nits suitability for neuromorphic computing platforms performing temporal\ninformation encoding.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 05:10:06 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 00:13:17 GMT"}, {"version": "v3", "created": "Sun, 29 Dec 2019 07:23:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Kezhou", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "1911.08555", "submitter": "Abhronil Sengupta", "authors": "Akul Malhotra, Sen Lu, Kezhou Yang, Abhronil Sengupta", "title": "Exploiting Oxide Based Resistive RAM Variability for Bayesian Neural\n  Network Hardware Design", "comments": null, "journal-ref": null, "doi": "10.1109/TNANO.2020.2982819", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty plays a key role in real-time machine learning. As a significant\nshift from standard deep networks, which does not consider any uncertainty\nformulation during its training or inference, Bayesian deep networks are being\ncurrently investigated where the network is envisaged as an ensemble of\nplausible models learnt by the Bayes' formulation in response to uncertainties\nin sensory data. Bayesian deep networks consider each synaptic weight as a\nsample drawn from a probability distribution with learnt mean and variance.\nThis paper elaborates on a hardware design that exploits cycle-to-cycle\nvariability of oxide based Resistive Random Access Memories (RRAMs) as a means\nto realize such a probabilistic sampling function, instead of viewing it as a\ndisadvantage.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 04:06:08 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:55:20 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 06:43:43 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 00:02:48 GMT"}, {"version": "v5", "created": "Fri, 20 Mar 2020 16:33:18 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Malhotra", "Akul", ""], ["Lu", "Sen", ""], ["Yang", "Kezhou", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "1911.08633", "submitter": "Soheil Salehi", "authors": "Soheil Salehi, and Ronald F. DeMara", "title": "Adaptive Non-Uniform Compressive Sensing using SOT-MRAM Multibit\n  Crossbar Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Compressive Sensing (CS) approach is applied to utilize intrinsic\ncomputation capabilities of Spin-Orbit Torque Magnetic Random Access Memory\n(SOT-MRAM) devices for IoT applications wherein lifetime energy, device area,\nand manufacturing costs are highly-constrained while the sensing environment\nvaries rapidly. In this manuscript, we propose the Adaptive Compressed-sampling\nvia Multibit Crossbar Array (ACMCA) approach to intelligently generate the CS\nmeasurement matrix using a multibit SOT-MRAM crossbar array. SPICE circuit and\nMATLAB algorithm simulation results indicate that ACMCA reduces reconstruction\nTime-Averaged Normalized Mean Squared Error (TNMSE) by 5dB on average while\nproviding up to 160$\\mu$m$^2$ area reduction compared to a similar previous\ndesign presented in the literature while incurring a negligible increase in the\nenergy consumption of generating the CS measurement matrix.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:03:27 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 19:49:34 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:07:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Salehi", "Soheil", ""], ["DeMara", "Ronald F.", ""]]}, {"id": "1911.08674", "submitter": "Oussama Abderrahmane Dambri Mr", "authors": "Oussama Abderrahmane Dambri and Soumaya Cherkaoui", "title": "Toward a Wired Ad Hoc Nanonetwork", "comments": "submitted to IEEE International Conference on Communications 2020\n  (ICC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanomachines promise to enable new medical applications, including drug\ndelivery and real time chemical reactions' detection inside the human body.\nSuch complex tasks need cooperation between nanomachines using a communication\nnetwork. Wireless Ad hoc networks, using molecular or electromagnetic-based\ncommunication have been proposed in the literature to create flexible\nnanonetworks between nanomachines. In this paper, we propose a Wired Ad hoc\nNanoNETwork (WANNET) model design using actin-based nano-communication. In the\nproposed model, actin filaments self-assembly and disassembly is used to create\nflexible nanowires between nanomachines, and electrons are used as carriers of\ninformation. We give a general overview of the application layer, Medium Access\nControl (MAC) layer and a physical layer of the model. We also detail the\nanalytical model of the physical layer using actin nanowire equivalent\ncircuits, and we present an estimation of the circuit component's values.\nNumerical results of the derived model are provided in terms of attenuation,\nphase and delay as a function of the frequency and distances between\nnanomachines. The maximum throughput of the actin-based nanowire is also\nprovided, and a comparison between the maximum throughput of the proposed\nWANNET, vs other proposed approaches is presented. The obtained results prove\nthat the proposed wired ad hoc nanonetwork can give a very high achievable\nthroughput with a smaller delay compared to other proposed wireless molecular\ncommunication networks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:58:55 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:30:52 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Dambri", "Oussama Abderrahmane", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "1911.09104", "submitter": "Harun Siljak", "authors": "Harun Siljak", "title": "Reversible Computation in Wireless Communications", "comments": "Book chapter in IC 1405 COST Action on Reversible Computation book.\n  arXiv admin note: text overlap with arXiv:1911.06438", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.SY eess.SY nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter presents the pioneering work in applying reversible computation\nparadigms to wireless communications. These applications range from developing\nreversible hardware architectures for underwater acoustic communications to\nnovel distributed optimisation procedures in large radio-frequency antenna\narrays based on reversing Petri nets. Throughout the chapter, we discuss the\nrationale for introducing reversible computation in the domain of wireless\ncommunications, exploring the inherently reversible properties of communication\nchannels and systems formed by devices in a wireless network.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:53:04 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Siljak", "Harun", ""]]}, {"id": "1911.10109", "submitter": "Benjamin Steel", "authors": "Benjamin D. Steel", "title": "Implementation of Optical Deep Neural Networks using the Fabry-Perot\n  Interferometer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future developments in deep learning applications requiring large datasets\nwill be limited by power and speed limitations of silicon based Von-Neumann\ncomputing architectures. Optical architectures provide a low power and high\nspeed hardware alternative. Recent publications have suggested promising\nimplementations of optical neural networks (ONNs), showing huge orders of\nmagnitude efficiency and speed gains over current state of the art hardware\nalternatives. In this work, the transmission of the Fabry-Perot Interferometer\n(FPI) is proposed as a low power, low footprint activation function unit.\nNumerical simulations of optical CNNs using the FPI based activation functions\nshow accuracies of 98% on the MNIST dataset. An investigation of possible\nphysical implementation of the network shows that an ONN based on current\ntunable FPIs could be slowed by actuation delays, but rapidly developing\noptical hardware fabrication techniques could make an integrated approach using\nthe proposed FPI setups a powerful solution for previously inaccessible deep\nlearning applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:12:05 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 03:22:35 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Steel", "Benjamin D.", ""]]}, {"id": "1911.10351", "submitter": "Andrei Velichko", "authors": "Andrei Velichko, Petr Boriskov", "title": "Oscillator Circuit for Spike Neural Network with Sigmoid Like Activation\n  Function and Firing Rate Coding", "comments": "9 pages, 8 figures. in IEEE Transactions on Circuits and Systems II:\n  Express Briefs", "journal-ref": null, "doi": "10.1109/TCSII.2020.2997117", "report-no": null, "categories": "cs.ET cs.NE physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents an oscillator circuit for a spike neural network with the\npossibility of firing rate coding and sigmoid-like activation function. The\ncircuit contains a switching element with an S-shaped current-voltage\ncharacteristic and two capacitors; one of the capacitors is shunted by a\ncontrol resistor. The circuit is characterised by a strong dependence of the\nfrequency of relaxation oscillations on the magnitude of the control resistor.\nThe dependence has a sigmoid-like form and we present an analytical method for\ndependence calculation. Finally, we describe the concept of the spike neural\nnetwork architecture with firing rate coding based on the presented circuit for\ncreating neuromorphic devices and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 11:36:08 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Velichko", "Andrei", ""], ["Boriskov", "Petr", ""]]}, {"id": "1911.10741", "submitter": "Jun Zhou", "authors": "Bo Wang, Jun Zhou, Weng-Fai Wong, and Li-Shiuan Peh", "title": "Shenjing: A low power reconfigurable neuromorphic accelerator with\n  partial-sum and spike networks-on-chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next wave of on-device AI will likely require energy-efficient deep\nneural networks. Brain-inspired spiking neural networks (SNN) has been\nidentified to be a promising candidate. Doing away with the need for\nmultipliers significantly reduces energy. For on-device applications, besides\ncomputation, communication also incurs a significant amount of energy and time.\nIn this paper, we propose Shenjing, a configurable SNN architecture which fully\nexposes all on-chip communications to software, enabling software mapping of\nSNN models with high accuracy at low power. Unlike prior SNN architectures like\nTrueNorth, Shenjing does not require any model modification and retraining for\nthe mapping. We show that conventional artificial neural networks (ANN) such as\nmultilayer perceptron, convolutional neural networks, as well as the latest\nresidual neural networks can be mapped successfully onto Shenjing, realizing\nANNs with SNN's energy efficiency. For the MNIST inference problem using a\nmultilayer perceptron, we were able to achieve an accuracy of 96% while\nconsuming just 1.26mW using 10 Shenjing cores.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:32:24 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wang", "Bo", ""], ["Zhou", "Jun", ""], ["Wong", "Weng-Fai", ""], ["Peh", "Li-Shiuan", ""]]}, {"id": "1911.11204", "submitter": "Matthew Daniels", "authors": "Matthew W. Daniels, Advait Madhavan, Philippe Talatchian, Alice\n  Mizrahi, Mark D. Stiles", "title": "Energy-efficient stochastic computing with superparamagnetic tunnel\n  junctions", "comments": "20 pages (12 pages main text), 12 figures", "journal-ref": "Phys. Rev. Applied 13, 034016 (2020)", "doi": "10.1103/PhysRevApplied.13.034016", "report-no": null, "categories": "cs.ET cond-mat.mes-hall physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superparamagnetic tunnel junctions (SMTJs) have emerged as a competitive,\nrealistic nanotechnology to support novel forms of stochastic computation in\nCMOS-compatible platforms. One of their applications is to generate random\nbitstreams suitable for use in stochastic computing implementations. We\ndescribe a method for digitally programmable bitstream generation based on\npre-charge sense amplifiers. This generator is significantly more energy\nefficient than SMTJ-based bitstream generators that tune probabilities with\nspin currents and a factor of two more efficient than related CMOS-based\nimplementations. The true randomness of this bitstream generator allows us to\nuse them as the fundamental units of a novel neural network architecture. To\ntake advantage of the potential savings, we codesign the algorithm with the\ncircuit, rather than directly transcribing a classical neural network into\nhardware. The flexibility of the neural network mathematics allows us to adapt\nthe network to the explicitly energy efficient choices we make at the device\nlevel. The result is a convolutional neural network design operating at\n$\\approx$ 150 nJ per inference with 97 % performance on MNIST -- a factor of\n1.4 to 7.7 improvement in energy efficiency over comparable proposals in the\nrecent literature.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:11:43 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 14:02:24 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Daniels", "Matthew W.", ""], ["Madhavan", "Advait", ""], ["Talatchian", "Philippe", ""], ["Mizrahi", "Alice", ""], ["Stiles", "Mark D.", ""]]}, {"id": "1911.12352", "submitter": "Necati Uysal", "authors": "Baogang Zhang, Necati Uysal, Deliang Fan, Rickard Ewetz", "title": "Representable Matrices: Enabling High Accuracy Analog Computation for\n  Inference of DNNs using Memristors", "comments": "6 pages, ASPDAC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog computing based on memristor technology is a promising solution to\naccelerating the inference phase of deep neural networks (DNNs). A fundamental\nproblem is to map an arbitrary matrix to a memristor crossbar array (MCA) while\nmaximizing the resulting computational accuracy. The state-of-the-art mapping\ntechnique is based on a heuristic that only guarantees to produce the correct\noutput for two input vectors. In this paper, a technique that aims to produce\nthe correct output for every input vector is proposed, which involves\nspecifying the memristor conductance values and a scaling factor realized by\nthe peripheral circuitry. The key insight of the paper is that the conductance\nmatrix realized by an MCA is only required to be proportional to the target\nmatrix. The selection of the scaling factor between the two regulates the\nutilization of the programmable memristor conductance range and the\nrepresentability of the target matrix. Consequently, the scaling factor is set\nto balance precision and value range errors. Moreover, a technique of\nconverting conductance values into state variables and vice versa is proposed\nto handle memristors with non-ideal device characteristics. Compared with the\nstate-of-the-art technique, the proposed mapping results in 4X-9X smaller\nerrors. The improvements translate into that the classification accuracy of a\nseven-layer convolutional neural network (CNN) on CIFAR-10 is improved from\n20.5% to 71.8%.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:53:18 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zhang", "Baogang", ""], ["Uysal", "Necati", ""], ["Fan", "Deliang", ""], ["Ewetz", "Rickard", ""]]}, {"id": "1911.12691", "submitter": "Stefan Hillmich", "authors": "Alwin Zulehner, Stefan Hillmich, Robert Wille", "title": "How to Efficiently Handle Complex Values? Implementing Decision Diagrams\n  for Quantum Computing", "comments": null, "journal-ref": "International Conference on Computer-Aided Design, 2019", "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing promises substantial speedups by exploiting quantum\nmechanical phenomena such as superposition and entanglement. Corresponding\ndesign methods require efficient means of representation and manipulation of\nquantum functionality. In the classical domain, decision diagrams have been\nsuccessfully employed as a powerful alternative to straightforward means such\nas truth tables. This motivated extensive research on whether decision diagrams\nprovide similar potential in the quantum domain -- resulting in new types of\ndecision diagrams capable of substantially reducing the complexity of\nrepresenting quantum states and functionality. From an implementation\nperspective, many concepts and techniques from the classical domain can be\nre-used in order to implement decision diagrams packages for the quantum realm.\nHowever, new problems -- namely how to efficiently handle complex numbers --\narise. In this work, we propose a solution to overcome these problems.\nExperimental evaluations confirm that this yields improvements of orders of\nmagnitude in the runtime needed to create and to utilize these decision\ndiagrams. The resulting implementation is publicly available as a quantum DD\npackage at http://iic.jku.at/eda/research/quantum_dd.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:03:44 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Zulehner", "Alwin", ""], ["Hillmich", "Stefan", ""], ["Wille", "Robert", ""]]}, {"id": "1911.12815", "submitter": "Weidong Cao", "authors": "Weidong Cao, Liu Ke, Ayan Chakrabarti, Xuan Zhang", "title": "Neural Network-Inspired Analog-to-Digital Conversion to Achieve\n  Super-Resolution with Low-Precision RRAM Devices", "comments": "7 pages, ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works propose neural network- (NN-) inspired analog-to-digital\nconverters (NNADCs) and demonstrate their great potentials in many emerging\napplications. These NNADCs often rely on resistive random-access memory (RRAM)\ndevices to realize the NN operations and require high-precision RRAM cells\n(6~12-bit) to achieve a moderate quantization resolution (4~8-bit). Such\noptimistic assumption of RRAM resolution, however, is not supported by\nfabrication data of RRAM arrays in large-scale production process. In this\npaper, we propose an NN-inspired super-resolution ADC based on low-precision\nRRAM devices by taking the advantage of a co-design methodology that combines a\npipelined hardware architecture with a custom NN training framework. Results\nobtained from SPICE simulations demonstrate that our method leads to robust\ndesign of a 14-bit super-resolution ADC using 3-bit RRAM devices with improved\npower and speed performance and competitive figure-of-merits (FoMs). In\naddition to the linear uniform quantization, the proposed ADC can also support\nconfigurable high-resolution nonlinear quantization with high conversion speed\nand low conversion energy, enabling future intelligent analog-to-information\ninterfaces for near-sensor analytics and processing.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:09:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cao", "Weidong", ""], ["Ke", "Liu", ""], ["Chakrabarti", "Ayan", ""], ["Zhang", "Xuan", ""]]}, {"id": "1911.12855", "submitter": "Gushu Li", "authors": "Gushu Li, Li Zhou, Nengkun Yu, Yufei Ding, Mingsheng Ying, Yuan Xie", "title": "Proq: Projection-based Runtime Assertions for Debugging on a Quantum\n  Computer", "comments": "A major revision, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Proq, a runtime assertion scheme for testing and\ndebugging quantum programs on a quantum computer. The predicates in Proq are\nrepresented by projections (or equivalently, closed subspaces of the state\nspace), following Birkhoff-von Neumann quantum logic. The satisfaction of a\nprojection by a quantum state can be directly checked upon a small number of\nprojective measurements rather than a large number of repeated executions. On\nthe theory side, we rigorously prove that checking projection-based assertions\ncan help locate bugs or statistically assure that the semantic function of the\ntested program is close to what we expect, for both exact and approximate\nquantum programs. On the practice side, we consider hardware constraints and\nintroduce several techniques to transform the assertions, making them directly\nexecutable on the measurement-restricted quantum computers. We also propose to\nachieve simplified assertion implementation using local projection technique\nwith soundness guaranteed. We compare Proq with existing quantum program\nassertions and demonstrate the effectiveness and efficiency of Proq by its\napplications to assert two ingenious quantum algorithms, the\nHarrow-Hassidim-Lloyd algorithm and Shor's algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:24:11 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 20:56:55 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Li", "Gushu", ""], ["Zhou", "Li", ""], ["Yu", "Nengkun", ""], ["Ding", "Yufei", ""], ["Ying", "Mingsheng", ""], ["Xie", "Yuan", ""]]}, {"id": "1911.12879", "submitter": "Gushu Li", "authors": "Gushu Li, Yufei Ding, Yuan Xie", "title": "Towards Efficient Superconducting Quantum Processor Architecture Design", "comments": "Accepted by ASPLOS 2020, 15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More computational resources (i.e., more physical qubits and qubit\nconnections) on a superconducting quantum processor not only improve the\nperformance but also result in more complex chip architecture with lower yield\nrate. Optimizing both of them simultaneously is a difficult problem due to\ntheir intrinsic trade-off. Inspired by the application-specific design\nprinciple, this paper proposes an automatic design flow to generate simplified\nsuperconducting quantum processor architecture with negligible performance loss\nfor different quantum programs. Our architecture-design-oriented profiling\nmethod identifies program components and patterns critical to both the\nperformance and the yield rate. A follow-up hardware design flow decomposes the\ncomplicated design procedure into three subroutines, each of which focuses on\ndifferent hardware components and cooperates with corresponding profiling\nresults and physical constraints. Experimental results show that our design\nmethodology could outperform IBM's general-purpose design schemes with better\nPareto-optimal results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 22:15:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Gushu", ""], ["Ding", "Yufei", ""], ["Xie", "Yuan", ""]]}, {"id": "1911.13289", "submitter": "Kathleen Hamilton", "authors": "Kathleen E. Hamilton and Raphael C. Pooser", "title": "Error-mitigated data-driven circuit learning on noisy quantum hardware", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application-inspired benchmarks measure how well a quantum device performs\nmeaningful calculations. In the case of parameterized circuit training, the\ncomputational task is the preparation of a target quantum state via\noptimization over a loss landscape. This is complicated by various sources of\nnoise, fixed hardware connectivity, and for generative modeling, the choice of\ntarget distribution. Gradient-based training has become a useful benchmarking\ntask for noisy intermediate scale quantum computers because of the additional\nrequirement that the optimization step uses the quantum device to estimate the\nloss function gradient. In this work we use gradient-based data-driven circuit\nlearning to benchmark the performance of several superconducting platform\ndevices and present results that show how error mitigation can improve the\ntraining of quantum circuit Born machines with $28$ tunable parameters.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:45:28 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hamilton", "Kathleen E.", ""], ["Pooser", "Raphael C.", ""]]}]