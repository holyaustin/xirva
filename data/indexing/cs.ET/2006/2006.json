[{"id": "2006.00828", "submitter": "Davide Pierangeli", "authors": "Davide Pierangeli, Mushegh Rafayelyan, Claudio Conti, and Sylvain\n  Gigan", "title": "Scalable spin-glass optical simulator", "comments": "9 pages, 4 figures", "journal-ref": "Phys. Rev. Applied 15, 034087 (2021)", "doi": "10.1103/PhysRevApplied.15.034087", "report-no": null, "categories": "physics.optics cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many developments in science and engineering depend on tackling complex\noptimizations on large scales. The challenge motivates intense search for\nspecific computing hardware that takes advantage from quantum features,\nnonlinear dynamics, or photonics. A paradigmatic optimization problem is\nfinding low-energy states in classical spin systems with fully-random\ninteractions. To date no alternative computing platform can address such\nspin-glass problems on a large scale. Here we propose and realize an optical\nscalable spin-glass simulator based on spatial light modulation and multiple\nlight scattering. By tailoring optical transmission through a disordered\nmedium, we optically accelerate the computation of the ground state of large\nspin networks with all-to-all random couplings. Scaling of the operation time\nwith the problem size demonstrates optical advantage over conventional\ncomputing. Our results point out optical vector-matrix multiplication as a tool\nfor spin-glass problems and provide a general route towards large-scale\ncomputing that exploits speed, parallelism and coherence of light.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:13:19 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 22:10:44 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Pierangeli", "Davide", ""], ["Rafayelyan", "Mushegh", ""], ["Conti", "Claudio", ""], ["Gigan", "Sylvain", ""]]}, {"id": "2006.00987", "submitter": "Aritra Sarkar", "authors": "Aritra Sarkar, Zaid Al-Ars, Koen Bertels", "title": "Quantum Accelerated Estimation of Algorithmic Information", "comments": "31 pages, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL cs.ET cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this research we present a quantum circuit for estimating algorithmic\ninformation metrics like the universal prior distribution. This accelerates\ninferring algorithmic structure in data for discovering causal generative\nmodels. The computation model is restricted in time and space resources to make\nit computable in approximating the target metrics. A classical exhaustive\nenumeration is shown for a few examples. The precise quantum circuit design\nthat allows executing a superposition of automata is presented. As a use-case,\nan application framework for experimenting on DNA sequences for meta-biology is\nproposed. To our knowledge, this is the first time approximating algorithmic\ninformation is implemented for quantum computation. Our implementation on the\nOpenQL quantum programming language and the QX Simulator is copy-left and can\nbe found on https://github.com/Advanced-Research-Centre/QuBio.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 14:47:28 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sarkar", "Aritra", ""], ["Al-Ars", "Zaid", ""], ["Bertels", "Koen", ""]]}, {"id": "2006.01238", "submitter": "Ramtin Zand", "authors": "Brendan Reidy and Ramtin Zand", "title": "SOT-MRAM based Sigmoidal Neuron for Neuromorphic Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the intrinsic physical characteristics of spin-orbit torque\n(SOT) magnetoresistive random-access memory (MRAM) devices are leveraged to\nrealize sigmoidal neurons in neuromorphic architectures. Performance\ncomparisons with the previous power- and area-efficient sigmoidal neuron\ncircuits exhibit 74x and 12x reduction in power-area-product values for the\nproposed SOT-MRAM based neuron. To verify the functionally of the proposed\nneuron within larger scale designs, we have implemented a circuit realization\nof a 784x16x10 SOT-MRAM based multiplayer perceptron (MLP) for MNIST pattern\nrecognition application using SPICE circuit simulation tool. The results\nobtained exhibit that the proposed SOT-MRAM based MLP can achieve accuracies\ncomparable to an ideal binarized MLP architecture implemented on GPU, while\nrealizing orders of magnitude increase in processing speed.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 20:18:14 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Reidy", "Brendan", ""], ["Zand", "Ramtin", ""]]}, {"id": "2006.01425", "submitter": "Jianlei Yang", "authors": "Xueyan Wang, Jianlei Yang, Yinglin Zhao, Xiaotao Jia, Gang Qu,\n  Weisheng Zhao", "title": "Hardware Security in Spin-Based Computing-In-Memory: Analysis, Exploits,\n  and Mitigation Techniques", "comments": "accepted by ACM Journal on Emerging Technologies in Computing Systems\n  (JETC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computing-in-memory (CIM) is proposed to alleviate the processor-memory data\ntransfer bottleneck in traditional Von-Neumann architectures, and\nspintronics-based magnetic memory has demonstrated many facilitation in\nimplementing CIM paradigm. Since hardware security has become one of the major\nconcerns in circuit designs, this paper, for the first time, investigates\nspin-based computing-in-memory (SpinCIM) from a security perspective. We focus\non two fundamental questions: 1) how the new SpinCIM computing paradigm can be\nexploited to enhance hardware security? 2) what security concerns has this new\nSpinCIM computing paradigm incurred?\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:08:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Wang", "Xueyan", ""], ["Yang", "Jianlei", ""], ["Zhao", "Yinglin", ""], ["Jia", "Xiaotao", ""], ["Qu", "Gang", ""], ["Zhao", "Weisheng", ""]]}, {"id": "2006.01475", "submitter": "Iacopo Poli", "authors": "Julien Launay, Iacopo Poli, Kilian M\\\"uller, Igor Carron, Laurent\n  Daudet, Florent Krzakala, Sylvain Gigan", "title": "Light-in-the-loop: using a photonics co-processor for scalable training\n  of neural networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks grow larger and more complex and data-hungry, training\ncosts are skyrocketing. Especially when lifelong learning is necessary, such as\nin recommender systems or self-driving cars, this might soon become\nunsustainable. In this study, we present the first optical co-processor able to\naccelerate the training phase of digitally-implemented neural networks. We rely\non direct feedback alignment as an alternative to backpropagation, and perform\nthe error projection step optically. Leveraging the optical random projections\ndelivered by our co-processor, we demonstrate its use to train a neural network\nfor handwritten digits recognition.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:19:45 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 14:42:49 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["M\u00fcller", "Kilian", ""], ["Carron", "Igor", ""], ["Daudet", "Laurent", ""], ["Krzakala", "Florent", ""], ["Gigan", "Sylvain", ""]]}, {"id": "2006.01687", "submitter": "Shasha Guo", "authors": "Shasha Guo, Lei Wang, Xiaofan Chen, Limeng Zhang, Ziyang Kang, Weixia\n  Xu", "title": "SeqXFilter: A Memory-efficient Denoising Filter for Dynamic Vision\n  Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic event-based dynamic vision sensors (DVS) have much faster\nsampling rates and a higher dynamic range than frame-based imaging sensors.\nHowever, they are sensitive to background activity (BA) events that are\nunwanted. There are some filters for tackling this problem based on\nspatio-temporal correlation. However, they are either memory-intensive or\ncomputing-intensive. We propose \\emph{SeqXFilter}, a spatio-temporal\ncorrelation filter with only a past event window that has an O(1) space\ncomplexity and has simple computations. We explore the spatial correlation of\nan event with its past few events by analyzing the distribution of the events\nwhen applying different functions on the spatial distances. We find the best\nfunction to check the spatio-temporal correlation for an event for\n\\emph{SeqXFilter}, best separating real events and noise events. We not only\ngive the visual denoising effect of the filter but also use two metrics for\nquantitatively analyzing the filter's performance. Four neuromorphic\nevent-based datasets, recorded from four DVS with different output sizes, are\nused for validation of our method. The experimental results show that\n\\emph{SeqXFilter} achieves similar performance as baseline NNb filters, but\nwith extremely small memory cost and simple computation logic.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 15:04:04 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Guo", "Shasha", ""], ["Wang", "Lei", ""], ["Chen", "Xiaofan", ""], ["Zhang", "Limeng", ""], ["Kang", "Ziyang", ""], ["Xu", "Weixia", ""]]}, {"id": "2006.02149", "submitter": "Hazel Murray", "authors": "Hazel Murray, Jerry Horgan, Joao F. Santos, David Malone, Harun Siljak", "title": "Implementing a Quantum Coin Scheme", "comments": "7 pages, 2017 Irish Signal and Systems conference proceedings", "journal-ref": null, "doi": "10.1109/ISSC49989.2020.9180218", "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing has the power to break current cryptographic systems,\ndisrupting online banking, shopping, data storage and communications. Quantum\ncomputing also has the power to support stronger more resistant technologies.\nIn this paper, we describe a digital cash scheme created by Dmitry Gavinsky,\nwhich utilises the capability of quantum computing. We contribute by setting\nout the methods for implementing this scheme. For both the creation and\nverification of quantum coins we convert the algebraic steps into computing\nsteps. As part of this, we describe the methods used to convert information\nstored on classical bits to information stored on quantum bits.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:40:12 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Murray", "Hazel", ""], ["Horgan", "Jerry", ""], ["Santos", "Joao F.", ""], ["Malone", "David", ""], ["Siljak", "Harun", ""]]}, {"id": "2006.02824", "submitter": "Andrei Velichko", "authors": "Andrei Velichko", "title": "Neural Network for Low-Memory IoT Devices and MNIST Image Recognition\n  Using Kernels Based on Logistic Map", "comments": "17 pages, 7 figures, 2 tables, 1 Appendix", "journal-ref": "Electronics 2020, 9(9), 1432", "doi": "10.3390/electronics9091432", "report-no": null, "categories": "cs.NE cs.ET nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a neural network which uses filters based on logistic\nmapping (LogNNet). LogNNet has a feedforward network structure, but possesses\nthe properties of reservoir neural networks. The input weight matrix, set by a\nrecurrent logistic mapping, forms the kernels that transform the input space to\nthe higher-dimensional feature space. The most effective recognition of a\nhandwritten digit from MNIST-10 occurs under chaotic behavior of the logistic\nmap. The correlation of classification accuracy with the value of the Lyapunov\nexponent was obtained. An advantage of LogNNet implementation on IoT devices is\nthe significant savings in memory used. At the same time, LogNNet has a simple\nalgorithm and performance indicators comparable to those of the best\nresource-efficient algorithms available at the moment. The presented network\narchitecture uses an array of weights with a total memory size from 1 to 29 kB\nand achieves a classification accuracy of 80.3-96.3%. Memory is saved due to\nthe processor, which sequentially calculates the required weight coefficients\nduring the network operation using the analytical equation of the logistic\nmapping. The proposed neural network can be used in implementations of\nartificial intelligence based on constrained devices with limited memory, which\nare integral blocks for creating ambient intelligence in modern IoT\nenvironments. From a research perspective, LogNNet can contribute to the\nunderstanding of the fundamental issues of the influence of chaos on the\nbehavior of reservoir-type neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 12:55:17 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:42:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Velichko", "Andrei", ""]]}, {"id": "2006.03007", "submitter": "H\\\"usrev C{\\i}lasun", "authors": "H\\\"usrev C{\\i}lasun, Salonik Resch, Zamshed I. Chowdhury, Erin Olson,\n  Masoud Zabihi, Zhengyang Zhao, Thomas Peterson, Keshab Parhi, Jian-Ping Wang,\n  Sachin S. Sapatnekar, Ulya Karpuzcu", "title": "An Inference and Learning Engine for Spiking Neural Networks in\n  Computational RAM (CRAM)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNN) represent a biologically inspired computation\nmodel capable of emulating neural computation in human brain and brain-like\nstructures. The main promise is very low energy consumption. Unfortunately,\nclassic Von Neumann architecture based SNN accelerators often fail to address\ndemanding computation and data transfer requirements efficiently at scale. In\nthis work, we propose a promising alternative, an in-memory SNN accelerator\nbased on Spintronic Computational RAM (CRAM) to overcome scalability\nlimitations, which can reduce the energy consumption by up to 164.1$\\times$\nwhen compared to a representative ASIC solution.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:54:13 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["C\u0131lasun", "H\u00fcsrev", ""], ["Resch", "Salonik", ""], ["Chowdhury", "Zamshed I.", ""], ["Olson", "Erin", ""], ["Zabihi", "Masoud", ""], ["Zhao", "Zhengyang", ""], ["Peterson", "Thomas", ""], ["Parhi", "Keshab", ""], ["Wang", "Jian-Ping", ""], ["Sapatnekar", "Sachin S.", ""], ["Karpuzcu", "Ulya", ""]]}, {"id": "2006.03117", "submitter": "Brian Crafton Mr.", "authors": "Brian Crafton, Samuel Spetalnick, Arijit Raychowdhury", "title": "Counting Cards: Exploiting Variance and Data Distributions for Robust\n  Compute In-Memory", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compute in-memory (CIM) is a promising technique that minimizes data\ntransport, the primary performance bottleneck and energy cost of most data\nintensive applications. This has found wide-spread adoption in accelerating\nneural networks for machine learning applications. Utilizing a crossbar\narchitecture with emerging non-volatile memories (eNVM) such as dense resistive\nrandom access memory (RRAM) or phase change random access memory (PCRAM),\nvarious forms of neural networks can be implemented to greatly reduce power and\nincrease on chip memory capacity. However, compute in-memory faces its own\nlimitations at both the circuit and the device levels. In this work, we explore\nthe impact of device variation and peripheral circuit design constraints.\nFurthermore, we propose a new algorithm based on device variance and neural\nnetwork weight distributions to increase both performance and accuracy for\ncompute-in memory based designs. We demonstrate a 27% power improvement and 23%\nperformance improvement for low and high variance eNVM, while satisfying a\nprogrammable threshold for a target error tolerance, which depends on the\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:15:09 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:35:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Crafton", "Brian", ""], ["Spetalnick", "Samuel", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "2006.03269", "submitter": "Amirhossein Esmaili", "authors": "Arash Fayyazi, Amirhossein Esmaili and Massoud Pedram", "title": "HIPE-MAGIC: A Technology-Aware Synthesis and Mapping Flow for HIghly\n  Parallel Execution of Memristor-Aided LoGIC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts for finding novel computing paradigms that meet today's design\nrequirements have given rise to a new trend of processing-in-memory relying on\nnon-volatile memories. In this paper, we present HIPE-MAGIC, a technology-aware\nsynthesis and mapping flow for highly parallel execution of the memristor-based\nlogic. Our framework is built upon two fundamental contributions: balancing\ntechniques during the logic synthesis, mainly targeting benefits of the\nparallelism offered by memristive crossbar arrays (MCAs), and an efficient\ntechnology mapping framework to maximize the performance and area-efficiency of\nthe memristor-based logic. Our experimental evaluations across several\nbenchmark suites demonstrate the superior performance of HIPE-MAGIC in terms of\nthroughput and energy efficiency compared to recently developed synthesis and\nmapping flows targeting MCAs, as well as the conventional CPU computing.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:35:01 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Fayyazi", "Arash", ""], ["Esmaili", "Amirhossein", ""], ["Pedram", "Massoud", ""]]}, {"id": "2006.03379", "submitter": "Nurul Halimatul Asmak Ismail", "authors": "Nurul Halimatul Asmak Ismail, Samer A. B. Awwad, Rosilah Hassan", "title": "6RLR-ABC: 6LoWPAN Routing Protocol With Local Repair Using Bio Inspired\n  Artificial Bee Colony", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": "10.5121/ijcnc.2020.12302", "report-no": null, "categories": "cs.NI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Micro-Electro-Mechanical System (MEMS) has successfully\nenabled the development of IPv6 over Low power Wireless Personal Area Network\n(6LoWPAN). This network is equipped with low-cost, low-power, lightweight and\nvaried functions devices. These devices are capable of amassing, storing,\nprocessing environmental information and conversing with neighbouring sensors.\nThese requisites pose a new and interesting challenge for the development of\nIEEE 802.15.4 together with routing protocol. In this work, 6LoWPAN Routing\nProtocol with Local Repair Using Bio Inspired Artificial Bee Colony (6RLR-ABC)\nhas been introduced. This protocol supports connection establishment between\nnodes in an energy-efficient manner while maintaining high packet delivery\nratio and throughput and minimizing average end-to-end delay. This protocol has\nbeen evaluated based on increasing generated traffic. The performance of the\ndesigned 6RLR-ABC routing protocol has been evaluated compared to 6LoWPAN\nAd-hoc On-Demand Distance Vector (LOAD) routing protocol. LOAD protocol has\nbeen chosen since it is the most relevant existed 6LoWPANrouting protocol. The\nsimulation results show that the introduced 6RLR-ABC protocol achieves lower\npacket average end-to-end delay and lower energy consumption compared to LOAD\nprotocol.Additionally,the packet delivery ratio of the designed protocol is\nmuch higher than LOAD protocol. The proposed 6RLR-ABC achieved about 39% higher\npacket delivery ratio and about 54.8% higher throughput while simultaneously\noffering lower average end-to-end delay and lower average energy consumption\nthan LOAD protocol.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:27:44 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Ismail", "Nurul Halimatul Asmak", ""], ["Awwad", "Samer A. B.", ""], ["Hassan", "Rosilah", ""]]}, {"id": "2006.03845", "submitter": "Mathias Soeken", "authors": "Thomas H\\\"aner and Mathias Soeken", "title": "Lowering the T-depth of Quantum Circuits By Reducing the Multiplicative\n  Depth Of Logic Networks", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiplicative depth of a logic network over the gate basis $\\{\\land,\n\\oplus, \\neg\\}$ is the largest number of $\\land$ gates on any path from a\nprimary input to a primary output in the network. We describe a dynamic\nprogramming based logic synthesis algorithm to reduce the multiplicative depth\nin logic networks. It makes use of cut enumeration, tree balancing, and\nexclusive sum-of-products (ESOP) representations. Our algorithm has\napplications to cryptography and quantum computing, as a reduction in the\nmultiplicative depth directly translates to a lower $T$-depth of the\ncorresponding quantum circuit. Our experimental results show improvements in\n$T$-depth over state-of-the-art methods and over several hand-optimized quantum\ncircuits for instances of AES, SHA, and floating-point arithmetic.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 11:08:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["H\u00e4ner", "Thomas", ""], ["Soeken", "Mathias", ""]]}, {"id": "2006.04831", "submitter": "Jason Larkin", "authors": "Jason Larkin, Mat\\'ias Jonsson, Daniel Justice, and Gian Giacomo\n  Guerreschi", "title": "Evaluation of QAOA based on the approximation ratio of individual\n  samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Approximate Optimization Algorithm (QAOA) is a hybrid\nquantum-classical algorithm to solve binary-variable optimization problems. Due\nto the short circuit depth and its expected robustness to systematic errors, it\nis one of the promising candidates likely to run on near-term quantum devices.\nWe simulate the performance of QAOA applied to the Max-Cut problem and compare\nit with some of the best classical alternatives, for exact, approximate and\nheuristic solution. When comparing solvers, their performance is characterized\nby the computational time taken to achieve a given quality of solution. Since\nQAOA is based on sampling, we utilize performance metrics based on the\nprobability of observing a sample above a certain quality. In addition, we show\nthat the QAOA performance varies significantly with the graph type. By\nselecting a suitable optimizer for the variational parameters and reducing the\nnumber of function evaluations, QAOA performance improves by up to 2 orders of\nmagnitude compared to previous estimates. Especially for 3-regular random\ngraphs, this setting decreases the performance gap with classical alternatives.\nBecause of the evolving QAOA computational complexity-theoretic guidance, we\nutilize a framework for the search for quantum advantage which incorporates a\nlarge number of problem instances and all three classical solver modalities:\nexact, approximate, and heuristic.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:00:18 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 20:03:38 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Larkin", "Jason", ""], ["Jonsson", "Mat\u00edas", ""], ["Justice", "Daniel", ""], ["Guerreschi", "Gian Giacomo", ""]]}, {"id": "2006.05657", "submitter": "Vivek Parmar", "authors": "Sandeep Kaur Kingra, Vivek Parmar, Shubham Negi, Sufyan Khan, Boris\n  Hudec, Tuo-Hung Hou and Manan Suri", "title": "Methodology for Realizing VMM with Binary RRAM Arrays: Experimental\n  Demonstration of Binarized-ADALINE Using OxRAM Crossbar", "comments": "Accepted for presentation at the IEEE International Symposium on\n  Circuits and Systems (ISCAS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient hardware mapping methodology for\nrealizing vector matrix multiplication (VMM) on resistive memory (RRAM) arrays.\nUsing the proposed VMM computation technique, we experimentally demonstrate a\nbinarized-ADALINE (Adaptive Linear) classifier on an OxRAM crossbar. An 8x8\nOxRAM crossbar with Ni/3-nm HfO2/7 nm Al-doped-TiO2/TiN device stack is used.\nWeight training for the binarized-ADALINE classifier is performed ex-situ on\nUCI cancer dataset. Post weight generation the OxRAM array is carefully\nprogrammed to binary weight-states using the proposed weight mapping technique\non a custom-built testbench. Our VMM powered binarized-ADALINE network achieves\na classification accuracy of 78% in simulation and 67% in experiments.\nExperimental accuracy was found to drop mainly due to crossbar inherent\nsneak-path issues and RRAM device programming variability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:18:13 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kingra", "Sandeep Kaur", ""], ["Parmar", "Vivek", ""], ["Negi", "Shubham", ""], ["Khan", "Sufyan", ""], ["Hudec", "Boris", ""], ["Hou", "Tuo-Hung", ""], ["Suri", "Manan", ""]]}, {"id": "2006.05696", "submitter": "Supriya Chakraborty", "authors": "Supriya Chakraborty, Abhishek Gupta, and Manan Suri", "title": "Unified Characterization Platform for Emerging NVM Technology: Neural\n  Network Application Benchmarking Using off-the-shelf NVM Chips", "comments": "Accepted at 2020 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": "2020 IEEE International Symposium on Circuits and Systems (ISCAS)", "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a unified FPGA based electrical test-bench for\ncharacterizing different emerging NonVolatile Memory (NVM) chips. In\nparticular, we present detailed electrical characterization and benchmarking of\nmultiple commercially available, off-the-shelf, NVM chips viz.: MRAM, FeRAM,\nCBRAM, and ReRAM. We investigate important NVM parameters such as: (i) current\nconsumption patterns, (ii) endurance, and (iii) error characterization. The\nproposed FPGA based testbench is then utilized for a Proof-of-Concept (PoC)\nNeural Network (NN) image classification application. Four emerging NVM chips\nare benchmarked against standard SRAM and Flash technology for the AI\napplication as active weight memory during inference mode.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:27:14 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chakraborty", "Supriya", ""], ["Gupta", "Abhishek", ""], ["Suri", "Manan", ""]]}, {"id": "2006.05868", "submitter": "Anup Das", "authors": "Shihao Song, Anup Das, Nagarajan Kandasamy", "title": "Improving Dependability of Neuromorphic Computing With Non-Volatile\n  Memory", "comments": "8 pages, 13 figures, accepted in 16th European Dependable Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As process technology continues to scale aggressively, circuit aging in a\nneuromorphic hardware due to negative bias temperature instability (NBTI) and\ntime-dependent dielectric breakdown (TDDB) is becoming a critical reliability\nissue and is expected to proliferate when using non-volatile memory (NVM) for\nsynaptic storage. This is because an NVM requires high voltage and current to\naccess its synaptic weight, which further accelerates the circuit aging in a\nneuromorphic hardware. Current methods for qualifying reliability are overly\nconservative, since they estimate circuit aging considering worst-case\noperating conditions and unnecessarily constrain performance. This paper\nproposes RENEU, a reliability-oriented approach to map machine learning\napplications to neuromorphic hardware, with the aim of improving system-wide\nreliability without compromising key performance metrics such as execution time\nof these applications on the hardware. Fundamental to RENEU is a novel\nformulation of the aging of CMOS-based circuits in a neuromorphic hardware\nconsidering different failure mechanisms. Using this formulation, RENEU\ndevelops a system-wide reliability model which can be used inside a\ndesign-space exploration framework involving the mapping of neurons and\nsynapses to the hardware. To this end, RENEU uses an instance of Particle Swarm\nOptimization (PSO) to generate mappings that are Pareto-optimal in terms of\nperformance and reliability. We evaluate RENEU using different machine learning\napplications on a state-of-the-art neuromorphic hardware with NVM synapses. Our\nresults demonstrate an average 38\\% reduction in circuit aging, leading to an\naverage 18% improvement in the lifetime of the hardware compared to current\npractices. RENEU only introduces a marginal performance overhead of 5% compared\nto a performance-oriented state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:50:28 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Song", "Shihao", ""], ["Das", "Anup", ""], ["Kandasamy", "Nagarajan", ""]]}, {"id": "2006.06092", "submitter": "Sergio Cano-Andrade", "authors": "J. A. Monta\\~nez-Barrera, Cesar E. Damian-Ascencio, Michael R. von\n  Spakovsky, Sergio Cano-Andrade", "title": "Loss-of-entanglement prediction of a controlled-PHASE gate in the\n  framework of steepest-entropy-ascent quantum thermodynamics", "comments": null, "journal-ref": "Physical Review A 101, 052336 (2020)", "doi": "10.1103/PhysRevA.101.052336", "report-no": null, "categories": "quant-ph cs.ET physics.atom-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As has been shown elsewhere, a reasonable model of the loss of entanglement\nor correlation that occurs in quantum computations is one which assumes that\nthey can effectively be predicted by a framework that presupposes the presence\nof irreversibilities internal to the system. It is based on the\nsteepest-entropy-ascent principle and is used here to reproduce the behavior of\na controlled-PHASE gate in good agreement with experimental data. The results\nshow that the loss of entanglement predicted is related to the\nirreversibilities in a nontrivial way, providing a possible alternative\napproach that warrants exploration to that conventionally used to predict the\nloss of entanglement. The results provide a means for understanding this loss\nin quantum protocols from a nonequilibrium thermodynamic standpoint. This\nframework permits the development of strategies for extending either the\nmaximum fidelity of the computation or the entanglement time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 22:26:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Monta\u00f1ez-Barrera", "J. A.", ""], ["Damian-Ascencio", "Cesar E.", ""], ["von Spakovsky", "Michael R.", ""], ["Cano-Andrade", "Sergio", ""]]}, {"id": "2006.06541", "submitter": "Rawan Alghamdi", "authors": "Rawan Alghamdi, Reem Alhadrami, Dalia Alhothali, Heba Almorad, Alice\n  Faisal, Sara Helal, Rahaf Shalabi, Rawan Asfour, Noofa Hammad, Asmaa Shams,\n  Nasir Saeed, Hayssam Dahrouj, Tareq Y. Al-Naffouri, Mohamed-Slim Alouini", "title": "Intelligent Surfaces for 6G Wireless Networks: A Survey of Optimization\n  and Performance Analysis Techniques", "comments": "Submitted to IEEE Access; We added more references in the second\n  version and fixed some notations in the equations. We also included further\n  discussion, clarification, and research directions", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the optimization frameworks and performance analysis\nmethods for large intelligent surfaces (LIS), which have been emerging as\nstrong candidates to support the sixth-generation wireless physical platforms\n(6G). Due to their ability to adjust the behavior of interacting\nelectromagnetic (EM) waves through intelligent manipulations of the reflections\nphase shifts, LIS have shown promising merits at improving the spectral\nefficiency of wireless networks. In this context, researchers have been\nrecently exploring LIS technology in depth as a means to achieve programmable,\nvirtualized, and distributed wireless network infrastructures. From a system\nlevel perspective, LIS have also been proven to be a low-cost, green,\nsustainable, and energy-efficient solution for 6G systems. This paper provides\na unique blend that surveys the principles of operation of LIS, together with\ntheir optimization and performance analysis frameworks. The paper first\nintroduces the LIS technology and its physical working principle. Then, it\npresents various optimization frameworks that aim to optimize specific\nobjectives, namely, maximizing energy efficiency, sum-rate, secrecy-rate, and\ncoverage. The paper afterwards discusses various relevant performance analysis\nworks including capacity analysis, the impact of hardware impairments on\ncapacity, uplink/downlink data rate analysis, and outage probability. The paper\nfurther presents the impact of adopting the LIS technology for positioning\napplications. Finally, we identify numerous exciting open challenges for\nLIS-aided 6G wireless networks, including resource allocation problems, hybrid\nradio frequency/visible light communication (RF-VLC) systems, health\nconsiderations, and localization.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:55:15 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 17:29:15 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Alghamdi", "Rawan", ""], ["Alhadrami", "Reem", ""], ["Alhothali", "Dalia", ""], ["Almorad", "Heba", ""], ["Faisal", "Alice", ""], ["Helal", "Sara", ""], ["Shalabi", "Rahaf", ""], ["Asfour", "Rawan", ""], ["Hammad", "Noofa", ""], ["Shams", "Asmaa", ""], ["Saeed", "Nasir", ""], ["Dahrouj", "Hayssam", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2006.06777", "submitter": "Anup Das", "authors": "Adarsha Balaji and Thibaut Marty and Anup Das and Francky Catthoor", "title": "Run-time Mapping of Spiking Neural Networks to Neuromorphic Hardware", "comments": "Accepted in Springer Journal of Signal Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a design methodology to partition and map the\nneurons and synapses of online learning SNN-based applications to neuromorphic\narchitectures at {run-time}. Our design methodology operates in two steps --\nstep 1 is a layer-wise greedy approach to partition SNNs into clusters of\nneurons and synapses incorporating the constraints of the neuromorphic\narchitecture, and step 2 is a hill-climbing optimization algorithm that\nminimizes the total spikes communicated between clusters, improving energy\nconsumption on the shared interconnect of the architecture. We conduct\nexperiments to evaluate the feasibility of our algorithm using synthetic and\nrealistic SNN-based applications. We demonstrate that our algorithm reduces SNN\nmapping time by an average 780x compared to a state-of-the-art design-time\nbased SNN partitioning approach with only 6.25\\% lower solution quality.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 19:56:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Balaji", "Adarsha", ""], ["Marty", "Thibaut", ""], ["Das", "Anup", ""], ["Catthoor", "Francky", ""]]}, {"id": "2006.07239", "submitter": "Sebastian Billaudelle", "authors": "Benjamin Cramer, Sebastian Billaudelle, Simeon Kanya, Aron Leibfried,\n  Andreas Gr\\\"ubl, Vitali Karasenko, Christian Pehle, Korbinian Schreiber,\n  Yannik Stradmann, Johannes Weis, Johannes Schemmel, Friedemann Zenke", "title": "Surrogate gradients for analog neuromorphic computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To rapidly process temporal information at a low metabolic cost, biological\nneurons integrate inputs as an analog sum but communicate with spikes, binary\nevents in time. Analog neuromorphic hardware uses the same principles to\nemulate spiking neural networks with exceptional energy-efficiency. However,\ninstantiating high-performing spiking networks on such hardware remains a\nsignificant challenge due to device mismatch and the lack of efficient training\nalgorithms. Here, we introduce a general in-the-loop learning framework based\non surrogate gradients that resolves these issues. Using the BrainScaleS-2\nneuromorphic system, we show that learning self-corrects for device mismatch\nresulting in competitive spiking network performance on both vision and speech\nbenchmarks. Our networks display sparse spiking activity with, on average, far\nless than one spike per hidden neuron and input, perform inference at rates of\nup to 85 k frames/second, and consume less than 200 mW. In summary, our work\nsets several new benchmarks for low-energy spiking network processing on analog\nneuromorphic hardware and paves the way for future on-chip learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:45:12 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:52:22 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 14:13:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cramer", "Benjamin", ""], ["Billaudelle", "Sebastian", ""], ["Kanya", "Simeon", ""], ["Leibfried", "Aron", ""], ["Gr\u00fcbl", "Andreas", ""], ["Karasenko", "Vitali", ""], ["Pehle", "Christian", ""], ["Schreiber", "Korbinian", ""], ["Stradmann", "Yannik", ""], ["Weis", "Johannes", ""], ["Schemmel", "Johannes", ""], ["Zenke", "Friedemann", ""]]}, {"id": "2006.07853", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Toshitake Asabuki", "title": "Continual General Chunking Problem and SyncMap", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans possess an inherent ability to chunk sequences into their constituent\nparts. In fact, this ability is thought to bootstrap language skills and\nlearning of image patterns which might be a key to a more animal-like type of\nintelligence. Here, we propose a continual generalization of the chunking\nproblem (an unsupervised problem), encompassing fixed and probabilistic chunks,\ndiscovery of temporal and causal structures and their continual variations.\nAdditionally, we propose an algorithm called SyncMap that can learn and adapt\nto changes in the problem by creating a dynamic map which preserves the\ncorrelation between variables. Results of SyncMap suggest that the proposed\nalgorithm learn near optimal solutions, despite the presence of many types of\nstructures and their continual variation. When compared to Word2vec, PARSER and\nMRIL, SyncMap surpasses or ties with the best algorithm on $66\\%$ of the\nscenarios while being the second best in the remaining $34\\%$. SyncMap's\nmodel-free simple dynamics and the absence of loss functions reveal that,\nperhaps surprisingly, much can be done with self-organization alone. Code\navailable at https://github.com/zweifel/SyncMap.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 09:39:56 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:00:10 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 07:17:42 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 09:40:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Asabuki", "Toshitake", ""]]}, {"id": "2006.08533", "submitter": "Armin Mehrabian", "authors": "Armin Mehrabian, Volker J. Sorger, Tarek El-Ghazawi", "title": "A Design Methodology for Post-Moore's Law Accelerators: The Case of a\n  Photonic Neuromorphic Processor", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade alternative technologies have gained momentum as\nconventional digital electronics continue to approach their limitations, due to\nthe end of Moore's Law and Dennard Scaling. At the same time, we are facing new\napplication challenges such as those due to the enormous increase in data. The\nattention, has therefore, shifted from homogeneous computing to specialized\nheterogeneous solutions. As an example, brain-inspired computing has re-emerged\nas a viable solution for many applications. Such new processors, however, have\nwidened the abstraction gamut from device level to applications. Therefore,\nefficient abstractions that can provide vertical design-flow tools for such\ntechnologies became critical. Photonics in general, and neuromorphic photonics\nin particular, are among the promising alternatives to electronics. While the\narsenal of device level toolbox for photonics, and high-level neural network\nplatforms are rapidly expanding, there has not been much work to bridge this\ngap. Here, we present a design methodology to mitigate this problem by\nextending high-level hardware-agnostic neural network design tools with\nfunctional and performance models of photonic components. In this paper we\ndetail this tool and methodology by using design examples and associated\nresults. We show that adopting this approach enables designers to efficiently\nnavigate the design space and devise hardware-aware systems with alternative\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:39:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mehrabian", "Armin", ""], ["Sorger", "Volker J.", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "2006.09127", "submitter": "Harald Koestler Prof. Dr.", "authors": "Michael Holzmann and Harald Koestler", "title": "Quantum simulation and circuit design for solving multidimensional\n  Poisson equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods solve Poisson equations by using grid techniques which\ndiscretize the problem in each dimension. Most of these algorithms are subject\nto the curse of dimensionality, so that they need exponential runtime. In the\npaper \"Quantum algorithm and circuit design solving the Poisson equation\" a\nquantum algorithm is shown running in polylog time to produce a quantum state\nrepresenting the solution of the Poisson equation. In this paper a quantum\nsimulation of an extended circuit design based on this algorithm is made on a\nclassical computer. Our purpose is to test an efficient circuit design which\ncan break the curse of dimensionality on a quantum computer. Due to the\nexponential rise of the Hilbert space this design is optimized on a small\nnumber of qubits. We use Microsoft's Quantum Development Kit and its simulator\nof an ideal quantum computer to validate the correctness of this algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 13:17:31 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Holzmann", "Michael", ""], ["Koestler", "Harald", ""]]}, {"id": "2006.09774", "submitter": "Max Bartunik", "authors": "Max Bartunik and Marco Fleischer and Werner Haselmayr and Jens\n  Kirchner", "title": "Colour-Specific Microfluidic Droplet Detection for Molecular\n  Communication", "comments": null, "journal-ref": null, "doi": "10.1145/3411295.3411304", "report-no": null, "categories": "cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Droplet-based microfluidic systems are a promising platform forlab-on-a-chip\n(LoC) applications. These systems can also be used toenhance LoC applications\nwith integrated droplet control information or for data transmission scenarios\nin the context of molecular communication. For both use-cases the detection and\ncharacterisation of droplets in small microfluidic channels is crucial. So far,\nonly complex lab setups with restricted capabilities have been presented as\ndetection devices. We present a new low-cost and portable droplet detector. The\ndevice is used to confidently distinguish between individual droplets in a\ndroplet-based microfluidic system. Using on-off keying a 16-bit sequence is\nsuccessfully transmittedfor the first time with such a setup. Furthermore, the\ndevices capabilities to characterise droplets regarding colour and size are\ndemonstrated. Such an application of a spectral sensor in a microfluidic system\npresents new possibilities, such as colour-coded data transmission or analysis\nof droplet content.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 10:53:23 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 09:35:04 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bartunik", "Max", ""], ["Fleischer", "Marco", ""], ["Haselmayr", "Werner", ""], ["Kirchner", "Jens", ""]]}, {"id": "2006.10656", "submitter": "Austin Gilliam", "authors": "Austin Gilliam, Marco Pistoia, and Constantin Gonciulea", "title": "Canonical Construction of Quantum Oracles", "comments": "11 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting a set of basis states is a common task in quantum computing, in\norder to increase and/or evaluate their probabilities. This is similar to\ndesigning WHERE clauses in classical database queries. Even though one can find\nheuristic methods to achieve this, it is desirable to automate the process. A\ncommon, but inefficient automation approach is to use oracles with classical\nevaluation of all the states at circuit design time. In this paper, we present\na novel, canonical way to produce a quantum oracle from an algebraic expression\n(in particular, an Ising model), that maps a set of selected states to the same\nvalue, coupled with a simple oracle that matches that particular value. We also\nintroduce a general form of the Grover iterate that standardizes this type of\noracle. We then apply this new methodology to particular cases of Ising\nHamiltonians that model the zero-sum subset problem and the computation of\nFibonacci numbers. In addition, this paper presents experimental results\nobtained on real quantum hardware, the new Honeywell computer based on\ntrapped-ion technology with quantum volume 64.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 16:28:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Gilliam", "Austin", ""], ["Pistoia", "Marco", ""], ["Gonciulea", "Constantin", ""]]}, {"id": "2006.11595", "submitter": "Damien Querlioz", "authors": "Bogdan Penkovsky, Marc Bocquet, Tifenn Hirtzlin, Jacques-Olivier\n  Klein, Etienne Nowak, Elisa Vianello, Jean-Michel Portal and Damien Querlioz", "title": "In-Memory Resistive RAM Implementation of Binarized Neural Networks for\n  Medical Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of deep learning has considerably accelerated machine learning\ndevelopment. The deployment of deep neural networks at the edge is however\nlimited by their high memory and energy consumption requirements. With new\nmemory technology available, emerging Binarized Neural Networks (BNNs) are\npromising to reduce the energy impact of the forthcoming machine learning\nhardware generation, enabling machine learning on the edge devices and avoiding\ndata transfer over the network. In this work, after presenting our\nimplementation employing a hybrid CMOS - hafnium oxide resistive memory\ntechnology, we suggest strategies to apply BNNs to biomedical signals such as\nelectrocardiography and electroencephalography, keeping accuracy level and\nreducing memory requirements. We investigate the memory-accuracy trade-off when\nbinarizing whole network and binarizing solely the classifier part. We also\ndiscuss how these results translate to the edge-oriented Mobilenet~V1 neural\nnetwork on the Imagenet task. The final goal of this research is to enable\nsmart autonomous healthcare devices.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 15:27:21 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Penkovsky", "Bogdan", ""], ["Bocquet", "Marc", ""], ["Hirtzlin", "Tifenn", ""], ["Klein", "Jacques-Olivier", ""], ["Nowak", "Etienne", ""], ["Vianello", "Elisa", ""], ["Portal", "Jean-Michel", ""], ["Querlioz", "Damien", ""]]}, {"id": "2006.11958", "submitter": "Abdullah Zyarah", "authors": "Abdullah M. Zyarah, Kevin Gomez, and Dhireesha Kudithipudi", "title": "End-to-End Memristive HTM System for Pattern Recognition and Sequence\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2020.3000183", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic systems that learn and predict from streaming inputs hold\nsignificant promise in pervasive edge computing and its applications. In this\npaper, a neuromorphic system that processes spatio-temporal information on the\nedge is proposed. Algorithmically, the system is based on hierarchical temporal\nmemory that inherently offers online learning, resiliency, and fault tolerance.\nArchitecturally, it is a full custom mixed-signal design with an underlying\ndigital communication scheme and analog computational modules. Therefore, the\nproposed system features reconfigurability, real-time processing, low power\nconsumption, and low-latency processing. The proposed architecture is\nbenchmarked to predict on real-world streaming data. The network's mean\nabsolute percentage error on the mixed-signal system is 1.129X lower compared\nto its baseline algorithm model. This reduction can be attributed to device\nnon-idealities and probabilistic formation of synaptic connections. We\ndemonstrate that the combined effect of Hebbian learning and network sparsity\nalso plays a major role in extending the overall network lifespan. We also\nillustrate that the system offers 3.46X reduction in latency and 77.02X\nreduction in power consumption when compared to a custom CMOS digital design\nimplemented at the same technology node. By employing specific low power\ntechniques, such as clock gating, we observe 161.37X reduction in power\nconsumption.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 01:12:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zyarah", "Abdullah M.", ""], ["Gomez", "Kevin", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "2006.12133", "submitter": "Safdar Jamil Mr", "authors": "Taeuk Kim, Safdar Jamil, Joongeon Park, Youngjae Kim", "title": "Optimizing Placement of Heap Memory Objects in Energy-Constrained Hybrid\n  Memory Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Main memory (DRAM) significantly impacts the power and energy utilization of\nthe overall server system. Non-Volatile Memory (NVM) devices, such as Phase\nChange Memory and Spin-Transfer Torque RAM, are suitable candidates for main\nmemory to reduce energy consumption. But unlike DRAM, NVMs access latencies are\nhigher than DRAM and NVM writes are more energy sensitive than DRAM write\noperations. Thus, Hybrid Main Memory Systems (HMMS) employing DRAM and NVM have\nbeen proposed to reduce the overall energy depletion of main memory while\noptimizing the performance of NVM. This paper proposes eMap, an optimal heap\nmemory object placement planner in HMMS. eMap considers the object-level access\npatterns and energy consumption at the application level and provides an ideal\nplacement strategy for each object to augment performance and energy\nutilization. eMap is equipped with two modules, eMPlan and eMDyn. Specifically,\neMPlan is a static placement planner which provides one time placement policies\nfor memory object to meet the energy budget while eMDyn is a runtime placement\nplanner to consider the change in energy limiting constraint during the runtime\nand shuffles the memory objects by taking into account the access patterns as\nwell as the migration cost in terms of energy and performance. The evaluation\nshows that our proposed solution satisfies both the energy limiting constraint\nand the performance. We compare our methodology with the state-of-the-art\nmemory object classification and allocation (MOCA) framework. Our extensive\nevaluation shows that our proposed solution, eMPlan meets the energy constraint\nwith 4.17 times less costly and reducing the energy consumption up to 14% with\nthe same performance. eMDyn also satisfies the performance and energy\nrequirement while considering the migration cost in terms of time and energy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:37:40 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:28:19 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kim", "Taeuk", ""], ["Jamil", "Safdar", ""], ["Park", "Joongeon", ""], ["Kim", "Youngjae", ""]]}, {"id": "2006.13849", "submitter": "Eduardo R. Miranda Prof", "authors": "Eduardo R. Miranda", "title": "Quantum Computer: Hello, Music!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.SD eess.AS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is emerging as a promising technology, which is built on\nthe principles of subatomic physics. By the time of writing, fully fledged\npractical quantum computers are not widely available. But research and\ndevelopment are advancing rapidly. Various software simulators are already\navailable. And a few companies have already started to provide access to\nquantum hardware via the cloud. These initiatives have enabled experiments with\nquantum computing to tackle some realistic problems in science; e.g., in\nchemistry and cryptography. In spite of continuing progress in developing\nincreasingly more sophisticated hardware and software, research in quantum\ncomputing has been focusing primarily on developing scientific applications. Up\ntill now there has been virtually no research activity aimed at widening the\nrange of applications of this technology beyond science and engineering. In\nparticular applications for the entertainment industry and creative economies.\nThis article introduces a new field of research, which is referred to as\nQuantum Computer Music. This research is aimed at the development of quantum\ncomputing tools and approaches to creating, performing, listening to and\ndistributing music. The article begins with a brief historical background.\nThen, it introduces the notion of algorithmic music and presents two quantum\ncomputer music systems: a singing voice synthesiser and a musical sequencer\nbased on quantum walk. A primer on quantum computing is also given. The chapter\nends with a concluding discussion and advice for further work to develop this\nnew exciting area of research.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 22:42:20 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Miranda", "Eduardo R.", ""]]}, {"id": "2006.13926", "submitter": "Liane Bernstein", "authors": "Liane Bernstein (1), Alexander Sludds (1), Ryan Hamerly (1 and 2),\n  Vivienne Sze (1), Joel Emer (1 and 3), Dirk Englund (1) ((1) Massachusetts\n  Institute of Technology, (2) NTT Research Inc., (3) NVIDIA)", "title": "Freely scalable and reconfigurable optical hardware for deep learning", "comments": "19 pages (15 main and 4 supplementary), 11 figures (6 main and 5\n  supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural network (DNN) models grow ever-larger, they can achieve higher\naccuracy and solve more complex problems. This trend has been enabled by an\nincrease in available compute power; however, efforts to continue to scale\nelectronic processors are impeded by the costs of communication, thermal\nmanagement, power delivery and clocking. To improve scalability, we propose a\ndigital optical neural network (DONN) with intralayer optical interconnects and\nreconfigurable input values. The near path-length-independence of optical\nenergy consumption enables information locality between a transmitter and\narbitrarily arranged receivers, which allows greater flexibility in\narchitecture design to circumvent scaling limitations. In a proof-of-concept\nexperiment, we demonstrate optical multicast in the classification of 500 MNIST\nimages with a 3-layer, fully-connected network. We also analyze the energy\nconsumption of the DONN and find that optical data transfer is beneficial over\nelectronics when the spacing of computational units is on the order of >10\nmicrometers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:54:01 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Bernstein", "Liane", "", "1 and 2"], ["Sludds", "Alexander", "", "1 and 2"], ["Hamerly", "Ryan", "", "1 and 2"], ["Sze", "Vivienne", "", "1 and 3"], ["Emer", "Joel", "", "1 and 3"], ["Englund", "Dirk", ""]]}, {"id": "2006.13933", "submitter": "Daniel Brunner", "authors": "T. Heuser, M. Pfl\\\"uger, I. Fischer, J. A. Lott, D. Brunner, S.\n  Reitzenstein", "title": "Developing of a photonic hardware platform for brain-inspired computing\n  based on $5\\times5$ VCSEL arrays", "comments": null, "journal-ref": null, "doi": "10.1088/2515-7647/aba671", "report-no": null, "categories": "cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-inspired computing concepts like artificial neural networks have become\npromising alternatives to classical von Neumann computer architectures.\nPhotonic neural networks target the realizations of neurons, network\nconnections and potentially learning in photonic substrates. Here, we report\nthe development of a nanophotonic hardware platform of fast and\nenergy-efficient photonic neurons via arrays of high-quality vertical cavity\nsurface emitting lasers (VCSELs). The developed $5\\times5$ VCSEL arrays provide\nhigh optical injection locking efficiency through homogeneous fabrication\ncombined with individual control over the laser wavelengths. Injection locking\nis crucial for the reliable processing of information in VCSEL-based photonic\nneurons, and we demonstrate the suitability of the VCSEL arrays by injection\nlocking measurements and current-induced spectral fine-tuning. We find that our\ninvestigated array can readily be tuned to the required spectral homogeneity,\nand as such show that VCSEL arrays based on our technology can act as highly\nenergy efficient and ultra-fast photonic neurons for next generation photonic\nneural networks. Combined with fully parallel photonic networks our substrates\nare promising for ultra-fast operation reaching 10s of GHz bandwidths, and we\nshow that a nonlinear transformation based on our lasers will consume only\nabout 100 fJ per VCSEL, which is highly competitive, compared to other\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 09:30:25 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Heuser", "T.", ""], ["Pfl\u00fcger", "M.", ""], ["Fischer", "I.", ""], ["Lott", "J. A.", ""], ["Brunner", "D.", ""], ["Reitzenstein", "S.", ""]]}, {"id": "2006.14162", "submitter": "Sheir Yarkoni", "authors": "Sheir Yarkoni, Florian Neukart, Eliane Moreno Gomez Tagle, Nicole\n  Magiera, Bharat Mehta, Kunal Hire, Swapnil Narkhede, Martin Hofmann", "title": "Quantum Shuttle: Traffic Navigation with Quantum Computing", "comments": null, "journal-ref": null, "doi": "10.1145/3412451.3428500", "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web Summit conference in Lisbon, Portugal, is one of the biggest\ntechnology conferences in Europe, attended by tens of thousands of people every\nyear. The high influx of people into Lisbon causes significant stress on the\ncity's transit services for the duration of the conference. For the Web Summit\n2019, Volkswagen AG partnered with the city of Lisbon for a pilot project to\nprovide quantum computing-based traffic optimization. A two-phase solution was\nimplemented: the first phase used data science techniques to analyze the\nmovement of people from previous conferences to build temporary new bus routes\nthroughout the city. The second phase used a custom Android navigation app\ninstalled in the buses operated by Carris, powered by a quantum optimization\nservice provided by Volkswagen that connected to live traffic data and a D-Wave\nquantum processing unit to optimize the buses' routes in real-time. To our\nknowledge, this is the first commercial application that depends on a quantum\nprocessor to perform a critical live task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:19:22 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Yarkoni", "Sheir", ""], ["Neukart", "Florian", ""], ["Tagle", "Eliane Moreno Gomez", ""], ["Magiera", "Nicole", ""], ["Mehta", "Bharat", ""], ["Hire", "Kunal", ""], ["Narkhede", "Swapnil", ""], ["Hofmann", "Martin", ""]]}, {"id": "2006.14270", "submitter": "Giacomo Indiveri", "authors": "Arianna Rubino, Can Livanelioglu, Ning Qiao, Melika Payvand, and\n  Giacomo Indiveri", "title": "Ultra-Low-Power FDSOI Neural Circuits for Extreme-Edge Neuromorphic\n  Intelligence", "comments": "11 pages, 9 figures, TCAS submission", "journal-ref": null, "doi": "10.1109/TCSI.2020.3035575", "report-no": null, "categories": "cs.ET cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing interest in the development of\nartificial intelligence circuits and systems for edge computing applications.\nIn-memory computing mixed-signal neuromorphic architectures provide promising\nultra-low-power solutions for edge-computing sensory-processing applications,\nthanks to their ability to emulate spiking neural networks in real-time. The\nfine-grain parallelism offered by this approach allows such neural circuits to\nprocess the sensory data efficiently by adapting their dynamics to the ones of\nthe sensed signals, without having to resort to the time-multiplexed computing\nparadigm of von Neumann architectures. To reduce power consumption even\nfurther, we present a set of mixed-signal analog/digital circuits that exploit\nthe features of advanced Fully-Depleted Silicon on Insulator (FDSOI)\nintegration processes. Specifically, we explore the options of advanced FDSOI\ntechnologies to address analog design issues and optimize the design of the\nsynapse integrator and of the adaptive neuron circuits accordingly. We present\ncircuit simulation results and demonstrate the circuit's ability to produce\nbiologically plausible neural dynamics with compact designs, optimized for the\nrealization of large-scale spiking neural networks in neuromorphic processors.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:31:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 07:17:17 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Rubino", "Arianna", ""], ["Livanelioglu", "Can", ""], ["Qiao", "Ning", ""], ["Payvand", "Melika", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2006.15438", "submitter": "Ajinkya Borle", "authors": "Ajinkya Borle, Vincent E. Elfving, Samuel J. Lomonaco", "title": "Quantum Approximate Optimization for Hard Problems in Linear Algebra", "comments": "18 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Quantum Approximate Optimization Algorithm (QAOA) by Farhi et al. is a\nquantum computational framework for solving quantum or classical optimization\ntasks. Here, we explore using QAOA for Binary Linear Least Squares (BLLS); a\nproblem that can serve as a building block of several other hard problems in\nlinear algebra, such as the Non-negative Binary Matrix Factorization (NBMF) and\nother variants of the Non-negative Matrix Factorization (NMF) problem. Most of\nthe previous efforts in quantum computing for solving these problems were done\nusing the quantum annealing paradigm. For the scope of this work, our\nexperiments were done on noiseless quantum simulators, a simulator including a\ndevice-realistic noise-model, and two IBM Q 5-qubit machines. We highlight the\npossibilities of using QAOA and QAOA-like variational algorithms for solving\nsuch problems, where trial solutions can be obtained directly as samples,\nrather than being amplitude-encoded in the quantum wavefunction. Our numerics\nshow that Simulated Annealing can outperform QAOA for BLLS at a QAOA depth of\n$p\\leq3$ for the probability of sampling the ground state. Finally, we point\nout some of the challenges involved in current-day experimental implementations\nof this technique on cloud-based quantum computers.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 20:13:24 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 19:42:22 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 23:02:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Borle", "Ajinkya", ""], ["Elfving", "Vincent E.", ""], ["Lomonaco", "Samuel J.", ""]]}, {"id": "2006.15470", "submitter": "Murat Kuscu Dr", "authors": "Murat Kuscu, Hamideh Ramezani, Ergin Dinc, Shahab Akhavan, Ozgur B.\n  Akan", "title": "Graphene-based Nanoscale Molecular Communication Receiver: Fabrication\n  and Microfluidic Analysis", "comments": "References fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired molecular communications (MC), where molecules are used to\ntransfer information, is the most promising technique to realise the Internet\nof Nano Things (IoNT), thanks to its inherent biocompatibility,\nenergy-efficiency, and reliability in physiologically-relevant environments.\nDespite a substantial body of theoretical work concerning MC, the lack of\npractical micro/nanoscale MC devices and MC testbeds has led researchers to\nmake overly simplifying assumptions about the implications of the channel\nconditions and the physical architectures of the practical transceivers in\ndeveloping theoretical models and devising communication methods for MC. On the\nother hand, MC imposes unique challenges resulting from the highly complex,\nnonlinear, time-varying channel properties that cannot be always tackled by\nconventional information and communication tools and technologies (ICT). As a\nresult, the reliability of the existing MC methods, which are mostly adopted\nfrom electromagnetic communications and not validated with practical testbeds,\nis highly questionable. As the first step to remove this discrepancy, in this\nstudy, we report on the fabrication of a nanoscale MC receiver based on\ngraphene field-effect transistor biosensors. We perform its ICT\ncharacterisation in a custom-designed microfluidic MC system with the\ninformation encoded into the concentration of single-stranded DNA molecules.\nThis experimental platform is the first practical implementation of a\nmicro/nanoscale MC system with nanoscale MC receivers, and can serve as a\ntestbed for developing realistic MC methods and IoNT applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 00:10:58 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 22:58:08 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Kuscu", "Murat", ""], ["Ramezani", "Hamideh", ""], ["Dinc", "Ergin", ""], ["Akhavan", "Shahab", ""], ["Akan", "Ozgur B.", ""]]}, {"id": "2006.16243", "submitter": "Katsuaki Tanabe", "authors": "Katsuaki Tanabe", "title": "Mutual Information in Coupled Double Quantum Dots: A Simple Analytic\n  Model for Potential Artificial Consciousness", "comments": "10 pages, 6 figures", "journal-ref": "J. Stat. Mech. (2020) 093209", "doi": "10.1088/1742-5468/abb233", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integrated information theory is thought to be a key clue towards the\ntheoretical understanding of consciousness. In this study, we propose a simple\nnumerical model comprising a set of coupled double quantum dots, where the\ndisconnection of the elements is represented by the removal of Coulomb\ninteraction between the quantum dots, for the quantitative investigation of\nintegrated information. As a measure of integrated information, we calculate\nthe mutual information in the model system, as the Kullback-Leibler divergence\nbetween the connected and disconnected status, through the probability\ndistribution of the electronic states from the master transition-rate\nequations. We reasonably demonstrate that the increase in the strength of\ninteraction between the quantum dots leads to higher mutual information, owing\nto the larger divergence in the probability distributions of the electronic\nstates. Our model setup could be a useful basic tool for numerical analyses in\nthe field of integrated information theory.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 05:18:46 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 11:57:50 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Tanabe", "Katsuaki", ""]]}, {"id": "2006.16302", "submitter": "Alexander Jones", "authors": "Alexander Jones and Rashmi Jha", "title": "A Compact Gated-Synapse Model for Neuromorphic Circuits", "comments": "Submitted to IEEE Transactions on Computer-Aided Design for\n  Integrated Circuits and Systems for review. \"This work has been submitted to\n  the IEEE for possible publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work reports a compact behavioral model for gated-synaptic memory. The\nmodel is developed in Verilog-A for easy integration into computer-aided design\nof neuromorphic circuits using emerging memory. The model encompasses various\nforms of gated synapses within a single framework and is not restricted to only\na single type. The behavioral theory of the model is described in detail along\nwith a full list of the default parameter settings. The model includes\nparameters such as a device's ideal set time, threshold voltage, general\nevolution of the conductance with respect to time, decay of the device's state,\netc. Finally, the model's validity is shown via extensive simulation and\nfitting to experimentally reported data on published gated-synapses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 18:22:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jones", "Alexander", ""], ["Jha", "Rashmi", ""]]}, {"id": "2006.16702", "submitter": "Hannu Reittu", "authors": "Hannu Reittu, Ville Kotovirta, Lasse Leskel\\\"a, Hannu Rummukainen,\n  Tomi R\\\"aty", "title": "Towards analyzing large graphs with quantum annealing and quantum gate\n  computers", "comments": "Extended version of a conference paper, IEEE BigData 2019, Los\n  Angeles U.S.A. International Journal of Data Mining Science (IJDAT), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of quantum computing in graph community detection and regularity\nchecking related to Szemeredi's Regularity Lemma (SRL) are demonstrated with\nD-Wave Systems' quantum annealer and simulations. We demonstrate the capability\nof quantum computing in solving hard problems relevant to big data. A new\ncommunity detection algorithm based on SRL is also introduced and tested. In\nworst case scenario of regularity check we use Grover's algorithm and quantum\nphase estimation algorithm, in order to speed-up computations using a quantum\ngate computers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 11:51:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Reittu", "Hannu", ""], ["Kotovirta", "Ville", ""], ["Leskel\u00e4", "Lasse", ""], ["Rummukainen", "Hannu", ""], ["R\u00e4ty", "Tomi", ""]]}]