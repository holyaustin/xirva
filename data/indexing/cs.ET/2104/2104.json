[{"id": "2104.00198", "submitter": "Farah Ferdaus", "authors": "Farah Ferdaus, B. M. S. Bahar Talukder, Mehdi Sadi, and Md Tauhidur\n  Rahman", "title": "True Random Number Generation using Latency Variations of Commercial\n  MRAM Chips", "comments": null, "journal-ref": "22nd International Symposium for Quality in Electronic Design\n  (ISQED), CA, USA, 2021", "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging magneto-resistive RAM (MRAM) has considerable potential to\nbecome a universal memory technology because of its several advantages:\nunlimited endurance, lower read/write latency, ultralow-power operation,\nhigh-density, and CMOS compatibility, etc. This paper will demonstrate an\neffective technique to generate random numbers from energy-efficient\nconsumer-off-the-shelf (COTS) MRAM chips. In the proposed scheme, the inherent\n(intrinsic/extrinsic process variation) stochastic switching behavior of\nmagnetic tunnel junctions (MTJs) is exploited by manipulating the write latency\nof COTS MRAM chips. This is the first system-level experimental implementation\nof true random number generator (TRNG) using COTS toggle MRAM technology to the\nbest of our knowledge. The experimental results and subsequent NIST SP-800-22\nsuite test reveal that the proposed latency-based TRNG is acceptably fast (~22\nMbit/s in the worst case) and robust over a wide range of operating conditions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 01:59:28 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ferdaus", "Farah", ""], ["Talukder", "B. M. S. Bahar", ""], ["Sadi", "Mehdi", ""], ["Rahman", "Md Tauhidur", ""]]}, {"id": "2104.00311", "submitter": "Satoshi Sunada", "authors": "Satoshi Sunada, Kazutaka Kanno, and Atsushi Uchida", "title": "Using multidimensional speckle dynamics for high-speed, large-scale,\n  parallel photonic computing", "comments": "12 pages, 8 figures", "journal-ref": "Optics Express Vol. 28, Issue 21, pp. 30349-30361 (2020)", "doi": null, "report-no": null, "categories": "physics.optics cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rapid increase in demand for data processing has resulted in the\nneed for novel machine learning concepts and hardware. Physical reservoir\ncomputing and an extreme learning machine are novel computing paradigms based\non physical systems themselves, where the high dimensionality and nonlinearity\nplay a crucial role in the information processing. Herein, we propose the use\nof multidimensional speckle dynamics in multimode fibers for information\nprocessing, where input information is mapped into the space, frequency, and\ntime domains by an optical phase modulation technique. The speckle-based\nmapping of the input information is high-dimensional and nonlinear and can be\nrealized at the speed of light; thus, nonlinear time-dependent information\nprocessing can successfully be achieved at fast rates when applying a\nreservoir-computing-like-approach. As a proof-of-concept, we experimentally\ndemonstrate chaotic time-series prediction at input rates of 12.5 Gigasamples\nper second. Moreover, we show that owing to the passivity of multimode fibers,\nmultiple tasks can be simultaneously processed within a single system, i.e.,\nmultitasking. These results offer a novel approach toward realizing parallel,\nhigh-speed, and large-scale photonic computing.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:36:00 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Sunada", "Satoshi", ""], ["Kanno", "Kazutaka", ""], ["Uchida", "Atsushi", ""]]}, {"id": "2104.00409", "submitter": "Parfait Atchade", "authors": "Parfait Atchade-Adelomou, Daniel Casado-Fauli, Elisabet\n  Golobardes-Ribe and Xavier Vilasis-Cardona", "title": "quantum Case-Based Reasoning (qCBR)", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Case-Based Reasoning (CBR) is an artificial intelligence approach to\nproblem-solving with a good record of success. This article proposes using\nQuantum Computing to improve some of the key processes of CBR defining so a\nQuantum Case-Based Reasoning (qCBR) paradigm. The focus is set on designing and\nimplementing a qCBR based on the variational principle that improves its\nclassical counterpart in terms of average accuracy, scalability and tolerance\nto overlapping. A comparative study of the proposed qCBR with a classic CBR is\nperformed for the case of the Social Workers' Problem as a sample of a\ncombinatorial optimization problem with overlapping. The algorithm's quantum\nfeasibility is modelled with docplex and tested on IBMQ computers, and\nexperimented on the Qibo framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 11:34:22 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Atchade-Adelomou", "Parfait", ""], ["Casado-Fauli", "Daniel", ""], ["Golobardes-Ribe", "Elisabet", ""], ["Vilasis-Cardona", "Xavier", ""]]}, {"id": "2104.00746", "submitter": "Junde Li", "authors": "Junde Li, Mahabubul Alam, Congzhou M Sha, Jian Wang, Nikolay V.\n  Dokholyan, Swaroop Ghosh", "title": "Drug Discovery Approaches using Quantum Machine Learning", "comments": "Li and Alam contributed equally to this work. arXiv admin note: text\n  overlap with arXiv:2101.03438", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional drug discovery pipeline takes several years and cost billions of\ndollars. Deep generative and predictive models are widely adopted to assist in\ndrug development. Classical machines cannot efficiently produce atypical\npatterns of quantum computers which might improve the training quality of\nlearning tasks. We propose a suite of quantum machine learning techniques e.g.,\ngenerative adversarial network (GAN), convolutional neural network (CNN) and\nvariational auto-encoder (VAE) to generate small drug molecules, classify\nbinding pockets in proteins, and generate large drug molecules, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 19:53:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Junde", ""], ["Alam", "Mahabubul", ""], ["Sha", "Congzhou M", ""], ["Wang", "Jian", ""], ["Dokholyan", "Nikolay V.", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2104.01638", "submitter": "Renate Krause", "authors": "Renate Krause (1), Joanne J.A. van Bavel (2), Chenxi Wu (1), Marc A.\n  Vos (2), Alain Nogaret (3), and Giacomo Indiveri (1) ((1) Institute of\n  Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland,\n  (2) Department of Medical Physiology, Division Heart & Lungs, University\n  Medical Center Utrecht, Utrecht, The Netherlands, (3) Department of Physics,\n  University of Bath Claverton Down, Bath, UK)", "title": "Robust neuromorphic coupled oscillators for adaptive pacemakers", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural coupled oscillators are a useful building block in numerous models and\napplications. They were analyzed extensively in theoretical studies and more\nrecently, in biologically realistic simulations of spiking neural networks. The\nadvent of mixed-signal analog/digital neuromorphic electronic circuits provides\nnew means for implementing neural coupled oscillators on compact low-power\nspiking neural network hardware platforms. However, their implementation on\nthis noisy, low-precision and inhomogeneous computing substrate raises new\nchallenges with regards to stability and controllability. In this work, we\npresent a robust, spiking neural network model of neural coupled oscillators\nand validate it with an implementation on a mixed-signal neuromorphic\nprocessor. We demonstrate its robustness showing how to reliably control and\nmodulate the oscillator's frequency and phase shift, despite the variability of\nthe silicon synapse and neuron properties. We show how this ultra-low power\nneural processing system can be used to build an adaptive cardiac pacemaker\nmodulating the heart rate with respect to the respiration phases and compare it\nwith surface ECG and respiratory signal recordings of dogs at rest. The\nimplementation of our model in neuromorphic electronic hardware shows its\nrobustness on a highly variable substrate and extends the toolbox for\napplications requiring rhythmic outputs such as pacemakers.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 16:00:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Krause", "Renate", ""], ["van Bavel", "Joanne J. A.", ""], ["Wu", "Chenxi", ""], ["Vos", "Marc A.", ""], ["Nogaret", "Alain", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2104.02553", "submitter": "Natalia Berloff", "authors": "Kirill P. Kalinin and Natalia G. Berloff", "title": "Large-scale Sustainable Search on Unconventional Computing Hardware", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.ET cs.IR physics.comp-ph physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the advent of the Internet, quantifying the relative importance of web\npages is at the core of search engine methods. According to one algorithm,\nPageRank, the worldwide web structure is represented by the Google matrix,\nwhose principal eigenvector components assign a numerical value to web pages\nfor their ranking. Finding such a dominant eigenvector on an ever-growing\nnumber of web pages becomes a computationally intensive task incompatible with\nMoore's Law. We demonstrate that special-purpose optical machines such as\nnetworks of optical parametric oscillators, lasers, and gain-dissipative\ncondensates, may aid in accelerating the reliable reconstruction of principal\neigenvectors of real-life web graphs. We discuss the feasibility of simulating\nthe PageRank algorithm on large Google matrices using such unconventional\nhardware. We offer alternative rankings based on the minimisation of spin\nHamiltonians. Our estimates show that special-purpose optical machines may\nprovide dramatic improvements in power consumption over classical computing\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:48:01 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kalinin", "Kirill P.", ""], ["Berloff", "Natalia G.", ""]]}, {"id": "2104.02804", "submitter": "Alisha Menon", "authors": "Alisha Menon, Anirudh Natarajan, Reva Agashe, Daniel Sun, Melvin\n  Aristio, Harrison Liew, Yakun Sophia Shao, Jan M. Rabaey", "title": "Efficient emotion recognition using hyperdimensional computing with\n  combinatorial channel encoding and cellular automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a hardware-optimized approach to emotion recognition based on\nthe efficient brain-inspired hyperdimensional computing (HDC) paradigm is\nproposed. Emotion recognition provides valuable information for human-computer\ninteractions, however the large number of input channels (>200) and modalities\n(>3) involved in emotion recognition are significantly expensive from a memory\nperspective. To address this, methods for memory reduction and optimization are\nproposed, including a novel approach that takes advantage of the combinatorial\nnature of the encoding process, and an elementary cellular automaton. HDC with\nearly sensor fusion is implemented alongside the proposed techniques achieving\ntwo-class multi-modal classification accuracies of >76% for valence and >73%\nfor arousal on the multi-modal AMIGOS and DEAP datasets, almost always better\nthan state of the art. The required vector storage is seamlessly reduced by 98%\nand the frequency of vector requests by at least 1/5. The results demonstrate\nthe potential of efficient hyperdimensional computing for low-power,\nmulti-channeled emotion recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:46:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Menon", "Alisha", ""], ["Natarajan", "Anirudh", ""], ["Agashe", "Reva", ""], ["Sun", "Daniel", ""], ["Aristio", "Melvin", ""], ["Liew", "Harrison", ""], ["Shao", "Yakun Sophia", ""], ["Rabaey", "Jan M.", ""]]}, {"id": "2104.04939", "submitter": "Abdul Wahid", "authors": "Abdul Wahid, Rajesh Sharma, and Chandra Sekhara Rao Annavarapu", "title": "A Graph Convolutional Neural Network based Framework for Estimating\n  Future Citations Count of Research Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific publications play a vital role in the career of a researcher.\nHowever, some articles become more popular than others among the research\ncommunity and subsequently drive future research directions. One of the\nindicative signs of popular articles is the number of citations an article\nreceives. The citation count, which is also the basis with various other\nmetrics, such as the journal impact factor score, the $h$-index, is an\nessential measure for assessing a scientific paper's quality. In this work, we\nproposed a Graph Convolutional Network (GCN) based framework for estimating\nfuture research publication citations for both the short-term (1-year) and\nlong-term (for 5-years and 10-years) duration. We have tested our proposed\napproach over the AMiner dataset, specifically on research articles from the\ncomputer science domain, consisting of more than 0.8 million articles.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 07:20:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wahid", "Abdul", ""], ["Sharma", "Rajesh", ""], ["Annavarapu", "Chandra Sekhara Rao", ""]]}, {"id": "2104.05332", "submitter": "Maximilian Sch\\\"afer", "authors": "Maximilian Sch\\\"afer and Yolanda Salinas and Alexander Ruderer and\n  Franz Enzenhofer and Oliver Br\\\"uggemann and Robert Schober and Werner\n  Haselmayr", "title": "Channel Modeling for Drug Carrier Matrices", "comments": "6 pages, 5 figures, submitted to 2021 IEEE Global Communications\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular communications is a promising framework for the design of\ncontrolled-release drug delivery systems. In this framework, drug carriers are\nmodeled as transmitters, the diseased cells as absorbing receivers, and the\nchannel between transmitter and receiver as diffusive channel. However,\nexisting works on drug delivery systems consider only simple drug carrier\nmodels, which limits their practical applicability. In this paper, we\ninvestigate diffusion-based spherical matrix-type drug carriers, which are\nemployed in practice. In a matrix carrier, the drug molecules are dispersed in\nthe matrix and diffuse from the inner to the outer layers of the carrier once\nimmersed in a dissolution medium. We derive the channel response of the matrix\ncarrier transmitter for an absorbing receiver and validate the results through\nparticle-based simulations. Moreover, we show that a transparent spherical\ntransmitter, with the drug molecules uniformly distributed over the entire\nvolume, is as special case of the considered matrix system. For this case, we\nprovide an analytical expression for the channel response. Finally, we compare\nthe channel response of the matrix transmitter with those of point and\ntransparent spherical transmitters to reveal the necessity of considering\npractical models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:21:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sch\u00e4fer", "Maximilian", ""], ["Salinas", "Yolanda", ""], ["Ruderer", "Alexander", ""], ["Enzenhofer", "Franz", ""], ["Br\u00fcggemann", "Oliver", ""], ["Schober", "Robert", ""], ["Haselmayr", "Werner", ""]]}, {"id": "2104.05417", "submitter": "Kevin Brol{\\o}s", "authors": "Kevin Ren\\'e Brol{\\o}s, Meera Vieira Machado, Chris Cave, Jaan Kasak,\n  Valdemar Stentoft-Hansen, Victor Galindo Batanero, Tom Jelen, Casper Wilstrup", "title": "An Approach to Symbolic Regression Using Feyn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we introduce the supervised machine learning tool called\nFeyn. The simulation engine that powers this tool is called the QLattice. The\nQLattice is a supervised machine learning tool inspired by Richard Feynman's\npath integral formulation, that explores many potential models that solves a\ngiven problem. It formulates these models as graphs that can be interpreted as\nmathematical equations, allowing the user to completely decide on the trade-off\nbetween interpretability, complexity and model performance.\n  We touch briefly upon the inner workings of the QLattice, and show how to\napply the python package, Feyn, to scientific problems. We show how it differs\nfrom traditional machine learning approaches, what it has in common with them,\nas well as some of its commonalities with symbolic regression. We describe the\nbenefits of this approach as opposed to black box models.\n  To illustrate this, we go through an investigative workflow using a basic\ndata set and show how the QLattice can help you reason about the relationships\nbetween your features and do data discovery.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:50:50 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Brol\u00f8s", "Kevin Ren\u00e9", ""], ["Machado", "Meera Vieira", ""], ["Cave", "Chris", ""], ["Kasak", "Jaan", ""], ["Stentoft-Hansen", "Valdemar", ""], ["Batanero", "Victor Galindo", ""], ["Jelen", "Tom", ""], ["Wilstrup", "Casper", ""]]}, {"id": "2104.05773", "submitter": "Hrishav Bakul Barua", "authors": "Hrishav Bakul Barua", "title": "Towards a Next Generation Computing Paradigm: Approximate Computing in\n  Robotics Systems and Environment-Experimentation, Case Study and Practical\n  Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate computing is a computation domain which can be used to trade time\nand energy with quality and therefore is useful in embedded systems. Energy is\nthe prime resource in battery-driven embedded systems, like robots. Approximate\ncomputing can be used as a technique to generate approximate version of the\ncontrol functionalities of a robot, enabling it to ration energy for\ncomputation at the cost of degraded quality. Usually, the programmer of the\nfunction specifies the extent of degradation that is safe for the overall\nsafety of the system. However, in a collaborative environment, where several\nsub-systems co-exist and some of the functionality of each of them have been\napproximated, the safety of the overall system may be compromised. In this\npaper, we consider multiple identical robots operate in a warehouse, and the\npath planning function of the robot is approximated. Although the planned paths\nare safe for individual robots (i.e. they do not collide with the racks), we\nshow that this leads to a collision among the robots. So, a controlled\napproximation needs to be carried out in such situations to harness the full\npower of this new paradigm if it needs to be a mainstream paradigm in future.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 19:03:48 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Barua", "Hrishav Bakul", ""]]}, {"id": "2104.05943", "submitter": "Aakarshitha Suresh", "authors": "Aakarshitha Suresh and Abdullah Ash Saki and Mahabubul Alam and Rasit\n  o Topalaglu and Dr. Swaroop Ghosh", "title": "A Quantum Circuit Obfuscation Methodology for Security and Privacy", "comments": "Submitted to IEEE transactions in quantum engineering (TQE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Optimization of quantum circuits using an efficient compiler is key to its\nsuccess for NISQ computers. Several 3rd party compilers are evolving to offer\nimproved performance for large quantum circuits. These 3rd parties, or just a\ncertain release of an otherwise trustworthy compiler, may possibly be untrusted\nand this could lead to an adversary to Reverse Engineer (RE) the quantum\ncircuit for extracting sensitive aspects e.g., circuit topology, program, and\nits properties. In this paper, we propose obfuscation of quantum circuits to\nhide the functionality. Quantum circuits have inherent margin between correct\nand incorrect outputs. Therefore, obfuscation (i.e., corruption of\nfunctionality) by inserting dummy gates is nontrivial. We insert dummy SWAP\ngates one at a time for maximum corruption of functionality before sending the\nquantum circuit to an untrusted compiler. If an untrusted party clones the\ndesign, they get incorrect functionality. The designer removes the dummy SWAP\ngate post-compilation to restore the correct functionality. Compared to a\nclassical counterpart, the quantum chip does not reveal the circuit\nfunctionality. Therefore, an adversary cannot guess the SWAP gate and\nlocation/validate using an oracle model. Evaluation of realistic quantum\ncircuit with/without SWAP insertion is impossible in classical computers.\nTherefore, we propose a metric-based SWAP gate insertion process. The objective\nof the metric is to ensure maximum corruption of functionality measured using\nTotal Variation Distance (TVD). The proposed approach is validated using IBM\ndefault noisy simulation model. Our metric-based approach predicts the SWAP\nposition to achieve TVD of upto 50%, and performs 7.5% better than average TVD,\nand performs within 12.3% of the best obtainable TVD for the benchmarks. We\nobtain an overhead of < 5% for the number of gates and circuit depth after SWAP\naddition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 05:09:45 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Suresh", "Aakarshitha", ""], ["Saki", "Abdullah Ash", ""], ["Alam", "Mahabubul", ""], ["Topalaglu", "Rasit o", ""], ["Ghosh", "Dr. Swaroop", ""]]}, {"id": "2104.07341", "submitter": "Daniel Martins", "authors": "Daniel P. Martins, Michael Taynnan Barros, Benjamin O'Sullivan, Ian\n  Seymour, Alan O'Riordan, Lee Coffey, Joseph Sweeney, and Sasitharan\n  Balasubramaniam", "title": "Microfluidic-based Bacterial Molecular Computing on a Chip", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET eess.SP q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biocomputing systems based on engineered bacteria can lead to novel tools for\nenvironmental monitoring and detection of metabolic diseases. In this paper, we\npropose a Bacterial Molecular Computing on a Chip (BMCoC) using microfluidic\nand electrochemical sensing technologies. The computing can be flexibly\nintegrated into the chip, but we focus on engineered bacterial AND Boolean\nlogic gate and ON-OFF switch sensors that produces secondary signals to change\nthe pH and dissolved oxygen concentrations. We present a prototype with\nexperimental results that shows the electrochemical sensors can detect small pH\nand dissolved oxygen concentration changes created by the engineered bacterial\npopulations' molecular signals. Additionally, we present a theoretical model\nanalysis of the BMCoC computation reliability when subjected to unwanted\neffects, i.e., molecular signal delays and noise, and electrochemical sensors\nthreshold settings that are based on either standard or blind detectors. Our\nnumerical analysis found that the variations in the production delay and the\nmolecular output signal concentration can impact on the computation reliability\nfor the AND logic gate and ON-OFF switch. The molecular communications of\nsynthetic engineered cells for logic gates integrated with sensing systems can\nlead to a new breed of biochips that can be used for numerous diagnostic\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:01:58 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Martins", "Daniel P.", ""], ["Barros", "Michael Taynnan", ""], ["O'Sullivan", "Benjamin", ""], ["Seymour", "Ian", ""], ["O'Riordan", "Alan", ""], ["Coffey", "Lee", ""], ["Sweeney", "Joseph", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "2104.09117", "submitter": "Janardan Misra", "authors": "Janardan Misra, Vikrant Kaulgud, Rupesh Kaslay, Sanjay Podder", "title": "When to Build Quantum Software?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite ongoing advancements in quantum computing, businesses are still faced\nwith the problem to decide if they would benefit from investing into this novel\ntechnology for building a business critical application. This uncertainty is\nnot only owing to the limitations in the current state of the technology but\nalso due to the gap between the level at which business applications are\nanalyzed (e.g., using high level semi-formal languages) and the level at which\nquantum computing related information is currently available (e.g., formally\nspecified computational problems, their algorithmic solutions with\ncomputational complexity theoretic analysis) to make informed decisions. To\nfill the discourse gap, in this paper, we present design of an interactive\nadvisor, which augments users while deciding to invest into quantum software\ndevelopment as a plausible future option in their application context. Towards\nthat we apply business process modeling and natural language similarity\nanalysis using text-embeddings to associated business context with\ncomputational problems and formulate constraints in terms of quantum speedup\nand resource requirements to select software development platforms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:14:15 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Misra", "Janardan", ""], ["Kaulgud", "Vikrant", ""], ["Kaslay", "Rupesh", ""], ["Podder", "Sanjay", ""]]}, {"id": "2104.09357", "submitter": "Frank Wang", "authors": "Frank Zhigang Wang", "title": "Reply to \"Comment on Phi memristor: Real memristor found\",\n  arXiv:1909.12464", "comments": "Reply to arXiv:1909.12464 7 pages, 4 figures", "journal-ref": "J. Appl. Phys. 125, 054504 (2019)", "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this reply, we will provide our impersonal, point-to-point responses to\nthe major criticisms (in bold and underlined) in arXiv:1909.12464. Firstly, we\nwill identify a number of (imperceptibly hidden) mistakes in the Comment in\nunderstanding/interpreting our physical model. Secondly, we will use a\n3rd-party experiment carried out in 1961 (plus other 3rd-party experiments\nthereafter) to further support our claim that our invented Phi memristor is\nmemristive in spite of the existence of a parasitic inductor effect. Thirdly,\nwe will analyse this parasitic effect mathematically, introduce our\nwork-in-progress (in nanoscale) and point out that this parasitic inductor\neffect should not become a big worry since it can be completely removed in the\nmacro-scale devices and safely neglected in the nano-scale devices.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 15:58:29 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wang", "Frank Zhigang", ""]]}, {"id": "2104.09503", "submitter": "Davide Vodola", "authors": "Eugenio Cocchi, Edoardo Tignone, Davide Vodola", "title": "Graph Partitioning into Hamiltonian Subgraphs on a Quantum Annealer", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate that a quantum annealer can be used to solve the NP-complete\nproblem of graph partitioning into subgraphs containing Hamiltonian cycles of\nconstrained length. We present a method to find a partition of a given directed\ngraph into Hamiltonian subgraphs with three or more vertices, called vertex\n3-cycle cover. We formulate the problem as a quadratic unconstrained binary\noptimisation and run it on a D-Wave Advantage quantum annealer. We test our\nmethod on synthetic graphs constructed by adding a number of random edges to a\nset of disjoint cycles. We show that the probability of solution is independent\nof the cycle length, and a solution is found for graphs up to 4000 vertices and\n5200 edges, close to the number of physical working qubits available on the\nquantum annealer.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:15:00 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Cocchi", "Eugenio", ""], ["Tignone", "Edoardo", ""], ["Vodola", "Davide", ""]]}, {"id": "2104.10297", "submitter": "Jason Kamran Jr Eshraghian", "authors": "Xiaoyuan Wang, Zhiru Wu, Pengfei Zhou, Herbert H.C. Iu, Jason K.\n  Eshraghian, and Sung Mo Kang", "title": "FPGA Synthesis of Ternary Memristor-CMOS Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for a compatible application of memristor-CMOS logic gates has\nremained elusive, as the data density benefits are offset by slow switching\nspeeds and resistive dissipation. Active microdisplays typically prioritize\npixel density (and therefore resolution) over that of speed, where the most\nwidely used refresh rates fall between 25-240 Hz. Therefore, memristor-CMOS\nlogic is a promising fit for peripheral IO logic in active matrix displays. In\nthis paper, we design and implement a ternary 1-3 line decoder and a ternary\n2-9 line decoder which are used to program a seven segment LED display. SPICE\nsimulations are conducted in a 50-nm process, and the decoders are synthesized\non an Altera Cyclone IV field-programmable gate array (FPGA) development board\nwhich implements a ternary memristor model designed in Quartus II. We compare\nour hardware results to a binary coded decimal (BCD)-to-seven segment display\ndecoder, and show our memristor-CMOS approach reduces the total IO power\nconsumption by a factor of approximately 6 times at a maximum synthesizable\nfrequency of 293.77MHz. Although the speed is approximately half of the native\nbuilt-in BCD-to-seven decoder, the comparatively slow refresh rates of typical\nmicrodisplays indicate this to be a tolerable trade-off, which promotes data\ndensity over speed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 01:05:31 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wang", "Xiaoyuan", ""], ["Wu", "Zhiru", ""], ["Zhou", "Pengfei", ""], ["Iu", "Herbert H. C.", ""], ["Eshraghian", "Jason K.", ""], ["Kang", "Sung Mo", ""]]}, {"id": "2104.11311", "submitter": "Benjamin Krakoff", "authors": "Benjamin Krakoff, Susan M. Mniszewski, Christian F. A. Negre", "title": "A QUBO Algorithm to Compute Eigenvectors of Symmetric Matrices", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an algorithm to compute the extremal eigenvalues and\ncorresponding eigenvectors of a symmetric matrix by solving a sequence of\nQuadratic Binary Optimization problems. This algorithm is robust across many\ndifferent classes of symmetric matrices, can compute the eigenvector/eigenvalue\npair to essentially arbitrary precision, and with minor modifications can also\nsolve the generalized eigenvalue problem. Performance is analyzed on small\nrandom matrices and selected larger matrices from practical applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 20:41:57 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Krakoff", "Benjamin", ""], ["Mniszewski", "Susan M.", ""], ["Negre", "Christian F. A.", ""]]}, {"id": "2104.11864", "submitter": "Xinyu Huang", "authors": "Xinyu Huang, Yuting Fang, Adam Noel, Nan Yang", "title": "Membrane Fusion-Based Transmitter Design for Static and Diffusive Mobile\n  Molecular Communication Systems", "comments": "30 pages, 9 figures. Submitted to IEEE Transactions on\n  Communications. arXiv admin note: substantial text overlap with\n  arXiv:2011.00887", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.ET math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel imperfect transmitter (TX) model, namely the\nmembrane fusion (MF)-based TX, that adopts MF between a vesicle and the TX\nmembrane to release molecules encapsulated within the vesicle. For the MF-based\nTX, the molecule release probability and the fraction of molecules released\nfrom the TX membrane are derived. Incorporating molecular degradation and a\nfully-absorbing receiver (RX), the channel impulse response (CIR) is derived\nfor two scenarios: 1) Both TX and RX are static, and 2) both TX and RX are\ndiffusion-based mobile. Moreover, a sequence of bits transmitted from the TX to\nthe RX is considered. For the mobile scenario, the probability mass function\n(PMF) of the number of molecules absorbed is calculated. Based on the derived\nPMF, the average bit error rate (BER) is derived for both scenarios.\nFurthermore, a simulation framework is proposed for the MF-based TX, based on\nwhich the derived analytical expressions are validated. Simulation results show\nthat a low MF probability or low vesicle mobility slows the release of\nmolecules and reduces the molecule hitting probability at the RX. Simulation\nresults also indicate the difference between the MF-based TX and an ideal point\nTX in terms of the inter-symbol interference (ISI).\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 02:54:06 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Huang", "Xinyu", ""], ["Fang", "Yuting", ""], ["Noel", "Adam", ""], ["Yang", "Nan", ""]]}, {"id": "2104.13386", "submitter": "Tatsuhiro Onodera Mr.", "authors": "Logan G. Wright, Tatsuhiro Onodera, Martin M. Stein, Tianyu Wang,\n  Darren T. Schachter, Zoey Hu, Peter L. McMahon", "title": "Deep physical neural networks enabled by a backpropagation algorithm for\n  arbitrary physical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.ET physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have become a pervasive tool in science and engineering.\nHowever, modern deep neural networks' growing energy requirements now\nincreasingly limit their scaling and broader use. We propose a radical\nalternative for implementing deep neural network models: Physical Neural\nNetworks. We introduce a hybrid physical-digital algorithm called Physics-Aware\nTraining to efficiently train sequences of controllable physical systems to act\nas deep neural networks. This method automatically trains the functionality of\nany sequence of real physical systems, directly, using backpropagation, the\nsame technique used for modern deep neural networks. To illustrate their\ngenerality, we demonstrate physical neural networks with three diverse physical\nsystems-optical, mechanical, and electrical. Physical neural networks may\nfacilitate unconventional machine learning hardware that is orders of magnitude\nfaster and more energy efficient than conventional electronic processors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:00:02 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wright", "Logan G.", ""], ["Onodera", "Tatsuhiro", ""], ["Stein", "Martin M.", ""], ["Wang", "Tianyu", ""], ["Schachter", "Darren T.", ""], ["Hu", "Zoey", ""], ["McMahon", "Peter L.", ""]]}, {"id": "2104.13467", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Shi-Yuan Ma, Logan G. Wright, Tatsuhiro Onodera, Brian\n  Richard and Peter L. McMahon", "title": "An optical neural network using less than 1 photon per multiplication", "comments": "42 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has rapidly become a widespread tool in both scientific and\ncommercial endeavors. Milestones of deep learning exceeding human performance\nhave been achieved for a growing number of tasks over the past several years,\nacross areas as diverse as game-playing, natural-language translation, and\nmedical-image analysis. However, continued progress is increasingly hampered by\nthe high energy costs associated with training and running deep neural networks\non electronic processors. Optical neural networks have attracted attention as\nan alternative physical platform for deep learning, as it has been\ntheoretically predicted that they can fundamentally achieve higher energy\nefficiency than neural networks deployed on conventional digital computers.\nHere, we experimentally demonstrate an optical neural network achieving 99%\naccuracy on handwritten-digit classification using ~3.2 detected photons per\nweight multiplication and ~90% accuracy using ~0.64 photons (~$2.4 \\times\n10^{-19}$ J of optical energy) per weight multiplication. This performance was\nachieved using a custom free-space optical processor that executes\nmatrix-vector multiplications in a massively parallel fashion, with up to ~0.5\nmillion scalar (weight) multiplications performed at the same time. Using\ncommercially available optical components and standard neural-network training\nmethods, we demonstrated that optical neural networks can operate near the\nstandard quantum limit with extremely low optical powers and still achieve high\naccuracy. Our results provide a proof-of-principle for low-optical-power\noperation, and with careful system design including the surrounding electronics\nused for data storage and control, open up a path to realizing optical\nprocessors that require only $10^{-16}$ J total energy per scalar\nmultiplication -- which is orders of magnitude more efficient than current\ndigital processors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:43:23 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Tianyu", ""], ["Ma", "Shi-Yuan", ""], ["Wright", "Logan G.", ""], ["Onodera", "Tatsuhiro", ""], ["Richard", "Brian", ""], ["McMahon", "Peter L.", ""]]}, {"id": "2104.13870", "submitter": "Yunseong Nam", "authors": "Ming Li, Jason Amini, Yunseong Nam", "title": "Two-qubit gates in a trapped-ion quantum computer by engineering\n  motional modes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A global race towards developing a gate-based, universal quantum computer\nthat one day promises to unlock the never before seen computational power has\nbegun and the biggest challenge in achieving this goal arguably is the quality\nimplementation of a two-qubit gate. In a trapped-ion quantum computer, one of\nthe leading quantum computational platforms, a two-qubit gate is typically\nimplemented by modulating the individual addressing beams that illuminate the\ntwo target ions, which, together with others, form a linear chain. The required\nmodulation, expectedly so, becomes increasingly more complex, especially as the\nquantum computer becomes larger and runs faster, complicating the control\nhardware design. Here, we develop a simple method to essentially remove the\npulse-modulation complexity at the cost of engineering the normal modes of the\nion chain. We demonstrate that the required mode engineering is possible for a\nthree ion chain, even with a trapped-ion quantum computational system built and\noptimized for a completely different mode of operations. This indicates that a\nsystem, if manufactured to target specifically for the mode-engineering based\ntwo-qubit gates, would readily be able to implement the gates without\nsignificant additional effort.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:34:48 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Li", "Ming", ""], ["Amini", "Jason", ""], ["Nam", "Yunseong", ""]]}, {"id": "2104.13983", "submitter": "Prasanna Date", "authors": "Prasanna Date, Catherine Schuman, Bill Kay, Thomas Potok", "title": "Neuromorphic Computing is Turing-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC cs.CL cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing is a non-von Neumann computing paradigm that performs\ncomputation by emulating the human brain. Neuromorphic systems are extremely\nenergy-efficient and known to consume thousands of times less power than CPUs\nand GPUs. They have the potential to drive critical use cases such as\nautonomous vehicles, edge computing and internet of things in the future. For\nthis reason, they are sought to be an indispensable part of the future\ncomputing landscape. Neuromorphic systems are mainly used for spike-based\nmachine learning applications, although there are some non-machine learning\napplications in graph theory, differential equations, and spike-based\nsimulations. These applications suggest that neuromorphic computing might be\ncapable of general-purpose computing. However, general-purpose computability of\nneuromorphic computing has not been established yet. In this work, we prove\nthat neuromorphic computing is Turing-complete and therefore capable of\ngeneral-purpose computing. Specifically, we present a model of neuromorphic\ncomputing, with just two neuron parameters (threshold and leak), and two\nsynaptic parameters (weight and delay). We devise neuromorphic circuits for\ncomputing all the {\\mu}-recursive functions (i.e., constant, successor and\nprojection functions) and all the {\\mu}-recursive operators (i.e., composition,\nprimitive recursion and minimization operators). Given that the {\\mu}-recursive\nfunctions and operators are precisely the ones that can be computed using a\nTuring machine, this work establishes the Turing-completeness of neuromorphic\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 19:25:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Date", "Prasanna", ""], ["Schuman", "Catherine", ""], ["Kay", "Bill", ""], ["Potok", "Thomas", ""]]}, {"id": "2104.14000", "submitter": "De Mi", "authors": "Zheng Chu, Pei Xiao, De Mi, Wanming Hao, Mohsen Khalily, Lie-Liang\n  Yang", "title": "A Novel Transmission Policy for Intelligent Reflecting Surface Assisted\n  Wireless Powered Sensor Networks", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel transmission policy for an intelligent reflecting\nsurface (IRS) assisted wireless powered sensor network (WPSN). An IRS is\ndeployed to enhance the performance of wireless energy transfer (WET) and\nwireless information transfer (WIT) by intelligently adjusting phase shifts of\neach reflecting elements. To achieve its self-sustainability, the IRS needs to\ncollect energy from energy station to support its control circuit operation.\nOur proposed policy for the considered WPSN is called IRS assisted\nharvest-then-transmit time switching, which is able to schedule the\ntransmission time slots by switching between energy collection and energy\nreflection modes. We study the achievable sum throughput of the proposed\ntransmission policy and investigate a joint design of the transmission time\nslots, the power allocation, as well as the discrete phase shifts of the WET\nand WIT. This formulates the problem as a mixed-integer non-linear program,\nwhich is NP-hard and non-convex. We first relax it to one with continuous phase\nshifts, and then propose a two-step approach and decompose the original problem\ninto two sub-problems. We solve the first sub-problem with respect to the phase\nshifts of the WIT in terms of closed-form expression. For the second\nsub-problem, we consider a special case without the circuit power of each\nsensor node, the Lagrange dual method and the KKT conditions are applied to\nderive the optimal closed-form transmission time slots, power allocation, and\nphase shift of the WET. Then we generalise the case with the circuit power of\neach sensor node, which can be solved via employing a semi-definite programming\nrelaxation. The optimal discrete phase shifts can be obtained by quantizing the\ncontinuous values. Numerical results demonstrate the effectiveness of the\nproposed policy and validate the beneficial role of the IRS in comparison to\nthe benchmark schemes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 20:07:37 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chu", "Zheng", ""], ["Xiao", "Pei", ""], ["Mi", "De", ""], ["Hao", "Wanming", ""], ["Khalily", "Mohsen", ""], ["Yang", "Lie-Liang", ""]]}, {"id": "2104.14433", "submitter": "Amy Marconnet", "authors": "Meghavin Bhatasana, Amy Marconnet", "title": "Machine-Learning Assisted Optimization Strategies for Phase Change\n  Materials Embedded within Electronic Packages", "comments": "13 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the latent heat of phase change materials (PCMs) can reduce the\npeak temperatures and transient variations in temperature in electronic\ndevices. But as the power levels increase, the thermal conduction pathway from\nthe heat source to the heat sink limits the effectiveness of these systems. In\nthis work, we evaluate embedding the PCM within the silicon device layer of an\nelectronic device to minimize the thermal resistance between the source and the\nPCM to minimize this thermal resistance and enhance the thermal performance of\nthe device. The geometry and material properties of the embedded PCM regions\nare optimized using a combination of parametric and machine learning\nalgorithms. For a fixed geometry, considering commercially available materials,\nSolder 174 significantly outperforms other organic and metallic PCMs. Also with\na fixed geometry, the optimal melting points to minimize the peak temperature\nis higher than the optimal melting point to minimize the amplitude of the\ntransient temperature oscillation, and both optima increase with increasing\nheater power. Extending beyond conventional optimization strategies, genetic\nalgorithms and particle swarm optimization with and without neural network\nsurrogate models are used to enable optimization of many geometric and material\nproperties. For the test case evaluated, the optimized geometries and\nproperties are similar between all ML-assisted algorithms, but the\ncomputational time depends on the technique. Ultimately, the optimized design\nwith embedded phase change materials reduces the maximum temperature rise by\n19% and the fluctuations by up to 88% compared to devices without PCM.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:20:04 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bhatasana", "Meghavin", ""], ["Marconnet", "Amy", ""]]}, {"id": "2104.14517", "submitter": "Anthony Kenyon", "authors": "Adnan Mehonic and Anthony J Kenyon", "title": "Brain-inspired computing: We need a master plan", "comments": "9 oages 4 figures. Perspectives commentary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  New computing technologies inspired by the brain promise fundamentally\ndifferent ways to process information with extreme energy efficiency and the\nability to handle the avalanche of unstructured and noisy data that we are\ngenerating at an ever-increasing rate. To realise this promise requires a brave\nand coordinated plan to bring together disparate research communities and to\nprovide them with the funding, focus and support needed. We have done this in\nthe past with digital technologies; we are in the process of doing it with\nquantum technologies; can we now do it for brain-inspired computing?\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:34:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Mehonic", "Adnan", ""], ["Kenyon", "Anthony J", ""]]}, {"id": "2104.14885", "submitter": "Dimitrios Antoniadis", "authors": "Dimitrios Antoniadis, Peilong Feng, Andrea Mifsud, Timothy G.\n  Constandinou", "title": "Open-Source Memory Compiler for Automatic RRAM Generation and\n  Verification", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The lack of open-source memory compilers in academia typically causes\nsignificant delays in research and design implementations. This paper presents\nan open-source memory compiler that is irectly integrated within the Cadence\nVirtuoso environment using physical verification tools provided by Mentor\nGraphics (Calibre). It facilitates the entire memory generation process from\nnetlist generation to layout implementation, and physical implementation\nverification. To the best of our knowledge, this is the first open-source\nmemory compiler that has been developed specifically to automate Resistive\nRandom Access Memory (RRAM) generation. RRAM holds the promise of achieving\nhigh speed, high density and non-volatility. A novel RRAM architecture,\nadditionally is proposed, and a number of generated RRAM arrays are evaluated\nto identify their worst case control line parasitics and worst case settling\ntime across the memristors of their cells. The total capacitance of lines SEL,\nN and P is 5.83 fF/cell, 3.31 fF/cell and 2.48 fF/cell respectively, while the\ntotal calculated resistance for SEL is 1.28 Ohm/cell and 0.14 Ohm/cell for both\nN and P lines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:15:55 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Antoniadis", "Dimitrios", ""], ["Feng", "Peilong", ""], ["Mifsud", "Andrea", ""], ["Constandinou", "Timothy G.", ""]]}, {"id": "2104.14915", "submitter": "Akira Hirose", "authors": "Takehiro Ichimura, Ryosho Nakane, Gouhei Tanaka and Akira Hirose", "title": "A numerical exploration of signal detector arrangement in a spin-wave\n  reservoir computing device", "comments": null, "journal-ref": "IEEE Access, 9 (2021) 72637 - 72646", "doi": "10.1109/ACCESS.2021.3079583", "report-no": null, "categories": "cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies numerically how the signal detector arrangement influences\nthe performance of reservoir computing using spin waves excited in a\nferrimagnetic garnet film. This investigation is essentially important since\nthe input information is not only conveyed but also transformed by the spin\nwaves into high-dimensional information space when the waves propagate in the\nfilm in a spatially distributed manner. This spatiotemporal dynamics realizes a\nrich reservoir-computational functionality. First, we simulate spin waves in a\nrectangular garnet film with two input electrodes to obtain spatial\ndistributions of the reservoir states in response to input signals, which are\nrepresented as spin vectors and used for a machine-learning waveform\nclassification task. The detected reservoir states are combined through readout\nconnection weights to generate a final output. We visualize the spatial\ndistribution of the weights after training to discuss the number and positions\nof the output electrodes by arranging them at grid points, equiangularly\ncircular points or at random. We evaluate the classification accuracy by\nchanging the number of the output electrodes, and find that a high accuracy\n($>$ 90\\%) is achieved with only several tens of output electrodes regardless\nof grid, circular or random arrangement. These results suggest that the spin\nwaves possess sufficiently complex and rich dynamics for this type of tasks.\nThen we investigate in which area useful information is distributed more by\narranging the electrodes locally on the chip. Finally, we show that this device\nhas generalization ability for input wave-signal frequency in a certain\nfrequency range. These results will lead to practical design of spin-wave\nreservoir devices for low-power intelligent computing in the near future.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:23:59 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ichimura", "Takehiro", ""], ["Nakane", "Ryosho", ""], ["Tanaka", "Gouhei", ""], ["Hirose", "Akira", ""]]}]