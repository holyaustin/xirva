[{"id": "1803.00254", "submitter": "Daniel Etiemble", "authors": "Daniel Etiemble (LRI)", "title": "45-year CPU evolution: one law and two equations", "comments": null, "journal-ref": "Second Workshop on Pioneering Processor Paradigms, Feb 2018,\n  Vienne, Austria", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moore's law and two equations allow to explain the main trends of CPU\nevolution since MOS technologies have been used to implement microprocessors.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 08:58:21 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Etiemble", "Daniel", "", "LRI"]]}, {"id": "1803.02490", "submitter": "Song Chen", "authors": "Song Chen, Qi Xu, Bei Yu", "title": "Adaptive 3D-IC TSV Fault Tolerance Structure Generation", "comments": "Submitted to IEEE Trans. on CAD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In three dimensional integrated circuits (3D-ICs), through silicon via (TSV)\nis a critical technique in providing vertical connections. However, the yield\nand reliability is one of the key obstacles to adopt the TSV based 3D-ICs\ntechnology in industry. Various fault-tolerance structures using spare TSVs to\nrepair faulty functional TSVs have been proposed in literature for yield and\nreliability enhancement, but a valid structure cannot always be found due to\nthe lack of effective generation methods for fault-tolerance structures. In\nthis paper, we focus on the problem of adaptive fault-tolerance structure\ngeneration. Given the relations between functional TSVs and spare TSVs, we\nfirst calculate the maximum number of tolerant faults in each TSV group. Then\nwe propose an integer linear programming (ILP) based model to construct\nadaptive fault-tolerance struc- ture with minimal multiplexer delay overhead\nand hardware cost. We further develop a speed-up technique through efficient\nmin-cost-max-flow (MCMF) model. All the proposed method- ologies are embedded\nin a top-down TSV planning framework to form functional TSV groups and generate\nadaptive fault- tolerance structures. Experimental results show that, compared\nwith state-of-the-art, the number of spare TSVs used for fault tolerance can be\neffectively reduced.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 00:37:24 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Chen", "Song", ""], ["Xu", "Qi", ""], ["Yu", "Bei", ""]]}, {"id": "1803.02657", "submitter": "Subho Sankar Banerjee", "authors": "Subho S. Banerjee, Mohamed El-Hadedy, Jong Bin Lim, Zbigniew T.\n  Kalbarczyk, Deming Chen, Steve Lumetta, Ravishankar K. Iyer", "title": "ASAP: Accelerated Short-Read Alignment on Programmable Hardware", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2018.2875733", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of high-throughput sequencing machines ensures rapid\ngeneration of up to billions of short nucleotide fragments in a short period of\ntime. This massive amount of sequence data can quickly overwhelm today's\nstorage and compute infrastructure. This paper explores the use of hardware\nacceleration to significantly improve the runtime of short-read alignment, a\ncrucial step in preprocessing sequenced genomes. We focus on the Levenshtein\ndistance (edit-distance) computation kernel and propose the ASAP accelerator,\nwhich utilizes the intrinsic delay of circuits for edit-distance computation\nelements as a proxy for computation. Our design is implemented on an Xilinx\nVirtex 7 FPGA in an IBM POWER8 system that uses the CAPI interface for cache\ncoherence across the CPU and FPGA. Our design is $200\\times$ faster than the\nequivalent C implementation of the kernel running on the host processor and\n$2.2\\times$ faster for an end-to-end alignment tool for 120-150 base-pair\nshort-read sequences. Further the design represents a $3760\\times$ improvement\nover the CPU in performance/Watt terms.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:54:28 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:07:30 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Banerjee", "Subho S.", ""], ["El-Hadedy", "Mohamed", ""], ["Lim", "Jong Bin", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Chen", "Deming", ""], ["Lumetta", "Steve", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1803.02660", "submitter": "Vinamra Benara", "authors": "Vinamra Benara, Ziaul Choudhury, Suresh Purini, Uday Bondhugula", "title": "Synthesizing Power and Area Efficient Image Processing Pipelines on\n  FPGAs using Customized Bit-widths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level synthesis (HLS) has received significant attention in recent\nyears, improving programmability for FPGAs. PolyMage is a domain-specific\nlanguage (DSL) for image processing pipelines that also has a HLS backend to\ntranslate the input DSL into an equivalent circuit that can be synthesized on\nFPGAs, while leveraging an HLS suite. The data at each stage of a pipeline is\nstored using a fixed-point data type (alpha,beta) where alpha and beta denote\nthe number of integral and fractional bits. The power and area savings while\nperforming arithmetic operations on fixed-point data type is known to be\nsignificant over using floating point. In this paper, we first propose an\ninterval-arithmetic based range analysis (alpha-analysis) algorithm to estimate\nthe number of bits required to store the integral part of the data at each\nstage of an image processing pipeline. The analysis algorithm uses the\nhomogeneity of pixel signals at each stage to cluster them and perform a\ncombined range analysis. Secondly, we propose a software architecture for\neasily deploying any kind of interval/affine arithmetic based range analyses in\nthe DSL compiler. Thirdly, we propose a new range analysis technique using\nSatisfiability Modulo Theory (SMT) solvers, and show that the range estimates\nobtained through it are very close to the lower bounds obtained through\nprofile-driven analysis.We evaluated our bitwidth analysis algorithms on four\nimage processing benchmarks listed in the order of increasing complexity:\nUnsharp Mask, Down-Up Sampling, Harris Corner Detection and Horn-Schunck\nOptical Flow. For example, on Optical Flow, the interval analysis based\napproach showed an 1.4x and 1.14x improvement on area and power metrics over\nfloating-point representation respectively; whereas the SMT solver based\napproach showed 2.49x and 1.58x improvement on area and power metrics when\ncompared to interval analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 16:04:28 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 11:25:01 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 22:09:40 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Benara", "Vinamra", ""], ["Choudhury", "Ziaul", ""], ["Purini", "Suresh", ""], ["Bondhugula", "Uday", ""]]}, {"id": "1803.03331", "submitter": "Hassan Rabah", "authors": "Marwa Hannachi and Abdesslam B. Abdelali and Hassan Rabah and\n  Abdellatif Mtibaa", "title": "Efficient reconfigurable regions management method for adaptive and\n  dynamic FPGA based systems", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive systems based on field programmable gate array (FPGA) architectures\ncan greatly benefi t fro m th e high degree of flexibility offered by dynamic\npartial reconfiguration (DPR). By using this technique, hardware tasks can be\nloaded and reloaded on demand depending on the system requirements. In this\npaper, we propose to use the DPR for dynamic and adaptive implementation of a\nvideo cut detection application based on the MPEG-7 color structure descriptor\n(CSD). In the proposed implementation, different scenarios have been tested.\nDepending on the application and the system requirements, the CSD module can be\nloaded at any time with variable module size (corresponding to different\nversion of the CSD) and allocated in different possible reconfigurable regions.\nSuch implementation entails many problems related to communication, relocation\nand reconfigurable region management. We will demonstrate how we have made this\nimplementation successful through the use of an appropriate design method. This\nmethod was proposed to support the management of variable-size hardware tasks\non DPR FPGAs based adaptive systems. It permits to efficiently handle the\nreconfigurable area and to relocate the reconfigurable modules in different\npossible regions. The implementation results for the considered application\nshow an important optimization in terms of configuration time (until 66 %) and\nmemory storage (until 87 %) and an efficient hardware resources utilization\nrate (until 90%).\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 23:08:21 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Hannachi", "Marwa", ""], ["Abdelali", "Abdesslam B.", ""], ["Rabah", "Hassan", ""], ["Mtibaa", "Abdellatif", ""]]}, {"id": "1803.03748", "submitter": "Song Chen", "authors": "Song Chen, Jinglei Huang, Xiaodong Xu, and Qi Xu", "title": "Integrated Optimization of Partitioning, Scheduling and Floorplanning\n  for Partially Dynamically Reconfigurable Systems", "comments": "14 pages, accepted by IEEE Transactions on computer-aided design for\n  review (A 4-page preliminary version was published on ACM GLSVLSI 2017.)", "journal-ref": null, "doi": "10.1109/TCAD.2018.2883982", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confronted with the challenge of high performance for applications and the\nrestriction of hardware resources for field-programmable gate arrays (FPGAs),\npartial dynamic reconfiguration (PDR) technology is anticipated to accelerate\nthe reconfiguration process and alleviate the device shortage. In this paper,\nwe propose an integrated optimization framework for task partitioning,\nscheduling and floorplanning on partially dynamically reconfigurable FPGAs. The\npartitions, schedule, and floorplan of the tasks are represented by the\npartitioned sequence triple P-ST (PS,QS,RS), where (PS,QS) is a hybrid nested\nsequence pair (HNSP) for representing the spatial and temporal partitions, as\nwell as the floorplan, and RS is the partitioned dynamic configuration order of\nthe tasks. The floorplanning and scheduling of task modules can be computed\nfrom the partitioned sequence triple P-ST in O(n^2) time. To integrate the\nexploration of the scheduling and floorplanning design space, we use a\nsimulated annealing-based search engine and elaborate a perturbation method,\nwhere a randomly chosen task module is removed from the partition sequence\ntriple and then inserted back into a proper position selected from all the\n(n+1)^3 possible combinations of partitions, schedule and floorplan. The\nexperimental results demonstrate the efficiency and effectiveness of the\nproposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 03:23:10 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 12:57:17 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Chen", "Song", ""], ["Huang", "Jinglei", ""], ["Xu", "Xiaodong", ""], ["Xu", "Qi", ""]]}, {"id": "1803.03790", "submitter": "Junzhong Shen", "authors": "Junzhong Shen, Yuran Qiao, You Huang, Mei Wen, Chunyuan Zhang", "title": "Towards a Multi-array Architecture for Accelerating Large-scale Matrix\n  Multiplication on FPGAs", "comments": "This paper has been accepet by IEEE International Symposium on\n  Circuits and Systems (ISCAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale floating-point matrix multiplication is a fundamental kernel in\nmany scientific and engineering applications. Most existing work only focus on\naccelerating matrix multiplication on FPGA by adopting a linear systolic array.\nThis paper towards the extension of this architecture by proposing a scalable\nand highly configurable multi-array architecture. In addition, we propose a\nwork-stealing scheme to ensure the equality in the workload partition among\nmultiple linear arrays. Furthermore, an analytical model is developed to\ndetermine the optimal design parameters. Experiments on a real-life\nconvolutional neural network (CNN) show that we can obtain the optimal\nextension of the linear array architecture.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 10:33:28 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Shen", "Junzhong", ""], ["Qiao", "Yuran", ""], ["Huang", "You", ""], ["Wen", "Mei", ""], ["Zhang", "Chunyuan", ""]]}, {"id": "1803.03951", "submitter": "Ofir Shwartz", "authors": "Ofir Shwartz, Yitzhak Birk", "title": "The Secure Machine: Efficient Secure Execution On Untrusted Platforms", "comments": "A PhD thesis, to appear at the Technion's library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present the Secure Machine, SeM for short, a CPU architecture\nextension for secure computing. SeM uses a small amount of in-chip additional\nhardware that monitors key communication channels inside the CPU chip, and only\nacts when required. SeM provides confidentiality and integrity for a secure\nprogram without trusting the platform software or any off-chip hardware. SeM\nsupports existing binaries of single- and multi-threaded applications running\non single- or multi-core, multi-CPU. The performance reduction caused by it is\nonly few percent, most of which is due to the memory encryption layer that is\ncommonly used in many secure architectures.\n  We also developed SeM-Prepare, a software tool that automatically instruments\nexisting applications (binaries) with additional instructions so they can be\nsecurely executed on our architecture without requiring any programming efforts\nor the availability of the desired program`s source code.\n  To enable secure data sharing in shared memory environments, we developed\nSecure Distributed Shared Memory (SDSM), an efficient (time and memory)\nalgorithm for allowing thousands of compute nodes to share data securely while\nrunning on an untrusted computing environment. SDSM shows a negligible\nreduction in performance, and it requires negligible and hardware resources. We\ndeveloped Distributed Memory Integrity Trees, a method for enhancing single\nnode integrity trees for preserving the integrity of a distributed application\nrunning on an untrusted computing environment. We show that our method is\napplicable to existing single node integrity trees such as Merkle Tree, Bonsai\nMerkle Tree, and Intel`s SGX memory integrity engine. All these building blocks\nmay be used together to form a practical secure system, and some can be used in\nconjunction with other secure systems.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 12:09:27 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Shwartz", "Ofir", ""], ["Birk", "Yitzhak", ""]]}, {"id": "1803.04783", "submitter": "Fabian Schuiki", "authors": "Fabian Schuiki, Michael Schaffner, Frank K. G\\\"urkaynak, Luca Benini", "title": "A Scalable Near-Memory Architecture for Training Deep Neural Networks on\n  Large In-Memory Datasets", "comments": "14 pages, submitted to IEEE Transactions on Computers journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most investigations into near-memory hardware accelerators for deep neural\nnetworks have primarily focused on inference, while the potential of\naccelerating training has received relatively little attention so far. Based on\nan in-depth analysis of the key computational patterns in state-of-the-art\ngradient-based training methods, we propose an efficient near-memory\nacceleration engine called NTX that can be used to train state-of-the-art deep\nconvolutional neural networks at scale. Our main contributions are: (i) a loose\ncoupling of RISC-V cores and NTX co-processors reducing offloading overhead by\n7x over previously published results; (ii) an optimized IEEE754 compliant data\npath for fast high-precision convolutions and gradient propagation; (iii)\nevaluation of near-memory computing with NTX embedded into residual area on the\nLogic Base die of a Hybrid Memory Cube; and (iv) a scaling analysis to meshes\nof HMCs in a data center scenario. We demonstrate a 2.7x energy efficiency\nimprovement of NTX over contemporary GPUs at 4.4x less silicon area, and a\ncompute performance of 1.2 Tflop/s for training large state-of-the-art networks\nwith full floating-point precision. At the data center scale, a mesh of NTX\nachieves above 95% parallel and energy efficiency, while providing 2.1x energy\nsavings or 3.1x performance improvement over a GPU-based system.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 09:28:22 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 08:28:37 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 14:56:53 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 10:25:49 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Schuiki", "Fabian", ""], ["Schaffner", "Michael", ""], ["G\u00fcrkaynak", "Frank K.", ""], ["Benini", "Luca", ""]]}, {"id": "1803.04786", "submitter": "Prasanna Kansakar", "authors": "Prasanna Kansakar and Arslan Munir", "title": "A Design Space Exploration Methodology for Parameter Optimization in\n  Multicore Processors", "comments": "Published in IEEE Transactions on Parallel and Distributed Systems.\n  arXiv admin note: text overlap with arXiv:1802.05123", "journal-ref": "IEEE Transactions on Parallel and Distributed Systems ( Volume:\n  29, Issue: 1, Jan. 1 2018 ) Page(s): 2 - 15", "doi": "10.1109/TPDS.2017.2745580", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for application-specific design of multicore/manycore processing\nplatforms is evident with computing systems finding use in diverse application\ndomains. In order to tailor multicore/manycore processors for application\nspecific requirements, a multitude of processor design parameters have to be\ntuned accordingly which involves rigorous and extensive design space\nexploration over large search spaces. In this paper, we propose an efficient\nmethodology for design space exploration. We evaluate our methodology over two\nsearch spaces - small and large, using a cycle-accurate simulator (ESESC) and a\nstandard set of PARSEC and SPLASH-2 benchmarks. For the smaller design space,\nwe compare results obtained from our design space exploration methodology with\nresults obtained from fully exhaustive search. The results show that solution\nquality obtained from our methodology are within 1.35% - 3.69% of the results\nobtained from fully exhaustive search while only exploring 2.74% - 3% of the\ndesign space. For larger design space, we compare solution quality of different\nresults obtained by varying the number of tunable processor design parameters\nincluded in the exhaustive search phase of our methodology. The results show\nthat including more number of tunable parameters in the exhaustive search phase\nof our methodology greatly improves solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:43:05 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Kansakar", "Prasanna", ""], ["Munir", "Arslan", ""]]}, {"id": "1803.04862", "submitter": "Vincent T. Lee", "authors": "Vincent T. Lee, Armin Alaghi, Luis Ceze", "title": "Correlation Manipulating Circuits for Stochastic Computing", "comments": "6 pages, 5 figures, 4 tables, Design, Automation and Test in Europe\n  Conference and Exhibition (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic computing (SC) is an emerging computing technique that promises\nhigh density, low power, and error tolerant solutions. In SC, values are\nencoded as unary bitstreams and SC arithmetic circuits operate on one or more\nbitstreams. In many cases, the input bitstreams must be correlated or\nuncorrelated for SC arithmetic to produce accurate results. As a result, a key\nchallenge for designing SC accelerators is manipulating the impact of\ncorrelation across SC operations. This paper presents and evaluates a set of\nnovel correlation manipulating circuits to manage correlation in SC\ncomputation: a synchronizer, desynchronizer, and decorrelator. We then use\nthese circuits to propose improved SC maximum, minimum, and saturating adder\ndesigns. Compared to existing correlation manipulation techniques, our circuits\nare more accurate and up to 3x more energy efficient. In the context of an\nimage processing pipeline, these circuits can reduce the total energy\nconsumption by up to 24%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:17:22 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Lee", "Vincent T.", ""], ["Alaghi", "Armin", ""], ["Ceze", "Luis", ""]]}, {"id": "1803.05131", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James", "title": "Feature extraction without learning in an analog Spatial Pooler\n  memristive-CMOS circuit design of Hierarchical Temporal Memory", "comments": null, "journal-ref": "Analog Integrated Circuits and Signal Processing, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a neuromorphic algorithm that emulates\nsparsity, hierarchy and modularity resembling the working principles of\nneocortex. Feature encoding is an important step to create sparse binary\npatterns. This sparsity is introduced by the binary weights and random weight\nassignment in the initialization stage of the HTM. We propose the alternative\ndeterministic method for the HTM initialization stage, which connects the HTM\nweights to the input data and preserves natural sparsity of the input\ninformation. Further, we introduce the hardware implementation of the\ndeterministic approach and compare it to the traditional HTM and existing\nhardware implementation. We test the proposed approach on the face recognition\nproblem and show that it outperforms the conventional HTM approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:18:47 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1803.05132", "submitter": "Alex James Dr", "authors": "Aidana Irmanova, Alex Pappachen James", "title": "Neuron inspired data encoding memristive multi-level memory cell", "comments": null, "journal-ref": "Analog Integrated Circuits and Signal Processing, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping neuro-inspired algorithms to sensor backplanes of on-chip hardware\nrequire shifting the signal processing from digital to the analog domain,\ndemanding memory technologies beyond conventional CMOS binary storage units.\nUsing memristors for building analog data storage is one of the promising\napproaches amongst emerging non-volatile memory technologies. Recently, a\nmemristive multi-level memory (MLM) cell for storing discrete analog values has\nbeen developed in which memory system is implemented combining memristors in\nvoltage divider configuration. In given example, the memory cell of 3 sub-cells\nwith a memristor in each was programmed to store ternary bits which overall\nachieved 10 and 27 discrete voltage levels. However, for further use of\nproposed memory cell in analog signal processing circuits data encoder is\nrequired to generate control voltages for programming memristors to store\ndiscrete analog values. In this paper, we present the design and performance\nanalysis of data encoder that generates write pattern signals for 10 level\nmemristive memory.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:21:33 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Irmanova", "Aidana", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1803.05320", "submitter": "Farhad Merchant", "authors": "Farhad Merchant, Tarun Vatwani, Anupam Chattopadhyay, Soumyendu Raha,\n  S K Nandy, Ranjani Narayan, and Rainer Leupers", "title": "Efficient Realization of Givens Rotation through Algorithm-Architecture\n  Co-design for Acceleration of QR Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient realization of Generalized Givens Rotation (GGR) based\nQR factorization that achieves 3-100x better performance in terms of\nGflops/watt over state-of-the-art realizations on multicore, and General\nPurpose Graphics Processing Units (GPGPUs). GGR is an improvement over\nclassical Givens Rotation (GR) operation that can annihilate multiple elements\nof rows and columns of an input matrix simultaneously. GGR takes 33% lesser\nmultiplications compared to GR. For custom implementation of GGR, we identify\nmacro operations in GGR and realize them on a Reconfigurable Data-path (RDP)\ntightly coupled to pipeline of a Processing Element (PE). In PE, GGR attains\nspeed-up of 1.1x over Modified Householder Transform (MHT) presented in the\nliterature. For parallel realization of GGR, we use REDEFINE, a scalable\nmassively parallel Coarse-grained Reconfigurable Architecture, and show that\nthe speed-up attained is commensurate with the hardware resources in REDEFINE.\nGGR also outperforms General Matrix Multiplication (gemm) by 10% in-terms of\nGflops/watt which is counter-intuitive.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 14:41:52 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 08:41:53 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Merchant", "Farhad", ""], ["Vatwani", "Tarun", ""], ["Chattopadhyay", "Anupam", ""], ["Raha", "Soumyendu", ""], ["Nandy", "S K", ""], ["Narayan", "Ranjani", ""], ["Leupers", "Rainer", ""]]}, {"id": "1803.05849", "submitter": "Renzo Andri", "authors": "Andrawes Al Bahou, Geethan Karunaratne, Renzo Andri, Lukas Cavigelli,\n  Luca Benini", "title": "XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying state-of-the-art CNNs requires power-hungry processors and off-chip\nmemory. This precludes the implementation of CNNs in low-power embedded\nsystems. Recent research shows CNNs sustain extreme quantization, binarizing\ntheir weights and intermediate feature maps, thereby saving 8-32\\x memory and\ncollapsing energy-intensive sum-of-products into XNOR-and-popcount operations.\n  We present XNORBIN, an accelerator for binary CNNs with computation tightly\ncoupled to memory for aggressive data reuse. Implemented in UMC 65nm technology\nXNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of\n2.0 TOp/s/MGE at 0.8 V.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:41:28 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Bahou", "Andrawes Al", ""], ["Karunaratne", "Geethan", ""], ["Andri", "Renzo", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1803.05900", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris, Alexandros Kouris, Christos-Savvas Bouganis", "title": "Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey\n  and Future Directions", "comments": "Accepted for publication at the ACM Computing Surveys (CSUR) journal,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, Convolutional Neural Networks (CNNs) have demonstrated\nstate-of-the-art performance in various Artificial Intelligence tasks. To\naccelerate the experimentation and development of CNNs, several software\nframeworks have been released, primarily targeting power-hungry CPUs and GPUs.\nIn this context, reconfigurable hardware in the form of FPGAs constitutes a\npotential alternative platform that can be integrated in the existing deep\nlearning ecosystem to provide a tunable balance between performance, power\nconsumption and programmability. In this paper, a survey of the existing\nCNN-to-FPGA toolflows is presented, comprising a comparative study of their key\ncharacteristics which include the supported applications, architectural\nchoices, design space exploration methods and achieved performance. Moreover,\nmajor challenges and objectives introduced by the latest trends in CNN\nalgorithmic research are identified and presented. Finally, a uniform\nevaluation methodology is proposed, aiming at the comprehensive, complete and\nin-depth evaluation of CNN-to-FPGA toolflows.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:58:19 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Kouris", "Alexandros", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1803.06068", "submitter": "Bahar Asgari", "authors": "Bahar Asgari, Saibal Mukhopadhyay, Sudhakar Yalamanchili", "title": "Memory Slices: A Modular Building Block for Scalable, Intelligent Memory\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reduction in feature size makes computation cheaper in terms of\nlatency, area, and power consumption, performance of emerging data-intensive\napplications is determined by data movement. These trends have introduced the\nconcept of scalability as reaching a desirable performance per unit cost by\nusing as few number of units as possible. Many proposals have moved compute\ncloser to the memory. However, these efforts ignored maintaining a balance\nbetween bandwidth and compute rate of an architecture, with those of\napplications, which is a key principle in designing scalable large systems.\nThis paper proposes the use of memory slices, a modular building block for\nscalable memory systems integrated with compute, in which performance scales\nwith memory size (and volume of data). The slice architecture utilizes a\nprogrammable memory interface feeding a systolic compute engine with high reuse\nrate. The modularity feature of slice-based systems is exploited with a\npartitioning and data mapping strategy across allocated memory slices where\ntraining performance scales with the data size. These features enable shifting\nthe most pressure to cheap compute units rather than expensive memory accesses\nor transfers via interconnection network. An application of the memory slices\nto a scale-out memory system is accelerating the training of recurrent,\nconvolutional, and hybrid neural networks (RNNs and RNNs+CNN) that are forming\ncloud workloads. The results of our cycle-level simulations show that memory\nslices exhibits a superlinear speedup when the number of slices increases.\nFurthermore, memory slices improve power efficiency to 747 GFLOPs/J for\ntraining LSTMs. While our current evaluation uses memory slices with 3D\npackaging, a major value is that slices can also be constructed with a variety\nof packaging options, for example with DDR-based memory units.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 03:39:45 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Asgari", "Bahar", ""], ["Mukhopadhyay", "Saibal", ""], ["Yalamanchili", "Sudhakar", ""]]}, {"id": "1803.06185", "submitter": "Stuart Biles", "authors": "Nigel Stephens, Stuart Biles, Matthias Boettcher, Jacob Eapen, Mbou\n  Eyole, Giacomo Gabrielli, Matt Horsnell, Grigorios Magklis, Alejandro\n  Martinez, Nathanael Premillieu, Alastair Reid, Alejandro Rico, Paul Walker", "title": "The ARM Scalable Vector Extension", "comments": "8 pages, 8 figures, IEEE Micro paper", "journal-ref": "IEEE Micro ( Volume: 37, Issue: 2, Mar.-Apr. 2017 )", "doi": "10.1109/MM.2017.35", "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the ARM Scalable Vector Extension (SVE). Several goals\nguided the design of the architecture. First was the need to extend the vector\nprocessing capability associated with the ARM AArch64 execution state to better\naddress the computational requirements in domains such as high-performance\ncomputing, data analytics, computer vision, and machine learning. Second was\nthe desire to introduce an extension that can scale across multiple\nimplementations, both now and into the future, allowing CPU designers to choose\nthe vector length most suitable for their power, performance, and area targets.\nFinally, the architecture should avoid imposing a software development cost as\nthe vector length changes and where possible reduce it by improving the reach\nof compiler auto-vectorization technologies. SVE achieves these goals. It\nallows implementations to choose a vector register length between 128 and 2,048\nbits. It supports a vector-length agnostic programming model that lets code run\nand scale automatically across all vector lengths without recompilation.\nFinally, it introduces several innovative features that begin to overcome some\nof the traditional barriers to autovectorization.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 12:16:36 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Stephens", "Nigel", ""], ["Biles", "Stuart", ""], ["Boettcher", "Matthias", ""], ["Eapen", "Jacob", ""], ["Eyole", "Mbou", ""], ["Gabrielli", "Giacomo", ""], ["Horsnell", "Matt", ""], ["Magklis", "Grigorios", ""], ["Martinez", "Alejandro", ""], ["Premillieu", "Nathanael", ""], ["Reid", "Alastair", ""], ["Rico", "Alejandro", ""], ["Walker", "Paul", ""]]}, {"id": "1803.06305", "submitter": "Zhe Li", "authors": "Shuo Wang, Zhe Li, Caiwen Ding, Bo Yuan, Yanzhi Wang, Qinru Qiu, Yun\n  Liang", "title": "C-LSTM: Enabling Efficient LSTM using Structured Compression Techniques\n  on FPGAs", "comments": "Proceedings of the 2018 ACM/SIGDA International Symposium on\n  Field-Programmable Gate Arrays", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant accuracy improvement has been achieved for acoustic\nrecognition systems by increasing the model size of Long Short-Term Memory\n(LSTM) networks. Unfortunately, the ever-increasing size of LSTM model leads to\ninefficient designs on FPGAs due to the limited on-chip resources. The previous\nwork proposes to use a pruning based compression technique to reduce the model\nsize and thus speedups the inference on FPGAs. However, the random nature of\nthe pruning technique transforms the dense matrices of the model to highly\nunstructured sparse ones, which leads to unbalanced computation and irregular\nmemory accesses and thus hurts the overall performance and energy efficiency.\n  In contrast, we propose to use a structured compression technique which could\nnot only reduce the LSTM model size but also eliminate the irregularities of\ncomputation and memory accesses. This approach employs block-circulant instead\nof sparse matrices to compress weight matrices and reduces the storage\nrequirement from $\\mathcal{O}(k^2)$ to $\\mathcal{O}(k)$. Fast Fourier Transform\nalgorithm is utilized to further accelerate the inference by reducing the\ncomputational complexity from $\\mathcal{O}(k^2)$ to\n$\\mathcal{O}(k\\text{log}k)$. The datapath and activation functions are\nquantized as 16-bit to improve the resource utilization. More importantly, we\npropose a comprehensive framework called C-LSTM to automatically optimize and\nimplement a wide range of LSTM variants on FPGAs. According to the experimental\nresults, C-LSTM achieves up to 18.8X and 33.5X gains for performance and energy\nefficiency compared with the state-of-the-art LSTM implementation under the\nsame experimental setup, and the accuracy degradation is very small.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:19:37 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Shuo", ""], ["Li", "Zhe", ""], ["Ding", "Caiwen", ""], ["Yuan", "Bo", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""], ["Liang", "Yun", ""]]}, {"id": "1803.06617", "submitter": "Aaron Smith", "authors": "Jan Gray and Aaron Smith", "title": "Towards an Area-Efficient Implementation of a High ILP EDGE Soft\n  Processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-order scalar RISC architectures have been the dominant paradigm in FPGA\nsoft processor design for twenty years. Prior out-of-order superscalar\nimplementations have not exhibited competitive area or absolute performance.\nThis paper describes a new way to build fast and area-efficient out-of-order\nsuperscalar soft processors by utilizing an Explicit Data Graph Execution\n(EDGE) instruction set architecture. By carefully mapping the EDGE\nmicroarchitecture, and in particular, its dataflow instruction scheduler, we\ndemonstrate the feasibility of an out-of-order FPGA architecture. Two scheduler\ndesign alternatives are compared.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 07:18:58 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Gray", "Jan", ""], ["Smith", "Aaron", ""]]}, {"id": "1803.06913", "submitter": "Anirban Nag", "authors": "Anirban Nag, Ali Shafiee, Rajeev Balasubramonian, Vivek Srikumar and\n  Naveen Muralimanohar", "title": "Newton: Gravitating Towards the Physical Limits of Crossbar Acceleration", "comments": "13 pages with Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have designed accelerators for Convolutional Neural\nNetworks (CNNs). While digital accelerators have relied on near data\nprocessing, analog accelerators have further reduced data movement by\nperforming in-situ computation. Recent works take advantage of highly parallel\nanalog in-situ computation in memristor crossbars to accelerate the many\nvector-matrix multiplication operations in CNNs. However, these in-situ\naccelerators have two significant short-comings that we address in this work.\nFirst, the ADCs account for a large fraction of chip power and area. Second,\nthese accelerators adopt a homogeneous design where every resource is\nprovisioned for the worst case. By addressing both problems, the new\narchitecture, Newton, moves closer to achieving optimal energy-per-neuron for\ncrossbar accelerators.\n  We introduce multiple new techniques that apply at different levels of the\ntile hierarchy. Two of the techniques leverage heterogeneity: one adapts ADC\nprecision based on the requirements of every sub-computation (with zero impact\non accuracy), and the other designs tiles customized for convolutions or\nclassifiers. Two other techniques rely on divide-and-conquer numeric algorithms\nto reduce computations and ADC pressure. Finally, we place constraints on how a\nworkload is mapped to tiles, thus helping reduce resource provisioning in\ntiles. For a wide range of CNN dataflows and structures, Newton achieves a 77%\ndecrease in power, 51% improvement in energy efficiency, and 2.2x higher\nthroughput/area, relative to the state-of-the-art ISAAC accelerator.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 05:06:57 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Nag", "Anirban", ""], ["Shafiee", "Ali", ""], ["Balasubramonian", "Rajeev", ""], ["Srikumar", "Vivek", ""], ["Muralimanohar", "Naveen", ""]]}, {"id": "1803.06955", "submitter": "Ulya R. Karpuzcu", "authors": "Alexandra Ferreron, Jesus Alastruey-Benede, Dario Suarez-Gracia, Ulya\n  R. Karpuzcu", "title": "AISC: Approximate Instruction Set Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes the case for a single-ISA heterogeneous computing platform,\nAISC, where each compute engine (be it a core or an accelerator) supports a\ndifferent subset of the very same ISA. An ISA subset may not be functionally\ncomplete, but the union of the (per compute engine) subsets renders a\nfunctionally complete, platform-wide single ISA. Tailoring the\nmicroarchitecture of each compute engine to the subset of the ISA that it\nsupports can easily reduce hardware complexity. At the same time, the energy\nefficiency of computing can improve by exploiting algorithmic noise tolerance:\nby mapping code sequences that can tolerate (any potential inaccuracy induced\nby) the incomplete ISA-subsets to the corresponding compute engines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:36:12 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Ferreron", "Alexandra", ""], ["Alastruey-Benede", "Jesus", ""], ["Suarez-Gracia", "Dario", ""], ["Karpuzcu", "Ulya R.", ""]]}, {"id": "1803.06958", "submitter": "Rachata Ausavarungnirun", "authors": "Rachata Ausavarungnirun", "title": "Techniques for Shared Resource Management in Systems with Throughput\n  Processors", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continued growth of the computational capability of throughput processors\nhas made throughput processors the platform of choice for a wide variety of\nhigh performance computing applications. Graphics Processing Units (GPUs) are a\nprime example of throughput processors that can deliver high performance for\napplications ranging from typical graphics applications to general-purpose data\nparallel (GPGPU) applications. However, this success has been accompanied by\nnew performance bottlenecks throughout the memory hierarchy of GPU-based\nsystems. We identify and eliminate performance bottlenecks caused by major\nsources of interference throughout the memory hierarchy.\n  We introduce changes to the memory hierarchy for systems with GPUs that allow\nthe memory hierarchy to be aware of both CPU and GPU applications'\ncharacteristics. We introduce mechanisms to dynamically analyze different\napplications' characteristics and propose four major changes throughout the\nmemory hierarchy. We propose changes to the cache management and memory\nscheduling mechanisms to mitigate intra-application interference in GPGPU\napplications. We propose changes to the memory controller design and its\nscheduling policy to mitigate inter-application interference in heterogeneous\nCPU-GPU systems. We redesign the MMU and the memory hierarchy in GPUs to be\naware of ddress-translation data in order to mitigate the inter-address-space\ninterference. We introduce a hardware-software cooperative technique that\nmodifies the memory allocation policy to enable large page support in order to\nfurther reduce the inter-address-space interference at the shared Translation\nLookaside Buffer (TLB). Our evaluations show that the GPU-aware cache and\nmemory management techniques proposed in this dissertation are effective at\nmitigating the interference caused by GPUs on current and future GPU-based\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:41:40 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ausavarungnirun", "Rachata", ""]]}, {"id": "1803.07613", "submitter": "Radhika Jagtap", "authors": "Radhika Jagtap, Matthias Jung, Wendy Elsasser, Christian Weis, Andreas\n  Hansson, Norbert Wehn", "title": "Integrating DRAM Power-Down Modes in gem5 and Quantifying their Impact", "comments": null, "journal-ref": "In Proceedings of MEMSYS 2017, Alexandria, VA, USA, October 2,\n  2017, 10 pages, ACM", "doi": "10.1145/3132402.3132444", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across applications, DRAM is a significant contributor to the overall system\npower, with the DRAM access energy per bit up to three orders of magnitude\nhigher compared to on-chip memory accesses. To improve the power efficiency,\nDRAM technology incorporates multiple power-down modes, each with different\ntrade-offs between achievable power savings and performance impact due to entry\nand exit delay requirements. Accurate modeling of these low power modes and\nentry and exit control is crucial to analyze the trade-offs across controller\nconfigurations and workloads with varied memory access characteristics. To\naddress this, we integrate the power-down modes into the DRAM controller model\nin the open-source simulator gem5. This is the first publicly available\nfull-system simulator with DRAM power-down modes, providing the research\ncommunity a tool for DRAM power analysis for a breadth of use cases. We\nvalidate the power-down functionality with sweep tests, which trigger defined\nmemory access characteristics. We further evaluate the model with real HPC\nworkloads, illustrating the value of integrating low power functionality into a\nfull system simulator.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:22:27 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Jagtap", "Radhika", ""], ["Jung", "Matthias", ""], ["Elsasser", "Wendy", ""], ["Weis", "Christian", ""], ["Hansson", "Andreas", ""], ["Wehn", "Norbert", ""]]}, {"id": "1803.09584", "submitter": "Radhika Jagtap", "authors": "Alexandra Ferreron, Radhika Jagtap, Sascha Bischoff, Roxana Rusitoru", "title": "Crossing the Architectural Barrier: Evaluating Representative Regions of\n  Parallel HPC Applications", "comments": "2017 IEEE International Symposium on Performance Analysis of Systems\n  and Software (ISPASS)", "journal-ref": null, "doi": "10.1109/ISPASS.2017.7975275", "report-no": null, "categories": "cs.PF cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exascale computing will get mankind closer to solving important social,\nscientific and engineering problems. Due to high prototyping costs, High\nPerformance Computing (HPC) system architects make use of simulation models for\ndesign space exploration and hardware-software co-design. However, as HPC\nsystems reach exascale proportions, the cost of simulation increases, since\nsimulators themselves are largely single-threaded. Tools for selecting\nrepresentative parts of parallel applications to reduce running costs are\nwidespread, e.g., BarrierPoint achieves this by analysing, in simulation,\nabstract characteristics such as basic blocks and reuse distances. However,\narchitectures new to HPC have a limited set of tools available.\n  In this work, we provide an independent cross-architectural evaluation on\nreal hardware - across Intel and ARM - of the BarrierPoint methodology, when\napplied to parallel HPC proxy applications. We present both cases: when the\nmethodology can be applied and when it cannot. In the former case, results show\nthat we can predict the performance of full application execution by running\nshorter representative sections. In the latter case, we dive into the\nunderlying issues and suggest improvements. We demonstrate a total simulation\ntime reduction of up to 178x, whilst keeping the error below 2.3% for both\ncycles and instructions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:40:03 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Ferreron", "Alexandra", ""], ["Jagtap", "Radhika", ""], ["Bischoff", "Sascha", ""], ["Rusitoru", "Roxana", ""]]}, {"id": "1803.10323", "submitter": "EPTCS", "authors": "Quentin L. Meunier (Sorbonne Universit\\'e, CNRS, Laboratoire\n  d'Informatique de Paris 6), Yann Thierry-Mieg (Sorbonne Universit\\'e, CNRS,\n  Laboratoire d'Informatique de Paris 6), Emmanuelle Encrenaz (Sorbonne\n  Universit\\'e, CNRS, Laboratoire d'Informatique de Paris 6)", "title": "Modeling a Cache Coherence Protocol with the Guarded Action Language", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 88-103", "doi": "10.4204/EPTCS.268.3", "report-no": null, "categories": "cs.LO cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal model built for verification of the hardware Tera-Scale\nARchitecture (TSAR), focusing on its Distributed Hybrid Cache Coherence\nProtocol (DHCCP). This protocol is by nature asynchronous, concurrent and\ndistributed, which makes classical validation of the design (e.g. through\ntesting) difficult. We therefore applied formal methods to prove essential\nproperties of the protocol, such as absence of deadlocks, eventual consensus,\nand fairness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:59:08 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Meunier", "Quentin L.", "", "Sorbonne Universit\u00e9, CNRS, Laboratoire\n  d'Informatique de Paris 6"], ["Thierry-Mieg", "Yann", "", "Sorbonne Universit\u00e9, CNRS,\n  Laboratoire d'Informatique de Paris 6"], ["Encrenaz", "Emmanuelle", "", "Sorbonne\n  Universit\u00e9, CNRS, Laboratoire d'Informatique de Paris 6"]]}, {"id": "1803.11207", "submitter": "Xuan-Thuan Nguyen Dr", "authors": "Xuan-Thuan Nguyen, Trong-Thuc Hoang, Hong-Thu Nguyen, Katsumi Inoue,\n  and Cong-Kha Pham", "title": "An FPGA-Based Hardware Accelerator for Energy-Efficient Bitmap Index\n  Creation", "comments": "14 pages", "journal-ref": "IEEE Access, Vol. 6, No. 1, pp. 16046-16059, March 2018", "doi": "10.1109/ACCESS.2018.2816039", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitmap index is recognized as a promising candidate for online analytics\nprocessing systems, because it effectively supports not only parallel\nprocessing but also complex and multi-dimensional queries. However, bitmap\nindex creation is a time-consuming task. In this study, by taking full\nadvantage of massive parallel computing of field-programmable gate array\n(FPGA), two hardware accelerators of bitmap index creation, namely BIC64K8 and\nBIC32K16, are originally proposed. Each of the accelerator contains two primary\ncomponents, namely an enhanced content-addressable memory and a query logic\narray module, which allow BIC64K8 and BIC32K16 to index 65,536 8-bit words and\n32,768 16-bit words in parallel, at every clock cycle. The experimental results\non an Intel Arria V 5ASTFD5 FPGA prove that at 100 MHz, BIC64K8 and BIC32K16\nachieve the approximate indexing throughput of 1.43 GB/s and 1.46 GB/s,\nrespectively. The throughputs are also proven to be stable, regardless the size\nof the data sets. More significantly, BIC32K16 only consumes as low as 6.76%\nand 3.28% of energy compared to the central-processing-unit- and\ngraphic-processing-unit-based designs, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:58:03 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 18:31:54 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Nguyen", "Xuan-Thuan", ""], ["Hoang", "Trong-Thuc", ""], ["Nguyen", "Hong-Thu", ""], ["Inoue", "Katsumi", ""], ["Pham", "Cong-Kha", ""]]}, {"id": "1803.11440", "submitter": "Avi Mendelson", "authors": "Ori Chalak, Cai Weiguang, Li Wei, Fang Lei, Zheng Libing, Wang\n  Jintang, Wu Zuguang, Gu Xiongli, Wang Haibin, Avi Mendelson", "title": "ScaleSimulator: A Fast and Cycle-Accurate Parallel Simulator for\n  Architectural Exploration", "comments": "Was published in SIMUTools 2017\n  https://drive.google.com/file/d/0B-bj84Yl7TM4R0NJRC16dnUxX0U/view", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of next generation computer systems should be supported by simulation\ninfrastructure that must achieve a few contradictory goals such as fast\nexecution time, high accuracy, and enough flexibility to allow comparison\nbetween large numbers of possible design points. Most existing architecture\nlevel simulators are designed to be flexible and to execute the code in\nparallel for greater efficiency, but at the cost of scarified accuracy. This\npaper presents the ScaleSimulator simulation environment, which is based on a\nnew design methodology whose goal is to achieve near cycle accuracy while still\nbeing flexible enough to simulate many different future system architectures\nand efficient enough to run meaningful workloads. We achieve these goals by\nmaking the parallelism a first-class citizen in our methodology. Thus, this\npaper focuses mainly on the ScaleSimulator design points that enable better\nparallel execution while maintaining the scalability and cycle accuracy of a\nsimulated architecture. The paper indicates that the new proposed\nScaleSimulator tool can (1) efficiently parallelize the execution of a\ncycle-accurate architecture simulator, (2) efficiently simulate complex\narchitectures (e.g., out-of-order CPU pipeline, cache coherency protocol, and\nnetwork) and massive parallel systems, and (3) use meaningful workloads, such\nas full simulation of OLTP benchmarks, to examine future architectural choices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:20:20 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Chalak", "Ori", ""], ["Weiguang", "Cai", ""], ["Wei", "Li", ""], ["Lei", "Fang", ""], ["Libing", "Zheng", ""], ["Jintang", "Wang", ""], ["Zuguang", "Wu", ""], ["Xiongli", "Gu", ""], ["Haibin", "Wang", ""], ["Mendelson", "Avi", ""]]}]