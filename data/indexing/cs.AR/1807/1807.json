[{"id": "1807.00217", "submitter": "Kamel Abdelouahab", "authors": "Kamel Abdelouahab, Fran\\c{c}ois Berry, Maxime Pelcat", "title": "The Challenge of Multi-Operand Adders in CNNs on FPGAs: How not to solve\n  it!", "comments": "Proceedings of the International Conference on Embedded Computer\n  Systems: Architectures, Modeling, and Simulation - SAMOS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are computationally intensive algorithms\nthat currently require dedicated hardware to be executed. In the case of\nFPGA-Based accelerators, we point-out in this work the challenge of\nMulti-Operand Adders (MOAs) and their high resource utilization in an FPGA\nimplementation of a CNN. To address this challenge, two optimization\nstrategies, that rely on time-multiplexing and approximate computing, are\ninvestigated. At first glance, the two strategies looked promising to reduce\nthe footprint of a given architectural mapping, but when synthesized on the\ndevice, none of them gave the expected results. Experimental sections analyze\nthe reasons of these unexpected results.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 18:57:43 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Abdelouahab", "Kamel", ""], ["Berry", "Fran\u00e7ois", ""], ["Pelcat", "Maxime", ""]]}, {"id": "1807.00480", "submitter": "Jeff  (Jun) Zhang", "authors": "Jeff Zhang, Siddharth Garg", "title": "FATE: Fast and Accurate Timing Error Prediction Framework for Low Power\n  DNN Accelerator Design", "comments": "To appear at IEEE/ACM International Conference On Computer Aided\n  Design 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are increasingly being accelerated on\napplication-specific hardware such as the Google TPU designed especially for\ndeep learning. Timing speculation is a promising approach to further increase\nthe energy efficiency of DNN accelerators. Architectural exploration for timing\nspeculation requires detailed gate-level timing simulations that can be\ntime-consuming for large DNNs that execute millions of multiply-and-accumulate\n(MAC) operations. In this paper we propose FATE, a new methodology for fast and\naccurate timing simulations of DNN accelerators like the Google TPU. FATE\nproposes two novel ideas: (i) DelayNet, a DNN based timing model for MAC units;\nand (ii) a statistical sampling methodology that reduces the number of MAC\noperations for which timing simulations are performed. We show that FATE\nresults in between 8 times-58 times speed-up in timing simulations, while\nintroducing less than 2% error in classification accuracy estimates. We\ndemonstrate the use of FATE by comparing to conventional DNN accelerator that\nuses 2's complement (2C) arithmetic with an alternative implementation that\nuses signed magnitude representations (SMR). We show that that the SMR\nimplementation provides 18% more energy savings for the same classification\naccuracy than 2C, a result that might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:21:23 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Zhang", "Jeff", ""], ["Garg", "Siddharth", ""]]}, {"id": "1807.00962", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James, Leon O. Chua", "title": "Neuro-memristive Circuits for Edge Computing: A review", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2899262", "report-no": null, "categories": "cs.ET cs.AI cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The volume, veracity, variability, and velocity of data produced from the\never-increasing network of sensors connected to Internet pose challenges for\npower management, scalability, and sustainability of cloud computing\ninfrastructure. Increasing the data processing capability of edge computing\ndevices at lower power requirements can reduce several overheads for cloud\ncomputing solutions. This paper provides the review of neuromorphic\nCMOS-memristive architectures that can be integrated into edge computing\ndevices. We discuss why the neuromorphic architectures are useful for edge\ndevices and show the advantages, drawbacks and open problems in the field of\nneuro-memristive circuits for edge computing.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 04:07:23 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 03:55:48 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""], ["Chua", "Leon O.", ""]]}, {"id": "1807.01340", "submitter": "Peng Wei", "authors": "Jason Cong, Zhenman Fang, Yuchen Hao, Peng Wei, Cody Hao Yu, Chen\n  Zhang, Peipei Zhou", "title": "Best-Effort FPGA Programming: A Few Steps Can Go a Long Way", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGA-based heterogeneous architectures provide programmers with the ability\nto customize their hardware accelerators for flexible acceleration of many\nworkloads. Nonetheless, such advantages come at the cost of sacrificing\nprogrammability. FPGA vendors and researchers attempt to improve the\nprogrammability through high-level synthesis (HLS) technologies that can\ndirectly generate hardware circuits from high-level language descriptions.\nHowever, reading through recent publications on FPGA designs using HLS, one\noften gets the impression that FPGA programming is still hard in that it leaves\nprogrammers to explore a very large design space with many possible\ncombinations of HLS optimization strategies.\n  In this paper we make two important observations and contributions. First, we\ndemonstrate a rather surprising result: FPGA programming can be made easy by\nfollowing a simple best-effort guideline of five refinement steps using HLS. We\nshow that for a broad class of accelerator benchmarks from MachSuite, the\nproposed best-effort guideline improves the FPGA accelerator performance by\n42-29,030x. Compared to the baseline CPU performance, the FPGA accelerator\nperformance is improved from an average 292.5x slowdown to an average 34.4x\nspeedup. Moreover, we show that the refinement steps in the best-effort\nguideline, consisting of explicit data caching, customized pipelining,\nprocessing element duplication, computation/communication overlapping and\nscratchpad reorganization, correspond well to the best practice guidelines for\nmulticore CPU programming. Although our best-effort guideline may not always\nlead to the optimal solution, it substantially simplifies the FPGA programming\neffort, and will greatly support the wide adoption of FPGA-based acceleration\nby the software programming community.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 18:34:47 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Cong", "Jason", ""], ["Fang", "Zhenman", ""], ["Hao", "Yuchen", ""], ["Wei", "Peng", ""], ["Yu", "Cody Hao", ""], ["Zhang", "Chen", ""], ["Zhou", "Peipei", ""]]}, {"id": "1807.01431", "submitter": "Naveen Kumar Macha", "authors": "Naveen Kumar Macha, Sandeep Geedipally, Bhavana Repalle, Md Arif\n  Iqbal, Wafi Danesh, Mostafizur Rahman", "title": "Crosstalk based Fine-Grained Reconfiguration Techniques for Polymorphic\n  Circuits", "comments": "7 pages, 6 figures, 2 tables, Nanoarch 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truly polymorphic circuits, whose functionality/circuit behavior can be\naltered using a control variable, can provide tremendous benefits in\nmulti-functional system design and resource sharing. For secure and fault\ntolerant hardware designs these can be crucial as well. Polymorphic circuits\nwork in literature so far either rely on environmental parameters such as\ntemperature, variation etc. or on special devices such as ambipolar FET,\nconfigurable magnetic devices, etc., that often result in inefficiencies in\nperformance and/or realization. In this paper, we introduce a novel polymorphic\ncircuit design approach where deterministic interference between nano-metal\nlines is leveraged for logic computing and configuration. For computing, the\nproposed approach relies on nano-metal lines, their interference and commonly\nused FETs, and for polymorphism, it requires only an extra metal line that\ncarries the control signal. In this paper, we show a wide range of crosstalk\npolymorphic (CT-P) logic gates and their evaluation results. We also show an\nexample of a large circuit that performs both the functionalities of multiplier\nand sorter depending on the configuration signal. Our benchmarking results are\npresented in this paper. For CT-P, the transistor count was found to be\nsignificantly less compared to other existing approaches, ranging from 25% to\n83%. For example, CT-P AOI21-OA21 cell show 83%, 85% and 50% transistor count\nreduction, and MultiplierSorter circuit show 40%, 36% and 28% transistor count\nreduction with respect to CMOS, genetically evolved, and ambipolar transistor\nbased polymorphic circuits respectively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 02:43:33 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Macha", "Naveen Kumar", ""], ["Geedipally", "Sandeep", ""], ["Repalle", "Bhavana", ""], ["Iqbal", "Md Arif", ""], ["Danesh", "Wafi", ""], ["Rahman", "Mostafizur", ""]]}, {"id": "1807.01433", "submitter": "Naveen Kumar Macha", "authors": "Naveen Kumar Macha, Bhavana Tejaswini Repalle, Sandeep Geedipally,\n  Rafael Rios, Mostafizur Rahman", "title": "A New Paradigm for Fault-Tolerant Computing with Interconnect Crosstalks", "comments": "6 pages, 5 figures, 2 tables, International conference on rebooting\n  computing. arXiv admin note: text overlap with arXiv:1807.01431", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CMOS integrated chips at advanced technology nodes are becoming more\nvulnerable to various sources of faults like manufacturing imprecisions,\nvariations, aging, etc. Additionally, the intentional fault attacks (e.g., high\npower microwave, cybersecurity threats, etc.) and environmental effects (i.e.,\nradiation) also pose reliability threats to integrated circuits. Though the\ntraditional hardware redundancy-based techniques like Triple Modular Redundancy\n(TMR), Quadded (QL) Logic etc. mitigate the risk to some extent, they add huge\nhardware overhead and are not very effective. Truly polymorphic circuits that\nare inherently capable of achieving multiple functionalities in a limited\nfootprint could enhance the faultresilience/recovery of the circuits with\nlimited overhead. We demonstrate a novel crosstalk logic based polymorphic\ncircuit approach to achieve compact and efficient fault resilient circuits. We\nshow a range of polymorphic primitive gates and their usage in a functional\nunit. The functional unit is a single arithmetic circuit that is capable of\ndelivering Multiplication/Sorting/Addition output depending on the control\ninputs. Using such polymorphic computing units in an ALU would imply that a\ncorrect path for functional output is possible even when 2/3rd of the ALU is\ndamaged. Our comparison results with respect to existing polymorphic techniques\nand CMOS reveal 28% and 62% reduction in transistor count respectively for the\nsame functionalities. In conjunction with fault detection algorithms, the\nproposed polymorphic circuit concept can be transformative for fault tolerant\ncircuit design directions with minimum overhead.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 02:56:42 GMT"}], "update_date": "2018-07-08", "authors_parsed": [["Macha", "Naveen Kumar", ""], ["Repalle", "Bhavana Tejaswini", ""], ["Geedipally", "Sandeep", ""], ["Rios", "Rafael", ""], ["Rahman", "Mostafizur", ""]]}, {"id": "1807.03010", "submitter": "Francesco Conti", "authors": "Francesco Conti, Pasquale Davide Schiavone and Luca Benini", "title": "XNOR Neural Engine: a Hardware Accelerator IP for 21.6 fJ/op Binary\n  Neural Network Inference", "comments": "11 pages, 8 figures, 2 tables, 3 listings. Accepted for presentation\n  at CODES'18 and for publication in IEEE Transactions on Computer-Aided Design\n  of Circuits and Systems (TCAD) as part of the ESWEEK-TCAD special issue", "journal-ref": null, "doi": "10.1109/TCAD.2018.2857019", "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are promising to deliver accuracy comparable to\nconventional deep neural networks at a fraction of the cost in terms of memory\nand energy. In this paper, we introduce the XNOR Neural Engine (XNE), a fully\ndigital configurable hardware accelerator IP for BNNs, integrated within a\nmicrocontroller unit (MCU) equipped with an autonomous I/O subsystem and hybrid\nSRAM / standard cell memory. The XNE is able to fully compute convolutional and\ndense layers in autonomy or in cooperation with the core in the MCU to realize\nmore complex behaviors. We show post-synthesis results in 65nm and 22nm\ntechnology for the XNE IP and post-layout results in 22nm for the full MCU\nindicating that this system can drop the energy cost per binary operation to\n21.6fJ per operation at 0.4V, and at the same time is flexible and performant\nenough to execute state-of-the-art BNN topologies such as ResNet-34 in less\nthan 2.2mJ per frame at 8.9 fps.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:40:37 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Conti", "Francesco", ""], ["Schiavone", "Pasquale Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1807.04013", "submitter": "Yongming Shen", "authors": "Yongming Shen (1), Tianchu Ji (1), Michael Ferdman (1), Peter Milder\n  (1) ((1) Stony Brook University)", "title": "Medusa: A Scalable Interconnect for Many-Port DNN Accelerators and Wide\n  DRAM Controller Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the increasing demand and computational intensity of deep neural\nnetworks (DNNs), industry and academia have turned to accelerator technologies.\nIn particular, FPGAs have been shown to provide a good balance between\nperformance and energy efficiency for accelerating DNNs. While significant\nresearch has focused on how to build efficient layer processors, the\ncomputational building blocks of DNN accelerators, relatively little attention\nhas been paid to the on-chip interconnects that sit between the layer\nprocessors and the FPGA's DRAM controller.\n  We observe a disparity between DNN accelerator interfaces, which tend to\ncomprise many narrow ports, and FPGA DRAM controller interfaces, which tend to\nbe wide buses. This mismatch causes traditional interconnects to consume\nsignificant FPGA resources. To address this problem, we designed Medusa: an\noptimized FPGA memory interconnect which transposes data in the interconnect\nfabric, tailoring the interconnect to the needs of DNN layer processors.\nCompared to a traditional FPGA interconnect, our design can reduce LUT and FF\nuse by 4.7x and 6.0x, and improves frequency by 1.8x.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:06:20 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Shen", "Yongming", "", "Stony Brook University"], ["Ji", "Tianchu", "", "Stony Brook University"], ["Ferdman", "Michael", "", "Stony Brook University"], ["Milder", "Peter", "", "Stony Brook University"]]}, {"id": "1807.04093", "submitter": "Vladimir Rybalkin", "authors": "Vladimir Rybalkin, Alessandro Pappalardo, Muhammad Mohsin Ghaffar,\n  Giulio Gambardella, Norbert Wehn, Michaela Blott", "title": "FINN-L: Library Extensions and Design Trade-off Analysis for Variable\n  Precision LSTM Networks on FPGAs", "comments": "Accepted for publication, 28th International Conference on Field\n  Programmable Logic and Applications (FPL), August, 2018, Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that many types of artificial neural networks, including\nrecurrent networks, can achieve a high classification accuracy even with\nlow-precision weights and activations. The reduction in precision generally\nyields much more efficient hardware implementations in regards to hardware\ncost, memory requirements, energy, and achievable throughput. In this paper, we\npresent the first systematic exploration of this design space as a function of\nprecision for Bidirectional Long Short-Term Memory (BiLSTM) neural network.\nSpecifically, we include an in-depth investigation of precision vs. accuracy\nusing a fully hardware-aware training flow, where during training quantization\nof all aspects of the network including weights, input, output and in-memory\ncell activations are taken into consideration. In addition, hardware resource\ncost, power consumption and throughput scalability are explored as a function\nof precision for FPGA-based implementations of BiLSTM, and multiple approaches\nof parallelizing the hardware. We provide the first open source HLS library\nextension of FINN for parameterizable hardware architectures of LSTM layers on\nFPGAs which offers full precision flexibility and allows for parameterizable\nperformance scaling offering different levels of parallelism within the\narchitecture. Based on this library, we present an FPGA-based accelerator for\nBiLSTM neural network designed for optical character recognition, along with\nnumerous other experimental proof points for a Zynq UltraScale+ XCZU7EV MPSoC\nwithin the given design space.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 11:52:59 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Rybalkin", "Vladimir", ""], ["Pappalardo", "Alessandro", ""], ["Ghaffar", "Muhammad Mohsin", ""], ["Gambardella", "Giulio", ""], ["Wehn", "Norbert", ""], ["Blott", "Michaela", ""]]}, {"id": "1807.05102", "submitter": "Saugata Ghose", "authors": "Saugata Ghose, Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}, Raghav Gupta,\n  Donghyuk Lee, Kais Kudrolli, William X. Liu, Hasan Hassan, Kevin K. Chang,\n  Niladrish Chatterjee, Aditya Agrawal, Mike O'Connor, Onur Mutlu", "title": "What Your DRAM Power Models Are Not Telling You: Lessons from a Detailed\n  Experimental Study", "comments": "presented at SIGMETRICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Main memory (DRAM) consumes as much as half of the total system power in a\ncomputer today, resulting in a growing need to develop new DRAM architectures\nand systems that consume less power. Researchers have long relied on DRAM power\nmodels that are based off of standardized current measurements provided by\nvendors, called IDD values. Unfortunately, we find that these models are highly\ninaccurate, and do not reflect the actual power consumed by real DRAM devices.\n  We perform the first comprehensive experimental characterization of the power\nconsumed by modern real-world DRAM modules. Our extensive characterization of\n50 DDR3L DRAM modules from three major vendors yields four key new observations\nabout DRAM power consumption: (1) across all IDD values that we measure, the\ncurrent consumed by real DRAM modules varies significantly from the current\nspecified by the vendors; (2) DRAM power consumption strongly depends on the\ndata value that is read or written; (3) there is significant structural\nvariation, where the same banks and rows across multiple DRAM modules from the\nsame model consume more power than other banks or rows; and (4) over successive\nprocess technology generations, DRAM power consumption has not decreased by as\nmuch as vendor specifications have indicated.\n  Based on our detailed analysis and characterization data, we develop the\nVariation-Aware model of Memory Power Informed by Real Experiments (VAMPIRE).\nWe show that VAMPIRE has a mean absolute percentage error of only 6.8% compared\nto actual measured DRAM power. VAMPIRE enables a wide range of studies that\nwere not possible using prior DRAM power models. As an example, we use VAMPIRE\nto evaluate a new power-aware data encoding mechanism, which can reduce DRAM\nenergy consumption by an average of 12.2%. We plan to open-source both VAMPIRE\nand our extensive raw data collected during our experimental characterization.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 14:22:09 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Ghose", "Saugata", ""], ["Ya\u011fl\u0131k\u00e7\u0131", "Abdullah Giray", ""], ["Gupta", "Raghav", ""], ["Lee", "Donghyuk", ""], ["Kudrolli", "Kais", ""], ["Liu", "William X.", ""], ["Hassan", "Hasan", ""], ["Chang", "Kevin K.", ""], ["Chatterjee", "Niladrish", ""], ["Agrawal", "Aditya", ""], ["O'Connor", "Mike", ""], ["Mutlu", "Onur", ""]]}, {"id": "1807.05140", "submitter": "Saugata Ghose", "authors": "Yixin Luo, Saugata Ghose, Yu Cai, Erich F. Haratsch, Onur Mutlu", "title": "Improving 3D NAND Flash Memory Lifetime by Tolerating Early Retention\n  Loss and Process Variation", "comments": "presented at SIGMETRICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to planar (i.e., two-dimensional) NAND flash memory, 3D NAND flash\nmemory uses a new flash cell design, and vertically stacks dozens of silicon\nlayers in a single chip. This allows 3D NAND flash memory to increase storage\ndensity using a much less aggressive manufacturing process technology than\nplanar NAND flash memory. The circuit-level and structural changes in 3D NAND\nflash memory significantly alter how different error sources affect the\nreliability of the memory.\n  In this paper, through experimental characterization of real,\nstate-of-the-art 3D NAND flash memory chips, we find that 3D NAND flash memory\nexhibits three new error sources that were not previously observed in planar\nNAND flash memory: (1) layer-to-layer process variation, where the average\nerror rate of each 3D-stacked layer in a chip is significantly different; (2)\nearly retention loss, a new phenomenon where the number of errors due to charge\nleakage increases quickly within several hours after programming; and (3)\nretention interference, a new phenomenon where the rate at which charge leaks\nfrom a flash cell is dependent on the data value stored in the neighboring\ncell.\n  Based on our experimental results, we develop new analytical models of\nlayer-to-layer process variation and retention loss in 3D NAND flash memory.\nMotivated by our new findings and models, we develop four new techniques to\nmitigate process variation and early retention loss in 3D NAND flash memory.\nThese four techniques are complementary, and can be combined together to\nsignificantly improve flash memory reliability. Compared to a state-of-the-art\nbaseline, our techniques, when combined, improve flash memory lifetime by\n1.85x. Alternatively, if a NAND flash vendor wants to keep the lifetime of the\n3D NAND flash memory device constant, our techniques reduce the storage\noverhead required to hold error correction information by 78.9%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:34:59 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 16:11:53 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Luo", "Yixin", ""], ["Ghose", "Saugata", ""], ["Cai", "Yu", ""], ["Haratsch", "Erich F.", ""], ["Mutlu", "Onur", ""]]}, {"id": "1807.05442", "submitter": "Tobias Strauch", "authors": "Tobias Strauch", "title": "Deriving AOC C-Models from D&V Languages for Single- or Multi-Threaded\n  Execution Using C or C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The C language is getting more and more popular as a design and verification\nlanguage (DVL). SystemC, ParC [1] and Cx [2] are based on C. C-models of the\ndesign and verification environment can also be generated from new DVLs (e.g.\nChisel [3]) or classical DVLs such as VHDL or Verilog. The execution of these\nmodels is usually license free and presumably faster than their alternative\ncounterparts (simulators). This paper proposes activity-dependent, ordered,\ncycle-accurate (AOC) C-models to speed up simulation time. It compares the\nresults with alternative concepts. The paper also examines the execution of the\nAOC C-model on a multithreaded processor environment.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 20:56:12 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Strauch", "Tobias", ""]]}, {"id": "1807.05446", "submitter": "Tobias Strauch", "authors": "Tobias Strauch", "title": "Timing Driven C-Slow Retiming on RTL for MultiCores on FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper C-Slow Retiming (CSR) on RTL is discussed. CSR multiplies the\nfunctionality of cores by adding the same number of registers into each path.\nThe technique is ideal for FPGAs with their already existing registers.\nPreviously publications are limited to adding registers on netlist level, which\ngenerates a lot of system verification problems and which is assumed to be the\nmajor drawback to use this technology in the modern multicore times. The paper\nshows how CSR can efficiently be done with timing driven automatic RTL\nmodification. The methodology provided with this paper can be used as guidance\nfor using CSR in high level synthesis (HLS). The paper shows the results of a\nCSR-ed complex RISC core on RTL implemented on FPGAs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 20:58:49 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Strauch", "Tobias", ""]]}, {"id": "1807.05764", "submitter": "Alexios Balatsoukas-Stimming", "authors": "Michiel Van Beirendonck, Louis-Charles Trudeau, Pascal Giard, Alexios\n  Balatsoukas-Stimming", "title": "A Lyra2 FPGA Core for Lyra2REv2-Based Cryptocurrencies", "comments": "5 pages, to be presented at the IEEE International Symposium on\n  Circuits and Systems (ISCAS) 2019", "journal-ref": null, "doi": "10.1109/ISCAS.2019.8702498", "report-no": null, "categories": "cs.CR cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyra2REv2 is a hashing algorithm that consists of a chain of individual\nhashing algorithms and it is used as a proof-of-work function in several\ncryptocurrencies that aim to be ASIC-resistant. The most crucial hashing\nalgorithm in the Lyra2REv2 chain is a specific instance of the general Lyra2\nalgorithm. In this work we present the first FPGA implementation of the\naforementioned instance of Lyra2 and we explain how several properties of the\nalgorithm can be exploited in order to optimize the design.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 10:01:47 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 16:41:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Van Beirendonck", "Michiel", ""], ["Trudeau", "Louis-Charles", ""], ["Giard", "Pascal", ""], ["Balatsoukas-Stimming", "Alexios", ""]]}, {"id": "1807.06434", "submitter": "Mohamed Abdelfattah", "authors": "Mohamed S. Abdelfattah, David Han, Andrew Bitar, Roberto DiCecco,\n  Shane OConnell, Nitika Shanker, Joseph Chu, Ian Prins, Joshua Fender, Andrew\n  C. Ling, Gordon R. Chiu", "title": "DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration", "comments": "Accepted in the International Conference on Field-Programmable Logic\n  and Applications (FPL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlays have shown significant promise for field-programmable gate-arrays\n(FPGAs) as they allow for fast development cycles and remove many of the\nchallenges of the traditional FPGA hardware design flow. However, this often\ncomes with a significant performance burden resulting in very little adoption\nof overlays for practical applications. In this paper, we tailor an overlay to\na specific application domain, and we show how we maintain its full\nprogrammability without paying for the performance overhead traditionally\nassociated with overlays. Specifically, we introduce an overlay targeted for\ndeep neural network inference with only ~1% overhead to support the control and\nreprogramming logic using a lightweight very-long instruction word (VLIW)\nnetwork. Additionally, we implement a sophisticated domain specific graph\ncompiler that compiles deep learning languages such as Caffe or Tensorflow to\neasily target our overlay. We show how our graph compiler performs\narchitecture-driven software optimizations to significantly boost performance\nof both convolutional and recurrent neural networks (CNNs/RNNs) - we\ndemonstrate a 3x improvement on ResNet-101 and a 12x improvement for long\nshort-term memory (LSTM) cells, compared to naive implementations. Finally, we\ndescribe how we can tailor our hardware overlay, and use our graph compiler to\nachieve ~900 fps on GoogLeNet on an Intel Arria 10 1150 - the fastest ever\nreported on comparable FPGAs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:25:56 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Abdelfattah", "Mohamed S.", ""], ["Han", "David", ""], ["Bitar", "Andrew", ""], ["DiCecco", "Roberto", ""], ["OConnell", "Shane", ""], ["Shanker", "Nitika", ""], ["Chu", "Joseph", ""], ["Prins", "Ian", ""], ["Fender", "Joshua", ""], ["Ling", "Andrew C.", ""], ["Chiu", "Gordon R.", ""]]}, {"id": "1807.07023", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Subhendu Roy, Jin Miao, Jiamin Chen, Bei Yu", "title": "Cross-layer Optimization for High Speed Adders: A Pareto Driven Machine\n  Learning Approach", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of maturity to the modern electronic design automation (EDA) tools,\noptimized designs at architectural stage may become sub-optimal after going\nthrough physical design flow. Adder design has been such a long studied\nfundamental problem in VLSI industry yet designers cannot achieve optimal\nsolutions by running EDA tools on the set of available prefix adder\narchitectures. In this paper, we enhance a state-of-the-art prefix adder\nsynthesis algorithm to obtain a much wider solution space in architectural\ndomain. On top of that, a machine learning-based design space exploration\nmethodology is applied to predict the Pareto frontier of the adders in physical\ndomain, which is infeasible by exhaustively running EDA tools for innumerable\narchitectural solutions. Considering the high cost of obtaining the true values\nfor learning, an active learning algorithm is utilized to select the\nrepresentative data during learning process, which uses less labeled data while\nachieving better quality of Pareto frontier. Experimental results demonstrate\nthat our framework can achieve Pareto frontier of high quality over a wide\ndesign space, bridging the gap between architectural and physical designs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 16:23:26 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 04:37:28 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Ma", "Yuzhe", ""], ["Roy", "Subhendu", ""], ["Miao", "Jin", ""], ["Chen", "Jiamin", ""], ["Yu", "Bei", ""]]}, {"id": "1807.07685", "submitter": "Vinson Young", "authors": "Vinson Young, Sanjay Kariyappa, Moinuddin K. Qureshi", "title": "CRAM: Efficient Hardware-Based Memory Compression for Bandwidth\n  Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates hardware-based memory compression designs to increase\nthe memory bandwidth. When lines are compressible, the hardware can store\nmultiple lines in a single memory location, and retrieve all these lines in a\nsingle access, thereby increasing the effective memory bandwidth. However,\nrelocating and packing multiple lines together depending on the compressibility\ncauses a line to have multiple possible locations. Therefore, memory\ncompression designs typically require metadata to specify the compressibility\nof the line. Unfortunately, even in the presence of dedicated metadata caches,\nmaintaining and accessing this metadata incurs significant bandwidth overheads\nand can degrade performance by as much as 40%. Ideally, we want to implement\nmemory compression while eliminating the bandwidth overheads of metadata\naccesses.\n  This paper proposes CRAM, a bandwidth-efficient design for memory compression\nthat is entirely hardware based and does not require any OS support or changes\nto the memory modules or interfaces. CRAM uses a novel implicit-metadata\nmechanism, whereby the compressibility of the line can be determined by\nscanning the line for a special marker word, eliminating the overheads of\nmetadata access. CRAM is equipped with a low-cost Line Location Predictor (LLP)\nthat can determine the location of the line with 98% accuracy. Furthermore, we\nalso develop a scheme that can dynamically enable or disable compression based\non the bandwidth cost of storing compressed lines and the bandwidth benefits of\nobtaining compressed lines, ensuring no degradation for workloads that do not\nbenefit from compression. Our evaluations, over a diverse set of 27 workloads,\nshow that CRAM provides a speedup of up to 73% (average 6%) without causing\nslowdown for any of the workloads, and consuming a storage overhead of less\nthan 300 bytes at the memory controller.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 01:28:40 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Young", "Vinson", ""], ["Kariyappa", "Sanjay", ""], ["Qureshi", "Moinuddin K.", ""]]}, {"id": "1807.09250", "submitter": "Hadi Mardani Kamali", "authors": "Hadi Mardani Kamali", "title": "Using Multi-Core HW/SW Co-design Architecture for Accelerating K-means\n  Clustering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability of classifying and clustering a desired set of data is an\nessential part of building knowledge from data. However, as the size and\ndimensionality of input data increases, the run-time for such clustering\nalgorithms is expected to grow superlinearly, making it a big challenge when\ndealing with BigData. K-mean clustering is an essential tool for many big data\napplications including data mining, predictive analysis, forecasting studies,\nand machine learning. However, due to large size (volume) of Big-Data, and\nlarge dimensionality of its data points, even the application of a simple\nk-mean clustering may become extremely time and resource demanding. Specially\nwhen it is necessary to have a fast and modular dataset analysis flow. In this\npaper, we demonstrate that using a two-level filtering algorithm based on\nbinary kd-tree structure is able to decrease the time of convergence in K-means\nalgorithm for large datasets. The two-level filtering algorithm based on binary\nkd-tree structure evolves the SW to naturally divide the classification into\nsmaller data sets, based on the number of available cores and size of logic\navailable in a target FPGA. The empirical result on this two-level structure\nover multi-core FPGA-based architecture provides 330X speed-up compared to a\nconventional software-only solution.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 17:38:42 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Kamali", "Hadi Mardani", ""]]}, {"id": "1807.09449", "submitter": "Mart\\'i Anglada", "authors": "Mart\\'i Anglada, Enrique de Lucas, Joan-Manuel Parcerisa, Juan L.\n  Arag\\'on, Pedro Marcuello, Antonio Gonz\\'alez", "title": "Rendering Elimination: Early Discard of Redundant Tiles in the Graphics\n  Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are one of the most energy-consuming components for real-time rendering\napplications, since a large number of fragment shading computations and memory\naccesses are involved. Main memory bandwidth is especially taxing\nbattery-operated devices such as smartphones. Tile-Based Rendering GPUs divide\nthe screen space into multiple tiles that are independently rendered in on-chip\nbuffers, thus reducing memory bandwidth and energy consumption. We have\nobserved that, in many animated graphics workloads, a large number of screen\ntiles have the same color across adjacent frames. In this paper, we propose\nRendering Elimination (RE), a novel micro-architectural technique that\naccurately determines if a tile will be identical to the same tile in the\npreceding frame before rasterization by means of comparing signatures. Since RE\nidentifies redundant tiles early in the graphics pipeline, it completely avoids\nthe computation and memory accesses of the most power consuming stages of the\npipeline, which substantially reduces the execution time and the energy\nconsumption of the GPU. For widely used Android applications, we show that RE\nachieves an average speedup of 1.74x and energy reduction of 43% for the\nGPU/Memory system, surpassing by far the benefits of Transaction Elimination, a\nstate-of-the-art memory bandwidth reduction technique available in some\ncommercial Tile-Based Rendering GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 06:29:11 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Anglada", "Mart\u00ed", ""], ["de Lucas", "Enrique", ""], ["Parcerisa", "Joan-Manuel", ""], ["Arag\u00f3n", "Juan L.", ""], ["Marcuello", "Pedro", ""], ["Gonz\u00e1lez", "Antonio", ""]]}, {"id": "1807.09762", "submitter": "P Balasubramanian", "authors": "P Balasubramanian", "title": "Asynchronous Ripple Carry Adder based on Area Optimized Early Output\n  Dual-Bit Full Adder", "comments": "12 pages. arXiv admin note: substantial text overlap with\n  arXiv:1706.04487, arXiv:1704.07619", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical note presents the design of a new area optimized asynchronous\nearly output dual-bit full adder (DBFA). An asynchronous ripple carry adder\n(RCA) is constructed based on the new asynchronous DBFAs and existing\nasynchronous early output single-bit full adders (SBFAs). The asynchronous\nDBFAs and SBFAs incorporate redundant logic and are encoded using the\ndelay-insensitive dual-rail code (i.e. homogeneous data encoding) and follow a\n4-phase return-to-zero handshaking. Compared to the previous asynchronous RCAs\ninvolving DBFAs and SBFAs, which are based on homogeneous or heterogeneous\ndelay-insensitive data encodings and which correspond to different timing\nmodels, the early output asynchronous RCA incorporating the proposed DBFAs\nand/or SBFAs is found to result in reduced area for the dual-operand addition\noperation and feature significantly less latency than the asynchronous RCAs\nwhich consist of only SBFAs. The proposed asynchronous DBFA requires 28.6% less\nsilicon than the previously reported asynchronous DBFA. For a 32-bit\nasynchronous RCA, utilizing 2 stages of SBFAs in the least significant\npositions and 15 stages of DBFAs in the more significant positions leads to\noptimization in the latency. The new early output 32-bit asynchronous RCA\ncontaining DBFAs and SBFAs reports the following optimizations in design\nmetrics over its counterparts: i) 18.8% reduction in area than a previously\nreported 32-bit early output asynchronous RCA which also has 15 stages of DBFAs\nand 2 stages of SBFAs, ii) 29.4% reduction in latency than a 32-bit early\noutput asynchronous RCA containing only SBFAs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 03:30:54 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Balasubramanian", "P", ""]]}, {"id": "1807.10309", "submitter": "Rozita Teymourzadeh", "authors": "Rozita Teymourzadeh, Yazan Samir Algnabi, Masuri Othman, Md Shabiul\n  Islam, Mok Vee Hong", "title": "VLSI Implementation of Novel Class of High Speed Pipelined Digital\n  Signal Processing Filter for Wireless Receivers", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.00704", "journal-ref": "American Journal of Engineering and Applied Sciences.\n  3(4):663-669, 2010, ISSN 1941-7020", "doi": "10.3844/ajeassp.2010.663.669", "report-no": null, "categories": "eess.SP cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for a high-performance transceiver with high Signal to Noise Ratio\n(SNR) has driven the communication system to utilize the latest technique\nidentified as oversampling systems. It was the most economical modulator and\ndecimation in the communication system. It has been proven to increase the SNR\nand is used in many high-performance systems such as in the Analog to Digital\nConverter (ADC) for wireless transceiver. This research work presented the\ndesign of the novel class of decimation and it's VLSI implementation which was\nthe sub-component in the oversampling technique. The design and realization of\nthe main unit of decimation stage that was the Cascaded Integrator Comb (CIC)\nfilter, the associated half-band filters, and the droop correction are also\ndesigned. The Verilog HDL code in Xilinx ISE environment has been derived to\ndescribe the proposed advanced CIC filter properties. Consequently, Virtex-II\nFPGA board was used to implement and test the design on the real hardware. The\nASIC design implementation was performed accordingly and resulted in power and\narea measurement on-chip core layout. The proposed design focused on the\ntrade-off between the high speed and the low power consumption as well as the\nsilicon area and high resolution for the chip implementation which satisfies\nwireless communication systems. The synthesis report illustrates the maximum\nclock frequency of 332 MHz with the active core area of 0.308 x 0.308 mm2. It\ncan be concluded that VLSI implementation of proposed filter architecture is an\nenabler in solving problems that affect communication capability in DSP\napplication.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 21:12:51 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Teymourzadeh", "Rozita", ""], ["Algnabi", "Yazan Samir", ""], ["Othman", "Masuri", ""], ["Islam", "Md Shabiul", ""], ["Hong", "Mok Vee", ""]]}, {"id": "1807.10695", "submitter": "Ruolong Lian", "authors": "Jin Hee Kim, Brett Grady, Ruolong Lian, John Brothers, Jason H.\n  Anderson", "title": "FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C\n  Software", "comments": null, "journal-ref": "J. H. Kim, B. Grady, R. Lian, J. Brothers and J. H. Anderson,\n  \"FPGA-based CNN inference accelerator synthesized from multi-threaded C\n  software,\" 2017 30th IEEE International System-on-Chip Conference (SOCC),\n  Munich, 2017, pp. 268-273", "doi": "10.1109/SOCC.2017.8226056", "report-no": null, "categories": "cs.LG cs.AR cs.PF cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning inference accelerator is synthesized from a C-language\nsoftware program parallelized with Pthreads. The software implementation uses\nthe well-known producer/consumer model with parallel threads interconnected by\nFIFO queues. The LegUp high-level synthesis (HLS) tool synthesizes threads into\nparallel FPGA hardware, translating software parallelism into spatial\nparallelism. A complete system is generated where convolution, pooling and\npadding are realized in the synthesized accelerator, with remaining tasks\nexecuting on an embedded ARM processor. The accelerator incorporates reduced\nprecision, and a novel approach for zero-weight-skipping in convolution. On a\nmid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective\nGOPS.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:46:16 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Kim", "Jin Hee", ""], ["Grady", "Brett", ""], ["Lian", "Ruolong", ""], ["Brothers", "John", ""], ["Anderson", "Jason H.", ""]]}, {"id": "1807.11311", "submitter": "Mostafa Darvishi", "authors": "Mostafa Darvishi, Yves Audet, Yves Blaquiere", "title": "Delay Monitor Circuit for Sensitive Nodes in SRAM-Based FPGA", "comments": "6 Figures, 5 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.space-ph cs.AR physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel monitor circuit architecture and experiments\nperformed for detection of extra combinational delays in a high frequency\nSRAM-Based FPGA on delay sensitive nodes due to transient ionizing radiation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 12:23:10 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Darvishi", "Mostafa", ""], ["Audet", "Yves", ""], ["Blaquiere", "Yves", ""]]}, {"id": "1807.11396", "submitter": "Xiaoqing Xu", "authors": "Xiaoqing Xu, Nishi Shah, Andrew Evans, Saurabh Sinha, Brian Cline, and\n  Greg Yeric", "title": "Standard Cell Library Design and Optimization Methodology for ASAP7 PDK", "comments": "6 papes, ICCAD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard cell libraries are the foundation for the entire backend design and\noptimization flow in modern application-specific integrated circuit designs. At\n7nm technology node and beyond, standard cell library design and optimization\nis becoming increasingly difficult due to extremely complex design constraints,\nas described in the ASAP7 process design kit (PDK). Notable complexities\ninclude discrete transistor sizing due to FinFETs, complicated design rules\nfrom lithography and restrictive layout space from modern standard cell\narchitectures. The design methodology presented in this paper enables efficient\nand high-quality standard cell library design and optimization with the ASAP7\nPDK. The key techniques include exhaustive transistor sizing for cell timing\noptimization, transistor placement with generalized Euler paths and back-end\ndesign prototyping for library-level explorations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 15:34:36 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Xu", "Xiaoqing", ""], ["Shah", "Nishi", ""], ["Evans", "Andrew", ""], ["Sinha", "Saurabh", ""], ["Cline", "Brian", ""], ["Yeric", "Greg", ""]]}]