[{"id": "1612.00445", "submitter": "Javier Picorel", "authors": "Javier Picorel, Djordje Jevdjic and Babak Falsafi", "title": "Near-Memory Address Translation", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory and logic integration on the same chip is becoming increasingly cost\neffective, creating the opportunity to offload data-intensive functionality to\nprocessing units placed inside memory chips. The introduction of memory-side\nprocessing units (MPUs) into conventional systems faces virtual memory as the\nfirst big showstopper: without efficient hardware support for address\ntranslation MPUs have highly limited applicability. Unfortunately, conventional\ntranslation mechanisms fall short of providing fast translations as\ncontemporary memories exceed the reach of TLBs, making expensive page walks\ncommon.\n  In this paper, we are the first to show that the historically important\nflexibility to map any virtual page to any page frame is unnecessary in today's\nservers. We find that while limiting the associativity of the\nvirtual-to-physical mapping incurs no penalty, it can break the\ntranslate-then-fetch serialization if combined with careful data placement in\nthe MPU's memory, allowing for translation and data fetch to proceed\nindependently and in parallel. We propose the Distributed Inverted Page Table\n(DIPTA), a near-memory structure in which the smallest memory partition keeps\nthe translation information for its data share, ensuring that the translation\ncompletes together with the data fetch. DIPTA completely eliminates the\nperformance overhead of translation, achieving speedups of up to 3.81x and\n2.13x over conventional translation using 4KB and 1GB pages respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 17:45:18 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 20:09:02 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Picorel", "Javier", ""], ["Jevdjic", "Djordje", ""], ["Falsafi", "Babak", ""]]}, {"id": "1612.02913", "submitter": "Mohammed Zidan", "authors": "Mohammed A. Zidan, YeonJoo Jeong, Jong Hong Shin, Chao Du, Zhengya\n  Zhang, Wei D. Lu", "title": "Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, advances in electronics were directly driven by the scaling of\nCMOS transistors according to Moore's law. However, both the CMOS scaling and\nthe classical computer architecture are approaching fundamental and practical\nlimits, and new computing architectures based on emerging devices, such as\nresistive random-access memory (RRAM) devices, are expected to sustain the\nexponential growth of computing capability. Here we propose a novel\nmemory-centric, reconfigurable, general purpose computing platform that is\ncapable of handling the explosive amount of data in a fast and energy-efficient\nmanner. The proposed computing architecture is based on a uniform, physical,\nresistive, memory-centric fabric that can be optimally reconfigured and\nutilized to perform different computing and data storage tasks in a massively\nparallel approach. The system can be tailored to achieve maximal energy\nefficiency based on the data flow by dynamically allocating the basic computing\nfabric for storage, arithmetic, and analog computing including neuromorphic\ncomputing tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 04:41:25 GMT"}, {"version": "v2", "created": "Sun, 18 Dec 2016 05:57:43 GMT"}, {"version": "v3", "created": "Mon, 3 Jul 2017 14:45:28 GMT"}, {"version": "v4", "created": "Thu, 20 Jul 2017 14:55:45 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Zidan", "Mohammed A.", ""], ["Jeong", "YeonJoo", ""], ["Shin", "Jong Hong", ""], ["Du", "Chao", ""], ["Zhang", "Zhengya", ""], ["Lu", "Wei D.", ""]]}, {"id": "1612.03182", "submitter": "Mark D. Hill", "authors": "Luis Ceze, Mark D. Hill, and Thomas F. Wenisch", "title": "Arch2030: A Vision of Computer Architecture Research over the Next 15\n  Years", "comments": "A Computing Community Consortium (CCC) white paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application trends, device technologies and the architecture of systems drive\nprogress in information technologies. However, the former engines of such\nprogress - Moore's Law and Dennard Scaling - are rapidly reaching the point of\ndiminishing returns. The time has come for the computing community to boldly\nconfront a new challenge: how to secure a foundational future for information\ntechnology's continued progress. The computer architecture community engaged in\nseveral visioning exercises over the years. Five years ago, we released a white\npaper, 21st Century Computer Architecture, which influenced funding programs in\nboth academia and industry. More recently, the IEEE Rebooting Computing\nInitiative explored the future of computing systems in the architecture,\ndevice, and circuit domains. This report stems from an effort to continue this\ndialogue, reach out to the applications and devices/circuits communities, and\nunderstand their trends and vision. We aim to identify opportunities where\narchitecture research can bridge the gap between the application and device\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 21:02:13 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Ceze", "Luis", ""], ["Hill", "Mark D.", ""], ["Wenisch", "Thomas F.", ""]]}, {"id": "1612.04197", "submitter": "Sandeep Aswath Narayana", "authors": "Sandeep Aswath Narayana", "title": "An Artificial Neural Networks based Temperature Prediction Framework for\n  Network-on-Chip based Multicore Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous improvement in silicon process technologies has made possible the\nintegration of hundreds of cores on a single chip. However, power and heat have\nbecome dominant constraints in designing these massive multicore chips causing\nissues with reliability, timing variations and reduced lifetime of the chips.\nDynamic Thermal Management (DTM) is a solution to avoid high temperatures on\nthe die. Typical DTM schemes only address core level thermal issues. However,\nthe Network-on-chip (NoC) paradigm, which has emerged as an enabling\nmethodology for integrating hundreds to thousands of cores on the same die can\ncontribute significantly to the thermal issues. Moreover, the typical DTM is\ntriggered reactively based on temperature measurements from on-chip thermal\nsensor requiring long reaction times whereas predictive DTM method estimates\nfuture temperature in advance, eliminating the chance of temperature overshoot.\nArtificial Neural Networks (ANNs) have been used in various domains for\nmodeling and prediction with high accuracy due to its ability to learn and\nadapt. This thesis concentrates on designing an ANN prediction engine to\npredict the thermal profile of the cores and Network-on-Chip elements of the\nchip. This thermal profile of the chip is then used by the predictive DTM that\ncombines both core level and network level DTM techniques. On-chip wireless\ninterconnect which is recently envisioned to enable energy-efficient data\nexchange between cores in a multicore environment, will be used to provide a\nbroadcast-capable medium to efficiently distribute thermal control messages to\ntrigger and manage the DTM schemes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 09:11:13 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Narayana", "Sandeep Aswath", ""]]}, {"id": "1612.04277", "submitter": "Juyong Shin", "authors": "Juyong Shin, Jongbo Bae, Ansu Na, Sang Lyul Min", "title": "Copycat: A High Precision Real Time NAND Simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the design and implementation of a high precision\nreal time NAND simulator called Copycat that runs on a commodity multi-core\ndesktop environment. This NAND simulator facilitates the development of\nembedded flash memory management software such as the flash translation layer\n(FTL). The simulator also allows a comprehensive fault injection for testing\nthe reliability of the FTL. Compared against a real FPGA implementation, the\nsimulator's response time deviation is under 0.28% on average, with a maximum\nof 10.12%.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 01:43:11 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Shin", "Juyong", ""], ["Bae", "Jongbo", ""], ["Na", "Ansu", ""], ["Min", "Sang Lyul", ""]]}, {"id": "1612.04855", "submitter": "Bayan Nasri", "authors": "Bayan Nasri, Sunit P. Sebastian, Kae-Dyi You, RamKumar RanjithKumar,\n  Davood Shahrjerdi", "title": "A 700uW 1GS/s 4-bit Folding-Flash ADC in 65nm CMOS for Wideband Wireless\n  Communications", "comments": "submitted to the the IEEE International Symposium of Circuits and\n  Systems (ISCAS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design of a low-power 4-bit 1GS/s folding-flash ADC with a\nfolding factor of two. The design of a new unbalanced double-tail dynamic\ncomparator affords an ultra-low power operation and a high dynamic range.\nUnlike the conventional approaches, this design uses a fully matched input\nstage, an unbalanced latch stage, and a two-clock operation scheme. A\ncombination of these features yields significant reduction of the kick-back\nnoise, while allowing the design flexibility for adjusting the trip points of\nthe comparators. As a result, the ADC achieves SNDR of 22.3 dB at 100MHz and\n21.8 dB at 500MHz (i.e. the Nyquist frequency). The maximum INL and DNL are\nabout 0.2 LSB. The converter consumes about 700uW from a 1-V supply yielding a\nfigure of merit of 65fJ/conversion step. These attributes make the proposed\nfolding-flash ADC attractive for the next-generation wireless applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 21:52:33 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Nasri", "Bayan", ""], ["Sebastian", "Sunit P.", ""], ["You", "Kae-Dyi", ""], ["RanjithKumar", "RamKumar", ""], ["Shahrjerdi", "Davood", ""]]}, {"id": "1612.04986", "submitter": "EPTCS", "authors": "Luk\\'a\\v{s} Charv\\'at (Faculty of Information Technology, Brno\n  University of Technology), Ale\\v{s} Smr\\v{c}ka (IT4Innovations Centre of\n  Excellence, FIT, Brno University of Technology), Tom\\'a\\v{s} Vojnar\n  (IT4Innovations Centre of Excellence, FIT, Brno University of Technology)", "title": "HADES: Microprocessor Hazard Analysis via Formal Verification of\n  Parameterized Systems", "comments": "In Proceedings MEMICS 2016, arXiv:1612.04037", "journal-ref": "EPTCS 233, 2016, pp. 87-93", "doi": "10.4204/EPTCS.233.9", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HADES is a fully automated verification tool for pipeline-based\nmicroprocessors that aims at flaws caused by improperly handled data hazards.\nIt focuses on single-pipeline microprocessors designed at the register transfer\nlevel (RTL) and deals with read-after-write, write-after-write, and\nwrite-after-read hazards. HADES combines several techniques, including\ndata-flow analysis, error pattern matching, SMT solving, and abstract regular\nmodel checking. It has been successfully tested on several microprocessors for\nembedded applications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 08:51:02 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Charv\u00e1t", "Luk\u00e1\u0161", "", "Faculty of Information Technology, Brno\n  University of Technology"], ["Smr\u010dka", "Ale\u0161", "", "IT4Innovations Centre of\n  Excellence, FIT, Brno University of Technology"], ["Vojnar", "Tom\u00e1\u0161", "", "IT4Innovations Centre of Excellence, FIT, Brno University of Technology"]]}, {"id": "1612.05166", "submitter": "Tobias Strauch", "authors": "Tobias Strauch", "title": "A Novel RTL ATPG Model Based on Gate Inherent Faults (GIF-PO) of Complex\n  Gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper starts with a comprehensive survey on RTL ATPG. It then proposes a\nnovel RTL ATPG model based on \"Gate Inherent Faults\" (GIF). These GIF are\nextracted from each complex gate (adder, case-statement, etc.) of the RTL\nsource code individually. They are related to the internal logic paths of a\ncomplex gate. They are not related to any net/signal in the RTL design. It is\nobserved, that when all GIF on RTL are covered (100%) and the same stimulus is\napplied, then all gate level stuck-at faults of the netlist are covered (100%)\nas well. The proposed RTL ATPG model is therefore synthesis independent. This\nis shown on ITC'99 testcases. The applied semi-automatic test pattern\ngeneration process is based on functional simulation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 17:55:06 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Strauch", "Tobias", ""]]}, {"id": "1612.05547", "submitter": "Jong Hun Han", "authors": "Jong Hun Han, Noa Zilberman, Bjoern A. Zeeb, Andreas Fiessler, Andrew\n  W. Moore", "title": "Prototyping RISC Based, Reconfigurable Networking Applications in Open\n  Source", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade we have witnessed a rapid growth in data center systems,\nrequiring new and highly complex networking devices. The need to refresh\nnetworking infrastructure whenever new protocols or functions are introduced,\nand the increasing costs that this entails, are of a concern to all data center\nproviders. New generations of Systems on Chip (SoC), integrating\nmicroprocessors and higher bandwidth interfaces, are an emerging solution to\nthis problem. These devices permit entirely new systems and architectures that\ncan obviate the replacement of existing networking devices while enabling\nseamless functionality change. In this work, we explore open source, RISC\nbased, SoC architectures with high performance networking capabilities. The\nprototype architectures are implemented on the NetFPGA-SUME platform. Beyond\ndetails of the architecture, we also describe the hardware implementation and\nthe porting of operating systems to the platform. The platform can be exploited\nfor the development of practical networking appliances, and we provide use case\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 16:42:28 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Han", "Jong Hun", ""], ["Zilberman", "Noa", ""], ["Zeeb", "Bjoern A.", ""], ["Fiessler", "Andreas", ""], ["Moore", "Andrew W.", ""]]}, {"id": "1612.05974", "submitter": "Francesco Conti", "authors": "Francesco Conti, Robert Schilling, Pasquale Davide Schiavone, Antonio\n  Pullini, Davide Rossi, Frank Kagan G\\\"urkaynak, Michael Muehlberghuber,\n  Michael Gautschi, Igor Loi, Germain Haugou, Stefan Mangard, Luca Benini", "title": "An IoT Endpoint System-on-Chip for Secure and Energy-Efficient\n  Near-Sensor Analytics", "comments": "15 pages, 12 figures, accepted for publication to the IEEE\n  Transactions on Circuits and Systems - I: Regular Papers", "journal-ref": null, "doi": "10.1109/TCSI.2017.2698019", "report-no": null, "categories": "cs.AR cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-sensor data analytics is a promising direction for IoT endpoints, as it\nminimizes energy spent on communication and reduces network load - but it also\nposes security concerns, as valuable data is stored or sent over the network at\nvarious stages of the analytics pipeline. Using encryption to protect sensitive\ndata at the boundary of the on-chip analytics engine is a way to address data\nsecurity issues. To cope with the combined workload of analytics and encryption\nin a tight power envelope, we propose Fulmine, a System-on-Chip based on a\ntightly-coupled multi-core cluster augmented with specialized blocks for\ncompute-intensive data processing and encryption functions, supporting software\nprogrammability for regular computing tasks. The Fulmine SoC, fabricated in\n65nm technology, consumes less than 20mW on average at 0.8V achieving an\nefficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to\n25MIPS/mW in software. As a strong argument for real-life flexible application\nof our platform, we show experimental results for three secure analytics use\ncases: secure autonomous aerial surveillance with a state-of-the-art deep CNN\nconsuming 3.16pJ per equivalent RISC op; local CNN-based face detection with\nsecured remote recognition in 5.74pJ/op; and seizure detection with encrypted\ndata collection from EEG within 12.7pJ/op.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 19:20:42 GMT"}, {"version": "v2", "created": "Sun, 2 Apr 2017 22:55:15 GMT"}, {"version": "v3", "created": "Sun, 23 Apr 2017 17:39:09 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Conti", "Francesco", ""], ["Schilling", "Robert", ""], ["Schiavone", "Pasquale Davide", ""], ["Pullini", "Antonio", ""], ["Rossi", "Davide", ""], ["G\u00fcrkaynak", "Frank Kagan", ""], ["Muehlberghuber", "Michael", ""], ["Gautschi", "Michael", ""], ["Loi", "Igor", ""], ["Haugou", "Germain", ""], ["Mangard", "Stefan", ""], ["Benini", "Luca", ""]]}, {"id": "1612.06748", "submitter": "Oskar Schirmer", "authors": "Oskar Schirmer", "title": "NOP - A Simple Experimental Processor for Parallel Deployment", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of a parallel computing system using several thousands or even up\nto a million processors asks for processing units that are simple and thus\nsmall in space, to make as many processing units as possible fit on a single\ndie.\n  The design presented herewith is far from being optimised, it is not meant to\ncompete with industry performance devices. Its main purpose is to allow for a\nprototypical implementation of a dynamic software system as a proof of concept.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 16:49:43 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Schirmer", "Oskar", ""]]}, {"id": "1612.07119", "submitter": "Yaman Umuroglu", "authors": "Yaman Umuroglu, Nicholas J. Fraser, Giulio Gambardella, Michaela\n  Blott, Philip Leong, Magnus Jahre, Kees Vissers", "title": "FINN: A Framework for Fast, Scalable Binarized Neural Network Inference", "comments": "To appear in the 25th International Symposium on Field-Programmable\n  Gate Arrays, February 2017", "journal-ref": null, "doi": "10.1145/3020078.3021744", "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that convolutional neural networks contain significant\nredundancy, and high classification accuracy can be obtained even when weights\nand activations are reduced from floating point to binary values. In this\npaper, we present FINN, a framework for building fast and flexible FPGA\naccelerators using a flexible heterogeneous streaming architecture. By\nutilizing a novel set of optimizations that enable efficient mapping of\nbinarized neural networks to hardware, we implement fully connected,\nconvolutional and pooling layers, with per-layer compute resources being\ntailored to user-provided throughput requirements. On a ZC706 embedded FPGA\nplatform drawing less than 25 W total system power, we demonstrate up to 12.3\nmillion image classifications per second with 0.31 {\\mu}s latency on the MNIST\ndataset with 95.8% accuracy, and 21906 image classifications per second with\n283 {\\mu}s latency on the CIFAR-10 and SVHN datasets with respectively 80.1%\nand 94.9% accuracy. To the best of our knowledge, ours are the fastest\nclassification rates reported to date on these benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 22:19:47 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Umuroglu", "Yaman", ""], ["Fraser", "Nicholas J.", ""], ["Gambardella", "Giulio", ""], ["Blott", "Michaela", ""], ["Leong", "Philip", ""], ["Jahre", "Magnus", ""], ["Vissers", "Kees", ""]]}, {"id": "1612.08163", "submitter": "Mahdi Jelodari Mamaghani", "authors": "Ana Lava, Mahdi Jelodari Mamaghani, Siamak Mohammadi and Steve Furber", "title": "Application-aware Retiming of Accelerators: A High-level Data-driven\n  Approach", "comments": "7 pages, 6 figures, submitted to IEEE Design and Test Journal -\n  special issue on Accelerators in October 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexibility at hardware level is the main driving force behind adaptive\nsystems whose aim is to realise microarhitecture deconfiguration 'online'. This\nfeature allows the software/hardware stack to tolerate drastic changes of the\nworkload in data centres. With emerge of FPGA reconfigurablity this technology\nis becoming a mainstream computing paradigm. Adaptivity is usually accompanied\nby the high-level tools to facilitate multi-dimensional space exploration. An\nessential aspect in this space is memory orchestration where on-chip and\noff-chip memory distribution significantly influences the architecture in\ncoping with the critical spatial and timing constraints, e.g. Place and Route.\nThis paper proposes a memory smart technique for a particular class of adaptive\nsystems: Elastic Circuits which enjoy slack elasticity at fine level of\ngranularity. We explore retiming of a set of popular benchmarks via\ninvestigating the memory distribution within and among accelerators. The area,\nperformance and power patterns are adopted by our high-level synthesis\nframework, with respect to the behaviour of the input descriptions, to improve\nthe quality of the synthesised elastic circuits.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 10:55:46 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Lava", "Ana", ""], ["Mamaghani", "Mahdi Jelodari", ""], ["Mohammadi", "Siamak", ""], ["Furber", "Steve", ""]]}, {"id": "1612.08239", "submitter": "Nanditha Rao Ms", "authors": "Nanditha P. Rao and Madhav P. Desai", "title": "Neutron induced strike: On the likelihood of multiple bit-flips in logic\n  circuits", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High energy particles from cosmic rays or packaging materials can generate a\nglitch or a current transient (single event transient or SET) in a logic\ncircuit. This SET can eventually get captured in a register resulting in a flip\nof the register content, which is known as soft error or single-event upset\n(SEU). A soft error is typically modeled as a probabilistic single bit-flip\nmodel. In developing such abstract fault models, an important issue to consider\nis the likelihood of multiple bit errors caused by particle strikes. The fact\nthat an SET causes multiple flips is noted in the literature. We perform a\ncharacterization study of the impact of an SET on a logic circuit to quantify\nthe extent to which an SET can cause multiple bit flips. We use post-layout\ncircuit simulations and Monte Carlo sampling scheme to get accurate bit-flip\nstatistics. We perform our simulations on ISCAS'85, ISCAS'89 and ITC'99\nbenchmarks in 180nm and 65nm technologies. We find that a substantial fraction\nof SEU outcomes had multiple register flips. We futher analyse the individual\ncontributions of the strike on a register and the strike on a logic gate, to\nmultiple flips. We find that, amongst the erroneous outcomes, the probability\nof multiple bit-flips for 'gate-strike' cases was substantial and went up to\n50%, where as those for 'register-strike' cases was just about 2%. This implies\nthat, in principle, we can eliminate the flips due to register strikes using\nhardened flip-flop designs. However, in such designs, out of the remaining\nflips which will be due to gate strikes, a large fraction is likely to be\nmultiple flips.\n", "versions": [{"version": "v1", "created": "Sun, 25 Dec 2016 06:20:51 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 04:42:02 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Rao", "Nanditha P.", ""], ["Desai", "Madhav P.", ""]]}, {"id": "1612.09524", "submitter": "Hamza Bendaoudi", "authors": "Hamza Bendaoudi, Farida Cheriet and J. M. Pierre Langlois", "title": "Memory Efficient Multi-Scale Line Detector Architecture for Retinal\n  Blood Vessel Segmentation", "comments": "This paper was accepted and presented at Conference on Design and\n  Architectures for Signal and Image Processing - DASIP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a memory efficient architecture that implements the\nMulti-Scale Line Detector (MSLD) algorithm for real-time retinal blood vessel\ndetection in fundus images on a Zynq FPGA. This implementation benefits from\nthe FPGA parallelism to drastically reduce the memory requirements of the MSLD\nfrom two images to a few values. The architecture is optimized in terms of\nresource utilization by reusing the computations and optimizing the bit-width.\nThe throughput is increased by designing fully pipelined functional units. The\narchitecture is capable of achieving a comparable accuracy to its software\nimplementation but 70x faster for low resolution images. For high resolution\nimages, it achieves an acceleration by a factor of 323x.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 19:06:28 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Bendaoudi", "Hamza", ""], ["Cheriet", "Farida", ""], ["Langlois", "J. M. Pierre", ""]]}]