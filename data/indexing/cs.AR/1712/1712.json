[{"id": "1712.00076", "submitter": "Ryan Kim", "authors": "Ryan Gary Kim, Janardhan Rao Doppa, Partha Pratim Pande, Diana\n  Marculescu, Radu Marculescu", "title": "Machine Learning and Manycore Systems Design: A Serendipitous Symbiosis", "comments": "To appear in a future publication of IEEE Computer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tight collaboration between experts of machine learning and manycore system\ndesign is necessary to create a data-driven manycore design framework that\nintegrates both learning and expert knowledge. Such a framework will be\nnecessary to address the rising complexity of designing large-scale manycore\nsystems and machine learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 20:56:17 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kim", "Ryan Gary", ""], ["Doppa", "Janardhan Rao", ""], ["Pande", "Partha Pratim", ""], ["Marculescu", "Diana", ""], ["Marculescu", "Radu", ""]]}, {"id": "1712.00905", "submitter": "Zhiwei Luo", "authors": "Haoyuan Wang and Zhiwei Luo", "title": "Data Cache Prefetching with Perceptron Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache prefetcher greatly eliminates compulsory cache misses, by fetching data\nfrom slower memory to faster cache before it is actually required by\nprocessors. Sophisticated prefetchers predict next use cache line by repeating\nprogram's historical spatial and temporal memory access pattern. However, they\nare error prone and the mis-predictions lead to cache pollution and exert extra\npressure on memory subsystem. In this paper, a novel scheme of data cache\nprefetching with perceptron learning is proposed. The key idea is a two-level\nprefetching mechanism. A primary decision is made by utilizing previous\ntable-based prefetching mechanism, e.g. stride prefetching or Markov\nprefetching, and then, a neural network, perceptron is taken to detect and\ntrace program memory access patterns, to help reject those unnecessary\nprefetching decisions. The perceptron can learn from both local and global\nhistory in time and space, and can be easily implemented by hardware. This\nmechanism boost execution performance by ideally mitigating cache pollution and\neliminating redundant memory request issued by prefetcher. Detailed evaluation\nand analysis were conducted based on SPEC CPU 2006 benchmarks. The simulation\nresults show that generally the proposed scheme yields a geometric mean of\n60.64%-83.84% decrease in prefetching memory requests without loss in\ninstruction per cycle(IPC)(floating between -2.22% and 2.55%) and cache hit\nrate(floating between -1.67% and 2.46%). Though it is possible that perceptron\nmay refuse useful blocks and thus cause minor raise in cache miss rate, lower\nmemory request count can decrease average memory access latency, which\ncompensate for the loss, and in the meantime, enhance overall performance in\nmulti-programmed workloads.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 05:01:30 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Wang", "Haoyuan", ""], ["Luo", "Zhiwei", ""]]}, {"id": "1712.00994", "submitter": "Francesco Conti", "authors": "Paolo Meloni, Alessandro Capotondi, Gianfranco Deriu, Michele Brian,\n  Francesco Conti, Davide Rossi, Luigi Raffo, Luca Benini", "title": "NEURAghe: Exploiting CPU-FPGA Synergies for Efficient and Flexible CNN\n  Inference Acceleration on Zynq SoCs", "comments": "22 pages, 14 figures, submitted to ACM Transactions on Reconfigurable\n  Technology and Systems", "journal-ref": "ACM Transactions on Reconfigurable Technology and Systems, Vol. 11\n  No. 3 (2018), Article 18", "doi": "10.1145/3284357", "report-no": null, "categories": "cs.NE cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) obtain outstanding results in tasks\nthat require human-level understanding of data, like image or speech\nrecognition. However, their computational load is significant, motivating the\ndevelopment of CNN-specialized accelerators. This work presents NEURAghe, a\nflexible and efficient hardware/software solution for the acceleration of CNNs\non Zynq SoCs. NEURAghe leverages the synergistic usage of Zynq ARM cores and of\na powerful and flexible Convolution-Specific Processor deployed on the\nreconfigurable logic. The Convolution-Specific Processor embeds both a\nconvolution engine and a programmable soft core, releasing the ARM processors\nfrom most of the supervision duties and allowing the accelerator to be\ncontrolled by software at an ultra-fine granularity. This methodology opens the\nway for cooperative heterogeneous computing: while the accelerator takes care\nof the bulk of the CNN workload, the ARM cores can seamlessly execute\nhard-to-accelerate parts of the computational graph, taking advantage of the\nNEON vector engines to further speed up computation. Through the companion\nNeuDNN SW stack, NEURAghe supports end-to-end CNN-based classification with a\npeak performance of 169 Gops/s, and an energy efficiency of 17 Gops/W. Thanks\nto our heterogeneous computing model, our platform improves upon the\nstate-of-the-art, achieving a frame rate of 5.5 fps on the end-to-end execution\nof VGG-16, and 6.6 fps on ResNet-18.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 10:41:53 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Meloni", "Paolo", ""], ["Capotondi", "Alessandro", ""], ["Deriu", "Gianfranco", ""], ["Brian", "Michele", ""], ["Conti", "Francesco", ""], ["Rossi", "Davide", ""], ["Raffo", "Luigi", ""], ["Benini", "Luca", ""]]}, {"id": "1712.01021", "submitter": "Florian Glaser", "authors": "Florian Glaser and Stefan Mach and Abbas Rahimi and Frank K.\n  G\\\"urkaynak and Qiuting Huang and Luca Benini", "title": "An 826 MOPS, 210 uW/MHz Unum ALU in 65 nm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the limitations of conventional floating-point number formats, an\ninterval arithmetic and variable-width storage format called universal number\n(unum) has been recently introduced. This paper presents the first (to the best\nof our knowledge) silicon implementation measurements of an\napplication-specific integrated circuit (ASIC) for unum floating-point\narithmetic. The designed chip includes a 128-bit wide unum arithmetic unit to\nexecute additions and subtractions, while also supporting lossless (for\nintermediate results) and lossy (for external data movements) compression units\nto exploit the memory usage reduction potential of the unum format. Our chip,\nfabricated in a 65 nm CMOS process, achieves a maximum clock frequency of 413\nMHz at 1.2 V with an average measured power of 210 uW/MHz.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:43:58 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 01:45:29 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Glaser", "Florian", ""], ["Mach", "Stefan", ""], ["Rahimi", "Abbas", ""], ["G\u00fcrkaynak", "Frank K.", ""], ["Huang", "Qiuting", ""], ["Benini", "Luca", ""]]}, {"id": "1712.01507", "submitter": "Hardik Sharma", "authors": "Hardik Sharma, Jongse Park, Naveen Suda, Liangzhen Lai, Benson Chau,\n  Joon Kyung Kim, Vikas Chandra, Hadi Esmaeilzadeh", "title": "Bit Fusion: Bit-Level Dynamically Composable Architecture for\n  Accelerating Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully realizing the potential of acceleration for Deep Neural Networks (DNNs)\nrequires understanding and leveraging algorithmic properties. This paper builds\nupon the algorithmic insight that bitwidth of operations in DNNs can be reduced\nwithout compromising their classification accuracy. However, to prevent\naccuracy loss, the bitwidth varies significantly across DNNs and it may even be\nadjusted for each layer. Thus, a fixed-bitwidth accelerator would either offer\nlimited benefits to accommodate the worst-case bitwidth requirements, or lead\nto a degradation in final accuracy. To alleviate these deficiencies, this work\nintroduces dynamic bit-level fusion/decomposition as a new dimension in the\ndesign of DNN accelerators. We explore this dimension by designing Bit Fusion,\na bit-flexible accelerator, that constitutes an array of bit-level processing\nelements that dynamically fuse to match the bitwidth of individual DNN layers.\nThis flexibility in the architecture enables minimizing the computation and the\ncommunication at the finest granularity possible with no loss in accuracy. We\nevaluate the benefits of BitFusion using eight real-world feed-forward and\nrecurrent DNNs. The proposed microarchitecture is implemented in Verilog and\nsynthesized in 45 nm technology. Using the synthesis results and cycle accurate\nsimulation, we compare the benefits of Bit Fusion to two state-of-the-art DNN\naccelerators, Eyeriss and Stripes. In the same area, frequency, and process\ntechnology, BitFusion offers 3.9x speedup and 5.1x energy savings over Eyeriss.\nCompared to Stripes, BitFusion provides 2.6x speedup and 3.9x energy reduction\nat 45 nm node when BitFusion area and frequency are set to those of Stripes.\nScaling to GPU technology node of 16 nm, BitFusion almost matches the\nperformance of a 250-Watt Titan Xp, which uses 8-bit vector instructions, while\nBitFusion merely consumes 895 milliwatts of power.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 07:20:33 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 14:56:34 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sharma", "Hardik", ""], ["Park", "Jongse", ""], ["Suda", "Naveen", ""], ["Lai", "Liangzhen", ""], ["Chau", "Benson", ""], ["Kim", "Joon Kyung", ""], ["Chandra", "Vikas", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1712.01743", "submitter": "Lukas Cavigelli", "authors": "Manuele Rusci, Lukas Cavigelli, Luca Benini", "title": "Design Automation for Binarized Neural Networks: A Quantum Leap\n  Opportunity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AR cs.CV cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design automation in general, and in particular logic synthesis, can play a\nkey role in enabling the design of application-specific Binarized Neural\nNetworks (BNN). This paper presents the hardware design and synthesis of a\npurely combinational BNN for ultra-low power near-sensor processing. We\nleverage the major opportunities raised by BNN models, which consist mostly of\nlogical bit-wise operations and integer counting and comparisons, for pushing\nultra-low power deep learning circuits close to the sensor and coupling it with\nbinarized mixed-signal image sensor data. We analyze area, power and energy\nmetrics of BNNs synthesized as combinational networks. Our synthesis results in\nGlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for\nimplementing a combinational BNN with 32x32 binary input sensor receptive field\nand weight parameters fixed at design time. This is 2.2x smaller than a\nsynthesized network with re-configurable parameters. With respect to other\ncomparable techniques for deep learning near-sensor processing, our approach\nfeatures a 10x higher energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 09:54:37 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Rusci", "Manuele", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1712.02053", "submitter": "Chenyang Xia", "authors": "ChenYang Xia and YouZhe Fan and Ji Chen and Chi-Ying Tsui", "title": "On Path Memory in List Successive Cancellation Decoder of Polar Codes", "comments": "5 pages, 6 figures, 2 tables", "journal-ref": null, "doi": "10.1109/ISCAS.2018.8351462", "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polar code is a breakthrough in coding theory. Using list successive\ncancellation decoding with large list size L, polar codes can achieve excellent\nerror correction performance. The L partial decoded vectors are stored in the\npath memory and updated according to the results of list management. In the\nstate-of-the-art designs, the memories are implemented with registers and a\nlarge crossbar is used for copying the partial decoded vectors from one block\nof memory to another during the update. The architectures are quite area-costly\nwhen the code length and list size are large. To solve this problem, we propose\ntwo optimization schemes for the path memory in this work. First, a folded path\nmemory architecture is presented to reduce the area cost. Second, we show a\nscheme that the path memory can be totally removed from the architecture.\nExperimental results show that these schemes effectively reduce the area of\npath memory.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 06:18:30 GMT"}, {"version": "v2", "created": "Sat, 9 Dec 2017 13:00:37 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Xia", "ChenYang", ""], ["Fan", "YouZhe", ""], ["Chen", "Ji", ""], ["Tsui", "Chi-Ying", ""]]}, {"id": "1712.03411", "submitter": "Guanshun Yu", "authors": "Guanshun Yu, Tom Y. Cheng, Blayne Kettlewell, Harrison Liew, Mingoo\n  Seok, Peter R. Kinget", "title": "FPGA with Improved Routability and Robustness in 130nm CMOS with\n  Open-Source CAD Targetability", "comments": "4 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines an FPGA VLSI design methodology that was used to realize\na fully functioning FPGA chip in 130nm CMOS with improved routability and\nmemory robustness. The architectural design space exploration and synthesis\ncapability were enabled by the Verilog-to-Routing CAD tool. The capabilities of\nthis tool were extended to enable bitstream generation and deployment. To\nvalidate the architecture and bitstream implementation, a Chisel (Constructing\nHardware in the Embedded Scala Language) model of the FPGA was created to\nrapidly verify the microarchitectural details of the device prior to schematic\ndesign. A custom carrier board and configuration tool were used to verify\ncorrect operational characteristics of the FPGA over various resource\nutilizations and clock frequencies.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 16:46:08 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Yu", "Guanshun", ""], ["Cheng", "Tom Y.", ""], ["Kettlewell", "Blayne", ""], ["Liew", "Harrison", ""], ["Seok", "Mingoo", ""], ["Kinget", "Peter R.", ""]]}, {"id": "1712.03477", "submitter": "Xuan-Thuan Nguyen Dr", "authors": "Xuan-Thuan Nguyen, Duc-Hung Le, Trong-Tu Bui, Huu-Thuan Huynh, and\n  Cong-Kha Pham", "title": "A Flexible High-Bandwidth Low-Latency Multi-Port Memory Controller", "comments": "13 pages", "journal-ref": "Vietnam Journal of Science and Technology, Vol. 56(3), 2018, pp.\n  357-369", "doi": "10.15625/2525-2518/56/3/11103", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-port memory controllers (MPMCs) have become increasingly important in\nmany modern applications due to the tremendous growth in bandwidth requirement.\nMany approaches so far have focused on improving either the memory access\nlatency or the bandwidth utilization for specific applications. Moreover, the\napplication systems are likely to require certain adjustments to connect with\nan MPMC, since the MPMC interface is limited to a single-clock and single\ndata-width domain. In this paper, we propose efficient techniques to improve\nthe flexibility, latency, and bandwidth of an MPMC. Firstly, MPMC interfaces\nemploy a pair of dual-clock dual-port FIFOs at each port, so any multi-clock\nmulti-data-width application system can connect to an MPMC without requiring\nextra resources. Secondly, memory access latency is significantly reduced\nbecause parallel FIFOs temporarily keep the data transfer between the\napplication system and memory. Lastly, a proposed arbitration scheme, namely\nwindow-based first-come-first-serve, considerably enhances the bandwidth\nutilization. Depending on the applications, MPMC can be properly configured by\nupdating several internal configuration registers. The experimental results in\nan Altera Cyclone FPGA prove that MPMC is fully operational at 150 MHz and\nsupports up to 32 concurrent connections at various clocks and data widths.\nMore significantly, achieved bandwidth utilization is approximately 93.2% of\nthe theoretical bandwidth, and the access latency is minimized as compared to\nprevious designs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 07:34:59 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 14:39:46 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Nguyen", "Xuan-Thuan", ""], ["Le", "Duc-Hung", ""], ["Bui", "Trong-Tu", ""], ["Huynh", "Huu-Thuan", ""], ["Pham", "Cong-Kha", ""]]}, {"id": "1712.03478", "submitter": "Xuan-Thuan Nguyen Dr", "authors": "Xuan-Thuan Nguyen, Hong-Thu Nguyen, and Cong-Kha Pham", "title": "A Scalable High-Performance Priority Encoder Using 1D-Array to 2D-Array\n  Conversion", "comments": "5 pages", "journal-ref": "IEEE Transactions on Circuits and Systems II: Express Briefs (\n  Volume: 64, Issue: 9, Sept. 2017 )", "doi": "10.1109/TCSII.2017.2672865", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our prior study of an L-bit priority encoder (PE), a so-called\none-directional-array to two-directional-array conversion method is deployed to\nturn an L-bit input data into an MxN-bit matrix. Following this, an N-bit PE\nand an M-bit PE are employed to obtain a row index and column index. From\nthose, the highest priority bit of L-bit input data is achieved. This brief\nextends our previous work to construct a scalable architecture of\nhigh-performance large-sized PEs. An optimum pair of (M, N) and look-ahead\nsignal are proposed to improve the overall PE performance significantly. The\nevaluation is achieved by implementing a variety of PEs whose L varies from\n4-bit to 4096-bit in 180-nm CMOS technology. According to post-place-and-route\nsimulation results, at PE size of 64 bits, 256 bits, and 2048 bits the\noperating frequencies reach 649 MHz, 520 MHz, and 370 MHz, which are 1.2 times,\n1.5 times, and 1.4 times, as high as state-of-the-art ones.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 07:44:56 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Nguyen", "Xuan-Thuan", ""], ["Nguyen", "Hong-Thu", ""], ["Pham", "Cong-Kha", ""]]}, {"id": "1712.03948", "submitter": "Yanxiang Huang", "authors": "Yanxiang Huang", "title": "Cross-Layer Optimization for Power-Efficient and Robust Digital Circuits\n  and Systems", "comments": "190 pages", "journal-ref": "KU Leuven PhD thesis 2017", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the increasing digital services demand, performance and power-efficiency\nbecome vital requirements for digital circuits and systems. However, the\nenabling CMOS technology scaling has been facing significant challenges of\ndevice uncertainties, such as process, voltage, and temperature variations. To\nensure system reliability, worst-case corner assumptions are usually made in\neach design level. However, the over-pessimistic worst-case margin leads to\nunnecessary power waste and performance loss as high as 2.2x. Since\noptimizations are traditionally confined to each specific level, those safe\nmargins can hardly be properly exploited.\n  To tackle the challenge, it is therefore advised in this Ph.D. thesis to\nperform a cross-layer optimization for digital signal processing circuits and\nsystems, to achieve a global balance of power consumption and output quality.\n  To conclude, the traditional over-pessimistic worst-case approach leads to\nhuge power waste. In contrast, the adaptive voltage scaling approach saves\npower (25% for the CORDIC application) by providing a just-needed supply\nvoltage. The power saving is maximized (46% for CORDIC) when a more aggressive\nvoltage over-scaling scheme is applied. These sparsely occurred circuit errors\nproduced by aggressive voltage over-scaling are mitigated by higher level error\nresilient designs. For functions like FFT and CORDIC, smart error mitigation\nschemes were proposed to enhance reliability (soft-errors and timing-errors,\nrespectively). Applications like Massive MIMO systems are robust against lower\nlevel errors, thanks to the intrinsically redundant antennas. This property\nmakes it applicable to embrace digital hardware that trades quality for power\nsavings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:54:49 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Huang", "Yanxiang", ""]]}, {"id": "1712.03994", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Carlo Condo and Warren J. Gross", "title": "Multi-Mode Inference Engine for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past few years, interest in convolutional neural networks (CNNs)\nhas risen constantly, thanks to their excellent performance on a wide range of\nrecognition and classification tasks. However, they suffer from the high level\nof complexity imposed by the high-dimensional convolutions in convolutional\nlayers. Within scenarios with limited hardware resources and tight power and\nlatency constraints, the high computational complexity of CNNs makes them\ndifficult to be exploited. Hardware solutions have striven to reduce the power\nconsumption using low-power techniques, and to limit the processing time by\nincreasing the number of processing elements (PEs). While most of ASIC designs\nclaim a peak performance of a few hundred giga operations per seconds, their\naverage performance is substantially lower when applied to state-of-the-art\nCNNs such as AlexNet, VGGNet and ResNet, leading to low resource utilization.\nTheir performance efficiency is limited to less than 55% on average, which\nleads to unnecessarily high processing latency and silicon area. In this paper,\nwe propose a dataflow which enables to perform both the fully-connected and\nconvolutional computations for any filter/layer size using the same PEs. We\nthen introduce a multi-mode inference engine (MMIE) based on the proposed\ndataflow. Finally, we show that the proposed MMIE achieves a performance\nefficiency of more than 84% when performing the computations of the three\nrenown CNNs (i.e., AlexNet, VGGNet and ResNet), outperforming the best\narchitecture in the state-of-the-art in terms of energy consumption, processing\nlatency and silicon area.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 19:31:52 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Ardakani", "Arash", ""], ["Condo", "Carlo", ""], ["Gross", "Warren J.", ""]]}, {"id": "1712.04322", "submitter": "Francois Berry", "authors": "Kamel Abdelouahab (IP), Maxime Pelcat (IETR), Jocelyn S\\'erot (IP),\n  C\\'edric Bourrasset (IP), Fran\\c{c}ois Berry (IP), Jocelyn Serot (LASMEA)", "title": "Tactics to Directly Map CNN graphs on Embedded FPGAs", "comments": "IEEE Embedded Systems Letters, Institute of Electrical and\n  Electronics Engineers, A Para\\^itre, pp.1 - 1. arXiv admin note: text overlap\n  with arXiv:1705.04543", "journal-ref": null, "doi": "10.1109/LES.2017.2743247", "report-no": null, "categories": "cs.DC cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) are the state-of-the-art in image\nclassification. Since CNN feed forward propagation involves highly regular\nparallel computation, it benefits from a significant speed-up when running on\nfine grain parallel programmable logic devices. As a consequence, several\nstudies have proposed FPGA-based accelerators for CNNs. However, because of the\nlarge computationalpower required by CNNs, none of the previous studies has\nproposed a direct mapping of the CNN onto the physical resources of an FPGA,\nallocating each processing actor to its own hardware instance.In this paper, we\ndemonstrate the feasibility of the so called direct hardware mapping (DHM) and\ndiscuss several tactics we explore to make DHM usable in practice. As a proof\nof concept, we introduce the HADDOC2 open source tool, that automatically\ntransforms a CNN description into a synthesizable hardware description with\nplatform-independent direct hardware mapping.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 08:13:39 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Abdelouahab", "Kamel", "", "IP"], ["Pelcat", "Maxime", "", "IETR"], ["S\u00e9rot", "Jocelyn", "", "IP"], ["Bourrasset", "C\u00e9dric", "", "IP"], ["Berry", "Fran\u00e7ois", "", "IP"], ["Serot", "Jocelyn", "", "LASMEA"]]}, {"id": "1712.04614", "submitter": "Skanda Koppula", "authors": "Mohamed Abdelhamid, Skanda Koppula", "title": "Applying the Residue Number System to Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the lesser studied objective of optimizing the\nmultiply-and-accumulates executed during evaluation of the network. In\nparticular, we propose using the Residue Number System (RNS) as the internal\nnumber representation across all layer evaluations, allowing us to explore\nusage of the more power-efficient RNS multipliers and adders. Using results\nfrom simulation of our RNS arithmetic block implementations, we show\ntheoretical power advantages of using RNS for an end-to-end evaluator.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 05:48:44 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Abdelhamid", "Mohamed", ""], ["Koppula", "Skanda", ""]]}, {"id": "1712.04771", "submitter": "Wenqi Lou", "authors": "Chao Wang, Wenqi Lou, Lei Gong, Lihui Jin, Luchao Tan, Yahui Hu, Xi\n  Li, Xuehai Zhou", "title": "Reconfigurable Hardware Accelerators: Opportunities, Trends, and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging big data applications of Machine Learning, Speech\nRecognition, Artificial Intelligence, and DNA Sequencing in recent years,\ncomputer architecture research communities are facing the explosive scale of\nvarious data explosion. To achieve high efficiency of data-intensive computing,\nstudies of heterogeneous accelerators which focus on latest applications, have\nbecome a hot issue in computer architecture domain. At present, the\nimplementation of heterogeneous accelerators mainly relies on heterogeneous\ncomputing units such as Application-specific Integrated Circuit (ASIC),\nGraphics Processing Unit (GPU), and Field Programmable Gate Array (FPGA). Among\nthe typical heterogeneous architectures above, FPGA-based reconfigurable\naccelerators have two merits as follows: First, FPGA architecture contains a\nlarge number of reconfigurable circuits, which satisfy requirements of high\nperformance and low power consumption when specific applications are running.\nSecond, the reconfigurable architectures of employing FPGA performs prototype\nsystems rapidly and features excellent customizability and reconfigurability.\nNowadays, in top-tier conferences of computer architecture, emerging a batch of\naccelerating works based on FPGA or other reconfigurable architectures. To\nbetter review the related work of reconfigurable computing accelerators\nrecently, this survey reserves latest high-level research products of\nreconfigurable accelerator architectures and algorithm applications as the\nbasis. In this survey, we compare hot research issues and concern domains,\nfurthermore, analyze and illuminate advantages, disadvantages, and challenges\nof reconfigurable accelerators. In the end, we prospect the development\ntendency of accelerator architectures in the future, hoping to provide a\nreference for computer architecture researchers.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 14:01:19 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Wang", "Chao", ""], ["Lou", "Wenqi", ""], ["Gong", "Lei", ""], ["Jin", "Lihui", ""], ["Tan", "Luchao", ""], ["Hu", "Yahui", ""], ["Li", "Xi", ""], ["Zhou", "Xuehai", ""]]}, {"id": "1712.04892", "submitter": "Nirmal Prajapati", "authors": "Nirmal Prajapati, Sanjay Rajopadhye, Hristo Djidjev, Nandkishore\n  Santhi, Tobias Grosser and Rumen Andonov", "title": "Accelerator Codesign as Non-Linear Optimization", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an optimization approach for determining both hardware and\nsoftware parameters for the efficient implementation of a (family of)\napplications called dense stencil computations on programmable GPGPUs. We first\nintroduce a simple, analytical model for the silicon area usage of accelerator\narchitectures and a workload characterization of stencil computations. We\ncombine this characterization with a parametric execution time model and\nformulate a mathematical optimization problem. That problem seeks to maximize a\ncommon objective function of 'all the hardware and software parameters'. The\nsolution to this problem, therefore \"solves\" the codesign problem:\nsimultaneously choosing software-hardware parameters to optimize total\nperformance.\n  We validate this approach by proposing architectural variants of the NVIDIA\nMaxwell GTX-980 (respectively, Titan X) specifically tuned to a predetermined\nworkload of four common 2D stencils (Heat, Jacobi, Laplacian, and Gradient) and\ntwo 3D ones (Heat and Laplacian). Our model predicts that performance would\npotentially improve by 28% (respectively, 33%) with simple tweaks to the\nhardware parameters such as adapting coarse and fine-grained parallelism by\nchanging the number of streaming multiprocessors and the number of compute\ncores each contains. We propose a set of Pareto-optimal design points to\nexploit the trade-off between performance and silicon area and show that by\nadditionally eliminating GPU caches, we can get a further 2-fold improvement.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 18:00:58 GMT"}], "update_date": "2017-12-26", "authors_parsed": [["Prajapati", "Nirmal", ""], ["Rajopadhye", "Sanjay", ""], ["Djidjev", "Hristo", ""], ["Santhi", "Nandkishore", ""], ["Grosser", "Tobias", ""], ["Andonov", "Rumen", ""]]}, {"id": "1712.04902", "submitter": "Mauro Olivieri", "authors": "Abdallah Cheikh, Gianmarco Cerutti, Antonio Mastrandrea, Francesco\n  Menichelli, Mauro Olivieri", "title": "The microarchitecture of a multi-threaded RISC-V compliant processing\n  core family for IoT end-nodes", "comments": "8 pages", "journal-ref": "ApplePies 2017. Lecture Notes in Electrical Engineering, vol 512.\n  2019. Springer", "doi": "10.1007/978-3-319-93082-4_12", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things end-nodes demand low power processing platforms\ncharacterized by heterogeneous dedicated units, controlled by a processor core\nrunning concurrent control threads. Such architecture scheme fits one of the\nmain target application domain of the RISC-V instruction set. We present an\nopen-source processing core compliant with RISC-V on the software side and with\nthe popular Pulpino processor platform on the hardware side, while supporting\ninterleaved multi-threading for IoT applications. The latter feature is a novel\ncontribution in this application domain. We report details about the\nmicroarchitecture design along with performance data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 18:14:18 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Cheikh", "Abdallah", ""], ["Cerutti", "Gianmarco", ""], ["Mastrandrea", "Antonio", ""], ["Menichelli", "Francesco", ""], ["Olivieri", "Mauro", ""]]}, {"id": "1712.06272", "submitter": "Sakyasingha Dasgupta", "authors": "Farhan Shafiq, Takato Yamada, Antonio T. Vilchez, and Sakyasingha\n  Dasgupta", "title": "Automated flow for compressing convolution neural networks for efficient\n  edge-computation with FPGA", "comments": "7 pages, 9 figures. Accepted and presented at MLPCD workshop, NIPS\n  2017 (LongBeach, California)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) based solutions are the current\nstate- of-the-art for computer vision tasks. Due to the large size of these\nmodels, they are typically run on clusters of CPUs or GPUs. However, power\nrequirements and cost budgets can be a major hindrance in adoption of CNN for\nIoT applications. Recent research highlights that CNN contain significant\nredundancy in their structure and can be quantized to lower bit-width\nparameters and activations, while maintaining acceptable accuracy. Low\nbit-width and especially single bit-width (binary) CNN are particularly\nsuitable for mobile applications based on FPGA implementation, due to the\nbitwise logic operations involved in binarized CNN. Moreover, the transition to\nlower bit-widths opens new avenues for performance optimizations and model\nimprovement. In this paper, we present an automatic flow from trained\nTensorFlow models to FPGA system on chip implementation of binarized CNN. This\nflow involves quantization of model parameters and activations, generation of\nnetwork and model in embedded-C, followed by automatic generation of the FPGA\naccelerator for binary convolutions. The automated flow is demonstrated through\nimplementation of binarized \"YOLOV2\" on the low cost, low power Cyclone- V FPGA\ndevice. Experiments on object detection using binarized YOLOV2 demonstrate\nsignificant performance benefit in terms of model size and inference speed on\nFPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire\nautomated flow from trained models to FPGA synthesis can be completed within\none hour.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 07:02:07 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Shafiq", "Farhan", ""], ["Yamada", "Takato", ""], ["Vilchez", "Antonio T.", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1712.06497", "submitter": "Andreas Kurth", "authors": "Andreas Kurth, Pirmin Vogel, Alessandro Capotondi, Andrea Marongiu,\n  Luca Benini", "title": "HERO: Heterogeneous Embedded Research Platform for Exploring RISC-V\n  Manycore Accelerators on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous embedded systems on chip (HESoCs) co-integrate a standard host\nprocessor with programmable manycore accelerators (PMCAs) to combine\ngeneral-purpose computing with domain-specific, efficient processing\ncapabilities. While leading companies successfully advance their HESoC\nproducts, research lags behind due to the challenges of building a prototyping\nplatform that unites an industry-standard host processor with an open research\nPMCA architecture. In this work we introduce HERO, an FPGA-based research\nplatform that combines a PMCA composed of clusters of RISC-V cores, implemented\nas soft cores on an FPGA fabric, with a hard ARM Cortex-A multicore host\nprocessor. The PMCA architecture mapped on the FPGA is silicon-proven,\nscalable, configurable, and fully modifiable. HERO includes a complete software\nstack that consists of a heterogeneous cross-compilation toolchain with support\nfor OpenMP accelerator programming, a Linux driver, and runtime libraries for\nboth host and PMCA. HERO is designed to facilitate rapid exploration on all\nsoftware and hardware layers: run-time behavior can be accurately analyzed by\ntracing events, and modifications can be validated through fully automated hard\nware and software builds and executed tests. We demonstrate the usefulness of\nHERO by means of case studies from our research.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 16:14:49 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Kurth", "Andreas", ""], ["Vogel", "Pirmin", ""], ["Capotondi", "Alessandro", ""], ["Marongiu", "Andrea", ""], ["Benini", "Luca", ""]]}, {"id": "1712.07754", "submitter": "Kevin Chang", "authors": "Kevin K. Chang, Donghyuk Lee, Zeshan Chishti, Alaa R. Alameldeen,\n  Chris Wilkerson, Yoongu Kim, Onur Mutlu", "title": "Improving DRAM Performance by Parallelizing Refreshes with Accesses", "comments": "The original paper published in the International Symposium on\n  High-Performance Computer Architecture (HPCA) contains an error. The arxiv\n  version has an erratum that describes the error and the fix for it", "journal-ref": "2014 IEEE 20th International Symposium on High Performance\n  Computer Architecture (HPCA), Orlando, FL, 2014, pp. 356-367", "doi": "10.1109/HPCA.2014.6835946", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern DRAM cells are periodically refreshed to prevent data loss due to\nleakage. Commodity DDR DRAM refreshes cells at the rank level. This degrades\nperformance significantly because it prevents an entire rank from serving\nmemory requests while being refreshed. DRAM designed for mobile platforms,\nLPDDR DRAM, supports an enhanced mode, called per-bank refresh, that refreshes\ncells at the bank level. This enables a bank to be accessed while another in\nthe same rank is being refreshed, alleviating part of the negative performance\nimpact of refreshes. However, there are two shortcomings of per-bank refresh.\nFirst, the per-bank refresh scheduling scheme does not exploit the full\npotential of overlapping refreshes with accesses across banks because it\nrestricts the banks to be refreshed in a sequential round-robin order. Second,\naccesses to a bank that is being refreshed have to wait.\n  To mitigate the negative performance impact of DRAM refresh, we propose two\ncomplementary mechanisms, DARP (Dynamic Access Refresh Parallelization) and\nSARP (Subarray Access Refresh Parallelization). The goal is to address the\ndrawbacks of per-bank refresh by building more efficient techniques to\nparallelize refreshes and accesses within DRAM. First, instead of issuing\nper-bank refreshes in a round-robin order, DARP issues per-bank refreshes to\nidle banks in an out-of-order manner. Furthermore, DARP schedules refreshes\nduring intervals when a batch of writes are draining to DRAM. Second, SARP\nexploits the existence of mostly-independent subarrays within a bank. With\nminor modifications to DRAM organization, it allows a bank to serve memory\naccesses to an idle subarray while another subarray is being refreshed.\nExtensive evaluations show that our mechanisms improve system performance and\nenergy efficiency compared to state-of-the-art refresh policies and the benefit\nincreases as DRAM density increases.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 00:35:24 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Chang", "Kevin K.", ""], ["Lee", "Donghyuk", ""], ["Chishti", "Zeshan", ""], ["Alameldeen", "Alaa R.", ""], ["Wilkerson", "Chris", ""], ["Kim", "Yoongu", ""], ["Mutlu", "Onur", ""]]}, {"id": "1712.08254", "submitter": "Himanshu Thapliyal", "authors": "Edgard Mu\\~noz-Coreas and Himanshu Thapliyal", "title": "T-count and Qubit Optimized Quantum Circuit Design of the Non-Restoring\n  Square Root Algorithm", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum circuits for basic mathematical functions such as the square root are\nrequired to implement scientific computing algorithms on quantum computers.\nQuantum circuits that are based on Clifford+T gates can easily be made fault\ntolerant but the T gate is very costly to implement. As a result, reducing\nT-count has become an important optimization goal. Further, quantum circuits\nwith many qubits are difficult to realize, making designs that save qubits and\nproduce no garbage outputs desirable. In this work, we present a T-count\noptimized quantum square root circuit with only $2 \\cdot n +1$ qubits and no\ngarbage output. To make a fair comparison against existing work, the Bennett's\ngarbage removal scheme is used to remove garbage output from existing works. We\ndetermined that our proposed design achieves an average T-count savings of\n$43.44 \\%$, $98.95 \\%$, $41.06 \\%$ and $20.28 \\%$ as well as qubit savings of\n$85.46 \\%$, $95.16 \\%$, $90.59 \\%$ and $86.77 \\%$ compared to existing works.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 23:56:19 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 18:52:13 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 22:08:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Mu\u00f1oz-Coreas", "Edgard", ""], ["Thapliyal", "Himanshu", ""]]}, {"id": "1712.08304", "submitter": "Kevin Chang", "authors": "Kevin K. Chang", "title": "Understanding and Improving the Latency of DRAM-Based Memory Systems", "comments": "PhD Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, the storage capacity and access bandwidth of main\nmemory have improved tremendously, by 128x and 20x, respectively. These\nimprovements are mainly due to the continuous technology scaling of DRAM\n(dynamic random-access memory), which has been used as the physical substrate\nfor main memory. In stark contrast with capacity and bandwidth, DRAM latency\nhas remained almost constant, reducing by only 1.3x in the same time frame.\nTherefore, long DRAM latency continues to be a critical performance bottleneck\nin modern systems. Increasing core counts, and the emergence of increasingly\nmore data-intensive and latency-critical applications further stress the\nimportance of providing low-latency memory access.\n  In this dissertation, we identify three main problems that contribute\nsignificantly to long latency of DRAM accesses. To address these problems, we\npresent a series of new techniques. Our new techniques significantly improve\nboth system performance and energy efficiency. We also examine the critical\nrelationship between supply voltage and latency in modern DRAM chips and\ndevelop new mechanisms that exploit this voltage-latency trade-off to improve\nenergy efficiency.\n  The key conclusion of this dissertation is that augmenting DRAM architecture\nwith simple and low-cost features, and developing a better understanding of\nmanufactured DRAM chips together lead to significant memory latency reduction\nas well as energy efficiency improvement. We hope and believe that the proposed\narchitectural techniques and the detailed experimental data and observations on\nreal commodity DRAM chips presented in this dissertation will enable\ndevelopment of other new mechanisms to improve the performance, energy\nefficiency, or reliability of future memory systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 04:59:10 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Chang", "Kevin K.", ""]]}, {"id": "1712.08934", "submitter": "Kaiyuan Guo", "authors": "Kaiyuan Guo, Shulin Zeng, Jincheng Yu, Yu Wang and Huazhong Yang", "title": "A Survey of FPGA-Based Neural Network Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches on neural network have shown significant advantage in\nmachine learning over traditional algorithms based on handcrafted features and\nmodels. Neural network is now widely adopted in regions like image, speech and\nvideo recognition. But the high computation and storage complexity of neural\nnetwork inference poses great difficulty on its application. CPU platforms are\nhard to offer enough computation capacity. GPU platforms are the first choice\nfor neural network process because of its high computation capacity and easy to\nuse development frameworks.\n  On the other hand, FPGA-based neural network inference accelerator is\nbecoming a research topic. With specifically designed hardware, FPGA is the\nnext possible solution to surpass GPU in speed and energy efficiency. Various\nFPGA-based accelerator designs have been proposed with software and hardware\noptimization techniques to achieve high speed and energy efficiency. In this\npaper, we give an overview of previous work on neural network inference\naccelerators based on FPGA and summarize the main techniques used. An\ninvestigation from software to hardware, from circuit level to system level is\ncarried out to complete analysis of FPGA-based neural network inference\naccelerator design and serves as a guide to future work.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 14:54:41 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 07:04:22 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 07:28:26 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Guo", "Kaiyuan", ""], ["Zeng", "Shulin", ""], ["Yu", "Jincheng", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "1712.09818", "submitter": "Payman Behnam", "authors": "Payman Behnam, Bijan Alizadeh, and Sajjad Taheri", "title": "Automated Formal Equivalence Verification of Pipelined Nested Loops in\n  Datapath Designs", "comments": "14 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient formal approach to check the\nequivalence of synthesized RTL against the high-level specification in the\npresence of pipelining transformations. To increase the scalability of our\nproposed method, we dynamically divide the designs into several smaller parts\ncalled segments by introducing cut-points. Then we employ Modular Horner\nExpansion Diagram (M-HED) to check whether the specification and implementation\nare equivalent or not. In an iterative manner, the equivalence checking for\neach segment is performed. At each step, the equivalent nodes and those nodes\nwhich have an impact on them are removed until the whole design is covered. Our\nproposed method enables us to deal with the equivalence checking problem for\nbehaviorally synthesized designs even in the presence of pipelines for nested\nloops. The empirical results demonstrate the efficiency and scalability of our\nproposed method in terms of run-time and memory usage for several large designs\nsynthesized by a commercial behavioral synthesis tool. Average improvements in\nterms of the memory usage and run time in comparison with SMT- and SAT-based\nequivalence checking are 16.7x and 111.9x, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 10:46:05 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Behnam", "Payman", ""], ["Alizadeh", "Bijan", ""], ["Taheri", "Sajjad", ""]]}]