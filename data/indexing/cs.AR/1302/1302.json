[{"id": "1302.1078", "submitter": "Erik Saule", "authors": "Erik Saule, Kamer Kaya, Umit V. Catalyurek", "title": "Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel\n  Xeon Phi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Xeon Phi is a recently released high-performance coprocessor which\nfeatures 61 cores each supporting 4 hardware threads with 512-bit wide SIMD\nregisters achieving a peak theoretical performance of 1Tflop/s in double\nprecision. Many scientific applications involve operations on large sparse\nmatrices such as linear solvers, eigensolver, and graph mining algorithms. The\ncore of most of these applications involves the multiplication of a large,\nsparse matrix with a dense vector (SpMV). In this paper, we investigate the\nperformance of the Xeon Phi coprocessor for SpMV. We first provide a\ncomprehensive introduction to this new architecture and analyze its peak\nperformance with a number of micro benchmarks. Although the design of a Xeon\nPhi core is not much different than those of the cores in modern processors,\nits large number of cores and hyperthreading capability allow many application\nto saturate the available memory bandwidth, which is not the case for many\ncutting-edge processors. Yet, our performance studies show that it is the\nmemory latency not the bandwidth which creates a bottleneck for SpMV on this\narchitecture. Finally, our experiments show that Xeon Phi's sparse kernel\nperformance is very promising and even better than that of cutting-edge general\npurpose processors and GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 16:06:15 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Saule", "Erik", ""], ["Kaya", "Kamer", ""], ["Catalyurek", "Umit V.", ""]]}, {"id": "1302.1390", "submitter": "Raphael `kena' Poss", "authors": "Mike Lankamp and Raphael Poss and Qiang Yang and Jian Fu and Irfan\n  Uddin and Chris R. Jesshope", "title": "MGSim - Simulation tools for multi-core processor architectures", "comments": "33 pages, 22 figures, 4 listings, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MGSim is an open source discrete event simulator for on-chip hardware\ncomponents, developed at the University of Amsterdam. It is intended to be a\nresearch and teaching vehicle to study the fine-grained hardware/software\ninteractions on many-core and hardware multithreaded processors. It includes\nsupport for core models with different instruction sets, a configurable\nmulti-core interconnect, multiple configurable cache and memory models, a\ndedicated I/O subsystem, and comprehensive monitoring and interaction\nfacilities. The default model configuration shipped with MGSim implements\nMicrogrids, a many-core architecture with hardware concurrency management.\nMGSim is furthermore written mostly in C++ and uses object classes to represent\nchip components. It is optimized for architecture models that can be described\nas process networks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:00:35 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Lankamp", "Mike", ""], ["Poss", "Raphael", ""], ["Yang", "Qiang", ""], ["Fu", "Jian", ""], ["Uddin", "Irfan", ""], ["Jesshope", "Chris R.", ""]]}, {"id": "1302.4172", "submitter": "Nilesh Mohota Ashok", "authors": "Nilesh A. Mohota, Sanjay L. Badjate", "title": "Reduction in Packet Delay Through the use of Common Buffer over\n  Distributed Buffer in the Routing Node of NOC Architecture", "comments": "8 Pages, 10 Figures, 2 Tables", "journal-ref": "International Journal of Innovative Technology and Creative\n  Engineering, ISSN : 2045-8711, December 2012 Issue, Volume2, No. 12", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance evaluation of the routing node in terms of latency is the\ncharacteristics of an efficient design of Buffer in input module. It is\nintended to study and quantify the behavior of the single packet array design\nin relation to the multiple packet array design. The utilization efficiency of\nthe packet buffer array improves when a common buffer is used instead of\nindividual buffers in each input port. First Poissons Queuing model was\nprepared to manifest the differences in packet delays. The queuing model can be\nclassified as (M/M/1), (32/FIFO). Arrival rate has been assumed to be Poisson\ndistributed with a mean arrival rate of 10 x 1000000. The service rate is\nassumed to be exponentially distributed with a mean service rate of 10.05 x\n1000000. It has been observed that latency in Common Buffer improved by 46\npercent over its distributed buffer. A Simulink model later simulated on MATLAB\nto calculate the improvement in packet delay. It has been observed that the\ndelay improved by approximately 40 percent through the use of a common buffer.\nA verilog RTL for both common and shared buffer has been prepared and later\nsynthesized using Design Compiler of SYNOPSYS. In distributed buffer, arrival\nof data packet could be delayed by 2 or 4 clock cycles which lead to latency\nimprovement either by 17 percent or 34 percent in a common buffer\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 07:35:15 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Mohota", "Nilesh A.", ""], ["Badjate", "Sanjay L.", ""]]}, {"id": "1302.4463", "submitter": "Hooman Jarollahi", "authors": "Hooman Jarollahi, Vincent Gripon, Naoya Onizawa, Warren J. Gross", "title": "A Low-Power Content-Addressable-Memory Based on\n  Clustered-Sparse-Networks", "comments": "Submitted to IEEE ASAP 2013", "journal-ref": null, "doi": "10.1109/ASAP.2013.6567594", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A low-power Content-Addressable-Memory (CAM) is introduced employing a new\nmechanism for associativity between the input tags and the corresponding\naddress of the output data. The proposed architecture is based on a recently\ndeveloped clustered-sparse-network using binary-weighted connections that\non-average will eliminate most of the parallel comparisons performed during a\nsearch. Therefore, the dynamic energy consumption of the proposed design is\nsignificantly lower compared to that of a conventional low-power CAM design.\nGiven an input tag, the proposed architecture computes a few possibilities for\nthe location of the matched tag and performs the comparisons on them to locate\na single valid match. A 0.13 um CMOS technology was used for simulation\npurposes. The energy consumption and the search delay of the proposed design\nare 9.5%, and 30.4% of that of the conventional NAND architecture respectively\nwith a 3.4% higher number of transistors.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 21:23:54 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Jarollahi", "Hooman", ""], ["Gripon", "Vincent", ""], ["Onizawa", "Naoya", ""], ["Gross", "Warren J.", ""]]}, {"id": "1302.4464", "submitter": "Hooman Jarollahi", "authors": "Hooman Jarollahi (EIT) (Student Member IEEE) and Richard F. Hobson", "title": "Dynamic Power Reduction in a Novel CMOS 5T-SRAM for Low-Power SoC", "comments": "7 pages, CDES'10 - The 2010 International Conference on Computer\n  Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a novel five-transistor (5T) CMOS SRAM design with high\nperformance and reliability in 65nm CMOS, and illustrates how it reduces the\ndynamic power consumption in comparison with the conventional and low-power 6T\nSRAM counterparts. This design can be used as cache memory in processors and\nlow-power portable devices. The proposed SRAM cell features ~13% area reduction\ncompared to a conventional 6T cell, and features a unique bit-line and negative\nsupply voltage biasing methodology and ground control architecture to enhance\nperformance, and suppress standby leakage power.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 21:24:22 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Jarollahi", "Hooman", "", "EIT"], ["Hobson", "Richard F.", ""]]}, {"id": "1302.6515", "submitter": "Chris Yakopcic", "authors": "Chris Yakopcic and Tarek M. Taha", "title": "Hybrid Crossbar Architecture for a Memristor Based Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new memristor crossbar architecture that is proposed\nfor use in a high density cache design. This design has less than 10% of the\nwrite energy consumption than a simple memristor crossbar. Also, it has up to 4\ntimes the bit density of an STT-MRAM system and up to 11 times the bit density\nof an SRAM architecture. The proposed architecture is analyzed using a detailed\nSPICE analysis that accounts for the resistance of the wires in the memristor\nstructure. Additionally, the memristor model used in this work has been matched\nto specific device characterization data to provide accurate results in terms\nof energy, area, and timing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 17:48:12 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 15:39:24 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Yakopcic", "Chris", ""], ["Taha", "Tarek M.", ""]]}, {"id": "1302.6911", "submitter": "Oskar Schirmer", "authors": "Oskar Schirmer", "title": "Using Virtual Addresses with Communication Channels", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While for single processor and SMP machines, memory is the allocatable\nquantity, for machines made up of large amounts of parallel computing units,\neach with its own local memory, the allocatable quantity is a single computing\nunit. Where virtual address management is used to keep memory coherent and\nallow allocation of more than physical memory is actually available, virtual\ncommunication channel references can be used to make computing units stay\nconnected across allocation and swapping.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 20:34:05 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Schirmer", "Oskar", ""]]}]