[{"id": "1608.01225", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, K Prasad", "title": "Early Output Hybrid Input Encoded Asynchronous Full Adder and\n  Relative-Timed Ripple Carry Adder", "comments": null, "journal-ref": "Proceedings of the 14th International Conference on Embedded\n  Systems, Cyber-physical Systems, and Applications, pp. 62-65, July 25-28,\n  2016, Las Vegas, USA", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new early output hybrid input encoded asynchronous full\nadder designed using dual-rail and 1-of-4 delay-insensitive data codes. The\nproposed full adder when cascaded to form a ripple carry adder (RCA)\nnecessitates the use of a small relative-timing assumption with respect to the\ninternal carries, which is independent of the RCA size. The forward latency of\nthe proposed hybrid input encoded full adder based RCA is data-dependent while\nits reverse latency is the least equaling the propagation delay of just one\nfull adder. Compared to the best of the existing hybrid input encoded full\nadders based 32-bit RCAs, the proposed early output hybrid input encoded full\nadder based 32-bit RCA enables respective reductions in forward latency and\narea by 7.9% and 5.6% whilst dissipating the same average power; in terms of\nthe theoretically computed cycle time, the latter reports a 10.9% reduction\ncompared to the former.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 15:40:01 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Balasubramanian", "P", ""], ["Prasad", "K", ""]]}, {"id": "1608.05930", "submitter": "Christophe Guyeux", "authors": "Jacques M. Bahi and Xiaole Fang and Christophe Guyeux and Laurent\n  Larger", "title": "FPGA Design for Pseudorandom Number Generator Based on Chaotic Iteration\n  used in Information Hiding Application", "comments": "arXiv admin note: text overlap with arXiv:1012.4620, arXiv:1112.1201", "journal-ref": "Applied Mathematics & Information Sciences. Vol. 7(6), pp.\n  2175-2188 (2013)", "doi": null, "report-no": null, "categories": "cs.CR cs.AR math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lots of researches indicate that the inefficient generation of random numbers\nis a significant bottleneck for information communication applications.\nTherefore, Field Programmable Gate Array (FPGA) is developed to process a\nscalable fixed-point method for random streams generation. In our previous\nresearches, we have proposed a technique by applying some well-defined discrete\nchaotic iterations that satisfy the reputed Devaney's definition of chaos,\nnamely chaotic iterations (CI). We have formerly proven that the generator with\nCI can provide qualified chaotic random numbers. In this paper, this generator\nbased on chaotic iterations is optimally redesigned for FPGA device. By doing\nso, the generation rate can be largely improved. Analyses show that these\nhardware generators can also provide good statistical chaotic random bits and\ncan be cryptographically secure too. An application in the information hiding\nsecurity field is finally given as an illustrative example.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 12:45:43 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Bahi", "Jacques M.", ""], ["Fang", "Xiaole", ""], ["Guyeux", "Christophe", ""], ["Larger", "Laurent", ""]]}, {"id": "1608.07036", "submitter": "P Balasubramanian", "authors": "P Balasubramanian", "title": "System Reliability, Fault Tolerance and Design Metrics Tradeoffs in the\n  Distributed Minority and Majority Voting Based Redundancy Scheme", "comments": null, "journal-ref": "WSEAS Transactions on Systems, vol. 15, Article #7, pp. 59-62,\n  2016", "doi": null, "report-no": null, "categories": "cs.AR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed minority and majority voting based redundancy (DMMR) scheme\nwas recently proposed as an efficient alternative to the conventional N-modular\nredundancy (NMR) scheme for the physical design of mission/safety-critical\ncircuits and systems. The DMMR scheme enables significant improvements in fault\ntolerance and design metrics compared to the NMR scheme albeit at the expense\nof a slight decrease in the system reliability. In this context, this paper\nstudies the system reliability, fault tolerance and design metrics tradeoffs in\nthe DMMR scheme compared to the NMR scheme when the majority logic group of the\nDMMR scheme is increased in size relative to the minority logic group. Some\nexample DMMR and NMR systems were realized using a 32/28nm CMOS process and\ncompared. The results show that 5-of-M DMMR systems have a similar or better\nfault tolerance whilst requiring similar or fewer function modules than their\ncounterpart NMR systems and simultaneously achieve optimizations in design\nmetrics. Nevertheless, 3-of-M DMMR systems have the upper hand with respect to\nfault tolerance and design metrics optimizations than the comparable NMR and\n5-of-M DMMR systems. With regard to system reliability, NMR systems are closely\nfollowed by 5-of-M DMMR systems which are closely followed by 3-of-M DMMR\nsystems. The verdict is 3-of-M DMMR systems are preferable to implement higher\nlevels of redundancy from a combined system reliability, fault tolerance and\ndesign metrics perspective to realize mission/safety-critical circuits and\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 07:26:33 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 05:06:03 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Balasubramanian", "P", ""]]}, {"id": "1608.07485", "submitter": "Jason Lowe-Power", "authors": "Jason Lowe-Power and Mark D. Hill and David A. Wood", "title": "When to use 3D Die-Stacked Memory for Bandwidth-Constrained Big Data\n  Workloads", "comments": "Originally presented The Seventh workshop on Big Data Benchmarks,\n  Performance Optimization, and Emerging Hardware (BPOE-7).\n  http://www.bafst.com/events/asplos16/bpoe7/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response time requirements for big data processing systems are shrinking. To\nmeet this strict response time requirement, many big data systems store all or\nmost of their data in main memory to reduce the access latency. Main memory\ncapacities have grown, and systems with 2 TB of main memory capacity available\ntoday. However, the rate at which processors can access this data--the memory\nbandwidth--has not grown at the same rate. In fact, some of these big-memory\nsystems can access less than 10% of their main memory capacity in one second\n(billions of processor cycles).\n  3D die-stacking is one promising solution to this bandwidth problem, and\nindustry is investing significantly in 3D die-stacking. We use a simple\nback-of-the-envelope-style model to characterize if and when the 3D die-stacked\narchitecture is more cost-effective than current architectures for in-memory\nbig data workloads. We find that die-stacking has much higher performance than\ncurrent systems (up to 256x lower response times), and it does not require\nexpensive memory over provisioning to meet real-time (10 ms) response time\nservice-level agreements. However, the power requirements of the die-stacked\nsystems are significantly higher (up to 50x) than current systems, and its\nmemory capacity is lower in many cases. Even in this limited case study, we\nfind 3D die-stacking is not a panacea. Today, die-stacking is the most\ncost-effective solution for strict SLAs and by reducing the power of the\ncompute chip and increasing memory densities die-stacking can be cost-effective\nunder other constraints in the future.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 15:04:20 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Lowe-Power", "Jason", ""], ["Hill", "Mark D.", ""], ["Wood", "David A.", ""]]}, {"id": "1608.07547", "submitter": "Caroline Trippel", "authors": "Caroline Trippel, Yatin A. Manerkar, Daniel Lustig, Michael Pellauer,\n  Margaret Martonosi", "title": "TriCheck: Memory Model Verification at the Trisection of Software,\n  Hardware, and ISA", "comments": "Proceedings of the Twenty-Second International Conference on\n  Architectural Support for Programming Languages and Operating Systems", "journal-ref": null, "doi": "10.1145/3037697.3037719", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory consistency models (MCMs) which govern inter-module interactions in a\nshared memory system, are a significant, yet often under-appreciated, aspect of\nsystem design. MCMs are defined at the various layers of the hardware-software\nstack, requiring thoroughly verified specifications, compilers, and\nimplementations at the interfaces between layers. Current verification\ntechniques evaluate segments of the system stack in isolation, such as proving\ncompiler mappings from a high-level language (HLL) to an ISA or proving\nvalidity of a microarchitectural implementation of an ISA.\n  This paper makes a case for full-stack MCM verification and provides a\ntoolflow, TriCheck, capable of verifying that the HLL, compiler, ISA, and\nimplementation collectively uphold MCM requirements. The work showcases\nTriCheck's ability to evaluate a proposed ISA MCM in order to ensure that each\nlayer and each mapping is correct and complete. Specifically, we apply TriCheck\nto the open source RISC-V ISA, seeking to verify accurate, efficient, and legal\ncompilations from C11. We uncover under-specifications and potential\ninefficiencies in the current RISC-V ISA documentation and identify possible\nsolutions for each. As an example, we find that a RISC-V-compliant\nmicroarchitecture allows 144 outcomes forbidden by C11 to be observed out of\n1,701 litmus tests examined. Overall, this paper demonstrates the necessity of\nfull-stack verification for detecting MCM-related bugs in the hardware-software\nstack.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 18:13:57 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 17:45:52 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Trippel", "Caroline", ""], ["Manerkar", "Yatin A.", ""], ["Lustig", "Daniel", ""], ["Pellauer", "Michael", ""], ["Martonosi", "Margaret", ""]]}, {"id": "1608.08376", "submitter": "Michael Gautschi", "authors": "Michael Gautschi and Pasquale Davide Schiavone and Andreas Traber and\n  Igor Loi and Antonio Pullini and Davide Rossi and Eric Flamand and Frank K.\n  Gurkaynak and Luca Benini", "title": "A near-threshold RISC-V core with DSP extensions for scalable IoT\n  Endpoint Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endpoint devices for Internet-of-Things not only need to work under extremely\ntight power envelope of a few milliwatts, but also need to be flexible in their\ncomputing capabilities, from a few kOPS to GOPS. Near-threshold(NT) operation\ncan achieve higher energy efficiency, and the performance scalability can be\ngained through parallelism. In this paper we describe the design of an\nopen-source RISC-V processor core specifically designed for NT operation in\ntightly coupled multi-core clusters. We introduce instruction-extensions and\nmicroarchitectural optimizations to increase the computational density and to\nminimize the pressure towards the shared memory hierarchy. For typical\ndata-intensive sensor processing workloads the proposed core is on average 3.5x\nfaster and 3.2x more energy-efficient, thanks to a smart L0 buffer to reduce\ncache access contentions and support for compressed instructions. SIMD\nextensions, such as dot-products, and a built-in L0 storage further reduce the\nshared memory accesses by 8x reducing contentions by 3.2x. With four\nNT-optimized cores, the cluster is operational from 0.6V to 1.2V achieving a\npeak efficiency of 67MOPS/mW in a low-cost 65nm bulk CMOS technology. In a low\npower 28nm FDSOI process a peak efficiency of 193MOPS/mW(40MHz, 1mW) can be\nachieved.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 09:14:14 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Gautschi", "Michael", ""], ["Schiavone", "Pasquale Davide", ""], ["Traber", "Andreas", ""], ["Loi", "Igor", ""], ["Pullini", "Antonio", ""], ["Rossi", "Davide", ""], ["Flamand", "Eric", ""], ["Gurkaynak", "Frank K.", ""], ["Benini", "Luca", ""]]}]