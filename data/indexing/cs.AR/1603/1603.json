[{"id": "1603.01187", "submitter": "Zeyad Aklah", "authors": "Zeyad Aklah, Sen Ma, David Andrews", "title": "A Dynamic Overlay Supporting Just-In-Time Assembly to Construct\n  Customized Hardware Accelerators", "comments": "2 pages, extended abstract, 2nd International Workshop on Overlay\n  Architectures for FPGAs (OLAF),Feburary 21, 2016 - Monterey, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barriers that prevent programmers from using FPGAs include the need to work\nwithin vendor specific CAD tools, knowledge of hardware programming models, and\nthe requirement to pass each design through synthesis, place and route. In this\nwork, a dynamic overlay is designed to support Just- In-Time assembly by\ncomposing hardware operators to construct full accelerators. The hardware\noperators are pre-synthesized bit- streams and can be downloaded to Partially\nReconfigurable(PR) regions at runtime.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 17:17:56 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Aklah", "Zeyad", ""], ["Ma", "Sen", ""], ["Andrews", "David", ""]]}, {"id": "1603.02580", "submitter": "Jeremy Morse", "authors": "Jeremy Morse, Steve Kerrison, Kerstin Eder", "title": "On the limitations of analysing worst-case dynamic energy of processing", "comments": null, "journal-ref": null, "doi": "10.1145/3173042", "report-no": null, "categories": "cs.CC cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines dynamic energy consumption caused by data during software\nexecution on deeply embedded microprocessors, which can be significant on some\ndevices. In worst-case energy consumption analysis, energy models are used to\nfind the most costly execution path. Taking each instruction's worst case\nenergy produces a safe but overly pessimistic upper bound. Algorithms for safe\nand tight bounds would be desirable. We show that finding exact worst-case\nenergy is NP-hard, and that tight bounds cannot be approximated with guaranteed\nsafety. We conclude that any energy model targeting tightness must either\nsacrifice safety or accept overapproximation proportional to data-dependent\nenergy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 19:22:13 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2016 12:55:19 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 11:06:30 GMT"}, {"version": "v4", "created": "Wed, 21 Feb 2018 16:10:19 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Morse", "Jeremy", ""], ["Kerrison", "Steve", ""], ["Eder", "Kerstin", ""]]}, {"id": "1603.04094", "submitter": "Romesh Laishram", "authors": "Aribam Balarampyari Devi, Manoj Kumar and Romesh Laishram", "title": "Design and Implementation of an Improved Carry Increment Adder", "comments": "vol.7,No.1,February 2016, pp 21-27", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex digital circuit comprises of adder as a basic unit. The performance\nof the circuit depends on the design of this basic adder unit. The speed of\noperation of a circuit is one of the important performance criteria of many\ndigital circuits which ultimately depends on the delay of the basic adder unit.\nMany research works have been devoted in improving the delay of the adder\ncircuit. In this paper we have proposed an improved carry increment adder (CIA)\nthat improves the delay performance of the circuit. The improvement is achieved\nby incorporating carry look adder (CLA) in the design of CIA contrary to the\nprevious design of CIA that employs ripple carry adder (RCA). A simulation\nstudy is carried out for comparative analysis. The coding is done in Verilog\nhardware description language (HDL) and the simulation is carried out in Xilinx\nISE 13.1 environment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 06:32:36 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Devi", "Aribam Balarampyari", ""], ["Kumar", "Manoj", ""], ["Laishram", "Romesh", ""]]}, {"id": "1603.04627", "submitter": "Basel Halak", "authors": "Basel Halak and Hsien-Chih Chiu", "title": "Modified Micropipline Architecture for Synthesizable Asynchronous FIR\n  Filter Design", "comments": "in International Journal of VLSI Design & Communication Systems 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of asynchronous design approaches to construct digital signal\nprocessing (DSP) systems is a rapidly growing research area driven by a wide\nrange of emerging energy constrained applications such as wireless sensor\nnetwork, portable medical devices and brain implants. The asynchronous design\ntechniques allow the construction of systems which are samples driven, which\nmeans they only dissipate dynamic energy when there processing data and idle\notherwise. This inherent advantage of asynchronous design over conventional\nsynchronous circuits allows them to be energy efficient. However the\nimplementation flow of asynchronous systems is still difficult due to its lack\nof compatibility with industry-standard synchronous design tools and modelling\nlanguages. This paper devises a novel asynchronous design for a finite impulse\nresponse (FIR) filter, an essential building block of DSP systems, which is\nsynthesizable and suitable for implementation using conventional synchronous\nsystems design flow and tools. The proposed design is based on a modified\nversion of the micropipline architecture and it is constructed using four phase\nbundled data protocol. A hardware prototype of the proposed filter has been\ndeveloped on an FPGA, and systematically verified. The results prove correct\nfunctionality of the novel design and a superior performance compared to a\nsynchronous FIR implementation. The findings of this work will allow a wider\nadoption of asynchronous circuits by DSP designers to harness their energy and\nperformance benefits.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 10:44:29 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Halak", "Basel", ""], ["Chiu", "Hsien-Chih", ""]]}, {"id": "1603.05154", "submitter": "Faisal Mahmood", "authors": "Faisal Mahmood, M\\\"art Toots, Lars-G\\\"oran \\\"Ofverstedt and Ulf\n  Skoglund", "title": "2D Discrete Fourier Transform with Simultaneous Edge Artifact Removal\n  for Real-Time Applications", "comments": "IEEE 2015 International Conference on Field Programmable Technology\n  (FPT), Queenstown, New Zealand", "journal-ref": null, "doi": "10.1109/FPT.2015.7393157", "report-no": null, "categories": "cs.CV cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-Dimensional (2D) Discrete Fourier Transform (DFT) is a basic and\ncomputationally intensive algorithm, with a vast variety of applications. 2D\nimages are, in general, non-periodic, but are assumed to be periodic while\ncalculating their DFTs. This leads to cross-shaped artifacts in the frequency\ndomain due to spectral leakage. These artifacts can have critical consequences\nif the DFTs are being used for further processing. In this paper we present a\nnovel FPGA-based design to calculate high-throughput 2D DFTs with simultaneous\nedge artifact removal. Standard approaches for removing these artifacts using\napodization functions or mirroring, either involve removing critical\nfrequencies or a surge in computation by increasing image size. We use a\nperiodic-plus-smooth decomposition based artifact removal algorithm optimized\nfor FPGA implementation, while still achieving real-time ($\\ge$23 frames per\nsecond) performance for a 512$\\times$512 size image stream. Our optimization\napproach leads to a significant decrease in external memory utilization thereby\navoiding memory conflicts and simplifies the design. We have tested our design\non a PXIe based Xilinx Kintex 7 FPGA system communicating with a host PC which\ngives us the advantage to further expand the design for industrial\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 15:52:13 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Mahmood", "Faisal", ""], ["Toots", "M\u00e4rt", ""], ["\u00d6fverstedt", "Lars-G\u00f6ran", ""], ["Skoglund", "Ulf", ""]]}, {"id": "1603.05273", "submitter": "Pascal Giard", "authors": "Pascal Giard, Alexios Balatsoukas-Stimming, Gabi Sarkis, Claude\n  Thibeault, and Warren J. Gross", "title": "Fast Low-Complexity Decoders for Low-Rate Polar Codes", "comments": "8 pages, 10 figures, submitted to Springer J. Signal Process. Syst", "journal-ref": null, "doi": "10.1007/s11265-016-1173-y", "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polar codes are capacity-achieving error-correcting codes with an explicit\nconstruction that can be decoded with low-complexity algorithms. In this work,\nwe show how the state-of-the-art low-complexity decoding algorithm can be\nimproved to better accommodate low-rate codes. More constituent codes are\nrecognized in the updated algorithm and dedicated hardware is added to\nefficiently decode these new constituent codes. We also alter the polar code\nconstruction to further decrease the latency and increase the throughput with\nlittle to no noticeable effect on error-correction performance. Rate-flexible\ndecoders for polar codes of length 1024 and 2048 are implemented on FPGA. Over\nthe previous work, they are shown to have from 22% to 28% lower latency and 26%\nto 34% greater throughput when decoding low-rate codes. On 65 nm ASIC CMOS\ntechnology, the proposed decoder for a (1024, 512) polar code is shown to\ncompare favorably against the state-of-the-art ASIC decoders. With a clock\nfrequency of 400 MHz and a supply voltage of 0.8 V, it has a latency of 0.41\n$\\mu$s and an area efficiency of 1.8 Gbps/mm$^2$ for an energy efficiency of 77\npJ/info. bit. At 600 MHz with a supply of 1 V, the latency is reduced to 0.27\n$\\mu$s and the area efficiency increased to 2.7 Gbps/mm$^2$ at 115 pJ/info.\nbit.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 20:49:30 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 02:47:46 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Giard", "Pascal", ""], ["Balatsoukas-Stimming", "Alexios", ""], ["Sarkis", "Gabi", ""], ["Thibeault", "Claude", ""], ["Gross", "Warren J.", ""]]}, {"id": "1603.07055", "submitter": "Bo Yuan", "authors": "Bo Yuan, Keshab K. Parhi", "title": "LLR-based Successive-Cancellation List Decoder for Polar Codes with\n  Multi-bit Decision", "comments": "accepted by IEEE Trans. Circuits and Systems II", "journal-ref": null, "doi": "10.1109/TCSII.2016.2546904", "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their capacity-achieving property, polar codes have become one of the\nmost attractive channel codes. To date, the successive cancellation list (SCL)\ndecoding algorithm is the primary approach that can guarantee outstanding\nerror-correcting performance of polar codes. However, the hardware designs of\nthe original SCL decoder have large silicon area and long decoding latency.\nAlthough some recent efforts can reduce either the area or latency of SCL\ndecoders, these two metrics still cannot be optimized at the same time. This\npaper, for the first time, proposes a general log-likelihood-ratio (LLR)-based\nSCL decoding algorithm with multi-bit decision. This new algorithm, referred as\nLLR-2Kb-SCL, can determine 2K bits simultaneously for arbitrary K with the use\nof LLR messages. In addition, a reduced-data-width scheme is presented to\nreduce the critical path of the sorting block. Then, based on the proposed\nalgorithm, a VLSI architecture of the new SCL decoder is developed. Synthesis\nresults show that for an example (1024, 512) polar code with list size 4, the\nproposed LLR-2Kb-SCL decoders achieve significant reduction in both area and\nlatency as compared to prior works. As a result, the hardware efficiency of the\nproposed designs with K=2 and 3 are 2.33 times and 3.32 times of that of the\nstate-of-the-art works, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 02:48:35 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Yuan", "Bo", ""], ["Parhi", "Keshab K.", ""]]}, {"id": "1603.07400", "submitter": "Raqibul Hasan", "authors": "Raqibul Hasan, and Tarek Taha", "title": "A Reconfigurable Low Power High Throughput Architecture for Deep Network\n  Training", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose computing systems are used for a large variety of\napplications. Extensive supports for flexibility in these systems limit their\nenergy efficiencies. Neural networks, including deep networks, are widely used\nfor signal processing and pattern recognition applications. In this paper we\npropose a multicore architecture for deep neural network based processing.\nMemristor crossbars are utilized to provide low power high throughput execution\nof neural networks. The system has both training and recognition (evaluation of\nnew input) capabilities. The proposed system could be used for classification,\ndimensionality reduction, feature extraction, and anomaly detection\napplications. The system level area and power benefits of the specialized\narchitecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental\nevaluations show that the proposed architecture can provide up to five orders\nof magnitude more energy efficiency over GPGPUs for deep neural network\nprocessing.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 00:52:22 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 01:26:31 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Hasan", "Raqibul", ""], ["Taha", "Tarek", ""]]}, {"id": "1603.07961", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, N E Mastorakis", "title": "ASIC-based Implementation of Synchronous Section-Carry Based Carry\n  Lookahead Adders", "comments": "in the Book, Recent Advances in Circuits, Systems, Signal Processing\n  and Communications, Included in ISI/SCI Web of Science and Web of Knowledge,\n  Proceedings of 10th International Conference on Circuits, Systems, Signal and\n  Telecommunications, pp. 58-64, 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The section-carry based carry lookahead adder (SCBCLA) topology was proposed\nas an improved high-speed alternative to the conventional carry lookahead adder\n(CCLA) topology in previous works. Self-timed and FPGA-based implementations of\nSCBCLAs and CCLAs were considered earlier, and it was found that SCBCLAs could\nhelp in delay reduction i.e. pave the way for improved speed compared to CCLAs\nat the expense of some increase in area and/or power parameters. In this work,\nwe consider semi-custom ASIC-based implementations of different variants of\nSCBCLAs and CCLAs to perform 32-bit dual-operand addition. Based on the\nsimulation results for 32-bit dual-operand addition obtained by targeting a\nhigh-end 32/28nm CMOS process, it is found that an optimized SCBCLA\narchitecture reports a 9.8% improvement in figure-of-merit (FOM) compared to an\noptimized CCLA architecture, where the FOM is defined as the inverse of the\nproduct of power, delay, and area. It is generally inferred from the\nsimulations that the SCBCLA architecture could be more beneficial compared to\nthe CCLA architecture in terms of the design metrics whilst benefitting a\nvariety of computer arithmetic operations involving dual-operand and/or\nmulti-operand additions. Also, it is observed that heterogeneous CLA\narchitectures tend to fare well compared to homogeneous CLA architectures, as\nsubstantiated by the simulation results.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 17:02:58 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Balasubramanian", "P", ""], ["Mastorakis", "N E", ""]]}, {"id": "1603.07962", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, N E Mastorakis", "title": "Global versus Local Weak-Indication Self-Timed Function Blocks - A\n  Comparative Analysis", "comments": "in the Book, Recent Advances in Circuits, Systems, Signal Processing\n  and Communications, Included in ISI/SCI Web of Science and Web of Knowledge,\n  Proceedings of 10th International Conference on Circuits, Systems, Signal and\n  Telecommunications, pp. 86-97, 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the merits and demerits of global weak-indication\nself-timed function blocks versus local weak-indication self-timed function\nblocks, implemented using a delay-insensitive data code and adhering to 4-phase\nreturn-to-zero handshaking. A self-timed ripple carry adder is considered as an\nexample function block for the analysis. The analysis shows that while global\nweak-indication could help in optimizing the power, latency and area\nparameters, local weak-indication facilitates the optimum performance in terms\nof realizing the data-dependent cycle time that is characteristic of a\nweak-indication self-timed design.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 17:11:33 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Balasubramanian", "P", ""], ["Mastorakis", "N E", ""]]}, {"id": "1603.07964", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, N E Mastorakis", "title": "Power, Delay and Area Comparisons of Majority Voters relevant to TMR\n  Architectures", "comments": "in the Book, Recent Advances in Circuits, Systems, Signal Processing\n  and Communications, Included in ISI/SCI Web of Science and Web of Knowledge,\n  Proceedings of 10th International Conference on Circuits, Systems, Signal and\n  Telecommunications, pp. 110-117, 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N-modular redundancy (NMR) is commonly used to enhance the fault tolerance of\na circuit/system, when subject to a fault-inducing environment such as in space\nor military systems, where upsets due to radiation phenomena, temperature\nand/or other environmental conditions are anticipated. Triple Modular\nRedundancy (TMR), which is a 3-tuple version of NMR, is widely preferred for\nmission-control space, military, and aerospace, and safety-critical nuclear,\npower, medical, and industrial control and automation systems. The TMR scheme\ninvolves the two-times duplication of a simplex system hardware, with a\nmajority voter ensuring correctness provided at least two out of three copies\nof the hardware remain operational. Thus the majority voter plays a pivotal\nrole in ensuring the correct operation of the TMR scheme. In this paper, a\nnumber of standard-cell based majority voter designs relevant to TMR\narchitectures are presented, and their power, delay and area parameters are\nestimated based on physical realization using a 32/28nm CMOS process.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 17:14:55 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Balasubramanian", "P", ""], ["Mastorakis", "N E", ""]]}, {"id": "1603.08454", "submitter": "Donghyuk Lee", "authors": "Donghyuk Lee, Yoongu Kim, Gennady Pekhimenko, Samira Khan, Vivek\n  Seshadri, Kevin Chang, Onur Mutlu", "title": "Adaptive-Latency DRAM (AL-DRAM)", "comments": "This is a summary of the original paper, entitled \"Adaptive-Latency\n  DRAM: Optimizing DRAM Timing for the Common-Case\" which appears in HPCA 2015", "journal-ref": null, "doi": null, "report-no": "SAFARI 2016-003", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the idea of Adaptive-Latency DRAM (AL-DRAM), which was\npublished in HPCA 2015. The key goal of AL-DRAM is to exploit the extra margin\nthat is built into the DRAM timing parameters to reduce DRAM latency. The key\nobservation is that the timing parameters are dictated by the worst-case\ntemperatures and worst-case DRAM cells, both of which lead to small amount of\ncharge storage and hence high access latency. One can therefore reduce latency\nby adapting the timing parameters to the current operating temperature and the\ncurrent DIMM that is being accessed. Using an FPGA-based testing platform, our\nwork first characterizes the extra margin for 115 DRAM modules from three major\nmanufacturers. The experimental results demonstrate that it is possible to\nreduce four of the most critical timing parameters by a minimum/maximum of\n17.3%/54.8% at 55C while maintaining reliable operation. AL-DRAM adaptively\nselects between multiple different timing parameters for each DRAM module based\non its current operating condition. AL-DRAM does not require any changes to the\nDRAM chip or its interface; it only requires multiple different timing\nparameters to be specified and supported by the memory controller. Real system\nevaluations show that AL-DRAM improves the performance of memory-intensive\nworkloads by an average of 14% without introducing any errors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 17:39:23 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Lee", "Donghyuk", ""], ["Kim", "Yoongu", ""], ["Pekhimenko", "Gennady", ""], ["Khan", "Samira", ""], ["Seshadri", "Vivek", ""], ["Chang", "Kevin", ""], ["Mutlu", "Onur", ""]]}, {"id": "1603.09062", "submitter": "Cansu Sen", "authors": "Cansu Sen, Soner Yesil, Ertugrul Kolagasioglu", "title": "FPGA Impementation of Erasure-Only Reed Solomon Decoders for Hybrid-ARQ\n  Systems", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the usage of the Reed Solomon Codes as the Forward Error\nCorrection (FEC) unit of the Hybrid Automatic Repeat Request (ARQ) methods.\nParametric and flexible FPGA implementation details of such Erasure-Only RS\ndecoders with high symbol lengths (e.g. GF(2^32)) have been presented. The\ndesign is based on the GF(2m) multiplier logic core operating at a single clock\ncycle, where the resource utilization and throughput are both directly\nproportional to the number of these cores. For a fixed implementation, the\nthroughput inversely decreases with the number of erasures to be corrected.\nImplementation in Zynq7020 SoC device of an example GF(2^32)-RS Decoder capable\nof correcting 64-erasures with a single multiplier resulted in 1641-LUTs and\n188-FFs achieving 15Mbps, whereas the design with 8 multipliers resulted in\n6128-LUTs and 628-FFs achieving 100Mbps.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2016 07:44:23 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Sen", "Cansu", ""], ["Yesil", "Soner", ""], ["Kolagasioglu", "Ertugrul", ""]]}]