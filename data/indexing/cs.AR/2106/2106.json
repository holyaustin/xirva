[{"id": "2106.01139", "submitter": "Luc Waeijen", "authors": "Shihua Huang, Luc Waeijen, Henk Corporaal", "title": "How Flexible is Your Computing System", "comments": "Partial preprint pending peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In literature computer architectures are frequently claimed to be highly\nflexible, typically implying there exist trade-offs between flexibility and\nperformance or energy efficiency. Processor flexibility, however, is not very\nsharply defined, and as such these claims can not be validated, nor can such\nhypothetical relations be fully understood and exploited in the design of\ncomputing systems. This paper is an attempt to introduce scientific rigour to\nthe notion of flexibility in computing systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:15:50 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Huang", "Shihua", ""], ["Waeijen", "Luc", ""], ["Corporaal", "Henk", ""]]}, {"id": "2106.01329", "submitter": "Giacomo Indiveri", "authors": "Giacomo Indiveri", "title": "Introducing \"Neuromorphic Computing and Engineering\"", "comments": "NCE Editorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CE cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard nature of computing is currently being challenged by a range of\nproblems that start to hinder technological progress. One of the strategies\nbeing proposed to address some of these problems is to develop novel\nbrain-inspired processing methods and technologies, and apply them to a wide\nrange of application scenarios. This is an extremely challenging endeavor that\nrequires researchers in multiple disciplines to combine their efforts and\nco-design at the same time the processing methods, the supporting computing\narchitectures, and their underlying technologies. The journal ``Neuromorphic\nComputing and Engineering'' (NCE) has been launched to support this new\ncommunity in this effort and provide a forum and repository for presenting and\ndiscussing its latest advances. Through close collaboration with our colleagues\non the editorial team, the scope and characteristics of NCE have been designed\nto ensure it serves a growing transdisciplinary and dynamic community across\nacademia and industry.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 20:12:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Indiveri", "Giacomo", ""]]}, {"id": "2106.01482", "submitter": "Christina Delimitrou", "authors": "Nikita Lazarev and Shaojie Xiang and Neil Adit and Zhiru Zhang and\n  Christina Delimitrou", "title": "Dagger: Accelerating RPCs in Cloud Microservices Through Tightly-Coupled\n  Reconfigurable NICs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ongoing shift of cloud services from monolithic designs to microservices\ncreates high demand for efficient and high performance datacenter networking\nstacks, optimized for fine-grained workloads. Commodity networking systems\nbased on software stacks and peripheral NICs introduce high overheads when it\ncomes to delivering small messages.\n  We present Dagger, a hardware acceleration fabric for cloud RPCs based on\nFPGAs, where the accelerator is closely-coupled with the host processor over a\nconfigurable memory interconnect. The three key design principle of Dagger are:\n(1) offloading the entire RPC stack to an FPGA-based NIC, (2) leveraging memory\ninterconnects instead of PCIe buses as the interface with the host CPU, and (3)\nmaking the acceleration fabric reconfigurable, so it can accommodate the\ndiverse needs of microservices. We show that the combination of these\nprinciples significantly improves the efficiency and performance of cloud RPC\nsystems while preserving their generality. Dagger achieves 1.3-3.8x higher\nper-core RPC throughput compared to both highly-optimized software stacks, and\nsystems using specialized RDMA adapters. It also scales up to 84 Mrps with 8\nthreads on 4 CPU cores, while maintaining state-of-the-art us-scale tail\nlatency. We also demonstrate that large third-party applications, like\nmemcached and MICA KVS, can be easily ported on Dagger with minimal changes to\ntheir codebase, bringing their median and tail KVS access latency down to 2.8 -\n3.5us and 5.4 - 7.8us, respectively. Finally, we show that Dagger is beneficial\nfor multi-tier end-to-end microservices with different threading models by\nevaluating it using an 8-tier application implementing a flight check-in\nservice.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:37:50 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Lazarev", "Nikita", ""], ["Xiang", "Shaojie", ""], ["Adit", "Neil", ""], ["Zhang", "Zhiru", ""], ["Delimitrou", "Christina", ""]]}, {"id": "2106.01671", "submitter": "Siyuan Niu", "authors": "Siyuan Niu (LIRMM), Aida Todri-Sanial (LIRMM, CNRS)", "title": "Analyzing crosstalk error in the NISQ era", "comments": null, "journal-ref": "IEEE Computer Society Annual Symposium on VLSI 2021, Jul 2021,\n  Tampa, Florida, United States", "doi": null, "report-no": null, "categories": "cs.AR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy Intermediate-Scale Quantum (NISQ) hardware has unavoidable noises, and\ncrosstalk error is a significant error source. When multiple quantum operations\nare executed simultaneously, the quantum state can be corrupted due to the\ncrosstalk between gates during simultaneous operations, decreasing the circuit\nfidelity. In this work, we first report on several protocols for characterizing\ncrosstalk. Then, we discuss different crosstalk mitigation methods from the\nhardware and software perspectives. Finally, we perform crosstalk injection\nexperiments on the IBM quantum device and demonstrate the fidelity improvement\nwith the crosstalk mitigation method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:20:40 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Niu", "Siyuan", "", "LIRMM"], ["Todri-Sanial", "Aida", "", "LIRMM, CNRS"]]}, {"id": "2106.01958", "submitter": "Abhishek Ramdas Nair", "authors": "Abhishek Ramdas Nair, Pallab Kumar Nath, Shantanu Chakrabartty, Chetan\n  Singh Thakur", "title": "Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel framework for designing multiplierless kernel machines\nthat can be used on resource-constrained platforms like intelligent edge\ndevices. The framework uses a piecewise linear (PWL) approximation based on a\nmargin propagation (MP) technique and uses only addition/subtraction, shift,\ncomparison, and register underflow/overflow operations. We propose a\nhardware-friendly MP-based inference and online training algorithm that has\nbeen optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA\nimplementation eliminates the need for DSP units and reduces the number of\nLUTs. By reusing the same hardware for inference and training, we show that the\nplatform can overcome classification errors and local minima artifacts that\nresult from the MP approximation. Using the FPGA platform, we also show that\nthe proposed multiplierless MP-kernel machine demonstrates superior performance\nin terms of power, performance, and area compared to other comparable\nimplementations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:06:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Nair", "Abhishek Ramdas", ""], ["Nath", "Pallab Kumar", ""], ["Chakrabartty", "Shantanu", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "2106.02855", "submitter": "Venkata Sai Santosh Siripurapu", "authors": "S. V. Sai Santosh and Sumit J. Darak", "title": "Multi-armed Bandit Algorithms on System-on-Chip: Go Frequentist or\n  Bayesian?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AR cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-armed Bandit (MAB) algorithms identify the best arm among multiple arms\nvia exploration-exploitation trade-off without prior knowledge of arm\nstatistics. Their usefulness in wireless radio, IoT, and robotics demand\ndeployment on edge devices, and hence, a mapping on system-on-chip (SoC) is\ndesired. Theoretically, the Bayesian approach-based Thompson Sampling (TS)\nalgorithm offers better performance than the frequentist approach-based Upper\nConfidence Bound (UCB) algorithm. However, TS is not synthesizable due to Beta\nfunction. We address this problem by approximating it via a pseudo-random\nnumber generator-based approach and efficiently realize the TS algorithm on\nZynq SoC. In practice, the type of arms distribution (e.g., Bernoulli,\nGaussian, etc.) is unknown and hence, a single algorithm may not be optimal. We\npropose a reconfigurable and intelligent MAB (RI-MAB) framework. Here,\nintelligence enables the identification of appropriate MAB algorithms for a\ngiven environment, and reconfigurability allows on-the-fly switching between\nalgorithms on the SoC. This eliminates the need for parallel implementation of\nalgorithms resulting in huge savings in resources and power consumption. We\nanalyze the functional correctness, area, power, and execution time of the\nproposed and existing architectures for various arm distributions, word-length,\nand hardware-software co-design approaches. We demonstrate the superiority of\nthe RI-MAB over TS and UCB only architectures.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 10:07:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Santosh", "S. V. Sai", ""], ["Darak", "Sumit J.", ""]]}, {"id": "2106.02976", "submitter": "Himanshu Thapliyal", "authors": "Carson Labrado, Himanshu Thapliyal, Saraju P. Mohanty", "title": "Fortifying Vehicular Security Through Low Overhead Physically Unclonable\n  Functions", "comments": "19 Pages", "journal-ref": "ACM Journal on Emerging Technologies in Computing Systems, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within vehicles, the Controller Area Network (CAN) allows efficient\ncommunication between the electronic control units (ECUs) responsible for\ncontrolling the various subsystems. The CAN protocol was not designed to\ninclude much support for secure communication. The fact that so many critical\nsystems can be accessed through an insecure communication network presents a\nmajor security concern. Adding security features to CAN is difficult due to the\nlimited resources available to the individual ECUs and the costs that would be\nassociated with adding the necessary hardware to support any additional\nsecurity operations without overly degrading the performance of standard\ncommunication. Replacing the protocol is another option, but it is subject to\nmany of the same problems. The lack of security becomes even more concerning as\nvehicles continue to adopt smart features. Smart vehicles have a multitude of\ncommunication interfaces would an attacker could exploit to gain access to the\nnetworks. In this work we propose a security framework that is based on\nphysically unclonable functions (PUFs) and lightweight cryptography (LWC). The\nframework does not require any modification to the standard CAN protocol while\nalso minimizing the amount of additional message overhead required for its\noperation. The improvements in our proposed framework results in major\nreduction in the number of CAN frames that must be sent during operation. For a\nsystem with 20 ECUs for example, our proposed framework only requires 6.5% of\nthe number of CAN frames that is required by the existing approach to\nsuccessfully authenticate every ECU.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 22:07:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Labrado", "Carson", ""], ["Thapliyal", "Himanshu", ""], ["Mohanty", "Saraju P.", ""]]}, {"id": "2106.04205", "submitter": "Vishal Gupta", "authors": "Vishal Gupta (Indian Institute of Technology, Kanpur) and Biswabandan\n  Panda (Indian Institute of Technology, Bombay)", "title": "Micro BTB: A High Performance and Lightweight Last-Level Branch Target\n  Buffer for Servers", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance branch target buffers (BTBs) and the L1I cache are key to\nhigh-performance front-end. Modern branch predictors are highly accurate, but\nwith an increase in code footprint in modern-day server workloads, BTB and L1I\nmisses are still frequent. Recent industry trend shows usage of large BTBs\n(100s of KB per core) that provide performance closer to the ideal BTB along\nwith a decoupled front-end that provides efficient fetch-directed L1I\ninstruction prefetching. On the other hand, techniques proposed by academia,\nlike BTB prefetching and using retire order stream for learning, fail to\nprovide significant performance with modern-day processor cores that are deeper\nand wider.\n  We solve the problem fundamentally by increasing the storage density of the\nlast-level BTB. We observe that not all branch instructions require a full\nbranch target address. Instead, we can store the branch target as a branch\noffset, relative to the branch instruction. Using branch offset enables the BTB\nto store multiple branches per entry. We reduce the BTB storage in half, but we\nobserve that it increases skewness in the BTB. We propose a skewed indexed and\ncompressed last-level BTB design called MicroBTB (MBTB) that stores multiple\nbranches per BTB entry. We evaluate MBTB on 100 industry-provided server\nworkloads. A 4K-entry MBTB provides 17.61% performance improvement compared to\nan 8K-entry baseline BTB design with a storage savings of 47.5KB per core.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:29:10 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 06:18:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gupta", "Vishal", "", "Indian Institute of Technology, Kanpur"], ["Panda", "Biswabandan", "", "Indian Institute of Technology, Bombay"]]}, {"id": "2106.04758", "submitter": "Himanshu Thapliyal", "authors": "Himanshu Thapliyal, Edgard Mu\\~noz-Coreas, Vladislav Khalus", "title": "Quantum Carry Lookahead Adders for NISQ and Quantum Image Processing", "comments": "4 Pages, 2020 IEEE 38th International Conference on Computer Design\n  (ICCD), Hartford, CT, USA, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Progress in quantum hardware design is progressing toward machines of\nsufficient size to begin realizing quantum algorithms in disciplines such as\nencryption and physics. Quantum circuits for addition are crucial to realize\nmany quantum algorithms on these machines. Ideally, quantum circuits based on\nfault-tolerant gates and error-correcting codes should be used as they tolerant\nenvironmental noise. However, current machines called Noisy Intermediate Scale\nQuantum (NISQ) machines cannot support the overhead associated with\nfaulttolerant design. In response, low depth circuits such as quantum carry\nlookahead adders (QCLA)s have caught the attention of researchers. The risk for\nnoise errors and decoherence increase as the number of gate layers (or depth)\nin the circuit increases. This work presents an out-of-place QCLA based on\nClifford+T gates. The QCLAs optimized for T gate count and make use of a novel\nuncomputation gate to save T gates. We base our QCLAs on Clifford+T gates\nbecause they can eventually be made faulttolerant with error-correcting codes\nonce quantum hardware that can support fault-tolerant designs becomes\navailable. We focus on T gate cost as the T gate is significantly more costly\nto make faulttolerant than the other Clifford+T gates. The proposed QCLAs are\ncompared and shown to be superior to existing works in terms of T-count and\ntherefore the total number of quantum gates. Finally, we illustrate the\napplication of the proposed QCLAs in quantum image processing by presenting\nquantum circuits for bilinear interpolation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 01:02:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Thapliyal", "Himanshu", ""], ["Mu\u00f1oz-Coreas", "Edgard", ""], ["Khalus", "Vladislav", ""]]}, {"id": "2106.04772", "submitter": "Cheng Chu", "authors": "Dawen Xu, Qianlong Wang, Cheng Liu, Cheng Chu, Ying Wang, Huawei Li,\n  Xiaowei Li, Kwang-Ting Cheng", "title": "HyCA: A Hybrid Computing Architecture for Fault Tolerant Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware faults on the regular 2-D computing array of a typical deep learning\naccelerator (DLA) can lead to dramatic prediction accuracy loss. Prior\nredundancy design approaches typically have each homogeneous redundant\nprocessing element (PE) to mitigate faulty PEs for a limited region of the 2-D\ncomputing array rather than the entire computing array to avoid the excessive\nhardware overhead. However, they fail to recover the computing array when the\nnumber of faulty PEs in any region exceeds the number of redundant PEs in the\nsame region. The mismatch problem deteriorates when the fault injection rate\nrises and the faults are unevenly distributed. To address the problem, we\npropose a hybrid computing architecture (HyCA) for fault-tolerant DLAs. It has\na set of dot-production processing units (DPPUs) to recompute all the\noperations that are mapped to the faulty PEs despite the faulty PE locations.\nAccording to our experiments, HyCA shows significantly higher reliability,\nscalability, and performance with less chip area penalty when compared to the\nconventional redundancy approaches. Moreover, by taking advantage of the\nflexible recomputing, HyCA can also be utilized to scan the entire 2-D\ncomputing array and detect the faulty PEs effectively at runtime.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:26:02 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Xu", "Dawen", ""], ["Wang", "Qianlong", ""], ["Liu", "Cheng", ""], ["Chu", "Cheng", ""], ["Wang", "Ying", ""], ["Li", "Huawei", ""], ["Li", "Xiaowei", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "2106.05050", "submitter": "Jawad Haj-Yahya", "authors": "Jawad Haj-Yahya, Jeremie S. Kim, A. Giray Yaglikci, Ivan Puddu, Lois\n  Orosa, Juan G\\'omez Luna, Mohammed Alser, Onur Mutlu", "title": "IChannels: Exploiting Current Management Mechanisms to Create Covert\n  Channels in Modern Processors", "comments": "To appear in ISCA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To operate efficiently across a wide range of workloads with varying power\nrequirements, a modern processor applies different current management\nmechanisms, which briefly throttle instruction execution while they adjust\nvoltage and frequency to accommodate for power-hungry instructions (PHIs) in\nthe instruction stream. Doing so 1) reduces the power consumption of non-PHI\ninstructions in typical workloads and 2) optimizes system voltage regulators'\ncost and area for the common use case while limiting current consumption when\nexecuting PHIs.\n  However, these mechanisms may compromise a system's confidentiality\nguarantees. In particular, we observe that multilevel side-effects of\nthrottling mechanisms, due to PHI-related current management mechanisms, can be\ndetected by two different software contexts (i.e., sender and receiver) running\non 1) the same hardware thread, 2) co-located Simultaneous Multi-Threading\n(SMT) threads, and 3) different physical cores.\n  Based on these new observations on current management mechanisms, we develop\na new set of covert channels, IChannels, and demonstrate them in real modern\nIntel processors (which span more than 70% of the entire client and server\nprocessor market). Our analysis shows that IChannels provides more than 24x the\nchannel capacity of state-of-the-art power management covert channels. We\npropose practical and effective mitigations to each covert channel in IChannels\nby leveraging the insights we gain through a rigorous characterization of real\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 13:03:08 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 09:24:57 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Haj-Yahya", "Jawad", ""], ["Kim", "Jeremie S.", ""], ["Yaglikci", "A. Giray", ""], ["Puddu", "Ivan", ""], ["Orosa", "Lois", ""], ["Luna", "Juan G\u00f3mez", ""], ["Alser", "Mohammed", ""], ["Mutlu", "Onur", ""]]}, {"id": "2106.05268", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, Mike Davies, E. Paxon Frady, Pentti Kanerva, Spencer J.\n  Kent, Bruno A. Olshausen, Evgeny Osipov, Jan M. Rabaey, Dmitri A.\n  Rachkovskij, Abbas Rahimi, Friedrich T. Sommer", "title": "Vector Symbolic Architectures as a Computing Framework for Nanoscale\n  Hardware", "comments": "28 pages, 15 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews recent progress in the development of the computing\nframework Vector Symbolic Architectures (also known as Hyperdimensional\nComputing). This framework is well suited for implementation in stochastic,\nnanoscale hardware and it naturally expresses the types of cognitive operations\nrequired for Artificial Intelligence (AI). We demonstrate in this article that\nthe ring-like algebraic structure of Vector Symbolic Architectures offers\nsimple but powerful operations on high-dimensional vectors that can support all\ndata structures and manipulations relevant in modern computing. In addition, we\nillustrate the distinguishing feature of Vector Symbolic Architectures,\n\"computing in superposition,\" which sets it apart from conventional computing.\nThis latter property opens the door to efficient solutions to the difficult\ncombinatorial search problems inherent in AI applications. Vector Symbolic\nArchitectures are Turing complete, as we show, and we see them acting as a\nframework for computing with distributed representations in myriad AI settings.\nThis paper serves as a reference for computer architects by illustrating\ntechniques and philosophy of VSAs for distributed computing and relevance to\nemerging computing hardware, such as neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 23:38:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kleyko", "Denis", ""], ["Davies", "Mike", ""], ["Frady", "E. Paxon", ""], ["Kanerva", "Pentti", ""], ["Kent", "Spencer J.", ""], ["Olshausen", "Bruno A.", ""], ["Osipov", "Evgeny", ""], ["Rabaey", "Jan M.", ""], ["Rachkovskij", "Dmitri A.", ""], ["Rahimi", "Abbas", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2106.05632", "submitter": "Lois Orosa", "authors": "Lois Orosa, Yaohua Wang, Mohammad Sadrosadati, Jeremie S. Kim, Minesh\n  Patel, Ivan Puddu, Haocong Luo, Kaveh Razavi, Juan G\\'omez-Luna, Hasan\n  Hassan, Nika Mansouri-Ghiasi, Saugata Ghose, Onur Mutlu", "title": "CODIC: A Low-Cost Substrate for Enabling Custom In-DRAM Functionalities\n  and Optimizations", "comments": "Extended version of an ISCA 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DRAM is the dominant main memory technology used in modern computing systems.\nComputing systems implement a memory controller that interfaces with DRAM via\nDRAM commands. DRAM executes the given commands using internal components\n(e.g., access transistors, sense amplifiers) that are orchestrated by DRAM\ninternal timings, which are fixed foreach DRAM command. Unfortunately, the use\nof fixed internal timings limits the types of operations that DRAM can perform\nand hinders the implementation of new functionalities and custom mechanisms\nthat improve DRAM reliability, performance and energy. To overcome these\nlimitations, we propose enabling programmable DRAM internal timings for\ncontrolling in-DRAM components. To this end, we design CODIC, a new low-cost\nDRAM substrate that enables fine-grained control over four previously fixed\ninternal DRAM timings that are key to many DRAM operations. We implement CODIC\nwith only minimal changes to the DRAM chip and the DDRx interface. To\ndemonstrate the potential of CODIC, we propose two new CODIC-based security\nmechanisms that outperform state-of-the-art mechanisms in several ways: (1) a\nnew DRAM Physical Unclonable Function (PUF) that is more robust and has\nsignificantly higher throughput than state-of-the-art DRAM PUFs, and (2) the\nfirst cold boot attack prevention mechanism that does not introduce any\nperformance or energy overheads at runtime.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:15:58 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Orosa", "Lois", ""], ["Wang", "Yaohua", ""], ["Sadrosadati", "Mohammad", ""], ["Kim", "Jeremie S.", ""], ["Patel", "Minesh", ""], ["Puddu", "Ivan", ""], ["Luo", "Haocong", ""], ["Razavi", "Kaveh", ""], ["G\u00f3mez-Luna", "Juan", ""], ["Hassan", "Hasan", ""], ["Mansouri-Ghiasi", "Nika", ""], ["Ghose", "Saugata", ""], ["Mutlu", "Onur", ""]]}, {"id": "2106.05825", "submitter": "Mohammad Samavatian", "authors": "Mohammad Hossein Samavatian, Saikat Majumdar, Kristin Barber, Radu\n  Teodorescu", "title": "HASI: Hardware-Accelerated Stochastic Inference, A Defense Against\n  Adversarial Machine Learning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) are employed in an increasing number of\napplications, some of which are safety critical. Unfortunately, DNNs are known\nto be vulnerable to so-called adversarial attacks that manipulate inputs to\ncause incorrect results that can be beneficial to an attacker or damaging to\nthe victim. Multiple defenses have been proposed to increase the robustness of\nDNNs. In general, these defenses have high overhead, some require\nattack-specific re-training of the model or careful tuning to adapt to\ndifferent attacks.\n  This paper presents HASI, a hardware-accelerated defense that uses a process\nwe call stochastic inference to detect adversarial inputs. We show that by\ncarefully injecting noise into the model at inference time, we can\ndifferentiate adversarial inputs from benign ones. HASI uses the output\ndistribution characteristics of noisy inference compared to a non-noisy\nreference to detect adversarial inputs. We show an adversarial detection rate\nof 86% when applied to VGG16 and 93% when applied to ResNet50, which exceeds\nthe detection rate of the state of the art approaches, with a much lower\noverhead. We demonstrate two software/hardware-accelerated co-designs, which\nreduces the performance impact of stochastic inference to 1.58X-2X relative to\nthe unprotected baseline, compared to 15X-20X overhead for a software-only GPU\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:31:28 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 14:01:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Samavatian", "Mohammad Hossein", ""], ["Majumdar", "Saikat", ""], ["Barber", "Kristin", ""], ["Teodorescu", "Radu", ""]]}, {"id": "2106.06242", "submitter": "Dragi Kimovski", "authors": "Roland Math\\'a, Dragi Kimovski, Anatoliy Zabrovskiy, Christian\n  Timmerer and Radu Prodan", "title": "Where to Encode: A Performance Analysis of x86 and Arm-based Amazon EC2\n  Instances", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video streaming became an undivided part of the Internet. To efficiently\nutilize the limited network bandwidth it is essential to encode the video\ncontent. However, encoding is a computationally intensive task, involving\nhigh-performance resources provided by private infrastructures or public\nclouds. Public clouds, such as Amazon EC2, provide a large portfolio of\nservices and instances optimized for specific purposes and budgets. The\nmajority of Amazon instances use x86 processors, such as Intel Xeon or AMD\nEPYC. However, following the recent trends in computer architecture, Amazon\nintroduced Arm-based instances that promise up to 40% better cost-performance\nratio than comparable x86 instances for specific workloads. We evaluate in this\npaper the video encoding performance of x86 and Arm instances of four instance\nfamilies using the latest FFmpeg version and two video codecs. We examine the\nimpact of the encoding parameters, such as different presets and bitrates, on\nthe time and cost for encoding. Our experiments reveal that Arm instances show\nhigh time and cost-saving potential of up to 33.63% for specific bitrates and\npresets, especially for the x264 codec. However, the x86 instances are more\ngeneral and achieve low encoding times, regardless of the codec.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:50:28 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 13:21:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Math\u00e1", "Roland", ""], ["Kimovski", "Dragi", ""], ["Zabrovskiy", "Anatoliy", ""], ["Timmerer", "Christian", ""], ["Prodan", "Radu", ""]]}, {"id": "2106.06293", "submitter": "Dionysios Diamantopoulos", "authors": "Dionysios Diamantopoulos, Raphael Polig, Burkhard Ringlein, Mitra\n  Purandare, Beat Weiss, Christoph Hagleitner, Mark Lantz, Francois Abel", "title": "Acceleration-as-a-{\\mu}Service: A Cloud-native Monte-Carlo Option\n  Pricing Engine on CPUs, GPUs and Disaggregated FPGAs", "comments": "3 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The evolution of cloud applications into loosely-coupled microservices opens\nnew opportunities for hardware accelerators to improve workload performance.\nExisting accelerator techniques for cloud sacrifice the consolidation benefits\nof microservices. This paper presents CloudiFi, a framework to deploy and\ncompare accelerators as a cloud service. We evaluate our framework in the\ncontext of a financial workload and present early results indicating up to 485x\ngains in microservice response time.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:27:11 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Diamantopoulos", "Dionysios", ""], ["Polig", "Raphael", ""], ["Ringlein", "Burkhard", ""], ["Purandare", "Mitra", ""], ["Weiss", "Beat", ""], ["Hagleitner", "Christoph", ""], ["Lantz", "Mark", ""], ["Abel", "Francois", ""]]}, {"id": "2106.06433", "submitter": "Gagandeep Singh", "authors": "Gagandeep Singh, Mohammed Alser, Damla Senol Cali, Dionysios\n  Diamantopoulos, Juan G\\'omez-Luna, Henk Corporaal, Onur Mutlu", "title": "FPGA-Based Near-Memory Acceleration of Modern Data-Intensive\n  Applications", "comments": "This is an extended and updated version of a paper published in IEEE\n  Micro, vol. 41, no. 4, pp. 39-48, 1 July-Aug. 2021", "journal-ref": null, "doi": "10.1109/MM.2021.3088396", "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data-intensive applications demand high computation capabilities with\nstrict power constraints. Unfortunately, such applications suffer from a\nsignificant waste of both execution cycles and energy in current computing\nsystems due to the costly data movement between the computation units and the\nmemory units. Genome analysis and weather prediction are two examples of such\napplications. Recent FPGAs couple a reconfigurable fabric with high-bandwidth\nmemory (HBM) to enable more efficient data movement and improve overall\nperformance and energy efficiency. This trend is an example of a paradigm shift\nto near-memory computing. We leverage such an FPGA with high-bandwidth memory\n(HBM) for improving the pre-alignment filtering step of genome analysis and\nrepresentative kernels from a weather prediction model. Our evaluation\ndemonstrates large speedups and energy savings over a high-end IBM POWER9\nsystem and a conventional FPGA board with DDR4 memory. We conclude that\nFPGA-based near-memory computing has the potential to alleviate the data\nmovement bottleneck for modern data-intensive applications.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:43:04 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 08:06:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Gagandeep", ""], ["Alser", "Mohammed", ""], ["Cali", "Damla Senol", ""], ["Diamantopoulos", "Dionysios", ""], ["G\u00f3mez-Luna", "Juan", ""], ["Corporaal", "Henk", ""], ["Mutlu", "Onur", ""]]}, {"id": "2106.06678", "submitter": "Debanjan Das", "authors": "Aparna Sinha, Debanjan Das, Venkanna Udutalapally, Mukil Kumar\n  Selvarajan and Saraju P. Mohanty", "title": "iThing: Designing Next-Generation Things with Battery Health\n  Self-Monitoring Capabilities for Sustainable IoT in Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate and reliable technique for predicting Remaining Useful Life (RUL)\nfor battery cells proves helpful in battery-operated IoT devices, especially in\nremotely operated sensor nodes. Data-driven methods have proved to be the most\neffective methods until now. These IoT devices have low computational\ncapabilities to save costs, but Data-Driven battery health techniques often\nrequire a comparatively large amount of computational power to predict SOH and\nRUL due to most methods being feature-heavy. This issue calls for ways to\npredict RUL with the least amount of calculations and memory. This paper\nproposes an effective and novel peak extraction method to reduce computation\nand memory needs and provide accurate prediction methods using the least number\nof features while performing all calculations on-board. The model can\nself-sustain, requires minimal external interference, and hence operate\nremotely much longer. Experimental results prove the accuracy and reliability\nof this method. The Absolute Error (AE), Relative error (RE), and Root Mean\nSquare Error (RMSE) are calculated to compare effectiveness. The training of\nthe GPR model takes less than 2 seconds, and the correlation between SOH from\npeak extraction and RUL is 0.97.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 03:37:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sinha", "Aparna", ""], ["Das", "Debanjan", ""], ["Udutalapally", "Venkanna", ""], ["Selvarajan", "Mukil Kumar", ""], ["Mohanty", "Saraju P.", ""]]}, {"id": "2106.06889", "submitter": "Feng Zhang", "authors": "Feng Zhang, Zaifeng Pan, Yanliang Zhou, Jidong Zhai, Xipeng Shen, Onur\n  Mutlu, Xiaoyong Du", "title": "G-TADOC: Enabling Efficient GPU-Based Text Analytics without\n  Decompression", "comments": "37th IEEE International Conference on Data Engineering (ICDE 2021)", "journal-ref": null, "doi": "10.1109/ICDE51399.2021.00148", "report-no": null, "categories": "cs.DB cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text analytics directly on compression (TADOC) has proven to be a promising\ntechnology for big data analytics. GPUs are extremely popular accelerators for\ndata analytics systems. Unfortunately, no work so far shows how to utilize GPUs\nto accelerate TADOC. We describe G-TADOC, the first framework that provides\nGPU-based text analytics directly on compression, effectively enabling\nefficient text analytics on GPUs without decompressing the input data. G-TADOC\nsolves three major challenges. First, TADOC involves a large amount of\ndependencies, which makes it difficult to exploit massive parallelism on a GPU.\nWe develop a novel fine-grained thread-level workload scheduling strategy for\nGPU threads, which partitions heavily-dependent loads adaptively in a\nfine-grained manner. Second, in developing G-TADOC, thousands of GPU threads\nwriting to the same result buffer leads to inconsistency while directly using\nlocks and atomic operations lead to large synchronization overheads. We develop\na memory pool with thread-safe data structures on GPUs to handle such\ndifficulties. Third, maintaining the sequence information among words is\nessential for lossless compression. We design a sequence-support strategy,\nwhich maintains high GPU parallelism while ensuring sequence information. Our\nexperimental evaluations show that G-TADOC provides 31.1x average speedup\ncompared to state-of-the-art TADOC.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 00:50:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Feng", ""], ["Pan", "Zaifeng", ""], ["Zhou", "Yanliang", ""], ["Zhai", "Jidong", ""], ["Shen", "Xipeng", ""], ["Mutlu", "Onur", ""], ["Du", "Xiaoyong", ""]]}, {"id": "2106.07084", "submitter": "Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}", "authors": "Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}, Jeremie S. Kim, Fabrice Devaux,\n  and Onur Mutlu", "title": "Security Analysis of the Silver Bullet Technique for RowHammer\n  Prevention", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this document is to study the security properties of the\nSilver Bullet algorithm against worst-case RowHammer attacks. We mathematically\ndemonstrate that Silver Bullet, when properly configured and implemented in a\nDRAM chip, can securely prevent RowHammer attacks. The demonstration focuses on\nthe most representative implementation of Silver Bullet, the patent claiming\nmany implementation possibilities not covered in this demonstration. Our study\nconcludes that Silver Bullet is a promising RowHammer prevention mechanism that\ncan be configured to operate securely against RowHammer attacks at various\nefficiency-area tradeoff points, supporting relatively small hammer count\nvalues (e.g., 1000) and Silver Bullet table sizes (e.g., 1.06KB).\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:31:06 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 23:34:56 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ya\u011fl\u0131k\u00e7\u0131", "Abdullah Giray", ""], ["Kim", "Jeremie S.", ""], ["Devaux", "Fabrice", ""], ["Mutlu", "Onur", ""]]}, {"id": "2106.07087", "submitter": "Aman Arora", "authors": "Aman Arora, Andrew Boutros, Daniel Rauch, Aishwarya Rajen, Aatman\n  Borda, Seyed Alireza Damghani, Samidh Mehta, Sangram Kate, Pragnesh Patel,\n  Kenneth B. Kent, Vaughn Betz, Lizy K. John", "title": "Koios: A Deep Learning Benchmark Suite for FPGA Architecture and CAD\n  Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the prevalence of deep learning (DL) in many applications, researchers\nare investigating different ways of optimizing FPGA architecture and CAD to\nachieve better quality-of-results (QoR) on DL-based workloads. In this\noptimization process, benchmark circuits are an essential component; the QoR\nachieved on a set of benchmarks is the main driver for architecture and CAD\ndesign choices. However, current academic benchmark suites are inadequate, as\nthey do not capture any designs from the DL domain. This work presents a new\nsuite of DL acceleration benchmark circuits for FPGA architecture and CAD\nresearch, called Koios. This suite of 19 circuits covers a wide variety of\naccelerated neural networks, design sizes, implementation styles, abstraction\nlevels, and numerical precisions. These designs are larger, more data parallel,\nmore heterogeneous, more deeply pipelined, and utilize more FPGA architectural\nfeatures compared to existing open-source benchmarks. This enables researchers\nto pin-point architectural inefficiencies for this class of workloads and\noptimize CAD tools on more realistic benchmarks that stress the CAD algorithms\nin different ways. In this paper, we describe the designs in our benchmark\nsuite, present results of running them through the Verilog-to-Routing (VTR)\nflow using a recent FPGA architecture model, and identify key insights from the\nresulting metrics. On average, our benchmarks have 3.7x more netlist\nprimitives, 1.8x and 4.7x higher DSP and BRAM densities, and 1.7x higher\nfrequency with 1.9x more near-critical paths compared to the widely-used VTR\nsuite. Finally, we present two example case studies showing how architectural\nexploration for DL-optimized FPGAs can be performed using our new benchmark\nsuite.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:40:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Arora", "Aman", ""], ["Boutros", "Andrew", ""], ["Rauch", "Daniel", ""], ["Rajen", "Aishwarya", ""], ["Borda", "Aatman", ""], ["Damghani", "Seyed Alireza", ""], ["Mehta", "Samidh", ""], ["Kate", "Sangram", ""], ["Patel", "Pragnesh", ""], ["Kent", "Kenneth B.", ""], ["Betz", "Vaughn", ""], ["John", "Lizy K.", ""]]}, {"id": "2106.07271", "submitter": "Dmytro Petryk", "authors": "Dmytro Petryk, Zoya Dyka, Roland Sorge, Jan Schaeffner and Peter\n  Langendoerfer", "title": "Optical Fault Injection Attacks against Radiation-Hard Registers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  If devices are physically accessible optical fault injection attacks pose a\ngreat threat since the data processed as well as the operation flow can be\nmanipulated. Successful physical attacks may lead not only to leakage of secret\ninformation such as cryptographic private keys, but can also cause economic\ndamage especially if as a result of such a manipulation a critical\ninfrastructure is successfully attacked. Laser based attacks exploit the\nsensitivity of CMOS technologies to electromagnetic radiation in the visible or\nthe infrared spectrum. It can be expected that radiation-hard designs,\nspecially crafted for space applications, are more robust not only against\nhigh-energy particles and short electromagnetic waves but also against optical\nfault injection attacks. In this work we investigated the sensitivity of\nradiation-hard JICG shift registers to optical fault injection attacks. In our\nexperiments, we were able to trigger bit-set and bit-reset repeatedly changing\nthe data stored in single JICG flip-flops despite their high-radiation fault\ntolerance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:46:30 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:20:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Petryk", "Dmytro", ""], ["Dyka", "Zoya", ""], ["Sorge", "Roland", ""], ["Schaeffner", "Jan", ""], ["Langendoerfer", "Peter", ""]]}, {"id": "2106.07449", "submitter": "Calvin Deutschbein", "authors": "Calvin Deutschbein, Andres Meza, Francesco Restuccia, Ryan Kastner and\n  Cynthia Sturton", "title": "A Methodology For Creating Information Flow Specifications of Hardware\n  Designs", "comments": "9 pages, 4 figures, submitted to ICCAD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a methodology for creating information flow specifications of\nhardware designs. Such specifications can help designers better understand\ntheir design and are necessary for security validation processes. By combining\ninformation flow tracking and specification mining, we are able to produce\ninformation flow properties of a design without prior knowledge of security\nagreements or specifications. We develop a tool, Isadora, to evaluate our\nmethodology. We demonstrate Isadora may define the information flows within an\naccess control module in isolation and within an SoC and over a RISC-V design.\nOver the access control module, Isadora mined output completely covers an\nassertion based security specification of the design provided by the designers.\nFor both the access control module and RISC-V, we sample Isadora output\nproperties and find 10 out of 10 and 8 out of 10 properties, respectively,\ndefine the design behavior to relevant to a Common Weakness Enumeration (CWE).\nWe find our methodology may independently mine security properties manually\ndeveloped by hardware designers, automatically generate properties describing\nCWEs over a design, and scale to SoC and CPU designs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:20:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Deutschbein", "Calvin", ""], ["Meza", "Andres", ""], ["Restuccia", "Francesco", ""], ["Kastner", "Ryan", ""], ["Sturton", "Cynthia", ""]]}, {"id": "2106.07456", "submitter": "Philippos Papaphilippou", "authors": "Philippos Papaphilippou, Paul H. J. Kelly, Wayne Luk", "title": "Extending the RISC-V ISA for exploring advanced reconfigurable SIMD\n  instructions", "comments": "Accepted at the Fifth Workshop on Computer Architecture Research with\n  RISC-V (CARRV 2021), co-located with ISCA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel, non-standard set of vector instruction types for\nexploring custom SIMD instructions in a softcore. The new types allow\nsimultaneous access to a relatively high number of operands, reducing the\ninstruction count where applicable. Additionally, a high-performance\nopen-source RISC-V (RV32 IM) softcore is introduced, optimised for exploring\ncustom SIMD instructions and streaming performance. By providing instruction\ntemplates for instruction development in HDL/Verilog, efficient FPGA-based\ninstructions can be developed with few low-level lines of code. In order to\nimprove custom SIMD instruction performance, the softcore's cache hierarchy is\noptimised for bandwidth, such as with very wide blocks for the last-level\ncache. The approach is demonstrated on example memory-intensive applications on\nan FPGA. Although the exploration is based on the softcore, the goal is to\nprovide a means to experiment with advanced SIMD instructions which could be\nloaded in future CPUs that feature reconfigurable regions as custom\ninstructions. Finally, we provide some insights on the challenges and\neffectiveness of such future micro-architectures.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:31:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Papaphilippou", "Philippos", ""], ["Kelly", "Paul H. J.", ""], ["Luk", "Wayne", ""]]}, {"id": "2106.07597", "submitter": "Colby Banbury", "authors": "Colby Banbury, Vijay Janapa Reddi, Peter Torelli, Jeremy Holleman, Nat\n  Jeffries, Csaba Kiraly, Pietro Montino, David Kanter, Sebastian Ahmed, Danilo\n  Pau, Urmish Thakker, Antonio Torrini, Peter Warden, Jay Cordaro, Giuseppe Di\n  Guglielmo, Javier Duarte, Stephen Gibellini, Videet Parekh, Honson Tran, Nhan\n  Tran, Niu Wenxu, Xu Xuesong", "title": "MLPerf Tiny Benchmark", "comments": "TinyML Benchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in ultra-low-power tiny machine learning (TinyML) systems\npromise to unlock an entirely new class of smart applications. However,\ncontinued progress is limited by the lack of a widely accepted and easily\nreproducible benchmark for these systems. To meet this need, we present MLPerf\nTiny, the first industry-standard benchmark suite for ultra-low-power tiny\nmachine learning systems. The benchmark suite is the collaborative effort of\nmore than 50 organizations from industry and academia and reflects the needs of\nthe community. MLPerf Tiny measures the accuracy, latency, and energy of\nmachine learning inference to properly evaluate the tradeoffs between systems.\nAdditionally, MLPerf Tiny implements a modular design that enables benchmark\nsubmitters to show the benefits of their product, regardless of where it falls\non the ML deployment stack, in a fair and reproducible manner. The suite\nfeatures four benchmarks: keyword spotting, visual wake words, image\nclassification, and anomaly detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:05:17 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 13:47:53 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Banbury", "Colby", ""], ["Reddi", "Vijay Janapa", ""], ["Torelli", "Peter", ""], ["Holleman", "Jeremy", ""], ["Jeffries", "Nat", ""], ["Kiraly", "Csaba", ""], ["Montino", "Pietro", ""], ["Kanter", "David", ""], ["Ahmed", "Sebastian", ""], ["Pau", "Danilo", ""], ["Thakker", "Urmish", ""], ["Torrini", "Antonio", ""], ["Warden", "Peter", ""], ["Cordaro", "Jay", ""], ["Di Guglielmo", "Giuseppe", ""], ["Duarte", "Javier", ""], ["Gibellini", "Stephen", ""], ["Parekh", "Videet", ""], ["Tran", "Honson", ""], ["Tran", "Nhan", ""], ["Wenxu", "Niu", ""], ["Xuesong", "Xu", ""]]}, {"id": "2106.07855", "submitter": "Himanshu Thapliyal", "authors": "Zachary Kahleifeh and Himanshu Thapliyal", "title": "Low-Energy and CPA-Resistant Adiabatic CMOS/MTJ Logic for IoT Devices", "comments": "6 pages, 2021 IEEE Computer Society Annual Symposium on VLSI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous growth in the number of Internet of Things (IoT) devices has\nincreased focus on the energy efficiency and security of an IoT device. In this\npaper, we will present a design level, non-volatile adiabatic architecture for\nlow-energy and Correlation Power Analysis (CPA) resistant IoT devices. IoT\ndevices constructed with CMOS integrated circuits suffer from high dynamic\nenergy and leakage power. To solve this, we look at both adiabatic logic and\nSTT-MTJs (Spin Transfer Torque Magnetic Tunnel Junctions) to reduce both\ndynamic energy and leakage power. Furthermore, CMOS integrated circuits suffer\nfrom side-channel leakage making them insecure against power analysis attacks.\nWe again look to adiabatic logic to design secure circuits with uniform power\nconsumption, thus, defending against power analysis attacks. We have developed\na hybrid adiabatic- MTJ architecture using two-phase adiabatic logic. We show\nthat hybrid adiabatic-MTJ circuits are both low energy and secure when compared\nwith CMOS circuits. As a case study, we have constructed one round of PRESENT\nand have shown energy savings of 64.29% at a frequency of 25 MHz. Furthermore,\nwe have performed a correlation power analysis attack on our proposed design\nand determined that the key was kept hidden.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 03:19:13 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kahleifeh", "Zachary", ""], ["Thapliyal", "Himanshu", ""]]}, {"id": "2106.07894", "submitter": "Jianlei Yang", "authors": "Jianlei Yang, Wenzhi Fu, Xingzhou Cheng, Xucheng Ye, Pengcheng Dai,\n  and Weisheng Zhao", "title": "S2Engine: A Novel Systolic Architecture for Sparse Convolutional Neural\n  Networks", "comments": "13 pages, 17 figures", "journal-ref": "IEEE Transactions on Computers, 2021", "doi": "10.1109/TC.2021.3087946", "report-no": null, "categories": "cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved great success in\nperforming cognitive tasks. However, execution of CNNs requires a large amount\nof computing resources and generates heavy memory traffic, which imposes a\nsevere challenge on computing system design. Through optimizing parallel\nexecutions and data reuse in convolution, systolic architecture demonstrates\ngreat advantages in accelerating CNN computations. However, regular internal\ndata transmission path in traditional systolic architecture prevents the\nsystolic architecture from completely leveraging the benefits introduced by\nneural network sparsity. Deployment of fine-grained sparsity on the existing\nsystolic architectures is greatly hindered by the incurred computational\noverheads. In this work, we propose S2Engine $-$ a novel systolic architecture\nthat can fully exploit the sparsity in CNNs with maximized data reuse. S2Engine\ntransmits compressed data internally and allows each processing element to\ndynamically select an aligned data from the compressed dataflow in convolution.\nCompared to the naive systolic array, S2Engine achieves about $3.2\\times$ and\nabout $3.0\\times$ improvements on speed and energy efficiency, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 06:08:37 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yang", "Jianlei", ""], ["Fu", "Wenzhi", ""], ["Cheng", "Xingzhou", ""], ["Ye", "Xucheng", ""], ["Dai", "Pengcheng", ""], ["Zhao", "Weisheng", ""]]}, {"id": "2106.07997", "submitter": "Qingqing Wu", "authors": "Qingqing Wu, Xinrong Guan, Rui Zhang", "title": "Intelligent Reflecting Surface Aided Wireless Energy and Information\n  Transmission: An Overview", "comments": "Invited by Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AR cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent reflecting surface (IRS) is a promising technology for achieving\nspectrum and energy efficient wireless networks cost-effectively. Most existing\nworks on IRS have focused on exploiting IRS to enhance the performance of\nwireless communication or wireless information transmission (WIT), while its\npotential for boosting the efficiency of radio-frequency (RF) wireless energy\ntransmission (WET) still remains largely open. Although IRS-aided WET shares\nsimilar characteristics with IRS-aided WIT, they differ fundamentally in terms\nof design objective, receiver architecture, and practical constraints. In this\npaper, we provide a tutorial overview on how to efficiently design IRS-aided\nWET systems as well as IRS-aided systems with both WIT and WET, namely\nIRS-aided simultaneous wireless information and power transfer (SWIPT) and\nIRS-aided wireless powered communication network (WPCN), mainly from a\ncommunication and signal processing perspective. In particular, we present\nstate-of-the-art solutions to tackle the unique challenges in operating these\nsystems, such as IRS passive reflection optimization, channel estimation and\ndeployment. In addition, we also propose new solution approaches and point out\nimportant directions for future research and investigation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 09:22:56 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 01:08:46 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 06:03:52 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Wu", "Qingqing", ""], ["Guan", "Xinrong", ""], ["Zhang", "Rui", ""]]}, {"id": "2106.08167", "submitter": "Duy Thanh Nguyen", "authors": "Duy Thanh Nguyen, Hyeonseung Je, Tuan Nghia Nguyen, Soojung Ryu,\n  Kyujung Lee, and Hyuk-Jae Lee", "title": "ShortcutFusion: From Tensorflow to FPGA-based accelerator with\n  reuse-aware memory allocation for shortcut data", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Residual block is a very common component in recent state-of-the art CNNs\nsuch as EfficientNet or EfficientDet. Shortcut data accounts for nearly 40% of\nfeature-maps access in ResNet152 [8]. Most of the previous DNN compilers,\naccelerators ignore the shortcut data optimization. This paper presents\nShortcutFusion, an optimization tool for FPGA-based accelerator with a\nreuse-aware static memory allocation for shortcut data, to maximize on-chip\ndata reuse given resource constraints. From TensorFlow DNN models, the proposed\ndesign generates instruction sets for a group of nodes which uses an optimized\ndata reuse for each residual block. The accelerator design implemented on the\nXilinx KCU1500 FPGA card significantly outperforms NVIDIA RTX 2080 Ti, Titan\nXp, and GTX 1080 Ti for the EfficientNet inference. Compared to RTX 2080 Ti,\nthe proposed design is 1.35-2.33x faster and 6.7-7.9x more power efficient.\nCompared to the result from baseline, in which the weights, inputs, and outputs\nare accessed from the off-chip memory exactly once per each layer,\nShortcutFusion reduces the DRAM access by 47.8-84.8% for RetinaNet, Yolov3,\nResNet152, and EfficientNet. Given a similar buffer size to ShortcutMining [8],\nwhich also mine the shortcut data in hardware, the proposed work reduces\noff-chip access for feature-maps 5.27x while accessing weight from off-chip\nmemory exactly once.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:10:10 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:59:04 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Nguyen", "Duy Thanh", ""], ["Je", "Hyeonseung", ""], ["Nguyen", "Tuan Nghia", ""], ["Ryu", "Soojung", ""], ["Lee", "Kyujung", ""], ["Lee", "Hyuk-Jae", ""]]}, {"id": "2106.08402", "submitter": "Masoud Zabihi", "authors": "Masoud Zabihi, Salonik Resch, Husrev C{\\i}lasun, Zamshed I. Chowdhury,\n  Zhengyang Zhao, Ulya R. Karpuzcu, Jian-Ping Wang, and Sachin S. Sapatnekar", "title": "Exploring the Feasibility of Using 3D XPoint as an In-Memory Computing\n  Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how 3D XPoint memory arrays can be used as in-memory\ncomputing accelerators. We first show that thresholded matrix-vector\nmultiplication (TMVM), the fundamental computational kernel in many\napplications including machine learning, can be implemented within a 3D XPoint\narray without requiring data to leave the array for processing. Using the\nimplementation of TMVM, we then discuss the implementation of a binary neural\ninference engine. We discuss the application of the core concept to address\nissues such as system scalability, where we connect multiple 3D XPoint arrays,\nand power integrity, where we analyze the parasitic effects of metal lines on\nnoise margins. To assure power integrity within the 3D XPoint array during this\nimplementation, we carefully analyze the parasitic effects of metal lines on\nthe accuracy of the implementations. We quantify the impact of parasitics on\nlimiting the size and configuration of a 3D XPoint array, and estimate the\nmaximum acceptable size of a 3D XPoint subarray.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 19:59:26 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zabihi", "Masoud", ""], ["Resch", "Salonik", ""], ["C\u0131lasun", "Husrev", ""], ["Chowdhury", "Zamshed I.", ""], ["Zhao", "Zhengyang", ""], ["Karpuzcu", "Ulya R.", ""], ["Wang", "Jian-Ping", ""], ["Sapatnekar", "Sachin S.", ""]]}, {"id": "2106.08800", "submitter": "Ebrahim Farahmand", "authors": "Ebrahim Farahmand, Ali Mahani, Muhammad Abdullah Hanif, Muhammad\n  Shafique", "title": "High Performance and Optimal Configuration of Accurate Heterogeneous\n  Block-Based Approximate Adder", "comments": "Submitted to the IEEE-TCAD journal, 16 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximate computing is an emerging paradigm to improve power and\nperformance efficiency for error-resilient application. Recent approximate\nadders have significantly extended the design space of accuracy-power\nconfigurable approximate adders, and find optimal designs by exploring the\ndesign space. In this paper, a new energy-efficient heterogeneous block-based\napproximate adder (HBBA) is proposed; which is a generic/configurable model\nthat can be transformed to a particular adder by defining some configurations.\nAn HBBA, in general, is composed of heterogeneous sub-adders, where each\nsub-adder can have a different configuration. A set of configurations of all\nthe sub-adders in an HBBA defines its configuration. The block-based adders are\napproximated through inexact logic configuration and truncated carry chains.\nHBBA increases design space providing additional design points that fall on the\nPareto-front and offer better power-accuracy trade-off compared to other\nconfigurations. Furthermore, to avoid Mont-Carlo simulations, we propose an\nanalytical modelling technique to evaluate the probability of error and\nProbability Mass Function (PMF) of error value. Moreover, the estimation method\nestimates delay, area and power of heterogeneous block-based approximate\nadders. Thus, based on the analytical model and estimation method, the optimal\nconfiguration under a given error constraint can be selected from the whole\ndesign space of the proposed adder model by exhaustive search. The simulation\nresults show that our HBBA provides improved accuracy in terms of error metrics\ncompared to some state-of-the-art approximate adders. HBBA with 32 bits length\nserves about 15% reduction in area and up to 17% reduction in energy compared\nto state-of-the-art approximate adders.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:03:49 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Farahmand", "Ebrahim", ""], ["Mahani", "Ali", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2106.08877", "submitter": "Mahya Morid Ahmadi", "authors": "Mahya Morid Ahmadi, Faiq Khalid, Muhammad Shafique", "title": "Side-Channel Attacks on RISC-V Processors: Current Progress, Challenges,\n  and Opportunities", "comments": "CYBER 2020, The Fifth International Conference on Cyber-Technologies\n  and Cyber-Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks on microprocessors, like the RISC-V, exhibit security\nvulnerabilities that lead to several design challenges. Hence, it is imperative\nto study and analyze these security vulnerabilities comprehensively. In this\npaper, we present a brief yet comprehensive study of the security\nvulnerabilities in modern microprocessors with respect to side-channel attacks\nand their respective mitigation techniques. The focus of this paper is to\nanalyze the hardware-exploitable side-channel attack using power consumption\nand software-exploitable side-channel attacks to manipulate cache. Towards\nthis, we perform an in-depth analysis of the applicability and practical\nimplications of cache attacks on RISC-V microprocessors and their associated\nchallenges. Finally, based on the comparative study and our analysis, we\nhighlight some key research directions to develop robust RISC-V microprocessors\nthat are resilient to side-channel attacks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:51:00 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ahmadi", "Mahya Morid", ""], ["Khalid", "Faiq", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2106.09104", "submitter": "Anup Das", "authors": "Shihao Song, Twisha Titirsha, Anup Das", "title": "Improving Inference Lifetime of Neuromorphic Systems via Intelligent\n  Synapse Mapping", "comments": "Accepted for publication at ASAP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-Volatile Memories (NVMs) such as Resistive RAM (RRAM) are used in\nneuromorphic systems to implement high-density and low-power analog synaptic\nweights. Unfortunately, an RRAM cell can switch its state after reading its\ncontent a certain number of times. Such behavior challenges the integrity and\nprogram-once-read-many-times philosophy of implementing machine learning\ninference on neuromorphic systems, impacting the Quality-of-Service (QoS).\nElevated temperatures and frequent usage can significantly shorten the number\nof times an RRAM cell can be reliably read before it becomes absolutely\nnecessary to reprogram. We propose an architectural solution to extend the read\nendurance of RRAM-based neuromorphic systems. We make two key contributions.\nFirst, we formulate the read endurance of an RRAM cell as a function of the\nprogrammed synaptic weight and its activation within a machine learning\nworkload. Second, we propose an intelligent workload mapping strategy\nincorporating the endurance formulation to place the synapses of a machine\nlearning model onto the RRAM cells of the hardware. The objective is to extend\nthe inference lifetime, defined as the number of times the model can be used to\ngenerate output (inference) before the trained weights need to be reprogrammed\non the RRAM cells of the system. We evaluate our architectural solution with\nmachine learning workloads on a cycle-accurate simulator of an RRAM-based\nneuromorphic system. Our results demonstrate a significant increase in\ninference lifetime with only a minimal performance impact.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:12:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Song", "Shihao", ""], ["Titirsha", "Twisha", ""], ["Das", "Anup", ""]]}, {"id": "2106.09144", "submitter": "Geng Yuan", "authors": "Geng Yuan, Payman Behnam, Zhengang Li, Ali Shafiee, Sheng Lin,\n  Xiaolong Ma, Hang Liu, Xuehai Qian, Mahdi Nazm Bojnordi, Yanzhi Wang, Caiwen\n  Ding", "title": "FORMS: Fine-grained Polarized ReRAM-based In-situ Computation for\n  Mixed-signal DNN Accelerator", "comments": "In Proceedings of the 48th Annual International Symposium on Computer\n  Architecture (ISCA), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works demonstrated the promise of using resistive random access memory\n(ReRAM) as an emerging technology to perform inherently parallel analog domain\nin-situ matrix-vector multiplication -- the intensive and key computation in\nDNNs. With weights stored in the ReRAM crossbar cells as conductance, when the\ninput vector is applied to word lines, the matrix-vector multiplication results\ncan be generated as the current in bit lines. A key problem is that the weight\ncan be either positive or negative, but the in-situ computation assumes all\ncells on each crossbar column with the same sign. The current architectures\neither use two ReRAM crossbars for positive and negative weights, or add an\noffset to weights so that all values become positive. Neither solution is\nideal: they either double the cost of crossbars, or incur extra offset\ncircuity. To better solve this problem, this paper proposes FORMS, a\nfine-grained ReRAM-based DNN accelerator with polarized weights. Instead of\ntrying to represent the positive/negative weights, our key design principle is\nto enforce exactly what is assumed in the in-situ computation -- ensuring that\nall weights in the same column of a crossbar have the same sign. It naturally\navoids the cost of an additional crossbar. Such weights can be nicely generated\nusing alternating direction method of multipliers (ADMM) regularized\noptimization, which can exactly enforce certain patterns in DNN weights. To\nachieve high accuracy, we propose to use fine-grained sub-array columns, which\nprovide a unique opportunity for input zero-skipping, significantly avoiding\nunnecessary computations. It also makes the hardware much easier to implement.\nPutting all together, with the same optimized models, FORMS achieves\nsignificant throughput improvement and speed up in frame per second over ISAAC\nwith similar area cost.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 21:42:08 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yuan", "Geng", ""], ["Behnam", "Payman", ""], ["Li", "Zhengang", ""], ["Shafiee", "Ali", ""], ["Lin", "Sheng", ""], ["Ma", "Xiaolong", ""], ["Liu", "Hang", ""], ["Qian", "Xuehai", ""], ["Bojnordi", "Mahdi Nazm", ""], ["Wang", "Yanzhi", ""], ["Ding", "Caiwen", ""]]}, {"id": "2106.09180", "submitter": "Yash Akhauri", "authors": "Yash Akhauri, Adithya Niranjan, J. Pablo Mu\\~noz, Suvadeep Banerjee,\n  Abhijit Davare, Pasquale Cocchini, Anton A. Sorokin, Ravi Iyer, Nilesh Jain", "title": "RHNAS: Realizable Hardware and Neural Architecture Search", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapidly evolving field of Artificial Intelligence necessitates automated\napproaches to co-design neural network architecture and neural accelerators to\nmaximize system efficiency and address productivity challenges. To enable joint\noptimization of this vast space, there has been growing interest in\ndifferentiable NN-HW co-design. Fully differentiable co-design has reduced the\nresource requirements for discovering optimized NN-HW configurations, but fail\nto adapt to general hardware accelerator search spaces. This is due to the\nexistence of non-synthesizable (invalid) designs in the search space of many\nhardware accelerators. To enable efficient and realizable co-design of\nconfigurable hardware accelerators with arbitrary neural network search spaces,\nwe introduce RHNAS. RHNAS is a method that combines reinforcement learning for\nhardware optimization with differentiable neural architecture search. RHNAS\ndiscovers realizable NN-HW designs with 1.84x lower latency and 1.86x lower\nenergy-delay product (EDP) on ImageNet and 2.81x lower latency and 3.30x lower\nEDP on CIFAR-10 over the default hardware accelerator design.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 00:15:42 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Akhauri", "Yash", ""], ["Niranjan", "Adithya", ""], ["Mu\u00f1oz", "J. Pablo", ""], ["Banerjee", "Suvadeep", ""], ["Davare", "Abhijit", ""], ["Cocchini", "Pasquale", ""], ["Sorokin", "Anton A.", ""], ["Iyer", "Ravi", ""], ["Jain", "Nilesh", ""]]}, {"id": "2106.09308", "submitter": "Ishan Thakkar", "authors": "Bobby Bose and Ishan Thakkar", "title": "Characterization and Mitigation of Electromigration Effects in TSV-Based\n  Power Delivery Network Enabled 3D-Stacked DRAMs", "comments": "To appear at IEEE/ACM GLSVLSI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With 3D-stacked DRAM architectures becoming more prevalent, it has become\nimportant to find ways to characterize and mitigate the adverse effects that\ncan hinder their inherent access parallelism and throughput. One example of\nsuch adversities is the electromigration (EM) effects in the through-silicon\nvias (TSVs) of the power delivery network (PDN) of 3D-stacked DRAM\narchitectures. Several prior works have addressed the effects of EM in TSVs of\n3D integrated circuits. However, no prior work has addressed the effects of EM\nin the PDN TSVs on the performance and lifetime of 3D-stacked DRAMs. In this\npaper, we characterize the effects of EM in PDN TSVs on a Hybrid Memory Cube\n(HMC) architecture employing the conventional PDN design with clustered layout\nof power and ground TSVs. We then present a new PDN design with a distributed\nlayout of power and ground TSVs and show that it can mitigate the adverse\neffects of EM on the HMC architecture performance without requiring additional\npower and ground pins. Our benchmark-driven simulation-based analysis shows\nthat compared to the clustered PDN layout, our proposed distributed PDN layout\nimproves the EM-affected lifetime of the HMC architecture by up to 10 years.\nDuring this useful lifetime, the HMC architecture yields up to 1.51 times less\nenergy-delay product (EDP).\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:22:22 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bose", "Bobby", ""], ["Thakkar", "Ishan", ""]]}, {"id": "2106.09536", "submitter": "Priyanka Joshi", "authors": "Priyanka Joshi and Bodhistwa Mazumdar", "title": "Single Event Transient Fault Analysis of ELEPHANT cipher", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel fault attack termed as Single Event\nTransient Fault Analysis (SETFA) attack, which is well suited for hardware\nimplementations. The proposed approach pinpoints hotspots in the cypher's Sbox\ncombinational logic circuit that significantly reduce the key entropy when\nsubjected to faults. ELEPHANT is a parallel authenticated encryption and\nassociated data (AEAD) scheme targeted to hardware implementations, a finalist\nin the Lightweight cryptography (LWC) competition launched by NIST. In this\nwork, we investigate vulnerabilities of ELEPHANT against fault analysis. We\nobserve that the use of 128-bit random nonce makes it resistant against many\ncryptanalysis techniques like differential, linear, etc., and their variants.\nHowever, the relaxed nature of Statistical Fault Analysis (SFA) methods makes\nthem widely applicable in restrictive environments. We propose a SETFA-based\nkey recovery attack on Elephant. We performed Single experiments with random\nplaintexts and keys, on Dumbo, a Sponge-based instance of the Elephant-AEAD\nscheme. Our proposed approach could recover the secret key in 85-250\nciphertexts. In essence, this work investigates new vulnerabilities towards\nfault analysis that may require to be addressed to ensure secure computations\nand communications in IoT scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 16:00:26 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Joshi", "Priyanka", ""], ["Mazumdar", "Bodhistwa", ""]]}, {"id": "2106.09975", "submitter": "George Papadimitriou Dr.", "authors": "George Papadimitriou, Manolis Kaliorakis, Athanasios Chatzidimitriou,\n  Dimitris Gizopoulos, Greg Favor, Kumar Sankaran, Shidhartha Das", "title": "A System-Level Voltage/Frequency Scaling Characterization Framework for\n  Multicore CPUs", "comments": "7 pages, 6 figures, SELSE '17, March 21-22, 2017, Boston, MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply voltage scaling is one of the most effective techniques to reduce the\npower consumption of microprocessors. However, technology limitations such as\naging and process variability enforce microprocessor designers to apply\npessimistic voltage guardbands to guarantee correct operation in the field for\nany foreseeable workload. This worst-case design practice makes energy\nefficiency hard to scale with technology evolution. Improving energy-efficiency\nrequires the identification of the chip design margins through time-consuming\nand comprehensive characterization of its operational limits. Such a\ncharacterization of state-of-the-art multi-core CPUs fabricated in aggressive\ntechnologies is a multi-parameter process, which requires statistically\nsignificant information. In this paper, we present an automated framework to\nsupport system-level voltage and frequency scaling characterization of Applied\nMicro's state-of-the-art ARMv8-based multicore CPUs used in the X-Gene 2\nmicro-server family. The fully automated framework can provide fine-grained\ninformation of the system's state by monitoring any abnormal behavior that may\noccur during reduced supply voltage conditions. We also propose a new metric to\nquantify the behavior of a microprocessor when it operates beyond nominal\nconditions. Our experimental results demonstrate potential uses of the\ncharacterization framework to identify the limits of operation for improved\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 07:55:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Papadimitriou", "George", ""], ["Kaliorakis", "Manolis", ""], ["Chatzidimitriou", "Athanasios", ""], ["Gizopoulos", "Dimitris", ""], ["Favor", "Greg", ""], ["Sankaran", "Kumar", ""], ["Das", "Shidhartha", ""]]}, {"id": "2106.09991", "submitter": "George Papadimitriou Dr.", "authors": "Odysseas Chatzopoulos, George-Marios Fragkoulis, George Papadimitriou,\n  Dimitris Gizopoulos", "title": "Towards Accurate Performance Modeling of RISC-V Designs", "comments": "8 pages, 4 figures, CARRV '21, June 17, 2021, Co-located with ISCA\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microprocessor design, debug, and validation research and development are\nincreasingly based on modeling and simulation at different abstraction layers.\nMicroarchitecture-level simulators have become the most commonly used tools for\nperformance evaluation, due to their high simulation throughput, compared to\nlower levels of abstraction, but usually come at the cost of loss of hardware\naccuracy. As a result, the implementation, speed, and accuracy of\nmicroarchitectural simulators are becoming more and more crucial for\nresearchers and microprocessor architects. One of the most critical aspects of\na microarchitectural simulator is its ability to accurately express design\nstandards as various aspects of the microarchitecture change during design\nrefinement. On the other hand, modern microprocessor models rely on dedicated\nhardware implementations, making the design space exploration a time-consuming\nprocess that can be performed using a variety of methods, ranging from\nhigh-level models to hardware prototyping. Therefore, the tradeoff between\nsimulation speed and accuracy, can be significantly varied, and an\napplication's performance measurements uncertain. In this paper, we present a\nmicroarchitecture-level simulation modeling study, which enables as accurate as\npossible performance modeling of a RISC-V out-of-order superscalar\nmicroprocessor core. By diligently adjusting several important\nmicroarchitectural parameters of the widely used gem5 simulator, we investigate\nthe challenges of accurate performance modeling on microarchitecture-level\nsimulation compared to accuracy and low simulation throughput of RTL simulation\nof the target design. Further, we demonstrate the main sources of errors that\nprevent high accuracy levels of the microarchitecture-level modeling.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 08:22:03 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chatzopoulos", "Odysseas", ""], ["Fragkoulis", "George-Marios", ""], ["Papadimitriou", "George", ""], ["Gizopoulos", "Dimitris", ""]]}, {"id": "2106.10382", "submitter": "Yusuke Sakemi Ph.D.", "authors": "Yusuke Sakemi, Takashi Morie, Takeo Hosomi, Kazuyuki Aihara", "title": "Effects of VLSI Circuit Constraints on Temporal-Coding Multilayer\n  Spiking Neural Networks", "comments": "corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural network (SNN) has been attracting considerable attention\nnot only as a mathematical model for the brain, but also as an energy-efficient\ninformation processing model for real-world applications. In particular, SNNs\nbased on temporal coding are expected to be much more efficient than those\nbased on rate coding, because the former requires substantially fewer spikes to\ncarry out tasks. As SNNs are continuous-state and continuous-time models, it is\nfavorable to implement them with analog VLSI circuits. However, the\nconstruction of the entire system with continuous-time analog circuits would be\ninfeasible when the system size is very large. Therefore, mixed-signal circuits\nmust be employed, and the time discretization and quantization of the synaptic\nweights are necessary. Moreover, the analog VLSI implementation of SNNs\nexhibits non-idealities, such as the effects of noise and device mismatches, as\nwell as other constraints arising from the analog circuit operation. In this\nstudy, we investigated the effects of the time discretization and/or weight\nquantization on the performance of SNNs. Furthermore, we elucidated the effects\nthe lower bound of the membrane potentials and the temporal fluctuation of the\nfiring threshold. Finally, we propose an optimal approach for the mapping of\nmathematical SNN models to analog circuits with discretized time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:51:58 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 01:27:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Sakemi", "Yusuke", ""], ["Morie", "Takashi", ""], ["Hosomi", "Takeo", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "2106.10392", "submitter": "Subhasish Mitra", "authors": "Karthik Ganesan, Florian Lonsing, Srinivasa Shashank Nuthakki, Eshan\n  Singh, Mohammad Rahmani Fadiheh, Wolfgang Kunz, Dominik Stoffel, Clark\n  Barrett, Subhasish Mitra", "title": "Effective Pre-Silicon Verification of Processor Cores by Breaking the\n  Bounds of Symbolic Quick Error Detection", "comments": "This article has the full author list which was missing in\n  arXiv:1908.06757. arXiv admin note: substantial text overlap with\n  arXiv:1908.06757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to pre-silicon verification of processor designs.\nThe purpose of pre-silicon verification is to find logic bugs in a design at an\nearly stage and thus avoid time- and cost-intensive post-silicon debugging. Our\napproach relies on symbolic quick error detection (Symbolic QED, or SQED). SQED\nis targeted at finding logic bugs in a symbolic representation of a design by\ncombining bounded model checking (BMC) with QED tests. QED tests are powerful\nin generating short sequences of instructions (traces) that trigger bugs. We\nextend an existing SQED approach with symbolic starting states. This way, we\nenable the BMC tool to select starting states arbitrarily when generating a\ntrace. To avoid false positives, (e.g., traces starting in unreachable states\nthat may not be-have in accordance with the processor instruction-set\narchitecture), we define constraints to restrict the set of possible starting\nstates. We demonstrate that these constraints, togeth-er with reasonable\nassumptions about the system behavior, allow us to avoid false positives. Using\nour approach, we discovered previously unknown bugs in open-source RISC-V\nprocessor cores that existing methods cannot detect. Moreover, our novel\napproach out-performs existing ones in the detection of bugs having long traces\nand in the detection of hardware Trojans, i.e., unauthorized modifications of a\ndesign.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 23:51:59 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ganesan", "Karthik", ""], ["Lonsing", "Florian", ""], ["Nuthakki", "Srinivasa Shashank", ""], ["Singh", "Eshan", ""], ["Fadiheh", "Mohammad Rahmani", ""], ["Kunz", "Wolfgang", ""], ["Stoffel", "Dominik", ""], ["Barrett", "Clark", ""], ["Mitra", "Subhasish", ""]]}, {"id": "2106.10499", "submitter": "Gordon E. Moon", "authors": "Gordon E. Moon, Hyoukjun Kwon, Geonhwa Jeong, Prasanth Chatarasi,\n  Sivasankaran Rajamanickam, Tushar Krishna", "title": "Evaluating Spatial Accelerator Architectures with Tiled Matrix-Matrix\n  Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing interest in custom spatial accelerators for machine\nlearning applications. These accelerators employ a spatial array of processing\nelements (PEs) interacting via custom buffer hierarchies and networks-on-chip.\nThe efficiency of these accelerators comes from employing optimized dataflow\n(i.e., spatial/temporal partitioning of data across the PEs and fine-grained\nscheduling) strategies to optimize data reuse. The focus of this work is to\nevaluate these accelerator architectures using a tiled general matrix-matrix\nmultiplication (GEMM) kernel. To do so, we develop a framework that finds\noptimized mappings (dataflow and tile sizes) for a tiled GEMM for a given\nspatial accelerator and workload combination, leveraging an analytical cost\nmodel for runtime and energy. Our evaluations over five spatial accelerators\ndemonstrate that the tiled GEMM mappings systematically generated by our\nframework achieve high performance on various GEMM workloads and accelerators.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 13:53:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Moon", "Gordon E.", ""], ["Kwon", "Hyoukjun", ""], ["Jeong", "Geonhwa", ""], ["Chatarasi", "Prasanth", ""], ["Rajamanickam", "Sivasankaran", ""], ["Krishna", "Tushar", ""]]}, {"id": "2106.10652", "submitter": "Md Ziaul Haque Zim", "authors": "Md Ziaul Haque Zim", "title": "TinyML: Analysis of Xtensa LX6 microprocessor for Neural Network\n  Applications by ESP32 SoC", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.28602.11204", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent decades, Machine Learning (ML) has become extremely important for\nmany computing applications. The pervasiveness of ultra-low-power embedded\ndevices such as ESP32 or ESP32 Cam with tiny Machine Learning (tinyML)\napplications will enable the mass proliferation of Artificial Intelligent\npowered Embedded IoT Devices. In the last few years, the microcontroller device\n(Espressif ESP32) became powerful enough to be used for small/tiny machine\nlearning (tinyML) tasks. The ease of use of platforms like Arduino IDE,\nMicroPython and TensorFlow Lite (TF) with tinyML application make it an\nindispensable topic of research for mobile robotics, modern computer science\nand electrical engineering. The goal of this paper is to analyze the speed of\nthe Xtensa dual core 32-bit LX6 microprocessor by running a neural network\napplication. The different number of inputs (9, 36, 144 and 576) inputted\nthrough the different number of neurons in neural networks with one and two\nhidden layers. Xtensa LX6 microprocessor has been analyzed because it comes\ninside with Espressif ESP32 and ESP32 Cam which are very easy to use, plug and\nplay IoT device. In this paper speed of the Xtensa LX6 microprocessor in\nfeed-forward mode has been analyzed.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 08:39:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zim", "Md Ziaul Haque", ""]]}, {"id": "2106.10860", "submitter": "Davis Blalock", "authors": "Davis Blalock, John Guttag", "title": "Multiplying Matrices Without Multiplying", "comments": "To appear at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplying matrices is among the most fundamental and compute-intensive\noperations in machine learning. Consequently, there has been significant work\non efficiently approximating matrix multiplies. We introduce a learning-based\nalgorithm for this task that greatly outperforms existing methods. Experiments\nusing hundreds of matrices from diverse domains show that it often runs\n$100\\times$ faster than exact matrix products and $10\\times$ faster than\ncurrent approximate methods. In the common case that one matrix is known ahead\nof time, our method also has the interesting property that it requires zero\nmultiply-adds. These results suggest that a mixture of hashing, averaging, and\nbyte shuffling$-$the core operations of our method$-$could be a more promising\nbuilding block for machine learning than the sparsified, factorized, and/or\nscalar quantized matrix products that have recently been the focus of\nsubstantial research and hardware investment.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 05:08:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Blalock", "Davis", ""], ["Guttag", "John", ""]]}, {"id": "2106.11376", "submitter": "Manor Askenazi PhD", "authors": "Ayush Salik, Manor Askenazi, Edward Rietman", "title": "Content Addressable Parallel Processors on a FPGA", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short article, we report on the implementation of a Content\nAddressable Parallel Processor using a FPGA. While Content addressable memories\nhave been implemented in FPGAs, to our knowledge this is the first\nimplementation in FPGA of Caxton C. Foster's vision of parallel processing,\nparticularly the notions of parallel write as well as the combining of output\nvalues, which are usually missing in more typical CAM implementations, such as\nthe ones designed for network routing. The resulting CAPP is made accessible to\na host computer over a USB/UART interface, using a straightforward serial\nprotocol that is demonstrated using a Python-based driver.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:21:33 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 20:53:49 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Salik", "Ayush", ""], ["Askenazi", "Manor", ""], ["Rietman", "Edward", ""]]}, {"id": "2106.11461", "submitter": "Ashwani Kumar", "authors": "Ashwani Kumar", "title": "Assertion Based Functional Verification of March Algorithm Based MBIST\n  Controller", "comments": "108 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The thesis work presents assertion based functional verification of RTL\nrepresentation of a digital design. The MBIST controller is designed based on a\nmemory testing March algorithm. This March algorithm is a little modified March\nC algorithm which is modified by adding a paused element to test memory data\nretention faults. In assertion based functional verification, creation of\nverification plan, for MBIST controller RTL model and the implementation &\nsimulation of the verification plan using System-Verilog and Synopsys-VCS are\ndone. In ABV, verification plan includes the MBIST controller design and\nfunctional specification, functional coverage goals, code coverage goals, and\nassertions. Assertions are used to check the errors in RTL model of MBIST\ncontroller and to provide the functionality coverage. Functional coverage\nmetrics are used to track the level or quality of verification. Most of the\nfunctional metrics score approximately reached the planned goal of 100 % which\nis planned in the verification plan. The designed MBIST controller is verified\nagainst the intended features. ABV approach helped to make the verification and\ndesign process efficient and less time-consuming by finding the bugs,\nexercising the corner cases in the design, and using the directed test cases in\na small design. ABV helped to write directed and efficient test cases (25)\nwhich are approx 32 % less than the use of maximum possible random test cases\n(88) for designed MBIST controller with 100% assertion coverage and\napproximately equal total functional coverage, i.e., 97 % approx. In this way,\nABV helped to fasten the design and verification process with better quality\nand assurance of correct functionality of MBIST controller after the\nintegration in MBIST architecture.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:40:54 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kumar", "Ashwani", ""]]}, {"id": "2106.11840", "submitter": "Koen Bertels", "authors": "Koen Bertels, Aritra Sarkar, Imran Ashraf", "title": "Quantum Computing -- from NISQ to PISQ", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given the impeding timeline of developing good quality quantum processing\nunits, it is the moment to rethink the approach to advance quantum computing\nresearch. Rather than waiting for quantum hardware technologies to mature, we\nneed to start assessing in tandem the impact of the occurrence of quantum\ncomputing in various scientific fields. However, to this purpose, we need to\nuse a complementary but quite different approach than proposed by the NISQ\nvision, which is heavily focused on and burdened by the engineering challenges.\nThat is why we propose and advocate the PISQ approach: Perfect Intermediate\nScale Quantum computing based on the already known concept of perfect qubits.\nThis will allow researchers to focus much more on the development of new\napplications by defining the algorithms in terms of perfect qubits and evaluate\nthem on quantum computing simulators that are executed on supercomputers. It is\nnot the long-term solution but will currently allow universities to research on\nquantum logic and algorithms and companies can already start developing their\ninternal know-how on quantum solutions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 14:56:55 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Bertels", "Koen", ""], ["Sarkar", "Aritra", ""], ["Ashraf", "Imran", ""]]}, {"id": "2106.12029", "submitter": "Arman Kazemi", "authors": "Arman Kazemi, Mohammad Mehdi Sharifi, Zhuowen Zou, Michael Niemier, X.\n  Sharon Hu, Mohsen Imani", "title": "MIMHD: Accurate and Efficient Hyperdimensional Inference Using Multi-Bit\n  In-Memory Computing", "comments": "Accepted at ISLPED 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperdimensional Computing (HDC) is an emerging computational framework that\nmimics important brain functions by operating over high-dimensional vectors,\ncalled hypervectors (HVs). In-memory computing implementations of HDC are\ndesirable since they can significantly reduce data transfer overheads. All\nexisting in-memory HDC platforms consider binary HVs where each dimension is\nrepresented with a single bit. However, utilizing multi-bit HVs allows HDC to\nachieve acceptable accuracies in lower dimensions which in turn leads to higher\nenergy efficiencies. Thus, we propose a highly accurate and efficient multi-bit\nin-memory HDC inference platform called MIMHD. MIMHD supports multi-bit\noperations using ferroelectric field-effect transistor (FeFET) crossbar arrays\nfor multiply-and-add and FeFET multi-bit content-addressable memories for\nassociative search. We also introduce a novel hardware-aware retraining\nframework (HWART) that trains the HDC model to learn to work with MIMHD. For\nsix popular datasets and 4000 dimension HVs, MIMHD using 3-bit (2-bit)\nprecision HVs achieves (i) average accuracies of 92.6% (88.9%) which is 8.5%\n(4.8%) higher than binary implementations; (ii) 84.1x (78.6x) energy\nimprovement over a GPU, and (iii) 38.4x (34.3x) speedup over a GPU,\nrespectively. The 3-bit $\\times$ is 4.3x and 13x faster and more\nenergy-efficient than binary HDC accelerators while achieving similar\naccuracies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 19:34:39 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kazemi", "Arman", ""], ["Sharifi", "Mohammad Mehdi", ""], ["Zou", "Zhuowen", ""], ["Niemier", "Michael", ""], ["Hu", "X. Sharon", ""], ["Imani", "Mohsen", ""]]}, {"id": "2106.12125", "submitter": "Shubham Negi", "authors": "Shubham Negi, Indranil Chakraborty, Aayush Ankit, Kaushik Roy", "title": "NAX: Co-Designing Neural Network and Hardware Architecture for\n  Memristive Xbar based Computing Systems", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In-Memory Computing (IMC) hardware using Memristive Crossbar Arrays (MCAs)\nare gaining popularity to accelerate Deep Neural Networks (DNNs) since it\nalleviates the \"memory wall\" problem associated with von-Neumann architecture.\nThe hardware efficiency (energy, latency and area) as well as application\naccuracy (considering device and circuit non-idealities) of DNNs mapped to such\nhardware are co-dependent on network parameters, such as kernel size, depth\netc. and hardware architecture parameters such as crossbar size. However,\nco-optimization of both network and hardware parameters presents a challenging\nsearch space comprising of different kernel sizes mapped to varying crossbar\nsizes. To that effect, we propose NAX -- an efficient neural architecture\nsearch engine that co-designs neural network and IMC based hardware\narchitecture. NAX explores the aforementioned search space to determine kernel\nand corresponding crossbar sizes for each DNN layer to achieve optimal\ntradeoffs between hardware efficiency and application accuracy. Our results\nfrom NAX show that the networks have heterogeneous crossbar sizes across\ndifferent network layers, and achieves optimal hardware efficiency and accuracy\nconsidering the non-idealities in crossbars. On CIFAR-10 and Tiny ImageNet, our\nmodels achieve 0.8%, 0.2% higher accuracy, and 17%, 4% lower EDAP\n(energy-delay-area product) compared to a baseline ResNet-20 and ResNet-18\nmodels, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 02:27:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Negi", "Shubham", ""], ["Chakraborty", "Indranil", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "2106.12169", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Tong Geng, Ang Li, Yufei Ding", "title": "APNN-TC: Accelerating Arbitrary Precision Neural Networks on Ampere GPU\n  Tensor Cores", "comments": "Accepted by SC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, accelerating neural networks with quantization has been\nwidely studied. Unfortunately, prior efforts with diverse precisions (e.g.,\n1-bit weights and 2-bit activations) are usually restricted by limited\nprecision support on GPUs (e.g., int1 and int4). To break such restrictions, we\nintroduce the first Arbitrary Precision Neural Network framework (APNN-TC) to\nfully exploit quantization benefits on Ampere GPU Tensor Cores. Specifically,\nAPNN-TC first incorporates a novel emulation algorithm to support arbitrary\nshort bit-width computation with int1 compute primitives and XOR/AND Boolean\noperations. Second, APNN-TC integrates arbitrary precision layer designs to\nefficiently map our emulation algorithm to Tensor Cores with novel batching\nstrategies and specialized memory organization. Third, APNN-TC embodies a novel\narbitrary precision NN design to minimize memory access across layers and\nfurther improve performance. Extensive evaluations show that APNN-TC can\nachieve significant speedup over CUTLASS kernels and various NN models, such as\nResNet and VGG.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 05:39:34 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Geng", "Tong", ""], ["Li", "Ang", ""], ["Ding", "Yufei", ""]]}, {"id": "2106.12701", "submitter": "Md Ziaul Haque Zim", "authors": "Md Ziaul Haque Zim and Nimai Chandra Das", "title": "Object Detection and Ranging for Autonomous Navigation of Mobile Robots", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.24148.94086", "report-no": null, "categories": "cs.RO cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the recent decade, electronic technology gets advanced day by day the\nmethodologies too should update. For the purpose of ranging various methods\nsuch Radio Detection and Ranging (RADAR), Light Detection and Ranging (LIDAR)\nand Sonic Navigation and Ranging (SONAR) etc. are used. Later, by adapting the\nearlier technologies and further modifying the purposes of detection and\nranging in navigation, the technology of Sonic Detection and Ranging (SODAR) is\nused in modern robotics. The SODAR can be defined as a child of SONAR and also\na twin of Echo sounder. The echo-sounder is used only for ranging. But the\nSODAR use the low-frequency wave of 33 kHz to measure the underwater depth and\nalso to detect the objects below the water medium. So, this work comprises the\ndesigning of a system to evaluate the Object Detection and Ranging for\nAutonomous Navigation of Mobile Robots.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 00:17:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zim", "Md Ziaul Haque", ""], ["Das", "Nimai Chandra", ""]]}, {"id": "2106.12810", "submitter": "Petar Jokic", "authors": "Petar Jokic, Erfan Azarkhish, Andrea Bonetti, Marc Pons, Stephane\n  Emery, and Luca Benini", "title": "A Construction Kit for Efficient Low Power Neural Network Accelerator\n  Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing embedded neural network processing at the edge requires\nefficient hardware acceleration that couples high computational performance\nwith low power consumption. Driven by the rapid evolution of network\narchitectures and their algorithmic features, accelerator designs are\nconstantly updated and improved. To evaluate and compare hardware design\nchoices, designers can refer to a myriad of accelerator implementations in the\nliterature. Surveys provide an overview of these works but are often limited to\nsystem-level and benchmark-specific performance metrics, making it difficult to\nquantitatively compare the individual effect of each utilized optimization\ntechnique. This complicates the evaluation of optimizations for new accelerator\ndesigns, slowing-down the research progress. This work provides a survey of\nneural network accelerator optimization approaches that have been used in\nrecent works and reports their individual effects on edge processing\nperformance. It presents the list of optimizations and their quantitative\neffects as a construction kit, allowing to assess the design choices for each\nbuilding block separately. Reported optimizations range from up to 10'000x\nmemory savings to 33x energy reductions, providing chip designers an overview\nof design choices for implementing efficient low power neural network\naccelerators.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 07:53:56 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Jokic", "Petar", ""], ["Azarkhish", "Erfan", ""], ["Bonetti", "Andrea", ""], ["Pons", "Marc", ""], ["Emery", "Stephane", ""], ["Benini", "Luca", ""]]}, {"id": "2106.13263", "submitter": "Francesco Restuccia", "authors": "Francesco Restuccia, Andres Meza, and Ryan Kastner", "title": "AKER: A Design and Verification Framework for Safe andSecure SoC Access\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern systems on a chip (SoCs) utilize heterogeneous architectures where\nmultiple IP cores have concurrent access to on-chip shared resources. In\nsecurity-critical applications, IP cores have different privilege levels for\naccessing shared resources, which must be regulated by an access control\nsystem. AKER is a design and verification framework for SoC access control.\nAKER builds upon the Access Control Wrapper (ACW) -- a high performance and\neasy-to-integrate hardware module that dynamically manages access to shared\nresources. To build an SoC access control system, AKER distributes the ACWs\nthroughout the SoC, wrapping controller IP cores, and configuring the ACWs to\nperform local access control. To ensure the access control system is\nfunctioning correctly and securely, AKER provides a property-driven security\nverification using MITRE common weakness enumerations. AKER verifies the SoC\naccess control at the IP level to ensure the absence of bugs in the\nfunctionalities of the ACW module, at the firmware level to confirm the secure\noperation of the ACW when integrated with a hardware root-of-trust (HRoT), and\nat the system level to evaluate security threats due to the interactions among\nshared resources. The performance, resource usage, and security of access\ncontrol systems implemented through AKER is experimentally evaluated on a\nXilinx UltraScale+ programmable SoC, it is integrated with the OpenTitan\nhardware root-of-trust, and it is used to design an access control system for\nthe OpenPULP multicore architecture.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 18:09:28 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Restuccia", "Francesco", ""], ["Meza", "Andres", ""], ["Kastner", "Ryan", ""]]}, {"id": "2106.13852", "submitter": "Viktor Teren", "authors": "Viktor Teren, Jordi Cortadella and Tiziano Villa", "title": "Decomposition of transition systems into sets of synchronizing state\n  machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transition systems (TS) and Petri nets (PN) are important models of\ncomputation ubiquitous in formal methods for modeling systems. An important\nproblem is how to extract from a given TS a PN whose reachability graph is\nequivalent (with a suitable notion of equivalence) to the original TS.\n  This paper addresses the decomposition of transition systems into\nsynchronizing state machines (SMs), which are a class of Petri nets where each\ntransition has one incoming and one outgoing arc and all markings have exactly\none token. This is an important case of the general problem of extracting a PN\nfrom a TS. The decomposition is based on the theory of regions, and it is shown\nthat a property of regions called excitation-closure is a sufficient condition\nto guarantee the equivalence between the original TS and a decomposition into\nSMs.\n  An efficient algorithm is provided which solves the problem by reducing its\ncritical steps to the maximal independent set problem (to compute a minimal set\nof irredundant SMs) or to satisfiability (to merge the SMs). We report\nexperimental results that show a good trade-off between quality of results vs.\ncomputation time.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 19:15:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Teren", "Viktor", ""], ["Cortadella", "Jordi", ""], ["Villa", "Tiziano", ""]]}, {"id": "2106.13914", "submitter": "Jiawei Zhao", "authors": "Jiawei Zhao, Steve Dai, Rangharajan Venkatesan, Ming-Yu Liu, Brucek\n  Khailany, Bill Dally, Anima Anandkumar", "title": "Low-Precision Training in Logarithmic Number System using Multiplicative\n  Weight Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale deep neural networks (DNNs) currently requires a\nsignificant amount of energy, leading to serious environmental impacts. One\npromising approach to reduce the energy costs is representing DNNs with\nlow-precision numbers. While it is common to train DNNs with forward and\nbackward propagation in low-precision, training directly over low-precision\nweights, without keeping a copy of weights in high-precision, still remains to\nbe an unsolved problem. This is due to complex interactions between learning\nalgorithms and low-precision number systems. To address this, we jointly design\na low-precision training framework involving a logarithmic number system (LNS)\nand a multiplicative weight update training method, termed LNS-Madam. LNS has a\nhigh dynamic range even in a low-bitwidth setting, leading to high energy\nefficiency and making it relevant for on-board training in energy-constrained\nedge devices. We design LNS to have the flexibility of choosing different bases\nfor weights and gradients, as they usually require different quantization gaps\nand dynamic ranges during training. By drawing the connection between LNS and\nmultiplicative update, LNS-Madam ensures low quantization error during weight\nupdate, leading to a stable convergence even if the bitwidth is limited.\nCompared to using a fixed-point or floating-point number system and training\nwith popular learning algorithms such as SGD and Adam, our joint design with\nLNS and LNS-Madam optimizer achieves better accuracy while requiring smaller\nbitwidth. Notably, with only 5-bit for gradients, the proposed training\nframework achieves accuracy comparable to full-precision state-of-the-art\nmodels such as ResNet-50 and BERT. After conducting energy estimations by\nanalyzing the math datapath units during training, the results show that our\ndesign achieves over 60x energy reduction compared to FP32 on BERT models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 00:32:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Jiawei", ""], ["Dai", "Steve", ""], ["Venkatesan", "Rangharajan", ""], ["Liu", "Ming-Yu", ""], ["Khailany", "Brucek", ""], ["Dally", "Bill", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2106.13987", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Jean-Luc Gaudiot", "title": "Rise of the Autonomous Machines", "comments": "to appear in IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After decades of uninterrupted progress and growth, information technology\nhas so evolved that it can be said we are entering the age of autonomous\nmachines, but there exist many roadblocks in the way of making this a reality.\nIn this article, we make a preliminary attempt at recognizing and categorizing\nthe technical and non-technical challenges of autonomous machines; for each of\nthe ten areas we have identified, we review current status, roadblocks, and\npotential research directions. It is hoped that this will help the community\ndefine clear, effective, and more formal development goalposts for the future.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 09:46:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Shaoshan", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "2106.14089", "submitter": "Zhiqiang Que", "authors": "Zhiqiang Que, Erwei Wang, Umar Marikar, Eric Moreno, Jennifer\n  Ngadiuba, Hamza Javed, Bart{\\l}omiej Borzyszkowski, Thea Aarrestad, Vladimir\n  Loncar, Sioni Summers, Maurizio Pierini, Peter Y Cheung, Wayne Luk", "title": "Accelerating Recurrent Neural Networks for Gravitational Wave\n  Experiments", "comments": "Accepted at the 2021 32nd IEEE International Conference on\n  Application-specific Systems, Architectures and Processors (ASAP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents novel reconfigurable architectures for reducing the\nlatency of recurrent neural networks (RNNs) that are used for detecting\ngravitational waves. Gravitational interferometers such as the LIGO detectors\ncapture cosmic events such as black hole mergers which happen at unknown times\nand of varying durations, producing time-series data. We have developed a new\narchitecture capable of accelerating RNN inference for analyzing time-series\ndata from LIGO detectors. This architecture is based on optimizing the\ninitiation intervals (II) in a multi-layer LSTM (Long Short-Term Memory)\nnetwork, by identifying appropriate reuse factors for each layer. A\ncustomizable template for this architecture has been designed, which enables\nthe generation of low-latency FPGA designs with efficient resource utilization\nusing high-level synthesis tools. The proposed approach has been evaluated\nbased on two LSTM models, targeting a ZYNQ 7045 FPGA and a U250 FPGA.\nExperimental results show that with balanced II, the number of DSPs can be\nreduced up to 42% while achieving the same IIs. When compared to other\nFPGA-based LSTM designs, our design can achieve about 4.92 to 12.4 times lower\nlatency.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 20:44:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Que", "Zhiqiang", ""], ["Wang", "Erwei", ""], ["Marikar", "Umar", ""], ["Moreno", "Eric", ""], ["Ngadiuba", "Jennifer", ""], ["Javed", "Hamza", ""], ["Borzyszkowski", "Bart\u0142omiej", ""], ["Aarrestad", "Thea", ""], ["Loncar", "Vladimir", ""], ["Summers", "Sioni", ""], ["Pierini", "Maurizio", ""], ["Cheung", "Peter Y", ""], ["Luk", "Wayne", ""]]}, {"id": "2106.14138", "submitter": "Ashish Gondimalla", "authors": "Ashish Gondimalla, Jianqiao Liu, T.N. Vijaykumar, Mithuna Thottethodi", "title": "OCCAM: Optimal Data Reuse for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are emerging as powerful tools for image\nprocessing in important commercial applications. We focus on the important\nproblem of improving the latency of image recognition. CNNs' large data at each\nlayer's input, filters, and output poses a memory bandwidth problem. While\nprevious work captures only some of the enormous data reuse, full reuse implies\nthat the initial input image and filters are read once from off chip and the\nfinal output is written once off chip without spilling the intermediate layers'\ndata to off-chip. We propose Occam to capture full reuse via four\ncontributions. (1) We identify the necessary condition for full reuse. (2) We\nidentify the dependence closure as the sufficient condition to capture full\nreuse using the least on-chip memory. (3) Because the dependence closure is\noften too large to fit in on-chip memory, we propose a dynamic programming\nalgorithm that optimally partitions a given CNN to guarantee the least off-chip\ntraffic at the partition boundaries for a given on-chip capacity. Occam's\npartitions reside on different chips forming a pipeline so that a partition's\nfilters and dependence closure remain on-chip as different images pass through\n(i.e., each partition incurs off-chip traffic only for its inputs and outputs).\n(4) because the optimal partitions may result in an unbalanced pipeline, we\npropose staggered asynchronous pipelines (STAP) which replicates the bottleneck\nstages to improve throughput by staggering the mini-batches across the\nreplicas. Importantly, STAP achieves balanced pipelines without changing\nOccam's optimal partitioning. Our simulations show that Occam cuts off-chip\ntransfers by 21x and achieves 2.06x and 1.36x better performance, and 33\\% and\n24\\% better energy than the base case and Layer Fusion, respectively. On an\nFPGA implementation, Occam performs 5.1x better than the base case.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 03:58:34 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gondimalla", "Ashish", ""], ["Liu", "Jianqiao", ""], ["Vijaykumar", "T. N.", ""], ["Thottethodi", "Mithuna", ""]]}, {"id": "2106.14241", "submitter": "Myoungsoo Jung", "authors": "Jie Zhang, Miryeong Kwon, Donghyun Gouk, Sungjoon Koh, Nam Sung Kim,\n  Mahmut Taylan Kandemir, Myoungsoo Jung", "title": "Revamping Storage Class Memory With Hardware Automated\n  Memory-Over-Storage Solution", "comments": null, "journal-ref": null, "doi": "10.1109/ISCA52012.2021.00065", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large persistent memories such as NVDIMM have been perceived as a disruptive\nmemory technology, because they can maintain the state of a system even after a\npower failure and allow the system to recover quickly. However, overheads\nincurred by a heavy software-stack intervention seriously negate the benefits\nof such memories. First, to significantly reduce the software stack overheads,\nwe propose HAMS, a hardware automated Memory-over-Storage (MoS) solution.\nSpecifically, HAMS aggregates the capacity of NVDIMM and ultra-low latency\nflash archives (ULL-Flash) into a single large memory space, which can be used\nas a working or persistent memory expansion, in an OS-transparent manner. HAMS\nresides in the memory controller hub and manages its MoS address pool over\nconventional DDR and NVMe interfaces; it employs a simple hardware cache to\nserve all the memory requests from the host MMU after mapping the storage space\nof ULL-Flash to the memory space of NVDIMM. Second, to make HAMS more\nenergy-efficient and reliable, we propose an \"advanced HAMS\" which removes\nunnecessary data transfers between NVDIMM and ULL-Flash after optimizing the\ndatapath and hardware modules of HAMS. This approach unleashes the ULL-Flash\nand its NVMe controller from the storage box and directly connects the HAMS\ndatapath to NVDIMM over the conventional DDR4 interface. Our evaluations show\nthat HAMS and advanced HAMS can offer 97% and 119% higher system performance\nthan a software-based hybrid NVDIMM design, while consuming 41% and 45% lower\nsystem energy, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 14:17:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhang", "Jie", ""], ["Kwon", "Miryeong", ""], ["Gouk", "Donghyun", ""], ["Koh", "Sungjoon", ""], ["Kim", "Nam Sung", ""], ["Kandemir", "Mahmut Taylan", ""], ["Jung", "Myoungsoo", ""]]}, {"id": "2106.14332", "submitter": "Weile Wei", "authors": "Joseph Huber, Weile Wei, Giorgis Georgakoudis, Johannes Doerfert,\n  Oscar Hernandez", "title": "A Case Study of LLVM-Based Analysis for Optimizing SIMD Code Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cond-mat.mtrl-sci cs.AR cs.CL cs.SE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a methodology for using LLVM-based tools to tune the\nDCA++ (dynamical clusterapproximation) application that targets the new ARM\nA64FX processor. The goal is to describethe changes required for the new\narchitecture and generate efficient single instruction/multiple data(SIMD)\ninstructions that target the new Scalable Vector Extension instruction set.\nDuring manualtuning, the authors used the LLVM tools to improve code\nparallelization by using OpenMP SIMD,refactored the code and applied\ntransformation that enabled SIMD optimizations, and ensured thatthe correct\nlibraries were used to achieve optimal performance. By applying these code\nchanges, codespeed was increased by 1.98X and 78 GFlops were achieved on the\nA64FX processor. The authorsaim to automatize parts of the efforts in the\nOpenMP Advisor tool, which is built on top of existingand newly introduced LLVM\ntooling.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 22:38:16 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Huber", "Joseph", ""], ["Wei", "Weile", ""], ["Georgakoudis", "Giorgis", ""], ["Doerfert", "Johannes", ""], ["Hernandez", "Oscar", ""]]}, {"id": "2106.14771", "submitter": "Dominik Marek Loroch", "authors": "Jonas Ney, Dominik Loroch, Vladimir Rybalkin, Nico Weber, Jens\n  Kr\\\"uger, Norbert Wehn", "title": "HALF: Holistic Auto Machine Learning for FPGAs", "comments": "Submitted at FPL2021. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are capable of solving complex problems in\ndomains related to embedded systems, such as image and natural language\nprocessing. To efficiently implement DNNs on a specific FPGA platform for a\ngiven cost criterion, e.g. energy efficiency, an enormous amount of design\nparameters has to be considered from the topology down to the final hardware\nimplementation. Interdependencies between the different design layers have to\nbe taken into account and explored efficiently, making it hardly possible to\nfind optimized solutions manually. An automatic, holistic design approach can\nimprove the quality of DNN implementations on FPGA significantly. To this end,\nwe present a cross-layer design space exploration methodology. It comprises\noptimizations starting from a hardware-aware topology search for DNNs down to\nthe final optimized implementation for a given FPGA platform. The methodology\nis implemented in our Holistic Auto machine Learning for FPGAs (HALF)\nframework, which combines an evolutionary search algorithm, various\noptimization steps and a library of parametrizable hardware DNN modules. HALF\nautomates both the exploration process and the implementation of optimized\nsolutions on a target FPGA platform for various applications. We demonstrate\nthe performance of HALF on a medical use case for arrhythmia detection for\nthree different design goals, i.e. low-energy, low-power and high-throughput\nrespectively. Our FPGA implementation outperforms a TensorRT optimized model on\nan Nvidia Jetson platform in both throughput and energy consumption.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:45:47 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ney", "Jonas", ""], ["Loroch", "Dominik", ""], ["Rybalkin", "Vladimir", ""], ["Weber", "Nico", ""], ["Kr\u00fcger", "Jens", ""], ["Wehn", "Norbert", ""]]}, {"id": "2106.15021", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris and Ioannis Panopoulos and Ilias Leontiadis and\n  Iakovos S. Venieris", "title": "How to Reach Real-Time AI on Consumer Devices? Solutions for\n  Programmable and Custom Architectures", "comments": "Invited paper at the 32nd IEEE International Conference on\n  Application-Specific Systems, Architectures and Processors (ASAP), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented performance of deep neural networks (DNNs) has led to large\nstrides in various Artificial Intelligence (AI) inference tasks, such as object\nand speech recognition. Nevertheless, deploying such AI models across commodity\ndevices faces significant challenges: large computational cost, multiple\nperformance objectives, hardware heterogeneity and a common need for high\naccuracy, together pose critical problems to the deployment of DNNs across the\nvarious embedded and mobile devices in the wild. As such, we have yet to\nwitness the mainstream usage of state-of-the-art deep learning algorithms\nacross consumer devices. In this paper, we provide preliminary answers to this\npotentially game-changing question by presenting an array of design techniques\nfor efficient AI systems. We start by examining the major roadblocks when\ntargeting both programmable processors and custom accelerators. Then, we\npresent diverse methods for achieving real-time performance following a\ncross-stack approach. These span model-, system- and hardware-level techniques,\nand their combination. Our findings provide illustrative examples of AI systems\nthat do not overburden mobile hardware, while also indicating how they can\nimprove inference accuracy. Moreover, we showcase how custom ASIC- and\nFPGA-based accelerators can be an enabling factor for next-generation AI\napplications, such as multi-DNN systems. Collectively, these results highlight\nthe critical need for further exploration as to how the various cross-stack\nsolutions can be best combined in order to bring the latest advances in deep\nlearning close to users, in a robust and efficient manner.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 11:23:12 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Panopoulos", "Ioannis", ""], ["Leontiadis", "Ilias", ""], ["Venieris", "Iakovos S.", ""]]}, {"id": "2106.15284", "submitter": "Ahsan Javed Awan Dr", "authors": "Stefano Corda, Madhurya Kumaraswamy, Ahsan Javed Awan, Roel Jordans,\n  Akash Kumar, Henk Corporaal", "title": "NMPO: Near-Memory Computing Profiling and Offloading", "comments": "Euromicro Conference on Digital System Design 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications are now processing big-data sets, often bottlenecked\nby the data movement between the compute units and the main memory. Near-memory\ncomputing (NMC), a modern data-centric computational paradigm, can alleviate\nthese bottlenecks, thereby improving the performance of applications. The lack\nof NMC system availability makes simulators the primary evaluation tool for\nperformance estimation. However, simulators are usually time-consuming, and\nmethods that can reduce this overhead would accelerate the early-stage design\nprocess of NMC systems. This work proposes Near-Memory computing Profiling and\nOffloading (NMPO), a high-level framework capable of predicting NMC offloading\nsuitability employing an ensemble machine learning model. NMPO predicts NMC\nsuitability with an accuracy of 85.6% and, compared to prior works, can reduce\nthe prediction time by using hardware-dependent applications features by up to\n3 order of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 11:55:05 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Corda", "Stefano", ""], ["Kumaraswamy", "Madhurya", ""], ["Awan", "Ahsan Javed", ""], ["Jordans", "Roel", ""], ["Kumar", "Akash", ""], ["Corporaal", "Henk", ""]]}, {"id": "2106.15565", "submitter": "Daniele De Sensi PhD", "authors": "Daniele De Sensi, Salvatore Di Girolamo, Saleh Ashkboos, Shigang Li,\n  Torsten Hoefler", "title": "Flare: Flexible In-Network Allreduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The allreduce operation is one of the most commonly used communication\nroutines in distributed applications. To improve its bandwidth and to reduce\nnetwork traffic, this operation can be accelerated by offloading it to network\nswitches, that aggregate the data received from the hosts, and send them back\nthe aggregated result. However, existing solutions provide limited\ncustomization opportunities and might provide suboptimal performance when\ndealing with custom operators and data types, with sparse data, or when\nreproducibility of the aggregation is a concern. To deal with these problems,\nin this work we design a flexible programmable switch by using as a building\nblock PsPIN, a RISC-V architecture implementing the sPIN programming model. We\nthen design, model, and analyze different algorithms for executing the\naggregation on this architecture, showing performance improvements compared to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:58:32 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["De Sensi", "Daniele", ""], ["Di Girolamo", "Salvatore", ""], ["Ashkboos", "Saleh", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}]