[{"id": "1903.00191", "submitter": "Reza Faghih Mirzaee", "authors": "Ahmad Ahmadi, Reza Faghih Mirzaee", "title": "MIPS-Core Application Specific Instruction-Set Processor for IDEA\n  Cryptography - Comparison between Single-Cycle and Multi-Cycle Architectures", "comments": "13 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A single-cycle processor completes the execution of an instruction in only\none clock cycle. However, its clock period is usually rather long. On the\ncontrary, although clock frequency is higher in a multi-cycle processor, it\ntakes several clock cycles to finish an instruction. Therefore, their runtime\nefficiencies depend on which program is executed. This paper presents a new\nprocessor for International Data Encryption Algorithm (IDEA) cryptography. The\nnew design is an Application Specific Instruction-set Processor (ASIP) in which\nboth general-purpose and special instructions are supported. It is a\nsingle-cycle MIPS-core architecture, whose average Clocks Per Instruction (CPI)\nis 1. Furthermore, a comparison is provided in this paper to show the\ndifferences between the proposed single-cycle processor and another comparable\nmulti-cycle crypto processor. FPGA implementation results show that both\narchitectures have almost the same encoding/decoding throughput. However, the\nprevious processor consumes nearly twice as many resources as the new one does.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 08:07:24 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Ahmadi", "Ahmad", ""], ["Mirzaee", "Reza Faghih", ""]]}, {"id": "1903.01314", "submitter": "Michael Bechtel", "authors": "Michael G Bechtel and Heechul Yun", "title": "Denial-of-Service Attacks on Shared Cache in Multicore: Analysis and\n  Prevention", "comments": "To be published as a conference paper at RTAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the feasibility of denial-of-service (DoS)\nattacks on shared caches in multicore platforms. With carefully engineered\nattacker tasks, we are able to cause more than 300X execution time increases on\na victim task running on a dedicated core on a popular embedded multicore\nplatform, regardless of whether we partition its shared cache or not. Based on\ncareful experimentation on real and simulated multicore platforms, we identify\nan internal hardware structure of a non-blocking cache, namely the cache\nwriteback buffer, as a potential target of shared cache DoS attacks. We propose\nan OS-level solution to prevent such DoS attacks by extending a\nstate-of-the-art memory bandwidth regulation mechanism. We implement the\nproposed mechanism in Linux on a real multicore platform and show its\neffectiveness in protecting against cache DoS attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:48:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Bechtel", "Michael G", ""], ["Yun", "Heechul", ""]]}, {"id": "1903.01512", "submitter": "Mohammed Fouda Mr", "authors": "Mohammed E Fouda, Ahmed M. Eltawil, and Fadi Kurdahi", "title": "On Resistive Memories: One Step Row Readout Technique and Sensing\n  Circuitry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transistor-based memories are rapidly approaching their maximum density per\nunit area. Resistive crossbar arrays enable denser memory due to the small size\nof switching devices. However, due to the resistive nature of these memories,\nthey suffer from current sneak paths complicating the readout procedure. In\nthis paper, we propose a row readout technique with circuitry that can be used\nto read {selector-less} resistive crossbar based memories. High throughput\nreading and writing techniques are needed to overcome the memory-wall\nbottleneck problem and to enable near memory computing paradigm. The proposed\ntechnique can read the entire row of dense crossbar arrays in one cycle, unlike\npreviously published techniques. The requirements for the readout circuitry are\ndiscussed and satisfied in the proposed circuit. Additionally, an approximated\nexpression for the power consumed while reading the array is derived. A figure\nof merit is defined and used to compare the proposed approach with existing\nreading techniques. Finally, a quantitative analysis of the effect of biasing\nmismatch on the array size is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 19:55:01 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Fouda", "Mohammed E", ""], ["Eltawil", "Ahmed M.", ""], ["Kurdahi", "Fadi", ""]]}, {"id": "1903.01776", "submitter": "Myoungsoo Jung", "authors": "Jie Zhang, Myoungsoo Jung, Mahmut Taylan Kandemir", "title": "FUSE: Fusing STT-MRAM into GPUs to Alleviate Off-Chip Memory Access\n  Overheads", "comments": null, "journal-ref": "HPCA 2019", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose FUSE, a novel GPU cache system that integrates\nspin-transfer torque magnetic random-access memory (STT-MRAM) into the on-chip\nL1D cache. FUSE can minimize the number of outgoing memory accesses over the\ninterconnection network of GPU's multiprocessors, which in turn can\nconsiderably improve the level of massive computing parallelism in GPUs.\nSpecifically, FUSE predicts a read-level of GPU memory accesses by extracting\nGPU runtime information and places write-once-read-multiple (WORM) data blocks\ninto the STT-MRAM, while accommodating write-multiple data blocks over a small\nportion of SRAM in the L1D cache. To further reduce the off-chip memory\naccesses, FUSE also allows WORM data blocks to be allocated anywhere in the\nSTT-MRAM by approximating the associativity with the limited number of tag\ncomparators and I/O peripherals. Our evaluation results show that, in\ncomparison to a traditional GPU cache, our proposed heterogeneous cache reduces\nthe number of outgoing memory references by 32% across the interconnection\nnetwork, thereby improving the overall performance by 217% and reducing energy\ncost by 53%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 11:56:32 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 12:44:11 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jie", ""], ["Jung", "Myoungsoo", ""], ["Kandemir", "Mahmut Taylan", ""]]}, {"id": "1903.02596", "submitter": "Esha Choukse", "authors": "Esha Choukse, Michael Sullivan, Mike O'Connor, Mattan Erez, Jeff Pool,\n  David Nellans, Steve Keckler", "title": "Buddy Compression: Enabling Larger Memory for Deep Learning and HPC\n  Workloads on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs offer orders-of-magnitude higher memory bandwidth than traditional\nCPU-only systems. However, GPU device memory tends to be relatively small and\nthe memory capacity can not be increased by the user. This paper describes\nBuddy Compression, a scheme to increase both the effective GPU memory capacity\nand bandwidth while avoiding the downsides of conventional memory-expanding\nstrategies. Buddy Compression compresses GPU memory, splitting each compressed\nmemory entry between high-speed device memory and a slower-but-larger\ndisaggregated memory pool (or system memory). Highly-compressible memory\nentries can thus be accessed completely from device memory, while\nincompressible entries source their data using both on and off-device accesses.\nIncreasing the effective GPU memory capacity enables us to run\nlarger-memory-footprint HPC workloads and larger batch-sizes or models for DL\nworkloads than current memory capacities would allow. We show that our solution\nachieves an average compression ratio of 2.2x on HPC workloads and 1.5x on DL\nworkloads, with a slowdown of just 1~2%.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 19:55:19 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 23:28:48 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Choukse", "Esha", ""], ["Sullivan", "Michael", ""], ["O'Connor", "Mike", ""], ["Erez", "Mattan", ""], ["Pool", "Jeff", ""], ["Nellans", "David", ""], ["Keckler", "Steve", ""]]}, {"id": "1903.03597", "submitter": "Asif Ali Khan", "authors": "Asif Ali Khan, Fazal Hameed, Robin Blaesing, Stuart Parkin, Jeronimo\n  Castrillon", "title": "ShiftsReduce: Minimizing Shifts in Racetrack Memory 4.0", "comments": "27 pages, 15 figures", "journal-ref": "ACM Trans. Archit. Code Optim., Vol. 16, No. 4, Article 56, Dec.\n  2019", "doi": "10.1145/3372489", "report-no": null, "categories": "cs.ET cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Racetrack memories (RMs) have significantly evolved since their conception in\n2008, making them a serious contender in the field of emerging memory\ntechnologies. Despite key technological advancements, the access latency and\nenergy consumption of an RM-based system are still highly influenced by the\nnumber of shift operations. These operations are required to move bits to the\nright positions in the racetracks. This paper presents data placement\ntechniques for RMs that maximize the likelihood that consecutive references\naccess nearby memory locations at runtime thereby minimizing the number of\nshifts. We present an integer linear programming (ILP) formulation for optimal\ndata placement in RMs, and revisit existing offset assignment heuristics,\noriginally proposed for random-access memories. We introduce a novel heuristic\ntailored to a realistic RM and combine it with a genetic search to further\nimprove the solution. We show a reduction in the number of shifts of up to\n52.5%, outperforming the state of the art by up to 16.1%.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 18:30:17 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Khan", "Asif Ali", ""], ["Hameed", "Fazal", ""], ["Blaesing", "Robin", ""], ["Parkin", "Stuart", ""], ["Castrillon", "Jeronimo", ""]]}, {"id": "1903.03916", "submitter": "Xing Hu", "authors": "Xing Hu and Ling Liang and Lei Deng and Shuangchen Li and Xinfeng Xie\n  and Yu Ji and Yufei Ding and Chang Liu and Timothy Sherwood and Yuan Xie", "title": "Neural Network Model Extraction Attacks in Edge Devices by Hearing\n  Architectural Hints", "comments": null, "journal-ref": "ASPLOS-2020", "doi": "10.1145/3373376.3378460", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks continue their reach into nearly every aspect of software\noperations, the details of those networks become an increasingly sensitive\nsubject. Even those that deploy neural networks embedded in physical devices\nmay wish to keep the inner working of their designs hidden -- either to protect\ntheir intellectual property or as a form of protection from adversarial inputs.\nThe specific problem we address is how, through heavy system stack, given noisy\nand imperfect memory traces, one might reconstruct the neural network\narchitecture including the set of layers employed, their connectivity, and\ntheir respective dimension sizes. Considering both the intra-layer architecture\nfeatures and the inter-layer temporal association information introduced by the\nDNN design empirical experience, we draw upon ideas from speech recognition to\nsolve this problem. We show that off-chip memory address traces and PCIe events\nprovide ample information to reconstruct such neural network architectures\naccurately. We are the first to propose such accurate model extraction\ntechniques and demonstrate an end-to-end attack experimentally in the context\nof an off-the-shelf Nvidia GPU platform with full system stack. Results show\nthat the proposed techniques achieve a high reverse engineering accuracy and\nimprove the one's ability to conduct targeted adversarial attack with success\nrate from 14.6\\%$\\sim$25.5\\% (without network architecture knowledge) to 75.9\\%\n(with extracted network architecture).\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 03:58:18 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Hu", "Xing", ""], ["Liang", "Ling", ""], ["Deng", "Lei", ""], ["Li", "Shuangchen", ""], ["Xie", "Xinfeng", ""], ["Ji", "Yu", ""], ["Ding", "Yufei", ""], ["Liu", "Chang", ""], ["Sherwood", "Timothy", ""], ["Xie", "Yuan", ""]]}, {"id": "1903.03988", "submitter": "Saugata Ghose", "authors": "Onur Mutlu, Saugata Ghose, Juan G\\'omez-Luna, Rachata Ausavarungnirun", "title": "Processing Data Where It Makes Sense: Enabling In-Memory Computation", "comments": "a revised version will appear in Micpro", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's systems are overwhelmingly designed to move data to computation. This\ndesign choice goes directly against at least three key trends in systems that\ncause performance, scalability and energy bottlenecks: (1) data access from\nmemory is already a key bottleneck as applications become more data-intensive\nand memory bandwidth and energy do not scale well, (2) energy consumption is a\nkey constraint in especially mobile and server systems, (3) data movement is\nvery expensive in terms of bandwidth, energy and latency, much more so than\ncomputation.\n  At the same time, conventional memory technology is facing many scaling\nchallenges in terms of reliability, energy, and performance. As a result,\nmemory system architects are open to organizing memory in different ways and\nmaking it more intelligent, at the expense of higher cost. The emergence of\n3D-stacked memory plus logic as well as the adoption of error correcting codes\ninside DRAM chips, and the necessity for designing new solutions to serious\nreliability and security issues, such as the RowHammer phenomenon, are an\nevidence of this trend.\n  Recent research aims to practically enable computation close to data. We\ndiscuss at least two promising directions for processing-in-memory (PIM): (1)\nperforming massively-parallel bulk operations in memory by exploiting the\nanalog operational properties of DRAM, with low-cost changes, (2) exploiting\nthe logic layer in 3D-stacked memory technology to accelerate important\ndata-intensive applications. In both approaches, we describe and tackle\nrelevant cross-layer research, design, and adoption challenges in devices,\narchitecture, systems, and programming models. Our focus is on the development\nof in-memory processing designs that can be adopted in real computing platforms\nat low cost.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 13:26:15 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Mutlu", "Onur", ""], ["Ghose", "Saugata", ""], ["G\u00f3mez-Luna", "Juan", ""], ["Ausavarungnirun", "Rachata", ""]]}, {"id": "1903.04188", "submitter": "Vojtech Mrazek", "authors": "Zdenek Vasicek and Vojtech Mrazek and Lukas Sekanina", "title": "Automated Circuit Approximation Method Driven by Data Distribution", "comments": "Accepted for publication at Design, Automation and Test in Europe\n  (DATE 2019). Florence, Italy", "journal-ref": null, "doi": "10.23919/DATE.2019.8714977", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an application-tailored data-driven fully automated method for\nfunctional approximation of combinational circuits. We demonstrate how an\napplication-level error metric such as the classification accuracy can be\ntranslated to a component-level error metric needed for an efficient and fast\nsearch in the space of approximate low-level components that are used in the\napplication. This is possible by employing a weighted mean error distance\n(WMED) metric for steering the circuit approximation process which is conducted\nby means of genetic programming. WMED introduces a set of weights (calculated\nfrom the data distribution measured on a selected signal in a given\napplication) determining the importance of each input vector for the\napproximation process. The method is evaluated using synthetic benchmarks and\napplication-specific approximate MAC (multiply-and-accumulate) units that are\ndesigned to provide the best trade-offs between the classification accuracy and\npower consumption of two image classifiers based on neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 09:36:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Vasicek", "Zdenek", ""], ["Mrazek", "Vojtech", ""], ["Sekanina", "Lukas", ""]]}, {"id": "1903.04611", "submitter": "Ang Li", "authors": "Ang Li and Shuaiwen Leon Song and Jieyang Chen and Jiajia Li and Xu\n  Liu and Nathan Tallent and Kevin Barker", "title": "Evaluating Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and\n  GPUDirect", "comments": "15 pages. The paper is going to be submitted to TPDS", "journal-ref": null, "doi": "10.1109/TPDS.2019.2928289", "report-no": null, "categories": "cs.AR cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High performance multi-GPU computing becomes an inevitable trend due to the\never-increasing demand on computation capability in emerging domains such as\ndeep learning, big data and planet-scale simulations. However, the lack of deep\nunderstanding on how modern GPUs can be connected and the real impact of\nstate-of-the-art interconnect technology on multi-GPU application performance\nbecome a hurdle. In this paper, we fill the gap by conducting a thorough\nevaluation on five latest types of modern GPU interconnects: PCIe, NVLink-V1,\nNVLink-V2, NVLink-SLI and NVSwitch, from six high-end servers and HPC\nplatforms: NVIDIA P100-DGX-1, V100-DGX-1, DGX-2, OLCF's SummitDev and Summit\nsupercomputers, as well as an SLI-linked system with two NVIDIA Turing RTX-2080\nGPUs. Based on the empirical evaluation, we have observed four new types of GPU\ncommunication network NUMA effects: three are triggered by NVLink's topology,\nconnectivity and routing, while one is caused by PCIe chipset design issue.\nThese observations indicate that, for an application running in a multi-GPU\nnode, choosing the right GPU combination can impose considerable impact on GPU\ncommunication efficiency, as well as the application's overall performance. Our\nevaluation can be leveraged in building practical multi-GPU performance models,\nwhich are vital for GPU task allocation, scheduling and migration in a shared\nenvironment (e.g., AI cloud and HPC centers), as well as communication-oriented\nperformance tuning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 21:21:21 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Li", "Ang", ""], ["Song", "Shuaiwen Leon", ""], ["Chen", "Jieyang", ""], ["Li", "Jiajia", ""], ["Liu", "Xu", ""], ["Tallent", "Nathan", ""], ["Barker", "Kevin", ""]]}, {"id": "1903.06697", "submitter": "Maciej Besta", "authors": "Maciej Besta, Dimitri Stanojevic, Johannes De Fine Licht, Tal Ben-Nun,\n  Torsten Hoefler", "title": "Graph Processing on FPGAs: Taxonomy, Survey, Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processing has become an important part of various areas, such as\nmachine learning, computational sciences, medical applications, social network\nanalysis, and many others. Various graphs, for example web or social networks,\nmay contain up to trillions of edges. The sheer size of such datasets, combined\nwith the irregular nature of graph processing, poses unique challenges for the\nruntime and the consumed power. Field Programmable Gate Arrays (FPGAs) can be\nan energy-efficient solution to deliver specialized hardware for graph\nprocessing. This is reflected by the recent interest in developing various\ngraph algorithms and graph processing frameworks on FPGAs. To facilitate\nunderstanding of this emerging domain, we present the first survey and taxonomy\non graph computations on FPGAs. Our survey describes and categorizes existing\nschemes and explains key ideas. Finally, we discuss research and engineering\nchallenges to outline the future of graph computations on FPGAs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 04:46:07 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 22:29:18 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 16:57:25 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Besta", "Maciej", ""], ["Stanojevic", "Dimitri", ""], ["Licht", "Johannes De Fine", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1903.08680", "submitter": "Lieuwe Leene B", "authors": "Lieuwe B. Leene, Shiva Letchumanan, Timothy G. Constandinou", "title": "A 68 uW 31 kS/s Fully-Capacitive Noise-Shaping SAR ADC with 102 dB SNDR", "comments": "5 pages, 7 figures, conference, iscas, ieee, accepted submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a 17 bit analogue-to-digital converter that incorporates\nmismatch and quantisation noise-shaping techniques into an energy-saving 10 bit\nsuccessive approximation quantiser to increase the dynamic range by another 42\ndB. We propose a novel fully-capacitive topology which allows for high-speed\nasynchronous conversion together with a background calibration scheme to reduce\nthe oversampling requirement by 10x compared to prior-art. A 0.18 um CMOS\ntechnology is used to demonstrate preliminary simulation results together with\nanalytic measures that optimise parameter and topology selection. The proposed\nsystem is able to achieve a FoMS of 183 dB for a maximum signal bandwidth of\n15.6 kHz while dissipating 68 uW from a 1.8 V supply. A peak SNDR of 102 dB is\ndemonstrated for this rate with a 0.201 mm^2 area requirement.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 18:17:03 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Leene", "Lieuwe B.", ""], ["Letchumanan", "Shiva", ""], ["Constandinou", "Timothy G.", ""]]}, {"id": "1903.08781", "submitter": "Christian M. Fuchs", "authors": "Christian M. Fuchs, Nadia Murillo, Aske Plaat, Erik Van der Kouwe,\n  Daniel Harsono, and Todor Stefanov", "title": "Fault-Tolerant Nanosatellite Computing on a Budget", "comments": null, "journal-ref": "Conference on Radiation Effects on Components and Systems 2018\n  (RADECS)", "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro- and nanosatellites have become popular platforms for a variety of\ncommercial and scientific applications, but today are considered suitable\nmainly for short and low-priority space missions due to their low reliability.\nIn part, this can be attributed to their reliance upon cheap, low-feature size,\nCOTS components originally designed for embedded and mobile-market\napplications, for which traditional hardware-voting concepts are ineffective.\nSoftware-fault-tolerance concepts have been shown effective for such systems,\nbut have largely been ignored by the space industry due to low maturity, as\nmost have only been researched in theory. In practice, designers of payload\ninstruments and miniaturized satellites are usually forced to sacrifice\nreliability in favor deliver the level of performance necessary for\ncutting-edge science and innovative commercial applications. Thus, we developed\na software-fault-tolerance-approach based upon thread-level coarse-grain\nlockstep, which was validated using fault-injection. To offer strong long-term\nfault coverage, our architecture is implemented as tiled MPSoC on an FPGA,\nutilizing partial reconfiguration, as well as mixed criticality. This\narchitecture can satisfy the high performance requirements of current and\nfuture scientific and commercial space missions at very low cost, while\noffering the strong fault-coverage guarantees necessary for platform control\neven for missions with a long duration. This architecture was developed for a\n4-year ESA project. Together with two industrial partners, we are developing a\nprototype to then undergo radiation testing.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 00:00:34 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Fuchs", "Christian M.", ""], ["Murillo", "Nadia", ""], ["Plaat", "Aske", ""], ["Van der Kouwe", "Erik", ""], ["Harsono", "Daniel", ""], ["Stefanov", "Todor", ""]]}, {"id": "1903.09433", "submitter": "P Balasubramanian", "authors": "P. Balasubramanian, D.L. Maskell, N.E. Mastorakis", "title": "Speed and Energy Optimised Quasi-Delay-Insensitive Block Carry Lookahead\n  Adder", "comments": "PLOS ONE Preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new asynchronous quasi-delay-insensitive (QDI) block carry\nlookahead adder with redundancy carry (BCLARC) realized using delay-insensitive\ndual-rail data encoding and 4-phase return-to-zero (RTZ) and 4-phase\nreturn-to-one (RTO) handshaking. The proposed QDI BCLARC is found to be faster\nand energy-efficient than the existing asynchronous adders which are QDI and\nnon-QDI (i.e., relative-timed). Compared to existing asynchronous adders\ncorresponding to various architectures such as ripple carry adder (RCA),\nconventional carry lookahead adder (CCLA), carry select adder (CSLA), BCLARC,\nand hybrid BCLARC-RCA, the proposed BCLARC is found to be faster and more\nenergy-optimised. The cycle time (CT), which is the sum of forward and reverse\nlatencies, governs the speed; and the product of average power dissipation and\ncycle time viz. the power-cycle time product (PCTP) defines the low\npower/energy efficiency. For a 32-bit addition, the proposed QDI BCLARC\nachieves the following average reductions in design metrics over its\ncounterparts when considering RTZ and RTO handshaking: i) 20.5% and 19.6%\nreductions in CT and PCTP respectively compared to an optimum QDI early output\nRCA, ii) 16.5% and 15.8% reductions in CT and PCTP respectively compared to an\noptimum relative-timed RCA, iii) 32.9% and 35.9% reductions in CT and PCTP\nrespectively compared to an optimum uniform input-partitioned QDI early output\nCSLA, iv) 47.5% and 47.2% reductions in CT and PCTP respectively compared to an\noptimum QDI early output CCLA, v) 14.2% and 27.3% reductions in CT and PCTP\nrespectively compared to an optimum QDI early output BCLARC, and vi) 12.2% and\n11.6% reductions in CT and PCTP respectively compared to an optimum QDI early\noutput hybrid BCLARC-RCA. The adders were implemented using a 32/28nm CMOS\ntechnology.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 10:25:04 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Balasubramanian", "P.", ""], ["Maskell", "D. L.", ""], ["Mastorakis", "N. E.", ""]]}, {"id": "1903.10067", "submitter": "Reza Salkhordeh", "authors": "Reza Salkhordeh, Onur Mutlu and Hossein Asadi", "title": "An Analytical Model for Performance and Lifetime Estimation of Hybrid\n  DRAM-NVM Main Memories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NVMs have promising advantages (e.g., lower idle power, higher density) over\nthe existing predominant main memory technology, DRAM. Yet, NVMs also have\ndisadvantages (e.g., limited endurance). System architects are therefore\nexamining hybrid DRAM-NVM main memories to enable the advantages of NVMs while\navoiding the disadvantages as much as possible. Unfortunately, the hybrid\nmemory design space is very large and complex due to the existence of very\ndifferent types of NVMs and their rapidly-changing characteristics. Therefore,\noptimization of performance and lifetime of hybrid memory based computing\nplatforms and their experimental evaluation using traditional simulation\nmethods can be very time-consuming and sometimes even impractical. As such, it\nis necessary to develop a fast and flexible analytical model to estimate the\nperformance and lifetime of hybrid memories on various workloads. This paper\npresents an analytical model for hybrid memories based on Markov decision\nprocesses. The proposed model estimates the hit ratio and lifetime for various\nconfigurations of DRAM-NVM hybrid main memories. Our model also provides\naccurate estimation of the effect of data migration policies on the hybrid\nmemory hit ratio, one of the most important factors in hybrid memory\nperformance and lifetime. Such an analytical model can aid designers to tune\nhybrid memory configurations to improve performance and/or lifetime. We present\nseveral optimizations that make our model more efficient while maintaining its\naccuracy. Our experimental evaluations show that the proposed model (a)\naccurately predicts the hybrid memory hit ratio with an average error of 4.61%\non a commodity server, (b) accurately estimates the NVM lifetime with an\naverage error of 2.93%, and (c) is on average 4x faster than conventional\nstate-of-the-art simulation platforms for hybrid memories.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 22:17:41 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Salkhordeh", "Reza", ""], ["Mutlu", "Onur", ""], ["Asadi", "Hossein", ""]]}, {"id": "1903.11264", "submitter": "Sitansusekhar Roymohapatra", "authors": "Sitansusekhar Roymohapatra, Ganesh R. Gore, Akanksha Yadav, Mahesh B.\n  Patil, Krishnan S. Rengarajan, Subhramanian S. Iyer, and Maryam Shojaei\n  Baghini", "title": "A Novel Hierarchical Circuit LUT Model for SOI Technology for Rapid\n  Prototyping", "comments": "This article was uploaded by mistake without taking consent of\n  co-authors including my Ph.D. guide. The co-authors are not in favor of\n  publication of this article in arXiv. Hence I am withdrawing it. This is my\n  mistake and I apologize for this", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is withdrawn because the co-authors are not in favor of\npublication.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 06:58:36 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 17:21:00 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Roymohapatra", "Sitansusekhar", ""], ["Gore", "Ganesh R.", ""], ["Yadav", "Akanksha", ""], ["Patil", "Mahesh B.", ""], ["Rengarajan", "Krishnan S.", ""], ["Iyer", "Subhramanian S.", ""], ["Baghini", "Maryam Shojaei", ""]]}, {"id": "1903.12514", "submitter": "Behzad Salami", "authors": "Behzad Salami, Osman S. Unsal, Adrian Cristal Kestelman", "title": "Evaluating Built-in ECC of FPGA on-chip Memories for the Mitigation of\n  Undervolting Faults", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1109/EMPDP.2019.8671543", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voltage underscaling below the nominal level is an effective solution for\nimproving energy efficiency in digital circuits, e.g., Field Programmable Gate\nArrays (FPGAs). However, further undervolting below a safe voltage level and\nwithout accompanying frequency scaling leads to timing related faults,\npotentially undermining the energy savings. Through experimental voltage\nunderscaling studies on commercial FPGAs, we observed that the rate of these\nfaults exponentially increases for on-chip memories, or Block RAMs (BRAMs). To\nmitigate these faults, we evaluated the efficiency of the built-in\nError-Correction Code (ECC) and observed that more than 90% of the faults are\ncorrectable and further 7% are detectable (but not correctable). This\nefficiency is the result of the single-bit type of these faults, which are then\neffectively covered by the Single-Error Correction and Double-Error Detection\n(SECDED) design of the built-in ECC. Finally, motivated by the above\nexperimental observations, we evaluated an FPGA-based Neural Network (NN)\naccelerator under low-voltage operations, while built-in ECC is leveraged to\nmitigate undervolting faults and thus, prevent NN significant accuracy loss. In\nconsequence, we achieve 40% of the BRAM power saving through undervolting below\nthe minimum safe voltage level, with a negligible NN accuracy loss, thanks to\nthe substantial fault coverage by the built-in ECC.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 13:28:22 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Salami", "Behzad", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}]