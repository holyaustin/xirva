[{"id": "1707.01697", "submitter": "Tanaji Kamble", "authors": "Tanaji U. Kamble, B.G. Patil and Rakhee S. Bhojakar", "title": "Pipelined Parallel FFT Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an optimized efficient VLSI architecture of a pipeline Fast\nFourier transform (FFT) processor capable of producing the reverse output order\nsequence is presented. Paper presents Radix-2 multipath delay architecture for\nFFT calculation. The implementation of FFT in hardware is very critical because\nfor calculation of FFT number of butterfly operations i.e. number of\nmultipliers requires due to which hardware gets increased means indirectly cost\nof hardware is automatically gets increased. Also multiplier operations are\nslow that's why it limits the speed of operation of architecture. The optimized\nVLSI implementation of FFT algorithm is presented in this paper. Here\narchitecture is pipelined to optimize it and to increase the speed of\noperation. Also to increase the speed of operation 2 levels parallel processing\nis used.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 09:11:24 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Kamble", "Tanaji U.", ""], ["Patil", "B. G.", ""], ["Bhojakar", "Rakhee S.", ""]]}, {"id": "1707.02973", "submitter": "Li Du", "authors": "Li Du, Yuan Du, Yilei Li, Mau-Chung Frank Chang", "title": "A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator\n  for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) offers significant accuracy in image\ndetection. To implement image detection using CNN in the internet of things\n(IoT) devices, a streaming hardware accelerator is proposed. The proposed\naccelerator optimizes the energy efficiency by avoiding unnecessary data\nmovement. With unique filter decomposition technique, the accelerator can\nsupport arbitrary convolution window size. In addition, max pooling function\ncan be computed in parallel with convolution by using separate pooling unit,\nthus achieving throughput improvement. A prototype accelerator was implemented\nin TSMC 65nm technology with a core size of 5mm2. The accelerator can support\nmajor CNNs and achieve 152GOPS peak throughput and 434GOPS/W energy efficiency\nat 350mW, making it a promising hardware accelerator for intelligent IoT\ndevices.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 19:31:38 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Du", "Li", ""], ["Du", "Yuan", ""], ["Li", "Yilei", ""], ["Chang", "Mau-Chung Frank", ""]]}, {"id": "1707.04657", "submitter": "Aswin Ramachandran", "authors": "Aswin Ramachandran, Louis Johnson", "title": "Variable Instruction Fetch Rate to Reduce Control Dependent Penalties", "comments": "8 pages, 6 Figures, Disclosure: The work is a part of my PhD\n  dissertation at OSU and not in anyway related to Intel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to overcome the branch execution penalties of hard-to-predict\ninstruction branches, two new instruction fetch micro-architectural methods are\nproposed in this paper. In addition, to compare performance of the two proposed\nmethods, different instruction fetch policy schemes of existing multi-branch\npath architectures are evaluated. An improvement in Instructions Per Cycle\n(IPC) of 29.4% on average over single-thread execution with gshare branch\npredictor on SPEC 2000/2006 benchmark is shown. In this paper, wide pipeline\nmachines are simulated for evaluation purposes. The methods discussed in this\npaper can be extended to High Performance Scientific Computing needs, if the\ndemands of IPC improvement are far more critical than $cost.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 22:50:47 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Ramachandran", "Aswin", ""], ["Johnson", "Louis", ""]]}, {"id": "1707.05189", "submitter": "Ehsan Rohani", "authors": "Ehsan Rohani, Gwan Choi, Mi Lu", "title": "The Normalized Singular Value Decomposition of Non-Symmetric Matrices\n  Using Givens fast Rotations", "comments": "17 pages, 22 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the algorithm and the fixed point hardware to\ncalculate the normalized singular value decomposition of a non-symmetric\nmatrices using Givens fast (approximate) rotations. This algorithm only uses\nthe basic combinational logic modules such as adders, multiplexers, encoders,\nBarrel shifters (B-shifters), and comparators and does not use any lookup\ntable. This method in fact combines the iterative properties of singular value\ndecomposition method and CORDIC method in one single iteration. The introduced\narchitecture is a systolic architecture that uses two different types of\nprocessors, diagonal and non-diagonal processors. The diagonal processor\ncalculates, transmits and applies the horizontal and vertical rotations, while\nthe non-diagonal processor uses a fully combinational architecture to receive,\nand apply the rotations. The diagonal processor uses priority encoders, Barrel\nshifters, and comparators to calculate the rotation angles. Both processors use\na series of adders to apply the rotation angles. The design presented in this\nwork provides $2.83\\sim649$ times better energy per matrix performance compared\nto the state of the art designs. This performance achieved without the\nemployment of pipelining; a better performance advantage is expected to be\nachieved employing pipelining.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 18:49:25 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Rohani", "Ehsan", ""], ["Choi", "Gwan", ""], ["Lu", "Mi", ""]]}, {"id": "1707.05260", "submitter": "Farzad Farshchi", "authors": "Farzad Farshchi, Prathap Kumar Valsan, Renato Mancuso, Heechul Yun", "title": "Deterministic Memory Abstraction and Supporting Multicore System\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor time predictability of multicore processors has been a long-standing\nchallenge in the real-time systems community. In this paper, we make a case\nthat a fundamental problem that prevents efficient and predictable real-time\ncomputing on multicore is the lack of a proper memory abstraction to express\nmemory criticality, which cuts across various layers of the system: the\napplication, OS, and hardware. We, therefore, propose a new holistic resource\nmanagement approach driven by a new memory abstraction, which we call\nDeterministic Memory. The key characteristic of deterministic memory is that\nthe platform - the OS and hardware - guarantees small and tightly bounded\nworst-case memory access timing. In contrast, we call the conventional memory\nabstraction as best-effort memory in which only highly pessimistic worst-case\nbounds can be achieved. We propose to utilize both abstractions to achieve high\ntime predictability but without significantly sacrificing performance. We\npresent deterministic memory-aware OS and architecture designs, including\nOS-level page allocator, hardware-level cache, and DRAM controller designs. We\nimplement the proposed OS and architecture extensions on Linux and gem5\nsimulator. Our evaluation results, using a set of synthetic and real-world\nbenchmarks, demonstrate the feasibility and effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 16:12:15 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 20:40:13 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 22:36:45 GMT"}, {"version": "v4", "created": "Thu, 19 Apr 2018 00:06:48 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Farshchi", "Farzad", ""], ["Valsan", "Prathap Kumar", ""], ["Mancuso", "Renato", ""], ["Yun", "Heechul", ""]]}, {"id": "1707.05399", "submitter": "Ramyad Hadidi", "authors": "Ramyad Hadidi, Bahar Asgari, Jeffrey Young, Burhan Ahmad Mudassar,\n  Kartikay Garg, Tushar Krishna, and Hyesoon Kim", "title": "Performance Implications of NoCs on 3D-Stacked Memories: Insights from\n  the Hybrid Memory Cube", "comments": null, "journal-ref": "2018 IEEE International Symposium on Performance Analysis of\n  Systems and Software (ISPASS)", "doi": "10.1109/ISPASS.2018.00018", "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memories that exploit three-dimensional (3D)-stacking technology, which\nintegrate memory and logic dies in a single stack, are becoming popular. These\nmemories, such as Hybrid Memory Cube (HMC), utilize a network-on-chip (NoC)\ndesign for connecting their internal structural organizations. This novel usage\nof NoC, in addition to aiding processing-in-memory capabilities, enables\nnumerous benefits such as high bandwidth and memory-level parallelism. However,\nthe implications of NoCs on the characteristics of 3D-stacked memories in terms\nof memory access latency and bandwidth have not been fully explored. This paper\naddresses this knowledge gap by (i) characterizing an HMC prototype on the\nAC-510 accelerator board and revealing its access latency behaviors, and (ii)\nby investigating the implications of such behaviors on system and software\ndesigns.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 21:19:28 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 17:18:15 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hadidi", "Ramyad", ""], ["Asgari", "Bahar", ""], ["Young", "Jeffrey", ""], ["Mudassar", "Burhan Ahmad", ""], ["Garg", "Kartikay", ""], ["Krishna", "Tushar", ""], ["Kim", "Hyesoon", ""]]}, {"id": "1707.05975", "submitter": "Mohsen Hajabdollahi", "authors": "Zohreh HosseinKhani, Mohsen Hajabdollahi, Nader Karimi, S.M. Reza\n  Soroushmehr, Shahram Shirani, Shadrokh Samavi, Kayvan Najarian", "title": "Real-Time Impulse Noise Removal from MR Images for Radiosurgery\n  Applications", "comments": "12 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years image processing techniques are used as a tool to improve\ndetection and diagnostic capabilities in the medical applications. Medical\napplications have been so much affected by these techniques which some of them\nare embedded in medical instruments such as MRI, CT and other medical devices.\nAmong these techniques, medical image enhancement algorithms play an essential\nrole in removal of the noise which can be produced by medical instruments and\nduring image transfer. It has been proved that impulse noise is a major type of\nnoise, which is produced during medical operations, such as MRI, CT, and\nangiography, by their image capturing devices. An embeddable hardware module\nwhich is able to denoise medical images before and during surgical operations\ncould be very helpful. In this paper an accurate algorithm is proposed for\nreal-time removal of impulse noise in medical images. All image blocks are\ndivided into three categories of edge, smooth, and disordered areas. A\ndifferent reconstruction method is applied to each category of blocks for the\npurpose of noise removal. The proposed method is tested on MR images.\nSimulation results show acceptable denoising accuracy for various levels of\nnoise. Also an FPAG implementation of our denoising algorithm shows acceptable\nhardware resource utilization. Hence, the algorithm is suitable for embedding\nin medical hardware instruments such as radiosurgery devices.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 08:35:28 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["HosseinKhani", "Zohreh", ""], ["Hajabdollahi", "Mohsen", ""], ["Karimi", "Nader", ""], ["Soroushmehr", "S. M. Reza", ""], ["Shirani", "Shahram", ""], ["Samavi", "Shadrokh", ""], ["Najarian", "Kayvan", ""]]}, {"id": "1707.06909", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, R T Naayagi", "title": "Redundant Logic Insertion and Fault Tolerance Improvement in\n  Combinational Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method to identify and insert redundant logic\ninto a combinational circuit to improve its fault tolerance without having to\nreplicate the entire circuit as is the case with conventional redundancy\ntechniques. In this context, it is discussed how to estimate the fault masking\ncapability of a combinational circuit using the truth-cum-fault enumeration\ntable, and then it is shown how to identify the logic that can introduced to\nadd redundancy into the original circuit without affecting its native\nfunctionality and with the aim of improving its fault tolerance though this\nwould involve some trade-off in the design metrics. However, care should be\ntaken while introducing redundant logic since redundant logic insertion may\ngive rise to new internal nodes and faults on those may impact the fault\ntolerance of the resulting circuit. The combinational circuit that is\nconsidered and its redundant counterparts are all implemented in semi-custom\ndesign style using a 32/28nm CMOS digital cell library and their respective\ndesign metrics and fault tolerances are compared.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 14:17:07 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Balasubramanian", "P", ""], ["Naayagi", "R T", ""]]}, {"id": "1707.06913", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, R T Naayagi", "title": "Mathematical Estimation of Logical Masking Capability of\n  Majority/Minority Gates Used in Nanoelectronic Circuits", "comments": null, "journal-ref": "International Conference on Circuits, System and Simulation, pp.\n  18-23, London, UK (2017)", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nanoelectronic circuit synthesis, the majority gate and the inverter form\nthe basic combinational logic primitives. This paper deduces the mathematical\nformulae to estimate the logical masking capability of majority gates, which\nare used extensively in nanoelectronic digital circuit synthesis. The\nmathematical formulae derived to evaluate the logical masking capability of\nmajority gates holds well for minority gates, and a comparison with the logical\nmasking capability of conventional gates such as NOT, AND/NAND, OR/NOR, and\nXOR/XNOR is provided. It is inferred from this research work that the logical\nmasking capability of majority/minority gates is similar to that of XOR/XNOR\ngates, and with an increase of fan-in the logical masking capability of\nmajority/minority gates also increases.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 14:22:36 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Balasubramanian", "P", ""], ["Naayagi", "R T", ""]]}, {"id": "1707.08134", "submitter": "Daniel Ziener", "authors": "Bernhard Schmidt, Daniel Ziener, J\\\"urgen Teich, Christian Z\\\"ollner", "title": "Optimizing Scrubbing by Netlist Analysis for FPGA Configuration Bit\n  Classification and Floorplanning", "comments": null, "journal-ref": "Integration, the VLSI Journal 59C (2017) pp. 98-108", "doi": "10.1016/j.vlsi.2017.06.012", "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing scrubbing techniques for SEU mitigation on FPGAs do not guarantee an\nerror-free operation after SEU recovering if the affected configuration bits do\nbelong to feedback loops of the implemented circuits. In this paper, we a)\nprovide a netlist-based circuit analysis technique to distinguish so-called\ncritical configuration bits from essential bits in order to identify\nconfiguration bits which will need also state-restoring actions after a\nrecovered SEU and which not. Furthermore, b) an alternative classification\napproach using fault injection is developed in order to compare both\nclassification techniques. Moreover, c) we will propose a floorplanning\napproach for reducing the effective number of scrubbed frames and d),\nexperimental results will give evidence that our optimization methodology not\nonly allows to detect errors earlier but also to minimize the\nMean-Time-To-Repair (MTTR) of a circuit considerably. In particular, we show\nthat by using our approach, the MTTR for datapath-intensive circuits can be\nreduced by up to 48.5% in comparison to standard approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 18:03:20 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Schmidt", "Bernhard", ""], ["Ziener", "Daniel", ""], ["Teich", "J\u00fcrgen", ""], ["Z\u00f6llner", "Christian", ""]]}, {"id": "1707.09450", "submitter": "Yunsung Kim", "authors": "Yunsung Kim, Guilherme Cox, Martha A. Kim, Abhishek Bhattacharjee", "title": "Address Translation Design Tradeoffs for Heterogeneous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a broad, pathfinding design space exploration of memory\nmanagement units (MMUs) for heterogeneous systems. We consider a variety of\ndesigns, ranging from accelerators tightly coupled with CPUs (and using their\nMMUs) to fully independent accelerators that have their own MMUs. We find that\nregardless of the CPU-accelerator communication, accelerators should not rely\non the CPU MMU for any aspect of address translation, and instead must have its\nown, local, fully-fledged MMU. That MMU, however, can and should be as\napplication-specific as the accelerator itself, as our data indicates that even\na 100% hit rate in a small, standard L1 Translation Lookaside Buffer (TLB)\npresents a substantial accelerator performance overhead. Furthermore, we\nisolate the benefits of individual MMU components (e.g., TLBs versus page table\nwalkers) and discover that their relative performance, area, and energy are\nworkload dependent, with their interplay resulting in different area-optimal\nand energy-optimal configurations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 02:12:36 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kim", "Yunsung", ""], ["Cox", "Guilherme", ""], ["Kim", "Martha A.", ""], ["Bhattacharjee", "Abhishek", ""]]}, {"id": "1707.09952", "submitter": "Matthew Marinella", "authors": "Matthew J. Marinella, Sapan Agarwal, Alexander Hsia, Isaac Richter,\n  Robin Jacobs-Gedrim, John Niroula, Steven J. Plimpton, Engin Ipek, Conrad D.\n  James", "title": "Multiscale Co-Design Analysis of Energy, Latency, Area, and Accuracy of\n  a ReRAM Analog Neural Training Accelerator", "comments": null, "journal-ref": null, "doi": "10.1109/JETCAS.2018.2796379", "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are an increasingly attractive algorithm for natural language\nprocessing and pattern recognition. Deep networks with >50M parameters are made\npossible by modern GPU clusters operating at <50 pJ per op and more recently,\nproduction accelerators capable of <5pJ per operation at the board level.\nHowever, with the slowing of CMOS scaling, new paradigms will be required to\nachieve the next several orders of magnitude in performance per watt gains.\nUsing an analog resistive memory (ReRAM) crossbar to perform key matrix\noperations in an accelerator is an attractive option. This work presents a\ndetailed design using a state of the art 14/16 nm PDK for of an analog crossbar\ncircuit block designed to process three key kernels required in training and\ninference of neural networks. A detailed circuit and device-level analysis of\nenergy, latency, area, and accuracy are given and compared to relevant designs\nusing standard digital ReRAM and SRAM operations. It is shown that the analog\naccelerator has a 270x energy and 540x latency advantage over a similar block\nutilizing only digital ReRAM and takes only 11 fJ per multiply and accumulate\n(MAC). Compared to an SRAM based accelerator, the energy is 430X better and\nlatency is 34X better. Although training accuracy is degraded in the analog\naccelerator, several options to improve this are presented. The possible gains\nover a similar digital-only version of this accelerator block suggest that\ncontinued optimization of analog resistive memories is valuable. This detailed\ncircuit and device analysis of a training accelerator may serve as a foundation\nfor further architecture-level studies.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 16:54:32 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 00:18:00 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Marinella", "Matthew J.", ""], ["Agarwal", "Sapan", ""], ["Hsia", "Alexander", ""], ["Richter", "Isaac", ""], ["Jacobs-Gedrim", "Robin", ""], ["Niroula", "John", ""], ["Plimpton", "Steven J.", ""], ["Ipek", "Engin", ""], ["James", "Conrad D.", ""]]}]