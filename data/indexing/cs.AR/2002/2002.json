[{"id": "2002.00787", "submitter": "Ahmet Cagri Bagbaba", "authors": "Ahmet Cagri Bagbaba, Maksim Jenihhin, Jaan Raik, Christian Sauer", "title": "Efficient Fault Injection based on Dynamic HDL Slicing Technique", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.09982", "journal-ref": null, "doi": "10.1109/IOLTS.2019.8854419", "report-no": null, "categories": "cs.AR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a fault injection methodology where Hardware Description\nLanguage (HDL) code slicing is exploited to prune fault injection locations,\nthus enabling more efficient campaigns for safety mechanisms evaluation. In\nparticular, the dynamic HDL slicing technique provides for a highly collapsed\ncritical fault list and allows avoiding injections at redundant locations or\ntime-steps. Experimental results show that the proposed methodology integrated\ninto commercial tool flow doubles the simulation speed when comparing to the\nstate-of-the-art industrial-grade EDA tool flows.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:23:02 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bagbaba", "Ahmet Cagri", ""], ["Jenihhin", "Maksim", ""], ["Raik", "Jaan", ""], ["Sauer", "Christian", ""]]}, {"id": "2002.01073", "submitter": "Adarsh Patil", "authors": "Adarsh Patil", "title": "TLB and Pagewalk Performance in Multicore Architectures with Large\n  Die-Stacked DRAM Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the overheads of virtual-to-physical address\ntranslation in processor architectures, like x86-64, that implement paged\nvirtual memory using a radix tree which are walked in hardware. Translation\nLookaside Buffers are critical to system performance, particularly as\napplications demand larger memory footprints and with the adoption of\nvirtualization; however the cost of a TLB miss potentially results in multiple\nmemory accesses to retrieve the translation. Architectural support for\nsuperpages has been introduced to increase TLB hits but are limited by the\noperating systems ability to find contiguous memory. Numerous prior studies\nhave proposed TLB designs to lower miss rates and reduce page walk overhead;\nhowever, these studies have modeled the behavior analytically. Further, to\neschew the paging overhead for big-memory workloads and virtualization, Direct\nSegment maps part of a process linear virtual address space with segment\nregisters albeit requiring a few application and operating system\nmodifications. The recently evolved die-stacked DRAM technology promises a high\nbandwidth and large last-level cache, in the order of Gigabytes, closer to the\nprocessors. With such large caches the amount of data that can be accessed\nwithout causing a TLB fault - the reach of a TLB, is inadequate. TLBs are on\nthe critical path for data accesses and incurring an expensive page walk can\nhinder system performance, especially when the data being accessed is a cache\nhit in the LLC. Hence, we are interested in exploring novel address translation\nmechanisms, commensurate to the size and latency of stacked DRAM. By accurately\nsimulating the multitude of multi-level address translation structures using\nthe QEMU based MARSSx86 full system simulator, we perform detailed study of\nTLBs in conjunction with the large LLCs using multi-programmed and\nmulti-threaded workloads.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:53:20 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Patil", "Adarsh", ""]]}, {"id": "2002.01241", "submitter": "Vasileios Tsoutsouras", "authors": "Vasileios Tsoutsouras, Max Vigdorchik, Phillip Stanley-Marbell", "title": "Synthesizing Compact Hardware for Accelerating Inference from Physical\n  Signals in Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present dimensional circuit synthesis, a new method for generating digital\nlogic circuits that improve the efficiency of training and inference of machine\nlearning models from sensor data. The hardware accelerators that the method\ngenerates are compact enough (a few thousand gates) to allow integration within\nlow-cost miniaturized sensor integrated circuits, right next to the sensor\ntransducer. The method takes as input a description of physical properties of\nrelevant signals in the sensor transduction process and generates as output a\nVerilog register transfer level (RTL) description for a circuit that computes\nlow-level features that exploit the units of measure of the signals in the\nsystem.\n  We implement dimensional circuit synthesis as a backend to the compiler for\nNewton, a language for describing physical systems. We evaluate the backend\nimplementation and the hardware it generates, on descriptions of 7 physical\nsystems. The results show that our implementation of dimensional circuit\nsynthesis generates circuits of as little as 1662 logic cells / 1239 gates for\nthe systems we evaluate.\n  We synthesize the designs generated by the dimensional circuit synthesis\ncompilation backend for a low-power miniature FPGA targeted by its manufacturer\nat sensor interface applications. The circuits which the method generated use\nas little as 27% of the resources of the 2.15x2.5 mm FPGA. We measure the power\ndissipation of the FPGA's isolated core supply rail and show that, driven with\na pseudorandom signal input stream, the synthesized designs use as little as\n1.0 mW and no more than 5.8 mW. These results show the feasibility of\nintegrating physics-inspired machine learning methods within low-cost\nminiaturized sensor integrated circuits, right next to the sensor transducer.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:59:13 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Tsoutsouras", "Vasileios", ""], ["Vigdorchik", "Max", ""], ["Stanley-Marbell", "Phillip", ""]]}, {"id": "2002.02072", "submitter": "Steven Herbst", "authors": "Steven Herbst, Byong Chan Lim, Mark Horowitz", "title": "Fast FPGA emulation of analog dynamics in digitally-driven systems", "comments": "ICCAD '18: Proceedings of the International Conference on\n  Computer-Aided Design", "journal-ref": null, "doi": "10.1145/3240765.3240808", "report-no": null, "categories": "cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an architecture for FPGA emulation of mixed-signal\nsystems that achieves high accuracy at a high throughput. We represent the\nanalog output of a block as a superposition of step responses to changes in its\nanalog input, and the output is evaluated only when needed by the digital\nsubsystem. Our architecture is therefore intended for digitally-driven systems;\nthat is, those in which the inputs of analog dynamical blocks change only on\ndigital clock edges. We implemented a high-speed link transceiver design using\nthe proposed architecture on a Xilinx FPGA. This design demonstrates how our\napproach breaks the link between simulation rate and time resolution that is\ncharacteristic of prior approaches. The emulator is flexible, allowing for the\nreal-time adjustment of analog dynamics, clock jitter, and various design\nparameters. We demonstrate that our architecture achieves 1% accuracy while\nrunning 3 orders of magnitude faster than a comparable high-performance CPU\nsimulation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:24:15 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Herbst", "Steven", ""], ["Lim", "Byong Chan", ""], ["Horowitz", "Mark", ""]]}, {"id": "2002.02094", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang, Clay Patterson, Yongpan Liu, Chengmo Yang, Chun Jason\n  Xue, Jingtong Hu", "title": "Low Overhead Online Data Flow Tracking for Intermittently Powered\n  Non-volatile FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy harvesting is an attractive way to power future IoT devices since it\ncan eliminate the need for battery or power cables. However, harvested energy\nis intrinsically unstable. While FPGAs have been widely adopted in various\nembedded systems, it is hard to survive unstable power since all the memory\ncomponents in FPGA are based on volatile SRAMs. The emerging non-volatile\nmemory based FPGAs provide promising potentials to keep configuration data on\nthe chip during power outages. Few works have considered implementing efficient\nruntime intermediate data checkpoint on non-volatile FPGAs. To realize\naccumulative computation under intermittent power on FPGA, this paper proposes\na low-cost design framework, Data-Flow-Tracking FPGA (DFT-FPGA), which utilizes\nbinary counters to track intermediate data flow. Instead of keeping all on-chip\nintermediate data, DFT-FPGA only targets on necessary data that is labeled by\noff-line analysis and identified by an online tracking system. The evaluation\nshows that compared with state-of-the-art techniques, DFT-FPGA can realize\naccumulative computing with less off-line workload and significantly reduce\nonline roll-back time and resource utilization.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:33:15 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Zhang", "Xinyi", ""], ["Patterson", "Clay", ""], ["Liu", "Yongpan", ""], ["Yang", "Chengmo", ""], ["Xue", "Chun Jason", ""], ["Hu", "Jingtong", ""]]}, {"id": "2002.02394", "submitter": "Sahand Salamat", "authors": "Sahand Salamat and Tajana Rosing", "title": "FPGA Acceleration of Sequence Alignment: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AR q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genomics is changing our understanding of humans, evolution, diseases, and\nmedicines to name but a few. As sequencing technology is developed collecting\nDNA sequences takes less time thereby generating more genetic data every day.\nToday the rate of generating genetic data is outpacing the rate of computation\npower growth. Current sequencing machines can sequence 50 humans genome per\nday; however, aligning the read sequences against a reference genome and\nassembling the genome will take 1300 CPU hours. The main step in constructing\nthe genome is aligning the reads against a reference genome. Numerous\naccelerators have been proposed to accelerate the DNA alignment process.\nProviding massive parallelism, FPGA-based accelerators have shown great\nperformance in accelerating DNA alignment algorithms. Additionally, FPGA-based\naccelerators provide better energy efficiency than general-purpose processors.\nIn this survey, we introduce three main DNA alignment algorithms and FPGA-based\nimplementation of these algorithms to accelerate the DNA alignment. We also,\ncompare these three alignment categories and show how accelerators are\ndeveloping during the time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:33:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 02:45:14 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Salamat", "Sahand", ""], ["Rosing", "Tajana", ""]]}, {"id": "2002.03568", "submitter": "Hiromu Miyazaki", "authors": "Hiromu Miyazaki, Takuto Kanamori, Md Ashraful Islam, Kenji Kise", "title": "RVCoreP : An optimized RISC-V soft processor of five-stage pipelining", "comments": "9 pages, 9 figures, this paper is submitted to the Institute of\n  Electronics, Information and Communication Engineers (IEICE)", "journal-ref": null, "doi": "10.1587/transinf.2020PAP0015", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RISC-V is a RISC based open and loyalty free instruction set architecture\nwhich has been developed since 2010, and can be used for cost-effective soft\nprocessors on FPGAs. The basic 32-bit integer instruction set in RISC-V is\ndefined as RV32I, which is sufficient to support the operating system\nenvironment and suits for embedded systems. In this paper, we propose an\noptimized RV32I soft processor named RVCoreP adopting five-stage pipelining.\nThe processor applies three effective optimization methods to improve the\noperating frequency. These methods are instruction fetch unit optimization\nincluding pipelined branch prediction mechanism, ALU optimization, and data\nalignment and sign-extension optimization for data memory output. We implement\nRVCoreP in Verilog HDL and verify the behavior using Verilog simulation and an\nactual Xilinx Atrix-7 FPGA board. We evaluate IPC (instructions per cycle),\noperating frequency, hardware resource utilization, and processor performance.\nFrom the evaluation results, we show that RVCoreP achieves 30.0% performance\nimprovement compared with VexRiscv, which is a high-performance and open source\nRV32I processor selected from some related works.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:54:26 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Miyazaki", "Hiromu", ""], ["Kanamori", "Takuto", ""], ["Islam", "Md Ashraful", ""], ["Kise", "Kenji", ""]]}, {"id": "2002.03576", "submitter": "Hiromu Miyazaki", "authors": "Junya Miura, Hiromu Miyazaki, Kenji Kise", "title": "A portable and Linux capable RISC-V computer system in Verilog HDL", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RISC-V is an open and royalty free instruction set architecture which has\nbeen developed at the University of California, Berkeley. The processors using\nRISC-V can be designed and released freely. Because of this, various processor\ncores and system on chips (SoCs) have been released so far. However, there are\na few public RISC-V computer systems that are portable and can boot Linux\noperating systems. In this paper, we describe a portable and Linux capable\nRISC-V computer system targeting FPGAs in Verilog HDL. This system can be\nimplemented on an FPGA with fewer hardware resources, and can be implemented on\nlow cost FPGAs or customized by introducing an accelerator. This paper also\ndescribes the knowledge obtained through the development of this RISC-V\ncomputer system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:44:02 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 09:11:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Miura", "Junya", ""], ["Miyazaki", "Hiromu", ""], ["Kise", "Kenji", ""]]}, {"id": "2002.03944", "submitter": "Valentin Puente", "authors": "Lucia G. Menezo, Valentin Puente, and Jose A. Gregorio", "title": "Rainbow: A Composable Coherence Protocol for Multi-Chip Servers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of multi-chip modules (MCM) and/or multi-socket boards is the most\nsuitable approach to increase the computation density of servers while keep\nchip yield attained. This paper introduces a new coherence protocol suitable,\nin terms of complexity and scalability, for this class of systems. The proposal\nuses two complementary ideas: (1) A mechanism that dissociates complexity from\nperformance by means of colored-token counting, (2) A construct that optimizes\nperformance and cost by means of two functionally symmetrical modules working\nin the last level cache of each chip (D|F-LLC) and each memory controller\n(D|F-MEM). Each of these structures is divided into two parts: (2.1) The first\none consists of a small loosely inclusive sparse directory where only the most\nactively shared data are tracked in the chip (D-LLC) from each memory\ncontroller (D-MEM) and, (2.2) The second is a d-left Counting Bloom Filter\nwhich stores approximate information about the blocks allocated, either inside\nthe chip (F-LLC) or in the home memory controller (F-MEM). The coordinated work\nof both structures minimizes the coherence-related effects on the average\nmemory latency perceived by the processor. Our proposal is able to improve on\nthe performance of a HyperTransport-like coherence protocol by from 25%-to-60%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:54:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Menezo", "Lucia G.", ""], ["Puente", "Valentin", ""], ["Gregorio", "Jose A.", ""]]}, {"id": "2002.05291", "submitter": "Mohammad Saeed Abrishami", "authors": "Mohammad Saeed Abrishami, Massoud Pedram, Shahin Nazarian", "title": "CSM-NN: Current Source Model Based Logic Circuit Simulation -- A Neural\n  Network Approach", "comments": "37th IEEE International Conference on Computer Design (ICCD), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The miniaturization of transistors down to 5nm and beyond, plus the\nincreasing complexity of integrated circuits, significantly aggravate short\nchannel effects, and demand analysis and optimization of more design corners\nand modes. Simulators need to model output variables related to circuit timing,\npower, noise, etc., which exhibit nonlinear behavior. The existing simulation\nand sign-off tools, based on a combination of closed-form expressions and\nlookup tables are either inaccurate or slow, when dealing with circuits with\nmore than billions of transistors. In this work, we present CSM-NN, a scalable\nsimulation framework with optimized neural network structures and processing\nalgorithms. CSM-NN is aimed at optimizing the simulation time by accounting for\nthe latency of the required memory query and computation, given the underlying\nCPU and GPU parallel processing capabilities. Experimental results show that\nCSM-NN reduces the simulation time by up to $6\\times$ compared to a\nstate-of-the-art current source model based simulator running on a CPU. This\nspeedup improves by up to $15\\times$ when running on a GPU. CSM-NN also\nprovides high accuracy levels, with less than $2\\%$ error, compared to HSPICE.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:29:44 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""], ["Nazarian", "Shahin", ""]]}, {"id": "2002.05455", "submitter": "Thomas Lange", "authors": "Thomas Lange, Maximilien Glorieux, Dan Alexandrescu, Luca Sterpone", "title": "Functional Failure Rate Due to Single-Event Transients in Clock\n  Distribution Networks", "comments": null, "journal-ref": null, "doi": "10.1109/DTIS.2019.8735052", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With technology scaling, lower supply voltages, and higher operating\nfrequencies clock distribution networks become more and more vulnerable to\ntransients faults. These faults can cause circuit-wide effects and thus,\nsignificantly contribute to the functional failure rate of the circuit. This\npaper proposes a methodology to analyse how the functional behaviour is\naffected by Single-Event Transients in the clock distribution network. The\napproach is based on logic-level simulation and thus, only uses the\nregister-transfer level description of a design. Therefore, a fault model is\nproposed which implements the main effects due to radiation-induced transients\nin the clock network. This fault model enables the computation of the\nfunctional failure rate caused by Single-Event Transients for each individual\nclock buffer, as well as the complete network. Further, it allows the\nidentification of the most vulnerable flip-flops related to Single-Event\nTransients in the clock network.\n  The proposed methodology is applied in a practical example and a fault\ninjection campaign is performed. In order to evaluate the impact of\nSingle-Event Transients in clock distribution networks, the obtained functional\nfailure rate is compared to the error rate caused by Single-Event Upsets in the\nsequential logic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:38:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Lange", "Thomas", ""], ["Glorieux", "Maximilien", ""], ["Alexandrescu", "Dan", ""], ["Sterpone", "Luca", ""]]}, {"id": "2002.06998", "submitter": "Niansong Zhang", "authors": "Niansong Zhang, Xiang Chen, Nachiket Kapre", "title": "RapidLayout: Fast Hard Block Placement of FPGA-optimized Systolic Arrays\n  using Evolutionary Algorithms", "comments": "8 pages, 10 figures. Conference: FPL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Evolutionary algorithms can outperform conventional placement algorithms such\nas simulated annealing, analytical placement as well as manual placement on\nmetrics such as runtime, wirelength, pipelining cost, and clock frequency when\nmapping FPGA hard block intensive designs such as systolic arrays on Xilinx\nUltraScale+ FPGAs. For certain hard-block intensive, systolic array accelerator\ndesigns, the commercial-grade Xilinx Vivado CAD tool is unable to provide a\nlegal routing solution without tedious manual placement constraints. Instead,\nwe formulate an automatic FPGA placement algorithm for these hard blocks as a\nmulti-objective optimization problem that targets wirelength squared and\nmaximum bounding box size metrics. We build an end-to-end placement and routing\nflow called RapidLayout using the Xilinx RapidWright framework. RapidLayout\nruns 5-6$\\times$ faster than Vivado with manual constraints and eliminates the\nweeks-long effort to generate placement constraints manually for the hard\nblocks. We also perform automated post-placement pipelining of the long wires\ninside each convolution block to target 650MHz URAM-limited operation.\nRapidLayout outperforms (1) the simulated annealer in VPR by 33% in runtime,\n1.9-2.4$\\times$ in wirelength, and 3-4$\\times$ in bounding box size, while also\n(2) beating the analytical placer UTPlaceF by 9.3$\\times$ in runtime,\n1.8-2.2$\\times$ in wirelength, and 2-2.7$\\times$ in bounding box size. We\nemploy transfer learning from a base FPGA device to speed-up placement\noptimization for similar FPGA devices in the UltraScale+ family by\n11-14$\\times$ than learning the placements from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:16:22 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 15:05:54 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 07:14:48 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zhang", "Niansong", ""], ["Chen", "Xiang", ""], ["Kapre", "Nachiket", ""]]}, {"id": "2002.07271", "submitter": "Anton Rakitsky", "authors": "Anton Rakitskiy and Boris Ryabko", "title": "Information Theory as a Means of Determining the Main Factors Affecting\n  the Processors Architecture", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we are investigating the computers development process in the\npast decades in order to identify the factors that influence it the most. We\ndescribe such factors and use them to predict the direction of further\ndevelopment. To solve these problems, we use the concept of the Computer\nCapacity, which allows us to estimate the performance of computers\ntheoretically, relying only on the description of its architecture.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:53:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Rakitskiy", "Anton", ""], ["Ryabko", "Boris", ""]]}, {"id": "2002.07507", "submitter": "Jaydeb Bhaumik", "authors": "Sayan Tripathi, Jhilam Jana and Jaydeb Bhaumik", "title": "Design of SEC-DED and SEC-DED-DAEC Codes of different lengths", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability is an important requirement for both communication and storage\nsystems. Due to continuous scale down of technology multiple adjacent bits\nerror probability increases. The data may be corrupted due soft errors. Error\ncorrection codes are used to detect and correct the errors. In this paper,\ndesign of single error correction-double error detection (SEC-DED) and single\nerror correction-double error detection-double adjacent error correction\n(SEC-DED-DAEC) codes of different data lengths have been proposed. Proposed\nSEC-DED and SEC-DED-DAEC codes require lower delay and power compared to\nexisting coding schemes. Area complexity in terms of logic gates of proposed\nand existing codes have been presented. ASIC-based synthesis results show a\nnotable reduction compared to existing SEC-DED codes. All the codec\narchitectures are synthesized on ASIC platform. Performances of different\nSEC-DED-DAEC codes are tabulated in terms of area, power and delay.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:55:19 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Tripathi", "Sayan", ""], ["Jana", "Jhilam", ""], ["Bhaumik", "Jaydeb", ""]]}, {"id": "2002.07711", "submitter": "Mehdi Ahmadi", "authors": "Mehdi Ahmadi, Shervin Vakili, J.M. Pierre Langlois", "title": "An Energy-Efficient Accelerator Architecture with Serial Accumulation\n  Dataflow for Deep CNNs", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have shown outstanding accuracy for many\nvision tasks during recent years. When deploying CNNs on portable devices and\nembedded systems, however, the large number of parameters and computations\nresult in long processing time and low battery life. An important factor in\ndesigning CNN hardware accelerators is to efficiently map the convolution\ncomputation onto hardware resources. In addition, to save battery life and\nreduce energy consumption, it is essential to reduce the number of DRAM\naccesses since DRAM consumes orders of magnitude more energy compared to other\noperations in hardware. In this paper, we propose an energy-efficient\narchitecture which maximally utilizes its computational units for convolution\noperations while requiring a low number of DRAM accesses. The implementation\nresults show that the proposed architecture performs one image recognition task\nusing the VGGNet model with a latency of 393 ms and only 251.5 MB of DRAM\naccesses.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:40:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ahmadi", "Mehdi", ""], ["Vakili", "Shervin", ""], ["Langlois", "J. M. Pierre", ""]]}, {"id": "2002.08947", "submitter": "Hanrui Wang", "authors": "Zhekai Zhang, Hanrui Wang, Song Han, William J. Dally", "title": "SpArch: Efficient Architecture for Sparse Matrix Multiplication", "comments": "The first two authors have equal contributions; 15 pages, 18 figures;\n  Published as a conference paper in HPCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Sparse Matrix-Matrix Multiplication (SpGEMM) is a ubiquitous task\nin various engineering and scientific applications. However, inner product\nbased SpGENN introduces redundant input fetches for mismatched nonzero\noperands, while outer product based approach suffers from poor output locality\ndue to numerous partial product matrices. Inefficiency in the reuse of either\ninputs or outputs data leads to extensive and expensive DRAM access.\n  To address this problem, this paper proposes an efficient sparse matrix\nmultiplication accelerator architecture, SpArch, which jointly optimizes the\ndata locality for both input and output matrices. We first design a highly\nparallelized streaming-based merger to pipeline the multiply and merge stage of\npartial matrices so that partial matrices are merged on chip immediately after\nproduced. We then propose a condensed matrix representation that reduces the\nnumber of partial matrices by three orders of magnitude and thus reduces DRAM\naccess by 5.4x. We further develop a Huffman tree scheduler to improve the\nscalability of the merger for larger sparse matrices, which reduces the DRAM\naccess by another 1.8x. We also resolve the increased input matrix read induced\nby the new representation using a row prefetcher with near-optimal buffer\nreplacement policy, further reducing the DRAM access by 1.5x. Evaluated on 20\nbenchmarks, SpArch reduces the total DRAM access by 2.8x over previous\nstate-of-the-art. On average, SpArch achieves 4x, 19x, 18x, 17x, 1285x speedup\nand 6x, 164x, 435x, 307x, 62x energy savings over OuterSPACE, MKL, cuSPARSE,\nCUSP, and ARM Armadillo, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:54:40 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zhang", "Zhekai", ""], ["Wang", "Hanrui", ""], ["Han", "Song", ""], ["Dally", "William J.", ""]]}, {"id": "2002.09783", "submitter": "Bochen Tan", "authors": "Bochen Tan, Jason Cong", "title": "Optimality Study of Existing Quantum Computing Layout Synthesis Tools", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TC.2020.3009140", "report-no": null, "categories": "quant-ph cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layout synthesis, an important step in quantum computing, processes quantum\ncircuits to satisfy device layout constraints. In this paper, we construct\nQUEKO benchmarks for this problem, which have known optimal depths and gate\ncounts. We use QUEKO to evaluate the optimality of current layout synthesis\ntools, including Cirq from Google, Qiskit from IBM,\n$\\mathsf{t}|\\mathsf{ket}\\rangle$ from Cambridge Quantum Computing, and recent\nacademic work. To our surprise, despite over a decade of research and\ndevelopment by academia and industry on compilation and synthesis for quantum\ncircuits, we are still able to demonstrate large optimality gaps: 1.5-12x on\naverage on a smaller device and 5-45x on average on a larger device. This\nsuggests substantial room for improvement of the efficiency of quantum computer\nby better layout synthesis tools. Finally, we also prove the NP-completeness of\nthe layout synthesis problem for quantum computing. We have made the QUEKO\nbenchmarks open-source.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:47:20 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:59:16 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 02:39:16 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 03:30:58 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Tan", "Bochen", ""], ["Cong", "Jason", ""]]}, {"id": "2002.10143", "submitter": "Florian Zaruba", "authors": "Florian Zaruba, Fabian Schuiki, Torsten Hoefler, and Luca Benini", "title": "Snitch: A tiny Pseudo Dual-Issue Processor for Area and Energy Efficient\n  Execution of Floating-Point Intensive Workloads", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2020.3027900", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-parallel applications, such as data analytics, machine learning, and\nscientific computing, are placing an ever-growing demand on floating-point\noperations per second on emerging systems. With increasing integration density,\nthe quest for energy efficiency becomes the number one design concern. While\ndedicated accelerators provide high energy efficiency, they are\nover-specialized and hard to adjust to algorithmic changes. We propose an\narchitectural concept that tackles the issues of achieving extreme energy\nefficiency while still maintaining high flexibility as a general-purpose\ncompute engine. The key idea is to pair a tiny 10kGE control core, called\nSnitch, with a double-precision FPU to adjust the compute to control ratio.\nWhile traditionally minimizing non-FPU area and achieving high floating-point\nutilization has been a trade-off, with Snitch, we achieve them both, by\nenhancing the ISA with two minimally intrusive extensions: stream semantic\nregisters (SSR) and a floating-point repetition instruction (FREP). SSRs allow\nthe core to implicitly encode load/store instructions as register reads/writes,\neliding many explicit memory instructions. The FREP extension decouples the\nfloating-point and integer pipeline by sequencing instructions from a\nmicro-loop buffer. These ISA extensions significantly reduce the pressure on\nthe core and free it up for other tasks, making Snitch and FPU effectively\ndual-issue at a minimal incremental cost of 3.2%. The two low overhead ISA\nextensions make Snitch more flexible than a contemporary vector processor lane,\nachieving a $2\\times$ energy-efficiency improvement. We have evaluated the\nproposed core and ISA extensions on an octa-core cluster in 22nm technology. We\nachieve more than $5\\times$ multi-core speed-up and a $3.5\\times$ gain in\nenergy efficiency on several parallel microkernels.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:19:23 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:31:43 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zaruba", "Florian", ""], ["Schuiki", "Fabian", ""], ["Hoefler", "Torsten", ""], ["Benini", "Luca", ""]]}, {"id": "2002.11163", "submitter": "Minsuk Koo", "authors": "Minsuk Koo, Gopalakrishnan Srinivasan, Yong Shim, and Kaushik Roy", "title": "sBSNN: Stochastic-Bits Enabled Binary Spiking Neural Network with\n  On-Chip Learning for Energy Efficient Neuromorphic Computing at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose stochastic Binary Spiking Neural Network (sBSNN)\ncomposed of stochastic spiking neurons and binary synapses (stochastic only\nduring training) that computes probabilistically with one-bit precision for\npower-efficient and memory-compressed neuromorphic computing. We present an\nenergy-efficient implementation of the proposed sBSNN using 'stochastic bit' as\nthe core computational primitive to realize the stochastic neurons and\nsynapses, which are fabricated in 90nm CMOS process, to achieve efficient\non-chip training and inference for image recognition tasks. The measured data\nshows that the 'stochastic bit' can be programmed to mimic spiking neurons, and\nstochastic Spike Timing Dependent Plasticity (or sSTDP) rule for training the\nbinary synaptic weights without expensive random number generators. Our results\nindicate that the proposed sBSNN realization offers possibility of up to 32x\nneuronal and synaptic memory compression compared to full precision (32-bit)\nSNN and energy efficiency of 89.49 TOPS/Watt for two-layer fully-connected SNN.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:11:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Koo", "Minsuk", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Shim", "Yong", ""], ["Roy", "Kaushik", ""]]}, {"id": "2002.11289", "submitter": "Febin Sunny", "authors": "Febin Sunny, Asif Mirza, Ishan Thakkar, Sudeep Pasricha and Nikdast\n  Mahdi", "title": "LORAX: Loss-Aware Approximations for Energy-Efficient Silicon Photonic\n  Networks-on-Chip", "comments": "Submitted and accepted at GLSVLSI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate computing paradigm advocates for relaxing accuracy goals in\napplications to improve energy-efficiency and performance. Recently, this\nparadigm has been explored to improve the energy efficiency of silicon photonic\nnetworks-on-chip (PNoCs). In this paper, we propose a novel framework (LORAX)\nto enable more aggressive approximation during communication over silicon\nphotonic links in PNoCs. Given that silicon photonic interconnects have\nsignificant power dissipation due to the laser sources that generate the\nwavelengths for photonic communication, our framework attempts to reduce laser\npower overheads while intelligently approximating communication such that\napplication output quality is not distorted beyond an acceptable limit. To the\nbest of our knowledge, this is the first work that considers loss-aware laser\npower management and multilevel signaling to enable effective data\napproximation and energy-efficiency in PNoCs. Simulation results show that our\nframework can achieve up to 31.4% lower laser power consumption and up to 12.2%\nbetter energy efficiency than the best known prior work on approximate\ncommunication with silicon photonic interconnects, for the same application\noutput quality\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:54:26 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sunny", "Febin", ""], ["Mirza", "Asif", ""], ["Thakkar", "Ishan", ""], ["Pasricha", "Sudeep", ""], ["Mahdi", "Nikdast", ""]]}]