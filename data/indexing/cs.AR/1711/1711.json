[{"id": "1711.00215", "submitter": "Bert Moons", "authors": "Bert Moons, Koen Goetschalckx, Nick Van Berckelaer, Marian Verhelst", "title": "Minimum Energy Quantized Neural Networks", "comments": "preprint for work presented at the 51st Asilomar Conference on\n  Signals, Systems and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work targets the automated minimum-energy optimization of Quantized\nNeural Networks (QNNs) - networks using low precision weights and activations.\nThese networks are trained from scratch at an arbitrary fixed point precision.\nAt iso-accuracy, QNNs using fewer bits require deeper and wider network\narchitectures than networks using higher precision operators, while they\nrequire less complex arithmetic and less bits per weights. This fundamental\ntrade-off is analyzed and quantified to find the minimum energy QNN for any\nbenchmark and hence optimize energy-efficiency. To this end, the energy\nconsumption of inference is modeled for a generic hardware platform. This\nallows drawing several conclusions across different benchmarks. First, energy\nconsumption varies orders of magnitude at iso-accuracy depending on the number\nof bits used in the QNN. Second, in a typical system, BinaryNets or int4\nimplementations lead to the minimum energy solution, outperforming int8\nnetworks up to 2-10x at iso-accuracy. All code used for QNN training is\navailable from https://github.com/BertMoons.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 05:50:19 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 09:37:02 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Moons", "Bert", ""], ["Goetschalckx", "Koen", ""], ["Van Berckelaer", "Nick", ""], ["Verhelst", "Marian", ""]]}, {"id": "1711.00425", "submitter": "Chen Zheng", "authors": "Patrick Benediktsson, Jon A. Flandrin, Chen Zheng", "title": "Non Uniform On Chip Power Delivery Network Synthesis Methodology", "comments": "6 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a non-uniform power delivery network (PDN)\nsynthesis methodology. It first constructs initial PDN using uniform approach.\nThen preliminary power integrity analysis is performed to derive IR-safe\ncandidate window. Congestion map is obtained based global route congestion\nestimation. A self-adaptive non-uniform PDN synthesis is then performed to\nglobally and locally optimize PDN over selected regions. The PDN synthesis is\ncongestion-driven and IR- guarded. Experimental results show significant timing\nimportant in trade-off small PDN length reduction with no EM/IR impact. We\nfurther explored potential power savings using our non-uniform PDN synthesis\nmethodology.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 16:34:48 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 23:00:31 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 23:00:30 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Benediktsson", "Patrick", ""], ["Flandrin", "Jon A.", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.01010", "submitter": "Amr Alanwar", "authors": "Amr Alanwar, Mona A. Aboelnaga, Yousra Alkabani, M. Watheq\n  El-Kharashi, Hassan Bedour", "title": "Dynamic FPGA Detection and Protection of Hardware Trojan: A Comparative\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware Trojan detection and protection is becoming more crucial as more\nuntrusted third parties manufacture many parts of critical systems nowadays.\nThe most common way to detect hardware Trojans is comparing the untrusted\ndesign with a golden (trusted) one. However, third-party intellectual\nproperties (IPs) are black boxes with no golden IPs to trust. So, previous\nattempts to detect hardware Trojans will not work with third-party IPs. In this\nwork, we present novel methods for Trojan protection and detection on field\nprogrammable gate arrays (FPGAs) without the need for golden chips. Presented\nmethods work at runtime instead of test time. We provide a wide spectrum of\nTrojan detection and protection methods. While the simplest methods have low\noverhead and provide limited protection mechanisms, more sophisticated and\ncostly techniques are introduced that can detect hardware Trojans and even\nclean up the system from infected IPs. Moreover, we study the cost of using the\nFPGA partial reconfiguration feature to get rid of infected IPs. In addition,\nwe discuss the possibility to construct IP core certificate authority that\nmaintains a centralized database of unsafe vendors and IPs. We show the\npracticality of the introduced schemes by implementing the different\nmethodologies on FPGAs. Results show that simple methods present negligible\noverheads and as we try to increase security the delay and power overheads\nincrease.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 03:25:45 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Alanwar", "Amr", ""], ["Aboelnaga", "Mona A.", ""], ["Alkabani", "Yousra", ""], ["El-Kharashi", "M. Watheq", ""], ["Bedour", "Hassan", ""]]}, {"id": "1711.01125", "submitter": "Jianlei Yang", "authors": "Xiaotao Jia, Jianlei Yang, Zhaohao Wang, Yiran Chen, Hai (Helen) Li\n  and Weisheng Zhao", "title": "Spintronics based Stochastic Computing for Efficient Bayesian Inference\n  System", "comments": "accepted by ASPDAC 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian inference is an effective approach for solving statistical learning\nproblems especially with uncertainty and incompleteness. However, inference\nefficiencies are physically limited by the bottlenecks of conventional\ncomputing platforms. In this paper, an emerging Bayesian inference system is\nproposed by exploiting spintronics based stochastic computing. A stochastic\nbitstream generator is realized as the kernel components by leveraging the\ninherent randomness of spintronics devices. The proposed system is evaluated by\ntypical applications of data fusion and Bayesian belief networks. Simulation\nresults indicate that the proposed approach could achieve significant\nimprovement on inference efficiencies in terms of power consumption and\ninference speed.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 12:23:59 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Jia", "Xiaotao", "", "Helen"], ["Yang", "Jianlei", "", "Helen"], ["Wang", "Zhaohao", "", "Helen"], ["Chen", "Yiran", "", "Helen"], ["Hai", "", "", "Helen"], ["Li", "", ""], ["Zhao", "Weisheng", ""]]}, {"id": "1711.01263", "submitter": "Jingyang Zhu", "authors": "Jingyang Zhu, Jingbo Jiang, Xizi Chen, Chi-Ying Tsui", "title": "SparseNN: An Energy-Efficient Neural Network Accelerator Exploiting\n  Input and Output Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary Deep Neural Network (DNN) contains millions of synaptic\nconnections with tens to hundreds of layers. The large computation and memory\nrequirements pose a challenge to the hardware design. In this work, we leverage\nthe intrinsic activation sparsity of DNN to substantially reduce the execution\ncycles and the energy consumption. An end-to-end training algorithm is proposed\nto develop a lightweight run-time predictor for the output activation sparsity\non the fly. From our experimental results, the computation overhead of the\nprediction phase can be reduced to less than 5% of the original feedforward\nphase with negligible accuracy loss. Furthermore, an energy-efficient hardware\narchitecture, SparseNN, is proposed to exploit both the input and output\nsparsity. SparseNN is a scalable architecture with distributed memories and\nprocessing elements connected through a dedicated on-chip network. Compared\nwith the state-of-the-art accelerators which only exploit the input sparsity,\nSparseNN can achieve a 10%-70% improvement in throughput and a power reduction\nof around 50%.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 09:21:08 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Zhu", "Jingyang", ""], ["Jiang", "Jingbo", ""], ["Chen", "Xizi", ""], ["Tsui", "Chi-Ying", ""]]}, {"id": "1711.01407", "submitter": "Chen Zheng", "authors": "Luis Charre, Bruno Gravano, R\\'emi P\\^ossas, Chen Zheng", "title": "Timing Aware Dummy Metal Fill Methodology", "comments": "3 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyzed parasitic coupling capacitance coming from dummy\nmetal fill and its impact on timing. Based on the modeling, we proposed two\napproaches to minimize the timing impact from dummy metal fill. The first\napproach applies more spacing between critical nets and metal fill, while the\nsecond approach leverages the shielding effects of reference nets. Experimental\nresults show consistent improvement compared to traditional metal fill method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 07:11:22 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 03:33:29 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Charre", "Luis", ""], ["Gravano", "Bruno", ""], ["P\u00f4ssas", "R\u00e9mi", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.02333", "submitter": "P Balasubramanian", "authors": "P Balasubramanian", "title": "Critique of \"Asynchronous Logic Implementation Based on Factorized DIMS\"", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper comments on \"Asynchronous Logic Implementation Based on Factorized\nDIMS\" [Journal of Circuits, Systems, and Computers, vol. 26, no. 5, 1750087:\n1-9, May 2017] with respect to two main problematic issues: i) the gate orphan\nproblem implicit in the factorized DIMS approach discussed in the referenced\narticle which affects its strong-indication, and ii) how the enumeration of\nproduct terms to represent the synthesis cost is skewed in the referenced\narticle because the logic expression contains sum of products and also product\nof sums. It is observed that the referenced article has not provided a general\nlogic synthesis algorithm excepting only an example illustration involving a\n3-input AND logic function. The absence of a general logic synthesis algorithm\nwould make it difficult to reproduce the research described in the referenced\narticle. Moreover, the example illustration in the referenced article describes\nan unsafe logic decomposition which is not suitable for the multi-level\nsynthesis of strong-indication asynchronous circuits. Further, a logic\nsynthesis method which safely decomposes the DIMS solution to synthesize\nmulti-level strong-indication asynchronous circuits is available in the\nexisting literature, which was neither cited nor taken up for comparison in the\nreferenced article, which is another drawback. Subsequently, it is concluded\nthat the referenced article has not advanced existing knowledge in the field\nbut on the contrary, has caused confusions. Hence, in the interest of readers,\nthis paper additionally highlights some important and relevant literature which\nprovide valuable information about robust asynchronous circuit synthesis\ntechniques which employ delay-insensitive codes for data representation and\nprocessing and the 4-phase return-to-zero handshake protocol for data\ncommunication.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 08:28:26 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 12:16:24 GMT"}, {"version": "v3", "created": "Sun, 23 Sep 2018 12:58:16 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Balasubramanian", "P", ""]]}, {"id": "1711.03229", "submitter": "Wanling Gao", "authors": "Wanling Gao, Lei Wang, Jianfeng Zhan, Chunjie Luo, Daoyi Zheng, Zhen\n  Jia, Biwei Xie, Chen Zheng, Qiang Yang, Haibin Wang", "title": "A Dwarf-based Scalable Big Data Benchmarking Methodology", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the traditional benchmarking methodology that creates a new\nbenchmark or proxy for every possible workload, this paper presents a scalable\nbig data benchmarking methodology. Among a wide variety of big data analytics\nworkloads, we identify eight big data dwarfs, each of which captures the common\nrequirements of each class of unit of computation while being reasonably\ndivorced from individual implementations. We implement the eight dwarfs on\ndifferent software stacks, e.g., OpenMP, MPI, Hadoop as the dwarf components.\nFor the purpose of architecture simulation, we construct and tune big data\nproxy benchmarks using the directed acyclic graph (DAG)-like combinations of\nthe dwarf components with different weights to mimic the benchmarks in\nBigDataBench. Our proxy benchmarks preserve the micro-architecture, memory, and\nI/O characteristics, and they shorten the simulation time by 100s times while\nmaintain the average micro-architectural data accuracy above 90 percentage on\nboth X86 64 and ARMv8 processors. We will open-source the big data dwarf\ncomponents and proxy benchmarks soon.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 01:55:44 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Gao", "Wanling", ""], ["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Luo", "Chunjie", ""], ["Zheng", "Daoyi", ""], ["Jia", "Zhen", ""], ["Xie", "Biwei", ""], ["Zheng", "Chen", ""], ["Yang", "Qiang", ""], ["Wang", "Haibin", ""]]}, {"id": "1711.03538", "submitter": "Lukas Cavigelli", "authors": "Manuel Eggimann, Christelle Gloor, Florian Scheidegger, Lukas\n  Cavigelli, Michael Schaffner, Aljosa Smolic, Luca Benini", "title": "Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in\n  65nm CMOS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AR cs.GR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern video processing pipelines rely on edge-aware (EA) filtering\nmethods. However, recent high-quality methods are challenging to run in\nreal-time on embedded hardware due to their computational load. To this end, we\npropose an area-efficient and real-time capable hardware implementation of a\nhigh quality EA method. In particular, we focus on the recently proposed\npermeability filter (PF) that delivers promising quality and performance in the\ndomains of HDR tone mapping, disparity and optical flow estimation. We present\nan efficient hardware accelerator that implements a tiled variant of the PF\nwith low on-chip memory requirements and a significantly reduced external\nmemory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out\nin 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and\nachieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded\nGPUs when scaled to the same technology node). The low area and bandwidth\nrequirements make the accelerator highly suitable for integration into SoCs\nwhere silicon area budget is constrained and external memory is typically a\nheavily contended resource.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:34:33 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Eggimann", "Manuel", ""], ["Gloor", "Christelle", ""], ["Scheidegger", "Florian", ""], ["Cavigelli", "Lukas", ""], ["Schaffner", "Michael", ""], ["Smolic", "Aljosa", ""], ["Benini", "Luca", ""]]}, {"id": "1711.04172", "submitter": "Chen Zheng", "authors": "Anthony Kim, Sung Hyun Chen, Chen Zheng", "title": "Depth First Always On Routing Trace Algorithm", "comments": "4 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discussed current limitation in the\nelectronic-design-automotation (EDA) tool on tracing the always on routing. We\ndeveloped an algorithm to efficiently track the secondary power routing and\naccurately estimate the routing quality using approximate voltage drop as the\ncriteria. The fast check can identify potential hotspot issues without going\nthrough sign-off checks. It helps designers to capture issues at early stages\nand fix the issues with less design effort. We also discussed some limitations\nto our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 17:06:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kim", "Anthony", ""], ["Chen", "Sung Hyun", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.05860", "submitter": "Yufeng Hao", "authors": "Yufeng Hao", "title": "A General Neural Network Hardware Architecture on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field Programmable Gate Arrays (FPGAs) plays an increasingly important role\nin data sampling and processing industries due to its highly parallel\narchitecture, low power consumption, and flexibility in custom algorithms.\nEspecially, in the artificial intelligence field, for training and implement\nthe neural networks and machine learning algorithms, high energy efficiency\nhardware implement and massively parallel computing capacity are heavily\ndemanded. Therefore, many global companies have applied FPGAs into AI and\nMachine learning fields such as autonomous driving and Automatic Spoken\nLanguage Recognition (Baidu) [1] [2] and Bing search (Microsoft) [3].\nConsidering the FPGAs great potential in these fields, we tend to implement a\ngeneral neural network hardware architecture on XILINX ZU9CG System On Chip\n(SOC) platform [4], which contains abundant hardware resource and powerful\nprocessing capacity. The general neural network architecture on the FPGA SOC\nplatform can perform forward and backward algorithms in deep neural networks\n(DNN) with high performance and easily be adjusted according to the type and\nscale of the neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:17:58 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Hao", "Yufeng", ""]]}, {"id": "1711.06315", "submitter": "Sanchari Sen", "authors": "Sanchari Sen, Shubham Jain, Swagath Venkataramani, Anand Raghunathan", "title": "SparCE: Sparsity aware General Purpose Core Extensions to Accelerate\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have emerged as the method of choice for solving\na wide range of machine learning tasks. The enormous computational demands\nposed by DNNs have most commonly been addressed through the design of custom\naccelerators. However, these accelerators are prohibitive in many design\nscenarios (e.g., wearable devices and IoT sensors), due to stringent area/cost\nconstraints. Accelerating DNNs on these low-power systems, comprising of mainly\nthe general-purpose processor (GPP) cores, requires new approaches. We improve\nthe performance of DNNs on GPPs by exploiting a key attribute of DNNs, i.e.,\nsparsity. We propose Sparsity aware Core Extensions (SparCE)- a set of\nmicro-architectural and ISA extensions that leverage sparsity and are minimally\nintrusive and low-overhead. We dynamically detect zero operands and skip a set\nof future instructions that use it. Our design ensures that the instructions to\nbe skipped are prevented from even being fetched, as squashing instructions\ncomes with a penalty. SparCE consists of 2 key micro-architectural\nenhancements- a Sparsity Register File (SpRF) that tracks zero registers and a\nSparsity aware Skip Address (SASA) table that indicates instructions to be\nskipped. When an instruction is fetched, SparCE dynamically pre-identifies\nwhether the following instruction(s) can be skipped and appropriately modifies\nthe program counter, thereby skipping the redundant instructions and improving\nperformance. We model SparCE using the gem5 architectural simulator, and\nevaluate our approach on 6 image-recognition DNNs in the context of both\ntraining and inference using the Caffe framework. On a scalar microprocessor,\nSparCE achieves 19%-31% reduction in application-level. We also evaluate SparCE\non a 4-way SIMD ARMv8 processor using the OpenBLAS library, and demonstrate\nthat SparCE achieves 8%-15% reduction in the application-level execution time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 01:20:19 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 16:42:03 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Sen", "Sanchari", ""], ["Jain", "Shubham", ""], ["Venkataramani", "Swagath", ""], ["Raghunathan", "Anand", ""]]}, {"id": "1711.06613", "submitter": "Jeferson Santiago da Silva", "authors": "Jeferson Santiago da Silva and Fran\\c{c}ois-Raymond Boyer and J.M.\n  Pierre Langlois", "title": "P4-compatible High-level Synthesis of Low Latency 100 Gb/s Streaming\n  Packet Parsers in FPGAs", "comments": "Accepted for publication at the 26th ACM/SIGDA International\n  Symposium on Field-Programmable Gate Arrays February 25 - 27, 2018 Monterey\n  Marriott Hotel, Monterey, California, 7 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1145/3174243.3174270", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet parsing is a key step in SDN-aware devices. Packet parsers in SDN\nnetworks need to be both reconfigurable and fast, to support the evolving\nnetwork protocols and the increasing multi-gigabit data rates. The combination\nof packet processing languages with FPGAs seems to be the perfect match for\nthese requirements. In this work, we develop an open-source FPGA-based\nconfigurable architecture for arbitrary packet parsing to be used in SDN\nnetworks. We generate low latency and high-speed streaming packet parsers\ndirectly from a packet processing program. Our architecture is pipelined and\nentirely modeled using templated C++ classes. The pipeline layout is derived\nfrom a parser graph that corresponds a P4 code after a series of graph\ntransformation rounds. The RTL code is generated from the C++ description using\nXilinx Vivado HLS and synthesized with Xilinx Vivado. Our architecture achieves\n100 Gb/s data rate in a Xilinx Virtex-7 FPGA while reducing the latency by 45%\nand the LUT usage by 40% compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 16:15:55 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["da Silva", "Jeferson Santiago", ""], ["Boyer", "Fran\u00e7ois-Raymond", ""], ["Langlois", "J. M. Pierre", ""]]}, {"id": "1711.06672", "submitter": "Mauricio Pilla", "authors": "Andrey M. Coppieters, Sheila de Oliveira, Felipe M. G. Fran\\c{c}a,\n  Maur\\'icio L. Pilla, Amarildo T. da Costa", "title": "Decanting the Contribution of Instruction Types and Loop Structures in\n  the Reuse of Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reuse has been proposed as a microarchitecture-level mechanism to reduce the\namount of executed instructions, collapsing dependencies and freeing resources\nfor other instructions. Previous works have used reuse domains such as memory\naccesses, integer or not floating point, based on the reusability rate.\nHowever, these works have not studied the specific contribution of reusing\ndifferent subsets of instructions for performance. In this work, we analysed\nthe sensitivity of trace reuse to instruction subsets, comparing their\nefficiency to their complementary subsets. We also studied the amount of reuse\nthat can be extracted from loops. Our experiments show that disabling trace\nreuse outside loops does not harm performance but reduces in 12% the number of\naccesses to the reuse table. Our experiments with reuse subsets show that most\nof the speedup can be retained even when not reusing all types of instructions\npreviously found in the reuse domain.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 18:57:24 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Coppieters", "Andrey M.", ""], ["de Oliveira", "Sheila", ""], ["Fran\u00e7a", "Felipe M. G.", ""], ["Pilla", "Maur\u00edcio L.", ""], ["da Costa", "Amarildo T.", ""]]}, {"id": "1711.06790", "submitter": "Sparsh Mittal", "authors": "Sparsh Mittal", "title": "Mitigating Read-disturbance Errors in STT-RAM Caches by Using Data\n  Compression", "comments": "Book Chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its high density and close-to-SRAM read latency, spin transfer torque\nRAM (STT-RAM) is considered one of the most-promising emerging memory\ntechnologies for designing large last level caches (LLCs). However, in deep\nsub-micron region, STT-RAM shows read-disturbance error (RDE) whereby a read\noperation may modify the stored data value and this presents a severe threat to\nperformance and reliability of STT-RAM caches. In this paper, we present a\ntechnique, named SHIELD, to mitigate RDE in STT-RAM LLCs. SHIELD uses data\ncompression to reduce number of read operations from STT-RAM blocks to avoid\nRDE and also to reduce the number of bits written to cache during both write\nand restore operations. Experimental results have shown that SHIELD provides\nsignificant improvement in performance and energy efficiency. SHIELD consumes\nsmaller energy than two previous RDE-mitigation techniques, namely high-current\nrestore required read (HCRR, also called restore-after-read) and low-current\nlong latency read (LCLL) and even an ideal RDE-free STT-RAM cache.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 01:43:14 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Mittal", "Sparsh", ""]]}, {"id": "1711.07480", "submitter": "Franyell Silfa", "authors": "Franyell Silfa, Gem Dot, Jose-Maria Arnau, Antonio Gonzalez", "title": "E-PUR: An Energy-Efficient Processing Unit for Recurrent Neural Networks", "comments": null, "journal-ref": "PACT '18 Proceedings of the 27th International Conference on\n  Parallel Architectures and Compilation Techniques, Article No. 18, 2018", "doi": "10.1145/3243176.3243184", "report-no": "UPC-DAC-RR-2017-8", "categories": "cs.NE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are a key technology for emerging\napplications such as automatic speech recognition, machine translation or image\ndescription. Long Short Term Memory (LSTM) networks are the most successful RNN\nimplementation, as they can learn long term dependencies to achieve high\naccuracy. Unfortunately, the recurrent nature of LSTM networks significantly\nconstrains the amount of parallelism and, hence, multicore CPUs and many-core\nGPUs exhibit poor efficiency for RNN inference. In this paper, we present\nE-PUR, an energy-efficient processing unit tailored to the requirements of LSTM\ncomputation. The main goal of E-PUR is to support large recurrent neural\nnetworks for low-power mobile devices. E-PUR provides an efficient hardware\nimplementation of LSTM networks that is flexible to support diverse\napplications. One of its main novelties is a technique that we call Maximizing\nWeight Locality (MWL), which improves the temporal locality of the memory\naccesses for fetching the synaptic weights, reducing the memory requirements by\na large extent. Our experimental results show that E-PUR achieves real-time\nperformance for different LSTM networks, while reducing energy consumption by\norders of magnitude with respect to general-purpose processors and GPUs, and it\nrequires a very small chip area. Compared to a modern mobile SoC, an NVIDIA\nTegra X1, E-PUR provides an average energy reduction of 92x.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:58:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Silfa", "Franyell", ""], ["Dot", "Gem", ""], ["Arnau", "Jose-Maria", ""], ["Gonzalez", "Antonio", ""]]}, {"id": "1711.08458", "submitter": "Elaheh Sadredini", "authors": "Elaheh Sadredini, Mohammadreza Najafi, Mahmood Fathy, Zaialabedin\n  Navabi", "title": "BILBO-friendly Hybrid BIST Architecture with Asymmetric Polynomial\n  Reseeding", "comments": null, "journal-ref": "Computer Architecture and Digital Systems (CADS), 2012 16th CSI\n  International Symposium on. IEEE, 2012", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By advances in technology, integrated circuits have come to include more\nfunctionality and more complexity in a single chip. Although methods of testing\nhave improved, but the increase in complexity of circuits, keeps testing a\nchallenging problem. Two important challenges in testing of digital circuits\nare test time and accessing the circuit under test (CUT) for testing. These\nchallenges become even more important in complex system on chip (SoC) zone.\nThis paper presents a multistage test strategy to be implemented on a BIST\narchitecture for reducing test time of a simple core as solution for more\nglobal application of SoC testing strategy. This strategy implements its test\npattern generation and output response analyzer in a BILBO architecture. The\nproposed method benefits from an irregular polynomial BILBO (IP-BILBO)\nstructure to improve its test results. Experimental results on ISCAS-89\nbenchmark circuits show an average of 35% improvement in test time in\nproportion to pervious work.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 03:53:34 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Sadredini", "Elaheh", ""], ["Najafi", "Mohammadreza", ""], ["Fathy", "Mahmood", ""], ["Navabi", "Zaialabedin", ""]]}, {"id": "1711.08572", "submitter": "SeyedMohammad Seyedzadeh", "authors": "Seyed Mohammad Seyedzadeh, Alex K. Jones, Rami Melhem", "title": "Enabling Fine-Grain Restricted Coset Coding Through Word-Level\n  Compression for PCM", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase change memory (PCM) has recently emerged as a promising technology to\nmeet the fast growing demand for large capacity memory in computer systems,\nreplacing DRAM that is impeded by physical limitations. Multi-level cell (MLC)\nPCM offers high density with low per-byte fabrication cost. However, despite\nmany advantages, such as scalability and low leakage, the energy for\nprogramming intermediate states is considerably larger than programing\nsingle-level cell PCM. In this paper, we study encoding techniques to reduce\nwrite energy for MLC PCM when the encoding granularity is lowered below the\ntypical cache line size. We observe that encoding data blocks at small\ngranularity to reduce write energy actually increases the write energy because\nof the auxiliary encoding bits. We mitigate this adverse effect by 1) designing\nsuitable codeword mappings that use fewer auxiliary bits and 2) proposing a new\nWord-Level Compression (WLC) which compresses more than 91% of the memory lines\nand provides enough room to store the auxiliary data using a novel restricted\ncoset encoding applied at small data block granularities.\n  Experimental results show that the proposed encoding at 16-bit data\ngranularity reduces the write energy by 39%, on average, versus the leading\nencoding approach for write energy reduction. Furthermore, it improves\nendurance by 20% and is more reliable than the leading approach. Hardware\nsynthesis evaluation shows that the proposed encoding can be implemented\non-chip with only a nominal area overhead.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 04:32:45 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Seyedzadeh", "Seyed Mohammad", ""], ["Jones", "Alex K.", ""], ["Melhem", "Rami", ""]]}, {"id": "1711.08740", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris and Christos-Savvas Bouganis", "title": "fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural\n  Networks on Embedded FPGAs", "comments": "Accepted at NIPS 2017 Workshop on Machine Learning on the Phone and\n  other Consumer Devices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Convolutional Neural Networks (ConvNets) have become an\nenabling technology for a wide range of novel embedded Artificial Intelligence\nsystems. Across the range of applications, the performance needs vary\nsignificantly, from high-throughput video surveillance to the very low-latency\nrequirements of autonomous cars. In this context, FPGAs can provide a potential\nplatform that can be optimally configured based on the different performance\nneeds. However, the complexity of ConvNet models keeps increasing making their\nmapping to an FPGA device a challenging task. This work presents fpgaConvNet,\nan end-to-end framework for mapping ConvNets on FPGAs. The proposed framework\nemploys an automated design methodology based on the Synchronous Dataflow (SDF)\nparadigm and defines a set of SDF transformations in order to efficiently\nexplore the architectural design space. By selectively optimising for\nthroughput, latency or multiobjective criteria, the presented tool is able to\nefficiently explore the design space and generate hardware designs from\nhigh-level ConvNet specifications, explicitly optimised for the performance\nmetric of interest. Overall, our framework yields designs that improve the\nperformance by up to 6.65x over highly optimised embedded GPU designs for the\nsame power constraints in embedded environments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 15:37:21 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1711.10374", "submitter": "Giuseppe Tagliavini", "authors": "Giuseppe Tagliavini, Stefan Mach, Davide Rossi, Andrea Marongiu, Luca\n  Benini", "title": "A Transprecision Floating-Point Platform for Ultra-Low Power Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern low-power embedded platforms, floating-point (FP) operations emerge\nas a major contributor to the energy consumption of compute-intensive\napplications with large dynamic range. Experimental evidence shows that 50% of\nthe energy consumed by a core and its data memory is related to FP\ncomputations. The adoption of FP formats requiring a lower number of bits is an\ninteresting opportunity to reduce energy consumption, since it allows to\nsimplify the arithmetic circuitry and to reduce the memory bandwidth between\nmemory and registers by enabling vectorization. From a theoretical point of\nview, the adoption of multiple FP types perfectly fits with the principle of\ntransprecision computing, allowing fine-grained control of approximation while\nmeeting specified constraints on the precision of final results. In this paper\nwe propose an extended FP type system with complete hardware support to enable\ntransprecision computing on low-power embedded processors, including two\nstandard formats (binary32 and binary16) and two new formats (binary8 and\nbinary16alt). First, we introduce a software library that enables exploration\nof FP types by tuning both precision and dynamic range of program variables.\nThen, we present a methodology to integrate our library with an external tool\nfor precision tuning, and experimental results that highlight the clear\nbenefits of introducing the new formats. Finally, we present the design of a\ntransprecision FP unit capable of handling 8-bit and 16-bit operations in\naddition to standard 32-bit operations. Experimental results on FP-intensive\nbenchmarks show that up to 90% of FP operations can be safely scaled down to\n8-bit or 16-bit formats. Thanks to precision tuning and vectorization,\nexecution time is decreased by 12% and memory accesses are reduced by 27% on\naverage, leading to a reduction of energy consumption up to 30%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 16:14:43 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Tagliavini", "Giuseppe", ""], ["Mach", "Stefan", ""], ["Rossi", "Davide", ""], ["Marongiu", "Andrea", ""], ["Benini", "Luca", ""]]}, {"id": "1711.10435", "submitter": "Albert Milner", "authors": "Tapio Bohn, Paul Salmi, Albert Milner", "title": "LP-Based Power Grid Enhancement Methodology", "comments": "4 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explored the opportunity to enhance power grid robustness\nafter routing stage, and propose a linear programming based algorithm that\nmaximizes the improvement of power grid strengthening with given available\nrouting resource. We further discussed some techniques to leverage tradeoffs\nbetween runtime and optimality of the solutions. Experimental results show\nsubstantial power integrity improvement with \"zero cost\".\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 16:33:31 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Bohn", "Tapio", ""], ["Salmi", "Paul", ""], ["Milner", "Albert", ""]]}, {"id": "1711.10673", "submitter": "Mohammad Bavandpour", "authors": "Mohammad Bavandpour, Mohammad Reza Mahmoodi, Dmitri B. Strukov", "title": "Energy-Efficient Time-Domain Vector-by-Matrix Multiplier for\n  Neurocomputing and Beyond", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extremely energy-efficient mixed-signal approach for performing\nvector-by-matrix multiplication in a time domain. In such implementation,\nmulti-bit values of the input and output vector elements are represented with\ntime-encoded digital signals, while multi-bit matrix weights are realized with\ncurrent sources, e.g. transistors biased in subthreshold regime. With our\napproach, multipliers can be chained together to implement large-scale circuits\ncompletely in a time domain. Multiplier operation does not rely on\nenergy-taxing static currents, which are typical for peripheral and\ninput/output conversion circuits of the conventional mixed-signal\nimplementations. As a case study, we have designed a multilayer perceptron,\nbased on two layers of 10x10 four-quadrant vector-by-matrix multipliers, in\n55-nm process with embedded NOR flash memory technology, which allows for\ncompact implementation of adjustable current sources. Our analysis, based on\nmemory cell measurements, shows that at high computing speed the drain-induced\nbarrier lowering is a major factor limiting multiplier precision to ~6 bit.\nPost-layout estimates for a conservative 6-bit digital input/output NxN\nmultiplier designed in 55 nm process, including I/O circuitry for converting\nbetween digital and time domain representations, show ~7 fJ/Op for N>200, which\ncan be further lowered well below 1 fJ/Op for more optimal and aggressive\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 04:05:02 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bavandpour", "Mohammad", ""], ["Mahmoodi", "Mohammad Reza", ""], ["Strukov", "Dmitri B.", ""]]}, {"id": "1711.11427", "submitter": "Saugata Ghose", "authors": "Yu Cai, Saugata Ghose, Erich F. Haratsch, Yixin Luo, Onur Mutlu", "title": "Errors in Flash-Memory-Based Solid-State Drives: Analysis, Mitigation,\n  and Recovery", "comments": "arXiv admin note: substantial text overlap with arXiv:1706.08642", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NAND flash memory is ubiquitous in everyday life today because its capacity\nhas continuously increased and cost has continuously decreased over decades.\nThis positive growth is a result of two key trends: (1) effective process\ntechnology scaling; and (2) multi-level (e.g., MLC, TLC) cell data coding.\nUnfortunately, the reliability of raw data stored in flash memory has also\ncontinued to become more difficult to ensure, because these two trends lead to\n(1) fewer electrons in the flash memory cell floating gate to represent the\ndata; and (2) larger cell-to-cell interference and disturbance effects. Without\nmitigation, worsening reliability can reduce the lifetime of NAND flash memory.\nAs a result, flash memory controllers in solid-state drives (SSDs) have become\nmuch more sophisticated: they incorporate many effective techniques to ensure\nthe correct interpretation of noisy data stored in flash memory cells.\n  In this chapter, we review recent advances in SSD error characterization,\nmitigation, and data recovery techniques for reliability and lifetime\nimprovement. We provide rigorous experimental data from state-of-the-art MLC\nand TLC NAND flash devices on various types of flash memory errors, to motivate\nthe need for such techniques. Based on the understanding developed by the\nexperimental characterization, we describe several mitigation and recovery\ntechniques, including (1) cell-tocell interference mitigation; (2) optimal\nmulti-level cell sensing; (3) error correction using state-of-the-art\nalgorithms and methods; and (4) data recovery when error correction fails. We\nquantify the reliability improvement provided by each of these techniques.\nLooking forward, we briefly discuss how flash memory and these techniques could\nevolve into the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 19:54:09 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 15:17:52 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Cai", "Yu", ""], ["Ghose", "Saugata", ""], ["Haratsch", "Erich F.", ""], ["Luo", "Yixin", ""], ["Mutlu", "Onur", ""]]}]