[{"id": "1701.01630", "submitter": "Pece Mitrevski", "authors": "Milcho Prisagjanec and Pece Mitrevski", "title": "Reducing Competitive Cache Misses in Modern Processor Architectures", "comments": "9 pages, 8 figures, 1 table", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT), Vol 8, No 6, pp. 49-57, December 2016", "doi": "10.5121/ijcsit.2016.8605", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing number of threads inside the cores of a multicore processor,\nand competitive access to the shared cache memory, become the main reasons for\nan increased number of competitive cache misses and performance decline.\nInevitably, the development of modern processor architectures leads to an\nincreased number of cache misses. In this paper, we make an attempt to\nimplement a technique for decreasing the number of competitive cache misses in\nthe first level of cache memory. This technique enables competitive access to\nthe entire cache memory when there is a hit - but, if there are cache misses,\nmemory data (by using replacement techniques) is put in a virtual part given to\nthreads, so that competitive cache misses are avoided. By using a simulator\ntool, the results show a decrease in the number of cache misses and performance\nincrease for up to 15%. The conclusion that comes out of this research is that\ncache misses are a real challenge for future processor designers, in order to\nhide memory latency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 13:32:36 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Prisagjanec", "Milcho", ""], ["Mitrevski", "Pece", ""]]}, {"id": "1701.03499", "submitter": "Maynk Parasar", "authors": "Mayank Parasar, Abhishek Bhattacharjee, Tushar Krishna", "title": "VESPA: VIPT Enhancements for Superpage Accesses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L1 caches are critical to the performance of modern computer systems. Their\ndesign involves a delicate balance between fast lookups, high hit rates, low\naccess energy, and simplicity of implementation. Unfortunately, constraints\nimposed by virtual memory make it difficult to satisfy all these attributes\ntoday. Specifically, the modern staple of supporting virtual-indexing and\nphysical-tagging (VIPT) for parallel TLB-L1 lookups means that L1 caches are\nusually grown with greater associativity rather than sets. This compromises\nperformance -- by degrading access times without significantly boosting hit\nrates -- and increases access energy. We propose VIPT Enhancements for\nSuperPage Accesses or VESPA in response. VESPA side-steps the traditional\nproblems of VIPT by leveraging the increasing ubiquity of superpages; since\nsuperpages have more page offset bits, they can accommodate L1 cache\norganizations with more sets than baseline pages can. VESPA dynamically adapts\nto any OS distribution of page sizes to operate L1 caches with good access\ntimes, hit rates, and energy, for both single- and multi-threaded workloads.\nSince the hardware changes are modest, and there are no OS or application\nchanges, VESPA is readily-implementable.\n  By superpages (also called huge or large pages) we refer to any page sizes\nsupported by the architecture bigger than baseline page size.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 20:31:53 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 07:58:57 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Parasar", "Mayank", ""], ["Bhattacharjee", "Abhishek", ""], ["Krishna", "Tushar", ""]]}, {"id": "1701.03534", "submitter": "Andrew Ling", "authors": "Utku Aydonat, Shane O'Connell, Davor Capalija, Andrew C. Ling, Gordon\n  R. Chiu", "title": "An OpenCL(TM) Deep Learning Accelerator on Arria 10", "comments": "To be published at FPGA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural nets (CNNs) have become a practical means to perform\nvision tasks, particularly in the area of image classification. FPGAs are well\nknown to be able to perform convolutions efficiently, however, most recent\nefforts to run CNNs on FPGAs have shown limited advantages over other devices\nsuch as GPUs. Previous approaches on FPGAs have often been memory bound due to\nthe limited external memory bandwidth on the FPGA device. We show a novel\narchitecture written in OpenCL(TM), which we refer to as a Deep Learning\nAccelerator (DLA), that maximizes data reuse and minimizes external memory\nbandwidth. Furthermore, we show how we can use the Winograd transform to\nsignificantly boost the performance of the FPGA. As a result, when running our\nDLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or\n23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs\nand is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the\nstate-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the\nbest publicly known implementation of AlexNet on nVidia's TitanX GPU.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 00:31:15 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Aydonat", "Utku", ""], ["O'Connell", "Shane", ""], ["Capalija", "Davor", ""], ["Ling", "Andrew C.", ""], ["Chiu", "Gordon R.", ""]]}, {"id": "1701.03709", "submitter": "Christof Schlaak", "authors": "Christof Schlaak, Maher Fakih, Ralf Stemmer", "title": "Power and Execution Time Measurement Methodology for SDF Applications on\n  FPGA-based MPSoCs", "comments": "Presented at HIP3ES, 2017 7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2017/1", "categories": "cs.DC cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timing and power consumption play an important role in the design of embedded\nsystems. Furthermore, both properties are directly related to the safety\nrequirements of many embedded systems. With regard to availability\nrequirements, power considerations are of uttermost importance for battery\noperated systems. Validation of timing and power requires observability of\nthese properties. In many cases this is difficult, because the observability is\neither not possible or requires big extra effort in the system validation\nprocess. In this paper, we present a measurement-based approach for the joint\ntiming and power analysis of Synchronous Dataflow (SDF) applications running on\na shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a\nproof-of-concept, we implement an MPSoC system with configurable power and\ntiming measurement interfaces inside a Field Programmable Gate Array (FPGA).\nOur experiments demonstrate the viability of our approach being able of\naccurately analyzing different mappings of image processing applications (Sobel\nfilter and JPEG encoder) on an FPGA-based MPSoC implementation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 16:15:53 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Schlaak", "Christof", ""], ["Fakih", "Maher", ""], ["Stemmer", "Ralf", ""]]}, {"id": "1701.03836", "submitter": "Khaza Anuarul Hoque", "authors": "Khaza Anuarul Hoque, Otmane Ait Mohamed, Yvon Savaria", "title": "Formal Analysis of SEU Mitigation for Early Dependability and\n  Performability Analysis of FPGA-based Space Applications", "comments": "Accepted version for publication in the Journal of Applied Science,\n  Elsevier", "journal-ref": null, "doi": "10.1016/j.jal.2017.03.001", "report-no": null, "categories": "cs.PF cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SRAM-based FPGAs are increasingly popular in the aerospace industry due to\ntheir field programmability and low cost. However, they suffer from cosmic\nradiation induced Single Event Upsets (SEUs). In safety-critical applications,\nthe dependability of the design is a prime concern since failures may have\ncatastrophic consequences. An early analysis of the relationship between\ndependability metrics, performability-area trade-off, and different mitigation\ntechniques for such applications can reduce the design effort while increasing\nthe design confidence. This paper introduces a novel methodology based on\nprobabilistic model checking, for the analysis of the reliability,\navailability, safety and performance-area tradeoffs of safety-critical systems\nfor early design decisions. Starting from the high-level description of a\nsystem, a Markov reward model is constructed from the Control Data Flow Graph\n(CDFG) and a component characterization library targeting FPGAs. The proposed\nmodel and exhaustive analysis capture all the failure states (based on the\nfault detection coverage) and repairs possible in the system. We present\nquantitative results based on an FIR filter circuit to illustrate the\napplicability of the proposed approach and to demonstrate that a wide range of\nuseful dependability and performability properties can be analyzed using the\nproposed methodology. The modeling results show the relationship between\ndifferent mitigation techniques and fault detection coverage, exposing their\ndirect impact on the design for early decisions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 17:07:36 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 17:21:29 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Hoque", "Khaza Anuarul", ""], ["Mohamed", "Otmane Ait", ""], ["Savaria", "Yvon", ""]]}, {"id": "1701.03878", "submitter": "Yatish Turakhia", "authors": "Yatish Turakhia, Subhasis Das, Tor M. Aamodt, William J. Dally", "title": "HoLiSwap: Reducing Wire Energy in L1 Caches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes HoLiSwap a method to reduce L1 cache wire energy, a\nsignificant fraction of total cache energy, by swapping hot lines to the cache\nway nearest to the processor. We observe that (i) a small fraction (<3%) of\ncache lines (hot lines) serve over 60% of the L1 cache accesses and (ii) the\ndifference in wire energy between the nearest and farthest cache subarray can\nbe over 6$\\times$. Our method exploits this difference in wire energy to\ndynamically identify hot lines and swap them to the nearest physical way in a\nset-associative L1 cache. This provides up to 44% improvement in the wire\nenergy (1.82% saving in overall system energy) with no impact on the cache miss\nrate and 0.13% performance drop. We also show that HoLiSwap can simplify\nway-prediction.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 04:03:50 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Turakhia", "Yatish", ""], ["Das", "Subhasis", ""], ["Aamodt", "Tor M.", ""], ["Dally", "William J.", ""]]}, {"id": "1701.06382", "submitter": "Daniel Sanz Ausin", "authors": "Daniel Sanz Ausin and Fabian Goerge", "title": "Design of an Audio Interface for Patmos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and implementation of an audio interface for\nthe Patmos processor, which runs on an Altera DE2-115 FPGA board. This board\nhas an audio codec included, the WM8731. The interface described in this work\nallows to receive and send audio from and to the WM8731, and to synthesize,\nstore or manipulate audio signals writing C programs for Patmos. The audio\ninterface described in this paper is intended to be used with the Patmos\nprocessor. Patmos is an open source RISC ISAs with a load-store architecture,\nthat is optimized for Real-Time Systems. Patmos is part of a project founded by\nthe European Union called T-CREST (Time-predictable Multi-Core Architecture for\nEmbedded Systems).[5] The structure of this project is integrated with the\nPatmos project: new hardware modules have been added as IOs, which allow the\ncommunication between the processor and the audio codec. These modules include\na clock generator for the audio chip, ADC and DAC modules for the audio\nconversion from analog to digital and vice versa, and an I2C module which\nallows setting configuration parameters on the audio codec. Moreover, a top\nmodule has been created, which connects all the modules previously mentioned\nbetween them, to Patmos and to the WM8731, using the external pins of the FPGA.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 13:40:16 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Ausin", "Daniel Sanz", ""], ["Goerge", "Fabian", ""]]}, {"id": "1701.06420", "submitter": "Erfan Azarkhish", "authors": "Erfan Azarkhish, Davide Rossi, Igor Loi, Luca Benini", "title": "Neurostream: Scalable and Energy Efficient Deep Learning with Smart\n  Memory Cubes", "comments": "14 pages, 13 figures, submitted to IEEE TPDS Journal", "journal-ref": null, "doi": "10.1109/TPDS.2017.2752706", "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing systems are moving towards 2.5D and 3D memory\nhierarchies, based on High Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC)\nto mitigate the main memory bottlenecks. This trend is also creating new\nopportunities to revisit near-memory computation. In this paper, we propose a\nflexible processor-in-memory (PIM) solution for scalable and energy-efficient\nexecution of deep convolutional networks (ConvNets), one of the fastest-growing\nworkloads for servers and high-end embedded systems. Our codesign approach\nconsists of a network of Smart Memory Cubes (modular extensions to the standard\nHMC) each augmented with a many-core PIM platform called NeuroCluster.\nNeuroClusters have a modular design based on NeuroStream coprocessors (for\nConvolution-intensive computations) and general-purpose RISCV cores. In\naddition, a DRAM-friendly tiling mechanism and a scalable computation paradigm\nare presented to efficiently harness this computational capability with a very\nlow programming effort. NeuroCluster occupies only 8% of the total logic-base\n(LoB) die area in a standard HMC and achieves an average performance of 240\nGFLOPS for complete execution of full-featured state-of-the-art (SoA) ConvNets\nwithin a power budget of 2.5W. Overall 11 W is consumed in a single SMC device,\nwith 22.5 GFLOPS/W energy-efficiency which is 3.5X better than the best GPU\nimplementations in similar technologies. The minor increase in system-level\npower and the negligible area increase make our PIM system a cost-effective and\nenergy efficient solution, easily scalable to 955 GFLOPS with a small network\nof just four SMCs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 14:44:47 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 15:43:01 GMT"}, {"version": "v3", "created": "Sun, 24 Sep 2017 17:47:10 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Azarkhish", "Erfan", ""], ["Rossi", "Davide", ""], ["Loi", "Igor", ""], ["Benini", "Luca", ""]]}, {"id": "1701.06741", "submitter": "Rhonda Zhang", "authors": "Rhonda P. Zhang", "title": "Variability-Aware Design for Energy Efficient Computational Artificial\n  Intelligence Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portable computing devices, which include tablets, smart phones and various\ntypes of wearable sensors, experienced a rapid development in recent years. One\nof the most critical limitations for these devices is the power consumption as\nthey use batteries as the power supply. However, the bottleneck of the power\nsaving schemes in both hardware design and software algorithm is the huge\nvariability in power consumption. The variability is caused by a myriad of\nfactors, including the manufacturing process, the ambient environment\n(temperature, humidity), the aging effects and etc. As the technology node\nscaled down to 28nm and even lower, the variability becomes more severe. As a\nresult, a platform for variability characterization seems to be very necessary\nand helpful.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 06:06:25 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 23:23:12 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2017 02:56:11 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Zhang", "Rhonda P.", ""]]}, {"id": "1701.07517", "submitter": "Zi Yan", "authors": "Zi Yan (1), Guilherme Cox (1), Jan Vesely (1), Abhishek Bhattacharjee\n  (1) ((1) Rutgers University)", "title": "Hardware Translation Coherence for Virtualized Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve system performance, modern operating systems (OSes) often\nundertake activities that require modification of virtual-to-physical page\ntranslation mappings. For example, the OS may migrate data between physical\nframes to defragment memory and enable superpages. The OS may migrate pages of\ndata between heterogeneous memory devices. We refer to all such activities as\npage remappings. Unfortunately, page remappings are expensive. We show that\ntranslation coherence is a major culprit and that systems employing\nvirtualization are especially badly affected by their overheads. In response,\nwe propose hardware translation invalidation and coherence or HATRIC, a readily\nimplementable hardware mechanism to piggyback translation coherence atop\nexisting cache coherence protocols. We perform detailed studies using KVM-based\nvirtualization, showing that HATRIC achieves up to 30% performance and 10%\nenergy benefits, for per-CPU area overheads of 2%. We also quantify HATRIC's\nbenefits on systems running Xen and find up to 33% performance improvements.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 23:27:30 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 16:36:28 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Yan", "Zi", "", "Rutgers University"], ["Cox", "Guilherme", "", "Rutgers University"], ["Vesely", "Jan", "", "Rutgers University"], ["Bhattacharjee", "Abhishek", "", "Rutgers University"]]}, {"id": "1701.08849", "submitter": "Amor Nafkha", "authors": "Amor Nafkha and Yves Louet", "title": "Accurate Measurement of Power Consumption Overhead During FPGA Dynamic\n  Partial Reconfiguration", "comments": "6 pages, 6 figures, 2016 International Symposium on Wireless\n  Communication Systems (ISWCS): Special sessions - Low Power Design Techniques\n  for Embedded Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of embedded systems design, two important challenges are still\nunder investigation. First, improve real-time data processing,\nreconfigurability, scalability, and self-adjusting capabilities of hardware\ncomponents. Second, reduce power consumption through low-power design\ntechniques as clock gating, logic gating, and dynamic partial reconfiguration\n(DPR) capabilities. Today, several application, e.g., cryptography,\nSoftware-defined radio or aerospace missions exploit the benefits of DPR of\nprogrammable logic devices. The DPR allows well defined reconfigurable FPGA\nregion to be modified during runtime. However, it introduces an overhead in\nterm of power consumption and time during the reconfiguration phase. In this\npaper, we present an investigation of power consumption overhead of the DPR\nprocess using a high-speed digital oscilloscope and the shunt resistor method.\nResults in terms of reconfiguration time and power consumption overhead for\nVirtex 5 FPGAs are shown.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 22:09:23 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Nafkha", "Amor", ""], ["Louet", "Yves", ""]]}, {"id": "1701.08877", "submitter": "Fei Li", "authors": "Yilei F. Li, Li Du", "title": "1.5 bit-per-stage 8-bit Pipelined CMOS A/D Converter for Neuromophic\n  Vision Processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic vision processor is an electronic implementation of vision\nalgorithm processor on semiconductor. To image the world, a low-power CMOS\nimage sensor array is required in the vision processor. The image sensor array\nis typically formed through photo diodes and analog to digital converter (ADC).\nTo achieve low power acquisition, a low-power mid-resolution ADC is necessary.\nIn this paper, a 1.8V, 8-bit, 166MS/s pipelined ADC was proposed in a 0.18 um\nCMOS technology. The ADC used operational amplifier sharing architecture to\nreduce power consumption and achieved maximum DNL of 0.24 LSB, maximum INL of\n0.35 LSB, at a power consumption of 38.9mW. When input frequency is 10.4MHz, it\nachieved an SNDR 45.9dB, SFDR 50dB, and an ENOB of 7.33 bit.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 00:14:32 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 02:56:28 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Li", "Yilei F.", ""], ["Du", "Li", ""]]}]