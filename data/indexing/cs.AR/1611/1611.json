[{"id": "1611.01571", "submitter": "Syed Kamran Haider", "authors": "Syed Kamran Haider and Marten van Dijk", "title": "Flat ORAM: A Simplified Write-Only Oblivious RAM Construction for Secure\n  Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious RAM (ORAM) is a cryptographic primitive which obfuscates the access\npatterns to a storage thereby preventing privacy leakage. So far in the current\nliterature, only `fully functional' ORAMs are widely studied which can protect,\nat a cost of considerable performance penalty, against the strong adversaries\nwho can monitor all read and write operations. However, recent research has\nshown that information can still be leaked even if only the write access\npattern (not reads) is visible to the adversary. For such weaker adversaries, a\nfully functional ORAM turns out to be an overkill causing unnecessary\noverheads. Instead, a simple `write-only' ORAM is sufficient, and, more\ninterestingly, is preferred as it can offer far more performance and energy\nefficiency than a fully functional ORAM.\n  In this work, we present Flat ORAM: an efficient write-only ORAM scheme which\noutperforms the closest existing write-only ORAM called HIVE. HIVE suffers from\nperformance bottlenecks while managing the memory occupancy information vital\nfor correctness of the protocol. Flat ORAM resolves these bottlenecks by\nintroducing a simple idea of Occupancy Map (OccMap) which efficiently manages\nthe memory occupancy information resulting in far better performance. Our\nsimulation results show that, on average, Flat ORAM only incurs a moderate\nslowdown of $3\\times$ over the insecure DRAM for memory intensive benchmarks\namong Splash2 and $1.6\\times$ for SPEC06. Compared to HIVE, Flat ORAM offers\n$50\\%$ performance gain on average and up to $80\\%$ energy savings.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 23:53:32 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 17:12:20 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 20:16:48 GMT"}, {"version": "v4", "created": "Sun, 10 Sep 2017 09:22:02 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Haider", "Syed Kamran", ""], ["van Dijk", "Marten", ""]]}, {"id": "1611.02450", "submitter": "Dong Wang", "authors": "Dong Wang, Jianjing An, Ke Xu", "title": "PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution\n  Neuron Networks", "comments": "First Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been widely employed in many\napplications such as image classification, video analysis and speech\nrecognition. Being compute-intensive, CNN computations are mainly accelerated\nby GPUs with high power dissipations. Recently, studies were carried out\nexploiting FPGA as CNN accelerator because of its reconfigurability and energy\nefficiency advantage over GPU, especially when OpenCL-based high-level\nsynthesis tools are now available providing fast verification and\nimplementation flows. Previous OpenCL-based design only focused on creating a\ngeneric framework to identify performance-related hardware parameters, without\nutilizing FPGA's special capability of pipelining kernel functions to minimize\nmemory bandwidth requirement. In this work, we propose an FPGA accelerator with\na new architecture of deeply pipelined OpenCL kernels. Data reuse and task\nmapping techniques are also presented to improve design efficiency. The\nproposed schemes are verified by implementing two representative large-scale\nCNNs, AlexNet and VGG on Altera Stratix-V A7 FPGA. We have achieved a similar\npeak performance of 33.9 GOPS with a 34% resource reduction on DSP blocks\ncompared to previous work. Our design is openly accessible and thus can be\nreused to explore new architectures for neural network accelerators.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 09:43:03 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Wang", "Dong", ""], ["An", "Jianjing", ""], ["Xu", "Ke", ""]]}, {"id": "1611.02792", "submitter": "Dhireesha Kudithipudi", "authors": "Lennard Streat, Dhireesha Kudithipudi, Kevin Gomez", "title": "Non-volatile Hierarchical Temporal Memory: Hardware for Spatial Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a biomimetic machine learning algorithm\nimbibing the structural and algorithmic properties of the neocortex. Two main\nfunctional components of HTM that enable spatio-temporal processing are the\nspatial pooler and temporal memory. In this research, we explore a scalable\nhardware realization of the spatial pooler closely coupled with the\nmathematical formulation of spatial pooler. This class of neuromorphic\nalgorithms are advantageous in solving a subset of the future engineering\nproblems by extracting nonintuitive patterns in complex data. The proposed\narchitecture, Non-volatile HTM (NVHTM), leverages large-scale solid state flash\nmemory to realize a optimal memory organization, area and power envelope. A\nbehavioral model of NVHTM is evaluated against the MNIST dataset, yielding\n91.98% classification accuracy. A full custom layout is developed to validate\nthe design in a TSMC 180nm process. The area and power profile of the spatial\npooler are 30.538mm2 and 64.394mW, respectively. This design is a\nproof-of-concept that storage processing is a viable platform for large scale\nHTM network models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 01:25:59 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Streat", "Lennard", ""], ["Kudithipudi", "Dhireesha", ""], ["Gomez", "Kevin", ""]]}, {"id": "1611.02915", "submitter": "Pradeep  Singla", "authors": "Pradeep Singla", "title": "Power Gating Structure for Reversible Programmable Logic Array", "comments": "14 Pages, 9 figures, Electrical and Computer Engineering:\n  International Journal, September 2015", "journal-ref": null, "doi": "10.14810/ecij.2015.4301", "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Throughout the world, the numbers of researchers or hardware designer\nstruggle for the reducing of power dissipation in low power VLSI systems. This\npaper presented an idea of using the power gating structure for reducing the\nsub threshold leakage in the reversible system. This concept presented in the\npaper is entirely new and presented in the literature of reversible logics. By\nusing the reversible logics for the digital systems, the energy can be saved up\nto the gate level implementation. But at the physical level designing of the\nreversible logics by the modern CMOS technology the heat or energy is\ndissipated due the sub-threshold leakage at the time of inactivity or standby\nmode. The Reversible Programming logic array (RPLA) is one of the important\nparts of the low power industrial applications and in this paper the physical\ndesign of the RPLA is presented by using the sleep transistor and the results\nis shown with the help of TINA- PRO software. The results for the proposed\ndesign is also compare with the CMOS design and shown that of 40.8% of energy\nsaving. The Transient response is also produces in the paper for the switching\nactivity and showing that the proposed design is much better that the modern\nCMOS design of the RPLA.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2015 04:27:53 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Singla", "Pradeep", ""]]}, {"id": "1611.03099", "submitter": "Sriseshan Srikanth", "authors": "Sriseshan Srikanth, Bobin Deng, Thomas M. Conte", "title": "A Brief Survey of Non-Residue Based Computational Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of computational error correction has been around for over half a\ncentury. The motivation has largely been to mitigate unreliable devices,\nmanufacturing defects or harsh environments, primarily as a mandatory measure\nto preserve reliability, or more recently, as a means to lower energy by\nallowing soft errors to occasionally creep. While residue codes have shown\ngreat promise for this purpose, there have been several orthogonal non-residue\nbased techniques. In this article, we provide a high level outline of some of\nthese non-residual approaches.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 21:23:16 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Srikanth", "Sriseshan", ""], ["Deng", "Bobin", ""], ["Conte", "Thomas M.", ""]]}, {"id": "1611.03109", "submitter": "Naresh Shanbhag", "authors": "Naresh R. Shanbhag", "title": "Energy-efficient Machine Learning in Silicon: A Communications-inspired\n  Approach", "comments": "This paper was presented at the 2016 ICML Workshop on On-Device\n  Intelligence, June 24, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This position paper advocates a communications-inspired approach to the\ndesign of machine learning systems on energy-constrained embedded `always-on'\nplatforms. The communications-inspired approach has two versions - 1) a\ndeterministic version where existing low-power communication IC design methods\nare repurposed, and 2) a stochastic version referred to as Shannon-inspired\nstatistical information processing employing information-based metrics,\nstatistical error compensation (SEC), and retraining-based methods to implement\nML systems on stochastic circuit/device fabrics operating at the limits of\nenergy-efficiency. The communications-inspired approach has the potential to\nfully leverage the opportunities afforded by ML algorithms and applications in\norder to address the challenges inherent in their deployment on\nenergy-constrained platforms.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 18:45:32 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Shanbhag", "Naresh R.", ""]]}, {"id": "1611.03380", "submitter": "Vijay Gadepally", "authors": "Sang-Woo Jun, Huy T. Nguyen, Vijay N. Gadepally, Arvind", "title": "In-Storage Embedded Accelerator for Sparse Pattern Processing", "comments": "Accepted to IEEE HPEC 2016", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761588", "report-no": null, "categories": "cs.AR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel architecture for sparse pattern processing, using flash\nstorage with embedded accelerators. Sparse pattern processing on large data\nsets is the essence of applications such as document search, natural language\nprocessing, bioinformatics, subgraph matching, machine learning, and graph\nprocessing. One slice of our prototype accelerator is capable of handling up to\n1TB of data, and experiments show that it can outperform C/C++ software\nsolutions on a 16-core system at a fraction of the power and cost; an optimized\nversion of the accelerator can match the performance of a 48-core server.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 16:21:51 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jun", "Sang-Woo", ""], ["Nguyen", "Huy T.", ""], ["Gadepally", "Vijay N.", ""], ["Arvind", "", ""]]}, {"id": "1611.04474", "submitter": "Zhenman Fang", "authors": "Jason Cong, Zhenman Fang, Hassan Kianinejad, Peng Wei", "title": "Revisiting FPGA Acceleration of Molecular Dynamics Simulation with\n  Dynamic Data Flow Behavior in High-Level Synthesis", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AR physics.atom-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics (MD) simulation is one of the past decade's most important\ntools for enabling biology scientists and researchers to explore human health\nand diseases. However, due to the computation complexity of the MD algorithm,\nit takes weeks or even months to simulate a comparatively simple biology entity\non conventional multicore processors. The critical path in molecular dynamics\nsimulations is the force calculation between particles inside the simulated\nenvironment, which has abundant parallelism. Among various acceleration\nplatforms, FPGA is an attractive alternative because of its low power and high\nenergy efficiency. However, due to its high programming cost using RTL, none of\nthe mainstream MD software packages has yet adopted FPGA for acceleration.\n  In this paper we revisit the FPGA acceleration of MD in high-level synthesis\n(HLS) so as to provide affordable programming cost. Our experience with the MD\nacceleration demonstrates that HLS optimizations such as loop pipelining,\nmodule duplication and memory partitioning are essential to improve the\nperformance, achieving a speedup of 9.5X compared to a 12-core CPU. More\nimportantly, we observe that even the fully optimized HLS design can still be\n2X slower than the reference RTL architecture due to the common dynamic\n(conditional) data flow behavior that is not yet supported by current HLS\ntools. To support such behavior, we further customize an array of processing\nelements together with a data-driven streaming network through a common RTL\ntemplate, and fully automate the design flow. Our final experimental results\ndemonstrate a 19.4X performance speedup and 39X energy efficiency for the\nwidely used ApoA1 MD benchmark on the Convey HC1ex FPGA compared to a 12-core\nIntel Xeon server.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 01:38:14 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Cong", "Jason", ""], ["Fang", "Zhenman", ""], ["Kianinejad", "Hassan", ""], ["Wei", "Peng", ""]]}, {"id": "1611.05415", "submitter": "Danila Gorodecky", "authors": "Danila Gorodecky", "title": "Multipliers: comparison of Fourier transformation based method and\n  Synopsys design technique for up to 32 bits inputs in regular and saturation\n  arithmetics", "comments": "Proceedings of the 12th International Workshop on Boolean Problems,\n  Freiberg, Germany, Sept. 22-23, 2016. Edited by B. Steinbach. Freiberg\n  University of Mining and Technology. P. 145-150. Changed title from\n  \"Multipliers design technique based disjunctive normal form minimizationa and\n  Fourier transformation\"; fixed some inaccuracies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technique for hardware multiplication based upon Fourier transformation\nhas been introduced. The technique has the highest efficiency on multiplication\nunits with up to 8 bit range. Each multiplication unit is realized on base of\nthe minimized Boolean functions. Experimental data showed that this technique\nthe multiplication process speed up to 20% higher for 2-8 bit range of input\noperands and up to 3% higher for 8-32 bit range of input operands than\nanalogues designed by Synopsys technique.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 19:39:08 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Gorodecky", "Danila", ""]]}, {"id": "1611.05438", "submitter": "Shawki Areibi", "authors": "A. Al-Wattar and S. Areibi and G. Grewal", "title": "An Efficient Framework for Floor-plan Prediction of Dynamic Runtime\n  Reconfigurable Systems", "comments": "23 pages, 12 figures", "journal-ref": "International Journal of Reconfigurable and Embedded Systems\n  (IJRES) Vol. 4, No. 2, July 2015, pp. 99~121", "doi": null, "report-no": null, "categories": "cs.OH cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several embedded application domains for reconfigurable systems tend to\ncombine frequent changes with high performance demands of their workloads such\nas image processing, wearable computing and network processors. Time\nmultiplexing of reconfigurable hardware resources raises a number of new\nissues, ranging from run-time systems to complex programming models that\nusually form a Reconfigurable hardware Operating System (ROS). The Operating\nSystem performs online task scheduling and handles resource management. There\nare many challenges in adaptive computing and dynamic reconfigurable systems.\nOne of the major understudied challenges is estimating the required resources\nin terms of soft cores, Programmable Reconfigurable Regions (PRRs), the\nappropriate communication infrastructure, and to predict a near optimal layout\nand floorplan of the reconfigurable logic fabric. Some of these issues are\nspecific to the application being designed, while others are more general and\nrelate to the underlying run-time environment. Static resource allocation for\nRun- Time Reconfiguration (RTR) often leads to inferior and unacceptable\nresults. In this paper, we present a novel adaptive and dynamic methodology,\nbased on a Machine Learning approach, for predicting and estimating the\nnecessary resources for an application based on past historical information. An\nimportant feature of the proposed methodology is that the system is able to\nlearn and generalize and, therefore, is expected to improve its accuracy over\ntime. The goal of the entire process is to extract useful hidden knowledge from\nthe data. This knowledge is the prediction and estimation of the necessary\nresources for an unknown or not previously seen application.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 21:48:29 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Al-Wattar", "A.", ""], ["Areibi", "S.", ""], ["Grewal", "G.", ""]]}, {"id": "1611.06078", "submitter": "Arief Wicaksana", "authors": "Arief Wicaksana (ITB), Arif Sasongko (ITB)", "title": "Fast and reconfigurable packet classification engine in FPGA-based\n  firewall", "comments": "in 2011 International Conference on Electrical Engineering and\n  Informatics (ICEEI), Jul 2011, Bandung, Indonesia", "journal-ref": null, "doi": "10.1109/ICEEI.2011.6021782", "report-no": null, "categories": "cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data communication via internet, security is becoming one of the most\ninfluential aspects. One way to support it is by classifying and filtering\nethernet packets within network devices. Packet classification is a fundamental\ntask for network devices such as routers, firewalls, and intrusion detection\nsystems. In this paper we present architecture of fast and reconfigurable\nPacket Classification Engine (PCE). This engine is used in FPGA-based firewall.\nOur PCE inspects multi-dimensional field of packet header sequentially based on\ntree-based algorithm. This algorithm simplifies overall system to a lower scale\nand leads to a more secure system. The PCE works with an adaptation of single\ncycle processor architecture in the system. Ethernet packet is examined with\nPCE based on Source IP Address, Destination IP Address, Source Port,\nDestination Port, and Protocol fields of the packet header. These are basic\nfields to know whether it is a dangerous or normal packet before inspecting the\ncontent. Using implementation of tree-based algorithm in the architecture,\nfirewall rules are rebuilt into 24-bit sub-rules which are read as processor\ninstruction in the inspection process. The inspection process is comparing one\nsub-rule with input field of header every clock cycle. The proposed PCE shows\n91 MHz clock frequency in Cyclone II EP2C70F896C6 with 13 clocks throughput\naverage from input to output generation. The use of tree-based algorithm\nsimplifies the multidimensional packet inspection and gives us reconfigurable\nas well as scalable system. The architecture is fast, reliable, and adaptable\nand also can maximize the advantages of the algorithm very well. Although the\nPCE has high frequency and little amount of clock, filtering speed of a\nfirewall also depends on the other components, such as packet FIFO buffer. Fast\nand reliable FIFO buffer is needed to support the PCE. This PCE also is not\ncompleted with rule update mechanism yet. This proposed PCE is tested as a\ncomponent of FPGA-based firewall to filter Ethernet packet with FPGA DE2 Board\nusing NIOS II platform.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 13:59:39 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Wicaksana", "Arief", "", "ITB"], ["Sasongko", "Arif", "", "ITB"]]}, {"id": "1611.07511", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "Can Broken Multicore Hardware be Mended?", "comments": "3 figures; a Viewpoint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A suggestion is made for mending multicore hardware, which has been diagnosed\nas broken.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 19:14:05 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "1611.09446", "submitter": "P Balasubramanian", "authors": "P Balasubramanian, N E Mastorakis", "title": "FPGA Based Implementation of Distributed Minority and Majority Voting\n  Based Redundancy for Mission and Safety-Critical Applications", "comments": null, "journal-ref": "International Journal of Circuits and Electronics, 2016, vol. 1,\n  pp. 185-190", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic circuits and systems used in mission and safety-critical\napplications usually employ redundancy in the design to overcome arbitrary\nfault(s) or failure(s) and guarantee the correct operation. In this context,\nthe distributed minority and majority voting based redundancy (DMMR) scheme\nforms an efficient alternative to the conventional N-modular redundancy (NMR)\nscheme for implementing mission and safety-critical circuits and systems by\nsignificantly minimizing their weight and design cost and also their design\nmetrics whilst providing a similar degree of fault tolerance. This article\npresents the first FPGAs based implementation of example DMMR circuits and\ncompares it with counterpart NMR circuits on the basis of area occupancy and\ncritical path delay viz. area-delay product (ADP). The example DMMR circuits\nand counterpart NMR circuits are able to accommodate the faulty or failure\nstates of 2, 3 and 4 function modules. For physical synthesis, two commercial\nXilinx FPGAs viz. Spartan 3E and Virtex 5 corresponding to 90nm and 65nm CMOS\nprocesses, and two radiation-tolerant and military grade Xilinx FPGAs viz. QPro\nVirtex 2 and QPro Virtex E corresponding to 150nm and 180nm CMOS processes were\nconsidered for the NMR and DMMR circuit realizations which employ the 4-by-4\narray multiplier as a representative function module. To achieve a fault\ntolerance of 2 function modules, both the DMMR and the NMR schemes provide near\nsimilar mean ADPs across all the four FPGAs. But while achieving a fault\ntolerance of 3 function modules the DMMR features reduced ADP by 44.5% on\naverage compared to the NMR, and in achieving a fault tolerance of 4 function\nmodules the DMMR reports reduced ADP by 56.5% on average compared to the NMR\nwith respect to all the four FPGAs considered.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 00:48:14 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Balasubramanian", "P", ""], ["Mastorakis", "N E", ""]]}, {"id": "1611.09452", "submitter": "Tiben Che", "authors": "Tiben Che, Gwan Choi", "title": "An Efficient Partial Sums Generator for Constituent Code based\n  Successive Cancellation Decoding of Polar Codes", "comments": "submitted to TCAS II", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the architecture of partial sum generator for constituent\ncodes based polar code decoder. Constituent codes based polar code decoder has\nthe advantage of low latency. However, no purposefully designed partial sum\ngenerator design exists that can yield desired timing for the decoder. We first\nderive the mathematical presentation with the partial sums set $\\bm{\\beta^c}$\nwhich is corresponding to each constituent codes. From this, we concoct a\nshift-register based partial sum generator. Next, the overall architecture and\ndesign details are described, and the overhead compared with conventional\npartial sum generator is evaluated. Finally, the implementation results with\nboth ASIC and FPGA technology and relevant discussions are presented.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 01:28:58 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 04:16:26 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Che", "Tiben", ""], ["Choi", "Gwan", ""]]}, {"id": "1611.09988", "submitter": "Vivek Seshadri", "authors": "Vivek Seshadri and Donghyuk Lee and Thomas Mullins and Hasan Hassan\n  and Amirali Boroumand and Jeremie Kim and Michael A. Kozuch and Onur Mutlu\n  and Phillip B. Gibbons and Todd C. Mowry", "title": "Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise\n  Operations Using DRAM", "comments": "arXiv admin note: text overlap with arXiv:1605.06483", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitwise operations are an important component of modern day programming. Many\nwidely-used data structures (e.g., bitmap indices in databases) rely on fast\nbitwise operations on large bit vectors to achieve high performance.\nUnfortunately, in existing systems, regardless of the underlying architecture\n(e.g., CPU, GPU, FPGA), the throughput of such bulk bitwise operations is\nlimited by the available memory bandwidth.\n  We propose Buddy, a new mechanism that exploits the analog operation of DRAM\nto perform bulk bitwise operations completely inside the DRAM chip. Buddy\nconsists of two components. First, simultaneous activation of three DRAM rows\nthat are connected to the same set of sense amplifiers enables us to perform\nbitwise AND and OR operations. Second, the inverters present in each sense\namplifier enables us to perform bitwise NOT operations, with modest changes to\nthe DRAM array. These two components make Buddy functionally complete. Our\nimplementation of Buddy largely exploits the existing DRAM structure and\ninterface, and incurs low overhead (1% of DRAM chip area).\n  Our evaluations based on SPICE simulations show that, across seven\ncommonly-used bitwise operations, Buddy provides between 10.9X---25.6X\nimprovement in raw throughput and 25.1X---59.5X reduction in energy\nconsumption. We evaluate three real-world data-intensive applications that\nexploit bitwise operations: 1) bitmap indices, 2) BitWeaving, and 3)\nbitvector-based implementation of sets. Our evaluations show that Buddy\nsignificantly outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 03:34:57 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Seshadri", "Vivek", ""], ["Lee", "Donghyuk", ""], ["Mullins", "Thomas", ""], ["Hassan", "Hasan", ""], ["Boroumand", "Amirali", ""], ["Kim", "Jeremie", ""], ["Kozuch", "Michael A.", ""], ["Mutlu", "Onur", ""], ["Gibbons", "Phillip B.", ""], ["Mowry", "Todd C.", ""]]}, {"id": "1611.10316", "submitter": "Mostafa Mahmoud", "authors": "Mostafa Mahmoud and Andreas Moshovos", "title": "Memory Controller Design Under Cloud Workloads", "comments": null, "journal-ref": "2016 IEEE International Symposium on Workload Characterization\n  (IISWC)", "doi": "10.1109/IISWC.2016.7581279", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the behavior of state-of-the-art memory controller designs\nwhen executing scale-out workloads. It considers memory scheduling techniques,\nmemory page management policies, the number of memory channels, and the address\nmapping scheme used. Experimental measurements demonstrate: 1)~Several recently\nproposed memory scheduling policies are not a good match for these scale-out\nworkloads. 2)~The relatively simple First-Ready-First-Come-First-Served\n(FR-FCFS) policy performs consistently better, and 3)~for most of the studied\nworkloads, the even simpler First-Come-First-Served scheduling policy is within\n1\\% of FR-FCFS. 4)~Increasing the number of memory channels offers negligible\nperformance benefits, e.g., performance improves by 1.7\\% on average for\n4-channels vs. 1-channel. 5)~77\\%-90\\% of DRAM rows activations are accessed\nonly once before closure. These observation can guide future development and\noptimization of memory controllers for scale-out workloads.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 19:09:07 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Mahmoud", "Mostafa", ""], ["Moshovos", "Andreas", ""]]}]