[{"id": "1910.00098", "submitter": "Mir Muntasir Hossain", "authors": "Mir Muntasir Hossain, Satyendra N. Biswas", "title": "Analysis and Design of a 32nm FinFET Dynamic Latch Comparator", "comments": "6 pages, 13 figures", "journal-ref": null, "doi": "10.1109/ICAEE48663.2019.8975615", "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Comparators have multifarious applications in various fields, especially used\nin analog to digital converters. Over the years, we have seen many different\ndesigns of single stage, dynamic latch type and double tail type comparators\nbased on CMOS technology, and all of them had to make the tradeoff between\npower consumption and delay time. Meanwhile, to mitigate the short channel\neffects of conventional CMOS based design, FinFET has emerged as the most\npromising alternative by owning the tremendous gate control feature over the\nchannel region. In this paper, we have analyzed the performance of some recent\ndynamic latch type comparators and proposed a new structure of dynamic latch\ncomparator; moreover, 32nm FinFET technology has been considered as the common\nplatform for all of the comparators circuit design. The proposed comparator has\nshown impressive performance in case of power consumption, time delay, power\ndelay product and offset voltage while compared with the other recent\ncomparators through simulations with LTspice.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 06:08:56 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Hossain", "Mir Muntasir", ""], ["Biswas", "Satyendra N.", ""]]}, {"id": "1910.00134", "submitter": "Johnathan Alsop", "authors": "Johnathan Alsop, Matthew D. Sinclair, Srikant Bharadwaj, Alexandru\n  Dutu, Anthony Gutierrez, Onur Kayiran, Michael LeBeane, Sooraj Puthoor,\n  Xianwei Zhang, Tsung Tai Yeh, and Bradford M. Beckmann", "title": "Optimizing GPU Cache Policies for MI Workloads", "comments": "Extended version of short paper published in the 2019 IEEE\n  International Symposium on Workload Characterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine intelligence (MI) applications have emerged as a\nmajor driver for the computing industry. Optimizing these workloads is\nimportant but complicated. As memory demands grow and data movement overheads\nincreasingly limit performance, determining the best GPU caching policy to use\nfor a diverse range of MI workloads represents one important challenge. To\nstudy this, we evaluate 17 MI applications and characterize their behaviors\nusing a range of GPU caching strategies. In our evaluations, we find that the\nchoice of caching policy in GPU caches involves multiple performance trade-offs\nand interactions, and there is no one-size-fits-all GPU caching policy for MI\nworkloads. Based on detailed simulation results, we motivate and evaluate a set\nof cache optimizations that consistently match the performance of the best\nstatic GPU caching policies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 22:18:22 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Alsop", "Johnathan", ""], ["Sinclair", "Matthew D.", ""], ["Bharadwaj", "Srikant", ""], ["Dutu", "Alexandru", ""], ["Gutierrez", "Anthony", ""], ["Kayiran", "Onur", ""], ["LeBeane", "Michael", ""], ["Puthoor", "Sooraj", ""], ["Zhang", "Xianwei", ""], ["Yeh", "Tsung Tai", ""], ["Beckmann", "Bradford M.", ""]]}, {"id": "1910.00197", "submitter": "Siavash Rezaei", "authors": "Siavash Rezaei, Eli Bozorgzadeh, Kanghee Kim", "title": "UltraShare: FPGA-based Dynamic Accelerator Sharing and Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite all the available commercial and open-source frameworks to ease\ndeploying FPGAs in accelerating applications, the current schemes fail to\nsupport sharing multiple accelerators among various applications. There are\nthree main features that an accelerator sharing scheme requires to support:\nexploiting dynamic parallelism of multiple accelerators for a single\napplication, sharing accelerators among multiple applications, and providing a\nnon-blocking congestion-free environment for applications to invoke the\naccelerators. In this paper, we developed a scalable fully functional hardware\ncontroller, called UltraShare, with a supporting software stack that provides a\ndynamic accelerator sharing scheme through an accelerators grouping mechanism.\nUltraShare allows software applications to fully utilize FPGA accelerators in a\nnon-blocking congestion-free environment. Our experimental results for a simple\nscenario of a combination of three streaming accelerators invocation show an\nimprovement of up to 8x in throughput of the accelerators by removing\naccelerators idle times.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:19:40 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Rezaei", "Siavash", ""], ["Bozorgzadeh", "Eli", ""], ["Kim", "Kanghee", ""]]}, {"id": "1910.00271", "submitter": "He Li", "authors": "He Li and James J. Davis and John Wickerson and George A.\n  Constantinides", "title": "ARCHITECT: Arbitrary-precision Hardware with Digit Elision for Efficient\n  Iterative Compute", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms feature an iterative loop that converges to the result of\ninterest. The numerical operations in such algorithms are generally implemented\nusing finite-precision arithmetic, either fixed- or floating-point, most of\nwhich operate least-significant digit first. This results in a fundamental\nproblem: if, after some time, the result has not converged, is this because we\nhave not run the algorithm for enough iterations or because the arithmetic in\nsome iterations was insufficiently precise? There is no easy way to answer this\nquestion, so users will often over-budget precision in the hope that the answer\nwill always be to run for a few more iterations. We propose a fundamentally new\napproach: with the appropriate arithmetic able to generate results from\nmost-significant digit first, we show that fixed compute-area hardware can be\nused to calculate an arbitrary number of algorithmic iterations to arbitrary\nprecision, with both precision and approximant index increasing in lockstep.\nConsequently, datapaths constructed following our principles demonstrate\nefficiency over their traditional arithmetic equivalents where the latter's\nprecisions are either under- or over-budgeted for the computation of a result\nto a particular accuracy. Use of most-significant digit-first arithmetic\nadditionally allows us to declare certain digits to be stable at runtime,\navoiding their recalculation in subsequent iterations and thereby increasing\nperformance and decreasing memory footprints. Versus arbitrary-precision\niterative solvers without the optimisations we detail herein, we achieve up-to\n16$\\times$ performance speedups and 1.9x memory savings for the evaluated\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:27:44 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "He", ""], ["Davis", "James J.", ""], ["Wickerson", "John", ""], ["Constantinides", "George A.", ""]]}, {"id": "1910.00735", "submitter": "Samaneh Ghandali", "authors": "Samaneh Ghandali, Daniel Holcomb, Christof Paar", "title": "Temperature-Based Hardware Trojan For Ring-Oscillator-Based TRNGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  True random number generators (TRNGs) are essential components of\ncryptographic designs, which are used to generate private keys for encryption\nand authentication, and are used in masking countermeasures. In this work, we\npresent a mechanism to design a stealthy parametric hardware Trojan for a ring\noscillator based TRNG architecture proposed by Yang et al. at ISSCC 2014. Once\nthe Trojan is triggered the malicious TRNG generates predictable non-random\noutputs. Such a Trojan does not require any additional logic (even a single\ngate) and is purely based on subtle manipulations on the sub-transistor level.\nThe underlying concept is to disable the entropy source at high temperature to\ntrigger the Trojan, while ensuring that Trojan-infected TRNG works correctly\nunder normal conditions. We show how an attack can be performed with the\nTrojan-infected TRNG design in which the attacker uses a stochastic Markov\nChain model to predict its reduced-entropy outputs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 18:48:40 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ghandali", "Samaneh", ""], ["Holcomb", "Daniel", ""], ["Paar", "Christof", ""]]}, {"id": "1910.00737", "submitter": "Samaneh Ghandali", "authors": "Samaneh Ghandali, Thorben Moos, Amir Moradi, Christof Paar", "title": "Side-Channel Hardware Trojan for Provably-Secure SCA-Protected\n  Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware Trojans have drawn the attention of academia, industry and\ngovernment agencies. Effective detection mechanisms and countermeasures against\nsuch malicious designs can only be developed when there is a deep understanding\nof how hardware Trojans can be built in practice, in particular Trojans\nspecifically designed to avoid detection. In this work, we present a mechanism\nto introduce an extremely stealthy hardware Trojan into cryptographic\nprimitives equipped with provably-secure first-order side-channel\ncountermeasures. Once the Trojan is triggered, the malicious design exhibits\nexploitable side-channel leakage, leading to successful key recovery attacks.\nGenerally, such a Trojan requires neither addition nor removal of any logic\nwhich makes it extremely hard to detect. On ASICs, it can be inserted by subtle\nmanipulations at the sub-transistor level and on FPGAs by changing the routing\nof particular signals, leading to \\textbf{zero} logic overhead. The underlying\nconcept is based on modifying a securely-masked hardware implementation in such\na way that running the device at a particular clock frequency violates one of\nits essential properties, leading to exploitable leakage. We apply our\ntechnique to a Threshold Implementation of the PRESENT block cipher realized in\ntwo different CMOS technologies, and show that triggering the Trojan makes the\nASIC prototypes vulnerable.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 20:58:15 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ghandali", "Samaneh", ""], ["Moos", "Thorben", ""], ["Moradi", "Amir", ""], ["Paar", "Christof", ""]]}, {"id": "1910.00976", "submitter": "Arish Sateesan", "authors": "S Arish and R.K. Sharma", "title": "An efficient floating point multiplier design for high speed\n  applications using Karatsuba algorithm and Urdhva-Tiryagbhyam algorithm", "comments": "arXiv admin note: text overlap with arXiv:1909.13318", "journal-ref": "2015 International Conference on Signal Processing and\n  Communication (ICSC)", "doi": "10.1109/ICSPCom.2015.7150666", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating point multiplication is a crucial operation in high power computing\napplications such as image processing, signal processing etc. And also\nmultiplication is the most time and power consuming operation. This paper\nproposes an efficient method for IEEE 754 floating point multiplication which\ngives a better implementation in terms of delay and power. A combination of\nKaratsuba algorithm and Urdhva-Tiryagbhyam algorithm (Vedic Mathematics) is\nused to implement unsigned binary multiplier for mantissa multiplication. The\nmultiplier is implemented using Verilog HDL, targeted on Spartan-3E and\nVirtex-4 FPGA.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:37:19 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 09:53:17 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Arish", "S", ""], ["Sharma", "R. K.", ""]]}, {"id": "1910.03075", "submitter": "Rahul Bera", "authors": "Rahul Bera, Anant V. Nori, Onur Mutlu, Sreenivas Subramoney", "title": "DSPatch: Dual Spatial Pattern Prefetcher", "comments": "This work is to appear in MICRO 2019", "journal-ref": null, "doi": "10.1145/3352460.3358325", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High main memory latency continues to limit performance of modern\nhigh-performance out-of-order cores. While DRAM latency has remained nearly the\nsame over many generations, DRAM bandwidth has grown significantly due to\nhigher frequencies, newer architectures (DDR4, LPDDR4, GDDR5) and 3D-stacked\nmemory packaging (HBM). Current state-of-the-art prefetchers do not do well in\nextracting higher performance when higher DRAM bandwidth is available.\nPrefetchers need the ability to dynamically adapt to available bandwidth,\nboosting prefetch count and prefetch coverage when headroom exists and\nthrottling down to achieve high accuracy when the bandwidth utilization is\nclose to peak. To this end, we present the Dual Spatial Pattern Prefetcher\n(DSPatch) that can be used as a standalone prefetcher or as a lightweight\nadjunct spatial prefetcher to the state-of-the-art delta-based Signature\nPattern Prefetcher (SPP). DSPatch builds on a novel and intuitive use of\nmodulated spatial bit-patterns. The key idea is to: (1) represent program\naccesses on a physical page as a bit-pattern anchored to the first \"trigger\"\naccess, (2) learn two spatial access bit-patterns: one biased towards coverage\nand another biased towards accuracy, and (3) select one bit-pattern at run-time\nbased on the DRAM bandwidth utilization to generate prefetches. Across a\ndiverse set of workloads, using only 3.6KB of storage, DSPatch improves\nperformance over an aggressive baseline with a PC-based stride prefetcher at\nthe L1 cache and the SPP prefetcher at the L2 cache by 6% (9% in\nmemory-intensive workloads and up to 26%). Moreover, the performance of\nDSPatch+SPP scales with increasing DRAM bandwidth, growing from 6% over SPP to\n10% when DRAM bandwidth is doubled.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:44:32 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bera", "Rahul", ""], ["Nori", "Anant V.", ""], ["Mutlu", "Onur", ""], ["Subramoney", "Sreenivas", ""]]}, {"id": "1910.03679", "submitter": "Oded Green", "authors": "Oded Green, James Fox, Jeffrey Young, Jun Shirako, David Bader", "title": "Performance Impact of Memory Channels on Sparse and Irregular Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processing is typically considered to be a memory-bound rather than\ncompute-bound problem. One common line of thought is that more available memory\nbandwidth corresponds to better graph processing performance. However, in this\nwork we demonstrate that the key factor in the utilization of the memory system\nfor graph algorithms is not necessarily the raw bandwidth or even the latency\nof memory requests. Instead, we show that performance is proportional to the\nnumber of memory channels available to handle small data transfers with limited\nspatial locality.\n  Using several widely used graph frameworks, including Gunrock (on the GPU)\nand GAPBS \\& Ligra (for CPUs), we evaluate key graph analytics kernels using\ntwo unique memory hierarchies, DDR-based and HBM/MCDRAM. Our results show that\nthe differences in the peak bandwidths of several Pascal-generation GPU memory\nsubsystems aren't reflected in the performance of various analytics.\nFurthermore, our experiments on CPU and Xeon Phi systems demonstrate that the\nnumber of memory channels utilized can be a decisive factor in performance\nacross several different applications. For CPU systems with smaller thread\ncounts, the memory channels can be underutilized while systems with high thread\ncounts can oversaturate the memory subsystem, which leads to limited\nperformance. Finally, we model the potential performance improvements of adding\nmore memory channels with narrower access widths than are found in current\nplatforms, and we analyze performance trade-offs for the two most prominent\ntypes of memory accesses found in graph algorithms, streaming and random\naccesses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 20:39:14 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Green", "Oded", ""], ["Fox", "James", ""], ["Young", "Jeffrey", ""], ["Shirako", "Jun", ""], ["Bader", "David", ""]]}, {"id": "1910.04436", "submitter": "Johannes de Fine Licht", "authors": "Johannes de Fine Licht, Torsten Hoefler", "title": "hlslib: Software Engineering for Hardware Design", "comments": "4 pages extended abstract accepted to H2RC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level synthesis (HLS) tools have brought FPGA development into the\nmainstream, by allowing programmers to design architectures using familiar\nlanguages such as C, C++, and OpenCL. While the move to these languages has\nbrought significant benefits, many aspects of traditional software engineering\nare still unsupported, or not exploited by developers in practice. Furthermore,\ndesigning reconfigurable architectures requires support for hardware\nconstructs, such as FIFOs and shift registers, that are not native to\nCPU-oriented languages. To address this gap, we have developed hlslib, a\ncollection of software tools, plug-in hardware modules, and code samples,\ndesigned to enhance the productivity of HLS developers. The goal of hlslib is\ntwo-fold: first, create a community-driven arena of bleeding edge development,\nwhich can move quicker, and provides more powerful abstractions than what is\nprovided by vendors; and second, collect a wide range of example codes, both\nminimal proofs of concept, and larger, real-world applications, that can be\nreused directly or inspire other work. hlslib is offered as an open source\nlibrary, containing CMake files, C++ headers, convenience scripts, and examples\ncodes, and is receptive to any contribution that can benefit HLS developers,\nthrough general functionality or examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:44:41 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Licht", "Johannes de Fine", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1910.04683", "submitter": "Kanika Monga", "authors": "Kanika Monga, Akul Malhotra, Nitin Chaturvedi, S. Gurunayaranan", "title": "A Novel Low Power Non-Volatile SRAM Cell with Self Write Termination", "comments": "Presented at: THE 10th INTERNATIONAL CONFERENCE ON COMPUTING,\n  COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT), 2019 Other information: 4\n  Pages, 2 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-volatile SRAM cell is proposed for low power applications using Spin\nTransfer Torque-Magnetic Tunnel Junction (STT-MTJ) devices. This novel cell\noffers non-volatile storage, thus allowing selected blocks of SRAM to be\nswitched off during standby operation. To further increase the power savings, a\nwrite termination circuit is designed which detects completion of MTJ write and\ncloses the bidirectional current path for the MTJ. A reduction of 25.81% in the\nnumber of transistors and a reduction of 2.95% in the power consumption is\nachieved in comparison to prior work on write termination circuits.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:06:24 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Monga", "Kanika", ""], ["Malhotra", "Akul", ""], ["Chaturvedi", "Nitin", ""], ["Gurunayaranan", "S.", ""]]}, {"id": "1910.04882", "submitter": "Pritam Majumder", "authors": "Pritam Majumder, Sungkeun Kim, Jiayi Huang, Ki Hwan Yum, Eun Jung Kim", "title": "Remote Control: A Simple Deadlock Avoidance Scheme for Modular System on\n  Chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in design cost and complexity have motivated designers to adopt\nmodular design of System on Chip (SoC) by integrating independently designed\nsmall chiplets. However, it introduces new challenges for correctness\nvalidation, increasing chances of forming deadlock in the system involving\nmultiple chiplets. Although there have been many solutions available for\ndeadlock freedom in flat networks, the study on deadlock issue in chiplet-based\nsystems is still in its infancy. A recent study suggests adding extra turn\nrestrictions as a viable solution for this problem. However, imposing extra\nturn restrictions reduces chiplet design flexibility and interposer design\ncomplexity. In addition, it may lead to non-minimal route and traffic imbalance\nforming hotspots, resulting in high latency and low throughput.\n  We propose Remote Control (RC), a simple routing oblivious deadlock avoidance\nscheme. Our proposal is based on two key observations. First, packets with\ndestinations in the current chiplet are blocked by packets with destinations\noutside the chiplet. Second, deadlock always involves multiple boundary\nrouters. Hence, we segregate different traffics to alleviate mutual blocking at\nthe chiplet's boundary routers. Along with guarantee of deadlock freedom and\nperformance enhancements, our simple RC scheme also provides more routing\nflexibility to both chiplet and SoC designers, as compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:24:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Majumder", "Pritam", ""], ["Kim", "Sungkeun", ""], ["Huang", "Jiayi", ""], ["Yum", "Ki Hwan", ""], ["Kim", "Eun Jung", ""]]}, {"id": "1910.04910", "submitter": "Ankit Wagle", "authors": "Ankit Wagle, Gian Singh, Jinghua Yang, Sunil Khatri, Sarma Vrudhula", "title": "Threshold Logic in a Flash", "comments": null, "journal-ref": null, "doi": "10.1109/ICCD46524.2019.00081", "report-no": null, "categories": "cs.ET cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel design of a threshold logic gate (a binary\nperceptron) and its implementation as a standard cell. This new cell structure,\nreferred to as flash threshold logic (FTL), uses floating gate (flash)\ntransistors to realize the weights associated with a threshold function. The\nthreshold voltages of the flash transistors serve as a proxy for the weights.\nAn FTL cell can be equivalently viewed as a multi-input, edge-triggered\nflipflop which computes a threshold function on a clock edge. Consequently, it\ncan be used in the automatic synthesis of ASICs. The use of flash transistors\nin the FTL cell allows programming of the weights after fabrication, thereby\npreventing discovery of its function by a foundry or by reverse engineering.\nThis paper focuses on the design and characteristics of the FTL cell. We\npresent a novel method for programming the weights of an FTL cell for a\nspecified threshold function using a modified perceptron learning algorithm.\nThe algorithm is further extended to select weights to maximize the robustness\nof the design in the presence of process variations. The FTL circuit was\ndesigned in 40nm technology and simulations with layout-extracted parasitics\nincluded, demonstrate significant improvements in the area (79.7%), power\n(61.1%), and performance (42.5%) when compared to the equivalent\nimplementations of the same function in conventional static CMOS design. Weight\nselection targeting robustness is demonstrated using Monte Carlo simulations.\nThe paper also shows how FTL cells can be used for fixing timing errors after\nfabrication.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:21:16 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wagle", "Ankit", ""], ["Singh", "Gian", ""], ["Yang", "Jinghua", ""], ["Khatri", "Sunil", ""], ["Vrudhula", "Sarma", ""]]}, {"id": "1910.05100", "submitter": "Arish Sateesan", "authors": "Arish S, R.K. Sharma", "title": "Run-Time-Reconfigurable Multi-Precision Floating-Point Matrix Multiplier\n  Intellectual Property Core on FPGA", "comments": null, "journal-ref": "Circuits, Systems, and Signal Processing, March 2017, Volume 36,\n  Issue 3", "doi": "10.1007/s00034-016-0335-2", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays world, high-power computing applications such as image processing,\ndigital signal processing, graphics, and robotics require enormous computing\npower. These applications use matrix operations, especially matrix\nmultiplication. Multiplication operations require a lot of computational time\nand are also complex in design. We can use field-programmable gate arrays as\nlow-cost hardware accelerators along with a low-cost general-purpose processor\ninstead of a high-cost application-specific processor for such applications. In\nthis work, we employ an efficient Strassens algorithm for matrix multiplication\nand a highly efficient run-time-reconfigurable floating-point multiplier for\nmatrix element multiplication. The run-time-reconfigurable floating-point\nmultiplier is implemented with custom floating-point format for\nvariable-precision applications. A very efficient combination of Karatsuba\nalgorithm and Urdhva Tiryagbhyam algorithm is used to implement the binary\nmultiplier. This design can effectively adjust the power and delay requirements\naccording to different accuracy requirements by reconfiguring itself during run\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 12:11:32 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 08:53:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["S", "Arish", ""], ["Sharma", "R. K.", ""]]}, {"id": "1910.05398", "submitter": "Jayneel Gandhi", "authors": "Reto Achermann, Ashish Panwar, Abhishek Bhattacharjee, Timothy Roscoe,\n  Jayneel Gandhi", "title": "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-socket machines with 1-100 TBs of physical memory are becoming\nprevalent. Applications running on multi-socket machines suffer non-uniform\nbandwidth and latency when accessing physical memory. Decades of research have\nfocused on data allocation and placement policies in NUMA settings, but there\nhave been no studies on the question of how to place page-tables amongst\nsockets. We make the case for explicit page-table allocation policies and show\nthat page-table placement is becoming crucial to overall performance. We\npropose Mitosis to mitigate NUMA effects on page-table walks by transparently\nreplicating and migrating page-tables across sockets without application\nchanges. This reduces the frequency of accesses to remote NUMA nodes when\nperforming page-table walks. Mitosis uses two components: (i) a mechanism to\nenable efficient page-table replication and migration; and (ii) policies for\nprocesses to efficiently manage and control page-table replication and\nmigration. We implement Mitosis in Linux and evaluate its benefits on real\nhardware. Mitosis improves performance for large-scale multi-socket workloads\nby up to 1.34x by replicating page-tables across sockets. Moreover, it improves\nperformance by up to 3.24x in cases when the OS migrates a process across\nsockets by enabling cross-socket page-table migration.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 20:26:14 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 06:36:11 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Achermann", "Reto", ""], ["Panwar", "Ashish", ""], ["Bhattacharjee", "Abhishek", ""], ["Roscoe", "Timothy", ""], ["Gandhi", "Jayneel", ""]]}, {"id": "1910.05683", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen", "title": "Hardware/Software Codesign for Training/Testing Multiple Neural Networks\n  on Multiple FPGAs", "comments": "It was submitted without proper permission granted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most neural network designs for FPGAs are inflexible. In this paper, we\npropose a flexible VHDL structure that would allow any neural network to be\nimplemented on multiple FPGAs. Moreover, the VHDL structure allows for testing\nas well as training multiple neural networks. The VHDL design consists of\nmultiple processor groups. There are two types of processor groups: Mini Vector\nMachine Processor Group and Activation Processor Group. Each processor group\nconsists of individual Mini Vector Machines and Activation Processor. The Mini\nVector Machines apply vector operations to the data, while the Activation\nProcessors apply activation functions to the data. A ring buffer was\nimplemented to connect the various processor groups.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 04:12:32 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 22:26:16 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yuen", "Brosnan", ""]]}, {"id": "1910.06672", "submitter": "Hasan Hassan", "authors": "Syed M. A. H. Jafri, Hasan Hassan, Ahmed Hemani, Onur Mutlu", "title": "Refresh Triggered Computation: Improving the Energy Efficiency of\n  Convolutional Neural Network Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To employ a Convolutional Neural Network (CNN) in an energy-constrained\nembedded system, it is critical for the CNN implementation to be highly energy\nefficient. Many recent studies propose CNN accelerator architectures with\ncustom computation units that try to improve energy-efficiency and performance\nof CNNs by minimizing data transfers from DRAM-based main memory. However, in\nthese architectures, DRAM is still responsible for half of the overall energy\nconsumption of the system, on average. A key factor of the high energy\nconsumption of DRAM is the refresh overhead, which is estimated to consume 40%\nof the total DRAM energy. In this paper, we propose a new mechanism, Refresh\nTriggered Computation (RTC), that exploits the memory access patterns of CNN\napplications to reduce the number of refresh operations. We propose three RTC\ndesigns (min-RTC, mid-RTC, and full-RTC), each of which requires a different\nlevel of aggressiveness in terms of customization to the DRAM subsystem. All of\nour designs have small overhead. Even the most aggressive RTC design (i.e.,\nfull-RTC) imposes an area overhead of only 0.18% in a 16 Gb DRAM chip and can\nhave less overhead for denser chips. Our experimental evaluation on six\nwell-known CNNs show that RTC reduces average DRAM energy consumption by 24.4%\nand 61.3%, for the least aggressive and the most aggressive RTC\nimplementations, respectively. Besides CNNs, we also evaluate our RTC mechanism\non three workloads from other domains. We show that RTC saves 31.9% and 16.9%\nDRAM energy for Face Recognition and Bayesian Confidence Propagation Neural\nNetwork (BCPNN), respectively. We believe RTC can be applied to other\napplications whose memory access patterns remain predictable for a sufficiently\nlong time.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 12:02:52 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 13:51:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Jafri", "Syed M. A. H.", ""], ["Hassan", "Hasan", ""], ["Hemani", "Ahmed", ""], ["Mutlu", "Onur", ""]]}, {"id": "1910.06674", "submitter": "Alexey Lastovetsky", "authors": "Semyon Khokhriakov, Ravi Reddy Manumachu, Alexey Lastovetsky", "title": "Modern Multicore CPUs are not Energy Proportional: Opportunity for\n  Bi-objective Optimization for Performance and Energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy proportionality is the key design goal followed by architects of\nmodern multicore CPUs. One of its implications is that optimization of an\napplication for performance will also optimize it for energy. In this work, we\nshow that energy proportionality does not hold true for multicore CPUs. This\nfinding creates the opportunity for bi-objective optimization of applications\nfor performance and energy. We propose and study the first application-level\nmethod for bi-objective optimization of multithreaded data-parallel\napplications for performance and energy. The method uses two decision\nvariables, the number of identical multithreaded kernels (threadgroups)\nexecuting the application and the number of threads in each threadgroup, with\nthe workload always partitioned equally between the threadgroups. We\nexperimentally demonstrate the efficiency of the method using four highly\noptimized multithreaded data-parallel applications, 2D fast Fourier transform\nbased on FFTW and Intel MKL, and dense matrix-matrix multiplication using\nOpenBLAS and Intel MKL. Four modern multicore CPUs are used in the experiments.\nThe experiments show that optimization for performance alone results in the\nincrease in dynamic energy consumption by up to 89% and optimization for\ndynamic energy alone degrades the performance by up to 49%. By solving the\nbi-objective optimization problem, the method determines up to 11 globally\nPareto-optimal solutions. Finally, we propose a qualitative dynamic energy\nmodel employing performance monitoring counters as parameters, which we use to\nexplain the discovered energy nonproportionality and the Pareto-optimal\nsolutions determined by our method. The model shows that the energy\nnonproportionality in our case is due to the activity of the data translation\nlookaside buffer (dTLB), which is disproportionately energy expensive.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 12:17:21 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Khokhriakov", "Semyon", ""], ["Manumachu", "Ravi Reddy", ""], ["Lastovetsky", "Alexey", ""]]}, {"id": "1910.06726", "submitter": "Hamid Reza Zohouri", "authors": "Hamid Reza Zohouri, Satoshi Matsuoka", "title": "The Memory Controller Wall: Benchmarking the Intel FPGA SDK for OpenCL\n  Memory Interface", "comments": "Published at H2RC'19: Fifth International Workshop on Heterogeneous\n  High-performance Reconfigurable Computing held in conjunction with SC'19", "journal-ref": null, "doi": "10.1109/H2RC49586.2019.00007", "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supported by their high power efficiency and recent advancements in High\nLevel Synthesis (HLS), FPGAs are quickly finding their way into HPC and cloud\nsystems. Large amounts of work have been done so far on loop and area\noptimizations for different applications on FPGAs using HLS. However, a\ncomprehensive analysis of the behavior and efficiency of the memory controller\nof FPGAs is missing in literature, which becomes even more crucial when the\nlimited memory bandwidth of modern FPGAs compared to their GPU counterparts is\ntaken into account. In this work, we will analyze the memory interface\ngenerated by Intel FPGA SDK for OpenCL with different configurations for\ninput/output arrays, vector size, interleaving, kernel programming model,\non-chip channels, operating frequency, padding, and multiple types of\noverlapped blocking. Our results point to multiple shortcomings in the memory\ncontroller of Intel FPGAs, especially with respect to memory access alignment,\nthat can hinder the programmer's ability in maximizing memory performance in\ntheir design. For some of these cases, we will provide work-arounds to improve\nmemory bandwidth efficiency; however, a general solution will require major\nchanges in the memory controller itself.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:32:19 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:55:15 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zohouri", "Hamid Reza", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1910.07408", "submitter": "Nina Engelhardt", "authors": "Nina Engelhardt and Hayden K.-H. So", "title": "GraVF-M: Graph Processing System Generation for Multi-FPGA Platforms", "comments": null, "journal-ref": "ACM Trans. Reconfigurable Technol. Syst. 12, 4, Article 21\n  (November 2019)", "doi": "10.1145/3357596", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the irregular nature of connections in most graph datasets,\npartitioning graph analysis algorithms across multiple computational nodes that\ndo not share a common memory inevitably leads to large amounts of interconnect\ntraffic. Previous research has shown that FPGAs can outcompete software-based\ngraph processing in shared memory contexts, but it remains an open question if\nthis advantage can be maintained in distributed systems.\n  In this work, we present GraVF-M, a framework designed to ease the\nimplementation of FPGA-based graph processing accelerators for multi-FPGA\nplatforms with distributed memory. Based on a lightweight description of the\nalgorithm kernel, the framework automatically generates optimized RTL code for\nthe whole multi-FPGA design. We exploit an aspect of the programming model to\npresent a familiar message-passing paradigm to the user, while under the hood\nimplementing a more efficient architecture that can reduce the necessary\ninter-FPGA network traffic by a factor equal to the average degree of the input\ngraph. A performance model based on a theoretical analysis of the factors\ninfluencing performance serves to evaluate the efficiency of our\nimplementation. With a throughput of up to 5.8 GTEPS (billions of traversed\nedges per second) on a 4-FPGA system, the designs generated by GraVF-M compare\nfavorably to state-of-the-art frameworks from the literature and reach 94% of\nthe projected performance limit of the system.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 10:09:14 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Engelhardt", "Nina", ""], ["So", "Hayden K. -H.", ""]]}, {"id": "1910.07557", "submitter": "Utsav Banerjee", "authors": "Utsav Banerjee and Tenzin S. Ukyab and Anantha P. Chandrakasan", "title": "Sapphire: A Configurable Crypto-Processor for Post-Quantum Lattice-based\n  Protocols", "comments": null, "journal-ref": "IACR Transactions on Cryptographic Hardware and Embedded Systems,\n  2019(4), pp. 17-61", "doi": "10.13154/tches.v2019.i4.17-61", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public key cryptography protocols, such as RSA and elliptic curve\ncryptography, will be rendered insecure by Shor's algorithm when large-scale\nquantum computers are built. Cryptographers are working on quantum-resistant\nalgorithms, and lattice-based cryptography has emerged as a prime candidate.\nHowever, high computational complexity of these algorithms makes it challenging\nto implement lattice-based protocols on low-power embedded devices. To address\nthis challenge, we present Sapphire - a lattice cryptography processor with\nconfigurable parameters. Efficient sampling, with a SHA-3-based PRNG, provides\ntwo orders of magnitude energy savings; a single-port RAM-based number\ntheoretic transform memory architecture is proposed, which provides 124k-gate\narea savings; while a low-power modular arithmetic unit accelerates polynomial\ncomputations. Our test chip was fabricated in TSMC 40nm low-power CMOS process,\nwith the Sapphire cryptographic core occupying 0.28 mm2 area consisting of 106k\nlogic gates and 40.25 KB SRAM. Sapphire can be programmed with custom\ninstructions for polynomial arithmetic and sampling, and it is coupled with a\nlow-power RISC-V micro-processor to demonstrate NIST Round 2 lattice-based\nCCA-secure key encapsulation and signature protocols Frodo, NewHope, qTESLA,\nCRYSTALS-Kyber and CRYSTALS-Dilithium, achieving up to an order of magnitude\nimprovement in performance and energy-efficiency compared to state-of-the-art\nhardware implementations. All key building blocks of Sapphire are constant-time\nand secure against timing and simple power analysis side-channel attacks. We\nalso discuss how masking-based DPA countermeasures can be implemented on the\nSapphire core without any changes to the hardware.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 18:08:21 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:04:17 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Banerjee", "Utsav", ""], ["Ukyab", "Tenzin S.", ""], ["Chandrakasan", "Anantha P.", ""]]}, {"id": "1910.08666", "submitter": "Arsalan Shahid", "authors": "Arsalan Shahid, Muhammad Tayyab, Muhammad Yasir Qadri, Nadia N. Qadri,\n  and Jameel Ahmed", "title": "Analytical models of Energy and Throughput for Caches in MPSoCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  General trends in computer architecture are shifting more towards\nparallelism. Multicore architectures have proven to be a major step in\nprocessor evolution. With the advancement in multicore architecture,\nresearchers are focusing on finding different solutions to fully utilize the\npower of multiple cores. With an ever-increasing number of cores on a chip, the\nrole of cache memory has become pivotal. An ideal memory configuration should\nbe both large and fast, however, in fact, system architects have to strike a\nbalance between the size and access time of the memory hierarchy. It is\nimportant to know the impact of a particular cache configuration on the\nthroughput and energy consumption of the system at design time. This paper\npresents an enhanced version of previously proposed cache energy and throughput\nmodels for multicore systems. These models use significantly a smaller number\nof input parameters as compared to other models. This paper also validates the\nproposed models through cycle accurate simulator and a renowned processor power\nestimator. The results show that the proposed energy models provide accuracy\nwithin a maximum error range of 10% for single-core processors and around 5%\nfor MPSoCs, and the throughput models result in a maximum error of up to 11.5%\nfor both single and multicore architectures.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 00:21:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shahid", "Arsalan", ""], ["Tayyab", "Muhammad", ""], ["Qadri", "Muhammad Yasir", ""], ["Qadri", "Nadia N.", ""], ["Ahmed", "Jameel", ""]]}, {"id": "1910.08683", "submitter": "Elham Azari", "authors": "Elham Azari and Sarma Vrudhula", "title": "ELSA: A Throughput-Optimized Design of an LSTM Accelerator for\n  Energy-Constrained Devices", "comments": null, "journal-ref": null, "doi": "10.1145/3366634", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next significant step in the evolution and proliferation of artificial\nintelligence technology will be the integration of neural network (NN) models\nwithin embedded and mobile systems. This calls for the design of compact,\nenergy efficient NN models in silicon. In this paper, we present a scalable\nASIC design of an LSTM accelerator named ELSA, that is suitable for\nenergy-constrained devices. It includes several architectural innovations to\nachieve small area and high energy efficiency. To reduce the area and power\nconsumption of the overall design, the compute-intensive units of ELSA employ\napproximate multiplications and still achieve high performance and accuracy.\nThe performance is further improved through efficient synchronization of the\nelastic pipeline stages to maximize the utilization. The paper also includes a\nperformance model of ELSA, as a function of the hidden nodes and time steps,\npermitting its use for the evaluation of any LSTM application. ELSA was\nimplemented in RTL and was synthesized and placed and routed in 65nm\ntechnology. Its functionality is demonstrated for language modeling-a common\napplication of LSTM. ELSA is compared against a baseline implementation of an\nLSTM accelerator with standard functional units and without any of the\narchitectural innovations of ELSA. The paper demonstrates that ELSA can achieve\nsignificant improvements in power, area and energy-efficiency when compared to\nthe baseline design and several ASIC implementations reported in the\nliterature, making it suitable for use in embedded systems and real-time\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 02:49:50 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Azari", "Elham", ""], ["Vrudhula", "Sarma", ""]]}, {"id": "1910.09020", "submitter": "Mohammed Alser", "authors": "Mohammed Alser, Taha Shahroodi, Juan Gomez-Luna, Can Alkan, and Onur\n  Mutlu", "title": "SneakySnake: A Fast and Accurate Universal Genome Pre-Alignment Filter\n  for CPUs, GPUs, and FPGAs", "comments": "To appear in Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: We introduce SneakySnake, a highly parallel and highly accurate\npre-alignment filter that remarkably reduces the need for computationally\ncostly sequence alignment. The key idea of SneakySnake is to reduce the\napproximate string matching (ASM) problem to the single net routing (SNR)\nproblem in VLSI chip layout. In the SNR problem, we are interested in finding\nthe optimal path that connects two terminals with the least routing cost on a\nspecial grid layout that contains obstacles. The SneakySnake algorithm quickly\nsolves the SNR problem and uses the found optimal path to decide whether or not\nperforming sequence alignment is necessary. Reducing the ASM problem into SNR\nalso makes SneakySnake efficient to implement on CPUs, GPUs, and FPGAs.\nResults: SneakySnake significantly improves the accuracy of pre-alignment\nfiltering by up to four orders of magnitude compared to the state-of-the-art\npre-alignment filters, Shouji, GateKeeper, and SHD. For short sequences,\nSneakySnake accelerates Edlib (state-of-the-art implementation of Myers's\nbit-vector algorithm) and Parasail (state-of-the-art sequence aligner with a\nconfigurable scoring function), by up to 37.7x and 43.9x (>12x on average),\nrespectively, with its CPU implementation, and by up to 413x and 689x (>400x on\naverage), respectively, with FPGA and GPU acceleration. For long sequences, the\nCPU implementation of SneakySnake accelerates Parasail and KSW2 (sequence\naligner of minimap2) by up to 979x (276.9x on average) and 91.7x (31.7x on\naverage), respectively. As SneakySnake does not replace sequence alignment,\nusers can still obtain all capabilities (e.g., configurable scoring functions)\nof the aligner of their choice, unlike existing acceleration efforts that\nsacrifice some aligner capabilities. Availability:\nhttps://github.com/CMU-SAFARI/SneakySnake\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 16:48:05 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 10:47:00 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 20:38:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Alser", "Mohammed", ""], ["Shahroodi", "Taha", ""], ["Gomez-Luna", "Juan", ""], ["Alkan", "Can", ""], ["Mutlu", "Onur", ""]]}, {"id": "1910.10075", "submitter": "Xuan Guo", "authors": "Yiren Zhao, Xitong Gao, Xuan Guo, Junyi Liu, Erwei Wang, Robert\n  Mullins, Peter Y. K. Cheung, George Constantinides, Cheng-Zhong Xu", "title": "Automatic Generation of Multi-precision Multi-arithmetic CNN\n  Accelerators for FPGAs", "comments": "To be published in International Conference on Field Programmable\n  Technology 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep Convolutional Neural Networks (CNNs) are computationally\ndemanding, yet real applications often require high throughput and low latency.\nTo help tackle these problems, we propose Tomato, a framework designed to\nautomate the process of generating efficient CNN accelerators. The generated\ndesign is pipelined and each convolution layer uses different arithmetics at\nvarious precisions. Using Tomato, we showcase state-of-the-art multi-precision\nmulti-arithmetic networks, including MobileNet-V1, running on FPGAs. To our\nknowledge, this is the first multi-precision multi-arithmetic auto-generation\nframework for CNNs. In software, Tomato fine-tunes pretrained networks to use a\nmixture of short powers-of-2 and fixed-point weights with a minimal loss in\nclassification accuracy. The fine-tuned parameters are combined with the\ntemplated hardware designs to automatically produce efficient inference\ncircuits in FPGAs. We demonstrate how our approach significantly reduces model\nsizes and computation complexities, and permits us to pack a complete ImageNet\nnetwork onto a single FPGA without accessing off-chip memories for the first\ntime. Furthermore, we show how Tomato produces implementations of networks with\nvarious sizes running on single or multiple FPGAs. To the best of our\nknowledge, our automatically generated accelerators outperform closest\nFPGA-based competitors by at least 2-4x for lantency and throughput; the\ngenerated accelerator runs ImageNet classification at a rate of more than 3000\nframes per second.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:39:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhao", "Yiren", ""], ["Gao", "Xitong", ""], ["Guo", "Xuan", ""], ["Liu", "Junyi", ""], ["Wang", "Erwei", ""], ["Mullins", "Robert", ""], ["Cheung", "Peter Y. K.", ""], ["Constantinides", "George", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1910.10234", "submitter": "Kunal Kishore Korgaonkar", "authors": "Kunal Korgaonkar, Ronny Ronen, Anupam Chattopadhyay, Shahar Kvatinsky", "title": "The Bitlet Model: Defining a Litmus Test for the Bitwise\n  Processing-in-Memory Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an analytical modeling tool called Bitlet that can be\nused, in a parameterized fashion, to understand the affinity of workloads to\nprocessing-in-memory (PIM) as opposed to traditional computing. The tool\nuncovers interesting trade-offs between operation complexity (cycles required\nto perform an operation through PIM) and other key parameters, such as system\nmemory bandwidth, data transfer size, the extent of data alignment, and\neffective memory capacity involved in PIM computations. Despite its simplicity,\nthe model has already proven useful. In the future, we intend to extend and\nrefine Bitlet to further increase its utility.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:14:16 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Korgaonkar", "Kunal", ""], ["Ronen", "Ronny", ""], ["Chattopadhyay", "Anupam", ""], ["Kvatinsky", "Shahar", ""]]}, {"id": "1910.10776", "submitter": "Onur Mutlu", "authors": "Konstantinos Kanellopoulos, Nandita Vijaykumar, Christina Giannoula,\n  Roknoddin Azizi, Skanda Koppula, Nika Mansouri Ghiasi, Taha Shahroodi, Juan\n  Gomez Luna and Onur Mutlu", "title": "SMASH: Co-designing Software Compression and Hardware-Accelerated\n  Indexing for Efficient Sparse Matrix Operations", "comments": null, "journal-ref": null, "doi": "10.1145/3352460.3358286", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important workloads, such as machine learning and graph analytics\napplications, heavily involve sparse linear algebra operations. These\noperations use sparse matrix compression as an effective means to avoid storing\nzeros and performing unnecessary computation on zero elements. However,\ncompression techniques like Compressed Sparse Row (CSR) that are widely used\ntoday introduce significant instruction overhead and expensive pointer-chasing\noperations to discover the positions of the non-zero elements. In this paper,\nwe identify the discovery of the positions (i.e., indexing) of non-zero\nelements as a key bottleneck in sparse matrix-based workloads, which greatly\nreduces the benefits of compression. We propose SMASH, a hardware-software\ncooperative mechanism that enables highly-efficient indexing and storage of\nsparse matrices. The key idea of SMASH is to explicitly enable the hardware to\nrecognize and exploit sparsity in data. To this end, we devise a novel software\nencoding based on a hierarchy of bitmaps. This encoding can be used to\nefficiently compress any sparse matrix, regardless of the extent and structure\nof sparsity. At the same time, the bitmap encoding can be directly interpreted\nby the hardware. We design a lightweight hardware unit, the Bitmap Management\nUnit (BMU), that buffers and scans the bitmap hierarchy to perform\nhighly-efficient indexing of sparse matrices. SMASH exposes an expressive and\nrich ISA to communicate with the BMU, which enables its use in accelerating any\nsparse matrix computation. We demonstrate the benefits of SMASH on four use\ncases that include sparse matrix kernels and graph analytics applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:37:12 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kanellopoulos", "Konstantinos", ""], ["Vijaykumar", "Nandita", ""], ["Giannoula", "Christina", ""], ["Azizi", "Roknoddin", ""], ["Koppula", "Skanda", ""], ["Ghiasi", "Nika Mansouri", ""], ["Shahroodi", "Taha", ""], ["Luna", "Juan Gomez", ""], ["Mutlu", "Onur", ""]]}, {"id": "1910.10794", "submitter": "Ayoosh Bansal", "authors": "Ayoosh Bansal, Chance Coats, Evan Lissoos and Benjamin Schreiber", "title": "Sidebar: Scratchpad Based Communication Between CPUs and Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware accelerators for neural networks have shown great promise for both\nperformance and power. These accelerators are at their most efficient when\noptimized for a fixed functionality. But this inflexibility limits the\nlongevity of the hardware itself as the underlying neural network algorithms\nand structures undergo improvements and changes. We propose and evaluate a\nflexible design paradigm for accelerators with a close coordination with host\nprocessors. The relatively static matrix operations are implemented in\nspecialized accelerators while fast-evolving functions, such as activations,\nare computed on the host processor. This architecture is enabled by a low\nlatency shared buffer we call Sidebar. Sidebar memory is shared between the\naccelerator and host, exists outside of program address space and holds\nintermediate data only. We show that a generalised DMA dependent flexible\naccelerator design performs poorly in both perf and energy as compared to an\nequivalent fixed function accelerator. Sidebar based accelerator design\nachieves near identical performance and energy to equivalent fixed function\naccelerator while still providing all the flexibility of computing activations\non the host processor.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:07:40 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Bansal", "Ayoosh", ""], ["Coats", "Chance", ""], ["Lissoos", "Evan", ""], ["Schreiber", "Benjamin", ""]]}, {"id": "1910.11253", "submitter": "Dimitrios Stathis", "authors": "Dimitrios Stathis, Panagiotis Chaourani, Syed M. A. H. Jafri, Ahmed\n  Hemani", "title": "Regional Clock Tree Generation by Abutment in Synchoros VLSI Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchoros VLSI design style has been proposed as an alternative to standard\ncell-based design. Standard cells are replaced by synchoros large grain VLSI\ndesign objects called SiLago blocks. This new design style enables end-to-end\nautomation of large scale designs by abutting the SiLago blocks to eliminate\nlogic and physical synthesis for the end-users. A key problem in this\nautomation process is the generation of regional clock tree. Synchoros design\nstyle requires that the clock tree should emerge by abutting its fragments. The\nclock tree fragments are absorbed in the SiLago blocks as a one-time\nengineering effort. The clock tree should not be ad-hoc, but a structured and\npredictable design whose cost metrics are known. Here, we present a new clock\ntree design that is compatible with the synchoros design style. The proposed\ndesign has been verified with static timing analysis and compared against\nfunctionally equivalent clock tree synthesised by the commercial EDA tools. The\nscheme is scalable and, in principle, can generate arbitrarily complex designs.\nIn this paper, we show as a proof of concept that a regional clock tree can be\ncreated by abutment. We prove that with the help of the generated clock tree,\nit is possible to generate valid VLSI designs from 0.5 to ~2 million gates. The\nresulting generated designs do not need a separate regional clock tree\nsynthesis. More critically, the synthesised design is correct by construction\nand requires no further verification. In contrast, the state-of-the-art\nhierarchical synthesis flow requires synthesis of the regional clock tree.\nAdditionally, the conventional clock tree and its design needs a verification\nstep because it lacks predictability. The results also demonstrate that the\ncapacitance, slew and the ability to balance skew of the clock tree created by\nabutment is comparable to the one generated by commercial EDA tools.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:55:48 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:41:50 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Stathis", "Dimitrios", ""], ["Chaourani", "Panagiotis", ""], ["Jafri", "Syed M. A. H.", ""], ["Hemani", "Ahmed", ""]]}, {"id": "1910.11566", "submitter": "Ronan Lashermes", "authors": "Thomas Trouchkine, S\\'ebanjila Kevin Bukasa, Mathieu Escouteloup,\n  Ronan Lashermes, Guillaume Bouffard", "title": "Electromagnetic fault injection against a System-on-Chip, toward new\n  micro-architectural fault models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electromagnetic fault injection (EMFI) is a well known technique used to\ndisturb the behaviour of a chip for weakening its security. These attacks are\nmostly done on simple microcontrollers. On these targets, the fault effects are\nrelatively simple and understood. Exploiting EMFI on modern system-on-chips\n(SoCs), the fast and complex chips ubiquitous today, requires to understand the\nimpact of such faults. In this paper, we propose an experimental setup and a\nforensic process to create exploitable faults and assess their impact on the\nSoC micro-architecture. On our targeted SoC (a BCM2837), the observed\nbehaviours are radically different to what were obtained with state-of-the-art\nfault injection attacks on microcontrollers. SoC subsystems (L1 caches, L2\ncache, memory management unit (MMU)) can be individually targeted leading to\nnew fault models. We also highlight the differences in the fault impact with\nand without an operating system (OS). This shows the importance of the software\nlayers in the exploitation of a fault. With this work, we demonstrate that the\ncomplexity and the speed of SoCs do not protect them against hardware fault\nattacks. To conclude our work, we introduce countermeasures to protect the SoC\ncaches and MMU against EMFI attacks based on the disclosed faults effects.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 08:24:47 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Trouchkine", "Thomas", ""], ["Bukasa", "S\u00e9banjila Kevin", ""], ["Escouteloup", "Mathieu", ""], ["Lashermes", "Ronan", ""], ["Bouffard", "Guillaume", ""]]}, {"id": "1910.12142", "submitter": "Jingbo Zhou", "authors": "Jingbo Zhou and Xinmiao Zhang", "title": "Generalized SAT-Attack-Resistant Logic Locking", "comments": null, "journal-ref": "in IEEE Transactions on Information Forensics and Security, vol.\n  16, pp. 2581-2592, 2021", "doi": "10.1109/TIFS.2021.3059271.", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic locking is used to protect integrated circuits (ICs) from piracy and\ncounterfeiting. An encrypted IC implements the correct function only when the\nright key is input. Many existing logic-locking methods are subject to the\npowerful satisfiability (SAT)-based attack. Recently, an Anti-SAT scheme has\nbeen developed. By adopting two complementary logic blocks that consist of\nAND/NAND trees, it makes the number of iterations needed by the SAT attack\nexponential to the number of input bits. Nevertheless, the Anti-SAT scheme is\nvulnerable to the later AppSAT and removal attacks. This paper proposes a\ngeneralized (G-)Anti-SAT scheme. Different from the Anti-SAT scheme, a variety\nof complementary or non-complementary functions can be adopted for the two\nblocks in our G-Anti-SAT scheme. The Anti-SAT scheme is just a special case of\nour proposed design. Our design can achieve higher output corruptibility, which\nis also tunable, so that better resistance to the AppSAT and removal attacks is\nachieved. Meanwhile, unlike existing AppSAT-resilient designs, our design does\nnot sacrifice the resistance to the SAT attack.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:50:01 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 14:15:00 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhou", "Jingbo", ""], ["Zhang", "Xinmiao", ""]]}, {"id": "1910.12897", "submitter": "Maciej Besta", "authors": "Maciej Besta, Torsten Hoefler", "title": "Active Access: A Mechanism for High-Performance Distributed Data-Centric\n  Computations", "comments": null, "journal-ref": "Proceedings of the 29th ACM International Conference on\n  Supercomputing (ACM ICS'15), 2015", "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote memory access (RMA) is an emerging high-performance programming model\nthat uses RDMA hardware directly. Yet, accessing remote memories cannot invoke\nactivities at the target which complicates implementation and limits\nperformance of data-centric algorithms. We propose Active Access (AA), a\nmechanism that integrates well-known active messaging (AM) semantics with RMA\nto enable high-performance distributed data-centric computations. AA supports a\nnew programming model where the user specifies handlers that are triggered when\nincoming puts and gets reference designated addresses. AA is based on a set of\nextensions to the Input/Output Memory Management Unit (IOMMU), a unit that\nprovides high-performance hardware support for remapping I/O accesses to\nmemory. We illustrate that AA outperforms existing AM and RMA designs,\naccelerates various codes such as distributed hashtables or logging schemes,\nand enables new protocols such as incremental checkpointing for RMA.We also\ndiscuss how extended IOMMUs can support a virtualized global address space in a\ndistributed system that offers features known from on-node memory\nvirtualization. We expect that AA can enhance the design of HPC operating and\nruntime systems in large computing centers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:09:23 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 23:13:52 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Besta", "Maciej", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1910.13063", "submitter": "Anuj Dubey", "authors": "Anuj Dubey, Rosario Cammarota and Aydin Aysu", "title": "MaskedNet: The First Hardware Inference Engine Aiming Power Side-Channel\n  Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Power Analysis (DPA) has been an active area of research for the\npast two decades to study the attacks for extracting secret information from\ncryptographic implementations through power measurements and their defenses.\nUnfortunately, the research on power side-channels have so far predominantly\nfocused on analyzing implementations of ciphers such as AES, DES, RSA, and\nrecently post-quantum cryptography primitives (e.g., lattices). Meanwhile,\nmachine-learning, and in particular deep-learning applications are becoming\nubiquitous with several scenarios where the Machine Learning Models are\nIntellectual Properties requiring confidentiality. Expanding side-channel\nanalysis to Machine Learning Model extraction, however, is largely unexplored.\n  This paper expands the DPA framework to neural-network classifiers. First, it\nshows DPA attacks during inference to extract the secret model parameters such\nas weights and biases of a neural network. Second, it proposes the\n$\\textit{first countermeasures}$ against these attacks by augmenting\n$\\textit{masking}$. The resulting design uses novel masked components such as\nmasked adder trees for fully-connected layers and masked Rectifier Linear Units\nfor activation functions. On a SAKURA-X FPGA board, experiments show that the\nfirst-order DPA attacks on the unprotected implementation can succeed with only\n200 traces and our protection respectively increases the latency and area-cost\nby 2.8x and 2.3x.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:19:16 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 18:42:02 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 19:05:59 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Dubey", "Anuj", ""], ["Cammarota", "Rosario", ""], ["Aysu", "Aydin", ""]]}, {"id": "1910.13683", "submitter": "Sasindu Wijeratne", "authors": "Sasindu Wijeratne, Ashen Ekanayake, Sandaruwan Jayaweera, Danuka\n  Ravishan, Ajith Pasqual", "title": "Scalable High Performance SDN Switch Architecture on FPGA for Core\n  Networks", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing heterogeneity in network user requirements, dynamically\nvarying day to day network traffic patterns and delay in-network service\ndeployment, there is a huge demand for scalability and flexibility in modern\nnetworking infrastructure, which in return has paved way for the introduction\nof Software Defined Networking (SDN) in core networks. In this paper, we\npresent an FPGA-based switch that is fully compliant with OpenFlow; the\npioneering protocol for southbound interface of SDN. The switch architecture is\ncompletely implemented on hardware. The design consists of an OpenFlow\nSouthbound agent which can process OpenFlow packets at a rate of 10Gbps. The\nproposed architecture speed scales up to 400Gbps while it consumes only 60% of\nresources on a Xilinx Virtex-7 featuring XC7VX485T FPGA.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:45:37 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Wijeratne", "Sasindu", ""], ["Ekanayake", "Ashen", ""], ["Jayaweera", "Sandaruwan", ""], ["Ravishan", "Danuka", ""], ["Pasqual", "Ajith", ""]]}]