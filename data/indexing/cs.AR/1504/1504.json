[{"id": "1504.00450", "submitter": "Yang Xue", "authors": "Yang Xue", "title": "Recent Development in Analog Computation - A Brief Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development in analog computation is reviewed in this paper.\nAnalog computation was used in many applications where power and energy\nefficiency is of paramount importance. It is shown that by using innovative\narchitecture and circuit design, analog computation systems can achieve much\nhigher energy efficiency than their digital counterparts, as they are able to\nexploit the computational power inherent to the devices and physics. However,\nthese systems do suffer from some disadvantages, such as lower accuracy and\nspeed, and designers have come up with novel approaches to overcome them. The\npaper provides an overview of analog computation systems, from basic components\nsuch as memory and arithmetic elements, to architecture and system design.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 06:29:09 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Xue", "Yang", ""]]}, {"id": "1504.01718", "submitter": "Paulo Matias", "authors": "Paulo Matias, Rafael Tuma Guariento, Lirio Onofre Baptista de Almeida,\n  Jan Frans Willem Slaets", "title": "Modular Acquisition and Stimulation System for Timestamp-Driven\n  Neuroscience Experiments", "comments": "Preprint submitted to ARC 2015. Extended: 16 pages, 10 figures. The\n  final publication is available at link.springer.com", "journal-ref": "Lecture Notes in Computer Science Volume 9040, 2015, pp 339-348", "doi": "10.1007/978-3-319-16214-0_29", "report-no": null, "categories": "q-bio.QM cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dedicated systems are fundamental for neuroscience experimental protocols\nthat require timing determinism and synchronous stimuli generation. We\ndeveloped a data acquisition and stimuli generator system for neuroscience\nresearch, optimized for recording timestamps from up to 6 spiking neurons and\nentirely specified in a high-level Hardware Description Language (HDL). Despite\nthe logic complexity penalty of synthesizing from such a language, it was\npossible to implement our design in a low-cost small reconfigurable device.\nUnder a modular framework, we explored two different memory arbitration schemes\nfor our system, evaluating both their logic element usage and resilience to\ninput activity bursts. One of them was designed with a decoupled and latency\ninsensitive approach, allowing for easier code reuse, while the other adopted a\ncentralized scheme, constructed specifically for our application. The usage of\na high-level HDL allowed straightforward and stepwise code modifications to\ntransform one architecture into the other. The achieved modularity is very\nuseful for rapidly prototyping novel electronic instrumentation systems\ntailored to scientific research.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 19:46:04 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Matias", "Paulo", ""], ["Guariento", "Rafael Tuma", ""], ["de Almeida", "Lirio Onofre Baptista", ""], ["Slaets", "Jan Frans Willem", ""]]}, {"id": "1504.03437", "submitter": "YouZhe Fan", "authors": "YouZhe Fan, Ji Chen, ChenYang Xia, Chi-ying Tsui, Jie Jin, Hui Shen,\n  and Bin Li", "title": "Low-latency List Decoding Of Polar Codes With Double Thresholding", "comments": "5 pages, 7 figures, 1 table, to be presented in the 40th IEEE\n  International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n  2015", "journal-ref": null, "doi": "10.1109/ICASSP.2015.7178128", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For polar codes with short-to-medium code length, list successive\ncancellation decoding is used to achieve a good error-correcting performance.\nHowever, list pruning in the current list decoding is based on the sorting\nstrategy and its timing complexity is high. This results in a long decoding\nlatency for large list size. In this work, aiming at a low-latency list\ndecoding implementation, a double thresholding algorithm is proposed for a fast\nlist pruning. As a result, with a negligible performance degradation, the list\npruning delay is greatly reduced. Based on the double thresholding, a\nlow-latency list decoding architecture is proposed and implemented using a UMC\n90nm CMOS technology. Synthesis results show that, even for a large list size\nof 16, the proposed low-latency architecture achieves a decoding throughput of\n220 Mbps at a frequency of 641 MHz.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 07:12:24 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Fan", "YouZhe", ""], ["Chen", "Ji", ""], ["Xia", "ChenYang", ""], ["Tsui", "Chi-ying", ""], ["Jin", "Jie", ""], ["Shen", "Hui", ""], ["Li", "Bin", ""]]}, {"id": "1504.04297", "submitter": "Hamza Sohail", "authors": "Hamza Bin Sohail, Balajee Vamanan, T. N. Vijaykumar", "title": "MigrantStore: Leveraging Virtual Memory in DRAM-PCM Memory Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the imminent slowing down of DRAM scaling, Phase Change Memory (PCM) is\nemerging as a lead alternative for main memory technology. While PCM achieves\nlow energy due to various technology-specific advantages, PCM is significantly\nslower than DRAM (especially for writes) and can endure far fewer writes before\nwearing out. Previous work has proposed to use a large, DRAM-based hardware\ncache to absorb writes and provide faster access. However, due to ineffectual\ncaching where blocks are evicted before sufficient number of accesses, hardware\ncaches incur significant overheads in energy and bandwidth, two key but scarce\nresources in modern multicores. Because using hardware for detecting and\nremoving such ineffectual caching would incur additional hardware cost and\ncomplexity, we leverage the OS virtual memory support for this purpose. We\npropose a DRAM-PCM hybrid memory architecture where the OS migrates pages on\ndemand from the PCM to DRAM. We call the DRAM part of our memory as\nMigrantStore which includes two ideas. First, to reduce the energy, bandwidth,\nand wear overhead of ineffectual migrations, we propose migration hysteresis.\nSecond, to reduce the software overhead of good replacement policies, we\npropose recently- accessed-page-id (RAPid) buffer, a hardware buffer to track\nthe addresses of recently-accessed MigrantStore pages.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 16:36:14 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Sohail", "Hamza Bin", ""], ["Vamanan", "Balajee", ""], ["Vijaykumar", "T. N.", ""]]}, {"id": "1504.04586", "submitter": "Syed Waqar Nabi Dr", "authors": "Syed Waqar Nabi and Saji N. Hameed and Wim Vanderbauwhede", "title": "A Reconfigurable Vector Instruction Processor for Accelerating a\n  Convection Parametrization Model on FPGAs", "comments": "This is an extended pre-print version of work that was presented at\n  the international symposium on Highly Efficient Accelerators and\n  Reconfigurable Technologies (HEART2014), Sendai, Japan, June 911, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Performance Computing (HPC) platforms allow scientists to model\ncomputationally intensive algorithms. HPC clusters increasingly use\nGeneral-Purpose Graphics Processing Units (GPGPUs) as accelerators; FPGAs\nprovide an attractive alternative to GPGPUs for use as co-processors, but they\nare still far from being mainstream due to a number of challenges faced when\nusing FPGA-based platforms. Our research aims to make FPGA-based high\nperformance computing more accessible to the scientific community. In this work\nwe present the results of investigating the acceleration of a particular\natmospheric model, Flexpart, on FPGAs. We focus on accelerating the most\ncomputationally intensive kernel from this model. The key contribution of our\nwork is the architectural exploration we undertook to arrive at a solution that\nbest exploits the parallelism available in the legacy code, and is also\nconvenient to program, so that eventually the compilation of high-level legacy\ncode to our architecture can be fully automated. We present the three different\ntypes of architecture, comparing their resource utilization and performance,\nand propose that an architecture where there are a number of computational\ncores, each built along the lines of a vector instruction processor, works best\nin this particular scenario, and is a promising candidate for a generic\nFPGA-based platform for scientific computation. We also present the results of\nexperiments done with various configuration parameters of the proposed\narchitecture, to show its utility in adapting to a range of scientific\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 17:27:27 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Nabi", "Syed Waqar", ""], ["Hameed", "Saji N.", ""], ["Vanderbauwhede", "Wim", ""]]}, {"id": "1504.06357", "submitter": "Simon Hollis", "authors": "Simon J. Hollis, Steve Kerrison", "title": "Overview of Swallow --- A Scalable 480-core System for Investigating the\n  Performance and Energy Efficiency of Many-core Applications and Operating\n  Systems", "comments": "An open source release of the Swallow system design and code will\n  follow and references to these will be added at a later date", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Swallow, a scalable many-core architecture, with a current\nconfiguration of 480 x 32-bit processors.\n  Swallow is an open-source architecture, designed from the ground up to\ndeliver scalable increases in usable computational power to allow\nexperimentation with many-core applications and the operating systems that\nsupport them.\n  Scalability is enabled by the creation of a tile-able system with a\nlow-latency interconnect, featuring an attractive communication-to-computation\nratio and the use of a distributed memory configuration.\n  We analyse the energy and computational and communication performances of\nSwallow. The system provides 240GIPS with each core consuming 71--193mW,\ndependent on workload. Power consumption per instruction is lower than almost\nall systems of comparable scale.\n  We also show how the use of a distributed operating system (nOS) allows the\neasy creation of scalable software to exploit Swallow's potential. Finally, we\nshow two use case studies: modelling neurons and the overlay of shared memory\non a distributed memory system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 22:36:46 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Hollis", "Simon J.", ""], ["Kerrison", "Steve", ""]]}]