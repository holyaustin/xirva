[{"id": "2004.00243", "submitter": "Sho Ko", "authors": "Sho Ko, Yun Joon Soh, Jishen Zhao", "title": "Efficient Implementation of Multi-Channel Convolution in Monolithic 3D\n  ReRAM Crossbar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) demonstrate promising accuracy in a wide\nrange of applications. Among all layers in CNNs, convolution layers are the\nmost computation-intensive and consume the most energy. As the maturity of\ndevice and fabrication technology, 3D resistive random access memory (ReRAM)\nreceives substantial attention for accelerating large vector-matrix\nmultiplication and convolution due to its high parallelism and energy\nefficiency benefits. However, implementing multi-channel convolution naively in\n3D ReRAM will either produce incorrect results or exploit only partial\nparallelism of 3D ReRAM. In this paper, we propose a 3D ReRAM-based convolution\naccelerator architecture, which efficiently maps multi-channel convolution to\nmonolithic 3D ReRAM. Our design has two key principles. First, we exploit the\nintertwined structure of 3D ReRAM to implement multi-channel convolution by\nusing a state-of-the-art convolution algorithm. Second, we propose a new\napproach to efficiently implement negative weights by separating them from\nnon-negative weights using configurable interconnects. Our evaluation\ndemonstrates that our mapping scheme in 16-layer 3D ReRAM achieves a speedup of\n5.79X, 927.81X, and 36.8X compared with a custom 2D ReRAM baseline and\nstate-of-the-art CPU and GPU. Our design also reduces energy consumption by\n2.12X, 1802.64X, and 114.1X compared with the same baseline.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 05:57:03 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ko", "Sho", ""], ["Soh", "Yun Joon", ""], ["Zhao", "Jishen", ""]]}, {"id": "2004.01353", "submitter": "Mihai Sima", "authors": "Ash Luft, Mihai Sima, Michael McGuire", "title": "Hardware Trojan with Frequency Modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of third-party IP cores in implementing applications in FPGAs has\ngiven rise to the threat of malicious alterations through the insertion of\nhardware Trojans. To address this threat, it is important to predict the way\nhardware Trojans are built and to identify their weaknesses. This paper\ndescribes a logic family for implementing robust hardware Trojans, which can\nevade the two major detection methods, namely unused-circuit identification and\nside-channel analysis. This robustness is achieved by encoding information in\nfrequency rather than amplitude so that the Trojan trigger circuitry's state\nwill never stay constant during 'normal' operation. In addition, the power\nconsumption of Trojan circuits built using the proposed logic family can be\nconcealed with minimal design effort and supplementary hardware resources.\nDefense measures against hardware Trojans with frequency modulation are\ndescribed.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:17:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Luft", "Ash", ""], ["Sima", "Mihai", ""], ["McGuire", "Michael", ""]]}, {"id": "2004.01635", "submitter": "Kaan Kara", "authors": "Kaan Kara, Christoph Hagleitner, Dionysios Diamantopoulos, Dimitris\n  Syrivelis, Gustavo Alonso", "title": "High Bandwidth Memory on FPGAs: A Data Analytics Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGA-based data processing in datacenters is increasing in popularity due to\nthe demands of modern workloads and the ensuing necessity for specialization in\nhardware. Driven by this trend, vendors are rapidly adapting reconfigurable\ndevices to suit data and compute intensive workloads. Inclusion of High\nBandwidth Memory (HBM) in FPGA devices is a recent example. HBM promises\novercoming the bandwidth bottleneck, faced often by FPGA-based accelerators due\nto their throughput oriented design. In this paper, we study the usage and\nbenefits of HBM on FPGAs from a data analytics perspective. We consider three\nworkloads that are often performed in analytics oriented databases and\nimplement them on FPGA showing in which cases they benefit from HBM: range\nselection, hash join, and stochastic gradient descent for linear model\ntraining. We integrate our designs into a columnar database (MonetDB) and show\nthe trade-offs arising from the integration related to data movement and\npartitioning. In certain cases, FPGA+HBM based solutions are able to surpass\nthe highest performance provided by either a 2-socket POWER9 system or a\n14-core XeonE5 by up to 1.8x (selection), 12.9x (join), and 3.2x (SGD).\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 11:29:31 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Kara", "Kaan", ""], ["Hagleitner", "Christoph", ""], ["Diamantopoulos", "Dionysios", ""], ["Syrivelis", "Dimitris", ""], ["Alonso", "Gustavo", ""]]}, {"id": "2004.01689", "submitter": "Fernando Cladera Ojeda", "authors": "Anthony Bisulco, Fernando Cladera Ojeda, Volkan Isler, Daniel D. Lee", "title": "Near-chip Dynamic Vision Filtering for Low-Bandwidth Pedestrian\n  Detection", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel end-to-end system for pedestrian detection using\nDynamic Vision Sensors (DVSs). We target applications where multiple sensors\ntransmit data to a local processing unit, which executes a detection algorithm.\nOur system is composed of (i) a near-chip event filter that compresses and\ndenoises the event stream from the DVS, and (ii) a Binary Neural Network (BNN)\ndetection module that runs on a low-computation edge computing device (in our\ncase a STM32F4 microcontroller). We present the system architecture and provide\nan end-to-end implementation for pedestrian detection in an office environment.\nOur implementation reduces transmission size by up to 99.6% compared to\ntransmitting the raw event stream. The average packet size in our system is\nonly 1397 bits, while 307.2 kb are required to send an uncompressed DVS time\nwindow. Our detector is able to perform a detection every 450 ms, with an\noverall testing F1 score of 83%. The low bandwidth and energy properties of our\nsystem make it ideal for IoT applications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:36:26 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bisulco", "Anthony", ""], ["Ojeda", "Fernando Cladera", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2004.01712", "submitter": "Sayan Sinha", "authors": "Manaar Alam, Sayan Sinha, Sarani Bhattacharya, Swastika Dutta, Debdeep\n  Mukhopadhyay, Anupam Chattopadhyay", "title": "RAPPER: Ransomware Prevention via Performance Counters", "comments": "Australian Workshop on Offensive Cryptography, Kangacrypt 2018. arXiv\n  admin note: substantial text overlap with arXiv:1802.03909", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ransomware can produce direct and controllable economic loss, which makes it\none of the most prominent threats in cyber security. As per the latest\nstatistics, more than half of malwares reported in Q1 of 2017 are ransomwares\nand there is a potent threat of a novice cybercriminals accessing\nransomware-as-a-service. The concept of public-key based data kidnapping and\nsubsequent extortion was introduced in 1996. Since then, variants of ransomware\nemerged with different cryptosystems and larger key sizes, the underlying\ntechniques remained same. Though there are works in literature which proposes a\ngeneric framework to detect the crypto ransomwares, we present a two step\nunsupervised detection tool which when suspects a process activity to be\nmalicious, issues an alarm for further analysis to be carried in the second\nstep and detects it with minimal traces. The two step detection framework-\nRAPPER uses Artificial Neural Network and Fast Fourier Transformation to\ndevelop a highly accurate, fast and reliable solution to ransomware detection\nusing minimal trace points. We also introduce a special detection module for\nsuccessful identification of disk encryption processes from potential\nransomware operations, both having similar characteristics but with different\nobjective. We provide a comprehensive solution to tackle almost all scenarios\n(standard benchmark, disk encryption and regular high computational processes)\npertaining to the crypto ransomwares in light of software security.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:53:02 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Alam", "Manaar", ""], ["Sinha", "Sayan", ""], ["Bhattacharya", "Sarani", ""], ["Dutta", "Swastika", ""], ["Mukhopadhyay", "Debdeep", ""], ["Chattopadhyay", "Anupam", ""]]}, {"id": "2004.02109", "submitter": "Shahin Nazarian", "authors": "Shahin Nazarian and Paul Bogdan", "title": "S4oC: A Self-optimizing, Self-adapting Secure System-on-Chip Design\n  Framework to Tackle Unknown Threats -- A Network Theoretic, Learning Approach", "comments": "This is an invited paper to ISCAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for the design and optimization of a secure\nself-optimizing, self-adapting system-on-chip (S4oC) architecture. The goal is\nto minimize the impact of attacks such as hardware Trojan and side-channel, by\nmaking real-time adjustments. S4oC learns to reconfigure itself, subject to\nvarious security measures and attacks, some of which possibly unknown at design\ntime. Furthermore, the data types and patterns of the target applications,\nenvironmental conditions, and sources of variations are incorporated. S4oC is a\nmanycore system, modeled as a four-layer graph, representing the model of\ncomputation (MoCp), model of connection (MoCn), model of memory (MoM) and model\nof storage (MoS), with a large number of elements including heterogeneous\nreconfigurable processing elements in MoCp, and memory elements in the MoM\nlayer. Security driven community detection, and neural networks are utilized\nfor application task clustering, and distributed reinforcement learning (RL)\nfor task mapping.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:55:05 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nazarian", "Shahin", ""], ["Bogdan", "Paul", ""]]}, {"id": "2004.02354", "submitter": "Zhi Zhang", "authors": "Minghua Wang, Zhi Zhang, Yueqiang Cheng, Surya Nepal", "title": "DRAMDig: A Knowledge-assisted Tool to Uncover DRAM Address Mapping", "comments": "Preprint of the work accepted at the Design Automation Conference\n  (DAC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As recently emerged rowhammer exploits require undocumented DRAM address\nmapping, we propose a generic knowledge-assisted tool, DRAMDig, which takes\ndomain knowledge into consideration to efficiently and deterministically\nuncover the DRAM address mappings on any Intel-based machines. We test DRAMDig\non a number of machines with different combinations of DRAM chips and\nmicroarchitectures ranging from Intel Sandy Bridge to Coffee Lake. Comparing to\nprevious works, DRAMDig deterministically reverse-engineered DRAM address\nmappings on all the test machines with only 7.8 minutes on average. Based on\nthe uncovered mappings, we perform double-sided rowhammer tests and the results\nshow that DRAMDig induced significantly more bit flips than previous works,\njustifying the correctness of the uncovered DRAM address mappings.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:58:59 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 06:47:27 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wang", "Minghua", ""], ["Zhang", "Zhi", ""], ["Cheng", "Yueqiang", ""], ["Nepal", "Surya", ""]]}, {"id": "2004.02997", "submitter": "Virinchi Roy Surabhi", "authors": "Virinchi Roy Surabhi, Prashanth Krishnamurthy, Hussam Amrouch, Kanad\n  Basu, J\\\"org Henkel, Ramesh Karri, Farshad Khorrami", "title": "Hardware Trojan Detection Using Controlled Circuit Aging", "comments": "21 pages, 34 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2989735", "report-no": null, "categories": "cs.AR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports a novel approach that uses transistor aging in an\nintegrated circuit (IC) to detect hardware Trojans. When a transistor is aged,\nit results in delays along several paths of the IC. This increase in delay\nresults in timing violations that reveal as timing errors at the output of the\nIC during its operation. We present experiments using aging-aware standard cell\nlibraries to illustrate the usefulness of the technique in detecting hardware\nTrojans. Combining IC aging with over-clocking produces a pattern of bit errors\nat the IC output by the induced timing violations. We use machine learning to\nlearn the bit error distribution at the output of a clean IC. We differentiate\nthe divergence in the pattern of bit errors because of a Trojan in the IC from\nthis baseline distribution. We simulate the golden IC and show robustness to\nIC-to-IC manufacturing variations. The approach is effective and can detect a\nTrojan even if we place it far off the critical paths. Results on benchmarks\nfrom the Trust-hub show a detection accuracy of $\\geq$99%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 21:19:50 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 00:27:40 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 01:03:16 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Surabhi", "Virinchi Roy", ""], ["Krishnamurthy", "Prashanth", ""], ["Amrouch", "Hussam", ""], ["Basu", "Kanad", ""], ["Henkel", "J\u00f6rg", ""], ["Karri", "Ramesh", ""], ["Khorrami", "Farshad", ""]]}, {"id": "2004.03021", "submitter": "Yaman Umuroglu", "authors": "Yaman Umuroglu, Yash Akhauri, Nicholas J. Fraser, Michaela Blott", "title": "LogicNets: Co-Designed Neural Networks and Circuits for\n  Extreme-Throughput Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep neural networks for applications that require very high\nthroughput or extremely low latency is a severe computational challenge,\nfurther exacerbated by inefficiencies in mapping the computation to hardware.\nWe present a novel method for designing neural network topologies that directly\nmap to a highly efficient FPGA implementation. By exploiting the equivalence of\nartificial neurons with quantized inputs/outputs and truth tables, we can train\nquantized neural networks that can be directly converted to a netlist of truth\ntables, and subsequently deployed as a highly pipelinable, massively parallel\nFPGA circuit. However, the neural network topology requires careful\nconsideration since the hardware cost of truth tables grows exponentially with\nneuron fan-in. To obtain smaller networks where the whole netlist can be\nplaced-and-routed onto a single FPGA, we derive a fan-in driven hardware cost\nmodel to guide topology design, and combine high sparsity with low-bit\nactivation quantization to limit the neuron fan-in. We evaluate our approach on\ntwo tasks with very high intrinsic throughput requirements in high-energy\nphysics and network intrusion detection. We show that the combination of\nsparsity and low-bit activation quantization results in high-speed circuits\nwith small logic depth and low LUT cost, demonstrating competitive accuracy\nwith less than 15 ns of inference latency and throughput in the hundreds of\nmillions of inferences per second.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:15:41 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Umuroglu", "Yaman", ""], ["Akhauri", "Yash", ""], ["Fraser", "Nicholas J.", ""], ["Blott", "Michaela", ""]]}, {"id": "2004.03244", "submitter": "Christian Hakert", "authors": "Christian Hakert, Kuan-Hsun Chen, Paul R. Genssler, Georg von der\n  Br\\\"uggen, Lars Bauer, Hussam Amrouch, Jian-Jia Chen, J\\\"org Henkel", "title": "SoftWear: Software-Only In-Memory Wear-Leveling for Non-Volatile Main\n  Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several emerging technologies for byte-addressable non-volatile memory (NVM)\nhave been considered to replace DRAM as the main memory in computer systems\nduring the last years. The disadvantage of a lower write endurance, compared to\nDRAM, of NVM technologies like Phase-Change Memory (PCM) or Ferroelectric RAM\n(FeRAM) has been addressed in the literature. As a solution, in-memory\nwear-leveling techniques have been proposed, which aim to balance the\nwear-level over all memory cells to achieve an increased memory lifetime.\nGenerally, to apply such advanced aging-aware wear-leveling techniques proposed\nin the literature, additional special hardware is introduced into the memory\nsystem to provide the necessary information about the cell age and thus enable\naging-aware wear-leveling decisions.\n  This paper proposes software-only aging-aware wear-leveling based on common\nCPU features and does not rely on any additional hardware support from the\nmemory subsystem. Specifically, we exploit the memory management unit (MMU),\nperformance counters, and interrupts to approximate the memory write counts as\nan aging indicator. Although the software-only approach may lead to slightly\nworse wear-leveling, it is applicable on commonly available hardware. We\nachieve page-level coarse-grained wear-leveling by approximating the current\ncell age through statistical sampling and performing physical memory remapping\nthrough the MMU. This method results in non-uniform memory usage patterns\nwithin a memory page. Hence, we further propose a fine-grained wear-leveling in\nthe stack region of C / C++ compiled software.\n  By applying both wear-leveling techniques, we achieve up to $78.43\\%$ of the\nideal memory lifetime, which is a lifetime improvement of more than a factor of\n$900$ compared to the lifetime without any wear-leveling.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:33:37 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:05:35 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Hakert", "Christian", ""], ["Chen", "Kuan-Hsun", ""], ["Genssler", "Paul R.", ""], ["von der Br\u00fcggen", "Georg", ""], ["Bauer", "Lars", ""], ["Amrouch", "Hussam", ""], ["Chen", "Jian-Jia", ""], ["Henkel", "J\u00f6rg", ""]]}, {"id": "2004.03640", "submitter": "Davide Giri", "authors": "Davide Giri, Kuan-Lin Chiu, Giuseppe Di Guglielmo, Paolo Mantovani and\n  Luca P. Carloni", "title": "ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine\n  Learning", "comments": "Paper published in the proceedings of the 2020 Design, Automation &\n  Test in Europe Conference & Exhibition (DATE)", "journal-ref": "Design, Automation and Test in Europe Conference & Exhibition\n  (DATE), Grenoble, France, 2020, pp. 1049-1054", "doi": "10.23919/DATE48585.2020.9116317", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ESP4ML, an open-source system-level design flow to build and\nprogram SoC architectures for embedded applications that require the hardware\nacceleration of machine learning and signal processing algorithms. We realized\nESP4ML by combining two established open-source projects (ESP and HLS4ML) into\na new, fully-automated design flow. For the SoC integration of accelerators\ngenerated by HLS4ML, we designed a set of new parameterized interface circuits\nsynthesizable with high-level synthesis. For accelerator configuration and\nmanagement, we developed an embedded software runtime system on top of Linux.\nWith this HW/SW layer, we addressed the challenge of dynamically shaping the\ndata traffic on a network-on-chip to activate and support the reconfigurable\npipelines of accelerators that are needed by the application workloads\ncurrently running on the SoC. We demonstrate our vertically-integrated\ncontributions with the FPGA-based implementations of complete SoC instances\nbooting Linux and executing computer-vision applications that process images\ntaken from the Google Street View database.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:25:50 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:14:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Giri", "Davide", ""], ["Chiu", "Kuan-Lin", ""], ["Di Guglielmo", "Giuseppe", ""], ["Mantovani", "Paolo", ""], ["Carloni", "Luca P.", ""]]}, {"id": "2004.03717", "submitter": "Anup Das", "authors": "Shihao Song, Adarsha Balaji, Anup Das, Nagarajan Kandasamy, and James\n  Shackleford", "title": "Compiling Spiking Neural Networks to Neuromorphic Hardware", "comments": "10 pages, 17 figures, accepted at 21st ACM SIGPLAN/SIGBED\n  International Conference on Languages, Compilers, and Tools for Embedded\n  Systems (LCTES 2020)", "journal-ref": null, "doi": "10.1145/3372799.3394364", "report-no": null, "categories": "cs.DC cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning applications that are implemented with spike-based\ncomputation model, e.g., Spiking Neural Network (SNN), have a great potential\nto lower the energy consumption when they are executed on a neuromorphic\nhardware. However, compiling and mapping an SNN to the hardware is challenging,\nespecially when compute and storage resources of the hardware (viz. crossbar)\nneed to be shared among the neurons and synapses of the SNN. We propose an\napproach to analyze and compile SNNs on a resource-constrained neuromorphic\nhardware, providing guarantee on key performance metrics such as execution time\nand throughput. Our approach makes the following three key contributions.\nFirst, we propose a greedy technique to partition an SNN into clusters of\nneurons and synapses such that each cluster can fit on to the resources of a\ncrossbar. Second, we exploit the rich semantics and expressiveness of\nSynchronous Dataflow Graphs (SDFGs) to represent a clustered SNN and analyze\nits performance using Max-Plus Algebra, considering the available compute and\nstorage capacities, buffer sizes, and communication bandwidth. Third, we\npropose a self-timed execution-based fast technique to compile and admit\nSNN-based applications to a neuromorphic hardware at run-time, adapting\ndynamically to the available resources on the hardware. We evaluate our\napproach with standard SNN-based applications and demonstrate a significant\nperformance improvement compared to current practices.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 21:13:27 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:02:31 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Song", "Shihao", ""], ["Balaji", "Adarsha", ""], ["Das", "Anup", ""], ["Kandasamy", "Nagarajan", ""], ["Shackleford", "James", ""]]}, {"id": "2004.03804", "submitter": "Hanchen Ye", "authors": "Hanchen Ye, Xiaofan Zhang, Zhize Huang, Gengsheng Chen, Deming Chen", "title": "HybridDNN: A Framework for High-Performance Hybrid DNN Accelerator\n  Design and Implementation", "comments": "Published as a conference paper at Design Automation Conference 2020\n  (DAC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To speedup Deep Neural Networks (DNN) accelerator design and enable effective\nimplementation, we propose HybridDNN, a framework for building high-performance\nhybrid DNN accelerators and delivering FPGA-based hardware implementations.\nNovel techniques include a highly flexible and scalable architecture with a\nhybrid Spatial/Winograd convolution (CONV) Processing Engine (PE), a\ncomprehensive design space exploration tool, and a complete design flow to\nfully support accelerator design and implementation. Experimental results show\nthat the accelerators generated by HybridDNN can deliver 3375.7 and 83.3 GOPS\non a high-end FPGA (VU9P) and an embedded FPGA (PYNQ-Z1), respectively, which\nachieve a 1.8x higher performance improvement compared to the state-of-art\naccelerator designs. This demonstrates that HybridDNN is flexible and scalable\nand can target both cloud and embedded hardware platforms with vastly different\nresource constraints.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 04:28:38 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ye", "Hanchen", ""], ["Zhang", "Xiaofan", ""], ["Huang", "Zhize", ""], ["Chen", "Gengsheng", ""], ["Chen", "Deming", ""]]}, {"id": "2004.04509", "submitter": "Artur Podobas PhD", "authors": "Artur Podobas, Kentaro Sano, Satoshi Matsuoka", "title": "A Survey on Coarse-Grained Reconfigurable Architectures from a\n  Performance Perspective", "comments": null, "journal-ref": "IEEE Access, 2020 (https://ieeexplore.ieee.org/document/9149601)", "doi": "10.1109/ACCESS.2020.3012084", "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the end of both Dennard's scaling and Moore's law, computer users and\nresearchers are aggressively exploring alternative forms of computing in order\nto continue the performance scaling that we have come to enjoy. Among the more\nsalient and practical of the post-Moore alternatives are reconfigurable\nsystems, with Coarse-Grained Reconfigurable Architectures (CGRAs) seemingly\ncapable of striking a balance between performance and programmability. In this\npaper, we survey the landscape of CGRAs. We summarize nearly three decades of\nliterature on the subject, with a particular focus on the premise behind the\ndifferent CGRAs and how they have evolved. Next, we compile metrics of\navailable CGRAs and analyze their performance properties in order to understand\nand discover knowledge gaps and opportunities for future CGRA research\nspecialized towards High-Performance Computing (HPC). We find that there are\nample opportunities for future research on CGRAs, in particular with respect to\nsize, functionality, support for parallel programming models, and to evaluate\nmore complex applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 12:12:05 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 15:25:04 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Podobas", "Artur", ""], ["Sano", "Kentaro", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "2004.04852", "submitter": "Rachit Nigam", "authors": "Rachit Nigam, Sachille Atapattu, Samuel Thomas, Zhijing Li, Theodore\n  Bauer, Yuwei Ye, Apurva Koti, Adrian Sampson, Zhiru Zhang", "title": "Predictable Accelerator Design with Time-Sensitive Affine Types", "comments": "Full paper with soundness proof and MachSuite ports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field-programmable gate arrays (FPGAs) provide an opportunity to co-design\napplications with hardware accelerators, yet they remain difficult to program.\nHigh-level synthesis (HLS) tools promise to raise the level of abstraction by\ncompiling C or C++ to accelerator designs. Repurposing legacy software\nlanguages, however, requires complex heuristics to map imperative code onto\nhardware structures. We find that the black-box heuristics in HLS can be\nunpredictable: changing parameters in the program that should improve\nperformance can counterintuitively yield slower and larger designs. This paper\nproposes a type system that restricts HLS to programs that can predictably\ncompile to hardware accelerators. The key idea is to model consumable hardware\nresources with a time-sensitive affine type system that prevents simultaneous\nuses of the same hardware structure. We implement the type system in Dahlia, a\nlanguage that compiles to HLS C++, and show that it can reduce the size of HLS\nparameter spaces while accepting Pareto-optimal designs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:23:07 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:48:13 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Nigam", "Rachit", ""], ["Atapattu", "Sachille", ""], ["Thomas", "Samuel", ""], ["Li", "Zhijing", ""], ["Bauer", "Theodore", ""], ["Ye", "Yuwei", ""], ["Koti", "Apurva", ""], ["Sampson", "Adrian", ""], ["Zhang", "Zhiru", ""]]}, {"id": "2004.04865", "submitter": "Sho Ko", "authors": "Sho Ko, Shimeng Yu", "title": "SMART Paths for Latency Reduction in ReRAM Processing-In-Memory\n  Architecture for CNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research work proposes a design of an analog ReRAM-based PIM\n(processing-in-memory) architecture for fast and efficient CNN (convolutional\nneural network) inference. For the overall architecture, we use the basic\nhardware hierarchy such as node, tile, core, and subarray. On the top of that,\nwe design intra-layer pipelining, inter-layer pipelining, and batch pipelining\nto exploit parallelism in the architecture and increase overall throughput for\nthe inference of an input image stream. We also optimize the performance of the\nNoC (network-on-chip) routers by decreasing hop counts using SMART\n(single-cycle multi-hop asynchronous repeated traversal) flow control. Finally,\nwe experiment with weight replications for different CNN layers in VGG (A-E)\nfor large-scale data set ImageNet. In our simulation, we achieve 40.4027 TOPS\n(tera-operations per second) for the best-case performance, which corresponds\nto over 1029 FPS (frames per second). We also achieve 3.5914 TOPS/W\n(tera-operaions per second per watt) for the best-case energy efficiency. In\naddition, the architecture with aggressive pipelining and weight replications\ncan achieve 14X speedup compared to the baseline architecture with basic\npipelining, and SMART flow control achieves 1.08X speedup in this architecture\ncompared to the baseline. Last but not least, we also evaluate the performance\nof SMART flow control using synthetic traffic.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 00:34:31 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Ko", "Sho", ""], ["Yu", "Shimeng", ""]]}, {"id": "2004.05518", "submitter": "Fei Wen", "authors": "Fei Wen, Mian Qin, Paul Gratz, Narasimha Reddy", "title": "Hardware Memory Management for Future Mobile Hybrid Memory Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current mobile applications have rapidly growing memory footprints,\nposing a great challenge for memory system design. Insufficient DRAM main\nmemory will incur frequent data swaps between memory and storage, a process\nthat hurts performance, consumes energy and deteriorates the write endurance of\ntypical flash storage devices. Alternately, a larger DRAM has higher leakage\npower and drains the battery faster. Further, DRAM scaling trends make further\ngrowth of DRAMin the mobile space prohibitive due to cost. Emerging\nnon-volatile memory (NVM) has the potential to alleviate these issues due to\nits higher capacity per cost than DRAM and mini-mal static power. Recently, a\nwide spectrum of NVM technologies, including phase-change memories (PCM),\nmemristor, and 3D XPoint have emerged. Despite the mentioned advantages, NVM\nhas longer access latency compared to DRAMand NVM writes can incur higher\nlatencies and wear costs. Therefore integration of these new memory\ntechnologies in the memory hierarchy requires a fundamental rearchitect-ing of\ntraditional system designs. In this work, we propose a hardware-accelerated\nmemory manager (HMMU) that addresses both types of memory in a flat space\naddress space. We design a set of data placement and data migration policies\nwithin this memory manager, such that we may exploit the advantages of each\nmemory technology. By augmenting the system with this HMMU, we reduce the\noverall memory latency while also reducing writes to the NVM. Experimental\nresults show that our design achieves a 39% reduction in energy consumption\nwith only a 12% performance degradation versus an all-DRAM baseline that is\nlikely untenable in the future.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 01:25:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wen", "Fei", ""], ["Qin", "Mian", ""], ["Gratz", "Paul", ""], ["Reddy", "Narasimha", ""]]}, {"id": "2004.06061", "submitter": "Joshua Mack", "authors": "Spencer Valancius, Edward Richter, Ruben Purdy, Kris Rockowitz,\n  Michael Inouye, Joshua Mack, Nirmal Kumbhare, Kaitlin Fair, John Mixter, Ali\n  Akoglu", "title": "FPGA Based Emulation Environment for Neuromorphic Architectures", "comments": "8 pages, 8 figures. To be published in proceedings of 27th\n  Reconfigurable Architectures Workshop https://raw.necst.it. For associated\n  source files, see https://www.github.com/UA-RCL/RANC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic architectures such as IBM's TrueNorth and Intel's Loihi have\nbeen introduced as platforms for energy efficient spiking neural network\nexecution. However, there is no framework that allows for rapidly experimenting\nwith neuromorphic architectures and studying the trade space on hardware\nperformance and network accuracy. Fundamentally, this creates a barrier to\nentry for hardware designers looking to explore neuromorphic architectures. In\nthis paper we present an open-source FPGA based emulation environment for\nneuromorphic computing research. We prototype IBM's TrueNorth architecture as a\nreference design and discuss FPGA specific design decisions made when\nimplementing and integrating it's core components. We conduct resource\nutilization analysis and realize a streaming-enabled TrueNorth architecture on\nthe Zynq UltraScale+ MPSoC. We then perform functional verification by\nimplementing networks for MNIST dataset and vector matrix multiplication (VMM)\nin our emulation environment and present an accuracy-based comparison based on\nthe same networks generated using IBM's Compass simulation environment. We\ndemonstrate the utility of our emulation environment for hardware designers and\napplication engineers by altering the neuron behavior for VMM mapping, which\nis, to the best of our knowledge, not feasible with any other tool including\nIBM's Compass environment. The proposed parameterized and configurable\nemulation platform serves as a basis for expanding its features to support\nemerging architectures, studying hypothetical neuromorphic architectures, or\nrapidly converging to hardware configuration through incremental changes based\non bottlenecks as they become apparent during application mapping process.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 06:05:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Valancius", "Spencer", ""], ["Richter", "Edward", ""], ["Purdy", "Ruben", ""], ["Rockowitz", "Kris", ""], ["Inouye", "Michael", ""], ["Mack", "Joshua", ""], ["Kumbhare", "Nirmal", ""], ["Fair", "Kaitlin", ""], ["Mixter", "John", ""], ["Akoglu", "Ali", ""]]}, {"id": "2004.06662", "submitter": "Florian Glaser", "authors": "Florian Glaser, Giuseppe Tagliavini, Davide Rossi, Germain Haugou,\n  Qiuting Huang, Luca Benini", "title": "Energy-Efficient Hardware-Accelerated Synchronization for\n  Shared-L1-Memory Multiprocessor Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The steeply growing performance demands for highly power- and\nenergy-constrained processing systems such as end-nodes of the\ninternet-of-things (IoT) have led to parallel near-threshold computing (NTC),\njoining the energy-efficiency benefits of low-voltage operation with the\nperformance typical of parallel systems. Shared-L1-memory multiprocessor\nclusters are a promising architecture, delivering performance in the order of\nGOPS and over 100 GOPS/W of energy-efficiency. However, this level of\ncomputational efficiency can only be reached by maximizing the effective\nutilization of the processing elements (PEs) available in the clusters. Along\nwith this effort, the optimization of PE-to-PE synchronization and\ncommunication is a critical factor for performance. In this work, we describe a\nlight-weight hardware-accelerated synchronization and communication unit (SCU)\nfor tightly-coupled clusters of processors. We detail the architecture, which\nenables fine-grain per-PE power management, and its integration into an\neight-core cluster of RISC-V processors. To validate the effectiveness of the\nproposed solution, we implemented the eight-core cluster in advanced 22nm FDX\ntechnology and evaluated performance and energy-efficiency with tunable\nmicrobenchmarks and a set of real-life applications and kernels. The proposed\nsolution allows synchronization-free regions as small as 42 cycles, over 41\ntimes smaller than the baseline implementation based on fast test-and-set\naccess to L1 memory when constraining the microbenchmarks to 10%\nsynchronization overhead. When evaluated on the real-life DSP-applications, the\nproposed SCU improves performance by up to 92% and 23% on average and energy\nefficiency by up to 98% and 39% on average.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:02:43 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Glaser", "Florian", ""], ["Tagliavini", "Giuseppe", ""], ["Rossi", "Davide", ""], ["Haugou", "Germain", ""], ["Huang", "Qiuting", ""], ["Benini", "Luca", ""]]}, {"id": "2004.07415", "submitter": "Aninda Manocha", "authors": "Opeoluwa Matthews, Aninda Manocha, Davide Giri, Marcelo Orenes-Vera,\n  Esin Tureci, Tyler Sorensen, Tae Jun Ham, Juan L. Arag\\'on, Luca P. Carloni,\n  Margaret Martonosi", "title": "The MosaicSim Simulator (Full Technical Report)", "comments": "This is a full technical report on the MosaicSim simulator. This\n  version is a variation of the original ISPASS publication with additions\n  describing the accuracy of MosaicSim's memory hierarchy performance modeling\n  and additional hardware features, e.g. branch predictors. This technical\n  report will be maintained as the MosaicSim developers continue to augment the\n  simulator with more features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Moore's Law has slowed and Dennard Scaling has ended, architects are\nincreasingly turning to heterogeneous parallelism and domain-specific\nhardware-software co-designs. These trends present new challenges for\nsimulation-based performance assessments that are central to early-stage\narchitectural exploration. Simulators must be lightweight to support rich\nheterogeneous combinations of general purpose cores and specialized processing\nunits. They must also support agile exploration of hardware-software co-design,\ni.e. changes in the programming model, compiler, ISA, and specialized hardware.\n  To meet these challenges, we introduce MosaicSim, a lightweight, modular\nsimulator for heterogeneous systems, offering accuracy and agility designed\nspecifically for hardware-software co-design explorations. By integrating the\nLLVM toolchain, MosaicSim enables efficient modeling of instruction\ndependencies and flexible additions across the stack. Its modularity also\nallows the composition and integration of different hardware components. We\nfirst demonstrate that MosaicSim captures architectural bottlenecks in\napplications, and accurately models both scaling trends in a multicore setting\nand accelerator behavior. We then present two case-studies where MosaicSim\nenables straightforward design space explorations for emerging systems, i.e.\ndata science application acceleration and heterogeneous parallel architectures.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 01:23:39 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Matthews", "Opeoluwa", ""], ["Manocha", "Aninda", ""], ["Giri", "Davide", ""], ["Orenes-Vera", "Marcelo", ""], ["Tureci", "Esin", ""], ["Sorensen", "Tyler", ""], ["Ham", "Tae Jun", ""], ["Arag\u00f3n", "Juan L.", ""], ["Carloni", "Luca P.", ""], ["Martonosi", "Margaret", ""]]}, {"id": "2004.07733", "submitter": "Thomas Luinaud", "authors": "Thomas Luinaud, Thibaut Stimpfling, Jeferson Santiago da Silva, Yvon\n  Savaria and J.M. Pierre Langlois", "title": "Bridging the Gap: FPGAs as Programmable Switches", "comments": "To be published in : IEEE International Conference on High\n  Performance Switching and Routing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of P4, a domain specific language, coupled to PISA, a domain\nspecific architecture, is revolutionizing the networking field. P4 allows to\ndescribe how packets are processed by a programmable data plane, spanning ASICs\nand CPUs, implementing PISA. Because the processing flexibility can be limited\non ASICs, while the CPUs performance for networking tasks lag behind, recent\nworks have proposed to implement PISA on FPGAs. However, little effort has been\ndedicated to analyze whether FPGAs are good candidates to implement PISA. In\nthis work, we take a step back and evaluate the micro-architecture efficiency\nof various PISA blocks. We demonstrate, supported by a theoretical and\nexperimental analysis, that the performance of a few PISA blocks is severely\nlimited by the current FPGA architectures. Specifically, we show that match\ntables and programmable packet schedulers represent the main performance\nbottlenecks for FPGA-based programmable switches. Thus, we explore two avenues\nto alleviate these shortcomings. First, we identify network applications well\ntailored to current FPGAs. Second, to support a wider range of networking\napplications, we propose modifications to the FPGA architectures which can also\nbe of interest out of the networking field.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:15:51 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Luinaud", "Thomas", ""], ["Stimpfling", "Thibaut", ""], ["da Silva", "Jeferson Santiago", ""], ["Savaria", "Yvon", ""], ["Langlois", "J. M. Pierre", ""]]}, {"id": "2004.08906", "submitter": "Evgenii Zheltonozshkii", "authors": "Alex Karbachevsky, Chaim Baskin, Evgenii Zheltonozhskii, Yevgeny\n  Yermolin, Freddy Gabbay, Alex M. Bronstein, Avi Mendelson", "title": "HCM: Hardware-Aware Complexity Metric for Neural Network Architectures", "comments": null, "journal-ref": null, "doi": "10.3390/su13020717", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become common in many fields\nincluding computer vision, speech recognition, and natural language processing.\nAlthough CNN hardware accelerators are already included as part of many SoC\narchitectures, the task of achieving high accuracy on resource-restricted\ndevices is still considered challenging, mainly due to the vast number of\ndesign parameters that need to be balanced to achieve an efficient solution.\nQuantization techniques, when applied to the network parameters, lead to a\nreduction of power and area and may also change the ratio between communication\nand computation. As a result, some algorithmic solutions may suffer from lack\nof memory bandwidth or computational resources and fail to achieve the expected\nperformance due to hardware constraints. Thus, the system designer and the\nmicro-architect need to understand at early development stages the impact of\ntheir high-level decisions (e.g., the architecture of the CNN and the amount of\nbits used to represent its parameters) on the final product (e.g., the expected\npower saving, area, and accuracy). Unfortunately, existing tools fall short of\nsupporting such decisions.\n  This paper introduces a hardware-aware complexity metric that aims to assist\nthe system designer of the neural network architectures, through the entire\nproject lifetime (especially at its early stages) by predicting the impact of\narchitectural and micro-architectural decisions on the final product. We\ndemonstrate how the proposed metric can help evaluate different design\nalternatives of neural network models on resource-restricted devices such as\nreal-time embedded systems, and to avoid making design mistakes at early\nstages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:42:51 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 12:56:25 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Karbachevsky", "Alex", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Yermolin", "Yevgeny", ""], ["Gabbay", "Freddy", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "2004.09309", "submitter": "Gil Shomron", "authors": "Gil Shomron, Uri Weiser", "title": "Non-Blocking Simultaneous Multithreading: Embracing the Resiliency of\n  Deep Neural Networks", "comments": "MICRO-53", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known for their inability to utilize\nunderlying hardware resources due to hardware susceptibility to sparse\nactivations and weights. Even in finer granularities, many of the non-zero\nvalues hold a portion of zero-valued bits that may cause inefficiencies when\nexecuted on hardware. Inspired by conventional CPU simultaneous multithreading\n(SMT) that increases computer resource utilization by sharing them across\nseveral threads, we propose non-blocking SMT (NB-SMT) designated for DNN\naccelerators. Like conventional SMT, NB-SMT shares hardware resources among\nseveral execution flows. Yet, unlike SMT, NB-SMT is non-blocking, as it handles\nstructural hazards by exploiting the algorithmic resiliency of DNNs. Instead of\nopportunistically dispatching instructions while they wait in a reservation\nstation for available hardware, NB-SMT temporarily reduces the computation\nprecision to accommodate all threads at once, enabling a non-blocking\noperation. We demonstrate NB-SMT applicability using SySMT, an NB-SMT-enabled\noutput-stationary systolic array (OS-SA). Compared with a conventional OS-SA, a\n2-threaded SySMT consumes 1.4x the area and delivers 2x speedup with 33% energy\nsavings and less than 1% accuracy degradation of state-of-the-art CNNs with\nImageNet. A 4-threaded SySMT consumes 2.5x the area and delivers, for example,\n3.4x speedup and 39% energy savings with 1% accuracy degradation of 40%-pruned\nResNet-18.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:29:56 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 20:54:37 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Shomron", "Gil", ""], ["Weiser", "Uri", ""]]}, {"id": "2004.09453", "submitter": "Franz-Josef Streit", "authors": "Franz-Josef Streit, Florian Fritz, Andreas Becher, Stefan Wildermann,\n  Stefan Werner, Martin Schmidt-Korth, Michael Pschyklenk, J\\\"urgen Teich", "title": "Secure Boot from Non-Volatile Memory for Programmable SoC Architectures", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern embedded systems, the trust in comprehensive security standards all\nalong the product life cycle has become an increasingly important\naccess-to-market requirement. However, these security standards rely on\nmandatory immunity assumptions such as the integrity and authenticity of an\ninitial system configuration typically loaded from Non-Volatile Memory (NVM).\nThis applies especially to FPGA-based Programmable System-on-Chip (PSoC)\narchitectures, since object codes as well as configuration data easily exceed\nthe capacity of a secure bootROM. In this context, an attacker could try to\nalter the content of the NVM device in order to manipulate the system. The PSoC\ntherefore relies on the integrity of the NVM particularly at boot-time. In this\npaper, we propose a methodology for securely booting from an NVM in a\npotentially unsecure environment by exploiting the reconfigurable logic of the\nFPGA. Here, the FPGA serves as a secure anchor point by performing required\nintegrity and authenticity verifications prior to the configuration and\nexecution of any user application loaded from the NVM on the PSoC. The proposed\nsecure boot process is based on the following assumptions and steps: 1) The\nboot configurationis stored on a fully encrypted Secure Digital memory card (SD\ncard) or alternatively Flash acting as NVM. 2) At boot time, a hardware design\ncalled Trusted Memory-Interface Unit (TMIU) is loaded to verify first the\nauthenticity of the deployed NVM and then after decryption the integrity of its\ncontent. To demonstrate the practicability of our approach, we integrated the\nmethodology into the vendor-specific secure boot process of a Xilinx Zynq PSoC\nand evaluated the design objectives performance, power and resource costs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:09:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Streit", "Franz-Josef", ""], ["Fritz", "Florian", ""], ["Becher", "Andreas", ""], ["Wildermann", "Stefan", ""], ["Werner", "Stefan", ""], ["Schmidt-Korth", "Martin", ""], ["Pschyklenk", "Michael", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "2004.09679", "submitter": "Weizhe Hua", "authors": "Weizhe Hua, Muhammad Umar, Zhiru Zhang, G. Edward Suh", "title": "MgX: Near-Zero Overhead Memory Protection with an Application to Secure\n  DNN Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose MgX, a near-zero overhead memory protection scheme\nfor hardware accelerators. MgX minimizes the performance overhead of off-chip\nmemory encryption and integrity verification by exploiting the\napplication-specific aspect of accelerators. Accelerators tend to explicitly\nmanage data movement between on-chip and off-chip memory, typically at an\nobject granularity that is much larger than cache lines. Exploiting these\naccelerator-specific characteristics, MgX generates version numbers used in\nmemory encryption and integrity verification only using on-chip state without\nstoring them in memory, and also customizes the granularity of the memory\nprotection to match the granularity used by the accelerator. To demonstrate the\napplicability of MgX, we present an in-depth study of MgX for deep neural\nnetwork (DNN) and also describe implementations for H.264 video decoding and\ngenome alignment. Experimental results show that applying MgX has less than 1%\nperformance overhead for both DNN inference and training on state-of-the-art\nDNN architectures.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:46:22 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hua", "Weizhe", ""], ["Umar", "Muhammad", ""], ["Zhang", "Zhiru", ""], ["Suh", "G. Edward", ""]]}, {"id": "2004.09858", "submitter": "Jean-Christophe Le Lann", "authors": "Jean-Christophe Le Lann, Hannah Badier, Florent Kermarrec", "title": "Towards a Hardware DSL Ecosystem : RubyRTL and Friends", "comments": "Open Source Design Automation Workshop, in conjunction with DATE'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For several years, hardware design has been undergoing a surprising revival:\nfueled by open source initiatives, various tools and architectures have\nrecently emerged. This resurgence also involves new hardware description\nlanguages. Inspired by the Migen Python community, we present RubyRTL, a novel\ninternal domain-specific language for hardware design embedded in the Ruby\nlanguage. Ruby -- which is best known in the field of web design -- has proven\nto be an excellent solution for the design of such DSLs, because of its\nmeta-programming features. This paper presents the main aspects of RubyRTL,\nalong with illustrating examples. We also propose a language-neutral\ninterchange format, named Sexpir, that allows to seamlessly exchange RTL\ndesigns between Migen Python DSL and RubyRTL. This paves the way for\ninteractions between various agile communities in the field of open source\nhardware design.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:34:49 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lann", "Jean-Christophe Le", ""], ["Badier", "Hannah", ""], ["Kermarrec", "Florent", ""]]}, {"id": "2004.09923", "submitter": "Seyyed Hossein SeyyedAghaei Rezaei", "authors": "Seyyed Hossein SeyyedAghaei Rezaei, Mehdi Modarressi, Rachata\n  Ausavarungnirun, Mohammad Sadrosadati, Onur Mutlu and Masoud Daneshtalab", "title": "NOM: Network-On-Memory for Inter-Bank Data Transfer in Highly-Banked\n  Memories", "comments": "To appear in IEEE Computer Architecture Letters in 2020", "journal-ref": null, "doi": "10.1109/LCA.2020.2990599", "report-no": "CAL-2019-12-0121", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data copy is a widely-used memory operation in many programs and operating\nsystem services. In conventional computers, data copy is often carried out by\ntwo separate read and write transactions that pass data back and forth between\nthe DRAM chip and the processor chip. Some prior mechanisms propose to avoid\nthis unnecessary data movement by using the shared internal bus in the DRAM\nchip to directly copy data within the DRAM chip (e.g., between two DRAM banks).\nWhile these methods exhibit superior performance compared to conventional\ntechniques, data copy across different DRAM banks is still greatly slower than\ndata copy within the same DRAM bank. Hence, these techniques have limited\nbenefit for the emerging 3D-stacked memories (e.g., HMC and HBM) that contain\nhundreds of DRAM banks across multiple memory controllers. In this paper, we\npresent Network-on-Memory (NoM), a lightweight inter-bank data communication\nscheme that enables direct data copy across both memory banks of a 3D-stacked\nmemory. NoM adopts a TDM-based circuit-switching design, where circuit setup is\ndone by the memory controller. Compared to state-of-the-art approaches, NoM\nenables both fast data copy between multiple DRAM banks and concurrent data\ntransfer operations. Our evaluation shows that NoM improves the performance of\ndata-intensive workloads by 3.8X and 75%, on average, compared to the baseline\nconventional 3D-stacked DRAM architecture and state-of-the-art techniques,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 11:45:29 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Rezaei", "Seyyed Hossein SeyyedAghaei", ""], ["Modarressi", "Mehdi", ""], ["Ausavarungnirun", "Rachata", ""], ["Sadrosadati", "Mohammad", ""], ["Mutlu", "Onur", ""], ["Daneshtalab", "Masoud", ""]]}, {"id": "2004.10044", "submitter": "Fabian Ritter", "authors": "Fabian Ritter and Sebastian Hack", "title": "PMEvo: Portable Inference of Port Mappings for Out-of-Order Processors\n  by Evolutionary Optimization", "comments": "15 pages, accepted at PLDI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving peak performance in a computer system requires optimizations in\nevery layer of the system, be it hardware or software. A detailed understanding\nof the underlying hardware, and especially the processor, is crucial to\noptimize software. One key criterion for the performance of a processor is its\nability to exploit instruction-level parallelism. This ability is determined by\nthe port mapping of the processor, which describes the execution units of the\nprocessor for each instruction.\n  Processor manufacturers usually do not share the port mappings of their\nmicroarchitectures. While approaches to automatically infer port mappings from\nexperiments exist, they are based on processor-specific hardware performance\ncounters that are not available on every platform.\n  We present PMEvo, a framework to automatically infer port mappings solely\nbased on the measurement of the execution time of short instruction sequences.\nPMEvo uses an evolutionary algorithm that evaluates the fitness of candidate\nmappings with an analytical throughput model formulated as a linear program.\nOur prototype implementation infers a port mapping for Intel's Skylake\narchitecture that predicts measured instruction throughput with an accuracy\nthat is competitive to existing work. Furthermore, it finds port mappings for\nAMD's Zen+ architecture and the ARM Cortex-A72 architecture, which are out of\nscope of existing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:34:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ritter", "Fabian", ""], ["Hack", "Sebastian", ""]]}, {"id": "2004.10341", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad\n  Shafique", "title": "DRMap: A Generic DRAM Data Mapping Policy for Energy-Efficient\n  Processing of Convolutional Neural Networks", "comments": "To appear at the 57th Design Automation Conference (DAC), July 2020,\n  San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many convolutional neural network (CNN) accelerators face performance- and\nenergy-efficiency challenges which are crucial for embedded implementations,\ndue to high DRAM access latency and energy. Recently, some DRAM architectures\nhave been proposed to exploit subarray-level parallelism for decreasing the\naccess latency. Towards this, we present a design space exploration methodology\nto study the latency and energy of different mapping policies on different DRAM\narchitectures, and identify the pareto-optimal design choices. The results show\nthat the energy-efficient DRAM accesses can be achieved by a mapping policy\nthat orderly prioritizes to maximize the row buffer hits, bank- and\nsubarray-level parallelism.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:26:23 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2004.10470", "submitter": "Marcelo Brandalero", "authors": "Marcelo Brandalero, Bernardo Neuhaus Lignati, Antonio Carlos Schneider\n  Beck, Muhammad Shafique, Michael H\\\"ubner", "title": "Proactive Aging Mitigation in CGRAs through Utilization-Aware Allocation", "comments": "Please cite this as: M. Brandalero, B. N. Lignati, A. Carlos\n  Schneider Beck, M. Shafique and M. H\\\"ubner, \"Proactive Aging Mitigation in\n  CGRAs through Utilization-Aware Allocation,\" 2020 57th ACM/IEEE Design\n  Automation Conference (DAC), San Francisco, CA, USA, 2020, pp. 1-6, doi:\n  10.1109/DAC18072.2020.9218586", "journal-ref": null, "doi": "10.1109/DAC18072.2020.9218586", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource balancing has been effectively used to mitigate the long-term aging\neffects of Negative Bias Temperature Instability (NBTI) in multi-core and\nGraphics Processing Unit (GPU) architectures. In this work, we investigate this\nstrategy in Coarse-Grained Reconfigurable Arrays (CGRAs) with a novel\napplication-to-CGRA allocation approach. By introducing important extensions to\nthe reconfiguration logic and the datapath, we enable the dynamic movement of\nconfigurations throughout the fabric and allow overutilized Functional Units\n(FUs) to recover from stress-induced NBTI aging. Implementing the approach in a\nresource-constrained state-of-the-art CGRA reveals $2.2\\times$ lifetime\nimprovement with negligible performance overheads and less than $10\\%$ increase\nin area.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:57:15 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 14:35:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Brandalero", "Marcelo", ""], ["Lignati", "Bernardo Neuhaus", ""], ["Beck", "Antonio Carlos Schneider", ""], ["Shafique", "Muhammad", ""], ["H\u00fcbner", "Michael", ""]]}, {"id": "2004.10483", "submitter": "Vojtech Mrazek", "authors": "Vojtech Mrazek, Lukas Sekanina, Zdenek Vasicek", "title": "Using Libraries of Approximate Circuits in Design of Hardware\n  Accelerators of Deep Neural Networks", "comments": "To appear at the 2nd IEEE International Conference on Artificial\n  Intelligence Circuits and Systems (AICAS 2020)", "journal-ref": null, "doi": "10.1109/AICAS48895.2020.9073837", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate circuits have been developed to provide good tradeoffs between\npower consumption and quality of service in error resilient applications such\nas hardware accelerators of deep neural networks (DNN). In order to accelerate\nthe approximate circuit design process and to support a fair benchmarking of\ncircuit approximation methods, libraries of approximate circuits have been\nintroduced. For example, EvoApprox8b contains hundreds of 8-bit approximate\nadders and multipliers. By means of genetic programming we generated an\nextended version of the library in which thousands of 8- to 128-bit approximate\narithmetic circuits are included. These circuits form Pareto fronts with\nrespect to several error metrics, power consumption and other circuit\nparameters. In our case study we show how a large set of approximate\nmultipliers can be used to perform a resilience analysis of a hardware\naccelerator of ResNet DNN and to select the most suitable approximate\nmultiplier for a given application. Results are reported for various instances\nof the ResNet DNN trained on CIFAR-10 benchmark problem.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:42:27 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Mrazek", "Vojtech", ""], ["Sekanina", "Lukas", ""], ["Vasicek", "Zdenek", ""]]}, {"id": "2004.10502", "submitter": "Bharath Srinivas Prabakaran", "authors": "Bharath Srinivas Prabakaran, Vojtech Mrazek, Zdenek Vasicek, Lukas\n  Sekanina, Muhammad Shafique", "title": "ApproxFPGAs: Embracing ASIC-Based Approximate Arithmetic Components for\n  FPGA-Based Systems", "comments": "Accepted for Publication at the 57th Design Automation Conference\n  (DAC), July 2020, San Francisco, CA, USA", "journal-ref": null, "doi": "10.1109/DAC18072.2020.9218533", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been abundant research on the development of Approximate Circuits\n(ACs) for ASICs. However, previous studies have illustrated that ASIC-based ACs\noffer asymmetrical gains in FPGA-based accelerators. Therefore, an AC that\nmight be pareto-optimal for ASICs might not be pareto-optimal for FPGAs. In\nthis work, we present the ApproxFPGAs methodology that uses machine learning\nmodels to reduce the exploration time for analyzing the state-of-the-art\nASIC-based ACs to determine the set of pareto-optimal FPGA-based ACs. We also\nperform a case-study to illustrate the benefits obtained by deploying these\npareto-optimal FPGA-based ACs in a state-of-the-art automation framework to\nsystematically generate pareto-optimal approximate accelerators that can be\ndeployed in FPGA-based systems to achieve high performance or low-power\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:27:47 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Prabakaran", "Bharath Srinivas", ""], ["Mrazek", "Vojtech", ""], ["Vasicek", "Zdenek", ""], ["Sekanina", "Lukas", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2004.10675", "submitter": "Yuan Xue", "authors": "Shuangbai Xue and Yuan Xue", "title": "Speeding-up Logic Design and Refining Hardware EDA Flow by Exploring\n  Chinese Character based Graphical Representation", "comments": "6 pages, may add some evaluations soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical design automation (EDA) techniques have deeply influenced the\ncomputer hardware design, especially in the field of very large scale\nIntegration (VLSI) circuits. Particularly, the popularity of FPGA, ASIC and SOC\napplications have been dramatically increased due to the well developed EDA\ntool chains. Over decades, improving EDA tool in terms of functionality,\nefficiency, accuracy and intelligence is not only the academic research hot\nspot, but the industry attempting goal as well.\n  In this paper, a novel perspective is taken to review current mainstream EDA\nworking flow and design methods, aiming to shorten the EDA design periods and\nsimplify the logic design overload significantly. Specifically, three major\ncontributions are devoted. First, a Chinese character based representation\nsystem (CCRS), which is used for presenting logical abstract syntax tree, is\nproposed. Second, the register-transfer-level (RTL) level symbolic description\ntechnique for CCRS are introduced to replace traditional text-based programming\nmethods. Finally, the refined EDA design flow based on CCRS is discussed. It is\nconvincing that the graphic non-pure-english based EDA flow could lower the\ndesign cost and complexity. As a fundamental trial in this new field, it is\nconfirmative that a lot of following works will make the related EDA\ndevelopment prosperous.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:24:43 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Xue", "Shuangbai", ""], ["Xue", "Yuan", ""]]}, {"id": "2004.10936", "submitter": "Siyu Liao", "authors": "Chunhua Deng, Siyu Liao, Yi Xie, Keshab K. Parhi, Xuehai Qian, Bo Yuan", "title": "PERMDNN: Efficient Compressed DNN Architecture with Permuted Diagonal\n  Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) has emerged as the most important and popular\nartificial intelligent (AI) technique. The growth of model size poses a key\nenergy efficiency challenge for the underlying computing platform. Thus, model\ncompression becomes a crucial problem. However, the current approaches are\nlimited by various drawbacks. Specifically, network sparsification approach\nsuffers from irregularity, heuristic nature and large indexing overhead. On the\nother hand, the recent structured matrix-based approach (i.e., CirCNN) is\nlimited by the relatively complex arithmetic computation (i.e., FFT), less\nflexible compression ratio, and its inability to fully utilize input sparsity.\nTo address these drawbacks, this paper proposes PermDNN, a novel approach to\ngenerate and execute hardware-friendly structured sparse DNN models using\npermuted diagonal matrices. Compared with unstructured sparsification approach,\nPermDNN eliminates the drawbacks of indexing overhead, non-heuristic\ncompression effects and time-consuming retraining. Compared with circulant\nstructure-imposing approach, PermDNN enjoys the benefits of higher reduction in\ncomputational complexity, flexible compression ratio, simple arithmetic\ncomputation and full utilization of input sparsity. We propose PermDNN\narchitecture, a multi-processing element (PE) fully-connected (FC)\nlayer-targeted computing engine. The entire architecture is highly scalable and\nflexible, and hence it can support the needs of different applications with\ndifferent model configurations. We implement a 32-PE design using CMOS 28nm\ntechnology. Compared with EIE, PermDNN achieves 3.3x~4.8x higher throughout,\n5.9x~8.5x better area efficiency and 2.8x~4.0x better energy efficiency on\ndifferent workloads. Compared with CirCNN, PermDNN achieves 11.51x higher\nthroughput and 3.89x better energy efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 02:26:40 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Deng", "Chunhua", ""], ["Liao", "Siyu", ""], ["Xie", "Yi", ""], ["Parhi", "Keshab K.", ""], ["Qian", "Xuehai", ""], ["Yuan", "Bo", ""]]}, {"id": "2004.11059", "submitter": "Marius Meyer", "authors": "Marius Meyer, Tobias Kenter and Christian Plessl", "title": "Evaluating FPGA Accelerator Performance with a Parameterized OpenCL\n  Adaptation of the HPCChallenge Benchmark Suite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGAs have found increasing adoption in data center applications since a new\ngeneration of high-level tools have become available which noticeably reduce\ndevelopment time for FPGA accelerators and still provide high quality of\nresults. There is however no high-level benchmark suite available which\nspecifically enables a comparison of FPGA architectures, programming tools and\nlibraries for HPC applications.\n  To fill this gap, we have developed an OpenCL-based open source\nimplementation of the HPCC benchmark suite for Xilinx and Intel FPGAs. This\nbenchmark can serve to analyze the current capabilities of FPGA devices, cards\nand development tool flows, track progress over time and point out specific\ndifficulties for FPGA acceleration in the HPC domain. Additionally, the\nbenchmark documents proven performance optimization patterns. We will continue\noptimizing and porting the benchmark for new generations of FPGAs and design\ntools and encourage active participation to create a valuable tool for the\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:38:18 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:41:06 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:16:08 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Meyer", "Marius", ""], ["Kenter", "Tobias", ""], ["Plessl", "Christian", ""]]}, {"id": "2004.11080", "submitter": "Thomas Preu{\\ss}er", "authors": "Thomas B. Preu{\\ss}er, Monica Chiosa, Alexander Weiss, Gustavo Alonso", "title": "Using DSP Slices as Content-Addressable Update Queues", "comments": "Submitted to FPL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-Addressable Memory (CAM) is a powerful abstraction for building\nmemory caches, routing tables and hazard detection logic. Without a native CAM\nstructure available on FPGA devices, their functionality must be emulated using\nthe structural primitives at hand. Such an emulation causes significant\noverhead in the consumption of the underlying resources, typically\ngeneral-purpose fabric and on-chip block RAM (BRAM). This often motivates\nmitigating trade-offs, such as the reduction of the associativity of memory\ncaches. This paper describes a technique to implement the hazard resolution in\na memory update queue that hides the off-chip memory readout latency of\nread-modify-write cycles while guaranteeing the delivery of the full memory\nbandwidth. The innovative use of DSP slices allows them to assume and combine\nthe functions of (a) the tag and data storage, (b) the tag matching, and (c)\nthe data update in this key-value storage scenario. The proposed approach\nprovides designers with extra flexibility by adding this resource type as\nanother option to implement CAM.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:19:37 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Preu\u00dfer", "Thomas B.", ""], ["Chiosa", "Monica", ""], ["Weiss", "Alexander", ""], ["Alonso", "Gustavo", ""]]}, {"id": "2004.13027", "submitter": "Sangkug Lym", "authors": "Sangkug Lym, Mattan Erez", "title": "FlexSA: Flexible Systolic Array Architecture for Efficient Pruned DNN\n  Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Modern deep learning models have high memory and computation cost. To make\nthem fast and memory-cost efficient, structured model pruning is commonly used.\nWe find that pruning a model using a common training accelerator with large\nsystolic arrays is extremely performance-inefficient. To make a systolic array\nefficient for pruning and training, we propose FlexSA, a flexible systolic\narray architecture. FlexSA dynamically reconfigures the systolic array\nstructure and offers multiple sub-systolic operating modes, which are designed\nfor energy- and memory bandwidth-efficient processing of tensors with different\nsizes and shapes. We also present a compilation heuristic for tiling\nmatrix-multiplication-and-accumulation operations in a training workload to\nbest utilize the resources of FlexSA. Based on our evaluation, FlexSA with the\nproposed compilation heuristic improves compute resource utilization of pruning\nand training modern CNN models by 37% compared to a conventional training\naccelerator with a large systolic array. FlexSA also improves on-chip data\nreuse by 1.7X saving 28% energy compared to naive systolic array splitting.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:51:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lym", "Sangkug", ""], ["Erez", "Mattan", ""]]}, {"id": "2004.13074", "submitter": "Phat Nguyen", "authors": "Kevin Weston, Vahid Jafanza, Arnav Kansal, Abhishek Taur, Mohamed\n  Zahran, Abdullah Muzahid", "title": "The Case for Learning Application Behavior to Improve Hardware Energy\n  Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer applications are continuously evolving. However, significant\nknowledge can be harvested from a set of applications and applied in the\ncontext of unknown applications. In this paper, we propose to use the harvested\nknowledge to tune hardware configurations. The goal of such tuning is to\nmaximize hardware efficiency (i.e., maximize an applications performance while\nminimizing the energy consumption). Our proposed approach, called FORECASTER,\nuses a deep learning model to learn what configuration of hardware resources\nprovides the optimal energy efficiency for a certain behavior of an\napplication. During the execution of an unseen application, the model uses the\nlearned knowledge to reconfigure hardware resources in order to maximize energy\nefficiency. We have provided a detailed design and implementation of FORECASTER\nand compared its performance against a prior state-of-the-art hardware\nreconfiguration approach. Our results show that FORECASTER can save as much as\n18.4% system power over the baseline set up with all resources. On average,\nFORECASTER saves 16% system power over the baseline setup while sacrificing\nless than 0.01% of overall performance. Compared to the prior scheme,\nFORECASTER increases power savings by 7%.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:11:12 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:12:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Weston", "Kevin", ""], ["Jafanza", "Vahid", ""], ["Kansal", "Arnav", ""], ["Taur", "Abhishek", ""], ["Zahran", "Mohamed", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "2004.13075", "submitter": "Kim Bjerge", "authors": "Kim Bjerge, Jonathan Horsted Schougaard and Daniel Ejnar Larsen", "title": "A scalable and efficient convolutional neural network accelerator using\n  HLS for a System on Chip design", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a configurable Convolutional Neural Network Accelerator\n(CNNA) for a System on Chip design (SoC). The goal was to accelerate inference\nof different deep learning networks on an embedded SoC platform. The presented\nCNNA has a scalable architecture which uses High Level Synthesis (HLS) and\nSystemC for the hardware accelerator. It is able to accelerate any\nConvolutional Neural Network (CNN) exported from Python and supports a\ncombination of convolutional, max-pooling, and fully connected layers. A\ntraining method with fixed-point quantized weights is proposed and presented in\nthe paper. The CNNA is template-based, enabling it to scale for different\ntargets of the Xilinx Zynq platform. This approach enables design space\nexploration, which makes it possible to explore several configurations of the\nCNNA during C- and RTL-simulation, fitting it to the desired platform and\nmodel. The CNN VGG16 was used to test the solution on a Xilinx Ultra96 board\nusing PYNQ. The result gave a high level of accuracy in training with an\nauto-scaled fixed-point Q2.14 format compared to a similar floating-point\nmodel. It was able to perform inference in 2.0 seconds, while having an average\npower consumption of 2.63 W, which corresponds to a power efficiency of 6.0\nGOPS/W.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:12:22 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 06:58:55 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Bjerge", "Kim", ""], ["Schougaard", "Jonathan Horsted", ""], ["Larsen", "Daniel Ejnar", ""]]}, {"id": "2004.13320", "submitter": "Sheldon Tan", "authors": "Shuyuan Yu, Han Zhou, Shaoyi Peng, Hussam Amrouch, Joerg Henkel,\n  Sheldon X.-D. Tan", "title": "Run-Time Accuracy Reconfigurable Stochastic Computing for Dynamic\n  Reliability and Power Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel accuracy-reconfigurable stochastic\ncomputing (ARSC) framework for dynamic reliability and power management.\nDifferent than the existing stochastic computing works, where the accuracy\nversus power/energy trade-off is carried out in the design time, the new ARSC\ndesign can change accuracy or bit-width of the data in the run-time so that it\ncan accommodate the long-term aging effects by slowing the system clock\nfrequency at the cost of accuracy while maintaining the throughput of the\ncomputing. We validate the ARSC concept on a discrete cosine transformation\n(DCT) and inverse DCT designs for image compressing/decompressing applications,\nwhich are implemented on Xilinx Spartan-6 family XC6SLX45 platform.\nExperimental results shows that the new design can easily mitigate the\nlong-term aging induced effects by accuracy trade-off while maintaining the\nthroughput of the whole computing process using simple frequency scaling. We\nfurther show that one-bit precision loss for input data, which translated to\n3.44dB of the accuracy loss in term of Peak Signal to Noise Ratio for images,\nwe can sufficiently compensate the NBTI induced aging effects in 10 years while\nmaintaining the pre-aging computing throughput of 7.19 frames per second. At\nthe same time, we can save 74\\% power consumption by 10.67dB of accuracy loss.\nThe proposed ARSC computing framework also allows much aggressive frequency\nscaling, which can lead to order of magnitude power savings compared to the\ntraditional dynamic voltage and frequency scaling (DVFS) techniques.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:22:49 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yu", "Shuyuan", ""], ["Zhou", "Han", ""], ["Peng", "Shaoyi", ""], ["Amrouch", "Hussam", ""], ["Henkel", "Joerg", ""], ["Tan", "Sheldon X. -D.", ""]]}]