[{"id": "2003.00151", "submitter": "John Demme PhD", "authors": "John Demme", "title": "A Compiler Infrastructure for FPGA and ASIC Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This whitepaper proposes a unified framework for hardware design tools to\nease the development and inter-operability of said tools. By creating a large\necosystem of hardware development tools across vendors, academia, and the open\nsource community, we hope to significantly increase much need productivity in\nhardware design.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 01:52:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Demme", "John", ""]]}, {"id": "2003.00840", "submitter": "Avichal Rakesh", "authors": "Abhishek Saroha, Avichal Rakesh, Rajiv Kumar Tripathi", "title": "FPGA Implementation of Minimum Mean Brightness Error Bi-Histogram\n  Equalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histogram Equalization (HE) is a popular method for contrast enhancement.\nGenerally, mean brightness is not conserved in Histogram Equalization.\nInitially, Bi-Histogram Equalization (BBHE) was proposed to enhance contrast\nwhile maintaining a the mean brightness. However, when mean brightness is\nprimary concern, Minimum Mean Brightness Error Bi-Histogram Equalization\n(MMBEBHE) is the best technique. There are several implementations of Histogram\nEqualization on FPGA, however to our knowledge MMBEBHE has not been implemented\non FPGAs before. Therefore, we present an implementation of MMBEBHE on FPGA.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 06:42:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Saroha", "Abhishek", ""], ["Rakesh", "Avichal", ""], ["Tripathi", "Rajiv Kumar", ""]]}, {"id": "2003.00862", "submitter": "Bing Li", "authors": "Grace Li Zhang, Bing Li, Meng Li, Bei Yu, David Z. Pan, Michaela\n  Brunner, Georg Sigl and Ulf Schlichtmann", "title": "TimingCamouflage+: Netlist Security Enhancement with Unconventional\n  Timing (with Appendix)", "comments": null, "journal-ref": null, "doi": "10.1109/TCAD.2020.2974338", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in reverse engineering, attackers can reconstruct a\nnetlist to counterfeit chips by opening the die and scanning all layers of\nauthentic chips. This relatively easy counterfeiting is made possible by the\nuse of the standard simple clocking scheme, where all combinational blocks\nfunction within one clock period, so that a netlist of combinational logic\ngates and flip-flops is sufficient to duplicate a design. In this paper, we\npropose to invalidate the assumption that a netlist completely represents the\nfunction of a circuit with unconventional timing. With the introduced\nwave-pipelining paths, attackers have to capture gate and interconnect delays\nduring reverse engineering, or to test a huge number of combinational paths to\nidentify the wave-pipelining paths. To hinder the test-based attack, we\nconstruct false paths with wave-pipelining to increase the counterfeiting\nchallenge. Experimental results confirm that wave-pipelining true paths and\nfalse paths can be constructed in benchmark circuits successfully with only a\nnegligible cost, thus thwarting the potential attack techniques.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:10:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Grace Li", ""], ["Li", "Bing", ""], ["Li", "Meng", ""], ["Yu", "Bei", ""], ["Pan", "David Z.", ""], ["Brunner", "Michaela", ""], ["Sigl", "Georg", ""], ["Schlichtmann", "Ulf", ""]]}, {"id": "2003.01551", "submitter": "Yang Zhao", "authors": "Hongjie Wang, Yang Zhao, Chaojian Li, Yue Wang, Yingyan Lin", "title": "A New MRAM-based Process In-Memory Accelerator for Efficient Neural\n  Network Training with Floating Point Precision", "comments": "Accepted by the IEEE International Symposium on Circuits and Systems\n  2020 (ISCAS'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The excellent performance of modern deep neural networks (DNNs) comes at an\noften prohibitive training cost, limiting the rapid development of DNN\ninnovations and raising various environmental concerns. To reduce the dominant\ndata movement cost of training, process in-memory (PIM) has emerged as a\npromising solution as it alleviates the need to access DNN weights. However,\nstate-of-the-art PIM DNN training accelerators employ either analog/mixed\nsignal computing which has limited precision or digital computing based on a\nmemory technology that supports limited logic functions and thus requires\ncomplicated procedure to realize floating point computation. In this paper, we\npropose a spin orbit torque magnetic random access memory (SOT-MRAM) based\ndigital PIM accelerator that supports floating point precision. Specifically,\nthis new accelerator features an innovative (1) SOT-MRAM cell, (2) full\naddition design, and (3) floating point computation. Experiment results show\nthat the proposed SOT-MRAM PIM based DNN training accelerator can achieve\n3.3$\\times$, 1.8$\\times$, and 2.5$\\times$ improvement in terms of energy,\nlatency, and area, respectively, compared with a state-of-the-art PIM based DNN\ntraining accelerator.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:58:54 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:49:47 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wang", "Hongjie", ""], ["Zhao", "Yang", ""], ["Li", "Chaojian", ""], ["Wang", "Yue", ""], ["Lin", "Yingyan", ""]]}, {"id": "2003.03043", "submitter": "Seyedramin Rasoulinezhad", "authors": "SeyedRamin Rasoulinezhad, Siddhartha, Hao Zhou, Lingli Wang, David\n  Boland, Philip H.W. Leong", "title": "LUXOR: An FPGA Logic Cell Architecture for Efficient Compressor Tree\n  Implementations", "comments": "In Proceedings of the 2020 ACM/SIGDA International Symposium on\n  Field-Programmable Gate Arrays (FPGA'20), February 23-25, 2020, Seaside, CA,\n  USA", "journal-ref": null, "doi": "10.1145/3373087.3375303", "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two tiers of modifications to FPGA logic cell architecture to\ndeliver a variety of performance and utilization benefits with only minor area\noverheads. In the irst tier, we augment existing commercial logic cell\ndatapaths with a 6-input XOR gate in order to improve the expressiveness of\neach element, while maintaining backward compatibility. This new architecture\nis vendor-agnostic, and we refer to it as LUXOR. We also consider a secondary\ntier of vendor-speciic modifications to both Xilinx and Intel FPGAs, which we\nrefer to as X-LUXOR+ and I-LUXOR+ respectively. We demonstrate that compressor\ntree synthesis using generalized parallel counters (GPCs) is further improved\nwith the proposed modifications. Using both the Intel adaptive logic module and\nthe Xilinx slice at the 65nm technology node for a comparative study, it is\nshown that the silicon area overhead is less than 0.5% for LUXOR and 5-6% for\nLUXOR+, while the delay increments are 1-6% and 3-9% respectively. We\ndemonstrate that LUXOR can deliver an average reduction of 13-19% in logic\nutilization on micro-benchmarks from a variety of domains.BNN benchmarks\nbenefit the most with an average reduction of 37-47% in logic utilization,\nwhich is due to the highly-efficient mapping of the XnorPopcount operation on\nour proposed LUXOR+ logic cells.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:54:11 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Rasoulinezhad", "SeyedRamin", ""], ["Siddhartha", "", ""], ["Zhou", "Hao", ""], ["Wang", "Lingli", ""], ["Boland", "David", ""], ["Leong", "Philip H. W.", ""]]}, {"id": "2003.04498", "submitter": "Stefan Saroiu", "authors": "Lucian Cojocar, Jeremie Kim, Minesh Patel, Lillian Tsai, Stefan\n  Saroiu, Alec Wolman, Onur Mutlu", "title": "Are We Susceptible to Rowhammer? An End-to-End Methodology for Cloud\n  Providers", "comments": "A version of this paper will appear in the IEEE S&P 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers are concerned that Rowhammer poses a potentially critical\nthreat to their servers, yet today they lack a systematic way to test whether\nthe DRAM used in their servers is vulnerable to Rowhammer attacks. This paper\npresents an end-to-end methodology to determine if cloud servers are\nsusceptible to these attacks. With our methodology, a cloud provider can\nconstruct worst-case testing conditions for DRAM.\n  We apply our methodology to three classes of servers from a major cloud\nprovider. Our findings show that none of the CPU instruction sequences used in\nprior work to mount Rowhammer attacks create worst-case DRAM testing\nconditions. To address this limitation, we develop an instruction sequence that\nleverages microarchitectural side-effects to ``hammer'' DRAM at a near-optimal\nrate on modern Intel Skylake and Cascade Lake platforms. We also design a DDR4\nfault injector that can reverse engineer row adjacency for any DDR4 DIMM. When\napplied to our cloud provider's DIMMs, we find that DRAM rows do not always\nfollow a linear map.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 02:05:13 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Cojocar", "Lucian", ""], ["Kim", "Jeremie", ""], ["Patel", "Minesh", ""], ["Tsai", "Lillian", ""], ["Saroiu", "Stefan", ""], ["Wolman", "Alec", ""], ["Mutlu", "Onur", ""]]}, {"id": "2003.05315", "submitter": "Michihiro Shintani Dr.", "authors": "Riaz-ul-haque Mian and Michihiro Shintani and Michiko Inoue", "title": "Cycle-Accurate Evaluation of Software-Hardware Co-Design of Decimal\n  Computation in RISC-V Ecosystem", "comments": "IEEE double column format, 6 pages with 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-hardware co-design solutions for decimal computation can provide\nseveral Pareto points to development of embedded systems in terms of hardware\ncost and performance. This paper demonstrates how to accurately evaluate such\nco-design solutions using RISC-V ecosystem. In a software-hardware co-design\nsolution, a part of solution requires dedicated hardware. In our evaluation\nframework, we develop new decimal oriented instructions supported by an\naccelerator. The framework can realize cycle-accurate analysis for performance\nas well as hardware overhead for co-design solutions for decimal computation.\nThe obtained performance result is compared with an estimation with dummy\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:06:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Mian", "Riaz-ul-haque", ""], ["Shintani", "Michihiro", ""], ["Inoue", "Michiko", ""]]}, {"id": "2003.06310", "submitter": "Pai-Yu Tan", "authors": "Pai-Yu Tan, Po-Yao Chuang, Yen-Ting Lin, Cheng-Wen Wu, and Juin-Ming\n  Lu", "title": "A Power-Efficient Binary-Weight Spiking Neural Network Architecture for\n  Real-Time Object Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network hardware is considered an essential part of future edge\ndevices. In this paper, we propose a binary-weight spiking neural network\n(BW-SNN) hardware architecture for low-power real-time object classification on\nedge platforms. This design stores a full neural network on-chip, and hence\nrequires no off-chip bandwidth. The proposed systolic array maximizes data\nreuse for a typical convolutional layer. A 5-layer convolutional BW-SNN\nhardware is implemented in 90nm CMOS. Compared with state-of-the-art designs,\nthe area cost and energy per classification are reduced by 7$\\times$ and\n23$\\times$, respectively, while also achieving a higher accuracy on the MNIST\nbenchmark. This is also a pioneering SNN hardware architecture that supports\nadvanced CNN architectures.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 11:25:00 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Tan", "Pai-Yu", ""], ["Chuang", "Po-Yao", ""], ["Lin", "Yen-Ting", ""], ["Wu", "Cheng-Wen", ""], ["Lu", "Juin-Ming", ""]]}, {"id": "2003.06727", "submitter": "Farzad Farshchi", "authors": "Farzad Farshchi, Muhammad Saeed Abrishami, and Sied Mehdi Fakhraie", "title": "New Approximate Multiplier for Low Power Digital Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper a low power multiplier is proposed. The proposed multiplier\nutilizes Broken-Array Multiplier approximation method on the conventional\nmodified Booth multiplier. This method reduces the total power consumption of\nmultiplier up to 58% at the cost of a small decrease in output accuracy. The\nproposed multiplier is compared with other approximate multipliers in terms of\npower consumption and accuracy. Furthermore, to have a better evaluation of the\nproposed multiplier efficiency, it has been used in designing a 30-tap low-pass\nFIR filter and the power consumption and accuracy are compared with that of a\nfilter with conventional booth multipliers. The simulation results show a 17.1%\npower reduction at the cost of only 0.4dB decrease in the output SNR.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 01:04:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Farshchi", "Farzad", ""], ["Abrishami", "Muhammad Saeed", ""], ["Fakhraie", "Sied Mehdi", ""]]}, {"id": "2003.07440", "submitter": "Archisman Ghosh", "authors": "Archisman Ghosh, Debayan Das and Shreyas Sen", "title": "Physical Time-Varying Transfer Functions as Generic Low-Overhead\n  Power-SCA Countermeasure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically-secure cryptographic algorithms leak significant side channel\ninformation through their power supplies when implemented on a physical\nplatform. These side channel leakages can be exploited by an attacker to\nextract the secret key of an embedded device. The existing state-of-the-art\ncountermeasures mainly focus on the power balancing, gate-level masking, or\nsignal-to-noise (SNR) reduction using noise injection and signature\nattenuation, all of which suffer either from the limitations of high power/area\noverheads, performance degradation or are not synthesizable. In this article,\nwe propose a generic low-overhead digital-friendly power SCA countermeasure\nutilizing physical Time-Varying Transfer Functions (TVTF) by randomly shuffling\ndistributed switched capacitors to significantly obfuscate the traces in the\ntime domain. System-level simulation results of the TVTF-AES implemented in\nTSMC 65nm CMOS technology show > 4000x MTD improvement over the unprotected\nimplementation with nearly 1.25x power and 1.2x area overheads, and without any\nperformance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:06:04 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ghosh", "Archisman", ""], ["Das", "Debayan", ""], ["Sen", "Shreyas", ""]]}, {"id": "2003.08648", "submitter": "Khanh N. Dang", "authors": "Khanh N. Dang, Akram Ben Ahmed, Abderazek Ben Abdallah, and Xuan-Tu\n  Tran", "title": "Report on power, thermal and reliability prediction for 3D\n  Networks-on-Chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By combining Three Dimensional Integrated Circuits with the Network-on-Chip\ninfrastructure to obtain 3D Networks-on-Chip (3D-NoCs), the new on-chip\ncommunication paradigm brings several advantages on lower power, smaller\nfootprint and lower latency. However, thermal dissipation is one of the most\ncritical challenges for 3D-ICs where the heat cannot easily transfer through\nseveral layers of silicon. Consequently, the high-temperature area also\nconfronts the reliability threat as the Mean Time to Failure (MTTF) decreases\nexponentially with the operating temperature. Apparently, 3D-NoCs must tackle\nthis fundamental problem in order to be widely used. Therefore, in this work,\nwe investigate the thermal distribution and reliability prediction of 3D-NoCs.\nWe first present a new method to help simulate the temperature (both steady and\ntransient) using traffics value from realistic and synthetic benchmarks and the\npower consumption from standard VLSI design flow. Then, based on the proposed\nmethod, we further predict the relative reliability between different parts of\nthe network. Experimental results show that the method has an extremely fast\nexecution time in comparison to the acceleration lifetime test. Furthermore, we\ncompare the thermal behavior and reliability between Monolithic design and\nTSV-based TSV. We also explorer the ability to implement the thermal via a\nmechanism to help reduce the operating temperature.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 09:50:43 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Dang", "Khanh N.", ""], ["Ahmed", "Akram Ben", ""], ["Abdallah", "Abderazek Ben", ""], ["Tran", "Xuan-Tu", ""]]}, {"id": "2003.09016", "submitter": "Anish N K", "authors": "Samet E. Arda, Anish NK, A. Alper Goksoy, Nirmal Kumbhare, Joshua\n  Mack, Anderson L. Sartor, Ali Akoglu, Radu Marculescu, Umit Y. Ogras", "title": "DS3: A System-Level Domain-Specific System-on-Chip Simulation Framework", "comments": "14 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous systems-on-chip (SoCs) are highly favorable computing platforms\ndue to their superior performance and energy efficiency potential compared to\nhomogeneous architectures. They can be further tailored to a specific domain of\napplications by incorporating processing elements (PEs) that accelerate\nfrequently used kernels in these applications. However, this potential is\ncontingent upon optimizing the SoC for the target domain and utilizing its\nresources effectively at runtime. To this end, system-level design - including\nscheduling, power-thermal management algorithms and design space exploration\nstudies - plays a crucial role. This paper presents a system-level\ndomain-specific SoC simulation (DS3) framework to address this need. DS3\nenables both design space exploration and dynamic resource management for\npower-performance optimization of domain applications. We showcase DS3 using\nsix real-world applications from wireless communications and radar processing\ndomain. DS3, as well as the reference applications, is shared as open-source\nsoftware to stimulate research in this area.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 21:00:09 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Arda", "Samet E.", ""], ["NK", "Anish", ""], ["Goksoy", "A. Alper", ""], ["Kumbhare", "Nirmal", ""], ["Mack", "Joshua", ""], ["Sartor", "Anderson L.", ""], ["Akoglu", "Ali", ""], ["Marculescu", "Radu", ""], ["Ogras", "Umit Y.", ""]]}, {"id": "2003.09616", "submitter": "Khanh N. Dang", "authors": "Khanh N. Dang, Yuichi Okuyama, Abderazek Ben Abdallah", "title": "Soft-Error and Hard-fault Tolerant Architecture and Routing Algorithm\n  for Reliable 3D-NoC Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network-on-Chip (NoC) paradigm has been proposed as an auspicious solution to\nhandle the strict communication requirements between the increasingly large\nnumber of cores on a single multi and many-core chips. However, NoC systems are\nexposed to a variety of manufacturing, design and energetic particles factors\nmaking them vulnerable to permanent (hard) faults and transient (soft) errors.\nIn this paper, we present a comprehensive soft error and hard fault tolerant\n3D-NoC architecture, named 3D-Hard-Fault-Soft-Error-Tolerant-OASIS-NoC\n(3D-FETO). With the aid of adaptive algorithms, 3D-FETO is capable of detecting\nand recovering from soft errors occurring in the routing pipeline stages and is\nleveraging on reconfigurable components to handle permanent faults occurrence\nin links, input buffers, and crossbar. In-depth evaluation results show that\nthe 3D-FETO system is able to work around different kinds of hard faults and\nsoft errors while ensuring graceful performance degradation, minimizing the\nadditional hardware complexity and remaining power-efficient.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 09:53:31 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Dang", "Khanh N.", ""], ["Okuyama", "Yuichi", ""], ["Abdallah", "Abderazek Ben", ""]]}, {"id": "2003.09617", "submitter": "Khanh N. Dang", "authors": "Khanh N Dang, Michael Meyer, Yuichi Okuyama, Abderazek Ben Abdallah", "title": "Reliability Assessment and Quantitative Evaluation of Soft-Error\n  Resilient 3D Network-on-Chip Systems", "comments": null, "journal-ref": "2016 IEEE 25th Asian Test Symposium (ATS)", "doi": "10.1109/ATS.2016.37", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-Dimensional Networks-on-Chips (3D-NoCs) have been proposed as an\nauspicious solution, merging the high parallelism of the Network-on-Chip (NoC)\nparadigm with the high-performance and low-power cost of 3D-ICs. However, as\ntechnology scales down, the reliability issues are becoming more crucial,\nespecially for complex 3D-NoC which provides the communication requirements of\nmulti and many-core systems-on-chip. Reliability assessment is prominent for\nearly stages of the manufacturing process to prevent costly redesigns of a\ntarget system. In this paper, we present an accurate reliability assessment and\nquantitative evaluation of a soft-error resilient 3D-NoC based on a soft-error\nresilient mechanism. The system can recover from transient errors occurring in\ndifferent pipeline stages of the router. Based on this analysis, the effects of\nfailures in the network's principal components are determined.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 09:57:53 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Dang", "Khanh N", ""], ["Meyer", "Michael", ""], ["Okuyama", "Yuichi", ""], ["Abdallah", "Abderazek Ben", ""]]}, {"id": "2003.10300", "submitter": "Sumon Bose Mr.", "authors": "Sumon Kumar Bose, Vivek Mohan, and Arindam Basu", "title": "A 75kb SRAM in 65nm CMOS for In-Memory Computing Based Neuromorphic\n  Image Denoising", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an in-memory computing (IMC) architecture for image\ndenoising. The proposed SRAM based in-memory processing framework works in\ntandem with approximate computing on a binary image generated from neuromorphic\nvision sensors. Implemented in TSMC 65nm process, the proposed architecture\nenables approximately 2000X energy savings (approximately 222X from IMC)\ncompared to a digital implementation when tested with the video recordings from\na DAVIS sensor and achieves a peak throughput of 1.25-1.66 frames/us.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:36:12 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bose", "Sumon Kumar", ""], ["Mohan", "Vivek", ""], ["Basu", "Arindam", ""]]}, {"id": "2003.10472", "submitter": "Alexander Beasley", "authors": "Alexander E. Beasley", "title": "A distributed memory, local configuration technique for re-configurable\n  logic designs", "comments": "13 files, 19 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use and location of memory in integrated circuits plays a key factor in\ntheir performance. Memory requires large physical area, access times limit\noverall system performance and connectivity can result in large fan-out. Modern\nFPGA systems and ASICs contain an area of memory used to set the operation of\nthe device from a series of commands set by a host. Implementing these settings\nregisters requires a level of care otherwise the resulting implementation can\nresult in a number of large fan-out nets that consume valuable resources\ncomplicating the placement of timing critical pathways. This paper presents an\narchitecture for implementing and programming these settings registers in a\ndistributed method across an FPGA and how the presented architecture works in\nboth clock-domain crossing and dynamic partial re-configuration applications.\nThe design is compared to that of a `global' settings register architecture. We\nimplement the architectures using Intel FPGAs Quartus Prime software targeting\nan Intel FPGA Cyclone V. It is shown that the distributed memory architecture\nhas a smaller resource cost (as small as 25% of the ALMs and 20% of the\nregisters) compared to the global memory architectures.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:05:22 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Beasley", "Alexander E.", ""]]}, {"id": "2003.10644", "submitter": "Fabio Lorenzo Traversa Ph.D.", "authors": "John Aiken and Fabio L. Traversa", "title": "Memcomputing for Accelerated Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce the concept of an entirely new circuit\narchitecture based on the novel, physics-inspired computing paradigm:\nMemcomputing. In particular, we focus on digital memcomputing machines (DMMs)\nthat can be designed leveraging properties of non-linear dynamical systems;\nultimate descriptors of electronic circuits. The working principle of these\nsystems relies on the ability of currents and voltages of the circuit to\nself-organize in order to satisfy mathematical relations. In particular for\nthis work, we discuss self-organizing gates, namely Self-Organizing Algebraic\nGates (SOAGs), aimed to solve linear inequalities and therefore used to solve\noptimization problems in Integer Linear Programming (ILP) format. Unlike\nconventional I\\O gates, SOAGs are terminal-agnostic, meaning each terminal\nhandles a superposition of input and output signals. When appropriately\nassembled to represent a given ILP problem, the corresponding self-organizing\ncircuit converges to the equilibria that express the solutions to the problem\nat hand. Because DMM's components are non-quantum, the ordinary differential\nequations describing it can be efficiently simulated on our modern computers in\nsoftware, as well as be built in hardware with off-of-the-shelf technology. As\nan example, we show the performance of this novel approach implemented as\nSoftware as a Service (MemCPU XPC) to address an ILP problem. Compared to\ntoday's best solution found using a world renowned commercial solver, MemCPU\nXPC brings the time to solution down from 23 hours to less than 2 minutes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:49:40 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Aiken", "John", ""], ["Traversa", "Fabio L.", ""]]}, {"id": "2003.11018", "submitter": "Khanh N. Dang", "authors": "Khanh N Dang, Michael Meyer, Yuichi Okuyama, Abderazek Ben Abdallah", "title": "A low-overhead soft-hard fault-tolerant architecture, design and\n  management scheme for reliable high-performance many-core 3D-NoC systems", "comments": "arXiv admin note: text overlap with arXiv:2003.09616", "journal-ref": "The Journal of Supercomputing volume 73 (2017)", "doi": "10.1007/s11227-016-1951-0", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Network-on-Chip (NoC) paradigm has been proposed as a favorable solution\nto handle the strict communication requirements between the increasingly large\nnumber of cores on a single chip. However, NoC systems are exposed to the\naggressive scaling down of transistors, low operating voltages, and high\nintegration and power densities, making them vulnerable to permanent (hard)\nfaults and transient (soft) errors. A hard fault in a NoC can lead to external\nblocking, causing congestion across the whole network. A soft error is more\nchallenging because of its silent data corruption, which leads to a large area\nof erroneous data due to error propagation, packet re-transmission, and\ndeadlock. In this paper, we present the architecture and design of a\ncomprehensive soft error and hard fault-tolerant 3D-NoC system, named\n3D-Hard-Fault-Soft-Error-Tolerant-OASIS-NoC (3D-FETO). With the aid of\nefficient mechanisms and algorithms, 3D-FETO is capable of detecting and\nrecovering from soft errors which occur in the routing pipeline stages and\nleverages reconfigurable components to handle permanent faults in links, input\nbuffers, and crossbars. In-depth evaluation results show that the 3D-FETO\nsystem is able to work around different kinds of hard faults and soft errors,\nensuring graceful performance degradation, while minimizing additional hardware\ncomplexity and remaining power efficient.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 10:13:23 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dang", "Khanh N", ""], ["Meyer", "Michael", ""], ["Okuyama", "Yuichi", ""], ["Abdallah", "Abderazek Ben", ""]]}, {"id": "2003.11455", "submitter": "Andreas Gr\\\"ubl", "authors": "Andreas Gr\\\"ubl, Sebastian Billaudelle, Benjamin Cramer, Vitali\n  Karasenko, Johannes Schemmel", "title": "Verification and Design Methods for the BrainScaleS Neuromorphic\n  Hardware System", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents verification and implementation methods that have been\ndeveloped for the design of the BrainScaleS-2 65nm ASICs. The 2nd generation\nBrainScaleS chips are mixed-signal devices with tight coupling between\nfull-custom analog neuromorphic circuits and two general purpose\nmicroprocessors (PPU) with SIMD extension for on-chip learning and plasticity.\nSimulation methods for automated analysis and pre-tapeout calibration of the\nhighly parameterizable analog neuron and synapse circuits and for\nhardware-software co-development of the digital logic and software stack are\npresented. Accelerated operation of neuromorphic circuits and highly-parallel\ndigital data buses between the full-custom neuromorphic part and the PPU\nrequire custom methodologies to close the digital signal timing at the\ninterfaces. Novel extensions to the standard digital physical implementation\ndesign flow are highlighted. We present early results from the first full-size\nBrainScaleS-2 ASIC containing 512 neurons and 130K synapses, demonstrating the\nsuccessful application of these methods. An application example illustrates the\nfull functionality of the BrainScaleS-2 hybrid plasticity architecture.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:48:54 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Gr\u00fcbl", "Andreas", ""], ["Billaudelle", "Sebastian", ""], ["Cramer", "Benjamin", ""], ["Karasenko", "Vitali", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2003.12101", "submitter": "Shulin Zeng", "authors": "Shulin Zeng, Guohao Dai, Hanbo Sun, Kai Zhong, Guangjun Ge, Kaiyuan\n  Guo, Yu Wang, Huazhong Yang", "title": "Enabling Efficient and Flexible FPGA Virtualization for Deep Learning in\n  the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGAs have shown great potential in providing low-latency and\nenergy-efficient solutions for deep neural network (DNN) inference\napplications. Currently, the majority of FPGA-based DNN accelerators in the\ncloud run in a time-division multiplexing way for multiple users sharing a\nsingle FPGA, and require re-compilation with $\\sim$100 s overhead. Such designs\nlead to poor isolation and heavy performance loss for multiple users, which are\nfar away from providing efficient and flexible FPGA virtualization for neither\npublic nor private cloud scenarios.\n  To solve these problems, we introduce a novel virtualization framework for\ninstruction architecture set (ISA) based on DNN accelerators by sharing a\nsingle FPGA. We enable the isolation by introducing a two-level instruction\ndispatch module and a multi-core based hardware resources pool. Such designs\nprovide isolated and runtime-programmable hardware resources, further leading\nto performance isolation for multiple users. On the other hand, to overcome the\nheavy re-compilation overheads, we propose a tiling-based instruction frame\npackage design and two-stage static-dynamic compilation. Only the light-weight\nruntime information is re-compiled with $\\sim$1 ms overhead, thus the\nperformance is guaranteed for the private cloud. Our extensive experimental\nresults show that the proposed virtualization design achieves 1.07-1.69x and\n1.88-3.12x throughput improvement over previous static designs using the\nsingle-core and the multi-core architectures, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 18:34:11 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Zeng", "Shulin", ""], ["Dai", "Guohao", ""], ["Sun", "Hanbo", ""], ["Zhong", "Kai", ""], ["Ge", "Guangjun", ""], ["Guo", "Kaiyuan", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2003.12448", "submitter": "Lev Mukhanov", "authors": "Lev Mukhanov, Konstantinos Tovletoglou, Hans Vandierendonck, Dimitrios\n  S. Nikolopoulos, Georgios Karakonstantis", "title": "Workload-Aware DRAM Error Prediction using Machine Learning", "comments": null, "journal-ref": "In Proceedings of the IEEE International Symposium on Workload\n  Characterization (IISWC), Orlando, Florida, USA, 2019", "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aggressive scaling of technology may have helped to meet the growing\ndemand for higher memory capacity and density, but has also made DRAM cells\nmore prone to errors. Such a reality triggered a lot of interest in modeling\nDRAM behavior for either predicting the errors in advance or for adjusting DRAM\ncircuit parameters to achieve a better trade-off between energy efficiency and\nreliability. Existing modeling efforts may have studied the impact of few\noperating parameters and temperature on DRAM reliability using custom FPGAs\nsetups, however they neglected the combined effect of workload-specific\nfeatures that can be systematically investigated only on a real system. In this\npaper, we present the results of our study on workload-dependent DRAM error\nbehavior within a real server considering various operating parameters, such as\nthe refresh rate, voltage and temperature. We show that the rate of single- and\nmulti-bit errors may vary across workloads by 8x, indicating that program\ninherent features can affect DRAM reliability significantly. Based on this\nobservation, we extract 249 features, such as the memory access rate, the rate\nof cache misses, the memory reuse time and data entropy, from various\ncompute-intensive, caching and analytics benchmarks. We apply several\nsupervised learning methods to construct the DRAM error behavior model for 72\nserver-grade DRAM chips using the memory operating parameters and extracted\nprogram inherent features. Our results show that, with an appropriate choice of\nprogram features and supervised learning method, the rate of single- and\nmulti-bit errors can be predicted for a specific DRAM module with an average\nerror of less than 10.5 %, as opposed to the 2.9x estimation error obtained for\na conventional workload-unaware error model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 05:09:17 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Mukhanov", "Lev", ""], ["Tovletoglou", "Konstantinos", ""], ["Vandierendonck", "Hans", ""], ["Nikolopoulos", "Dimitrios S.", ""], ["Karakonstantis", "Georgios", ""]]}, {"id": "2003.12632", "submitter": "Tamzidul Hoque", "authors": "Tamzidul Hoque, Shuo Yang, Aritra Bhattacharyay, Jonathan Cruz, and\n  Swarup Bhunia", "title": "An Automated Framework for Board-level Trojan Benchmarking", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Economic and operational advantages have led the supply chain of printed\ncircuit boards (PCBs) to incorporate various untrusted entities. Any of the\nuntrusted entities are capable of introducing malicious alterations to\nfacilitate a functional failure or leakage of secret information during field\noperation. While researchers have been investigating the threat of malicious\nmodification within the scale of individual microelectronic components, the\npossibility of a board-level malicious manipulation has essentially been\nunexplored. In the absence of standard benchmarking solutions, prospective\ncountermeasures for PCB trust assurance are likely to utilize homegrown\nrepresentation of the attacks that undermines their evaluation and does not\nprovide scope for comparison with other techniques. In this paper, we have\ndeveloped the first-ever benchmarking solution to facilitate an unbiased and\ncomparable evaluation of countermeasures applicable to PCB trust assurance.\nBased on a taxonomy tailored for PCB-level alterations, we have developed\nhigh-level Trojan models. From these models, we have generated a custom pool of\nboard-level Trojan designs of varied complexity and functionality. We have also\ndeveloped a tool-flow for automatically inserting these Trojans into various\nPCB designs and generate the Trojan benchmarks (i.e., PCB designs with Trojan).\nThe tool-based Trojan insertion facilitate a comprehensive evaluation against\nlarge number of diverse Trojan implementations and application of data mining\nfor trust verification. Finally, with experimental measurements from a\nfabricated PCB, we analyze the stealthiness of the Trojan designs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 20:44:50 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hoque", "Tamzidul", ""], ["Yang", "Shuo", ""], ["Bhattacharyay", "Aritra", ""], ["Cruz", "Jonathan", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2003.13054", "submitter": "Maria Ang\\'elica D\\'avila Guzm\\'an", "authors": "Maria A. D\\'avila-Guzm\\'an and Rub\\'en Gran Tejero and Mar\\'ia\n  Villarroya-Gaud\\'o and Dar\\'io Su\\'arez Gracia", "title": "Analytical Model of Memory-Bound Applications Compiled with High Level\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demand of dedicated accelerators to improve energy efficiency\nand performance has highlighted FPGAs as a promising option to deliver both.\nHowever, programming FPGAs in hardware description languages requires long time\nand effort to achieve optimal results, which discourages many programmers from\nadopting this technology.\n  High Level Synthesis tools improve the accessibility to FPGAs, but the\noptimization process is still time expensive due to the large compilation time,\nbetween minutes and days, required to generate a single bitstream. Whereas\nplacing and routing take most of this time, the RTL pipeline and memory\norganization are known in seconds. This early information about the\norganization of the upcoming bitstream is enough to provide an accurate and\nfast performance model.\n  This paper presents a performance analytical model for HLS designs focused on\nmemory bound applications. With a careful analysis of the generated memory\narchitecture and DRAM organization, the model predicts the execution time with\na maximum error of 9.2% for a set of representative applications. Compared with\nprevious works, our predictions reduce on average at least $2\\times$ the\nestimation error.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 15:25:20 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["D\u00e1vila-Guzm\u00e1n", "Maria A.", ""], ["Tejero", "Rub\u00e9n Gran", ""], ["Villarroya-Gaud\u00f3", "Mar\u00eda", ""], ["Gracia", "Dar\u00edo Su\u00e1rez", ""]]}]