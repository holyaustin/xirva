[{"id": "1505.01139", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa, Lorenz K. M\\\"uller, Giacomo Indiveri", "title": "An event-based architecture for solving constraint satisfaction problems", "comments": "First two authors contributed equally to this work", "journal-ref": "Nature Communications 6, Article number: 8941 (2015), pg. 1-10", "doi": "10.1038/ncomms9941", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint satisfaction problems (CSPs) are typically solved using\nconventional von Neumann computing architectures. However, these architectures\ndo not reflect the distributed nature of many of these problems and are thus\nill-suited to solving them. In this paper we present a hybrid analog/digital\nhardware architecture specifically designed to solve such problems. We cast\nCSPs as networks of stereotyped multi-stable oscillatory elements that\ncommunicate using digital pulses, or events. The oscillatory elements are\nimplemented using analog non-stochastic circuits. The non-repeating phase\nrelations among the oscillatory elements drive the exploration of the solution\nspace. We show that this hardware architecture can yield state-of-the-art\nperformance on a number of CSPs under reasonable assumptions on the\nimplementation. We present measurements from a prototype electronic chip to\ndemonstrate that a physical implementation of the proposed architecture is\nrobust to practical non-idealities and to validate the theory proposed.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 13:23:48 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Mostafa", "Hesham", ""], ["M\u00fcller", "Lorenz K.", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1505.01459", "submitter": "Pascal Giard", "authors": "Pascal Giard, Gabi Sarkis, Claude Thibeault, and Warren J. Gross", "title": "Multi-mode Unrolled Architectures for Polar Decoders", "comments": "11 pages, 9 figures, IEEE Transactions on Circuits and Systems I", "journal-ref": null, "doi": "10.1109/TCSI.2016.2586218", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a family of architectures for polar decoders using a\nreduced-complexity successive-cancellation decoding algorithm that employs\nunrolling to achieve extremely high throughput values while retaining moderate\nimplementation complexity. The resulting fully-unrolled, deeply-pipelined\narchitecture is capable of achieving a coded throughput in excess of 1 Tbps on\na 65 nm ASIC at 500 MHz---three orders of magnitude greater than current\nstate-of-the-art polar decoders. However, unrolled decoders are built for a\nspecific, fixed code. Therefore we also present a new method to enable the use\nof multiple code lengths and rates in a fully-unrolled polar decoder\narchitecture. This method leads to a length- and rate-flexible decoder while\nretaining the very high speed typical to unrolled decoders. The resulting\ndecoders can decode a master polar code of a given rate and length, and several\nshorter codes of different rates and lengths. We present results for two\nversions of a multi-mode decoder supporting eight and ten different polar\ncodes, respectively. Both are capable of a peak throughput of 25.6 Gbps. For\neach decoder, the energy efficiency for the longest supported polar code is\nshown to be of 14.8 pJ/bit at 250 MHz and of 8.8 pJ/bit at 500 MHz.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 19:00:56 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 08:38:06 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Giard", "Pascal", ""], ["Sarkis", "Gabi", ""], ["Thibeault", "Claude", ""], ["Gross", "Warren J.", ""]]}, {"id": "1505.02211", "submitter": "Tony Wu", "authors": "Tony F. Wu, Karthik Ganesan, Yunqing Alexander Hu, H.-S. Philip Wong,\n  Simon Wong, Subhasish Mitra", "title": "TPAD: Hardware Trojan Prevention and Detection for Trusted Integrated\n  Circuits", "comments": "17 pages, 23 figures. Extended version of paper to appear in IEEE\n  Trans. on CAD", "journal-ref": null, "doi": "10.1109/TCAD.2015.2474373", "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are increasing concerns about possible malicious modifications of\nintegrated circuits (ICs) used in critical applications. Such attacks are often\nreferred to as hardware Trojans. While many techniques focus on hardware Trojan\ndetection during IC testing, it is still possible for attacks to go undetected.\nUsing a combination of new design techniques and new memory technologies, we\npresent a new approach that detects a wide variety of hardware Trojans during\nIC testing and also during system operation in the field. Our approach can also\nprevent a wide variety of attacks during synthesis, place-and-route, and\nfabrication of ICs. It can be applied to any digital system, and can be tuned\nfor both traditional and split-manufacturing methods. We demonstrate its\napplicability for both ASICs and FPGAs. Using fabricated test chips with Trojan\nemulation capabilities and also using simulations, we demonstrate: 1. The area\nand power costs of our approach can range between 7.4-165% and 0.07-60%,\nrespectively, depending on the design and the attacks targeted; 2. The speed\nimpact can be minimal (close to 0%); 3. Our approach can detect 99.998% of\nTrojans (emulated using test chips) that do not require detailed knowledge of\nthe design being attacked; 4. Our approach can prevent 99.98% of specific\nattacks (simulated) that utilize detailed knowledge of the design being\nattacked (e.g., through reverse-engineering). 5. Our approach never produces\nany false positives, i.e., it does not report attacks when the IC operates\ncorrectly.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 00:11:31 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2015 02:19:49 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wu", "Tony F.", ""], ["Ganesan", "Karthik", ""], ["Hu", "Yunqing Alexander", ""], ["Wong", "H. -S. Philip", ""], ["Wong", "Simon", ""], ["Mitra", "Subhasish", ""]]}, {"id": "1505.03476", "submitter": "Mingyu Chen", "authors": "Zehan Cui, Tianyue Lu, Haiyang Pan, Sally A. Mckee, Mingyu Chen", "title": "Twin-Load: Building a Scalable Memory System over the Non-Scalable\n  Interface", "comments": "submitted to PACT15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commodity memory interfaces have difficulty in scaling memory capacity to\nmeet the needs of modern multicore and big data systems. DRAM device density\nand maximum device count are constrained by technology, package, and signal in-\ntegrity issues that limit total memory capacity. Synchronous DRAM protocols\nrequire data to be returned within a fixed latency, and thus memory extension\nmethods over commodity DDRx interfaces fail to support scalable topologies.\nCurrent extension approaches either use slow PCIe interfaces, or require\nexpensive changes to the memory interface, which limits commercial\nadoptability. Here we propose twin-load, a lightweight asynchronous memory\naccess mechanism over the synchronous DDRx interface. Twin-load uses two\nspecial loads to accomplish one access request to extended memory, the first\nserves as a prefetch command to the DRAM system, and the second asynchronously\ngets the required data. Twin-load requires no hardware changes on the processor\nside and only slight soft- ware modifications. We emulate this system on a\nprototype to demonstrate the feasibility of our approach. Twin-load has\ncomparable performance to NUMA extended memory and outperforms a page-swapping\nPCIe-based system by several orders of magnitude. Twin-load thus enables\ninstant capacity increases on commodity platforms, but more importantly, our\narchitecture opens opportunities for the design of novel, efficient, scalable,\ncost-effective memory subsystems.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 17:54:15 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Cui", "Zehan", ""], ["Lu", "Tianyue", ""], ["Pan", "Haiyang", ""], ["Mckee", "Sally A.", ""], ["Chen", "Mingyu", ""]]}, {"id": "1505.03899", "submitter": "Josef Spjut", "authors": "Jean Sung, Sebastian Krupa, Andrew Fishberg, Josef Spjut", "title": "An Approach to Data Prefetching Using 2-Dimensional Selection Criteria", "comments": "4 pages, 5 figures, submitted to Second Data Prefetching Championship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to data memory prefetching which augments the standard\nprefetch buffer with selection criteria based on performance and usage pattern\nof a given instruction. This approach is built on top of a pattern matching\nbased prefetcher, specifically one which can choose between a stream, a stride,\nor a stream followed by a stride. We track the most recently called\ninstructions to make a decision on the quantity of data to prefetch next. The\ndecision is based on the frequency with which these instructions are called and\nthe hit/miss rate of the prefetcher. In our approach, we separate the amount of\ndata to prefetch into three categories: a high degree, a standard degree and a\nlow degree. We ran tests on different values for the high prefetch degree,\nstandard prefetch degree and low prefetch degree to determine that the most\noptimal combination was 1, 4, 8 lines respectively. The 2 dimensional selection\ncriteria improved the performance of the prefetcher by up to 9.5% over the\nfirst data prefetching championship winner. Unfortunately performance also fell\nby as much as 14%, but remained similar on average across all of the benchmarks\nwe tested.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 21:57:26 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Sung", "Jean", ""], ["Krupa", "Sebastian", ""], ["Fishberg", "Andrew", ""], ["Spjut", "Josef", ""]]}, {"id": "1505.04339", "submitter": "Swapnil Mhaske", "authors": "Swapnil Mhaske, David Uliana, Hojin Kee, Tai Ly, Ahsan Aziz, Predrag\n  Spasojevic", "title": "A 2.48Gb/s QC-LDPC Decoder Implementation on the NI USRP-2953R", "comments": "3 figures, 5 pages. arXiv admin note: text overlap with\n  arXiv:1503.02986", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing data rates expected to be of the order of Gb/s for future\nwireless systems directly impact the throughput requirements of the modulation\nand coding subsystems of the physical layer. In an effort to design a suitable\nchannel coding solution for 5G wireless systems, in this brief we present a\nmassively-parallel 2.48Gb/s Quasi-Cyclic Low-Density Parity-Check (QC-LDPC)\ndecoder implementation operating at 200MHz on the NI USRP-2953R, on a single\nFPGA. The high-level description of the entire massively-parallel decoder was\ntranslated to a Hardware Description Language (HDL), namely VHDL, using the\nalgorithmic compiler in the National Instruments LabVIEW Communication System\nDesign Suite (CSDS) in approximately 2 minutes. This implementation not only\ndemonstrates the scalability of our decoder architecture but also, the rapid\nprototyping capability of the LabVIEW CSDS tools. As per our knowledge, at the\ntime of writing this paper, this is the fastest implementation of a standard\ncompliant QC-LDPC decoder on a USRP using an algorithmic compiler.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 23:32:40 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Mhaske", "Swapnil", ""], ["Uliana", "David", ""], ["Kee", "Hojin", ""], ["Ly", "Tai", ""], ["Aziz", "Ahsan", ""], ["Spasojevic", "Predrag", ""]]}, {"id": "1505.04569", "submitter": "Suman Sau", "authors": "Suman Sau, Swagata Mandal, Jogender Saini, Amlan Chakrabarti and\n  Subhasis Chattopadhyay", "title": "High speed fault tolerant secure communication for muon chamber using\n  fpga based gbt emulator", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/664/8/082049", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Compressed Baryonic Matter (CBM) experiment is a part of the Facility for\nAntiproton and Ion Research (FAIR) in Darmstadt at the GSI. The CBM experiment\nwill investigate the highly compressed nuclear matter using nucleus-nucleus\ncollisions. This experiment will examine heavy-ion collisions in fixed target\ngeometry and will be able to measure hadrons, electrons and muons. CBM requires\nprecise time synchronization, compact hardware, radiation tolerance,\nself-triggered front-end electronics, efficient data aggregation schemes and\ncapability to handle high data rate (up to several TB/s). As a part of the\nimplementation of read out chain of MUCH in India, we have tried to implement\nFPGA based emulator of GBTx in India. GBTx is a radiation tolerant ASIC that\ncan be used to implement multipurpose high speed bidirectional optical links\nfor high-energy physics (HEP) experiments and is developed by CERN. GBTx will\nbe used in highly irradiated area and more prone to be affected by multi bit\nerror. To mitigate this effect instead of single bit error correcting RS code\nwe have used two bit error correcting (15, 7) BCH code. It will increase the\nredundancy which in turn increases the reliability of the coded data. So the\ncoded data will be less prone to be affected by noise due to radiation. Data\nwill go from detector to PC through multiple nodes through the communication\nchannel. In order to make the data communication secure, advanced encryption\nstandard (AES - a symmetric key cryptography) and RSA (asymmetric key\ncryptography) are used after the channel coding.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 09:32:11 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Sau", "Suman", ""], ["Mandal", "Swagata", ""], ["Saini", "Jogender", ""], ["Chakrabarti", "Amlan", ""], ["Chattopadhyay", "Subhasis", ""]]}, {"id": "1505.07502", "submitter": "Lavanya Subramanian", "authors": "Hiroyuki Usui, Lavanya Subramanian, Kevin Chang, Onur Mutlu", "title": "SQUASH: Simple QoS-Aware High-Performance Memory Scheduler for\n  Heterogeneous Systems with Hardware Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAFARI Technical Report No. 2015-003", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SoCs integrate multiple CPU cores and Hardware Accelerators (HWAs)\nthat share the same main memory system, causing interference among memory\nrequests from different agents. The result of this interference, if not\ncontrolled well, is missed deadlines for HWAs and low CPU performance.\nState-of-the-art mechanisms designed for CPU-GPU systems strive to meet a\ntarget frame rate for GPUs by prioritizing the GPU close to the time when it\nhas to complete a frame. We observe two major problems when such an approach is\nadapted to a heterogeneous CPU-HWA system. First, HWAs miss deadlines because\nthey are prioritized only close to their deadlines. Second, such an approach\ndoes not consider the diverse memory access characteristics of different\napplications running on CPUs and HWAs, leading to low performance for\nlatency-sensitive CPU applications and deadline misses for some HWAs, including\nGPUs.\n  In this paper, we propose a Simple Quality of service Aware memory Scheduler\nfor Heterogeneous systems (SQUASH), that overcomes these problems using three\nkey ideas, with the goal of meeting deadlines of HWAs while providing high CPU\nperformance. First, SQUASH prioritizes a HWA when it is not on track to meet\nits deadline any time during a deadline period. Second, SQUASH prioritizes HWAs\nover memory-intensive CPU applications based on the observation that the\nperformance of memory-intensive applications is not sensitive to memory\nlatency. Third, SQUASH treats short-deadline HWAs differently as they are more\nlikely to miss their deadlines and schedules their requests based on worst-case\nmemory access time estimates.\n  Extensive evaluations across a wide variety of different workloads and\nsystems show that SQUASH achieves significantly better CPU performance than the\nbest previous scheduler while always meeting the deadlines for all HWAs,\nincluding GPUs, thereby largely improving frame rates.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 22:07:28 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Usui", "Hiroyuki", ""], ["Subramanian", "Lavanya", ""], ["Chang", "Kevin", ""], ["Mutlu", "Onur", ""]]}]