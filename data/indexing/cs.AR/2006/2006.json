[{"id": "2006.00053", "submitter": "Lin Bai", "authors": "Lin Bai, Yecheng Lyu and Xinming Huang", "title": "A Unified Hardware Architecture for Convolutions and Deconvolutions in\n  CNN", "comments": "This paper has been accepted by ISCAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a scalable neural network hardware architecture for image\nsegmentation is proposed. By sharing the same computing resources, both\nconvolution and deconvolution operations are handled by the same process\nelement array. In addition, access to on-chip and off-chip memories is\noptimized to alleviate the burden introduced by partial sum. As an example,\nSegNet-Basic has been implemented using the proposed unified architecture by\ntargeting on Xilinx ZC706 FPGA, which achieves the performance of 151.5 GOPS\nand 94.3 GOPS for convolution and deconvolution respectively. This unified\nconvolution/deconvolution design is applicable to other CNNs with\ndeconvolution.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 19:54:29 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bai", "Lin", ""], ["Lyu", "Yecheng", ""], ["Huang", "Xinming", ""]]}, {"id": "2006.00364", "submitter": "Farhad Merchant", "authors": "Riya Jain, Niraj Sharma, Farhad Merchant, Sachin Patkar, Rainer\n  Leupers", "title": "CLARINET: A RISC-V Based Framework for Posit Arithmetic Empiricism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many engineering and scientific applications require high precision\narithmetic. IEEE 754-2008 compliant (floating-point) arithmetic is the de facto\nstandard for performing these computations. Recently, posit arithmetic has been\nproposed as a drop-in replacement for floating-point arithmetic. The posit data\nrepresentation and arithmetic offer several absolute advantages over the\nfloating-point format and arithmetic including higher dynamic range, better\naccuracy, and superior performance-area trade-offs.\n  In this paper, we present a consolidated general-purpose processor-based\nframework to support posit arithmetic empiricism. The end-users of the\nframework have the liberty to seamlessly experiment with their applications\nusing posit and floating-point arithmetic since the framework is designed for\nthe two number systems to coexist. The framework consists of Melodica and\nClarinet. Melodica is a posit arithmetic core that implements parametric\nfused-multiply-accumulate and, more importantly, supports the quire data type.\nClarinet is a Melodica-enabled processor based on the RISC-V ISA. To the best\nof our knowledge, this is the first-ever integration of quire to a RISC-V core.\nTo show the effectiveness of the Clarinet platform, we perform an extensive\napplication study and benchmarking on some of the common linear algebra and\ncomputer vision kernels. We perform ASIC synthesis of Clarinet and Melodica on\na 90 nm-CMOS Faraday process. Finally, based on our analysis and synthesis\nresults, we define a quality metric for the different instances of Clarinet\nthat gives us initial recommendations on the goodness of the instances.\nClarinet-Melodica is an easy-to-experiment platform that will be made available\nin open-source for posit arithmetic empiricism.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 20:59:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 08:12:21 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 07:04:04 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Jain", "Riya", ""], ["Sharma", "Niraj", ""], ["Merchant", "Farhad", ""], ["Patkar", "Sachin", ""], ["Leupers", "Rainer", ""]]}, {"id": "2006.00532", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "How to extend the Single-Processor Paradigm to the Explicitly\n  Many-Processor Approach", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The computing paradigm invented for processing a small amount of data on a\nsingle segregated processor cannot meet the challenges set by the present-day\ncomputing demands. The paper proposes a new computing paradigm (extending the\nold one to use several processors explicitly) and discusses some questions of\nits possible implementation. Some advantages of the implemented approach,\nillustrated with the results of a loosely-timed simulator, are presented.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 14:31:30 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "2006.01049", "submitter": "George Papadimitriou Dr.", "authors": "George Papadimitriou, Athanasios Chatzidimitriou, Dimitris Gizopoulos,\n  Vijay Janapa Reddi, Jingwen Leng, Behzad Salami, Osman S. Unsal, Adrian\n  Cristal Kestelman", "title": "Exceeding Conservative Limits: A Consolidated Analysis on Modern\n  Hardware Margins", "comments": "Accepted for publication in IEEE Transactions on Device and Materials\n  Reliability", "journal-ref": null, "doi": "10.1109/TDMR.2020.2989813", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale computing systems (data centers, supercomputers, cloud and\nedge setups and high-end cyber-physical systems) employ heterogeneous\narchitectures that consist of multicore CPUs, general-purpose many-core GPUs,\nand programmable FPGAs. The effective utilization of these architectures poses\nseveral challenges, among which a primary one is power consumption. Voltage\nreduction is one of the most efficient methods to reduce power consumption of a\nchip. With the galloping adoption of hardware accelerators (i.e., GPUs and\nFPGAs) in large datacenters and other large-scale computing infrastructures, a\ncomprehensive evaluation of the safe voltage reduction levels for each\ndifferent chip can be employed for efficient reduction of the total power. We\npresent a survey of recent studies in voltage margins reduction at the system\nlevel for modern CPUs, GPUs and FPGAs. The pessimistic voltage guardbands\ninserted by the silicon vendors can be exploited in all devices for significant\npower savings. On average, voltage reduction can reach 12% in multicore CPUs,\n20% in manycore GPUs and 39% in FPGAs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:21:19 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Papadimitriou", "George", ""], ["Chatzidimitriou", "Athanasios", ""], ["Gizopoulos", "Dimitris", ""], ["Reddi", "Vijay Janapa", ""], ["Leng", "Jingwen", ""], ["Salami", "Behzad", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}, {"id": "2006.01425", "submitter": "Jianlei Yang", "authors": "Xueyan Wang, Jianlei Yang, Yinglin Zhao, Xiaotao Jia, Gang Qu,\n  Weisheng Zhao", "title": "Hardware Security in Spin-Based Computing-In-Memory: Analysis, Exploits,\n  and Mitigation Techniques", "comments": "accepted by ACM Journal on Emerging Technologies in Computing Systems\n  (JETC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computing-in-memory (CIM) is proposed to alleviate the processor-memory data\ntransfer bottleneck in traditional Von-Neumann architectures, and\nspintronics-based magnetic memory has demonstrated many facilitation in\nimplementing CIM paradigm. Since hardware security has become one of the major\nconcerns in circuit designs, this paper, for the first time, investigates\nspin-based computing-in-memory (SpinCIM) from a security perspective. We focus\non two fundamental questions: 1) how the new SpinCIM computing paradigm can be\nexploited to enhance hardware security? 2) what security concerns has this new\nSpinCIM computing paradigm incurred?\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:08:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Wang", "Xueyan", ""], ["Yang", "Jianlei", ""], ["Zhao", "Yinglin", ""], ["Jia", "Xiaotao", ""], ["Qu", "Gang", ""], ["Zhao", "Weisheng", ""]]}, {"id": "2006.02012", "submitter": "Furkan Ercan", "authors": "Furkan Ercan, Thibaud Tonnellier, Carlo Condo, Warren J. Gross", "title": "Operation Merging for Hardware Implementations of Fast Polar Decoders", "comments": "13 figures, 8 tables, 11 pages, published on November 3, 2018 in\n  Journal of Signal Processing Systems (JSPS), vol. 91, pp. 995-1007", "journal-ref": null, "doi": "10.1007/s11265-018-1413-4", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polar codes are a class of linear block codes that provably achieves channel\ncapacity. They have been selected as a coding scheme for the control channel of\nenhanced mobile broadband (eMBB) scenario for $5^{\\text{th}}$ generation\nwireless communication networks (5G) and are being considered for additional\nuse scenarios. As a result, fast decoding techniques for polar codes are\nessential. Previous works targeting improved throughput for\nsuccessive-cancellation (SC) decoding of polar codes are semi-parallel\nimplementations that exploit special maximum-likelihood (ML) nodes. In this\nwork, we present a new fast simplified SC (Fast-SSC) decoder architecture.\nCompared to a baseline Fast-SSC decoder, our solution is able to reduce the\nmemory requirements. We achieve this through a more efficient memory\nutilization, which also enables to execute multiple operations in a single\nclock cycle. Finally, we propose new special node merging techniques that\nimprove the throughput further, and detail a new Fast-SSC-based decoder\narchitecture to support merged operations. The proposed decoder reduces the\noperation sequence requirement by up to $39\\%$, which enables to reduce the\nnumber of time steps to decode a codeword by $35\\%$. ASIC implementation\nresults with 65 nm TSMC technology show that the proposed decoder has a\nthroughput improvement of up to $31\\%$ compared to previous Fast-SSC decoder\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 02:19:33 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Ercan", "Furkan", ""], ["Tonnellier", "Thibaud", ""], ["Condo", "Carlo", ""], ["Gross", "Warren J.", ""]]}, {"id": "2006.03117", "submitter": "Brian Crafton Mr.", "authors": "Brian Crafton, Samuel Spetalnick, Arijit Raychowdhury", "title": "Counting Cards: Exploiting Variance and Data Distributions for Robust\n  Compute In-Memory", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compute in-memory (CIM) is a promising technique that minimizes data\ntransport, the primary performance bottleneck and energy cost of most data\nintensive applications. This has found wide-spread adoption in accelerating\nneural networks for machine learning applications. Utilizing a crossbar\narchitecture with emerging non-volatile memories (eNVM) such as dense resistive\nrandom access memory (RRAM) or phase change random access memory (PCRAM),\nvarious forms of neural networks can be implemented to greatly reduce power and\nincrease on chip memory capacity. However, compute in-memory faces its own\nlimitations at both the circuit and the device levels. In this work, we explore\nthe impact of device variation and peripheral circuit design constraints.\nFurthermore, we propose a new algorithm based on device variance and neural\nnetwork weight distributions to increase both performance and accuracy for\ncompute-in memory based designs. We demonstrate a 27% power improvement and 23%\nperformance improvement for low and high variance eNVM, while satisfying a\nprogrammable threshold for a target error tolerance, which depends on the\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:15:09 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:35:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Crafton", "Brian", ""], ["Spetalnick", "Samuel", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "2006.03250", "submitter": "Jieru Zhao", "authors": "Jieru Zhao, Tingyuan Liang, Liang Feng, Wenchao Ding, Sharad Sinha,\n  Wei Zhang and Shaojie Shen", "title": "FP-Stereo: Hardware-Efficient Stereo Vision for Embedded Applications", "comments": "IEEE International Conference on Field Programmable Logic and\n  Applications (FPL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and accurate depth estimation, or stereo matching, is essential in\nembedded stereo vision systems, requiring substantial design effort to achieve\nan appropriate balance among accuracy, speed and hardware cost. To reduce the\ndesign effort and achieve the right balance, we propose FP-Stereo for building\nhigh-performance stereo matching pipelines on FPGAs automatically. FP-Stereo\nconsists of an open-source hardware-efficient library, allowing designers to\nobtain the desired implementation instantly. Diverse methods are supported in\nour library for each stage of the stereo matching pipeline and a series of\ntechniques are developed to exploit the parallelism and reduce the resource\noverhead. To improve the usability, FP-Stereo can generate synthesizable C code\nof the FPGA accelerator with our optimized HLS templates automatically. To\nguide users for the right design choice meeting specific application\nrequirements, detailed comparisons are performed on various configurations of\nour library to investigate the accuracy/speed/cost trade-off. Experimental\nresults also show that FP-Stereo outperforms the state-of-the-art FPGA design\nfrom all aspects, including 6.08% lower error, 2x faster speed, 30% less\nresource usage and 40% less energy consumption. Compared to GPU designs,\nFP-Stereo achieves the same accuracy at a competitive speed while consuming\nmuch less energy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 06:17:43 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 07:44:10 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 07:04:33 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 09:20:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Zhao", "Jieru", ""], ["Liang", "Tingyuan", ""], ["Feng", "Liang", ""], ["Ding", "Wenchao", ""], ["Sinha", "Sharad", ""], ["Zhang", "Wei", ""], ["Shen", "Shaojie", ""]]}, {"id": "2006.05693", "submitter": "Alexandra Angerd", "authors": "Alexandra Angerd, Erik Sintorn, Per Stenstr\\\"om", "title": "A GPU Register File using Static Data Compression", "comments": "Accepted to ICPP'20", "journal-ref": null, "doi": "10.1145/3404397.3404431", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs rely on large register files to unlock thread-level parallelism for high\nthroughput. Unfortunately, large register files are power hungry, making it\nimportant to seek for new approaches to improve their utilization.\n  This paper introduces a new register file organization for efficient\nregister-packing of narrow integer and floating-point operands designed to\nleverage on advances in static analysis. We show that the hardware/software\nco-designed register file organization yields a performance improvement of up\nto 79%, and 18.6%, on average, at a modest output-quality degradation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:24:19 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Angerd", "Alexandra", ""], ["Sintorn", "Erik", ""], ["Stenstr\u00f6m", "Per", ""]]}, {"id": "2006.05696", "submitter": "Supriya Chakraborty", "authors": "Supriya Chakraborty, Abhishek Gupta, and Manan Suri", "title": "Unified Characterization Platform for Emerging NVM Technology: Neural\n  Network Application Benchmarking Using off-the-shelf NVM Chips", "comments": "Accepted at 2020 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": "2020 IEEE International Symposium on Circuits and Systems (ISCAS)", "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a unified FPGA based electrical test-bench for\ncharacterizing different emerging NonVolatile Memory (NVM) chips. In\nparticular, we present detailed electrical characterization and benchmarking of\nmultiple commercially available, off-the-shelf, NVM chips viz.: MRAM, FeRAM,\nCBRAM, and ReRAM. We investigate important NVM parameters such as: (i) current\nconsumption patterns, (ii) endurance, and (iii) error characterization. The\nproposed FPGA based testbench is then utilized for a Proof-of-Concept (PoC)\nNeural Network (NN) image classification application. Four emerging NVM chips\nare benchmarked against standard SRAM and Flash technology for the AI\napplication as active weight memory during inference mode.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:27:14 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chakraborty", "Supriya", ""], ["Gupta", "Abhishek", ""], ["Suri", "Manan", ""]]}, {"id": "2006.05868", "submitter": "Anup Das", "authors": "Shihao Song, Anup Das, Nagarajan Kandasamy", "title": "Improving Dependability of Neuromorphic Computing With Non-Volatile\n  Memory", "comments": "8 pages, 13 figures, accepted in 16th European Dependable Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As process technology continues to scale aggressively, circuit aging in a\nneuromorphic hardware due to negative bias temperature instability (NBTI) and\ntime-dependent dielectric breakdown (TDDB) is becoming a critical reliability\nissue and is expected to proliferate when using non-volatile memory (NVM) for\nsynaptic storage. This is because an NVM requires high voltage and current to\naccess its synaptic weight, which further accelerates the circuit aging in a\nneuromorphic hardware. Current methods for qualifying reliability are overly\nconservative, since they estimate circuit aging considering worst-case\noperating conditions and unnecessarily constrain performance. This paper\nproposes RENEU, a reliability-oriented approach to map machine learning\napplications to neuromorphic hardware, with the aim of improving system-wide\nreliability without compromising key performance metrics such as execution time\nof these applications on the hardware. Fundamental to RENEU is a novel\nformulation of the aging of CMOS-based circuits in a neuromorphic hardware\nconsidering different failure mechanisms. Using this formulation, RENEU\ndevelops a system-wide reliability model which can be used inside a\ndesign-space exploration framework involving the mapping of neurons and\nsynapses to the hardware. To this end, RENEU uses an instance of Particle Swarm\nOptimization (PSO) to generate mappings that are Pareto-optimal in terms of\nperformance and reliability. We evaluate RENEU using different machine learning\napplications on a state-of-the-art neuromorphic hardware with NVM synapses. Our\nresults demonstrate an average 38\\% reduction in circuit aging, leading to an\naverage 18% improvement in the lifetime of the hardware compared to current\npractices. RENEU only introduces a marginal performance overhead of 5% compared\nto a performance-oriented state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:50:28 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Song", "Shihao", ""], ["Das", "Anup", ""], ["Kandasamy", "Nagarajan", ""]]}, {"id": "2006.07137", "submitter": "Francisco Mu\\~noz-Mart\\'inez", "authors": "Francisco Mu\\~noz-Mart\\'inez, Jos\\'e L. Abell\\'an, Manuel E. Acacio,\n  Tushar Krishna", "title": "STONNE: A Detailed Architectural Simulator for Flexible Neural Network\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of specialized architectures for accelerating the inference\nprocedure of Deep Neural Networks (DNNs) is a booming area of research\nnowadays. First-generation rigid proposals have been rapidly replaced by more\nadvanced flexible accelerator architectures able to efficiently support a\nvariety of layer types and dimensions. As the complexity of the designs grows,\nit is more and more appealing for researchers to have cycle-accurate simulation\ntools at their disposal to allow for fast and accurate design-space\nexploration, and rapid quantification of the efficacy of architectural\nenhancements during the early stages of a design. To this end, we present\nSTONNE (Simulation TOol of Neural Network Engines), a cycle-accurate,\nhighly-modular and highly-extensible simulation framework that enables\nend-to-end evaluation of flexible accelerator architectures running complete\ncontemporary DNN models. We use STONNE to model the recently proposed MAERI\narchitecture and show how it can closely approach the performance results of\nthe publicly available BSV-coded MAERI implementation. Then, we conduct a\ncomprehensive evaluation and demonstrate that the folding strategy implemented\nfor MAERI results in very low compute unit utilization (25% on average across 5\nDNN models) which in the end translates into poor performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 19:20:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Mu\u00f1oz-Mart\u00ednez", "Francisco", ""], ["Abell\u00e1n", "Jos\u00e9 L.", ""], ["Acacio", "Manuel E.", ""], ["Krishna", "Tushar", ""]]}, {"id": "2006.07450", "submitter": "Arash Fouman", "authors": "Arash Fouman Ajirlou and Inna Partin-Vaisband", "title": "A Unified Learning Platform for Dynamic Frequency Scaling in Pipelined\n  Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning (ML) design framework is proposed for dynamically\nadjusting clock frequency based on propagation delay of individual\ninstructions. A Random Forest model is trained to classify propagation delays\nin real-time, utilizing current operation type, current operands, and\ncomputation history as ML features. The trained model is implemented in Verilog\nas an additional pipeline stage within a baseline processor. The modified\nsystem is simulated at the gate-level in 45 nm CMOS technology, exhibiting a\nspeed-up of 68% and energy reduction of 37% with coarse-grained ML\nclassification. A speed-up of 95% is demonstrated with finer granularities at\nadditional energy costs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 20:07:06 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ajirlou", "Arash Fouman", ""], ["Partin-Vaisband", "Inna", ""]]}, {"id": "2006.08026", "submitter": "Joel Mandebi Mbongue", "authors": "Joel Mandebi Mbongue, Alex Shuping, Pankaj Bhowmik, Christophe Bobda", "title": "Architecture Support for FPGA Multi-tenancy in the Cloud", "comments": "This paper was accepted as a full-paper (8pages) at the 31st IEEE\n  International Conference on Application-specific Systems, Architectures and\n  Processors (ASAP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud deployments now increasingly provision FPGA accelerators as part of\nvirtual instances. While FPGAs are still essentially single-tenant, the growing\ndemand for hardware acceleration will inevitably lead to the need for methods\nand architectures supporting FPGA multi-tenancy. In this paper, we propose an\narchitecture supporting space-sharing of FPGA devices among multiple tenants in\nthe cloud. The proposed architecture implements a network-on-chip (NoC)\ndesigned for fast data movement and low hardware footprint. Prototyping the\nproposed architecture on a Xilinx Virtex Ultrascale+ demonstrated near\nspecification maximum frequency for on-chip data movement and high throughput\nin virtual instance access to hardware accelerators. We demonstrate similar\nperformance compared to single-tenant deployment while increasing FPGA\nutilization ( we achieved 6x higher FPGA utilization with our case study),\nwhich is one of the major goals of virtualization. Overall, our NoC\ninterconnect achieved about 2x higher maximum frequency than the\nstate-of-the-art and a bandwidth of 25.6 Gbps.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 21:27:15 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mbongue", "Joel Mandebi", ""], ["Shuping", "Alex", ""], ["Bhowmik", "Pankaj", ""], ["Bobda", "Christophe", ""]]}, {"id": "2006.08487", "submitter": "Priyank Faldu", "authors": "Priyank Faldu", "title": "Addressing Variability in Reuse Prediction for Last-Level Caches", "comments": "PhD Thesis submitted to the School of Informatics, The University of\n  Edinburgh (Advisor: Prof. Boris Grot, Examiners: Prof. Michael O'Boyle and\n  Dr. Gabriel Loh)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last-Level Cache (LLC) represents the bulk of a modern CPU processor's\ntransistor budget and is essential for application performance as LLC enables\nfast access to data in contrast to much slower main memory. However,\napplications with large working set size often exhibit streaming and/or\nthrashing access patterns at LLC. As a result, a large fraction of the LLC\ncapacity is occupied by dead blocks that will not be referenced again, leading\nto inefficient utilization of the LLC capacity. To improve cache efficiency,\nthe state-of-the-art cache management techniques employ prediction mechanisms\nthat learn from the past access patterns with an aim to accurately identify as\nmany dead blocks as possible. Once identified, dead blocks are evicted from LLC\nto make space for potentially high reuse cache blocks.\n  In this thesis, we identify variability in the reuse behavior of cache blocks\nas the key limiting factor in maximizing cache efficiency for state-of-the-art\npredictive techniques. Variability in reuse prediction is inevitable due to\nnumerous factors that are outside the control of LLC. The sources of\nvariability include control-flow variation, speculative execution and\ncontention from cores sharing the cache, among others. Variability in reuse\nprediction challenges existing techniques in reliably identifying the end of a\nblock's useful lifetime, thus causing lower prediction accuracy, coverage, or\nboth. To address this challenge, this thesis aims to design robust cache\nmanagement mechanisms and policies for LLC in the face of variability in reuse\nprediction to minimize cache misses, while keeping the cost and complexity of\nthe hardware implementation low. To that end, we propose two cache management\ntechniques, one domain-agnostic and one domain-specialized, to improve cache\nefficiency by addressing variability in reuse prediction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:43:37 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Faldu", "Priyank", ""]]}, {"id": "2006.08975", "submitter": "Myoungsoo Jung", "authors": "Jie Zhang and Myoungsoo Jung", "title": "ZnG: Architecting GPU Multi-Processors with New Flash for Scalable Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ZnG, a new GPU-SSD integrated architecture, which can maximize the\nmemory capacity in a GPU and address performance penalties imposed by an SSD.\nSpecifically, ZnG replaces all GPU internal DRAMs with an ultra-low-latency SSD\nto maximize the GPU memory capacity. ZnG further removes performance bottleneck\nof the SSD by replacing its flash channels with a high-throughput flash network\nand integrating SSD firmware in the GPU's MMU to reap the benefits of hardware\naccelerations. Although flash arrays within the SSD can deliver high\naccumulated bandwidth, only a small fraction of such bandwidth can be utilized\nby GPU's memory requests due to mismatches of their access granularity. To\naddress this, ZnG employs a large L2 cache and flash registers to buffer the\nmemory requests. Our evaluation results indicate that ZnG can achieve 7.5x\nhigher performance than prior work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 08:07:21 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zhang", "Jie", ""], ["Jung", "Myoungsoo", ""]]}, {"id": "2006.09982", "submitter": "Trevor E. Carlson", "authors": "Srivatsa P and Kyle Timothy Ng Chu and Burin Amornpaisannon and\n  Yaswanth Tavva and Venkata Pavan Kumar Miriyala and Jibin Wu and Malu Zhang\n  and Haizhou Li and Trevor E. Carlson", "title": "You Only Spike Once: Improving Energy-Efficient Neuromorphic Inference\n  to ANN-Level Accuracy", "comments": "10 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible. This work is an extended\n  version of the paper accepted to the 2nd Workshop on Accelerated Machine\n  Learning (AccML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, advances in Artificial Neural Networks (ANNs) have\nallowed them to perform extremely well for a wide range of tasks. In fact, they\nhave reached human parity when performing image recognition, for example.\nUnfortunately, the accuracy of these ANNs comes at the expense of a large\nnumber of cache and/or memory accesses and compute operations. Spiking Neural\nNetworks (SNNs), a type of neuromorphic, or brain-inspired network, have\nrecently gained significant interest as power-efficient alternatives to ANNs,\nbecause they are sparse, accessing very few weights, and typically only use\naddition operations instead of the more power-intensive multiply-and-accumulate\n(MAC) operations. The vast majority of neuromorphic hardware designs support\nrate-encoded SNNs, where the information is encoded in spike rates.\nRate-encoded SNNs could be seen as inefficient as an encoding scheme because it\ninvolves the transmission of a large number of spikes. A more efficient\nencoding scheme, Time-To-First-Spike (TTFS) encoding, encodes information in\nthe relative time of arrival of spikes. While TTFS-encoded SNNs are more\nefficient than rate-encoded SNNs, they have, up to now, performed poorly in\nterms of accuracy compared to previous methods. Hence, in this work, we aim to\novercome the limitations of TTFS-encoded neuromorphic systems. To accomplish\nthis, we propose: (1) a novel optimization algorithm for TTFS-encoded SNNs\nconverted from ANNs and (2) a novel hardware accelerator for TTFS-encoded SNNs,\nwith a scalable and low-power design. Overall, our work in TTFS encoding and\ntraining improves the accuracy of SNNs to achieve state-of-the-art results on\nMNIST MLPs, while reducing power consumption by 1.46$\\times$ over the\nstate-of-the-art neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:55:53 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 09:10:57 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["P", "Srivatsa", ""], ["Chu", "Kyle Timothy Ng", ""], ["Amornpaisannon", "Burin", ""], ["Tavva", "Yaswanth", ""], ["Miriyala", "Venkata Pavan Kumar", ""], ["Wu", "Jibin", ""], ["Zhang", "Malu", ""], ["Li", "Haizhou", ""], ["Carlson", "Trevor E.", ""]]}, {"id": "2006.11025", "submitter": "Vassos Soteriou", "authors": "Costas Iordanou, Vassos Soteriou, Konstantinos Aisopos", "title": "Design of a Near-Ideal Fault-Tolerant Routing Algorithm for\n  Network-on-Chip-Based Multicores", "comments": "14 pages, 12 figures, 3 pictures. Journal format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With relentless CMOS technology downsizing Networks-on-Chips (NoCs) are\ninescapably experiencing escalating susceptibility to wearout and reduced\nreliability. While faults in processors and memories may be masked via\nredundancy, or mitigated via techniques such as task migration, NoCs are\nespecially vulnerable to hardware faults as a single link breakdown may cause\ninter-tile communication to halt indefinitely, rendering the whole multicore\nchip inoperable. As such, NoCs impose the risk of becoming the pivotal point of\nfailure in chip multicores that utilize them. Aiming towards seamless NoC\noperation in the presence of faulty links we propose Hermes, a near-ideal\nfault-tolerant routing algorithm that meets the objectives of exhibiting high\nlevels of robustness, operating in a distributed mode, guaranteeing freedom\nfrom deadlocks, and evening-out traffic, among many. Hermes is a\nlimited-overhead deadlock-free hybrid routing algorithm, utilizing\nload-balancing routing on fault-free paths to sustain high-throughput, while\nproviding pre-reconfigured escape path selection in the vicinity of faults.\nUnder such online mechanisms, Hermes's performance degrades gracefully with\nincreasing faulty link counts, a crucially desirable response lacking in\nprior-art. Additionally, Hermes identifies non-communicating network partitions\nin scenarios where faulty links are topologically densely distributed such that\npackets being routed to physically isolated regions cause no network stagnation\ndue to indefinite chained blockages starting at sub-network boundaries. An\nextensive experimental evaluation, including utilizing traffic workloads\ngathered from full-system chip multi-processor simulations, shows that Hermes\nimproves network throughput by up to $3\\times$ when compared against the\nstate-of-the-art. Further, hardware synthesis results prove Hermes's efficacy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:09:24 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Iordanou", "Costas", ""], ["Soteriou", "Vassos", ""], ["Aisopos", "Konstantinos", ""]]}, {"id": "2006.11479", "submitter": "Jongouk Choi", "authors": "Jongouk Choi, Qingrui Liu, Changhee Jung", "title": "Compiler Directed Speculative Intermittent Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents CoSpec, a new architecture/compiler co-design scheme that\nworks for commodity in-order processors used in energy-harvesting systems. To\nachieve crash consistency without requiring unconventional architectural\nsupport, CoSpec leverages speculation assuming that power failure is not going\nto occur and thus holds all committed stores in a store buffer (SB), as if they\nwere speculative, in case of mispeculation. CoSpec compiler first partitions a\ngiven program into a series of recoverable code regions with the SB size in\nmind, so that no region overflows the SB. When the program control reaches the\nend of each region, the speculation turns out to be successful, thus releasing\nall the buffered stores of the region to NVM. If power failure occurs during\nthe execution of a region, all its speculative stores disappear in the volatile\nSB, i.e., they never affect program states in NVM. Consequently, the\ninterrupted region can be restarted with consistent program states in the wake\nof power failure. To hide the latency of the SB release, i.e., essentially NVM\nwrites, at each region boundary, CoSpec overlaps the NVM writes of the current\nregion with the speculative execution of the next region. Such instruction\nlevel parallelism gives an illusion of out-of-order execution on top of the\nin-order processor, achieving a speedup of more than 1.2X when there is no\npower outage. Our experiments on a set of real energy harvesting traces with\nfrequent outages demonstrate that CoSpec outperforms the state-of-the-art\nscheme by 1.8~3X on average.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 02:50:12 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Choi", "Jongouk", ""], ["Liu", "Qingrui", ""], ["Jung", "Changhee", ""]]}, {"id": "2006.11669", "submitter": "Steven Herbst", "authors": "Lenny Truong, Steven Herbst, Rajsekhar Setaluri, Makai Mann, Ross\n  Daly, Keyi Zhang, Caleb Donovick, Daniel Stanley, Mark Horowitz, Clark\n  Barrett, and Pat Hanrahan", "title": "fault: A Python Embedded Domain-Specific Language For Metaprogramming\n  Portable Hardware Verification Components", "comments": "CAV 2020: 32nd International Conference on Computer-Aided\n  Verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While hardware generators have drastically improved design productivity, they\nhave introduced new challenges for the task of verification. To effectively\ncover the functionality of a sophisticated generator, verification engineers\nrequire tools that provide the flexibility of metaprogramming. However,\nflexibility alone is not enough; components must also be portable in order to\nencourage the proliferation of verification libraries as well as enable new\nmethodologies. This paper introduces fault, a Python embedded hardware\nverification language that aims to empower design teams to realize the full\npotential of generators.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 22:50:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Truong", "Lenny", ""], ["Herbst", "Steven", ""], ["Setaluri", "Rajsekhar", ""], ["Mann", "Makai", ""], ["Daly", "Ross", ""], ["Zhang", "Keyi", ""], ["Donovick", "Caleb", ""], ["Stanley", "Daniel", ""], ["Horowitz", "Mark", ""], ["Barrett", "Clark", ""], ["Hanrahan", "Pat", ""]]}, {"id": "2006.12133", "submitter": "Safdar Jamil Mr", "authors": "Taeuk Kim, Safdar Jamil, Joongeon Park, Youngjae Kim", "title": "Optimizing Placement of Heap Memory Objects in Energy-Constrained Hybrid\n  Memory Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Main memory (DRAM) significantly impacts the power and energy utilization of\nthe overall server system. Non-Volatile Memory (NVM) devices, such as Phase\nChange Memory and Spin-Transfer Torque RAM, are suitable candidates for main\nmemory to reduce energy consumption. But unlike DRAM, NVMs access latencies are\nhigher than DRAM and NVM writes are more energy sensitive than DRAM write\noperations. Thus, Hybrid Main Memory Systems (HMMS) employing DRAM and NVM have\nbeen proposed to reduce the overall energy depletion of main memory while\noptimizing the performance of NVM. This paper proposes eMap, an optimal heap\nmemory object placement planner in HMMS. eMap considers the object-level access\npatterns and energy consumption at the application level and provides an ideal\nplacement strategy for each object to augment performance and energy\nutilization. eMap is equipped with two modules, eMPlan and eMDyn. Specifically,\neMPlan is a static placement planner which provides one time placement policies\nfor memory object to meet the energy budget while eMDyn is a runtime placement\nplanner to consider the change in energy limiting constraint during the runtime\nand shuffles the memory objects by taking into account the access patterns as\nwell as the migration cost in terms of energy and performance. The evaluation\nshows that our proposed solution satisfies both the energy limiting constraint\nand the performance. We compare our methodology with the state-of-the-art\nmemory object classification and allocation (MOCA) framework. Our extensive\nevaluation shows that our proposed solution, eMPlan meets the energy constraint\nwith 4.17 times less costly and reducing the energy consumption up to 14% with\nthe same performance. eMDyn also satisfies the performance and energy\nrequirement while considering the migration cost in terms of time and energy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:37:40 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:28:19 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kim", "Taeuk", ""], ["Jamil", "Safdar", ""], ["Park", "Joongeon", ""], ["Kim", "Youngjae", ""]]}, {"id": "2006.13095", "submitter": "Sina Sayyah Ensan", "authors": "Sina Sayyah Ensan, Karthikeyan Nagarajan, Mohammad Nasim Imtia Khan,\n  and Swaroop Ghosh", "title": "SCARE: Side Channel Attack on In-Memory Computing for Reverse\n  Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-memory computing architectures provide a much needed solution to\nenergy-efficiency barriers posed by Von-Neumann computing due to the movement\nof data between the processor and the memory. Functions implemented in such\nin-memory architectures are often proprietary and constitute confidential\nIntellectual Property. Our studies indicate that IMCs implemented using RRAM\nare susceptible to Side Channel Attack. Unlike conventional SCAs that are aimed\nto leak private keys from cryptographic implementations, SCARE can reveal the\nsensitive IP implemented within the memory. Therefore, the adversary does not\nneed to perform invasive Reverse Engineering to unlock the functionality. We\ndemonstrate SCARE by taking recent IMC architectures such as DCIM and MAGIC as\ntest cases. Simulation results indicate that AND, OR, and NOR gates (building\nblocks of complex functions) yield distinct power and timing signatures based\non the number of inputs making them vulnerable to SCA. Although process\nvariations can obfuscate the signatures due to significant overlap, we show\nthat the adversary can use statistical modeling and analysis to identify the\nstructure of the implemented function. SCARE can find the implemented IP by\ntesting a limited number of patterns. For example, the proposed technique\nreduces the number of patterns by 64% compared to a brute force attack for a+bc\nfunction. Additionally, analysis shows improvement in SCAREs detection model\ndue to adversarial change in supply voltage for both DCIM and MAGIC. We also\npropose countermeasures such as redundant inputs and expansion of literals.\nRedundant inputs can mask the IP with 25% area and 20% power overhead. However,\nfunctions can be found by greater RE effort. Expansion of literals incurs 36%\npower overhead. However, it imposes brute force search by the adversary for\nwhich the RE effort increases by 3.04X.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 15:36:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ensan", "Sina Sayyah", ""], ["Nagarajan", "Karthikeyan", ""], ["Khan", "Mohammad Nasim Imtia", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2006.13547", "submitter": "Rakesh Kumar", "authors": "Truls Asheim, Rakesh Kumar, Boris Grot", "title": "Fetch-Directed Instruction Prefetching Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has observed that fetch-directed prefetching (FDIP) is highly\neffective at covering instruction cache misses. The key to FDIP's effectiveness\nis having a sufficiently large BTB to accommodate the application's branch\nworking set. In this work, we introduce several optimizations that\nsignificantly extend the reach of the BTB within the available storage budget.\nOur optimizations target nearly every source of storage overhead in each BTB\nentry; namely, the tag, target address, and size fields.\n  We observe that while most dynamic branch instances have short offsets, a\nlarge number of branches has longer offsets or requires the use of full target\naddresses. Based on this insight, we break-up the BTB into multiple smaller\nBTBs, each storing offsets of different length. This enables a dramatic\nreduction in storage for target addresses. We further compress tags to 16 bits\nand avoid the use of the basic-block-oriented BTB advocated in prior FDIP\nvariants. The latter optimization eliminates the need to store the basic block\nsize in each BTB entry. Our final design, called FDIP-X, uses an ensemble of 4\nBTBs and always outperforms conventional FDIP with a unified\nbasic-block-oriented BTB for equal storage budgets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:14:11 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Asheim", "Truls", ""], ["Kumar", "Rakesh", ""], ["Grot", "Boris", ""]]}, {"id": "2006.13977", "submitter": "David Stutz", "authors": "David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele", "title": "Bit Error Robustness for Energy-Efficient DNN Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) accelerators received considerable attention in\npast years due to saved energy compared to mainstream hardware. Low-voltage\noperation of DNN accelerators allows to further reduce energy consumption\nsignificantly, however, causes bit-level failures in the memory storing the\nquantized DNN weights. In this paper, we show that a combination of robust\nfixed-point quantization, weight clipping, and random bit error training\n(RandBET) improves robustness against random bit errors in (quantized) DNN\nweights significantly. This leads to high energy savings from both low-voltage\noperation as well as low-precision quantization. Our approach generalizes\nacross operating voltages and accelerators, as demonstrated on bit errors from\nprofiled SRAM arrays. We also discuss why weight clipping alone is already a\nquite effective way to achieve robustness against bit errors. Moreover, we\nspecifically discuss the involved trade-offs regarding accuracy, robustness and\nprecision: Without losing more than 1% in accuracy compared to a normally\ntrained 8-bit DNN, we can reduce energy consumption on CIFAR-10 by 20%. Higher\nenergy savings of, e.g., 30%, are possible at the cost of 2.5% accuracy, even\nfor 4-bit DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 18:23:10 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 16:00:52 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 15:24:12 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Stutz", "David", ""], ["Chandramoorthy", "Nandhini", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "2006.14008", "submitter": "Kevin Stehle", "authors": "Kevin Stehle and G\\\"unther Schindler and Holger Fr\\\"oning", "title": "On the Difficulty of Designing Processor Arrays for Deep Neural Networks", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systolic arrays are a promising computing concept which is in particular\ninline with CMOS technology trends and linear algebra operations found in the\nprocessing of artificial neural networks. The recent success of such deep\nlearning methods in a wide set of applications has led to a variety of models,\nwhich albeit conceptual similar as based on convolutions and fully-connected\nlayers, in detail show a huge diversity in operations due to a large design\nspace: An operand's dimension varies substantially since it depends on design\nprinciples such as receptive field size, number of features, striding, dilating\nand grouping of features. Last, recent networks extent previously plain\nfeedforward models by various connectivity, such as in ResNet or DenseNet. The\nproblem of choosing an optimal systolic array configuration cannot be solved\nanalytically, thus instead methods and tools are required that facilitate a\nfast and accurate reasoning about optimality in terms of total cycles,\nutilization, and amount of data movements. In this work we introduce Camuy, a\nlightweight model of a weight-stationary systolic array for linear algebra\noperations that allows quick explorations of different configurations, such as\nsystolic array dimensions and input/output bitwidths. Camuy aids accelerator\ndesigners in either finding optimal configurations for a particular network\narchitecture or for robust performance across a variety of network\narchitectures. It offers simple integration into existing machine learning tool\nstacks (e.g TensorFlow) through custom operators. We present an analysis of\npopular DNN models to illustrate how it can estimate required cycles, data\nmovement costs, as well as systolic array utilization, and show how the\nprogress in network architecture design impacts the efficiency of inference on\naccelerators based on systolic arrays.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 19:24:08 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Stehle", "Kevin", ""], ["Schindler", "G\u00fcnther", ""], ["Fr\u00f6ning", "Holger", ""]]}, {"id": "2006.14105", "submitter": "Rafael Ulises Pizarro Solar", "authors": "Rafael Pizarro Solar and Michal Pleskowicz", "title": "Block-matching in FPGA", "comments": "19 pages, 15 figures, paper submitted in \"CS413 - Computational\n  Photography\" at EPFL, for project repository see\n  $\\href{https://github.com/UlisesLuzius/ImageProcessingPipeline/}{\\text{link}}$", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block-matching and 3D filtering (BM3D) is an image denoising algorithm that\nworks in two similar steps. Both of these steps need to perform grouping by\nblock-matching. We implement the block-matching in an FPGA, leveraging its\nability to perform parallel computations. Our goal is to enable other\nresearchers to use our solution in the future for real-time video denoising in\nvideo cameras that use FPGAs (such as the AXIOM Beta).\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 23:53:28 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Solar", "Rafael Pizarro", ""], ["Pleskowicz", "Michal", ""]]}, {"id": "2006.14256", "submitter": "Pasquale Davide Schiavone", "authors": "Pasquale Davide Schiavone, Davide Rossi, Alfio Di Mauro, Frank\n  Gurkaynak, Timothy Saxe, Mao Wang, Ket Chong Yap and Luca Benini", "title": "Arnold: an eFPGA-Augmented RISC-V SoC for Flexible and Low-Power IoT\n  End-Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of Internet of Things (IoT) applications require powerful,\nenergy-efficient and flexible end-nodes to acquire data from multiple sources,\nprocess and distill the sensed data through near-sensor data analytics\nalgorithms, and transmit it wirelessly. This work presents Arnold: a 0.5 V to\n0.8 V, 46.83 uW/MHz, 600 MOPS fully programmable RISC-V Microcontroller unit\n(MCU) fabricated in 22 nm Globalfoundries GF22FDX (GF22FDX) technology, coupled\nwith a stateof-the-art (SoA) microcontroller to an embedded Field Programmable\nGate Array (FPGA). We demonstrate the flexibility of the System-OnChip (SoC) to\ntackle the challenges of many emerging IoT applications, such as (i)\ninterfacing sensors and accelerators with non-standard interfaces, (ii)\nperforming on-the-fly pre-processing tasks on data streamed from peripherals,\nand (iii) accelerating near-sensor analytics, encryption, and machine learning\ntasks. A unique feature of the proposed SoC is the exploitation of body-biasing\nto reduce leakage power of the embedded FPGA (eFPGA) fabric by up to 18x at 0.5\nV, achieving SoA state bitstream-retentive sleep power for the eFPGA fabric, as\nlow as 20.5 uW. The proposed SoC provides 3.4x better performance and 2.9x\nbetter energy efficiency than other fabricated heterogeneous re-configurable\nSoCs of the same class.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:02:24 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Schiavone", "Pasquale Davide", ""], ["Rossi", "Davide", ""], ["Di Mauro", "Alfio", ""], ["Gurkaynak", "Frank", ""], ["Saxe", "Timothy", ""], ["Wang", "Mao", ""], ["Yap", "Ket Chong", ""], ["Benini", "Luca", ""]]}, {"id": "2006.14317", "submitter": "Yeonsoo Jeon", "authors": "Yeonsoo Jeon and Dongsuk Jeon", "title": "A Fast Finite Field Multiplier for SIKE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various post-quantum cryptography algorithms have been recently proposed.\nSupersingluar isogeny Diffie-Hellman key exchange (SIKE) is one of the most\npromising candidates due to its small key size. However, the SIKE scheme\nrequires numerous finite field multiplications for its isogeny computation, and\nhence suffers from slow encryption and decryption process. In this paper, we\npropose a fast finite field multiplier design that performs multiplications in\nGF(p) with high throughput and low latency. The design accelerates the\ncomputation by adopting deep pipelining, and achieves high hardware utilization\nthrough data interleaving. The proposed finite field multiplier demonstrates\n4.48 times higher throughput than prior work based on the identical fast\nmultiplication algorithm and 1.43 times higher throughput than the\nstate-of-the-art fast finite field multiplier design aimed at SIKE.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 11:37:30 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 05:31:39 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jeon", "Yeonsoo", ""], ["Jeon", "Dongsuk", ""]]}, {"id": "2006.15103", "submitter": "Nandan Kumar Jha", "authors": "Nandan Kumar Jha, Shreyas Ravishankar, Sparsh Mittal, Arvind Kaushik,\n  Dipan Mandal, Mahesh Chandra", "title": "DRACO: Co-Optimizing Hardware Utilization, and Performance of DNNs on\n  Systolic Accelerator", "comments": "Accepted as a conference paper in the IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI). Limassol, CYPRUS, July 6-8, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of processing elements (PEs) in a fixed-sized systolic accelerator\nis well matched for large and compute-bound DNNs; whereas, memory-bound DNNs\nsuffer from PE underutilization and fail to achieve peak performance and energy\nefficiency. To mitigate this, specialized dataflow and/or micro-architectural\ntechniques have been proposed. However, due to the longer development cycle and\nthe rapid pace of evolution in the deep learning fields, these hardware-based\nsolutions can be obsolete and ineffective in dealing with PE underutilization\nfor state-of-the-art DNNs. In this work, we address the challenge of PE\nunderutilization at the algorithm front and propose data reuse aware\nco-optimization (DRACO). This improves the PE utilization of memory-bound DNNs\nwithout any additional need for dataflow/micro-architecture modifications.\nFurthermore, unlike the previous co-optimization methods, DRACO not only\nmaximizes performance and energy efficiency but also improves the predictive\nperformance of DNNs. To the best of our knowledge, DRACO is the first work that\nresolves the resource underutilization challenge at the algorithm level and\ndemonstrates a trade-off between computational efficiency, PE utilization, and\npredictive performance of DNN. Compared to the state-of-the-art row stationary\ndataflow, DRACO achieves 41.8% and 42.6% improvement in average PE utilization\nand inference latency (respectively) with negligible loss in predictive\nperformance in MobileNetV1 on a $64\\times64$ systolic array. DRACO provides\nseminal insights for utilization-aware DNN design methodologies that can fully\nleverage the computation power of systolic array-based hardware accelerators.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 17:06:41 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Jha", "Nandan Kumar", ""], ["Ravishankar", "Shreyas", ""], ["Mittal", "Sparsh", ""], ["Kaushik", "Arvind", ""], ["Mandal", "Dipan", ""], ["Chandra", "Mahesh", ""]]}, {"id": "2006.15469", "submitter": "Abdelkader Nasreddine Belkacem", "authors": "Abdelkader Nasreddine Belkacem, Sofia Ouhbi, Abderrahmane Lakas,\n  Elhadj Benkhelifa, Chao Chen", "title": "End-to-End AI-Based Point-of-Care Diagnosis System for Classifying\n  Respiratory Illnesses and Early Detection of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.AR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory symptoms can be a caused by different underlying conditions, and\nare often caused by viral infections, such as Influenza-like illnesses or other\nemerging viruses like the Coronavirus. These respiratory viruses, often, have\ncommon symptoms, including coughing, high temperature, congested nose, and\ndifficulty breathing. However, early diagnosis of the type of the virus, can be\ncrucial, especially in cases such as the recent COVID-19 pandemic. One of the\nfactors that contributed to the spread of the pandemic, was the late diagnosis\nor confusing it with regular flu-like symptoms. Science has proved that one of\nthe possible differentiators of the underlying causes of these different\nrespiratory diseases is coughing, which comes in different types and forms.\nTherefore, a reliable lab-free tool for early and more accurate diagnosis that\ncan differentiate between different respiratory diseases is very much needed.\nThis paper proposes an end-to-end portable system that can record data from\npatients with symptom, including coughs (voluntary or involuntary) and\ntranslate them into health data for diagnosis, and with the aid of machine\nlearning, classify them into different respiratory illnesses, including\nCOVID-19. With the ongoing efforts to stop the spread of the COVID-19 disease\neverywhere today, and against similar diseases in the future, our proposed low\ncost and user-friendly solution can play an important part in the early\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 00:06:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Belkacem", "Abdelkader Nasreddine", ""], ["Ouhbi", "Sofia", ""], ["Lakas", "Abderrahmane", ""], ["Benkhelifa", "Elhadj", ""], ["Chen", "Chao", ""]]}, {"id": "2006.16239", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Milad Hashemi, Kevin Swersky, Parthasarathy\n  Ranganathan, Junwhan Ahn", "title": "An Imitation Learning Approach for Cache Replacement", "comments": "International Conference on Machine Learning (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Program execution speed critically depends on increasing cache hits, as cache\nhits are orders of magnitude faster than misses. To increase cache hits, we\nfocus on the problem of cache replacement: choosing which cache line to evict\nupon inserting a new line. This is challenging because it requires planning far\nahead and currently there is no known practical solution. As a result, current\nreplacement policies typically resort to heuristics designed for specific\ncommon access patterns, which fail on more diverse and complex access patterns.\nIn contrast, we propose an imitation learning approach to automatically learn\ncache access patterns by leveraging Belady's, an oracle policy that computes\nthe optimal eviction decision given the future cache accesses. While directly\napplying Belady's is infeasible since the future is unknown, we train a policy\nconditioned only on past accesses that accurately approximates Belady's even on\ndiverse and complex access patterns, and call this approach Parrot. When\nevaluated on 13 of the most memory-intensive SPEC applications, Parrot\nincreases cache miss rates by 20% over the current state of the art. In\naddition, on a large-scale web search benchmark, Parrot increases cache hit\nrates by 61% over a conventional LRU policy. We release a Gym environment to\nfacilitate research in this area, as data is plentiful, and further\nadvancements can have significant real-world impact.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 17:58:40 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 21:13:34 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Hashemi", "Milad", ""], ["Swersky", "Kevin", ""], ["Ranganathan", "Parthasarathy", ""], ["Ahn", "Junwhan", ""]]}, {"id": "2006.16345", "submitter": "Andrea Mondelli", "authors": "Andrea Mondelli, Paul Gazzillo and Yan Solihin", "title": "SeMPE: Secure Multi Path Execution Architecture for Removing Conditional\n  Branch Side Channels", "comments": "This paper is currently under submission. We arXiv our paper to\n  establish credit for inventing this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most prevalent source of side channel vulnerabilities is the\nsecret-dependent behavior of conditional branches (SDBCB). The state-of-the-art\nsolution relies on Constant-Time Expressions, which require high programming\neffort and incur high performance overheads. In this paper, we propose SeMPE,\nan approach that relies on architecture support to eliminate SDBCB without\nrequiring much programming effort while incurring low performance overheads.\nThe key idea is that when a secret-dependent branch is encountered, the SeMPE\nmicroarchitecture fetches, executes, and commits both paths of the branch,\npreventing the adversary from inferring secret values from the branching\nbehavior of the program. To enable that, SeMPE relies on an architecture that\nis capable of safely executing both branch paths sequentially. Through\nmicrobenchmarks and an evaluation of a real-world library, we show that SeMPE\nincurs near ideal execution time overheads, which is the sum of the execution\ntime of all branch paths of secret-dependent branches. SeMPE outperforms code\ngenerated by FaCT, a constant-time expression language, by up to a factor of\n18x.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:06:53 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 06:44:07 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Mondelli", "Andrea", ""], ["Gazzillo", "Paul", ""], ["Solihin", "Yan", ""]]}, {"id": "2006.16535", "submitter": "You Wu", "authors": "You Wu, Xuehai Qian", "title": "A Case for Reversible Coherence Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first Reversible Coherence Protocol (RCP), a new protocol\ndesigned from ground up that enables invisible speculative load. RCP takes a\nbold approach by including the speculative loads and merge/purge operation in\nthe interface between processor and cache coherence, and allowing them to\nparticipate in the coherence protocol. It means, speculative load, ordinary\nload/store, and merge/purge can all affect the state of a given cache line. RCP\nis the first coherence protocol that enables the commit and squash of the\nspeculative load among distributed cache components in a general memory\nhierarchy. RCP incurs an average slowdown of (3.0%,8.3%,7.4%) on\n(SPEC2006,SPEC2017,PARSEC), which is lower compared to (26.5%,12%,18.3%) in\nInvisiSpec and (3.2%,9.4%,24.2%) in CleanupSpec. The coherence traffic overhead\nis on average 46%, compared to 40% and 27% of InvisiSpec and CleanupSpec,\nrespectively. Even with higher traffic overhead (~46%), the performance\noverhead of RCP is lower than InvisiSpec and comparable to CleanupSpec. It\nreveals a key advantage of RCP: the coherence actions triggered by the merge\nand purge operations are not in the critical path of the execution and can be\nperformed in the cache hierarchy concurrently with processor execution\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 05:16:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 01:11:12 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 00:21:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "You", ""], ["Qian", "Xuehai", ""]]}, {"id": "2006.16921", "submitter": "Jiska Classen", "authors": "J\\\"orn Tillmanns, Jiska Classen, Felix Rohrbach, Matthias Hollick", "title": "Firmware Insider: Bluetooth Randomness is Mostly Random", "comments": "WOOT'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth chips must include a Random Number Generator (RNG). This RNG is\nused internally within cryptographic primitives but also exposed to the\noperating system for chip-external applications. In general, it is a black box\nwith security-critical authentication and encryption mechanisms depending on\nit. In this paper, we evaluate the quality of RNGs in various Broadcom and\nCypress Bluetooth chips. We find that the RNG implementation significantly\nchanged over the last decade. Moreover, most devices implement an insecure\nPseudo-Random Number Generator (PRNG) fallback. Multiple popular devices, such\nas the Samsung Galaxy S8 and its variants as well as an iPhone, rely on the\nweak fallback due to missing a Hardware Random Number Generator (HRNG). We\nstatistically evaluate the output of various HRNGs in chips used by hundreds of\nmillions of devices. While the Broadcom and Cypress HRNGs pass advanced tests,\nit remains indistinguishable for users if a Bluetooth chip implements a secure\nRNG without an extensive analysis as in this paper. We describe our measurement\nmethods and publish our tools to enable further public testing.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 15:51:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Tillmanns", "J\u00f6rn", ""], ["Classen", "Jiska", ""], ["Rohrbach", "Felix", ""], ["Hollick", "Matthias", ""]]}]