[{"id": "1507.01777", "submitter": "Suman Sau", "authors": "Swagata Mandal, Suman Sau, Amlan Chakrabarti, Jogendra Saini, Sushanta\n  Kumar Pal and Subhasish Chattopadhyay", "title": "FPGA based Novel High Speed DAQ System Design with Error Correction", "comments": "ISVLSI 2015. arXiv admin note: substantial text overlap with\n  arXiv:1505.04569, arXiv:1503.08819", "journal-ref": null, "doi": null, "report-no": "01A", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Present state of the art applications in the area of high energy physics\nexperiments (HEP), radar communication, satellite communication and bio medical\ninstrumentation require fault resilient data acquisition (DAQ) system with the\ndata rate in the order of Gbps. In order to keep the high speed DAQ system\nfunctional in such radiation environment where direct intervention of human is\nnot possible, a robust and error free communication system is necessary. In\nthis work we present an efficient DAQ design and its implementation on field\nprogrammable gate array (FPGA). The proposed DAQ system supports high speed\ndata communication (~4.8 Gbps) and achieves multi-bit error correction\ncapabilities. BCH code (named after Raj Bose and D. K. RayChaudhuri) has been\nused for multi-bit error correction. The design has been implemented on Xilinx\nKintex-7 board and is tested for board to board communication as well as for\nboard to PC using PCIe (Peripheral Component Interconnect express) interface.\nTo the best of our knowledge, the proposed FPGA based high speed DAQ system\nutilizing optical link and multi-bit error resiliency can be considered first\nof its kind. Performance estimation of the implemented DAQ system is done based\non resource utilization, critical path delay, efficiency and bit error rate\n(BER).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 12:24:25 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Mandal", "Swagata", ""], ["Sau", "Suman", ""], ["Chakrabarti", "Amlan", ""], ["Saini", "Jogendra", ""], ["Pal", "Sushanta Kumar", ""], ["Chattopadhyay", "Subhasish", ""]]}, {"id": "1507.03303", "submitter": "Yang Li", "authors": "Yang Li (1), Jongmoo Choi (2), Jin Sun (1), Saugata Ghose (1), Hui\n  Wang (3), Justin Meza (1), Jinglei Ren (4), Onur Mutlu (1) ((1) Carnegie\n  Mellon University, (2) Dankook University, (3) Beihang University, (4)\n  Tsinghua University)", "title": "Managing Hybrid Main Memories with a Page-Utility Driven Performance\n  Model", "comments": null, "journal-ref": "https://www.andrew.cmu.edu/user/yangli1/UHMEM_Cluster2017.pdf", "doi": null, "report-no": "SAFARI Technical Report No. 2015-010", "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid memory systems comprised of dynamic random access memory (DRAM) and\nnon-volatile memory (NVM) have been proposed to exploit both the capacity\nadvantage of NVM and the latency and dynamic energy advantages of DRAM. An\nimportant problem for such systems is how to place data between DRAM and NVM to\nimprove system performance.\n  In this paper, we devise the first mechanism, called UBM (page Utility Based\nhybrid Memory management), that systematically estimates the system performance\nbenefit of placing a page in DRAM versus NVM and uses this estimate to guide\ndata placement. UBM's estimation method consists of two major components.\nFirst, it estimates how much an application's stall time can be reduced if the\naccessed page is placed in DRAM. To do this, UBM comprehensively considers\naccess frequency, row buffer locality, and memory level parallelism (MLP) to\nestimate the application's stall time reduction. Second, UBM estimates how much\neach application's stall time reduction contributes to overall system\nperformance. Based on this estimation method, UBM can determine and place the\nmost critical data in DRAM to directly optimize system performance.\nExperimental results show that UBM improves system performance by 14% on\naverage (and up to 39%) compared to the best of three state-of-the-art\nmechanisms for a large number of data-intensive workloads from the SPEC CPU2006\nand Yahoo Cloud Serving Benchmark (YCSB) suites.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 01:47:16 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Li", "Yang", ""], ["Choi", "Jongmoo", ""], ["Sun", "Jin", ""], ["Ghose", "Saugata", ""], ["Wang", "Hui", ""], ["Meza", "Justin", ""], ["Ren", "Jinglei", ""], ["Mutlu", "Onur", ""]]}, {"id": "1507.08340", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "How Data Volume Affects Spark Based Data Analytics on a Scale-up Server", "comments": "accepted to 6th International Workshop on Big Data Benchmarks,\n  Performance Optimization and Emerging Hardware (BpoE-6) held in conjunction\n  with VLDB 2015. arXiv admin note: text overlap with arXiv:1506.07742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sheer increase in volume of data over the last decade has triggered research\nin cluster computing frameworks that enable web enterprises to extract big\ninsights from big data. While Apache Spark is gaining popularity for exhibiting\nsuperior scale-out performance on the commodity machines, the impact of data\nvolume on the performance of Spark based data analytics in scale-up\nconfiguration is not well understood. We present a deep-dive analysis of Spark\nbased applications on a large scale-up server machine. Our analysis reveals\nthat Spark based data analytics are DRAM bound and do not benefit by using more\nthan 12 cores for an executor. By enlarging input data size, application\nperformance degrades significantly due to substantial increase in wait time\nduring I/O operations and garbage collection, despite 10\\% better instruction\nretirement rate (due to lower L1 cache misses and higher core utilization). We\nmatch memory behaviour with the garbage collector to improve performance of\napplications between 1.6x to 3x.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 22:59:49 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}]