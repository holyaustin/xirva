[{"id": "1801.00005", "submitter": "Walter Schneider", "authors": "Walter Schneider", "title": "Analytical Inverter Delay Modeling Using Matlab's Curve Fitting Toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents a new analytical propagation delay model for deep\nsubmicron CMOS inverters. The model is inspired by the key observation that the\ninverter delay is a complicated function of several process parameters as well\nas load capacitance. These relationships are considered by fitting functions\nfor each parameter derived from the Curve Fitting Toolbox in Matlab. Compared\nto SPICE simulations based on the BSIM4 transistor model, the analytical delay\nmodel shows very good accuracy with an average error less than 2% over a wide\nrange of process parameters and output loads. Hence, the proposed model can be\nefficiently used for different technology nodes as well as statistical gate\ndelay characterisation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 14:33:16 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Schneider", "Walter", ""]]}, {"id": "1801.00472", "submitter": "Chuan Zhang", "authors": "Zhiwei Zhong (1 and 2), Xiaohu You (2), Chuan Zhang (1 and 2) ((1) Lab\n  of Efficient Architectures for Digital-communication and Signal-processing\n  (LEADS), (2) National Mobile Communications Research Laboratory, Southeast\n  University, Nanjing, China)", "title": "Auto-Generation of Pipelined Hardware Designs for Polar Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general framework for auto-generation of pipelined\npolar encoder architectures. The proposed framework could be well represented\nby a general formula. Given arbitrary code length $N$ and the level of\nparallelism $M$, the formula could specify the corresponding hardware\narchitecture. We have written a compiler which could read the formula and then\nautomatically generate its register-transfer level (RTL) description suitable\nfor FPGA or ASIC implementation. With this hardware generation system, one\ncould explore the design space and make a trade-off between cost and\nperformance. Our experimental results have demonstrated the efficiency of this\nauto-generator for polar encoder architectures.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 16:50:09 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Zhong", "Zhiwei", "", "1 and 2"], ["You", "Xiaohu", "", "1 and 2"], ["Zhang", "Chuan", "", "1 and 2"]]}, {"id": "1801.01114", "submitter": "Bo-Yuan Huang", "authors": "Bo-Yuan Huang, Hongce Zhang, Pramod Subramanyan, Yakir Vizel, Aarti\n  Gupta, and Sharad Malik", "title": "Instruction-Level Abstraction (ILA): A Uniform Specification for\n  System-on-Chip (SoC) Verification", "comments": "24 pages, 3 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3282444", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and\ncontain specialized semi-programmable accelerators in addition to programmable\nprocessors. In contrast to the pre-accelerator era, when the ISA played an\nimportant role in verification by enabling a clean separation of concerns\nbetween software and hardware, verification of these \"accelerator-rich\" SoCs\npresents new challenges. From the perspective of hardware designers, there is a\nlack of a common framework for the formal functional specification of\naccelerator behavior. From the perspective of software developers, there exists\nno unified framework for reasoning about software/hardware interactions of\nprograms that interact with accelerators. This paper addresses these challenges\nby providing a formal specification and high-level abstraction for accelerator\nfunctional behavior. It formalizes the concept of an Instruction Level\nAbstraction (ILA), developed informally in our previous work, and shows its\napplication in modeling and verification of accelerators. This formal ILA\nextends the familiar notion of instructions to accelerators and provides a\nuniform, modular, and hierarchical abstraction for modeling software-visible\nbehavior of both accelerators and programmable processors. We demonstrate the\napplicability of the ILA through several case studies of accelerators (for\nimage processing, machine learning, and cryptography), and a general-purpose\nprocessor (RISC-V). We show how the ILA model facilitates equivalence checking\nbetween two ILAs, and between an ILA and its hardware finite-state machine\n(FSM) implementation. Further, this equivalence checking supports accelerator\nupgrades using the notion of ILA compatibility, similar to processor upgrades\nusing ISA compatibility.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 18:54:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 06:38:15 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Huang", "Bo-Yuan", ""], ["Zhang", "Hongce", ""], ["Subramanyan", "Pramod", ""], ["Vizel", "Yakir", ""], ["Gupta", "Aarti", ""], ["Malik", "Sharad", ""]]}, {"id": "1801.02190", "submitter": "Stylianos Venieris", "authors": "Michalis Rizakis, Stylianos I. Venieris, Alexandros Kouris and\n  Christos-Savvas Bouganis", "title": "Approximate FPGA-based LSTMs under Computation Time Constraints", "comments": "Accepted at the 14th International Symposium in Applied\n  Reconfigurable Computing (ARC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)\nnetworks have demonstrated state-of-the-art accuracy in several emerging\nArtificial Intelligence tasks. However, the models are becoming increasingly\ndemanding in terms of computational and memory load. Emerging latency-sensitive\napplications including mobile robots and autonomous vehicles often operate\nunder stringent computation time constraints. In this paper, we address the\nchallenge of deploying computationally demanding LSTMs at a constrained time\nbudget by introducing an approximate computing scheme that combines iterative\nlow-rank compression and pruning, along with a novel FPGA-based LSTM\narchitecture. Combined in an end-to-end framework, the approximation method's\nparameters are optimised and the architecture is configured to address the\nproblem of high-performance LSTM execution in time-constrained applications.\nQuantitative evaluation on a real-life image captioning application indicates\nthat the proposed methods required up to 6.5x less time to achieve the same\napplication-level accuracy compared to a baseline method, while achieving an\naverage of 25x higher accuracy under the same computation time constraints.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 13:46:03 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Rizakis", "Michalis", ""], ["Venieris", "Stylianos I.", ""], ["Kouris", "Alexandros", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1801.02508", "submitter": "Ella Gale", "authors": "Ella M. Gale", "title": "Spiking memristor logic gates are a type of time-variant perceptron", "comments": "8 pages, 3 figures. Poster presentation at a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristors are low-power memory-holding resistors thought to be useful for\nneuromophic computing, which can compute via spike-interactions mediated\nthrough the device's short-term memory. Using interacting spikes, it is\npossible to build an AND gate that computes OR at the same time, similarly a\nfull adder can be built that computes the arithmetical sum of its inputs. Here\nwe show how these gates can be understood by modelling the memristors as a\nnovel type of perceptron: one which is sensitive to input order. The\nmemristor's memory can change the input weights for later inputs, and thus the\nmemristor gates cannot be accurately described by a single perceptron,\nrequiring either a network of time-invarient perceptrons or a complex\ntime-varying self-reprogrammable perceptron. This work demonstrates the high\nfunctionality of memristor logic gates, and also that the addition of\ntheasholding could enable the creation of a standard perceptron in hardware,\nwhich may have use in building neural net chips.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:33:53 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Gale", "Ella M.", ""]]}, {"id": "1801.03534", "submitter": "Tad Hogg", "authors": "Ralph C. Merkle, Robert A. Freitas Jr., Tad Hogg, Thomas E. Moore,\n  Matthew S. Moses, James Ryley", "title": "Mechanical Computing Systems Using Only Links and Rotary Joints", "comments": null, "journal-ref": "ASME Journal on Mechanisms and Robotics 10:061006 (2018)", "doi": "10.1115/1.4041209", "report-no": null, "categories": "cs.ET cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new model for mechanical computing is demonstrated that requires only two\nbasic parts: links and rotary joints. These basic parts are combined into two\nmain higher level structures: locks and balances, which suffice to create all\nnecessary combinatorial and sequential logic required for a Turing-complete\ncomputational system. While working systems have yet to be implemented using\nthis new approach, the mechanical simplicity of the systems described may lend\nthemselves better to, e.g., microfabrication, than previous mechanical\ncomputing designs. Additionally, simulations indicate that if molecular-scale\nimplementations could be realized, they would be far more energy-efficient than\nconventional electronic computers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 19:51:05 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 23:00:41 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Merkle", "Ralph C.", ""], ["Freitas", "Robert A.", "Jr."], ["Hogg", "Tad", ""], ["Moore", "Thomas E.", ""], ["Moses", "Matthew S.", ""], ["Ryley", "James", ""]]}, {"id": "1801.03712", "submitter": "Andrea Reale", "authors": "Dimitris Syrivelis, Andrea Reale, Kostas Katrinis, Christian Pinto", "title": "A Software-defined SoC Memory Bus Bridge Architecture for Disaggregated\n  Computing", "comments": "3rd International Workshop on Advanced Interconnect Solutions and\n  Technologies for Emerging Computing Systems (AISTECS 2018, part of HiPEAC\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disaggregation and rack-scale systems have the potential of drastically\ndecreasing TCO and increasing utilization of cloud datacenters, while\nmaintaining performance. While the concept of organising resources in separate\npools and interconnecting them together on demand is straightforward, its\nmaterialisation can be radically different in terms of performance and scale\npotential.\n  In this paper, we present a memory bus bridge architecture which enables\ncommunication between 100s of masters and slaves in todays complex\nmultiprocessor SoCs, that are physically intregrated in different chips and\neven different mainboards. The bridge tightly couples serial transceivers and a\ncircuit network for chip-to-chip transfers. A key property of the proposed\nbridge architecture is that it is software-defined and thus can be configured\nat runtime, via a software control plane, to prepare and steer memory access\ntransactions to remote slaves. This is particularly important because it\nenables datacenter orchestration tools to manage the disaggregated resource\nallocation. Moreover, we evaluate a bridge prototype we have build for ARM AXI4\nmemory bus interconnect and we discuss application-level observed performance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 11:15:31 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Syrivelis", "Dimitris", ""], ["Reale", "Andrea", ""], ["Katrinis", "Kostas", ""], ["Pinto", "Christian", ""]]}, {"id": "1801.04886", "submitter": "Khaza Anuarul Hoque", "authors": "Khaza Anuarul Hoque, Otmane Ait Mohamed, Yvon Savaria", "title": "Dependability modeling and optimization of triple modular redundancy\n  partitioning for SRAM-based FPGAs", "comments": "Published in Reliability Engineering & System Safety Volume 182,\n  February 2019, Pages 107-119", "journal-ref": "Reliability Engineering & System Safety Volume 182, February 2019,\n  Pages 107-119", "doi": "10.1016/j.ress.2018.10.011", "report-no": null, "categories": "cs.DC cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SRAM-based FPGAs are popular in the aerospace industry for their field\nprogrammability and low cost. However, they suffer from cosmic\nradiation-induced Single Event Upsets (SEUs). Triple Modular Redundancy (TMR)\nis a well-known technique to mitigate SEUs in FPGAs that is often used with\nanother SEU mitigation technique known as configuration scrubbing. Traditional\nTMR provides protection against a single fault at a time, while partitioned TMR\nprovides improved reliability and availability. In this paper, we present a\nmethodology to analyze TMR partitioning at early design stage using\nprobabilistic model checking. The proposed formal model can capture both single\nand multiple-cell upset scenarios, regardless of any assumption of equal\npartition sizes. Starting with a high-level description of a design, a Markov\nmodel is constructed from the Data Flow Graph (DFG) using a specified number of\npartitions, a component characterization library and a user defined scrub rate.\nSuch a model and exhaustive analysis captures all the considered failures and\nrepairs possible in the system within the radiation environment. Various\nreliability and availability properties are then verified automatically using\nthe PRISM model checker exploring the relationship between the scrub frequency\nand the number of TMR partitions required to meet the design requirements.\nAlso, the reported results show that based on a known voter failure rate, it is\npossible to find an optimal number of partitions at early design stages using\nour proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 19:00:22 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 20:38:27 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 17:11:31 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Hoque", "Khaza Anuarul", ""], ["Mohamed", "Otmane Ait", ""], ["Savaria", "Yvon", ""]]}, {"id": "1801.05178", "submitter": "Dani Voitsechov", "authors": "Dani Voitsechov and Yoav Etsion", "title": "Inter-thread Communication in Multithreaded, Reconfigurable Coarse-grain\n  Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional von Neumann GPGPUs only allow threads to communicate through\nmemory on a group-to-group basis. In this model, a group of producer threads\nwrites intermediate values to memory, which are read by a group of consumer\nthreads after a barrier synchronization. To alleviate the memory bandwidth\nimposed by this method of communication, GPGPUs provide a small scratchpad\nmemory that prevents intermediate values from overloading DRAM bandwidth. In\nthis paper we introduce direct inter-thread communications for massively\nmultithreaded CGRAs, where intermediate values are communicated directly\nthrough the compute fabric on a point-to-point basis. This method avoids the\nneed to write values to memory, eliminates the need for a dedicated scratchpad,\nand avoids workgroup-global barriers. The paper introduces the programming\nmodel (CUDA) and execution model extensions, as well as the hardware primitives\nthat facilitate the communication. Our simulations of Rodinia benchmarks\nrunning on the new system show that direct inter-thread communication provides\nan average speedup of 4.5x (13.5x max) and reduces system power by an average\nof 7x (33x max), when compared to an equivalent Nvidia GPGPU.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 09:38:46 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Voitsechov", "Dani", ""], ["Etsion", "Yoav", ""]]}, {"id": "1801.05215", "submitter": "Antonio Gonzalez", "authors": "Antonio Gonzalez", "title": "Trends in Processor Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of the main trends in processor architecture.\nIt starts with an analysis of the past evolution of processors and the main\ndriving forces behind it, and then it focuses on a description of the main\narchitectural features of current processors. Finally, it presents a discussion\non some promising directions for future evolution of processor architectures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 11:42:56 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Gonzalez", "Antonio", ""]]}, {"id": "1801.05731", "submitter": "Roberto Bifulco", "authors": "Giuseppe Siracusano, Roberto Bifulco", "title": "In-network Neural Networks", "comments": "Accepted at SysML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present N2Net, a system that implements binary neural networks using\ncommodity switching chips deployed in network switches and routers. Our system\nshows that these devices can run simple neural network models, whose input is\nencoded in the network packets' header, at packet processing speeds (billions\nof packets per second). Furthermore, our experience highlights that switching\nchips could support even more complex models, provided that some minor and\ncheap modifications to the chip's design are applied. We believe N2Net provides\nan interesting building block for future end-to-end networked systems.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 16:17:28 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Siracusano", "Giuseppe", ""], ["Bifulco", "Roberto", ""]]}, {"id": "1801.05997", "submitter": "Jung-Woo Chang", "authors": "Jung-Woo Chang, Keon-Woo Kang, and Suk-Ju Kang", "title": "An Energy-Efficient FPGA-based Deconvolutional Neural Networks\n  Accelerator for Single Image Super-Resolution", "comments": "Accepted for publication in IEEE Transactions on Circuits and Systems\n  for Video Technology (TCSVT)", "journal-ref": null, "doi": "10.1109/TCSVT.2018.2888898", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) demonstrate excellent performance in\nvarious computer vision applications. In recent years, FPGA-based CNN\naccelerators have been proposed for optimizing performance and power\nefficiency. Most accelerators are designed for object detection and recognition\nalgorithms that are performed on low-resolution (LR) images. However, real-time\nimage super-resolution (SR) cannot be implemented on a typical accelerator\nbecause of the long execution cycles required to generate high-resolution (HR)\nimages, such as those used in ultra-high-definition (UHD) systems. In this\npaper, we propose a novel CNN accelerator with efficient parallelization\nmethods for SR applications. First, we propose a new methodology for optimizing\nthe deconvolutional neural networks (DCNNs) used for increasing feature maps.\nSecondly, we propose a novel method to optimize CNN dataflow so that the SR\nalgorithm can be driven at low power in display applications. Finally, we\nquantize and compress a DCNN-based SR algorithm into an optimal model for\nefficient inference using on-chip memory. We present an energy-efficient\narchitecture for SR and validate our architecture on a mobile panel with\nquad-high-definition (QHD) resolution. Our experimental results show that, with\nthe same hardware resources, the proposed DCNN accelerator achieves a\nthroughput up to 108 times greater than that of a conventional DCNN\naccelerator. In addition, our SR system achieves an energy efficiency of 144.9\nGOPS/W, 293.0 GOPS/W, and 500.2 GOPS/W at SR scale factors of 2, 3, and 4,\nrespectively. Furthermore, we demonstrate that our system can restore HR images\nto a high quality while greatly reducing the data bit-width and the number of\nparameters compared to conventional SR algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 13:04:53 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 00:50:24 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 15:52:43 GMT"}, {"version": "v4", "created": "Tue, 18 Dec 2018 14:00:40 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Chang", "Jung-Woo", ""], ["Kang", "Keon-Woo", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "1801.06027", "submitter": "Divya Mahajan", "authors": "Divya Mahajan, Joon Kyung Kim, Jacob Sacks, Adel Ardalan, Arun Kumar,\n  Hadi Esmaeilzadeh", "title": "In-RDBMS Hardware Acceleration of Advanced Analytics", "comments": null, "journal-ref": "Divya Mahajan, Joon Kyung Kim, Jacob Sacks, Adel Ardalan, Arun\n  Kumar, and Hadi Esmaeilzadeh. In-RDBMS Hardware Acceleration of Advanced\n  Analytics. PVLDB, 11(11): 1317-1331, 2018", "doi": "10.14778/3236187.3236188", "report-no": null, "categories": "cs.DB cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data revolution is fueled by advances in machine learning, databases, and\nhardware design. Programmable accelerators are making their way into each of\nthese areas independently. As such, there is a void of solutions that enables\nhardware acceleration at the intersection of these disjoint fields. This paper\nsets out to be the initial step towards a unifying solution for in-Database\nAcceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such\nas FPGAs, for in-database analytics currently requires hand-designing the\nhardware and manually routing the data. Instead, DAnA automatically maps a\nhigh-level specification of advanced analytics queries to an FPGA accelerator.\nThe accelerator implementation is generated for a User Defined Function (UDF),\nexpressed as a part of an SQL query using a Python-embedded Domain-Specific\nLanguage (DSL). To realize an efficient in-database integration, DAnA\naccelerators contain a novel hardware structure, Striders, that directly\ninterface with the buffer pool of the database. Striders extract, cleanse, and\nprocess the training data tuples that are consumed by a multi-threaded FPGA\nengine that executes the analytics algorithm. We integrate DAnA with PostgreSQL\nto generate hardware accelerators for a range of real-world and synthetic\ndatasets running diverse ML algorithms. Results show that DAnA-enhanced\nPostgreSQL provides, on average, 8.3x end-to-end speedup for real datasets,\nwith a maximum of 28.2x. Moreover, DAnA-enhanced PostgreSQL is, on average,\n4.0x faster than the multi-threaded Apache MADLib running on Greenplum. DAnA\nprovides these benefits while hiding the complexity of hardware design from\ndata scientists and allowing them to express the algorithm in =30-60 lines of\nPython.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:04:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 13:55:56 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Mahajan", "Divya", ""], ["Kim", "Joon Kyung", ""], ["Sacks", "Jacob", ""], ["Ardalan", "Adel", ""], ["Kumar", "Arun", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1801.06070", "submitter": "P Balasubramanian", "authors": "P Balasubramanian", "title": "Approximate Early Output Asynchronous Adders Based on Dual-Rail Data\n  Encoding and 4-Phase Return-to-Zero and Return-to-One Handshaking", "comments": "arXiv admin note: text overlap with arXiv:1711.02333", "journal-ref": "Intl. Jour. of Ckts., Sys. and Signal Processing, vol. 11, pp.\n  445-453, 2017", "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate computing is emerging as an alternative to accurate computing due\nto its potential for realizing digital circuits and systems with low power\ndissipation, less critical path delay, and less area occupancy for an\nacceptable trade-off in the accuracy of results. In the domain of computer\narithmetic, several approximate adders and multipliers have been designed and\ntheir potential have been showcased versus accurate adders and multipliers for\npractical digital signal processing applications. Nevertheless, in the existing\nliterature, almost all the approximate adders and multipliers reported\ncorrespond to the synchronous design method. In this work, we consider robust\nasynchronous i.e. quasi-delay-insensitive realizations of approximate adders by\nemploying delay-insensitive codes for data representation and processing, and\nthe 4-phase handshake protocols for data communication. The 4-phase handshake\nprotocols used are the return-to-zero and the return-to-one protocols.\nSpecifically, we consider the implementations of 32-bit approximate adders\nbased on the return-to-zero and return-to-one handshake protocols by adopting\nthe delay-insensitive dual-rail code for data encoding. We consider a range of\napproximations varying from 4-bits to 20-bits for the least significant\npositions of the accurate 32-bit asynchronous adder. The asynchronous adders\ncorrespond to early output (i.e. early reset) type, which are based on the\nwell-known ripple carry adder architecture. The experimental results show that\napproximate asynchronous adders achieve reductions in the design metrics such\nas latency, cycle time, average power dissipation, and silicon area compared to\nthe accurate asynchronous adders. Further, the reductions in the design metrics\nare greater for the return-to-one protocol compared to the return-to-zero\nprotocol. The design metrics were estimated using a 32/28nm CMOS technology.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 11:36:04 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Balasubramanian", "P", ""]]}, {"id": "1801.06274", "submitter": "Yuhao Zhu", "authors": "Yuhao Zhu, Matthew Mattina, Paul Whatmough", "title": "Mobile Machine Learning Hardware at ARM: A Systems-on-Chip (SoC)\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is playing an increasingly significant role in emerging\nmobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware\narchitects have designed customized hardware for machine learning algorithms,\nespecially neural networks, to improve compute efficiency. However, machine\nlearning is typically just one processing stage in complex end-to-end\napplications, involving multiple components in a mobile Systems-on-a-chip\n(SoC). Focusing only on ML accelerators loses bigger optimization opportunity\nat the system (SoC) level. This paper argues that hardware architects should\nexpand the optimization scope to the entire SoC. We demonstrate one particular\ncase-study in the domain of continuous computer vision where camera sensor,\nimage signal processor (ISP), memory, and NN accelerator are synergistically\nco-designed to achieve optimal system-level efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 02:42:10 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:54:27 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Zhu", "Yuhao", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul", ""]]}, {"id": "1801.06726", "submitter": "Dmitrii Ustiugov", "authors": "Dmitrii Ustiugov, Alexandros Daglis, Javier Picorel, Mark Sutherland,\n  Edouard Bugnion, Babak Falsafi, Dionisios Pnevmatikatos", "title": "Design Guidelines for High-Performance SCM Hierarchies", "comments": "Published at MEMSYS'18", "journal-ref": null, "doi": "10.1145/3240302.3240310", "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With emerging storage-class memory (SCM) nearing commercialization, there is\nevidence that it will deliver the much-anticipated high density and access\nlatencies within only a few factors of DRAM. Nevertheless, the\nlatency-sensitive nature of memory-resident services makes seamless integration\nof SCM in servers questionable. In this paper, we ask the question of how best\nto introduce SCM for such servers to improve overall performance/cost over\nexisting DRAM-only architectures. We first show that even with the most\noptimistic latency projections for SCM, the higher memory access latency\nresults in prohibitive performance degradation. However, we find that\ndeployment of a modestly sized high-bandwidth 3D stacked DRAM cache makes the\nperformance of an SCM-mostly memory system competitive. The high degree of\nspatial locality that memory-resident services exhibit not only simplifies the\nDRAM cache's design as page-based, but also enables the amortization of\nincreased SCM access latencies and the mitigation of SCM's read/write latency\ndisparity.\n  We identify the set of memory hierarchy design parameters that plays a key\nrole in the performance and cost of a memory system combining an SCM technology\nand a 3D stacked DRAM cache. We then introduce a methodology to drive\nprovisioning for each of these design parameters under a target\nperformance/cost goal. Finally, we use our methodology to derive concrete\nresults for specific SCM technologies. With PCM as a case study, we show that a\ntwo bits/cell technology hits the performance/cost sweet spot, reducing the\nmemory subsystem cost by 40% while keeping performance within 3% of the best\nperforming DRAM-only system, whereas single-level and triple-level cell\norganizations are impractical for use as memory replacements.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 20:42:49 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 13:18:32 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 17:52:18 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 19:03:49 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Ustiugov", "Dmitrii", ""], ["Daglis", "Alexandros", ""], ["Picorel", "Javier", ""], ["Sutherland", "Mark", ""], ["Bugnion", "Edouard", ""], ["Falsafi", "Babak", ""], ["Pnevmatikatos", "Dionisios", ""]]}, {"id": "1801.07397", "submitter": "Jiliang Zhang", "authors": "Jiliang Zhang, Binhang Qi, Gang Qu", "title": "HCIC: Hardware-assisted Control-flow Integrity Checking", "comments": "14 pages", "journal-ref": "IEEE Internet of Things Journal.(2018) 1-14", "doi": "10.1109/JIOT.2018.2866164", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, code reuse attacks (CRAs), such as return-oriented programming\n(ROP) and jump-oriented programming (JOP), have emerged as a new class of\ningenious security threatens. Attackers can utilize CRAs to hijack the control\nflow of programs to perform malicious actions without injecting any codes. Many\ndefenses, classed into software-based and hardware-based, have been proposed.\nHowever, software-based methods are difficult to be deployed in practical\nsystems due to high performance overhead. Hardware-based methods can reduce\nperformance overhead but may require extending instruction set architectures\n(ISAs) and modifying compiler or suffer the vulnerability of key leakage. To\ntackle these issues, this paper proposes a new hardware-based control flow\nchecking method to resist CRAs with negligible performance overhead without\nextending ISAs, modifying compiler and leaking the encryption/decryption key.\nThe key technique involves two control flow checking mechanisms. The first one\nis the encrypted Hamming distances (EHDs) matching between the physical\nunclonable function (PUF) response and the return addresses, which prevents\nattackers from returning between gadgets so long as the PUF response is secret,\nthus resisting ROP attacks. The second one is the liner encryption/decryption\noperation (XOR) between PUF response and the instructions at target addresses\nof call and jmp instructions to defeat JOP attacks. Advanced return-based\nfull-function reuse attacks will be prevented with the dynamic key-updating\nmethod. Experimental evaluations on benchmarks demonstrate that the proposed\nmethod introduces negligible 0.95% run-time overhead and 0.78% binary size\noverhead on average.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 05:28:44 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 05:59:23 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Zhang", "Jiliang", ""], ["Qi", "Binhang", ""], ["Qu", "Gang", ""]]}, {"id": "1801.08088", "submitter": "Nitish Kumar Srivastava", "authors": "Nitish Kumar Srivastava and Akshay Dilip Navalakha", "title": "Pointer-Chase Prefetcher for Linked Data Structures", "comments": "12 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caches only exploit spatial and temporal locality in a set of address\nreferenced in a program. Due to dynamic construction of linked data-structures,\nthey are difficult to cache as the spatial locality between the nodes is highly\ndependent on the data layout. Prefetching can play an important role in\nimproving the performance of linked data-structures. In this project, a pointer\nchase mechanism along with compiler hints is adopted to design a prefetcher for\nlinked data-structures. The design is evaluated against the baseline of\nprocessor with cache in terms of performance, area and energy\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 02:53:45 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Srivastava", "Nitish Kumar", ""], ["Navalakha", "Akshay Dilip", ""]]}, {"id": "1801.10219", "submitter": "James Garland", "authors": "James Garland, David Gregg", "title": "Low Complexity Multiply-Accumulate Units for Convolutional Neural\n  Networks with Weight-Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are one of the most successful machine\nlearning techniques for image, voice and video processing. CNNs require large\namounts of processing capacity and memory bandwidth. Hardware accelerators have\nbeen proposed for CNNs which typically contain large numbers of\nmultiply-accumulate (MAC) units, the multipliers of which are large in an\nintegrated circuit (IC) gate count and power consumption. \"Weight sharing\"\naccelerators have been proposed where the full range of weight values in a\ntrained CNN are compressed and put into bins and the bin index used to access\nthe weight-shared value. We reduce power and area of the CNN by implementing\nparallel accumulate shared MAC (PASM) in a weight shared CNN. PASM\nre-architects the MAC to instead count the frequency of each weight and place\nit in a bin. The accumulated value is computed in a subsequent multiply phase,\nsignificantly reducing gate count and power consumption of the CNN. In this\npaper, we implement PASM in a weight-shared CNN convolution hardware\naccelerator and analyze its effectiveness. Experiments show that for a clock\nspeed 1GHz implemented on a 45nm ASIC process our approach results in fewer\ngates, smaller logic, and reduced power with only a slight increase in latency.\nWe also show that the same weight-shared-with-PASM CNN accelerator can be\nimplemented in resource-constrained FPGAs, where the FPGA has limited numbers\nof digital signal processor (DSP) units to accelerate the MAC operations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 20:45:17 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 13:45:01 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:07:42 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Garland", "James", ""], ["Gregg", "David", ""]]}]