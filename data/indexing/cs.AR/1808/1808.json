[{"id": "1808.00650", "submitter": "Shaolin Xie", "authors": "Shaolin Xie and Michael Bedford Taylor", "title": "The BaseJump Manycore Accelerator Network", "comments": "Technical Report of Bespoke Silicon Group, University of Washington.\n  http://bjump.org/manycore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BaseJump Manycore Accelerator-Network is an open source mesh-based\nOn-Chip-Network which is designed leveraging the Bespoke Silicon Group's 20+\nyears of experience in designing manycore architectures. It has been used in\nthe 16nm 511-core RISC-V compatible Celerity chip Davidson et al. (2018),\nforming the basis of both a 1 GHz 496-core RISC-V manycore and a 10-core\nalways-on low voltage complex. It was also used in the 180nm BSG Ten chip,\nwhich featured ten cores and a mesh that extends over off-chip links to an\nFPGA. To facilitate use by the open source community of the BaseJump Manycore\nnetwork, we explain the ideas, protocols, interfaces and potential uses of the\nmesh network. We also show an example with source code that demonstrates how to\nintegrate user designs into the mesh network.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 03:20:01 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 13:08:55 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Xie", "Shaolin", ""], ["Taylor", "Michael Bedford", ""]]}, {"id": "1808.01728", "submitter": "Hossein Sayadi", "authors": "Hossein Sayadi", "title": "Energy-Efficiency Prediction of Multithreaded Workloads on Heterogeneous\n  Composite Cores Architectures using Machine Learning Techniques", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous architectures have emerged as a promising alternative for\nhomogeneous architectures to improve the energy-efficiency of computer systems.\nComposite Cores Architecture (CCA), a class of dynamic heterogeneous\narchitectures enabling the computer system to construct the right core at\nrun-time for each application by composing cores together to build larger core\nor decomposing a large core into multiple smaller cores. While this\narchitecture provides more flexibility for the running application to find the\nbest run-time settings to maximize energy-efficiency, due to the\ninterdependence of various tuning parameters such as the type of the core,\nrun-time voltage and frequency and the number of threads, it makes it more\nchallenging for scheduling. Prior studies mainly addressed the scheduling\nproblem in CCAs by looking at one or two of these tuning parameters. However,\nas we will show in this paper, it is important to concurrently optimize and\nfine-tune these parameters. In addition, most previous works on CCA mainly\nstudy traditional single threaded CPU applications. This paper describes a\nsystematic approach to predict the right configurations for running\nmultithreaded workloads on CCAs. It achieves this by developing a machine\nlearning-based approach to predict core type, voltage and frequency setting to\nmaximize the energy-efficiency. Our predictor learns offline from an extensive\nset of training multithreaded workloads. It is then applied to predict the\noptimal processor configuration at run-time by taking into account the\nmultithreaded application characteristics and the optimization objective. For\nthis purpose, five well-known machine learning models are implemented for\nenergy-efficiency optimization and precisely compared in terms of accuracy and\nhardware overhead to guide the scheduling decisions in a CCA.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 04:11:55 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Sayadi", "Hossein", ""]]}, {"id": "1808.01756", "submitter": "Huazi Zhang", "authors": "Huazi Zhang, Jiajie Tong, Rong Li, Pengcheng Qiu, Yourui Huangfu, Chen\n  Xu, Xianbin Wang, Jun Wang", "title": "A Flip-Syndrome-List Polar Decoder Architecture for Ultra-Low-Latency\n  Communications", "comments": "10 pages, submitted to IEEE Access (Special Issue on Advances in\n  Channel Coding for 5G and Beyond)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider practical hardware implementation of Polar decoders. To reduce\nlatency due to the serial nature of successive cancellation (SC), existing\noptimizations improve parallelism with two approaches, i.e., multi-bit decision\nor reduced path splitting. In this paper, we combine the two procedures into\none with an error-pattern-based architecture. It simultaneously generates a set\nof candidate paths for multiple bits with pre-stored patterns. For rate-1 (R1)\nor single parity-check (SPC) nodes, we prove that a small number of\ndeterministic patterns are required to guarantee performance preservation. For\ngeneral nodes, low-weight error patterns are indexed by syndrome in a look-up\ntable and retrieved in O(1) time. The proposed flip-syndrome-list (FSL) decoder\nfully parallelizes all constituent code blocks without sacrificing performance,\nthus is suitable for ultra-low-latency applications. Meanwhile, two code\nconstruction optimizations are presented to further reduce complexity and\nimprove performance, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 07:51:02 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Zhang", "Huazi", ""], ["Tong", "Jiajie", ""], ["Li", "Rong", ""], ["Qiu", "Pengcheng", ""], ["Huangfu", "Yourui", ""], ["Xu", "Chen", ""], ["Wang", "Xianbin", ""], ["Wang", "Jun", ""]]}, {"id": "1808.02449", "submitter": "Xiang Fu", "authors": "X. Fu, L. Riesebos, M. A. Rol, J. van Straten, J. van Someren, N.\n  Khammassi, I. Ashraf, R. F. L. Vermeulen, V. Newsum, K. K. L. Loh, J. C. de\n  Sterke, W. J. Vlothuizen, R. N. Schouten, C. G. Almudever, L. DiCarlo, K.\n  Bertels", "title": "eQASM: An Executable Quantum Instruction Set Architecture", "comments": "13 pages, 8 figures; added abstract, re-positioned figures", "journal-ref": "Proceedings of the 25th International Symposium on\n  High-Performance Computer Architecture (HPCA'19), 2019", "doi": null, "report-no": null, "categories": "cs.AR cs.SY quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely-used quantum programming paradigm comprises of both the data flow\nand control flow. Existing quantum hardware cannot well support the control\nflow, significantly limiting the range of quantum software executable on the\nhardware. By analyzing the constraints in the control microarchitecture, we\nfound that existing quantum assembly languages are either too high-level or too\nrestricted to support comprehensive flow control on the hardware. Also, as\nobserved with the quantum microinstruction set QuMIS, the quantum instruction\nset architecture (QISA) design may suffer from limited scalability and\nflexibility because of microarchitectural constraints. It is an open challenge\nto design a scalable and flexible QISA which provides a comprehensive\nabstraction of the quantum hardware.\n  In this paper, we propose an executable QISA, called eQASM, that can be\ntranslated from quantum assembly language (QASM), supports comprehensive\nquantum program flow control, and is executed on a quantum control\nmicroarchitecture. With efficient timing specification,\nsingle-operation-multiple-qubit execution, and a very-long-instruction-word\narchitecture, eQASM presents better scalability than QuMIS. The definition of\neQASM focuses on the assembly level to be expressive. Quantum operations are\nconfigured at compile time instead of being defined at QISA design time. We\ninstantiate eQASM into a 32-bit instruction set targeting a seven-qubit\nsuperconducting quantum processor. We validate our design by performing several\nexperiments on a two-qubit quantum processor.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 16:25:20 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 15:55:35 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2019 06:06:01 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fu", "X.", ""], ["Riesebos", "L.", ""], ["Rol", "M. A.", ""], ["van Straten", "J.", ""], ["van Someren", "J.", ""], ["Khammassi", "N.", ""], ["Ashraf", "I.", ""], ["Vermeulen", "R. F. L.", ""], ["Newsum", "V.", ""], ["Loh", "K. K. L.", ""], ["de Sterke", "J. C.", ""], ["Vlothuizen", "W. J.", ""], ["Schouten", "R. N.", ""], ["Almudever", "C. G.", ""], ["DiCarlo", "L.", ""], ["Bertels", "K.", ""]]}, {"id": "1808.03083", "submitter": "Danila Gorodecky", "authors": "Danila Gorodecky and Tiziano Villa", "title": "Hardware realization of residue number system algorithms by Boolean\n  functions minimization", "comments": "1 picture, 1 table, 4 plots; it is the same paper as for 13th\n  International Workshop on Boolean Problems (Bremen, Germany) paper with a\n  title \"Efficient hardware realization of arithmetic operations for the\n  residue number system by Boolean minimization\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residue number systems (RNS) represent numbers by their remainders modulo a\nset of relatively prime numbers. This paper pro- poses an efficient hardware\nimplementation of modular multiplication and of the modulo function (X(mod P)),\nbased on Boolean minimiza- tion. We report experiments showing a performance\nadvantage up to 30 times for our approach vs. the results obtained by\nstate-of-art industrial tools.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 11:01:09 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Gorodecky", "Danila", ""], ["Villa", "Tiziano", ""]]}, {"id": "1808.04016", "submitter": "Yixin Luo", "authors": "Yixin Luo", "title": "Architectural Techniques for Improving NAND Flash Memory Reliability", "comments": "Thesis, Carnegie Mellon University (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raw bit errors are common in NAND flash memory and will increase in the\nfuture. These errors reduce flash reliability and limit the lifetime of a flash\nmemory device. We aim to improve flash reliability with a multitude of low-cost\narchitectural techniques. We show that NAND flash memory reliability can be\nimproved at low cost and with low performance overhead by deploying various\narchitectural techniques that are aware of higher-level application behavior\nand underlying flash device characteristics.\n  We analyze flash error characteristics and workload behavior through\nexperimental characterization, and design new flash controller algorithms that\nuse the insights gained from our analysis to improve flash reliability at a low\ncost. We investigate four directions through this approach. (1) We propose a\nnew technique called WARM that improves flash reliability by 12.9 times by\nmanaging flash retention differently for write-hot data and write-cold data.\n(2) We propose a new framework that learns an online flash channel model for\neach chip and enables four new flash controller algorithms to improve flash\nreliability by up to 69.9%. (3) We identify three new error characteristics in\n3D NAND through a comprehensive experimental characterization of real 3D NAND\nchips, and propose four new techniques that mitigate these new errors and\nimprove 3D NAND reliability by up to 66.9%. (4) We propose a new technique\ncalled HeatWatch that improves 3D NAND reliability by 3.85 times by utilizing\nself-healing effect to mitigate retention errors in 3D NAND.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 23:07:09 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Luo", "Yixin", ""]]}, {"id": "1808.04286", "submitter": "Jeremie Kim", "authors": "Jeremie S. Kim, Minesh Patel, Hasan Hassan, Lois Orosa, Onur Mutlu", "title": "D-RaNGe: Using Commodity DRAM Devices to Generate True Random Numbers\n  with Low Latency and High Throughput", "comments": "An earlier version was submitted to and reviewed by the International\n  Symposium on Microarchitecture (51) 2018, with a submission deadline on April\n  6th, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new DRAM-based true random number generator (TRNG) that\nleverages DRAM cells as an entropy source. The key idea is to intentionally\nviolate the DRAM access timing parameters and use the resulting errors as the\nsource of randomness. Our technique specifically decreases the DRAM row\nactivation latency (timing parameter tRCD) below manufacturer-recommended\nspecifications, to induce read errors, or activation failures, that exhibit\ntrue random behavior. We then aggregate the resulting data from multiple cells\nto obtain a TRNG capable of providing a high throughput of random numbers at\nlow latency.\n  To demonstrate that our TRNG design is viable using commodity DRAM chips, we\nrigorously characterize the behavior of activation failures in 282\nstate-of-the-art LPDDR4 devices from three major DRAM manufacturers. We verify\nour observations using four additional DDR3 DRAM devices from the same\nmanufacturers. Our results show that many cells in each device produce random\ndata that remains robust over both time and temperature variation. We use our\nobservations to develop D-RanGe, a methodology for extracting true random\nnumbers from commodity DRAM devices with high throughput and low latency by\ndeliberately violating the read access timing parameters. We evaluate the\nquality of our TRNG using the commonly-used NIST statistical test suite for\nrandomness and find that D-RaNGe: 1) successfully passes each test, and 2)\ngenerates true random numbers with over two orders of magnitude higher\nthroughput than the previous highest-throughput DRAM-based TRNG.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:22:53 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 20:27:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Kim", "Jeremie S.", ""], ["Patel", "Minesh", ""], ["Hassan", "Hasan", ""], ["Orosa", "Lois", ""], ["Mutlu", "Onur", ""]]}, {"id": "1808.04864", "submitter": "Mohammad Bakhshalipour", "authors": "Pouya Esmaili-Dokht, Mohammad Bakhshalipour, Behnam Khodabandeloo,\n  Pejman Lotfi-Kamran, Hamid Sarbazi-Azad", "title": "Scale-Out Processors & Energy Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale-out workloads like media streaming or Web search serve millions of\nusers and operate on a massive amount of data, and hence, require enormous\ncomputational power. As the number of users is increasing and the size of data\nis expanding, even more computational power is necessary for powering up such\nworkloads. Data centers with thousands of servers are providing the\ncomputational power necessary for executing scale-out workloads. As operating\ndata centers requires enormous capital outlay, it is important to optimize them\nto execute scale-out workloads efficiently. Server processors contribute\nsignificantly to the data center capital outlay, and hence, are a prime\ncandidate for optimizations. While data centers are constrained with power, and\npower consumption is one of the major components contributing to the total cost\nof ownership (TCO), a recently-introduced scale-out design methodology\noptimizes server processors for data centers using performance per unit area.\nIn this work, we use a more relevant performance-per-power metric as the\noptimization criterion for optimizing server processors and reevaluate the\nscale-out design methodology. Interestingly, we show that a scale-out processor\nthat delivers the maximum performance per unit area, also delivers the highest\nperformance per unit power.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 19:07:46 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Esmaili-Dokht", "Pouya", ""], ["Bakhshalipour", "Mohammad", ""], ["Khodabandeloo", "Behnam", ""], ["Lotfi-Kamran", "Pejman", ""], ["Sarbazi-Azad", "Hamid", ""]]}, {"id": "1808.05024", "submitter": "Mohammad Bakhshalipour", "authors": "Seyed Armin Vakil Ghahani, Sara Mahdizadeh Shahri, Mohammad\n  Bakhshalipour, Pejman Lotfi-Kamran, Hamid Sarbazi-Azad", "title": "Making Belady-Inspired Replacement Policies More Effective Using\n  Expected Hit Count", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-intensive workloads operate on massive amounts of data that cannot be\ncaptured by last-level caches (LLCs) of modern processors. Consequently,\nprocessors encounter frequent off-chip misses, and hence, lose a significant\nperformance potential. One way to reduce the number of off-chip misses is\nthrough using a well-behaved replacement policy in the LLC. Existing processors\nemploy a variation of least recently used (LRU) policy to determine a victim\nfor replacement. Unfortunately, there is a large gap between what LRU offers\nand that of Belady's MIN, which is the optimal replacement policy. Belady's MIN\nrequires selecting a victim with the longest reuse distance, and hence, is\nunfeasible due to the need to know the future. Consequently, Belady-inspired\nreplacement polices use Belady's MIN to derive an indicator to help them choose\na victim for replacement.\n  In this work, we show that the indicator that is used in the state-of-the-art\nBelady-inspired replacement policy is not decisive in picking a victim in a\nconsiderable number of cases, and hence, the policy has to rely on a standard\nmetric (e.g., recency or frequency) to pick a victim, which is inefficient. We\nobserve that there exist strong correlations among the hit counts of cache\nblocks in the same region of memory when Belady's MIN is the replacement\npolicy. Taking advantage of this observation, we propose an expected-hit-count\nindicator for the memory regions and use it to improve the victim selection\nmechanism of Belady-inspired replacement policies when the main indicator is\nnot decisive. Our proposal offers a 5.2\\% performance improvement over the\nbaseline LRU and outperforms Hawkeye, which is the state-of-the-art replacement\npolicy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 10:18:55 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Ghahani", "Seyed Armin Vakil", ""], ["Shahri", "Sara Mahdizadeh", ""], ["Bakhshalipour", "Mohammad", ""], ["Lotfi-Kamran", "Pejman", ""], ["Sarbazi-Azad", "Hamid", ""]]}, {"id": "1808.06334", "submitter": "Jeffrey Young", "authors": "Will Powell, Jason Riedy, Jeffrey S. Young, Thomas M. Conte", "title": "Wrangling Rogues: Managing Experimental Post-Moore Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rogues Gallery is a new experimental testbed that is focused on tackling\n\"rogue\" architectures for the Post-Moore era of computing. While some of these\ndevices have roots in the embedded and high-performance computing spaces,\nmanaging current and emerging technologies provides a challenge for system\nadministration that are not always foreseen in traditional data center\nenvironments.\n  We present an overview of the motivations and design of the initial Rogues\nGallery testbed and cover some of the unique challenges that we have seen and\nforesee with upcoming hardware prototypes for future post-Moore research.\nSpecifically, we cover the networking, identity management, scheduling of\nresources, and tools and sensor access aspects of the Rogues Gallery and\ntechniques we have developed to manage these new platforms.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 07:57:47 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 14:37:33 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 20:52:05 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2019 00:45:12 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Powell", "Will", ""], ["Riedy", "Jason", ""], ["Young", "Jeffrey S.", ""], ["Conte", "Thomas M.", ""]]}, {"id": "1808.09087", "submitter": "Karthik Rao", "authors": "Karthik Rao and William Song and Yorai Wardi and Sudhakar Yalamanchili", "title": "TRINITY: Coordinated Performance, Energy and Temperature Management in\n  3D Processor-Memory Stacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consistent demand for better performance has lead to innovations at\nhardware and microarchitectural levels. 3D stacking of memory and logic dies\ndelivers an order of magnitude improvement in available memory bandwidth. The\nprice paid however is, tight thermal constraints.\n  In this paper, we study the complex multiphysics interactions between\nperformance, energy and temperature. Using a cache coherent multicore processor\ncycle level simulator coupled with power and thermal estimation tools, we\ninvestigate the interactions between (a) thermal behaviors (b) compute and\nmemory microarchitecture and (c) application workloads. The key insights from\nthis exploration reveal the need to manage performance, energy and temperature\nin a coordinated fashion. Furthermore, we identify the concept of \"effective\nheat capacity\" i.e. the heat generated beyond which no further gains in\nperformance is observed with increases in voltage-frequency of the compute\nlogic. Subsequently, a real-time, numerical optimization based, application\nagnostic controller (TRINITY) is developed which intelligently manages the\nthree parameters of interest. We observe up to $30\\%$ improvement in Energy\nDelay$^2$ Product and up to $8$ Kelvin lower core temperatures as compared to\nfixed frequencies. Compared to the \\texttt{ondemand} Linux CPU DVFS governor,\nfor similar energy efficiency, TRINITY keeps the cores cooler by $6$ Kelvin\nwhich increases the lifetime reliability by up to 59\\%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 01:48:05 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 19:30:03 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Rao", "Karthik", ""], ["Song", "William", ""], ["Wardi", "Yorai", ""], ["Yalamanchili", "Sudhakar", ""]]}, {"id": "1808.09651", "submitter": "Kapil Dev", "authors": "Kapil Dev, Indrani Paul, Wei Huang, Yasuko Eckert, Wayne Burleson, and\n  Sherief Reda", "title": "Implications of Integrated CPU-GPU Processors on Thermal and Power\n  Management Techniques", "comments": "9 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous processors with architecturally different cores (CPU and GPU)\nintegrated on the same die lead to new challenges and opportunities for thermal\nand power management techniques because of shared thermal/power budgets between\nthese cores. In this paper, we show that new parallel programming paradigms\n(e.g., OpenCL) for CPU-GPU processors create a tighter coupling between the\nworkload, the thermal/power management unit and the operating system. Using\ndetailed thermal and power maps of the die from infrared imaging, we\ndemonstrate that in contrast to traditional multi-core CPUs, heterogeneous\nprocessors exhibit higher coupled behavior for dynamic voltage and frequency\nscaling and workload scheduling, in terms of their effect on performance,\npower, and temperature. Further, we show that by taking the differences in core\narchitectures and relative proximity of different computing cores on the die\ninto consideration, better scheduling schemes could be implemented to reduce\nboth the power density and peak temperature of the die. The findings presented\nin the paper can be used to improve thermal and power efficiency of\nheterogeneous CPU-GPU processors.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 06:17:07 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Dev", "Kapil", ""], ["Paul", "Indrani", ""], ["Huang", "Wei", ""], ["Eckert", "Yasuko", ""], ["Burleson", "Wayne", ""], ["Reda", "Sherief", ""]]}, {"id": "1808.09751", "submitter": "Andreas Kurth", "authors": "Andreas Kurth, Pirmin Vogel, Andrea Marongiu, Luca Benini", "title": "Scalable and Efficient Virtual Memory Sharing in Heterogeneous SoCs with\n  TLB Prefetching and MMU-Aware DMA Engine", "comments": "9 pages, 5 figures. Accepted for publication in Proceedings of the\n  36th IEEE International Conference on Computer Design (ICCD), October 7-10,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared virtual memory (SVM) is key in heterogeneous systems on chip (SoCs),\nwhich combine a general-purpose host processor with a many-core accelerator,\nboth for programmability and to avoid data duplication. However, SVM can bring\na significant run time overhead when translation lookaside buffer (TLB) entries\nare missing. Moreover, allowing DMA burst transfers to write SVM traditionally\nrequires buffers to absorb transfers that miss in the TLB. These buffers have\nto be overprovisioned for the maximum burst size, wasting precious on-chip\nmemory, and stall all SVM accesses once they are full, hampering the\nscalability of parallel accelerators.\n  In this work, we present our SVM solution that avoids the majority of TLB\nmisses with prefetching, supports parallel burst DMA transfers without\nadditional buffers, and can be scaled with the workload and number of parallel\nprocessors. Our solution is based on three novel concepts: To minimize the rate\nof TLB misses, the TLB is proactively filled by compiler-generated Prefetching\nHelper Threads, which use run-time information to issue timely prefetches. To\nreduce the latency of TLB misses, misses are handled by a variable number of\nparallel Miss Handling Helper Threads. To support parallel burst DMA transfers\nto SVM without additional buffers, we add lightweight hardware to a standard\nDMA engine to detect and react to TLB misses. Compared to the state of the art,\nour work improves accelerator performance for memory-intensive kernels by up to\n4x and by up to 60% for irregular and regular memory access patterns,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 12:18:12 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Kurth", "Andreas", ""], ["Vogel", "Pirmin", ""], ["Marongiu", "Andrea", ""], ["Benini", "Luca", ""]]}]