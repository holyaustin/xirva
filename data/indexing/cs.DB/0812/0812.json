[{"id": "0812.0438", "submitter": "Sabu Thampi m", "authors": "Sabu M. Thampi", "title": "An Introduction to Knowledge Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge has been lately recognized as one of the most important assets of\norganizations. Managing knowledge has grown to be imperative for the success of\na company. This paper presents an overview of Knowledge Management and various\naspects of secure knowledge management. A case study of knowledge management\nactivities at Tata Steel is also discussed\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2008 09:00:27 GMT"}], "update_date": "2008-12-03", "authors_parsed": [["Thampi", "Sabu M.", ""]]}, {"id": "0812.0564", "submitter": "James Cheney", "authors": "James Cheney, Umut Acar, Amal Ahmed", "title": "Provenance Traces", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provenance is information about the origin, derivation, ownership, or history\nof an object. It has recently been studied extensively in scientific databases\nand other settings due to its importance in helping scientists judge data\nvalidity, quality and integrity. However, most models of provenance have been\nstated as ad hoc definitions motivated by informal concepts such as \"comes\nfrom\", \"influences\", \"produces\", or \"depends on\". These models lack clear\nformalizations describing in what sense the definitions capture these intuitive\nconcepts. This makes it difficult to compare approaches, evaluate their\neffectiveness, or argue about their validity.\n  We introduce provenance traces, a general form of provenance for the nested\nrelational calculus (NRC), a core database query language. Provenance traces\ncan be thought of as concrete data structures representing the operational\nsemantics derivation of a computation; they are related to the traces that have\nbeen used in self-adjusting computation, but differ in important respects. We\ndefine a tracing operational semantics for NRC queries that produces both an\nordinary result and a trace of the execution. We show that three pre-existing\nforms of provenance for the NRC can be extracted from provenance traces.\nMoreover, traces satisfy two semantic guarantees: consistency, meaning that the\ntraces describe what actually happened during execution, and fidelity, meaning\nthat the traces \"explain\" how the expression would behave if the input were\nchanged. These guarantees are much stronger than those contemplated for\nprevious approaches to provenance; thus, provenance traces provide a general\nsemantic foundation for comparing and unifying models of provenance in\ndatabases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2008 18:17:23 GMT"}], "update_date": "2008-12-03", "authors_parsed": [["Cheney", "James", ""], ["Acar", "Umut", ""], ["Ahmed", "Amal", ""]]}, {"id": "0812.2049", "submitter": "Jian Li", "authors": "Jian Li, Amol Deshpande", "title": "Consensus Answers for Queries over Probabilistic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding a \"best\" deterministic query answer to a\nquery over a probabilistic database. For this purpose, we propose the notion of\na consensus world (or a consensus answer) which is a deterministic world\n(answer) that minimizes the expected distance to the possible worlds (answers).\nThis problem can be seen as a generalization of the well-studied inconsistent\ninformation aggregation problems (e.g. rank aggregation) to probabilistic\ndatabases. We consider this problem for various types of queries including SPJ\nqueries, \\Topk queries, group-by aggregate queries, and clustering. For\ndifferent distance metrics, we obtain polynomial time optimal or approximation\nalgorithms for computing the consensus answers (or prove NP-hardness). Most of\nour results are for a general probabilistic database model, called {\\em and/xor\ntree model}, which significantly generalizes previous probabilistic database\nmodels like x-tuples and block-independent disjoint models, and is of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2008 23:20:17 GMT"}], "update_date": "2008-12-12", "authors_parsed": [["Li", "Jian", ""], ["Deshpande", "Amol", ""]]}, {"id": "0812.2195", "submitter": "Rada Chirkova", "authors": "Rada Chirkova, Michael Genesereth", "title": "Equivalence of SQL Queries in Presence of Embedded Dependencies", "comments": "Correction of the previous version as described in the last sentence\n  of the Abstract", "journal-ref": null, "doi": null, "report-no": "NCSU CSC TR-2008-27", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding equivalent minimal-size reformulations of\nSQL queries in presence of embedded dependencies [1]. Our focus is on\nselect-project-join (SPJ) queries with equality comparisons, also known as safe\nconjunctive (CQ) queries, possibly with grouping and aggregation. For SPJ\nqueries, the semantics of the SQL standard treat query answers as multisets\n(a.k.a. bags), whereas the stored relations may be treated either as sets,\nwhich is called bag-set semantics for query evaluation, or as bags, which is\ncalled bag semantics. (Under set semantics, both query answers and stored\nrelations are treated as sets.)\n  In the context of the above Query-Reformulation Problem, we develop a\ncomprehensive framework for equivalence of CQ queries under bag and bag-set\nsemantics in presence of embedded dependencies, and make a number of conceptual\nand technical contributions. Specifically, we develop equivalence tests for CQ\nqueries in presence of arbitrary sets of embedded dependencies under bag and\nbag-set semantics, under the condition that chase [9] under set semantics\n(set-chase) on the inputs terminates. We also present equivalence tests for\naggregate CQ queries in presence of embedded dependencies. We use our\nequivalence tests to develop sound and complete (whenever set-chase on the\ninputs terminates) algorithms for solving instances of the Query-Reformulation\nProblem with CQ queries under each of bag and bag-set semantics, as well as for\ninstances of the problem with aggregate queries.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2008 17:25:55 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 19:22:10 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2009 22:28:22 GMT"}], "update_date": "2009-06-27", "authors_parsed": [["Chirkova", "Rada", ""], ["Genesereth", "Michael", ""]]}, {"id": "0812.2874", "submitter": "Richard McClatchey", "authors": "Andrew Branson, Tamas Hauer, Richard McClatchey, Dmitry Rogulin and\n  Jetendr Shamdasani", "title": "A Data Model for Integrating Heterogeneous Medical Data in the\n  Health-e-Child Project", "comments": "10 pages, 4 figures, 1 table. Proceedings the 6th HealthGrid Int.\n  Conference (HG08)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much research activity in recent times about providing the\ndata infrastructures needed for the provision of personalised healthcare. In\nparticular the requirement of integrating multiple, potentially distributed,\nheterogeneous data sources in the medical domain for the use of clinicians has\nset challenging goals for the healthgrid community. The approach advocated in\nthis paper surrounds the provision of an Integrated Data Model plus links\nto/from ontologies to homogenize biomedical (from genomic, through cellular,\ndisease, patient and population-related) data in the context of the EC\nFramework 6 Health-e-Child project. Clinical requirements are identified, the\ndesign approach in constructing the model is detailed and the integrated model\ndescribed in the context of examples taken from that project. Pointers are\ngiven to future work relating the model to medical ontologies and challenges to\nthe use of fully integrated models and ontologies are identified.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2008 18:25:51 GMT"}], "update_date": "2008-12-16", "authors_parsed": [["Branson", "Andrew", ""], ["Hauer", "Tamas", ""], ["McClatchey", "Richard", ""], ["Rogulin", "Dmitry", ""], ["Shamdasani", "Jetendr", ""]]}, {"id": "0812.2879", "submitter": "Richard McClatchey", "authors": "Kamran Munir, Mohammed Odeh and Richard McClatchey", "title": "Ontology Assisted Query Reformulation Using Semantic and Assertion\n  Capabilities of OWL-DL Ontologies", "comments": "15 pages, 4 figures. Proceedings of the 12th International Database\n  Engineering & Applications Symposium (Ideas2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End users of recent biomedical information systems are often unaware of the\nstorage structure and access mechanisms of the underlying data sources and can\nrequire simplified mechanisms for writing domain specific complex queries. This\nresearch aims to assist users and their applications in formulating queries\nwithout requiring complete knowledge of the information structure of underlying\ndata sources. To achieve this, query reformulation techniques and algorithms\nhave been developed that can interpret ontology-based search criteria and\nassociated domain knowledge in order to reformulate a relational query. These\nquery reformulation algorithms exploit the semantic relationships and assertion\ncapabilities of OWL-DL based domain ontologies for query reformulation. In this\npaper, this approach is applied to the integrated database schema of the EU\nfunded Health-e-Child (HeC) project with the aim of providing ontology assisted\nquery reformulation techniques to simplify the global access that is needed to\nmillions of medical records across the UK and Europe.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2008 18:34:44 GMT"}], "update_date": "2008-12-16", "authors_parsed": [["Munir", "Kamran", ""], ["Odeh", "Mohammed", ""], ["McClatchey", "Richard", ""]]}, {"id": "0812.3550", "submitter": "Pierre Genev\\`es", "authors": "Pierre Geneves and Nabil Layaida", "title": "XML Static Analyzer User Manual", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6726", "categories": "cs.PL cs.DB cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes how to use the XML static analyzer in practice. It\nprovides informal documentation for using the XML reasoning solver\nimplementation. The solver allows automated verification of properties that are\nexpressed as logical formulas over trees. A logical formula may for instance\nexpress structural constraints or navigation properties (like e.g. path\nexistence and node selection) in finite trees. Logical formulas can be\nexpressed using the syntax of XPath expressions, DTD, XML Schemas, and Relax NG\ndefinitions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2008 15:22:46 GMT"}], "update_date": "2008-12-19", "authors_parsed": [["Geneves", "Pierre", ""], ["Layaida", "Nabil", ""]]}, {"id": "0812.3715", "submitter": "Aurelie Bissay", "authors": "Aur\\'elie Bissay (LIESP), Philippe Pernelle (LIESP), Arnaud Lefebvre\n  (LIESP), Abdelaziz Bouras (LIESP)", "title": "Business processes integration and performance indicators in a PLM", "comments": null, "journal-ref": "APMS'08, Espoo : Finlande (2008)", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an economic environment more and more competitive, the effective\nmanagement of information and knowledge is a strategic issue for industrial\nenterprises. In the global marketplace, companies must use reactive strategies\nand reduce their products development cycle. In this context, the PLM (Product\nLifecycle Management) is considered as a key component of the information\nsystem. The aim of this paper is to present an approach to integrate Business\nProcesses in a PLM system. This approach is implemented in automotive sector\nwith second-tier subcontractor\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2008 07:52:46 GMT"}], "update_date": "2008-12-22", "authors_parsed": [["Bissay", "Aur\u00e9lie", "", "LIESP"], ["Pernelle", "Philippe", "", "LIESP"], ["Lefebvre", "Arnaud", "", "LIESP"], ["Bouras", "Abdelaziz", "", "LIESP"]]}, {"id": "0812.3788", "submitter": "Michael Schmidt", "authors": "Michael Schmidt, Michael Meier, Georg Lausen", "title": "Foundations of SPARQL Query Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SPARQL query language is a recent W3C standard for processing RDF data, a\nformat that has been developed to encode information in a machine-readable way.\nWe investigate the foundations of SPARQL query optimization and (a) provide\nnovel complexity results for the SPARQL evaluation problem, showing that the\nmain source of complexity is operator OPTIONAL alone; (b) propose a\ncomprehensive set of algebraic query rewriting rules; (c) present a framework\nfor constraint-based SPARQL optimization based upon the well-known chase\nprocedure for Conjunctive Query minimization. In this line, we develop two\nnovel termination conditions for the chase. They subsume the strongest\nconditions known so far and do not increase the complexity of the recognition\nproblem, thus making a larger class of both Conjunctive and SPARQL queries\namenable to constraint-based optimization. Our results are of immediate\npractical interest and might empower any SPARQL query optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2008 13:51:57 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2009 12:52:36 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Schmidt", "Michael", ""], ["Meier", "Michael", ""], ["Lausen", "Georg", ""]]}, {"id": "0812.4986", "submitter": "Albrecht Schmidt", "authors": "Albrecht Schmidt", "title": "An Array Algebra", "comments": "Five pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a proposal of an algebra which aims at distributed array processing.\nThe focus lies on re-arranging and distributing array data, which may be\nmulti-dimensional. The context of the work is scientific processing; thus, the\ncore science operations are assumed to be taken care of in external libraries\nor languages. A main design driver is the desire to carry over some of the\nstrategies of the relational algebra into the array domain.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2008 23:14:00 GMT"}], "update_date": "2008-12-31", "authors_parsed": [["Schmidt", "Albrecht", ""]]}]