[{"id": "1001.1276", "submitter": "Claude Duvallet", "authors": "Nizar Idoudi (LITIS), Nada louati (LITIS), Claude Duvallet (LITIS),\n  Bruno Sadeg (LITIS), Rafik Bouaziz (LITIS), Faiez Gargouri (LITIS)", "title": "A framework to model real-time databases", "comments": null, "journal-ref": "International Journal of Computing and Information Sciences\n  (IJCIS) 6, 1 (2008) On line", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time databases deal with time-constrained data and time-constrained\ntransactions. The design of this kind of databases requires the introduction of\nnew concepts to support both data structures and the dynamic behaviour of the\ndatabase. In this paper, we give an overview about different aspects of\nreal-time databases and we clarify requirements of their modelling. Then, we\npresent a framework for real-time database design and describe its fundamental\noperations. A case study demonstrates the validity of the structural model and\nillustrates SQL queries and Java code generated from the classes of the model\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2010 13:53:15 GMT"}], "update_date": "2010-02-25", "authors_parsed": [["Idoudi", "Nizar", "", "LITIS"], ["louati", "Nada", "", "LITIS"], ["Duvallet", "Claude", "", "LITIS"], ["Sadeg", "Bruno", "", "LITIS"], ["Bouaziz", "Rafik", "", "LITIS"], ["Gargouri", "Faiez", "", "LITIS"]]}, {"id": "1001.1454", "submitter": "Mugurel Ionut Andreica", "authors": "Madalina Ecaterina Andreica, Mugurel Ionut Andreica, Nicolae Cataniciu", "title": "Multidimensional Data Structures and Techniques for Efficient Decision\n  Making", "comments": null, "journal-ref": "Proc. of the 10th WSEAS Intl. Conf. on Mathematics and Computers\n  in Business and Economics (MCBE), pp. 249-254, Prague, Czech Republic, 23-25\n  March, 2009. (ISBN: 978-960-474-063-5 / ISSN: 1790-5109)", "doi": null, "report-no": null, "categories": "cs.CG cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present several novel efficient techniques and\nmultidimensional data structures which can improve the decision making process\nin many domains. We consider online range aggregation, range selection and\nrange weighted median queries; for most of them, the presented data structures\nand techniques can provide answers in polylogarithmic time. The presented\nresults have applications in many business and economic scenarios, some of\nwhich are described in detail in the paper.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2010 22:04:02 GMT"}], "update_date": "2010-01-12", "authors_parsed": [["Andreica", "Madalina Ecaterina", ""], ["Andreica", "Mugurel Ionut", ""], ["Cataniciu", "Nicolae", ""]]}, {"id": "1001.1991", "submitter": "Rdv Ijcsis", "authors": "M. Anandhavalli, M. K. Ghose, K. Gauthaman", "title": "Mining Spatial Gene Expression Data Using Negative Association Rules", "comments": "4 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS December 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 3, pp. 117-120, December 2009, USA", "doi": null, "report-no": "Volume 6, No. 3, ISSN 1947 5500", "categories": "cs.DB cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, data mining has attracted most of the attention from the\nresearch community. The researchers attempt to develop faster, more scalable\nalgorithms to navigate over the ever increasing volumes of spatial gene\nexpression data in search of meaningful patterns. Association rules are a data\nmining technique that tries to identify intrinsic patterns in spatial gene\nexpression data. It has been widely used in different applications, a lot of\nalgorithms introduced to discover these rules. However Priori like algorithms\nhas been used to find positive association rules. In contrast to positive\nrules, negative rules encapsulate relationship between the occurrences of one\nset of items with absence of the other set of items. In this paper, an\nalgorithm for mining negative association rules from spatial gene expression\ndata is introduced. The algorithm intends to discover the negative association\nrules which are complementary to the association rules often generated by\nPriori like algorithm. Our study shows that negative association rules can be\ndiscovered efficiently from spatial gene expression data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 19:39:41 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Anandhavalli", "M.", ""], ["Ghose", "M. K.", ""], ["Gauthaman", "K.", ""]]}, {"id": "1001.2186", "submitter": "Tao Zhou", "authors": "Luo-Luo Jiang, Matus Medo, Joseph R. Wakeling, Yi-Cheng Zhang, Tao\n  Zhou", "title": "Building reputation systems for better ranking", "comments": "5 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to rank web pages, scientists and online resources has recently attracted\nincreasing attention from both physicists and computer scientists. In this\npaper, we study the ranking problem of rating systems where users vote objects\nby discrete ratings. We propose an algorithm that can simultaneously evaluate\nthe user reputation and object quality in an iterative refinement way.\nAccording to both the artificially generated data and the real data from\nMovieLens and Amazon, our algorithm can considerably enhance the ranking\naccuracy. This work highlights the significance of reputation systems in the\nInternet era and points out a way to evaluate and compare the performances of\ndifferent reputation systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 14:48:05 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Jiang", "Luo-Luo", ""], ["Medo", "Matus", ""], ["Wakeling", "Joseph R.", ""], ["Zhang", "Yi-Cheng", ""], ["Zhou", "Tao", ""]]}, {"id": "1001.2270", "submitter": "Rdv Ijcsis", "authors": "Rajesh Kumar Boora, Ruchi Shukla, A. K. Misra", "title": "An Improved Approach to High Level Privacy Preserving Itemset Mining", "comments": "8 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS December 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 3, pp. 216-223, December 2009, USA", "doi": null, "report-no": "Volume 6, No. 3, ISSN 1947 5500", "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving association rule mining has triggered the development of\nmany privacy preserving data mining techniques. A large fraction of them use\nrandomized data distortion techniques to mask the data for preserving. This\npaper proposes a new transaction randomization method which is a combination of\nthe fake transaction randomization method and a new per transaction\nrandomization method. This method distorts the items within each transaction\nand ensures a higher level of data privacy in comparison to the previous\napproaches. The pertransaction randomization method involves a randomization\nfunction to replace the item by a random number guarantying privacy within the\ntransaction also. A tool has also been developed to implement the proposed\napproach to mine frequent itemsets and association rules from the data\nguaranteeing the antimonotonic property.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 19:08:49 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Boora", "Rajesh Kumar", ""], ["Shukla", "Ruchi", ""], ["Misra", "A. K.", ""]]}, {"id": "1001.2275", "submitter": "Rdv Ijcsis", "authors": "Mohammad Nadimi Shahraki, Norwati Mustapha, Md Nasir B Sulaiman, Ali B\n  Mamat", "title": "Efficient Candidacy Reduction For Frequent Pattern Mining", "comments": "8 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS December 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 3, pp. 230-237, December 2009, USA", "doi": null, "report-no": "Volume 6, No. 3, ISSN 1947 5500", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certainly, nowadays knowledge discovery or extracting knowledge from large\namount of data is a desirable task in competitive businesses. Data mining is a\nmain step in knowledge discovery process. Meanwhile frequent patterns play\ncentral role in data mining tasks such as clustering, classification, and\nassociation analysis. Identifying all frequent patterns is the most time\nconsuming process due to a massive number of candidate patterns. For the past\ndecade there have been an increasing number of efficient algorithms to mine the\nfrequent patterns. However reducing the number of candidate patterns and\ncomparisons for support counting are still two problems in this field which\nhave made the frequent pattern mining one of the active research themes in data\nmining. A reasonable solution is identifying a small candidate pattern set from\nwhich can generate all frequent patterns. In this paper, a method is proposed\nbased on a new candidate set called candidate head set or H which forms a small\nset of candidate patterns. The experimental results verify the accuracy of the\nproposed method and reduction of the number of candidate patterns and\ncomparisons.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 19:19:06 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Shahraki", "Mohammad Nadimi", ""], ["Mustapha", "Norwati", ""], ["Sulaiman", "Md Nasir B", ""], ["Mamat", "Ali B", ""]]}, {"id": "1001.2625", "submitter": "Arnab Bhattacharya", "authors": "Arnab Bhattacharya, Abhishek Bhowmick, Ambuj K. Singh", "title": "Finding top-k similar pairs of objects annotated with terms from an\n  ontology", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing focus on semantic searches and interpretations, an\nincreasing number of standardized vocabularies and ontologies are being\ndesigned and used to describe data. We investigate the querying of objects\ndescribed by a tree-structured ontology. Specifically, we consider the case of\nfinding the top-k best pairs of objects that have been annotated with terms\nfrom such an ontology when the object descriptions are available only at\nruntime. We consider three distance measures. The first one defines the object\ndistance as the minimum pairwise distance between the sets of terms describing\nthem, and the second one defines the distance as the average pairwise term\ndistance. The third and most useful distance measure, earth mover's distance,\nfinds the best way of matching the terms and computes the distance\ncorresponding to this best matching. We develop lower bounds that can be\naggregated progressively and utilize them to speed up the search for top-k\nobject pairs when the earth mover's distance is used. For the minimum pairwise\ndistance, we devise an algorithm that runs in O(D + Tk log k) time, where D is\nthe total information size and T is the total number of terms in the ontology.\nWe also develop a novel best-first search strategy for the average pairwise\ndistance that utilizes lower bounds generated in an ordered manner. Experiments\non real and synthetic datasets demonstrate the practicality and scalability of\nour algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 07:01:37 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2010 11:23:28 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Bhattacharya", "Arnab", ""], ["Bhowmick", "Abhishek", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "1001.2767", "submitter": "Mangesh Gupte", "authors": "Mangesh Gupte and Mukund Sundararajan", "title": "Universally Optimal Privacy Mechanisms for Minimax Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A scheme that publishes aggregate information about sensitive data must\nresolve the trade-off between utility to information consumers and privacy of\nthe database participants. Differential privacy is a well-established\ndefinition of privacy--this is a universal guarantee against all attackers,\nwhatever their side-information or intent. In this paper, we present a\nuniversal treatment of utility based on the standard minimax rule from decision\ntheory (in contrast to the utility model in, which is Bayesian). In our model,\ninformation consumers are minimax (risk-averse) agents, each possessing some\nside-information about the query, and each endowed with a loss-function which\nmodels their tolerance to inaccuracies. Further, information consumers are\nrational in the sense that they actively combine information from the mechanism\nwith their side-information in a way that minimizes their loss. Under this\nassumption of rational behavior, we show that for every fixed count query, a\ncertain geometric mechanism is universally optimal for all minimax information\nconsumers. Additionally, our solution makes it possible to release query\nresults at multiple levels of privacy in a collusion-resistant manner.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 20:56:37 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["Gupte", "Mangesh", ""], ["Sundararajan", "Mukund", ""]]}, {"id": "1001.3488", "submitter": "William Jackson", "authors": "Pratima Gautam, Neelu Khare, K. R. Pardasani", "title": "A Model for Mining Multilevel Fuzzy Association Rule in Database", "comments": null, "journal-ref": "Journal of Computing, Vol. 2, Issue 1, January 2010", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of developing models and algorithms for multilevel association\nmining pose for new challenges for mathematics and computer science. These\nproblems become more challenging, when some form of uncertainty like fuzziness\nis present in data or relationships in data. This paper proposes a multilevel\nfuzzy association rule mining models for extracting knowledge implicit in\ntransactions database with different support at each level. The proposed\nalgorithm adopts a top-down progressively deepening approach to derive large\nitemsets. This approach incorporates fuzzy boundaries instead of sharp boundary\nintervals. An example is also given to demonstrate that the proposed mining\nalgorithm can derive the multiple-level association rules under different\nsupports in a simple and effective manner.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 07:49:15 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Gautam", "Pratima", ""], ["Khare", "Neelu", ""], ["Pardasani", "K. R.", ""]]}, {"id": "1001.3494", "submitter": "William Jackson", "authors": "Mohammad-Reza Feizi-Derakhshi, Hasan Asil, Amir Asil", "title": "Proposing a New Method for Query Processing Adaption in DataBase", "comments": null, "journal-ref": "Journal of Computing, Vol. 2, Issue 1, January 2010", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multi agent system by compiling two technologies, query\nprocessing optimization and agents which contains features of personalized\nqueries and adaption with changing of requirements. This system uses a new\nalgorithm based on modeling of users' long-term requirements and also GA to\ngather users' query data. Experimented Result shows more adaption capability\nfor presented algorithm in comparison with classic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 08:02:20 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Asil", "Hasan", ""], ["Asil", "Amir", ""]]}, {"id": "1001.3498", "submitter": "William Jackson", "authors": "M.Anandhavalli, M.K.Ghose, and K.Gauthaman", "title": "Interestingness Measure for Mining Spatial Gene Expression Data using\n  Association Rule", "comments": null, "journal-ref": "Journal of Computing, Vol. 2, Issue 1, January 2010", "doi": null, "report-no": null, "categories": "cs.DB q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for interesting association rules is an important topic in\nknowledge discovery in spatial gene expression databases. The set of admissible\nrules for the selected support and confidence thresholds can easily be\nextracted by algorithms based on support and confidence, such as Apriori.\nHowever, they may produce a large number of rules, many of them are\nuninteresting. The challenge in association rule mining (ARM) essentially\nbecomes one of determining which rules are the most interesting. Association\nrule interestingness measures are used to help select and rank association rule\npatterns. Besides support and confidence, there are other interestingness\nmeasures, which include generality reliability, peculiarity, novelty,\nsurprisingness, utility, and applicability. In this paper, the application of\nthe interesting measures entropy and variance for association pattern discovery\nfrom spatial gene expression data has been studied. In this study the fast\nmining algorithm has been used which produce candidate itemsets and it spends\nless time for calculating k-supports of the itemsets with the Boolean matrix\npruned, and it scans the database only once and needs less memory space.\nExperimental results show that using entropy as the measure of interest for the\nspatial gene expression data has more diverse and interesting rules.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 08:12:52 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Anandhavalli", "M.", ""], ["Ghose", "M. K.", ""], ["Gauthaman", "K.", ""]]}, {"id": "1001.3720", "submitter": "Yi-Reun Kim", "authors": "Yi-Reun Kim, Kyu-Young Whang, and Il-Yeol Song", "title": "Page-Differential Logging: An Efficient and DBMS-independent Approach\n  for Storing Data into Flash Memory", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flash memory is widely used as the secondary storage in lightweight computing\ndevices due to its outstanding advantages over magnetic disks. Flash memory has\nmany access characteristics different from those of magnetic disks, and how to\ntake advantage of them is becoming an important research issue. There are two\nexisting approaches to storing data into flash memory: page-based and\nlog-based. The former has good performance for read operations, but poor\nperformance for write operations. In contrast, the latter has good performance\nfor write operations when updates are light, but poor performance for read\noperations. In this paper, we propose a new method of storing data, called\npage-differential logging, for flash-based storage systems that solves the\ndrawbacks of the two methods. The primary characteristics of our method are:\n(1) writing only the difference (which we define as the page-differential)\nbetween the original page in flash memory and the up-to-date page in memory;\n(2) computing and writing the page-differential only once at the time the page\nneeds to be reflected into flash memory. The former contrasts with existing\npage-based methods that write the whole page including both changed and\nunchanged parts of data or from log-based ones that keep track of the history\nof all the changes in a page. Our method allows existing disk-based DBMSs to be\nreused as flash-based DBMSs just by modifying the flash memory driver, i.e., it\nis DBMS-independent. Experimental results show that the proposed method\nimproves the I/O performance by 1.2 ~ 6.1 times over existing methods for the\nTPC-C data of approximately 1 Gbytes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 05:18:08 GMT"}], "update_date": "2010-01-22", "authors_parsed": [["Kim", "Yi-Reun", ""], ["Whang", "Kyu-Young", ""], ["Song", "Il-Yeol", ""]]}, {"id": "1001.3745", "submitter": "Mat\\'u\\v{s} Medo", "authors": "Matus Medo and Joseph Rushton Wakeling", "title": "The effect of discrete vs. continuous-valued ratings on reputation and\n  ranking systems", "comments": "6 pages, 2 figures", "journal-ref": "EPL 91, 48004, 2010", "doi": "10.1209/0295-5075/91/48004", "report-no": null, "categories": "cs.IR cs.AI cs.DB physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When users rate objects, a sophisticated algorithm that takes into account\nability or reputation may produce a fairer or more accurate aggregation of\nratings than the straightforward arithmetic average. Recently a number of\nauthors have proposed different co-determination algorithms where estimates of\nuser and object reputation are refined iteratively together, permitting\naccurate measures of both to be derived directly from the rating data. However,\nsimulations demonstrating these methods' efficacy assumed a continuum of rating\nvalues, consistent with typical physical modelling practice, whereas in most\nactual rating systems only a limited range of discrete values (such as a 5-star\nsystem) is employed. We perform a comparative test of several co-determination\nalgorithms with different scales of discrete ratings and show that this\nseemingly minor modification in fact has a significant impact on algorithms'\nperformance. Paradoxically, where rating resolution is low, increased noise in\nusers' ratings may even improve the overall performance of the system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 14:03:09 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2010 21:41:45 GMT"}, {"version": "v3", "created": "Thu, 12 Aug 2010 16:19:49 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Medo", "Matus", ""], ["Wakeling", "Joseph Rushton", ""]]}, {"id": "1001.4880", "submitter": "Benjamin Nguyen", "authors": "Benjamin Nguyen and Spyros Zoupanos", "title": "The WebContent XML Store", "comments": "Must be compiled with pdflatex", "journal-ref": "RFIA 2010 Workshop \"Sources Ouvertes et Services\"", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe the XML storage system used in the WebContent\nproject. We begin by advocating the use of an XML database in order to store\nWebContent documents, and we present two different ways of storing and querying\nthese documents : the use of a centralized XML database and the use of a P2P\nXML database.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 09:33:54 GMT"}], "update_date": "2010-01-28", "authors_parsed": [["Nguyen", "Benjamin", ""], ["Zoupanos", "Spyros", ""]]}, {"id": "1001.4892", "submitter": "Benjamin Nguyen Ph.D.", "authors": "Ivan Bedini, Benjamin Nguyen, Georges Gardarin", "title": "Janus: Automatic Ontology Builder from XSD Files", "comments": null, "journal-ref": "Proceedings of the World Wide Web Conference (WWW), Beijin, China,\n  April 2008 (Developper Track), 2008", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of a reference ontology for a large domain still remains an\nhard human task. The process is sometimes assisted by software tools that\nfacilitate the information extraction from a textual corpus. Despite of the\ngreat use of XML Schema files on the internet and especially in the B2B domain,\ntools that offer a complete semantic analysis of XML schemas are really rare.\nIn this paper we introduce Janus, a tool for automatically building a reference\nknowledge base starting from XML Schema files. Janus also provides different\nuseful views to simplify B2B application integration.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 10:38:51 GMT"}], "update_date": "2010-01-28", "authors_parsed": [["Bedini", "Ivan", ""], ["Nguyen", "Benjamin", ""], ["Gardarin", "Georges", ""]]}, {"id": "1001.4901", "submitter": "Benjamin Nguyen Ph.D.", "authors": "Ivan Bedini, Georges Gardarin, Benjamin Nguyen", "title": "Deriving Ontologies from XML Schema", "comments": null, "journal-ref": "Entrepots de Donnees et Analyse en Ligne (EDA) Conference, Invited\n  Paper, 2008", "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method and a tool for deriving a skeleton of an\nontology from XML schema files. We first recall what an is ontology and its\nrelationships with XML schemas. Next, we focus on ontology building methodology\nand associated tool requirements. Then, we introduce Janus, a tool for building\nan ontology from various XML schemas in a given domain. We summarize the main\nfeatures of Janus and illustrate its functionalities through a simple example.\nFinally, we compare our approach to other existing ontology building tools.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 10:44:26 GMT"}], "update_date": "2010-01-28", "authors_parsed": [["Bedini", "Ivan", ""], ["Gardarin", "Georges", ""], ["Nguyen", "Benjamin", ""]]}]