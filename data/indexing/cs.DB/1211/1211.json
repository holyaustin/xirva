[{"id": "1211.0176", "submitter": "Matteo Magnani", "authors": "Matteo Magnani, Danilo Montesi", "title": "Joining relations under discrete uncertainty", "comments": "database join operator, uncertain relations with discrete\n  uncertainty, algorithms and experimental evaluation (28 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and experimentally compare alternative algorithms\nto join uncertain relations. Different algorithms are based on specific\nprinciples, e.g., sorting, indexing, or building intermediate relational tables\nto apply traditional approaches. As a consequence their performance is affected\nby different features of the input data, and each algorithm is shown to be more\nefficient than the others in specific cases. In this way statistics explicitly\nrepresenting the amount and kind of uncertainty in the input uncertain\nrelations can be used to choose the most efficient algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 13:45:04 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Magnani", "Matteo", ""], ["Montesi", "Danilo", ""]]}, {"id": "1211.0224", "submitter": "Lorena Etcheverry", "authors": "Lorena Etcheverry and Alejandro A. Vaisman", "title": "Views over RDF Datasets: A State-of-the-Art and Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Views on RDF datasets have been discussed in several works, nevertheless\nthere is no consensus on their definition nor the requirements they should\nfulfill. In traditional data management systems, views have proved to be useful\nin different application scenarios such as data integration, query answering,\ndata security, and query modularization.\n  In this work we have reviewed existent work on views over RDF datasets, and\ndiscussed the application of existent view definition mechanisms to four\nscenarios in which views have proved to be useful in traditional (relational)\ndata management systems. To give a framework for the discussion we provided a\ndefinition of views over RDF datasets, an issue over which there is no\nconsensus so far. We finally chose the three proposals closer to this\ndefinition, and analyzed them with respect to four selected goals.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 17:00:27 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Etcheverry", "Lorena", ""], ["Vaisman", "Alejandro A.", ""]]}, {"id": "1211.1565", "submitter": "Michael Hausenblas", "authors": "Michael Hausenblas and Boris Villazon-Terrazas and Richard Cyganiak", "title": "Data Shapes and Data Transformations", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Nowadays, information management systems deal with data originating from\ndifferent sources including relational databases, NoSQL data stores, and Web\ndata formats, varying not only in terms of data formats, but also in the\nunderlying data model. Integrating data from heterogeneous data sources is a\ntime-consuming and error-prone engineering task; part of this process requires\nthat the data has to be transformed from its original form to other forms,\nrepeating all along the life cycle. With this report we provide a principled\noverview on the fundamental data shapes tabular, tree, and graph as well as\ntransformations between them, in order to gain a better understanding for\nperforming said transformations more efficiently and effectively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 14:54:46 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Hausenblas", "Michael", ""], ["Villazon-Terrazas", "Boris", ""], ["Cyganiak", "Richard", ""]]}, {"id": "1211.1788", "submitter": "Dipti Patil", "authors": "Dipti Patil, Dr. Vijay M. Wadhai, Mayuri Gund, Richa Biyani, Snehal\n  Andhalkar, Bhagyashree Agrawal", "title": "An Adaptive parameter free data mining approach for healthcare\n  application", "comments": "arXiv admin note: text overlap with arXiv:1105.1950 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's world, healthcare is the most important factor affecting human\nlife. Due to heavy work load it is not possible for personal healthcare. The\nproposed system acts as a preventive measure for determining whether a person\nis fit or unfit based on person's historical and real time data by applying\nclustering algorithms like K-means and D-stream. The Density-based clustering\nalgorithm i.e. the D-stream algorithm overcomes drawbacks of K-Means algorithm.\nBy calculating their performance measures we finally find out effectiveness and\nefficiency of both the algorithms. Both clustering algorithms are applied on\npatient's bio-medical historical database. To check the correctness of both the\nalgorithms, we apply them on patient's current bio-medical data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2012 08:29:50 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Patil", "Dipti", ""], ["Wadhai", "Dr. Vijay M.", ""], ["Gund", "Mayuri", ""], ["Biyani", "Richa", ""], ["Andhalkar", "Snehal", ""], ["Agrawal", "Bhagyashree", ""]]}, {"id": "1211.2041", "submitter": "Yuan Yao", "authors": "Yuan Yao, Hanghang Tong, Xifeng Yan, Feng Xu, Jian Lu", "title": "MaTrust: An Effective Multi-Aspect Trust Inference Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust is a fundamental concept in many real-world applications such as\ne-commerce and peer-to-peer networks. In these applications, users can generate\nlocal opinions about the counterparts based on direct experiences, and these\nopinions can then be aggregated to build trust among unknown users. The\nmechanism to build new trust relationships based on existing ones is referred\nto as trust inference. State-of-the-art trust inference approaches employ the\ntransitivity property of trust by propagating trust along connected users. In\nthis paper, we propose a novel trust inference model (MaTrust) by exploring an\nequally important property of trust, i.e., the multi-aspect property. MaTrust\ndirectly characterizes multiple latent factors for each trustor and trustee\nfrom the locally-generated trust relationships. Furthermore, it can naturally\nincorporate prior knowledge as specified factors. These factors in turn serve\nas the basis to infer the unseen trustworthiness scores. Experimental\nevaluations on real data sets show that the proposed MaTrust significantly\noutperforms several benchmark trust inference models in both effectiveness and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 04:46:47 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Yao", "Yuan", ""], ["Tong", "Hanghang", ""], ["Yan", "Xifeng", ""], ["Xu", "Feng", ""], ["Lu", "Jian", ""]]}, {"id": "1211.2126", "submitter": "Hela Ltifi Ms", "authors": "Hela Ltifi, Ghada Trabelsi, Mounir Ben Ayed, Adel M. Alimi", "title": "Dynamic Decision Support System Based on Bayesian Networks Application\n  to fight against the Nosocomial Infections", "comments": "8 pages, 6 figures, 43 references", "journal-ref": "International Journal of Advanced Research in Artificial\n  Intelligence (IJARAI), vol 1(1), pp. 22-29, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The improvement of medical care quality is a significant interest for the\nfuture years. The fight against nosocomial infections (NI) in the intensive\ncare units (ICU) is a good example. We will focus on a set of observations\nwhich reflect the dynamic aspect of the decision, result of the application of\na Medical Decision Support System (MDSS). This system has to make dynamic\ndecision on temporal data. We use dynamic Bayesian network (DBN) to model this\ndynamic process. It is a temporal reasoning within a real-time environment; we\nare interested in the Dynamic Decision Support Systems in healthcare domain\n(MDDSS).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 13:36:44 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Ltifi", "Hela", ""], ["Trabelsi", "Ghada", ""], ["Ayed", "Mounir Ben", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1211.2354", "submitter": "Amin Milani Fard", "authors": "Amin Milani Fard", "title": "Privacy Preserving Web Query Log Publishing: A Survey on Anonymization\n  Techniques", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Releasing Web query logs which contain valuable information for research or\nmarketing, can breach the privacy of search engine users. Therefore rendering\nquery logs to limit linking a query to an individual while preserving the data\nusefulness for analysis, is an important research problem. This survey provides\nan overview and discussion on the recent studies on this direction.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 21:43:40 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Fard", "Amin Milani", ""]]}, {"id": "1211.2367", "submitter": "Ada Wai-chee Fu", "authors": "Ada Wai-Chee Fu and Huanhuan Wu and James Cheng and Shumo Chu and\n  Raymond Chi-Wing Wong", "title": "IS-LABEL: an Independent-Set based Labeling Scheme for Point-to-Point\n  Distance Querying on Large Graphs", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing shortest path or distance between two query\nvertices in a graph, which has numerous important applications. Quite a number\nof indexes have been proposed to answer such distance queries. However, all of\nthese indexes can only process graphs of size barely up to 1 million vertices,\nwhich is rather small in view of many of the fast-growing real-world graphs\ntoday such as social networks and Web graphs. We propose an efficient index,\nwhich is a novel labeling scheme based on the independent set of a graph. We\nshow that our method can handle graphs of size three orders of magnitude larger\nthan those existing indexes.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2012 01:59:11 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Fu", "Ada Wai-Chee", ""], ["Wu", "Huanhuan", ""], ["Cheng", "James", ""], ["Chu", "Shumo", ""], ["Wong", "Raymond Chi-Wing", ""]]}, {"id": "1211.3016", "submitter": "Paolo Guagliardo", "authors": "Enrico Franconi, Paolo Guagliardo", "title": "The View Update Problem Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the view update problem in a relational setting and\npropose a framework based on the notion of determinacy under constraints.\nWithin such a framework, we characterise when a view mapping is invertible,\nestablishing that this is the case precisely when each database symbol has an\nexact rewriting in terms of the view symbols under the given constraints, and\nwe provide a general effective criterion to understand whether the changes\nintroduced by a view update can be propagated to the underlying database\nrelations in a unique and unambiguous way.\n  Afterwards, we show how determinacy under constraints can be checked, and\nrewritings effectively found, in three different relevant scenarios in the\nabsence of view constraints. First, we settle the long-standing open issue of\nhow to solve the view update problem in a multi-relational database with views\nthat are projections of joins of relations, and we do so in a more general\nsetting where views are defined by arbitrary conjunctive queries and database\nconstraints are stratified embedded dependencies. Next, we study a setting\nbased on horizontal decompositions of a single database relation, where views\nare defined by selections on possibly interpreted attributes (e.g., arithmetic\ncomparisons) in the presence of domain constraints over the database schema.\nLastly, we look into another multi-relational database setting, where views are\ndefined in an expressive \"Type\" Relational Algebra based on the n-ary\nDescription Logic DLR and database constraints are inclusions of expressions in\nthat algebra.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 15:07:48 GMT"}], "update_date": "2012-11-14", "authors_parsed": [["Franconi", "Enrico", ""], ["Guagliardo", "Paolo", ""]]}, {"id": "1211.3375", "submitter": "Stephan Seufert", "authors": "Stephan Seufert, Avishek Anand, Srikanta Bedathur, Gerhard Weikum", "title": "High-Performance Reachability Query Processing under Index Size\n  Restrictions", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a scalable and highly efficient index structure for\nthe reachability problem over graphs. We build on the well-known node interval\nlabeling scheme where the set of vertices reachable from a particular node is\ncompactly encoded as a collection of node identifier ranges. We impose an\nexplicit bound on the size of the index and flexibly assign approximate\nreachability ranges to nodes of the graph such that the number of index probes\nto answer a query is minimized. The resulting tunable index structure generates\na better range labeling if the space budget is increased, thus providing a\ndirect control over the trade off between index size and the query processing\nperformance. By using a fast recursive querying method in conjunction with our\nindex structure, we show that in practice, reachability queries can be answered\nin the order of microseconds on an off-the-shelf computer - even for the case\nof massive-scale real world graphs. Our claims are supported by an extensive\nset of experimental results using a multitude of benchmark and real-world\nweb-scale graph datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2012 18:28:28 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2012 16:06:19 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2012 14:13:28 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2012 09:40:31 GMT"}, {"version": "v5", "created": "Thu, 29 Nov 2012 21:28:22 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Seufert", "Stephan", ""], ["Anand", "Avishek", ""], ["Bedathur", "Srikanta", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1211.3871", "submitter": "Neelamadhab Padhy Padhy", "authors": "Neelamadhab Padhy, Rasmita Panigrahi", "title": "Multi Relational Data Mining Approaches: A Data Mining Technique", "comments": "10 pages, 1 Figure, 3 Tables \"Published with International Journal of\n  Computer Applications (IJCA)\"", "journal-ref": null, "doi": "10.5120/9207-3742", "report-no": null, "categories": "cs.DB", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The multi relational data mining approach has developed as an alternative way\nfor handling the structured data such that RDBMS. This will provides the mining\nin multiple tables directly. In MRDM the patterns are available in multiple\ntables (relations) from a relational database. As the data are available over\nthe many tables which will affect the many problems in the practice of the data\nmining. To deal with this problem, one either constructs a single table by\nPropositionalisation, or uses a Multi-Relational Data Mining algorithm. MRDM\napproaches have been successfully applied in the area of bioinformatics. Three\npopular pattern finding techniques classification, clustering and association\nare frequently used in MRDM. Multi relational approach has developed as an\nalternative for analyzing the structured data such as relational database. MRDM\nallowing applying directly in the data mining in multiple tables. To avoid the\nexpensive joining operations and semantic losses we used the MRDM technique.\nThis paper focuses some of the application areas of MRDM and feature directions\nas well as the comparison of ILP, GM, SSDM and MRDM\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 12:07:11 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Padhy", "Neelamadhab", ""], ["Panigrahi", "Rasmita", ""]]}, {"id": "1211.4371", "submitter": "Osama Sheta El-Sayed", "authors": "Osama El-Sayed Sheta and Ahmed Nour Eldeen", "title": "Building a health care data warehouse for cancer diseases", "comments": "8 pages,4 figures", "journal-ref": null, "doi": "10.5121/ijdms.2012.4503", "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents architecture for health care data warehouse specific to\ncancer diseases which could be used by executive managers, doctors, physicians\nand other health professionals to support the healthcare process. The data\ntoday existing in multi-sources with different formats makes it necessary to\nhave some techniques for data integration. Executive managers need access to\nInformation so that decision makers can react in real time to changing needs.\nInformation is one of the most factors to an organization success that\nexecutive managers or physicians would need to base their decisions on, during\ndecision making. A health care data warehouse is therefore necessary to\nintegrate the different data sources into a central data repository and\nanalysis this data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 11:50:32 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Sheta", "Osama El-Sayed", ""], ["Eldeen", "Ahmed Nour", ""]]}, {"id": "1211.4414", "submitter": "Raluca Diaconu", "authors": "Joaqu\\'in Keller, Raluca Diaconu (LIP6), Mathieu Valero (LIP6, INRIA\n  Rocquencourt)", "title": "Towards a Scalable Dynamic Spatial Database System", "comments": "(2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of GPS-enabled smartphones and other similar mobile devices,\nmassive amounts of location data are available. However, no scalable solutions\nfor soft real-time spatial queries on large sets of moving objects have yet\nemerged. In this paper we explore and measure the limits of actual algorithms\nand implementations regarding different application scenarios. And finally we\npropose a novel distributed architecture to solve the scalability issues.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 13:43:39 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Keller", "Joaqu\u00edn", "", "LIP6"], ["Diaconu", "Raluca", "", "LIP6"], ["Valero", "Mathieu", "", "LIP6, INRIA\n  Rocquencourt"]]}, {"id": "1211.4521", "submitter": "Tyler Clemons Mr", "authors": "Tyler Clemons, S. M. Faisal, Shirish Tatikonda, Charu Aggarawl, and\n  Srinivasan Parthasarathy", "title": "Hash in a Flash: Hash Tables for Solid State Devices", "comments": "16 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, information retrieval algorithms have taken center stage for\nextracting important data in ever larger datasets. Advances in hardware\ntechnology have lead to the increasingly wide spread use of flash storage\ndevices. Such devices have clear benefits over traditional hard drives in terms\nof latency of access, bandwidth and random access capabilities particularly\nwhen reading data. There are however some interesting trade-offs to consider\nwhen leveraging the advanced features of such devices. On a relative scale\nwriting to such devices can be expensive. This is because typical flash devices\n(NAND technology) are updated in blocks. A minor update to a given block\nrequires the entire block to be erased, followed by a re-writing of the block.\nOn the other hand, sequential writes can be two orders of magnitude faster than\nrandom writes. In addition, random writes are degrading to the life of the\nflash drive, since each block can support only a limited number of erasures.\nTF-IDF can be implemented using a counting hash table. In general, hash tables\nare a particularly challenging case for the flash drive because this data\nstructure is inherently dependent upon the randomness of the hash function, as\nopposed to the spatial locality of the data. This makes it difficult to avoid\nthe random writes incurred during the construction of the counting hash table\nfor TF-IDF. In this paper, we will study the design landscape for the\ndevelopment of a hash table for flash storage devices. We demonstrate how to\neffectively design a hash table with two related hash functions, one of which\nexhibits a data placement property with respect to the other. Specifically, we\nfocus on three designs based on this general philosophy and evaluate the\ntrade-offs among them along the axes of query performance, insert and update\ntimes and I/O time through an implementation of the TF-IDF algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 17:55:01 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Clemons", "Tyler", ""], ["Faisal", "S. M.", ""], ["Tatikonda", "Shirish", ""], ["Aggarawl", "Charu", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1211.4866", "submitter": "Suprativ Saha", "authors": "Suprativ Saha and Rituparna Chaki", "title": "A Brief Review of Data Mining Application Involving Protein Sequence\n  Classification", "comments": "10 pages, 1 table, 1 figure. arXiv admin note: substantial text\n  overlap with arXiv:1211.4654", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining techniques have been used by researchers for analyzing protein\nsequences. In protein analysis, especially in protein sequence classification,\nselection of feature is most important. Popular protein sequence classification\ntechniques involve extraction of specific features from the sequences.\nResearchers apply some well-known classification techniques like neural\nnetworks, Genetic algorithm, Fuzzy ARTMAP, Rough Set Classifier etc for\naccurate classification. This paper presents a review is with three different\nclassification models such as neural network model, fuzzy ARTMAP model and\nRough set classifier model. A new technique for classifying protein sequences\nhave been proposed in the end. The proposed technique tries to reduce the\ncomputational overheads encountered by earlier approaches and increase the\naccuracy of classification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 03:08:19 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Saha", "Suprativ", ""], ["Chaki", "Rituparna", ""]]}, {"id": "1211.5009", "submitter": "Seyed-Mehdi-Reza Beheshti", "authors": "Seyed-Mehdi-Reza Beheshti, Hamid Reza Motahari-Nezhad, Boualem\n  Benatallah", "title": "Temporal Provenance Model (TPM): Model and Query Language", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": "UNSW-CSE-TR-1116", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provenance refers to the documentation of an object's lifecycle. This\ndocumentation (often represented as a graph) should include all the information\nnecessary to reproduce a certain piece of data or the process that led to it.\nIn a dynamic world, as data changes, it is important to be able to get a piece\nof data as it was, and its provenance graph, at a certain point in time.\nSupporting time-aware provenance querying is challenging and requires: (i)\nexplicitly representing the time information in the provenance graphs, and (ii)\nproviding abstractions and efficient mechanisms for time-aware querying of\nprovenance graphs over an ever growing volume of data. The existing provenance\nmodels treat time as a second class citizen (i.e. as an optional annotation).\nThis makes time-aware querying of provenance data inefficient and sometimes\ninaccessible. We introduce an extended provenance graph model to explicitly\nrepresent time as an additional dimension of provenance data. We also provide a\nquery language, novel abstractions and efficient mechanisms to query and\nanalyze timed provenance graphs. The main contributions of the paper include:\n(i) proposing a Temporal Provenance Model (TPM) as a timed provenance model;\nand (ii) introducing two concepts of timed folder, as a container of related\nset of objects and their provenance relationship over time, and timed paths, to\nrepresent the evolution of objects tracing information over time, for analyzing\nand querying TPM graphs. We have implemented the approach on top of FPSPARQL, a\nquery engine for large graphs, and have evaluated for querying TPM models. The\nevaluation shows the viability and efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 11:58:47 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Beheshti", "Seyed-Mehdi-Reza", ""], ["Motahari-Nezhad", "Hamid Reza", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1211.5084", "submitter": "Haitao Wang", "authors": "Haitao Wang and Wuzhou Zhang", "title": "On Top-$k$ Weighted SUM Aggregate Nearest and Farthest Neighbors in the\n  $L_1$ Plane", "comments": "24 pages; this version extends our results in the previous version to\n  more general problem settings, and the title has been changed accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study top-$k$ aggregate (or group) nearest neighbor queries\nusing the weighted SUM operator under the $L_1$ metric in the plane. Given a\nset $P$ of $n$ points, for any query consisting of a set $Q$ of $m$ weighted\npoints and an integer $k$, $ 1 \\le k \\le n$, the top-$k$ aggregate nearest\nneighbor query asks for the $k$ points of $P$ whose aggregate distances to $Q$\nare the smallest, where the aggregate distance of each point $p$ of $P$ to $Q$\nis the sum of the weighted distances from $p$ to all points of $Q$. We build an\n$O(n\\log n\\log\\log n)$-size data structure in $O(n\\log n \\log\\log n)$ time,\nsuch that each top-$k$ query can be answered in $O(m\\log m+(k+m)\\log^2 n)$\ntime. We also obtain other results with trade-off between preprocessing and\nquery. Even for the special case where $k=1$, our results are better than the\npreviously best method (in PODS 2012), which requires $O(n\\log^2 n)$\npreprocessing time, $O(n\\log^2 n)$ space, and $O(m^2\\log^3 n)$ query time. In\naddition, for the one-dimensional version of this problem, our approach can\nbuild an $O(n)$-size data structure in $O(n\\log n)$ time that can support\n$O(\\min\\{k,\\log m\\}\\cdot m+k+\\log n)$ time queries. Further, we extend our\ntechniques to the top-$k$ aggregate farthest neighbor queries, with the same\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 16:48:06 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 22:08:51 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2013 05:48:46 GMT"}, {"version": "v4", "created": "Sun, 18 Aug 2013 17:31:38 GMT"}, {"version": "v5", "created": "Sat, 29 Nov 2014 00:40:32 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Wang", "Haitao", ""], ["Zhang", "Wuzhou", ""]]}, {"id": "1211.5418", "submitter": "Roselin Selvarani", "authors": "D. Roselin Selvarani and T. N. Ravi", "title": "A survey on data and transaction management in mobile databases", "comments": "20 Pages; International Journal of Database Management Systems\n  (IJDMS) Vol.4, No.5, October 2012. arXiv admin note: text overlap with\n  arXiv:0908.0076, arXiv:1005.1747, arXiv:1108.6195 by other authors", "journal-ref": null, "doi": "10.5121/ijdms.2012.4501", "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of the Mobile Database is increasing day by day as people need\ninformation even on the move in the fast changing world. This database\ntechnology permits employees using mobile devices to connect to their corporate\nnetworks, hoard the needed data, work in the disconnected mode and reconnect to\nthe network to synchronize with the corporate database. In this scenario, the\ndata is being moved closer to the applications in order to improve the\nperformance and autonomy. This leads to many interesting problems in mobile\ndatabase research and Mobile Database has become a fertile land for many\nresearchers. In this paper a survey is presented on data and Transaction\nmanagement in Mobile Databases from the year 2000 onwards. The survey focuses\non the complete study on the various types of Architectures used in Mobile\ndatabases and Mobile Transaction Models. It also addresses the data management\nissues namely Replication and Caching strategies and the transaction management\nfunctionalities such as Concurrency Control and Commit protocols,\nSynchronization, Query Processing, Recovery and Security. It also provides\nResearch Directions in Mobile databases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 06:29:45 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Selvarani", "D. Roselin", ""], ["Ravi", "T. N.", ""]]}, {"id": "1211.5629", "submitter": "Wook-Sung Yoo", "authors": "Wook-Sung Yoo", "title": "Prototype for Extended XDB Using Wiki", "comments": "8 pages", "journal-ref": "International Journal of Database Management Systems (IJDMS)\n  Vol.4, No.5, October 2012", "doi": null, "report-no": null, "categories": "cs.DB cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a prototype of extended XDB. XDB is an open-source and\nextensible database architecture developed by National Aeronautics and Space\nAdministration (NASA) to provide integration of heterogeneous and distributed\ninformation resources for scientific and engineering applications. XDB enables\nan unlimited number of desktops and distributed information sources to be\nlinked seamlessly and efficiently into an information grid using Data Access\nand Retrieval Composition (DARC) protocol which provides a contextual search\nand retrieval capability useful for lightweight web applications. This paper\nshows the usage of XDB on common data management in the enterprise without\nburdening users and application developers with unnecessary complexity and\nformal schemas. Supported by NASA Ames Research Center through NASA Exploration\nSystem Mission Directorate (ESMD) Higher Education grant, a project team at\nFairfield University extended this concept and developed an extended XDB\nprotocol and a prototype providing text-searches for Wiki. The technical\nspecification of the protocol was posted to Source Forge (sourceforge.net) and\na prototype providing text-searches for Wiki was developed. The prototype was\ncreated for 16 tags of the MediaWiki dialect. As part of future works, the\nprototype will be further extended to the complete Wiki markups and other\ndialects of Wiki.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 00:58:19 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Yoo", "Wook-Sung", ""]]}, {"id": "1211.5723", "submitter": "Neelamadhab Padhy Padhy", "authors": "Neelamadhab Padhy, Dr. Pragnyaban Mishra, and Rasmita Panigrahi", "title": "The Survey of Data Mining Applications And Feature Scope", "comments": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol.2, No.3, June 2012, 16 pages, 1 table", "journal-ref": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol.2, No.3,page no-43 June 2012 ,DOI :\n  10.5121/ijcseit.2012.2303", "doi": "10.5121/ijcseit.2012.2303", "report-no": null, "categories": "cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we have focused a variety of techniques, approaches and\ndifferent areas of the research which are helpful and marked as the important\nfield of data mining Technologies. As we are aware that many Multinational\ncompanies and large organizations are operated in different places of the\ndifferent countries.Each place of operation may generate large volumes of data.\nCorporate decision makers require access from all such sources and take\nstrategic decisions.The data warehouse is used in the significant business\nvalue by improving the effectiveness of managerial decision-making. In an\nuncertain and highly competitive business environment, the value of strategic\ninformation systems such as these are easily recognized however in todays\nbusiness environment,efficiency or speed is not the only key for\ncompetitiveness.This type of huge amount of data are available in the form of\ntera-topeta-bytes which has drastically changed in the areas of science and\nengineering.To analyze,manage and make a decision of such type of huge amount\nof data we need techniques called the data mining which will transforming in\nmany fields.This paper imparts more number of applications of the data mining\nand also focuses scope of the data mining which will helpful in the further\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 04:08:07 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Padhy", "Neelamadhab", ""], ["Mishra", "Dr. Pragnyaban", ""], ["Panigrahi", "Rasmita", ""]]}, {"id": "1211.5724", "submitter": "Neelamadhab Padhy Padhy", "authors": "Neelamadhab Padhy and Rasmita Panigrahi", "title": "Data Mining: A prediction Technique for the workers in the PR Department\n  of Orissa (Block and Panchayat)", "comments": "2tables,3 diagrams, volume-2, Number-5,in the month of November2012", "journal-ref": null, "doi": "10.5121/ijcseit.2012.2503", "report-no": null, "categories": "cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents the method of mining the data and which contains the\ninformation about the large information about the PR (Panchayat Raj\nDepartment)of Orissa.We have focused some of the techniques,approaches and\ndifferent methodologies of the demand forecasting. Every organizations are\noperated in different places of the country. Each place of operation may\ngenerate a huge amount of data. In an organization, worker prediction is the\ndifficult task of the manager. It is the complex process not only because its\nnature of feature prediction but also various approaches methodologies always\nmakes user confused. This paper aims to deal with the problem selection\nprocess. In this paper we have used some of the approaches from literature are\nbeen introduced and analyzed to find its suitable organization and situation.\nBased on this we have designed with automatic selection function to help users\nmake a prejudgment. This information about each approach will be showed to\nusers with examples to help understanding. This system also provides\ncalculation function to help users work out a predication result. Generally the\nnew developed system has a more comprehensive functions compared with existing\nones. It aims to improve the accuracy of demand forecasting by implementing the\nforecasting algorithm. While it is still a decision support system with no\nability of make the final judgment.This type of huge amount of data are are\navailable in the form of different ways which has drastically changed in the\nareas of science and engineering.To analyze, manage and make a decision of such\ntype of huge amount of data we need techniques called the data mining which\nwill transforming in many fields. We have implemented the algorithms in JAVA\ntechnology. This paper provides the prediction algorithm Linear Regression,\nresult which will helpful in the further research.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 04:24:02 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Padhy", "Neelamadhab", ""], ["Panigrahi", "Rasmita", ""]]}, {"id": "1211.5817", "submitter": "Seyed-Mehdi-Reza Beheshti", "authors": "Seyed-Mehdi-Reza Beheshti, Sherif Sakr, Boualem Benatallah, Hamid Reza\n  Motahari-Nezhad", "title": "Extending SPARQL to Support Entity Grouping and Path Queries", "comments": "23 pages. arXiv admin note: text overlap with arXiv:1211.5009", "journal-ref": null, "doi": null, "report-no": "UNSW-CSE-TR-1019", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to efficiently find relevant subgraphs and paths in a large graph\nto a given query is important in many applications including scientific data\nanalysis, social networks, and business intelligence. Currently, there is\nlittle support and no efficient approaches for expressing and executing such\nqueries. This paper proposes a data model and a query language to address this\nproblem. The contributions include supporting the construction and selection\nof: (i) folder nodes, representing a set of related entities, and (ii) path\nnodes, representing a set of paths in which a path is the transitive\nrelationship of two or more entities in the graph. Folders and paths can be\nstored and used for future queries. We introduce FPSPARQL which is an extension\nof the SPARQL supporting folder and path nodes. We have implemented a query\nengine that supports FPSPARQL and the evaluation results shows its viability\nand efficiency for querying large graph datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 10:55:36 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Beheshti", "Seyed-Mehdi-Reza", ""], ["Sakr", "Sherif", ""], ["Benatallah", "Boualem", ""], ["Motahari-Nezhad", "Hamid Reza", ""]]}, {"id": "1211.6176", "submitter": "Reynold Xin", "authors": "Reynold Xin, Josh Rosen, Matei Zaharia, Michael J. Franklin, Scott\n  Shenker, Ion Stoica", "title": "Shark: SQL and Rich Analytics at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCB/EECS-2012-214", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shark is a new data analysis system that marries query processing with\ncomplex analytics on large clusters. It leverages a novel distributed memory\nabstraction to provide a unified engine that can run SQL queries and\nsophisticated analytics functions (e.g., iterative machine learning) at scale,\nand efficiently recovers from failures mid-query. This allows Shark to run SQL\nqueries up to 100x faster than Apache Hive, and machine learning programs up to\n100x faster than Hadoop. Unlike previous systems, Shark shows that it is\npossible to achieve these speedups while retaining a MapReduce-like execution\nengine, and the fine-grained fault tolerance properties that such engines\nprovide. It extends such an engine in several ways, including column-oriented\nin-memory storage and dynamic mid-query replanning, to effectively execute SQL.\nThe result is a system that matches the speedups reported for MPP analytic\ndatabases over MapReduce, while offering fault tolerance properties and complex\nanalytics capabilities that they lack.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 01:36:58 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Xin", "Reynold", ""], ["Rosen", "Josh", ""], ["Zaharia", "Matei", ""], ["Franklin", "Michael J.", ""], ["Shenker", "Scott", ""], ["Stoica", "Ion", ""]]}, {"id": "1211.6273", "submitter": "Hadi Saboohi", "authors": "Amineh Amini, Hadi Saboohi, and Nasser Nemat bakhsh", "title": "A RDF-based Data Integration Framework", "comments": "National Electrical Engineering Conference (NEEC) 2008, Najafabad,\n  Iran, March 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration is one of the main problems in distributed data sources. An\napproach is to provide an integrated mediated schema for various data sources.\nThis research work aims at developing a framework for defining an integrated\nschema and querying on it. The basic idea is to employ recent standard\nlanguages and tools to provide a unified data integration framework. RDF is\nused for integrated schema descriptions as well as providing a unified view of\ndata. RDQL is used for query reformulation. Furthermore, description logic\ninference services provide necessary means for satisfiability checking of\nconcepts in integrated schema. The framework has tools to display integrated\nschema, query on it, and provides enough flexibilities to be used in different\napplication domains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 11:17:09 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Amini", "Amineh", ""], ["Saboohi", "Hadi", ""], ["bakhsh", "Nasser Nemat", ""]]}, {"id": "1211.6664", "submitter": "Fabien Campagne", "authors": "Fabien Campagne, Kevin C. Dorff, Nyasha Chambwe, James T. Robinson,\n  Jill P. Mesirov and Thomas D. Wu", "title": "Compression of structured high-throughput sequencing data", "comments": "main article: 2 figures, 2 tables. Supplementary material: 2 figures,\n  4 tables. Comment on this manuscript on Twitter or Google Plus using handle\n  #Goby2Paper", "journal-ref": null, "doi": "10.1371/journal.pone.0079871", "report-no": null, "categories": "q-bio.QM cs.DB q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large biological datasets are being produced at a rapid pace and create\nsubstantial storage challenges, particularly in the domain of high-throughput\nsequencing (HTS). Most approaches currently used to store HTS data are either\nunable to quickly adapt to the requirements of new sequencing or analysis\nmethods (because they do not support schema evolution), or fail to provide\nstate of the art compression of the datasets. We have devised new approaches to\nstore HTS data that support seamless data schema evolution and compress\ndatasets substantially better than existing approaches. Building on these new\napproaches, we discuss and demonstrate how a multi-tier data organization can\ndramatically reduce the storage, computational and network burden of\ncollecting, analyzing, and archiving large sequencing datasets. For instance,\nwe show that spliced RNA-Seq alignments can be stored in less than 4% the size\nof a BAM file with perfect data fidelity. Compared to the previous compression\nstate of the art, these methods reduce dataset size more than 20% when storing\ngene expression and epigenetic datasets. The approaches have been integrated in\na comprehensive suite of software tools (http://goby.campagnelab.org) that\nsupport common analyses for a range of high-throughput sequencing assays.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 17:11:54 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Campagne", "Fabien", ""], ["Dorff", "Kevin C.", ""], ["Chambwe", "Nyasha", ""], ["Robinson", "James T.", ""], ["Mesirov", "Jill P.", ""], ["Wu", "Thomas D.", ""]]}, {"id": "1211.7302", "submitter": "Aaron Roth", "authors": "Zhiyi Huang and Aaron Roth", "title": "Exploiting Metric Structure for Efficient Private Query Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of privately answering queries defined on databases\nwhich are collections of points belonging to some metric space. We give simple,\ncomputationally efficient algorithms for answering distance queries defined\nover an arbitrary metric. Distance queries are specified by points in the\nmetric space, and ask for the average distance from the query point to the\npoints contained in the database, according to the specified metric. Our\nalgorithms run efficiently in the database size and the dimension of the space,\nand operate in both the online query release setting, and the offline setting\nin which they must in polynomial time generate a fixed data structure which can\nanswer all queries of interest. This represents one of the first subclasses of\nlinear queries for which efficient algorithms are known for the private query\nrelease problem, circumventing known hardness results for generic linear\nqueries.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 16:28:46 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Huang", "Zhiyi", ""], ["Roth", "Aaron", ""]]}]