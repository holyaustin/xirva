[{"id": "1107.1104", "submitter": "Samur Araujo", "authors": "Samur Araujo, Jan Hidders, Daniel Schwabe and Arjen P. de Vries", "title": "SERIMI - Resource Description Similarity, RDF Instance Matching and\n  Interlinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interlinking of datasets published in the Linked Data Cloud is a\nchallenging problem and a key factor for the success of the Semantic Web.\nManual rule-based methods are the most effective solution for the problem, but\nthey require skilled human data publishers going through a laborious, error\nprone and time-consuming process for manually describing rules mapping\ninstances between two datasets. Thus, an automatic approach for solving this\nproblem is more than welcome. In this paper, we propose a novel interlinking\nmethod, SERIMI, for solving this problem automatically. SERIMI matches\ninstances between a source and a target datasets, without prior knowledge of\nthe data, domain or schema of these datasets. Experiments conducted with\nbenchmark collections demonstrate that our approach considerably outperforms\nstate-of-the-art automatic approaches for solving the interlinking problem on\nthe Linked Data Cloud.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2011 11:56:34 GMT"}], "update_date": "2011-07-07", "authors_parsed": [["Araujo", "Samur", ""], ["Hidders", "Jan", ""], ["Schwabe", "Daniel", ""], ["de Vries", "Arjen P.", ""]]}, {"id": "1107.1456", "submitter": "Andre Hernich", "authors": "Andre Hernich (Humboldt-Universit\\\"at zu Berlin)", "title": "Answering Non-Monotonic Queries in Relational Data Exchange", "comments": "55 pages, 3 figures", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  1, 2011) lmcs:904", "doi": "10.2168/LMCS-7(3:9)2011", "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data exchange is the problem of translating relational data from a\nsource schema into a target schema, according to a specification of the\nrelationship between the source data and the target data. One of the basic\nissues is how to answer queries that are posed against target data. While\nconsensus has been reached on the definitive semantics for monotonic queries,\nthis issue turned out to be considerably more difficult for non-monotonic\nqueries. Several semantics for non-monotonic queries have been proposed in the\npast few years. This article proposes a new semantics for non-monotonic\nqueries, called the GCWA*-semantics. It is inspired by semantics from the area\nof deductive databases. We show that the GCWA*-semantics coincides with the\nstandard open world semantics on monotonic queries, and we further explore the\n(data) complexity of evaluating non-monotonic queries under the\nGCWA*-semantics. In particular, we introduce a class of schema mappings for\nwhich universal queries can be evaluated under the GCWA*-semantics in\npolynomial time (data complexity) on the core of the universal solutions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 17:08:44 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2011 09:14:51 GMT"}, {"version": "v3", "created": "Thu, 1 Sep 2011 07:37:48 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hernich", "Andre", "", "Humboldt-Universit\u00e4t zu Berlin"]]}, {"id": "1107.1779", "submitter": "Eya Ben Ahmed", "authors": "Eya Ben Ahmed, Ahlem Nabli, Fa\\\"iez Gargouri", "title": "A Survey of User-Centric Data Warehouses: From Personalization to\n  Recommendation", "comments": "13 pages, 3 figures, 1 table", "journal-ref": "The International Journal of Database Management Systems (IJDMS),\n  May 2011, Volume 3, Number 2", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Providing a customized support for the OLAP brings tremendous challenges to\nthe OLAP technology. Standing at the crossroads of the preferences and the data\nwarehouse, two emerging trends are pointed out; namely: (i) the personalization\nand (ii) the recommendation. Although the panoply of the proposed approaches,\nthe user-centric data warehouse community issues have not been addressed yet.\nIn this paper we draw an overview of several user centric data warehouse\nproposals. We also discuss the two promising concepts in this issue, namely,\nthe personalization and the recommendation of the data warehouses. We compare\nthe current approaches among each others with respect to some criteria.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jul 2011 12:26:14 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Ahmed", "Eya Ben", ""], ["Nabli", "Ahlem", ""], ["Gargouri", "Fa\u00efez", ""]]}, {"id": "1107.3350", "submitter": "Yang Li Daniel", "authors": "Yang D. Li, Zhenjie Zhang, Marianne Winslett, Yin Yang", "title": "Compressive Mechanism: Utilizing Sparse Representation in Differential\n  Privacy", "comments": "20 pages, 6 figures", "journal-ref": "WPES '11 Proceedings of the 10th annual ACM workshop on Privacy in\n  the electronic society ACM New York, NY, USA (2011), pages 177-182", "doi": "10.1145/2046556.2046581", "report-no": null, "categories": "cs.DS cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides the first theoretical foundation with provable\nprivacy guarantee against adversaries with arbitrary prior knowledge. The main\nidea to achieve differential privacy is to inject random noise into statistical\nquery results. Besides correctness, the most important goal in the design of a\ndifferentially private mechanism is to reduce the effect of random noise,\nensuring that the noisy results can still be useful.\n  This paper proposes the \\emph{compressive mechanism}, a novel solution on the\nbasis of state-of-the-art compression technique, called \\emph{compressive\nsensing}. Compressive sensing is a decent theoretical tool for compact synopsis\nconstruction, using random projections. In this paper, we show that the amount\nof noise is significantly reduced from $O(\\sqrt{n})$ to $O(\\log(n))$, when the\nnoise insertion procedure is carried on the synopsis samples instead of the\noriginal database. As an extension, we also apply the proposed compressive\nmechanism to solve the problem of continual release of statistical results.\nExtensive experiments using real datasets justify our accuracy claims.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2011 03:20:58 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Li", "Yang D.", ""], ["Zhang", "Zhenjie", ""], ["Winslett", "Marianne", ""], ["Yang", "Yin", ""]]}, {"id": "1107.3606", "submitter": "Hideaki Kimura", "authors": "Hideaki Kimura, Carleton Coffrin, Alexander Rasin, Stanley B. Zdonik", "title": "Optimizing Index Deployment Order for Evolving OLAP (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query workloads and database schemas in OLAP applications are becoming\nincreasingly complex. Moreover, the queries and the schemas have to continually\n\\textit{evolve} to address business requirements. During such repetitive\ntransitions, the \\textit{order} of index deployment has to be considered while\ndesigning the physical schemas such as indexes and MVs.\n  An effective index deployment ordering can produce (1) a prompt query runtime\nimprovement and (2) a reduced total deployment time. Both of these are\nessential qualities of design tools for quickly evolving databases, but\noptimizing the problem is challenging because of complex index interactions and\na factorial number of possible solutions.\n  We formulate the problem in a mathematical model and study several techniques\nfor solving the index ordering problem. We demonstrate that Constraint\nProgramming (CP) is a more flexible and efficient platform to solve the problem\nthan other methods such as mixed integer programming and A* search. In addition\nto exact search techniques, we also studied local search algorithms to find\nnear optimal solution very quickly.\n  Our empirical analysis on the TPC-H dataset shows that our pruning techniques\ncan reduce the size of the search space by tens of orders of magnitude. Using\nthe TPC-DS dataset, we verify that our local search algorithm is a highly\nscalable and stable method for quickly finding a near-optimal solution.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2011 01:52:52 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2011 00:25:35 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2012 15:46:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kimura", "Hideaki", ""], ["Coffrin", "Carleton", ""], ["Rasin", "Alexander", ""], ["Zdonik", "Stanley B.", ""]]}, {"id": "1107.3784", "submitter": "Kato Mivule", "authors": "Kato Mivule and Claude Turner", "title": "Applying Data Privacy Techniques on Tabular Data in Uganda", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of Information Technology(IT) in Africa has led to an increase in\nthe utilization of communication networks for data transaction across the\ncontinent. A growing number of entities in the private sector, academia, and\ngovernment, have deployed the Internet as a medium to transact in data,\nroutinely posting statistical and non statistical data online and thereby\nmaking many in Africa increasingly dependent on the Internet for data\ntransactions. In the country of Uganda, exponential growth in data transaction\nhas presented a new challenge: What is the most efficient way to implement data\nprivacy. This article discusses data privacy challenges faced by the country of\nUganda and implementation of data privacy techniques for published tabular\ndata. We make the case for data privacy, survey concepts of data privacy, and\nimplementations that could be employed to provide data privacy in Uganda.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2011 17:31:37 GMT"}], "update_date": "2011-07-20", "authors_parsed": [["Mivule", "Kato", ""], ["Turner", "Claude", ""]]}, {"id": "1107.4570", "submitter": "Marco Manna", "authors": "Marco Manna, Francesco Ricca and Giorgio Terracina", "title": "Consistent Query Answering via ASP from Different Perspectives: Theory\n  and Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data integration system provides transparent access to different data\nsources by suitably combining their data, and providing the user with a unified\nview of them, called global schema. However, source data are generally not\nunder the control of the data integration process, thus integrated data may\nviolate global integrity constraints even in presence of locally-consistent\ndata sources. In this scenario, it may be anyway interesting to retrieve as\nmuch consistent information as possible. The process of answering user queries\nunder global constraint violations is called consistent query answering (CQA).\nSeveral notions of CQA have been proposed, e.g., depending on whether\nintegrated information is assumed to be sound, complete, exact or a variant of\nthem. This paper provides a contribution in this setting: it uniforms solutions\ncoming from different perspectives under a common ASP-based core, and provides\nquery-driven optimizations designed for isolating and eliminating\ninefficiencies of the general approach for computing consistent answers.\nMoreover, the paper introduces some new theoretical results enriching existing\nknowledge on decidability and complexity of the considered problems. The\neffectiveness of the approach is evidenced by experimental results.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2011 16:45:21 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 14:09:50 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Manna", "Marco", ""], ["Ricca", "Francesco", ""], ["Terracina", "Giorgio", ""]]}, {"id": "1107.4924", "submitter": "Anastasios Arvanitis", "authors": "Anastasios Arvanitis, Antonios Deligiannakis", "title": "Discovering Attractive Products based on Influence Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skyline queries have been widely used as a practical tool for multi-criteria\ndecision analysis and for applications involving preference queries. For\nexample, in a typical online retail application, skyline queries can help\ncustomers select the most interesting, among a pool of available, products.\nRecently, reverse skyline queries have been proposed, highlighting the\nmanufacturer's perspective, i.e. how to determine the expected buyers of a\ngiven product. In this work we develop novel algorithms for two important\nclasses of queries involving customer preferences. We first propose a novel\nalgorithm, termed as RSA, for answering reverse skyline queries. We then\nintroduce a new type of queries, namely the k-Most Attractive Candidates k-MAC\nquery. In this type of queries, given a set of existing product specifications\nP, a set of customer preferences C and a set of new candidate products Q, the\nk-MAC query returns the set of k candidate products from Q that jointly\nmaximizes the total number of expected buyers, measured as the cardinality of\nthe union of individual reverse skyline sets (i.e., influence sets). Applying\nexisting approaches to solve this problem would require calculating the reverse\nskyline set for each candidate, which is prohibitively expensive for large data\nsets. We, thus, propose a batched algorithm for this problem and compare its\nperformance against a branch-and-bound variant that we devise. Both of these\nalgorithms use in their core variants of our RSA algorithm. Our experimental\nstudy using both synthetic and real data sets demonstrates that our proposed\nalgorithms outperform existing, or naive solutions to our studied classes of\nqueries.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 12:38:15 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Arvanitis", "Anastasios", ""], ["Deligiannakis", "Antonios", ""]]}]