[{"id": "0908.0411", "submitter": "Gerhard Mayer", "authors": "Gerhard Mayer", "title": "Data management in systems biology I - Overview and bibliography", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large systems biology projects can encompass several workgroups often located\nin different countries. An overview about existing data standards in systems\nbiology and the management, storage, exchange and integration of the generated\ndata in large distributed research projects is given, the pros and cons of the\ndifferent approaches are illustrated from a practical point of view, the\nexisting software - open source as well as commercial - and the relevant\nliterature is extensively overview, so that the reader should be enabled to\ndecide which data management approach is the best suited for his special needs.\nAn emphasis is laid on the use of workflow systems and of TAB-based formats.\nThe data in this format can be viewed and edited easily using spreadsheet\nprograms which are familiar to the working experimental biologists. The use of\nworkflows for the standardized access to data in either own or publicly\navailable databanks and the standardization of operation procedures is\npresented. The use of ontologies and semantic web technologies for data\nmanagement will be discussed in a further paper.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 08:53:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2009 08:35:53 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2009 09:09:32 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Mayer", "Gerhard", ""]]}, {"id": "0908.0464", "submitter": "S{\\l}awomir Staworko", "authors": "Slawomir Staworko, Jan Chomicki and Jerzy Marcinkowski", "title": "Prioritized Repairing and Consistent Query Answering in Relational\n  Databases", "comments": "Accepted to the special SUM'08 issue of AMAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A consistent query answer in an inconsistent database is an answer obtained\nin every (minimal) repair. The repairs are obtained by resolving all conflicts\nin all possible ways. Often, however, the user is able to provide a preference\non how conflicts should be resolved. We investigate here the framework of\npreferred consistent query answers, in which user preferences are used to\nnarrow down the set of repairs to a set of preferred repairs. We axiomatize\ndesirable properties of preferred repairs. We present three different families\nof preferred repairs and study their mutual relationships. Finally, we\ninvestigate the complexity of preferred repairing and computing preferred\nconsistent query answers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 15:10:25 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2010 13:27:17 GMT"}, {"version": "v3", "created": "Fri, 7 Oct 2011 16:45:52 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Staworko", "Slawomir", ""], ["Chomicki", "Jan", ""], ["Marcinkowski", "Jerzy", ""]]}, {"id": "0908.0567", "submitter": "Oktie Hassanzadeh", "authors": "Oktie Hassanzadeh, Anastasios Kementsietsidis, Lipyeow Lim, Renee J.\n  Miller, Min Wang", "title": "LinkedCT: A Linked Data Space for Clinical Trials", "comments": "5 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CE cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Linked Clinical Trials (LinkedCT) project aims at publishing the first\nopen semantic web data source for clinical trials data. The database exposed by\nLinkedCT is generated by (1) transforming existing data sources of clinical\ntrials into RDF, and (2) discovering semantic links between the records in the\ntrials data and several other data sources. In this paper, we discuss several\nchallenges involved in these two steps and present the methodology used in\nLinkedCT to overcome these challenges. Our approach for semantic link discovery\ninvolves using state-of-the-art approximate string matching techniques combined\nwith ontology-based semantic matching of the records, all performed in a\ndeclarative and easy-to-use framework. We present an evaluation of the\nperformance of our proposed techniques in several link discovery scenarios in\nLinkedCT.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 23:30:46 GMT"}], "update_date": "2009-08-06", "authors_parsed": [["Hassanzadeh", "Oktie", ""], ["Kementsietsidis", "Anastasios", ""], ["Lim", "Lipyeow", ""], ["Miller", "Renee J.", ""], ["Wang", "Min", ""]]}, {"id": "0908.0984", "submitter": "R Doomun", "authors": "C. Balasubramanian, K. Duraiswamy", "title": "An Application of Bayesian classification to Interval Encoded Temporal\n  mining with prioritized items", "comments": "7 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real life, media information has time attributes either implicitly or\nexplicitly known as temporal data. This paper investigates the usefulness of\napplying Bayesian classification to an interval encoded temporal database with\nprioritized items. The proposed method performs temporal mining by encoding the\ndatabase with weighted items which prioritizes the items according to their\nimportance from the user perspective. Naive Bayesian classification helps in\nmaking the resulting temporal rules more effective. The proposed priority based\ntemporal mining (PBTM) method added with classification aids in solving\nproblems in a well informed and systematic manner. The experimental results are\nobtained from the complaints database of the telecommunications system, which\nshows the feasibility of this method of classification based temporal mining.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2009 05:36:51 GMT"}], "update_date": "2009-08-10", "authors_parsed": [["Balasubramanian", "C.", ""], ["Duraiswamy", "K.", ""]]}, {"id": "0908.0994", "submitter": "R Doomun", "authors": "Dr. Durgesh Kumar Mishra, Neha Koria, Nikhil Kapoor, Ravish Bahety", "title": "A Secure Multi-Party Computation Protocol for Malicious Computation\n  Prevention for preserving privacy during Data Mining", "comments": "6 Pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Volume 3, Number 1, July 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure Multi-Party Computation (SMC) allows parties with similar background\nto compute results upon their private data, minimizing the threat of\ndisclosure. The exponential increase in sensitive data that needs to be passed\nupon networked computers and the stupendous growth of internet has precipitated\nvast opportunities for cooperative computation, where parties come together to\nfacilitate computations and draw out conclusions that are mutually beneficial;\nat the same time aspiring to keep their private data secure. These computations\nare generally required to be done between competitors, who are obviously weary\nof each-others intentions. SMC caters not only to the needs of such parties but\nalso provides plausible solutions to individual organizations for problems like\nprivacy-preserving database query, privacy-preserving scientific computations,\nprivacy-preserving intrusion detection and privacy-preserving data mining. This\npaper is an extension to a previously proposed protocol Encrytpo_Random, which\npresented a plain sailing yet effective approach to SMC and also put forward an\naptly crafted architecture, whereby such an efficient protocol, involving the\nparties that have come forward for joint-computations and the third party who\nundertakes such computations, can be developed. Through this extended work an\nattempt has been made to further strengthen the existing protocol thus paving\nthe way for a more secure multi-party computational process.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2009 07:22:06 GMT"}], "update_date": "2009-08-10", "authors_parsed": [["Mishra", "Dr. Durgesh Kumar", ""], ["Koria", "Neha", ""], ["Kapoor", "Nikhil", ""], ["Bahety", "Ravish", ""]]}, {"id": "0908.2588", "submitter": "Davood Rafiei", "authors": "Davood Rafiei, Haobin Li", "title": "Wild Card Queries for Searching Resources on the Web", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a domain-independent framework for searching and retrieving facts\nand relationships within natural language text sources. In this framework, an\nextraction task over a text collection is expressed as a query that combines\ntext fragments with wild cards, and the query result is a set of facts in the\nform of unary, binary and general $n$-ary tuples. A significance of our\nquerying mechanism is that, despite being both simple and declarative, it can\nbe applied to a wide range of extraction tasks. A problem in querying natural\nlanguage text though is that a user-specified query may not retrieve enough\nexact matches. Unlike term queries which can be relaxed by removing some of the\nterms (as is done in search engines), removing terms from a wild card query\nwithout ruining its meaning is more challenging. Also, any query expansion has\nthe potential to introduce false positives. In this paper, we address the\nproblem of query expansion, and also analyze a few ranking alternatives to\nscore the results and to remove false positives. We conduct experiments and\nreport an evaluation of the effectiveness of our querying and scoring\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2009 15:17:19 GMT"}], "update_date": "2009-08-19", "authors_parsed": [["Rafiei", "Davood", ""], ["Li", "Haobin", ""]]}, {"id": "0908.3957", "submitter": "Jerome Darmont", "authors": "Hadj Mahboubi (ERIC), J\\'er\\^ome Darmont (ERIC)", "title": "Enhancing XML Data Warehouse Query Performance by Fragmentation", "comments": null, "journal-ref": "24th Annual ACM Symposium on Applied Computing (SAC 09), Hawaii :\n  United States (2009)", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XML data warehouses form an interesting basis for decision-support\napplications that exploit heterogeneous data from multiple sources. However,\nXML-native database systems currently suffer from limited performances in terms\nof manageable data volume and response time for complex analytical queries.\nFragmenting and distributing XML data warehouses (e.g., on data grids) allow to\naddress both these issues. In this paper, we work on XML warehouse\nfragmentation. In relational data warehouses, several studies recommend the use\nof derived horizontal fragmentation. Hence, we propose to adapt it to the XML\ncontext. We particularly focus on the initial horizontal fragmentation of\ndimensions' XML documents and exploit two alternative algorithms. We\nexperimentally validate our proposal and compare these alternatives with\nrespect to a unified XML warehouse model we advocate for.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2009 09:12:08 GMT"}], "update_date": "2009-08-28", "authors_parsed": [["Mahboubi", "Hadj", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}]