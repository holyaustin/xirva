[{"id": "0802.0137", "submitter": "Pierre Sutra", "authors": "Pierre Sutra (INRIA Rocquencourt), Marc Shapiro (INRIA Rocquencourt)", "title": "Fault-Tolerant Partial Replication in Large-Scale Database Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6440", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a decentralised approach to committing transactions in a\nreplicated database, under partial replication. Previous protocols either\nre-execute transactions entirely and/or compute a total order of transactions.\nIn contrast, ours applies update values, and orders only conflicting\ntransactions. It results that transactions execute faster, and distributed\ndatabases commit in small committees. Both effects contribute to preserve\nscalability as the number of databases and transactions increase. Our algorithm\nensures serializability, and is live and safe in spite of faults.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 14:47:24 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2008 16:47:09 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2009 14:41:43 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Sutra", "Pierre", "", "INRIA Rocquencourt"], ["Shapiro", "Marc", "", "INRIA Rocquencourt"]]}, {"id": "0802.3448", "submitter": "Haim Kaplan", "authors": "Edith Cohen and Haim Kaplan", "title": "Sketch-Based Estimation of Subpopulation-Weight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.NI cs.PF", "license": null, "abstract": "  Summaries of massive data sets support approximate query processing over the\noriginal data. A basic aggregate over a set of records is the weight of\nsubpopulations specified as a predicate over records' attributes. Bottom-k\nsketches are a powerful summarization format of weighted items that includes\npriority sampling and the classic weighted sampling without replacement. They\ncan be computed efficiently for many representations of the data including\ndistributed databases and data streams.\n  We derive novel unbiased estimators and efficient confidence bounds for\nsubpopulation weight. Our estimators and bounds are tailored by distinguishing\nbetween applications (such as data streams) where the total weight of the\nsketched set can be computed by the summarization algorithm without a\nsignificant use of additional resources, and applications (such as sketches of\nnetwork neighborhoods) where this is not the case.\n  Our rigorous derivations are based on clever applications of the\nHorvitz-Thompson estimator, and are complemented by efficient computational\nmethods. We demonstrate their benefit on a wide range of Pareto distributions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2008 15:25:04 GMT"}], "update_date": "2008-02-26", "authors_parsed": [["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "0802.3582", "submitter": "Erich Schikuta", "authors": "Erich Schikuta", "title": "Neural Networks and Database Systems", "comments": "19 pages, Festschrift Informationssysteme, in honor of G. Vinek", "journal-ref": "pp. 133-152, 2007, publisher Austrian Computer Society", "doi": null, "report-no": null, "categories": "cs.DB cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-oriented database systems proved very valuable at handling and\nadministrating complex objects. In the following guidelines for embedding\nneural networks into such systems are presented. It is our goal to treat\nnetworks as normal data in the database system. From the logical point of view,\na neural network is a complex data value and can be stored as a normal data\nobject. It is generally accepted that rule-based reasoning will play an\nimportant role in future database applications. The knowledge base consists of\nfacts and rules, which are both stored and handled by the underlying database\nsystem. Neural networks can be seen as representation of intensional knowledge\nof intelligent database systems. So they are part of a rule based knowledge\npool and can be used like conventional rules. The user has a unified view about\nhis knowledge base regardless of the origin of the unique rules.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2008 09:57:31 GMT"}], "update_date": "2008-02-26", "authors_parsed": [["Schikuta", "Erich", ""]]}, {"id": "0802.4126", "submitter": "Alexei Botchkarev", "authors": "Peter Andru, Alexei Botchkarev", "title": "Hospital Case Cost Estimates Modelling - Algorithm Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DB", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Ontario (Canada) Health System stakeholders support the idea and necessity of\nthe integrated source of data that would include both clinical (e.g. diagnosis,\nintervention, length of stay, case mix group) and financial (e.g. cost per\nweighted case, cost per diem) characteristics of the Ontario healthcare system\nactivities at the patient-specific level. At present, the actual patient-level\ncase costs in the explicit form are not available in the financial databases\nfor all hospitals. The goal of this research effort is to develop financial\nmodels that will assign each clinical case in the patient-specific data\nwarehouse a dollar value, representing the cost incurred by the Ontario health\ncare facility which treated the patient. Five mathematical models have been\ndeveloped and verified using real dataset. All models can be classified into\ntwo groups based on their underlying method: 1. Models based on using relative\nintensity weights of the cases, and 2. Models based on using cost per diem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2008 04:56:48 GMT"}], "update_date": "2008-02-29", "authors_parsed": [["Andru", "Peter", ""], ["Botchkarev", "Alexei", ""]]}]