[{"id": "0809.0116", "submitter": "David Martin", "authors": "David J. Martin, Johannes Gehrke, Joseph Y. Halpern", "title": "Toward Expressive and Scalable Sponsored Search Auctions", "comments": "10 pages, 13 figures, ICDE 2008", "journal-ref": "David J. Martin, Johannes Gehrke, and Joseph Y. Halpern. Toward\n  Expressive and Scalable Sponsored Search Auctions. In Proceedings of the 24th\n  IEEE International Conference on Data Engineering, pages 237--246. April 2008", "doi": "10.1109/ICDE.2008.4497432", "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet search results are a growing and highly profitable advertising\nplatform. Search providers auction advertising slots to advertisers on their\nsearch result pages. Due to the high volume of searches and the users' low\ntolerance for search result latency, it is imperative to resolve these auctions\nfast. Current approaches restrict the expressiveness of bids in order to\nachieve fast winner determination, which is the problem of allocating slots to\nadvertisers so as to maximize the expected revenue given the advertisers' bids.\nThe goal of our work is to permit more expressive bidding, thus allowing\nadvertisers to achieve complex advertising goals, while still providing fast\nand scalable techniques for winner determination.\n", "versions": [{"version": "v1", "created": "Sun, 31 Aug 2008 12:24:38 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Martin", "David J.", ""], ["Gehrke", "Johannes", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "0809.1551", "submitter": "Slawomir Staworko", "authors": "Slawomir Staworko, Jan Chomicki", "title": "Consistent Query Answers in the Presence of Universal Constraints", "comments": "Submitted to Information Systems", "journal-ref": null, "doi": null, "report-no": "UB CSE TR 2008-15", "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of consistent query answers and repairs has been introduced to\nalleviate the impact of inconsistent data on the answers to a query. A repair\nis a minimally different consistent instance and an answer is consistent if it\nis present in every repair. In this article we study the complexity of\nconsistent query answers and repair checking in the presence of universal\nconstraints.\n  We propose an extended version of the conflict hypergraph which allows to\ncapture all repairs w.r.t. a set of universal constraints. We show that repair\nchecking is in PTIME for the class of full tuple-generating dependencies and\ndenial constraints, and we present a polynomial repair algorithm. This\nalgorithm is sound, i.e. always produces a repair, but also complete, i.e.\nevery repair can be constructed. Next, we present a polynomial-time algorithm\ncomputing consistent answers to ground quantifier-free queries in the presence\nof denial constraints, join dependencies, and acyclic full-tuple generating\ndependencies. Finally, we show that extending the class of constraints leads to\nintractability. For arbitrary full tuple-generating dependencies consistent\nquery answering becomes coNP-complete. For arbitrary universal constraints\nconsistent query answering is \\Pi_2^p-complete and repair checking\ncoNP-complete.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2008 15:04:52 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2009 11:56:52 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Staworko", "Slawomir", ""], ["Chomicki", "Jan", ""]]}, {"id": "0809.1963", "submitter": "Jerome Darmont", "authors": "Hadj Mahboubi (ERIC), Kamel Aouiche (ERIC), J\\'er\\^ome Darmont (ERIC)", "title": "Materialized View Selection by Query Clustering in XML Data Warehouses", "comments": null, "journal-ref": "4th International Multiconference on Computer Science and\n  Information Technology (CSIT 06), Amman : Jordanie (2006)", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XML data warehouses form an interesting basis for decision-support\napplications that exploit complex data. However, native XML database management\nsystems currently bear limited performances and it is necessary to design\nstrategies to optimize them. In this paper, we propose an automatic strategy\nfor the selection of XML materialized views that exploits a data mining\ntechnique, more precisely the clustering of the query workload. To validate our\nstrategy, we implemented an XML warehouse modeled along the XCube\nspecifications. We executed a workload of XQuery decision-support queries on\nthis warehouse, with and without using our strategy. Our experimental results\ndemonstrate its efficiency, even when queries are complex.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 11:59:00 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Mahboubi", "Hadj", "", "ERIC"], ["Aouiche", "Kamel", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.1965", "submitter": "Jerome Darmont", "authors": "St\\'ephane Azefack (ERIC), Kamel Aouiche (ERIC), J\\'er\\^ome Darmont\n  (ERIC)", "title": "Dynamic index selection in data warehouses", "comments": null, "journal-ref": "4th International Conference on Innovations in Information\n  Technology (Innovations 07), Dubai : \\'Emirats arabes unis (2006)", "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analytical queries defined on data warehouses are complex and use several\njoin operations that are very costly, especially when run on very large data\nvolumes. To improve response times, data warehouse administrators casually use\nindexing techniques. This task is nevertheless complex and fastidious. In this\npaper, we present an automatic, dynamic index selection method for data\nwarehouses that is based on incremental frequent itemset mining from a given\nquery workload. The main advantage of this approach is that it helps update the\nset of selected indexes when workload evolves instead of recreating it from\nscratch. Preliminary experimental results illustrate the efficiency of this\napproach, both in terms of performance enhancement and overhead.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 12:01:34 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Azefack", "St\u00e9phane", "", "ERIC"], ["Aouiche", "Kamel", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.1971", "submitter": "Jerome Darmont", "authors": "Jean-Christian Ralaivao (ERIC), J\\'er\\^ome Darmont (ERIC)", "title": "Knowledge and Metadata Integration for Warehousing Complex Data", "comments": "6th International Conference on Information Systems Technology and\n  its Applications (ISTA 07), Kharkiv : Ukraine (2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-growing availability of so-called complex data, especially on\nthe Web, decision-support systems such as data warehouses must store and\nprocess data that are not only numerical or symbolic. Warehousing and analyzing\nsuch data requires the joint exploitation of metadata and domain-related\nknowledge, which must thereby be integrated. In this paper, we survey the types\nof knowledge and metadata that are needed for managing complex data, discuss\nthe issue of knowledge and metadata integration, and propose a CWM-compliant\nintegration solution that we incorporate into an XML complex data warehousing\nframework we previously designed.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 12:20:00 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Ralaivao", "Jean-Christian", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.1981", "submitter": "Jerome Darmont", "authors": "Hadj Mahboubi (ERIC), Kamel Aouiche (ERIC), J\\'er\\^ome Darmont (ERIC)", "title": "A Join Index for XML Data Warehouses", "comments": "2008 International Conference on Information Resources Management\n  (Conf-IRM 08), Niagra Falls : Canada (2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XML data warehouses form an interesting basis for decision-support\napplications that exploit complex data. However, native-XML database management\nsystems (DBMSs) currently bear limited performances and it is necessary to\nresearch for ways to optimize them. In this paper, we propose a new join index\nthat is specifically adapted to the multidimensional architecture of XML\nwarehouses. It eliminates join operations while preserving the information\ncontained in the original warehouse. A theoretical study and experimental\nresults demonstrate the efficiency of our join index. They also show that\nnative XML DBMSs can compete with XML-compatible, relational DBMSs when\nwarehousing and analyzing XML data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2008 12:44:10 GMT"}], "update_date": "2008-09-12", "authors_parsed": [["Mahboubi", "Hadj", "", "ERIC"], ["Aouiche", "Kamel", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.2532", "submitter": "Neil J. Gunther", "authors": "Tanel Poder and Neil J. Gunther", "title": "Multidimensional Visualization of Oracle Performance Using Barry007", "comments": "To appear in the Proc. CMG International Conference, Las Vegas,\n  Nevada, December 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most generic performance tools display only system-level performance data\nusing 2-dimensional plots or diagrams and this limits the informational detail\nthat can be displayed. Moreover, a modern relational database system, like\nOracle, can concurrently serve thousands of client processes with different\nworkload characteristics, so that generic performance-data displays inevitably\nhide important information. Drawing on our previous work, this paper\ndemonstrates the application of Barry007 multidimensional visualization to the\nanalysis of Oracle end-user, session-level, performance data, showing both\ncollective trends and individual performance anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2008 14:11:34 GMT"}], "update_date": "2008-09-16", "authors_parsed": [["Poder", "Tanel", ""], ["Gunther", "Neil J.", ""]]}, {"id": "0809.2686", "submitter": "Jerome Darmont", "authors": "Omar Boussa\\\"id (ERIC), Fadila Bentayeb (ERIC), J\\'er\\^ome Darmont\n  (ERIC)", "title": "An MAS-Based ETL Approach for Complex Data", "comments": "in 10th ISPE International Conference on Concurrent Engineering:\n  Research and Applications (CE 03), Madeira : Portugal (2003)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a data warehousing process, the phase of data integration is crucial. Many\nmethods for data integration have been published in the literature. However,\nwith the development of the Internet, the availability of various types of data\n(images, texts, sounds, videos, databases...) has increased, and structuring\nsuch data is a difficult task. We name these data, which may be structured or\nunstructured, \"complex data\". In this paper, we propose a new approach for\ncomplex data integration, based on a Multi-Agent System (MAS), in association\nto a data warehousing approach. Our objective is to take advantage of the MAS\nto perform the integration phase for complex data. We indeed consider the\ndifferent tasks of the data integration process as services offered by agents.\nTo validate this approach, we have actually developed an MAS for complex data\nintegration.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2008 11:42:42 GMT"}], "update_date": "2008-09-17", "authors_parsed": [["Boussa\u00efd", "Omar", "", "ERIC"], ["Bentayeb", "Fadila", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.2687", "submitter": "Jerome Darmont", "authors": "Kamel Aouiche (ERIC), J\\'er\\^ome Darmont (ERIC), Le Gruenwald", "title": "Frequent itemsets mining for database auto-administration", "comments": "in 7th International Database Engineering and Application Symposium\n  (IDEAS 03), Hong-Kong : Chine (2003)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide development of databases in general and data warehouses in\nparticular, it is important to reduce the tasks that a database administrator\nmust perform manually. The aim of auto-administrative systems is to\nadministrate and adapt themselves automatically without loss (or even with a\ngain) in performance. The idea of using data mining techniques to extract\nuseful knowledge for administration from the data themselves has existed for\nsome years. However, little research has been achieved. This idea nevertheless\nremains a very promising approach, notably in the field of data warehousing,\nwhere queries are very heterogeneous and cannot be interpreted easily. The aim\nof this study is to search for a way of extracting useful knowledge from stored\ndata themselves to automatically apply performance optimization techniques, and\nmore particularly indexing techniques. We have designed a tool that extracts\nfrequent itemsets from a given workload to compute an index configuration that\nhelps optimizing data access time. The experiments we performed showed that the\nindex configurations generated by our tool allowed performance gains of 15% to\n25% on a test database and a test data warehouse.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2008 11:44:39 GMT"}], "update_date": "2008-09-17", "authors_parsed": [["Aouiche", "Kamel", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"], ["Gruenwald", "Le", ""]]}, {"id": "0809.2688", "submitter": "Jerome Darmont", "authors": "J\\'er\\^ome Darmont (ERIC), Emerson Olivier (ERIC)", "title": "A Complex Data Warehouse for Personalized, Anticipative Medicine", "comments": "in 17th Information Resources Management Association International\n  Conference (IRMA 06), Wahsington, DC : \\'Etats-Unis d'Am\\'erique (2006)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing use of new technologies, healthcare is nowadays undergoing\nsignificant changes. Information-based medicine has to exploit medical\ndecision-support systems and requires the analysis of various, heterogeneous\ndata, such as patient records, medical images, biological analysis results,\netc. In this paper, we present the design of the complex data warehouse\nrelating to high-level athletes. It is original in two ways. First, it is aimed\nat storing complex medical data. Second, it is designed to allow innovative and\nquite different kinds of analyses to support: (1) personalized and anticipative\nmedicine (in opposition to curative medicine) for well-identified patients; (2)\nbroad-band statistical studies over a given population of patients.\nFurthermore, the system includes data relating to several medical fields. It is\nalso designed to be evolutionary to take into account future advances in\nmedical research.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2008 11:47:58 GMT"}], "update_date": "2008-09-17", "authors_parsed": [["Darmont", "J\u00e9r\u00f4me", "", "ERIC"], ["Olivier", "Emerson", "", "ERIC"]]}, {"id": "0809.2691", "submitter": "Jerome Darmont", "authors": "Marouane Hachicha (ERIC), Hadj Mahboubi (ERIC), J\\'er\\^ome Darmont\n  (ERIC)", "title": "Expressing OLAP operators with the TAX XML algebra", "comments": "in 3rd International Workshop on Database Technologies for Handling\n  XML Information on the Web (DataX-EDBT 08), Nantes : France (2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of XML as a standard for representing business data, XML data\nwarehouses appear as suitable solutions for Web-based decision-support\napplications. In this context, it is necessary to allow OLAP analyses over XML\ndata cubes (XOLAP). Thus, XQuery extensions are needed. To help define a formal\nframework and allow much-needed performance optimizations on analytical queries\nexpressed in XQuery, having an algebra at one's disposal is desirable. However,\nXOLAP approaches and algebras from the literature still largely rely on the\nrelational model and/or only feature a small number of OLAP operators. In\nopposition, we propose in this paper to express a broad set of OLAP operators\nwith the TAX XML algebra.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2008 12:12:15 GMT"}], "update_date": "2008-09-17", "authors_parsed": [["Hachicha", "Marouane", "", "ERIC"], ["Mahboubi", "Hadj", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "0809.3027", "submitter": "Evimaria Terzi", "authors": "Heikki Mannila and Evimaria Terzi", "title": "Finding links and initiators: a graph reconstruction problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB physics.soc-ph", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Consider a 0-1 observation matrix M, where rows correspond to entities and\ncolumns correspond to signals; a value of 1 (or 0) in cell (i,j) of M indicates\nthat signal j has been observed (or not observed) in entity i. Given such a\nmatrix we study the problem of inferring the underlying directed links between\nentities (rows) and finding which entries in the matrix are initiators.\n  We formally define this problem and propose an MCMC framework for estimating\nthe links and the initiators given the matrix of observations M. We also show\nhow this framework can be extended to incorporate a temporal aspect; instead of\nconsidering a single observation matrix M we consider a sequence of observation\nmatrices M1,..., Mt over time.\n  We show the connection between our problem and several problems studied in\nthe field of social-network analysis. We apply our method to paleontological\nand ecological data and show that our algorithms work well in practice and give\nreasonable results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2008 22:28:29 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Mannila", "Heikki", ""], ["Terzi", "Evimaria", ""]]}, {"id": "0809.3140", "submitter": "Fang Wei", "authors": "Georg Gottlob, Reinhard Pichler, Fang Wei", "title": "Monadic Datalog over Finite Structures with Bounded Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded treewidth and Monadic Second Order (MSO) logic have proved to be key\nconcepts in establishing fixed-parameter tractability results. Indeed, by\nCourcelle's Theorem we know: Any property of finite structures, which is\nexpressible by an MSO sentence, can be decided in linear time (data complexity)\nif the structures have bounded treewidth.\n  In principle, Courcelle's Theorem can be applied directly to construct\nconcrete algorithms by transforming the MSO evaluation problem into a tree\nlanguage recognition problem. The latter can then be solved via a finite tree\nautomaton (FTA). However, this approach has turned out to be problematical,\nsince even relatively simple MSO formulae may lead to a ``state explosion'' of\nthe FTA.\n  In this work we propose monadic datalog (i.e., datalog where all intentional\npredicate symbols are unary) as an alternative method to tackle this class of\nfixed-parameter tractable problems. We show that if some property of finite\nstructures is expressible in MSO then this property can also be expressed by\nmeans of a monadic datalog program over the structure plus the tree\ndecomposition.\n  Moreover, we show that the resulting fragment of datalog can be evaluated in\nlinear time (both w.r.t. the program size and w.r.t. the data size). This new\napproach is put to work by devising new algorithms for the 3-Colorability\nproblem of graphs and for the PRIMALITY problem of relational schemas (i.e.,\ntesting if some attribute in a relational schema is part of a key). We also\nreport on experimental results with a prototype implementation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2008 12:40:49 GMT"}], "update_date": "2008-09-19", "authors_parsed": [["Gottlob", "Georg", ""], ["Pichler", "Reinhard", ""], ["Wei", "Fang", ""]]}]