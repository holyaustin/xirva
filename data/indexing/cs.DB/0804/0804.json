[{"id": "0804.1409", "submitter": "Murat Ali Bayir Mr.", "authors": "Murat Ali Bayir, Ismail Hakki Toroslu, Ahmet Cosar, Guven Fidan", "title": "Discovering More Accurate Frequent Web Usage Patterns", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web usage mining is a type of web mining, which exploits data mining\ntechniques to discover valuable information from navigation behavior of World\nWide Web users. As in classical data mining, data preparation and pattern\ndiscovery are the main issues in web usage mining. The first phase of web usage\nmining is the data processing phase, which includes the session reconstruction\noperation from server logs. Session reconstruction success directly affects the\nquality of the frequent patterns discovered in the next phase. In reactive web\nusage mining techniques, the source data is web server logs and the topology of\nthe web pages served by the web server domain. Other kinds of information\ncollected during the interactive browsing of web site by user, such as cookies\nor web logs containing similar information, are not used. The next phase of web\nusage mining is discovering frequent user navigation patterns. In this phase,\npattern discovery methods are applied on the reconstructed sessions obtained in\nthe first phase in order to discover frequent user patterns. In this paper, we\npropose a frequent web usage pattern discovery method that can be applied after\nsession reconstruction phase. In order to compare accuracy performance of\nsession reconstruction phase and pattern discovery phase, we have used an agent\nsimulator, which models behavior of web users and generates web user navigation\nas well as the log data kept by the web server.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2008 05:46:26 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Bayir", "Murat Ali", ""], ["Toroslu", "Ismail Hakki", ""], ["Cosar", "Ahmet", ""], ["Fidan", "Guven", ""]]}, {"id": "0804.1845", "submitter": "Ely Porat", "authors": "Ely Porat", "title": "An Optimal Bloom Filter Replacement Based on Matrix Solving", "comments": "A lectureon this paper will be available in Google video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a method for holding a dictionary data structure, which maps keys\nto values, in the spirit of Bloom Filters. The space requirements of the\ndictionary we suggest are much smaller than those of a hashtable. We allow\nstoring n keys, each mapped to value which is a string of k bits. Our suggested\nmethod requires nk + o(n) bits space to store the dictionary, and O(n) time to\nproduce the data structure, and allows answering a membership query in O(1)\nmemory probes. The dictionary size does not depend on the size of the keys.\nHowever, reducing the space requirements of the data structure comes at a\ncertain cost. Our dictionary has a small probability of a one sided error. When\nattempting to obtain the value for a key that is stored in the dictionary we\nalways get the correct answer. However, when testing for membership of an\nelement that is not stored in the dictionary, we may get an incorrect answer,\nand when requesting the value of such an element we may get a certain random\nvalue. Our method is based on solving equations in GF(2^k) and using several\nhash functions. Another significant advantage of our suggested method is that\nwe do not require using sophisticated hash functions. We only require pairwise\nindependent hash functions. We also suggest a data structure that requires only\nnk bits space, has O(n2) preprocessing time, and has a O(log n) query time.\nHowever, this data structures requires a uniform hash functions. In order\nreplace a Bloom Filter of n elements with an error proability of 2^{-k}, we\nrequire nk + o(n) memory bits, O(1) query time, O(n) preprocessing time, and\nonly pairwise independent hash function. Even the most advanced previously\nknown Bloom Filter would require nk+O(n) space, and a uniform hash functions,\nso our method is significantly less space consuming especially when k is small.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2008 11:24:04 GMT"}], "update_date": "2008-04-14", "authors_parsed": [["Porat", "Ely", ""]]}, {"id": "0804.3171", "submitter": "Prashanth Alluvada", "authors": "Prashanth Alluvada", "title": "Optimization Approach for Detecting the Critical Data on a Database", "comments": "6 pages, 1 figure, 3 tables. corrected typos, added remarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through purposeful introduction of malicious transactions (tracking\ntransactions) into randomly select nodes of a (database) graph, soiled and\nclean segments are identified. Soiled and clean measures corresponding those\nsegments are then computed. These measures are used to repose the problem of\ncritical database elements detection as an optimization problem over the graph.\nThis method is universally applicable over a large class of graphs (including\ndirected, weighted, disconnected, cyclic) that occur in several contexts of\ndatabases. A generalization argument is presented which extends the critical\ndata problem to abstract settings.\n", "versions": [{"version": "v1", "created": "Sun, 20 Apr 2008 03:23:38 GMT"}, {"version": "v2", "created": "Sun, 27 Apr 2008 19:32:31 GMT"}], "update_date": "2008-04-27", "authors_parsed": [["Alluvada", "Prashanth", ""]]}, {"id": "0804.4740", "submitter": "Bart Kuijpers", "authors": "Sofie Haesevoets and Bart Kuijpers", "title": "An Affine-invariant Time-dependent Triangulation of Spatio-temporal Data", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the geometric data model for spatio-temporal data, introduced by Chomicki\nand Revesz, spatio-temporal data are modelled as a finite collection of\ntriangles that are transformed by time-dependent affinities of the plane. To\nfacilitate querying and animation of spatio-temporal data, we present a normal\nform for data in the geometric data model. We propose an algorithm for\nconstructing this normal form via a spatio-temporal triangulation of geometric\ndata objects. This triangulation algorithm generates new geometric data objects\nthat partition the given objects both in space and in time. A particular\nproperty of the proposed partition is that it is invariant under time-dependent\naffine transformations, and hence independent of the particular choice of\ncoordinate system used to describe he spatio-temporal data in. We can show that\nour algorithm works correctly and has a polynomial time complexity (of\nreasonably low degree in the number of input triangles and the maximal degree\nof the polynomial functions that describe the transformation functions). We\nalso discuss several possible applications of this spatio-temporal\ntriangulation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 06:02:56 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Haesevoets", "Sofie", ""], ["Kuijpers", "Bart", ""]]}]