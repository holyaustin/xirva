[{"id": "0904.0313", "submitter": "Petar Kormushev", "authors": "Petar Kormushev", "title": "Visual approach for data mining on medical information databases using\n  Fastmap algorithm", "comments": "Master's Thesis in Bio- and Medical Informatics, 76 pages, in\n  Bulgarian. Submitted to Faculty of Mathematics and Informatics, Sofia\n  University, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of tools for acquisition and storage of information has\nlead to the formation of enormous medical databases. The large quantity of data\ndefinitely surpasses the abilities of humans for efficient usage without\nspecialized tools for analysis. The situation is described as rich in data, but\npoor in information. In order to fill this growing gap, different approaches\nfrom the field of Data Mining are applied. These methods perform analysis of\nlarge sets of observed data in order to find new dependencies or concise\nrepresentation of the data, which is more meaningful to humans. One of the\npossible approaches for discovery of dependencies is the visual approach, in\nwhich data is processed and visualized in a way suitable for analysis by a\ndomain expert. This work proposes a visual approach, in which data is processed\nand visualized in a way suitable for analysis by a domain expert. We design and\nimplement a software solution for visualization of multi-dimensional,\nclassified medical data using the FastMap algorithm for graduate reduction of\ndimensions. The implementation of the graphical user interface is described in\ndetail since it is the most important factor for the ease of use of these tools\nby non-professionals in data mining.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2009 06:14:42 GMT"}], "update_date": "2009-04-03", "authors_parsed": [["Kormushev", "Petar", ""]]}, {"id": "0904.0682", "submitter": "Michaela Goetz", "authors": "Michaela Goetz, Ashwin Machanavajjhala, Guozhang Wang, Xiaokui Xiao,\n  Johannes Gehrke", "title": "Privacy in Search Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engine companies collect the \"database of intentions\", the histories\nof their users' search queries. These search logs are a gold mine for\nresearchers. Search engine companies, however, are wary of publishing search\nlogs in order not to disclose sensitive information. In this paper we analyze\nalgorithms for publishing frequent keywords, queries and clicks of a search\nlog. We first show how methods that achieve variants of $k$-anonymity are\nvulnerable to active attacks. We then demonstrate that the stronger guarantee\nensured by $\\epsilon$-differential privacy unfortunately does not provide any\nutility for this problem. We then propose an algorithm ZEALOUS and show how to\nset its parameters to achieve $(\\epsilon,\\delta)$-probabilistic privacy. We\nalso contrast our analysis of ZEALOUS with an analysis by Korolova et al. [17]\nthat achieves $(\\epsilon',\\delta')$-indistinguishability. Our paper concludes\nwith a large experimental study using real applications where we compare\nZEALOUS and previous work that achieves $k$-anonymity in search log publishing.\nOur results show that ZEALOUS yields comparable utility to $k-$anonymity while\nat the same time achieving much stronger privacy guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 05:49:00 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2009 08:42:17 GMT"}, {"version": "v3", "created": "Sun, 29 Aug 2010 20:08:44 GMT"}, {"version": "v4", "created": "Wed, 11 May 2011 22:39:23 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Goetz", "Michaela", ""], ["Machanavajjhala", "Ashwin", ""], ["Wang", "Guozhang", ""], ["Xiao", "Xiaokui", ""], ["Gehrke", "Johannes", ""]]}, {"id": "0904.0942", "submitter": "Michael Hay", "authors": "Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu", "title": "Boosting the Accuracy of Differentially-Private Histograms Through\n  Consistency", "comments": "15 pages, 7 figures, minor revisions to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is possible to significantly improve the accuracy of a\ngeneral class of histogram queries while satisfying differential privacy. Our\napproach carefully chooses a set of queries to evaluate, and then exploits\nconsistency constraints that should hold over the noisy output. In a\npost-processing phase, we compute the consistent input most likely to have\nproduced the noisy output. The final output is differentially-private and\nconsistent, but in addition, it is often much more accurate. We show, both\ntheoretically and experimentally, that these techniques can be used for\nestimating the degree sequence of a graph very precisely, and for computing a\nhistogram that can support arbitrary range queries accurately.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 14:58:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2009 20:45:13 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2009 14:07:04 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2010 20:34:17 GMT"}, {"version": "v5", "created": "Fri, 9 Jul 2010 01:34:32 GMT"}], "update_date": "2010-07-12", "authors_parsed": [["Hay", "Michael", ""], ["Rastogi", "Vibhor", ""], ["Miklau", "Gerome", ""], ["Suciu", "Dan", ""]]}, {"id": "0904.1366", "submitter": "Jian Li", "authors": "Jian Li, Barna Saha, Amol Deshpande", "title": "A Unified Approach to Ranking in Probabilistic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dramatic growth in the number of application domains that naturally\ngenerate probabilistic, uncertain data has resulted in a need for efficiently\nsupporting complex querying and decision-making over such data. In this paper,\nwe present a unified approach to ranking and top-k query processing in\nprobabilistic databases by viewing it as a multi-criteria optimization problem,\nand by deriving a set of features that capture the key properties of a\nprobabilistic dataset that dictate the ranked result. We contend that a single,\nspecific ranking function may not suffice for probabilistic databases, and we\ninstead propose two parameterized ranking functions, called PRF-w and PRF-e,\nthat generalize or can approximate many of the previously proposed ranking\nfunctions. We present novel generating functions-based algorithms for\nefficiently ranking large datasets according to these ranking functions, even\nif the datasets exhibit complex correlations modeled using probabilistic\nand/xor trees or Markov networks. We further propose that the parameters of the\nranking function be learned from user preferences, and we develop an approach\nto learn those parameters. Finally, we present a comprehensive experimental\nstudy that illustrates the effectiveness of our parameterized ranking\nfunctions, especially PRF-e, at approximating other ranking functions and the\nscalability of our proposed algorithms for exact or approximate ranking.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 15:30:58 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2009 04:42:10 GMT"}, {"version": "v3", "created": "Tue, 14 Dec 2010 19:25:42 GMT"}, {"version": "v4", "created": "Wed, 15 Dec 2010 21:12:37 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Li", "Jian", ""], ["Saha", "Barna", ""], ["Deshpande", "Amol", ""]]}, {"id": "0904.1931", "submitter": "Byron Gao", "authors": "Obi L. Griffith, Byron J. Gao, Mikhail Bilenky, Yuliya Prichyna,\n  Martin Ester, Steven J.M. Jones", "title": "KiWi: A Scalable Subspace Clustering Algorithm for Gene Expression\n  Analysis", "comments": "International Conference on Bioinformatics and Biomedical Engineering\n  (iCBBE), 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering has gained increasing popularity in the analysis of gene\nexpression data. Among subspace cluster models, the recently introduced\norder-preserving sub-matrix (OPSM) has demonstrated high promise. An OPSM,\nessentially a pattern-based subspace cluster, is a subset of rows and columns\nin a data matrix for which all the rows induce the same linear ordering of\ncolumns. Existing OPSM discovery methods do not scale well to increasingly\nlarge expression datasets. In particular, twig clusters having few genes and\nmany experiments incur explosive computational costs and are completely pruned\noff by existing methods. However, it is of particular interest to determine\nsmall groups of genes that are tightly coregulated across many conditions. In\nthis paper, we present KiWi, an OPSM subspace clustering algorithm that is\nscalable to massive datasets, capable of discovering twig clusters and\nidentifying negative as well as positive correlations. We extensively validate\nKiWi using relevant biological datasets and show that KiWi correctly assigns\nredundant probes to the same cluster, groups experiments with common clinical\nannotations, differentiates real promoter sequences from negative control\nsequences, and shows good association with cis-regulatory motif predictions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 08:16:53 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Griffith", "Obi L.", ""], ["Gao", "Byron J.", ""], ["Bilenky", "Mikhail", ""], ["Prichyna", "Yuliya", ""], ["Ester", "Martin", ""], ["Jones", "Steven J. M.", ""]]}, {"id": "0904.2012", "submitter": "David Spivak", "authors": "David I. Spivak", "title": "Simplicial Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we define a category DB, called the category of simplicial\ndatabases, whose objects are databases and whose morphisms are data-preserving\nmaps. Along the way we give a precise formulation of the category of relational\ndatabases, and prove that it is a full subcategory of DB. We also prove that\nlimits and colimits always exist in DB and that they correspond to queries such\nas select, join, union, etc.\n  One feature of our construction is that the schema of a simplicial database\nhas a natural geometric structure: an underlying simplicial set. The geometry\nof a schema is a way of keeping track of relationships between distinct tables,\nand can be thought of as a system of foreign keys. The shape of a schema is\ngenerally intuitive (e.g. the schema for round-trip flights is a circle\nconsisting of an edge from $A$ to $B$ and an edge from $B$ to $A$), and as\nsuch, may be useful for analyzing data.\n  We give several applications of our approach, as well as possible advantages\nit has over the relational model. We also indicate some directions for further\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 21:20:57 GMT"}], "update_date": "2009-04-15", "authors_parsed": [["Spivak", "David I.", ""]]}, {"id": "0904.3060", "submitter": "Yingyu Zhang", "authors": "Heping Hu, Yingyu Zhang, Zhengding Lu", "title": "An efficient quantum search engine on unsorted database", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding one or more desired items out of an\nunsorted database. Patel has shown that if the database permits quantum\nqueries, then mere digitization is sufficient for efficient search for one\ndesired item. The algorithm, called factorized quantum search algorithm,\npresented by him can locate the desired item in an unsorted database using\n$O(log_{4}N)$ queries to factorized oracles. But the algorithm requires that\nall the property values must be distinct from each other. In this paper, we\ndiscuss how to make a database satisfy the requirements, and present a quantum\nsearch engine based on the algorithm. Our goal is achieved by introducing\nauxiliary files for the property values that are not distinct, and converting\nevery complex query request into a sequence of calls to factorized quantum\nsearch algorithm. The query complexity of our algorithm is $O(P*Q*M*log_{4}N)$,\nwhere P is the number of the potential simple query requests in the complex\nquery request, Q is the maximum number of calls to the factorized quantum\nsearch algorithm of the simple queries, M is the number of the auxiliary files\nfor the property on which our algorithm are searching for desired items. This\nimplies that to manage an unsorted database on an actual quantum computer is\npossible and efficient.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2009 15:43:06 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Hu", "Heping", ""], ["Zhang", "Yingyu", ""], ["Lu", "Zhengding", ""]]}, {"id": "0904.3310", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Abdul Rauf Baig", "title": "FastLMFI: An Efficient Approach for Local Maximal Patterns Propagation\n  and Maximal Patterns Superset Checking", "comments": "8 Pages, In the proceedings of 4th ACS/IEEE International Conference\n  on Computer Systems and Applications 2006, March 8, 2006, Dubai/Sharjah, UAE,\n  2006, Page(s) 452-459", "journal-ref": null, "doi": "10.1109/AICCSA.2006.205130", "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximal frequent patterns superset checking plays an important role in the\nefficient mining of complete Maximal Frequent Itemsets (MFI) and maximal search\nspace pruning. In this paper we present a new indexing approach, FastLMFI for\nlocal maximal frequent patterns (itemset) propagation and maximal patterns\nsuperset checking. Experimental results on different sparse and dense datasets\nshow that our work is better than the previous well known progressive focusing\ntechnique. We have also integrated our superset checking approach with an\nexisting state of the art maximal itemsets algorithm Mafia, and compare our\nresults with current best maximal itemsets algorithms afopt-max and FP\n(zhu)-max. Our results outperform afopt-max and FP (zhu)-max on dense (chess\nand mushroom) datasets on almost all support thresholds, which shows the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:33:04 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3312", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, and Abdul Rauf Baig", "title": "HybridMiner: Mining Maximal Frequent Itemsets Using Hybrid Database\n  Representation Approach", "comments": "8 Pages In the proceedings of 9th IEEE-INMIC 2005, Karachi, Pakistan,\n  2005", "journal-ref": null, "doi": "10.1109/INMIC.2005.334484", "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel hybrid (arraybased layout and vertical\nbitmap layout) database representation approach for mining complete Maximal\nFrequent Itemset (MFI) on sparse and large datasets. Our work is novel in terms\nof scalability, item search order and two horizontal and vertical projection\ntechniques. We also present a maximal algorithm using this hybrid database\nrepresentation approach. Different experimental results on real and sparse\nbenchmark datasets show that our approach is better than previous state of art\nmaximal algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:38:25 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3316", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, and Abdul Rauf Baig", "title": "Ramp: Fast Frequent Itemset Mining with Efficient Bit-Vector Projection\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent itemset using bit-vector representation approach is very\nefficient for dense type datasets, but highly inefficient for sparse datasets\ndue to lack of any efficient bit-vector projection technique. In this paper we\npresent a novel efficient bit-vector projection technique, for sparse and dense\ndatasets. To check the efficiency of our bit-vector projection technique, we\npresent a new frequent itemset mining algorithm Ramp (Real Algorithm for Mining\nPatterns) build upon our bit-vector projection technique. The performance of\nthe Ramp is compared with the current best (all, maximal and closed) frequent\nitemset mining algorithms on benchmark datasets. Different experimental results\non sparse and dense datasets show that mining frequent itemset using Ramp is\nfaster than the current best algorithms, which show the effectiveness of our\nbit-vector projection idea. We also present a new local maximal frequent\nitemsets propagation and maximal itemset superset checking approach FastLMFI,\nbuild upon our PBR bit-vector projection technique. Our different computational\nexperiments suggest that itemset maximality checking using FastLMFI is fast and\nefficient than a previous will known progressive focusing approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:49:13 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3319", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Zahoor Jan, Abdul Rauf Baig", "title": "Fast Algorithms for Mining Interesting Frequent Itemsets without Minimum\n  Support", "comments": "25 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world datasets are sparse, dirty and contain hundreds of items. In such\nsituations, discovering interesting rules (results) using traditional frequent\nitemset mining approach by specifying a user defined input support threshold is\nnot appropriate. Since without any domain knowledge, setting support threshold\nsmall or large can output nothing or a large number of redundant uninteresting\nresults. Recently a novel approach of mining only N-most/Top-K interesting\nfrequent itemsets has been proposed, which discovers the top N interesting\nresults without specifying any user defined support threshold. However, mining\ninteresting frequent itemsets without minimum support threshold are more costly\nin terms of itemset search space exploration and processing cost. Thereby, the\nefficiency of their mining highly depends upon three main factors (1) Database\nrepresentation approach used for itemset frequency counting, (2) Projection of\nrelevant transactions to lower level nodes of search space and (3) Algorithm\nimplementation technique. Therefore, to improve the efficiency of mining\nprocess, in this paper we present two novel algorithms called (N-MostMiner and\nTop-K-Miner) using the bit-vector representation approach which is very\nefficient in terms of itemset frequency counting and transactions projection.\nIn addition to this, several efficient implementation techniques of N-MostMiner\nand Top-K-Miner are also present which we experienced in our implementation.\nOur experimental results on benchmark datasets suggest that the NMostMiner and\nTop-K-Miner are very efficient in terms of processing time as compared to\ncurrent best algorithms BOMO and TFP.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:07:35 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Jan", "Zahoor", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3320", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Saad Razzaq, Umer Maqbool, Sonya Tahir, Abdul Rauf Baig", "title": "Using Association Rules for Better Treatment of Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of training data for knowledge discovery in databases (KDD) and\ndata mining depends upon many factors, but handling missing values is\nconsidered to be a crucial factor in overall data quality. Today real world\ndatasets contains missing values due to human, operational error, hardware\nmalfunctioning and many other factors. The quality of knowledge extracted,\nlearning and decision problems depend directly upon the quality of training\ndata. By considering the importance of handling missing values in KDD and data\nmining tasks, in this paper we propose a novel Hybrid Missing values Imputation\nTechnique (HMiT) using association rules mining and hybrid combination of\nk-nearest neighbor approach. To check the effectiveness of our HMiT missing\nvalues imputation technique, we also perform detail experimental results on\nreal world datasets. Our results suggest that the HMiT technique is not only\nbetter in term of accuracy but it also take less processing time as compared to\ncurrent best missing values imputation technique based on k-nearest neighbor\napproach, which shows the effectiveness of our missing values imputation\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:09:57 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Razzaq", "Saad", ""], ["Maqbool", "Umer", ""], ["Tahir", "Sonya", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3321", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Saad Razzaq, Umer Maqbool, Sonya Tahir, Abdul Rauf Baig", "title": "Introducing Partial Matching Approach in Association Rules for Better\n  Treatment of Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling missing values in training datasets for constructing learning models\nor extracting useful information is considered to be an important research task\nin data mining and knowledge discovery in databases. In recent years, lot of\ntechniques are proposed for imputing missing values by considering attribute\nrelationships with missing value observation and other observations of training\ndataset. The main deficiency of such techniques is that, they depend upon\nsingle approach and do not combine multiple approaches, that why they are less\naccurate. To improve the accuracy of missing values imputation, in this paper\nwe introduce a novel partial matching concept in association rules mining,\nwhich shows better results as compared to full matching concept that we\ndescribed in our previous work. Our imputation technique combines the partial\nmatching concept in association rules with k-nearest neighbor approach. Since\nthis is a hybrid technique, therefore its accuracy is much better than as\ncompared to those techniques which depend upon single approach. To check the\nefficiency of our technique, we also provide detail experimental results on\nnumber of benchmark datasets which show better results as compared to previous\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:16:00 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Razzaq", "Saad", ""], ["Maqbool", "Umer", ""], ["Tahir", "Sonya", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.4041", "submitter": "Mario Nascimento", "authors": "Jie Luo and Mario A. Nascimento", "title": "Content-Based Sub-Image Retrieval with Relevance Feedback", "comments": "A preliminary version of this paper appeared in the Proceedings of\n  the 1st ACM International Workshop on Multimedia Databases, p. 63-69. 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical content-based image retrieval problem is to find images within a\ndatabase that are similar to a given query image. This paper presents a\nsolution to a different problem, namely that of content based sub-image\nretrieval, i.e., finding images from a database that contains another image.\nNote that this is different from finding a region in a (segmented) image that\nis similar to another image region given as a query. We present a technique for\nCBsIR that explores relevance feedback, i.e., the user's input on intermediary\nresults, in order to improve retrieval efficiency. Upon modeling images as a\nset of overlapping and recursive tiles, we use a tile re-weighting scheme that\nassigns penalties to each tile of the database images and updates the tile\npenalties for all relevant images retrieved at each iteration using both the\nrelevant and irrelevant images identified by the user. Each tile is modeled by\nmeans of its color content using a compact but very efficient method which can,\nindirectly, capture some notion of texture as well, despite the fact that only\ncolor information is maintained. Performance evaluation on a largely\nheterogeneous dataset of over 10,000 images shows that the system can achieve a\nstable average recall value of 70% within the top 20 retrieved (and presented)\nimages after only 5 iterations, with each such iteration taking about 2 seconds\non an off-the-shelf desktop computer.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2009 17:50:33 GMT"}], "update_date": "2009-04-28", "authors_parsed": [["Luo", "Jie", ""], ["Nascimento", "Mario A.", ""]]}]