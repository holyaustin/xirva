[{"id": "1310.0178", "submitter": "Tanja Hartmann", "authors": "Tanja Hartmann and Dorothea Wagner", "title": "Dynamic Gomory-Hu Tree Construction -- fast and simple", "comments": "12 pages, 6 figures, Full version of the ISAAC 2012 publication \"Fast\n  and Simple Fully-Dynamic Cut Tree Construction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cut tree (or Gomory-Hu tree) of an undirected weighted graph G=(V,E)\nencodes a minimum s-t-cut for each vertex pair {s,t} \\subseteq V and can be\niteratively constructed by n-1 maximum flow computations. They solve the\nmultiterminal network flow problem, which asks for the all-pairs maximum flow\nvalues in a network and at the same time they represent n-1 non-crossing,\nlinearly independent cuts that constitute a minimum cut basis of G. Hence, cut\ntrees are resident in at least two fundamental fields of network analysis and\ngraph theory, which emphasizes their importance for many applications. In this\nwork we present a fully-dynamic algorithm that efficiently maintains a cut tree\nfor a changing graph. The algorithm is easy to implement and has a high\npotential for saving cut computations under the assumption that a local change\nin the underlying graph does rarely affect the global cut structure. We\ndocument the good practicability of our approach in a brief experiment on real\nworld data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 08:15:28 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Hartmann", "Tanja", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1310.0395", "submitter": "Wajeb Gharibi", "authors": "Wajeb Gharibi, Marwah Mohammed Bakri", "title": "Protein Threading Based on Nonlinear Integer Programming", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1204.4562", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein threading is a method of computational protein structure prediction\nused for protein sequences which have the same fold as proteins of known\nstructures but do not have homologous proteins with known structure. The most\npopular algorithm is based on linear integer programming. In this paper, we\nconsider methods based on nonlinear integer programming. Actually, the existing\nlinear integer programming is directly linearized from the original quadratic\ninteger programming. We then develop corresponding efficient algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 17:03:06 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Gharibi", "Wajeb", ""], ["Bakri", "Marwah Mohammed", ""]]}, {"id": "1310.0398", "submitter": "Lin Chen", "authors": "Lin Chen, Klaus Jansen, Guochuan Zhang", "title": "On the optimality of approximation schemes for the classical scheduling\n  problem", "comments": "33 pages, to appear in SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical scheduling problem on parallel identical machines\nto minimize the makespan, and achieve the following results under the\nExponential Time Hypothesis (ETH)\n  1. The scheduling problem on a constant number $m$ of identical machines,\nwhich is denoted as $Pm||C_{max}$, is known to admit a fully polynomial time\napproximation scheme (FPTAS) of running time $O(n) + (1/\\epsilon)^{O(m)}$\n(indeed, the algorithm works for an even more general problem where machines\nare unrelated). We prove this algorithm is essentially the best possible in the\nsense that a $(1/\\epsilon)^{O(m^{1-\\delta})}+n^{O(1)}$ time FPTAS for any\n$\\delta>0$ implies that ETH fails.\n  2. The scheduling problem on an arbitrary number of identical machines, which\nis denoted as $P||C_{max}$, is known to admit a polynomial time approximation\nscheme (PTAS) of running time $2^{O(1/\\epsilon^2\\log^3(1/\\epsilon))}+n^{O(1)}$.\nWe prove this algorithm is nearly optimal in the sense that a\n$2^{O((1/\\epsilon)^{1-\\delta})}+n^{O(1)}$ time PTAS for any $\\delta>0$ implies\nthat ETH fails, leaving a small room for improvement.\n  To obtain these results we will provide two new reductions from 3SAT, one for\n$Pm||C_{max}$ and another for $P||C_{max}$. Indeed, the new reductions explore\nthe structure of scheduling problems and can also lead to other interesting\nresults. For example, using the framework of our reduction for $P||C_{max}$,\nChen et al. (arXiv:1306.3727) is able to prove the APX-hardness of the\nscheduling problem in which the matrix of job processing times\n$P=(p_{ij})_{m\\times n}$ is of rank 3, solving the open problem mentioned by\nBhaskara et al. (SODA 2013).\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 17:25:57 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Chen", "Lin", ""], ["Jansen", "Klaus", ""], ["Zhang", "Guochuan", ""]]}, {"id": "1310.1048", "submitter": "Jean-Lou De Carufel", "authors": "Prosenjit Bose, Jean-Lou De Carufel and Stephane Durocher", "title": "Revisiting the Problem of Searching on a Line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of searching for a target at an unknown location on a\nline when given upper and lower bounds on the distance D that separates the\ninitial position of the searcher from the target. Prior to this work, only\nasymptotic bounds were known for the optimal competitive ratio achievable by\nany search strategy in the worst case. We present the first tight bounds on the\nexact optimal competitive ratio achievable, parameterized in terms of the given\nbounds on D, along with an optimal search strategy that achieves this\ncompetitive ratio. We prove that this optimal strategy is unique. We\ncharacterize the conditions under which an optimal strategy can be computed\nexactly and, when it cannot, we explain how numerical methods can be used\nefficiently. In addition, we answer several related open questions, including\nthe maximal reach problem, and we discuss how to generalize these results to m\nrays, for any m >= 2.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2013 15:05:58 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Bose", "Prosenjit", ""], ["De Carufel", "Jean-Lou", ""], ["Durocher", "Stephane", ""]]}, {"id": "1310.1076", "submitter": "Ping Li", "authors": "Ping Li, Cun-Hui Zhang, Tong Zhang", "title": "Compressed Counting Meets Compressed Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (sparse signal recovery) has been a popular and important\nresearch topic in recent years. By observing that natural signals are often\nnonnegative, we propose a new framework for nonnegative signal recovery using\nCompressed Counting (CC). CC is a technique built on maximally-skewed p-stable\nrandom projections originally developed for data stream computations. Our\nrecovery procedure is computationally very efficient in that it requires only\none linear scan of the coordinates. Our analysis demonstrates that, when\n0<p<=0.5, it suffices to use M= O(C/eps^p log N) measurements so that all\ncoordinates will be recovered within eps additive precision, in one scan of the\ncoordinates. The constant C=1 when p->0 and C=pi/2 when p=0.5. In particular,\nwhen p->0 the required number of measurements is essentially M=K\\log N, where K\nis the number of nonzero coordinates of the signal.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 19:48:44 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Li", "Ping", ""], ["Zhang", "Cun-Hui", ""], ["Zhang", "Tong", ""]]}, {"id": "1310.1440", "submitter": "Dekel Tsur", "authors": "Gregory Kucherov, Kamil Salikhov and Dekel Tsur", "title": "Approximate String Matching using a Bidirectional Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study strategies of approximate pattern matching that exploit\nbidirectional text indexes, extending and generalizing ideas of Lam et al. We\nintroduce a formalism, called search schemes, to specify search strategies of\nthis type, then develop a probabilistic measure for the efficiency of a search\nscheme, prove several combinatorial results on efficient search schemes, and\nfinally, provide experimental computations supporting the superiority of our\nstrategies.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 04:24:28 GMT"}, {"version": "v2", "created": "Sat, 8 Mar 2014 20:15:05 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2015 04:16:41 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Kucherov", "Gregory", ""], ["Salikhov", "Kamil", ""], ["Tsur", "Dekel", ""]]}, {"id": "1310.1448", "submitter": "Keisuke Goto", "authors": "Keisuke Goto, Hideo Bannai", "title": "Space Efficient Linear Time Lempel-Ziv Factorization on\n  Constant~Size~Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for computing the Lempel-Ziv Factorization (LZ77)\nof a given string of length $N$ in linear time, that utilizes only $N\\log N +\nO(1)$ bits of working space, i.e., a single integer array, for constant size\ninteger alphabets. This greatly improves the previous best space requirement\nfor linear time LZ77 factorization (K\\\"arkk\\\"ainen et al. CPM 2013), which\nrequires two integer arrays of length $N$. Computational experiments show that\ndespite the added complexity of the algorithm, the speed of the algorithm is\nonly around twice as slow as previous fastest linear time algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 06:10:43 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Goto", "Keisuke", ""], ["Bannai", "Hideo", ""]]}, {"id": "1310.1493", "submitter": "Tselil Schramm", "authors": "Prasad Raghavendra and Tselil Schramm", "title": "Gap Amplification for Small-Set Expansion via Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we achieve gap amplification for the Small-Set Expansion\nproblem. Specifically, we show that an instance of the Small-Set Expansion\nProblem with completeness $\\epsilon$ and soundness $\\frac{1}{2}$ is at least as\ndifficult as Small-Set Expansion with completeness $\\epsilon$ and soundness\n$f(\\epsilon)$, for any function $f(\\epsilon)$ which grows faster than\n$\\sqrt{\\epsilon}$. We achieve this amplification via random walks -- our gadget\nis the graph with adjacency matrix corresponding to a random walk on the\noriginal graph. An interesting feature of our reduction is that unlike gap\namplification via parallel repetition, the size of the instances (number of\nvertices) produced by the reduction remains the same.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 16:35:35 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 17:34:55 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 07:18:59 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Schramm", "Tselil", ""]]}, {"id": "1310.1649", "submitter": "David Haws", "authors": "David Haws", "title": "QuickLexSort: An efficient algorithm for lexicographically sorting\n  nested restrictions of a database", "comments": "17, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicographical sorting is a fundamental problem with applications to\ncontingency tables, databases, Bayesian networks, and more. A standard method\nto lexicographically sort general data is to iteratively use a stable sort -- a\nsort which preserves existing orders. Here we present a new method of\nlexicographical sorting called QuickLexSort. Whereas a stable sort based\nlexicographical sorting algorithm operates from the least important to most\nimportant features, in contrast, QuickLexSort sorts from the most important to\nleast important features, refining the sort as it goes. QuickLexSort first\nrequires a one-time modest pre-processing step where each feature of the data\nset is sorted independently. When lexicographically sorting a database,\nQuickLexSort (including pre-processing) has comparable running time to using a\nstable sort based approach. For a data base with $m$ rows and $n$ columns, and\na sorting algorithm running in time $O(mlog(m))$, a stable sort based\nlexicographical sort and QuickLexSort will both take time $O(nmlog(m))$.\nHowever in many applications one has the need to lexicographically sort nested\ndata, e.g.\\ all possible sub-matrices up to a certain cardinality of columns.\nIn such cases we show QuickLexSort gives a performance improvement of a log\nfactor of the database length (rows in matrix) over using a standard stable\nsort based approach. E.g.\\ to sort all sub-matrices up to cardinality $k$,\nQuickLexSort has running time $O(mn^k)$ whereas a stable sort based\nlexicographical sort will take time $O(mlog(m)n^k)$. After the pre-processing\nstep that is run only once for the entire matrix, QuickLexSort has a running\ntime linear in the number of nested sub-matrices to sort. We conclude with an\napplication to Bayesian network scoring to detect epistasis using SNP marker\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2013 23:55:57 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Haws", "David", ""]]}, {"id": "1310.1845", "submitter": "Therese Biedl", "authors": "Therese Biedl", "title": "On triangulating k-outerplanar graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A k-outerplanar graph is a graph that can be drawn in the plane without\ncrossing such that after k-fold removal of the vertices on the outer-face there\nare no vertices left. In this paper, we study how to triangulate a\nk-outerplanar graph while keeping its outerplanarity small. Specifically, we\nshow that not all k-outerplanar graphs can be triangulated so that the result\nis k-outerplanar, but they can be triangulated so that the result is\n(k+1)-outerplanar.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 16:12:49 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2013 18:22:14 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Biedl", "Therese", ""]]}, {"id": "1310.1896", "submitter": "Jos\\'e A. Soto", "authors": "Jos\\'e R. Correa, Omar Larr\\'e, and Jos\\'e A. Soto", "title": "TSP Tours in Cubic Graphs: Beyond 4/3", "comments": "23 pages. A preliminary version appeared in ESA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a sequence of improvements Boyd, Sitters, van der Ster, and Stougie\nproved that any 2-connected graph whose n vertices have degree 3, i.e., a cubic\n2-connected graph, has a Hamiltonian tour of length at most (4/3)n,\nestablishing in particular that the integrality gap of the subtour LP is at\nmost 4/3 for cubic 2-connected graphs and matching the conjectured value of the\nfamous 4/3 conjecture. In this paper we improve upon this result by designing\nan algorithm that finds a tour of length (4/3 - 1/61236)n, implying that cubic\n2-connected graphs are among the few interesting classes of graphs for which\nthe integrality gap of the subtour LP is strictly less than 4/3. With the\nprevious result, and by considering an even smaller epsilon, we show that the\nintegrality gap of the TSP relaxation is at most 4/3 - epsilon, even if the\ngraph is not 2-connected (i.e. for cubic connected graphs), implying that the\napproximability threshold of the TSP in cubic graphs is strictly below 4/3.\nFinally, using similar techniques we show, as an additional result, that every\nBarnette graph admits a tour of length at most (4/3 - 1/18)n.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 19:35:53 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Correa", "Jos\u00e9 R.", ""], ["Larr\u00e9", "Omar", ""], ["Soto", "Jos\u00e9 A.", ""]]}, {"id": "1310.1971", "submitter": "Frederic Gillet", "authors": "Frederic Gillet", "title": "Solving 3-SAT and 3-dimensional matching in polynomial time", "comments": "The proposed method does not work. Updated the article with an\n  analysis of why the general method suggested cannot work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the implementation of conservative logic gates on flow networks\nsuggests a way to solve 3SAT and 3-dimensional matching problems in polynomial\ntime by using standard minimum-cost flow methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 22:56:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 14:37:38 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2013 04:11:53 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2013 14:11:43 GMT"}, {"version": "v5", "created": "Wed, 27 Nov 2013 19:51:07 GMT"}, {"version": "v6", "created": "Tue, 4 Feb 2014 20:07:45 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Gillet", "Frederic", ""]]}, {"id": "1310.2026", "submitter": "Ramji Venkataramanan", "authors": "Ramji Venkataramanan, Vasuki Narasimha Swamy, and Kannan Ramchandran", "title": "Low-Complexity Interactive Algorithms for Synchronization from\n  Deletions, Insertions, and Substitutions", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, vol. 61, no. 10, pp.\n  5670-5689, October 2015", "doi": "10.1109/TIT.2015.2466635", "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider two remote nodes having binary sequences $X$ and $Y$, respectively.\n$Y$ is an edited version of ${X}$, where the editing involves random deletions,\ninsertions, and substitutions, possibly in bursts. The goal is for the node\nwith $Y$ to reconstruct $X$ with minimal exchange of information over a\nnoiseless link. The communication is measured in terms of both the total number\nof bits exchanged and the number of interactive rounds of communication.\n  This paper focuses on the setting where the number of edits is\n$o(\\tfrac{n}{\\log n})$, where $n$ is the length of $X$. We first consider the\ncase where the edits are a mixture of insertions and deletions (indels), and\npropose an interactive synchronization algorithm with near-optimal\ncommunication rate and average computational complexity of $O(n)$ arithmetic\noperations. The algorithm uses interaction to efficiently split the source\nsequence into substrings containing exactly one deletion or insertion. Each of\nthese substrings is then synchronized using an optimal one-way synchronization\ncode based on the single-deletion correcting channel codes of Varshamov and\nTenengolts (VT codes).\n  We then build on this synchronization algorithm in three different ways.\nFirst, it is modified to work with a single round of interaction. The reduction\nin the number of rounds comes at the expense of higher communication, which is\nquantified. Next, we present an extension to the practically important case\nwhere the insertions and deletions may occur in (potentially large) bursts.\nFinally, we show how to synchronize the sources to within a target Hamming\ndistance. This feature can be used to differentiate between substitution and\nindel edits. In addition to theoretical performance bounds, we provide several\nvalidating simulation results for the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 08:03:46 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 14:53:46 GMT"}, {"version": "v3", "created": "Mon, 7 Jul 2014 14:05:02 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2015 02:58:46 GMT"}, {"version": "v5", "created": "Tue, 28 Jul 2015 05:26:12 GMT"}, {"version": "v6", "created": "Sat, 12 Sep 2015 09:41:24 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Venkataramanan", "Ramji", ""], ["Swamy", "Vasuki Narasimha", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1310.2118", "submitter": "Loukas Georgiadis", "authors": "Wojciech Fraczak, Loukas Georgiadis, Andrew Miller, Robert E. Tarjan", "title": "Finding Dominators via Disjoint Set Union", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding dominators in a directed graph has many important\napplications, notably in global optimization of computer code. Although linear\nand near-linear-time algorithms exist, they use sophisticated data structures.\nWe develop an algorithm for finding dominators that uses only a \"static tree\"\ndisjoint set data structure in addition to simple lists and maps. The algorithm\nruns in near-linear or linear time, depending on the implementation of the\ndisjoint set data structure. We give several versions of the algorithm,\nincluding one that computes loop nesting information (needed in many kinds of\nglobal code optimization) and that can be made self-certifying, so that the\ncorrectness of the computed dominators is very easy to verify.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 12:53:57 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Fraczak", "Wojciech", ""], ["Georgiadis", "Loukas", ""], ["Miller", "Andrew", ""], ["Tarjan", "Robert E.", ""]]}, {"id": "1310.2322", "submitter": "Morgan Chopin", "authors": "Janka Chleb\\'ikov\\'a and Morgan Chopin", "title": "The Firefighter Problem: A Structural Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity of the firefighter problem where b>=1 firefighters\nare available at each time step. This problem is proved NP-complete even on\ntrees of degree at most three and budget one (Finbow et al.,2007) and on trees\nof bounded degree b+3 for any fixed budget b>=2 (Bazgan et al.,2012). In this\npaper, we provide further insight into the complexity landscape of the problem\nby showing that the pathwidth and the maximum degree of the input graph govern\nits complexity. More precisely, we first prove that the problem is NP-complete\neven on trees of pathwidth at most three for any fixed budget b>=1. We then\nshow that the problem turns out to be fixed parameter-tractable with respect to\nthe combined parameter \"pathwidth\" and \"maximum degree\" of the input graph.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 01:39:10 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2014 07:49:59 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Chleb\u00edkov\u00e1", "Janka", ""], ["Chopin", "Morgan", ""]]}, {"id": "1310.2378", "submitter": "Dimitrios Thilikos", "authors": "Isolde Adler, Stavros G. Kolliopoulos, Philipp Klaus Krause, Daniel\n  Lokshtanov, Saket Saurabhh, Dimitrios M. Thilikos", "title": "Irrelevant Vertices for the Planar Disjoint Paths Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Disjoint Paths Problem asks, given a graph $G$ and a set of pairs of\nterminals $(s_{1},t_{1}),\\ldots,(s_{k},t_{k})$, whether there is a collection\nof $k$ pairwise vertex-disjoint paths linking $s_{i}$ and $t_{i}$, for\n$i=1,\\ldots,k.$ In their $f(k)\\cdot n^{3}$ algorithm for this problem,\nRobertson and Seymour introduced the irrelevant vertex technique according to\nwhich in every instance of treewidth greater than $g(k)$ there is an\n\"irrelevant\" vertex whose removal creates an equivalent instance of the\nproblem. This fact is based on the celebrated Unique Linkage Theorem, whose -\nvery technical - proof gives a function $g(k)$ that is responsible for an\nimmense parameter dependence in the running time of the algorithm. In this\npaper we give a new and self-contained proof of this result that strongly\nexploits the combinatorial properties of planar graphs and achieves\n$g(k)=O(k^{3/2}\\cdot 2^{k}).$ Our bound is radically better than the bounds\nknown for general graphs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 07:27:46 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2015 12:26:56 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 11:11:08 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 11:10:34 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Adler", "Isolde", ""], ["Kolliopoulos", "Stavros G.", ""], ["Krause", "Philipp Klaus", ""], ["Lokshtanov", "Daniel", ""], ["Saurabhh", "Saket", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1310.2386", "submitter": "Bartosz Rybicki", "authors": "Jaroslaw Byrka, Shanfei Li, Bartosz Rybicki", "title": "Improved approximation algorithm for k-level UFL with penalties, a\n  simplistic view on randomizing the scaling parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in approximation algorithms for facility location\nproblems are complicated combinations of various techniques. In particular, the\ncurrently best 1.488-approximation algorithm for the uncapacitated facility\nlocation (UFL) problem by Shi Li is presented as a result of a non-trivial\nrandomization of a certain scaling parameter in the LP-rounding algorithm by\nChudak and Shmoys combined with a primal-dual algorithm of Jain et al. In this\npaper we first give a simple interpretation of this randomization process in\nterms of solving an aux- iliary (factor revealing) LP. Then, armed with this\nsimple view point, Abstract. we exercise the randomization on a more\ncomplicated algorithm for the k-level version of the problem with penalties in\nwhich the planner has the option to pay a penalty instead of connecting chosen\nclients, which results in an improved approximation algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 08:09:20 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Byrka", "Jaroslaw", ""], ["Li", "Shanfei", ""], ["Rybicki", "Bartosz", ""]]}, {"id": "1310.2387", "submitter": "Bodo Manthey", "authors": "Kamiel Cornelissen, Ruben Hoeksma, Bodo Manthey, N. S. Narayanaswamy,\n  C. S. Rahul", "title": "Approximability of Connected Factors", "comments": "To appear in the proceedings of WAOA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a d-regular spanning subgraph (or d-factor) of a graph is easy by\nTutte's reduction to the matching problem. By the same reduction, it is easy to\nfind a minimal or maximal d-factor of a graph. However, if we require that the\nd-factor is connected, these problems become NP-hard - finding a minimal\nconnected 2-factor is just the traveling salesman problem (TSP).\n  Given a complete graph with edge weights that satisfy the triangle\ninequality, we consider the problem of finding a minimal connected $d$-factor.\nWe give a 3-approximation for all $d$ and improve this to an\n(r+1)-approximation for even d, where r is the approximation ratio of the TSP.\nThis yields a 2.5-approximation for even d. The same algorithm yields an\n(r+1)-approximation for the directed version of the problem, where r is the\napproximation ratio of the asymmetric TSP. We also show that none of these\nminimization problems can be approximated better than the corresponding TSP.\n  Finally, for the decision problem of deciding whether a given graph contains\na connected d-factor, we extend known hardness results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 08:23:13 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Cornelissen", "Kamiel", ""], ["Hoeksma", "Ruben", ""], ["Manthey", "Bodo", ""], ["Narayanaswamy", "N. S.", ""], ["Rahul", "C. S.", ""]]}, {"id": "1310.2711", "submitter": "Mohammad Hajiaghayi", "authors": "Mohammad T. Hajiaghayi and Rohit Khandekar and Guy Kortsarz", "title": "Fixed Parameter Inapproximability for Clique and SetCover in Time\n  Super-exponential in OPT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider proving inapproximability in terms of OPT and thus\nwe base the foundations of fixed parameter inapproximability.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 06:08:03 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 01:13:16 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Hajiaghayi", "Mohammad T.", ""], ["Khandekar", "Rohit", ""], ["Kortsarz", "Guy", ""]]}, {"id": "1310.2745", "submitter": "Arnaud de Mesmay", "authors": "\\'Eric Colin de Verdi\\`ere, Arnaud de Mesmay", "title": "Testing Graph Isotopy on Surfaces", "comments": "31 pages, to appear in Discrete and Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the following problem: Given two embeddings G_1 and G_2 of the\nsame abstract graph G on an orientable surface S, decide whether G_1 and G_2\nare isotopic; in other words, whether there exists a continuous family of\nembeddings between G_1 and G_2. We provide efficient algorithms to solve this\nproblem in two models. In the first model, the input consists of the\narrangement of G_1 (resp., G_2) with a fixed graph cellularly embedded on S;\nour algorithm is linear in the input complexity, and thus, optimal. In the\nsecond model, G_1 and G_2 are piecewise-linear embeddings in the plane minus a\nfinite set of points; our algorithm runs in O(n^{3/2}\\log n) time, where n is\nthe complexity of the input. The graph isotopy problem is a natural variation\nof the homotopy problem for closed curves on surfaces and on the punctured\nplane, for which algorithms have been given by various authors; we use some of\nthese algorithms as a subroutine. As a by-product, we reprove the following\nmathematical characterization, first observed by Ladegaillerie (1984): Two\ngraph embeddings are isotopic if and only if they are homotopic and congruent\nby an oriented homeomorphism.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 09:38:31 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["de Verdi\u00e8re", "\u00c9ric Colin", ""], ["de Mesmay", "Arnaud", ""]]}, {"id": "1310.2778", "submitter": "Guillaume Cheze", "authors": "Alin Bostan (INRIA Saclay - Ile de France, MSR - INRIA), Guillaume\n  Ch\\`eze (IMT), Thomas Cluzeau (XLIM), Jacques-Arthur Weil (XLIM)", "title": "Efficient Algorithms for Computing Rational First Integrals and Darboux\n  Polynomials of Planar Polynomial Vector Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS math.CA nlin.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fast algorithms for computing rational first integrals with\nbounded degree of a planar polynomial vector field. Our approach is inspired by\nan idea of Ferragut and Giacomini. We improve upon their work by proving that\nrational first integrals can be computed via systems of linear equations\ninstead of systems of quadratic equations. This leads to a probabilistic\nalgorithm with arithmetic complexity $\\bigOsoft(N^{2 \\omega})$ and to a\ndeterministic algorithm solving the problem in $\\bigOsoft(d^2N^{2 \\omega+1})$\narithmetic operations, where $N$ denotes the given bound for the degree of the\nrational first integral, and where $d \\leq N$ is the degree of the vector\nfield, and $\\omega$ the exponent of linear algebra. We also provide a fast\nheuristic variant which computes a rational first integral, or fails, in\n$\\bigOsoft(N^{\\omega+2})$ arithmetic operations. By comparison, the best\nprevious algorithm uses at least $d^{\\omega+1}\\, N^{4\\omega +4}$ arithmetic\noperations. We then show how to apply a similar method to the computation of\nDarboux polynomials. The algorithms are implemented in a Maple package which is\navailable to interested readers with examples showing its efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 11:39:24 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Bostan", "Alin", "", "INRIA Saclay - Ile de France, MSR - INRIA"], ["Ch\u00e8ze", "Guillaume", "", "IMT"], ["Cluzeau", "Thomas", "", "XLIM"], ["Weil", "Jacques-Arthur", "", "XLIM"]]}, {"id": "1310.2841", "submitter": "Magnus Wahlstr\\\"om", "authors": "Yoichi Iwata and Magnus Wahlstr\\\"om and Yuichi Yoshida", "title": "Half-integrality, LP-branching and FPT Algorithms", "comments": "Added results on linear-time FPT algorithms (not present in SODA\n  paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend in parameterized algorithms is the application of polytope\ntools (specifically, LP-branching) to FPT algorithms (e.g., Cygan et al., 2011;\nNarayanaswamy et al., 2012). However, although interesting results have been\nachieved, the methods require the underlying polytope to have very restrictive\nproperties (half-integrality and persistence), which are known only for few\nproblems (essentially Vertex Cover (Nemhauser and Trotter, 1975) and Node\nMultiway Cut (Garg et al., 1994)). Taking a slightly different approach, we\nview half-integrality as a \\emph{discrete} relaxation of a problem, e.g., a\nrelaxation of the search space from $\\{0,1\\}^V$ to $\\{0,1/2,1\\}^V$ such that\nthe new problem admits a polynomial-time exact solution. Using tools from CSP\n(in particular Thapper and \\v{Z}ivn\\'y, 2012) to study the existence of such\nrelaxations, we provide a much broader class of half-integral polytopes with\nthe required properties, unifying and extending previously known cases.\n  In addition to the insight into problems with half-integral relaxations, our\nresults yield a range of new and improved FPT algorithms, including an\n$O^*(|\\Sigma|^{2k})$-time algorithm for node-deletion Unique Label Cover with\nlabel set $\\Sigma$ and an $O^*(4^k)$-time algorithm for Group Feedback Vertex\nSet, including the setting where the group is only given by oracle access. All\nthese significantly improve on previous results. The latter result also implies\nthe first single-exponential time FPT algorithm for Subset Feedback Vertex Set,\nanswering an open question of Cygan et al. (2012).\n  Additionally, we propose a network flow-based approach to solve some cases of\nthe relaxation problem. This gives the first linear-time FPT algorithm to\nedge-deletion Unique Label Cover.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 14:49:10 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2014 14:04:02 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["Iwata", "Yoichi", ""], ["Wahlstr\u00f6m", "Magnus", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1310.3252", "submitter": "Robert Krauthgamer", "authors": "Alexandr Andoni, Anupam Gupta, Robert Krauthgamer", "title": "Towards (1+\\epsilon)-Approximate Flow Sparsifiers", "comments": "Full version of a paper accepted to SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A useful approach to \"compress\" a large network $G$ is to represent it with a\n{\\em flow-sparsifier}, i.e., a small network $H$ that supports the same flows\nas $G$, up to a factor $q \\geq 1$ called the quality of sparsifier.\nSpecifically, we assume the network $G$ contains a set of $k$ terminals $T$,\nshared with the network $H$, i.e., $T\\subseteq V(G)\\cap V(H)$, and we want $H$\nto preserve all multicommodity flows that can be routed between the terminals\n$T$. The challenge is to construct $H$ that is small.\n  These questions have received a lot of attention in recent years, leading to\nsome known tradeoffs between the sparsifier's quality $q$ and its size\n$|V(H)|$. Nevertheless, it remains an outstanding question whether every $G$\nadmits a flow-sparsifier $H$ with quality $q=1+\\epsilon$, or even $q=O(1)$, and\nsize $|V(H)|\\leq f(k,\\epsilon)$ (in particular, independent of $|V(G)|$ and the\nedge capacities). Making a first step in this direction, we present new\nconstructions for several scenarios:\n  * Our main result is that for quasi-bipartite networks $G$, one can construct\na $(1+\\epsilon)$-flow-sparsifier of size $\\poly(k/\\eps)$. In contrast, exact\n($q=1$) sparsifiers for this family of networks are known to require size\n$2^{\\Omega(k)}$.\n  * For networks $G$ of bounded treewidth $w$, we construct a flow-sparsifier\nwith quality $q=O(\\log w / \\log\\log w)$ and size $O(w\\cdot \\poly(k))$.\n  * For general networks $G$, we construct a {\\em sketch} $sk(G)$, that stores\nall the feasible multicommodity flows up to factor $q=1+\\eps$, and its size\n(storage requirement) is $f(k,\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 19:23:21 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Andoni", "Alexandr", ""], ["Gupta", "Anupam", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1310.3314", "submitter": "Hung Ngo", "authors": "Hung Q. Ngo and Christopher Re and Atri Rudra", "title": "Skew Strikes Back: New Developments in the Theory of Join Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the relational join is one of the central algorithmic and most\nwell-studied problems in database systems. A staggering number of variants have\nbeen considered including Block-Nested loop join, Hash-Join, Grace, Sort-merge\nfor discussions of more modern issues). Commercial database engines use finely\ntuned join heuristics that take into account a wide variety of factors\nincluding the selectivity of various predicates, memory, IO, etc. In spite of\nthis study of join queries, the textbook description of join processing is\nsuboptimal. This survey describes recent results on join algorithms that have\nprovable worst-case optimality runtime guarantees. We survey recent work and\nprovide a simpler and unified description of these algorithms that we hope is\nuseful for theory-minded readers, algorithm designers, and systems\nimplementors.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 00:08:02 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2013 15:39:40 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Ngo", "Hung Q.", ""], ["Re", "Christopher", ""], ["Rudra", "Atri", ""]]}, {"id": "1310.3341", "submitter": "Pawel Rzazewski", "authors": "Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Exact Algorithm for Graph Homomorphism and Locally Injective Graph\n  Homomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs $G$ and $H$, a homomorphism from $G$ to $H$ is a function $\\varphi\n\\colon V(G) \\to V(H)$, which maps vertices adjacent in $G$ to adjacent vertices\nof $H$. A homomorphism is locally injective if no two vertices with a common\nneighbor are mapped to a single vertex in $H$. Many cases of graph homomorphism\nand locally injective graph homomorphism are NP-complete, so there is little\nhope to design polynomial-time algorithms for them. In this paper we present an\nalgorithm for graph homomorphism and locally injective homomorphism working in\ntime $\\mathcal{O}^*((b + 2)^{|V(G)|})$, where $b$ is the bandwidth of the\ncomplement of $H$.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 06:01:45 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1310.3353", "submitter": "Gunnar W. Klau", "authors": "Thomas Bellitto and Tobias Marschall and Alexander Sch\\\"onhuth and\n  Gunnar W. Klau", "title": "Next Generation Cluster Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at improving the quality of structural variant prediction from\nthe mapped reads of a sequenced genome. We suggest a new model based on cluster\nediting in weighted graphs and introduce a new heuristic algorithm that allows\nto solve this problem quickly and with a good approximation on the huge graphs\nthat arise from biological datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 09:34:30 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Bellitto", "Thomas", ""], ["Marschall", "Tobias", ""], ["Sch\u00f6nhuth", "Alexander", ""], ["Klau", "Gunnar W.", ""]]}, {"id": "1310.3486", "submitter": "Varsha Dani", "authors": "Varsha Dani, Valerie King, Mahnush Movahedi and Jared Saia", "title": "Quorums Quicken Queries: Efficient Asynchronous Secure Multiparty\n  Computation", "comments": "ICDCN version: 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an asynchronous algorithm to solve secure multiparty computation\n(MPC) over n players, when strictly less than a 1/8 fraction of the players are\ncontrolled by a static adversary. For any function f over a field that can be\ncomputed by a circuit with m gates, our algorithm requires each player to send\na number of field elements and perform an amount of computation that is O (m/n\n+ \\sqrt{n}). This significantly improves over traditional algorithms, which\nrequire each player to both send a number of messages and perform computation\nthat is {\\Omega}(nm). Additionally, we define the threshold counting problem\nand present a distributed algorithm to solve it in the asynchronous\ncommunication model. Our algorithm is load balanced, with computation,\ncommunication and latency complexity of O(log n), and may be of independent\ninterest to other applications with a load balancing goal in mind.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2013 14:29:24 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Dani", "Varsha", ""], ["King", "Valerie", ""], ["Movahedi", "Mahnush", ""], ["Saia", "Jared", ""]]}, {"id": "1310.3580", "submitter": "Wanrong Tang", "authors": "Wanrong Tang, Suzhi Bi and Ying Jun (Angela) Zhang", "title": "Online Coordinated Charging Decision Algorithm for Electric Vehicles\n  without Future Information", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large-scale integration of plug-in electric vehicles (PEVs) to the power\ngrid spurs the need for efficient charging coordination mechanisms. It can be\nshown that the optimal charging schedule smooths out the energy consumption\nover time so as to minimize the total energy cost. In practice, however, it is\nhard to smooth out the energy consumption perfectly, because the future PEV\ncharging demand is unknown at the moment when the charging rate of an existing\nPEV needs to be determined. In this paper, we propose an Online cooRdinated\nCHARging Decision (ORCHARD) algorithm, which minimizes the energy cost without\nknowing the future information. Through rigorous proof, we show that ORCHARD is\nstrictly feasible in the sense that it guarantees to fulfill all charging\ndemands before due time. Meanwhile, it achieves the best known competitive\nratio of 2.39. To further reduce the computational complexity of the algorithm,\nwe propose a novel reduced-complexity algorithm to replace the standard convex\noptimization techniques used in ORCHARD. Through extensive simulations, we show\nthat the average performance gap between ORCHARD and the offline optimal\nsolution, which utilizes the complete future information, is as small as 14%.\nBy setting a proper speeding factor, the average performance gap can be further\nreduced to less than 6%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 07:27:33 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2013 06:05:26 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2013 03:21:19 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2013 14:30:38 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Tang", "Wanrong", "", "Angela"], ["Bi", "Suzhi", "", "Angela"], ["Jun", "Ying", "", "Angela"], ["Zhang", "", ""]]}, {"id": "1310.3609", "submitter": "Sean Sedwards", "authors": "Axel Legay, Sean Sedwards and Louis-Marie Traonouez", "title": "Scalable Verification of Markov Decision Processes", "comments": "V4: FMDS version, 12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDP) are useful to model concurrent process\noptimisation problems, but verifying them with numerical methods is often\nintractable. Existing approximative approaches do not scale well and are\nlimited to memoryless schedulers. Here we present the basis of scalable\nverification for MDPSs, using an O(1) memory representation of\nhistory-dependent schedulers. We thus facilitate scalable learning techniques\nand the use of massively parallel verification.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 09:50:49 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 13:17:58 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2014 07:31:27 GMT"}, {"version": "v4", "created": "Wed, 17 Sep 2014 11:07:09 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Legay", "Axel", ""], ["Sedwards", "Sean", ""], ["Traonouez", "Louis-Marie", ""]]}, {"id": "1310.3673", "submitter": "Tongu\\c{c} \\\"Unl\\\"uyurt", "authors": "Sarah R. Allen, Lisa Hellerstein, Devorah Kletenik, Tongu\\c{c}\n  \\\"Unl\\\"uyurt", "title": "Evaluation of DNF Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Boolean Function Evaluation (SBFE) is the problem of determining\nthe value of a given Boolean function $f$ on an unknown input $x$, when each\nbit of $x_i$ of $x$ can only be determined by paying a given associated cost\n$c_i$. Further, $x$ is drawn from a given product distribution: for each $x_i$,\n$Prob[x_i=1] = p_i$, and the bits are independent. The goal is to minimize the\nexpected cost of evaluation. Stochastic Boolean Function Evaluation (SBFE) is\nthe problem of determining the value of a given Boolean function $f$ on an\nunknown input $x$, when each bit of $x_i$ of $x$ can only be determined by\npaying a given associated cost $c_i$. Further, $x$ is drawn from a given\nproduct distribution: for each $x_i$, $Prob[x_i=1] = p_i$, and the bits are\nindependent. The goal is to minimize the expected cost of evaluation. In this\npaper, we study the complexity of the SBFE problem for classes of DNF formulas.\nWe consider both exact and approximate versions of the problem for subclasses\nof DNF, for arbitrary costs and product distributions, and for unit costs\nand/or the uniform distribution.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 13:19:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2013 12:38:22 GMT"}, {"version": "v3", "created": "Wed, 8 Oct 2014 14:26:10 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Allen", "Sarah R.", ""], ["Hellerstein", "Lisa", ""], ["Kletenik", "Devorah", ""], ["\u00dcnl\u00fcyurt", "Tongu\u00e7", ""]]}, {"id": "1310.3898", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall and Harumichi Nishimura", "title": "Quantum Algorithms for Matrix Products over Semirings", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we construct quantum algorithms for matrix products over\nseveral algebraic structures called semirings, including the (max,min)-matrix\nproduct, the distance matrix product and the Boolean matrix product. In\nparticular, we obtain the following results.\n  We construct a quantum algorithm computing the product of two n x n matrices\nover the (max,min) semiring with time complexity O(n^{2.473}). In comparison,\nthe best known classical algorithm for the same problem, by Duan and Pettie,\nhas complexity O(n^{2.687}). As an application, we obtain a O(n^{2.473})-time\nquantum algorithm for computing the all-pairs bottleneck paths of a graph with\nn vertices, while classically the best upper bound for this task is\nO(n^{2.687}), again by Duan and Pettie.\n  We construct a quantum algorithm computing the L most significant bits of\neach entry of the distance product of two n x n matrices in time O(2^{0.64L}\nn^{2.46}). In comparison, prior to the present work, the best known classical\nalgorithm for the same problem, by Vassilevska and Williams and Yuster, had\ncomplexity O(2^{L}n^{2.69}). Our techniques lead to further improvements for\nclassical algorithms as well, reducing the classical complexity to\nO(2^{0.96L}n^{2.69}), which gives a sublinear dependency on 2^L.\n  The above two algorithms are the first quantum algorithms that perform better\nthan the $\\tilde O(n^{5/2})$-time straightforward quantum algorithm based on\nquantum search for matrix multiplication over these semirings. We also consider\nthe Boolean semiring, and construct a quantum algorithm computing the product\nof two n x n Boolean matrices that outperforms the best known classical\nalgorithms for sparse matrices. For instance, if the input matrices have\nO(n^{1.686...}) non-zero entries, then our algorithm has time complexity\nO(n^{2.277}), while the best classical algorithm has complexity O(n^{2.373}).\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 01:57:28 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "1310.4127", "submitter": "Seiichiro Tani", "authors": "Fran\\c{c}ois Le Gall, Harumichi Nishimura, Seiichiro Tani", "title": "Quantum Algorithms for Finding Constant-sized Sub-hypergraphs", "comments": "18 pages; v2: changed title, added more backgrounds to the\n  introduction, added another application", "journal-ref": "Theoretical Computer Science 609, pp. 569-582, 2016", "doi": "10.1016/j.tcs.2015.10.006", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general framework to construct quantum algorithms that detect if\na $3$-uniform hypergraph given as input contains a sub-hypergraph isomorphic to\na prespecified constant-sized hypergraph. This framework is based on the\nconcept of nested quantum walks recently proposed by Jeffery, Kothari and\nMagniez [SODA'13], and extends the methodology designed by Lee, Magniez and\nSantha [SODA'13] for similar problems over graphs. As applications, we obtain a\nquantum algorithm for finding a $4$-clique in a $3$-uniform hypergraph on $n$\nvertices with query complexity $O(n^{1.883})$, and a quantum algorithm for\ndetermining if a ternary operator over a set of size $n$ is associative with\nquery complexity $O(n^{2.113})$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 17:44:17 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 00:55:31 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1310.4290", "submitter": "Irena Rusu Ph.D.", "authors": "Irena Rusu", "title": "Extending Common Intervals Searching from Permutations to Sequences", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common intervals have been defined as a modelisation of gene clusters in\ngenomes represented either as permutations or as sequences. Whereas optimal\nalgorithms for finding common intervals in permutations exist even for an\narbitrary number of permutations, in sequences no optimal algorithm has been\nproposed yet even for only two sequences. Surprisingly enough, when sequences\nare reduced to permutations, the existing algorithms perform far from the\noptimum, showing that their performances are not dependent, as they should be,\non the structural complexity of the input sequences.\n  In this paper, we propose to characterize the structure of a sequence by the\nnumber $q$ of different dominating orders composing it (called the domination\nnumber), and to use a recent algorithm for permutations in order to devise a\nnew algorithm for two sequences. Its running time is in\n$O(q_1q_2p+q_1n_1+q_2n_2+N)$, where $n_1, n_2$ are the sizes of the two\nsequences, $q_1,q_2$ are their respective domination numbers, $p$ is the\nalphabet size and $N$ is the number of solutions to output. This algorithm\nperforms better as $q_1$ and/or $q_2$ reduce, and when the two sequences are\nreduced to permutations (i.e. when $q_1=q_2=1$) it has the same running time as\nthe best algorithms for permutations. It is also the first algorithm for\nsequences whose running time involves the parameter size of the solution. As a\ncounterpart, when $q_1$ and $q_2$ are of $O(n_1)$ and $O(n_2)$ respectively,\nthe algorithm is less efficient than other approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 07:58:02 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Rusu", "Irena", ""]]}, {"id": "1310.4366", "submitter": "Dmitry Ignatov", "authors": "Elena Nenova and Dmitry I. Ignatov and Andrey V. Konstantinov", "title": "An FCA-based Boolean Matrix Factorisation for Collaborative Filtering", "comments": "http://ceur-ws.org/Vol-977/paper8.pdf", "journal-ref": "In: C. Carpineto, A. Napoli, S.O. Kuznetsov (eds), FCA Meets IR\n  2013, Vol. 977, CEUR Workshop Proceeding, 2013. P. 57-73", "doi": null, "report-no": null, "categories": "cs.IR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for Collaborative Filtering which is based on\nBoolean Matrix Factorisation (BMF) and Formal Concept Analysis. In a series of\nexperiments on real data (Movielens dataset) we compare the approach with the\nSVD- and NMF-based algorithms in terms of Mean Average Error (MAE). One of the\nexperimental consequences is that it is enough to have a binary-scaled rating\ndata to obtain almost the same quality in terms of MAE by BMF than for the\nSVD-based algorithm in case of non-scaled data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 13:17:37 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Nenova", "Elena", ""], ["Ignatov", "Dmitry I.", ""], ["Konstantinov", "Andrey V.", ""]]}, {"id": "1310.4415", "submitter": "Justin Ward", "authors": "Marek Adamczyk, Maxim Sviridenko, Justin Ward", "title": "Submodular Stochastic Probing on Matroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a stochastic probing problem we are given a universe $E$, where each\nelement $e \\in E$ is active independently with probability $p_e$, and only a\nprobe of e can tell us whether it is active or not. On this universe we execute\na process that one by one probes elements --- if a probed element is active,\nthen we have to include it in the solution, which we gradually construct.\nThroughout the process we need to obey inner constraints on the set of elements\ntaken into the solution, and outer constraints on the set of all probed\nelements. This abstract model was presented by Gupta and Nagarajan (IPCO '13),\nand provides a unified view of a number of problems. Thus far, all the results\nfalling under this general framework pertain mainly to the case in which we are\nmaximizing a linear objective function of the successfully probed elements. In\nthis paper we generalize the stochastic probing problem by considering a\nmonotone submodular objective function. We give a $(1 - 1/e)/(k_{in} +\nk_{out}+1)$-approximation algorithm for the case in which we are given $k_{in}$\nmatroids as inner constraints and $k_{out}$ matroids as outer constraints.\nAdditionally, we obtain an improved $1/(k_{in} + k_{out})$-approximation\nalgorithm for linear objective functions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 15:24:05 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2013 16:01:24 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2014 16:04:52 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 12:18:59 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Adamczyk", "Marek", ""], ["Sviridenko", "Maxim", ""], ["Ward", "Justin", ""]]}, {"id": "1310.4541", "submitter": "Marcelo Cicconet", "authors": "Marcelo Cicconet, Davi Geiger", "title": "A Dynamic Programming Solution to the Monotonic Path of Minimal Cost in\n  a 3-Rows Matrix", "comments": "1 page, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding the path of minimal cost going from left\nto right in a 3-rows matrix, starting at the third row, and not going\ndownwards, where there is an additional cost related to not changing rows, such\nthat the higher the change in intensity within the row, the higher the cost of\nnot moving upwards.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 22:42:31 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Cicconet", "Marcelo", ""], ["Geiger", "Davi", ""]]}, {"id": "1310.4595", "submitter": "EPTCS", "authors": "Keren Censor-Hillel (Technion), Valerie King (University of Victoria)", "title": "Proceedings Ninth International Workshop on Foundations of Mobile\n  Computing", "comments": null, "journal-ref": "EPTCS 132, 2013", "doi": "10.4204/EPTCS.132", "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile communication has become a vigorous field of research in computer\nscience, due to the wide spreading of mobile technologies, applications and\nservices. The intertwining of communication, computation and mobility\nconstantly poses new challenges to algorithmic design in this area. The\nFoundations of Mobile Computing (FOMC) workshop is dedicated to all aspects\nthat cover contributions both in the design and analysis of\ndiscrete/distributed algorithms, and in the system modeling of mobile, wireless\nand similarly dynamic networks. It aims to bring together the practitioners and\ntheoreticians of the field to foster cooperation between research in mobile\ncomputing and algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 07:16:35 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Censor-Hillel", "Keren", "", "Technion"], ["King", "Valerie", "", "University of Victoria"]]}, {"id": "1310.4843", "submitter": "D\\'ora Erd\\H{o}s", "authors": "D\\'ora Erd\\H{o}s, Pauli Miettinen", "title": "Scalable Boolean Tensor Factorizations using Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensors are becoming increasingly common in data mining, and consequently,\ntensor factorizations are becoming more and more important tools for data\nminers. When the data is binary, it is natural to ask if we can factorize it\ninto binary factors while simultaneously making sure that the reconstructed\ntensor is still binary. Such factorizations, called Boolean tensor\nfactorizations, can provide improved interpretability and find Boolean\nstructure that is hard to express using normal factorizations. Unfortunately\nthe algorithms for computing Boolean tensor factorizations do not usually scale\nwell. In this paper we present a novel algorithm for finding Boolean CP and\nTucker decompositions of large and sparse binary tensors. In our experimental\nevaluation we show that our algorithm can handle large tensors and accurately\nreconstructs the latent Boolean structure.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 20:09:48 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Erd\u0151s", "D\u00f3ra", ""], ["Miettinen", "Pauli", ""]]}, {"id": "1310.4908", "submitter": "EPTCS", "authors": "John Augustine (Indian Institute of Technology Madras), Tejas Kulkarni\n  (Indian Institute of Technology Madras), Paresh Nakhe (Indian Institute of\n  Technology Madras), Peter Robinson (Nanyang Technological University)", "title": "Robust Leader Election in a Fast-Changing World", "comments": "In Proceedings FOMC 2013, arXiv:1310.4595", "journal-ref": "EPTCS 132, 2013, pp. 38-49", "doi": "10.4204/EPTCS.132.4", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of electing a leader among nodes in a highly dynamic\nnetwork where the adversary has unbounded capacity to insert and remove nodes\n(including the leader) from the network and change connectivity at will. We\npresent a randomized Las Vegas algorithm that (re)elects a leader in O(D\\log n)\nrounds with high probability, where D is a bound on the dynamic diameter of the\nnetwork and n is the maximum number of nodes in the network at any point in\ntime. We assume a model of broadcast-based communication where a node can send\nonly 1 message of O(\\log n) bits per round and is not aware of the receivers in\nadvance. Thus, our results also apply to mobile wireless ad-hoc networks,\nimproving over the optimal (for deterministic algorithms) O(Dn) solution\npresented at FOMC 2011. We show that our algorithm is optimal by proving that\nany randomized Las Vegas algorithm takes at least omega(D\\log n) rounds to\nelect a leader with high probability, which shows that our algorithm yields the\nbest possible (up to constants) termination time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 04:11:02 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Augustine", "John", "", "Indian Institute of Technology Madras"], ["Kulkarni", "Tejas", "", "Indian Institute of Technology Madras"], ["Nakhe", "Paresh", "", "Indian Institute of\n  Technology Madras"], ["Robinson", "Peter", "", "Nanyang Technological University"]]}, {"id": "1310.4954", "submitter": "Miguel A. Martinez-Prieto", "authors": "Sandra \\'Alvarez-Garc\\'ia and Nieves R. Brisaboa and Javier D.\n  Fern\\'andez and Miguel A. Mart\\'inez-Prieto and Gonzalo Navarro", "title": "Compressed Vertical Partitioning for Full-In-Memory RDF Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web of Data has been gaining momentum and this leads to increasingly\npublish more semi-structured datasets following the RDF model, based on atomic\ntriple units of subject, predicate, and object. Although it is a simple model,\ncompression methods become necessary because datasets are increasingly larger\nand various scalability issues arise around their organization and storage.\nThis requirement is more restrictive in RDF stores because efficient SPARQL\nresolution on the compressed RDF datasets is also required.\n  This article introduces a novel RDF indexing technique (called k2-triples)\nsupporting efficient SPARQL resolution in compressed space. k2-triples, uses\nthe predicate to vertically partition the dataset into disjoint subsets of\npairs (subject, object), one per predicate. These subsets are represented as\nbinary matrices in which 1-bits mean that the corresponding triple exists in\nthe dataset. This model results in very sparse matrices, which are efficiently\ncompressed using k2-trees. We enhance this model with two compact indexes\nlisting the predicates related to each different subject and object, in order\nto address the specific weaknesses of vertically partitioned representations.\nThe resulting technique not only achieves by far the most compressed\nrepresentations, but also the best overall performance for RDF retrieval in our\nexperiments. Our approach uses up to 10 times less space than a state of the\nart baseline, and outperforms its performance by several order of magnitude on\nthe most basic query patterns. In addition, we optimize traditional join\nalgorithms on k2-triples and define a novel one leveraging its specific\nfeatures. Our experimental results show that our technique overcomes\ntraditional vertical partitioning for join resolution, reporting the best\nnumbers for joins in which the non-joined nodes are provided, and being\ncompetitive in the majority of the cases.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 08:58:01 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 09:00:47 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["\u00c1lvarez-Garc\u00eda", "Sandra", ""], ["Brisaboa", "Nieves R.", ""], ["Fern\u00e1ndez", "Javier D.", ""], ["Mart\u00ednez-Prieto", "Miguel A.", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1310.5037", "submitter": "Riccardo Dondi", "authors": "Niko Beerenwinkel, Stefano Beretta, Paola Bonizzoni, Riccardo Dondi,\n  Yuri Pirola", "title": "Covering Pairs in Directed Acyclic Graphs", "comments": null, "journal-ref": "Proc. of Language and Automata Theory and Applications (LATA\n  2014), LNCS Vol. 8370, 2014, pp 126-137", "doi": "10.1007/978-3-319-04921-2_10", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Path Cover problem on directed acyclic graphs (DAGs) is a\nclassical problem that provides a clear and simple mathematical formulation for\nseveral applications in different areas and that has an efficient algorithmic\nsolution. In this paper, we study the computational complexity of two\nconstrained variants of Minimum Path Cover motivated by the recent introduction\nof next-generation sequencing technologies in bioinformatics. The first problem\n(MinPCRP), given a DAG and a set of pairs of vertices, asks for a minimum\ncardinality set of paths \"covering\" all the vertices such that both vertices of\neach pair belong to the same path. For this problem, we show that, while it is\nNP-hard to compute if there exists a solution consisting of at most three\npaths, it is possible to decide in polynomial time whether a solution\nconsisting of at most two paths exists. The second problem (MaxRPSP), given a\nDAG and a set of pairs of vertices, asks for a path containing the maximum\nnumber of the given pairs of vertices. We show its NP-hardness and also its\nW[1]-hardness when parametrized by the number of covered pairs. On the positive\nside, we give a fixed-parameter algorithm when the parameter is the maximum\noverlapping degree, a natural parameter in the bioinformatics applications of\nthe problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 14:33:06 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Beerenwinkel", "Niko", ""], ["Beretta", "Stefano", ""], ["Bonizzoni", "Paola", ""], ["Dondi", "Riccardo", ""], ["Pirola", "Yuri", ""]]}, {"id": "1310.5367", "submitter": "Udi Wieder", "authors": "Kunal Talwar, Udi Wieder", "title": "Balanced Allocations: A Simple Proof for the Heavily Loaded Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a relatively simple proof that the expected gap between the\nmaximum load and the average load in the two choice process is bounded by\n$(1+o(1))\\log \\log n$, irrespective of the number of balls thrown. The theorem\nwas first proven by Berenbrink et al. Their proof uses heavy machinery from\nMarkov-Chain theory and some of the calculations are done using computers. In\nthis manuscript we provide a significantly simpler proof that is not aided by\ncomputers and is self contained. The simplification comes at a cost of weaker\nbounds on the low order terms and a weaker tail bound for the probability of\ndeviating from the expectation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2013 20:15:07 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Talwar", "Kunal", ""], ["Wieder", "Udi", ""]]}, {"id": "1310.5407", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla, Gopal Pandurangan", "title": "Distributed Computation of Sparse Cuts", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding sparse cuts is an important tool in analyzing large-scale distributed\nnetworks such as the Internet and Peer-to-Peer networks, as well as large-scale\ngraphs such as the web graph, online social communities, and VLSI circuits. In\ndistributed communication networks, they are useful for topology maintenance\nand for designing better search and routing algorithms.\n  In this paper, we focus on developing fast distributed algorithms for\ncomputing sparse cuts in networks. Given an undirected $n$-node network $G$\nwith conductance $\\phi$, the goal is to find a cut set whose conductance is\nclose to $\\phi$. We present two distributed algorithms that find a cut set with\nsparsity $\\tilde O(\\sqrt{\\phi})$ ($\\tilde{O}$ hides $\\polylog{n}$ factors).\nBoth our algorithms work in the CONGEST distributed computing model and output\na cut of conductance at most $\\tilde O(\\sqrt{\\phi})$ with high probability, in\n$\\tilde O(\\frac{1}{b}(\\frac{1}{\\phi} + n))$ rounds, where $b$ is balance of the\ncut of given conductance. In particular, to find a sparse cut of constant\nbalance, our algorithms take $\\tilde O(\\frac{1}{\\phi} + n)$ rounds.\n  Our algorithms can also be used to output a {\\em local} cluster, i.e., a\nsubset of vertices near a given source node, and whose conductance is within a\nquadratic factor of the best possible cluster around the specified node. Both\nour distributed algorithm can work without knowledge of the optimal $\\phi$\nvalue and hence can be used to find approximate conductance values both\nglobally and with respect to a given source node. We also give a lower bound on\nthe time needed for any distributed algorithm to compute any non-trivial sparse\ncut --- any distributed approximation algorithm (for any non-trivial\napproximation ratio) for computing sparsest cut will take $\\tilde\n\\Omega(\\sqrt{n} + D)$ rounds, where $D$ is the diameter of the graph.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 03:02:51 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1310.5422", "submitter": "Takuro Fukunaga", "authors": "Takuro Fukunaga", "title": "Spider covers for prize-collecting network activation problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the network activation problem, each edge in a graph is associated with an\nactivation function, that decides whether the edge is activated from\nnode-weights assigned to its end-nodes. The feasible solutions of the problem\nare the node-weights such that the activated edges form graphs of required\nconnectivity, and the objective is to find a feasible solution minimizing its\ntotal weight. In this paper, we consider a prize-collecting version of the\nnetwork activation problem, and present first non- trivial approximation\nalgorithms. Our algorithms are based on a new LP relaxation of the problem.\nThey round optimal solutions for the relaxation by repeatedly computing\nnode-weights activating subgraphs called spiders, which are known to be useful\nfor approximating the network activation problem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 04:33:55 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 02:29:34 GMT"}, {"version": "v3", "created": "Fri, 26 Sep 2014 05:45:41 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Fukunaga", "Takuro", ""]]}, {"id": "1310.5469", "submitter": "Petr Golovach", "authors": "Manfred Cochefert, Jean-Fran\\c{c}ois Couturier, Petr A. Golovach,\n  Dieter Kratsch, and Dani\\\"el Paulusma", "title": "Parameterized Algorithms for Finding Square Roots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the following two problems are fixed-parameter tractable with\nparameter k: testing whether a connected n-vertex graph with m edges has a\nsquare root with at most n-1+k edges and testing whether such a graph has a\nsquare root with at least m-k edges. Our first result implies that squares of\ngraphs obtained from trees by adding at most k edges can be recognized in\npolynomial time for every fixed k>=0; previously this result was known only for\nk=0. Our second result is equivalent to stating that deciding whether a graph\ncan be modified into a square root of itself by at most k edge deletions is\nfixed-parameter tractable with parameter k.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 08:57:19 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Cochefert", "Manfred", ""], ["Couturier", "Jean-Fran\u00e7ois", ""], ["Golovach", "Petr A.", ""], ["Kratsch", "Dieter", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "1310.5786", "submitter": "Chengwei Guo", "authors": "Leizhen Cai, Chengwei Guo", "title": "Contracting Graphs to Split Graphs and Threshold Graphs", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of Split Contraction and Threshold\nContraction. In these problems we are given a graph G and an integer k and\nasked whether G can be modified into a split graph or a threshold graph,\nrespectively, by contracting at most k edges. We present an FPT algorithm for\nSplit Contraction, and prove that Threshold Contraction on split graphs, i.e.,\ncontracting an input split graph to a threshold graph, is FPT when\nparameterized by the number of contractions. To give a complete picture, we\nshow that these two problems admit no polynomial kernels unless NP\\subseteq\ncoNP/poly.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 03:01:41 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Cai", "Leizhen", ""], ["Guo", "Chengwei", ""]]}, {"id": "1310.6019", "submitter": "Andrea Kappes", "authors": "Tobias Fleck, Andrea Kappes and Dorothea Wagner", "title": "Graph Clustering with Surprise: Complexity and Exact Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering graphs based on a comparison of the number of links within\nclusters and the expected value of this quantity in a random graph has gained a\nlot of attention and popularity in the last decade. Recently, Aldecoa and Marin\nproposed a related, but slightly different approach leading to the quality\nmeasure surprise, and reported good behavior in the context of synthetic and\nreal world benchmarks. We show that the problem of finding a clustering with\noptimum surprise is NP-hard. Moreover, a bicriterial view on the problem\npermits to compute optimum solutions for small instances by solving a small\nnumber of integer linear programs, and leads to a polynomial time algorithm on\ntrees.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 15:07:16 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Fleck", "Tobias", ""], ["Kappes", "Andrea", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1310.6084", "submitter": "Md. Iqbal Hossain", "authors": "Md. Iqbal Hossain, Md. Saidur Rahman", "title": "Monotone Grid Drawings of Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A monotone drawing of a planar graph $G$ is a planar straight-line drawing of\n$G$ where a monotone path exists between every pair of vertices of $G$ in some\ndirection. Recently monotone drawings of planar graphs have been proposed as a\nnew standard for visualizing graphs. A monotone drawing of a planar graph is a\nmonotone grid drawing if every vertex in the drawing is drawn on a grid point.\nIn this paper we study monotone grid drawings of planar graphs in a variable\nembedding setting. We show that every connected planar graph of $n$ vertices\nhas a monotone grid drawing on a grid of size $O(n)\\times O(n^2)$, and such a\ndrawing can be found in O(n) time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 00:50:53 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Hossain", "Md. Iqbal", ""], ["Rahman", "Md. Saidur", ""]]}, {"id": "1310.6271", "submitter": "Daniel Bundala", "authors": "Daniel Bundala, Jakub Z\\'avodn\\'y", "title": "Optimal Sorting Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper settles the optimality of sorting networks given in The Art of\nComputer Programming vol. 3 more than 40 years ago. The book lists efficient\nsorting networks with n <= 16 inputs. In this paper we give general\ncombinatorial arguments showing that if a sorting network with a given depth\nexists then there exists one with a special form. We then construct\npropositional formulas whose satisfiability is necessary for the existence of\nsuch a network. Using a SAT solver we conclude that the listed networks have\noptimal depth. For n <= 10 inputs where optimality was known previously, our\nalgorithm is four orders of magnitude faster than those in prior work.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 16:09:19 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2013 22:47:19 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Bundala", "Daniel", ""], ["Z\u00e1vodn\u00fd", "Jakub", ""]]}, {"id": "1310.6780", "submitter": "Arko Provo Mukherjee", "authors": "Arko Provo Mukherjee and Pan Xu and Srikanta Tirthapura", "title": "Mining Maximal Cliques from an Uncertain Graph", "comments": "ICDE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider mining dense substructures (maximal cliques) from an uncertain\ngraph, which is a probability distribution on a set of deterministic graphs.\nFor parameter 0 < {\\alpha} < 1, we present a precise definition of an\n{\\alpha}-maximal clique in an uncertain graph. We present matching upper and\nlower bounds on the number of {\\alpha}-maximal cliques possible within an\nuncertain graph. We present an algorithm to enumerate {\\alpha}-maximal cliques\nin an uncertain graph whose worst-case runtime is near-optimal, and an\nexperimental evaluation showing the practical utility of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 21:29:44 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 21:25:37 GMT"}, {"version": "v3", "created": "Wed, 22 Oct 2014 07:55:18 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Mukherjee", "Arko Provo", ""], ["Xu", "Pan", ""], ["Tirthapura", "Srikanta", ""]]}, {"id": "1310.6887", "submitter": "Filipe Brand\\~ao M.Sc", "authors": "Filipe Brand\\~ao, Jo\\~ao Pedro Pedroso", "title": "Bin Packing and Related Problems: General Arc-flow Formulation with\n  Graph Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": "DCC-2013-08", "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an exact method, based on an arc-flow formulation with side\nconstraints, for solving bin packing and cutting stock problems --- including\nmulti-constraint variants --- by simply representing all the patterns in a very\ncompact graph. Our method includes a graph compression algorithm that usually\nreduces the size of the underlying graph substantially without weakening the\nmodel. As opposed to our method, which provides strong models, conventional\nmodels are usually highly symmetric and provide very weak lower bounds.\n  Our formulation is equivalent to Gilmore and Gomory's, thus providing a very\nstrong linear relaxation. However, instead of using column-generation in an\niterative process, the method constructs a graph, where paths from the source\nto the target node represent every valid packing pattern.\n  The same method, without any problem-specific parameterization, was used to\nsolve a large variety of instances from several different cutting and packing\nproblems. In this paper, we deal with vector packing, graph coloring, bin\npacking, cutting stock, cardinality constrained bin packing, cutting stock with\ncutting knife limitation, cutting stock with binary patterns, bin packing with\nconflicts, and cutting stock with binary patterns and forbidden pairs. We\nreport computational results obtained with many benchmark test data sets, all\nof them showing a large advantage of this formulation with respect to the\ntraditional ones.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2013 11:55:30 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Brand\u00e3o", "Filipe", ""], ["Pedroso", "Jo\u00e3o Pedro", ""]]}, {"id": "1310.6955", "submitter": "Thomas Hackl", "authors": "Oswin Aichholzer and Thomas Hackl and Sarah Lutteropp and Tamara\n  Mchedlidze and Alexander Pilz and Birgit Vogtenhuber", "title": "Monotone Simultaneous Embedding of Directed Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study monotone simultaneous embeddings of upward planar digraphs, which\nare simultaneous embeddings where the drawing of each digraph is upward planar,\nand the directions of the upwardness of different graphs can differ. We first\nconsider the special case where each digraph is a directed path. In contrast to\nthe known result that any two directed paths admit a monotone simultaneous\nembedding, there exist examples of three paths that do not admit such an\nembedding for any possible choice of directions of monotonicity. We prove that\nif a monotone simultaneous embedding of three paths exists then it also exists\nfor any possible choice of directions of monotonicity. We provide a\npolynomial-time algorithm that, given three paths, decides whether a monotone\nsimultaneous embedding exists and, in the case of existence, also constructs\nsuch an embedding. On the other hand, we show that already for three paths, any\nmonotone simultaneous embedding might need a grid of exponential (w.r.t. the\nnumber of vertices) size. For more than three paths, we present a\npolynomial-time algorithm that, given any number of paths and predefined\ndirections of monotonicity, decides whether the paths admit a monotone\nsimultaneous embedding with respect to the given directions, including the\nconstruction of a solution if it exists. Further, we show several implications\nof our results on monotone simultaneous embeddings of general upward planar\ndigraphs. Finally, we discuss complexity issues related to our problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2013 15:14:34 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2014 13:19:11 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Aichholzer", "Oswin", ""], ["Hackl", "Thomas", ""], ["Lutteropp", "Sarah", ""], ["Mchedlidze", "Tamara", ""], ["Pilz", "Alexander", ""], ["Vogtenhuber", "Birgit", ""]]}, {"id": "1310.7205", "submitter": "Moritz Schattka", "authors": "Moritz Schattka", "title": "Algorithms for Timed Consistency Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in distributed systems is establishing\nconsistency among replicated data in a timely fashion. While the consistent\nordering of events has been extensively researched, the time span to reach a\nconsistent state is mostly considered an effect of the chosen consistency\nmodel, rather than being considered a parameter itself. This paper argues that\nit is possible to give guarantees on the timely consistency of an operation.\nSubsequent to an update the cloud and all connected clients will either be\nconsistent with the update within the defined upper bound of time or the update\nwill be returned. This paper suggests the respective algorithms and protocols\ncapable of producing such comprehensive Timed Consistency, as conceptually\nproposed by Torres-Rojas et al. The solution offers business customers an\nincreasing level of predictability and adjustability. The temporal certainty\nconcerning the execution makes the cloud a more attractive tool for\ntime-critical or mission-critical applications fearing the poor availability of\nStrong Consistency in cloud environments.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 15:39:18 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Schattka", "Moritz", ""]]}, {"id": "1310.7232", "submitter": "Ananya Christman", "authors": "Ananya Christman, William Forcier", "title": "Maximizing Revenues for Online-Dial-a-Ride", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic Dial-a-Ride Problem, a server travels in some metric space to\nserve requests for rides. Each request has a source, destination, and release\ntime. We study a variation of this problem where each request also has a\nrevenue that is earned if the request is satisfied. The goal is to serve\nrequests within a time limit such that the total revenue is maximized. We first\nprove that the version of this problem where edges in the input graph have\nvarying weights is NP-complete. We also prove that no algorithm can be\ncompetitive for this problem. We therefore consider the version where edges in\nthe graph have unit weight and develop a 2-competitive algorithm for this\nproblem.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 19:01:05 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Christman", "Ananya", ""], ["Forcier", "William", ""]]}, {"id": "1310.7409", "submitter": "Sebastian Wild", "authors": "Sebastian Wild and Markus E. Nebel", "title": "Average Case Analysis of Java 7's Dual Pivot Quicksort", "comments": "Best paper award at ESA 2012, recorded talk:\n  http://www.slideshare.net/sebawild/average-case-analysis-of-java-7s-dual-pivot-quicksort", "journal-ref": "In L. Epstein & P. Ferragina (Eds.), ESA 2012 (LNCS 7501, pp.\n  825-836). Springer Berlin/Heidelberg", "doi": "10.1007/978-3-642-33090-2_71", "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a new Quicksort variant due to Yaroslavskiy was chosen as standard\nsorting method for Oracle's Java 7 runtime library. The decision for the change\nwas based on empirical studies showing that on average, the new algorithm is\nfaster than the formerly used classic Quicksort. Surprisingly, the improvement\nwas achieved by using a dual pivot approach, an idea that was considered not\npromising by several theoretical studies in the past. In this paper, we\nidentify the reason for this unexpected success. Moreover, we present the first\nprecise average case analysis of the new algorithm showing e.g. that a random\npermutation of length $n$ is sorted using $1.9n\\ln n-2.46n+\\mathcal{O}(\\ln n)$\nkey comparisons and $0.6n\\ln n+0.08n+\\mathcal{O}(\\ln n)$ swaps.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 13:28:09 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Wild", "Sebastian", ""], ["Nebel", "Markus E.", ""]]}, {"id": "1310.7665", "submitter": "Madhav Jha", "authors": "Madhav Jha, C. Seshadhri, Ali Pinar", "title": "Counting Triangles in Real-World Graph Streams: Dealing with Repeated\n  Edges and Time Windows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world graphs often manifest as a massive temporal stream of edges. The\nneed for real-time analysis of such large graph streams has led to progress on\nlow memory, one-pass streaming graph algorithms. These algorithms were designed\nfor simple graphs, assuming an edge is not repeated in the stream. Real graph\nstreams however, are almost always multigraphs i.e., they contain many\nduplicate edges. The assumption of no repeated edges requires an extra pass\n*storing all the edges* just for deduplication, which defeats the purpose of\nsmall memory algorithms.\n  We describe an algorithm for estimating the triangle count of a multigraph\nstream of edges. We show that all previous streaming algorithms for triangle\ncounting fail for multigraph streams, despite their impressive accuracies for\nsimple graphs. The bias created by duplicate edges is a major problem, and\nleads these algorithms astray. Our algorithm avoids these biases through\ncareful debiasing strategies and has provable theoretical guarantees and\nexcellent empirical performance. Our algorithm builds on the previously\nintroduced wedge sampling methodology.\n  Another challenge in analyzing temporal graphs is finding the right temporal\nwindow size. Our algorithm seamlessly handles multiple time windows, and does\nnot require committing to any window size(s) a priori. We apply our algorithm\nto discover fascinating transitivity and triangle trends in real-world graph\nstreams.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 02:36:20 GMT"}, {"version": "v2", "created": "Tue, 14 Oct 2014 20:57:33 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Jha", "Madhav", ""], ["Seshadhri", "C.", ""], ["Pinar", "Ali", ""]]}, {"id": "1310.7741", "submitter": "Ciaran McCreesh", "authors": "Ciaran McCreesh and Patrick Prosser", "title": "Greedy Graph Colouring is a Misleading Heuristic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art maximum clique algorithms use a greedy graph colouring as a\nbound. We show that greedy graph colouring can be misleading, which has\nimplications for parallel branch and bound.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 10:23:35 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["McCreesh", "Ciaran", ""], ["Prosser", "Patrick", ""]]}, {"id": "1310.7766", "submitter": "Or Sattath", "authors": "Itai Arad, Or Sattath", "title": "A Constructive Quantum Lov\\'asz Local Lemma for Commuting Projectors", "comments": null, "journal-ref": "Quantum Information & Computation 15(11&12): 987-996 (2015)", "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Satisfiability problem generalizes the Boolean satisfiability\nproblem to the quantum setting by replacing classical clauses with local\nprojectors. The Quantum Lov\\'asz Local Lemma gives a sufficient condition for a\nQuantum Satisfiability problem to be satisfiable [AKS12], by generalizing the\nclassical Lov\\'asz Local Lemma.\n  The next natural question that arises is: can a satisfying quantum state be\nefficiently found, when these conditions hold? In this work we present such an\nalgorithm, with the additional requirement that all the projectors commute. The\nproof follows the information theoretic proof given by Moser's breakthrough\nresult in the classical setting [Mos09].\n  Similar results were independently published in [CS11,CSV13].\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 11:44:51 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Arad", "Itai", ""], ["Sattath", "Or", ""]]}, {"id": "1310.7828", "submitter": "Sebastian Ordyniak", "authors": "Christer Baeckstroem, Peter Jonsson, Sebastian Ordyniak, Stefan\n  Szeider", "title": "A Complete Parameterized Complexity Analysis of Bounded Planning", "comments": "The paper is a combined and extended version of the papers \"The\n  Complexity of Planning Revisited - A Parameterized Analysis\" (AAAI 2012,\n  arXiv:1208.2566) and \"Parameterized Complexity and Kernel Bounds for Hard\n  Planning Problems\" (CIAC 2013, arXiv:1211.0479)", "journal-ref": "Proc. AAAI'12, pp. 1735-1741, AAAI Press 2012 and Proc. CIAC'13,\n  pp. 13-24, Springer", "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The propositional planning problem is a notoriously difficult computational\nproblem, which remains hard even under strong syntactical and structural\nrestrictions. Given its difficulty it becomes natural to study planning in the\ncontext of parameterized complexity. In this paper we continue the work\ninitiated by Downey, Fellows and Stege on the parameterized complexity of\nplanning with respect to the parameter \"length of the solution plan.\" We\nprovide a complete classification of the parameterized complexity of the\nplanning problem under two of the most prominent syntactical restrictions,\ni.e., the so called PUBS restrictions introduced by Baeckstroem and Nebel and\nrestrictions on the number of preconditions and effects as introduced by\nBylander. We also determine which of the considered fixed-parameter tractable\nproblems admit a polynomial kernel and which don't.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 15:12:15 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["Baeckstroem", "Christer", ""], ["Jonsson", "Peter", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1310.7834", "submitter": "Chaitanya Swamy", "authors": "Chaitanya Swamy", "title": "Improved Approximation Algorithms for Matroid and Knapsack Median\n  Problems and Applications", "comments": "Added a figure and made some minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the {\\em matroid median} problem \\cite{KrishnaswamyKNSS11},\nwherein we are given a set of facilities with opening costs and a matroid on\nthe facility-set, and clients with demands and connection costs, and we seek to\nopen an independent set of facilities and assign clients to open facilities so\nas to minimize the sum of the facility-opening and client-connection costs. We\ngive a simple 8-approximation algorithm for this problem based on LP-rounding,\nwhich improves upon the 16-approximation in \\cite{KrishnaswamyKNSS11}. Our\ntechniques illustrate that much of the work involved in the rounding algorithm\nof in \\cite{KrishnaswamyKNSS11} can be avoided by first converting the LP\nsolution to a half-integral solution, which can then be rounded to an integer\nsolution using a simple uncapacitated-facility-location (UFL) style clustering\nstep. We illustrate the power of these ideas by deriving: (a) a\n24-approximation algorithm for matroid median with penalties, which is a vast\nimprovement over the 360-approximation obtained in \\cite{KrishnaswamyKNSS11};\nand (b) an 8-approximation for the {\\em two-matroid median} problem, a\ngeneralization of matroid median that we introduce involving two matroids. We\nshow that a variety of seemingly disparate facility-location problems\nconsidered in the literature---data placement problem, mobile facility\nlocation, $k$-median forest, metric uniform minimum-latency UFL---in fact\nreduce to the matroid median or two-matroid median problems, and thus obtain\nimproved approximation guarantees for all these problems. Our techniques also\nyield an improvement for the knapsack median problem.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 15:21:22 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2013 00:38:26 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2014 04:52:24 GMT"}, {"version": "v4", "created": "Thu, 29 Sep 2016 02:08:18 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Swamy", "Chaitanya", ""]]}, {"id": "1310.7840", "submitter": "Rahul Mehta", "authors": "Rahul Mehta", "title": "A New Push-Relabel Algorithm for Sparse Networks", "comments": "23 pages. arXiv admin note: substantial text overlap with\n  arXiv:1309.2525 - This version includes an extension of the result to the\n  O(n) edge case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new push-relabel algorithm for the maximum flow\nproblem on flow networks with $n$ vertices and $m$ arcs. Our algorithm computes\na maximum flow in $O(mn)$ time on sparse networks where $m = O(n)$. To our\nknowledge, this is the first $O(mn)$ time push-relabel algorithm for the $m =\nO(n)$ edge case; previously, it was known that push-relabel implementations\ncould find a max-flow in $O(mn)$ time when $m = \\Omega(n^{1+\\epsilon})$ (King,\net. al., SODA `92). This also matches a recent flow decomposition-based\nalgorithm due to Orlin (STOC `13), which finds a max-flow in $O(mn)$ time on\nsparse networks.\n  Our main result is improving on the Excess-Scaling algorithm (Ahuja & Orlin,\n1989) by reducing the number of nonsaturating pushes to $O(mn)$ across all\nscaling phases. This is reached by combining Ahuja and Orlin's algorithm with\nOrlin's compact flow networks. A contribution of this paper is demonstrating\nthat the compact networks technique can be extended to the push-relabel family\nof algorithms. We also provide evidence that this approach could be a promising\navenue towards an $O(mn)$-time algorithm for all edge densities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 15:33:11 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 14:46:34 GMT"}, {"version": "v3", "created": "Tue, 10 Jun 2014 22:39:51 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["Mehta", "Rahul", ""]]}, {"id": "1310.7890", "submitter": "Prashant Kumar", "authors": "Adarsh Kumar Verma, Prashant Kumar", "title": "List Sort: A New Approach for Sorting List to Reduce Execution Time", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we are proposing a new sorting algorithm, List Sort algorithm,\nis based on the dynamic memory allocation. In this research study we have also\nshown the comparison of various efficient sorting techniques with List sort.\nDue the dynamic nature of the List sort, it becomes much more fast than some\nconventional comparison sorting techniques and comparable to Quick Sort and\nMerge Sort. List sort takes the advantage of the data which is already sorted\neither in ascending order or in descending order.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2013 20:09:13 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["Verma", "Adarsh Kumar", ""], ["Kumar", "Prashant", ""]]}, {"id": "1310.7898", "submitter": "Eleni Akrida", "authors": "Paul G. Spirakis, Eleni Ch. Akrida", "title": "Moving in temporal graphs with very sparse random availability of edges", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work we consider temporal graphs, i.e. graphs, each edge of which is\nassigned a set of discrete time-labels drawn from a set of integers. The labels\nof an edge indicate the discrete moments in time at which the edge is\navailable. We also consider temporal paths in a temporal graph, i.e. paths\nwhose edges are assigned a strictly increasing sequence of labels. Furthermore,\nwe assume the uniform case (UNI-CASE), in which every edge of a graph is\nassigned exactly one time label from a set of integers and the time labels\nassigned to the edges of the graph are chosen randomly and independently, with\nthe selection following the uniform distribution. We call uniform random\ntemporal graphs the graphs that satisfy the UNI-CASE. We begin by deriving the\nexpected number of temporal paths of a given length in the uniform random\ntemporal clique. We define the term temporal distance of two vertices, which is\nthe arrival time, i.e. the time-label of the last edge, of the temporal path\nthat connects those vertices, which has the smallest arrival time amongst all\ntemporal paths that connect those vertices. We then propose and study two\nstatistical properties of temporal graphs. One is the maximum expected temporal\ndistance which is, as the term indicates, the maximum of all expected temporal\ndistances in the graph. The other one is the temporal diameter which, loosely\nspeaking, is the expectation of the maximum temporal distance in the graph. We\nderive the maximum expected temporal distance of a uniform random temporal star\ngraph as well as an upper bound on both the maximum expected temporal distance\nand the temporal diameter of the normalized version of the uniform random\ntemporal clique, in which the largest time-label available equals the number of\nvertices. Finally, we provide an algorithm that solves an optimization problem\non a specific type of temporal (multi)graphs of two vertices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 17:58:57 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["Spirakis", "Paul G.", ""], ["Akrida", "Eleni Ch.", ""]]}, {"id": "1310.8062", "submitter": "Hsueh-I Lu", "authors": "Cheng-Wei Lee and Hsueh-I Lu", "title": "Replacement Paths via Row Minima of Concise Matrices", "comments": "23 pages, 1 table, 9 figures, accepted to SIAM Journal on Discrete\n  Mathematics", "journal-ref": "SIAM Journal on Discrete Mathematics 28(1):206-225, 2014", "doi": "10.1137/120897146", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix $M$ is {\\em $k$-concise} if the finite entries of each column of $M$\nconsist of $k$ or less intervals of identical numbers. We give an $O(n+m)$-time\nalgorithm to compute the row minima of any $O(1)$-concise $n\\times m$ matrix.\nOur algorithm yields the first $O(n+m)$-time reductions from the\nreplacement-paths problem on an $n$-node $m$-edge undirected graph\n(respectively, directed acyclic graph) to the single-source shortest-paths\nproblem on an $O(n)$-node $O(m)$-edge undirected graph (respectively, directed\nacyclic graph). That is, we prove that the replacement-paths problem is no\nharder than the single-source shortest-paths problem on undirected graphs and\ndirected acyclic graphs. Moreover, our linear-time reductions lead to the first\n$O(n+m)$-time algorithms for the replacement-paths problem on the following\nclasses of $n$-node $m$-edge graphs (1) undirected graphs in the word-RAM model\nof computation, (2) undirected planar graphs, (3) undirected minor-closed\ngraphs, and (4) directed acyclic graphs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 08:20:10 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Lee", "Cheng-Wei", ""], ["Lu", "Hsueh-I", ""]]}, {"id": "1310.8245", "submitter": "Akaki Mamageishvili", "authors": "Akaki Mamageishvili, Matus Mihalak, and Dominik Muller", "title": "Tree Nash Equilibria in the Network Creation Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the network creation game with n vertices, every vertex (a player) buys a\nset of adjacent edges, each at a fixed amount {\\alpha} > 0. It has been\nconjectured that for {\\alpha} >= n, every Nash equilibrium is a tree, and has\nbeen confirmed for every {\\alpha} >= 273n. We improve upon this bound and show\nthat this is true for every {\\alpha} >= 65n. To show this, we provide new and\nimproved results on the local structure of Nash equilibria. Technically, we\nshow that if there is a cycle in a Nash equilibrium, then {\\alpha} < 65n.\nProving this, we only consider relatively simple strategy changes of the\nplayers involved in the cycle. We further show that this simple approach cannot\nbe used to show the desired upper bound {\\alpha} < n (for which a cycle may\nexist), but conjecture that a slightly worse bound {\\alpha} < 1.3n can be\nachieved with this approach. Towards this conjecture, we show that if a Nash\nequilibrium has a cycle of length at most 10, then indeed {\\alpha} < 1.3n. We\nfurther provide experimental evidence suggesting that when the girth of a Nash\nequilibrium is increasing, the upper bound on {\\alpha} obtained by the simple\nstrategy changes is not increasing. To the end, we investigate the approach for\na coalitional variant of Nash equilibrium, where coalitions of two players\ncannot collectively improve, and show that if {\\alpha} >= 41n, then every such\nNash equilibrium is a tree.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 17:53:46 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Mamageishvili", "Akaki", ""], ["Mihalak", "Matus", ""], ["Muller", "Dominik", ""]]}, {"id": "1310.8381", "submitter": "Edith Cohen", "authors": "Edith Cohen, Amos Fiat, Haim Kaplan, Liam Roditty", "title": "A Labeling Approach to Incremental Cycle Detection", "comments": "15 pages, one figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\emph{incremental cycle detection} problem arcs are added to a\ndirected acyclic graph and the algorithm has to report if the new arc closes a\ncycle. One seeks to minimize the total time to process the entire sequence of\narc insertions, or until a cycle appears.\n  In a recent breakthrough, Bender, Fineman, Gilbert and Tarjan\n\\cite{BeFiGiTa11} presented two different algorithms, with time complexity\n$O(n^2 \\log n)$ and $O(m \\cdot \\min \\{m^{1/2}, n^{2/3} \\})$, respectively.\n  In this paper we introduce a new technique for incremental cycle detection\nthat allows us to obtain both bounds (up to a logarithmic factor). Furthermore,\nour approach seems more amiable for distributed implementation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 04:41:06 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Cohen", "Edith", ""], ["Fiat", "Amos", ""], ["Kaplan", "Haim", ""], ["Roditty", "Liam", ""]]}, {"id": "1310.8426", "submitter": "Eren Metin El\\c{c}i", "authors": "Eren Metin El\\c{c}i and Martin Weigel", "title": "Dynamic connectivity algorithms for Monte Carlo simulations of the\n  random-cluster model", "comments": "Contribution to the \"XXV IUPAP Conference on Computational Physics\"\n  proceedings; Corrected equation 3 and error in the maximal number of edge\n  levels", "journal-ref": "J. Phys. Conf. Ser. 510, 012013 (2014)", "doi": "10.1088/1742-6596/510/1/012013", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review Sweeny's algorithm for Monte Carlo simulations of the random\ncluster model. Straightforward implementations suffer from the problem of\ncomputational critical slowing down, where the computational effort per edge\noperation scales with a power of the system size. By using a tailored dynamic\nconnectivity algorithm we are able to perform all operations with a\npoly-logarithmic computational effort. This approach is shown to be efficient\nin keeping online connectivity information and is of use for a number of\napplications also beyond cluster-update simulations, for instance in monitoring\ndroplet shape transitions. As the handling of the relevant data structures is\nnon-trivial, we provide a Python module with a full implementation for future\nreference.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 08:49:43 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2013 11:02:00 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["El\u00e7i", "Eren Metin", ""], ["Weigel", "Martin", ""]]}]