[{"id": "2103.00005", "submitter": "Qiulin Lin", "authors": "Yanfang Mo, Qiulin Lin, Minghua Chen, and Si-Zhao Joe Qin", "title": "Competitive Online Peak-Demand Minimization Using Energy Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online peak-demand minimization under energy storage\nconstraints. It is motivated by an increasingly popular scenario where\nlarge-load customers utilize energy storage to reduce the peak procurement from\nthe grid, which accounts for up to $90\\%$ of their electric bills. The problem\nis uniquely challenging due to (i) the coupling of online decisions across time\nimposed by the inventory constraints and (ii) the noncumulative nature of the\npeak procurement. In this paper, we develop an optimal online algorithm for the\nproblem, attaining the best possible competitive ratio (CR) among all\ndeterministic and randomized algorithms. We show that the optimal CR can be\ncomputed in polynomial time, by solving a linear number of linear-fractional\nproblems. More importantly, we generalize our approach to develop an\n\\emph{anytime-optimal} online algorithm that achieves the best possible CR at\nany epoch, given the inputs and online decisions so far. The algorithm retains\nthe optimal worst-case performance and achieves adaptive average-case\nperformance. Simulation results based on real-world traces show that, under\ntypical settings, our algorithms improve peak reduction by over $19\\%$ as\ncompared to baseline alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 06:41:06 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 03:31:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mo", "Yanfang", ""], ["Lin", "Qiulin", ""], ["Chen", "Minghua", ""], ["Qin", "Si-Zhao Joe", ""]]}, {"id": "2103.00076", "submitter": "Haitao Wang", "authors": "Haitao Wang", "title": "An Optimal Deterministic Algorithm for Geodesic Farthest-Point Voronoi\n  Diagrams in Simple Polygons", "comments": "To appear in SoCG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $S$ of $m$ point sites in a simple polygon $P$ of $n$ vertices,\nwe consider the problem of computing the geodesic farthest-point Voronoi\ndiagram for $S$ in $P$. It is known that the problem has an $\\Omega(n+m\\log m)$\ntime lower bound. Previously, a randomized algorithm was proposed [Barba, SoCG\n2019] that can solve the problem in $O(n+m\\log m)$ expected time. The previous\nbest deterministic algorithms solve the problem in $O(n\\log \\log n+ m\\log m)$\ntime [Oh, Barba, and Ahn, SoCG 2016] or in $O(n+m\\log m+m\\log^2 n)$ time [Oh\nand Ahn, SoCG 2017]. In this paper, we present a deterministic algorithm of\n$O(n+m\\log m)$ time, which is optimal. This answers an open question posed by\nMitchell in the Handbook of Computational Geometry two decades ago.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 22:45:00 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 03:32:13 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wang", "Haitao", ""]]}, {"id": "2103.00451", "submitter": "Giulia Preti", "authors": "Giulia Preti, Polina Rozenshtein, Aristides Gionis, Yannis Velegrakis", "title": "Discovering Dense Correlated Subgraphs in Dynamic Networks", "comments": "Full version of the paper included in the proceedings of the PAKDD\n  2021 conference", "journal-ref": "PAKDD 2021", "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a dynamic network, where edges appear and disappear over time, we are\ninterested in finding sets of edges that have similar temporal behavior and\nform a dense subgraph. Formally, we define the problem as the enumeration of\nthe maximal subgraphs that satisfy specific density and similarity thresholds.\nTo measure the similarity of the temporal behavior, we use the correlation\nbetween the binary time series that represent the activity of the edges. For\nthe density, we study two variants based on the average degree. For these\nproblem variants we enumerate the maximal subgraphs and compute a compact\nsubset of subgraphs that have limited overlap. We propose an approximate\nalgorithm that scales well with the size of the network, while achieving a high\naccuracy. We evaluate our framework on both real and synthetic datasets. The\nresults of the synthetic data demonstrate the high accuracy of the\napproximation and show the scalability of the framework.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:02:54 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Preti", "Giulia", ""], ["Rozenshtein", "Polina", ""], ["Gionis", "Aristides", ""], ["Velegrakis", "Yannis", ""]]}, {"id": "2103.00462", "submitter": "Dmitry Kosolobov", "authors": "Djamal Belazzougui, Dmitry Kosolobov, Simon J. Puglisi, and Rajeev\n  Raman", "title": "Weighted Ancestors in Suffix Trees Revisited", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The weighted ancestor problem is a well-known generalization of the\npredecessor problem to trees. It is known to require $\\Omega(\\log\\log n)$ time\nfor queries provided $O(n\\mathop{\\mathrm{polylog}} n)$ space is available and\nweights are from $[0..n]$, where $n$ is the number of tree nodes. However, when\napplied to suffix trees, the problem, surprisingly, admits an $O(n)$-space\nsolution with constant query time, as was shown by Gawrychowski, Lewenstein,\nand Nicholson (Proc. ESA 2014). This variant of the problem can be reformulated\nas follows: given the suffix tree of a string $s$, we need a data structure\nthat can locate in the tree any substring $s[p..q]$ of $s$ in $O(1)$ time (as\nif one descended from the root reading $s[p..q]$ along the way). Unfortunately,\nthe data structure of Gawrychowski et al. has no efficient construction\nalgorithm, limiting its wider usage as an algorithmic tool. In this paper we\nresolve this issue, describing a data structure for weighted ancestors in\nsuffix trees with constant query time and a linear construction algorithm. Our\nsolution is based on a novel approach using so-called irreducible LCP values.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:28:13 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 16:51:07 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Kosolobov", "Dmitry", ""], ["Puglisi", "Simon J.", ""], ["Raman", "Rajeev", ""]]}, {"id": "2103.00504", "submitter": "Xianghui Zhong", "authors": "Xianghui Zhong", "title": "On the Approximation Ratio of the 3-Opt Algorithm for the (1,2)-TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (1,2)-TSP is a special case of the TSP where each edge has cost either 1\nor 2. In this paper we give a lower bound of $\\frac{3}{2}$ for the\napproximation ratio of the 2-Opt algorithm for the (1,2)-TSP. Moreover, we show\nthat the 3-Opt algorithm has an exact approximation ratio of $\\frac{11}{8}$ for\nthe (1,2)-TSP. Furthermore, we introduce the 3-Opt++-algorithm, an improved\nversion of the 3-Opt algorithm for the (1-2)-TSP with an exact approximation\nratio of $\\frac{4}{3}$.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 13:21:51 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 14:28:29 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Zhong", "Xianghui", ""]]}, {"id": "2103.00564", "submitter": "Casper Benjamin Freksen", "authors": "Casper Benjamin Freksen", "title": "An Introduction to Johnson-Lindenstrauss Transforms", "comments": "The text was previously a main part of the introduction of my PhD\n  thesis, but it has been adapted to be self contained and serve as a\n  (hopefully good) starting point for readers interested in the topic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Johnson--Lindenstrauss Transforms are powerful tools for reducing the\ndimensionality of data while preserving key characteristics of that data, and\nthey have found use in many fields from machine learning to differential\nprivacy and more. This note explains what they are; it gives an overview of\ntheir use and their development since they were introduced in the 1980s; and it\nprovides many references should the reader wish to explore these topics more\ndeeply.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 16:57:41 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Freksen", "Casper Benjamin", ""]]}, {"id": "2103.00713", "submitter": "Yu Zheng", "authors": "Xin Li, Yu Zheng", "title": "Lower Bounds and Improved Algorithms for Asymmetric Streaming Edit\n  Distance and Longest Common Subsequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study edit distance (ED) and longest common subsequence\n(LCS) in the asymmetric streaming model, introduced by Saks and Seshadhri\n[SS13]. As an intermediate model between the random access model and the\nstreaming model, this model allows one to have streaming access to one string\nand random access to the other string.\n  Our first main contribution is a systematic study of space lower bounds for\nED and LCS in the asymmetric streaming model. Previously, there are no\nexplicitly stated results in this context, although some lower bounds about LCS\ncan be inferred from the lower bounds for longest increasing subsequence (LIS)\nin [SW07][GG10][EJ08]. Yet these bounds only work for large alphabet size. In\nthis paper, we develop several new techniques to handle ED in general and LCS\nfor small alphabet size, thus establishing strong lower bounds for both\nproblems. In particular, our lower bound for ED provides an exponential\nseparation between edit distance and Hamming distance in the asymmetric\nstreaming model. Our lower bounds also extend to LIS and longest non-decreasing\nsequence (LNS) in the standard streaming model. Together with previous results,\nour bounds provide an almost complete picture for these two problems.\n  As our second main contribution, we give improved algorithms for ED and LCS\nin the asymmetric streaming model. For ED, we improve the space complexity of\nthe constant factor approximation algorithms in [FHRS20][CJLZ20] from\n$\\tilde{O}(\\frac{n^\\delta}{\\delta})$ to\n$O(\\frac{d^\\delta}{\\delta}\\;\\mathsf{polylog}(n))$, where $n$ is the length of\neach string and $d$ is the edit distance between the two strings. For LCS, we\ngive the first $1/2+\\epsilon$ approximation algorithm with space $n^{\\delta}$\nfor any constant $\\delta>0$, over a binary alphabet.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 02:49:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Xin", ""], ["Zheng", "Yu", ""]]}, {"id": "2103.00882", "submitter": "Dimitrios Thilikos", "authors": "Ignasi Sau and Giannos Stamoulis and Dimitrios M. Thilikos", "title": "k-apices of minor-closed graph classes. I. Bounding the obstructions", "comments": "46 pages and 12 figures. arXiv admin note: text overlap with\n  arXiv:2004.12692", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\cal G}$ be a minor-closed graph class. We say that a graph $G$ is a\n$k$-apex of ${\\cal G}$ if $G$ contains a set $S$ of at most $k$ vertices such\nthat $G\\setminus S$ belongs to ${\\cal G}.$ We denote by ${\\cal A}_k ({\\cal G})$\nthe set of all graphs that are $k$-apices of ${\\cal G}.$ We prove that every\ngraph in the obstruction set of ${\\cal A}_k ({\\cal G}),$ i.e., the\nminor-minimal set of graphs not belonging to ${\\cal A}_k ({\\cal G}),$ has size\nat most $2^{2^{2^{2^{{\\sf poly}(k)}}}},$ where ${\\sf poly}$ is a polynomial\nfunction whose degree depends on the size of the minor-obstructions of ${\\cal\nG}.$ This bound drops to $2^{2^{{\\sf poly}(k)}}$ when ${\\cal G}$ excludes some\napex graph as a minor.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 10:07:46 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sau", "Ignasi", ""], ["Stamoulis", "Giannos", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2103.01024", "submitter": "Davide Zorzenon", "authors": "Davide Zorzenon, Jan Komenda, Joerg Raisch", "title": "Periodic trajectories in P-time event graphs and the non-positive\n  circuit weight problem", "comments": "Minor corrections", "journal-ref": null, "doi": "10.1109/LCSYS.2021.3085521", "report-no": null, "categories": "cs.DS cs.DM cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  P-time event graphs (P-TEGs) are specific timed discrete-event systems, in\nwhich the timing of events is constrained by intervals. An important problem is\nto check, for all natural numbers $d$, the existence of consistent $d$-periodic\ntrajectories for a given P-TEG. In graph theory, the\nProportional-Inverse-Constant-Non-positive Circuit weight Problem (PIC-NCP)\nconsists in finding all the values of a parameter such that a particular\nparametric weighted directed graph does not contain circuits with positive\nweight. In a related paper, we have proposed a strongly polynomial algorithm\nthat solves the PIC-NCP in lower worst-case complexity compared to other\nalgorithms reported in literature. In the present paper, we show that the first\nproblem can be formulated as an instance of the second; consequently, we prove\nthat the same algorithm can be used to find $d$-periodic trajectories in\nP-TEGs. Moreover, exploiting the connection between the PIC-NCP and max-plus\nalgebra we prove that, given a P-TEG, the existence of a consistent 1-periodic\ntrajectory of a certain period is a necessary and sufficient condition for the\nexistence of a consistent $d$-periodic trajectory of the same period, for any\nvalue of $d$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 16:28:13 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 15:40:40 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 07:56:39 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 11:35:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zorzenon", "Davide", ""], ["Komenda", "Jan", ""], ["Raisch", "Joerg", ""]]}, {"id": "2103.01046", "submitter": "Anil Shukla", "authors": "Anish Mallick, Anil Shukla", "title": "Extending Prolog for Quantified Boolean Horn Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prolog is a well known declarative programming language based on\npropositional Horn formulas. It is useful in various areas, including\nartificial intelligence, automated theorem proving, mathematical logic and so\non. An active research area for many years is to extend Prolog to larger\nclasses of logic. Some important extensions of it includes the constraint logic\nprogramming, and the object oriented logic programming. However, it cannot\nsolve problems having arbitrary quantified Horn formulas.\n  To be precise, the facts, rules and queries in Prolog are not allowed to have\narbitrary quantified variables. The paper overcomes this major limitations of\nProlog by extending it for the quantified Boolean Horn formulas. We achieved\nthis by extending the SLD-resolution proof system for quantified Boolean Horn\nformulas, followed by proposing an efficient model for implementation. The\npaper shows that the proposed implementation also supports the first-order\npredicate Horn logic with arbitrary quantified variables.\n  The paper also introduces for the first time, a declarative programming for\nthe quantified Boolean Horn formulas.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:39:56 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mallick", "Anish", ""], ["Shukla", "Anil", ""]]}, {"id": "2103.01052", "submitter": "Neal E. Young", "authors": "Marek Chrobak and Mordecai Golin and J. Ian Munro and Neal E. Young", "title": "On the Cost of Unsuccessful Searches in Search Trees with Two-way\n  Comparisons", "comments": "v2 has updated bibliography", "journal-ref": "Information and Computation (2021)", "doi": "10.1016/j.ic.2021.104707", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search trees are commonly used to implement access operations to a set of\nstored keys. If this set is static and the probabilities of membership queries\nare known in advance, then one can precompute an optimal search tree, namely\none that minimizes the expected access cost. For a non-key query, a search tree\ncan determine its approximate location by returning the inter-key interval\ncontaining the query. This is in contrast to other dictionary data structures,\nlike hash tables, that only report a failed search. We address the question\n\"what is the additional cost of determining approximate locations for non-key\nqueries\"? We prove that for two-way comparison trees this additional cost is at\nmost 1. Our proof is based on a novel probabilistic argument that involves\nconverting a search tree that does not identify non-key queries into a random\ntree that does.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:50:29 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 14:45:51 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chrobak", "Marek", ""], ["Golin", "Mordecai", ""], ["Munro", "J. Ian", ""], ["Young", "Neal E.", ""]]}, {"id": "2103.01084", "submitter": "Neal E. Young", "authors": "Marek Chrobak, Mordecai Golin, J. Ian Munro, Neal E. Young", "title": "A Simple Algorithm for Optimal Search Trees with Two-Way Comparisons", "comments": "v2 has updated references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple $O(n^4)$-time algorithm for computing optimal search\ntrees with two-way comparisons. The only previous solution to this problem, by\nAnderson et al., has the same running time, but is significantly more\ncomplicated and is restricted to the variant where only successful queries are\nallowed. Our algorithm extends directly to solve the standard full variant of\nthe problem, which also allows unsuccessful queries and for which no\npolynomial-time algorithm was previously known. The correctness proof of our\nalgorithm relies on a new structural theorem for two-way-comparison search\ntrees.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 15:53:28 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:14:30 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chrobak", "Marek", ""], ["Golin", "Mordecai", ""], ["Munro", "J. Ian", ""], ["Young", "Neal E.", ""]]}, {"id": "2103.01216", "submitter": "Yan Gu", "authors": "Yan Gu, Omar Obeya, Julian Shun", "title": "Parallel In-Place Algorithms: Theory and Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many parallel algorithms use at least linear auxiliary space in the size of\nthe input to enable computations to be done independently without conflicts.\nUnfortunately, this extra space can be prohibitive for memory-limited machines,\npreventing large inputs from being processed. Therefore, it is desirable to\ndesign parallel in-place algorithms that use sublinear (or even\npolylogarithmic) auxiliary space.\n  In this paper, we bridge the gap between theory and practice for parallel\nin-place (PIP) algorithms. We first define two computational models based on\nfork-join parallelism, which reflect modern parallel programming environments.\nWe then introduce a variety of new parallel in-place algorithms that are simple\nand efficient, both in theory and in practice. Our algorithmic highlight is the\nDecomposable Property introduced in this paper, which enables existing\nnon-in-place but highly-optimized parallel algorithms to be converted into\nparallel in-place algorithms. Using this property, we obtain algorithms for\nrandom permutation, list contraction, tree contraction, and merging that take\nlinear work, $O(n^{1-\\epsilon})$ auxiliary space, and\n$O(n^\\epsilon\\cdot\\text{polylog}(n))$ span for $0<\\epsilon<1$. We also present\nnew parallel in-place algorithms for scan, filter, merge, connectivity,\nbiconnectivity, and minimum spanning forest using other techniques.\n  In addition to theoretical results, we present experimental results for\nimplementations of many of our parallel in-place algorithms. We show that on a\n72-core machine with two-way hyper-threading, the parallel in-place algorithms\nusually outperform existing parallel algorithms for the same problems that use\nlinear auxiliary space, indicating that the theory developed in this paper\nindeed leads to practical benefits in terms of both space usage and running\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 18:59:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gu", "Yan", ""], ["Obeya", "Omar", ""], ["Shun", "Julian", ""]]}, {"id": "2103.01294", "submitter": "Huanyu Zhang", "authors": "Huanyu Zhang, Ilya Mironov, Meisam Hejazinia", "title": "Wide Network Learning with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite intense interest and considerable effort, the current generation of\nneural networks suffers a significant loss of accuracy under most practically\nrelevant privacy training regimes. One particularly challenging class of neural\nnetworks are the wide ones, such as those deployed for NLP typeahead prediction\nor recommender systems. Observing that these models share something in\ncommon--an embedding layer that reduces the dimensionality of the input--we\nfocus on developing a general approach towards training these models that takes\nadvantage of the sparsity of the gradients. More abstractly, we address the\nproblem of differentially private empirical risk minimization (ERM) for models\nthat admit sparse gradients. We demonstrate that for non-convex ERM problems,\nthe loss is logarithmically dependent on the number of parameters, in contrast\nwith polynomial dependence for the general case. Following the same intuition,\nwe propose a novel algorithm for privately training neural networks. Finally,\nwe provide an empirical study of a DP wide neural network on a real-world\ndataset, which has been rarely explored in the previous work.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 20:31:50 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 14:55:33 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 14:46:30 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhang", "Huanyu", ""], ["Mironov", "Ilya", ""], ["Hejazinia", "Meisam", ""]]}, {"id": "2103.01398", "submitter": "Lunjia Hu", "authors": "Moses Charikar, Lunjia Hu", "title": "Approximation Algorithms for Orthogonal Non-negative Matrix\n  Factorization", "comments": "26 pages, 5 figures. To be published in AISTATS 2021. Font size\n  increased", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the non-negative matrix factorization (NMF) problem, the input is an\n$m\\times n$ matrix $M$ with non-negative entries and the goal is to factorize\nit as $M\\approx AW$. The $m\\times k$ matrix $A$ and the $k\\times n$ matrix $W$\nare both constrained to have non-negative entries. This is in contrast to\nsingular value decomposition, where the matrices $A$ and $W$ can have negative\nentries but must satisfy the orthogonality constraint: the columns of $A$ are\northogonal and the rows of $W$ are also orthogonal. The orthogonal non-negative\nmatrix factorization (ONMF) problem imposes both the non-negativity and the\northogonality constraints, and previous work showed that it leads to better\nperformances than NMF on many clustering tasks. We give the first\nconstant-factor approximation algorithm for ONMF when one or both of $A$ and\n$W$ are subject to the orthogonality constraint. We also show an interesting\nconnection to the correlation clustering problem on bipartite graphs. Our\nexperiments on synthetic and real-world data show that our algorithm achieves\nsimilar or smaller errors compared to previous ONMF algorithms while ensuring\nperfect orthogonality (many previous algorithms do not satisfy the hard\northogonality constraint).\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 01:22:10 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 08:20:14 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Charikar", "Moses", ""], ["Hu", "Lunjia", ""]]}, {"id": "2103.01628", "submitter": "Bhaskar Ray Chaudhury Mr.", "authors": "Bhaskar Ray Chaudhury, Jugal Garg, Kurt Mehlhorn, Ruta Mehta,\n  Pranabendu Misra", "title": "Improving EFX Guarantees through Rainbow Cycle Number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of fairly allocating a set of indivisible goods among\n$n$ agents with additive valuations. Envy-freeness up to any good (EFX) is\narguably the most compelling fairness notion in this context. However, the\nexistence of EFX allocations has not been settled and is one of the most\nimportant problems in fair division. Towards resolving this problem, many\nimpressive results show the existence of its relaxations, e.g., the existence\nof $0.618$-EFX allocations, and the existence of EFX at most $n-1$ unallocated\ngoods. The latter result was recently improved for three agents, in which the\ntwo unallocated goods are allocated through an involved procedure. Reducing the\nnumber of unallocated goods for arbitrary number of agents is a systematic way\nto settle the big question. In this paper, we develop a new approach, and show\nthat for every $\\varepsilon \\in (0,1/2]$, there always exists a\n$(1-\\varepsilon)$-EFX allocation with sublinear number of unallocated goods and\nhigh Nash welfare.\n  For this, we reduce the EFX problem to a novel problem in extremal graph\ntheory. We introduce the notion of rainbow cycle number $R(\\cdot)$. For all $d\n\\in \\mathbb{N}$, $R(d)$ is the largest $k$ such that there exists a $k$-partite\ndigraph $G =(\\cup_{i \\in [k]} V_i, E)$, in which\n  1) each part has at most $d$ vertices, i.e., $\\lvert V_i \\rvert \\leq d$ for\nall $i \\in [k]$,\n  2) for any two parts $V_i$ and $V_j$, each vertex in $V_i$ has an incoming\nedge from some vertex in $V_j$ and vice-versa, and\n  3) there exists no cycle in $G$ that contains at most one vertex from each\npart.\n  We show that any upper bound on $R(d)$ directly translates to a sublinear\nbound on the number of unallocated goods. We establish a polynomial upper bound\non $R(d)$, yielding our main result. Furthermore, our approach is constructive,\nwhich also gives a polynomial-time algorithm for finding such an allocation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 10:40:11 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Chaudhury", "Bhaskar Ray", ""], ["Garg", "Jugal", ""], ["Mehlhorn", "Kurt", ""], ["Mehta", "Ruta", ""], ["Misra", "Pranabendu", ""]]}, {"id": "2103.01640", "submitter": "Bertrand Simon", "authors": "Alexander Lindermayr, Nicole Megow, Bertrand Simon", "title": "Double Coverage with Machine-Learned Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fundamental online $k$-server problem in a learning-augmented\nsetting. While in the traditional online model, an algorithm has no information\nabout the request sequence, we assume that there is given some advice (e.g.\nmachine-learned predictions) on an algorithm's decision. There is, however, no\nguarantee on the quality of the prediction and it might be far from being\ncorrect.\n  Our main result is a learning-augmented variation of the well-known Double\nCoverage algorithm for k-server on the line (Chrobak et al., SIDMA 1991) in\nwhich we integrate predictions as well as our trust into their quality. We give\nan error-dependent competitive ratio, which is a function of a user-defined\ntrustiness parameter, and which interpolates smoothly between an optimal\nconsistency, the performance in case that all predictions are correct, and the\nbest-possible robustness regardless of the prediction quality. When given good\npredictions, we improve upon known lower bounds for online algorithms without\nadvice. We further show that our algorithm achieves for any k an almost optimal\nconsistency-robustness tradeoff, within a class of deterministic algorithms\nrespecting local and memoryless properties. Our algorithm outperforms a\npreviously proposed (more general) learning-augmented algorithm. It is\nremarkable that the previous algorithm heavily exploits memory, whereas our\nalgorithm is memoryless. Finally, we demonstrate in experiments the\npracticability and the superior performance of our algorithm on real-world\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 11:04:33 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Lindermayr", "Alexander", ""], ["Megow", "Nicole", ""], ["Simon", "Bertrand", ""]]}, {"id": "2103.01872", "submitter": "Dimitrios Thilikos", "authors": "\\\"Oznur Ya\\c{s}ar Diner and Archontia C. Giannopoulou and Giannos\n  Stamoulis and Dimitrios M. Thilikos", "title": "Block Elimination Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the block elimination distance as a measure of how close a graph\nis to some particular graph class. Formally, given a graph class ${\\cal G}$,\nthe class ${\\cal B}({\\cal G})$ contains all graphs whose blocks belong to\n${\\cal G}$ and the class ${\\cal A}({\\cal G})$ contains all graphs where the\nremoval of a vertex creates a graph in ${\\cal G}$. Given a hereditary graph\nclass ${\\cal G}$, we recursively define ${\\cal G}^{(k)}$ so that ${\\cal\nG}^{(0)}={\\cal B}({\\cal G})$ and, if $k\\geq 1$, ${\\cal G}^{(k)}={\\cal B}({\\cal\nA}({\\cal G}^{(k-1)}))$. The block elimination distance of a graph $G$ to a\ngraph class ${\\cal G}$ is the minimum $k$ such that $G\\in{\\cal G}^{(k)}$ and\ncan be seen as an analog of the elimination distance parameter, with the\ndifference that connectivity is now replaced by biconnectivity. We show that,\nfor every non-trivial hereditary class ${\\cal G}$, the problem of deciding\nwhether $G\\in{\\cal G}^{(k)}$ is NP-complete. We focus on the case where ${\\cal\nG}$ is minor-closed and we study the minor obstruction set of ${\\cal G}^{(k)}$.\nWe prove that the size of the obstructions of ${\\cal G}^{(k)}$ is upper bounded\nby some explicit function of $k$ and the maximum size of a minor obstruction of\n${\\cal G}$. This implies that the problem of deciding whether $G\\in{\\cal\nG}^{(k)}$ is constructively fixed parameter tractable, when parameterized by\n$k$. Our results are based on a structural characterization of the obstructions\nof ${\\cal B}({\\cal G})$, relatively to the obstructions of ${\\cal G}$. We give\ntwo graph operations that generate members of ${\\cal G}^{(k)}$ from members of\n${\\cal G}^{(k-1)}$ and we prove that this set of operations is complete for the\nclass ${\\cal O}$ of outerplanar graphs. This yields the identification of all\nmembers ${\\cal O}\\cap{\\cal G}^{(k)}$, for every $k\\in\\mathbb{N}$ and every\nnon-trivial minor-closed graph class ${\\cal G}$.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 17:12:09 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Diner", "\u00d6znur Ya\u015far", ""], ["Giannopoulou", "Archontia C.", ""], ["Stamoulis", "Giannos", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2103.02013", "submitter": "Leonidas Tsepenekas", "authors": "Brian Brubach, Darshan Chakrabarti, John P. Dickerson, Aravind\n  Srinivasan, Leonidas Tsepenekas", "title": "Fairness, Semi-Supervised Learning, and More: A General Framework for\n  Clustering with Stochastic Pairwise Constraints", "comments": "This paper appeared in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric clustering is fundamental in areas ranging from Combinatorial\nOptimization and Data Mining, to Machine Learning and Operations Research.\nHowever, in a variety of situations we may have additional requirements or\nknowledge, distinct from the underlying metric, regarding which pairs of points\nshould be clustered together. To capture and analyze such scenarios, we\nintroduce a novel family of \\emph{stochastic pairwise constraints}, which we\nincorporate into several essential clustering objectives (radius/median/means).\nMoreover, we demonstrate that these constraints can succinctly model an\nintriguing collection of applications, including among others \\emph{Individual\nFairness} in clustering and \\emph{Must-link} constraints in semi-supervised\nlearning. Our main result consists of a general framework that yields\napproximation algorithms with provable guarantees for important clustering\nobjectives, while at the same time producing solutions that respect the\nstochastic pairwise constraints. Furthermore, for certain objectives we devise\nimproved results in the case of Must-link constraints, which are also the best\npossible from a theoretical perspective. Finally, we present experimental\nevidence that validates the effectiveness of our algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 20:27:58 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Brubach", "Brian", ""], ["Chakrabarti", "Darshan", ""], ["Dickerson", "John P.", ""], ["Srinivasan", "Aravind", ""], ["Tsepenekas", "Leonidas", ""]]}, {"id": "2103.02014", "submitter": "Avishek Bose", "authors": "Andjela Mladenovic, Avishek Joey Bose, Hugo Berard, William L.\n  Hamilton, Simon Lacoste-Julien, Pascal Vincent, Gauthier Gidel", "title": "Online Adversarial Attacks", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 20:36:04 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:47:35 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 02:19:04 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Mladenovic", "Andjela", ""], ["Bose", "Avishek Joey", ""], ["Berard", "Hugo", ""], ["Hamilton", "William L.", ""], ["Lacoste-Julien", "Simon", ""], ["Vincent", "Pascal", ""], ["Gidel", "Gauthier", ""]]}, {"id": "2103.02253", "submitter": "Agnes Cseh", "authors": "Haris Aziz, Agnes Cseh, John P. Dickerson, Duncan C. McElfresh", "title": "Optimal Kidney Exchange with Immunosuppressants", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms for exchange of kidneys is one of the key successful applications\nin market design, artificial intelligence, and operations research. Potent\nimmunosuppressant drugs suppress the body's ability to reject a transplanted\norgan up to the point that a transplant across blood- or tissue-type\nincompatibility becomes possible. In contrast to the standard kidney exchange\nproblem, we consider a setting that also involves the decision about which\nrecipients receive from the limited supply of immunosuppressants that make them\ncompatible with originally incompatible kidneys. We firstly present a general\ncomputational framework to model this problem. Our main contribution is a range\nof efficient algorithms that provide flexibility in terms of meeting meaningful\nobjectives. Motivated by the current reality of kidney exchanges using\nsophisticated mathematical-programming-based clearing algorithms, we then\npresent a general but scalable approach to optimal clearing with\nimmunosuppression; we validate our approach on realistic data from a large\nfielded exchange.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 08:38:27 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Aziz", "Haris", ""], ["Cseh", "Agnes", ""], ["Dickerson", "John P.", ""], ["McElfresh", "Duncan C.", ""]]}, {"id": "2103.02512", "submitter": "Ali Vakilian", "authors": "Yury Makarychev and Ali Vakilian", "title": "Approximation Algorithms for Socially Fair Clustering", "comments": "COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $(e^{O(p)} \\frac{\\log \\ell}{\\log\\log\\ell})$-approximation\nalgorithm for socially fair clustering with the $\\ell_p$-objective. In this\nproblem, we are given a set of points in a metric space. Each point belongs to\none (or several) of $\\ell$ groups. The goal is to find a $k$-medians,\n$k$-means, or, more generally, $\\ell_p$-clustering that is simultaneously good\nfor all of the groups. More precisely, we need to find a set of $k$ centers $C$\nso as to minimize the maximum over all groups $j$ of $\\sum_{u \\text{ in group\n}j} d(u,C)^p$. The socially fair clustering problem was independently proposed\nby Ghadiri, Samadi, and Vempala [2021] and Abbasi, Bhaskara, and\nVenkatasubramanian [2021]. Our algorithm improves and generalizes their\n$O(\\ell)$-approximation algorithms for the problem. The natural LP relaxation\nfor the problem has an integrality gap of $\\Omega(\\ell)$. In order to obtain\nour result, we introduce a strengthened LP relaxation and show that it has an\nintegrality gap of $\\Theta(\\frac{\\log \\ell}{\\log\\log\\ell})$ for a fixed $p$.\nAdditionally, we present a bicriteria approximation algorithm, which\ngeneralizes the bicriteria approximation of Abbasi et al. [2021].\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 16:36:21 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 04:06:21 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Makarychev", "Yury", ""], ["Vakilian", "Ali", ""]]}, {"id": "2103.02515", "submitter": "Peter C Dillinger", "authors": "Peter C. Dillinger and Stefan Walzer", "title": "Ribbon filter: practically smaller than Bloom and Xor", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Filter data structures over-approximate a set of hashable keys, i.e. set\nmembership queries may incorrectly come out positive. A filter with false\npositive rate $f \\in (0,1]$ is known to require $\\ge \\log_2(1/f)$ bits per key.\nAt least for larger $f \\ge 2^{-4}$, existing practical filters require a space\noverhead of at least 20% with respect to this information-theoretic bound.\n  We introduce the Ribbon filter: a new filter for static sets with a broad\nrange of configurable space overheads and false positive rates with competitive\nspeed over that range, especially for larger $f \\ge 2^{-7}$. In many cases,\nRibbon is faster than existing filters for the same space overhead, or can\nachieve space overhead below 10% with some additional CPU time. An experimental\nRibbon design with load balancing can even achieve space overheads below 1%.\n  A Ribbon filter resembles an Xor filter modified to maximize locality and is\nconstructed by solving a band-like linear system over Boolean variables. In\nprevious work, Dietzfelbinger and Walzer describe this linear system and an\nefficient Gaussian solver. We present and analyze a faster, more adaptable\nsolving process we call \"Rapid Incremental Boolean Banding ON the fly,\" which\nresembles hash table construction. We also present and analyze an attractive\nRibbon variant based on making the linear system homogeneous, and describe\nseveral more practical enhancements.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 16:41:36 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 16:14:45 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Dillinger", "Peter C.", ""], ["Walzer", "Stefan", ""]]}, {"id": "2103.02605", "submitter": "Andreas Rosowski", "authors": "Andreas Rosowski", "title": "On Fast Computation of a Circulant Matrix-Vector Product", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with circulant matrices. It is shown that a circulant matrix\ncan be multiplied by a vector in time O(n log(n)) in a ring with roots of unity\nwithout making use of an FFT algorithm. With our algorithm we achieve a speedup\nof a factor of about 2.25 for the multiplication of two polynomials with\ninteger coefficients compared to multiplication by an FFT algorithm. Moreover\nthis paper discusses multiplication of large integers as further application.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 11:33:34 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Rosowski", "Andreas", ""]]}, {"id": "2103.02914", "submitter": "Stefano Ardizzoni", "authors": "Stefano Ardizzoni, Luca Consolini, Mattia Laurini, Marco Locatelli", "title": "The Bounded Acceleration Shortest Path problem: complexity and solution\n  algorithms", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The purpose of this work is to introduce and characterize the Bounded\nAcceleration Shortest Path (BASP) problem, a generalization of the Shortest\nPath (SP) problem. This problem is associated to a graph: the nodes represent\npositions of a mobile vehicle and the arcs are associated to pre-assigned\ngeometric paths that connect these positions. BASP consists in finding the\nminimum-time path between two nodes. Differently from SP, we require that the\nvehicle satisfy bounds on maximum and minimum acceleration and speed, that\ndepend on the vehicle position on the currently traveled arc. We prove that\nBASP is NP-hard and define solution algorithm that achieves polynomial\ntime-complexity under some additional hypotheses on problem data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 09:39:54 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ardizzoni", "Stefano", ""], ["Consolini", "Luca", ""], ["Laurini", "Mattia", ""], ["Locatelli", "Marco", ""]]}, {"id": "2103.02919", "submitter": "Ngai Lam Ho", "authors": "Francis Yuk Lun Chin and Ngai Lam Ho and Alfredo De Santis and S.K.\n  Kim", "title": "A Simple Algorithm for the Constrained Sequence Problems", "comments": "https://doi.org/10.1016/j.ipl.2004.02.008", "journal-ref": "Elsevier Information Processing Letters Volume 90, Issue 4, 31 May\n  2004, Pages 175-179", "doi": "10.1016/j.ipl.2004.02.008", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the constrained longest common subsequence problem.\nGiven two sequences $X$, $Y$ and a constrained sequence $P$, a sequence $Z$ is\na constrained longest common subsequence for $X$ and $Y$ with respect to $P$ if\n$Z$ is the longest subsequence of $X$ and $Y$ such that $P$ is a subsequence of\n$Z$. Recently, Tsai \\cite{Tsai} proposed an $O(n^2 \\cdot m^2 \\cdot r)$ time\nalgorithm to solve this problem using dynamic programming technique, where $n$,\n$m$ and $r$ are the lengths of $X$, $Y$ and $P$, respectively. In this paper,\nwe present a simple algorithm to solve the constrained longest common\nsubsequence problem in $O(n \\cdot m \\cdot r)$ time and show that the\nconstrained longest common subsequence problem is equivalent to a special case\nof the constrained multiple sequence alignment problem which can also be\nsolved.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 09:50:45 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Chin", "Francis Yuk Lun", ""], ["Ho", "Ngai Lam", ""], ["De Santis", "Alfredo", ""], ["Kim", "S. K.", ""]]}, {"id": "2103.02936", "submitter": "Dhanyamol Antony", "authors": "Dhanyamol Antony, Jay Garchar, Sagartanu Pal, R. B. Sandeep, Sagnik\n  Sen, and R. Subashini", "title": "On subgraph complementation to H-free graphs", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a class $\\mathcal{G}$ of graphs, the problem SUBGRAPH COMPLEMENT TO\n$\\mathcal{G}$ asks whether one can find a subset $S$ of vertices of the input\ngraph $G$ such that complementing the subgraph induced by $S$ in $G$ results in\na graph in $\\mathcal{G}$. We investigate the complexity of the problem when\n$\\mathcal{G}$ is $H$-free for $H$ being a complete graph, a star, a path, or a\ncycle. We obtain the following results:\n  - When $H$ is a $K_t$ (a complete graph on $t$ vertices) for any fixed $t\\geq\n1$, the problem is solvable in polynomial-time. This applies even when\n$\\mathcal{G}$ is a subclass of $K_t$-free graphs recognizable in\npolynomial-time, for example, the class of $(t-2)$-degenerate graphs.\n  - When $H$ is a $K_{1,t}$ (a star graph on $t+1$ vertices), we obtain that\nthe problem is NP-complete for every $t\\geq 5$. This, along with known results,\nleaves only two unresolved cases - $K_{1,3}$ and $K_{1,4}$.\n  - When $H$ is a $P_t$ (a path on $t$ vertices), we obtain that the problem is\nNP-complete for every $t\\geq 7$, leaving behind only two unresolved cases -\n$P_5$ and $P_6$.\n  - When $H$ is a $C_t$ (a cycle on $t$ vertices), we obtain that the problem\nis NP-complete for every $t\\geq 8$, leaving behind four unresolved cases -\n$C_4, C_5, C_6,$ and $C_7$.\n  Further, we prove that these hard problems do not admit subexponential-time\nalgorithms (algorithms running in time $2^{o(|V(G)|)}$), assuming the\nExponential Time Hypothesis. A simple complementation argument implies that\nresults for $\\mathcal{G}$ are applicable for $\\overline{\\mathcal{G}}$, thereby\nobtaining similar results for $H$ being the complement of a complete graph, a\nstar, a path, or a cycle. Our results generalize two main results and resolve\none open question by Fomin et al. (Algorithmica, 2020).\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 10:37:09 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Antony", "Dhanyamol", ""], ["Garchar", "Jay", ""], ["Pal", "Sagartanu", ""], ["Sandeep", "R. B.", ""], ["Sen", "Sagnik", ""], ["Subashini", "R.", ""]]}, {"id": "2103.02972", "submitter": "Tim Seppelt", "authors": "Gaurav Rattan and Tim Seppelt", "title": "Weisfeiler--Leman, Graph Spectra, and Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Weisfeiler--Leman algorithm is a ubiquitous tool for the Graph\nIsomorphism Problem with various characterisations in e.g. descriptive\ncomplexity and convex optimisation. It is known that graphs that are not\ndistinguished by the two-dimensional variant have cospectral adjacency\nmatrices. We tackle a converse problem by proposing a set of matrices called\nGeneralised Laplacians that characterises the expressiveness of WL in terms of\nspectra. As an application to random walks, we show using Generalised\nLaplacians that the edge colours produced by 2-WL determine commute distances.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 11:48:09 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Rattan", "Gaurav", ""], ["Seppelt", "Tim", ""]]}, {"id": "2103.03035", "submitter": "Charis Papadopoulos", "authors": "Charis Papadopoulos and Spyridon Tzimas", "title": "Computing Subset Feedback Vertex Set via Leafage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chordal graphs are characterized as the intersection graphs of subtrees in a\ntree and such a representation is known as the tree model. Restricting the\ncharacterization results in well-known subclasses of chordal graphs such as\ninterval graphs or split graphs. A typical example that behaves computationally\ndifferent in subclasses of chordal graph is the \\textsc{Subset Feedback Vertex\nSet} (SFVS) problem: given a graph $G=(V,E)$ and a set $S\\subseteq V$, SFVS\nasks for a minimum set of vertices that intersects all cycles containing a\nvertex of $S$. SFVS is known to be polynomial-time solvable on interval graphs,\nwhereas SFVS remains \\NP-complete on split graphs and, consequently, on chordal\ngraphs. Towards a better understanding of the complexity of SFVS on subclasses\nof chordal graphs, we exploit structural properties of a tree model in order to\ncope with the hardness of SFVS. Here we consider variants of the \\emph{leafage}\nthat measures the minimum number of leaves in a tree model. We show that SFVS\ncan be solved in polynomial time for every chordal graph with bounded leafage.\nIn particular, given a chordal graph on $n$ vertices with leafage $\\ell$, we\nprovide an algorithm for SFVS with running time $n^{O(\\ell)}$. Pushing further\nour positive result, it is natural to consider a slight generalization of\nleafage, the \\emph{vertex leafage}, which measures the smallest number among\nthe maximum number of leaves of all subtrees in a tree model. However, we show\nthat it is unlikely to obtain a similar result, as we prove that SFVS remains\n\\NP-complete on undirected path graphs, i.e., graphs having vertex leafage at\nmost two. Moreover, we strengthen previously-known polynomial-time algorithm\nfor SFVS on directed path graphs that form a proper subclass of undirected path\ngraphs and graphs of mim-width one.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 13:48:41 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Papadopoulos", "Charis", ""], ["Tzimas", "Spyridon", ""]]}, {"id": "2103.03228", "submitter": "Richard Phillips", "authors": "Avrim Blum, Nika Haghtalab, Richard Lanas Phillips, Han Shao", "title": "One for One, or All for All: Equilibria and Optimality of Collaboration\n  in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, federated learning has been embraced as an approach for\nbringing about collaboration across large populations of learning agents.\nHowever, little is known about how collaboration protocols should take agents'\nincentives into account when allocating individual resources for communal\nlearning in order to maintain such collaborations. Inspired by game theoretic\nnotions, this paper introduces a framework for incentive-aware learning and\ndata sharing in federated learning. Our stable and envy-free equilibria capture\nnotions of collaboration in the presence of agents interested in meeting their\nlearning objectives while keeping their own sample collection burden low. For\nexample, in an envy-free equilibrium, no agent would wish to swap their\nsampling burden with any other agent and in a stable equilibrium, no agent\nwould wish to unilaterally reduce their sampling burden.\n  In addition to formalizing this framework, our contributions include\ncharacterizing the structural properties of such equilibria, proving when they\nexist, and showing how they can be computed. Furthermore, we compare the sample\ncomplexity of incentive-aware collaboration with that of optimal collaboration\nwhen one ignores agents' incentives.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 18:53:17 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Blum", "Avrim", ""], ["Haghtalab", "Nika", ""], ["Phillips", "Richard Lanas", ""], ["Shao", "Han", ""]]}, {"id": "2103.03264", "submitter": "Eddie Schoute", "authors": "Aniruddha Bapat, Andrew M. Childs, Alexey V. Gorshkov, Samuel King,\n  Eddie Schoute, Hrishee Shastri", "title": "Quantum routing with fast reversals", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methods for implementing arbitrary permutations of qubits under\ninteraction constraints. Our protocols make use of previous methods for rapidly\nreversing the order of qubits along a path. Given nearest-neighbor interactions\non a path of length $n$, we show that there exists a constant $\\epsilon \\approx\n0.034$ such that the quantum routing time is at most $(1-\\epsilon)n$, whereas\nany swap-based protocol needs at least time $n-1$. This represents the first\nknown quantum advantage over swap-based routing methods and also gives improved\nquantum routing times for realistic architectures such as grids. Furthermore,\nwe show that our algorithm approaches a quantum routing time of $2n/3$ in\nexpectation for uniformly random permutations, whereas swap-based protocols\nrequire time $n$ asymptotically. Additionally, we consider sparse permutations\nthat route $k \\le n$ qubits and give algorithms with quantum routing time at\nmost $n/3 + O(k^2)$ on paths and at most $2r/3 + O(k^2)$ on general graphs with\nradius $r$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 19:00:11 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bapat", "Aniruddha", ""], ["Childs", "Andrew M.", ""], ["Gorshkov", "Alexey V.", ""], ["King", "Samuel", ""], ["Schoute", "Eddie", ""], ["Shastri", "Hrishee", ""]]}, {"id": "2103.03294", "submitter": "Panagiotis Charalampopoulos", "authors": "Panagiotis Charalampopoulos, Pawe{\\l} Gawrychowski, Shay Mozes, Oren\n  Weimann", "title": "An Almost Optimal Edit Distance Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of preprocessing two strings $S$ and $T$, of lengths\n$m$ and $n$, respectively, in order to be able to efficiently answer the\nfollowing queries: Given positions $i,j$ in $S$ and positions $a,b$ in $T$,\nreturn the optimal alignment of $S[i \\mathinner{.\\,.} j]$ and $T[a\n\\mathinner{.\\,.} b]$. Let $N=mn$. We present an oracle with preprocessing time\n$N^{1+o(1)}$ and space $N^{1+o(1)}$ that answers queries in $\\log^{2+o(1)}N$\ntime. In other words, we show that we can query the alignment of every two\nsubstrings in almost the same time it takes to compute just the alignment of\n$S$ and $T$. Our oracle uses ideas from our distance oracle for planar graphs\n[STOC 2019] and exploits the special structure of the alignment graph.\nConditioned on popular hardness conjectures, this result is optimal up to\nsubpolynomial factors. Our results apply to both edit distance and longest\ncommon subsequence (LCS).\n  The best previously known oracle with construction time and size\n$\\mathcal{O}(N)$ has slow $\\Omega(\\sqrt{N})$ query time [Sakai, TCS 2019], and\nthe one with size $N^{1+o(1)}$ and query time $\\log^{2+o(1)}N$ (using a planar\ngraph distance oracle) has slow $\\Omega(N^{3/2})$ construction time [Long &\nPettie, SODA 2021]. We improve both approaches by roughly a $\\sqrt N$ factor.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 20:07:00 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Charalampopoulos", "Panagiotis", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Mozes", "Shay", ""], ["Weimann", "Oren", ""]]}, {"id": "2103.03337", "submitter": "Tanvi Bajpai", "authors": "Tanvi Bajpai, Deeparnab Chakrabarty, Chandra Chekuri, Maryam Negahbani", "title": "Revisiting Priority $k$-Center: Fairness and Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Priority $k$-Center problem, the input consists of a metric space\n$(X,d)$, an integer $k$ and for each point $v \\in X$ a priority radius $r(v)$.\nThe goal is to choose $k$-centers $S \\subseteq X$ to minimize $\\max_{v \\in X}\n\\frac{1}{r(v)} d(v,S)$. If all $r(v)$'s were uniform, one obtains the classical\n$k$-center problem. Plesn\\'ik [Plesn\\'ik, Disc. Appl. Math. 1987] introduced\nthis problem and gave a $2$-approximation algorithm matching the best possible\nalgorithm for vanilla $k$-center. We show how the problem is related to two\ndifferent notions of fair clustering [Harris et al., NeurIPS 2018; Jung et al.,\nFORC 2020]. Motivated by these developments we revisit the problem and, in our\nmain technical contribution, develop a framework that yields constant factor\napproximation algorithms for Priority $k$-Center with outliers. Our framework\nextends to generalizations of Priority $k$-Center to matroid and knapsack\nconstraints, and as a corollary, also yields algorithms with fairness\nguarantees in the lottery model of Harris et al.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 21:15:37 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bajpai", "Tanvi", ""], ["Chakrabarty", "Deeparnab", ""], ["Chekuri", "Chandra", ""], ["Negahbani", "Maryam", ""]]}, {"id": "2103.03346", "submitter": "Joanna Berli\\'nska", "authors": "Yakov Zinder and Joanna Berli\\'nska and Charlie Peter", "title": "Maximising the total weight of on-time jobs on parallel machines subject\n  to a conflict graph", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-77876-7_19", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers scheduling on parallel machines under the constraint that\nsome pairs of jobs cannot be processed concurrently. Each job has an associated\nweight, and all jobs have the same deadline. The objective is to maximise the\ntotal weight of on-time jobs. The problem is known to be strongly NP-hard in\ngeneral. A polynomial-time algorithm for scheduling unit execution time jobs on\ntwo machines is proposed. The performance of a broad family of approximation\nalgorithms for scheduling unit execution time jobs on more than two machines is\nanalysed. For the case of arbitrary job processing times, two integer linear\nprogramming formulations are proposed and compared with two formulations known\nfrom the earlier literature. An iterated variable neighborhood search algorithm\nis also proposed and evaluated by means of computational experiments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 21:54:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zinder", "Yakov", ""], ["Berli\u0144ska", "Joanna", ""], ["Peter", "Charlie", ""]]}, {"id": "2103.03468", "submitter": "Shunsuke Inenaga", "authors": "Shiori Mitsuya, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai,\n  Masayuki Takeda", "title": "Compressed Communication Complexity of Hamming Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the communication complexity of the Hamming distance of two\nstrings. Bille et al. [SPIRE 2018] considered the communication complexity of\nthe longest common prefix (LCP) problem in the setting where the two parties\nhave their strings in a compressed form, i.e., represented by the Lempel-Ziv 77\nfactorization (LZ77) with/without self-references. We present a randomized\npublic-coin protocol for a joint computation of the Hamming distance of two\nstrings represented by LZ77 without self-references. While our scheme is\nheavily based on Bille et al.'s LCP protocol, our complexity analysis is\noriginal which uses Crochemore's C-factorization and Rytter's AVL-grammar. As a\nbyproduct, we also show that LZ77 with/without self-references are not\nmonotonic in the sense that their sizes can increase by a factor of 4/3 when a\nprefix of the string is removed.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 04:35:35 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 01:43:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Mitsuya", "Shiori", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""]]}, {"id": "2103.03653", "submitter": "Maciej Besta", "authors": "Maciej Besta, Zur Vonarburg-Shmaria, Yannick Schaffner, Leonardo\n  Schwarz, Grzegorz Kwasniewski, Lukas Gianinazzi, Jakub Beranek, Kacper Janda,\n  Tobias Holenstein, Sebastian Leisinger, Peter Tatkowski, Esref Ozdemir,\n  Adrian Balla, Marcin Copik, Philipp Lindenberger, Pavel Kalvoda, Marek\n  Konieczny, Onur Mutlu, Torsten Hoefler", "title": "GraphMineSuite: Enabling High-Performance and Programmable Graph Mining\n  Algorithms with Set Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.DS cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GraphMineSuite (GMS): the first benchmarking suite for graph\nmining that facilitates evaluating and constructing high-performance graph\nmining algorithms. First, GMS comes with a benchmark specification based on\nextensive literature review, prescribing representative problems, algorithms,\nand datasets. Second, GMS offers a carefully designed software platform for\nseamless testing of different fine-grained elements of graph mining algorithms,\nsuch as graph representations or algorithm subroutines. The platform includes\nparallel implementations of more than 40 considered baselines, and it\nfacilitates developing complex and fast mining algorithms. High modularity is\npossible by harnessing set algebra operations such as set intersection and\ndifference, which enables breaking complex graph mining algorithms into simple\nbuilding blocks that can be separately experimented with. GMS is supported with\na broad concurrency analysis for portability in performance insights, and a\nnovel performance metric to assess the throughput of graph mining algorithms,\nenabling more insightful evaluation. As use cases, we harness GMS to rapidly\nredesign and accelerate state-of-the-art baselines of core graph mining\nproblems: degeneracy reordering (by up to >2x), maximal clique listing (by up\nto >9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x),\nalso obtaining better theoretical performance bounds.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 13:26:18 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Besta", "Maciej", ""], ["Vonarburg-Shmaria", "Zur", ""], ["Schaffner", "Yannick", ""], ["Schwarz", "Leonardo", ""], ["Kwasniewski", "Grzegorz", ""], ["Gianinazzi", "Lukas", ""], ["Beranek", "Jakub", ""], ["Janda", "Kacper", ""], ["Holenstein", "Tobias", ""], ["Leisinger", "Sebastian", ""], ["Tatkowski", "Peter", ""], ["Ozdemir", "Esref", ""], ["Balla", "Adrian", ""], ["Copik", "Marcin", ""], ["Lindenberger", "Philipp", ""], ["Kalvoda", "Pavel", ""], ["Konieczny", "Marek", ""], ["Mutlu", "Onur", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2103.03868", "submitter": "Kyriakos Axiotis", "authors": "Kyriakos Axiotis, Adam Karczmarz, Anish Mukherjee, Piotr Sankowski,\n  Adrian Vladu", "title": "Decomposable Submodular Function Minimization via Maximum Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper bridges discrete and continuous optimization approaches for\ndecomposable submodular function minimization, in both the standard and\nparametric settings.\n  We provide improved running times for this problem by reducing it to a number\nof calls to a maximum flow oracle. When each function in the decomposition acts\non $O(1)$ elements of the ground set $V$ and is polynomially bounded, our\nrunning time is up to polylogarithmic factors equal to that of solving maximum\nflow in a sparse graph with $O(\\vert V \\vert)$ vertices and polynomial integral\ncapacities.\n  We achieve this by providing a simple iterative method which can optimize to\nhigh precision any convex function defined on the submodular base polytope,\nprovided we can efficiently minimize it on the base polytope corresponding to\nthe cut function of a certain graph that we construct. We solve this\nminimization problem by lifting the solutions of a parametric cut problem,\nwhich we obtain via a new efficient combinatorial reduction to maximum flow.\nThis reduction is of independent interest and implies some previously unknown\nbounds for the parametric minimum $s,t$-cut problem in multiple settings.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 18:46:38 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Axiotis", "Kyriakos", ""], ["Karczmarz", "Adam", ""], ["Mukherjee", "Anish", ""], ["Sankowski", "Piotr", ""], ["Vladu", "Adrian", ""]]}, {"id": "2103.03914", "submitter": "Frank Sommer", "authors": "Tomohiro Koana and Christian Komusiewicz and Frank Sommer", "title": "Essentially Tight Kernels for (Weakly) Closed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study kernelization of classic hard graph problems when the input graphs\nfulfill triadic closure properties. More precisely, we consider the recently\nintroduced parameters closure number $c$ and the weak closure number $\\gamma$\n[Fox et al., SICOMP 2020] in addition to the standard parameter solution size\n$k$. For Capacitated Vertex Cover, Connected Vertex Cover, and Induced Matching\nwe obtain the first kernels of size $k^{\\mathcal{O}(\\gamma)}$ and $(\\gamma\nk)^{\\mathcal{O}(\\gamma)}$, respectively, thus extending previous kernelization\nresults on degenerate graphs. The kernels are essentially tight, since these\nproblems are unlikely to admit kernels of size $k^{o(\\gamma)}$ by previous\nresults on their kernelization complexity in degenerate graphs [Cygan et al.,\nACM TALG 2017]. In addition, we provide lower bounds for the kernelization of\nIndependent Set on graphs with constant closure number~$c$ and kernels for\nDominating Set on weakly closed split graphs and weakly closed bipartite\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 19:45:11 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Koana", "Tomohiro", ""], ["Komusiewicz", "Christian", ""], ["Sommer", "Frank", ""]]}, {"id": "2103.03959", "submitter": "Krzysztof Sornat", "authors": "Krzysztof Sornat, Virginia Vassilevska Williams, Yinzhan Xu", "title": "Fine-Grained Complexity and Algorithms for the Schulze Voting Method", "comments": "19 pages, 2 algorithms, 2 tables. A previous version of this work\n  appears in EC 2021. In this version we strengthen Theorem 6.2 which now holds\n  also for the problem of finding a Schulze winner", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computational aspects of a well-known single-winner voting rule\ncalled the Schulze method [Schulze, 2003] which is used broadly in practice. In\nthis method the voters give (weak) ordinal preference ballots which are used to\ndefine the weighted majority graph (WMG) of direct comparisons between pairs of\ncandidates. The choice of the winner comes from indirect comparisons in the\ngraph, and more specifically from considering directed paths instead of direct\ncomparisons between candidates.\n  When the input is the WMG, to our knowledge, the fastest algorithm for\ncomputing all winners in the Schulze method uses a folklore reduction to the\nAll-Pairs Bottleneck Paths problem and runs in $O(m^{2.69})$ time, where $m$ is\nthe number of candidates. It is an interesting open question whether this can\nbe improved. Our first result is a combinatorial algorithm with a nearly\nquadratic running time for computing all winners. This running time is\nessentially optimal. If the input to the Schulze winners problem is not the WMG\nbut the preference profile, then constructing the WMG is a bottleneck that\nincreases the running time significantly; in the special case when there are\n$m$ candidates and $n=O(m)$ voters, the running time is $O(m^{2.69})$, or\n$O(m^{2.5})$ if there is a nearly-linear time algorithm for multiplying dense\nsquare matrices. To address this bottleneck, we prove a formal equivalence\nbetween the well-studied Dominance Product problem and the problem of computing\nthe WMG. We prove a similar connection between the so called Dominating Pairs\nproblem and the problem of finding a winner in the Schulze method.\n  Our paper is the first to bring fine-grained complexity into the field of\ncomputational social choice. Using it we can identify voting protocols that are\nunlikely to be practical for large numbers of candidates and/or voters, as\ntheir complexity is likely, say at least cubic.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 22:27:36 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:06:08 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Sornat", "Krzysztof", ""], ["Williams", "Virginia Vassilevska", ""], ["Xu", "Yinzhan", ""]]}, {"id": "2103.04205", "submitter": "Shaddin Dughmi", "authors": "Shaddin Dughmi", "title": "Matroid Secretary is Equivalent to Contention Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the matroid secretary problem is equivalent to correlated\ncontention resolution in the online random-order model. Specifically, the\nmatroid secretary conjecture is true if and only if every matroid admits an\nonline random-order contention resolution scheme which, given an arbitrary\n(possibly correlated) prior distribution over subsets of the ground set,\nmatches the balance ratio of the best offline scheme for that distribution up\nto a constant. We refer to such a scheme as universal. Our result indicates\nthat the core challenge of the matroid secretary problem lies in resolving\ncontention for positively correlated inputs, in particular when the positive\ncorrelation is benign in as much as offline contention resolution is concerned.\n  Our result builds on our previous work which establishes one direction of\nthis equivalence, namely that the secretary conjecture implies universal\nrandom-order contention resolution, as well as a weak converse, which derives a\nmatroid secretary algorithm from a random-order contention resolution scheme\nwith only partial knowledge of the distribution. It is this weak converse that\nwe strengthen in this paper: We show that universal random-order contention\nresolution for matroids, in the usual setting of a fully known prior\ndistribution, suffices to resolve the matroid secretary conjecture in the\naffirmative.\n  Our proof is the composition of three reductions. First, we use duality\narguments to reduce the matroid secretary problem to the matroid prophet\nsecretary problem with arbitrarily correlated distributions. Second, we\nintroduce a generalization of contention resolution we term labeled contention\nresolution, to which we reduce the correlated matroid prophet secretary\nproblem. Finally, we combine duplication of elements with limiting arguments to\nreduce labeled contention resolution to classical contention resolution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 22:46:29 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:31:59 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dughmi", "Shaddin", ""]]}, {"id": "2103.04447", "submitter": "Matthieu Latapy", "authors": "Matthieu Latapy, Thi Ha Duong Phan, Christophe Crespelle, Thanh Qui\n  Nguyen", "title": "Termination of Multipartite Graph Series Arising from Complex Network\n  Modelling", "comments": "Published in LNCS, proceedings of the 4th International Conference on\n  Combinatorial Optimization and Applications (COCOA), 2010", "journal-ref": null, "doi": "10.1007/978-3-642-17458-2_1", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An intense activity is nowadays devoted to the definition of models capturing\nthe properties of complex networks. Among the most promising approaches, it has\nbeen proposed to model these graphs via their clique incidence bipartite\ngraphs. However, this approach has, until now, severe limitations resulting\nfrom its incapacity to reproduce a key property of this object: the overlapping\nnature of cliques in complex networks. In order to get rid of these limitations\nwe propose to encode the structure of clique overlaps in a network thanks to a\nprocess consisting in iteratively factorising the maximal bicliques between the\nupper level and the other levels of a multipartite graph. We show that the most\nnatural definition of this factorising process leads to infinite series for\nsome instances. Our main result is to design a restriction of this process that\nterminates for any arbitrary graph. Moreover, we show that the resulting\nmultipartite graph has remarkable combinatorial properties and is closely\nrelated to another fundamental combinatorial object. Finally, we show that, in\npractice, this multipartite graph is computationally tractable and has a size\nthat makes it suitable for complex network modelling.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:30:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Latapy", "Matthieu", ""], ["Phan", "Thi Ha Duong", ""], ["Crespelle", "Christophe", ""], ["Nguyen", "Thanh Qui", ""]]}, {"id": "2103.04451", "submitter": "Matthieu Latapy", "authors": "Christophe Crespelle, Matthieu Latapy, Thi Ha Duong Phan", "title": "On the Termination of Some Biclique Operators on Multipartite Graphs", "comments": null, "journal-ref": "Discrete Applied Mathematics 195, 2015", "doi": "10.1016/j.dam.2015.02.006", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a new graph operator, called the weak-factor graph, which comes\nfrom the context of complex network modelling. The weak-factor operator is\nclose to the well-known clique-graph operator but it rather operates in terms\nof bicliques in a multipartite graph. We address the problem of the termination\nof the series of graphs obtained by iteratively applying the weak-factor\noperator starting from a given input graph. As for the clique-graph operator,\nit turns out that some graphs give rise to series that do not terminate.\nTherefore, we design a slight variation of the weak-factor operator, called\nclean-factor, and prove that its associated series terminates for all input\ngraphs. In addition, we show that the multipartite graph on which the series\nterminates has a very nice combinatorial structure: we exhibit a bijection\nbetween its vertices and the chains of the inclusion order on the intersections\nof the maximal cliques of the input graph.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:42:34 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Crespelle", "Christophe", ""], ["Latapy", "Matthieu", ""], ["Phan", "Thi Ha Duong", ""]]}, {"id": "2103.04502", "submitter": "Kyle E. C. Booth", "authors": "Kyle E. C. Booth, Bryan O'Gorman, Jeffrey Marshall, Stuart Hadfield,\n  Eleanor Rieffel", "title": "Quantum-accelerated constraint programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint programming (CP) is a paradigm used to model and solve constraint\nsatisfaction and combinatorial optimization problems. In CP, problems are\nmodeled with constraints that describe acceptable solutions and solved with\nbacktracking tree search augmented with logical inference. In this paper, we\nshow how quantum algorithms can accelerate CP, at both the levels of inference\nand search. Leveraging existing quantum algorithms, we introduce a\nquantum-accelerated filtering algorithm for the $\\texttt{alldifferent}$ global\nconstraint and discuss its applicability to a broader family of global\nconstraints with similar structure. We propose frameworks for the integration\nof quantum filtering algorithms within both classical and quantum backtracking\nsearch schemes, including a novel hybrid classical-quantum backtracking search\nmethod. This work suggests that CP is a promising candidate application for\nearly fault-tolerant quantum computers and beyond.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 01:29:53 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Booth", "Kyle E. C.", ""], ["O'Gorman", "Bryan", ""], ["Marshall", "Jeffrey", ""], ["Hadfield", "Stuart", ""], ["Rieffel", "Eleanor", ""]]}, {"id": "2103.04519", "submitter": "Mark Moir", "authors": "Victor Cacciari Miraldo and Harold Carr and Mark Moir and Lisandra\n  Silva and Guy L. Steele Jr", "title": "Formal Verification of Authenticated, Append-Only Skip Lists in Agda:\n  Extended Version", "comments": "This is an extended version of our paper published in the 10th ACM\n  SIGPLAN International Conference on Certified Programs and Proofs (CPP 2021).\n  This version (2021-02-23) presents a stronger version of the evocr property\n  than originally presented, and provides a link to our development in open\n  source", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Authenticated Append-Only Skiplists (AAOSLs) enable maintenance and querying\nof an authenticated log (such as a blockchain) without requiring any single\nparty to store or verify the entire log, or to trust another party regarding\nits contents. AAOSLs can help to enable efficient dynamic participation (e.g.,\nin consensus) and reduce storage overhead.\n  In this paper, we formalize an AAOSL originally described by Maniatis and\nBaker, and prove its key correctness properties. Our model and proofs are\nmachine checked in Agda. Our proofs apply to a generalization of the original\nconstruction and provide confidence that instances of this generalization can\nbe used in practice. Our formalization effort has also yielded some\nsimplifications and optimizations.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 02:43:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Miraldo", "Victor Cacciari", ""], ["Carr", "Harold", ""], ["Moir", "Mark", ""], ["Silva", "Lisandra", ""], ["Steele", "Guy L.", "Jr"]]}, {"id": "2103.04543", "submitter": "Young-San Lin", "authors": "Elena Grigorescu, Young-San Lin, and Kent Quanrud", "title": "Online Directed Spanners and Steiner Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present online algorithms for directed spanners and Steiner forests. These\nproblems fall under the unifying framework of online covering linear\nprogramming formulations, developed by Buchbinder and Naor (MOR, 34, 2009),\nbased on primal-dual techniques. Our results include the following:\n  For the pairwise spanner problem, in which the pairs of vertices to be\nspanned arrive online, we present an efficient randomized\n$\\tilde{O}(n^{4/5})$-competitive algorithm for graphs with general lengths,\nwhere $n$ is the number of vertices. With uniform lengths, we give an efficient\nrandomized $\\tilde{O}(n^{2/3+\\epsilon})$-competitive algorithm, and an\nefficient deterministic $\\tilde{O}(k^{1/2+\\epsilon})$-competitive algorithm,\nwhere $k$ is the number of terminal pairs. These are the first online\nalgorithms for directed spanners. In the offline setting, the current best\napproximation ratio with uniform lengths is $\\tilde{O}(n^{3/5 + \\epsilon})$,\ndue to Chlamtac, Dinitz, Kortsarz, and Laekhanukit (TALG 2020).\n  For the directed Steiner forest problem with uniform costs, in which the\npairs of vertices to be connected arrive online, we present an efficient\nrandomized $\\tilde{O}(n^{2/3 + \\epsilon})$-competitive algorithm. The\nstate-of-the-art online algorithm for general costs is due to Chakrabarty, Ene,\nKrishnaswamy, and Panigrahi (SICOMP 2018) and is $\\tilde{O}(k^{1/2 +\n\\epsilon})$-competitive. In the offline version, the current best approximation\nratio with uniform costs is $\\tilde{O}(n^{26/45 + \\epsilon})$, due to Abboud\nand Bodwin (SODA 2018).\n  A small modification of the online covering framework by Buchbinder and Naor\nimplies a polynomial-time primal-dual approach with separation oracles, which a\npriori might perform exponentially many calls. We convert the online spanner\nproblem and the online Steiner forest problem into online covering problems and\nround in a problem-specific fashion.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 04:37:09 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 01:00:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Grigorescu", "Elena", ""], ["Lin", "Young-San", ""], ["Quanrud", "Kent", ""]]}, {"id": "2103.04556", "submitter": "Jiaye Teng", "authors": "Jiaye Teng, Zeren Tan, Yang Yuan", "title": "T-SCI: A Two-Stage Conformal Inference Algorithm with Guaranteed\n  Coverage for Cox-MLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to deal with censored data, where we only have access to\nthe incomplete information of survival time instead of its exact value.\nFortunately, under linear predictor assumption, people can obtain guaranteed\ncoverage for the confidence band of survival time using methods like Cox\nRegression. However, when relaxing the linear assumption with neural networks\n(e.g., Cox-MLP (Katzman et al., 2018; Kvamme et al., 2019)), we lose the\nguaranteed coverage. To recover the guaranteed coverage without linear\nassumption, we propose two algorithms based on conformal inference. In the\nfirst algorithm WCCI, we revisit weighted conformal inference and introduce a\nnew non-conformity score based on partial likelihood. We then propose a\ntwo-stage algorithm T-SCI, where we run WCCI in the first stage and apply\nquantile conformal inference to calibrate the results in the second stage.\nTheoretical analysis shows that T-SCI returns guaranteed coverage under milder\nassumptions than WCCI. We conduct extensive experiments on synthetic data and\nreal data using different methods, which validate our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 05:42:05 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 07:20:34 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Teng", "Jiaye", ""], ["Tan", "Zeren", ""], ["Yuan", "Yang", ""]]}, {"id": "2103.04595", "submitter": "Naoto Ohsaka", "authors": "Naoto Ohsaka", "title": "A Fully Polynomial Parameterized Algorithm for Counting the Number of\n  Reachable Vertices in a Digraph", "comments": "minor changes, acknowledgments added", "journal-ref": null, "doi": "10.1016/j.ipl.2021.106137", "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the problem of counting the number of vertices reachable from\neach vertex in a digraph $G$, which is equal to computing all the out-degrees\nof the transitive closure of $G$. The current (theoretically) fastest\nalgorithms run in quadratic time; however, Borassi has shown that this probl m\nis not solvable in truly subquadratic time unless the Strong Exponential Time\nHypothesis fails [Inf. Process. Lett., 116(10):628--630, 2016]. In this paper,\nwe present an $\\mathcal{O}(f^3n)$-time exact algorithm, where $n$ is the number\nof vertices in $G$ and $f$ is the feedback edge number of $G$. Our algorithm\nthus runs in truly subquadratic time for digraphs of\n$f=\\mathcal{O}(n^{\\frac{1}{3}-\\epsilon})$ for any $\\epsilon > 0$, i.e., the\nnumber of edges is $n$ plus $\\mathcal{O}(n^{\\frac{1}{3}-\\epsilon})$, and is\nfully polynomial fixed parameter tractable, the notion of which was first\nintroduced by Fomin, Lokshtanov, Pilipczuk, Saurabh, and Wrochna [ACM Trans.\nAlgorithms, 14(3):34:1--34:45, 2018]. We also show that the same result holds\nfor vertex-weighted digraphs, where the task is to compute the total weights of\nvertices reachable from each vertex.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 08:24:47 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 13:47:24 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Ohsaka", "Naoto", ""]]}, {"id": "2103.04668", "submitter": "Rion Brattig Correia", "authors": "Tiago Simas and Rion Brattig Correia and Luis M. Rocha", "title": "The distance backbone of complex networks", "comments": "To appear in the Journal of Complex Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.IR q-bio.QM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Redundancy needs more precise characterization as it is a major factor in the\nevolution and robustness of networks of multivariate interactions. We\ninvestigate the complexity of such interactions by inferring a connection\ntransitivity that includes all possible measures of path length for weighted\ngraphs. The result, without breaking the graph into smaller components, is a\ndistance backbone subgraph sufficient to compute all shortest paths. This is\nimportant for understanding the dynamics of spread and communication phenomena\nin real-world networks. The general methodology we formally derive yields a\nprincipled graph reduction technique and provides a finer characterization of\nthe triangular geometry of all edges -- those that contribute to shortest paths\nand those that do not but are involved in other network phenomena. We\ndemonstrate that the distance backbone is very small in large networks across\ndomains ranging from air traffic to the human brain connectome, revealing that\nnetwork robustness to attacks and failures seems to stem from surprisingly vast\namounts of redundancy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 11:08:59 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 16:24:33 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Simas", "Tiago", ""], ["Correia", "Rion Brattig", ""], ["Rocha", "Luis M.", ""]]}, {"id": "2103.04955", "submitter": "Evangelos Kipouridis", "authors": "Evangelos Kipouridis, Paul G. Spirakis, Kostas Tsichlas", "title": "Threshold-based Network Structural Dynamics", "comments": "29 pages, extension of the Post-print containing all proofs, to\n  appear in SIROCCO 2021", "journal-ref": null, "doi": "10.1007/978-3-030-79527-6_8", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in dynamic processes on networks is steadily rising in recent\nyears. In this paper, we consider the $(\\alpha,\\beta)$-Thresholded Network\nDynamics ($(\\alpha,\\beta)$-Dynamics), where $\\alpha\\leq \\beta$, in which only\nstructural dynamics (dynamics of the network) are allowed, guided by local\nthresholding rules executed in each node. In particular, in each discrete round\n$t$, each pair of nodes $u$ and $v$ that are allowed to communicate by the\nscheduler, computes a value $\\mathcal{E}(u,v)$ (the potential of the pair) as a\nfunction of the local structure of the network at round $t$ around the two\nnodes. If $\\mathcal{E}(u,v) < \\alpha$ then the link (if it exists) between $u$\nand $v$ is removed; if $\\alpha \\leq \\mathcal{E}(u,v) < \\beta$ then an existing\nlink among $u$ and $v$ is maintained; if $\\beta \\leq \\mathcal{E}(u,v)$ then a\nlink between $u$ and $v$ is established if not already present.\n  The microscopic structure of $(\\alpha,\\beta)$-Dynamics appears to be simple,\nso that we are able to rigorously argue about it, but still flexible, so that\nwe are able to design meaningful microscopic local rules that give rise to\ninteresting macroscopic behaviors. Our goals are the following: a) to\ninvestigate the properties of the $(\\alpha,\\beta)$-Thresholded Network Dynamics\nand b) to show that $(\\alpha,\\beta)$-Dynamics is expressive enough to solve\ncomplex problems on networks.\n  Our contribution in these directions is twofold. We rigorously exhibit the\nclaim about the expressiveness of $(\\alpha,\\beta)$-Dynamics, both by designing\na simple protocol that provably computes the $k$-core of the network as well as\nby showing that $(\\alpha,\\beta)$-Dynamics is in fact Turing-Complete. Second\nand most important, we construct general tools for proving stabilization that\nwork for a subclass of $(\\alpha,\\beta)$-Dynamics and prove speed of convergence\nin a restricted setting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 18:23:11 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 14:15:49 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 06:51:47 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kipouridis", "Evangelos", ""], ["Spirakis", "Paul G.", ""], ["Tsichlas", "Kostas", ""]]}, {"id": "2103.05138", "submitter": "Nicolas Emmenegger", "authors": "Nicolas Emmenegger, Rasmus Kyng and Ahad N. Zehmakan", "title": "On the Oracle Complexity of Higher-Order Smooth Non-Convex Finite-Sum\n  Optimization", "comments": "Added missing upper bound assumption on n in Theorems 4.7 and 4.10", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove lower bounds for higher-order methods in smooth non-convex\nfinite-sum optimization. Our contribution is threefold: We first show that a\ndeterministic algorithm cannot profit from the finite-sum structure of the\nobjective, and that simulating a pth-order regularized method on the whole\nfunction by constructing exact gradient information is optimal up to constant\nfactors. We further show lower bounds for randomized algorithms and compare\nthem with the best known upper bounds. To address some gaps between the bounds,\nwe propose a new second-order smoothness assumption that can be seen as an\nanalogue of the first-order mean-squared smoothness assumption. We prove that\nit is sufficient to ensure state-of-the-art convergence guarantees, while\nallowing for a sharper lower bound.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 23:33:58 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 13:23:36 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Emmenegger", "Nicolas", ""], ["Kyng", "Rasmus", ""], ["Zehmakan", "Ahad N.", ""]]}, {"id": "2103.05394", "submitter": "Fatih Ta\\c{s}yaran", "authors": "Fatih Ta\\c{s}yaran, Berkay Demireller, Kamer Kaya, Bora U\\c{c}ar", "title": "Streaming Hypergraph Partitioning Algorithms on Limited Memory\n  Environments", "comments": "8 pages, 6 algorithms, 2 figures, 4 tables, submitted to HPCS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many well-known, real-world problems involve dynamic data which describe the\nrelationship among the entities. Hypergraphs are powerful combinatorial\nstructures that are frequently used to model such data. For many of today's\ndata-centric applications, this data is streaming; new items arrive\ncontinuously, and the data grows with time. With paradigms such as Internet of\nThings and Edge Computing, such applications become more natural and more\npractical. In this work, we assume a streaming model where the data is modeled\nas a hypergraph, which is generated at the edge. This data then partitioned and\nsent to remote nodes via an algorithm running on a memory-restricted device\nsuch as a single board computer. Such a partitioning is usually performed by\ntaking a connectivity metric into account to minimize the communication cost of\nlater analyses that will be performed in a distributed fashion. Although there\nare many offline tools that can partition static hypergraphs excellently,\nalgorithms for the streaming settings are rare. We analyze a well-known\nalgorithm from the literature and significantly improve its running time by\naltering its inner data structure. For instance, on a medium-scale hypergraph,\nthe new algorithm reduces the runtime from 17800 seconds to 10 seconds. We then\npropose sketch- and hash-based algorithms, as well as ones that can leverage\nextra memory to store a small portion of the data to enable the refinement of\npartitioning when possible. We experimentally analyze the performance of these\nalgorithms and report their run times, connectivity metric scores, and memory\nuses on a high-end server and four different single-board computer\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 12:33:57 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Ta\u015fyaran", "Fatih", ""], ["Demireller", "Berkay", ""], ["Kaya", "Kamer", ""], ["U\u00e7ar", "Bora", ""]]}, {"id": "2103.05460", "submitter": "Tetto Obata", "authors": "Tetto Obata", "title": "Dynamic Range Mode Enumeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The range mode problem is a fundamental problem and there is a lot of work\nabout it. There is also some work for the dynamic version of it and the\nenumerating version of it, but there is no previous research about the dynamic\nand enumerating version of it. We found an efficient algorithm for it.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 14:50:49 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Obata", "Tetto", ""]]}, {"id": "2103.05588", "submitter": "Marc Roth", "authors": "Marco Bressan and Marc Roth", "title": "Exact and Approximate Pattern Counting in Degenerate Graphs: New\n  Algorithms, Hardness Results, and Complexity Dichotomies", "comments": "44 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problems of counting the homomorphisms, counting the copies, and\ncounting the induced copies of a $k$-vertex graph $H$ in a $d$-degenerate\n$n$-vertex graph $G$. Our main result establishes exhaustive and explicit\ncomplexity classifications for counting subgraphs and induced subgraphs. We\nshow that the (not necessarily induced) copies of $H$ in $G$ can be counted in\ntime $f(k,d)\\cdot n^{\\max(\\mathsf{imn}(H),1)}\\cdot \\log n$, where $f$ is some\ncomputable function and $\\mathsf{imn}(H)$ is the size of the largest induced\nmatching of $H$. Whenever the class of allowed patterns has unbounded induced\nmatching number, this algorithm is essentially optimal: Unless the Exponential\nTime Hypothesis (ETH) fails, there is no algorithm running in time $f(k,d)\\cdot\nn^{o(\\mathsf{imn}(H)/\\log \\mathsf{imn}(H))}$ for any function $f$. In case of\ncounting induced subgraphs, we obtain a similar classification along the\nindependence number $\\alpha$: we can count the induced copies of $H$ in $G$ in\ntime $f(k,d)\\cdot n^{\\alpha(H)}\\cdot \\log n$, and if the class of allowed\npatterns has unbounded independence number, an algorithm running in time\n$f(k,d)\\cdot n^{o(\\alpha(H)/\\log \\alpha(H))}$ is impossible, unless ETH fails.\nIn the language of parameterized complexity, our results yield dichotomies in\nfixed-parameter tractable and $\\#\\mathsf{W}[1]$-hard cases if we parameterize\nby the size of the pattern and the degeneracy of the host graph. Our results\nimply that several patterns cannot be counted in time $f(k,d)\\cdot n^{o(k/\\log\nk)}$, including $k$-matchings, $k$-independent sets, (induced) $k$-paths,\n(induced) $k$-cycles, and induced $(k,k)$-bicliques, unless ETH fails. Those\nlower bounds for exact counting are complemented with new algorithms for\napproximate counting of subgraphs and induced subgraphs in degenerate graphs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 17:52:27 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 16:30:26 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Bressan", "Marco", ""], ["Roth", "Marc", ""]]}, {"id": "2103.05604", "submitter": "Stefano Leonardi", "authors": "Yossi Azar, Stefano Leonardi, Noam Touitou", "title": "Flow Time Scheduling with Uncertain Processing Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online scheduling on a single machine in order to\nminimize weighted flow time. The existing algorithms for this problem (STOC\n'01, SODA '03, FOCS '18) all require exact knowledge of the processing time of\neach job. This assumption is crucial, as even a slight perturbation of the\nprocessing time would lead to polynomial competitive ratio. However, this\nassumption very rarely holds in real-life scenarios.\n  In this paper, we present the first algorithm for weighted flow time which do\nnot require exact knowledge of the processing times of jobs. Specifically, we\nintroduce the Scheduling with Predicted Processing Time (SPPT) problem, where\nthe algorithm is given a prediction for the processing time of each job,\ninstead of its real processing time. For the case of a constant factor\ndistortion between the predictions and the real processing time, our algorithms\nmatch all the best known competitiveness bounds for weighted flow time --\nnamely $O(\\log P), O(\\log D)$ and $O(\\log W)$, where $P,D,W$ are the maximum\nratios of processing times, densities, and weights, respectively. For larger\nerrors, the competitiveness of our algorithms degrades gracefully.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 18:25:02 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Azar", "Yossi", ""], ["Leonardi", "Stefano", ""], ["Touitou", "Noam", ""]]}, {"id": "2103.05608", "submitter": "Manu Aggarwal", "authors": "Manu Aggarwal and Vipul Periwal", "title": "Dory: Overcoming Barriers to Computing Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.AT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistent homology (PH) is an approach to topological data analysis (TDA)\nthat computes multi-scale topologically invariant properties of\nhigh-dimensional data that are robust to noise. While PH has revealed useful\npatterns across various applications, computational requirements have limited\napplications to small data sets of a few thousand points. We present Dory, an\nefficient and scalable algorithm that can compute the persistent homology of\nlarge data sets. Dory uses significantly less memory than published algorithms\nand also provides significant reductions in the computation time compared to\nmost algorithms. It scales to process data sets with millions of points. As an\napplication, we compute the PH of the human genome at high resolution as\nrevealed by a genome-wide Hi-C data set. Results show that the topology of the\nhuman genome changes significantly upon treatment with auxin, a molecule that\ndegrades cohesin, corroborating the hypothesis that cohesin plays a crucial\nrole in loop formation in DNA.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 18:28:22 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 17:23:50 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 02:34:47 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Aggarwal", "Manu", ""], ["Periwal", "Vipul", ""]]}, {"id": "2103.05631", "submitter": "Bohdan Kivva", "authors": "Bohdan Kivva", "title": "Improved upper bounds for the rigidity of Kronecker products", "comments": "To appear at MFCS'21. This version includes rigidity bounds for\n  Hadamard matrices (Section 6), which were not present in the previous arxiv\n  version. 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rigidity of a matrix $A$ for target rank $r$ is the minimum number of\nentries of $A$ that need to be changed in order to obtain a matrix of rank at\nmost $r$. At MFCS'77, Valiant introduced matrix rigidity as a tool to prove\ncircuit lower bounds for linear functions and since then this notion received\nmuch attention and found applications in other areas of complexity theory. The\nproblem of constructing an explicit family of matrices that are sufficiently\nrigid for Valiant's reduction (Valiant-rigid) still remains open. Moreover,\nsince 2017 most of the long-studied candidates have been shown not to be\nValiant-rigid. Some of those former candidates for rigidity are Kronecker\nproducts of small matrices.\n  In a recent paper (STOC'21), Alman gave a general non-rigidity result for\nsuch matrices: he showed that if an $n\\times n$ matrix $A$ (over any field) is\na Kronecker product of $d\\times d$ matrices $M_1,\\dots, M_k$ (so $n=d^k$)\n$(d\\ge 2)$ then changing only $n^{1+\\varepsilon}$ entries of $A$ one can reduce\nits rank to $\\le n^{1-\\gamma}$, where $1/\\gamma$ is roughly\n$2^d/\\varepsilon^2$.\n  In this note we improve this result in two directions. First, we do not\nrequire the matrices $M_i$ to have equal size. Second, we reduce $1/\\gamma$\nfrom exponential in $d$ to roughly $d^{3/2}/\\varepsilon^2$ (where $d$ is the\nmaximum size of the matrices $M_i$), and to nearly linear (roughly\n$d/\\varepsilon^2$) for matrices $M_i$ of sizes within a constant factor of each\nother.\n  As an application of our results we significantly expand the class of\nHadamard matrices that are known not to be Valiant-rigid; these now include the\nKronecker products of Paley-Hadamard matrices and Hadamard matrices of bounded\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 18:59:17 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:55:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Kivva", "Bohdan", ""]]}, {"id": "2103.05933", "submitter": "Barun Gorain", "authors": "Barun Gorain, Kaushik Mondal, Himadri Nayak, and Supantha Pandit", "title": "Pebble Guided Near Optimal Treasure Hunt in Anonymous Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of treasure hunt in a graph by a mobile agent. The nodes\nin the graph are anonymous and the edges at any node $v$ of degree $deg(v)$ are\nlabeled arbitrarily as $0,1,\\ldots, deg(v)-1$. A mobile agent, starting from a\nnode, must find a stationary object, called {\\it treasure} that is located on\nan unknown node at a distance $D$ from its initial position. The agent finds\nthe treasure when it reaches the node where the treasure is present. The {\\it\ntime} of treasure hunt is defined as the number of edges the agent visits\nbefore it finds the treasure. The agent does not have any prior knowledge about\nthe graph or the position of the treasure. An Oracle, that knows the graph, the\ninitial position of the agent, and the position of the treasure, places some\npebbles on the nodes, at most one per node, of the graph to guide the agent\ntowards the treasure.\n  We target to answer the question: what is the fastest possible treasure hunt\nalgorithm regardless of the number of pebbles are placed?\n  We show an algorithm that uses $O(D \\log \\Delta)$ pebbles to find the\ntreasure in a graph $G$ in time $O(D \\log \\Delta + \\log^3 \\Delta)$, where\n$\\Delta$ is the maximum degree of a node in $G$ and $D$ is the distance from\nthe initial position of the agent to the treasure. We show an almost matching\nlower bound of $\\Omega(D \\log \\Delta)$ on time of the treasure hunt using any\nnumber of pebbles.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 08:45:07 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Gorain", "Barun", ""], ["Mondal", "Kaushik", ""], ["Nayak", "Himadri", ""], ["Pandit", "Supantha", ""]]}, {"id": "2103.05952", "submitter": "Petar Nikolov", "authors": "Petar Nikolov", "title": "Quantum Algorithms in Cybernetics", "comments": "Doctoral Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.SY eess.SY math.PR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A new method for simulation of a binary homogeneous Markov process using a\nquantum computer was proposed. This new method allows using the distinguished\nproperties of the quantum mechanical systems -- superposition, entanglement and\nprobability calculations. Implementation of an algorithm based on this method\nrequires the creation of a new quantum logic gate, which creates entangled\nstate between two qubits. This is a two-qubit logic gate and it must perform a\npredefined rotation over the X-axis for the qubit that acts as a target, where\nthe rotation accurately represents the transient probabilities for a given\nMarkov process. This gate fires only when the control qubit is in state |1>. It\nis necessary to develop an algorithm, which uses the distribution for the\ntransient probabilities of the process in a simple and intuitive way and then\ntransform those into X-axis offsets. The creation of a quantum controlled n-th\nroot of X gate using only the existing basic quantum logic gates at the\navailable cloud platforms is possible, although the hardware devices are still\ntoo noisy, which results in a significant measurement error increase. The IBM's\nYorktown 'bow-tie' back-end performs quite better than the 5-qubit T-shaped and\nthe 14-qubit Melbourne quantum processors in terms of quantum fidelity. The\nsimulation of the binary homogeneous Markov process on a real quantum processor\ngives best results on the Vigo and Yorktown (both 5-qubit) back-ends with\nHellinger fidelity of near 0.82. The choice of the right quantum circuit, based\non the available hardware (topology, size, timing properties), would be the\napproach for maximizing the fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 09:19:12 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 09:15:23 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Nikolov", "Petar", ""]]}, {"id": "2103.06102", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani", "title": "Effectively Counting s-t Simple Paths in Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important tool in analyzing complex social and information networks is s-t\nsimple path counting, which is known to be #P-complete. In this paper, we study\nefficient s-t simple path counting in directed graphs. For a given pair of\nvertices s and t in a directed graph, first we propose a pruning technique that\ncan efficiently and considerably reduce the search space. Then, we discuss how\nthis technique can be adjusted with exact and approximate algorithms, to\nimprove their efficiency. In the end, by performing extensive experiments over\nseveral networks from different domains, we show high empirical efficiency of\nour proposed technique. Our algorithm is not a competitor of existing methods,\nrather, it is a friend that can be used as a fast pre-processing step, before\napplying any existing algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 14:57:34 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "2103.06139", "submitter": "Pierre-Alain Fayolle", "authors": "Markus Friedrich and Pierre-Alain Fayolle", "title": "On the Complexity of the CSG Tree Extraction Problem", "comments": "Add references for the programming language based approaches and the\n  construction of the intersection graph", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we discuss the complexity of the search space for the\nproblem of finding a CSG expression (or CSG tree) corresponding to an input\npoint-cloud and a list of fitted solid primitives.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 10:52:51 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 04:41:26 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Friedrich", "Markus", ""], ["Fayolle", "Pierre-Alain", ""]]}, {"id": "2103.06218", "submitter": "Marek Soko{\\l}owski", "authors": "Marek Soko{\\l}owski", "title": "Bounds on half graph orders in powers of sparse graphs", "comments": "83 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Half graphs and their variants, such as ladders, semi-ladders and\nco-matchings, are combinatorial objects that encode total orders in graphs.\nWorks by Adler and Adler (Eur. J. Comb.; 2014) and Fabia\\'nski et al. (STACS;\n2019) prove that in the powers of sparse graphs, one cannot find arbitrarily\nlarge objects of this kind. However, these proofs either are non-constructive,\nor provide only loose upper bounds on the orders of half graphs and\nsemi-ladders. In this work we provide nearly tight asymptotic lower and upper\nbounds on the maximum order of half graphs, parameterized on the distance, in\nthe following classes of sparse graphs: planar graphs, graphs with bounded\nmaximum degree, graphs with bounded pathwidth or treewidth, and graphs\nexcluding a fixed clique as a minor.\n  The most significant part of our work is the upper bound for planar graphs.\nHere, we employ techniques of structural graph theory to analyze semi-ladders\nin planar graphs through the notion of cages, which expose a topological\nstructure in semi-ladders. As an essential building block of this proof, we\nalso state and prove a new structural result, yielding a fully polynomial bound\non the neighborhood complexity in the class of planar graphs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 17:44:41 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Soko\u0142owski", "Marek", ""]]}, {"id": "2103.06264", "submitter": "Vijay Garg", "authors": "Vijay K. Garg", "title": "A Lattice Linear Predicate Parallel Algorithm for the Dynamic\n  Programming Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been shown that the parallel Lattice Linear Predicate (LLP) algorithm\nsolves many combinatorial optimization problems such as the shortest path\nproblem, the stable marriage problem and the market clearing price problem. In\nthis paper, we give the parallel LLP algorithm for many dynamic programming\nproblems. In particular, we show that the LLP algorithm solves the longest\nsubsequence problem, the optimal binary search tree problem, and the knapsack\nproblem. Furthermore, the algorithm can be used to solve the constrained\nversions of these problems so long as the constraints are lattice linear. The\nparallel LLP algorithm requires only read-write atomicity and no higher-level\natomic instructions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 18:54:04 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Garg", "Vijay K.", ""]]}, {"id": "2103.06536", "submitter": "Ignasi Sau", "authors": "Julien Baste, Ignasi Sau, Dimitrios M. Thilikos", "title": "Hitting minors on bounded treewidth graphs. II. Single-exponential\n  algorithms", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a finite collection of graphs ${\\cal F}$, the ${\\cal F}$-M-DELETION\n(resp. ${\\cal F}$-TM-DELETION) problem consists in, given a graph $G$ and an\ninteger $k$, decide whether there exists $S \\subseteq V(G)$ with $|S| \\leq k$\nsuch that $G \\setminus S$ does not contain any of the graphs in ${\\cal F}$ as a\nminor (resp. topological minor). We are interested in the parameterized\ncomplexity of both problems when the parameter is the treewidth of $G$, denoted\nby $tw$, and specifically in the cases where ${\\cal F}$ contains a single\nconnected planar graph $H$. We present algorithms running in time $2^{O(tw)}\n\\cdot n^{O(1)}$, called single-exponential, when $H$ is either $P_3$, $P_4$,\n$C_4$, the paw, the chair, and the banner for both $\\{H\\}$-M-DELETION and\n$\\{H\\}$-TM-DELETION, and when $H=K_{1,i}$, with $i \\geq 1$, for\n$\\{H\\}$-TM-DELETION. Some of these algorithms use the rank-based approach\nintroduced by Bodlaender et al. [Inform Comput, 2015]. This is the second of a\nseries of articles on this topic, and the results given here together with\nother ones allow us, in particular, to provide a tight dichotomy on the\ncomplexity of $\\{H\\}$-M-DELETION in terms of $H$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 08:57:26 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Baste", "Julien", ""], ["Sau", "Ignasi", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2103.06614", "submitter": "Ignasi Sau", "authors": "Julien Baste, Ignasi Sau, Dimitrios M. Thilikos", "title": "Hitting minors on bounded treewidth graphs. III. Lower bounds", "comments": "41 pages, 20 figures. arXiv admin note: substantial text overlap with\n  arXiv:1907.04442, arXiv:1704.07284", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a finite collection of graphs ${\\cal F}$, the ${\\cal F}$-M-DELETION\nproblem consists in, given a graph $G$ and an integer $k$, decide whether there\nexists $S \\subseteq V(G)$ with $|S| \\leq k$ such that $G \\setminus S$ does not\ncontain any of the graphs in ${\\cal F}$ as a minor. We are interested in the\nparameterized complexity of ${\\cal F}$-M-DELETION when the parameter is the\ntreewidth of $G$, denoted by $tw$. Our objective is to determine, for a fixed\n${\\cal F}$, the smallest function $f_{{\\cal F}}$ such that ${\\cal\nF}$-M-DELETION can be solved in time $f_{{\\cal F}}(tw) \\cdot n^{O(1)}$ on\n$n$-vertex graphs. We provide lower bounds under the ETH on $f_{{\\cal F}}$ for\nseveral collections ${\\cal F}$. We first prove that for any ${\\cal F}$\ncontaining connected graphs of size at least two, $f_{{\\cal F}}(tw)=\n2^{\\Omega(tw)}$, even if the input graph $G$ is planar. Our main contribution\nconsists of superexponential lower bounds for a number of collections ${\\cal\nF}$, inspired by a reduction of Bonnet et al.~[IPEC, 2017]. In particular, we\nprove that when ${\\cal F}$ contains a single connected graph $H$ that is either\n$P_5$ or is not a minor of the banner (that is, the graph consisting of a $C_4$\nplus a pendent edge), then $f_{{\\cal F}}(tw)= 2^{\\Omega(tw \\cdot \\log tw)}$.\nThis is the third of a series of articles on this topic, and the results given\nhere together with other ones allow us, in particular, to provide a tight\ndichotomy on the complexity of $\\{H\\}$-M-DELETION, in terms of $H$, when $H$ is\nconnected.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 11:34:12 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Baste", "Julien", ""], ["Sau", "Ignasi", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2103.06665", "submitter": "David Schaller", "authors": "David Schaller, Manuela Gei{\\ss}, Marc Hellmuth, Peter F. Stadler", "title": "Arc-Completion of 2-Colored Best Match Graphs to Binary-Explainable Best\n  Match Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best match graphs (BMGs) are vertex-colored digraphs that naturally arise in\nmathematical phylogenetics to formalize the notion of evolutionary closest\ngenes w.r.t. an a priori unknown phylogenetic tree. BMGs are explained by\nunique least resolved trees. We prove that the property of a rooted,\nleaf-colored tree to be least resolved for some BMG is preserved by the\ncontraction of inner edges. For the special case of two-colored BMGs, this\nleads to a characterization of the least resolved trees (LRTs) of\nbinary-explainable trees and a simple, polynomial-time algorithm for the\nminimum cardinality completion of the arc set of a BMG to reach a BMG that can\nbe explained by a binary tree.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 13:41:41 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Schaller", "David", ""], ["Gei\u00df", "Manuela", ""], ["Hellmuth", "Marc", ""], ["Stadler", "Peter F.", ""]]}, {"id": "2103.06707", "submitter": "Jayson Lynch", "authors": "Oswin Aichholzer, Erik D. Demaine, Matias Korman, Jayson Lynch, Anna\n  Lubiw, Zuzana Mas, Mikhail Rudoy, Virginia Vassilevska Williams, Nicole Wein", "title": "Hardness of Token Swapping on Trees", "comments": "52 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph where every vertex has exactly one labeled token, how can we\nmost quickly execute a given permutation on the tokens? In (sequential) token\nswapping, the goal is to use the shortest possible sequence of swaps, each of\nwhich exchanges the tokens at the two endpoints of an edge of the graph. In\nparallel token swapping, the goal is to use the fewest rounds, each of which\nconsists of one or more swaps on the edges of a matching. We prove that both of\nthese problems remain NP-hard when the graph is restricted to be a tree.\n  These token swapping problems have been studied by disparate groups of\nresearchers in discrete mathematics, theoretical computer science, robot motion\nplanning, game theory, and engineering. Previous work establishes\nNP-completeness on general graphs (for both problems); polynomial-time\nalgorithms for simple graph classes such as cliques, stars, paths, and cycles;\nand constant-factor approximation algorithms in some cases. The two natural\ncases of sequential and parallel token swapping in trees were first studied\nover thirty years ago (as \"sorting with a transposition tree\") and over\ntwenty-five years ago (as \"routing permutations via matchings\"), yet their\ncomplexities were previously unknown.\n  We also show limitations on approximation of sequential token swapping on\ntrees: we identify a broad class of algorithms that encompass all three known\npolynomial-time algorithms that achieve the best known approximation factor\n(which is $2$) and show that no such algorithm can achieve an approximation\nfactor less than $2$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 14:51:25 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Aichholzer", "Oswin", ""], ["Demaine", "Erik D.", ""], ["Korman", "Matias", ""], ["Lynch", "Jayson", ""], ["Lubiw", "Anna", ""], ["Mas", "Zuzana", ""], ["Rudoy", "Mikhail", ""], ["Williams", "Virginia Vassilevska", ""], ["Wein", "Nicole", ""]]}, {"id": "2103.06942", "submitter": "Kartik Vempala", "authors": "Kartik Vempala (Bloomberg LP)", "title": "Imagined-Trailing-Whitespace-Agnostic Levenshtein Distance For Plaintext\n  Table Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The standard algorithm for Levenshtein distance, treats trailing whitespace\nthe same as any other letter or symbol. However, when humans compare 2 strings,\nwe implicitly assume that both strings are padded by infinite trailing\nwhitespace. This informs our expectations for what the costs for insertion,\ndeletion and replacement, should be. This violation of our expectations results\nin non-intuitive edit distance values. To account for this specific human\nintuition, a naive approach which considers \"all possible\" substrings of\ntrailing whitespace would yield an $O(n^3)$ algorithm. In this work, we provide\nan efficient $O(n^2)$ algorithm to compute the same. Keywords: Imagined\nInfinite Trailing Whitespace, Human Friendly, Intuitive Edit Distance, Table\nDetection, Table Alignment\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 20:39:40 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Vempala", "Kartik", "", "Bloomberg LP"]]}, {"id": "2103.07027", "submitter": "Peter Robinson", "authors": "Christian Konrad, Peter Robinson, Viktor Zamaraev", "title": "Robust Lower Bounds for Graph Problems in the Blackboard Model of\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give lower bounds on the communication complexity of graph problems in the\nmulti-party blackboard model. In this model, the edges of an $n$-vertex input\ngraph are partitioned among $k$ parties, who communicate solely by writing\nmessages on a shared blackboard that is visible to every party. We show that\nany non-trivial graph problem on $n$-vertex graphs has blackboard communication\ncomplexity $\\Omega(n)$ bits, even if the edges of the input graph are randomly\nassigned to the $k$ parties. We say that a graph problem is non-trivial if the\noutput cannot be computed in a model where every party holds at most one edge\nand no communication is allowed. Our lower bound thus holds for essentially all\nkey graph problems relevant to distributed computing, including Maximal\nIndependent Set (MIS), Maximal Matching, ($\\Delta+1$)-coloring, and Dominating\nSet. In many cases, e.g., MIS, Maximal Matching, and $(\\Delta+1)$-coloring, our\nlower bounds are optimal, up to poly-logarithmic factors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 01:27:12 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Konrad", "Christian", ""], ["Robinson", "Peter", ""], ["Zamaraev", "Viktor", ""]]}, {"id": "2103.07360", "submitter": "Jeroen Huijben", "authors": "Jeroen Huijben, Viresh Patel, Guus Regts", "title": "Sampling from the low temperature Potts model through a Markov chain on\n  flows", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the algorithmic problem of sampling from the Potts\nmodel and computing its partition function at low temperatures. Instead of\ndirectly working with spin configurations, we consider the equivalent problem\nof sampling flows. We show, using path coupling, that a simple and natural\nMarkov chain on the set of flows is rapidly mixing. As a result we find a\n$\\delta$-approximate sampling algorithm for the Potts model at low enough\ntemperatures, whose running time is bounded by $O(m^2\\log(m\\delta^{-1}))$ for\ngraphs $G$ with $m$ edges.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 15:51:11 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Huijben", "Jeroen", ""], ["Patel", "Viresh", ""], ["Regts", "Guus", ""]]}, {"id": "2103.07367", "submitter": "Ya-Chun Liang", "authors": "Ya-Chun Liang, Kuan-Yun Lai, Ho-Lin Chen, Kazuo Iwama", "title": "Tight Competitive Analyses of Online Car-sharing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The car-sharing problem, proposed by Luo, Erlebach and Xu in 2018, mainly\nfocuses on an online model in which there are two locations: 0 and 1, and $k$\ntotal cars. Each request which specifies its pick-up time and pick-up location\n(among 0 and 1, and the other is the drop-off location) is released in each\nstage a fixed amount of time before its specified start (i.e. pick-up) time.\nThe time between the booking (i.e. released) time and the start time is enough\nto move empty cars between 0 and 1 for relocation if they are not used in that\nstage. The model, called $k$S2L-F, assumes that requests in each stage arrive\nsequentially regardless of the same booking time and the decision (accept or\nreject) must be made immediately. The goal is to accept as many requests as\npossible. In spite of only two locations, the analysis does not seem easy and\nthe (tight) competitive ratio (CR) is only known to be 2.0 for $k=2$ and 1.5\nfor a restricted value of $k$, i.e., a multiple of three. In this paper, we\nremove all the holes of unknown CR's; namely we prove that the CR is\n$\\frac{2k}{k + \\lfloor k/3 \\rfloor}$ for all $k\\geq 2$. Furthermore, if the\nalgorithm can delay its decision until all requests have come in each stage,\nthe CR is improved to roughly 4/3. We can take this advantage even further,\nprecisely we can achieve a CR of $\\frac{2+R}{3}$ if the number of requests in\neach stage is at most $Rk$, $1 \\leq R \\leq 2$, where we do not have to know the\nvalue of $R$ in advance. Finally we demonstrate that randomization also helps\nto get (slightly) better CR's.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 16:03:44 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 17:16:08 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 11:11:48 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Liang", "Ya-Chun", ""], ["Lai", "Kuan-Yun", ""], ["Chen", "Ho-Lin", ""], ["Iwama", "Kazuo", ""]]}, {"id": "2103.07459", "submitter": "Zongchen Chen", "authors": "Antonio Blanca, Pietro Caputo, Zongchen Chen, Daniel Parisi, Daniel\n  \\v{S}tefankovi\\v{c}, Eric Vigoda", "title": "On Mixing of Markov Chains: Coupling, Spectral Independence, and Entropy\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.DS math-ph math.FA math.MP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For general spin systems, we prove that a contractive coupling for any local\nMarkov chain implies optimal bounds on the mixing time and the modified\nlog-Sobolev constant for a large class of Markov chains including the Glauber\ndynamics, arbitrary heat-bath block dynamics, and the Swendsen-Wang dynamics.\nThis reveals a novel connection between probabilistic techniques for bounding\nthe convergence to stationarity and analytic tools for analyzing the decay of\nrelative entropy. As a corollary of our general results, we obtain\n$O(n\\log{n})$ mixing time and $\\Omega(1/n)$ modified log-Sobolev constant of\nthe Glauber dynamics for sampling random $q$-colorings of an $n$-vertex graph\nwith constant maximum degree $\\Delta$ when $q > (11/6 - \\epsilon_0)\\Delta$ for\nsome fixed $\\epsilon_0>0$. We also obtain $O(\\log{n})$ mixing time and\n$\\Omega(1)$ modified log-Sobolev constant of the Swendsen-Wang dynamics for the\nferromagnetic Ising model on an $n$-vertex graph of constant maximum degree\nwhen the parameters of the system lie in the tree uniqueness region. At the\nheart of our results are new techniques for establishing spectral independence\nof the spin system and block factorization of the relative entropy. On one hand\nwe prove that a contractive coupling of a local Markov chain implies spectral\nindependence of the Gibbs distribution. On the other hand we show that spectral\nindependence implies factorization of entropy for arbitrary blocks,\nestablishing optimal bounds on the modified log-Sobolev constant of the\ncorresponding block dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 18:48:40 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Blanca", "Antonio", ""], ["Caputo", "Pietro", ""], ["Chen", "Zongchen", ""], ["Parisi", "Daniel", ""], ["\u0160tefankovi\u010d", "Daniel", ""], ["Vigoda", "Eric", ""]]}, {"id": "2103.07510", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang, Richard Kueng, John Preskill", "title": "Efficient estimation of Pauli observables by derandomization", "comments": "12 pages, 2 figures, 1 table; open-source code available at\n  https://github.com/momohuang/predicting-quantum-properties", "journal-ref": "Phys. Rev. Lett. 127, 030503 (2021)", "doi": "10.1103/PhysRevLett.127.030503", "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of jointly estimating expectation values of many\nPauli observables, a crucial subroutine in variational quantum algorithms.\nStarting with randomized measurements, we propose an efficient derandomization\nprocedure that iteratively replaces random single-qubit measurements with fixed\nPauli measurements; the resulting deterministic measurement procedure is\nguaranteed to perform at least as well as the randomized one. In particular,\nfor estimating any $L$ low-weight Pauli observables, a deterministic\nmeasurement on only of order $\\log(L)$ copies of a quantum state suffices. In\nsome cases, for example when some of the Pauli observables have a high weight,\nthe derandomized procedure is substantially better than the randomized one.\nSpecifically, numerical experiments highlight the advantages of our\nderandomized protocol over various previous methods for estimating the\nground-state energies of small molecules.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 20:09:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Kueng", "Richard", ""], ["Preskill", "John", ""]]}, {"id": "2103.07522", "submitter": "Andrea Marino", "authors": "Andrea Marino and Ana Silva", "title": "K\\\"{o}nigsberg Sightseeing: Eulerian Walks in Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An Eulerian walk (or Eulerian trail) is a walk (resp. trail) that visits\nevery edge of a graph $G$ at least (resp. exactly) once. This notion was first\ndiscussed by Leonhard Euler while solving the famous Seven Bridges of\nK\\\"{o}nigsberg problem in 1736. What if Euler had to take a bus? In a temporal\ngraph $(G,\\lambda)$, with $\\lambda: E(G)\\to 2^{[\\tau]}$, an edge $e\\in E(G)$ is\navailable only at the times specified by $\\lambda(e)\\subseteq [\\tau]$, in the\nsame way the connections of the public transportation network of a city or of\nsightseeing tours are available only at scheduled times. In this scenario, even\nthough several translations of Eulerian trails and walks are possible in\ntemporal terms, only a very particular variation has been exploited in the\nliterature, specifically for infinite dynamic networks (Orlin, 1984). In this\npaper, we deal with temporal walks, local trails, and trails, respectively\nreferring to edge traversal with no constraints, constrained to not repeating\nthe same edge in a single timestamp, and constrained to never repeating the\nsame edge throughout the entire traversal. We show that, if the edges are\nalways available, then deciding whether $(G,\\lambda)$ has a temporal walk or\ntrail is polynomial, while deciding whether it has a local trail is NP-complete\neven if it has lifetime~2. In contrast, in the general case, solving any of\nthese problems is NP-complete, even under very strict hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 20:51:14 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Marino", "Andrea", ""], ["Silva", "Ana", ""]]}, {"id": "2103.08211", "submitter": "Shay Sapir", "authors": "Robert Krauthgamer and Shay Sapir", "title": "Smoothness of Schatten Norms and Sliding-Window Matrix Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large matrices are often accessed as a row-order stream. We consider the\nsetting where rows are time-sensitive (i.e. they expire), which can be\ndescribed by the sliding-window row-order model, and provide the first\n$(1+\\epsilon)$-approximation of Schatten $p$-norms in this setting. Our main\ntechnical contribution is a proof that Schatten $p$-norms in row-order streams\nare smooth, and thus fit the smooth-histograms technique of Braverman and\nOstrovsky (FOCS 2007) for sliding-window streams.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 08:46:30 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Krauthgamer", "Robert", ""], ["Sapir", "Shay", ""]]}, {"id": "2103.08281", "submitter": "Lukas Burgholzer", "authors": "Lukas Burgholzer, Rudy Raymond, Indranil Sengupta and Robert Wille", "title": "Efficient Construction of Functional Representations for Quantum\n  Algorithms", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the significant progress made in the implementation of quantum\nhardware, efficient methods and tools to design corresponding algorithms become\nincreasingly important. Many of these tools rely on functional representations\nof certain building blocks or even entire quantum algorithms which, however,\ninherently exhibit an exponential complexity. Although several alternative\nrepresentations have been proposed to cope with this complexity, the\nconstruction of those representations remains a bottleneck. In this work, we\npropose solutions for efficiently constructing representations of quantum\nfunctionality based on the idea of conducting as many operations as possible on\nas small as possible intermediate representations -- using Decision Diagrams as\na representative functional description. Experimental evaluations show that\napplying these solutions allows to construct the desired representations\nseveral factors faster than with state-of-the-art methods. Moreover, if\nrepeating structures (which frequently occur in quantum algorithms) are\nexplicitly exploited, exponential improvements are possible -- allowing to\nconstruct the functionality of certain algorithms within seconds, whereas the\nstate of the art fails to construct it in an entire day.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 11:20:40 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Burgholzer", "Lukas", ""], ["Raymond", "Rudy", ""], ["Sengupta", "Indranil", ""], ["Wille", "Robert", ""]]}, {"id": "2103.08394", "submitter": "Vaclav Rozhon", "authors": "Jan Greb\\'ik, V\\'aclav Rozho\\v{n}", "title": "Local Problems on Grids from the Perspective of Distributed Algorithms,\n  Finitary Factors, and Descriptive Combinatorics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an intimate connection among the following fields:\n  (a) distributed local algorithms: coming from the area of computer science,\n  (b) finitary factors of iid processes: coming from the area of analysis of\nrandomized processes,\n  (c) descriptive combinatorics: coming from the area of combinatorics and\nmeasure theory.\n  In particular, we study locally checkable labellings in grid graphs from all\nthree perspectives. Most of our results are for the perspective (b) where we\nprove time hierarchy theorems akin to those known in the field (a) [Chang,\nPettie FOCS 2017]. This approach that borrows techniques from the fields (a)\nand (c) implies a number of results about possible complexities of finitary\nfactor solutions. Among others, it answers three open questions of [Holroyd et\nal. Annals of Prob. 2017] or the more general question of [Brandt et al. PODC\n2017] who asked for a formal connection between the fields (a) and (b). In\ngeneral, we hope that our treatment will help to view all three perspectives as\na part of a common theory of locality, in which we follow the insightful paper\nof [Bernshteyn 2020+] .\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 14:04:36 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 13:27:43 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Greb\u00edk", "Jan", ""], ["Rozho\u0148", "V\u00e1clav", ""]]}, {"id": "2103.08683", "submitter": "Farzam Ebrahimnejad", "authors": "Farzam Ebrahimnejad, Ansh Nagda, Shayan Oveis Gharan", "title": "Counting and Sampling Perfect Matchings in Regular Expanding\n  Non-Bipartite Graphs", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the ratio of the number of near perfect matchings to the number\nof perfect matchings in $d$-regular strong expander (non-bipartite) graphs,\nwith $2n$ vertices, is a polynomial in $n$, thus the Jerrum and Sinclair Markov\nchain [JS89] mixes in polynomial time and generates an (almost) uniformly\nrandom perfect matching. Furthermore, we prove that such graphs have at least\n$\\Omega(d)^n$ any perfect matchings, thus proving the Lovasz-Plummer conjecture\n[LP86] for this family of graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 19:59:46 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ebrahimnejad", "Farzam", ""], ["Nagda", "Ansh", ""], ["Gharan", "Shayan Oveis", ""]]}, {"id": "2103.08936", "submitter": "Antonio Fern\\'andez Anta", "authors": "Vicent Cholvi, Antonio Fern\\'andez Anta, Chryssis Georgiou, Nicolas\n  Nicolaou, Michel Raynal, Antonio Russo", "title": "Byzantine-tolerant Distributed Grow-only Sets: Specification and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to formalize Distributed Ledger Technologies and their\ninterconnections, a recent line of research work has formulated the notion of\nDistributed Ledger Object (DLO), which is a concurrent object that maintains a\ntotally ordered sequence of records, abstracting blockchains and distributed\nledgers. Through DLO, the Atomic Appends problem, intended as the need of a\nprimitive able to append multiple records to distinct ledgers in an atomic way,\nis studied as a basic interconnection problem among ledgers.\n  In this work, we propose the Distributed Grow-only Set object (DSO), which\ninstead of maintaining a sequence of records, as in a DLO, maintains a set of\nrecords in an immutable way: only Add and Get operations are provided. This\nobject is inspired by the Grow-only Set (G-Set) data type which is part of the\nConflict-free Replicated Data Types. We formally specify the object and we\nprovide a consensus-free Byzantine-tolerant implementation that guarantees\neventual consistency. We then use our Byzantine-tolerant DSO (BDSO)\nimplementation to provide consensus-free algorithmic solutions to the Atomic\nAppends and Atomic Adds (the analogous problem of atomic appends applied on\nG-Sets) problems, as well as to construct consensus-free Single-Writer BDLOs.\nWe believe that the BDSO has applications beyond the above-mentioned problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 09:40:15 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Cholvi", "Vicent", ""], ["Anta", "Antonio Fern\u00e1ndez", ""], ["Georgiou", "Chryssis", ""], ["Nicolaou", "Nicolas", ""], ["Raynal", "Michel", ""], ["Russo", "Antonio", ""]]}, {"id": "2103.09033", "submitter": "Tharrmashastha Sapv", "authors": "Debajyoti Bera, Tharrmashastha SAPV", "title": "Space efficient quantum algorithms for mode, min-entropy and\n  k-distinctness", "comments": "19 Pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of determining if the mode of the output distribution of\na quantum circuit given as a black-box is larger than a given threshold. We\ndesign a quantum algorithm for a promised version of this problem whose space\ncomplexity is logarithmic in the size of the domain of the distribution.\nDeveloping on top of that we further design an algorithm to estimate the\nlargest probability among the outcomes of that circuit. This allows to revisit\na few recently studied problems in the few-qubits scenario, namely\n$k$-distinctness and its gapped version, estimating the largest frequency in an\narray, and estimating the min-entropy of a distribution. In particular, our\nalgorithm for $k$-distinctness on $n$-sized $m$-valued arrays requires $O(\\log\nn + \\log m)$ qubits compared to $\\Omega(poly(n))$ qubits required by all the\nprevious algorithms, and its query complexity is optimal for $k=\\Omega(n)$. We\nalso study reductions between the above problems and derive better lower bounds\nfor some of them. The time-complexities of our algorithms have a small overhead\nover their query complexities making them efficiently implementable on\ncurrently available quantum backends.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 13:06:36 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Bera", "Debajyoti", ""], ["SAPV", "Tharrmashastha", ""]]}, {"id": "2103.09080", "submitter": "Majid Salimi", "authors": "Majid Salimi, Hamid Mala", "title": "A Polynomial-Time Algorithm for Special Cases of the Unbounded\n  Subset-Sum Problem", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Unbounded Subset-Sum Problem (USSP) is defined as: given sum $s$ and a\nset of integers $W\\leftarrow \\{p_1,\\dots,p_n\\}$ output a set of non-negative\nintegers $\\{y_1,\\dots,y_n\\}$ such that $p_1y_1+\\dots+p_ny_n=s$. The USSP is an\nNP-complete problem that does not have any known polynomial-time solution.\nThere is a pseudo-polynomial algorithm for the USSP problem with\n$O((p_{1})^{2}+n)$ time complexity and $O(p_{1})$ memory complexity, where\n$p_{1}$ is the smallest element of $W$ \\cite{PH}. This algorithm is polynomial\nin term of the number of inputs, but exponential in the size of $p_1$.\nTherefore, this solution is impractical for the large-scale problems.\n  In this paper, first we propose an efficient polynomial-time algorithm with\n$O(n)$ computational complexity for solving the specific case of the USSP where\n$ s> \\sum_{i=1}^{k-1}q_iq_{i+1}-q_i-q_{i+1}$, $q_i$'s are the elements of a\nsmall subset of $W$ in which $gcd$ of its elements divides $s$ and $2\\le k \\le\nn$. Second, we present another algorithm for smaller values of $s$ with\n$O(n^2)$ computational complexity that finds the answer for some inputs with a\nprobability between $0.5$ to $1$. Its success probability is directly related\nto the number of subsets of $W$ in which $gcd$ of their elements divides $s$.\nThis algorithm can solve the USSP problem with large inputs in the\npolynomial-time, no matter how big inputs are, but, in some special cases where\n$s$ is small, it cannot find the answer.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 14:12:46 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Salimi", "Majid", ""], ["Mala", "Hamid", ""]]}, {"id": "2103.09362", "submitter": "Igor Tunev Nikolaevich", "authors": "Igor N. Tunev", "title": "On Linear Solution of \"Cherry Pickup II\". Max Weight of Two Disjoint\n  Paths in Node-Weighted Gridlike DAG", "comments": "not for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"Minimum Falling Path Sum\" (MFPS) is classic question in programming - \"Given\na grid of size $N{\\times}N$ with integers in cells, return the minimum sum of a\nfalling path through grid. A falling path starts at any cell in the first row\nand ends in last row, with the rule of motion - the next element after the cell\n$(i,j)$ is one of the cells $(i+1,j-1),(i+1,j)$ and $(i+1,j+1)$\". This problem\nhas linear solution (LS) (i.e. O($N^2$)) using dynamic programming method\n(DPM). There is an Multi-Agent version of MFPS called \"Cherry Pickup II\" (CP2).\nCP2 is a search for the maximum sum of 2 falling paths started from top\ncorners, where each covered cell summed up one time. All known fast solutions\nof CP2 uses DPM, but have O($N^3$) time complexity on grid $N{\\times}N$. Here\nwe offer a LS of CP2 (also using DPM) as finding maximum total weight of 2\nvertex-disjoint paths. Also, we extend this LS for some extended version of CP2\nwith wider motion rules.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 23:16:23 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 07:26:47 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Tunev", "Igor N.", ""]]}, {"id": "2103.09715", "submitter": "Micha{\\l} W{\\l}odarczyk", "authors": "Bart M. P. Jansen, Jari J. H. de Kroon, Micha{\\l} W{\\l}odarczyk", "title": "Vertex Deletion Parameterized by Elimination Distance and Even Less", "comments": "77 pages, to appear at STOC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the parameterized complexity of various classic vertex deletion\nproblems such as Odd cycle transversal, Vertex planarization, and Chordal\nvertex deletion under hybrid parameterizations. Existing FPT algorithms for\nthese problems either focus on the parameterization by solution size, detecting\nsolutions of size $k$ in time $f(k) \\cdot n^{O(1)}$, or width\nparameterizations, finding arbitrarily large optimal solutions in time $f(w)\n\\cdot n^{O(1)}$ for some width measure $w$ like treewidth. We unify these lines\nof research by presenting FPT algorithms for parameterizations that can\nsimultaneously be arbitrarily much smaller than the solution size and the\ntreewidth.\n  We consider two classes of parameterizations which are relaxations of either\ntreedepth of treewidth. They are related to graph decompositions in which\nsubgraphs that belong to a target class H (e.g., bipartite or planar) are\nconsidered simple. First, we present a framework for computing approximately\noptimal decompositions for miscellaneous classes H. Namely, if the cost of an\noptimal decomposition is $k$, we show how to find a decomposition of cost\n$k^{O(1)}$ in time $f(k) \\cdot n^{O(1)}$. Secondly, we exploit the constructed\ndecompositions for solving vertex-deletion problems by extending ideas from\nalgorithms using iterative compression and the finite state property. For the\nthree mentioned vertex-deletion problems, and all problems which can be\nformulated as hitting a finite set of connected forbidden (a) minors or (b)\n(induced) subgraphs, we obtain FPT algorithms with respect to both studied\nparameterizations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 15:17:41 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:56:23 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["de Kroon", "Jari J. H.", ""], ["W\u0142odarczyk", "Micha\u0142", ""]]}, {"id": "2103.09735", "submitter": "Arnab Maiti", "authors": "Arindam Khan, Arnab Maiti, Amatya Sharma, Andreas Wiese", "title": "On Guillotine Separable Packings for the Two-dimensional Geometric\n  Knapsack Problem", "comments": "39 pages, 13 figures, To appear in SOCG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two-dimensional geometric knapsack problem, we are given a set of n\naxis-aligned rectangular items and an axis-aligned square-shaped knapsack. Each\nitem has integral width, integral height and an associated integral profit. The\ngoal is to find a (non-overlapping axis-aligned) packing of a maximum profit\nsubset of rectangles into the knapsack. A well-studied and frequently used\nconstraint in practice is to allow only packings that are guillotine separable,\ni.e., every rectangle in the packing can be obtained by recursively applying a\nsequence of edge-to-edge axis-parallel cuts that do not intersect any item of\nthe solution. In this paper we study approximation algorithms for the geometric\nknapsack problem under guillotine cut constraints. We present polynomial time\n(1 + {\\epsilon})-approximation algorithms for the cases with and without\nallowing rotations by 90 degrees, assuming that all input numeric data are\npolynomially bounded in n. In comparison, the best-known approximation factor\nfor this setting is 3 + {\\epsilon} [Jansen-Zhang, SODA 2004], even in the\ncardinality case where all items have the same profit. Our main technical\ncontribution is a structural lemma which shows that any guillotine packing can\nbe converted into another structured guillotine packing with almost the same\nprofit. In this packing, each item is completely contained in one of a constant\nnumber of boxes and L-shaped regions, inside which the items are placed by a\nsimple greedy routine. In particular, we provide a clean sufficient condition\nwhen such a packing obeys the guillotine cut constraints which might be useful\nfor other settings where these constraints are imposed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 15:47:42 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Khan", "Arindam", ""], ["Maiti", "Arnab", ""], ["Sharma", "Amatya", ""], ["Wiese", "Andreas", ""]]}, {"id": "2103.09807", "submitter": "Yatharth Dubey", "authors": "Santanu S. Dey, Yatharth Dubey, Marco Molinaro", "title": "Lower Bounds on the Size of General Branch-and-Bound Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \\emph{general branch-and-bound tree} is a branch-and-bound tree which is\nallowed to use general disjunctions of the form $\\pi^{\\top} x \\leq \\pi_0\n\\,\\vee\\, \\pi^{\\top}x \\geq \\pi_0 + 1$, where $\\pi$ is an integer vector and\n$\\pi_0$ is an integer scalar, to create child nodes. We construct a packing\ninstance, a set covering instance, and a Traveling Salesman Problem instance,\nsuch that any general branch-and-bound tree that solves these instances must be\nof exponential size. We also verify that an exponential lower bound on the size\nof general branch-and-bound trees persists when we add Gaussian noise to the\ncoefficients of the cross polytope, thus showing that polynomial-size \"smoothed\nanalysis\" upper bound is not possible. The results in this paper can be viewed\nas the branch-and-bound analog of the seminal paper by Chv\\'atal et al.\n\\cite{chvatal1989cutting}, who proved lower bounds for the Chv\\'atal-Gomory\nrank.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 17:49:01 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Dey", "Santanu S.", ""], ["Dubey", "Yatharth", ""], ["Molinaro", "Marco", ""]]}, {"id": "2103.09900", "submitter": "Nodari Vakhania", "authors": "Nodari Vakhania", "title": "Compact enumeration for scheduling one machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strongly NP-hard scheduling problem in which non-simultaneously released\njobs with delivery times are to be scheduled on a single machine with the\nobjective to minimize the maximum job full completion time is considered. We\ndescribe an exact implicit enumeration algorithm (IEA) and a polynomial-time\napproximation scheme (PTAS) for the single-machine environment. Although the\nworst-case complexity analysis of IEA yields a factor of $\\nu!$, $\\nu>n$, large\nsets of the permutations of the critical jobs can be discarded by incorporating\na heuristic search strategy, in which the permutations of the so-called\ncritical jobs are considered in a special priority order. Not less importantly,\nin practice, the number $\\nu$ turns out to be several times smaller than the\ntotal number of jobs $n$, and it becomes smaller when $n$ increases. The above\ncharacteristics also apply to the proposed PTAS, which worst-case time\ncomplexity can be expressed as $O(\\kappa!\\kappa k n \\log n)$, where $\\kappa$ is\nthe number of the long critical jobs ($\\kappa<<\\nu$) and the corresponding\napproximation factor is $1+1/k$, where $\\kappa<k$. We show that the probability\nthat a considerable number of permutations (far less than $\\kappa!$) are\nenumerated is close to 0. Hence, with a high probability, the running time of\nPTAS is fully polynomial.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 20:50:10 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Vakhania", "Nodari", ""]]}, {"id": "2103.09952", "submitter": "Yeganeh Alimohammadi", "authors": "Yeganeh Alimohammadi, Christian Borgs, Amin Saberi", "title": "Locality of Random Digraphs on Expanders", "comments": "Added a proof on infinite order phase transition of PA graphs.\n  Revised introduction and moved the proof on applications to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study random digraphs on sequences of expanders with bounded average\ndegree and weak local limit. The threshold for the existence of a giant\nstrongly connected component, as well as the asymptotic fraction of nodes with\ngiant fan-in or giant fan-out are local, in the sense that they are the same\nfor two sequences with the same weak local limit. The digraph has a bow-tie\nstructure, with all but a vanishing fraction of nodes lying either in the\nunique strongly connected giant and its fan-in and fan-out, or in sets with\nsmall fan-in and small fan-out. All local quantities are expressed in terms of\npercolation on the limiting rooted graph, without any structural assumptions on\nthe limit, allowing, in particular, for non tree-like limits.\n  In the course of proving these results, we prove that for unoriented\npercolation, there is a unique giant above criticality, whose size and critical\nthreshold are again local. An application of our methods shows that the\ncritical threshold for bond percolation and random digraphs on preferential\nattachment graphs is $p_c=0$, with an infinite order phase transition at $p_c$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 23:45:33 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 22:07:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Alimohammadi", "Yeganeh", ""], ["Borgs", "Christian", ""], ["Saberi", "Amin", ""]]}, {"id": "2103.10008", "submitter": "Cheng Lu", "authors": "Cheng Lu, Wenguo Yang, Suixiang Gao", "title": "Regularized Non-monotone Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a thorough study of maximizing a regularized\nnon-monotone submodular function subject to various constraints, i.e., $\\max \\{\ng(A) - \\ell(A) : A \\in \\mathcal{F} \\}$, where $g \\colon 2^\\Omega \\to\n\\mathbb{R}_+$ is a non-monotone submodular function, $\\ell \\colon 2^\\Omega \\to\n\\mathbb{R}_+$ is a normalized modular function and $\\mathcal{F}$ is the\nconstraint set. Though the objective function $f := g - \\ell$ is still\nsubmodular, the fact that $f$ could potentially take on negative values\nprevents the existing methods for submodular maximization from providing a\nconstant approximation ratio for the regularized submodular maximization\nproblem. To overcome the obstacle, we propose several algorithms which can\nprovide a relatively weak approximation guarantee for maximizing regularized\nnon-monotone submodular functions. More specifically, we propose a continuous\ngreedy algorithm for the relaxation of maximizing $g - \\ell$ subject to a\nmatroid constraint. Then, the pipage rounding procedure can produce an integral\nsolution $S$ such that $\\mathbb{E} [g(S) - \\ell(S)] \\geq e^{-1}g(OPT) -\n\\ell(OPT) - O(\\epsilon)$. Moreover, we present a much faster algorithm for\nmaximizing $g - \\ell$ subject to a cardinality constraint, which can output a\nsolution $S$ with $\\mathbb{E} [g(S) - \\ell(S)] \\geq (e^{-1} - \\epsilon) g(OPT)\n- \\ell(OPT)$ using $O(\\frac{n}{\\epsilon^2} \\ln \\frac 1\\epsilon)$ value oracle\nqueries. We also consider the unconstrained maximization problem and give an\nalgorithm which can return a solution $S$ with $\\mathbb{E} [g(S) - \\ell(S)]\n\\geq e^{-1} g(OPT) - \\ell(OPT)$ using $O(n)$ value oracle queries.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 03:59:35 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Lu", "Cheng", ""], ["Yang", "Wenguo", ""], ["Gao", "Suixiang", ""]]}, {"id": "2103.10115", "submitter": "Marc Demange", "authors": "Marc Demange, Alessia Di Fonso, Gabriele Di Stefano and Pierpaolo\n  Vittorini", "title": "A graph theoretical approach to the firebreak locating problem", "comments": "37 pages, 10 figures, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, wildfires have become wider and more destructive. The\nclimate change and the growth of urban areas may further increase the\nprobability of incidence of large-scale fires. The risk of fire can be lowered\nwith preventive measures. Among them, firefighting lines are used to stop the\nfire from spreading beyond them. Due to high costs of installation and\nmaintenance, their placement must be carefully planned. In this work, we\naddress the wildfire management problem from a theoretical point of view and\ndefine a risk function to model the fire diffusion phenomena. The land is\nmodeled by a mixed graph in which vertices are areas subject to fire with a\ncertain probability while edges model the probability of fire spreading from\none area to another. To reduce the risk, we introduce the {\\sc Windy Firebreak\nLocation} problem that addresses the optimal positioning of firefighting lines\nunder budget constraints. We study the complexity of the problem and prove its\nhardness even when the graph is planar, bipartite, with maximum degree four and\nthe propagation probabilities are equal to one. We also show an efficient\npolynomial time algorithm for particular instances on trees.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 09:43:19 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Demange", "Marc", ""], ["Di Fonso", "Alessia", ""], ["Di Stefano", "Gabriele", ""], ["Vittorini", "Pierpaolo", ""]]}, {"id": "2103.10244", "submitter": "Markus Anders", "authors": "Markus Anders and Pascal Schweitzer and Florian Wetzels", "title": "Comparative Design-Choice Analysis of Color Refinement Algorithms Beyond\n  the Worst Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color refinement is a crucial subroutine in symmetry detection in theory as\nwell as practice. It has further applications in machine learning and in\ncomputational problems from linear algebra. While tight lower bounds for the\nworst case complexity are known [Berkholz, Bonsma, Grohe, ESA2013] no\ncomparative analysis of design choices for color refinement algorithms is\navailable. We devise two models within which we can compare color refinement\nalgorithms using formal methods, an online model and an approximation model. We\nuse these to show that no online algorithm is competitive beyond a logarithmic\nfactor and no algorithm can approximate the optimal color refinement splitting\nscheme beyond a logarithmic factor. We also directly compare strategies used in\npractice showing that, on some graphs, queue based strategies outperform stack\nbased ones by a logarithmic factor and vice versa. Similar results hold for\nstrategies based on priority queues.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 13:30:50 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Anders", "Markus", ""], ["Schweitzer", "Pascal", ""], ["Wetzels", "Florian", ""]]}, {"id": "2103.10359", "submitter": "Valentin Buchhold", "authors": "Valentin Buchhold and Dorothea Wagner", "title": "Nearest-Neighbor Queries in Customizable Contraction Hierarchies and\n  Applications", "comments": "Will be presented at the 19th International Symposium on Experimental\n  Algorithms (SEA'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customizable contraction hierarchies are one of the most popular route\nplanning frameworks in practice, due to their simplicity and versatility. In\nthis work, we present a novel algorithm for finding k-nearest neighbors in\ncustomizable contraction hierarchies by systematically exploring the associated\nseparator decomposition tree. Compared to previous bucket-based approaches, our\nalgorithm requires much less target-dependent preprocessing effort. Moreover,\nwe use our novel approach in two concrete applications. The first application\nare online k-closest point-of-interest queries, where the points of interest\nare only revealed at query time. We achieve query times of about 25\nmilliseconds on a continental road network, which is fast enough for\ninteractive systems. The second application is travel demand generation. We\nshow how to accelerate a recently introduced travel demand generator by a\nfactor of more than 50 using our novel nearest-neighbor algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 16:29:05 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Buchhold", "Valentin", ""], ["Wagner", "Dorothea", ""]]}, {"id": "2103.10406", "submitter": "Diego Ram\\'irez-Romero", "authors": "Waldo G\\'alvez, Fabrizio Grandoni, Arindam Khan, Diego\n  Ram\\'irez-Romero, Andreas Wiese", "title": "Improved Approximation Algorithms for 2-Dimensional Knapsack: Packing\n  into Multiple L-Shapes, Spirals, and More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\textsc{2-Dimensional Knapsack} problem (2DK) we are given a square\nknapsack and a collection of $n$ rectangular items with integer sizes and\nprofits. Our goal is to find the most profitable subset of items that can be\npacked non-overlappingly into the knapsack. The currently best known\npolynomial-time approximation factor for 2DK is $17/9+\\varepsilon<1.89$ and\nthere is a $(3/2+\\varepsilon)$-approximation algorithm if we are allowed to\nrotate items by 90 degrees~{[}G\\'alvez et al., FOCS 2017{]}. In this paper, we\ngive $(4/3+\\varepsilon)$-approximation algorithms in polynomial time for both\ncases, assuming that all input data are {integers polynomially bounded in $n$}.\n  G\\'alvez et al.'s algorithm for 2DK partitions the knapsack into a constant\nnumber of rectangular regions plus \\emph{one} L-shaped region and packs items\ninto those {in a structured way}. We generalize this approach by allowing up to\na \\emph{constant} number of {\\emph{more general}} regions that can have the\nshape of an L, a U, a Z, a spiral, and more, and therefore obtain an improved\napproximation ratio. {In particular, we present an algorithm that computes the\nessentially optimal structured packing into these regions. }\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 17:42:20 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["G\u00e1lvez", "Waldo", ""], ["Grandoni", "Fabrizio", ""], ["Khan", "Arindam", ""], ["Ram\u00edrez-Romero", "Diego", ""], ["Wiese", "Andreas", ""]]}, {"id": "2103.10536", "submitter": "Wenzheng Li", "authors": "Wenzheng Li, Jan Vondr\\'ak", "title": "A constant-factor approximation algorithm for Nash Social Welfare with\n  submodular valuations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a $380$-approximation algorithm for the Nash Social Welfare\nproblem with submodular valuations. Our algorithm builds on and extends a\nrecent constant-factor approximation for Rado valuations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 21:45:40 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Wenzheng", ""], ["Vondr\u00e1k", "Jan", ""]]}, {"id": "2103.10990", "submitter": "Andrzej Dorobisz", "authors": "Andrzej Dorobisz and Jakub Kozik", "title": "Local Computation Algorithms for Coloring of Uniform Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a progress on local computation algorithms for two coloring of\n$k$-uniform hypergraphs. We focus on instances that satisfy strengthened\nassumption of Local Lemma of the form $2^{1-\\alpha k} (\\Delta+1) e < 1$, where\n$\\Delta$ is the bound on the maximum edge degree of the hypergraph. We discuss\nhow previous works on the subject can be used to obtain an algorithm that works\nin polylogarithmic time per query for $\\alpha$ up to about $0.139$. Then, we\npresent a procedure that, within similar bounds on running time, solves wider\nrange of instances by allowing $\\alpha$ at most about $0.227$.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 19:17:14 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Dorobisz", "Andrzej", ""], ["Kozik", "Jakub", ""]]}, {"id": "2103.11216", "submitter": "Steven Damelin Dr", "authors": "Gurpreet S. Kalsi and Steven B. Damelin", "title": "Preprocessing power weighted shortest path data using a s-Well Separated\n  Pair Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $s$ $>$ 0, we consider an algorithm that computes all $s$-well separated\npairs in certain point sets in $\\mathbb{R}^{n}$, $n$ $>1$. For an integer $K$\n$>1$, we also consider an algorithm that is a permutation of Dijkstra's\nalgorithm, that computes $K$-nearest neighbors using a certain power weighted\nshortest path metric in $\\mathbb{R}^{n}$, $n$ $>$ $1$. We describe each\nalgorithm and their respective dependencies on the input data. We introduce a\nway to combine both algorithms into a fused algorithm. Several open problems\nare given for future research.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 17:38:13 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 20:27:09 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kalsi", "Gurpreet S.", ""], ["Damelin", "Steven B.", ""]]}, {"id": "2103.11333", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "ANITA: An Optimal Loopless Accelerated Variance-Reduced Gradient Method", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel accelerated variance-reduced gradient method called ANITA\nfor finite-sum optimization. In this paper, we consider both general convex and\nstrongly convex settings. In the general convex setting, ANITA achieves the\nconvergence result $O\\big(n\\min\\big\\{1+\\log\\frac{1}{\\epsilon\\sqrt{n}},\n\\log\\sqrt{n}\\big\\} + \\sqrt{\\frac{nL}{\\epsilon}} \\big)$, which improves the\nprevious best result $O\\big(n\\min\\{\\log\\frac{1}{\\epsilon}, \\log\nn\\}+\\sqrt{\\frac{nL}{\\epsilon}}\\big)$ given by Varag (Lan et al., 2019). In\nparticular, for a very wide range of $\\epsilon$, i.e., $\\epsilon \\in\n(0,\\frac{L}{n\\log^2\\sqrt{n}}]\\cup [\\frac{1}{\\sqrt{n}},+\\infty)$, where\n$\\epsilon$ is the error tolerance $f(x_T)-f^*\\leq \\epsilon$ and $n$ is the\nnumber of data samples, ANITA can achieve the optimal convergence result\n$O\\big(n+\\sqrt{\\frac{nL}{\\epsilon}}\\big)$ matching the lower bound\n$\\Omega\\big(n+\\sqrt{\\frac{nL}{\\epsilon}}\\big)$ provided by Woodworth and Srebro\n(2016). To the best of our knowledge, ANITA is the \\emph{first} accelerated\nalgorithm which can \\emph{exactly} achieve this optimal result\n$O\\big(n+\\sqrt{\\frac{nL}{\\epsilon}}\\big)$ for general convex finite-sum\nproblems. In the strongly convex setting, we also show that ANITA can achieve\nthe optimal convergence result\n$O\\Big(\\big(n+\\sqrt{\\frac{nL}{\\mu}}\\big)\\log\\frac{1}{\\epsilon}\\Big)$ matching\nthe lower bound\n$\\Omega\\Big(\\big(n+\\sqrt{\\frac{nL}{\\mu}}\\big)\\log\\frac{1}{\\epsilon}\\Big)$\nprovided by Lan and Zhou (2015). Moreover, ANITA enjoys a simpler loopless\nalgorithmic structure unlike previous accelerated algorithms such as Katyusha\n(Allen-Zhu, 2017) and Varag (Lan et al., 2019) where they use an inconvenient\ndouble-loop structure. Finally, the experimental results also show that ANITA\nconverges faster than previous state-of-the-art Varag (Lan et al., 2019),\nvalidating our theoretical results and confirming the practical superiority of\nANITA.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 08:14:40 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "2103.11469", "submitter": "Wes Gurnee", "authors": "Wes Gurnee and David B. Shmoys", "title": "Fairmandering: A column generation heuristic for fairness-optimized\n  political districting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The American winner-take-all congressional district system empowers\npoliticians to engineer electoral outcomes by manipulating district boundaries.\nExisting computational solutions mostly focus on drawing unbiased maps by\nignoring political and demographic input, and instead simply optimize for\ncompactness. We claim that this is a flawed approach because compactness and\nfairness are orthogonal qualities, and introduce a scalable two-stage method to\nexplicitly optimize for arbitrary piecewise-linear definitions of fairness. The\nfirst stage is a randomized divide-and-conquer column generation heuristic\nwhich produces an exponential number of distinct district plans by exploiting\nthe compositional structure of graph partitioning problems. This district\nensemble forms the input to a master selection problem to choose the districts\nto include in the final plan. Our decoupled design allows for unprecedented\nflexibility in defining fairness-aligned objective functions. The pipeline is\narbitrarily parallelizable, is flexible to support additional redistricting\nconstraints, and can be applied to a wide array of other regionalization\nproblems. In the largest ever ensemble study of congressional districts, we use\nour method to understand the range of possible expected outcomes and the\nimplications of this range on potential definitions of fairness.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 19:22:42 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 20:48:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gurnee", "Wes", ""], ["Shmoys", "David B.", ""]]}, {"id": "2103.11595", "submitter": "Xin Hong", "authors": "Xin Hong, Mingsheng Ying, Yuan Feng, Xiangzhen Zhou and Sanjiang Li", "title": "Approximate Equivalence Checking of Noisy Quantum Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental design automation problem of equivalence checking in\nthe NISQ (Noisy Intermediate-Scale Quantum) computing realm where quantum noise\nis present inevitably. The notion of approximate equivalence of (possibly\nnoisy) quantum circuits is defined based on the Jamiolkowski fidelity which\nmeasures the average distance between output states of two super-operators when\nthe input is chosen at random. By employing tensor network contraction, we\npresent two algorithms, aiming at different situations where the number of\nnoises varies, for computing the fidelity between an ideal quantum circuit and\nits noisy implementation. The effectiveness of our algorithms is demonstrated\nby experimenting on benchmarks of real NISQ circuits. When compared with the\nstate-of-the-art implementation incorporated in Qiskit, experimental results\nshow that the proposed algorithms outperform in both efficiency and\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 05:47:41 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:10:54 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Hong", "Xin", ""], ["Ying", "Mingsheng", ""], ["Feng", "Yuan", ""], ["Zhou", "Xiangzhen", ""], ["Li", "Sanjiang", ""]]}, {"id": "2103.11609", "submitter": "Kuikui Liu", "authors": "Kuikui Liu", "title": "From Coupling to Spectral Independence and Blackbox Comparison with the\n  Down-Up Walk", "comments": "v2: accepted to RANDOM 2021, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math-ph math.MP math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the existence of a \"good\"' coupling w.r.t. Hamming distance for\nany local Markov chain on a discrete product space implies rapid mixing of the\nGlauber dynamics in a blackbox fashion. More specifically, we only require the\nexpected distance between successive iterates under the coupling to be\nsummable, as opposed to being one-step contractive in the worst case. Combined\nwith recent local-to-global arguments \\cite{CLV21}, we establish asymptotically\noptimal lower bounds on the standard and modified log-Sobolev constants for the\nGlauber dynamics for sampling from spin systems on bounded-degree graphs when a\ncurvature condition \\cite{Oll09} is satisfied. To achieve this, we use Stein's\nmethod for Markov chains \\cite{BN19, RR19} to show that a \"good\" coupling for a\nlocal Markov chain yields strong bounds on the spectral independence of the\ndistribution in the sense of \\cite{ALO20}.\n  Our primary application is to sampling proper list-colorings on\nbounded-degree graphs. In particular, combining the coupling for the flip\ndynamics given by \\cite{Vig00, CDMPP19} with our techniques, we show optimal\n$O(n\\log n)$ mixing for the Glauber dynamics for sampling proper list-colorings\non any bounded-degree graph with maximum degree $\\Delta$ whenever the size of\nthe color lists are at least $\\left(\\frac{11}{6} - \\epsilon\\right)\\Delta$,\nwhere $\\epsilon \\approx 10^{-5}$ is small constant. While $O(n^{2})$ mixing was\nalready known before, our approach additionally yields Chernoff-type\nconcentration bounds for Hamming Lipschitz functions in this regime, which was\nnot known before. Our approach is markedly different from prior works\nestablishing spectral independence for spin systems using spatial mixing\n\\cite{ALO20, CLV20, CGSV20, FGYZ20}, which crucially is still open in this\nregime for proper list-colorings.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 06:32:11 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 07:02:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Kuikui", ""]]}, {"id": "2103.11669", "submitter": "Michael Kapralov", "authors": "Michael Kapralov", "title": "Space Lower Bounds for Approximating Maximum Matching in the Edge\n  Arrival Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bipartite matching problem in the online and streaming settings has\nreceived a lot of attention recently. The classical vertex arrival setting, for\nwhich the celebrated Karp, Vazirani and Vazirani (KVV) algorithm achieves a\n$1-1/e$ approximation, is rather well understood: the $1-1/e$ approximation is\noptimal in both the online and semi-streaming setting, where the algorithm is\nconstrained to use $n\\cdot \\log^{O(1)} n$ space. The more challenging the edge\narrival model has seen significant progress recently in the online algorithms\nliterature. For the strictly online model (no preemption) approximations better\nthan trivial factor $1/2$ have been ruled out [Gamlath et al'FOCS'19]. For the\nless restrictive online preemptive model a better than $\\frac1{1+\\ln\n2}$-approximation [Epstein et al'STACS'12] and even a better than\n$(2-\\sqrt{2})$-approximation[Huang et al'SODA'19] have been ruled out.\n  The recent hardness results for online preemptive matching in the edge\narrival model are based on the idea of stringing together multiple copies of a\nKVV hard instance using edge arrivals. In this paper, we show how to implement\nsuch constructions using ideas developed in the literature on Ruzsa-Szemer\\'edi\ngraphs. As a result, we show that any single pass streaming algorithm that\napproximates the maximum matching in a bipartite graph with $n$ vertices to a\nfactor better than $\\frac1{1+\\ln 2}\\approx 0.59$ requires\n$n^{1+\\Omega(1/\\log\\log n)}\\gg n \\log^{O(1)} n$ space. This gives the first\nseparation between the classical one sided vertex arrival setting and the edge\narrival setting in the semi-streaming model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 08:49:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Kapralov", "Michael", ""]]}, {"id": "2103.12024", "submitter": "Nikita Zhivotovskiy", "authors": "Yegor Klochkov and Nikita Zhivotovskiy", "title": "Stability and Deviation Optimal Risk Bounds with Convergence Rate\n  $O(1/n)$", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sharpest known high probability generalization bounds for uniformly\nstable algorithms (Feldman, Vondr\\'{a}k, 2018, 2019), (Bousquet, Klochkov,\nZhivotovskiy, 2020) contain a generally inevitable sampling error term of order\n$\\Theta(1/\\sqrt{n})$. When applied to excess risk bounds, this leads to\nsuboptimal results in several standard stochastic convex optimization problems.\nWe show that if the so-called Bernstein condition is satisfied, the term\n$\\Theta(1/\\sqrt{n})$ can be avoided, and high probability excess risk bounds of\norder up to $O(1/n)$ are possible via uniform stability. Using this result, we\nshow a high probability excess risk bound with the rate $O(\\log n/n)$ for\nstrongly convex and Lipschitz losses valid for \\emph{any} empirical risk\nminimization method. This resolves a question of Shalev-Shwartz, Shamir,\nSrebro, and Sridharan (2009). We discuss how $O(\\log n/n)$ high probability\nexcess risk bounds are possible for projected gradient descent in the case of\nstrongly convex and Lipschitz losses without the usual smoothness assumption.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 17:28:40 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Klochkov", "Yegor", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2103.12878", "submitter": "Renato Portugal", "authors": "G. A. Bezerra, P. H. G. Lug\\~ao, and R. Portugal", "title": "Quantum walk-based search algorithms with multiple marked vertices", "comments": "12 pages, 1 table, 2 figs", "journal-ref": "Phys. Rev. A 103, 062202 (2021)", "doi": "10.1103/PhysRevA.103.062202", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quantum walk is a powerful tool to develop quantum algorithms, which\nusually are based on searching for a vertex in a graph with multiple marked\nvertices, Ambainis's quantum algorithm for solving the element distinctness\nproblem being the most shining example. In this work, we address the problem of\ncalculating analytical expressions of the time complexity of finding a marked\nvertex using quantum walk-based search algorithms with multiple marked vertices\non arbitrary graphs, extending previous analytical methods based on Szegedy's\nquantum walk, which can be applied only to bipartite graphs. Two examples based\non the coined quantum walk on two-dimensional lattices and hypercubes show the\ndetails of our method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 22:57:07 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 01:53:19 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 13:01:54 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bezerra", "G. A.", ""], ["Lug\u00e3o", "P. H. G.", ""], ["Portugal", "R.", ""]]}, {"id": "2103.12894", "submitter": "Bart de Keijzer", "authors": "Bart de Keijzer and Dominik Wojtczak", "title": "Facility Reallocation on the Line", "comments": "28 Pages, 5 Figures. A prelimininary version of the paper, with most\n  proofs omitted, has appeared at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-stage facility reallocation problems on the real line,\nwhere a facility is being moved between time stages based on the locations\nreported by $n$ agents. The aim of the reallocation algorithm is to minimise\nthe social cost, i.e., the sum over the total distance between the facility and\nall agents at all stages, plus the cost incurred for moving the facility. We\nstudy this problem both in the offline setting and online setting. In the\noffline case the algorithm has full knowledge of the agent locations in all\nfuture stages, and in the online setting the algorithm does not know these\nfuture locations and must decide the location of the facility on a\nstage-per-stage basis. We derive the optimal algorithm in both cases. For the\nonline setting we show that its competitive ratio is $(n+2)/(n+1)$. As neither\nof these algorithms turns out to yield a strategy-proof mechanism, we propose\nanother strategy-proof mechanism which has a competitive ratio of $(n+3)/(n+1)$\nfor odd $n$ and $(n+4)/n$ for even $n$, which we conjecture to be the best\npossible. We also consider a generalisation with multiple facilities and\nweighted agents, for which we show that the optimum can be computed in\npolynomial time for a fixed number of facilities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 23:48:45 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["de Keijzer", "Bart", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "2103.12908", "submitter": "Kent Quanrud", "authors": "Chandra Chekuri and Kent Quanrud", "title": "Isolating Cuts, (Bi-)Submodularity, and Faster Algorithms for Global\n  Connectivity Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Li and Panigrahi, in recent work, obtained the first deterministic algorithm\nfor the global minimum cut of a weighted undirected graph that runs in time\n$o(mn)$. They introduced an elegant and powerful technique to find isolating\ncuts for a terminal set in a graph via a small number of $s$-$t$ minimum cut\ncomputations.\n  In this paper we generalize their isolating cut approach to the abstract\nsetting of symmetric bisubmodular functions (which also capture symmetric\nsubmodular functions). Our generalization to bisubmodularity is motivated by\napplications to element connectivity and vertex connectivity. Utilizing the\ngeneral framework and other ideas we obtain significantly faster randomized\nalgorithms for computing global (and subset) connectivity in a number of\nsettings including hypergraphs, element connectivity and vertex connectivity in\ngraphs, and for symmetric submodular functions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 01:12:09 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Chekuri", "Chandra", ""], ["Quanrud", "Kent", ""]]}, {"id": "2103.13024", "submitter": "Xinkai Shu", "authors": "Zhiyi Huang, Xinkai Shu", "title": "Online Stochastic Matching, Poisson Arrivals, and the Natural Linear\n  Program", "comments": "24 pages. Accepted by STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online stochastic matching problem. Consider a bipartite graph\nwith offline vertices on one side, and with i.i.d.online vertices on the other\nside. The offline vertices and the distribution of online vertices are known to\nthe algorithm beforehand. The realization of the online vertices, however, is\nrevealed one at a time, upon which the algorithm immediately decides how to\nmatch it. For maximizing the cardinality of the matching, we give a\n$0.711$-competitive online algorithm, which improves the best previous ratio of\n$0.706$. When the offline vertices are weighted, we introduce a\n$0.7009$-competitive online algorithm for maximizing the total weight of the\nmatched offline vertices, which improves the best previous ratio of $0.662$.\n  Conceptually, we find that the analysis of online algorithms simplifies if\nthe online vertices follow a Poisson process, and establish an approximate\nequivalence between this Poisson arrival model and online stochstic matching.\nTechnically, we propose a natural linear program for the Poisson arrival model,\nand demonstrate how to exploit its structure by introducing a converse of\nJensen's inequality. Moreover, we design an algorithmic amortization to replace\nthe analytic one in previous work, and as a result get the first\nvertex-weighted online stochastic matching algorithm that improves the results\nin the weaker random arrival model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 07:12:42 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Huang", "Zhiyi", ""], ["Shu", "Xinkai", ""]]}, {"id": "2103.13089", "submitter": "Matthew Faw", "authors": "Constantine Caramanis, Matthew Faw, Orestis Papadigenopoulos,\n  Emmanouil Pountourakis", "title": "Single-Sample Prophet Inequalities Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the prophet inequality problem in the limited information regime\nwas initiated by Azar et al. [SODA'14] in the pursuit of prior-independent\nposted-price mechanisms. As they show, $O(1)$-competitive policies are\nachievable using only a single sample from the distribution of each agent. A\nnotable portion of their results relies on reducing the design of single-sample\nprophet inequalities (SSPIs) to that of order-oblivious secretary (OOS)\npolicies. The above reduction comes at the cost of not fully utilizing the\navailable samples. However, to date, this is essentially the only method for\nproving SSPIs for many combinatorial sets. Very recently, Rubinstein et al.\n[ITCS'20] give a surprisingly simple algorithm which achieves the optimal\ncompetitive ratio for the single-choice SSPI problem $-$ a result which is\nunobtainable going through the reduction to secretary problems. Motivated by\nthis discrepancy, we study the competitiveness of simple SSPI policies\ndirectly, without appealing to results from OOS literature. In this direction,\nwe first develop a framework for analyzing policies against a greedy-like\nprophet solution. Using this framework, we obtain the first SSPI for general\n(non-bipartite) matching environments, as well as improved competitive ratios\nfor transversal and truncated partition matroids. Second, motivated by the\nobservation that many OOS policies for matroids decompose the problem into\nindependent rank-$1$ instances, we provide a meta-theorem which applies to any\nmatroid satisfying this partition property. Leveraging the recent results by\nRubinstein et al., we obtain improved competitive guarantees (most by a factor\nof $2$) for a number of matroids captured by the reduction of Azar et al.\nFinally, we discuss applications of our SSPIs to the design of mechanisms for\nmulti-dimensional limited information settings with improved revenue and\nwelfare guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 11:03:05 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Caramanis", "Constantine", ""], ["Faw", "Matthew", ""], ["Papadigenopoulos", "Orestis", ""], ["Pountourakis", "Emmanouil", ""]]}, {"id": "2103.13331", "submitter": "Martin Schirneck", "authors": "Thomas Bl\\\"asius, Tobias Friedrich, Martin Schirneck", "title": "The Complexity of Dependency Detection and Discovery in Relational\n  Databases", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-column dependencies in relational databases come associated with two\ndifferent computational tasks. The detection problem is to decide whether a\ndependency of a certain type and size holds in a given database, the discovery\nproblem asks to enumerate all valid dependencies of that type. We settle the\ncomplexity of both of these problems for unique column combinations (UCCs),\nfunctional dependencies (FDs), and inclusion dependencies (INDs). We show that\nthe detection of UCCs and FDs is W[2]-complete when parameterized by the\nsolution size. The discovery of inclusion-wise minimal UCCs is proven to be\nequivalent under parsimonious reductions to the transversal hypergraph problem\nof enumerating the minimal hitting sets of a hypergraph. The discovery of FDs\nis equivalent to the simultaneous enumeration of the hitting sets of multiple\ninput hypergraphs. We further identify the detection of INDs as one of the\nfirst natural W[3]-complete problems. The discovery of maximal INDs is shown to\nbe equivalent to enumerating the maximal satisfying assignments of\nantimonotone, 3-normalized Boolean formulas.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 16:34:43 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Bl\u00e4sius", "Thomas", ""], ["Friedrich", "Tobias", ""], ["Schirneck", "Martin", ""]]}, {"id": "2103.13462", "submitter": "Tengyu Ma", "authors": "Tengyu Ma", "title": "Why Do Local Methods Solve Nonconvex Problems?", "comments": "This is the Chapter 21 of the book \"Beyond the Worst-Case Analysis of\n  Algorithms\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-convex optimization is ubiquitous in modern machine learning. Researchers\ndevise non-convex objective functions and optimize them using off-the-shelf\noptimizers such as stochastic gradient descent and its variants, which leverage\nthe local geometry and update iteratively. Even though solving non-convex\nfunctions is NP-hard in the worst case, the optimization quality in practice is\noften not an issue -- optimizers are largely believed to find approximate\nglobal minima. Researchers hypothesize a unified explanation for this\nintriguing phenomenon: most of the local minima of the practically-used\nobjectives are approximately global minima. We rigorously formalize it for\nconcrete instances of machine learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 19:34:11 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Ma", "Tengyu", ""]]}, {"id": "2103.13577", "submitter": "Oded Green", "authors": "Oded Green", "title": "ButterFly BFS -- An Efficient Communication Pattern for Multi Node\n  Traversals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breadth-First Search (BFS) is a building block used in a wide array of graph\nanalytics and is used in various network analysis domains: social, road,\ntransportation, communication, and much more. Over the last two decades,\nnetwork sizes have continued to grow. The popularity of BFS has brought with it\na need for significantly faster traversals. Thus, BFS algorithms have been\ndesigned to exploit shared-memory and shared-nothing systems -- this includes\nalgorithms for accelerators such as the GPU. GPUs offer extremely fast\ntraversals at the cost of processing smaller graphs due to their limited memory\nsize. In contrast, CPU shared-memory systems can scale to graphs with several\nbillion edges but do not have enough compute resources needed for fast\ntraversals. This paper introduces ButterFly BFS, a multi-GPU traversal\nalgorithm that allows analyzing significantly larger networks at high rates.\nButterFly BFS scales to the similar-sized graphs processed by shared-memory\nsystems while improving performance by more than 10X compared to CPUs. We\nevaluate our new algorithm on an NVIDIA DGX-2 server with 16 V100 GPUS and show\nthat our algorithm scales with an increase in the number of GPUS. We show that\nwe can achieve a roughly $70\\%$ performance linear speedup, which is\nnon-trivial for BFS. For a scale 29 Kronecker graph and edge factor of 8, our\nnew algorithm traverses the graph at a rate of over 300 GTEP/s. That is a high\ntraversal rate for a single server.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 03:22:01 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Green", "Oded", ""]]}, {"id": "2103.14068", "submitter": "Rachel Cummings", "authors": "Chris Waites and Rachel Cummings", "title": "Differentially Private Normalizing Flows for Privacy-Preserving Density\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flow models have risen as a popular solution to the problem of\ndensity estimation, enabling high-quality synthetic data generation as well as\nexact probability density evaluation. However, in contexts where individuals\nare directly associated with the training data, releasing such a model raises\nprivacy concerns. In this work, we propose the use of normalizing flow models\nthat provide explicit differential privacy guarantees as a novel approach to\nthe problem of privacy-preserving density estimation. We evaluate the efficacy\nof our approach empirically using benchmark datasets, and we demonstrate that\nour method substantially outperforms previous state-of-the-art approaches. We\nadditionally show how our algorithm can be applied to the task of\ndifferentially private anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 18:39:51 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Waites", "Chris", ""], ["Cummings", "Rachel", ""]]}, {"id": "2103.14112", "submitter": "Vaclav Rozhon", "authors": "Jan Greb\\'ik and V\\'aclav Rozho\\v{n}", "title": "Classification of Local Problems on Paths from the Perspective of\n  Descriptive Combinatorics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify which local problems with inputs on oriented paths have so-called\nBorel solution and show that this class of problems remains the same if we\ninstead require a measurable solution, a factor of iid solution, or a solution\nwith the property of Baire.\n  Together with the work from the field of distributed computing [Balliu et al.\nPODC 2019], the work from the field of descriptive combinatorics [Gao et al.\narXiv:1803.03872, Bernshteyn arXiv:2004.04905] and the work from the field of\nrandom processes [Holroyd et al. Annals of Prob. 2017, Greb\\'ik, Rozho\\v{n}\narXiv:2103.08394], this finishes the classification of local problems with\ninputs on oriented paths using complexity classes from these three fields.\n  A simple picture emerges: there are four classes of local problems and most\nclasses have natural definitions in all three fields.\n  Moreover, we now know that randomness does \\emph{not} help with solving local\nproblems on oriented paths.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 20:03:52 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Greb\u00edk", "Jan", ""], ["Rozho\u0148", "V\u00e1clav", ""]]}, {"id": "2103.14511", "submitter": "Marco Fanizza", "authors": "Marco Fanizza, Raffaele Salvia, Vittorio Giovannetti", "title": "Testing identity of collections of quantum states: sample complexity\n  analysis", "comments": "20+6 pages, 0 figures. Typos corrected, improved presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing identity of a collection of unknown quantum\nstates given sample access to this collection, each state appearing with some\nknown probability. We show that for a collection of $d$-dimensional quantum\nstates of cardinality $N$, the sample complexity is $O(\\sqrt{N}d/\\epsilon^2)$,\nwhich is optimal up to a constant. The test is obtained by estimating the mean\nsquared Hilbert-Schmidt distance between the states, thanks to a suitable\ngeneralization of the estimator of the Hilbert-Schmidt distance between two\nunknown states by B\\u{a}descu, O'Donnell, and Wright\n(https://dl.acm.org/doi/10.1145/3313276.3316344).\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 15:13:45 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 08:45:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fanizza", "Marco", ""], ["Salvia", "Raffaele", ""], ["Giovannetti", "Vittorio", ""]]}, {"id": "2103.15217", "submitter": "Adam Polak", "authors": "Adam Polak, Adrian Siwiec, Micha{\\l} Stobierski", "title": "Euler Meets GPU: Practical Graph Algorithms with Theoretical Guarantees", "comments": "IPDPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euler tour technique is a classical tool for designing parallel graph\nalgorithms, originally proposed for the PRAM model. We ask whether it can be\nadapted to run efficiently on GPU. We focus on two established applications of\nthe technique: (1) the problem of finding lowest common ancestors (LCA) of\npairs of nodes in trees, and (2) the problem of finding bridges in undirected\ngraphs. In our experiments, we compare theoretically optimal algorithms using\nthe Euler tour technique against simpler heuristics supposed to perform\nparticularly well on typical instances. We show that the Euler tour-based\nalgorithms not only fulfill their theoretical promises and outperform practical\nheuristics on hard instances, but also perform on par with them on easy\ninstances.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 21:02:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Polak", "Adam", ""], ["Siwiec", "Adrian", ""], ["Stobierski", "Micha\u0142", ""]]}, {"id": "2103.15234", "submitter": "Amelia Regan", "authors": "Naveen Haghani, Julian Yarkony, Amelia Regan", "title": "Family Column Generation: A Principled Stabilized Column Generation\n  Approach", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of accelerating column generation (CG) approaches to\nset cover formulations in operations research. At each iteration of CG we\ngenerate a dual solution that approximately solves the LP over all columns\nconsisting of a subset of columns in the nascent set. We refer to this linear\nprogram (LP) as the Family Restricted Master Problem (FRMP), which provides a\ntighter bound on the master problem at each iteration of CG, while preserving\nefficient inference. For example, in the single source capacitated facility\nlocation problem (SSCFLP) the family of a column $l$ associated with facility\n$f$ and customer set $N_l$ contains the set of columns associated with $f$ and\nthe customer set that lies in the power set of $N_l$. The solution to FRMP\noptimization is attacked with a coordinate ascent method in the dual. The\ngeneration of direction of travel corresponds to solving the restricted master\nproblem over columns corresponding to the reduced lowest cost column in each\nfamily given specific dual variables based on the incumbent dual, and is easily\ngenerated without resolving complex pricing problems. We apply our algorithm to\nthe SSCFLP and demonstrate improved performance over two relevant baselines.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 22:19:05 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Haghani", "Naveen", ""], ["Yarkony", "Julian", ""], ["Regan", "Amelia", ""]]}, {"id": "2103.15329", "submitter": "Dustin Cobas", "authors": "Dustin Cobas, Travis Gagie and Gonzalo Navarro", "title": "A Fast and Small Subsampled R-index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $r$-index (Gagie et al., JACM 2020) represented a breakthrough in\ncompressed indexing of repetitive text collections, outperforming its\nalternatives by orders of magnitude. Its space usage, $\\mathcal{O}(r)$ where\n$r$ is the number of runs in the Burrows-Wheeler Transform of the text, is\nhowever larger than Lempel-Ziv and grammar-based indexes, and makes it\nuninteresting in various real-life scenarios of milder repetitiveness. In this\npaper we introduce the $sr$-index, a variant that limits the space to\n$\\mathcal{O}(\\min(r,n/s))$ for a text of length $n$ and a given parameter $s$,\nat the expense of multiplying by $s$ the time per occurrence reported. The\n$sr$-index is obtained by carefully subsampling the text positions indexed by\nthe $r$-index, in a way that we prove is still able to support pattern matching\nwith guaranteed performance. Our experiments demonstrate that the $sr$-index\nsharply outperforms virtually every other compressed index on repetitive texts,\nboth in time and space, even matching the performance of the $r$-index while\nusing 1.5--3.0 times less space. Only some Lempel-Ziv-based indexes achieve\nbetter compression than the $sr$-index, using about half the space, but they\nare an order of magnitude slower.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 04:54:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Cobas", "Dustin", ""], ["Gagie", "Travis", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "2103.15352", "submitter": "Daogao Liu", "authors": "Janardhan Kulkarni, Yin Tat Lee, Daogao Liu", "title": "Private Non-smooth Empirical Risk Minimization and Stochastic Convex\n  Optimization in Subquadratic Steps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differentially private Empirical Risk Minimization (ERM) and\nStochastic Convex Optimization (SCO) problems for non-smooth convex functions.\nWe get a (nearly) optimal bound on the excess empirical risk and excess\npopulation loss with subquadratic gradient complexity. More precisely, our\ndifferentially private algorithm requires $O(\\frac{N^{3/2}}{d^{1/8}}+\n\\frac{N^2}{d})$ gradient queries for optimal excess empirical risk, which is\nachieved with the help of subsampling and smoothing the function via\nconvolution. This is the first subquadratic algorithm for the non-smooth case\nwhen $d$ is super constant. As a direct application, using the iterative\nlocalization approach of Feldman et al. \\cite{fkt20}, we achieve the optimal\nexcess population loss for stochastic convex optimization problem, with\n$O(\\min\\{N^{5/4}d^{1/8},\\frac{ N^{3/2}}{d^{1/8}}\\})$ gradient queries. Our work\nmakes progress towards resolving a question raised by Bassily et al.\n\\cite{bfgt20}, giving first algorithms for private ERM and SCO with\nsubquadratic steps.\n  We note that independently Asi et al. \\cite{afkt21} gave other algorithms for\nprivate ERM and SCO with subquadratic steps.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 05:58:56 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:45:26 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kulkarni", "Janardhan", ""], ["Lee", "Yin Tat", ""], ["Liu", "Daogao", ""]]}, {"id": "2103.15703", "submitter": "Sorrachai Yingchareonthawornchai", "authors": "Max Franck, Sorrachai Yingchareonthawornchai", "title": "Engineering Nearly Linear-Time Algorithms for Small Vertex Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex connectivity is a well-studied concept in graph theory with numerous\napplications. A graph is $k$-connected if it remains connected after removing\nany $k-1$ vertices. The vertex connectivity of a graph is the maximum $k$ such\nthat the graph is $k$-connected. There is a long history of algorithmic\ndevelopment for efficiently computing vertex connectivity. Recently, two near\nlinear-time algorithms for small k were introduced by [Forster et al. SODA\n2020]. Prior to that, the best known algorithm was one by [Henzinger et al.\nFOCS'96] with quadratic running time when k is small.\n  In this paper, we study the practical performance of the algorithms by\nForster et al. In addition, we introduce a new heuristic on a key subroutine\ncalled local cut detection, which we call degree counting. We prove that the\nnew heuristic improves space-efficiency (which can be good for caching\npurposes) and allows the subroutine to terminate earlier. According to\nexperimental results on random graphs with planted vertex cuts, random\nhyperbolic graphs, and real world graphs with vertex connectivity between 4 and\n15, the degree counting heuristic offers a factor of 2-4 speedup over the\noriginal non-degree counting version for most of our data. It also outperforms\nthe previous state-of-the-art algorithm by Henzinger et al. even on relatively\nsmall graphs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 15:39:54 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Franck", "Max", ""], ["Yingchareonthawornchai", "Sorrachai", ""]]}, {"id": "2103.15724", "submitter": "Sagnik Mukhopadhyay", "authors": "Sagnik Mukhopadhyay, Danupon Nanongkai", "title": "A Note on Isolating Cut Lemma for Submodular Function Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been observed independently by many researchers that the isolating cut\nlemma of Li and Panigrahi [FOCS 2020] can be easily extended to obtain new\nalgorithms for finding the non-trivial minimizer of a symmetric submodular\nfunction and solving the hypergraph minimum cut problem. This note contains\nthese observations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 16:11:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mukhopadhyay", "Sagnik", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "2103.16182", "submitter": "Nikolaos Kallimanis", "authors": "Nikolaos D. Kallimanis", "title": "Synch: A framework for concurrent data-structures and benchmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent advancements in multicore machines highlight the need to simplify\nconcurrent programming in order to leverage their computational power. One way\nto achieve this is by designing efficient concurrent data structures (e.g.\nstacks, queues, hash-tables, etc.) and synchronization techniques (e.g. locks,\ncombining techniques, etc.) that perform well in machines with large amounts of\ncores. In contrast to ordinary, sequential data-structures, the concurrent\ndata-structures allow multiple threads to simultaneously access and/or modify\nthem.\n  Synch is an open-source framework that not only provides some common\nhigh-performant concurrent data-structures, but it also provides researchers\nwith the tools for designing and benchmarking high performant concurrent\ndata-structures. The Synch framework contains a substantial set of concurrent\ndata-structures such as queues, stacks, combining-objects, hash-tables, locks,\netc. and it provides a user-friendly runtime for developing and benchmarking\nconcurrent data-structures. Among other features, the provided runtime provides\nfunctionality for creating threads easily (both POSIX and user-level threads),\ntools for measuring performance, etc. Moreover, the provided concurrent\ndata-structures and the runtime are highly optimized for contemporary NUMA\nmultiprocessors such as AMD Epyc and Intel Xeon.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 09:03:22 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kallimanis", "Nikolaos D.", ""]]}, {"id": "2103.16185", "submitter": "Jakub Ruszil", "authors": "Jakub Ruszil", "title": "Approximation algorithm for finding short synchronizing words in\n  weighted automata", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DM cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we are dealing with the issue of finding possibly short\nsynchronizing words in automata with weight assigned to each letter in the\nalphabet $\\Sigma$. First we discuss some complexity problems, and then we\npresent new approximation algorithm in four variations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 09:07:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ruszil", "Jakub", ""]]}, {"id": "2103.16245", "submitter": "Bartosz Meglicki", "authors": "Bartosz Meglicki", "title": "Linear time DBSCAN for sorted 1D data and laser range scan segmentation", "comments": "Technical report from personal research (2016/2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DS eess.SP stat.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces new algorithm for line extraction from laser range data\nincluding methodology for efficient computation. The task is cast to series of\none dimensional problems in various spaces. A fast and simple specialization of\nDBSCAN algorithm is proposed to solve one dimensional subproblems. Experiments\nsuggest that the method is suitable for real-time applications, handles noise\nwell and may be useful in practice.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 10:50:02 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Meglicki", "Bartosz", ""]]}, {"id": "2103.16251", "submitter": "Sebastian Brandt", "authors": "Sebastian Brandt, Christoph Grunau, V\\'aclav Rozho\\v{n}", "title": "The randomized local computation complexity of the Lov\\'asz local lemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Local Computation Algorithm (LCA) model is a popular model in the field\nof sublinear-time algorithms that measures the complexity of an algorithm by\nthe number of probes the algorithm makes in the neighborhood of one node to\ndetermine that node's output.\n  In this paper we show that the randomized LCA complexity of the Lov\\'asz\nLocal Lemma (LLL) on constant degree graphs is $\\Theta(\\log n)$. The lower\nbound follows by proving an $\\Omega(\\log n)$ lower bound for the Sinkless\nOrientation problem introduced in [Brandt et al. STOC 2016]. This answers a\nquestion of [Rosenbaum, Suomela PODC 2020].\n  Additionally, we show that every randomized LCA algorithm for a locally\ncheckable problem with a probe complexity of $o(\\sqrt{\\log{n}})$ can be turned\ninto a deterministic LCA algorithm with a probe complexity of $O(\\log^* n)$.\nThis improves exponentially upon the currently best known speed-up result from\n$o(\\log \\log n)$ to $O(\\log^* n)$ implied by the result of [Chang, Pettie FOCS\n2017] in the LOCAL model.\n  Finally, we show that for every fixed constant $c \\geq 2$, the deterministic\nVOLUME complexity of $c$-coloring a bounded degree tree is $\\Theta(n)$, where\nthe VOLUME model is a close relative of the LCA model that was recently\nintroduced by [Rosenbaum, Suomela PODC 2020].\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 11:06:05 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Brandt", "Sebastian", ""], ["Grunau", "Christoph", ""], ["Rozho\u0148", "V\u00e1clav", ""]]}, {"id": "2103.16340", "submitter": "Maximilian Janke", "authors": "Susanne Albers, Maximilian Janke", "title": "Scheduling in the Secretary Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Makespan Minimization in the secretary model. Formally,\njobs, specified by their processing times, are presented in a uniformly random\norder. An online algorithm has to assign each job permanently and irrevocably\nto one of m parallel and identical machines such that the expected time it\ntakes to process them all, the makespan, is minimized. We give two\ndeterministic algorithms. First, a straightforward adaptation of the\nsemi-online strategy LightLoad provides a very simple algorithm retaining its\ncompetitive ratio of 1.75. A new and sophisticated algorithm is\n1.535-competitive. These competitive ratios are not only obtained in\nexpectation but, in fact, for all but a very tiny fraction of job orders.\nClassically, online makespan minimization only considers the worst-case order.\nHere, no competitive ratio below 1.885 for deterministic algorithms and 1.581\nusing randomization is possible. The best randomized algorithm so far is\n1.916-competitive. Our results show that classical worst-case orders are quite\nrare and pessimistic for many applications. They also demonstrate the power of\nrandomization when compared to much stronger deterministic reordering models.\nWe complement our results by providing first lower bounds. A competitive ratio\nobtained on nearly all possible job orders must be at least 1.257. This implies\na lower bound of 1.043 for both deterministic and randomized algorithms in the\ngeneral model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:33:34 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Albers", "Susanne", ""], ["Janke", "Maximilian", ""]]}, {"id": "2103.16615", "submitter": "Wensheng Gan", "authors": "Chunkai Zhang, Zilin Du, Quanjian Dai, Wensheng Gan, Jian Weng, and\n  Philip S. Yu", "title": "TUSQ: Targeted High-Utility Sequence Querying", "comments": "Preprint. 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant efforts have been expended in the research and development of a\ndatabase management system (DBMS) that has a wide range of applications for\nmanaging an enormous collection of multisource, heterogeneous, complex, or\ngrowing data. Besides the primary function (i.e., create, delete, and update),\na practical and impeccable DBMS can interact with users through information\nselection, that is, querying with their targets. Previous querying algorithms,\nsuch as frequent itemset querying and sequential pattern querying (SPQ) have\nfocused on the measurement of frequency, which does not involve the concept of\nutility, which is helpful for users to discover more informative patterns. To\napply the querying technology for wider applications, we incorporate utility\ninto target-oriented SPQ and formulate the task of targeted utility-oriented\nsequence querying. To address the proposed problem, we develop a novel\nalgorithm, namely targeted high-utility sequence querying (TUSQ), based on two\nnovel upper bounds suffix remain utility and terminated descendants utility as\nwell as a vertical Last Instance Table structure. For further efficiency, TUSQ\nrelies on a projection technology utilizing a compact data structure called the\ntargeted chain. An extensive experimental study conducted on several real and\nsynthetic datasets shows that the proposed algorithm outperformed the designed\nbaseline algorithm in terms of runtime, memory consumption, and candidate\nfiltering.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 18:39:09 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhang", "Chunkai", ""], ["Du", "Zilin", ""], ["Dai", "Quanjian", ""], ["Gan", "Wensheng", ""], ["Weng", "Jian", ""], ["Yu", "Philip S.", ""]]}, {"id": "2103.16787", "submitter": "Ryan Rogers", "authors": "Adrian Rivera Cardoso, Ryan Rogers", "title": "Differentially Private Histograms under Continual Observation: Streaming\n  Selection into the Unknown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the continuous observation privacy setting from Dwork et al.\n'10 and Chan et al. '11 by allowing each event in a stream to be a subset of\nsome (possibly unknown) universe of items. We design differentially private\n(DP) algorithms for histograms in several settings, including top-$k$\nselection, with privacy loss that scales with polylog$(T)$, where $T$ is the\nmaximum length of the input stream. We present a meta-algorithm that can use\nexisting one-shot top-$k$ DP algorithms as a subroutine to continuously release\nprivate histograms from a stream. Further, we present more practical DP\nalgorithms for two settings: 1) continuously releasing the top-$k$ counts from\na histogram over a known domain when an event can consist of an arbitrary\nnumber of items, and 2) continuously releasing histograms over an unknown\ndomain when an event has a limited number of items.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 03:13:15 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Rogers", "Ryan", ""]]}, {"id": "2103.16796", "submitter": "Harumi  Haraguchi", "authors": "Hiroshi Arai and Harumi Haraguchi", "title": "Ising formulations for two-dimensional cutting stock problem with setup\n  cost", "comments": "8 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed the method that translates the 2-D CSP for minimizing the number\nof cuts to the Ising model. After that, we conducted computer experiments of\nthe proposed model using the benchmark problem. From the above, the following\nresults are obtained. (1) The proposed Ising model adequately represents the\ntarget problem. (2) Acceptance rates were low as 0.2% to 9.8% and from 21.8% to\n49.4%. (3) Error rates from optimal solution were broad as 0% to 25.9%. As the\nfuture work, (1) Improve the Hamiltonian for Constraints. (2) Improve the\nproposed model to adjust more complex 2-D CSP and reduce the number of spins\nwhen it deals with large materials and components. (3) Conduct experiments\nusing a quantum annealer.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 04:08:14 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Arai", "Hiroshi", ""], ["Haraguchi", "Harumi", ""]]}, {"id": "2103.17041", "submitter": "Pranabendu Misra", "authors": "Daniel Lokshtanov, Pranabendu Misra, Michal Pilipczuk, Saket Saurabh\n  and Meirav Zehavi", "title": "An Exponential Time Parameterized Algorithm for Planar Disjoint Paths", "comments": "Full version of STOC 2020 paper; 83 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Disjoint Paths problem, the input is an undirected graph $G$ on $n$\nvertices and a set of $k$ vertex pairs, $\\{s_i,t_i\\}_{i=1}^k$, and the task is\nto find $k$ pairwise vertex-disjoint paths connecting $s_i$ to $t_i$. The\nproblem was shown to have an $f(k)n^3$ algorithm by Robertson and Seymour. In\nmodern terminology, this means that Disjoint Paths is fixed parameter tractable\n(FPT), parameterized by the number of vertex pairs. This algorithm is the\ncornerstone of the entire graph minor theory, and a vital ingredient in the\n$g(k)n^3$ algorithm for Minor Testing (given two undirected graphs, $G$ and $H$\non $n$ and $k$ vertices, respectively, the objective is to check whether $G$\ncontains $H$ as a minor). All we know about $f$ and $g$ is that these are\ncomputable functions. Thus, a challenging open problem in graph algorithms is\nto devise an algorithm for Disjoint Paths where $f$ is single exponential. That\nis, $f$ is of the form $2^{{\\sf poly}(k)}$. The algorithm of Robertson and\nSeymour relies on topology and essentially reduces the problem to\nsurface-embedded graphs. Thus, the first major obstacle that has to be overcome\nin order to get an algorithm with a single exponential running time for\nDisjoint Paths and {\\sf Minor Testing} on general graphs is to solve Disjoint\nPaths in single exponential time on surface-embedded graphs and in particular\non planar graphs. Even when the inputs to Disjoint Paths are restricted to\nplanar graphs, a case called the Planar Disjoint Paths problem, the best known\nalgorithm has running time $2^{2^{O(k)}}n^2$. In this paper, we make the first\nstep towards our quest for designing a single exponential time algorithm for\nDisjoint Paths by giving a $2^{O(k^2)}n^{O(1)}$-time algorithm for Planar\nDisjoint Paths.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 12:52:14 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Misra", "Pranabendu", ""], ["Pilipczuk", "Michal", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}]