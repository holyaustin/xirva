[{"id": "1309.0081", "submitter": "Zhenbo Wang", "authors": "Kameng Nip, Zhenbo Wang, Fabrice Talla Nobibon and Roel Leus", "title": "A Combination of Flow Shop Scheduling and the Shortest Path Problem", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "KBI_1316", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a combinatorial optimization problem which is obtained by\ncombining the flow shop scheduling problem and the shortest path problem. The\nobjective of the obtained problem is to select a subset of jobs that\nconstitutes a feasible solution to the shortest path problem, and to execute\nthe selected jobs on the flow shop machines to minimize the makespan. We argue\nthat this problem is NP-hard even if the number of machines is two, and is\nNP-hard in the strong sense for the general case. We propose an intuitive\napproximation algorithm for the case where the number of machines is an input,\nand an improved approximation algorithm for fixed number of machines.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2013 09:12:42 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Nip", "Kameng", ""], ["Wang", "Zhenbo", ""], ["Nobibon", "Fabrice Talla", ""], ["Leus", "Roel", ""]]}, {"id": "1309.0082", "submitter": "Zhenbo Wang", "authors": "Kameng Nip, Zhenbo Wang and Wenxun Xing", "title": "Combinations of Some Shop Scheduling Problems and the Shortest Path\n  Problem: Complexity and Approximation Algorithms", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several combinatorial optimization problems which combine the\nclassic shop scheduling problems, namely open shop scheduling or job shop\nscheduling, and the shortest path problem. The objective of the obtained\nproblem is to select a subset of jobs that forms a feasible solution of the\nshortest path problem, and to execute the selected jobs on the open (or job)\nshop machines to minimize the makespan. We show that these problems are NP-hard\neven if the number of machines is two, and cannot be approximated within a\nfactor less than 2 if the number of machines is an input unless P=NP. We\npresent several approximation algorithms for these combination problems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2013 09:28:11 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Nip", "Kameng", ""], ["Wang", "Zhenbo", ""], ["Xing", "Wenxun", ""]]}, {"id": "1309.0192", "submitter": "Kamen Lozev", "authors": "Kamen M. Lozev", "title": "Reconstruction and uniqueness of moving obstacles", "comments": "21 pages, 6 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1111.6321", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the uniqueness and accuracy of the numerical solution of the problem\nof reconstruction of the shape and trajectory of a reflecting obstacle moving\nin an inhomogeneous medium from travel times, start and end points, and initial\nangles of ultrasonic rays reflecting at the obstacle. The speed of sound in the\ndomain when there is no obstacle present is known and provided as an input\nparameter which together with the other initial data enables the algorithm to\ntrace ray paths and find their reflection points. The reflection points\ndetermine with high-resolution the shape and trajectory of the obstacle. The\nmethod has predictable computational complexity and performance and is very\nefficient when it is parallelized and optimized because only a small portion of\nthe domain is reconstructed.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2013 08:48:17 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 08:54:23 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Lozev", "Kamen M.", ""]]}, {"id": "1309.0195", "submitter": "Mordechai Shalom", "authors": "George B. Mertzios, Mordechai Shalom, Prudence W.H. Wong, Shmuel Zaks", "title": "Online Regenerator Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between nodes in optical networks are realized by lightpaths. Due\nto the decay of the signal, a regenerator has to be placed on every lightpath\nafter at most $d$ hops, for some given positive integer $d$. A regenerator can\nserve only one lightpath. The placement of regenerators has become an active\narea of research during recent years, and various optimization problems have\nbeen studied. The first such problem is the Regeneration Location Problem\n($\\prb$), where the goal is to place the regenerators so as to minimize the\ntotal number of nodes containing them. We consider two extreme cases of online\n$\\prb$ regarding the value of $d$ and the number $k$ of regenerators that can\nbe used in any single node. (1) $d$ is arbitrary and $k$ unbounded. In this\ncase a feasible solution always exists. We show an $O(\\log \\abs{X} \\cdot \\log\nd)$-competitive randomized algorithm for any network topology, where $X$ is the\nset of paths of length $d$. The algorithm can be made deterministic in some\ncases. We show a deterministic lower bound of $\\Omega \\lb$, where $E$ is the\nedge set. (2) $d=2$ and $k=1$. In this case there is not necessarily a solution\nfor a given input. We distinguish between feasible inputs (for which there is a\nsolution) and infeasible ones. In the latter case, the objective is to satisfy\nthe maximum number of lightpaths. For a path topology we show a lower bound of\n$\\sqrt{l}/2$ for the competitive ratio (where $l$ is the number of internal\nnodes of the longest lightpath) on infeasible inputs, and a tight bound of 3\nfor the competitive ratio on feasible inputs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2013 09:01:59 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Mertzios", "George B.", ""], ["Shalom", "Mordechai", ""], ["Wong", "Prudence W. H.", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1309.0249", "submitter": "Igor Carboni Oliveira", "authors": "Igor C. Oliveira", "title": "Algorithms versus Circuit Lower Bounds", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different techniques have been used to prove several transference theorems of\nthe form \"nontrivial algorithms for a circuit class C yield circuit lower\nbounds against C\". In this survey we revisit many of these results. We discuss\nhow circuit lower bounds can be obtained from derandomization, compression,\nlearning, and satisfiability algorithms. We also cover the connection between\ncircuit lower bounds and useful properties, a notion that turns out to be\nfundamental in the context of these transference theorems. Along the way, we\nobtain a few new results, simplify several proofs, and show connections\ninvolving different frameworks. We hope that our presentation will serve as a\nself-contained introduction for those interested in pursuing research in this\narea.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2013 18:13:36 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Oliveira", "Igor C.", ""]]}, {"id": "1309.0251", "submitter": "Adi Vardi", "authors": "Yossi Azar and Adi Vardi", "title": "Colored Packets with Deadlines and Metric Space Transition Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider scheduling of colored packets with transition costs which form a\ngeneral metric space. We design a $1 - O(\\sqrt{MST(G) / L})$ competitive\nalgorithm. Our main result is a hardness result of $1 - \\Omega(\\sqrt{MST(G) /\nL})$ which matches the competitive ratio of the algorithm for each metric space\nseparately. In particular, we improve the hardness result of Azar at el. 2009\nfor uniform metric spaces.\n  We also extend our result to weighted directed graphs which obey the\ntriangular inequality and show a $1 - O(\\sqrt{TSP(G) / L})$ competitive\nalgorithm and a nearly-matching hardness result. In proving our hardness\nresults we use some interesting non-standard embedding.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2013 18:26:33 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Azar", "Yossi", ""], ["Vardi", "Adi", ""]]}, {"id": "1309.0302", "submitter": "Dacheng Tao", "authors": "Tianyi Zhou and Dacheng Tao", "title": "Unmixing Incoherent Structures of Big Data by Randomized or Greedy\n  Decomposition", "comments": "42 pages, 5 figures, 4 tables, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Learning big data by matrix decomposition always suffers from expensive\ncomputation, mixing of complicated structures and noise. In this paper, we\nstudy more adaptive models and efficient algorithms that decompose a data\nmatrix as the sum of semantic components with incoherent structures. We firstly\nintroduce \"GO decomposition (GoDec)\", an alternating projection method\nestimating the low-rank part $L$ and the sparse part $S$ from data matrix\n$X=L+S+G$ corrupted by noise $G$. Two acceleration strategies are proposed to\nobtain scalable unmixing algorithm on big data: 1) Bilateral random projection\n(BRP) is developed to speed up the update of $L$ in GoDec by a closed-form\nbuilt from left and right random projections of $X-S$ in lower dimensions; 2)\nGreedy bilateral (GreB) paradigm updates the left and right factors of $L$ in a\nmutually adaptive and greedy incremental manner, and achieve significant\nimprovement in both time and sample complexities. Then we proposes three\nnontrivial variants of GoDec that generalizes GoDec to more general data type\nand whose fast algorithms can be derived from the two strategies......\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 05:07:31 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Zhou", "Tianyi", ""], ["Tao", "Dacheng", ""]]}, {"id": "1309.0346", "submitter": "Alfredo Braunstein", "authors": "Indaco Biazzo, Alfredo Braunstein, Riccardo Zecchina", "title": "On the performance of a cavity method based algorithm for the\n  Prize-Collecting Steiner Tree Problem on graphs", "comments": null, "journal-ref": "Phys. Rev. E 86, 026706 (2012)", "doi": "10.1103/PhysRevE.86.026706", "report-no": null, "categories": "cs.DS cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of an algorithm derived from the cavity method for the\nPrize-Collecting Steiner Tree (PCST) problem on graphs. The algorithm is based\non the zero temperature limit of the cavity equations and as such is formally\nsimple (a fixed point equation resolved by iteration) and distributed\n(parallelizable). We provide a detailed comparison with state-of-the-art\nalgorithms on a wide range of existing benchmarks networks and random graphs.\nSpecifically, we consider an enhanced derivative of the Goemans-Williamson\nheuristics and the DHEA solver, a Branch and Cut Linear/Integer Programming\nbased approach. The comparison shows that the cavity algorithm outperforms the\ntwo algorithms in most large instances both in running time and quality of the\nsolution. Finally we prove a few optimality properties of the solutions\nprovided by our algorithm, including optimality under the two post-processing\nprocedures defined in the Goemans-Williamson derivative and global optimality\nin some limit cases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 10:05:17 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Biazzo", "Indaco", ""], ["Braunstein", "Alfredo", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1309.0563", "submitter": "James Lee", "authors": "Siu On Chan and James R. Lee and Prasad Raghavendra and David Steurer", "title": "Approximate Constraint Satisfaction Requires Large LP Relaxations", "comments": "29 pages; significant revisions, new references, simpler proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove super-polynomial lower bounds on the size of linear programming\nrelaxations for approximation versions of constraint satisfaction problems. We\nshow that for these problems, polynomial-sized linear programs are exactly as\npowerful as programs arising from a constant number of rounds of the\nSherali-Adams hierarchy.\n  In particular, any polynomial-sized linear program for Max Cut has an\nintegrality gap of 1/2 and any such linear program for Max 3-Sat has an\nintegrality gap of 7/8.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 00:30:03 GMT"}, {"version": "v2", "created": "Sun, 22 Feb 2015 14:56:25 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2016 08:11:10 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Chan", "Siu On", ""], ["Lee", "James R.", ""], ["Raghavendra", "Prasad", ""], ["Steurer", "David", ""]]}, {"id": "1309.0647", "submitter": "Nathana\\\"el Fran\\c{c}ois", "authors": "Nathana\\\"el Fran\\c{c}ois, Rahul Jain and Frederic Magniez", "title": "Unidirectional Input/Output Streaming Complexity of Reversal and Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unidirectional data streams with restricted access, such as\nread-only and write-only streams. For read-write streams, we also introduce a\nnew complexity measure called expansion, the ratio between the space used on\nthe stream and the input size. We give tight bounds for the complexity of\nreversing a stream of length $n$ in several of the possible models. In the\nread-only and write-only model, we show that $p$-pass algorithms need memory\nspace ${\\Theta}(n/p)$. But if either the output stream or the input stream is\nread-write, then the complexity falls to ${\\Theta}(n/p^2)$. It becomes\n$polylog(n)$ if $p = O(log n)$ and both streams are read-write. We also study\nthe complexity of sorting a stream and give two algorithms with small\nexpansion. Our main sorting algorithm is randomized and has $O(1)$ expansion,\n$O(log n)$ passes and $O(log n)$ memory.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 11:42:39 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2013 13:40:55 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2013 10:48:29 GMT"}, {"version": "v4", "created": "Tue, 6 May 2014 16:18:26 GMT"}, {"version": "v5", "created": "Fri, 18 Jul 2014 13:18:49 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Fran\u00e7ois", "Nathana\u00ebl", ""], ["Jain", "Rahul", ""], ["Magniez", "Frederic", ""]]}, {"id": "1309.0700", "submitter": "Mohammad Tofighi", "authors": "Mohammad Tofighi, Kivanc Kose, Ahmet Enis Cetin", "title": "Denoising Using Projection Onto Convex Sets (POCS) Based Framework", "comments": "arXiv admin note: substantial text overlap with arXiv:1306.2516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two new optimization techniques based on projections onto convex space (POCS)\nframework for solving convex optimization problems are presented. The dimension\nof the minimization problem is lifted by one and sets corresponding to the cost\nfunction are defined. If the cost function is a convex function in R^N the\ncorresponding set is also a convex set in R^{N+1}. The iterative optimization\napproach starts with an arbitrary initial estimate in R^{N+1} and an orthogonal\nprojection is performed onto one of the sets in a sequential manner at each\nstep of the optimization problem. The method provides globally optimal\nsolutions in total-variation (TV), filtered variation (FV), L_1, and entropic\ncost functions. A new denoising algorithm using the TV framework is developed.\nThe new algorithm does not require any of the regularization parameter\nadjustment. Simulation examples are presented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 14:33:25 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Tofighi", "Mohammad", ""], ["Kose", "Kivanc", ""], ["Cetin", "Ahmet Enis", ""]]}, {"id": "1309.0874", "submitter": "Rachit Agarwal", "authors": "Rachit Agarwal, Matthew Caesar, P. Brighten Godfrey, Ben Y. Zhao", "title": "Shortest Paths in Microseconds", "comments": "Extended version of WOSN'12 paper: new techniques (reduced memory,\n  faster computations), distributed (MapReduce) algorithm, multiple paths\n  between a source-destination pair", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing shortest paths is a fundamental primitive for several social\nnetwork applications including socially-sensitive ranking, location-aware\nsearch, social auctions and social network privacy. Since these applications\ncompute paths in response to a user query, the goal is to minimize latency\nwhile maintaining feasible memory requirements. We present ASAP, a system that\nachieves this goal by exploiting the structure of social networks.\n  ASAP preprocesses a given network to compute and store a partial shortest\npath tree (PSPT) for each node. The PSPTs have the property that for any two\nnodes, each edge along the shortest path is with high probability contained in\nthe PSPT of at least one of the nodes. We show that the structure of social\nnetworks enable the PSPT of each node to be an extremely small fraction of the\nentire network; hence, PSPTs can be stored efficiently and each shortest path\ncan be computed extremely quickly.\n  For a real network with 5 million nodes and 69 million edges, ASAP computes a\nshortest path for most node pairs in less than 49 microseconds per pair. ASAP,\nunlike any previous technique, also computes hundreds of paths (along with\ncorresponding distances) between any node pair in less than 100 microseconds.\nFinally, ASAP admits efficient implementation on distributed programming\nframeworks like MapReduce.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 23:43:10 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["Agarwal", "Rachit", ""], ["Caesar", "Matthew", ""], ["Godfrey", "P. Brighten", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1309.0896", "submitter": "EPTCS", "authors": "Matteo Mio (CWI), Alex Simpson (University of Edinburgh)", "title": "{\\L}ukasiewicz mu-Calculus", "comments": "In Proceedings FICS 2013, arXiv:1308.5896", "journal-ref": "EPTCS 126, 2013, pp. 87-104", "doi": "10.4204/EPTCS.126.7", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores properties of {\\L}ukasiewicz mu-calculus, a version of the\nquantitative/probabilistic modal mu-calculus containing both weak and strong\nconjunctions and disjunctions from {\\L}ukasiewicz (fuzzy) logic. We show that\nthis logic encodes the well-known probabilistic temporal logic PCTL. And we\ngive a model-checking algorithm for computing the rational denotational value\nof a formula at any state in a finite rational probabilistic nondeterministic\ntransition system.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 02:13:47 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["Mio", "Matteo", "", "CWI"], ["Simpson", "Alex", "", "University of Edinburgh"]]}, {"id": "1309.1051", "submitter": "Elis\\^angela Silva Dias", "authors": "Elis\\^angela Silva Dias and Diane Castonguay and Humberto Longo and\n  Walid Abdala Rfaei Jradi", "title": "Efficient Enumeration of Chordless Cycles", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a finite undirected simple graph, a {\\it chordless cycle} is an induced\nsubgraph which is a cycle. We propose two algorithms to enumerate all chordless\ncycles of such a graph. Compared to other similar algorithms, the proposed\nalgorithms have the advantage of finding each chordless cycle only once. To\nensure this, we introduced the concepts of vertex labeling and initial valid\nvertex triplet. To guarantee that the expansion of a given chordless path will\nalways lead to a chordless cycle, we use a breadth-first search in a subgraph\nobtained by the elimination of many of the vertices from the original graph.\nThe resulting algorithm has time complexity $\\mathcal{O}(n + m)$ in the output\nsize, where $n$ is the number of vertices and $m$ is the number of edges.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 14:42:36 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 02:54:03 GMT"}, {"version": "v3", "created": "Thu, 20 Nov 2014 19:52:30 GMT"}, {"version": "v4", "created": "Thu, 27 Nov 2014 16:29:19 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Dias", "Elis\u00e2ngela Silva", ""], ["Castonguay", "Diane", ""], ["Longo", "Humberto", ""], ["Jradi", "Walid Abdala Rfaei", ""]]}, {"id": "1309.1347", "submitter": "Ashwin Arulselvan", "authors": "Ashwin Arulselvan and Daniel Karch", "title": "A proof for Padberg's conjecture on rank of matching polytope", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Padberg introduced a geometric notion of ranks for (mixed) integer rational\npolyhedrons and conjectured that the geometric rank of the matching polytope is\none. In this work, we prove that this conjecture is true.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 13:49:31 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Arulselvan", "Ashwin", ""], ["Karch", "Daniel", ""]]}, {"id": "1309.1453", "submitter": "Yi Wang", "authors": "Peng Guo, Wenming Cheng, Yi Wang", "title": "Parallel machine scheduling with step deteriorating jobs and setup times\n  by a hybrid discrete cuckoo search algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers the parallel machine scheduling problem with\nstep-deteriorating jobs and sequence-dependent setup times. The objective is to\nminimize the total tardiness by determining the allocation and sequence of jobs\non identical parallel machines. In this problem, the processing time of each\njob is a step function dependent upon its starting time. An individual extended\ntime is penalized when the starting time of a job is later than a specific\ndeterioration date. The possibility of deterioration of a job makes the\nparallel machine scheduling problem more challenging than ordinary ones. A\nmixed integer programming model for the optimal solution is derived. Due to its\nNP-hard nature, a hybrid discrete cuckoo search algorithm is proposed to solve\nthis problem. In order to generate a good initial swarm, a modified heuristic\nnamed the MBHG is incorporated into the initialization of population. Several\ndiscrete operators are proposed in the random walk of L\\'{e}vy Flights and the\ncrossover search. Moreover, a local search procedure based on variable\nneighborhood descent is integrated into the algorithm as a hybrid strategy in\norder to improve the quality of elite solutions. Computational experiments are\nexecuted on two sets of randomly generated test instances. The results show\nthat the proposed hybrid algorithm can yield better solutions in comparison\nwith the commercial solver CPLEX with one hour time limit, discrete cuckoo\nsearch algorithm and the existing variable neighborhood search algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 03:34:44 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Guo", "Peng", ""], ["Cheng", "Wenming", ""], ["Wang", "Yi", ""]]}, {"id": "1309.1507", "submitter": "Laurent Jacques", "authors": "Laurent Jacques", "title": "A Quantized Johnson Lindenstrauss Lemma: The Finding of Buffon's Needle", "comments": "27 pages, 2 figures (note: this version corrects a few typos in the\n  abstract)", "journal-ref": null, "doi": null, "report-no": "TR-LJ-2013.03", "categories": "cs.IT cs.DS math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1733, Georges-Louis Leclerc, Comte de Buffon in France, set the ground of\ngeometric probability theory by defining an enlightening problem: What is the\nprobability that a needle thrown randomly on a ground made of equispaced\nparallel strips lies on two of them? In this work, we show that the solution to\nthis problem, and its generalization to $N$ dimensions, allows us to discover a\nquantized form of the Johnson-Lindenstrauss (JL) Lemma, i.e., one that combines\na linear dimensionality reduction procedure with a uniform quantization of\nprecision $\\delta>0$. In particular, given a finite set $\\mathcal S \\subset\n\\mathbb R^N$ of $S$ points and a distortion level $\\epsilon>0$, as soon as $M >\nM_0 = O(\\epsilon^{-2} \\log S)$, we can (randomly) construct a mapping from\n$(\\mathcal S, \\ell_2)$ to $(\\delta\\mathbb Z^M, \\ell_1)$ that approximately\npreserves the pairwise distances between the points of $\\mathcal S$.\nInterestingly, compared to the common JL Lemma, the mapping is quasi-isometric\nand we observe both an additive and a multiplicative distortions on the\nembedded distances. These two distortions, however, decay as $O(\\sqrt{(\\log\nS)/M})$ when $M$ increases. Moreover, for coarse quantization, i.e., for high\n$\\delta$ compared to the set radius, the distortion is mainly additive, while\nfor small $\\delta$ we tend to a Lipschitz isometric embedding. Finally, we\nprove the existence of a \"nearly\" quasi-isometric embedding of $(\\mathcal S,\n\\ell_2)$ into $(\\delta\\mathbb Z^M, \\ell_2)$. This one involves a non-linear\ndistortion of the $\\ell_2$-distance in $\\mathcal S$ that vanishes for distant\npoints in this set. Noticeably, the additive distortion in this case is slower,\nand decays as $O(\\sqrt[4]{(\\log S)/M})$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 23:18:53 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2013 06:56:28 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2013 13:40:28 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2015 10:52:23 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2015 15:51:32 GMT"}, {"version": "v6", "created": "Wed, 22 Jul 2015 12:46:26 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Jacques", "Laurent", ""]]}, {"id": "1309.1559", "submitter": "Ioan Todinca", "authors": "Fedor Fomin, Ioan Todinca and Yngve Villanger", "title": "Large induced subgraphs via triangulations and CMSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain an algorithmic meta-theorem for the following optimization problem.\nLet \\phi\\ be a Counting Monadic Second Order Logic (CMSO) formula and t be an\ninteger. For a given graph G, the task is to maximize |X| subject to the\nfollowing: there is a set of vertices F of G, containing X, such that the\nsubgraph G[F] induced by F is of treewidth at most t, and structure (G[F],X)\nmodels \\phi.\n  Some special cases of this optimization problem are the following generic\nexamples. Each of these cases contains various problems as a special subcase:\n  1) \"Maximum induced subgraph with at most l copies of cycles of length 0\nmodulo m\", where for fixed nonnegative integers m and l, the task is to find a\nmaximum induced subgraph of a given graph with at most l vertex-disjoint cycles\nof length 0 modulo m.\n  2) \"Minimum \\Gamma-deletion\", where for a fixed finite set of graphs \\Gamma\\\ncontaining a planar graph, the task is to find a maximum induced subgraph of a\ngiven graph containing no graph from \\Gamma\\ as a minor.\n  3) \"Independent \\Pi-packing\", where for a fixed finite set of connected\ngraphs \\Pi, the task is to find an induced subgraph G[F] of a given graph G\nwith the maximum number of connected components, such that each connected\ncomponent of G[F] is isomorphic to some graph from \\Pi.\n  We give an algorithm solving the optimization problem on an n-vertex graph G\nin time O(#pmc n^{t+4} f(t,\\phi)), where #pmc is the number of all potential\nmaximal cliques in G and f is a function depending of t and \\phi\\ only. We also\nshow how a similar running time can be obtained for the weighted version of the\nproblem. Pipelined with known bounds on the number of potential maximal\ncliques, we deduce that our optimization problem can be solved in time\nO(1.7347^n) for arbitrary graphs, and in polynomial time for graph classes with\npolynomial number of minimal separators.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 08:02:41 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Fomin", "Fedor", ""], ["Todinca", "Ioan", ""], ["Villanger", "Yngve", ""]]}, {"id": "1309.1645", "submitter": "Dohy Hong", "authors": "Dohy Hong", "title": "Fast ranking algorithm for very large data", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new ranking method inspired from previous results\non the diffusion approach to solve linear equation. We describe new\nmathematical equations corresponding to this method and show through\nexperimental results the potential computational gain. This ranking method is\nalso compared to the well known PageRank model.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 14:06:14 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Hong", "Dohy", ""]]}, {"id": "1309.1732", "submitter": "Vincent Chau", "authors": "Eric Angel, Evripidis Bampis, Vincent Chau", "title": "Throughput Maximization in the Speed-Scaling Setting", "comments": "submitted to SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are given a set of $n$ jobs and a single processor that can vary its speed\ndynamically. Each job $J_j$ is characterized by its processing requirement\n(work) $p_j$, its release date $r_j$ and its deadline $d_j$. We are also given\na budget of energy $E$ and we study the scheduling problem of maximizing the\nthroughput (i.e. the number of jobs which are completed on time). We propose a\ndynamic programming algorithm that solves the preemptive case of the problem,\ni.e. when the execution of the jobs may be interrupted and resumed later, in\npseudo-polynomial time. Our algorithm can be adapted for solving the weighted\nversion of the problem where every job is associated with a weight $w_j$ and\nthe objective is the maximization of the sum of the weights of the jobs that\nare completed on time. Moreover, we provide a strongly polynomial time\nalgorithm to solve the non-preemptive unweighed case when the jobs have the\nsame processing requirements. For the weighted case, our algorithm can be\nadapted for solving the non-preemptive version of the problem in\npseudo-polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 18:48:07 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Angel", "Eric", ""], ["Bampis", "Evripidis", ""], ["Chau", "Vincent", ""]]}, {"id": "1309.1776", "submitter": "Youming Qiao", "authors": "Joshua A. Grochow and Youming Qiao", "title": "Algorithms for group isomorphism via group extensions and cohomology", "comments": "54 pages + 14-page appendix. Significantly improved presentation,\n  with some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The isomorphism problem for finite groups of order n (GpI) has long been\nknown to be solvable in $n^{\\log n+O(1)}$ time, but only recently were\npolynomial-time algorithms designed for several interesting group classes.\nInspired by recent progress, we revisit the strategy for GpI via the extension\ntheory of groups.\n  The extension theory describes how a normal subgroup N is related to G/N via\nG, and this naturally leads to a divide-and-conquer strategy that splits GpI\ninto two subproblems: one regarding group actions on other groups, and one\nregarding group cohomology. When the normal subgroup N is abelian, this\nstrategy is well-known. Our first contribution is to extend this strategy to\nhandle the case when N is not necessarily abelian. This allows us to provide a\nunified explanation of all recent polynomial-time algorithms for special group\nclasses.\n  Guided by this strategy, to make further progress on GpI, we consider\ncentral-radical groups, proposed in Babai et al. (SODA 2011): the class of\ngroups such that G mod its center has no abelian normal subgroups. This class\nis a natural extension of the group class considered by Babai et al. (ICALP\n2012), namely those groups with no abelian normal subgroups. Following the\nabove strategy, we solve GpI in $n^{O(\\log \\log n)}$ time for central-radical\ngroups, and in polynomial time for several prominent subclasses of\ncentral-radical groups. We also solve GpI in $n^{O(\\log\\log n)}$ time for\ngroups whose solvable normal subgroups are elementary abelian but not\nnecessarily central. As far as we are aware, this is the first time there have\nbeen worst-case guarantees on a $n^{o(\\log n)}$-time algorithm that tackles\nboth aspects of GpI---actions and cohomology---simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 20:52:49 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 13:54:31 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Qiao", "Youming", ""]]}, {"id": "1309.1807", "submitter": "Haitao Wang", "authors": "Haitao Wang", "title": "Aggregate-Max Nearest Neighbor Searching in the Plane", "comments": "17 pages, 14 figures; preliminary results appeared in CCCG 2013, and\n  in this new version we extend the top-1 queries to top-k queries for the L_1\n  case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the aggregate/group nearest neighbor searching for the MAX operator\nin the plane. For a set $P$ of $n$ points and a query set $Q$ of $m$ points,\nthe query asks for a point of $P$ whose maximum distance to the points in $Q$\nis minimized. We present data structures for answering such queries for both\n$L_1$ and $L_2$ distance measures. Previously, only heuristic and approximation\nalgorithms were given for both versions. For the $L_1$ version, we build a data\nstructure of O(n) size in $O(n\\log n)$ time, such that each query can be\nanswered in $O(m+\\log n)$ time. For the $L_2$ version, we build a data\nstructure in $O(n\\log n)$ time and $O(n\\log \\log n)$ space, such that each\nquery can be answered in $O(m\\sqrt{n}\\log^{O(1)} n)$ time, and alternatively,\nwe build a data structure in $O(n^{2+\\epsilon})$ time and space for any\n$\\epsilon>0$, such that each query can be answered in $O(m\\log n)$ time.\nFurther, we extend our result for the $L_1$ version to the top-$k$ queries\nwhere each query asks for the $k$ points of $P$ whose maximum distances to $Q$\nare the smallest for any $k$ with $1\\leq k\\leq n$: We build a data structure of\nO(n) size in $O(n\\log n)$ time, such that each top-$k$ query can be answered in\n$O(m+k\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2013 02:35:40 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Wang", "Haitao", ""]]}, {"id": "1309.1846", "submitter": "Haniyeh Fallah", "authors": "Haniyeh Fallah, Farzad Didehvar, Farhad Rahmati", "title": "Approximation Algorithms for the Load Balanced Capacitated Vehicle\n  Routing Problem", "comments": "22 pages, 3 figures, accepted in Bulletin of iranian mathematical\n  society", "journal-ref": "Bulletin of iranian mathematical society 2020", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the load balanced capacitated vehicle routing problem (LBCVRP): the\nproblem is to design a collection of tours for a fixed fleet of vehicles with\ncapacity Q to distribute a supply from a single depot between a number of\npredefined clients, in a way that the total traveling cost is a minimum, and\nthe vehicle loads are balanced. The unbalanced loads cause the decrease of\ndistribution quality especially in business environments and exibility in the\nlogistics activities. The problem being NP-hard, we propose two approximation\nalgorithms. When the demands are equal, we present a (1-1/Q)p+3/2approximation\nalgorithm that finds balanced loads. Here, p is the approximation ratio for the\nknown metric traveling salesman problem (TSP). This result leads to a 2.5-1/Q\napproximation ratio for the tree metrics since an optimal solution can be found\nfor the TSP on a tree. We present an improved 2 approximation algorithm. When\nthe demands are unequal, we focus on obtaining approximate solutions since\nfinding balanced loads is NP-complete. We propose an algorithm that provides a\n4 approximation for the balance of the loads. We assume a second approach to\nget around the difficulties of the feasibility. In this approach, we redefine\nand convert the problem into a multi-objective problem. The algorithm we\npropose has a 4 factor of approximation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2013 10:03:11 GMT"}, {"version": "v2", "created": "Sat, 30 Jul 2016 07:58:39 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 12:11:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fallah", "Haniyeh", ""], ["Didehvar", "Farzad", ""], ["Rahmati", "Farhad", ""]]}, {"id": "1309.1981", "submitter": "Pritom Ahmed", "authors": "Pritom Ahmed, Costas S. Iliopoulos, A.S.M. Sohidull Islam, M. Sohel\n  Rahman", "title": "The Swap Matching Problem Revisited", "comments": "23 pages, 3 Figures and 17 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the much studied problem of Pattern Matching with\nSwaps (Swap Matching problem, for short). We first present a graph-theoretic\nmodel, which opens a new and so far unexplored avenue to solve the problem.\nThen, using the model, we devise two efficient algorithms to solve the swap\nmatching problem. The resulting algorithms are adaptations of the classic\nshift-and algorithm. For patterns having length similar to the word-size of the\ntarget machine, both the algorithms run in linear time considering a fixed\nalphabet.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2013 17:15:21 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2013 15:15:24 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Ahmed", "Pritom", ""], ["Iliopoulos", "Costas S.", ""], ["Islam", "A. S. M. Sohidull", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "1309.2038", "submitter": "Sagar Kale", "authors": "Amit Chakrabarti and Sagar Kale", "title": "Submodular Maximization Meets Streaming: Matchings, Matroids, and More", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a maximum matching in a graph given by an\ninput stream listing its edges in some arbitrary order, where the quantity to\nbe maximized is given by a monotone submodular function on subsets of edges.\nThis problem, which we call maximum submodular-function matching (MSM), is a\nnatural generalization of maximum weight matching (MWM), which is in turn a\ngeneralization of maximum cardinality matching (MCM). We give two incomparable\nalgorithms for this problem with space usage falling in the semi-streaming\nrange---they store only $O(n)$ edges, using $O(n\\log n)$ working memory---that\nachieve approximation ratios of $7.75$ in a single pass and $(3+\\epsilon)$ in\n$O(\\epsilon^{-3})$ passes respectively. The operations of these algorithms\nmimic those of Zelke's and McGregor's respective algorithms for MWM; the\nnovelty lies in the analysis for the MSM setting. In fact we identify a general\nframework for MWM algorithms that allows this kind of adaptation to the broader\nsetting of MSM.\n  In the sequel, we give generalizations of these results where the\nmaximization is over \"independent sets\" in a very general sense. This\ngeneralization captures hypermatchings in hypergraphs as well as independence\nin the intersection of multiple matroids.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2013 03:53:48 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2013 00:51:20 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Kale", "Sagar", ""]]}, {"id": "1309.2476", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Sangita Patel, Shiba Prasad Dash, Burle Sharma", "title": "TRANS outperforms MTF for two special types of request sequences without\n  locality of reference", "comments": "9 Pages, Proceedings of International Conference on Communication,\n  Computing and Security (ICCCS)-2012, India.\n  http://www.sciencedirect.com/science/article/pii/S2212017312006123", "journal-ref": "Procedia Technology, Elsevier, Vol 6, pages 556-563, 2012", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various list accessing algorithms have been proposed in the literature and\ntheir performances have been analyzed theoretically and experimentally.\nMove-To-Front (MTF) and Transpose (TRANS) are two well known primitive list\naccessing algorithms. MTF has been proved to be the best performing online\nalgorithm till date in the literature for real life inputs and practical\napplications with locality of reference. It has been shown that when storage\nspace is extremely limited and pointers for lists cannot be used, then array\nimplementation of TRANS gives efficient reorganization. Use of MTF is extensive\nin the literature whereas, the use of TRANS is rare. As mentioned as an open\nproblem in literature, direct bounds on the behavior and performance of various\nlist accessing algorithms are needed to allow realistic comparisons. Since it\nhas been shown that no single optimal permutation algorithm exists, it becomes\nnecessary to characterize the circumstances that indicate the advantage in\nusing a particular list accessing algorithm. Motivated by above challenging\nresearch issue, in this paper we have made an analytical study for evaluating\nthe performance of TRANS list accessing algorithm using two special types of\nrequest sequences without locality of reference. We have compared the\nperformance of TRANS with MTF and observed that TRANS outperforms MTF for these\nconsidered types of request sequences.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 12:24:50 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Patel", "Sangita", ""], ["Dash", "Shiba Prasad", ""], ["Sharma", "Burle", ""]]}, {"id": "1309.2525", "submitter": "Rahul Mehta", "authors": "Rahul Mehta", "title": "Max-Flows on Sparse and Dense Networks", "comments": "This paper has been withdrawn due to issues relating to nonsaturating\n  pushes and the validity of the labeling. A slightly modified result is\n  contained in the paper \"A New Push-Relabel Algorithm for the Max-Flow\n  Problem\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an improved algorithm for the maximum flow problem\non general networks with $n$ vertices and $m$ arcs. We show how to solve the\nproblem in $O(mn)$ time, when $m = O(n^{2-\\epsilon})$, for some $0 <\\epsilon\n\\leq 1$. This improves upon the results of both Orlin and King, et. al., who\nsolved the problem in $O(mn + m^{31/16} \\log^2 n)$ and $O(mn\\log_{m/n\\log n}n)$\ntime, respectively. Our main result is reducing the number of nonsaturating\npushes to $O(mn)$ across all scaling phases. Our algorithm can be seen as\ncomplementary to King, et. al., in the sense that we solve the max-flow problem\nin $O(mn)$ time when $m = O(n^{2-\\epsilon})$ (all sparse and non-dense\nnetworks), whereas King, et. al. solve it in $O(mn)$ time when $m =\n\\Omega(n^{1+\\epsilon})$ (all dense and non-sparse networks).\n  Our improvement is reached by a novel combination of Ahuja and Orlin's excess\nscaling method and Orlin's compact flow networks. To our knowledge, this is the\nfirst $O(mn)$ time max-flow algorithm that runs on this range of networks.\nFurther, we extend the range of Orlin's $O(mn)$ time algorithm from\n$O(n^{16/15-\\epsilon})$ to $O(n^{2-\\epsilon})$, which is an improvement of\napproximately $O(n^{0.94})$. Our result also establishes that the problem can\nbe solved for all $n$ and $m$ using exclusively the push-relabel method. We\nalso give improved algorithms for parametric flows and efficiently constructing\nGomory-Hu trees, and suggest a new approach to the minimum-cost flow problem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 14:32:04 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 05:30:18 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2013 13:57:42 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["Mehta", "Rahul", ""]]}, {"id": "1309.2675", "submitter": "Robert McColl", "authors": "Rob McColl, David Ediger, Jason Poovey, Dan Campbell, David Bader", "title": "A Brief Study of Open Source Graph Databases", "comments": "WSSSPE13, 4 Pages, 18 Pages with Appendix, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  With the proliferation of large irregular sparse relational datasets, new\nstorage and analysis platforms have arisen to fill gaps in performance and\ncapability left by conventional approaches built on traditional database\ntechnologies and query languages. Many of these platforms apply graph\nstructures and analysis techniques to enable users to ingest, update, query and\ncompute on the topological structure of these relationships represented as\nset(s) of edges between set(s) of vertices. To store and process Facebook-scale\ndatasets, they must be able to support data sources with billions of edges,\nupdate rates of millions of updates per second, and complex analysis kernels.\nThese platforms must provide intuitive interfaces that enable graph experts and\nnovice programmers to write implementations of common graph algorithms. In this\npaper, we explore a variety of graph analysis and storage platforms. We compare\ntheir capabil- ities, interfaces, and performance by implementing and computing\na set of real-world graph algorithms on synthetic graphs with up to 256 million\nedges. In the spirit of full disclosure, several authors are affiliated with\nthe development of STINGER.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 18:36:33 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["McColl", "Rob", ""], ["Ediger", "David", ""], ["Poovey", "Jason", ""], ["Campbell", "Dan", ""], ["Bader", "David", ""]]}, {"id": "1309.2729", "submitter": "Ankit Sharma", "authors": "Ankit Sharma and Jan Vondr\\'ak", "title": "Multiway Cut, Pairwise Realizable Distributions, and Descending\n  Thresholds", "comments": "This is an updated version and is the full version of STOC 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design new approximation algorithms for the Multiway Cut problem,\nimproving the previously known factor of 1.32388 [Buchbinder et al., 2013].\n  We proceed in three steps. First, we analyze the rounding scheme of\nBuchbinder et al., 2013 and design a modification that improves the\napproximation to (3+sqrt(5))/4 (approximately 1.309017). We also present a\ntight example showing that this is the best approximation one can achieve with\nthe type of cuts considered by Buchbinder et al., 2013: (1) partitioning by\nexponential clocks, and (2) single-coordinate cuts with equal thresholds.\n  Then, we prove that this factor can be improved by introducing a new rounding\nscheme: (3) single-coordinate cuts with descending thresholds. By combining\nthese three schemes, we design an algorithm that achieves a factor of (10 + 4\nsqrt(3))/13 (approximately 1.30217). This is the best approximation factor that\nwe are able to verify by hand.\n  Finally, we show that by combining these three rounding schemes with the\nscheme of independent thresholds from Karger et al., 2004, the approximation\nfactor can be further improved to 1.2965. This approximation factor has been\nverified only by computer.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 04:15:30 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 04:24:05 GMT"}, {"version": "v3", "created": "Mon, 12 May 2014 00:31:21 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Sharma", "Ankit", ""], ["Vondr\u00e1k", "Jan", ""]]}, {"id": "1309.2796", "submitter": "Ferdinando Cicalese", "authors": "Ferdinando Cicalese and Eduardo Laber and Aline Medeiros Saettler", "title": "Decision Trees for Function Evaluation - Simultaneous Optimization of\n  Worst and Expected Cost", "comments": "A preliminary version of this paper was accepted for presentation at\n  ICML 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several applications of automatic diagnosis and active learning a central\nproblem is the evaluation of a discrete function by adaptively querying the\nvalues of its variables until the values read uniquely determine the value of\nthe function. In general, the process of reading the value of a variable might\ninvolve some cost, computational or even a fee to be paid for the experiment\nrequired for obtaining the value. This cost should be taken into account when\ndeciding the next variable to read. The goal is to design a strategy for\nevaluating the function incurring little cost (in the worst case or in\nexpectation according to a prior distribution on the possible variables'\nassignments). Our algorithm builds a strategy (decision tree) which attains a\nlogarithmic approxima- tion simultaneously for the expected and worst cost\nspent. This is best possible under the assumption that $P \\neq NP.$\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2013 11:50:44 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2014 15:42:05 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Cicalese", "Ferdinando", ""], ["Laber", "Eduardo", ""], ["Saettler", "Aline Medeiros", ""]]}, {"id": "1309.3210", "submitter": "Kalle Rutanen", "authors": "Kalle Rutanen", "title": "O-notation in algorithm analysis", "comments": "Proved a minimal axiom-set for O-notation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an extensive list of desirable properties for an O-notation --- as\nused in algorithm analysis --- and reduce them to 8 primitive properties. We\nprove that the primitive properties are equivalent to the definition of the\nO-notation as linear dominance. We abstract the existing definitions of the\nO-notation under local linear dominance, and show that it has a\ncharacterization by limits over filters for positive functions. We define the\nO-mappings as a general tool for manipulating the O-notation, and show that\nMaster theorems hold under linear dominance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 16:21:46 GMT"}, {"version": "v10", "created": "Sun, 7 Sep 2014 12:35:37 GMT"}, {"version": "v11", "created": "Tue, 9 Sep 2014 08:45:16 GMT"}, {"version": "v12", "created": "Mon, 15 Sep 2014 15:44:25 GMT"}, {"version": "v13", "created": "Sun, 28 Sep 2014 17:28:40 GMT"}, {"version": "v14", "created": "Sun, 5 Oct 2014 08:15:22 GMT"}, {"version": "v15", "created": "Mon, 15 Dec 2014 15:09:39 GMT"}, {"version": "v16", "created": "Thu, 12 Feb 2015 19:48:58 GMT"}, {"version": "v17", "created": "Sat, 28 Feb 2015 11:29:05 GMT"}, {"version": "v18", "created": "Wed, 4 Mar 2015 00:16:38 GMT"}, {"version": "v19", "created": "Mon, 22 Jun 2015 17:56:37 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2013 09:32:07 GMT"}, {"version": "v20", "created": "Tue, 14 Jul 2015 20:55:30 GMT"}, {"version": "v21", "created": "Thu, 3 Sep 2015 14:14:32 GMT"}, {"version": "v22", "created": "Wed, 16 Sep 2015 21:16:09 GMT"}, {"version": "v23", "created": "Mon, 12 Oct 2015 18:31:11 GMT"}, {"version": "v24", "created": "Fri, 30 Oct 2015 08:58:46 GMT"}, {"version": "v25", "created": "Sun, 8 Nov 2015 20:09:53 GMT"}, {"version": "v26", "created": "Sun, 3 Jul 2016 15:08:52 GMT"}, {"version": "v27", "created": "Sat, 9 Jul 2016 23:47:39 GMT"}, {"version": "v28", "created": "Sat, 23 Jul 2016 13:41:52 GMT"}, {"version": "v29", "created": "Sun, 14 Aug 2016 21:43:11 GMT"}, {"version": "v3", "created": "Wed, 16 Apr 2014 11:27:04 GMT"}, {"version": "v30", "created": "Tue, 13 Sep 2016 22:30:45 GMT"}, {"version": "v31", "created": "Wed, 12 Oct 2016 10:05:27 GMT"}, {"version": "v32", "created": "Sat, 29 Oct 2016 19:46:38 GMT"}, {"version": "v4", "created": "Thu, 17 Apr 2014 21:56:33 GMT"}, {"version": "v5", "created": "Tue, 17 Jun 2014 13:50:09 GMT"}, {"version": "v6", "created": "Sat, 21 Jun 2014 23:34:06 GMT"}, {"version": "v7", "created": "Sat, 19 Jul 2014 23:50:34 GMT"}, {"version": "v8", "created": "Wed, 6 Aug 2014 15:51:42 GMT"}, {"version": "v9", "created": "Mon, 1 Sep 2014 19:15:21 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Rutanen", "Kalle", ""]]}, {"id": "1309.3223", "submitter": "Shayan Oveis Gharan", "authors": "Shayan Oveis Gharan and Luca Trevisan", "title": "Partitioning into Expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G=(V,E) be an undirected graph, lambda_k be the k-th smallest eigenvalue\nof the normalized laplacian matrix of G. There is a basic fact in algebraic\ngraph theory that lambda_k > 0 if and only if G has at most k-1 connected\ncomponents. We prove a robust version of this fact. If lambda_k>0, then for\nsome 1\\leq \\ell\\leq k-1, V can be {\\em partitioned} into l sets P_1,\\ldots,P_l\nsuch that each P_i is a low-conductance set in G and induces a high conductance\ninduced subgraph. In particular, \\phi(P_i)=O(l^3\\sqrt{\\lambda_l}) and\n\\phi(G[P_i]) >= \\lambda_k/k^2).\n  We make our results algorithmic by designing a simple polynomial time\nspectral algorithm to find such partitioning of G with a quadratic loss in the\ninside conductance of P_i's. Unlike the recent results on higher order\nCheeger's inequality [LOT12,LRTV12], our algorithmic results do not use higher\norder eigenfunctions of G. If there is a sufficiently large gap between\nlambda_k and lambda_{k+1}, more precisely, if \\lambda_{k+1} >= \\poly(k)\nlambda_{k}^{1/4} then our algorithm finds a k partitioning of V into sets\nP_1,...,P_k such that the induced subgraph G[P_i] has a significantly larger\nconductance than the conductance of P_i in G. Such a partitioning may represent\nthe best k clustering of G. Our algorithm is a simple local search that only\nuses the Spectral Partitioning algorithm as a subroutine. We expect to see\nfurther applications of this simple algorithm in clustering applications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 17:28:33 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2013 17:13:41 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2013 19:00:57 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1309.3321", "submitter": "Tamara Kolda", "authors": "C. Seshadhri and Ali Pinar and Tamara G. Kolda", "title": "Wedge Sampling for Computing Clustering Coefficients and Triangle Counts\n  on Large Graphs", "comments": "Full version of SDM 2013 paper \"Triadic Measures on Graphs: The Power\n  of Wedge Sampling\" (arxiv:1202.5230)", "journal-ref": "Statistical Analysis and Data Mining, Vol. 7, No. 4, pp. 294-307,\n  August 2014", "doi": "10.1002/sam.11224", "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are used to model interactions in a variety of contexts, and there is\na growing need to quickly assess the structure of such graphs. Some of the most\nuseful graph metrics are based on triangles, such as those measuring social\ncohesion. Algorithms to compute them can be extremely expensive, even for\nmoderately-sized graphs with only millions of edges. Previous work has\nconsidered node and edge sampling; in contrast, we consider wedge sampling,\nwhich provides faster and more accurate approximations than competing\ntechniques. Additionally, wedge sampling enables estimation local clustering\ncoefficients, degree-wise clustering coefficients, uniform triangle sampling,\nand directed triangle counts. Our methods come with provable and practical\nprobabilistic error estimates for all computations. We provide extensive\nresults that show our methods are both more accurate and faster than\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 22:18:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2014 22:11:36 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Seshadhri", "C.", ""], ["Pinar", "Ali", ""], ["Kolda", "Tamara G.", ""]]}, {"id": "1309.3458", "submitter": "Gabriele D'Angelo", "authors": "Moreno Marzolla, Gabriele D'Angelo, Marco Mandrioli", "title": "A Parallel Data Distribution Management Algorithm", "comments": "In proc. of the IEEE/ACM International Symposium on Distributed\n  Simulation and Real Time Applications (DS-RT 2013), oct 30-nov 1, 2013,\n  Delft, the Netherlands", "journal-ref": null, "doi": "10.1109/DS-RT.2013.23", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying intersections among a set of d-dimensional rectangular regions\n(d-rectangles) is a common problem in many simulation and modeling\napplications. Since algorithms for computing intersections over a large number\nof regions can be computationally demanding, an obvious solution is to take\nadvantage of the multiprocessing capabilities of modern multicore processors.\nUnfortunately, many solutions employed for the Data Distribution Management\nservice of the High Level Architecture are either inefficient, or can only\npartially be parallelized. In this paper we propose the Interval Tree Matching\n(ITM) algorithm for computing intersections among d-rectangles. ITM is based on\na simple Interval Tree data structure, and exhibits an embarrassingly parallel\nstructure. We implement the ITM algorithm, and compare its sequential\nperformance with two widely used solutions (brute force and sort-based\nmatching). We also analyze the scalability of ITM on shared-memory multicore\nprocessors. The results show that the sequential implementation of ITM is\ncompetitive with sort-based matching; moreover, the parallel implementation\nprovides good speedup on multicore processors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 14:02:28 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 07:52:07 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 12:25:56 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Marzolla", "Moreno", ""], ["D'Angelo", "Gabriele", ""], ["Mandrioli", "Marco", ""]]}, {"id": "1309.3545", "submitter": "Shen Chen Xu", "authors": "Gary L. Miller, Richard Peng, Adrian Vladu, Shen Chen Xu", "title": "Improved Parallel Algorithms for Spanners and Hopsets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use exponential start time clustering to design faster and more\nwork-efficient parallel graph algorithms involving distances. Previous\nalgorithms usually rely on graph decomposition routines with strict\nrestrictions on the diameters of the decomposed pieces. We weaken these bounds\nin favor of stronger local probabilistic guarantees. This allows more direct\nanalyses of the overall process, giving: * Linear work parallel algorithms that\nconstruct spanners with $O(k)$ stretch and size $O(n^{1+1/k})$ in unweighted\ngraphs, and size $O(n^{1+1/k} \\log k)$ in weighted graphs. * Hopsets that lead\nto the first parallel algorithm for approximating shortest paths in undirected\ngraphs with $O(m\\;\\mathrm{polylog}\\;n)$ work.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 19:27:36 GMT"}, {"version": "v2", "created": "Mon, 4 Aug 2014 18:41:13 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2015 02:56:54 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Miller", "Gary L.", ""], ["Peng", "Richard", ""], ["Vladu", "Adrian", ""], ["Xu", "Shen Chen", ""]]}, {"id": "1309.3675", "submitter": "Sungjin Im", "authors": "Sungjin Im and Maxim Sviridenko", "title": "Optimizing Maximum Flow Time and Maximum Throughput in Broadcast\n  Scheduling", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the pull-based broadcast scheduling model. In this model, there\nare n unit-sized pages of information available at the server. Requests arrive\nover time at the server asking for a specific page. When the server transmits a\npage, all outstanding requests for the page are simultaneously satisfied, and\nthis is what distinguishes broadcast scheduling from the standard scheduling\nsetting where each job must be processed separately by the server. Broadcast\nscheduling has received a considerable amount of attention due to the\nalgorithmic challenges that it gives in addition to its applications in\nmulticast systems and wireless and LAN networks. In this paper, we give the\nfollowing new approximation results for two popular objectives:\n  - For the objective of minimizing the maximum flow time, we give the first\nPTAS. Previously, it was known that the algorithm First-In-First-Out (FIFO) is\na 2-approximation, and it is tight. It has been suggested as an open problem to\nobtain a better approximation.\n  - For the objective of maximizing the throughput, we give a\n0.7759-approximation which improves upon the previous best known\n0.75-approximation.\n  Our improved results are enabled by our novel rounding schemes and linear\nprogramming which can effectively reduce congestion in schedule which is often\nthe main bottleneck in designing scheduling algorithms based on linear\nprogramming. We believe that our algorithmic ideas and techniques could be of\npotential use for other scheduling problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 14:34:48 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Im", "Sungjin", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "1309.3701", "submitter": "Agnes Cseh", "authors": "\\'Agnes Cseh, Jannik Matuschke", "title": "New and simple algorithms for stable flow problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable flows generalize the well-known concept of stable matchings to markets\nin which transactions may involve several agents, forwarding flow from one to\nanother. An instance of the problem consists of a capacitated directed network,\nin which vertices express their preferences over their incident edges. A\nnetwork flow is stable if there is no group of vertices that all could benefit\nfrom rerouting the flow along a walk.\n  Fleiner established that a stable flow always exists by reducing it to the\nstable allocation problem. We present an augmenting-path algorithm for\ncomputing a stable flow, the first algorithm that achieves polynomial running\ntime for this problem without using stable allocation as a black-box\nsubroutine. We further consider the problem of finding a stable flow such that\nthe flow value on every edge is within a given interval. For this problem, we\npresent an elegant graph transformation and based on this, we devise a simple\nand fast algorithm, which also can be used to find a solution to the stable\nmarriage problem with forced and forbidden edges.\n  Finally, we study the stable multicommodity flow model introduced by\nKir\\'{a}ly and Pap. The original model is highly involved and allows for\ncommodity-dependent preference lists at the vertices and commodity-specific\nedge capacities. We present several graph-based reductions that show\nequivalence to a significantly simpler model. We further show that it is\nNP-complete to decide whether an integral solution exists.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 21:17:28 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 20:45:06 GMT"}, {"version": "v3", "created": "Mon, 24 Dec 2018 09:29:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Cseh", "\u00c1gnes", ""], ["Matuschke", "Jannik", ""]]}, {"id": "1309.3849", "submitter": "Tong-Wook Shinn", "authors": "Tong-Wook Shinn and Tadao Takaoka", "title": "Efficient Graph Algorithms for Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GC problem is to identify a pre-determined number of center vertices such\nthat the distances or costs from (or to) the centers to (or from) other\nvertices is minimized. The bottleneck of a path is the minimum capacity of\nedges on the path. The Bottleneck Paths (BP) problem is to compute the paths\nthat give us the maximum bottleneck values between pairs of vertices. The Graph\nBottleneck (GB) problem is to find the minimum bottleneck value out of\nbottleneck paths for all possible pairs of vertices. We give two similar\nalgorithms that are based on binary search to solve the 1-center GC problem and\nthe GB problem on directed graphs with unit edge costs. We achieve\n$\\tilde{O}(n^{2.373})$ worst case time complexity for both the 1-center GC\nproblem and the GB problem, where $n$ is the number of vertices in the graph.\nThis is better than the straightforward methods of solving the two problems in\n$O(n^{2.575})$ and $O(n^{2.688})$ time bounds, respectively.\n  We then combine the Bottleneck Paths (BP) problem with the well known\nShortest Paths (SP) problem to compute the shortest paths for all possible flow\nvalues. We call this problem the Shortest Paths for All Flows (SP-AF) problem.\nWe show that if the flow demand is uncertain, but between two consecutive\ncapacity values, the unique shortest path can be computed to push that flow. If\nthe uncertainty stretches over two intervals, we need to prepare two shortest\npaths to accommodate the uncertainty, etc. In introducing this new problem, we\ndefine a new semi-ring called the distance/flow semi-ring, and show that the\nwell known algorithm by Floyd can be used over the distance/flow semi-ring to\nsolve the All Pairs Shortest Paths for All Flows (APSP-AF) problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 08:25:21 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Shinn", "Tong-Wook", ""], ["Takaoka", "Tadao", ""]]}, {"id": "1309.4022", "submitter": "P{\\aa}l Gr{\\o}n{\\aa}s Drange", "authors": "P{\\aa}l Gr{\\o}n{\\aa}s Drange, Fedor V. Fomin, Micha{\\l} Pilipczuk,\n  Yngve Villanger", "title": "Exploring Subexponential Parameterized Complexity of Completion Problems", "comments": "32 pages, 16 figures, A preliminary version of this paper appeared in\n  the proceedings of STACS'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\cal F}$ be a family of graphs. In the ${\\cal F}$-Completion problem,\nwe are given a graph $G$ and an integer $k$ as input, and asked whether at most\n$k$ edges can be added to $G$ so that the resulting graph does not contain a\ngraph from ${\\cal F}$ as an induced subgraph. It appeared recently that special\ncases of ${\\cal F}$-Completion, the problem of completing into a chordal graph\nknown as Minimum Fill-in, corresponding to the case of ${\\cal\nF}=\\{C_4,C_5,C_6,\\ldots\\}$, and the problem of completing into a split graph,\ni.e., the case of ${\\cal F}=\\{C_4, 2K_2, C_5\\}$, are solvable in parameterized\nsubexponential time $2^{O(\\sqrt{k}\\log{k})}n^{O(1)}$. The exploration of this\nphenomenon is the main motivation for our research on ${\\cal F}$-Completion.\n  In this paper we prove that completions into several well studied classes of\ngraphs without long induced cycles also admit parameterized subexponential time\nalgorithms by showing that:\n  - The problem Trivially Perfect Completion is solvable in parameterized\nsubexponential time $2^{O(\\sqrt{k}\\log{k})}n^{O(1)}$, that is ${\\cal\nF}$-Completion for ${\\cal F} =\\{C_4, P_4\\}$, a cycle and a path on four\nvertices.\n  - The problems known in the literature as Pseudosplit Completion, the case\nwhere ${\\cal F} = \\{2K_2, C_4\\}$, and Threshold Completion, where ${\\cal F} =\n\\{2K_2, P_4, C_4\\}$, are also solvable in time $2^{O(\\sqrt{k}\\log{k})}\nn^{O(1)}$.\n  We complement our algorithms for ${\\cal F}$-Completion with the following\nlower bounds:\n  - For ${\\cal F} = \\{2K_2\\}$, ${\\cal F} = \\{C_4\\}$, ${\\cal F} = \\{P_4\\}$, and\n${\\cal F} = \\{2K_2, P_4\\}$, ${\\cal F}$-Completion cannot be solved in time\n$2^{o(k)} n^{O(1)}$ unless the Exponential Time Hypothesis (ETH) fails.\n  Our upper and lower bounds provide a complete picture of the subexponential\nparameterized complexity of ${\\cal F}$-Completion problems for ${\\cal\nF}\\subseteq\\{2K_2, C_4, P_4\\}$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 16:16:41 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 08:28:11 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Drange", "P\u00e5l Gr\u00f8n\u00e5s", ""], ["Fomin", "Fedor V.", ""], ["Pilipczuk", "Micha\u0142", ""], ["Villanger", "Yngve", ""]]}, {"id": "1309.4140", "submitter": "Bruce  Shepherd", "authors": "Navin Goyal and Neil Olver and F. Bruce Shepherd", "title": "Dynamic vs Oblivious Routing in Network Design", "comments": null, "journal-ref": "Algorithmica, Vol 61, Issue 1, Sept 2011, pp 161-173", "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the robust network design problem of finding a minimum cost network\nwith enough capacity to route all traffic demand matrices in a given polytope.\nWe investigate the impact of different routing models in this robust setting:\nin particular, we compare \\emph{oblivious} routing, where the routing between\neach terminal pair must be fixed in advance, to \\emph{dynamic} routing, where\nroutings may depend arbitrarily on the current demand. Our main result is a\nconstruction that shows that the optimal cost of such a network based on\noblivious routing (fractional or integral) may be a factor of\n$\\BigOmega(\\log{n})$ more than the cost required when using dynamic routing.\nThis is true even in the important special case of the asymmetric hose model.\nThis answers a question in \\cite{chekurisurvey07}, and is tight up to constant\nfactors. Our proof technique builds on a connection between expander graphs and\nrobust design for single-sink traffic patterns \\cite{ChekuriHardness07}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 23:59:27 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Goyal", "Navin", ""], ["Olver", "Neil", ""], ["Shepherd", "F. Bruce", ""]]}, {"id": "1309.4396", "submitter": "Panagiotis Bouros Panagiotis Bouros", "authors": "Dimitris Sacharidis, Panagiotis Bouros", "title": "Routing Directions: Keeping it Fast and Simple", "comments": "Full version of the SIGSPATIAL'13 paper", "journal-ref": "21st ACM SIGSPATIAL International Conference on Advances in\n  Geographic Information Systems (ACM SIGSPATIAL GIS 2013), Orlando, Florida,\n  USA, November 5-8, 2013", "doi": "10.1145/2525314.2525362", "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of providing meaningful routing directions over road networks is\nof great importance. In many real-life cases, the fastest route may not be the\nideal choice for providing directions in written, spoken text, or for an\nunfamiliar neighborhood, or in cases of emergency. Rather, it is often more\npreferable to offer \"simple\" directions that are easy to memorize, explain,\nunderstand or follow. However, there exist cases where the simplest route is\nconsiderably longer than the fastest. This paper tries to address this issue,\nby finding near-simplest routes which are as short as possible and near-fastest\nroutes which are as simple as possible. Particularly, we focus on efficiency,\nand propose novel algorithms, which are theoretically and experimentally shown\nto be significantly faster than existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 17:14:49 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Sacharidis", "Dimitris", ""], ["Bouros", "Panagiotis", ""]]}, {"id": "1309.4405", "submitter": "Piotr Skowron", "authors": "Piotr Skowron, Piotr Faliszewski", "title": "Approximating the MaxCover Problem with Bounded Frequencies in FPT Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximation algorithms for several variants of the MaxCover\nproblem, with the focus on algorithms that run in FPT time. In the MaxCover\nproblem we are given a set N of elements, a family S of subsets of N, and an\ninteger K. The goal is to find up to K sets from S that jointly cover (i.e.,\ninclude) as many elements as possible. This problem is well-known to be NP-hard\nand, under standard complexity-theoretic assumptions, the best possible\npolynomial-time approximation algorithm has approximation ratio (1 - 1/e). We\nfirst consider a variant of MaxCover with bounded element frequencies, i.e., a\nvariant where there is a constant p such that each element belongs to at most p\nsets in S. For this case we show that there is an FPT approximation scheme\n(i.e., for each B there is a B-approximation algorithm running in FPT time) for\nthe problem of maximizing the number of covered elements, and a randomized FPT\napproximation scheme for the problem of minimizing the number of elements left\nuncovered (we take K to be the parameter). Then, for the case where there is a\nconstant p such that each element belongs to at least p sets from S, we show\nthat the standard greedy approximation algorithm achieves approximation ratio\nexactly (1-e^{-max(pK/|S|, 1)}). We conclude by considering an unrestricted\nvariant of MaxCover, and show approximation algorithms that run in exponential\ntime and combine an exact algorithm with a greedy approximation. Some of our\nresults improve currently known results for MaxVertexCover.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 17:51:08 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Skowron", "Piotr", ""], ["Faliszewski", "Piotr", ""]]}, {"id": "1309.4602", "submitter": "Adrian  Neumann", "authors": "Sayan Bhattacharya, Parinya Chalermsook, Kurt Mehlhorn, Adrian Neumann", "title": "New Approximability Results for the Robust k-Median Problem", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider a robust variant of the classical $k$-median problem, introduced\nby Anthony et al. \\cite{AnthonyGGN10}. In the \\emph{Robust $k$-Median problem},\nwe are given an $n$-vertex metric space $(V,d)$ and $m$ client sets $\\set{S_i\n\\subseteq V}_{i=1}^m$. The objective is to open a set $F \\subseteq V$ of $k$\nfacilities such that the worst case connection cost over all client sets is\nminimized; in other words, minimize $\\max_{i} \\sum_{v \\in S_i} d(F,v)$. Anthony\net al.\\ showed an $O(\\log m)$ approximation algorithm for any metric and\nAPX-hardness even in the case of uniform metric. In this paper, we show that\ntheir algorithm is nearly tight by providing $\\Omega(\\log m/ \\log \\log m)$\napproximation hardness, unless ${\\sf NP} \\subseteq \\bigcap_{\\delta >0} {\\sf\nDTIME}(2^{n^{\\delta}})$. This hardness result holds even for uniform and line\nmetrics. To our knowledge, this is one of the rare cases in which a problem on\na line metric is hard to approximate to within logarithmic factor. We\ncomplement the hardness result by an experimental evaluation of different\nheuristics that shows that very simple heuristics achieve good approximations\nfor realistic classes of instances.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 10:11:31 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Bhattacharya", "Sayan", ""], ["Chalermsook", "Parinya", ""], ["Mehlhorn", "Kurt", ""], ["Neumann", "Adrian", ""]]}, {"id": "1309.4662", "submitter": "Iain Moffatt", "authors": "Joanna A. Ellis-Monaghan, Andrew McDowell, Iain Moffatt, and Greta\n  Pangborn", "title": "DNA origami and the complexity of Eulerian circuits with turning costs", "comments": null, "journal-ref": null, "doi": "10.1007/s11047-014-9457-2", "report-no": null, "categories": "math.CO cs.CE cs.DS q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a structure using self-assembly of DNA molecules by origami folding\nrequires finding a route for the scaffolding strand through the desired\nstructure. When the target structure is a 1-complex (or the geometric\nrealization of a graph), an optimal route corresponds to an Eulerian circuit\nthrough the graph with minimum turning cost. By showing that it leads to a\nsolution to the 3-SAT problem, we prove that the general problem of finding an\noptimal route for a scaffolding strand for such structures is NP-hard. We then\nshow that the problem may readily be transformed into a Traveling Salesman\nProblem (TSP), so that machinery that has been developed for the TSP may be\napplied to find optimal routes for the scaffolding strand in a DNA origami\nself-assembly process. We give results for a few special cases, showing for\nexample that the problem remains intractable for graphs with maximum degree 8,\nbut is polynomial time for 4-regular plane graphs if the circuit is restricted\nto following faces. We conclude with some implications of these results for\nrelated problems, such as biomolecular computing and mill routing problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 14:41:17 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 17:02:16 GMT"}, {"version": "v3", "created": "Sun, 1 Jun 2014 09:02:31 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Ellis-Monaghan", "Joanna A.", ""], ["McDowell", "Andrew", ""], ["Moffatt", "Iain", ""], ["Pangborn", "Greta", ""]]}, {"id": "1309.4713", "submitter": "Patrizio Angelini", "authors": "Patrizio Angelini, William Evans, Fabrizio Frati, Joachim Gudmundsson", "title": "SEFE with No Mapping via Large Induced Outerplane Graphs in Plane Graphs", "comments": "21 pages, 10 figures, 14 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every $n$-vertex planar graph admits a simultaneous embedding\nwith no mapping and with fixed edges with any $(n/2)$-vertex planar graph. In\norder to achieve this result, we prove that every $n$-vertex plane graph has an\ninduced outerplane subgraph containing at least $n/2$ vertices. Also, we show\nthat every $n$-vertex planar graph and every $n$-vertex planar partial 3-tree\nadmit a simultaneous embedding with no mapping and with fixed edges.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 17:22:52 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Angelini", "Patrizio", ""], ["Evans", "William", ""], ["Frati", "Fabrizio", ""], ["Gudmundsson", "Joachim", ""]]}, {"id": "1309.4882", "submitter": "Sushant Sachdeva", "authors": "Sushant Sachdeva and Nisheeth Vishnoi", "title": "Approximation Theory and the Design of Fast Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey key techniques and results from approximation theory in the context\nof uniform approximations to real functions such as e^{-x}, 1/x, and x^k. We\nthen present a selection of results demonstrating how such approximations can\nbe used to speed up primitives crucial for the design of fast algorithms for\nproblems such as simulating random walks, graph partitioning, solving linear\nsystem of equations, computing eigenvalues and combinatorial approaches to\nsolve semi-definite programs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 07:24:45 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Sachdeva", "Sushant", ""], ["Vishnoi", "Nisheeth", ""]]}, {"id": "1309.4919", "submitter": "Koji M. Kobayashi", "authors": "Jun Kawahara, Koji M. Kobayashi, Shuichi Miyazaki", "title": "Better Bounds for Online $k$-Frame Throughput Maximization in Network\n  Switches", "comments": "A short version will appear in the proceedings of the 24th\n  International Symposium on Algorithms and Computation (ISAAC2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the online buffer management problem in network\nswitches, called the $k$-frame throughput maximization problem ($k$-FTM). This\nproblem models the situation where a large frame is fragmented into $k$ packets\nand transmitted through the Internet, and the receiver can reconstruct the\nframe only if he/she accepts all the $k$ packets. Kesselman et al.\\ introduced\nthis problem and showed that its competitive ratio is unbounded even when\n$k=2$. They also introduced an \"order-respecting\" variant of $k$-FTM, called\n$k$-OFTM, where inputs are restricted in some natural way. They proposed an\nonline algorithm and showed that its competitive ratio is at most\n$\\frac{2kB}{\\lfloor B/k \\rfloor} + k$ for any $B \\ge k$, where $B$ is the size\nof the buffer. They also gave a lower bound of $\\frac{B}{\\lfloor 2B/k \\rfloor}$\nfor deterministic online algorithms when $2B \\geq k$ and $k$ is a power of 2.\nIn this paper, we improve upper and lower bounds on the competitive ratio of\n$k$-OFTM. Our main result is to improve an upper bound of $O(k^{2})$ by\nKesselman et al.\\ to $\\frac{5B + \\lfloor B/k \\rfloor - 4}{\\lfloor B/2k \\rfloor}\n= O(k)$ for $B\\geq 2k$. Note that this upper bound is tight up to a\nmultiplicative constant factor since the lower bound given by Kesselman et al.\\\nis $\\Omega(k)$. We also give two lower bounds. First we give a lower bound of\n$\\frac{2B}{\\lfloor {B/(k-1)} \\rfloor} + 1$ on the competitive ratio of\ndeterministic online algorithms for any $k \\geq 2$ and any $B \\geq k-1$, which\nimproves the previous lower bound of $\\frac{B}{\\lfloor 2B/k \\rfloor}$ by a\nfactor of almost four. Next, we present the first nontrivial lower bound on the\ncompetitive ratio of randomized algorithms. Specifically, we give a lower bound\nof $k-1$ against an oblivious adversary for any $k \\geq 3$ and any $B$.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 10:26:22 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2013 11:05:22 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Kawahara", "Jun", ""], ["Kobayashi", "Koji M.", ""], ["Miyazaki", "Shuichi", ""]]}, {"id": "1309.4953", "submitter": "Deepak Puthal", "authors": "Deepak Puthal", "title": "A Near Optimal Approximation Algorithm for Vertex-Cover Problem", "comments": "4 pages, 2 figures, 2 theorems, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recently, there has been increasing interest and progress in improvising the\napproximation algorithm for well-known NP-Complete problems, particularly the\napproximation algorithm for the Vertex-Cover problem. Here we have proposed a\npolynomial time efficient algorithm for vertex-cover problem for more\napproximate to the optimal solution, which lead to the worst time complexity\n?{\\theta}(V 2) and space complexity ?{\\theta}(V + E). We show that our proposed\nmethod is more approximate with example and theorem proof. Our algorithm also\ninduces improvement on previous algorithms for the independent set problem on\ngraphs of small and high degree.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 12:27:27 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Puthal", "Deepak", ""]]}, {"id": "1309.4958", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z, Markus Lohrey", "title": "Approximation of smallest linear tree grammar", "comments": "45 pages, published in Information and Computation. Approximation\n  ratio improved since the first version, figures improved, some examples\n  added. A small calculation error corrected since the previous version (all\n  claims hold as previously)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple linear-time algorithm for constructing a linear context-free tree\ngrammar of size O(rg + r g log (n/r g))for a given input tree T of size n is\npresented, where g is the size of a minimal linear context-free tree grammar\nfor T, and r is the maximal rank of symbols in T (which is a constant in many\napplications). This is the first example of a grammar-based tree compression\nalgorithm with a good, i.e. logarithmic in terms of the size of the input tree,\napproximation ratio. The analysis of the algorithm uses an extension of the\nrecompression technique from strings to trees.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 13:04:49 GMT"}, {"version": "v2", "created": "Sat, 23 Aug 2014 06:55:47 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 15:18:12 GMT"}, {"version": "v4", "created": "Sat, 6 Oct 2018 08:50:12 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Je\u017c", "Artur", ""], ["Lohrey", "Markus", ""]]}, {"id": "1309.4973", "submitter": "Spyros Kontogiannis", "authors": "Spyros Kontogiannis and Christos Zaroliagis", "title": "Distance Oracles for Time-Dependent Networks", "comments": "A preliminary version appeared as Technical Report ECOMPASS-TR-025 of\n  EU funded research project eCOMPASS (http://www.ecompass-project.eu/). An\n  extended abstract also appeared in the 41st International Colloquium on\n  Automata, Languages, and Programming (ICALP 2014, track-A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present the first approximate distance oracle for sparse directed networks\nwith time-dependent arc-travel-times determined by continuous, piecewise\nlinear, positive functions possessing the FIFO property.\n  Our approach precomputes $(1+\\epsilon)-$approximate distance summaries from\nselected landmark vertices to all other vertices in the network. Our oracle\nuses subquadratic space and time preprocessing, and provides two sublinear-time\nquery algorithms that deliver constant and $(1+\\sigma)-$approximate\nshortest-travel-times, respectively, for arbitrary origin-destination pairs in\nthe network, for any constant $\\sigma > \\epsilon$. Our oracle is based only on\nthe sparsity of the network, along with two quite natural assumptions about\ntravel-time functions which allow the smooth transition towards asymmetric and\ntime-dependent distance metrics.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 13:41:21 GMT"}, {"version": "v2", "created": "Thu, 7 Aug 2014 08:07:56 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2015 10:19:54 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Kontogiannis", "Spyros", ""], ["Zaroliagis", "Christos", ""]]}, {"id": "1309.5009", "submitter": "Arne Meier", "authors": "Nadia Creignou and Ra\\\"ida Ktari and Arne Meier and Julian-Steffen\n  M\\\"uller and Fr\\'ed\\'eric Olive and Heribert Vollmer", "title": "Parameterized Enumeration with Ordering", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classes Delay-FPT and Total-FPT recently have been introduced into\nparameterized complexity in order to capture the notion of efficiently solvable\nparameterized enumeration problems. In this paper we focus on ordered\nenumeration and will show how to obtain Delay-FPT and Total-FPT enumeration\nalgorithms for several important problems. We propose a generic algorithmic\nstrategy, combining well-known principles stemming from both parameterized\nalgorithmics and enumeration, which shows that, under certain preconditions,\nthe existence of a so-called neighbourhood function among the solutions implies\nthe existence of a Delay-FPT algorithm which outputs all ordered solutions. In\nmany cases, the cornerstone to obtain such a neighbourhood function is a\nTotal-FPT algorithm that outputs all minimal solutions. This strategy is\nformalized in the context of graph modification problems, and shown to be\napplicable to numerous other kinds of problems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 14:58:51 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 13:52:54 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Creignou", "Nadia", ""], ["Ktari", "Ra\u00efda", ""], ["Meier", "Arne", ""], ["M\u00fcller", "Julian-Steffen", ""], ["Olive", "Fr\u00e9d\u00e9ric", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1309.5130", "submitter": "EPTCS", "authors": "Torben {\\AE}. Mogensen (DIKU, University of Copenhagen, Denmark)", "title": "A Comparison of Well-Quasi Orders on Trees", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 30-40", "doi": "10.4204/EPTCS.129.3", "report-no": null, "categories": "cs.PL cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well-quasi orders such as homeomorphic embedding are commonly used to ensure\ntermination of program analysis and program transformation, in particular\nsupercompilation.\n  We compare eight well-quasi orders on how discriminative they are and their\ncomputational complexity. The studied well-quasi orders comprise two very\nsimple examples, two examples from literature on supercompilation and four new\nproposed by the author.\n  We also discuss combining several well-quasi orders to get well-quasi orders\nof higher discriminative power. This adds 19 more well-quasi orders to the\nlist.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:16 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Mogensen", "Torben \u00c6.", "", "DIKU, University of Copenhagen, Denmark"]]}, {"id": "1309.5172", "submitter": "Joachim Gudmundsson", "authors": "Fabrizio Frati, Serge Gaspers, Joachim Gudmundsson and Luke Mathieson", "title": "Augmenting graphs to minimize the diameter", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of augmenting a weighted graph by inserting edges of\nbounded total cost while minimizing the diameter of the augmented graph. Our\nmain result is an FPT 4-approximation algorithm for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 04:57:52 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Frati", "Fabrizio", ""], ["Gaspers", "Serge", ""], ["Gudmundsson", "Joachim", ""], ["Mathieson", "Luke", ""]]}, {"id": "1309.5206", "submitter": "Sergey Nikolenko", "authors": "Alex Davydow", "title": "New Algorithms for Solving Tropical Linear Systems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of solving tropical linear systems, a natural problem of tropical\nmathematics, has already proven to be very interesting from the algorithmic\npoint of view: it is known to be in $NP\\cap coNP$ but no polynomial time\nalgorithm is known, although counterexamples for existing pseudopolynomial\nalgorithms are (and have to be) very complex.\n  In this work, we continue the study of algorithms for solving tropical linear\nsystems. First, we present a new reformulation of Grigoriev's algorithm that\nbrings it closer to the algorithm of Akian, Gaubert, and Guterman; this lets us\nformulate a whole family of new algorithms, and we present algorithms from this\nfamily for which no known superpolynomial counterexamples work. Second, we\npresent a family of algorithms for solving overdetermined tropical systems. We\nshow that for weakly overdetermined systems, there are polynomial algorithms in\nthis family. We also present a concrete algorithm from this family that can\nsolve a tropical linear system defined by an $m\\times n$ matrix with maximal\nelement $M$ in time $\\Theta\\left({m \\choose n} \\mathrm{poly}\\left(m, n, \\log\nM\\right)\\right)$, and this time matches the complexity of the best of\npreviously known algorithms for feasibility testing.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 08:31:31 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Davydow", "Alex", ""]]}, {"id": "1309.5461", "submitter": "Arijit Ghosh", "authors": "Arijit Bishnu, Arijit Ghosh and Subhabrata Paul", "title": "Linear kernels for k-tuple and liar's domination in bounded genus graphs", "comments": "Title changed from \"Parameterized complexity of k-tuple and liar's\n  domination\" to \"Linear kernels for k-tuple and liar's domination in bounded\n  genus graphs\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A set $D\\subseteq V$ is called a $k$-tuple dominating set of a graph\n$G=(V,E)$ if $\\left| N_G[v] \\cap D \\right| \\geq k$ for all $v \\in V$, where\n$N_G[v]$ denotes the closed neighborhood of $v$. A set $D \\subseteq V$ is\ncalled a liar's dominating set of a graph $G=(V,E)$ if (i) $\\left| N_G[v] \\cap\nD \\right| \\geq 2$ for all $v\\in V$ and (ii) for every pair of distinct vertices\n$u, v\\in V$, $\\left| (N_G[u] \\cup N_G[v]) \\cap D \\right| \\geq 3$. Given a graph\n$G$, the decision versions of $k$-Tuple Domination Problem and the Liar's\nDomination Problem are to check whether there exists a $k$-tuple dominating set\nand a liar's dominating set of $G$ of a given cardinality, respectively. These\ntwo problems are known to be NP-complete \\cite{LiaoChang2003, Slater2009}. In\nthis paper, we study the parameterized complexity of these problems. We show\nthat the $k$-Tuple Domination Problem and the Liar's Domination Problem are\n$\\mathsf{W}[2]$-hard for general graphs but they admit linear kernels for\ngraphs with bounded genus.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 11:07:24 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2013 23:03:10 GMT"}, {"version": "v3", "created": "Thu, 14 Aug 2014 02:18:12 GMT"}, {"version": "v4", "created": "Mon, 18 Aug 2014 17:45:01 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Bishnu", "Arijit", ""], ["Ghosh", "Arijit", ""], ["Paul", "Subhabrata", ""]]}, {"id": "1309.5502", "submitter": "Washington Alves de Oliveira", "authors": "Washington Alves de Oliveira, Antonio Carlos Moretti and Ednei Felix\n  Reis", "title": "The multi-vehicle covering tour problem: building routes for urban\n  patrolling", "comments": "28 pages, 8 figures, 7 tables, Brazilian Operations Research Society;\n  Printed version ISSN 0101-7438 / Online version ISSN 1678-5142", "journal-ref": "Pesquisa Operacional (2015) 35(3): 617-644", "doi": "10.1590/0101-7438.2015.035.03.0617", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a particular aspect of the urban community policing:\nroutine patrol route planning. We seek routes that guarantee visibility, as\nthis has a sizable impact on the community perceived safety, allowing quick\nemergency responses and providing surveillance of selected sites (e.g.,\nhospitals, schools). The planning is restricted to the availability of vehicles\nand strives to achieve balanced routes. We study an adaptation of the model for\nthe multi-vehicle covering tour problem, in which a set of locations must be\nvisited, whereas another subset must be close enough to the planned routes. It\nconstitutes an NP-complete integer programming problem. Suboptimal solutions\nare obtained with several heuristics, some adapted from the literature and\nothers developed by us. We solve some adapted instances from TSPLIB and an\ninstance with real data, the former being compared with results from\nliterature, and latter being compared with empirical data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 17:17:46 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 23:16:49 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["de Oliveira", "Washington Alves", ""], ["Moretti", "Antonio Carlos", ""], ["Reis", "Ednei Felix", ""]]}, {"id": "1309.5618", "submitter": "Tatiana Starikovskaya", "authors": "Maxim Babenko, Pawe{\\l} Gawrychowski, Tomasz Kociumaka, and Tatiana\n  Starikovskaya", "title": "Substring Suffix Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following substring suffix selection problem: given a substring\nof a string T of length n, compute its k-th lexicographically smallest suffix.\nThis a natural generalization of the well-known question of computing the\nmaximal suffix of a string, which is a basic ingredient in many other problems.\nWe first revisit two special cases of the problem, introduced by Babenko,\nKolesnichenko and Starikovskaya [CPM'13], in which we are asked to compute the\nminimal non-empty and the maximal suffixes of a substring. For the maximal\nsuffixes problem, we give a linear-space structure with O(1) query time and\nlinear preprocessing time, i.e., we manage to achieve optimal construction and\noptimal query time simultaneously. For the minimal suffix problem, we give a\nlinear-space data structure with O(\\tau) query time and O(n log n / \\tau)\npreprocessing time, where 1 <= \\tau <= log n is a parameter of the data\nstructure. As a sample application, we show that this data structure can be\nused to compute the Lyndon decomposition of any substring of T in O(k \\tau)\ntime, where k is the number of distinct factors in the decomposition.\n  Finally, we move to the general case of the substring suffix selection\nproblem, where using any combinatorial properties seems more difficult.\nNevertheless, we develop a linear-space data structure with O(log^{2+\\epsilon}\nn) query time.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2013 17:06:40 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Babenko", "Maxim", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Kociumaka", "Tomasz", ""], ["Starikovskaya", "Tatiana", ""]]}, {"id": "1309.5687", "submitter": "Tong-Wook Shinn", "authors": "Tong-Wook Shinn and Tadao Takaoka", "title": "Combining All Pairs Shortest Paths and All Pairs Bottleneck Paths\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem that combines the well known All Pairs Shortest\nPaths (APSP) problem and the All Pairs Bottleneck Paths (APBP) problem to\ncompute the shortest paths for all pairs of vertices for all possible flow\namounts. We call this new problem the All Pairs Shortest Paths for All Flows\n(APSP-AF) problem. We firstly solve the APSP-AF problem on directed graphs with\nunit edge costs and real edge capacities in\n$\\tilde{O}(\\sqrt{t}n^{(\\omega+9)/4}) = \\tilde{O}(\\sqrt{t}n^{2.843})$ time,\nwhere $n$ is the number of vertices, $t$ is the number of distinct edge\ncapacities (flow amounts) and $O(n^{\\omega}) < O(n^{2.373})$ is the time taken\nto multiply two $n$-by-$n$ matrices over a ring. Secondly we extend the problem\nto graphs with positive integer edge costs and present an algorithm with\n$\\tilde{O}(\\sqrt{t}c^{(\\omega+5)/4}n^{(\\omega+9)/4}) =\n\\tilde{O}(\\sqrt{t}c^{1.843}n^{2.843})$ worst case time complexity, where $c$ is\nthe upper bound on edge costs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 03:00:58 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Shinn", "Tong-Wook", ""], ["Takaoka", "Tadao", ""]]}, {"id": "1309.5697", "submitter": "Mong-Jen Kao", "authors": "Mong-Jen Kao, Jian-Jia Chen, Ignaz Rutter, Dorothea Wagner", "title": "Competitive Design and Analysis for Machine-Minimizing Job Scheduling\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the machine-minimizing job scheduling problem, which has a rich\nhistory in the line of research, under an online setting. We consider systems\nwith arbitrary job arrival times, arbitrary job deadlines, and unit job\nexecution time. For this problem, we present a lower bound 2.09 on the\ncompetitive factor of \\emph{any} online algorithms, followed by designing a\n5.2-competitive online algorithm. We also point out a false claim made in an\nexisting paper of Shi and Ye regarding a further restricted case of the\nconsidered problem. To the best of our knowledge, what we present is the first\nconcrete result concerning online machine-minimizing job scheduling with\narbitrary job arrival times and deadlines.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 05:21:15 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Kao", "Mong-Jen", ""], ["Chen", "Jian-Jia", ""], ["Rutter", "Ignaz", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1309.5781", "submitter": "Melanie Schmidt", "authors": "Hendrik Fichtenberger and Melanie Schmidt", "title": "PROBI: A Heuristic for the probabilistic k-median problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the heuristic PROBI for the probabilistic Euclidean k-median\nproblem based on a coreset construction by Lammersen et al. Our algorithm\ncomputes a summary of the data and then uses an adapted version of k-means++\n(Arthur and Vassilvitskii, 2007) to compute a good solution on the summary. The\nsummary is maintained in a data stream, so PROBI can be used in a data stream\nsetting on very large data sets. We experimentally evaluate the quality of the\nsummary and of the computed solution and compare the running time to state of\nthe art data stream clustering algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 12:10:14 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Schmidt", "Melanie", ""]]}, {"id": "1309.5826", "submitter": "Stefan Schmid", "authors": "Chen Avin, Omer Dunay and Stefan Schmid", "title": "Simple Destination-Swap Strategies for Adaptive Intra- and Inter-Tenant\n  VM Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the opportunities and limitations of adaptive virtual\nmachine (VM) migration to reduce communication costs in a virtualized\nenvironment. We introduce a new formal model for the problem of online VM\nmigration in two scenarios: (1) VMs can be migrated arbitrarily in the\nsubstrate network; e.g., a private cloud provider may have an incentive to\nreduce the overall communication cost in the network. (2) VMs can only be\nmigrated within a given tenant; e.g., a user that was assigned a set of\nphysical machines may exchange the functionality of the VMs on these machines.\n  We propose a simple class of Destination-Swap algorithms which are based on\nan aggressive collocation strategy (inspired by splay datastructures) and which\nmaintain a minimal and local amount of per-node (amortized cost) information to\ndecide where to migrate a VM and how; thus, the algorithms react quickly to\nchanges in the load. The algorithms come in two main flavors, an indirect and\ndistributed variant which keeps existing VM placements local, and a direct\nvariant which keeps the number of affected VMs small.\n  We show that naturally, inter-tenant optimizations yield a larger potential\nfor optimization, but generally also a tenant itself can improve its embedding.\nMoreover, there exists an interesting tradeoff between direct and indirect\nstrategies: indirect variants are preferable under skewed and sparse\ncommunication patterns due to their locality properties.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 14:43:57 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Avin", "Chen", ""], ["Dunay", "Omer", ""], ["Schmid", "Stefan", ""]]}, {"id": "1309.5866", "submitter": "Xing Shi Cai", "authors": "Xing Shi Cai, Luc Devroye", "title": "A Probabilistic Analysis of Kademlia Networks", "comments": "ISAAC 2013", "journal-ref": null, "doi": "10.1007/978-3-642-45030-3_66", "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kademlia is currently the most widely used searching algorithm in P2P\n(peer-to-peer) networks. This work studies an essential question about Kademlia\nfrom a mathematical perspective: how long does it take to locate a node in the\nnetwork? To answer it, we introduce a random graph K and study how many steps\nare needed to locate a given vertex in K using Kademlia's algorithm, which we\ncall the routing time. Two slightly different versions of K are studied. In the\nfirst one, vertices of K are labelled with fixed IDs. In the second one,\nvertices are assumed to have randomly selected IDs. In both cases, we show that\nthe routing time is about c*log(n), where n is the number of nodes in the\nnetwork and c is an explicitly described constant.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 16:24:45 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Cai", "Xing Shi", ""], ["Devroye", "Luc", ""]]}, {"id": "1309.5927", "submitter": "Markus Lohrey", "authors": "Mireille Bousquet-Melou, Markus Lohrey, Sebastian Maneth, and Eric\n  Noeth", "title": "XML Compression via DAGs", "comments": "A short version of this paper appeared in the Proceedings of ICDT\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unranked trees can be represented using their minimal dag (directed acyclic\ngraph). For XML this achieves high compression ratios due to their repetitive\nmark up. Unranked trees are often represented through first child/next sibling\n(fcns) encoded binary trees. We study the difference in size (= number of\nedges) of minimal dag versus minimal dag of the fcns encoded binary tree. One\nmain finding is that the size of the dag of the binary tree can never be\nsmaller than the square root of the size of the minimal dag, and that there are\nexamples that match this bound. We introduce a new combined structure, the\nhybrid dag, which is guaranteed to be smaller than (or equal in size to) both\ndags. Interestingly, we find through experiments that last child/previous\nsibling encodings are much better for XML compression via dags, than fcns\nencodings. We determine the average sizes of unranked and binary dags over a\ngiven set of labels (under uniform distribution) in terms of their exact\ngenerating functions, and in terms of their asymptotical behavior.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 19:26:16 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Bousquet-Melou", "Mireille", ""], ["Lohrey", "Markus", ""], ["Maneth", "Sebastian", ""], ["Noeth", "Eric", ""]]}, {"id": "1309.5991", "submitter": "Michael Burr", "authors": "Michael A. Burr", "title": "Applications of Continuous Amortization to Bisection-based Root\n  Isolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous amortization is a technique for computing the complexity of\nalgorithms, and it was first presented by the author in Burr, Krahmer, & Yap\n(2009). Continuous amortization can result in simpler and more straight-forward\ncomplexity analyses, and it was used in Burr, Krahmer, & Yap (2009), Burr &\nKrahmer (2012), and Sharma & Yap (2012) to provide complexity bounds for simple\nroot isolation algorithms. This paper greatly extends the reach of continuous\namortization to serve as an overarching technique which can be used to compute\ncomplexity of many root isolation techniques in a straight-forward manner.\nAdditionally, the technique of continuous amortization is extended to higher\ndimensions and to the computation of the bit-complexity of algorithms. In this\npaper, six continuous amortization calculations are performed to compute\ncomplexity bounds (on either the size of the subdivision tree or the bit\ncomplexity) for several algorithms (including algorithms based on Sturm\nsequences, Descartes' rule of signs, and polynomial evaluation); in each case,\ncontinuous amortization achieves an optimal complexity bound.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2013 21:48:06 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Burr", "Michael A.", ""]]}, {"id": "1309.6069", "submitter": "Lukasz Kowalik", "authors": "Micha{\\l} Farnik, {\\L}ukasz Kowalik, Arkadiusz Soca{\\l}a", "title": "Beyond the Shannon's Bound", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E)$ be a multigraph of maximum degree $\\Delta$. The edges of $G$\ncan be colored with at most $\\frac{3}{2}\\Delta$ colors by Shannon's theorem. We\nstudy lower bounds on the size of subgraphs of $G$ that can be colored with\n$\\Delta$ colors.\n  Shannon's Theorem gives a bound of\n$\\frac{\\Delta}{\\lfloor\\frac{3}{2}\\Delta\\rfloor}|E|$. However, for $\\Delta=3$,\nKami\\'{n}ski and Kowalik [SWAT'10] showed that there is a 3-edge-colorable\nsubgraph of size at least $\\frac{7}{9}|E|$, unless $G$ has a connected\ncomponent isomorphic to $K_3+e$ (a $K_3$ with an arbitrary edge doubled). Here\nwe extend this line of research by showing that $G$ has a $\\Delta$-edge\ncolorable subgraph with at least\n$\\frac{\\Delta}{\\lfloor\\frac{3}{2}\\Delta\\rfloor-1}|E|$ edges, unless $\\Delta$ is\neven and $G$ contains $\\frac{\\Delta}{2}K_3$ or $\\Delta$ is odd and $G$ contains\n$\\frac{\\Delta-1}{2}K_3+e$. Moreover, the subgraph and its coloring can be found\nin polynomial time.\n  Our results have applications in approximation algorithms for the Maximum\n$k$-Edge-Colorable Subgraph problem, where given a graph $G$ (without any bound\non its maximum degree or other restrictions) one has to find a\n$k$-edge-colorable subgraph with maximum number of edges. In particular, for\nevery even $k \\ge 4$ we obtain a $\\frac{2k+2}{3k+2}$-approximation and for\nevery odd $k\\ge 5$ we get a $\\frac{2k+1}{3k}$-approximation. When $4\\le k \\le\n13$ this improves over earlier algorithms due to Feige et al. [APPROX'02]\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 07:51:56 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Farnik", "Micha\u0142", ""], ["Kowalik", "\u0141ukasz", ""], ["Soca\u0142a", "Arkadiusz", ""]]}, {"id": "1309.6078", "submitter": "Dmitry Gusev", "authors": "V. F. Romanov", "title": "Discordant Compact Logic-Arithmetic Structures in Discrete Optimization\n  Problems", "comments": "17 pages; typeset in LaTeX. arXiv admin note: substantial text\n  overlap with arXiv:1011.3944", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sphere of research of discrete optimization algorithms efficiency the\nimportant place occupies a method of polynomial reducibility of some problems\nto others with use of special purpose components. In this paper a novel method\nof compact representation for sets of binary sequences in the form of \"compact\ntriplets structures\" (CTS) and \"compact couples structures\" (CCS) is stated,\nsupposing both logic and arithmetic interpretation of data. It is shown that\nany non-empty CTS in dual interpretation represents some unique Boolean formula\nin 3-CNF and the tabular CTS contains all satisfyig sets of the formula as\nconcatenations of the triplets chosen from the neighbouring tiers. In general,\nany 3-CNF formula is transformed by decomposition to a system of discordant\nCTS's, each being associated with an individual permutation of variables\nconstructed by a polynomial algorithm. As a result the problem of the formula\nsatisfiability is reduced to the following one: ascertain the fact of existence\n(or absence) of a \"joint satisfying set\" (JSS) for all discordant structures,\nbased on the different permutations. Further transformation of each CTS to CCS\nis used; correctness of preservation of the allowed sets is reached by simple\nalgorithmic restrictions on triplets concatenation. Then the procedure of\n\"inverting of the same name columns\" in the various structures is entered for\nthe purpose of reducing the problem of JSS revealing to elementary detection of\nn-tuples of zeros in the CCS system. The formula is synthesized, being on the\nstructure a variation of 2-CNF, associated with the calculation procedure\nrealizing adaptation of the polynomial algorithm of constraints distribution\n(well-known in the optimization theory) to the efficient resolving Boolean\nformula coded by means of discordant compact structures.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 08:24:57 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Romanov", "V. F.", ""]]}, {"id": "1309.6115", "submitter": "Chengyu Lin", "authors": "Chengyu Lin and Jingcheng Liu and Pinyan Lu", "title": "A Simple FPTAS for Counting Edge Covers", "comments": "To appear in SODA 2014", "journal-ref": null, "doi": "10.1137/1.9781611973402.25", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An edge cover of a graph is a set of edges such that every vertex has at\nleast an adjacent edge in it. Previously, approximation algorithm for counting\nedge covers is only known for 3 regular graphs and it is randomized. We design\na very simple deterministic fully polynomial-time approximation scheme (FPTAS)\nfor counting the number of edge covers for any graph. Our main technique is\ncorrelation decay, which is a powerful tool to design FPTAS for counting\nproblems. In order to get FPTAS for general graphs without degree bound, we\nmake use of a stronger notion called computationally efficient correlation\ndecay, which is introduced in [Li, Lu, Yin SODA 2012].\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 11:35:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2013 07:36:11 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Lin", "Chengyu", ""], ["Liu", "Jingcheng", ""], ["Lu", "Pinyan", ""]]}, {"id": "1309.6129", "submitter": "Kyomin Jung", "authors": "Vincent Blondel, Kyomin Jung, Pushmeet Kohli, Devavrat Shah", "title": "Partition-Merge: Distributed Inference and Modularity Optimization", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel meta algorithm, Partition-Merge (PM), which takes\nexisting centralized algorithms for graph computation and makes them\ndistributed and faster. In a nutshell, PM divides the graph into small\nsubgraphs using our novel randomized partitioning scheme, runs the centralized\nalgorithm on each partition separately, and then stitches the resulting\nsolutions to produce a global solution. We demonstrate the efficiency of the PM\nalgorithm on two popular problems: computation of Maximum A Posteriori (MAP)\nassignment in an arbitrary pairwise Markov Random Field (MRF), and modularity\noptimization for community detection. We show that the resulting distributed\nalgorithms for these problems essentially run in time linear in the number of\nnodes in the graph, and perform as well -- or even better -- than the original\ncentralized algorithm as long as the graph has geometric structures. Here we\nsay a graph has geometric structures, or polynomial growth property, when the\nnumber of nodes within distance r of any given node grows no faster than a\npolynomial function of r. More precisely, if the centralized algorithm is a\nC-factor approximation with constant C \\ge 1, the resulting distributed\nalgorithm is a (C+\\delta)-factor approximation for any small \\delta>0; but if\nthe centralized algorithm is a non-constant (e.g. logarithmic) factor\napproximation, then the resulting distributed algorithm becomes a constant\nfactor approximation. For general graphs, we compute explicit bounds on the\nloss of performance of the resulting distributed algorithm with respect to the\ncentralized algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 12:32:34 GMT"}], "update_date": "2013-09-25", "authors_parsed": [["Blondel", "Vincent", ""], ["Jung", "Kyomin", ""], ["Kohli", "Pushmeet", ""], ["Shah", "Devavrat", ""]]}, {"id": "1309.6144", "submitter": "Konrad Dabrowski", "authors": "Nicolas Bourgeois and Konrad K. Dabrowski and Marc Demange and\n  Vangelis Th. Paschos", "title": "Playing with parameters: structural parameterization in graphs", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering a graph problem from a parameterized point of view, the\nparameter chosen is often the size of an optimal solution of this problem (the\n\"standard\" parameter). A natural subject for investigation is what happens when\nwe parameterize such a problem by various other parameters, some of which may\nbe the values of optimal solutions to different problems. Such research is\nknown as parameterized ecology. In this paper, we investigate seven natural\nvertex problems, along with their respective parameters: the size of a maximum\nindependent set, the size of a minimum vertex cover, the size of a maximum\nclique, the chromatic number, the size of a minimum dominating set, the size of\na minimum independent dominating set and the size of a minimum feedback vertex\nset. We study the parameterized complexity of each of these problems with\nrespect to the standard parameter of the others.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2013 13:12:41 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 01:31:02 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Bourgeois", "Nicolas", ""], ["Dabrowski", "Konrad K.", ""], ["Demange", "Marc", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1309.6453", "submitter": "Pawel Gawrychowski", "authors": "Pawel Gawrychowski and Przemyslaw Uznanski", "title": "Order-preserving pattern matching with k mismatches", "comments": "This is the full version of an extended abstract to appear in CPM'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the recently introduced order-preserving pattern\nmatching, where instead of looking for an exact copy of the pattern, we only\nrequire that the relative order between the elements is the same. In our\nvariant, we additionally allow up to k mismatches between the pattern and the\ntext, and the goal is to construct an efficient algorithm for small values of\nk. For a pattern of length m and a text of length n, our algorithm detects an\norder-preserving occurrence with up to k mismatches in O(n(loglogm + kloglogk))\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 10:11:33 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 23:05:50 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Gawrychowski", "Pawel", ""], ["Uznanski", "Przemyslaw", ""]]}, {"id": "1309.6477", "submitter": "Kim S. Larsen", "authors": "Marie G. Christ, Lene M. Favrholdt, Kim S. Larsen", "title": "Online Bin Covering: Expectations vs. Guarantees", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bin covering is a dual version of classic bin packing. Thus, the goal is to\ncover as many bins as possible, where covering a bin means packing items of\ntotal size at least one in the bin.\n  For online bin covering, competitive analysis fails to distinguish between\nmost algorithms of interest; all \"reasonable\" algorithms have a competitive\nratio of 1/2. Thus, in order to get a better understanding of the combinatorial\ndifficulties in solving this problem, we turn to other performance measures,\nnamely relative worst order, random order, and max/max analysis, as well as\nanalyzing input with restricted or uniformly distributed item sizes. In this\nway, our study also supplements the ongoing systematic studies of the relative\nstrengths of various performance measures.\n  Two classic algorithms for online bin packing that have natural dual versions\nare Harmonic and Next-Fit. Even though the algorithms are quite different in\nnature, the dual versions are not separated by competitive analysis. We make\nthe case that when guarantees are needed, even under restricted input\nsequences, dual Harmonic is preferable. In addition, we establish quite robust\ntheoretical results showing that if items come from a uniform distribution or\neven if just the ordering of items is uniformly random, then dual Next-Fit is\nthe right choice.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 12:20:20 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2014 11:40:37 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Christ", "Marie G.", ""], ["Favrholdt", "Lene M.", ""], ["Larsen", "Kim S.", ""]]}, {"id": "1309.6504", "submitter": "Valia Mitsou", "authors": "Michael Lampis and Valia Mitsou", "title": "The Computational Complexity of the Game of Set and its Theoretical\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of SET is a popular card game in which the objective is to form Sets\nusing cards from a special deck. In this paper we study single- and multi-round\nvariations of this game from the computational complexity point of view and\nestablish interesting connections with other classical computational problems.\nSpecifically, we first show that a natural generalization of the problem of\nfinding a single Set, parameterized by the size of the sought Set is W-hard;\nour reduction applies also to a natural parameterization of Perfect\nMulti-Dimensional Matching, a result which may be of independent interest.\nSecond, we observe that a version of the game where one seeks to find the\nlargest possible number of disjoint Sets from a given set of cards is a special\ncase of 3-Set Packing; we establish that this restriction remains NP-complete.\nSimilarly, the version where one seeks to find the smallest number of disjoint\nSets that overlap all possible Sets is shown to be NP-complete, through a close\nconnection to the Independent Edge Dominating Set problem. Finally, we study a\n2-player version of the game, for which we show a close connection to Arc\nKayles, as well as fixed-parameter tractability when parameterized by the\nnumber of rounds played.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 13:47:43 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Lampis", "Michael", ""], ["Mitsou", "Valia", ""]]}, {"id": "1309.6603", "submitter": "Quentin Bramas", "authors": "Quentin Bramas (LIP6), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "The Random Bit Complexity of Mobile Robots Scattering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scattering $n$ robots in a two dimensional\ncontinuous space. As this problem is impossible to solve in a deterministic\nmanner, all solutions must be probabilistic. We investigate the amount of\nrandomness (that is, the number of random bits used by the robots) that is\nrequired to achieve scattering. We first prove that $n \\log n$ random bits are\nnecessary to scatter $n$ robots in any setting. Also, we give a sufficient\ncondition for a scattering algorithm to be random bit optimal. As it turns out\nthat previous solutions for scattering satisfy our condition, they are hence\nproved random bit optimal for the scattering problem. Then, we investigate the\ntime complexity of scattering when strong multiplicity detection is not\navailable. We prove that such algorithms cannot converge in constant time in\nthe general case and in $o(\\log \\log n)$ rounds for random bits optimal\nscattering algorithms. However, we present a family of scattering algorithms\nthat converge as fast as needed without using multiplicity detection. Also, we\nput forward a specific protocol of this family that is random bit optimal ($n\n\\log n$ random bits are used) and time optimal ($\\log \\log n$ rounds are used).\nThis improves the time complexity of previous results in the same setting by a\n$\\log n$ factor. Aside from characterizing the random bit complexity of mobile\nrobot scattering, our study also closes its time complexity gap with and\nwithout strong multiplicity detection (that is, $O(1)$ time complexity is only\nachievable when strong multiplicity detection is available, and it is possible\nto approach it as needed otherwise).\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 18:37:40 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2015 10:58:03 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Bramas", "Quentin", "", "LIP6"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1309.6689", "submitter": "Qi Duan", "authors": "Qi Duan, Jinhui Xu", "title": "On the Connectivity Preserving Minimum Cut Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a generalization of the classical minimum cut prob-\nlem, called Connectivity Preserving Minimum Cut (CPMC) problem, which seeks a\nminimum cut to separate a pair (or pairs) of source and destination nodes and\nmeanwhile ensure the connectivity between the source and its partner node(s).\nThe CPMC problem is a rather powerful formulation for a set of problems and\nfinds applications in many other areas, such as network security, image\nprocessing, data mining, pattern recognition, and machine learning. For this\nimportant problem, we consider two variants, connectiv- ity preserving minimum\nnode cut (CPMNC) and connectivity preserving minimum edge cut (CPMEC). For\nCPMNC, we show that it cannot be ap- proximated within {\\alpha}logn for some\nconstant {\\alpha} unless P=NP, and cannot be approximated within any poly(logn)\nunless NP has quasi-polynomial time algorithms. The hardness results hold even\nfor graphs with unit weight and bipartite graphs. Particularly, we show that\npolynomial time solutions exist for CPMEC in planar graphs and for CPMNC in\nsome special planar graphs. The hardness of CPMEC in general graphs remains\nopen, but the polynomial time algorithm in planar graphs still has important\npractical applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 23:04:57 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Duan", "Qi", ""], ["Xu", "Jinhui", ""]]}, {"id": "1309.6797", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin, Petr A. Golovach, Jesper Nederlof, and Micha{\\l}\n  Pilipczuk", "title": "Minimizing Rosenthal Potential in Multicast Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multicast game is a network design game modelling how selfish\nnon-cooperative agents build and maintain one-to-many network communication.\nThere is a special source node and a collection of agents located at\ncorresponding terminals. Each agent is interested in selecting a route from the\nspecial source to its terminal minimizing the cost. The mutual influence of the\nagents is determined by a cost sharing mechanism, which evenly splits the cost\nof an edge among all the agents using it for routing. In this paper we provide\nseveral algorithmic and complexity results on finding a Nash equilibrium\nminimizing the value of Rosenthal potential. Let n be the number of agents and\nG be the communication network. We show that\n  - For a given strategy profile s and integer k>=1, there is a local search\nalgorithm which in time n^{O(k)}|G|^{O(1)} finds a better strategy profile, if\nthere is any, in a k-exchange neighbourhood of s. In other words, the algorithm\ndecides if Rosenthal potential can be decreased by changing strategies of at\nmost k agents;\n  - The running time of our local search algorithm is essentially tight: unless\nFPT= W[1], for any function f(k), searching of the k-neighbourhood cannot be\ndone in time f(k)|G|^{O(1)}.\n  The key ingredient of our algorithmic result is a subroutine that finds an\nequilibrium with minimum potential in 3^n|G|^{O(1)} time. In other words,\nfinding an equilibrium with minimum potential is fixed-parameter tractable when\nparameterized by the number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 11:08:47 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Nederlof", "Jesper", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1309.6850", "submitter": "Kiyohito Nagano", "authors": "Kiyohito Nagano, Yoshinobu Kawahara", "title": "Structured Convex Optimization under Submodular Constraints", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-459-468", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of discrete and continuous optimization problems in machine learning\nare related to convex minimization problems under submodular constraints. In\nthis paper, we deal with a submodular function with a directed graph structure,\nand we show that a wide range of convex optimization problems under submodular\nconstraints can be solved much more efficiently than general submodular\noptimization methods by a reduction to a maximum flow problem. Furthermore, we\ngive some applications, including sparse optimization methods, in which the\nproposed methods are effective. Additionally, we evaluate the performance of\nthe proposed method through computational experiments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:45:59 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Nagano", "Kiyohito", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1309.6851", "submitter": "Teppo Niinimaki", "authors": "Teppo Niinimaki, Mikko Koivisto", "title": "Treedy: A Heuristic for Counting and Sampling Subsets", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-469-477", "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a collection of weighted subsets of a ground set N. Given a query\nsubset Q of N, how fast can one (1) find the weighted sum over all subsets of\nQ, and (2) sample a subset of Q proportionally to the weights? We present a\ntree-based greedy heuristic, Treedy, that for a given positive tolerance d\nanswers such counting and sampling queries to within a guaranteed relative\nerror d and total variation distance d, respectively. Experimental results on\nartificial instances and in application to Bayesian structure discovery in\nBayesian networks show that approximations yield dramatic savings in running\ntime compared to exact computation, and that Treedy typically outperforms a\npreviously proposed sorting-based heuristic.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:46:13 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Niinimaki", "Teppo", ""], ["Koivisto", "Mikko", ""]]}, {"id": "1309.6872", "submitter": "Adrian Weller", "authors": "Adrian Weller, Tony S. Jebara", "title": "On MAP Inference by MWSS on Perfect Graphs", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-684-693", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most likely (MAP) configuration of a Markov random field (MRF) is\nNP-hard in general. A promising, recent technique is to reduce the problem to\nfinding a maximum weight stable set (MWSS) on a derived weighted graph, which\nif perfect, allows inference in polynomial time. We derive new results for this\napproach, including a general decomposition theorem for MRFs of any order and\nnumber of labels, extensions of results for binary pairwise models with\nsubmodular cost functions to higher order, and an exact characterization of\nwhich binary pairwise MRFs can be efficiently solved with this method. This\ndefines the power of the approach on this class of models, improves our toolbox\nand expands the range of tractable models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:53:41 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Weller", "Adrian", ""], ["Jebara", "Tony S.", ""]]}, {"id": "1309.7084", "submitter": "Ilias Diakonikolas", "authors": "Constantinos Daskalakis, Ilias Diakonikolas, Mihalis Yannakakis", "title": "How good is the Chord algorithm?", "comments": "47 pages, full version of SODA 2010 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chord algorithm is a popular, simple method for the succinct\napproximation of curves, which is widely used, under different names, in a\nvariety of areas, such as, multiobjective and parametric optimization,\ncomputational geometry, and graphics. We analyze the performance of the Chord\nalgorithm, as compared to the optimal approximation that achieves a desired\naccuracy with the minimum number of points. We prove sharp upper and lower\nbounds, both in the worst case and average case setting.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 22:44:21 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Diakonikolas", "Ilias", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1309.7141", "submitter": "Michel  Habib", "authors": "Ismael Belghiti and Michel Habib", "title": "A general method for common intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an elementary chain of vertex set V, seen as a labelling of V by the\nset {1, ...,n=|V|}, and another discrete structure over $V$, say a graph G, the\nproblem of common intervals is to compute the induced subgraphs G[I], such that\n$I$ is an interval of [1, n] and G[I] satisfies some property Pi (as for\nexample Pi= \"being connected\"). This kind of problems comes from comparative\ngenomic in bioinformatics, mainly when the graph $G$ is a chain or a tree\n(Heber and Stoye 2001, Heber and Savage 2005, Bergeron et al 2008).\n  When the family of intervals is closed under intersection, we present here\nthe combination of two approaches, namely the idea of potential beginning\ndeveloped in Uno, Yagiura 2000 and Bui-Xuan et al 2005 and the notion of\ngenerator as defined in Bergeron et al 2008. This yields a very simple generic\nalgorithm to compute all common intervals, which gives optimal algorithms in\nvarious applications. For example in the case where $G$ is a tree, our\nframework yields the first linear time algorithms for the two properties:\n\"being connected\" and \"being a path\". In the case where $G$ is a chain, the\nproblem is known as: common intervals of two permutations (Uno and Yagiura\n2000), our algorithm provides not only the set of all common intervals but also\nwith some easy modifications a tree structure that represents this set.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 08:14:11 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Belghiti", "Ismael", ""], ["Habib", "Michel", ""]]}, {"id": "1309.7440", "submitter": "Rishi Gupta", "authors": "Rishi Gupta, Tim Roughgarden, C. Seshadhri", "title": "Decompositions of Triangle-Dense Graphs", "comments": "20 pages. Version 1->2: Minor edits. 2->3: Strengthened {\\S}3.5,\n  removed appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High triangle density -- the graph property stating that a constant fraction\nof two-hop paths belong to a triangle -- is a common signature of social\nnetworks. This paper studies triangle-dense graphs from a structural\nperspective. We prove constructively that significant portions of a\ntriangle-dense graph are contained in a disjoint union of dense, radius 2\nsubgraphs. This result quantifies the extent to which triangle-dense graphs\nresemble unions of cliques. We also show that our algorithm recovers planted\nclusterings in approximation-stable k-median instances.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 08:08:51 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 17:43:53 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2014 10:37:52 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Gupta", "Rishi", ""], ["Roughgarden", "Tim", ""], ["Seshadhri", "C.", ""]]}, {"id": "1309.7508", "submitter": "Franc Brglez", "authors": "Franc Brglez (Computer Science, NC State University)", "title": "On Self-Avoiding Walks across n-Dimensional Dice and Combinatorial\n  Optimization: An Introduction", "comments": "15 pdf pages that include 4 full-page figure composites, 4 smaller\n  figure composites, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-avoiding walks (SAWs) were introduced in chemistry to model the\nreal-life behavior of chain-like entities such as solvents and polymers, whose\nphysical volume prohibits multiple occupation of the same spatial point. In\nmathematics, a SAW lives in the n-dimensional lattices.\n  In this paper, SAWs are a metaphor for walks across faces of n-dimensional\ndice, or more formally, a hyperhedron family H(Theta, b, n). Each face is\nassigned a label {x:Theta(x)}; x represents a unique n-dimensional coordinate\nstring, Theta(x) is the value of the function. The walk searches Theta(x) for\noptima by following five simple rules: (1) select a random coordinate and mark\nit as the `initial pivot'; (2) probe all unmarked adjacent coordinates, then\nselect and mark the coordinate with the 'best value' as the new pivot; (3)\ncontinue the walk until either the 'best value' <= `target value' or the walk\nis being blocked by adjacent coordinates that are already pivots; (4) if the\nwalk is blocked, restart the walk from a randomly selected `new initial pivot';\n(5) if needed, manage the memory overflow with a streaming-like buffer of\nappropriate size.\n  Hard instances from a number of problem domains, including the 2D protein\nfolding problem, with up to (2^{25})*(3^{24}) coordinates, have been solved\nwith SAWs in less than 1,000,000 steps -- while also exceeding the quality of\nbest known solutions to date.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 21:52:06 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Brglez", "Franc", "", "Computer Science, NC State University"]]}, {"id": "1309.7565", "submitter": "Frederic Magniez", "authors": "Frederic Magniez, Ashwin Nayak, Miklos Santha, Jonah Sherman, Gabor\n  Tardos, David Xiao", "title": "Improved bounds for the randomized decision tree complexity of recursive\n  majority", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the randomized decision tree complexity of the recursive\n3-majority function. We prove a lower bound of $(1/2-\\delta) \\cdot 2.57143^h$\nfor the two-sided-error randomized decision tree complexity of evaluating\nheight $h$ formulae with error $\\delta \\in [0,1/2)$. This improves the lower\nbound of $(1-2\\delta)(7/3)^h$ given by Jayram, Kumar, and Sivakumar (STOC'03),\nand the one of $(1-2\\delta) \\cdot 2.55^h$ given by Leonardos (ICALP'13).\nSecond, we improve the upper bound by giving a new zero-error randomized\ndecision tree algorithm that has complexity at most $(1.007) \\cdot 2.64944^h$.\nThe previous best known algorithm achieved complexity $(1.004) \\cdot\n2.65622^h$. The new lower bound follows from a better analysis of the base case\nof the recursion of Jayram et al. The new algorithm uses a novel \"interleaving\"\nof two recursive algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 10:00:34 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Magniez", "Frederic", ""], ["Nayak", "Ashwin", ""], ["Santha", "Miklos", ""], ["Sherman", "Jonah", ""], ["Tardos", "Gabor", ""], ["Xiao", "David", ""]]}, {"id": "1309.7713", "submitter": "Guoming Wang", "authors": "Guoming Wang", "title": "Span-program-based quantum algorithm for tree detection", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Span program is a linear-algebraic model of computation originally proposed\nfor studying the complexity theory. Recently, it has become a useful tool for\ndesigning quantum algorithms. In this paper, we present a time-efficient\nspan-program-based quantum algorithm for the following problem. Let $T$ be an\narbitrary tree. Given query access to the adjacency matrix of a graph $G$ with\n$n$ vertices, we need to determine whether $G$ contains $T$ as a subgraph, or\n$G$ does not contain $T$ as a minor, under the promise that one of these cases\nholds. We call this problem the subgraph/not-a-minor problem for $T$. We show\nthat this problem can be solved by a bounded-error quantum algorithm with\n$O(n)$ query complexity and $\\tilde{O}(n)$ time complexity. The query\ncomplexity is optimal, and the time complexity is tight up to polylog factors.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 03:26:52 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2014 17:34:54 GMT"}, {"version": "v3", "created": "Wed, 5 Mar 2014 05:35:15 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Wang", "Guoming", ""]]}, {"id": "1309.7724", "submitter": "Timothy Chu", "authors": "Alex Chen, Timothy Chu, Nathan Pinsker", "title": "The Dynamic Longest Increasing Subsequence Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we construct a data structure to efficiently compute the\nlongest increasing subsequence of a sequence subject to dynamic updates. Our\ndata structure supports a query for the longest increasing subsequence in\n$O(r+\\log n)$ worst-case time and supports inserts anywhere in the sequence in\n$O \\left(r\\log{n/r}\\right)$ worst-case time (where $r$ is the length of the\nlongest increasing subsequence). The same data structure with a minor\nmodification supports $O(\\log n)$ worst-case time insertions if the insertions\nare performed at the end of the sequence. The data structure presented can also\nbe augmented to support delete operations in the same worst-case time as\ninsertions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 05:24:37 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 02:43:41 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2013 21:43:39 GMT"}, {"version": "v4", "created": "Sun, 15 Dec 2013 22:57:43 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Chen", "Alex", ""], ["Chu", "Timothy", ""], ["Pinsker", "Nathan", ""]]}, {"id": "1309.7891", "submitter": "Archontia C. Giannopoulou", "authors": "Archontia C. Giannopoulou, Daniel Lokshtanov, Saket Saurabh, Ondrej\n  Suchy", "title": "Tree Deletion Set has a Polynomial Kernel (but no OPT^O(1)\n  approximation)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In the Tree Deletion Set problem the input is a graph G together with an\ninteger k. The objective is to determine whether there exists a set S of at\nmost k vertices such that G-S is a tree. The problem is NP-complete and even\nNP-hard to approximate within any factor of OPT^c for any constant c. In this\npaper we give a O(k^4) size kernel for the Tree Deletion Set problem. To the\nbest of our knowledge our result is the first counterexample to the\n\"conventional wisdom\" that kernelization algorithms automatically provide\napproximation algorithms with approximation ratio close to the size of the\nkernel. An appealing feature of our kernelization algorithm is a new algebraic\nreduction rule that we use to handle the instances on which Tree Deletion Set\nis hard to approximate.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 15:46:14 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""], ["Suchy", "Ondrej", ""]]}, {"id": "1309.7935", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Vivek Kumar Bagaria and Rahul Vaze", "title": "Maximizing Utility Among Selfish Users in Social Groups", "comments": "11 pages, 3 figures; submitted for review to the National Conference\n  on Communications (NCC) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a social group of users trying to obtain a\n\"universe\" of files, first from a server and then via exchange amongst\nthemselves. We consider the selfish file-exchange paradigm of give-and-take,\nwhereby two users can exchange files only if each has something unique to offer\nthe other. We are interested in maximizing the number of users who can obtain\nthe universe through a schedule of file-exchanges. We first present a practical\nparadigm of file acquisition. We then present an algorithm which ensures that\nat least half the users obtain the universe with high probability for $n$ files\nand $m=O(\\log n)$ users when $n\\rightarrow\\infty$, thereby showing an\napproximation ratio of 2. Extending these ideas, we show a $1+\\epsilon_1$ -\napproximation algorithm for $m=O(n)$, $\\epsilon_1>0$ and a $(1+z)/2\n+\\epsilon_2$ - approximation algorithm for $m=O(n^z)$, $z>1$, $\\epsilon_2>0$.\nFinally, we show that for any $m=O(e^{o(n)})$, there exists a schedule of file\nexchanges which ensures that at least half the users obtain the universe.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 17:36:28 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Bagaria", "Vivek Kumar", ""], ["Vaze", "Rahul", ""]]}, {"id": "1309.7955", "submitter": "Rafael C. S. Schouery", "authors": "Cristina G. Fernandes and Rafael C. S. Schouery", "title": "Approximation Algorithms for the Max-Buying Problem with Limited Supply", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Max-Buying Problem with Limited Supply, in which there are\n$n$ items, with $C_i$ copies of each item $i$, and $m$ bidders such that every\nbidder $b$ has valuation $v_{ib}$ for item $i$. The goal is to find a pricing\n$p$ and an allocation of items to bidders that maximizes the profit, where\nevery item is allocated to at most $C_i$ bidders, every bidder receives at most\none item and if a bidder $b$ receives item $i$ then $p_i \\leq v_{ib}$. Briest\nand Krysta presented a 2-approximation for this problem and Aggarwal et al.\npresented a 4-approximation for the Price Ladder variant where the pricing must\nbe non-increasing (that is, $p_1 \\geq p_2 \\geq \\cdots \\geq p_n$). We present an\n$e/(e-1)$-approximation for the Max-Buying Problem with Limited Supply and, for\nevery $\\varepsilon > 0$, a $(2+\\varepsilon)$-approximation for the Price Ladder\nvariant.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 18:45:23 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Fernandes", "Cristina G.", ""], ["Schouery", "Rafael C. S.", ""]]}]