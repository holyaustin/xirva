[{"id": "1009.0216", "submitter": "R\\'emy Belmonte", "authors": "R\\'emy Belmonte, Martin Vatshelle", "title": "On graph classes with logarithmic boolean-width", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean-width is a recently introduced graph parameter. Many problems are\nfixed parameter tractable when parametrized by boolean-width, for instance\n\"Minimum Weighted Dominating Set\" (MWDS) problem can be solved in $O^*(2^{3k})$\ntime given a boolean-decomposition of width $k$, hence for all graph classes\nwhere a boolean-decomposition of width $O(\\log n)$ can be found in polynomial\ntime, MWDS can be solved in polynomial time. We study graph classes having\nboolean-width $O(\\log n)$ and problems solvable in $O^*(2^{O(k)})$, combining\nthese two results to design polynomial algorithms. We show that for trapezoid\ngraphs, circular permutation graphs, convex graphs, Dilworth-$k$ graphs,\ncircular arc graphs and complements of $k$-degenerate graphs,\nboolean-decompositions of width $O(\\log n)$ can be found in polynomial time. We\nalso show that circular $k$-trapezoid graphs have boolean-width $O(\\log n)$,\nand find such a decomposition if a circular $k$-trapezoid intersection model is\ngiven. For many of the graph classes we also prove that they contain graphs of\nboolean-width $\\Theta(\\log n)$.\n  Further we apply the results from \\cite{boolw2} to give a new polynomial time\nalgorithm solving all vertex partitioning problems introduced by Proskurowski\nand Telle \\cite{TP97}. This extends previous results by Kratochv\\'il, Manuel\nand Miller \\cite{KMM95} showing that a large subset of the vertex partitioning\nproblems are polynomial solvable on interval graphs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Sep 2010 16:06:00 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 18:03:46 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Belmonte", "R\u00e9my", ""], ["Vatshelle", "Martin", ""]]}, {"id": "1009.0358", "submitter": "Juraj Stacho", "authors": "Tom\\'as Feder, Pavol Hell, David G. Schell, Juraj Stacho", "title": "Dichotomy for tree-structured trigraph list homomorphism problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trigraph list homomorphism problems (also known as list matrix partition\nproblems) have generated recent interest, partly because there are concrete\nproblems that are not known to be polynomial time solvable or NP-complete. Thus\nwhile digraph list homomorphism problems enjoy dichotomy (each problem is\nNP-complete or polynomial time solvable), such dichotomy is not necessarily\nexpected for trigraph list homomorphism problems. However, in this paper, we\nidentify a large class of trigraphs for which list homomorphism problems do\nexhibit a dichotomy. They consist of trigraphs with a tree-like structure, and,\nin particular, include all trigraphs whose underlying graphs are trees. In\nfact, we show that for these tree-like trigraphs, the trigraph list\nhomomorphism problem is polynomially equivalent to a related digraph list\nhomomorphism problem. We also describe a few examples illustrating that our\nconditions defining tree-like trigraphs are not unnatural, as relaxing them may\nlead to harder problems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 09:05:04 GMT"}], "update_date": "2010-09-03", "authors_parsed": [["Feder", "Tom\u00e1s", ""], ["Hell", "Pavol", ""], ["Schell", "David G.", ""], ["Stacho", "Juraj", ""]]}, {"id": "1009.0499", "submitter": "Yevgeny Seldin", "authors": "Yevgeny Seldin", "title": "A PAC-Bayesian Analysis of Graph Clustering and Pairwise Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate weighted graph clustering as a prediction problem: given a\nsubset of edge weights we analyze the ability of graph clustering to predict\nthe remaining edge weights. This formulation enables practical and theoretical\ncomparison of different approaches to graph clustering as well as comparison of\ngraph clustering with other possible ways to model the graph. We adapt the\nPAC-Bayesian analysis of co-clustering (Seldin and Tishby, 2008; Seldin, 2009)\nto derive a PAC-Bayesian generalization bound for graph clustering. The bound\nshows that graph clustering should optimize a trade-off between empirical data\nfit and the mutual information that clusters preserve on the graph nodes. A\nsimilar trade-off derived from information-theoretic considerations was already\nshown to produce state-of-the-art results in practice (Slonim et al., 2005;\nYom-Tov and Slonim, 2009). This paper supports the empirical evidence by\nproviding a better theoretical foundation, suggesting formal generalization\nguarantees, and offering a more accurate way to deal with finite sample issues.\nWe derive a bound minimization algorithm and show that it provides good results\nin real-life problems and that the derived PAC-Bayesian bound is reasonably\ntight.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 18:28:22 GMT"}], "update_date": "2010-09-03", "authors_parsed": [["Seldin", "Yevgeny", ""]]}, {"id": "1009.0556", "submitter": "Alexander Gutfraind", "authors": "Alexander Gutfraind, Aric A. Hagberg, David Izraelevitz, Feng Pan", "title": "Interdiction of a Markovian Evader", "comments": "Submitted to INFORMS Computing Society Conference (ICS2011)", "journal-ref": null, "doi": null, "report-no": "LA-UR-08-06551", "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shortest path network interdiction is a combinatorial optimization problem on\nan activity network arising in a number of important security-related\napplications. It is classically formulated as a bilevel maximin problem\nrepresenting an \"interdictor\" and an \"evader\". The evader tries to move from a\nsource node to the target node along a path of the least cost while the\ninterdictor attempts to frustrate this motion by cutting edges or nodes. The\ninterdiction objective is to find the optimal set of edges to cut given that\nthere is a finite interdiction budget and the interdictor must move first. We\nreformulate the interdiction problem for stochastic evaders by introducing a\nmodel in which the evader follows a Markovian random walk guided by the\nleast-cost path to the target. This model can represent incomplete knowledge\nabout the evader, and the resulting model is a nonlinear 0-1 optimization\nproblem. We then introduce an optimization heuristic based on betweenness\ncentrality that can rapidly find high-quality interdiction solutions by\nproviding a global view of the network.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 22:32:51 GMT"}], "update_date": "2010-09-06", "authors_parsed": [["Gutfraind", "Alexander", ""], ["Hagberg", "Aric A.", ""], ["Izraelevitz", "David", ""], ["Pan", "Feng", ""]]}, {"id": "1009.0670", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez and Jennifer H. Watkins", "title": "Grammar-Based Geodesics in Semantic Networks", "comments": "First draft written in 2007", "journal-ref": "Knowledge-Based Systems, 23(8), pp. 844-855, December 2010", "doi": "10.1016/j.knosys.2010.05.009", "report-no": "LA-UR-07-4042", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A geodesic is the shortest path between two vertices in a connected network.\nThe geodesic is the kernel of various network metrics including radius,\ndiameter, eccentricity, closeness, and betweenness. These metrics are the\nfoundation of much network research and thus, have been studied extensively in\nthe domain of single-relational networks (both in their directed and undirected\nforms). However, geodesics for single-relational networks do not translate\ndirectly to multi-relational, or semantic networks, where vertices are\nconnected to one another by any number of edge labels. Here, a more\nsophisticated method for calculating a geodesic is necessary. This article\npresents a technique for calculating geodesics in semantic networks with a\nfocus on semantic networks represented according to the Resource Description\nFramework (RDF). In this framework, a discrete \"walker\" utilizes an abstract\npath description called a grammar to determine which paths to include in its\ngeodesic calculation. The grammar-based model forms a general framework for\nstudying geodesic metrics in semantic networks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Sep 2010 13:49:47 GMT"}], "update_date": "2010-09-06", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Watkins", "Jennifer H.", ""]]}, {"id": "1009.0783", "submitter": "Lowell Trott", "authors": "David Eppstein, Michael T. Goodrich, Darren Strash, Lowell Trott", "title": "Extended h-Index Parameterized Data Structures for Computing Dynamic\n  Subgraph Statistics", "comments": null, "journal-ref": "Theor. Comput. Sci. 447: 44-52, 2012", "doi": "10.1016/j.tcs.2011.11.034", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present techniques for maintaining subgraph frequencies in a dynamic\ngraph, using data structures that are parameterized in terms of h, the h-index\nof the graph. Our methods extend previous results of Eppstein and Spiro for\nmaintaining statistics for undirected subgraphs of size three to directed\nsubgraphs and to subgraphs of size four. For the directed case, we provide a\ndata structure to maintain counts for all 3-vertex induced subgraphs in O(h)\namortized time per update. For the undirected case, we maintain the counts of\nsize-four subgraphs in O(h^2) amortized time per update. These extensions\nenable a number of new applications in Bioinformatics and Social Networking\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 3 Sep 2010 22:58:10 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""], ["Strash", "Darren", ""], ["Trott", "Lowell", ""]]}, {"id": "1009.0806", "submitter": "Geevarghese Philip", "authors": "Geevarghese Philip, Venkatesh Raman, Yngve Villanger", "title": "A Quartic Kernel for Pathwidth-One Vertex Deletion", "comments": "Full version of an extended abstract accepted for publication in the\n  proceedings of WG 2010. 18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pathwidth of a graph is a measure of how path-like the graph is. Given a\ngraph G and an integer k, the problem of finding whether there exist at most k\nvertices in G whose deletion results in a graph of pathwidth at most one is NP-\ncomplete. We initiate the study of the parameterized complexity of this\nproblem, parameterized by k. We show that the problem has a quartic\nvertex-kernel: We show that, given an input instance (G = (V, E), k); |V| = n,\nwe can construct, in polynomial time, an instance (G', k') such that (i) (G, k)\nis a YES instance if and only if (G', k') is a YES instance, (ii) G' has\nO(k^{4}) vertices, and (iii) k' \\leq k. We also give a fixed parameter\ntractable (FPT) algorithm for the problem that runs in O(7^{k} k \\cdot n^{2})\ntime.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 05:39:41 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Philip", "Geevarghese", ""], ["Raman", "Venkatesh", ""], ["Villanger", "Yngve", ""]]}, {"id": "1009.0862", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Andrei Dragus, Ana-Delia Sambotin, Nicolae\n  Tapus", "title": "Brief Announcement: Decentralized Construction of Multicast Trees\n  Embedded into P2P Overlay Networks based on Virtual Geometric Coordinates", "comments": "ISBN: 978-1-60558-888-9", "journal-ref": "Proceedings of the 29th Annual ACM SIGACT-SIGOPS Symposium on\n  Principles of Distributed Computing (PODC), pp. 283-284, Zurich, Switzerland,\n  25-28 July, 2010", "doi": "10.1145/1835698.1835766", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of efficiently constructing in a fully\ndistributed manner multicast trees which are embedded into P2P overlays using\nvirtual geometric node coordinates. We consider two objectives: to minimize the\nnumber of messages required for constructing a multicast tree by using the\ngeometric properties of the P2P overlay, and to construct stable multicast\ntrees when the lifetime durations of the peers are known.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 19:28:13 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Dragus", "Andrei", ""], ["Sambotin", "Ana-Delia", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1009.0870", "submitter": "Bo Tan", "authors": "Bo Tan and R. Srikant", "title": "Online Advertisement, Optimization and Stochastic Networks", "comments": "32 pages (single-column, double-spaced), 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a stochastic model to describe how search service\nproviders charge client companies based on users' queries for the keywords\nrelated to these companies' ads by using certain advertisement assignment\nstrategies. We formulate an optimization problem to maximize the long-term\naverage revenue for the service provider under each client's long-term average\nbudget constraint, and design an online algorithm which captures the stochastic\nproperties of users' queries and click-through behaviors. We solve the\noptimization problem by making connections to scheduling problems in wireless\nnetworks, queueing theory and stochastic networks. Unlike prior models, we do\nnot assume that the number of query arrivals is known. Due to the stochastic\nnature of the arrival process considered here, either temporary \"free\" service,\ni.e., service above the specified budget or under-utilization of the budget is\nunavoidable. We prove that our online algorithm can achieve a revenue that is\nwithin $O(\\epsilon)$ of the optimal revenue while ensuring that the overdraft\nor underdraft is $O(1/\\epsilon)$, where $\\epsilon$ can be arbitrarily small.\nWith a view towards practice, we can show that one can always operate strictly\nunder the budget. In addition, we extend our results to a click-through rate\nmaximization model, and also show how our algorithm can be modified to handle\nnon-stationary query arrival processes and clients with short-term contracts.\n  Our algorithm allows us to quantify the effect of errors in click-through\nrate estimation on the achieved revenue. We also show that in the long run, an\nexpected overdraft level of $\\Omega(\\log(1/\\epsilon))$ is unavoidable (a\nuniversal lower bound) under any stationary ad assignment algorithm which\nachieves a long-term average revenue within $O(\\epsilon)$ of the offline\noptimum.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 20:54:58 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2011 01:31:39 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2011 15:50:05 GMT"}, {"version": "v4", "created": "Thu, 2 Jun 2011 18:50:03 GMT"}, {"version": "v5", "created": "Wed, 20 Jul 2011 23:26:41 GMT"}, {"version": "v6", "created": "Fri, 7 Sep 2012 02:45:49 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["Tan", "Bo", ""], ["Srikant", "R.", ""]]}, {"id": "1009.0909", "submitter": "Bonnie Kirkpatrick", "authors": "Bonnie Kirkpatrick, Yakir Reshef, Hilary Finucane, Haitao Jiang,\n  Binhai Zhu, and Richard M. Karp", "title": "Comparing Pedigree Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedigree graphs, or family trees, are typically constructed by an expensive\nprocess of examining genealogical records to determine which pairs of\nindividuals are parent and child. New methods to automate this process take as\ninput genetic data from a set of extant individuals and reconstruct ancestral\nindividuals. There is a great need to evaluate the quality of these methods by\ncomparing the estimated pedigree to the true pedigree.\n  In this paper, we consider two main pedigree comparison problems. The first\nis the pedigree isomorphism problem, for which we present a linear-time\nalgorithm for leaf-labeled pedigrees. The second is the pedigree edit distance\nproblem, for which we present 1) several algorithms that are fast and exact in\nvarious special cases, and 2) a general, randomized heuristic algorithm.\n  In the negative direction, we first prove that the pedigree isomorphism\nproblem is as hard as the general graph isomorphism problem, and that the\nsub-pedigree isomorphism problem is NP-hard. We then show that the pedigree\nedit distance problem is APX-hard in general and NP-hard on leaf-labeled\npedigrees.\n  We use simulated pedigrees to compare our edit-distance algorithms to each\nother as well as to a branch-and-bound algorithm that always finds an optimal\nsolution.\n", "versions": [{"version": "v1", "created": "Sun, 5 Sep 2010 12:02:26 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 17:57:31 GMT"}], "update_date": "2011-10-19", "authors_parsed": [["Kirkpatrick", "Bonnie", ""], ["Reshef", "Yakir", ""], ["Finucane", "Hilary", ""], ["Jiang", "Haitao", ""], ["Zhu", "Binhai", ""], ["Karp", "Richard M.", ""]]}, {"id": "1009.1114", "submitter": "Jose Fontanari", "authors": "Jose F. Fontanari", "title": "Social interaction as a heuristic for combinatorial optimization\n  problems", "comments": null, "journal-ref": "Phys. Rev. E 82, 056118 (2010)", "doi": "10.1103/PhysRevE.82.056118", "report-no": null, "categories": "cs.DS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of a variant of Axelrod's model for\ndissemination of culture - the Adaptive Culture Heuristic (ACH) - on solving an\nNP-Complete optimization problem, namely, the classification of binary input\npatterns of size $F$ by a Boolean Binary Perceptron. In this heuristic, $N$\nagents, characterized by binary strings of length $F$ which represent possible\nsolutions to the optimization problem, are fixed at the sites of a square\nlattice and interact with their nearest neighbors only. The interactions are\nsuch that the agents' strings (or cultures) become more similar to the low-cost\nstrings of their neighbors resulting in the dissemination of these strings\nacross the lattice. Eventually the dynamics freezes into a homogeneous\nabsorbing configuration in which all agents exhibit identical solutions to the\noptimization problem. We find through extensive simulations that the\nprobability of finding the optimal solution is a function of the reduced\nvariable $F/N^{1/4}$ so that the number of agents must increase with the fourth\npower of the problem size, $N \\propto F^ 4$, to guarantee a fixed probability\nof success. In this case, we find that the relaxation time to reach an\nabsorbing configuration scales with $F^ 6$ which can be interpreted as the\noverall computational cost of the ACH to find an optimal set of weights for a\nBoolean Binary Perceptron, given a fixed probability of success.\n", "versions": [{"version": "v1", "created": "Sun, 22 Aug 2010 13:05:52 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 19:46:12 GMT"}], "update_date": "2010-12-01", "authors_parsed": [["Fontanari", "Jose F.", ""]]}, {"id": "1009.1381", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Mathieu Liedloff", "title": "A Branch-and-Reduce Algorithm for Finding a Minimum Independent\n  Dominating Set", "comments": "Full version. A preliminary version appeared in the proceedings of WG\n  2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An independent dominating set D of a graph G = (V,E) is a subset of vertices\nsuch that every vertex in V \\ D has at least one neighbor in D and D is an\nindependent set, i.e. no two vertices of D are adjacent in G. Finding a minimum\nindependent dominating set in a graph is an NP-hard problem. Whereas it is hard\nto cope with this problem using parameterized and approximation algorithms,\nthere is a simple exact O(1.4423^n)-time algorithm solving the problem by\nenumerating all maximal independent sets. In this paper we improve the latter\nresult, providing the first non trivial algorithm computing a minimum\nindependent dominating set of a graph in time O(1.3569^n). Furthermore, we give\na lower bound of \\Omega(1.3247^n) on the worst-case running time of this\nalgorithm, showing that the running time analysis is almost tight.\n", "versions": [{"version": "v1", "created": "Tue, 7 Sep 2010 19:57:23 GMT"}], "update_date": "2010-09-08", "authors_parsed": [["Gaspers", "Serge", ""], ["Liedloff", "Mathieu", ""]]}, {"id": "1009.1544", "submitter": "Darakhshan Mir", "authors": "Darakhshan Mir, S. Muthukrishnan, Aleksandar Nikolov, Rebecca N.\n  Wright", "title": "Pan-private Algorithms: When Memory Does Not Help", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider updates arriving online in which the $t$th input is $(i_t,d_t)$,\nwhere $i_t$'s are thought of as IDs of users. Informally, a randomized function\n$f$ is {\\em differentially private} with respect to the IDs if the probability\ndistribution induced by $f$ is not much different from that induced by it on an\ninput in which occurrences of an ID $j$ are replaced with some other ID $k$\nRecently, this notion was extended to {\\em pan-privacy} where the computation\nof $f$ retains differential privacy, even if the internal memory of the\nalgorithm is exposed to the adversary (say by a malicious break-in or by fiat\nby the government). This is a strong notion of privacy, and surprisingly, for\nbasic counting tasks such as distinct counts, heavy hitters and others, Dwork\net al~\\cite{dwork-pan} present pan-private algorithms with reasonable accuracy.\nThe pan-private algorithms are nontrivial, and rely on sampling. We reexamine\nthese basic counting tasks and show improved bounds. In particular, we estimate\nthe distinct count $\\Dt$ to within $(1\\pm \\eps)\\Dt \\pm O(\\polylog m)$, where\n$m$ is the number of elements in the universe. This uses suitably noisy\nstatistics on sketches known in the streaming literature. We also present the\nfirst known lower bounds for pan-privacy with respect to a single intrusion.\nOur lower bounds show that, even if allowed to work with unbounded memory,\npan-private algorithms for distinct counts can not be significantly more\naccurate than our algorithms. Our lower bound uses noisy decoding. For heavy\nhitter counts, we present a pan private streaming algorithm that is accurate to\nwithin $O(k)$ in worst case; previously known bound for this problem is\narbitrarily worse. An interesting aspect of our pan-private algorithms is that,\nthey deliberately use very small (polylogarithmic) space and tend to be\nstreaming algorithms, even though using more space is not forbidden.\n", "versions": [{"version": "v1", "created": "Wed, 8 Sep 2010 14:25:45 GMT"}], "update_date": "2010-09-09", "authors_parsed": [["Mir", "Darakhshan", ""], ["Muthukrishnan", "S.", ""], ["Nikolov", "Aleksandar", ""], ["Wright", "Rebecca N.", ""]]}, {"id": "1009.1697", "submitter": "Oleg Titov", "authors": "Oleg Titov", "title": "One method of storing information", "comments": "12 pages, article in russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formulate the problem as follows. Split a file into n pieces so that it can\nbe restored without any m parts (1<=m<=n). Such problems are called problems\nsecret sharing. There exists a set of methods for solving such problems, but\nthey all require a fairly large number of calculations applied to the problem\nposed above. The proposed method does not require calculations, and requires\nonly the operations of the division of the file into equal (nearly equal) parts\nand gluing them in a certain order in one or more files.\n", "versions": [{"version": "v1", "created": "Thu, 9 Sep 2010 07:41:22 GMT"}], "update_date": "2010-09-10", "authors_parsed": [["Titov", "Oleg", ""]]}, {"id": "1009.1904", "submitter": "David Eppstein", "authors": "David Eppstein, Michael T. Goodrich, Roberto Tamassia", "title": "Privacy-Preserving Data-Oblivious Geometric Algorithms for Geographic\n  Data", "comments": "19 pages, 5 figures. Extended version of a paper to appear in Proc.\n  18th ACM SIGSPATIAL Int. Conf. Advances in Geographic Information Systems\n  (ACM GIS 2010), San Jose, California", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give efficient data-oblivious algorithms for several fundamental geometric\nproblems that are relevant to geographic information systems, including planar\nconvex hulls and all-nearest neighbors. Our methods are \"data-oblivious\" in\nthat they don't perform any data-dependent operations, with the exception of\noperations performed inside low-level blackbox circuits having a constant\nnumber of inputs and outputs. Thus, an adversary who observes the control flow\nof one of our algorithms, but who cannot see the inputs and outputs to the\nblackbox circuits, cannot learn anything about the input or output. This\nbehavior makes our methods applicable to secure multiparty computation (SMC)\nprotocols for geographic data used in location-based services. In SMC\nprotocols, multiple parties wish to perform a computation on their combined\ndata without revealing individual data to the other parties. For instance, our\nmethods can be used to solve a problem posed by Du and Atallah, where Alice has\na set, A, of m private points in the plane, Bob has another set, B, of n\nprivate points in the plane, and Alice and Bob want to jointly compute the\nconvex hull of A u B without disclosing any more information than what can be\nderived from the answer. In particular, neither Alice nor Bob want to reveal\nany of their respective points that are in the interior of the convex hull of A\nu B.\n", "versions": [{"version": "v1", "created": "Thu, 9 Sep 2010 22:24:13 GMT"}], "update_date": "2010-09-13", "authors_parsed": [["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""], ["Tamassia", "Roberto", ""]]}, {"id": "1009.2109", "submitter": "Antonios Symvonis", "authors": "Evmorfia N. Argyriou, Michael A. Bekos, Antonios Symvonis", "title": "Maximizing the Total Resolution of Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major factor affecting the readability of a graph drawing is its\nresolution. In the graph drawing literature, the resolution of a drawing is\neither measured based on the angles formed by consecutive edges incident to a\ncommon node (angular resolution) or by the angles formed at edge crossings\n(crossing resolution). In this paper, we evaluate both by introducing the\nnotion of \"total resolution\", that is, the minimum of the angular and crossing\nresolution. To the best of our knowledge, this is the first time where the\nproblem of maximizing the total resolution of a drawing is studied.\n  The main contribution of the paper consists of drawings of asymptotically\noptimal total resolution for complete graphs (circular drawings) and for\ncomplete bipartite graphs (2-layered drawings). In addition, we present and\nexperimentally evaluate a force-directed based algorithm that constructs\ndrawings of large total resolution.\n", "versions": [{"version": "v1", "created": "Fri, 10 Sep 2010 21:46:39 GMT"}, {"version": "v2", "created": "Mon, 27 Sep 2010 10:30:19 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Argyriou", "Evmorfia N.", ""], ["Bekos", "Michael A.", ""], ["Symvonis", "Antonios", ""]]}, {"id": "1009.2160", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Eliana-Dina Tirsa", "title": "Clustering, Encoding and Diameter Computation Algorithms for\n  Multidimensional Data", "comments": "ISBN: 978-973-662-574-9", "journal-ref": "Proceedings of the IEEE International Conference on Automation,\n  Quality and Testing, Robotics (THETA 17) (AQTR) - Student Forum, Cluj-Napoca,\n  Romania, 28-30 May, 2010", "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present novel algorithms for several multidimensional data\nprocessing problems. We consider problems related to the computation of\nrestricted clusters and of the diameter of a set of points using a new distance\nfunction. We also consider two string (1D data) processing problems, regarding\nan optimal encoding method and the computation of the number of occurrences of\na substring within a string generated by a grammar. The algorithms have been\nthoroughly analyzed from a theoretical point of view and some of them have also\nbeen evaluated experimentally.\n", "versions": [{"version": "v1", "created": "Sat, 11 Sep 2010 12:03:26 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tirsa", "Eliana-Dina", ""]]}, {"id": "1009.2242", "submitter": "Saied Hosseini-Khayat", "authors": "Monireh Houshmand and Saied Hosseini-Khayat", "title": "Minimal-memory realization of pearl-necklace encoders of general quantum\n  convolutional codes", "comments": "16 pages, 5 figures; extends paper arXiv:1004.5179v1", "journal-ref": null, "doi": "10.1103/PhysRevA.83.022308", "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum convolutional codes, like their classical counterparts, promise to\noffer higher error correction performance than block codes of equivalent\nencoding complexity, and are expected to find important applications in\nreliable quantum communication where a continuous stream of qubits is\ntransmitted. Grassl and Roetteler devised an algorithm to encode a quantum\nconvolutional code with a \"pearl-necklace encoder.\" Despite their theoretical\nsignificance as a neat way of representing quantum convolutional codes, they\nare not well-suited to practical realization. In fact, there is no\nstraightforward way to implement any given pearl-necklace structure. This paper\ncloses the gap between theoretical representation and practical implementation.\nIn our previous work, we presented an efficient algorithm for finding a\nminimal-memory realization of a pearl-necklace encoder for\nCalderbank-Shor-Steane (CSS) convolutional codes. This work extends our\nprevious work and presents an algorithm for turning a pearl-necklace encoder\nfor a general (non-CSS) quantum convolutional code into a realizable quantum\nconvolutional encoder. We show that a minimal-memory realization depends on the\ncommutativity relations between the gate strings in the pearl-necklace encoder.\nWe find a realization by means of a weighted graph which details the\nnon-commutative paths through the pearl-necklace. The weight of the longest\npath in this graph is equal to the minimal amount of memory needed to implement\nthe encoder. The algorithm has a polynomial-time complexity in the number of\ngate strings in the pearl-necklace encoder.\n", "versions": [{"version": "v1", "created": "Sun, 12 Sep 2010 15:27:20 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Houshmand", "Monireh", ""], ["Hosseini-Khayat", "Saied", ""]]}, {"id": "1009.2322", "submitter": "Yong Zhang", "authors": "Joseph Wun-Tat Chan, Francis Y.L. Chin, Xin Han, Ka-Cheong Lam,\n  Hing-Fung Ting, and Yong Zhang", "title": "Deterministic Online Call Control in Cellular Networks and Triangle-Free\n  Cellular Networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Wireless Communication Networks based on Frequency Division Multiplexing (FDM\nin short) plays an important role in the field of communications, in which each\nrequest can be satisfied by assigning a frequency. To avoid interference, each\nassigned frequency must be different to the neighboring assigned frequencies.\nSince frequency is a scarce resource, the main problem in wireless networks is\nhow to fully utilize the given bandwidth of frequencies. In this paper, we\nconsider the online call control problem. Given a fixed bandwidth of\nfrequencies and a sequence of communication requests arrive over time, each\nrequest must be either satisfied immediately after its arrival by assigning an\navailable frequency, or rejected. The objective of call control problem is to\nmaximize the number of accepted requests. We study the asymptotic performance\nof this problem, i.e., the number of requests in the sequence and the bandwidth\nof frequencies are very large. In this paper, we give a 7/3-competitive\nalgorithm for call control problem in cellular network, improving the previous\n2.5-competitive result. Moreover, we investigate the triangle-free cellular\nnetwork, propose a 9/4-competitive algorithm and prove that the lower bound of\ncompetitive ratio is at least 5/3.\n", "versions": [{"version": "v1", "created": "Mon, 13 Sep 2010 08:36:19 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Chan", "Joseph Wun-Tat", ""], ["Chin", "Francis Y. L.", ""], ["Han", "Xin", ""], ["Lam", "Ka-Cheong", ""], ["Ting", "Hing-Fung", ""], ["Zhang", "Yong", ""]]}, {"id": "1009.2452", "submitter": "Chaitanya Swamy", "authors": "Deeparnab Chakrabarty and Chaitanya Swamy", "title": "Facility Location with Client Latencies: Linear-Programming based\n  Techniques for Minimum-Latency Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a problem that is a common generalization of the uncapacitated\nfacility location and minimum latency (ML) problems, where facilities need to\nbe opened to serve clients and also need to be sequentially activated before\nthey can provide service. Formally, we are given a set \\F of n facilities with\nfacility-opening costs {f_i}, a set of m clients, and connection costs {c_{ij}}\nspecifying the cost of assigning a client j to a facility i, a root node r\ndenoting the depot, and a time metric d on \\F\\cup{r}. Our goal is to open a\nsubset F of facilities, find a path P starting at r and spanning F to activate\nthe open facilities, and connect each client j to a facility \\phi(j)\\in F, so\nas to minimize \\sum_{i\\in F}f_i +\\sum_{clients j}(c_{\\phi(j),j}+t_j), where t_j\nis the time taken to reach \\phi(j) along path P. We call this the minimum\nlatency uncapacitated facility location (MLUFL) problem.\n  Our main result is an O(\\log n\\max{\\log n,\\log m})-approximation for MLUFL.\nWe also show that any improvement in this approximation guarantee, implies an\nimprovement in the (current-best) approximation factor for group Steiner tree.\nWe obtain constant approximations for two natural special cases of the problem:\n(a) related MLUFL (metric connection costs that are a scalar multiple of the\ntime metric); (b) metric uniform MLUFL (metric connection costs, unform\ntime-metric). Our LP-based methods are versatile and easily adapted to yield\napproximation guarantees for MLUFL in various more general settings, such as\n(i) when the latency-cost of a client is a function of the delay faced by the\nfacility to which it is connected; and (ii) the k-route version, where k\nvehicles are routed in parallel to activate the open facilities. Our LP-based\nunderstanding of MLUFL also offers some LP-based insights into ML, which we\nbelieve is a promising direction for obtaining improvements for ML.\n", "versions": [{"version": "v1", "created": "Mon, 13 Sep 2010 17:04:34 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1009.2521", "submitter": "Haitao Wang", "authors": "Danny Z. Chen and Haitao Wang", "title": "An Improved Algorithm for Reconstructing a Simple Polygon from the\n  Visibility Angles", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the following problem of reconstructing a simple\npolygon: Given a cyclically ordered vertex sequence of an unknown simple\npolygon P of n vertices and, for each vertex v of P, the sequence of angles\ndefined by all the visible vertices of v in P, reconstruct the polygon P (up to\nsimilarity). An O(n^3 log n) time algorithm has been proposed for this problem.\nWe present an improved algorithm with running time O(n^2), based on new\nobservations on the geometric structures of the problem. Since the input size\n(i.e., the total number of input visibility angles) is O(n^2) in the worst\ncase, our algorithm is worst-case optimal.\n", "versions": [{"version": "v1", "created": "Mon, 13 Sep 2010 20:58:34 GMT"}], "update_date": "2010-09-15", "authors_parsed": [["Chen", "Danny Z.", ""], ["Wang", "Haitao", ""]]}, {"id": "1009.2577", "submitter": "Praveen Manjunatha", "authors": "M. Praveen", "title": "Small Vertex Cover makes Petri Net Coverability and Boundedness Easier", "comments": "Full version of the paper appearing in IPEC 2010", "journal-ref": null, "doi": "10.1007/978-3-642-17493-3_21", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coverability and boundedness problems for Petri nets are known to be\nExpspace-complete. Given a Petri net, we associate a graph with it. With the\nvertex cover number k of this graph and the maximum arc weight W as parameters,\nwe show that coverability and boundedness are in ParaPspace. This means that\nthese problems can be solved in space O(ef(k,W)poly(n)), where ef(k,W) is some\nexponential function and poly(n) is some polynomial in the size of the input.\nWe then extend the ParaPspace result to model checking a logic that can express\nsome generalizations of coverability and boundedness.\n", "versions": [{"version": "v1", "created": "Tue, 14 Sep 2010 07:06:30 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Praveen", "M.", ""]]}, {"id": "1009.2591", "submitter": "Meghana Nasre Ms.", "authors": "Telikepalli Kavitha, Meghana Nasre, Prajakta Nimbhorkar", "title": "Popularity at Minimum Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an extension of the {\\em popular matching} problem in this paper.\nThe input to the popular matching problem is a bipartite graph G = (A U B,E),\nwhere A is a set of people, B is a set of items, and each person a belonging to\nA ranks a subset of items in an order of preference, with ties allowed. The\npopular matching problem seeks to compute a matching M* between people and\nitems such that there is no matching M where more people are happier with M\nthan with M*. Such a matching M* is called a popular matching. However, there\nare simple instances where no popular matching exists.\n  Here we consider the following natural extension to the above problem:\nassociated with each item b belonging to B is a non-negative price cost(b),\nthat is, for any item b, new copies of b can be added to the input graph by\npaying an amount of cost(b) per copy. When G does not admit a popular matching,\nthe problem is to \"augment\" G at minimum cost such that the new graph admits a\npopular matching. We show that this problem is NP-hard; in fact, it is NP-hard\nto approximate it within a factor of sqrt{n1}/2, where n1 is the number of\npeople. This problem has a simple polynomial time algorithm when each person\nhas a preference list of length at most 2. However, if we consider the problem\nof \"constructing\" a graph at minimum cost that admits a popular matching that\nmatches all people, then even with preference lists of length 2, the problem\nbecomes NP-hard. On the other hand, when the number of copies of each item is\n\"fixed\", we show that the problem of computing a minimum cost popular matching\nor deciding that no popular matching exists can be solved in O(mn1) time, where\nm is the number of edges.\n", "versions": [{"version": "v1", "created": "Tue, 14 Sep 2010 08:31:31 GMT"}], "update_date": "2010-09-15", "authors_parsed": [["Kavitha", "Telikepalli", ""], ["Nasre", "Meghana", ""], ["Nimbhorkar", "Prajakta", ""]]}, {"id": "1009.3134", "submitter": "Kostas Tsichlas", "authors": "G.S. Brodal, S. Sioutas, K. Tsichlas, and C. Zaroliagis", "title": "D$^2$-Tree: A New Overlay with Deterministic Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new overlay, called the {\\em Deterministic Decentralized tree}\n($D^2$-tree). The $D^2$-tree compares favourably to other overlays for the\nfollowing reasons: (a) it provides matching and better complexities, which are\ndeterministic for the supported operations; (b) the management of nodes (peers)\nand elements are completely decoupled from each other; and (c) an efficient\ndeterministic load-balancing mechanism is presented for the uniform\ndistribution of elements into nodes, while at the same time probabilistic\noptimal bounds are provided for the congestion of operations at the nodes. The\nload-balancing scheme of elements into nodes is deterministic and general\nenough to be applied to other hierarchical tree-based overlays. This\nload-balancing mechanism is based on an innovative lazy weight-balancing\nmechanism, which is interesting in its own right.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 10:11:04 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 20:05:39 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Brodal", "G. S.", ""], ["Sioutas", "S.", ""], ["Tsichlas", "K.", ""], ["Zaroliagis", "C.", ""]]}, {"id": "1009.3214", "submitter": "Mark Giesbrecht", "authors": "Mark Giesbrecht and Daniel S. Roche and Hrushikesh Tilak", "title": "Computing sparse multiples of polynomials", "comments": "Extended abstract appears in Proc. ISAAC 2010, pp. 266-278, LNCS 6506", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a sparse multiple of a polynomial. Given f\nin F[x] of degree d over a field F, and a desired sparsity t, our goal is to\ndetermine if there exists a multiple h in F[x] of f such that h has at most t\nnon-zero terms, and if so, to find such an h. When F=Q and t is constant, we\ngive a polynomial-time algorithm in d and the size of coefficients in h. When F\nis a finite field, we show that the problem is at least as hard as determining\nthe multiplicative order of elements in an extension field of F (a problem\nthought to have complexity similar to that of factoring integers), and this\nlower bound is tight when t=2.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 16:21:15 GMT"}, {"version": "v2", "created": "Sat, 1 Jan 2011 21:08:52 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Giesbrecht", "Mark", ""], ["Roche", "Daniel S.", ""], ["Tilak", "Hrushikesh", ""]]}, {"id": "1009.3502", "submitter": "Krishnam Raju Jampani", "authors": "Krishnam Raju Jampani and Anna Lubiw", "title": "Simultaneous Interval Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, we introduced the simultaneous representation problem\n(defined for any graph class C) and studied the problem for chordal,\ncomparability and permutation graphs. For interval graphs, the problem is\ndefined as follows. Two interval graphs G_1 and G_2, sharing some vertices I\n(and the corresponding induced edges), are said to be `simultaneous interval\ngraphs' if there exist interval representations R_1 and R_2 of G_1 and G_2,\nsuch that any vertex of I is mapped to the same interval in both R_1 and R_2.\nEquivalently, G_1 and G_2 are simultaneous interval graphs if there exist edges\nE' between G_1-I and G_2-I such that G_1 \\cup G_2 \\cup E' is an interval graph.\n  Simultaneous representation problems are related to simultaneous planar\nembeddings, and have applications in any situation where it is desirable to\nconsistently represent two related graphs, for example: interval graphs\ncapturing overlaps of DNA fragments of two similar organisms; or graphs\nconnected in time, where one is an updated version of the other.\n  In this paper we give an O(n^2*logn) time algorithm for recognizing\nsimultaneous interval graphs,where n = |G_1 \\cup G_2|. This result complements\nthe polynomial time algorithms for recognizing probe interval graphs and\nprovides an efficient algorithm for the interval graph sandwich problem for the\nspecial case where the set of optional edges induce a complete bipartite graph.\n", "versions": [{"version": "v1", "created": "Fri, 17 Sep 2010 20:25:56 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Jampani", "Krishnam Raju", ""], ["Lubiw", "Anna", ""]]}, {"id": "1009.3594", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Avrim Blum and Or Sheffet", "title": "Center-based Clustering under Perturbation Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering under most popular objective functions is NP-hard, even to\napproximate well, and so unlikely to be efficiently solvable in the worst case.\nRecently, Bilu and Linial \\cite{Bilu09} suggested an approach aimed at\nbypassing this computational barrier by using properties of instances one might\nhope to hold in practice. In particular, they argue that instances in practice\nshould be stable to small perturbations in the metric space and give an\nefficient algorithm for clustering instances of the Max-Cut problem that are\nstable to perturbations of size $O(n^{1/2})$. In addition, they conjecture that\ninstances stable to as little as O(1) perturbations should be solvable in\npolynomial time. In this paper we prove that this conjecture is true for any\ncenter-based clustering objective (such as $k$-median, $k$-means, and\n$k$-center). Specifically, we show we can efficiently find the optimal\nclustering assuming only stability to factor-3 perturbations of the underlying\nmetric in spaces without Steiner points, and stability to factor $2+\\sqrt{3}$\nperturbations for general metrics. In particular, we show for such instances\nthat the popular Single-Linkage algorithm combined with dynamic programming\nwill find the optimal clustering. We also present NP-hardness results under a\nweaker but related condition.\n", "versions": [{"version": "v1", "created": "Sat, 18 Sep 2010 22:57:43 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2011 17:52:44 GMT"}], "update_date": "2011-08-12", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Blum", "Avrim", ""], ["Sheffet", "Or", ""]]}, {"id": "1009.3809", "submitter": "arXiv Admin", "authors": "Ramesh C. Bagadi", "title": "One, Two, Three and N Dimensional String Search Algorithms", "comments": "withdrawn by arXiv admin due to authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research endeavor, some Sequence Alignment Algorithms are detailed\nthat are useful for finding or comparing 1 dimensional (1-D), 2 dimensional\n(2-D), 3 dimensional (3-D) sequences in or against a parent or mother database\nwhich is 1 dimensional (1-D), 2 dimensional (2-D), 3 dimensional (3-D)\nsequence. Inner Product [1], [2] based schemes are used to lay down such\nalgorithms. Also,in this research, a Sequence Alignment Algorithms is detailed\nthat is useful for finding or comparing an N-Dimensional (N-D) sequence in or\nagainst a parent or mother database which N-Dimensional (N-D) sequence. Inner\nProduct [1], [2] based schemes are used to lay down such an algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 13:11:52 GMT"}, {"version": "v2", "created": "Tue, 2 Nov 2010 19:30:09 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Bagadi", "Ramesh C.", ""]]}, {"id": "1009.3984", "submitter": "Hieu Dinh", "authors": "Hieu Dinh and Sanguthevar Rajasekaran", "title": "A memory-efficient data structure representing exact-match overlap\n  graphs with application for next generation DNA assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exact-match overlap graph of $n$ given strings of length $\\ell$ is an\nedge-weighted graph in which each vertex is associated with a string and there\nis an edge $(x,y)$ of weight $\\omega = \\ell - |ov_{max}(x,y)|$ if and only if\n$\\omega \\leq \\lambda$, where $|ov_{max}(x,y)|$ is the length of $ov_{max}(x,y)$\nand $\\lambda$ is a given threshold. In this paper, we show that the exact-match\noverlap graphs can be represented by a compact data structure that can be\nstored using at most $(2\\lambda -1 )(2\\lceil\\log n\\rceil +\n\\lceil\\log\\lambda\\rceil)n$ bits with a guarantee that the basic operation of\naccessing an edge takes $O(\\log \\lambda)$ time.\n  Exact-match overlap graphs have been broadly used in the context of DNA\nassembly and the \\emph{shortest super string problem} where the number of\nstrings $n$ ranges from a couple of thousands to a couple of billions, the\nlength $\\ell$ of the strings is from 25 to 1000, depending on DNA sequencing\ntechnologies. However, many DNA assemblers using overlap graphs are facing a\nmajor problem of constructing and storing them. Especially, it is impossible\nfor these DNA assemblers to handle the huge amount of data produced by the next\ngeneration sequencing technologies where the number of strings $n$ is usually\nvery large ranging from hundred million to a couple of billions. In fact, to\nour best knowledge there is no DNA assemblers that can handle such a large\nnumber of strings. Fortunately, with our compact data structure, the major\nproblem of constructing and storing overlap graphs is practically solved since\nit only requires linear time and and linear memory. As a result, it opens the\ndoor of possibilities to build a DNA assembler that can handle large-scale\ndatasets efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 02:39:34 GMT"}], "update_date": "2010-09-22", "authors_parsed": [["Dinh", "Hieu", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "1009.4102", "submitter": "Bjoern Andres", "authors": "Bjoern Andres and Joerg H. Kappes and Ullrich Koethe and Fred A.\n  Hamprecht", "title": "The Lazy Flipper: MAP Inference in Higher-Order Graphical Models by\n  Depth-limited Exhaustive Search", "comments": "C++ Source Code available from\n  http://hci.iwr.uni-heidelberg.de/software.php", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new search algorithm for the NP-hard problem of\noptimizing functions of binary variables that decompose according to a\ngraphical model. It can be applied to models of any order and structure. The\nmain novelty is a technique to constrain the search space based on the topology\nof the model. When pursued to the full search depth, the algorithm is\nguaranteed to converge to a global optimum, passing through a series of\nmonotonously improving local optima that are guaranteed to be optimal within a\ngiven and increasing Hamming distance. For a search depth of 1, it specializes\nto Iterated Conditional Modes. Between these extremes, a useful tradeoff\nbetween approximation quality and runtime is established. Experiments on models\nderived from both illustrative and real problems show that approximations found\nwith limited search depth match or improve those obtained by state-of-the-art\nmethods based on message passing and linear programming.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 14:07:51 GMT"}], "update_date": "2010-09-22", "authors_parsed": [["Andres", "Bjoern", ""], ["Kappes", "Joerg H.", ""], ["Koethe", "Ullrich", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1009.4214", "submitter": "Pramod Ganapathi", "authors": "Pramod Ganapathi, Rama B", "title": "A Versatile Algorithm to Generate Various Combinatorial Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms to generate various combinatorial structures find tremendous\nimportance in computer science. In this paper, we begin by reviewing an\nalgorithm proposed by Rohl that generates all unique permutations of a list of\nelements which possibly contains repetitions, taking some or all of the\nelements at a time, in any imposed order. The algorithm uses an auxiliary array\nthat maintains the number of occurrences of each unique element in the input\nlist. We provide a proof of correctness of the algorithm. We then show how one\ncan efficiently generate other combinatorial structures like combinations,\nsubsets, n-Parenthesizations, derangements and integer partitions &\ncompositions with minor changes to the same algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 20:59:51 GMT"}, {"version": "v2", "created": "Thu, 30 Sep 2010 07:48:15 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Ganapathi", "Pramod", ""], ["B", "Rama", ""]]}, {"id": "1009.4355", "submitter": "Rob van Stee", "authors": "Ho-Leung Chan, Nicole Megow, Rob van Stee, Rene Sitters", "title": "The Sorting Buffer Problem is NP-hard", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the offline sorting buffer problem. The input is a sequence of\nitems of different types. All items must be processed one by one by a server.\nThe server is equipped with a random-access buffer of limited capacity which\ncan be used to rearrange items. The problem is to design a scheduling strategy\nthat decides upon the order in which items from the buffer are sent to the\nserver. Each type change incurs unit cost, and thus, the cost minimizing\nobjective is to minimize the total number of type changes for serving the\nentire sequence. This problem is motivated by various applications in\nmanufacturing processes and computer science, and it has attracted significant\nattention in the last few years. The main focus has been on online competitive\nalgorithms. Surprisingly little is known on the basic offline problem. In this\npaper, we show that the sorting buffer problem with uniform cost is NP-hard\nand, thus, close one of the most fundamental questions for the offline problem.\nOn the positive side, we give an O(1)-approximation algorithm when the\nscheduler is given a buffer only slightly larger than double the original size.\nWe also give a dynamic programming algorithm for the special case of buffer\nsize two that solves the problem exactly in linear time, improving on the\nstandard DP which runs in cubic time.\n", "versions": [{"version": "v1", "created": "Wed, 22 Sep 2010 13:14:51 GMT"}], "update_date": "2010-09-23", "authors_parsed": [["Chan", "Ho-Leung", ""], ["Megow", "Nicole", ""], ["van Stee", "Rob", ""], ["Sitters", "Rene", ""]]}, {"id": "1009.4517", "submitter": "Krishnam Raju Jampani", "authors": "Bernhard Haeupler and Krishnam Raju Jampani and Anna Lubiw", "title": "Testing Simultaneous Planarity when the Common Graph is 2-Connected", "comments": "Appeared in ISAAC 2010, 15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two planar graphs G1 and G2 sharing some vertices and edges are\n`simultaneously planar' if they have planar drawings such that a shared vertex\n[edge] is represented by the same point [curve] in both drawings. It is an open\nproblem whether simultaneous planarity can be tested efficiently. We give a\nlinear-time algorithm to test simultaneous planarity when the two graphs share\na 2-connected subgraph. Our algorithm extends to the case of k planar graphs\nwhere each vertex [edge] is either common to all graphs or belongs to exactly\none of them.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 04:24:51 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2011 05:21:49 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Jampani", "Krishnam Raju", ""], ["Lubiw", "Anna", ""]]}, {"id": "1009.4529", "submitter": "Ulrich Michael Schwarz", "authors": "Ulrich M. Schwarz", "title": "A PTAS for Scheduling with Tree Assignment Restrictions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling with assignment restrictions is an important special case of\nscheduling unrelated machines which has attracted much attention in the recent\npast. While a lower bound on approximability of 3/2 is known for its most\ngeneral setting, subclasses of the problem admit polynomial-time approximation\nschemes. This note provides a PTAS for tree-like hierarchical structures,\nimproving on a recent 4/3-approximation by Huo and Leung.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 07:12:49 GMT"}], "update_date": "2010-09-24", "authors_parsed": [["Schwarz", "Ulrich M.", ""]]}, {"id": "1009.4830", "submitter": "Timon Hertli", "authors": "Timon Hertli, Robin A. Moser, Dominik Scheder", "title": "Improving PPSZ for 3-SAT using Critical Variables", "comments": "12 pages, 2 figures, corrected a typo in the title, added appendix\n  with bound O(1.32065^n)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical variable of a satisfiable CNF formula is a variable that has the\nsame value in all satisfying assignments. Using a simple case distinction on\nthe fraction of critical variables of a CNF formula, we improve the running\ntime for 3-SAT from O(1.32216^n) by Rolf [2006] to O(1.32153^n). Using a\ndifferent approach, Iwama et al. [2010] very recently achieved a running time\nof O(1.32113^n). Our method nicely combines with theirs, yielding the currently\nfastest known algorithm with running time O(1.32065^n). We also improve the\nbound for 4-SAT from O(1.47390^n) [Iwama, Tamaki 2004] to O(1.46928^n), where\nO(1.46981^n) can be obtained using the methods of [Iwama, Tamaki 2004] and\n[Rolf 2006].\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 13:06:34 GMT"}, {"version": "v2", "created": "Thu, 28 Oct 2010 08:32:21 GMT"}, {"version": "v3", "created": "Thu, 19 May 2011 12:43:59 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Hertli", "Timon", ""], ["Moser", "Robin A.", ""], ["Scheder", "Dominik", ""]]}, {"id": "1009.4841", "submitter": "Omer Khalid Mr", "authors": "Omer Khalid, Ivo Maljevic, Richard Anthony, Miltos Petridis, Kevin\n  Parrot, Markus Schulz", "title": "Dynamic scheduling of virtual machines running hpc workloads in\n  scientific grids", "comments": "5 pages, 5 figures, NTMS 2009, Cairo, Egypt", "journal-ref": "In Proceedings of 3rd IEEE International Conference of New\n  Technologies, Mobility and Security, 2009", "doi": "10.1145/1330555.1330556", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The primary motivation for uptake of virtualization has been resource\nisolation, capacity management and resource customization allowing resource\nproviders to consolidate their resources in virtual machines. Various\napproaches have been taken to integrate virtualization in to scientific Grids\nespecially in the arena of High Performance Computing (HPC) to run grid jobs in\nvirtual machines, thus enabling better provisioning of the underlying resources\nand customization of the execution environment on runtime. Despite the gains,\nvirtualization layer also incur a performance penalty and its not very well\nunderstood that how such an overhead will impact the performance of systems\nwhere jobs are scheduled with tight deadlines. Since this overhead varies the\ntypes of workload whether they are memory intensive, CPU intensive or network\nI/O bound, and could lead to unpredictable deadline estimation for the running\njobs in the system. In our study, we have attempted to tackle this problem by\ndeveloping an intelligent scheduling technique for virtual machines which\nmonitors the workload types and deadlines, and calculate the system over head\nin real time to maximize number of jobs finishing within their agreed\ndeadlines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 13:57:02 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Khalid", "Omer", ""], ["Maljevic", "Ivo", ""], ["Anthony", "Richard", ""], ["Petridis", "Miltos", ""], ["Parrot", "Kevin", ""], ["Schulz", "Markus", ""]]}, {"id": "1009.4880", "submitter": "Gerald Paul", "authors": "Gerald Paul", "title": "An Efficient Implementation of the Robust Tabu Search Heuristic for\n  Sparse Quadratic Assignment Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and develop an efficient implementation of the robust tabu search\nheuristic for sparse quadratic assignment problems. The traditional\nimplementation of the heuristic applicable to all quadratic assignment problems\nis of O(N^2) complexity per iteration for problems of size N. Using multiple\npriority queues to determine the next best move instead of scanning all\npossible moves, and using adjacency lists to minimize the operations needed to\ndetermine the cost of moves, we reduce the asymptotic complexity per iteration\nto O(N log N ). For practical sized problems, the complexity is O(N).\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 16:05:29 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Paul", "Gerald", ""]]}, {"id": "1009.4995", "submitter": "Andrey Rumyantsev", "authors": "Andrey Rumyantsev", "title": "Kolmogorov complexity, Lovasz local lemma and critical exponents", "comments": null, "journal-ref": "Andrey Yu. Rumyantsev, Kolmogorov Complexity, Lov\\'asz Local Lemma\n  and Critical Exponents, Springer, Lecture Notes in Computer Science, Volume\n  4649 / 2007, CSR 2007, pp. 349--355", "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  D. Krieger and J. Shallit have proved that every real number greater than 1\nis a critical exponent of some sequence. We show how this result can be derived\nfrom some general statements about sequences whose subsequences have (almost)\nmaximal Kolmogorov complexity. In this way one can also construct a sequence\nthat has no \"approximate\" fractional powers with exponent that exceeds a given\nvalue.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 08:44:10 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Rumyantsev", "Andrey", ""]]}, {"id": "1009.5143", "submitter": "Yixin Cao", "authors": "Yixin Cao and Jianer Chen", "title": "FAST: Kernelization based on Graph Modular Decomposition", "comments": "further improvement under progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernelization algorithms, usually a preprocessing step before other more\ntraditional algorithms, are very special in the sense that they return\n(reduced) instances, instead of final results. This characteristic excludes the\nfreedom of applying a kernelization algorithm for the weighted version of a\nproblem to its unweighted instances. Thus with only very few special cases,\nkernelization algorithms have to be studied separately for weigthed and\nunweighted versions of a single problem. {\\sc feedback arc set on tournament}\nis currently a very popular problem in recent research of parameterized, as\nwell as approximation computation, and its wide applications in many areas make\nit appear in all top conferences. The theory of graph modular decompositions is\na general approach in the study of graph structures, which only had its\nsurfaces touched in previous work on kernelization algorithms of {\\sc feedback\narc set on tournament}. In this paper, we study further properties of graph\nmodular decompositions and apply them to obtain the first linear kernel for the\nunweighted {\\sc feedback arc set on tournament} problem, which only admits\nlinear kernel in its weighted version, while quadratic kernel for the\nunweighted.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 02:29:59 GMT"}, {"version": "v2", "created": "Fri, 1 Oct 2010 19:56:30 GMT"}], "update_date": "2010-10-04", "authors_parsed": [["Cao", "Yixin", ""], ["Chen", "Jianer", ""]]}, {"id": "1009.5168", "submitter": "Konstantin Voevodski", "authors": "Konstantin Voevodski, Maria-Florina Balcan, Heiko Roglin, Shang-Hua\n  Teng, Yu Xia", "title": "Efficient Clustering with Limited Distance Information", "comments": "Full version of UAI 2010 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a point set S and an unknown metric d on S, we study the problem of\nefficiently partitioning S into k clusters while querying few distances between\nthe points. In our model we assume that we have access to one versus all\nqueries that given a point s in S return the distances between s and all other\npoints. We show that given a natural assumption about the structure of the\ninstance, we can efficiently find an accurate clustering using only O(k)\ndistance queries. Our algorithm uses an active selection strategy to choose a\nsmall set of points that we call landmarks, and considers only the distances\nbetween landmarks and other points to produce a clustering. We use our\nalgorithm to cluster proteins by sequence similarity. This setting nicely fits\nour model because we can use a fast sequence database search program to query a\nsequence against an entire dataset. We conduct an empirical study that shows\nthat even though we query a small fraction of the distances between the points,\nwe produce clusterings that are close to a desired clustering given by manual\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 06:29:35 GMT"}, {"version": "v2", "created": "Mon, 9 May 2011 04:03:47 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Voevodski", "Konstantin", ""], ["Balcan", "Maria-Florina", ""], ["Roglin", "Heiko", ""], ["Teng", "Shang-Hua", ""], ["Xia", "Yu", ""]]}, {"id": "1009.5227", "submitter": "Antonios Symvonis", "authors": "Evmorfia N. Argyriou, Michael A. Bekos, Antonios Symvonis", "title": "The Straight-Line RAC Drawing Problem is NP-Hard", "comments": "23 pages in total", "journal-ref": null, "doi": "10.1007/978-3-642-18381-2_6", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent cognitive experiments have shown that the negative impact of an edge\ncrossing on the human understanding of a graph drawing, tends to be eliminated\nin the case where the crossing angles are greater than 70 degrees. This\nmotivated the study of RAC drawings, in which every pair of crossing edges\nintersects at right angle. In this work, we demonstrate a class of graphs with\nunique RAC combinatorial embedding and we employ members of this class in order\nto show that it is NP-hard to decide whether a graph admits a straight-line RAC\ndrawing.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 11:33:39 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Argyriou", "Evmorfia N.", ""], ["Bekos", "Michael A.", ""], ["Symvonis", "Antonios", ""]]}, {"id": "1009.5397", "submitter": "Tugkan Batu", "authors": "Tugkan Batu, Lance Fortnow, Ronitt Rubinfeld, Warren D. Smith, and\n  Patrick White", "title": "Testing Closeness of Discrete Distributions", "comments": "26 pages, A preliminary version of this paper appeared in the 41st\n  Symposium on Foundations of Computer Science, 2000, Redondo Beach, CA, A\n  comment from W.D. Smith has been added on the title page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given samples from two distributions over an $n$-element set, we wish to test\nwhether these distributions are statistically close. We present an algorithm\nwhich uses sublinear in $n$, specifically, $O(n^{2/3}\\epsilon^{-8/3}\\log n)$,\nindependent samples from each distribution, runs in time linear in the sample\nsize, makes no assumptions about the structure of the distributions, and\ndistinguishes the cases when the distance between the distributions is small\n(less than $\\max\\{\\epsilon^{4/3}n^{-1/3}/32, \\epsilon n^{-1/2}/4\\}$) or large\n(more than $\\epsilon$) in $\\ell_1$ distance. This result can be compared to the\nlower bound of $\\Omega(n^{2/3}\\epsilon^{-2/3})$ for this problem given by\nValiant.\n  Our algorithm has applications to the problem of testing whether a given\nMarkov process is rapidly mixing. We present sublinear for several variants of\nthis problem as well.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 20:57:00 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 12:27:08 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Batu", "Tugkan", ""], ["Fortnow", "Lance", ""], ["Rubinfeld", "Ronitt", ""], ["Smith", "Warren D.", ""], ["White", "Patrick", ""]]}, {"id": "1009.5435", "submitter": "Guohun Zhu", "authors": "Guohun Zhu", "title": "Determining All Maximum Uniquely Restricted Matching in Bipartite Graphs", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approach mapping from a matching of bipartite graphs to digraphs has been\nsuccessfully used for forcing set problem, in this paper, it is extended to\nuniquely restricted matching problem. We show to determine a uniquely\nrestricted matching in a bipartite graph is equivalent to recognition a acyclic\ndigraph. Based on these results, it proves that determine the bipartite graphs\nwith all maximum matching are uniquely restricted is polynomial time. This\nanswers an open question of Levit and Mandrescu(Discrete Applied Mathematics\n132(2004) 163-164).\n", "versions": [{"version": "v1", "created": "Tue, 28 Sep 2010 03:45:38 GMT"}], "update_date": "2010-09-29", "authors_parsed": [["Zhu", "Guohun", ""]]}, {"id": "1009.5538", "submitter": "John Iacono", "authors": "Amr Elmasry, Arash Farzan, John Iacono", "title": "Priority Queues with Multiple Time Fingers", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A priority queue is presented that supports the operations insert and\nfind-min in worst-case constant time, and delete and delete-min on element x in\nworst-case O(lg(min{w_x, q_x}+2)) time, where w_x (respectively q_x) is the\nnumber of elements inserted after x (respectively before x) and are still\npresent at the time of the deletion of x. Our priority queue then has both the\nworking-set and the queueish properties, and more strongly it satisfies these\nproperties in the worst-case sense. We also define a new distribution-sensitive\nproperty---the time-finger property, which encapsulates and generalizes both\nthe working-set and queueish properties, and present a priority queue that\nsatisfies this property.\n  In addition, we prove a strong implication that the working-set property is\nequivalent to the unified bound (which is the minimum per operation among the\nstatic finger, static optimality, and the working-set bounds). This latter\nresult is of tremendous interest by itself as it had gone unnoticed since the\nintroduction of such bounds by Sleater and Tarjan [JACM 1985]. Accordingly, our\npriority queue satisfies other distribution-sensitive properties as the static\nfinger, static optimality, and the unified bound.\n", "versions": [{"version": "v1", "created": "Tue, 28 Sep 2010 11:48:57 GMT"}], "update_date": "2010-09-29", "authors_parsed": [["Elmasry", "Amr", ""], ["Farzan", "Arash", ""], ["Iacono", "John", ""]]}, {"id": "1009.5628", "submitter": "Sandor P. Fekete", "authors": "Erik D. Demaine, Sandor P. Fekete, Guenter Rote, Nils Schweer, Daria\n  Schymura, Mariano Zelke", "title": "Integer Point Sets Minimizing Average Pairwise L1-Distance: What is the\n  Optimal Shape of a Town?", "comments": "26 pages, 6 figures, to appear in Computational Geometry: Theory and\n  Applications", "journal-ref": "Computational Geometry, Theory and Applications 44 (2011), 82-94", "doi": "10.1016/j.comgeo.2010.09.004", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An n-town, for a natural number n, is a group of n buildings, each occupying\na distinct position on a 2-dimensional integer grid. If we measure the distance\nbetween two buildings along the axis-parallel street grid, then an n-town has\noptimal shape if the sum of all pairwise Manhattan distances is minimized. This\nproblem has been studied for cities, i.e., the limiting case of very large n.\nFor cities, it is known that the optimal shape can be described by a\ndifferential equation, for which no closed-form is known. We show that optimal\nn-towns can be computed in O(n^7.5) time. This is also practically useful, as\nit allows us to compute optimal solutions up to n=80.\n", "versions": [{"version": "v1", "created": "Tue, 28 Sep 2010 16:31:35 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Demaine", "Erik D.", ""], ["Fekete", "Sandor P.", ""], ["Rote", "Guenter", ""], ["Schweer", "Nils", ""], ["Schymura", "Daria", ""], ["Zelke", "Mariano", ""]]}, {"id": "1009.5734", "submitter": "Deeparnab Chakrabarty", "authors": "Deeparnab Chakrabarty and Chandra Chekuri and Sanjeev Khanna and\n  Nitish Korula", "title": "Approximability of Capacitated Network Design", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the {\\em capacitated} survivable network design problem (Cap-SNDP), we are\ngiven an undirected multi-graph where each edge has a capacity and a cost. The\ngoal is to find a minimum cost subset of edges that satisfies a given set of\npairwise minimum-cut requirements. Unlike its classical special case of SNDP\nwhen all capacities are unit, the approximability of Cap-SNDP is not well\nunderstood; even in very restricted settings no known algorithm achieves a\n$o(m)$ approximation, where $m$ is the number of edges in the graph. In this\npaper, we obtain several new results and insights into the approximability of\nCap-SNDP.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 01:46:05 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Chekuri", "Chandra", ""], ["Khanna", "Sanjeev", ""], ["Korula", "Nitish", ""]]}, {"id": "1009.5787", "submitter": "Jens Svalgaard Kohrt", "authors": "Martin R. Ehmsen, Jens S. Kohrt and Kim S. Larsen", "title": "List Factoring and Relative Worst Order Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": "CP3-Origins-2010-41", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative worst order analysis is a supplement or alternative to competitive\nanalysis which has been shown to give results more in accordance with observed\nbehavior of online algorithms for a range of different online problems. The\ncontribution of this paper is twofold. First, it adds the static list accessing\nproblem to the collection of online problems where relative worst order\nanalysis gives better results. Second, and maybe more interesting, it adds the\nnon-trivial supplementary proof technique of list factoring to the theoretical\ntoolbox for relative worst order analysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 07:17:38 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Ehmsen", "Martin R.", ""], ["Kohrt", "Jens S.", ""], ["Larsen", "Kim S.", ""]]}, {"id": "1009.5791", "submitter": "Yoram Bachrach", "authors": "Yoram Bachrach, Ely Porat", "title": "Fast Pseudo-Random Fingerprints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to exponentially speed up computation of various\nfingerprints, such as the ones used to compute similarity and rarity in massive\ndata sets. Rather then maintaining the full stream of $b$ items of a universe\n$[u]$, such methods only maintain a concise fingerprint of the stream, and\nperform computations using the fingerprints. The computations are done\napproximately, and the required fingerprint size $k$ depends on the desired\naccuracy $\\epsilon$ and confidence $\\delta$. Our technique maintains a single\nbit per hash function, rather than a single integer, thus requiring a\nfingerprint of length $k = O(\\frac{\\ln \\frac{1}{\\delta}}{\\epsilon^2})$ bits,\nrather than $O(\\log u \\cdot \\frac{\\ln \\frac{1}{\\delta}}{\\epsilon^2})$ bits\nrequired by previous approaches. The main advantage of the fingerprints we\npropose is that rather than computing the fingerprint of a stream of $b$ items\nin time of $O(b \\cdot k)$, we can compute it in time $O(b \\log k)$. Thus this\nallows an exponential speedup for the fingerprint construction, or\nalternatively allows achieving a much higher accuracy while preserving\ncomputation time. Our methods rely on a specific family of pseudo-random hashes\nfor which we can quickly locate hashes resulting in small values.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 07:32:27 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Bachrach", "Yoram", ""], ["Porat", "Ely", ""]]}, {"id": "1009.5853", "submitter": "Sandor P. Fekete", "authors": "Tobias Baumgartner, Sandor P. Fekete, Winfried Hellmann, Alexander\n  Kroeller", "title": "Simultaneous Event Execution in Heterogeneous Wireless Sensor Networks", "comments": "6 pages, 5 figures, 3 tables, to appear in Journal of Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a synchronization algorithm to let nodes in a sensor network\nsimultaneously execute a task at a given point in time. In contrast to other\ntime synchronization algorithms we do not provide a global time basis that is\nshared on all nodes. Instead, any node in the network can spontaneously\ninitiate a process that allows the simultaneous execution of arbitrary tasks.\nWe show that our approach is beneficial in scenarios where a global time is not\nneeded, as it requires little communication compared with other time\nsynchronization algorithms. We also show that our algorithm works in\nheterogeneous systems where the hardware provides highly varying clock\naccuracy. Moreover, heterogeneity does not only affect the hardware, but also\nthe communication channels. We deal with different connection types---from\nhighly unreliable and fluctuating wireless channels to reliable and fast wired\nconnections.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 11:52:14 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Baumgartner", "Tobias", ""], ["Fekete", "Sandor P.", ""], ["Hellmann", "Winfried", ""], ["Kroeller", "Alexander", ""]]}, {"id": "1009.5863", "submitter": "Johannes Fischer", "authors": "J\\'er\\'emy Barbay and Johannes Fischer", "title": "LRM-Trees: Compressed Indices, Adaptive Sorting, and Compressed\n  Permutations", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LRM-Trees are an elegant way to partition a sequence of values into sorted\nconsecutive blocks, and to express the relative position of the first element\nof each block within a previous block. They were used to encode ordinal trees\nand to index integer arrays in order to support range minimum queries on them.\nWe describe how they yield many other convenient results in a variety of areas,\nfrom data structures to algorithms: some compressed succinct indices for range\nminimum queries; a new adaptive sorting algorithm; and a compressed succinct\ndata structure for permutations supporting direct and indirect application in\ntime all the shortest as the permutation is compressible.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 12:28:52 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["Fischer", "Johannes", ""]]}, {"id": "1009.6114", "submitter": "Tobias Marschall", "authors": "Tobias Marschall and Sven Rahmann", "title": "Exact Analysis of Pattern Matching Algorithms with Probabilistic\n  Arithmetic Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for the exact probabilistic analysis of window-based\npattern matching algorithms, such as Boyer-Moore, Horspool, Backward DAWG\nMatching, Backward Oracle Matching, and more. In particular, we show how to\nefficiently obtain the distribution of such an algorithm's running time cost\nfor any given pattern in a random text model, which can be quite general, from\nsimple uniform models to higher-order Markov models or hidden Markov models\n(HMMs). Furthermore, we provide a technique to compute the exact distribution\nof \\emph{differences} in running time cost of two algorithms. In contrast to\nprevious work, our approach is neither limited to simple text models, nor to\nasymptotic statements, nor to moment computations such as expectation and\nvariance. Methodically, we use extensions of finite automata which we call\ndeterministic arithmetic automata (DAAs) and probabilistic arithmetic automata\n(PAAs) [13]. To our knowledge, this is the first time that substring- or\nsuffix-based pattern matching algorithms are analyzed exactly. Experimentally,\nwe compare Horspool's algorithm, Backward DAWG Matching, and Backward Oracle\nMatching on prototypical patterns of short length and provide statistics on the\nsize of minimal DAAs for these computations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 12:22:25 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Marschall", "Tobias", ""], ["Rahmann", "Sven", ""]]}, {"id": "1009.6215", "submitter": "Bjoern Andres", "authors": "Bjoern Andres, Ullrich Koethe, Thorben Kroeger, Fred A. Hamprecht", "title": "How to Extract the Geometry and Topology from Very Large 3D\n  Segmentations", "comments": "C++ source code, free command line tools and MATLAB mex files are\n  avilable from http://hci.iwr.uni-heidelberg.de/software.php", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation is often an essential intermediate step in image analysis. A\nvolume segmentation characterizes the underlying volume image in terms of\ngeometric information--segments, faces between segments, curves in which\nseveral faces meet--as well as a topology on these objects. Existing algorithms\nencode this information in designated data structures, but require that these\ndata structures fit entirely in Random Access Memory (RAM). Today, 3D images\nwith several billion voxels are acquired, e.g. in structural neurobiology.\nSince these large volumes can no longer be processed with existing methods, we\npresent a new algorithm which performs geometry and topology extraction with a\nruntime linear in the number of voxels and log-linear in the number of faces\nand curves. The parallelizable algorithm proceeds in a block-wise fashion and\nconstructs a consistent representation of the entire volume image on the hard\ndrive, making the structure of very large volume segmentations accessible to\nimage analysis. The parallelized C++ source code, free command line tools and\nMATLAB mex files are avilable from\nhttp://hci.iwr.uni-heidelberg.de/software.php\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 18:24:09 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Andres", "Bjoern", ""], ["Koethe", "Ullrich", ""], ["Kroeger", "Thorben", ""], ["Hamprecht", "Fred A.", ""]]}]