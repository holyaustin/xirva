[{"id": "0802.0017", "submitter": "Amir Rothschild", "authors": "Amihood Amir and Klim Efremenko and Oren Kapah and Ely Porat and Amir\n  Rothschild", "title": "Improved Deterministic Length Reduction", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  This paper presents a new technique for deterministic length reduction. This\ntechnique improves the running time of the algorithm presented in \\cite{LR07}\nfor performing fast convolution in sparse data. While the regular fast\nconvolution of vectors $V_1,V_2$ whose sizes are $N_1,N_2$ respectively, takes\n$O(N_1 \\log N_2)$ using FFT, using the new technique for length reduction, the\nalgorithm proposed in \\cite{LR07} performs the convolution in $O(n_1 \\log^3\nn_1)$, where $n_1$ is the number of non-zero values in $V_1$. The algorithm\nassumes that $V_1$ is given in advance, and $V_2$ is given in running time. The\nnovel technique presented in this paper improves the convolution time to $O(n_1\n\\log^2 n_1)$ {\\sl deterministically}, which equals the best running time given\nachieved by a {\\sl randomized} algorithm.\n  The preprocessing time of the new technique remains the same as the\npreprocessing time of \\cite{LR07}, which is $O(n_1^2)$. This assumes and deals\nthe case where $N_1$ is polynomial in $n_1$. In the case where $N_1$ is\nexponential in $n_1$, a reduction to a polynomial case can be used. In this\npaper we also improve the preprocessing time of this reduction from $O(n_1^4)$\nto $O(n_1^3{\\rm polylog}(n_1))$.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2008 21:59:33 GMT"}], "update_date": "2008-02-04", "authors_parsed": [["Amir", "Amihood", ""], ["Efremenko", "Klim", ""], ["Kapah", "Oren", ""], ["Porat", "Ely", ""], ["Rothschild", "Amir", ""]]}, {"id": "0802.0802", "submitter": "Ping Li", "authors": "Ping Li", "title": "On Approximating Frequency Moments of Data Streams with Skewed\n  Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose skewed stable random projections for approximating the pth\nfrequency moments of dynamic data streams (0<p<=2), which has been frequently\nstudied in theoretical computer science and database communities. Our method\nsignificantly (or even infinitely when p->1) improves previous methods based on\n(symmetric) stable random projections.\n  Our proposed method is applicable to data streams that are (a) insertion only\n(the cash-register model); or (b) always non-negative (the strict Turnstile\nmodel), or (c) eventually non-negative at check points. This is only a minor\nrestriction for practical applications.\n  Our method works particularly well when p = 1+/- \\Delta and \\Delta is small,\nwhich is a practically important scenario. For example, \\Delta may be the decay\nrate or interest rate, which are usually small. Of course, when \\Delta = 0, one\ncan compute the 1th frequent moment (i.e., the sum) essentially error-free\nusing a simple couter. Our method may be viewed as a ``genearlized counter'' in\nthat it can count the total value in the future, taking in account of the\neffect of decaying or interest accruement.\n  In a summary, our contributions are two-fold. (A) This is the first propsal\nof skewed stable random projections. (B) Based on first principle, we develop\nvarious statistical estimators for skewed stable distributions, including their\nvariances and error (tail) probability bounds, and consequently the sample\ncomplexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 13:56:51 GMT"}], "update_date": "2008-02-07", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "0802.0835", "submitter": "Rossano Venturini", "authors": "Paolo Ferragina, Igor Nitto and Rossano Venturini", "title": "Bit-Optimal Lempel-Ziv compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": null, "abstract": "  One of the most famous and investigated lossless data-compression scheme is\nthe one introduced by Lempel and Ziv about 40 years ago. This compression\nscheme is known as \"dictionary-based compression\" and consists of squeezing an\ninput string by replacing some of its substrings with (shorter) codewords which\nare actually pointers to a dictionary of phrases built as the string is\nprocessed. Surprisingly enough, although many fundamental results are nowadays\nknown about upper bounds on the speed and effectiveness of this compression\nprocess and references therein), ``we are not aware of any parsing scheme that\nachieves optimality when the LZ77-dictionary is in use under any constraint on\nthe codewords other than being of equal length'' [N. Rajpoot and C. Sahinalp.\nHandbook of Lossless Data Compression, chapter Dictionary-based data\ncompression. Academic Press, 2002. pag. 159]. Here optimality means to achieve\nthe minimum number of bits in compressing each individual input string, without\nany assumption on its generating source. In this paper we provide the first\nLZ-based compressor which computes the bit-optimal parsing of any input string\nin efficient time and optimal space, for a general class of variable-length\ncodeword encodings which encompasses most of the ones typically used in data\ncompression and in the design of search engines and compressed indexes.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 16:31:54 GMT"}], "update_date": "2008-02-07", "authors_parsed": [["Ferragina", "Paolo", ""], ["Nitto", "Igor", ""], ["Venturini", "Rossano", ""]]}, {"id": "0802.1026", "submitter": "Benjamin Sach Mr", "authors": "Benjamin Sach and Rapha\\\"el Clifford", "title": "An Empirical Study of Cache-Oblivious Priority Queues and their\n  Application to the Shortest Path Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SE", "license": null, "abstract": "  In recent years the Cache-Oblivious model of external memory computation has\nprovided an attractive theoretical basis for the analysis of algorithms on\nmassive datasets. Much progress has been made in discovering algorithms that\nare asymptotically optimal or near optimal. However, to date there are still\nrelatively few successful experimental studies. In this paper we compare two\ndifferent Cache-Oblivious priority queues based on the Funnel and Bucket Heap\nand apply them to the single source shortest path problem on graphs with\npositive edge weights. Our results show that when RAM is limited and data is\nswapping to external storage, the Cache-Oblivious priority queues achieve\norders of magnitude speedups over standard internal memory techniques. However,\nfor the single source shortest path problem both on simulated and real world\ngraph data, these speedups are markedly lower due to the time required to\naccess the graph adjacency list itself.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2008 18:02:11 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Sach", "Benjamin", ""], ["Clifford", "Rapha\u00ebl", ""]]}, {"id": "0802.1059", "submitter": "Tobias Friedrich", "authors": "Deepak Ajwani, Tobias Friedrich", "title": "Average-Case Analysis of Online Topological Ordering", "comments": "22 pages, long version of ISAAC'07 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications like pointer analysis and incremental compilation require\nmaintaining a topological ordering of the nodes of a directed acyclic graph\n(DAG) under dynamic updates. All known algorithms for this problem are either\nonly analyzed for worst-case insertion sequences or only evaluated\nexperimentally on random DAGs. We present the first average-case analysis of\nonline topological ordering algorithms. We prove an expected runtime of O(n^2\npolylog(n)) under insertion of the edges of a complete DAG in a random order\nfor the algorithms of Alpern et al. (SODA, 1990), Katriel and Bodlaender (TALG,\n2006), and Pearce and Kelly (JEA, 2006). This is much less than the best known\nworst-case bound O(n^{2.75}) for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2008 20:27:17 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Ajwani", "Deepak", ""], ["Friedrich", "Tobias", ""]]}, {"id": "0802.1237", "submitter": "Gwena\\\"el Joret", "authors": "Jean Cardinal, Samuel Fiorini, and Gwena\\\"el Joret", "title": "Minimum Entropy Orientations", "comments": "Referees' comments incorporated", "journal-ref": "Operations Research Letters 36 (2008), pp. 680-683", "doi": "10.1016/j.orl.2008.06.010", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study graph orientations that minimize the entropy of the in-degree\nsequence. The problem of finding such an orientation is an interesting special\ncase of the minimum entropy set cover problem previously studied by Halperin\nand Karp [Theoret. Comput. Sci., 2005] and by the current authors\n[Algorithmica, to appear]. We prove that the minimum entropy orientation\nproblem is NP-hard even if the graph is planar, and that there exists a simple\nlinear-time algorithm that returns an approximate solution with an additive\nerror guarantee of 1 bit. This improves on the only previously known algorithm\nwhich has an additive error guarantee of log_2 e bits (approx. 1.4427 bits).\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2008 01:38:06 GMT"}, {"version": "v2", "created": "Mon, 22 Sep 2008 14:43:52 GMT"}], "update_date": "2008-10-28", "authors_parsed": [["Cardinal", "Jean", ""], ["Fiorini", "Samuel", ""], ["Joret", "Gwena\u00ebl", ""]]}, {"id": "0802.1338", "submitter": "Shai  Gutner", "authors": "Shai Gutner and Michael Tarsi", "title": "Some results on (a:b)-choosability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A solution to a problem of Erd\\H{o}s, Rubin and Taylor is obtained by showing\nthat if a graph $G$ is $(a:b)$-choosable, and $c/d > a/b$, then $G$ is not\nnecessarily $(c:d)$-choosable. Applying probabilistic methods, an upper bound\nfor the $k^{th}$ choice number of a graph is given. We also prove that a\ndirected graph with maximum outdegree $d$ and no odd directed cycle is\n$(k(d+1):k)$-choosable for every $k \\geq 1$. Other results presented in this\narticle are related to the strong choice number of graphs (a generalization of\nthe strong chromatic number). We conclude with complexity analysis of some\ndecision problems related to graph choosability.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2008 17:46:54 GMT"}], "update_date": "2008-02-12", "authors_parsed": [["Gutner", "Shai", ""], ["Tarsi", "Michael", ""]]}, {"id": "0802.1427", "submitter": "Klim Efremenko", "authors": "Klim Efremenko, Ely Porat", "title": "Approximating General Metric Distances Between a Pattern and a Text", "comments": "This is updated version of paper appered in SODA 2008", "journal-ref": "SODA 2008", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $T=t_0 ... t_{n-1}$ be a text and $P = p_0 ... p_{m-1}$ a pattern taken\nfrom some finite alphabet set $\\Sigma$, and let $\\dist$ be a metric on\n$\\Sigma$. We consider the problem of calculating the sum of distances between\nthe symbols of $P$ and the symbols of substrings of $T$ of length $m$ for all\npossible offsets. We present an $\\epsilon$-approximation algorithm for this\nproblem which runs in time $O(\\frac{1}{\\epsilon^2}n\\cdot\n\\mathrm{polylog}(n,\\abs{\\Sigma}))$\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 12:36:31 GMT"}], "update_date": "2008-02-12", "authors_parsed": [["Efremenko", "Klim", ""], ["Porat", "Ely", ""]]}, {"id": "0802.1471", "submitter": "Ronald de Wolf", "authors": "Ronald de Wolf (CWI Amsterdam)", "title": "Error-Correcting Data Structures", "comments": "15 pages LaTeX; an abridged version will appear in the Proceedings of\n  the STACS 2009 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study data structures in the presence of adversarial noise. We want to\nencode a given object in a succinct data structure that enables us to\nefficiently answer specific queries about the object, even if the data\nstructure has been corrupted by a constant fraction of errors. This new model\nis the common generalization of (static) data structures and locally decodable\nerror-correcting codes. The main issue is the tradeoff between the space used\nby the data structure and the time (number of probes) needed to answer a query\nabout the encoded object. We prove a number of upper and lower bounds on\nvarious natural error-correcting data structure problems. In particular, we\nshow that the optimal length of error-correcting data structures for the\nMembership problem (where we want to store subsets of size s from a universe of\nsize n) is closely related to the optimal length of locally decodable codes for\ns-bit strings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2008 16:35:49 GMT"}, {"version": "v2", "created": "Mon, 1 Dec 2008 14:25:48 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["de Wolf", "Ronald", "", "CWI Amsterdam"]]}, {"id": "0802.1685", "submitter": "Christoph Durr", "authors": "Marcin Bienkowski, Marek Chrobak, Christoph Durr, Mathilde Hurand,\n  Artur Jez, Lukasz Jez, Jakub Lopuszanski, Grzegorz Stachowiak", "title": "Generalized Whac-a-Mole", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We consider online competitive algorithms for the problem of collecting\nweighted items from a dynamic set S, when items are added to or deleted from S\nover time. The objective is to maximize the total weight of collected items. We\nstudy the general version, as well as variants with various restrictions,\nincluding the following: the uniform case, when all items have the same weight,\nthe decremental sets, when all items are present at the beginning and only\ndeletion operations are allowed, and dynamic queues, where the dynamic set is\nordered and only its prefixes can be deleted (with no restriction on\ninsertions). The dynamic queue case is a generalization of bounded-delay packet\nscheduling (also referred to as buffer management). We present several upper\nand lower bounds on the competitive ratio for these variants.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2008 18:41:46 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2008 00:09:51 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Bienkowski", "Marcin", ""], ["Chrobak", "Marek", ""], ["Durr", "Christoph", ""], ["Hurand", "Mathilde", ""], ["Jez", "Artur", ""], ["Jez", "Lukasz", ""], ["Lopuszanski", "Jakub", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "0802.1722", "submitter": "Saket Saurabh", "authors": "Omid Amini, Fedor V. Fomin and Saket Saurabh", "title": "Parameterized Algorithms for Partial Cover Problems", "comments": "20 page, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering problems are fundamental classical problems in optimization,\ncomputer science and complexity theory. Typically an input to these problems is\na family of sets over a finite universe and the goal is to cover the elements\nof the universe with as few sets of the family as possible.\n  The variations of covering problems include well known problems like Set\nCover, Vertex Cover, Dominating Set and Facility Location to name a few.\nRecently there has been a lot of study on partial covering problems, a natural\ngeneralization of covering problems. Here, the goal is not to cover all the\nelements but to cover the specified number of elements with the minimum number\nof sets.\n  In this paper we study partial covering problems in graphs in the realm of\nparameterized complexity. Classical (non-partial) version of all these problems\nhave been intensively studied in planar graphs and in graphs excluding a fixed\ngraph $H$ as a minor. However, the techniques developed for parameterized\nversion of non-partial covering problems cannot be applied directly to their\npartial counterparts. The approach we use, to show that various partial\ncovering problems are fixed parameter tractable on planar graphs, graphs of\nbounded local treewidth and graph excluding some graph as a minor, is quite\ndifferent from previously known techniques. The main idea behind our approach\nis the concept of implicit branching. We find implicit branching technique to\nbe interesting on its own and believe that it can be used for some other\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2008 21:19:40 GMT"}], "update_date": "2008-02-14", "authors_parsed": [["Amini", "Omid", ""], ["Fomin", "Fedor V.", ""], ["Saurabh", "Saket", ""]]}, {"id": "0802.1957", "submitter": "Sudhir Singh", "authors": "Sudhir Kumar Singh, Vwani P. Roychowdhury", "title": "To Broad-Match or Not to Broad-Match : An Auctioneer's Dilemma ?", "comments": "33 pages, 10 figures, new results added, substantially revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of an interesting aspect of sponsored search\nadvertising, namely the consequences of broad match-a feature where an ad of an\nadvertiser can be mapped to a broader range of relevant queries, and not\nnecessarily to the particular keyword(s) that ad is associated with. Starting\nwith a very natural setting for strategies available to the advertisers, and\nvia a careful look through the algorithmic lens, we first propose solution\nconcepts for the game originating from the strategic behavior of advertisers as\nthey try to optimize their budget allocation across various keywords. Next, we\nconsider two broad match scenarios based on factors such as information\nasymmetry between advertisers and the auctioneer, and the extent of\nauctioneer's control on the budget splitting. In the first scenario, the\nadvertisers have the full information about broad match and relevant\nparameters, and can reapportion their own budgets to utilize the extra\ninformation; in particular, the auctioneer has no direct control over budget\nsplitting. We show that, the same broad match may lead to different equilibria,\none leading to a revenue improvement, whereas another to a revenue loss. This\nleaves the auctioneer in a dilemma - whether to broad-match or not. This\nmotivates us to consider another broad match scenario, where the advertisers\nhave information only about the current scenario, and the allocation of the\nbudgets unspent in the current scenario is in the control of the auctioneer. We\nobserve that the auctioneer can always improve his revenue by judiciously using\nbroad match. Thus, information seems to be a double-edged sword for the\nauctioneer.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 03:45:07 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2008 19:40:28 GMT"}], "update_date": "2008-07-21", "authors_parsed": [["Singh", "Sudhir Kumar", ""], ["Roychowdhury", "Vwani P.", ""]]}, {"id": "0802.2015", "submitter": "Steven de Rooij", "authors": "Wouter Koolen and Steven de Rooij", "title": "Combining Expert Advice Efficiently", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT", "license": null, "abstract": "  We show how models for prediction with expert advice can be defined concisely\nand clearly using hidden Markov models (HMMs); standard HMM algorithms can then\nbe used to efficiently calculate, among other things, how the expert\npredictions should be weighted according to the model. We cast many existing\nmodels as HMMs and recover the best known running times in each case. We also\ndescribe two new models: the switch distribution, which was recently developed\nto improve Bayesian/Minimum Description Length model selection, and a new\ngeneralisation of the fixed share algorithm based on run-length coding. We give\nloss bounds for all models and shed new light on their relationships.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 14:54:57 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2008 10:59:15 GMT"}], "update_date": "2008-02-15", "authors_parsed": [["Koolen", "Wouter", ""], ["de Rooij", "Steven", ""]]}, {"id": "0802.2130", "submitter": "Ashkan Aazami", "authors": "Ashkan Aazami", "title": "Domination in graphs with bounded propagation: algorithms, formulations\n  and hardness results", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  We introduce a hierarchy of problems between the \\textsc{Dominating Set}\nproblem and the \\textsc{Power Dominating Set} (PDS) problem called the\n$\\ell$-round power dominating set ($\\ell$-round PDS, for short) problem. For\n$\\ell=1$, this is the \\textsc{Dominating Set} problem, and for $\\ell\\geq n-1$,\nthis is the PDS problem; here $n$ denotes the number of nodes in the input\ngraph. In PDS the goal is to find a minimum size set of nodes $S$ that power\ndominates all the nodes, where a node $v$ is power dominated if (1) $v$ is in\n$S$ or it has a neighbor in $S$, or (2) $v$ has a neighbor $u$ such that $u$\nand all of its neighbors except $v$ are power dominated. Note that rule (1) is\nthe same as for the \\textsc{Dominating Set} problem, and that rule (2) is a\ntype of propagation rule that applies iteratively. The $\\ell$-round PDS problem\nhas the same set of rules as PDS, except we apply rule (2) in ``parallel'' in\nat most $\\ell-1$ rounds. We prove that $\\ell$-round PDS cannot be approximated\nbetter than $2^{\\log^{1-\\epsilon}{n}}$ even for $\\ell=4$ in general graphs. We\nprovide a dynamic programming algorithm to solve $\\ell$-round PDS optimally in\npolynomial time on graphs of bounded tree-width. We present a PTAS (polynomial\ntime approximation scheme) for $\\ell$-round PDS on planar graphs for\n$\\ell=O(\\tfrac{\\log{n}}{\\log{\\log{n}}})$. Finally, we give integer programming\nformulations for $\\ell$-round PDS.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 02:55:52 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Aazami", "Ashkan", ""]]}, {"id": "0802.2157", "submitter": "Shai  Gutner", "authors": "Shai Gutner", "title": "Choice numbers of graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A solution to a problem of Erd\\H{o}s, Rubin and Taylor is obtained by showing\nthat if a graph $G$ is $(a:b)$-choosable, and $c/d > a/b$, then $G$ is not\nnecessarily $(c:d)$-choosable. The simplest case of another problem, stated by\nthe same authors, is settled, proving that every 2-choosable graph is also\n$(4:2)$-choosable. Applying probabilistic methods, an upper bound for the\n$k^{th}$ choice number of a graph is given. We also prove that a directed graph\nwith maximum outdegree $d$ and no odd directed cycle is $(k(d+1):k)$-choosable\nfor every $k \\geq 1$. Other results presented in this article are related to\nthe strong choice number of graphs (a generalization of the strong chromatic\nnumber). We conclude with complexity analysis of some decision problems related\nto graph choosability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 09:05:54 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Gutner", "Shai", ""]]}, {"id": "0802.2184", "submitter": "Jean Cardinal", "authors": "Jean Cardinal, Christophe Dumeunier", "title": "Set Covering Problems with General Objective Functions", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We introduce a parameterized version of set cover that generalizes several\npreviously studied problems. Given a ground set V and a collection of subsets\nS_i of V, a feasible solution is a partition of V such that each subset of the\npartition is included in one of the S_i. The problem involves maximizing the\nmean subset size of the partition, where the mean is the generalized mean of\nparameter p, taken over the elements. For p=-1, the problem is equivalent to\nthe classical minimum set cover problem. For p=0, it is equivalent to the\nminimum entropy set cover problem, introduced by Halperin and Karp. For p=1,\nthe problem includes the maximum-edge clique partition problem as a special\ncase. We prove that the greedy algorithm simultaneously approximates the\nproblem within a factor of (p+1)^1/p for any p in R^+, and that this is the\nbest possible unless P=NP. These results both generalize and simplify previous\nresults for special cases. We also consider the corresponding graph coloring\nproblem, and prove several tractability and inapproximability results. Finally,\nwe consider a further generalization of the set cover problem in which we aim\nat minimizing the sum of some concave function of the part sizes. As an\napplication, we derive an approximation ratio for a Rent-or-Buy set cover\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 11:56:28 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Cardinal", "Jean", ""], ["Dumeunier", "Christophe", ""]]}, {"id": "0802.2228", "submitter": "Sebastian Ordyniak", "authors": "Stephan Kreutzer, Sebastian Ordyniak", "title": "Digraph Decompositions and Monotonicity in Digraph Searching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider monotonicity problems for graph searching games. Variants of\nthese games - defined by the type of moves allowed for the players - have been\nfound to be closely connected to graph decompositions and associated width\nmeasures such as path- or tree-width. Of particular interest is the question\nwhether these games are monotone, i.e. whether the cops can catch a robber\nwithout ever allowing the robber to reach positions that have been cleared\nbefore. The monotonicity problem for graph searching games has intensely been\nstudied in the literature, but for two types of games the problem was left\nunresolved. These are the games on digraphs where the robber is invisible and\nlazy or visible and fast. In this paper, we solve the problems by giving\nexamples showing that both types of games are non-monotone. Graph searching\ngames on digraphs are closely related to recent proposals for digraph\ndecompositions generalising tree-width to directed graphs. These proposals have\npartly been motivated by attempts to develop a structure theory for digraphs\nsimilar to the graph minor theory developed by Robertson and Seymour for\nundirected graphs, and partly by the immense number of algorithmic results\nusing tree-width of undirected graphs and the hope that part of this success\nmight be reproducible on digraphs using a directed tree-width. Unfortunately\nthe number of applications for the digraphs measures introduced so far is still\nsmall. We therefore explore the limits of the algorithmic applicability of\ndigraph decompositions. In particular, we show that various natural candidates\nfor problems that might benefit from digraphs having small directed tree-width\nremain NP-complete even on almost acyclic graphs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 15:44:34 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Kreutzer", "Stephan", ""], ["Ordyniak", "Sebastian", ""]]}, {"id": "0802.2305", "submitter": "Ping Li", "authors": "Ping Li", "title": "Compressed Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM cs.DS cs.LG math.IT", "license": null, "abstract": "  Counting is among the most fundamental operations in computing. For example,\ncounting the pth frequency moment has been a very active area of research, in\ntheoretical computer science, databases, and data mining. When p=1, the task\n(i.e., counting the sum) can be accomplished using a simple counter.\n  Compressed Counting (CC) is proposed for efficiently computing the pth\nfrequency moment of a data stream signal A_t, where 0<p<=2. CC is applicable if\nthe streaming data follow the Turnstile model, with the restriction that at the\ntime t for the evaluation, A_t[i]>= 0, which includes the strict Turnstile\nmodel as a special case. For natural data streams encountered in practice, this\nrestriction is minor.\n  The underly technique for CC is what we call skewed stable random\nprojections, which captures the intuition that, when p=1 a simple counter\nsuffices, and when p = 1+/\\Delta with small \\Delta, the sample complexity of a\ncounter system should be low (continuously as a function of \\Delta). We show at\nsmall \\Delta the sample complexity (number of projections) k = O(1/\\epsilon)\ninstead of O(1/\\epsilon^2).\n  Compressed Counting can serve a basic building block for other tasks in\nstatistics and computing, for example, estimation entropies of data streams,\nparameter estimations using the method of moments and maximum likelihood.\n  Finally, another contribution is an algorithm for approximating the\nlogarithmic norm, \\sum_{i=1}^D\\log A_t[i], and logarithmic distance. The\nlogarithmic distance is useful in machine learning practice with heavy-tailed\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2008 16:42:52 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2008 09:51:09 GMT"}], "update_date": "2008-02-24", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "0802.2418", "submitter": "Jacob Scott", "authors": "Christopher Crutchfield, Zoran Dzunic, Jeremy T. Fineman, David R.\n  Karger, and Jacob Scott", "title": "Improved Approximations for Multiprocessor Scheduling Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents improved approximation algorithms for the problem of\nmultiprocessor scheduling under uncertainty, or SUU, in which the execution of\neach job may fail probabilistically. This problem is motivated by the\nincreasing use of distributed computing to handle large, computationally\nintensive tasks. In the SUU problem we are given n unit-length jobs and m\nmachines, a directed acyclic graph G of precedence constraints among jobs, and\nunrelated failure probabilities q_{ij} for each job j when executed on machine\ni for a single timestep. Our goal is to find a schedule that minimizes the\nexpected makespan, which is the expected time at which all jobs complete.\n  Lin and Rajaraman gave the first approximations for this NP-hard problem for\nthe special cases of independent jobs, precedence constraints forming disjoint\nchains, and precedence constraints forming trees. In this paper, we present\nasymptotically better approximation algorithms. In particular, we give an\nO(loglog min(m,n))-approximation for independent jobs (improving on the\npreviously best O(log n)-approximation). We also give an O(log(n+m) loglog\nmin(m,n))-approximation algorithm for precedence constraints that form disjoint\nchains (improving on the previously best\nO(log(n)log(m)log(n+m)/loglog(n+m))-approximation by a (log n/loglog n)^2\nfactor when n = poly(m). Our algorithm for precedence constraints forming\nchains can also be used as a component for precedence constraints forming\ntrees, yielding a similar improvement over the previously best algorithms for\ntrees.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2008 20:57:17 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2008 02:58:36 GMT"}], "update_date": "2008-02-19", "authors_parsed": [["Crutchfield", "Christopher", ""], ["Dzunic", "Zoran", ""], ["Fineman", "Jeremy T.", ""], ["Karger", "David R.", ""], ["Scott", "Jacob", ""]]}, {"id": "0802.2528", "submitter": "Nitish Korula", "authors": "Chandra Chekuri, Nitish Korula", "title": "Min-Cost 2-Connected Subgraphs With k Terminals", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the k-2VC problem, we are given an undirected graph G with edge costs and\nan integer k; the goal is to find a minimum-cost 2-vertex-connected subgraph of\nG containing at least k vertices. A slightly more general version is obtained\nif the input also specifies a subset S \\subseteq V of terminals and the goal is\nto find a subgraph containing at least k terminals. Closely related to the\nk-2VC problem, and in fact a special case of it, is the k-2EC problem, in which\nthe goal is to find a minimum-cost 2-edge-connected subgraph containing k\nvertices. The k-2EC problem was introduced by Lau et al., who also gave a\npoly-logarithmic approximation for it. No previous approximation algorithm was\nknown for the more general k-2VC problem. We describe an O(\\log n \\log k)\napproximation for the k-2VC problem.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2008 18:34:28 GMT"}], "update_date": "2008-02-19", "authors_parsed": [["Chekuri", "Chandra", ""], ["Korula", "Nitish", ""]]}, {"id": "0802.2612", "submitter": "Sergey Gubin", "authors": "Sergey Gubin", "title": "On Subgraph Isomorphism", "comments": "Simplified, 6 pages", "journal-ref": "Polynomial size asymmetric linear model for Subgraph Isomorphism,\n  Proceedings WCECS 2008, ISBN: 978-988-98671-0-2, pp.241-246", "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article explicitly expresses Subgraph Isomorphism by a polynomial size\nasymmetric linear system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 09:06:40 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2008 22:22:49 GMT"}], "update_date": "2008-11-10", "authors_parsed": [["Gubin", "Sergey", ""]]}, {"id": "0802.2668", "submitter": "Shai  Gutner", "authors": "Shai Gutner", "title": "The complexity of planar graph choosability", "comments": null, "journal-ref": "Discrete Math. 159 (1996), 119-130", "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": null, "abstract": "  A graph $G$ is {\\em $k$-choosable} if for every assignment of a set $S(v)$ of\n$k$ colors to every vertex $v$ of $G$, there is a proper coloring of $G$ that\nassigns to each vertex $v$ a color from $S(v)$. We consider the complexity of\ndeciding whether a given graph is $k$-choosable for some constant $k$. In\nparticular, it is shown that deciding whether a given planar graph is\n4-choosable is NP-hard, and so is the problem of deciding whether a given\nplanar triangle-free graph is 3-choosable. We also obtain simple constructions\nof a planar graph which is not 4-choosable and a planar triangle-free graph\nwhich is not 3-choosable.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 15:26:19 GMT"}], "update_date": "2008-02-20", "authors_parsed": [["Gutner", "Shai", ""]]}, {"id": "0802.2825", "submitter": "Pascal Weil", "authors": "Thomas Thierauf, Fabian Wagner", "title": "The Isomorphism Problem for Planar 3-Connected Graphs is in Unambiguous\n  Logspace", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  The isomorphism problem for planar graphs is known to be efficiently\nsolvable. For planar 3-connected graphs, the isomorphism problem can be solved\nby efficient parallel algorithms, it is in the class $AC^1$. In this paper we\nimprove the upper bound for planar 3-connected graphs to unambiguous logspace,\nin fact to $UL \\cap coUL$. As a consequence of our method we get that the\nisomorphism problem for oriented graphs is in $NL$. We also show that the\nproblems are hard for $L$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:03:55 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Thierauf", "Thomas", ""], ["Wagner", "Fabian", ""]]}, {"id": "0802.2826", "submitter": "Pascal Weil", "authors": "Antti Valmari, Petri Lehtinen", "title": "Efficient Minimization of DFAs with Partial Transition Functions", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": null, "abstract": "  Let PT-DFA mean a deterministic finite automaton whose transition relation is\na partial function. We present an algorithm for minimizing a PT-DFA in $O(m \\lg\nn)$ time and $O(m+n+\\alpha)$ memory, where $n$ is the number of states, $m$ is\nthe number of defined transitions, and $\\alpha$ is the size of the alphabet.\nTime consumption does not depend on $\\alpha$, because the $\\alpha$ term arises\nfrom an array that is accessed at random and never initialized. It is not\nneeded, if transitions are in a suitable order in the input. The algorithm uses\ntwo instances of an array-based data structure for maintaining a refinable\npartition. Its operations are all amortized constant time. One instance\nrepresents the classical blocks and the other a partition of transitions. Our\nmeasurements demonstrate the speed advantage of our algorithm on PT-DFAs over\nan $O(\\alpha n \\lg n)$ time, $O(\\alpha n)$ memory algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:04:34 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Valmari", "Antti", ""], ["Lehtinen", "Petri", ""]]}, {"id": "0802.2827", "submitter": "Pascal Weil", "authors": "Johan M. M. Van Rooij, Hans L. Bodlaender", "title": "Design by Measure and Conquer, A Faster Exact Algorithm for Dominating\n  Set", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  The measure and conquer approach has proven to be a powerful tool to analyse\nexact algorithms for combinatorial problems, like Dominating Set and\nIndependent Set. In this paper, we propose to use measure and conquer also as a\ntool in the design of algorithms. In an iterative process, we can obtain a\nseries of branch and reduce algorithms. A mathematical analysis of an algorithm\nin the series with measure and conquer results in a quasiconvex programming\nproblem. The solution by computer to this problem not only gives a bound on the\nrunning time, but also can give a new reduction rule, thus giving a new,\npossibly faster algorithm. This makes design by measure and conquer a form of\ncomputer aided algorithm design. When we apply the methodology to a Set Cover\nmodelling of the Dominating Set problem, we obtain the currently fastest known\nexact algorithms for Dominating Set: an algorithm that uses $O(1.5134^n)$ time\nand polynomial space, and an algorithm that uses $O(1.5063^n)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:05:58 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Van Rooij", "Johan M. M.", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "0802.2829", "submitter": "Pascal Weil", "authors": "Maxime Crochemore (IGM), Lucian Ilie", "title": "Understanding maximal repetitions in strings", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": null, "abstract": "  The cornerstone of any algorithm computing all repetitions in a string of\nlength n in O(n) time is the fact that the number of runs (or maximal\nrepetitions) is O(n). We give a simple proof of this result. As a consequence\nof our approach, the stronger result concerning the linearity of the sum of\nexponents of all runs follows easily.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:10:15 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Crochemore", "Maxime", "", "IGM"], ["Ilie", "Lucian", ""]]}, {"id": "0802.2832", "submitter": "Pascal Weil", "authors": "Zvi Lotker, Boaz Patt-Shamir, Dror Rawitz", "title": "Rent, Lease or Buy: Randomized Algorithms for Multislope Ski Rental", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  In the Multislope Ski Rental problem, the user needs a certain resource for\nsome unknown period of time. To use the resource, the user must subscribe to\none of several options, each of which consists of a one-time setup cost\n(``buying price''), and cost proportional to the duration of the usage\n(``rental rate''). The larger the price, the smaller the rent. The actual usage\ntime is determined by an adversary, and the goal of an algorithm is to minimize\nthe cost by choosing the best option at any point in time. Multislope Ski\nRental is a natural generalization of the classical Ski Rental problem (where\nthe only options are pure rent and pure buy), which is one of the fundamental\nproblems of online computation. The Multislope Ski Rental problem is an\nabstraction of many problems where online decisions cannot be modeled by just\ntwo options, e.g., power management in systems which can be shut down in parts.\nIn this paper we study randomized algorithms for Multislope Ski Rental. Our\nresults include the best possible online randomized strategy for any additive\ninstance, where the cost of switching from one option to another is the\ndifference in their buying prices; and an algorithm that produces an\n$e$-competitive randomized strategy for any (non-additive) instance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:13:19 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Lotker", "Zvi", ""], ["Patt-Shamir", "Boaz", ""], ["Rawitz", "Dror", ""]]}, {"id": "0802.2834", "submitter": "Pascal Weil", "authors": "Andreas Bj\\\"orklund, Thore Husfeldt, Petteri Kaski (HIIT), Mikko\n  Koivisto (HIIT)", "title": "Trimmed Moebius Inversion and Graphs of Bounded Degree", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": null, "abstract": "  We study ways to expedite Yates's algorithm for computing the zeta and\nMoebius transforms of a function defined on the subset lattice. We develop a\ntrimmed variant of Moebius inversion that proceeds point by point, finishing\nthe calculation at a subset before considering its supersets. For an\n$n$-element universe $U$ and a family $\\scr F$ of its subsets, trimmed Moebius\ninversion allows us to compute the number of packings, coverings, and\npartitions of $U$ with $k$ sets from $\\scr F$ in time within a polynomial\nfactor (in $n$) of the number of supersets of the members of $\\scr F$. Relying\non an intersection theorem of Chung et al. (1986) to bound the sizes of set\nfamilies, we apply these ideas to well-studied combinatorial optimisation\nproblems on graphs of maximum degree $\\Delta$. In particular, we show how to\ncompute the Domatic Number in time within a polynomial factor of\n$(2^{\\Delta+1-2)^{n/(\\Delta+1)$ and the Chromatic Number in time within a\npolynomial factor of $(2^{\\Delta+1-\\Delta-1)^{n/(\\Delta+1)$. For any constant\n$\\Delta$, these bounds are $O\\bigl((2-\\epsilon)^n\\bigr)$ for $\\epsilon>0$\nindependent of the number of vertices $n$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:15:00 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Bj\u00f6rklund", "Andreas", "", "HIIT"], ["Husfeldt", "Thore", "", "HIIT"], ["Kaski", "Petteri", "", "HIIT"], ["Koivisto", "Mikko", "", "HIIT"]]}, {"id": "0802.2836", "submitter": "Pascal Weil", "authors": "Vincenzo Bonifaci, Peter Korteweg, Alberto Marchetti-Spaccamela, Leen\n  Stougie (CWI)", "title": "Minimizing Flow Time in the Wireless Gathering Problem", "comments": null, "journal-ref": "ACM Transactions on Algorithms 7(3): 33:1-33:20 (2011)", "doi": "10.1145/1978782.1978788", "report-no": null, "categories": "cs.DS cs.NI", "license": null, "abstract": "  We address the problem of efficient data gathering in a wireless network\nthrough multi-hop communication. We focus on the objective of minimizing the\nmaximum flow time of a data packet. We prove that no polynomial time algorithm\nfor this problem can have approximation ratio less than $\\Omega(m^{1/3)$ when\n$m$ packets have to be transmitted, unless $P = NP$. We then use resource\naugmentation to assess the performance of a FIFO-like strategy. We prove that\nthis strategy is 5-speed optimal, i.e., its cost remains within the optimal\ncost if we allow the algorithm to transmit data at a speed 5 times higher than\nthat of the optimal solution we compare to.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:18:24 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Bonifaci", "Vincenzo", "", "CWI"], ["Korteweg", "Peter", "", "CWI"], ["Marchetti-Spaccamela", "Alberto", "", "CWI"], ["Stougie", "Leen", "", "CWI"]]}, {"id": "0802.2838", "submitter": "Pascal Weil", "authors": "Chandan Saha", "title": "Factoring Polynomials over Finite Fields using Balance Test", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": null, "abstract": "  We study the problem of factoring univariate polynomials over finite fields.\nUnder the assumption of the Extended Riemann Hypothesis (ERH), (Gao, 2001)\ndesigned a polynomial time algorithm that fails to factor only if the input\npolynomial satisfies a strong symmetry property, namely square balance. In this\npaper, we propose an extension of Gao's algorithm that fails only under an even\nstronger symmetry property. We also show that our property can be used to\nimprove the time complexity of best deterministic algorithms on most input\npolynomials. The property also yields a new randomized polynomial time\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:18:52 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Saha", "Chandan", ""]]}, {"id": "0802.2841", "submitter": "Pascal Weil", "authors": "Patrick Briest, Martin Hoefer, Piotr Krysta", "title": "Stackelberg Network Pricing Games", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": null, "abstract": "  We study a multi-player one-round game termed Stackelberg Network Pricing\nGame, in which a leader can set prices for a subset of $m$ priceable edges in a\ngraph. The other edges have a fixed cost. Based on the leader's decision one or\nmore followers optimize a polynomial-time solvable combinatorial minimization\nproblem and choose a minimum cost solution satisfying their requirements based\non the fixed costs and the leader's prices. The leader receives as revenue the\ntotal amount of prices paid by the followers for priceable edges in their\nsolutions, and the problem is to find revenue maximizing prices. Our model\nextends several known pricing problems, including single-minded and unit-demand\npricing, as well as Stackelberg pricing for certain follower problems like\nshortest path or minimum spanning tree. Our first main result is a tight\nanalysis of a single-price algorithm for the single follower game, which\nprovides a $(1+\\epsilon) \\log m$-approximation for any $\\epsilon >0$. This can\nbe extended to provide a $(1+\\epsilon)(\\log k + \\log m)$-approximation for the\ngeneral problem and $k$ followers. The latter result is essentially best\npossible, as the problem is shown to be hard to approximate within\n$\\mathcal{O(\\log^\\epsilon k + \\log^\\epsilon m)$. If followers have demands, the\nsingle-price algorithm provides a $(1+\\epsilon)m^2$-approximation, and the\nproblem is hard to approximate within $\\mathcal{O(m^\\epsilon)$ for some\n$\\epsilon >0$. Our second main result is a polynomial time algorithm for\nrevenue maximization in the special case of Stackelberg bipartite vertex cover,\nwhich is based on non-trivial max-flow and LP-duality techniques. Our results\ncan be extended to provide constant-factor approximations for any constant\nnumber of followers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:19:33 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Briest", "Patrick", ""], ["Hoefer", "Martin", ""], ["Krysta", "Piotr", ""]]}, {"id": "0802.2843", "submitter": "Pascal Weil", "authors": "Joshua Brody, Amit Chakrabarti", "title": "Sublinear Communication Protocols for Multi-Party Pointer Jumping and a\n  Related Lower Bound", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": null, "abstract": "  We study the one-way number-on-the-forehead (NOF) communication complexity of\nthe $k$-layer pointer jumping problem with $n$ vertices per layer. This classic\nproblem, which has connections to many aspects of complexity theory, has seen a\nrecent burst of research activity, seemingly preparing the ground for an\n$\\Omega(n)$ lower bound, for constant $k$. Our first result is a surprising\nsublinear -- i.e., $o(n)$ -- upper bound for the problem that holds for $k \\ge\n3$, dashing hopes for such a lower bound. A closer look at the protocol\nachieving the upper bound shows that all but one of the players involved are\ncollapsing, i.e., their messages depend only on the composition of the layers\nahead of them. We consider protocols for the pointer jumping problem where all\nplayers are collapsing. Our second result shows that a strong $n - O(\\log n)$\nlower bound does hold in this case. Our third result is another upper bound\nshowing that nontrivial protocols for (a non-Boolean version of) pointer\njumping are possible even when all players are collapsing. Our lower bound\nresult uses a novel proof technique, different from those of earlier lower\nbounds that had an information-theoretic flavor. We hope this is useful in\nfurther study of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:20:14 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Brody", "Joshua", ""], ["Chakrabarti", "Amit", ""]]}, {"id": "0802.2845", "submitter": "Pascal Weil", "authors": "Eric Colin De Verdi\\`ere (LIENS), Alexander Schrijver (CWI)", "title": "Shortest Vertex-Disjoint Two-Face Paths in Planar Graphs", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": null, "abstract": "  Let $G$ be a directed planar graph of complexity $n$, each arc having a\nnonnegative length. Let $s$ and $t$ be two distinct faces of $G$; let\n$s_1,...,s_k$ be vertices incident with $s$; let $t_1,...,t_k$ be vertices\nincident with $t$. We give an algorithm to compute $k$ pairwise vertex-disjoint\npaths connecting the pairs $(s_i,t_i)$ in $G$, with minimal total length, in\n$O(kn\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:20:48 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["De Verdi\u00e8re", "Eric Colin", "", "LIENS"], ["Schrijver", "Alexander", "", "CWI"]]}, {"id": "0802.2846", "submitter": "Pascal Weil", "authors": "Atlas F. Cook IV, Carola Wenk", "title": "Geodesic Fr\\'echet Distance Inside a Simple Polygon", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": null, "abstract": "  We unveil an alluring alternative to parametric search that applies to both\nthe non-geodesic and geodesic Fr\\'echet optimization problems. This randomized\napproach is based on a variant of red-blue intersections and is appealing due\nto its elegance and practical efficiency when compared to parametric search. We\npresent the first algorithm for the geodesic Fr\\'echet distance between two\npolygonal curves $A$ and $B$ inside a simple bounding polygon $P$. The geodesic\nFr\\'echet decision problem is solved almost as fast as its non-geodesic sibling\nand requires $O(N^{2\\log k)$ time and $O(k+N)$ space after $O(k)$\npreprocessing, where $N$ is the larger of the complexities of $A$ and $B$ and\n$k$ is the complexity of $P$. The geodesic Fr\\'echet optimization problem is\nsolved by a randomized approach in $O(k+N^{2\\log kN\\log N)$ expected time and\n$O(k+N^{2)$ space. This runtime is only a logarithmic factor larger than the\nstandard non-geodesic Fr\\'echet algorithm (Alt and Godau 1995). Results are\nalso presented for the geodesic Fr\\'echet distance in a polygonal domain with\nobstacles and the geodesic Hausdorff distance for sets of points or sets of\nline segments inside a simple polygon $P$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:21:19 GMT"}], "update_date": "2008-05-21", "authors_parsed": [["Cook", "Atlas F.", "IV"], ["Wenk", "Carola", ""]]}, {"id": "0802.2847", "submitter": "Pascal Weil", "authors": "Ulrich Meyer", "title": "On Dynamic Breadth-First Search in External-Memory", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We provide the first non-trivial result on dynamic breadth-first search (BFS)\nin external-memory: For general sparse undirected graphs of initially $n$ nodes\nand O(n) edges and monotone update sequences of either $\\Theta(n)$ edge\ninsertions or $\\Theta(n)$ edge deletions, we prove an amortized\nhigh-probability bound of $O(n/B^{2/3}+\\sort(n)\\cdot \\log B)$ I/Os per update.\nIn contrast, the currently best approach for static BFS on sparse undirected\ngraphs requires $\\Omega(n/B^{1/2}+\\sort(n))$ I/Os.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:21:21 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Meyer", "Ulrich", ""]]}, {"id": "0802.2850", "submitter": "Pascal Weil", "authors": "Samir Datta, Raghav Kulkarni, Sambuddha Roy (IBM IRL)", "title": "Deterministically Isolating a Perfect Matching in Bipartite Planar\n  Graphs", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": null, "abstract": "  We present a deterministic way of assigning small (log bit) weights to the\nedges of a bipartite planar graph so that the minimum weight perfect matching\nbecomes unique. The isolation lemma as described in (Mulmuley et al. 1987)\nachieves the same for general graphs using a randomized weighting scheme,\nwhereas we can do it deterministically when restricted to bipartite planar\ngraphs. As a consequence, we reduce both decision and construction versions of\nthe matching problem to testing whether a matrix is singular, under the promise\nthat its determinant is 0 or 1, thus obtaining a highly parallel SPL algorithm\nfor bipartite planar graphs. This improves the earlier known bounds of\nnon-uniform SPL by (Allender et al. 1999) and $NC^2$ by (Miller and Naor 1995,\nMahajan and Varadarajan 2000). It also rekindles the hope of obtaining a\ndeterministic parallel algorithm for constructing a perfect matching in\nnon-bipartite planar graphs, which has been open for a long time. Our\ntechniques are elementary and simple.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:21:52 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Datta", "Samir", "", "IBM IRL"], ["Kulkarni", "Raghav", "", "IBM IRL"], ["Roy", "Sambuddha", "", "IBM IRL"]]}, {"id": "0802.2851", "submitter": "Pascal Weil", "authors": "Pinyan Lu, Changyuan Yu", "title": "An Improved Randomized Truthful Mechanism for Scheduling Unrelated\n  Machines", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We study the scheduling problem on unrelated machines in the mechanism design\nsetting. This problem was proposed and studied in the seminal paper (Nisan and\nRonen 1999), where they gave a 1.75-approximation randomized truthful mechanism\nfor the case of two machines. We improve this result by a 1.6737-approximation\nrandomized truthful mechanism. We also generalize our result to a\n$0.8368m$-approximation mechanism for task scheduling with $m$ machines, which\nimprove the previous best upper bound of $0.875m(Mu'alem and Schapira 2007).\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:22:30 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Lu", "Pinyan", ""], ["Yu", "Changyuan", ""]]}, {"id": "0802.2852", "submitter": "Pascal Weil", "authors": "Martin Dietzfelbinger, Jonathan E. Rowe, Ingo Wegener, Philipp Woelfel", "title": "Tight Bounds for Blind Search on the Integers", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We analyze a simple random process in which a token is moved in the interval\n$A=\\{0,...,n\\$: Fix a probability distribution $\\mu$ over $\\{1,...,n\\$.\nInitially, the token is placed in a random position in $A$. In round $t$, a\nrandom value $d$ is chosen according to $\\mu$. If the token is in position\n$a\\geq d$, then it is moved to position $a-d$. Otherwise it stays put. Let $T$\nbe the number of rounds until the token reaches position 0. We show tight\nbounds for the expectation of $T$ for the optimal distribution $\\mu$. More\nprecisely, we show that $\\min_\\mu\\{E_\\mu(T)\\=\\Theta((\\log n)^2)$. For the\nproof, a novel potential function argument is introduced. The research is\nmotivated by the problem of approximating the minimum of a continuous function\nover $[0,1]$ with a ``blind'' optimization strategy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:22:33 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Dietzfelbinger", "Martin", ""], ["Rowe", "Jonathan E.", ""], ["Wegener", "Ingo", ""], ["Woelfel", "Philipp", ""]]}, {"id": "0802.2854", "submitter": "Pascal Weil", "authors": "Thomas Erlebach, Torben Hagerup, Klaus Jansen, Moritz Minzlaff,\n  Alexander Wolff", "title": "Trimming of Graphs, with Application to Point Labeling", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": null, "abstract": "  For $t,g>0$, a vertex-weighted graph of total weight $W$ is $(t,g)$-trimmable\nif it contains a vertex-induced subgraph of total weight at least $(1-1/t)W$\nand with no simple path of more than $g$ edges. A family of graphs is trimmable\nif for each constant $t>0$, there is a constant $g=g(t)$ such that every\nvertex-weighted graph in the family is $(t,g)$-trimmable. We show that every\nfamily of graphs of bounded domino treewidth is trimmable. This implies that\nevery family of graphs of bounded degree is trimmable if the graphs in the\nfamily have bounded treewidth or are planar. Based on this result, we derive a\npolynomial-time approximation scheme for the problem of labeling weighted\npoints with nonoverlapping sliding labels of unit height and given lengths so\nas to maximize the total weight of the labeled points. This settles one of the\nlast major open questions in the theory of map labeling.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:23:38 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Erlebach", "Thomas", ""], ["Hagerup", "Torben", ""], ["Jansen", "Klaus", ""], ["Minzlaff", "Moritz", ""], ["Wolff", "Alexander", ""]]}, {"id": "0802.2855", "submitter": "Pascal Weil", "authors": "Thomas Erlebach, Michael Hoffmann, Danny Krizanc, Mat\\'us Mihal'\\'ak,\n  Rajeev Raman", "title": "Computing Minimum Spanning Trees with Uncertainty", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We consider the minimum spanning tree problem in a setting where information\nabout the edge weights of the given graph is uncertain. Initially, for each\nedge $e$ of the graph only a set $A_e$, called an uncertainty area, that\ncontains the actual edge weight $w_e$ is known. The algorithm can `update' $e$\nto obtain the edge weight $w_e \\in A_e$. The task is to output the edge set of\na minimum spanning tree after a minimum number of updates. An algorithm is\n$k$-update competitive if it makes at most $k$ times as many updates as the\noptimum. We present a 2-update competitive algorithm if all areas $A_e$ are\nopen or trivial, which is the best possible among deterministic algorithms. The\ncondition on the areas $A_e$ is to exclude degenerate inputs for which no\nconstant update competitive algorithm can exist. Next, we consider a setting\nwhere the vertices of the graph correspond to points in Euclidean space and the\nweight of an edge is equal to the distance of its endpoints. The location of\neach point is initially given as an uncertainty area, and an update reveals the\nexact location of the point. We give a general relation between the edge\nuncertainty and the vertex uncertainty versions of a problem and use it to\nderive a 4-update competitive algorithm for the minimum spanning tree problem\nin the vertex uncertainty model. Again, we show that this is best possible\namong deterministic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:24:10 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Erlebach", "Thomas", ""], ["Hoffmann", "Michael", ""], ["Krizanc", "Danny", ""], ["Mihal'\u00e1k", "Mat\u00fas", ""], ["Raman", "Rajeev", ""]]}, {"id": "0802.2856", "submitter": "Pascal Weil", "authors": "Javier Esparza, Stefan Kiefer, Michael Luttenberger", "title": "Convergence Thresholds of Newton's Method for Monotone Polynomial\n  Equations", "comments": "version 2 deposited February 29, after the end of the STACS\n  conference. Two minor mistakes corrected", "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.NA math.IT", "license": null, "abstract": "  Monotone systems of polynomial equations (MSPEs) are systems of fixed-point\nequations $X_1 = f_1(X_1, ..., X_n),$ $..., X_n = f_n(X_1, ..., X_n)$ where\neach $f_i$ is a polynomial with positive real coefficients. The question of\ncomputing the least non-negative solution of a given MSPE $\\vec X = \\vec f(\\vec\nX)$ arises naturally in the analysis of stochastic models such as stochastic\ncontext-free grammars, probabilistic pushdown automata, and back-button\nprocesses. Etessami and Yannakakis have recently adapted Newton's iterative\nmethod to MSPEs. In a previous paper we have proved the existence of a\nthreshold $k_{\\vec f}$ for strongly connected MSPEs, such that after $k_{\\vec\nf}$ iterations of Newton's method each new iteration computes at least 1 new\nbit of the solution. However, the proof was purely existential. In this paper\nwe give an upper bound for $k_{\\vec f}$ as a function of the minimal component\nof the least fixed-point $\\mu\\vec f$ of $\\vec f(\\vec X)$. Using this result we\nshow that $k_{\\vec f}$ is at most single exponential resp. linear for strongly\nconnected MSPEs derived from probabilistic pushdown automata resp. from\nback-button processes. Further, we prove the existence of a threshold for\narbitrary MSPEs after which each new iteration computes at least $1/w2^h$ new\nbits of the solution, where $w$ and $h$ are the width and height of the DAG of\nstrongly connected components.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:24:39 GMT"}, {"version": "v2", "created": "Fri, 29 Feb 2008 07:31:48 GMT"}], "update_date": "2008-02-29", "authors_parsed": [["Esparza", "Javier", ""], ["Kiefer", "Stefan", ""], ["Luttenberger", "Michael", ""]]}, {"id": "0802.2857", "submitter": "Pascal Weil", "authors": "Shachar Lovett", "title": "Lower bounds for adaptive linearity tests", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": null, "abstract": "  Linearity tests are randomized algorithms which have oracle access to the\ntruth table of some function f, and are supposed to distinguish between linear\nfunctions and functions which are far from linear. Linearity tests were first\nintroduced by (Blum, Luby and Rubenfeld, 1993), and were later used in the PCP\ntheorem, among other applications. The quality of a linearity test is described\nby its correctness c - the probability it accepts linear functions, its\nsoundness s - the probability it accepts functions far from linear, and its\nquery complexity q - the number of queries it makes. Linearity tests were\nstudied in order to decrease the soundness of linearity tests, while keeping\nthe query complexity small (for one reason, to improve PCP constructions).\nSamorodnitsky and Trevisan (Samorodnitsky and Trevisan 2000) constructed the\nComplete Graph Test, and prove that no Hyper Graph Test can perform better than\nthe Complete Graph Test. Later in (Samorodnitsky and Trevisan 2006) they prove,\namong other results, that no non-adaptive linearity test can perform better\nthan the Complete Graph Test. Their proof uses the algebraic machinery of the\nGowers Norm. A result by (Ben-Sasson, Harsha and Raskhodnikova 2005) allows to\ngeneralize this lower bound also to adaptive linearity tests. We also prove the\nsame optimal lower bound for adaptive linearity test, but our proof technique\nis arguably simpler and more direct than the one used in (Samorodnitsky and\nTrevisan 2006). We also study, like (Samorodnitsky and Trevisan 2006), the\nbehavior of linearity tests on quadratic functions. However, instead of\nanalyzing the Gowers Norm of certain functions, we provide a more direct\ncombinatorial proof, studying the behavior of linearity tests on random\nquadratic functions...\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:26:40 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Lovett", "Shachar", ""]]}, {"id": "0802.2864", "submitter": "Pascal Weil", "authors": "Iyad A. Kanj, Ljubomir Perkovic", "title": "On Geometric Spanners of Euclidean and Unit Disk Graphs", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We consider the problem of constructing bounded-degree planar geometric\nspanners of Euclidean and unit-disk graphs. It is well known that the Delaunay\nsubgraph is a planar geometric spanner with stretch factor $C_{del\\approx\n2.42$; however, its degree may not be bounded. Our first result is a very\nsimple linear time algorithm for constructing a subgraph of the Delaunay graph\nwith stretch factor $\\rho =1+2\\pi(k\\cos{\\frac{\\pi{k)^{-1$ and degree bounded by\n$k$, for any integer parameter $k\\geq 14$. This result immediately implies an\nalgorithm for constructing a planar geometric spanner of a Euclidean graph with\nstretch factor $\\rho \\cdot C_{del$ and degree bounded by $k$, for any integer\nparameter $k\\geq 14$. Moreover, the resulting spanner contains a Euclidean\nMinimum Spanning Tree (EMST) as a subgraph. Our second contribution lies in\ndeveloping the structural results necessary to transfer our analysis and\nalgorithm from Euclidean graphs to unit disk graphs, the usual model for\nwireless ad-hoc networks. We obtain a very simple distributed, {\\em\nstrictly-localized algorithm that, given a unit disk graph embedded in the\nplane, constructs a geometric spanner with the above stretch factor and degree\nbound, and also containing an EMST as a subgraph. The obtained results\ndramatically improve the previous results in all aspects, as shown in the\npaper.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:36:52 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Kanj", "Iyad A.", ""], ["Perkovic", "Ljubomir", ""]]}, {"id": "0802.2867", "submitter": "Pascal Weil", "authors": "Viet Tung Hoang, Wing-Kin Sung", "title": "Fixed Parameter Polynomial Time Algorithms for Maximum Agreement and\n  Compatible Supertrees", "comments": null, "journal-ref": "Dans Proceedings of the 25th Annual Symposium on the Theoretical\n  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)", "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  Consider a set of labels $L$ and a set of trees ${\\mathcal T} = \\{{\\mathcal\nT}^{(1), {\\mathcal T}^{(2), ..., {\\mathcal T}^{(k) \\$ where each tree\n${\\mathcal T}^{(i)$ is distinctly leaf-labeled by some subset of $L$. One\nfundamental problem is to find the biggest tree (denoted as supertree) to\nrepresent $\\mathcal T}$ which minimizes the disagreements with the trees in\n${\\mathcal T}$ under certain criteria. This problem finds applications in\nphylogenetics, database, and data mining. In this paper, we focus on two\nparticular supertree problems, namely, the maximum agreement supertree problem\n(MASP) and the maximum compatible supertree problem (MCSP). These two problems\nare known to be NP-hard for $k \\geq 3$. This paper gives the first polynomial\ntime algorithms for both MASP and MCSP when both $k$ and the maximum degree $D$\nof the trees are constant.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2008 14:38:47 GMT"}], "update_date": "2008-02-21", "authors_parsed": [["Hoang", "Viet Tung", ""], ["Sung", "Wing-Kin", ""]]}, {"id": "0802.3448", "submitter": "Haim Kaplan", "authors": "Edith Cohen and Haim Kaplan", "title": "Sketch-Based Estimation of Subpopulation-Weight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.NI cs.PF", "license": null, "abstract": "  Summaries of massive data sets support approximate query processing over the\noriginal data. A basic aggregate over a set of records is the weight of\nsubpopulations specified as a predicate over records' attributes. Bottom-k\nsketches are a powerful summarization format of weighted items that includes\npriority sampling and the classic weighted sampling without replacement. They\ncan be computed efficiently for many representations of the data including\ndistributed databases and data streams.\n  We derive novel unbiased estimators and efficient confidence bounds for\nsubpopulation weight. Our estimators and bounds are tailored by distinguishing\nbetween applications (such as data streams) where the total weight of the\nsketched set can be computed by the summarization algorithm without a\nsignificant use of additional resources, and applications (such as sketches of\nnetwork neighborhoods) where this is not the case.\n  Our rigorous derivations are based on clever applications of the\nHorvitz-Thompson estimator, and are complemented by efficient computational\nmethods. We demonstrate their benefit on a wide range of Pareto distributions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2008 15:25:04 GMT"}], "update_date": "2008-02-26", "authors_parsed": [["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "0802.3881", "submitter": "Jorge Sousa Pinto", "authors": "Jos\\'e Bacelar Almeida, Jorge Sousa Pinto", "title": "Deriving Sorting Algorithms", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": "DI-PURe-06.04.01", "categories": "cs.DS cs.LO", "license": null, "abstract": "  This paper proposes new derivations of three well-known sorting algorithms,\nin their functional formulation. The approach we use is based on three main\ningredients: first, the algorithms are derived from a simpler algorithm, i.e.\nthe specification is already a solution to the problem (in this sense our\nderivations are program transformations). Secondly, a mixture of inductive and\ncoinductive arguments are used in a uniform, algebraic style in our reasoning.\nFinally, the approach uses structural invariants so as to strengthen the\nequational reasoning with logical arguments that cannot be captured in the\nalgebraic framework.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2008 19:47:57 GMT"}], "update_date": "2008-02-27", "authors_parsed": [["Almeida", "Jos\u00e9 Bacelar", ""], ["Pinto", "Jorge Sousa", ""]]}, {"id": "0802.4040", "submitter": "Stephan Mertens", "authors": "Stefan Boettcher, Stephan Mertens", "title": "Analysis of the Karmarkar-Karp Differencing Algorithm", "comments": "9 pages, 8 figures; minor changes", "journal-ref": "European Physics Journal B 65, 131-140 (2008)", "doi": "10.1140/epjb/e2008-00320-9", "report-no": null, "categories": "cs.NA cond-mat.dis-nn cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Karmarkar-Karp differencing algorithm is the best known polynomial time\nheuristic for the number partitioning problem, fundamental in both theoretical\ncomputer science and statistical physics. We analyze the performance of the\ndifferencing algorithm on random instances by mapping it to a nonlinear rate\nequation. Our analysis reveals strong finite size effects that explain why the\nprecise asymptotics of the differencing solution is hard to establish by\nsimulations. The asymptotic series emerging from the rate equation satisfies\nall known bounds on the Karmarkar-Karp algorithm and projects a scaling\n$n^{-c\\ln n}$, where $c=1/(2\\ln2)=0.7213...$. Our calculations reveal subtle\nrelations between the algorithm and Fibonacci-like sequences, and we establish\nan explicit identity to that effect.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2008 17:24:07 GMT"}, {"version": "v2", "created": "Fri, 3 Oct 2008 09:48:52 GMT"}], "update_date": "2008-10-03", "authors_parsed": [["Boettcher", "Stefan", ""], ["Mertens", "Stephan", ""]]}, {"id": "0802.4244", "submitter": "Dimitris Papamichail", "authors": "Christos Tryfonas, Dimitris Papamichail, Andrew Mehler, Steven Skiena", "title": "Call Admission Control Algorithm for pre-stored VBR video streams", "comments": "12 pages, 9 figures, includes appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We examine the problem of accepting a new request for a pre-stored VBR video\nstream that has been smoothed using any of the smoothing algorithms found in\nthe literature. The output of these algorithms is a piecewise constant-rate\nschedule for a Variable Bit-Rate (VBR) stream. The schedule guarantees that the\ndecoder buffer does not overflow or underflow. The problem addressed in this\npaper is the determination of the minimal time displacement of each new\nrequested VBR stream so that it can be accomodated by the network and/or the\nvideo server without overbooking the committed traffic. We prove that this\ncall-admission control problem for multiple requested VBR streams is\nNP-complete and inapproximable within a constant factor, by reducing it from\nthe VERTEX COLOR problem. We also present a deterministic morphology-sensitive\nalgorithm that calculates the minimal time displacement of a VBR stream\nrequest. The complexity of the proposed algorithm make it suitable for\nreal-time determination of the time displacement parameter during the call\nadmission phase.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2008 17:45:03 GMT"}], "update_date": "2008-02-29", "authors_parsed": [["Tryfonas", "Christos", ""], ["Papamichail", "Dimitris", ""], ["Mehler", "Andrew", ""], ["Skiena", "Steven", ""]]}, {"id": "0802.4325", "submitter": "Mirela Damian", "authors": "Mirela Damian", "title": "A Simple Yao-Yao-Based Spanner of Bounded Degree", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a standing open question to decide whether the Yao-Yao structure for\nunit disk graphs (UDGs) is a length spanner of not. This question is highly\nrelevant to the topology control problem for wireless ad hoc networks. In this\npaper we make progress towards resolving this question by showing that the\nYao-Yao structure is a length spanner for UDGs of bounded aspect ratio. We also\npropose a new local algorithm, called Yao-Sparse-Sink, based on the Yao-Sink\nmethod introduced by Li, Wan, Wang and Frieder, that computes a (1+e)-spanner\nof bounded degree for a given UDG and for given e > 0. The Yao-Sparse-Sink\nmethod enables an efficient local computation of sparse sink trees. Finally, we\nshow that all these structures for UDGs -- Yao, Yao-Yao, Yao-Sink and\nYao-Sparse-Sink -- have arbitrarily large weight.\n", "versions": [{"version": "v1", "created": "Fri, 29 Feb 2008 14:39:59 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2008 14:40:40 GMT"}], "update_date": "2008-04-04", "authors_parsed": [["Damian", "Mirela", ""]]}]