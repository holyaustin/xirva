[{"id": "1207.0043", "submitter": "Bundit Laekhanukit", "authors": "Bundit Laekhanukit, Adrian Vetta, and Gordon Wilfong", "title": "Routing Regardless of Network Stability", "comments": "ESA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effectiveness of packet routing in this model for the broad\nclass next-hop preferences with filtering. Here each node v has a filtering\nlist D(v) consisting of nodes it does not want its packets to route through.\nAcceptable paths (those that avoid nodes in the filtering list) are ranked\naccording to the next-hop, that is, the neighbour of v that the path begins\nwith. On the negative side, we present a strong inapproximability result. For\nfiltering lists of cardinality at most one, given a network in which an\nequilibrium is guaranteed to exist, it is NP-hard to approximate the maximum\nnumber of packets that can be routed to within a factor of O(n^{1-\\epsilon}),\nfor any constant \\epsilon >0. On the positive side, we give algorithms to show\nthat in two fundamental cases every packet will eventually route with\nprobability one. The first case is when each node's filtering list contains\nonly itself, that is, D(v)={v}. Moreover, with positive probability every\npacket will be routed before the control plane reaches an equilibrium. The\nsecond case is when all the filtering lists are empty, that is,\n$\\mathcal{D}(v)=\\emptyset$. Thus, with probability one packets will route even\nwhen the nodes don't care if their packets cycle! Furthermore, with probability\none every packet will route even when the control plane has em no equilibrium\nat all.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2012 04:35:52 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 21:48:00 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Laekhanukit", "Bundit", ""], ["Vetta", "Adrian", ""], ["Wilfong", "Gordon", ""]]}, {"id": "1207.0240", "submitter": "Robert Georges", "authors": "Robert Georges, Frank Hoffmann, Klaus Kriegel (Freie Universit\\\"at\n  Berlin, Germany)", "title": "Online Exploration of Polygons with Holes", "comments": "16 pages, 9 figures, submitted to WAOA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online strategies for autonomous mobile robots with vision to\nexplore unknown polygons with at most h holes. Our main contribution is an\n(h+c_0)!-competitive strategy for such polygons under the assumption that each\nhole is marked with a special color, where c_0 is a universal constant. The\nstrategy is based on a new hybrid approach. Furthermore, we give a new lower\nbound construction for small h.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 19:27:57 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Georges", "Robert", "", "Freie Universit\u00e4t\n  Berlin, Germany"], ["Hoffmann", "Frank", "", "Freie Universit\u00e4t\n  Berlin, Germany"], ["Kriegel", "Klaus", "", "Freie Universit\u00e4t\n  Berlin, Germany"]]}, {"id": "1207.0271", "submitter": "Shuxin Cai Mr.", "authors": "Shuxin Cai, Wenguo Yang, Yaohua Tang", "title": "Approximating Soft-Capacitated Facility Location Problem With\n  Uncertainty", "comments": "This preliminary version has been withdrawn by the author due to a\n  crucial error in Lemma 1; a series of modification has been made afterward.\n  The final version has been published by Journal of Combinatorial Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first show that a better analysis of the algorithm for The Two-Sage\nStochastic Facility Location Problem from Srinivasan \\cite{sri07} and the\nalgorithm for The Robust Fault Tolerant Facility Location Problem from Byrka et\nal \\cite{bgs10} can render improved approximation factors of 2.206 and \\alpha+4\nwhere \\alpha is the maximum number an adversary can close, respectively, and\nwhich are the best ratios so far.\n  We then present new models for the soft-capacitated facility location problem\nwith uncertainty and design constant factor approximation algorithms to solve\nthem. We devise the stochastic and robust approaches to handle the uncertainty\nincorporated into the original model. Explicitly, in this paper we propose two\nnew problem, named The 2-Stage Soft-Capacitated Facility Location Problem and\nThe Robust Soft-Capacitated Facility Location Problem respectively, and present\nconstant factor approximation algorithms for them both. Our method uses\nreductions between facility location problems and linear-cost models, the\nrandomized thresholding technique of Srinivasan \\cite{sri07} and the filtering\nand clustering technique of Byrka et al \\cite{bgs10}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 03:22:06 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 12:23:54 GMT"}, {"version": "v3", "created": "Fri, 10 May 2013 05:21:29 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Cai", "Shuxin", ""], ["Yang", "Wenguo", ""], ["Tang", "Yaohua", ""]]}, {"id": "1207.0302", "submitter": "Ralph Neininger", "authors": "Kevin Leckey, Ralph Neininger, Wojciech Szpankowski", "title": "Towards More Realistic Probabilistic Models for Data Structures: The\n  External Path Length in Tries under the Markov Model", "comments": "minor revision; to appear in Proceedings of ACM-SIAM Symposium on\n  Discrete Algorithms (SODA) (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tries are among the most versatile and widely used data structures on words.\nThey are pertinent to the (internal) structure of (stored) words and several\nsplitting procedures used in diverse contexts ranging from document taxonomy to\nIP addresses lookup, from data compression (i.e., Lempel-Ziv'77 scheme) to\ndynamic hashing, from partial-match queries to speech recognition, from leader\nelection algorithms to distributed hashing tables and graph compression. While\nthe performance of tries under a realistic probabilistic model is of\nsignificant importance, its analysis, even for simplest memoryless sources, has\nproved difficult. Rigorous findings about inherently complex parameters were\nrarely analyzed (with a few notable exceptions) under more realistic models of\nstring generations. In this paper we meet these challenges: By a novel use of\nthe contraction method combined with analytic techniques we prove a central\nlimit theorem for the external path length of a trie under a general Markov\nsource. In particular, our results apply to the Lempel-Ziv'77 code. We envision\nthat the methods described here will have further applications to other trie\nparameters and data structures.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 07:54:10 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2012 20:03:21 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2012 20:00:41 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Leckey", "Kevin", ""], ["Neininger", "Ralph", ""], ["Szpankowski", "Wojciech", ""]]}, {"id": "1207.0316", "submitter": "Peng Zhang", "authors": "Angsheng Li, Peng Zhang", "title": "Algorithmic Aspects of Homophyly of Networks", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the algorithmic problems of the {\\it homophyly phenomenon} in\nnetworks. Given an undirected graph $G = (V, E)$ and a vertex coloring $c\n\\colon V \\rightarrow {1, 2, ..., k}$ of $G$, we say that a vertex $v\\in V$ is\n{\\it happy} if $v$ shares the same color with all its neighbors, and {\\it\nunhappy}, otherwise, and that an edge $e\\in E$ is {\\it happy}, if its two\nendpoints have the same color, and {\\it unhappy}, otherwise. Supposing $c$ is a\n{\\it partial vertex coloring} of $G$, we define the Maximum Happy Vertices\nproblem (MHV, for short) as to color all the remaining vertices such that the\nnumber of happy vertices is maximized, and the Maximum Happy Edges problem\n(MHE, for short) as to color all the remaining vertices such that the number of\nhappy edges is maximized.\n  Let $k$ be the number of colors allowed in the problems. We show that both\nMHV and MHE can be solved in polynomial time if $k = 2$, and that both MHV and\nMHE are NP-hard if $k \\geq 3$. We devise a $\\max {1/k,\n\\Omega(\\Delta^{-3})}$-approximation algorithm for the MHV problem, where\n$\\Delta$ is the maximum degree of vertices in the input graph, and a\n1/2-approximation algorithm for the MHE problem. This is the first theoretical\nprogress of these two natural and fundamental new problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 09:31:32 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Li", "Angsheng", ""], ["Zhang", "Peng", ""]]}, {"id": "1207.0361", "submitter": "Arnab Bhattacharya", "authors": "Sourav Dutta and Arnab Bhattacharya", "title": "INSTRUCT: Space-Efficient Structure for Indexing and Complete Query\n  Management of String Databases", "comments": "International Conference on Management of Data (COMAD), 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous expanse of search engines, dictionary and thesaurus storage,\nand other text mining applications, combined with the popularity of readily\navailable scanning devices and optical character recognition tools, has\nnecessitated efficient storage, retrieval and management of massive text\ndatabases for various modern applications. For such applications, we propose a\nnovel data structure, INSTRUCT, for efficient storage and management of\nsequence databases. Our structure uses bit vectors for reusing the storage\nspace for common triplets, and hence, has a very low memory requirement.\nINSTRUCT efficiently handles prefix and suffix search queries in addition to\nthe exact string search operation by iteratively checking the presence of\ntriplets. We also propose an extension of the structure to handle substring\nsearch efficiently, albeit with an increase in the space requirements. This\nextension is important in the context of trie-based solutions which are unable\nto handle such queries efficiently. We perform several experiments portraying\nthat INSTRUCT outperforms the existing structures by nearly a factor of two in\nterms of space requirements, while the query times are better. The ability to\nhandle insertion and deletion of strings in addition to supporting all kinds of\nqueries including exact search, prefix/suffix search and substring search makes\nINSTRUCT a complete data structure.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 12:38:47 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 04:54:37 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Dutta", "Sourav", ""], ["Bhattacharya", "Arnab", ""]]}, {"id": "1207.0370", "submitter": "Abderrahmane Euldji", "authors": "Abderrahmane Euldji, Abderrahim Tienti and Amine Boudghene Stambouli", "title": "A new path algorithm for the weighted multi-graphs WMGPA: application to\n  the Direct Topological Method", "comments": "7 pages, 1 figure, 4 tables", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 1, No 2, January 2012, pp. 248-254", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to present an algorithm which gives all the possible\npaths that start from a specific node to another of a weighted multi-graph.\nThis algorithm is intended to be applied for the direct topological method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 13:20:45 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Euldji", "Abderrahmane", ""], ["Tienti", "Abderrahim", ""], ["Stambouli", "Amine Boudghene", ""]]}, {"id": "1207.0560", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer and Jeff Bilmes", "title": "Algorithms for Approximate Minimization of the Difference Between\n  Submodular Functions, with Applications", "comments": "17 pages, 8 figures. A shorter version of this appeared in Proc.\n  Uncertainty in Artificial Intelligence (UAI), Catalina Islands, 2012", "journal-ref": "UAI-2012", "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We extend the work of Narasimhan and Bilmes [30] for minimizing set functions\nrepresentable as a difference between submodular functions. Similar to [30],\nour new algorithms are guaranteed to monotonically reduce the objective\nfunction at every step. We empirically and theoretically show that the\nper-iteration cost of our algorithms is much less than [30], and our algorithms\ncan be used to efficiently minimize a difference between submodular functions\nunder various combinatorial constraints, a problem not previously addressed. We\nprovide computational bounds and a hardness result on the mul- tiplicative\ninapproximability of minimizing the difference between submodular functions. We\nshow, however, that it is possible to give worst-case additive bounds by\nproviding a polynomial time computable lower-bound on the minima. Finally we\nshow how a number of machine learning problems can be modeled as minimizing the\ndifference between submodular functions. We experimentally show the validity of\nour algorithms by testing them on the problem of feature selection with\nsubmodular cost features.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 01:25:10 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2012 15:41:46 GMT"}, {"version": "v3", "created": "Sat, 25 Aug 2012 16:04:53 GMT"}, {"version": "v4", "created": "Sat, 24 Aug 2013 05:35:11 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Iyer", "Rishabh", ""], ["Bilmes", "Jeff", ""]]}, {"id": "1207.0578", "submitter": "Andrew M. Sutton", "authors": "Andrew M. Sutton and Frank Neumann", "title": "Parameterized Runtime Analyses of Evolutionary Algorithms for the\n  Euclidean Traveling Salesperson Problem", "comments": "A conference version has been accepted for AAAI 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized runtime analysis seeks to understand the influence of problem\nstructure on algorithmic runtime. In this paper, we contribute to the\ntheoretical understanding of evolutionary algorithms and carry out a\nparameterized analysis of evolutionary algorithms for the Euclidean traveling\nsalesperson problem (Euclidean TSP).\n  We investigate the structural properties in TSP instances that influence the\noptimization process of evolutionary algorithms and use this information to\nbound the runtime of simple evolutionary algorithms. Our analysis studies the\nruntime in dependence of the number of inner points $k$ and shows that $(\\mu +\n\\lambda)$ evolutionary algorithms solve the Euclidean TSP in expected time\n$O((\\mu/\\lambda) \\cdot n^3\\gamma(\\epsilon) + n\\gamma(\\epsilon) + (\\mu/\\lambda)\n\\cdot n^{4k}(2k-1)!)$ where $\\gamma$ is a function of the minimum angle\n$\\epsilon$ between any three points.\n  Finally, our analysis provides insights into designing a mutation operator\nthat improves the upper bound on expected runtime. We show that a mixed\nmutation strategy that incorporates both 2-opt moves and permutation jumps\nresults in an upper bound of $O((\\mu/\\lambda) \\cdot n^3\\gamma(\\epsilon) +\nn\\gamma(\\epsilon) + (\\mu/\\lambda) \\cdot n^{2k}(k-1)!)$ for the $(\\mu+\\lambda)$\nEA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 06:21:11 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 05:42:50 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Sutton", "Andrew M.", ""], ["Neumann", "Frank", ""]]}, {"id": "1207.0773", "submitter": "Carola Winzen", "authors": "Benjamin Doerr and Carola Doerr and Reto Sp\\\"ohel and Henning Thomas", "title": "Playing Mastermind with Many Colors", "comments": "Extended abstract appeared in SODA 2013. This full version has 22\n  pages and 1 picture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the general version of the classic guessing game Mastermind with\n$n$ positions and $k$ colors. Since the case $k \\le n^{1-\\varepsilon}$,\n$\\varepsilon>0$ a constant, is well understood, we concentrate on larger\nnumbers of colors. For the most prominent case $k = n$, our results imply that\nCodebreaker can find the secret code with $O(n \\log \\log n)$ guesses. This\nbound is valid also when only black answer-pegs are used. It improves the $O(n\n\\log n)$ bound first proven by Chv\\'atal (Combinatorica 3 (1983), 325--329). We\nalso show that if both black and white answer-pegs are used, then the $O(n\n\\log\\log n)$ bound holds for up to $n^2 \\log\\log n$ colors. These bounds are\nalmost tight as the known lower bound of $\\Omega(n)$ shows. Unlike for $k \\le\nn^{1-\\varepsilon}$, simply guessing at random until the secret code is\ndetermined is not sufficient. In fact, we show that an optimal non-adaptive\nstrategy (deterministic or randomized) needs $\\Theta(n \\log n)$ guesses.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 18:32:08 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 13:43:26 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""], ["Sp\u00f6hel", "Reto", ""], ["Thomas", "Henning", ""]]}, {"id": "1207.0835", "submitter": "Ignasi Sau", "authors": "Eun Jung Kim, Alexander Langer, Christophe Paul, Felix Reidl, Peter\n  Rossmanith, Ignasi Sau, and Somnath Sikdar", "title": "Linear kernels and single-exponential algorithms via protrusion\n  decompositions", "comments": "We would like to point out that this article replaces and extends the\n  results of [CoRR, abs/1201.2780, 2012]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \\emph{$t$-treewidth-modulator} of a graph $G$ is a set $X \\subseteq V(G)$\nsuch that the treewidth of $G-X$ is at most some constant $t-1$. In this paper,\nwe present a novel algorithm to compute a decomposition scheme for graphs $G$\nthat come equipped with a $t$-treewidth-modulator. This decomposition, called a\n\\emph{protrusion decomposition}, is the cornerstone in obtaining the following\ntwo main results.\n  We first show that any parameterized graph problem (with parameter $k$) that\nhas \\emph{finite integer index} and is \\emph{treewidth-bounding} admits a\nlinear kernel on $H$-topological-minor-free graphs, where $H$ is some arbitrary\nbut fixed graph. A parameterized graph problem is called treewidth-bounding if\nall positive instances have a $t$-treewidth-modulator of size $O(k)$, for some\nconstant $t$. This result partially extends previous meta-theorems on the\nexistence of linear kernels on graphs of bounded genus [Bodlaender et al., FOCS\n2009] and $H$-minor-free graphs [Fomin et al., SODA 2010].\n  Our second application concerns the Planar-$\\mathcal{F}$-Deletion problem.\nLet $\\mathcal{F}$ be a fixed finite family of graphs containing at least one\nplanar graph. Given an $n$-vertex graph $G$ and a non-negative integer $k$,\nPlanar-$\\mathcal{F}$-Deletion asks whether $G$ has a set $X\\subseteq V(G)$ such\nthat $|X|\\leq k$ and $G-X$ is $H$-minor-free for every $H\\in \\mathcal{F}$. Very\nrecently, an algorithm for Planar-$\\mathcal{F}$-Deletion with running time\n$2^{O(k)} n \\log^2 n$ (such an algorithm is called \\emph{single-exponential})\nhas been presented in [Fomin et al., FOCS 2012] under the condition that every\ngraph in $\\mathcal{F}$ is connected. Using our algorithm to construct\nprotrusion decompositions as a building block, we get rid of this connectivity\nconstraint and present an algorithm for the general\nPlanar-$\\mathcal{F}$-Deletion problem running in time $2^{O(k)} n^2$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 20:55:53 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2012 22:49:19 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Kim", "Eun Jung", ""], ["Langer", "Alexander", ""], ["Paul", "Christophe", ""], ["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Sau", "Ignasi", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1207.0869", "submitter": "EPTCS", "authors": "Srinivas Nedunuri (The University of Texas at Austin), William R. Cook\n  (The University of Texas at Austin), Douglas R. Smith (Kestrel Institute)", "title": "Theory and Techniques for Synthesizing a Family of Graph Algorithms", "comments": "In Proceedings SYNT 2012, arXiv:1207.0554", "journal-ref": "EPTCS 84, 2012, pp. 33-46", "doi": "10.4204/EPTCS.84.3", "report-no": null, "categories": "cs.SE cs.AI cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Breadth-First Search (BFS) has several advantages over Depth-First\nSearch (DFS) its prohibitive space requirements have meant that algorithm\ndesigners often pass it over in favor of DFS. To address this shortcoming, we\nintroduce a theory of Efficient BFS (EBFS) along with a simple recursive\nprogram schema for carrying out the search. The theory is based on dominance\nrelations, a long standing technique from the field of search algorithms. We\nshow how the theory can be used to systematically derive solutions to two graph\nalgorithms, namely the Single Source Shortest Path problem and the Minimum\nSpanning Tree problem. The solutions are found by making small systematic\nchanges to the derivation, revealing the connections between the two problems\nwhich are often obscured in textbook presentations of them.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 01:22:02 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Nedunuri", "Srinivas", "", "The University of Texas at Austin"], ["Cook", "William R.", "", "The University of Texas at Austin"], ["Smith", "Douglas R.", "", "Kestrel Institute"]]}, {"id": "1207.0892", "submitter": "Li Ning Mr.", "authors": "T-H. Hubert Chan, Mingfei Li, Li Ning", "title": "Incubators vs Zombies: Fault-Tolerant, Short, Thin and Lanky Spanners\n  for Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Elkin and Solomon gave a construction of spanners for doubling\nmetrics that has constant maximum degree, hop-diameter O(log n) and lightness\nO(log n) (i.e., weight O(log n)w(MST). This resolves a long standing conjecture\nproposed by Arya et al. in a seminal STOC 1995 paper.\n  However, Elkin and Solomon's spanner construction is extremely complicated;\nwe offer a simple alternative construction that is very intuitive and is based\non the standard technique of net tree with cross edges. Indeed, our approach\ncan be readily applied to our previous construction of k-fault tolerant\nspanners (ICALP 2012) to achieve k-fault tolerance, maximum degree O(k^2),\nhop-diameter O(log n) and lightness O(k^3 log n).\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 03:58:39 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Chan", "T-H. Hubert", ""], ["Li", "Mingfei", ""], ["Ning", "Li", ""]]}, {"id": "1207.0933", "submitter": "Marek Karpinski", "authors": "Marek Karpinski, Andrzej Lingas, Dzmitry Sledneu", "title": "Optimal Cuts and Bisections on the Real Line in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exact complexity of geometric cuts and bisections is the longstanding\nopen problem including even the dimension one. In this paper, we resolve this\nproblem for dimension one (the real line) by designing an exact polynomial time\nalgorithm. Our results depend on a new technique of dealing with metric\nequalities and their connection to dynamic programming. The method of our\nsolution could be also of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 10:02:15 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Karpinski", "Marek", ""], ["Lingas", "Andrzej", ""], ["Sledneu", "Dzmitry", ""]]}, {"id": "1207.1135", "submitter": "Tsvi Kopelowitz", "authors": "Philip Bille and Inge Li G{\\o}rtz and Tsvi Kopelowitz and Benjamin\n  Sach and Hjalte Wedel Vildh{\\o}j", "title": "Sparse Suffix Tree Construction with Small Space", "comments": "7 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing a sparse suffix tree (or suffix\narray) for $b$ suffixes of a given text $T$ of size $n$, using only $O(b)$\nwords of space during construction time. Breaking the naive bound of\n$\\Omega(nb)$ time for this problem has occupied many algorithmic researchers\nsince a different structure, the (evenly spaced) sparse suffix tree, was\nintroduced by K{\\\"a}rkk{\\\"a}inen and Ukkonen in 1996. While in the evenly\nspaced sparse suffix tree the suffixes considered must be evenly spaced in $T$,\nhere there is no constraint on the locations of the suffixes.\n  We show that the sparse suffix tree can be constructed in $O(n\\log^2b)$ time.\nTo achieve this we develop a technique, which may be of independent interest,\nthat allows to efficiently answer $b$ longest common prefix queries on suffixes\nof $T$, using only $O(b)$ space. We expect that this technique will prove\nuseful in many other applications in which space usage is a concern.\nFurthermore, additional tradeoffs between the space usage and the construction\ntime are given.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 22:41:51 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Bille", "Philip", ""], ["G\u00f8rtz", "Inge Li", ""], ["Kopelowitz", "Tsvi", ""], ["Sach", "Benjamin", ""], ["Vildh\u00f8j", "Hjalte Wedel", ""]]}, {"id": "1207.1141", "submitter": "Nicolaos Matsakis", "authors": "Nicolaos Matsakis", "title": "The Longest Queue Drop Policy for Shared-Memory Switches is\n  1.5-competitive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Longest Queue Drop memory management policy in shared-memory\nswitches consisting of $N$ output ports. The shared memory of size $M\\geq N$\nmay have an arbitrary number of input ports. Each packet may be admitted by any\nincoming port, but must be destined to a specific output port and each output\nport may be used by only one queue. The Longest Queue Drop policy is a natural\nonline strategy used in directing the packet flow in buffering problems.\nAccording to this policy and assuming unit packet values and cost of\ntransmission, every incoming packet is accepted, whereas if the shared memory\nbecomes full, one or more packets belonging to the longest queue are preempted,\nin order to make space for the newly arrived packets. It was proved in 2001\n[Hahne et al., SPAA '01] that the Longest Queue Drop policy is 2-competitive\nand at least $\\sqrt{2}$-competitive. It remained an open question whether a\n(2-\\epsilon) upper bound for the competitive ratio of this policy could be\nshown, for any positive constant \\epsilon. We show that the Longest Queue Drop\nonline policy is 1.5-competitive.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 23:22:31 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2012 13:45:05 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Matsakis", "Nicolaos", ""]]}, {"id": "1207.1161", "submitter": "Manish Gupta", "authors": "Abhishek Chhajer and Manish K. Gupta and Sandeep Vasani and Jaley\n  Dholakiya", "title": "Modular Arithmetic Expressions and Primality Testing via DNA\n  Self-Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-assembly is a fundamental process by which supramolecular species form\nspontaneously from their components. This process is ubiquitous throughout the\nlife chemistry and is central to biological information processing. Algorithms\nfor solving many mathematical and computational problems via tile self assembly\nhave been proposed by many researchers in the last decade. In particular tile\nset for doing basic arithmetic of two inputs have been given. In this work we\ngive tile set for doing basic arithmetic (addition, subtraction,\nmultiplication) of n inputs and subsequently computing its modulo. We also\npresent a tile set for primality testing. Finally we present a software\n'xtilemod' for doing modular arithmetic. This simplifies the task of creating\nthe input files to xgrow simulator for doing basic (addition, subtraction,\nmultiplication and division) as well as modular arithmetic of n inputs. Similar\nsoftware for creating tile set for primality testing is also given.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 04:55:03 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Chhajer", "Abhishek", ""], ["Gupta", "Manish K.", ""], ["Vasani", "Sandeep", ""], ["Dholakiya", "Jaley", ""]]}, {"id": "1207.1265", "submitter": "Martin Hoefer", "authors": "Martin Hoefer and Lisa Wagner", "title": "Locally Stable Marriage with Strict Preferences", "comments": "Conference version in ICALP 2013; to appear in SIAM J. Disc Math", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stable matching problems with locality of information and control.\nIn our model, each agent is a node in a fixed network and strives to be matched\nto another agent. An agent has a complete preference list over all other agents\nit can be matched with. Agents can match arbitrarily, and they learn about\npossible partners dynamically based on their current neighborhood. We consider\nconvergence of dynamics to locally stable matchings -- states that are stable\nwith respect to their imposed information structure in the network. In the\ntwo-sided case of stable marriage in which existence is guaranteed, we show\nthat the existence of a path to stability becomes NP-hard to decide. This holds\neven when the network exists only among one partition of agents. In contrast,\nif one partition has no network and agents remember a previous match every\nround, a path to stability is guaranteed and random dynamics converge with\nprobability 1. We characterize this positive result in various ways. For\ninstance, it holds for random memory and for cache memory with the most recent\npartner, but not for cache memory with the best partner. Also, it is crucial\nwhich partition of the agents has memory. Finally, we present results for\ncentralized computation of locally stable matchings, i.e., computing maximum\nlocally stable matchings in the two-sided case and deciding existence in the\nroommates case.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 14:14:40 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2012 13:32:39 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 19:51:15 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Hoefer", "Martin", ""], ["Wagner", "Lisa", ""]]}, {"id": "1207.1277", "submitter": "Shay Solomon", "authors": "Ofer Neiman and Shay Solomon", "title": "Simple Deterministic Algorithms for Fully Dynamic Maximal Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A maximal matching can be maintained in fully dynamic (supporting both\naddition and deletion of edges) $n$-vertex graphs using a trivial deterministic\nalgorithm with a worst-case update time of O(n). No deterministic algorithm\nthat outperforms the na\\\"{\\i}ve O(n) one was reported up to this date. The only\nprogress in this direction is due to Ivkovi\\'{c} and Lloyd \\cite{IL93}, who in\n1993 devised a deterministic algorithm with an \\emph{amortized} update time of\n$O((n+m)^{\\sqrt{2}/2})$, where $m$ is the number of edges.\n  In this paper we show the first deterministic fully dynamic algorithm that\noutperforms the trivial one. Specifically, we provide a deterministic\n\\emph{worst-case} update time of $O(\\sqrt{m})$. Moreover, our algorithm\nmaintains a matching which is in fact a 3/2-approximate maximum cardinality\nmatching (MCM). We remark that no fully dynamic algorithm for maintaining\n$(2-\\eps)$-approximate MCM improving upon the na\\\"{\\i}ve O(n) was known prior\nto this work, even allowing amortized time bounds and \\emph{randomization}.\n  For low arboricity graphs (e.g., planar graphs and graphs excluding fixed\nminors), we devise another simple deterministic algorithm with\n\\emph{sub-logarithmic update time}. Specifically, it maintains a fully dynamic\nmaximal matching with amortized update time of $O(\\log n/\\log \\log n)$. This\nresult addresses an open question of Onak and Rubinfeld \\cite{OR10}.\n  We also show a deterministic algorithm with optimal space usage, that for\narbitrary graphs maintains a maximal matching in amortized $O(\\sqrt{m})$ time,\nand uses only $O(n+m)$ space.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 14:50:31 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 13:57:05 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Neiman", "Ofer", ""], ["Solomon", "Shay", ""]]}, {"id": "1207.1307", "submitter": "Michalis Christou", "authors": "Michalis Christou, Maxime Crochemore and Costas S. Iliopoulos", "title": "Identifying all abelian periods of a string in quadratic time and\n  relevant problems", "comments": "Accepted in the \"International Journal of foundations of Computer\n  Science\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abelian periodicity of strings has been studied extensively over the last\nyears. In 2006 Constantinescu and Ilie defined the abelian period of a string\nand several algorithms for the computation of all abelian periods of a string\nwere given. In contrast to the classical period of a word, its abelian version\nis more flexible, factors of the word are considered the same under any\ninternal permutation of their letters. We show two O(|y|^2) algorithms for the\ncomputation of all abelian periods of a string y. The first one maps each\nletter to a suitable number such that each factor of the string can be\nidentified by the unique sum of the numbers corresponding to its letters and\nhence abelian periods can be identified easily. The other one maps each letter\nto a prime number such that each factor of the string can be identified by the\nunique product of the numbers corresponding to its letters and so abelian\nperiods can be identified easily. We also define weak abelian periods on\nstrings and give an O(|y|log(|y|)) algorithm for their computation, together\nwith some other algorithms for more basic problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 17:43:50 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Christou", "Michalis", ""], ["Crochemore", "Maxime", ""], ["Iliopoulos", "Costas S.", ""]]}, {"id": "1207.1333", "submitter": "Rico Zenklusen", "authors": "Patrick Jaillet and Jos\\'e A. Soto and Rico Zenklusen", "title": "Advances on Matroid Secretary Problems: Free Order Model and Laminar\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most well-known conjecture in the context of matroid secretary problems\nclaims the existence of a constant-factor approximation applicable to any\nmatroid. Whereas this conjecture remains open, modified forms of it were shown\nto be true, when assuming that the assignment of weights to the secretaries is\nnot adversarial but uniformly random (Soto [SODA 2011], Oveis Gharan and\nVondr\\'ak [ESA 2011]). However, so far, there was no variant of the matroid\nsecretary problem with adversarial weight assignment for which a\nconstant-factor approximation was found. We address this point by presenting a\n9-approximation for the \\emph{free order model}, a model suggested shortly\nafter the introduction of the matroid secretary problem, and for which no\nconstant-factor approximation was known so far. The free order model is a\nrelaxed version of the original matroid secretary problem, with the only\ndifference that one can choose the order in which secretaries are interviewed.\n  Furthermore, we consider the classical matroid secretary problem for the\nspecial case of laminar matroids. Only recently, a constant-factor\napproximation has been found for this case, using a clever but rather involved\nmethod and analysis (Im and Wang, [SODA 2011]) that leads to a\n16000/3-approximation. This is arguably the most involved special case of the\nmatroid secretary problem for which a constant-factor approximation is known.\nWe present a considerably simpler and stronger $3\\sqrt{3}e\\approx\n14.12$-approximation, based on reducing the problem to a matroid secretary\nproblem on a partition matroid.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 19:23:47 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 17:10:07 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Jaillet", "Patrick", ""], ["Soto", "Jos\u00e9 A.", ""], ["Zenklusen", "Rico", ""]]}, {"id": "1207.1371", "submitter": "Shuchi Chawla", "authors": "Shuchi Chawla, Cynthia Dwork, Frank McSherry, Kunal Talwar", "title": "On Privacy-Preserving Histograms", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-120-127", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advance the approach initiated by Chawla et al. for sanitizing (census)\ndata so as to preserve the privacy of respondents while simultaneously\nextracting \"useful\" statistical information. First, we extend the scope of\ntheir techniques to a broad and rich class of distributions, specifically,\nmixtures of highdimensional balls, spheres, Gaussians, and other \"nice\"\ndistributions. Second, we randomize the histogram constructions to preserve\nspatial characteristics of the data, allowing us to approximate various\nquantities of interest, e.g., cost of the minimum spanning tree on the data, in\na privacy-preserving fashion.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:06:07 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Chawla", "Shuchi", ""], ["Dwork", "Cynthia", ""], ["McSherry", "Frank", ""], ["Talwar", "Kunal", ""]]}, {"id": "1207.1395", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov, Martin Wainwright", "title": "On the optimality of tree-reweighted max-product message-passing", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-316-323", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-reweighted max-product (TRW) message passing is a modified form of the\nordinary max-product algorithm for attempting to find minimal energy\nconfigurations in Markov random field with cycles. For a TRW fixed point\nsatisfying the strong tree agreement condition, the algorithm outputs a\nconfiguration that is provably optimal. In this paper, we focus on the case of\nbinary variables with pairwise couplings, and establish stronger properties of\nTRW fixed points that satisfy only the milder condition of weak tree agreement\n(WTA). First, we demonstrate how it is possible to identify part of the optimal\nsolution|i.e., a provably optimal solution for a subset of nodes| without\nknowing a complete solution. Second, we show that for submodular functions, a\nWTA fixed point always yields a globally optimal solution. We establish that\nfor binary variables, any WTA fixed point always achieves the global maximum of\nthe linear programming relaxation underlying the TRW method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:16:43 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Kolmogorov", "Vladimir", ""], ["Wainwright", "Martin", ""]]}, {"id": "1207.1404", "submitter": "Mukund Narasimhan", "authors": "Mukund Narasimhan, Jeff A. Bilmes", "title": "A submodular-supermodular procedure with applications to discriminative\n  structure learning", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-404-412", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an algorithm for minimizing the difference between\ntwo submodular functions using a variational framework which is based on (an\nextension of) the concave-convex procedure [17]. Because several commonly used\nmetrics in machine learning, like mutual information and conditional mutual\ninformation, are submodular, the problem of minimizing the difference of two\nsubmodular problems arises naturally in many machine learning applications. Two\nsuch applications are learning discriminatively structured graphical models and\nfeature selection under computational complexity constraints. A commonly used\nmetric for measuring discriminative capacity is the EAR measure which is the\ndifference between two conditional mutual information terms. Feature selection\ntaking complexity considerations into account also fall into this framework\nbecause both the information that a set of features provide and the cost of\ncomputing and using the features can be modeled as submodular functions. This\nproblem is NP-hard, and we give a polynomial time heuristic for it. We also\npresent results on synthetic data to show that classifiers based on\ndiscriminative graphical models using this algorithm can significantly\noutperform classifiers based on generative graphical models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:20:12 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Narasimhan", "Mukund", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1207.1668", "submitter": "Shay Solomon", "authors": "Michael Elkin and Shay Solomon", "title": "Fast Constructions of Light-Weight Spanners for General Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To our knowledge, there are only two known algorithms for constructing sparse\nand light spanners for general graphs. One of them is the greedy algorithm of\nAlth$\\ddot{o}$fer et al. \\cite{ADDJS93}, analyzed by Chandra et al. in SoCG'92.\nThe greedy algorithm consructs, for every \\emph{weighted} undirected $n$-vertex\n$m$-edge graph $G = (V,E)$ and any integer $k \\ge 1$, a $(2k-1)$-spanner with\n$O(n^{1 + 1/k})$ edges and weight $O(k \\cdot n^{(1+\\eps)/k}) \\cdot\n\\omega(MST(G))$, for any $\\eps > 0$. The drawback of the greedy algorithm is\nthat it requires $O(m \\cdot (n^{1 + 1/k} + n \\cdot \\log n))$ time. The other\nalgorithm is due to Awerbuch et al. \\cite{ABP91}. It constructs $O(k)$-spanners\nwith $O(k \\cdot n^{1 + 1/k} \\cdot \\Lambda)$ edges, weight $O(k^2 \\cdot n^{1/k}\n\\cdot \\Lambda) \\cdot \\omega(MST(G))$, within time $O(m \\cdot k \\cdot n^{1/k}\n\\cdot \\Lambda)$, where $\\Lambda$ is the logarithm of the aspect ratio of the\ngraph. The running time of both these algorithms is unsatisfactory. Moreover,\nthe usually faster algorithm of \\cite{ABP91} pays for the speedup by\nsignificantly increasing both the stretch, the sparsity, and the weight of the\nresulting spanner.\n  In this paper we devise an efficient algorithm for constructing sparse and\nlight spanners. Specifically, our algorithm constructs $((2k-1) \\cdot\n(1+\\eps))$-spanners with $O(k \\cdot n^{1 + 1/k})$ edges and weight $O(k \\cdot\nn^{1/k}) \\cdot \\omega(MST(G))$, where $\\eps > 0$ is an arbitrarily small\nconstant. The running time of our algorithm is $O(k \\cdot m + \\min\\{n \\cdot\n\\log n,m \\cdot \\alpha(n)\\})$. Moreover, by slightly increasing the running time\nwe can reduce the other parameters. These results address an open problem from\nthe ESA'04 paper by Roditty and Zwick \\cite{RZ04}.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 15:46:23 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Elkin", "Michael", ""], ["Solomon", "Shay", ""]]}, {"id": "1207.1788", "submitter": "Leah Epstein", "authors": "Leah Epstein, Asaf Levin, Danny Segev, and Oren Weimann", "title": "Improved Bounds for Online Preemptive Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing a preemptive online algorithm for the maximum matching\nproblem, we wish to maintain a valid matching M while edges of the underlying\ngraph are presented one after the other. When presented with an edge e, the\nalgorithm should decide whether to augment the matching M by adding e (in which\ncase e may be removed later on) or to keep M in its current form without adding\ne (in which case e is lost for good). The objective is to eventually hold a\nmatching M with maximum weight.\n  The main contribution of this paper is to establish new lower and upper\nbounds on the competitive ratio achievable by preemptive online algorithms:\n  1. We provide a lower bound of 1+ln 2~1.693 on the competitive ratio of any\nrandomized algorithm for the maximum cardinality matching problem, thus\nimproving on the currently best known bound of e/(e-1)~1.581 due to Karp,\nVazirani, and Vazirani [STOC'90].\n  2. We devise a randomized algorithm that achieves an expected competitive\nratio of 5.356 for maximum weight matching. This finding demonstrates the power\nof randomization in this context, showing how to beat the tight bound of 3\n+2\\sqrt{2}~5.828 for deterministic algorithms, obtained by combining the 5.828\nupper bound of McGregor [APPROX'05] and the recent 5.828 lower bound of\nVaradaraja [ICALP'11].\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 11:49:05 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Epstein", "Leah", ""], ["Levin", "Asaf", ""], ["Segev", "Danny", ""], ["Weimann", "Oren", ""]]}, {"id": "1207.1794", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan", "title": "Design, Evaluation and Analysis of Combinatorial Optimization Heuristic\n  Algorithms", "comments": "202 pages. Ph. D. Thesis. Royal Holloway, University of London. 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization is widely applied in a number of areas nowadays.\nUnfortunately, many combinatorial optimization problems are NP-hard which\nusually means that they are unsolvable in practice. However, it is often\nunnecessary to have an exact solution. In this case one may use heuristic\napproach to obtain a near-optimal solution in some reasonable time.\n  We focus on two combinatorial optimization problems, namely the Generalized\nTraveling Salesman Problem and the Multidimensional Assignment Problem. The\nfirst problem is an important generalization of the Traveling Salesman Problem;\nthe second one is a generalization of the Assignment Problem for an arbitrary\nnumber of dimensions. Both problems are NP-hard and have hosts of applications.\n  In this work, we discuss different aspects of heuristics design and\nevaluation. A broad spectrum of related subjects, covered in this research,\nincludes test bed generation and analysis, implementation and performance\nissues, local search neighborhoods and efficient exploration algorithms,\nmetaheuristics design and population sizing in memetic algorithm.\n  The most important results are obtained in the areas of local search and\nmemetic algorithms for the considered problems. In both cases we have\nsignificantly advanced the existing knowledge on the local search neighborhoods\nand algorithms by systematizing and improving the previous results. We have\nproposed a number of efficient heuristics which dominate the existing\nalgorithms in a wide range of time/quality requirements.\n  Several new approaches, introduced in our memetic algorithms, make them the\nstate-of-the-art metaheuristics for the corresponding problems. Population\nsizing is one of the most promising among these approaches; it is expected to\nbe applicable to virtually any memetic algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 13:57:18 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Karapetyan", "Daniel", ""]]}, {"id": "1207.1831", "submitter": "Shay Solomon", "authors": "Michael Elkin and Shay Solomon", "title": "Optimal Euclidean spanners: really short, thin and lanky", "comments": "A technical report of this paper was available online from April 4,\n  2012", "journal-ref": null, "doi": null, "report-no": "TR CS-12-04, Ben-Gurion University", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a seminal STOC'95 paper, titled \"Euclidean spanners: short, thin and\nlanky\", Arya et al. devised a construction of Euclidean $(1+\\eps)$-spanners\nthat achieves constant degree, diameter $O(\\log n)$, and weight $O(\\log^2 n)\n\\cdot \\omega(MST)$, and has running time $O(n \\cdot \\log n)$. This construction\napplies to $n$-point constant-dimensional Euclidean spaces. Moreover, Arya et\nal. conjectured that the weight bound can be improved by a logarithmic factor,\nwithout increasing the degree and the diameter of the spanner, and within the\nsame running time.\n  This conjecture of Arya et al. became a central open problem in the area of\nEuclidean spanners.\n  In this paper we resolve the long-standing conjecture of Arya et al. in the\naffirmative. Specifically, we present a construction of spanners with the same\nstretch, degree, diameter, and running time, as in Arya et al.'s result, but\nwith optimal weight $O(\\log n) \\cdot \\omega(MST)$.\n  Moreover, our result is more general in three ways. First, we demonstrate\nthat the conjecture holds true not only in constant-dimensional Euclidean\nspaces, but also in doubling metrics. Second, we provide a general tradeoff\nbetween the three involved parameters, which is tight in the entire range.\nThird, we devise a transformation that decreases the lightness of spanners in\ngeneral metrics, while keeping all their other parameters in check. Our main\nresult is obtained as a corollary of this transformation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 22:39:46 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2012 16:45:38 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2012 14:53:25 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2012 15:37:50 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Elkin", "Michael", ""], ["Solomon", "Shay", ""]]}, {"id": "1207.1885", "submitter": "Markus Jalsenius", "authors": "Raphael Clifford, Markus Jalsenius, Benjamin Sach", "title": "Tight Cell-Probe Bounds for Online Hamming Distance Computation", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show tight bounds for online Hamming distance computation in the\ncell-probe model with word size w. The task is to output the Hamming distance\nbetween a fixed string of length n and the last n symbols of a stream. We give\na lower bound of Omega((d/w)*log n) time on average per output, where d is the\nnumber of bits needed to represent an input symbol. We argue that this bound is\ntight within the model. The lower bound holds under randomisation and\namortisation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 16:44:49 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 15:35:22 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2012 16:05:17 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Clifford", "Raphael", ""], ["Jalsenius", "Markus", ""], ["Sach", "Benjamin", ""]]}, {"id": "1207.2317", "submitter": "Sergio Cabello", "authors": "Sergio Cabello", "title": "Stackelberg Shortest Path Tree Game, Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G(V,E)$ be a directed graph with $n$ vertices and $m$ edges. The edges\n$E$ of $G$ are divided into two types: $E_F$ and $E_P$. Each edge of $E_F$ has\na fixed price. The edges of $E_P$ are the priceable edges and their price is\nnot fixed a priori. Let $r$ be a vertex of $G$. For an assignment of prices to\nthe edges of $E_P$, the revenue is given by the following procedure: select a\nshortest path tree $T$ from $r$ with respect to the prices (a tree of cheapest\npaths); the revenue is the sum, over all priceable edges $e$, of the product of\nthe price of $e$ and the number of vertices below $e$ in $T$.\n  Assuming that $k=|E_P|\\ge 2$ is a constant, we provide a data structure whose\nconstruction takes $O(m+n\\log^{k-1} n)$ time and with the property that, when\nwe assign prices to the edges of $E_P$, the revenue can be computed in\n$(\\log^{k-1} n)$. Using our data structure, we save almost a linear factor when\ncomputing the optimal strategy in the Stackelberg shortest paths tree game of\n[D. Bil{\\`o} and L. Gual{\\`a} and G. Proietti and P. Widmayer. Computational\naspects of a 2-Player Stackelberg shortest paths tree game. Proc. WINE 2008].\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 11:49:11 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Cabello", "Sergio", ""]]}, {"id": "1207.2335", "submitter": "Mayank Bakshi", "authors": "Mayank Bakshi and Sidharth Jaggi and Sheng Cai and Minghua Chen", "title": "SHO-FA: Robust compressive sensing with order-optimal complexity,\n  measurements, and bits", "comments": "Submitted to IEEE Transactions on Information Theory. A preliminary\n  version of this paper was presented at the 50th Annual Allerton Conference on\n  Communication, Control and Computing - 2012. A poster based on this work was\n  also presented at International Symposium on Information Theory 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose x is any exactly k-sparse vector in R^n. We present a class of sparse\nmatrices A, and a corresponding algorithm that we call SHO-FA (for Short and\nFast) that, with high probability over A, can reconstruct x from Ax. The SHO-FA\nalgorithm is related to the Invertible Bloom Lookup Tables recently introduced\nby Goodrich et al., with two important distinctions - SHO-FA relies on linear\nmeasurements, and is robust to noise. The SHO-FA algorithm is the first to\nsimultaneously have the following properties: (a) it requires only O(k)\nmeasurements, (b) the bit-precision of each measurement and each arithmetic\noperation is O (log(n) + P) (here 2^{-P} is the desired relative error in the\nreconstruction of x), (c) the decoding complexity is O(k) arithmetic operations\nand encoding complexity is O(n) arithmetic operations, and (d) if the\nreconstruction goal is simply to recover a single component of x instead of all\nof x, with significant probability over A this can be done in constant time.\nAll constants above are independent of all problem parameters other than the\ndesired success probability. For a wide range of parameters these properties\nare information-theoretically order-optimal. In addition, our SHO-FA algorithm\nworks over fairly general ensembles of \"sparse random matrices\", is robust to\nrandom noise, and (random) approximate sparsity for a large range of k. In\nparticular, suppose the measured vector equals A(x+z)+e, where z and e\ncorrespond respectively to the source tail and measurement noise. Under\nreasonable statistical assumptions on z and e our decoding algorithm\nreconstructs x with an estimation error of O(||z||_2 +||e||_2). The SHO-FA\nalgorithm works with high probability over A, z, and e, and still requires only\nO(k) steps and O(k) measurements over O(log n)-bit numbers. This is in contrast\nto the worst-case z model, where it is known O(k log n/k) measurements are\nnecessary.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 13:01:40 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2012 04:41:11 GMT"}], "update_date": "2012-11-16", "authors_parsed": [["Bakshi", "Mayank", ""], ["Jaggi", "Sidharth", ""], ["Cai", "Sheng", ""], ["Chen", "Minghua", ""]]}, {"id": "1207.2341", "submitter": "Casper Kejlberg-Rasmussen", "authors": "Casper Kejlberg-Rasmussen and Konstantinos Tsakalidis and Kostas\n  Tsichlas", "title": "I/O-Efficient Dynamic Planar Range Skyline Queries", "comments": "Submitted to SODA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present the first fully dynamic worst case I/O-efficient data structures\nthat support planar orthogonal \\textit{3-sided range skyline reporting queries}\nin $\\bigO (\\log_{2B^\\epsilon} n + \\frac{t}{B^{1-\\epsilon}})$ I/Os and updates\nin $\\bigO (\\log_{2B^\\epsilon} n)$ I/Os, using $\\bigO\n(\\frac{n}{B^{1-\\epsilon}})$ blocks of space, for $n$ input planar points, $t$\nreported points, and parameter $0 \\leq \\epsilon \\leq 1$. We obtain the result\nby extending Sundar's priority queues with attrition to support the operations\n\\textsc{DeleteMin} and \\textsc{CatenateAndAttrite} in $\\bigO (1)$ worst case\nI/Os, and in $\\bigO(1/B)$ amortized I/Os given that a constant number of blocks\nis already loaded in main memory. Finally, we show that any pointer-based\nstatic data structure that supports \\textit{dominated maxima reporting\nqueries}, namely the difficult special case of 4-sided skyline queries, in\n$\\bigO(\\log^{\\bigO(1)}n +t)$ worst case time must occupy $\\Omega(n \\frac{\\log\nn}{\\log \\log n})$ space, by adapting a similar lower bounding argument for\nplanar 4-sided range reporting queries.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 13:32:12 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Kejlberg-Rasmussen", "Casper", ""], ["Tsakalidis", "Konstantinos", ""], ["Tsichlas", "Kostas", ""]]}, {"id": "1207.2424", "submitter": "Daniel Jones", "authors": "Daniel C. Jones, Walter L. Ruzzo, Xinxia Peng, and Michael G. Katze", "title": "Compression of next-generation sequencing reads aided by highly\n  efficient de novo assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Quip, a lossless compression algorithm for next-generation\nsequencing data in the FASTQ and SAM/BAM formats. In addition to implementing\nreference-based compression, we have developed, to our knowledge, the first\nassembly-based compressor, using a novel de novo assembly algorithm. A\nprobabilistic data structure is used to dramatically reduce the memory required\nby traditional de Bruijn graph assemblers, allowing millions of reads to be\nassembled very efficiently. Read sequences are then stored as positions within\nthe assembled contigs. This is combined with statistical compression of read\nidentifiers, quality scores, alignment information, and sequences, effectively\ncollapsing very large datasets to less than 15% of their original size with no\nloss of information.\n  Availability: Quip is freely available under the BSD license from\nhttp://cs.washington.edu/homes/dcjones/quip.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 17:49:17 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Jones", "Daniel C.", ""], ["Ruzzo", "Walter L.", ""], ["Peng", "Xinxia", ""], ["Katze", "Michael G.", ""]]}, {"id": "1207.2506", "submitter": "Muad Abu-Ata", "authors": "Feodor F. Dragan and Muad Abu-Ata", "title": "Collective Additive Tree Spanners of Bounded Tree-Breadth Graphs with\n  Generalizations and Consequences", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study collective additive tree spanners for families of\ngraphs enjoying special Robertson-Seymour's tree-decompositions, and\ndemonstrate interesting consequences of obtained results. We say that a graph\n$G$ {\\em admits a system of $\\mu$ collective additive tree $r$-spanners}\n(resp., {\\em multiplicative tree $t$-spanners}) if there is a system $\\cT(G)$\nof at most $\\mu$ spanning trees of $G$ such that for any two vertices $x,y$ of\n$G$ a spanning tree $T\\in \\cT(G)$ exists such that $d_T(x,y)\\leq d_G(x,y)+r$\n(resp., $d_T(x,y)\\leq t\\cdot d_G(x,y)$). When $\\mu=1$ one gets the notion of\n{\\em additive tree $r$-spanner} (resp., {\\em multiplicative tree $t$-spanner}).\nIt is known that if a graph $G$ has a multiplicative tree $t$-spanner, then $G$\nadmits a Robertson-Seymour's tree-decomposition with bags of radius at most\n$\\lceil{t/2}\\rceil$ in $G$. We use this to demonstrate that there is a\npolynomial time algorithm that, given an $n$-vertex graph $G$ admitting a\nmultiplicative tree $t$-spanner, constructs a system of at most $\\log_2 n$\ncollective additive tree $O(t\\log n)$-spanners of $G$. That is, with a slight\nincrease in the number of trees and in the stretch, one can \"turn\" a\nmultiplicative tree spanner into a small set of collective additive tree\nspanners. We extend this result by showing that if a graph $G$ admits a\nmultiplicative $t$-spanner with tree-width $k-1$, then $G$ admits a\nRobertson-Seymour's tree-decomposition each bag of which can be covered with at\nmost $k$ disks of $G$ of radius at most $\\lceil{t/2}\\rceil$ each. This is used\nto demonstrate that, for every fixed $k$, there is a polynomial time algorithm\nthat, given an $n$-vertex graph $G$ admitting a multiplicative $t$-spanner with\ntree-width $k-1$, constructs a system of at most $k(1+ \\log_2 n)$ collective\nadditive tree $O(t\\log n)$-spanners of $G$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 22:41:45 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2012 18:03:04 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Dragan", "Feodor F.", ""], ["Abu-Ata", "Muad", ""]]}, {"id": "1207.2598", "submitter": "Shakhar Smorodinsky", "authors": "Guy Even, Shakhar Smorodinsky", "title": "Hitting Sets Online and Unique-Max Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of hitting sets online. The hypergraph (i.e.,\nrange-space consisting of points and ranges) is known in advance, and the\nranges to be stabbed are input one-by-one in an online fashion. The online\nalgorithm must stab each range upon arrival. An online algorithm may add points\nto the hitting set but may not remove already chosen points. The goal is to use\nthe smallest number of points. The best known competitive ratio for hitting\nsets online by Alon et al. \\cite{alon2009online} is $O(\\log n \\cdot \\log m)$\nfor general hypergraphs, where $n$ and $m$ denote the number of points and the\nnumber of ranges, respectively. We consider hypergraphs in which the union of\ntwo intersecting ranges is also a range. Our main result for such hypergraphs\nis as follows. The competitive ratio of the online hitting set problem is at\nmost the unique-max number and at least this number minus one.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 11:18:53 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Even", "Guy", ""], ["Smorodinsky", "Shakhar", ""]]}, {"id": "1207.2632", "submitter": "sharma V. Thankachan Mr", "authors": "Rahul Shah, Cheng Sheng, Sharma V. Thankachan, Jeffrey Scott Vitter", "title": "On Optimal Top-K String Retrieval", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\cal{D}}$ = $\\{d_1, d_2, d_3, ..., d_D\\}$ be a given set of $D$\n(string) documents of total length $n$. The top-$k$ document retrieval problem\nis to index $\\cal{D}$ such that when a pattern $P$ of length $p$, and a\nparameter $k$ come as a query, the index returns the $k$ most relevant\ndocuments to the pattern $P$. Hon et. al. \\cite{HSV09} gave the first linear\nspace framework to solve this problem in $O(p + k\\log k)$ time. This was\nimproved by Navarro and Nekrich \\cite{NN12} to $O(p + k)$. These results are\npowerful enough to support arbitrary relevance functions like frequency,\nproximity, PageRank, etc. In many applications like desktop or email search,\nthe data resides on disk and hence disk-bound indexes are needed. Despite of\ncontinued progress on this problem in terms of theoretical, practical and\ncompression aspects, any non-trivial bounds in external memory model have so\nfar been elusive. Internal memory (or RAM) solution to this problem decomposes\nthe problem into $O(p)$ subproblems and thus incurs the additive factor of\n$O(p)$. In external memory, these approaches will lead to $O(p)$ I/Os instead\nof optimal $O(p/B)$ I/O term where $B$ is the block-size. We re-interpret the\nproblem independent of $p$, as interval stabbing with priority over tree-shaped\nstructure. This leads us to a linear space index in external memory supporting\ntop-$k$ queries (with unsorted outputs) in near optimal $O(p/B + \\log_B n +\n\\log^{(h)} n + k/B)$ I/Os for any constant $h${$\\log^{(1)}n =\\log n$ and\n$\\log^{(h)} n = \\log (\\log^{(h-1)} n)$}. Then we get $O(n\\log^*n)$ space index\nwith optimal $O(p/B+\\log_B n + k/B)$ I/Os.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 13:30:06 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2012 15:55:16 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Shah", "Rahul", ""], ["Sheng", "Cheng", ""], ["Thankachan", "Sharma V.", ""], ["Vitter", "Jeffrey Scott", ""]]}, {"id": "1207.2837", "submitter": "Abdurashid Mamadolimov Ph.D.", "authors": "Abdurashid Mamadolimov", "title": "Search Algorithms for Conceptual Graph Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a database composed of a set of conceptual graphs. Using\nconceptual graphs and graph homomorphism it is possible to build a basic\nquery-answering mechanism based on semantic search. Graph homomorphism defines\na partial order over conceptual graphs. Since graph homomorphism checking is an\nNP-Complete problem, the main requirement for database organizing and managing\nalgorithms is to reduce the number of homomorphism checks. Searching is a basic\noperation for database manipulating problems. We consider the problem of\nsearching for an element in a partially ordered set. The goal is to minimize\nthe number of queries required to find a target element in the worst case.\nFirst we analyse conceptual graph database operations. Then we propose a new\nalgorithm for a subclass of lattices. Finally, we suggest a parallel search\nalgorithm for a general poset. Keywords. Conceptual Graph, Graph Homomorphism,\nPartial Order, Lattice, Search, Database.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 03:32:16 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Mamadolimov", "Abdurashid", ""]]}, {"id": "1207.2847", "submitter": "Kai Liu", "authors": "Kai Liu, Hock Beng Lim", "title": "Positioning Accuracy Improvement via Distributed Location Estimate in\n  Cooperative Vehicular Networks", "comments": "To appear in Proc. of the 15th International IEEE Conference on\n  Intelligent Transportation Systems (IEEE ITSC'12)", "journal-ref": null, "doi": "10.1109/ITSC.2012.6338743", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of cooperative vehicle safety (CVS) applications, such as\ncollision warnings, turning assistants, and speed advisories, etc., has\nreceived great attention in the past few years. Accurate vehicular localization\nis essential to enable these applications. In this study, motivated by the\nproliferation of the Global Positioning System (GPS) devices, and the\nincreasing sophistication of wireless communication technologies in vehicular\nnetworks, we propose a distributed location estimate algorithm to improve the\npositioning accuracy via cooperative inter-vehicle distance measurement. In\nparticular, we compute the inter-vehicle distance based on raw GPS pseudorange\nmeasurements, instead of depending on traditional radio-based ranging\ntechniques, which usually either suffer from high hardware cost or have\ninadequate positioning accuracy. In addition, we improve the estimation of the\nvehicles' locations only based on the inaccurate GPS fixes, without using any\nanchors with known exact locations. The algorithm is decentralized, which\nenhances its practicability in highly dynamic vehicular networks. We have\ndeveloped a simulation model to evaluate the performance of the proposed\nalgorithm, and the results demonstrate that the algorithm can significantly\nimprove the positioning accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 05:27:16 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2012 06:32:37 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2012 08:33:23 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Liu", "Kai", ""], ["Lim", "Hock Beng", ""]]}, {"id": "1207.3024", "submitter": "Jinyun Yan", "authors": "Jos\\'e Bento, Stratis Ioannidis, S. Muthukrishnan, Jinyun Yan", "title": "A Time and Space Efficient Algorithm for Contextual Linear Bandits", "comments": "European Conference on Machine Learning and Principles and Practice\n  of Knowledge Discovery in Databases (ECMLPKDD 2013), Prague, Czech Republic,\n  September 23-27, 2013. Proceedings. Springer, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit problem where payoffs are a linear function\nof an observed stochastic contextual variable. In the scenario where there\nexists a gap between optimal and suboptimal rewards, several algorithms have\nbeen proposed that achieve $O(\\log T)$ regret after $T$ time steps. However,\nproposed methods either have a computation complexity per iteration that scales\nlinearly with $T$ or achieve regrets that grow linearly with the number of\ncontexts $|\\myset{X}|$. We propose an $\\epsilon$-greedy type of algorithm that\nsolves both limitations. In particular, when contexts are variables in\n$\\reals^d$, we prove that our algorithm has a constant computation complexity\nper iteration of $O(poly(d))$ and can achieve a regret of $O(poly(d) \\log T)$\neven when $|\\myset{X}| = \\Omega (2^d) $. In addition, unlike previous\nalgorithms, its space complexity scales like $O(Kd^2)$ and does not grow with\n$T$.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 17:15:06 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2013 06:41:55 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2013 22:21:13 GMT"}, {"version": "v4", "created": "Sun, 6 Jul 2014 22:39:15 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Bento", "Jos\u00e9", ""], ["Ioannidis", "Stratis", ""], ["Muthukrishnan", "S.", ""], ["Yan", "Jinyun", ""]]}, {"id": "1207.3056", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal N. Chaudhury, Amit Singer", "title": "Non-Local Euclidean Medians", "comments": "6 figures, 1 table", "journal-ref": "IEEE Signal Processing Letters, vol. 19(11), pp. 745 - 748, 2012", "doi": "10.1109/LSP.2012.2217329", "report-no": null, "categories": "cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we note that the denoising performance of Non-Local Means\n(NLM) at large noise levels can be improved by replacing the mean by the\nEuclidean median. We call this new denoising algorithm the Non-Local Euclidean\nMedians (NLEM). At the heart of NLEM is the observation that the median is more\nrobust to outliers than the mean. In particular, we provide a simple geometric\ninsight that explains why NLEM performs better than NLM in the vicinity of\nedges, particularly at large noise levels. NLEM can be efficiently implemented\nusing iteratively reweighted least squares, and its computational complexity is\ncomparable to that of NLM. We provide some preliminary results to study the\nproposed algorithm and to compare it with NLM.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 18:39:10 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2012 21:25:51 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Chaudhury", "Kunal N.", ""], ["Singer", "Amit", ""]]}, {"id": "1207.3165", "submitter": "Kai-Simon Goetzmann", "authors": "Christina B\\\"using (1), Kai-Simon Goetzmann (2), Jannik Matuschke (2),\n  Sebastian Stiller (2) ((1) RWTH Aachen, (2) TU Berlin)", "title": "Reference Point Methods and Approximation in Multicriteria Optimization", "comments": "19 pages. Submitted. Small error in Section 4 corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operations research applications often pose multicriteria problems.\nMathematical research on multicriteria problems predominantly revolves around\nthe set of Pareto optimal solutions, while in practice, methods that output a\nsingle solution are more widespread. In real-world multicriteria optimization,\nreference point methods are widely used and successful examples of such\nmethods. A reference point solution is the solution closest to a given\nreference point in the objective space.\n  We study the approximation of reference point solutions. In particular, we\nestablish that approximating reference point solutions is polynomially\nequivalent to approximating the Pareto set. Complementing these results, we\nshow for a number of general algorithmic techniques in single criteria\noptimization how they can be lifted to reference point optimization. In\nparticular, we lift the link between dynamic programming and FPTAS, as well as\noblivious LP-rounding techniques. The latter applies, e.g., to Set Cover and\nseveral machine scheduling problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 08:27:08 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 10:35:13 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 14:12:05 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["B\u00fcsing", "Christina", "", "RWTH Aachen"], ["Goetzmann", "Kai-Simon", "", "TU Berlin"], ["Matuschke", "Jannik", "", "TU Berlin"], ["Stiller", "Sebastian", "", "TU Berlin"]]}, {"id": "1207.3523", "submitter": "Leah Epstein", "authors": "Leah Epstein, Asaf Levin, and Rob van Stee", "title": "A unified approach to truthful scheduling on related machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for designing deterministic monotone\npolynomial time approximation schemes (PTAS's) for a wide class of scheduling\nproblems on uniformly related machines. This class includes (among others)\nminimizing the makespan, maximizing the minimum load, and minimizing the l_p\nnorm of the machine loads vector. Previously, this kind of result was only\nknown for the makespan objective. Monotone algorithms have the property that an\nincrease in the speed of a machine cannot decrease the amount of work assigned\nto it. The key idea of our novel method is to show that for goal functions that\nare sufficiently well-behaved functions of the machine loads, it is possible to\ncompute in polynomial time a highly structured nearly optimal schedule.\nMonotone approximation schemes have an important role in the emerging area of\nalgorithmic mechanism design. In the game-theoretical setting of these\nscheduling problems there is a social goal, which is one of the objective\nfunctions that we study. Each machine is controlled by a selfish\nsingle-parameter agent, where its private information is its cost of processing\na unit sized job, which is also the inverse of the speed of its machine. Each\nagent wishes to maximize its own profit, defined as the payment it receives\nfrom the mechanism minus its cost for processing all jobs assigned to it, and\nplaces a bid which corresponds to its private information. For each one of the\nproblems, we show that we can calculate payments that guarantee truthfulness in\nan efficient manner. Thus, there exists a dominant strategy where agents report\ntheir true speeds, and we show the existence of a truthful mechanism which can\nbe implemented in polynomial time, where the social goal is approximated within\na factor of 1+epsilon for every epsilon>0.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2012 15:33:28 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Epstein", "Leah", ""], ["Levin", "Asaf", ""], ["van Stee", "Rob", ""]]}, {"id": "1207.3532", "submitter": "Xifeng Yan Xifeng Yan", "authors": "Yang Li, Pegah Kamousi, Fangqiu Han, Shengqi Yang, Xifeng Yan, Subhash\n  Suri", "title": "Memory Efficient De Bruijn Graph Construction", "comments": "13 pages, 19 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively parallel DNA sequencing technologies are revolutionizing genomics\nresearch. Billions of short reads generated at low costs can be assembled for\nreconstructing the whole genomes. Unfortunately, the large memory footprint of\nthe existing de novo assembly algorithms makes it challenging to get the\nassembly done for higher eukaryotes like mammals. In this work, we investigate\nthe memory issue of constructing de Bruijn graph, a core task in leading\nassembly algorithms, which often consumes several hundreds of gigabytes memory\nfor large genomes. We propose a disk-based partition method, called Minimum\nSubstring Partitioning (MSP), to complete the task using less than 10 gigabytes\nmemory, without runtime slowdown. MSP breaks the short reads into multiple\nsmall disjoint partitions so that each partition can be loaded into memory,\nprocessed individually and later merged with others to form a de Bruijn graph.\nBy leveraging the overlaps among the k-mers (substring of length k), MSP\nachieves astonishing compression ratio: The total size of partitions is reduced\nfrom $\\Theta(kn)$ to $\\Theta(n)$, where $n$ is the size of the short read\ndatabase, and $k$ is the length of a $k$-mer. Experimental results show that\nour method can build de Bruijn graphs using a commodity computer for any\nlarge-volume sequence dataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2012 19:45:19 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Li", "Yang", ""], ["Kamousi", "Pegah", ""], ["Han", "Fangqiu", ""], ["Yang", "Shengqi", ""], ["Yan", "Xifeng", ""], ["Suri", "Subhash", ""]]}, {"id": "1207.3564", "submitter": "Yitong Yin", "authors": "Yitong Yin and Chihao Zhang", "title": "Approximate Counting via Correlation Decay on Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show for a broad class of counting problems, correlation decay (strong\nspatial mixing) implies FPTAS on planar graphs. The framework for the counting\nproblems considered by us is the Holant problems with arbitrary constant-size\ndomain and symmetric constraint functions. We define a notion of regularity on\nthe constraint functions, which covers a wide range of natural and important\ncounting problems, including all multi-state spin systems, counting graph\nhomomorphisms, counting weighted matchings or perfect matchings, the subgraphs\nworld problem transformed from the ferromagnetic Ising model, and all counting\nCSPs and Holant problems with symmetric constraint functions of constant arity.\n  The core of our algorithm is a fixed-parameter tractable algorithm which\ncomputes the exact values of the Holant problems with regular constraint\nfunctions on graphs of bounded treewidth. By utilizing the locally tree-like\nproperty of apex-minor-free families of graphs, the parameterized exact\nalgorithm implies an FPTAS for the Holant problem on these graph families\nwhenever the Gibbs measure defined by the problem exhibits strong spatial\nmixing. We further extend the recursive coupling technique to Holant problems\nand establish strong spatial mixing for the ferromagnetic Potts model and the\nsubgraphs world problem. As consequences, we have new deterministic\napproximation algorithms on planar graphs and all apex-minor-free graphs for\nseveral counting problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 02:35:37 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Yin", "Yitong", ""], ["Zhang", "Chihao", ""]]}, {"id": "1207.3586", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin, Mark Jones", "title": "Directed Acyclic Subgraph Problem Parameterized above the Poljak-Turzik\n  Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An oriented graph is a directed graph without directed 2-cycles. Poljak and\nTurz\\'{i}k (1986) proved that every connected oriented graph $G$ on $n$\nvertices and $m$ arcs contains an acyclic subgraph with at least\n$\\frac{m}{2}+\\frac{n-1}{4}$ arcs. Raman and Saurabh (2006) gave another proof\nof this result and left it as an open question to establish the parameterized\ncomplexity of the following problem: does $G$ have an acyclic subgraph with\nleast $\\frac{m}{2}+\\frac{n-1}{4}+k$ arcs, where $k$ is the parameter? We answer\nthis question by showing that the problem can be solved by an algorithm of\nruntime $(12k)!n^{O(1)}$. Thus, the problem is fixed-parameter tractable. We\nalso prove that there is a polynomial time algorithm that either establishes\nthat the input instance of the problem is a Yes-instance or reduces the input\ninstance to an equivalent one of size $O(k^2)$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 06:36:56 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2012 13:10:18 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""]]}, {"id": "1207.3622", "submitter": "Liam Roditty", "authors": "Liam Roditty and Virginia Vassilevska Williams", "title": "Approximating the diameter of a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the fundamental problem of approximating the\ndiameter $D$ of directed or undirected graphs. In a seminal paper, Aingworth,\nChekuri, Indyk and Motwani [SIAM J. Comput. 1999] presented an algorithm that\ncomputes in $\\Ot(m\\sqrt n + n^2)$ time an estimate $\\hat{D}$ for the diameter\nof an $n$-node, $m$-edge graph, such that $\\lfloor 2/3 D \\rfloor \\leq \\hat{D}\n\\leq D$. In this paper we present an algorithm that produces the same estimate\nin $\\Ot(m\\sqrt n)$ expected running time. We then provide strong evidence that\na better approximation may be hard to obtain if we insist on an $O(m^{2-\\eps})$\nrunning time. In particular, we show that if there is some constant $\\eps>0$ so\nthat there is an algorithm for undirected unweighted graphs that runs in\n$O(m^{2-\\eps})$ time and produces an approximation $\\hat{D}$ such that $\n(2/3+\\eps) D \\leq \\hat{D} \\leq D$, then SAT for CNF formulas on $n$ variables\ncan be solved in $O^{*}((2-\\delta)^{n})$ time for some constant $\\delta>0$, and\nthe strong exponential time hypothesis of [Impagliazzo, Paturi, Zane JCSS'01]\nis false.\n  Motivated by this somewhat negative result, we study whether it is possible\nto obtain a better approximation for specific cases. For unweighted directed or\nundirected graphs, we show that if $D=3h+z$, where $h\\geq 0$ and $z\\in\n{0,1,2}$, then it is possible to report in $\\tilde{O}(\\min{m^{2/3}\nn^{4/3},m^{2-1/(2h+3)}})$ time an estimate $\\hat{D}$ such that $2h+z \\leq\n\\hat{D}\\leq D$, thus giving a better than 3/2 approximation whenever $z\\neq 0$.\nThis is significant for constant values of $D$ which is exactly when the\ndiameter approximation problem is hardest to solve. For the case of unweighted\nundirected graphs we present an $\\tilde{O}(m^{2/3} n^{4/3})$ time algorithm\nthat reports an estimate $\\hat{D}$ such that $\\lfloor 4D/5\\rfloor \\leq\n\\hat{D}\\leq D$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 10:25:13 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Roditty", "Liam", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1207.3807", "submitter": "Hao-Hsiang Hung", "authors": "Hao-Hsiang Hung", "title": "Light Spanner and Monotone Tree", "comments": "arXiv admin note: text overlap with arXiv:1104.4669", "journal-ref": null, "doi": "10.1007/978-3-642-32589-2_42", "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In approximation algorithm design, light spanners has applications in\ngraph-metric problems such as metric TSP (the traveling salesman problem). We\nhave developed an efficient algorithm for light spanners in bounded pathwidth\ngraphs, based on an intermediate data structure called monotone tree. In this\npaper, we extended the results to include bounded catwidth graphs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 20:01:55 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Hung", "Hao-Hsiang", ""]]}, {"id": "1207.3914", "submitter": "Gerd Zschaler", "authors": "Gerd Zschaler, Thilo Gross", "title": "Largenet2: an object-oriented programming library for simulating large\n  adaptive networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The largenet2 C++ library provides an infrastructure for the simulation of\nlarge dynamic and adaptive networks with discrete node and link states. The\nlibrary is released as free software. It is available at\nhttp://rincedd.github.com/largenet2. Largenet2 is licensed under the Creative\nCommons Attribution-NonCommercial 3.0 Unported License.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 08:41:07 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Zschaler", "Gerd", ""], ["Gross", "Thilo", ""]]}, {"id": "1207.3976", "submitter": "Manoj Gupta", "authors": "Abhash Anand and Surender Baswana and Manoj Gupta and Sandeep Sen", "title": "Maintaining Approximate Maximum Weighted Matching in Fully Dynamic\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully dynamic algorithm for maintaining approximate maximum\nweight matching in general weighted graphs. The algorithm maintains a matching\n${\\cal M}$ whose weight is at least $1/8 M^{*}$ where $M^{*}$ is the weight of\nthe maximum weight matching. The algorithm achieves an expected amortized\n$O(\\log n \\log \\mathcal C)$ time per edge insertion or deletion, where\n$\\mathcal C$ is the ratio of the weights of the highest weight edge to the\nsmallest weight edge in the given graph. Using a simple randomized scaling\ntechnique, we are able to obtain a matching whith expected approximation ratio\n4.9108.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 12:51:55 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2012 17:01:03 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2012 07:09:40 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Anand", "Abhash", ""], ["Baswana", "Surender", ""], ["Gupta", "Manoj", ""], ["Sen", "Sandeep", ""]]}, {"id": "1207.4074", "submitter": "Sebastian Roch", "authors": "Sebastien Roch", "title": "An analytical comparison of coalescent-based multilocus methods: The\n  three-taxon case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomplete lineage sorting (ILS) is a common source of gene tree incongruence\nin multilocus analyses. A large number of methods have been developed to infer\nspecies trees in the presence of ILS. Here we provide a mathematical analysis\nof several coalescent-based methods. Our analysis is performed on a three-taxon\nspecies tree and assumes that the gene trees are correctly reconstructed along\nwith their branch lengths.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:07:34 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Roch", "Sebastien", ""]]}, {"id": "1207.4079", "submitter": "Marcin Pilipczuk", "authors": "Rajesh Chitnis, Marek Cygan, MohammadTaghi Hajiaghayi, Marcin\n  Pilipczuk, Micha{\\l} Pilipczuk", "title": "Designing FPT algorithms for cut problems using randomized contractions", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new technique for designing fixed-parameter algorithms for cut\nproblems, namely randomized contractions. We apply our framework to obtain the\nfirst FPT algorithm for the Unique Label Cover problem and new FPT algorithms\nwith exponential speed up for the Steiner Cut and Node Multiway Cut-Uncut\nproblems. More precisely, we show the following:\n  - We prove that the parameterized version of the Unique Label Cover problem,\nwhich is the base of the Unique Games Conjecture, can be solved in 2^{O(k^2\\log\n|\\Sigma|)}n^4\\log n deterministic time (even in the stronger, vertex-deletion\nvariant) where k is the number of unsatisfied edges and |\\Sigma| is the size of\nthe alphabet. As a consequence, we show that one can in polynomial time solve\ninstances of Unique Games where the number of edges allowed not to be satisfied\nis upper bounded by O(\\sqrt{\\log n}) to optimality, which improves over the\ntrivial O(1) upper bound.\n  - We prove that the Steiner Cut problem can be solved in 2^{O(k^2\\log\nk)}n^4\\log n deterministic time and \\tilde{O}(2^{O(k^2\\log k)}n^2) randomized\ntime where k is the size of the cutset. This result improves the double\nexponential running time of the recent work of Kawarabayashi and Thorup\n(FOCS'11).\n  - We show how to combine considering `cut' and `uncut' constraints at the\nsame time. More precisely, we define a robust problem Node Multiway Cut-Uncut\nthat can serve as an abstraction of introducing uncut constraints, and show\nthat it admits an algorithm running in 2^{O(k^2\\log k)}n^4\\log n deterministic\ntime where k is the size of the cutset. To the best of our knowledge, the only\nknown way of tackling uncut constraints was via the approach of Marx,\nO'Sullivan and Razgon (STACS'10), which yields algorithms with double\nexponential running time.\n  An interesting aspect of our technique is that, unlike important separators,\nit can handle real weights.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:24:13 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 08:15:02 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Cygan", "Marek", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1207.4084", "submitter": "Aaron Roth", "authors": "Michael Kearns and Mallesh M. Pai and Aaron Roth and Jonathan Ullman", "title": "Mechanism Design in Large Games: Incentives and Privacy", "comments": "Conference version appeared in ITCS 2014. This paper has been merged\n  and subsumed by the preprint \"Robust Mediators in Large Games\":\n  http://arxiv.org/abs/1512.02698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of implementing equilibria of complete information games\nin settings of incomplete information, and address this problem using\n\"recommender mechanisms.\" A recommender mechanism is one that does not have the\npower to enforce outcomes or to force participation, rather it only has the\npower to suggestion outcomes on the basis of voluntary participation. We show\nthat despite these restrictions, recommender mechanisms can implement\nequilibria of complete information games in settings of incomplete information\nunder the condition that the game is large---i.e. that there are a large number\nof players, and any player's action affects any other's payoff by at most a\nsmall amount.\n  Our result follows from a novel application of differential privacy. We show\nthat any algorithm that computes a correlated equilibrium of a complete\ninformation game while satisfying a variant of differential privacy---which we\ncall joint differential privacy---can be used as a recommender mechanism while\nsatisfying our desired incentive properties. Our main technical result is an\nalgorithm for computing a correlated equilibrium of a large game while\nsatisfying joint differential privacy.\n  Although our recommender mechanisms are designed to satisfy game-theoretic\nproperties, our solution ends up satisfying a strong privacy property as well.\nNo group of players can learn \"much\" about the type of any player outside the\ngroup from the recommendations of the mechanism, even if these players collude\nin an arbitrary way. As such, our algorithm is able to implement equilibria of\ncomplete information games, without revealing information about the realized\ntypes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:49:58 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2012 20:24:37 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 19:29:53 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2015 16:24:11 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Kearns", "Michael", ""], ["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1207.4109", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Rina Dechter", "title": "A Complete Anytime Algorithm for Treewidth", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-201-208", "categories": "cs.DS cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Branch and Bound algorithm called QuickBB for\ncomputing the treewidth of an undirected graph. This algorithm performs a\nsearch in the space of perfect elimination ordering of vertices of the graph.\nThe algorithm uses novel pruning and propagation techniques which are derived\nfrom the theory of graph minors and graph isomorphism. We present a new\nalgorithm called minor-min-width for computing a lower bound on treewidth that\nis used within the branch and bound algorithm and which improves over earlier\navailable lower bounds. Empirical evaluation of QuickBB on randomly generated\ngraphs and benchmarks in Graph Coloring and Bayesian Networks shows that it is\nconsistently better than complete algorithms like QuickTree [Shoikhet and\nGeiger, 1997] in terms of cpu time. QuickBB also has good anytime performance,\nbeing able to generate a better upper bound on treewidth of some graphs whose\noptimal treewidth could not be computed up to now.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:41:27 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Gogate", "Vibhav", ""], ["Dechter", "Rina", ""]]}, {"id": "1207.4127", "submitter": "Bozhena Bidyuk", "authors": "Bozhena Bidyuk, Rina Dechter", "title": "On finding minimal w-cutset", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-43-50", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of a reasoning task over a graphical model is tied to the\ninduced width of the underlying graph. It is well-known that the conditioning\n(assigning values) on a subset of variables yields a subproblem of the reduced\ncomplexity where instantiated variables are removed. If the assigned variables\nconstitute a cycle-cutset, the rest of the network is singly-connected and\ntherefore can be solved by linear propagation algorithms. A w-cutset is a\ngeneralization of a cycle-cutset defined as a subset of nodes such that the\nsubgraph with cutset nodes removed has induced-width of w or less. In this\npaper we address the problem of finding a minimal w-cutset in a graph. We\nrelate the problem to that of finding the minimal w-cutset of a\ntreedecomposition. The latter can be mapped to the well-known set multi-cover\nproblem. This relationship yields a proof of NP-completeness on one hand and a\ngreedy algorithm for finding a w-cutset of a tree decomposition on the other.\nEmpirical evaluation of the algorithms is presented.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:47:24 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Bidyuk", "Bozhena", ""], ["Dechter", "Rina", ""]]}, {"id": "1207.4151", "submitter": "Mukund Narasimhan", "authors": "Mukund Narasimhan, Jeff A. Bilmes", "title": "PAC-learning bounded tree-width Graphical Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-410-417", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the class of strongly connected graphical models with treewidth\nat most k can be properly efficiently PAC-learnt with respect to the\nKullback-Leibler Divergence. Previous approaches to this problem, such as those\nof Chow ([1]), and Ho gen ([7]) have shown that this class is PAC-learnable by\nreducing it to a combinatorial optimization problem. However, for k > 1, this\nproblem is NP-complete ([15]), and so unless P=NP, these approaches will take\nexponential amounts of time. Our approach differs significantly from these, in\nthat it first attempts to find approximate conditional independencies by\nsolving (polynomially many) submodular optimization problems, and then using a\ndynamic programming formulation to combine the approximate conditional\nindependence information to derive a graphical model with underlying graph of\nthe tree-width specified. This gives us an efficient (polynomial time in the\nnumber of random variables) PAC-learning algorithm which requires only\npolynomial number of samples of the true distribution, and only polynomial\nrunning time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:57:38 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Narasimhan", "Mukund", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1207.4366", "submitter": "Zeev Nutov", "authors": "Zeev Nutov", "title": "Approximating minimum-cost edge-covers of crossing biset-families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordered pair $\\hat{S}=(S,S^+)$ of subsets of $V$ is called a {\\em biset}\nif $S \\subseteq S^+$; $(V-S^+,V-S)$ is the co-biset of $\\hat{S}$. Two bisets\n$\\hat{X},\\hat{Y}$ intersect if $X \\cap Y \\neq \\emptyset$ and cross if both $X\n\\cap Y \\neq \\emptyset$ and $X^+ \\cup Y^+ \\neq V$. The intersection and the\nunion of two bisets $\\hat{X},\\hat{Y}$ is defined by $\\hat{X} \\cap \\hat{Y} = (X\n\\cap Y, X^+ \\cap Y^+)$ and $\\hat{X} \\cup \\hat{Y} = (X \\cup Y,X^+ \\cup Y^+)$. A\nbiset-family ${\\cal F}$ is crossing (intersecting) if $\\hat{X} \\cap \\hat{Y},\n\\hat{X} \\cup \\hat{Y} \\in {\\cal F}$ for any $\\hat{X},\\hat{Y} \\in {\\cal F}$ that\ncross (intersect). A directed edge covers a biset $\\hat{S}$ if it goes from $S$\nto $V-S^+$. We consider the problem of covering a crossing biset-family ${\\cal\nF}$ by a minimum-cost set of directed edges. While for intersecting ${\\cal F}$,\na standard primal-dual algorithm computes an optimal solution, the\napproximability of the case of crossing ${\\cal F}$ is not yet understood, as it\nincludes several NP-hard problems, for which a poly-logarithmic approximation\nwas discovered only recently. Let us say that a biset-family ${\\cal F}$ is\n$k$-regular if $\\hat{X} \\cap \\hat{Y}, \\hat{X} \\cup \\hat{Y} \\in {\\cal F}$ for\nany $\\hat{X},\\hat{Y} \\in {\\cal F}$ with $|V-(X \\cup Y)| \\geq k+1$ that\nintersect. In this paper we obtain an $O(\\log |V|)$-approximation algorithm for\narbitrary crossing ${\\cal F}$; if in addition both ${\\cal F}$ and the family of\nco-bisets of ${\\cal F}$ are $k$-regular, our ratios are: $O(\\log\n\\frac{|V|}{|V|-k})$ if $|S^+ \\setminus S|=k$ for all $\\hat{S} \\in {\\cal F}$,\nand $O(\\frac{|V|}{|V|-k} \\log \\frac{|V|}{|V|-k})$ if $|S^+ \\setminus S| \\leq k$\nfor all $\\hat{S} \\in {\\cal F}$. Using these generic algorithms, we derive\napproximation algorithms for some network design problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 13:08:39 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Nutov", "Zeev", ""]]}, {"id": "1207.4372", "submitter": "Ali Sinop", "authors": "Venkatesan Guruswami and Ali Kemal Sinop", "title": "Faster SDP hierarchy solvers for local rounding algorithms", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations based on different hierarchies of linear/semi-definite\nprograms have been used recently to devise approximation algorithms for various\noptimization problems. The approximation guarantee of these algorithms improves\nwith the number of {\\em rounds} $r$ in the hierarchy, though the complexity of\nsolving (or even writing down the solution for) the $r$'th level program grows\nas $n^{\\Omega(r)}$ where $n$ is the input size.\n  In this work, we observe that many of these algorithms are based on {\\em\nlocal} rounding procedures that only use a small part of the SDP solution (of\nsize $n^{O(1)} 2^{O(r)}$ instead of $n^{\\Omega(r)}$). We give an algorithm to\nfind the requisite portion in time polynomial in its size. The challenge in\nachieving this is that the required portion of the solution is not fixed a\npriori but depends on other parts of the solution, sometimes in a complicated\niterative manner.\n  Our solver leads to $n^{O(1)} 2^{O(r)}$ time algorithms to obtain the same\nguarantees in many cases as the earlier $n^{O(r)}$ time algorithms based on $r$\nrounds of the Lasserre hierarchy. In particular, guarantees based on $O(\\log\nn)$ rounds can be realized in polynomial time.\n  We develop and describe our algorithm in a fairly general abstract framework.\nThe main technical tool in our work, which might be of independent interest in\nconvex optimization, is an efficient ellipsoid algorithm based separation\noracle for convex programs that can output a {\\em certificate of infeasibility\nwith restricted support}. This is used in a recursive manner to find a sequence\nof consistent points in nested convex bodies that \"fools\" local rounding\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 13:21:26 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 17:55:18 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1207.4382", "submitter": "Zhewei Wei", "authors": "Zhewei Wei, Ke Yi", "title": "The Space Complexity of 2-Dimensional Approximate Range Counting", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of $2$-dimensional orthogonal range counting with\nadditive error. Given a set $P$ of $n$ points drawn from an $n\\times n$ grid\nand an error parameter $\\eps$, the goal is to build a data structure, such that\nfor any orthogonal range $R$, it can return the number of points in $P\\cap R$\nwith additive error $\\eps n$. A well-known solution for this problem is the\n{\\em $\\eps$-approximation}, which is a subset $A\\subseteq P$ that can estimate\nthe number of points in $P\\cap R$ with the number of points in $A\\cap R$. It is\nknown that an $\\eps$-approximation of size $O(\\frac{1}{\\eps} \\log^{2.5}\n\\frac{1}{\\eps})$ exists for any $P$ with respect to orthogonal ranges, and the\nbest lower bound is $\\Omega(\\frac{1}{\\eps} \\log \\frac{1}{\\eps})$. The\n$\\eps$-approximation is a rather restricted data structure, as we are not\nallowed to store any information other than the coordinates of the points in\n$P$. In this paper, we explore what can be achieved without any restriction on\nthe data structure. We first describe a simple data structure that uses\n$O(\\frac{1}{\\eps}(\\log^2\\frac{1} {\\eps} + \\log n) )$ bits and answers queries\nwith error $\\eps n$. We then prove a lower bound that any data structure that\nanswers queries with error $\\eps n$ must use\n$\\Omega(\\frac{1}{\\eps}(\\log^2\\frac{1} {\\eps} + \\log n) )$ bits. Our lower bound\nis information-theoretic: We show that there is a collection of\n$2^{\\Omega(n\\log n)}$ point sets with large {\\em union combinatorial\ndiscrepancy}, and thus are hard to distinguish unless we use $\\Omega(n\\log n)$\nbits.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 14:25:56 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 12:13:49 GMT"}, {"version": "v3", "created": "Mon, 23 May 2016 02:38:05 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Wei", "Zhewei", ""], ["Yi", "Ke", ""]]}, {"id": "1207.4383", "submitter": "Zhewei Wei", "authors": "Zhewei Wei, Ke Yi", "title": "Equivalence between Priority Queues and Sorting in External Memory", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A priority queue is a fundamental data structure that maintains a dynamic\nordered set of keys and supports the followig basic operations: insertion of a\nkey, deletion of a key, and finding the smallest key. The complexity of the\npriority queue is closely related to that of sorting: A priority queue can be\nused to implement a sorting algorithm trivially. Thorup\n\\cite{thorup2007equivalence} proved that the converse is also true in the RAM\nmodel. In particular, he designed a priority queue that uses the sorting\nalgorithm as a black box, such that the per-operation cost of the priority\nqueue is asymptotically the same as the per-key cost of sorting. In this paper,\nwe prove an analogous result in the external memory model, showing that\npriority queues are computationally equivalent to sorting in external memory,\nunder some mild assumptions. The reduction provides a possibility for proving\nlower bounds for external sorting via showing a lower bound for priority\nqueues.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 14:32:57 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Wei", "Zhewei", ""], ["Yi", "Ke", ""]]}, {"id": "1207.4497", "submitter": "Nicholas Pippenger", "authors": "Connor Ahlbach, Jeremy Usatine and Nicholas Pippenger", "title": "Efficient Algorithms for Zeckendorf Arithmetic", "comments": "i+6 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of addition and subtraction using the Zeckendorf\nrepresentation of integers. We show that both operations can be performed in\nlinear time; in fact they can be performed by combinational logic networks with\nlinear size and logarithmic depth. The implications of these results for\nmultiplication, division and square-root extraction are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 20:27:09 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Ahlbach", "Connor", ""], ["Usatine", "Jeremy", ""], ["Pippenger", "Nicholas", ""]]}, {"id": "1207.4556", "submitter": "Ralph Neininger", "authors": "Ralph Neininger", "title": "Refined Quicksort asymptotics", "comments": "revised version; title slightly changed; accepted for publication in\n  Random Structures and Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of the Quicksort algorithm is usually measured by the number\nof key comparisons used during its execution. When operating on a list of $n$\ndata, permuted uniformly at random, the appropriately normalized complexity\n$Y_n$ is known to converge almost surely to a non-degenerate random limit $Y$.\nThis assumes a natural embedding of all $Y_n$ on one probability space, e.g.,\nvia random binary search trees. In this note a central limit theorem for the\nerror term in the latter almost sure convergence is shown:\n$$\\sqrt{\\frac{n}{2\\log n}}(Y_n-Y) \\stackrel{d}{\\longrightarrow} {\\cal N} \\qquad\n(n\\to\\infty),$$ where ${\\cal N}$ denotes a standard normal random variable.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 05:47:42 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 11:33:51 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Neininger", "Ralph", ""]]}, {"id": "1207.4567", "submitter": "Rong-Hua Li", "authors": "Rong-Hua Li, Jeffrey Xu Yu", "title": "Efficient Core Maintenance in Large Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-core decomposition in a graph is a fundamental problem for social\nnetwork analysis. The problem of $k$-core decomposition is to calculate the\ncore number for every node in a graph. Previous studies mainly focus on\n$k$-core decomposition in a static graph. There exists a linear time algorithm\nfor $k$-core decomposition in a static graph. However, in many real-world\napplications such as online social networks and the Internet, the graph\ntypically evolves over time. Under such applications, a key issue is to\nmaintain the core number of nodes given the graph changes over time. A simple\nimplementation is to perform the linear time algorithm to recompute the core\nnumber for every node after the graph is updated. Such simple implementation is\nexpensive when the graph is very large. In this paper, we propose a new\nefficient algorithm to maintain the core number for every node in a dynamic\ngraph. Our main result is that only certain nodes need to update their core\nnumber given the graph is changed by inserting/deleting an edge. We devise an\nefficient algorithm to identify and recompute the core number of such nodes.\nThe complexity of our algorithm is independent of the graph size. In addition,\nto further accelerate the algorithm, we develop two pruning strategies by\nexploiting the lower and upper bounds of the core number. Finally, we conduct\nextensive experiments over both real-world and synthetic datasets, and the\nresults demonstrate the efficiency of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 06:57:10 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Li", "Rong-Hua", ""], ["Yu", "Jeffrey Xu", ""]]}, {"id": "1207.4598", "submitter": "Lu\\'is M. S. Russo", "authors": "Lu\\'is M. S. Russo, Alexandre P. Francisco", "title": "Quick HyperVolume", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to calculate exact hypervolumes. Given a set of\n$d$-dimensional points, it computes the hypervolume of the dominated space.\nDetermining this value is an important subroutine of Multiobjective\nEvolutionary Algorithms (MOEAs). We analyze the \"Quick Hypervolume\" (QHV)\nalgorithm theoretically and experimentally. The theoretical results are a\nsignificant contribution to the current state of the art. Moreover the\nexperimental performance is also very competitive, compared with existing exact\nhypervolume algorithms.\n  A full description of the algorithm is currently submitted to IEEE\nTransactions on Evolutionary Computation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 09:56:17 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 17:06:11 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Russo", "Lu\u00eds M. S.", ""], ["Francisco", "Alexandre P.", ""]]}, {"id": "1207.4607", "submitter": "Hideo Bannai", "authors": "Hideo Bannai, Shunsuke Inenaga, Masayuki Takeda", "title": "Efficient LZ78 factorization of grammar compressed text", "comments": "SPIRE 2012", "journal-ref": null, "doi": "10.1007/978-3-642-34109-0_10", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm for computing the LZ78 factorization of a\ntext, where the text is represented as a straight line program (SLP), which is\na context free grammar in the Chomsky normal form that generates a single\nstring. Given an SLP of size $n$ representing a text $S$ of length $N$, our\nalgorithm computes the LZ78 factorization of $T$ in $O(n\\sqrt{N}+m\\log N)$ time\nand $O(n\\sqrt{N}+m)$ space, where $m$ is the number of resulting LZ78 factors.\nWe also show how to improve the algorithm so that the $n\\sqrt{N}$ term in the\ntime and space complexities becomes either $nL$, where $L$ is the length of the\nlongest LZ78 factor, or $(N - \\alpha)$ where $\\alpha \\geq 0$ is a quantity\nwhich depends on the amount of redundancy that the SLP captures with respect to\nsubstrings of $S$ of a certain length. Since $m = O(N/\\log_\\sigma N)$ where\n$\\sigma$ is the alphabet size, the latter is asymptotically at least as fast as\na linear time algorithm which runs on the uncompressed string when $\\sigma$ is\nconstant, and can be more efficient when the text is compressible, i.e. when\n$m$ and $n$ are small.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 10:28:56 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Bannai", "Hideo", ""], ["Inenaga", "Shunsuke", ""], ["Takeda", "Masayuki", ""]]}, {"id": "1207.4616", "submitter": "Patrick Prosser", "authors": "Patrick Prosser", "title": "Exact Algorithms for Maximum Clique: a computational study", "comments": "40 pages, 14 figures, 10 tables, 12 short java program listings, code\n  afailable to download at\n  http://www.dcs.gla.ac.uk/~pat/maxClique/distribution/", "journal-ref": null, "doi": null, "report-no": "TR-2012-333", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a number of recently reported exact algorithms for the maximum\nclique problem (MCQ, MCR, MCS, BBMC). The program code used is presented and\ncritiqued showing how small changes in implementation can have a drastic effect\non performance. The computational study demonstrates how problem features and\nhardware platforms influence algorithm behaviour. The minimum width order\n(smallest-last) is investigated, and MCS is broken into its consituent parts\nand we discover that one of these parts degrades performance. It is shown that\nthe standard procedure used for rescaling published results is unsafe.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 11:26:59 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Prosser", "Patrick", ""]]}, {"id": "1207.4666", "submitter": "Lukasz Kowalik", "authors": "Lukasz Kowalik, Marcin Mucha", "title": "A 9k kernel for nonseparating independent set in planar graphs", "comments": "An extended abstract was presented at WG 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study kernelization (a kind of efficient preprocessing) for NP-hard\nproblems on planar graphs. Our main result is a kernel of size at most 9k\nvertices for the Planar Maximum Nonseparating Independent Set problem. A direct\nconsequence of this result is that Planar Connected Vertex Cover has no kernel\nwith at most (9/8 - epsilon)k vertices, for any epsilon > 0, assuming P \\ne NP.\nWe also show a very simple 5k-vertices kernel for Planar Max Leaf, which\nresults in a lower bound of (5/4 - epsilon)k vertices for the kernel of Planar\nConnected Dominating Set (also under P \\ne NP).\n  As a by-product we show a few extremal graph theory results which might be of\nindependent interest. We prove that graphs that contain no separator consisting\nof only degree two vertices contain (a) a spanning tree with at least n/4\nleaves and (b) a nonseparating independent set of size at least n/9 (also,\nequivalently, a connected vertex cover of size at most 8/9n). The result (a) is\na generalization of a theorem of Kleitman and West [SIDMA 1991] who showed the\nsame bound for graphs of minimum degree three. Finally we show that every\nn-vertex outerplanar graph contains an independent set I and a collection of\nvertex-disjoint cycles C such that 9|I| >= 4n-3|C|.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 13:44:10 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Kowalik", "Lukasz", ""], ["Mucha", "Marcin", ""]]}, {"id": "1207.4681", "submitter": "Lukasz Kowalik", "authors": "Lukasz Kowalik", "title": "Nonblocker in H-minor free graphs: kernelization meets discharging", "comments": "16 pages; accepted to IPEC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps the best known kernelization result is the kernel of size 335k for\nthe Planar Dominating Set problem by Alber et al. [JACM 2004], later improved\nto 67k by Chen et al. [SICOMP 2007]. This result means roughly, that the\nproblem of finding the smallest dominating set in a planar graph is easy when\nthe optimal solution is small. On the other hand, it is known that Planar\nDominating Set parameterized by k'=|V|-k (also known as Planar Nonblocker) has\na kernel of size 2k'. This means that Planar Dominating Set is easy when the\noptimal solution is very large. We improve the kernel for Planar Nonblocker to\n7/4k'. This also implies that Planar Dominating Set has no kernel of size at\nmost (7/3-epsilon)k, for any epsilon>0, unless P=NP. This improves the previous\nlower bound of (2-epsilon)k of Chen et al. Both of these results immediately\ngeneralize to H-minor free graphs (without changing the constants). In our\nproof of the bound on the kernel size we use a variant of the discharging\nmethod (used e.g. in the proof of the four color theorem). We give some\narguments that this method is natural in the context of kernelization and we\nhope it will be applied to get improved kernel size bounds for other problems\nas well. As a by-product we show a result which might be of independent\ninterest: every n-vertex graph with no isolated vertices and such that every\npair of degree 1 vertices is at distance at least 5 and every pair of degree 2\nvertices is at distance at least 2 has a dominating set of size at most 3/7n.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 14:20:53 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Kowalik", "Lukasz", ""]]}, {"id": "1207.4684", "submitter": "Michael Mahoney", "authors": "Kenneth L. Clarkson and Petros Drineas and Malik Magdon-Ismail and\n  Michael W. Mahoney and Xiangrui Meng and David P. Woodruff", "title": "The Fast Cauchy Transform and Faster Robust Linear Regression", "comments": "48 pages; substantially extended and revised; short version in SODA\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide fast algorithms for overconstrained $\\ell_p$ regression and\nrelated problems: for an $n\\times d$ input matrix $A$ and vector\n$b\\in\\mathbb{R}^n$, in $O(nd\\log n)$ time we reduce the problem\n$\\min_{x\\in\\mathbb{R}^d} \\|Ax-b\\|_p$ to the same problem with input matrix\n$\\tilde A$ of dimension $s \\times d$ and corresponding $\\tilde b$ of dimension\n$s\\times 1$. Here, $\\tilde A$ and $\\tilde b$ are a coreset for the problem,\nconsisting of sampled and rescaled rows of $A$ and $b$; and $s$ is independent\nof $n$ and polynomial in $d$. Our results improve on the best previous\nalgorithms when $n\\gg d$, for all $p\\in[1,\\infty)$ except $p=2$. We also\nprovide a suite of improved results for finding well-conditioned bases via\nellipsoidal rounding, illustrating tradeoffs between running time and\nconditioning quality, including a one-pass conditioning algorithm for general\n$\\ell_p$ problems.\n  We also provide an empirical evaluation of implementations of our algorithms\nfor $p=1$, comparing them with related algorithms. Our empirical results show\nthat, in the asymptotic regime, the theory is a very good guide to the\npractical performance of these algorithms. Our algorithms use our faster\nconstructions of well-conditioned bases for $\\ell_p$ spaces and, for $p=1$, a\nfast subspace embedding of independent interest that we call the Fast Cauchy\nTransform: a distribution over matrices $\\Pi:\\mathbb{R}^n\\mapsto\n\\mathbb{R}^{O(d\\log d)}$, found obliviously to $A$, that approximately\npreserves the $\\ell_1$ norms: that is, with large probability, simultaneously\nfor all $x$, $\\|Ax\\|_1 \\approx \\|\\Pi Ax\\|_1$, with distortion $O(d^{2+\\eta})$,\nfor an arbitrarily small constant $\\eta>0$; and, moreover, $\\Pi A$ can be\ncomputed in $O(nd\\log d)$ time. The techniques underlying our Fast Cauchy\nTransform include fast Johnson-Lindenstrauss transforms, low-coherence\nmatrices, and rescaling by Cauchy random variables.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 14:26:05 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 00:49:03 GMT"}, {"version": "v3", "created": "Sat, 5 Apr 2014 04:48:55 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Clarkson", "Kenneth L.", ""], ["Drineas", "Petros", ""], ["Magdon-Ismail", "Malik", ""], ["Mahoney", "Michael W.", ""], ["Meng", "Xiangrui", ""], ["Woodruff", "David P.", ""]]}, {"id": "1207.4694", "submitter": "Martin R. Schuster", "authors": "Maciej Liskiewicz and Martin R. Schuster", "title": "A New Upper Bound for the Traveling Salesman Problem in Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new upper bound for traveling salesman problem (TSP) in cubic\ngraphs, i.e. graphs with maximum vertex degree three, and prove that the\nproblem for an $n$-vertex graph can be solved in $O(1.2553^n)$ time and in\nlinear space. We show that the exact TSP algorithm of Eppstein, with some minor\nmodifications, yields the stated result. The previous best known upper bound\n$O(1.251^n)$ was claimed by Iwama and Nakashima [Proc. COCOON 2007].\nUnfortunately, their analysis contains several mistakes that render the proof\nfor the upper bound invalid.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 14:58:30 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 13:44:09 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Liskiewicz", "Maciej", ""], ["Schuster", "Martin R.", ""]]}, {"id": "1207.4783", "submitter": "Arnab Bhattacharyya", "authors": "Sanjeev Arora and Arnab Bhattacharyya and Rajsekar Manokaran and\n  Sushant Sachdeva", "title": "Testing Permanent Oracles -- Revisited", "comments": "Appears at RANDOM '12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given an oracle that claims to approximate the permanent for\nmost matrices X, where X is chosen from the Gaussian ensemble (the matrix\nentries are i.i.d. univariate complex Gaussians). Can we test that the oracle\nsatisfies this claim? This paper gives a polynomial-time algorithm for the\ntask. The oracle-testing problem is of interest because a recent paper of\nAaronson and Arkhipov showed that if there is a polynomial-time algorithm for\nsimulating boson-boson interactions in quantum mechanics, then an approximation\noracle for the permanent (of the type described above) exists in BPP^NP. Since\ncomputing the permanent of even 0/1 matrices is #P-complete, this seems to\ndemonstrate more computational power in quantum mechanics than Shor's factoring\nalgorithm does. However, unlike factoring, which is in NP, it was unclear\npreviously how to test the correctness of an approximation oracle for the\npermanent, and this is the contribution of the paper. The technical difficulty\novercome here is that univariate polynomial self-correction, which underlies\nsimilar oracle-testing algorithms for permanent over finite fields --- and\nwhose discovery led to a revolution in complexity theory --- does not seem to\ngeneralize to complex (or even, real) numbers. We believe that this tester will\nmotivate further progress on understanding the permanent of Gaussian matrices.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 19:54:55 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Arora", "Sanjeev", ""], ["Bhattacharyya", "Arnab", ""], ["Manokaran", "Rajsekar", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1207.4825", "submitter": "Harish Sethu", "authors": "Harish Sethu and Xiaoyu Chu", "title": "A new algorithm for extracting a small representative subgraph from a\n  very large graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world networks are prohibitively large for data retrieval, storage\nand analysis of all of its nodes and links. Understanding the structure and\ndynamics of these networks entails creating a smaller representative sample of\nthe full graph while preserving its relevant topological properties. In this\nreport, we show that graph sampling algorithms currently proposed in the\nliterature are not able to preserve network properties even with sample sizes\ncontaining as many as 20% of the nodes from the original graph. We present a\nnew sampling algorithm, called Tiny Sample Extractor, with a new goal of a\nsample size smaller than 5% of the original graph while preserving two key\nproperties of a network, the degree distribution and its clustering\nco-efficient. Our approach is based on a new empirical method of estimating\nmeasurement biases in crawling algorithms and compensating for them\naccordingly. We present a detailed comparison of best known graph sampling\nalgorithms, focusing in particular on how the properties of the sample\nsubgraphs converge to those of the original graph as they grow. These results\nshow that our sampling algorithm extracts a smaller subgraph than other\nalgorithms while also achieving a closer convergence to the degree\ndistribution, measured by the degree exponent, of the original graph. The\nsubgraph generated by the Tiny Sample Extractor, however, is not necessarily\nrepresentative of the full graph with regard to other properties such as\nassortativity. This indicates that the problem of extracting a truly\nrepresentative small subgraph from a large graph remains unsolved.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 22:22:23 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Sethu", "Harish", ""], ["Chu", "Xiaoyu", ""]]}, {"id": "1207.4900", "submitter": "Bart M. P. Jansen", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Kernel Bounds for Structural Parameterizations of Pathwidth", "comments": "This paper contains the proofs omitted from the extended abstract\n  published in the proceedings of Algorithm Theory - SWAT 2012 - 13th\n  Scandinavian Symposium and Workshops, Helsinki, Finland, July 4-6, 2012", "journal-ref": "Lecture Notes in Computer Science 7357 (2012) 352-363", "doi": "10.1007/978-3-642-31155-0_31", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming the AND-distillation conjecture, the Pathwidth problem of\ndetermining whether a given graph G has pathwidth at most k admits no\npolynomial kernelization with respect to k. The present work studies the\nexistence of polynomial kernels for Pathwidth with respect to other,\nstructural, parameters. Our main result is that, unless NP is in coNP/poly,\nPathwidth admits no polynomial kernelization even when parameterized by the\nvertex deletion distance to a clique, by giving a cross-composition from\nCutwidth. The cross-composition works also for Treewidth, improving over\nprevious lower bounds by the present authors. For Pathwidth, our result rules\nout polynomial kernels with respect to the distance to various classes of\npolynomial-time solvable inputs, like interval or cluster graphs. This leads to\nthe question whether there are nontrivial structural parameters for which\nPathwidth does admit a polynomial kernelization. To answer this, we give a\ncollection of graph reduction rules that are safe for Pathwidth. We analyze the\nsuccess of these results and obtain polynomial kernelizations with respect to\nthe following parameters: the size of a vertex cover of the graph, the vertex\ndeletion distance to a graph where each connected component is a star, and the\nvertex deletion distance to a graph where each connected component has at most\nc vertices.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 10:09:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1207.5146", "submitter": "Michael Dinitz", "authors": "Michael Dinitz and Guy Kortsarz", "title": "Matroid Secretary for Regular and Decomposable Matroids", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the matroid secretary problem we are given a stream of elements and asked\nto choose a set of elements that maximizes the total value of the set, subject\nto being an independent set of a matroid given in advance. The difficulty comes\nfrom the assumption that decisions are irrevocable: if we choose to accept an\nelement when it is presented by the stream then we can never get rid of it, and\nif we choose not to accept it then we cannot later add it. Babaioff, Immorlica,\nand Kleinberg [SODA 2007] introduced this problem, gave O(1)-competitive\nalgorithms for certain classes of matroids, and conjectured that every matroid\nadmits an O(1)-competitive algorithm. However, most matroids that are known to\nadmit an O(1)-competitive algorithm can be easily represented using graphs\n(e.g. graphic and transversal matroids). In particular, there is very little\nknown about F-representable matroids (the class of matroids that can be\nrepresented as elements of a vector space over a field F), which are one of the\nfoundational matroid classes. Moreover, most of the known techniques are as\ndependent on graph theory as they are on matroid theory. We go beyond graphs by\ngiving an O(1)-competitive algorithm for regular matroids (the class of\nmatroids that are representable over every field), and use techniques that are\nmatroid-theoretic rather than graph-theoretic. We use the regular matroid\ndecomposition theorem of Seymour to decompose any regular matroid into matroids\nwhich are either graphic, cographic, or isomorphic to R_{10}, and then show how\nto combine algorithms for these basic classes into an algorithm for regular\nmatroids. This allows us to generalize beyond regular matroids to any class of\nmatroids that admits such a decomposition into classes for which we already\nhave good algorithms. In particular, we give an O(1)-competitive algorithm for\nthe class of max-flow min-cut matroids.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2012 14:36:38 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Dinitz", "Michael", ""], ["Kortsarz", "Guy", ""]]}, {"id": "1207.5200", "submitter": "Eric Price", "authors": "Gregory T. Minton and Eric Price", "title": "Improved Concentration Bounds for Count-Sketch", "comments": "25 pages SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a refined analysis of the classic Count-Sketch streaming heavy\nhitters algorithm [CCF02]. Count-Sketch uses O(k log n) linear measurements of\na vector x in R^n to give an estimate x' of x. The standard analysis shows that\nthis estimate x' satisfies ||x'-x||_infty^2 < ||x_tail||_2^2 / k, where x_tail\nis the vector containing all but the largest k coordinates of x. Our main\nresult is that most of the coordinates of x' have substantially less error than\nthis upper bound; namely, for any c < O(log n), we show that each coordinate i\nsatisfies (x'_i - x_i)^2 < (c/log n) ||x_tail||_2^2/k with probability\n1-2^{-Omega(c)}, as long as the hash functions are fully independent. This\nsubsumes the previous bound and is optimal for all c. Using these improved\npoint estimates, we prove a stronger concentration result for set estimates by\nfirst analyzing the covariance matrix and then using a\nmedian-of-median-of-medians argument to bootstrap the failure probability\nbounds. These results also give improved results for l_2 recovery of exactly\nk-sparse estimates x^* when x is drawn from a distribution with suitable decay,\nsuch as a power law or lognormal. We complement our results with simulations of\nCount-Sketch on a power law distribution. The empirical evidence indicates that\nour theoretical bounds give a precise characterization of the algorithm's\nperformance: the asymptotics are correct and the associated constants are\nsmall. Our proof shows that any symmetric random variable with finite variance\nand positive Fourier transform concentrates around 0 at least as well as a\nGaussian. This result, which may be of independent interest, gives good\nconcentration even when the noise does not converge to a Gaussian.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 06:23:09 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 19:20:27 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2013 22:15:51 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Minton", "Gregory T.", ""], ["Price", "Eric", ""]]}, {"id": "1207.5211", "submitter": "Danupon Nanongkai", "authors": "Michael Elkin and Hartmut Klauck and Danupon Nanongkai and Gopal\n  Pandurangan", "title": "Can Quantum Communication Speed Up Distributed Computation?", "comments": "Full version of PODC 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on {\\em quantum distributed} computation, where we\ninvestigate whether quantum communication can help in {\\em speeding up}\ndistributed network algorithms. Our main result is that for certain fundamental\nnetwork problems such as minimum spanning tree, minimum cut, and shortest\npaths, quantum communication {\\em does not} help in substantially speeding up\ndistributed algorithms for these problems compared to the classical setting.\n  In order to obtain this result, we extend the technique of Das Sarma et al.\n[SICOMP 2012] to obtain a uniform approach to prove non-trivial lower bounds\nfor quantum distributed algorithms for several graph optimization (both exact\nand approximate versions) as well as verification problems, some of which are\nnew even in the classical setting, e.g. tight randomized lower bounds for\nHamiltonian cycle and spanning tree verification, answering an open problem of\nDas Sarma et al., and a lower bound in terms of the weight aspect ratio,\nmatching the upper bounds of Elkin [STOC 2004]. Our approach introduces the\n{\\em Server model} and {\\em Quantum Simulation Theorem} which together provide\na connection between distributed algorithms and communication complexity. The\nServer model is the standard two-party communication complexity model augmented\nwith additional power; yet, most of the hardness in the two-party model is\ncarried over to this new model. The Quantum Simulation Theorem carries this\nhardness further to quantum distributed computing. Our techniques, except the\nproof of the hardness in the Server model, require very little knowledge in\nquantum computing, and this can help overcoming a usual impediment in proving\nbounds on quantum distributed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 09:55:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 07:15:40 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2013 03:27:09 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2013 12:09:07 GMT"}, {"version": "v5", "created": "Fri, 9 May 2014 01:19:39 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Elkin", "Michael", ""], ["Klauck", "Hartmut", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1207.5215", "submitter": "Sambuddha Roy", "authors": "Venkatesan T. Chakaravarthy and Natwar Modani and Sivaramakrishnan R.\n  Natarajan and Sambuddha Roy and Yogish Sabharwal", "title": "Density Functions subject to a Co-Matroid Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of finding the {\\em densest} subset\nsubject to {\\em co-matroid constraints}. We are given a {\\em monotone\nsupermodular} set function $f$ defined over a universe $U$, and the density of\na subset $S$ is defined to be $f(S)/\\crd{S}$. This generalizes the concept of\ngraph density. Co-matroid constraints are the following: given matroid $\\calM$\na set $S$ is feasible, iff the complement of $S$ is {\\em independent} in the\nmatroid. Under such constraints, the problem becomes $\\np$-hard. The specific\ncase of graph density has been considered in literature under specific\nco-matroid constraints, for example, the cardinality matroid and the partition\nmatroid. We show a 2-approximation for finding the densest subset subject to\nco-matroid constraints. Thus, for instance, we improve the approximation\nguarantees for the result for partition matroids in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 11:01:33 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2012 07:37:53 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Chakaravarthy", "Venkatesan T.", ""], ["Modani", "Natwar", ""], ["Natarajan", "Sivaramakrishnan R.", ""], ["Roy", "Sambuddha", ""], ["Sabharwal", "Yogish", ""]]}, {"id": "1207.5518", "submitter": "Yang Cai", "authors": "Yang Cai, Constantinos Daskalakis, S. Matthew Weinberg", "title": "Optimal Multi-Dimensional Mechanism Design: Reducing Revenue to Welfare\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a reduction from revenue maximization to welfare maximization in\nmulti-dimensional Bayesian auctions with arbitrary (possibly combinatorial)\nfeasibility constraints and independent bidders with arbitrary (possibly\ncombinatorial) demand constraints, appropriately extending Myerson's result to\nthis setting. We also show that every feasible Bayesian auction can be\nimplemented as a distribution over virtual VCG allocation rules. A virtual VCG\nallocation rule has the following simple form: Every bidder's type t_i is\ntransformed into a virtual type f_i(t_i), via a bidder-specific function. Then,\nthe allocation maximizing virtual welfare is chosen. Using this\ncharacterization, we show how to find and run the revenue-optimal auction given\nonly black box access to an implementation of the VCG allocation rule. We\ngeneralize this result to arbitrarily correlated bidders, introducing the\nnotion of a second-order VCG allocation rule.\n  We obtain our reduction from revenue to welfare optimization via two\nalgorithmic results on reduced forms in settings with arbitrary feasibility and\ndemand constraints. First, we provide a separation oracle for determining\nfeasibility of a reduced form. Second, we provide a geometric algorithm to\ndecompose any feasible reduced form into a distribution over virtual VCG\nallocation rules. In addition, we show how to execute both algorithms given\nonly black box access to an implementation of the VCG allocation rule.\n  Our results are computationally efficient for all multi-dimensional settings\nwhere the bidders are additive. In this case, our mechanisms run in time\npolynomial in the total number of bidder types, but not type profiles. For\ngeneric correlated distributions, this is the natural description complexity of\nthe problem. The runtime can be further improved to poly(#items, #bidders) in\nitem-symmetric settings by making use of recent techniques.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 20:02:44 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Cai", "Yang", ""], ["Daskalakis", "Constantinos", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1207.5636", "submitter": "Archontia C. Giannopoulou", "authors": "Archontia C. Giannopoulou, Iosif Salem, Dimitris Zoros", "title": "Effective Computation of Immersion Obstructions for Unions of Graph\n  Classes", "comments": "An extended abstract of this paper has appeared in the proceedings of\n  the 13th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2012)\n  that took place in Helsinki, Finland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In the final paper of the Graph Minors series N. Robertson and P. Seymour\nproved that graphs are well-quasi-ordered under the immersion ordering. A\ndirect implication of this theorem is that each class of graphs that is closed\nunder taking immersions can be fully characterized by forbidding a finite set\nof graphs (immersion obstruction set). However, as the proof of the\nwell-quasi-ordering theorem is non-constructive, there is no generic procedure\nfor computing such a set. Moreover, it remains an open issue to identify for\nwhich immersion-closed graph classes the computation of those sets can become\neffective. By adapting the tools that were introduced by I. Adler, M. Grohe and\nS. Kreutzer, for the effective computation of minor obstruction sets, we expand\nthe horizon of computability to immersion obstruction sets. In particular, our\nresults propagate the computability of immersion obstruction sets of\nimmersion-closed graph classes to immersion obstruction sets of finite unions\nof immersion closed graph classes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 09:43:09 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Salem", "Iosif", ""], ["Zoros", "Dimitris", ""]]}, {"id": "1207.5672", "submitter": "Gyorgy Dosa", "authors": "Gyorgy Dosa and Zsolt Tuza", "title": "Bin Packing/Covering with Delivery: Some variations, theoretical results\n  and efficient offline algorithms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent paper \\cite{BDT10} we introduced a new problem that we call Bin\nPacking/Covering with Delivery, or BP/CD for short. Mainly we mean under this\nexpression that we look for not only a good, but a \"good and fast\" packing or\ncovering. In that paper we mainly dealt with only one possible online BP/CD\nmodel, and proposed a new method that we call the Evolution of Algorithms. In\ncase of such methods a neighborhood structure is defined among algorithms, and\nusing a metaheuristic (for example simulated annealing) in some sense the best\nalgorithm is chosen to solve the problem. Now we turn to investigate the\noffline case. We define several ways to treat such a BP/CD problem, although we\ninvestigate only one of them here. For the analysis, a novel view on \"offline\noptimum\" is introduced, which appears to be relevant concerning all problems\nwhere a final solution is ordering-dependent. We prove that if the item sizes\nare not allowed to be arbitrarily close to zero, then an optimal offline\nsolution can be found in polynomial time. On the other hand, for unrestricted\nproblem instances, no polynomial-time algorithm can achieve an approximation\nratio better than 6/7 if $P\\ne NP$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 12:11:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Dosa", "Gyorgy", ""], ["Tuza", "Zsolt", ""]]}, {"id": "1207.5696", "submitter": "Ond\\v{r}ej Such\\'y", "authors": "Matthias Mnich, Geevarghese Philip, Saket Saurabh, and Ond\\v{r}ej\n  Such\\'y", "title": "Beyond Max-Cut: \\lambda-Extendible Properties Parameterized Above the\n  Poljak-Turz\\'{i}k Bound", "comments": "23 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poljak and Turz\\'ik (Discrete Math. 1986) introduced the notion of\n\\lambda-extendible properties of graphs as a generalization of the property of\nbeing bipartite. They showed that for any 0<\\lambda<1 and \\lambda-extendible\nproperty \\Pi, any connected graph G on n vertices and m edges contains a\nsubgraph H \\in {\\Pi} with at least \\lambda m+ (1-\\lambda)/2 (n-1) edges. The\nproperty of being bipartite is 1/2-extendible, and thus this bound generalizes\nthe Edwards-Erd\\H{o}s bound for Max-Cut.\n  We define a variant, namely strong \\lambda-extendibility, to which the bound\napplies. For a strongly \\lambda-extendible graph property \\Pi, we define the\nparameterized Above Poljak- Turz\\'ik (APT) (\\Pi) problem as follows: Given a\nconnected graph G on n vertices and m edges and an integer parameter k, does\nthere exist a spanning subgraph H of G such that H \\in {\\Pi} and H has at least\n\\lambda m + (1-\\lambda)/2 (n - 1) + k edges? The parameter is k, the surplus\nover the number of edges guaranteed by the Poljak-Turz\\'ik bound.\n  We consider properties {\\Pi} for which APT (\\Pi) is fixed- parameter\ntractable (FPT) on graphs which are O(k) vertices away from being a graph in\nwhich each block is a clique. We show that for all such properties, APT (\\Pi)\nis FPT for all 0<\\lambda<1. Our results hold for properties of oriented graphs\nand graphs with edge labels. Our results generalize the result of Crowston et\nal. (ICALP 2012) on Max-Cut parameterized above the Edwards-Erd\\H{o}s bound,\nand yield FPT algorithms for several graph problems parameterized above lower\nbounds, e.g., Max q-Colorable Subgraph problem. Our results also imply that the\nparameterized above-guarantee Oriented Max Acyclic Digraph problem is FPT, thus\nsolving an open question of Raman and Saurabh (Theor. Comput. Sci. 2006).\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 13:34:31 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Mnich", "Matthias", ""], ["Philip", "Geevarghese", ""], ["Saurabh", "Saket", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "1207.5722", "submitter": "Zachary Friggstad", "authors": "Joseph Cheriyan, Zachary Friggstad, and Zhihan Gao", "title": "Approximating Minimum-Cost Connected T-Joins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and analyse approximation algorithms for the minimum-cost connected\nT-join problem: given an undirected graph G = (V;E) with nonnegative costs on\nthe edges, and a subset of nodes T, find (if it exists) a spanning connected\nsubgraph H of minimum cost such that every node in T has odd degree and every\nnode not in T has even degree; H may have multiple copies of any edge of G. Two\nwell-known special cases are the TSP (|T| = 0) and the s-t path TSP (|T| = 2).\nRecently, An, Kleinberg, and Shmoys [STOC 2012] improved on the long-standing\n5/3-approximation guarantee for the latter problem and presented an algorithm\nbased on LP rounding that achieves an approximation guarantee of (1+sqrt(5))/2\n< 1.6181.\n  We show that the methods of An et al. extend to the minimum-cost connected\nT-join problem. They presented a new proof for a 5/3-approximation guarantee\nfor the s-t path TSP; their proof extends easily to the minimum-cost connected\nT-join problem. Next, we improve on the approximation guarantee of 5/3 by\nextending their LP-rounding algorithm to get an approximation guarantee of 13/8\n= 1.625 for all |T| >= 4.\n  Finally, we focus on the prize-collecting version of the problem, and present\na primal-dual algorithm that is \"Lagrangian multiplier preserving\" and that\nachieves an approximation guarantee 3 - 2/(|T|-1) when |T| >= 4. Our\nprimal-dual algorithm is a generalization of the known primal-dual\n2-approximation for the prize-collecting s-t path TSP. Furthermore, we show\nthat our analysis is tight by presenting instances with |T| >= 4 such that the\ncost of the solution found by the algorithm is exactly 3 - 2/(|T|-1) times the\ncost of the constructed dual solution.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 15:20:22 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Cheriyan", "Joseph", ""], ["Friggstad", "Zachary", ""], ["Gao", "Zhihan", ""]]}, {"id": "1207.5813", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran, Laszlo A. Vegh, Santosh Vempala", "title": "The Cutting Plane Method is Polynomial for Perfect Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cutting plane approach to optimal matchings has been discussed by several\nauthors over the past decades (e.g., Padberg and Rao '82, Grotschel and Holland\n'85, Lovasz and Plummer '86, Trick '87, Fischetti and Lodi '07) and its\nconvergence has been an open question. We give a cutting plane algorithm that\nconverges in polynomial-time using only Edmonds' blossom inequalities; it\nmaintains half-integral intermediate LP solutions supported by a disjoint union\nof odd cycles and edges. Our main insight is a method to retain only a subset\nof the previously added cutting planes based on their dual values. This allows\nus to quickly find violated blossom inequalities and argue convergence by\ntracking the number of odd cycles in the support of intermediate solutions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 20:21:38 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2012 17:32:54 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2014 16:21:38 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Vegh", "Laszlo A.", ""], ["Vempala", "Santosh", ""]]}, {"id": "1207.5959", "submitter": "Koji M. Kobayashi", "authors": "Jun Kawahara, Koji M. Kobayashi and Tomotaka Maeda", "title": "Tight Analysis of Priority Queuing Policy for Egress Traffic", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the problems of evaluating performances of switches and routers\nhave been formulated as online problems, and a great amount of results have\nbeen presented. In this paper, we focus on managing outgoing packets (called\n{\\em egress traffic}) on switches that support Quality of Service (QoS), and\nanalyze the performance of one of the most fundamental scheduling policies {\\em\nPriority Queuing} ($PQ$) using competitive analysis. We formulate the problem\nof managing egress queues as follows: An output interface is equipped with $m$\nqueues, each of which has a buffer of size $B$. The size of a packet is unit,\nand each buffer can store up to $B$ packets simultaneously. Each packet is\nassociated with one of $m$ priority values $\\alpha_{j}$ ($1 \\leq j \\leq m$),\nwhere $\\alpha_{1} \\leq \\alpha_{2} \\leq \\cdots \\leq \\alpha_{m}$, $\\alpha_{1} =\n1$, and $\\alpha_{m} = \\alpha$ and the task of an online algorithm is to select\none of $m$ queues at each scheduling step. The purpose of this problem is to\nmaximize the sum of the values of the scheduled packets. For any $B$ and any\n$m$, we show that the competitive ratio of $PQ$ is exactly $2 - \\min_{x \\in [1,\nm-1] } \\{ \\frac{ \\alpha_{x+1} }{ \\sum_{j = 1}^{x+1} \\alpha_{j} } \\}$. That is,\nwe conduct a complete analysis of the performance of $PQ$ using worst case\nanalysis. Moreover, we show that no deterministic online algorithm can have a\ncompetitive ratio smaller than $1 + \\frac{ \\alpha^3 + \\alpha^2 + \\alpha }{\n\\alpha^4 + 4 \\alpha^3 + 3 \\alpha^2 + 4 \\alpha + 1 }$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 11:43:26 GMT"}, {"version": "v2", "created": "Sat, 30 Aug 2014 11:44:36 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Kawahara", "Jun", ""], ["Kobayashi", "Koji M.", ""], ["Maeda", "Tomotaka", ""]]}, {"id": "1207.6199", "submitter": "Vaneet Aggarwal", "authors": "Vaneet Aggarwal and Shankar Krishnan", "title": "Achieving Approximate Soft Clustering in Data Streams", "comments": "8 page. arXiv admin note: text overlap with arXiv:1004.4864 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, data streaming has gained prominence due to advances in\ntechnologies that enable many applications to generate continuous flows of\ndata. This increases the need to develop algorithms that are able to\nefficiently process data streams. Additionally, real-time requirements and\nevolving nature of data streams make stream mining problems, including\nclustering, challenging research problems.\n  In this paper, we propose a one-pass streaming soft clustering (membership of\na point in a cluster is described by a distribution) algorithm which\napproximates the \"soft\" version of the k-means objective function. Soft\nclustering has applications in various aspects of databases and machine\nlearning including density estimation and learning mixture models. We first\nachieve a simple pseudo-approximation in terms of the \"hard\" k-means algorithm,\nwhere the algorithm is allowed to output more than $k$ centers. We convert this\nbatch algorithm to a streaming one (using an extension of the k-means++\nalgorithm recently proposed) in the \"cash register\" model. We also extend this\nalgorithm when the clustering is done over a moving window in the data stream.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 08:24:05 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Aggarwal", "Vaneet", ""], ["Krishnan", "Shankar", ""]]}, {"id": "1207.6246", "submitter": "Robert Krauthgamer", "authors": "Robert Krauthgamer and Inbal Rika", "title": "Mimicking Networks and Succinct Representations of Terminal Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large edge-weighted network $G$ with $k$ terminal vertices, we wish\nto compress it and store, using little memory, the value of the minimum cut (or\nequivalently, maximum flow) between every bipartition of terminals. One\nappealing methodology to implement a compression of $G$ is to construct a\n\\emph{mimicking network}: a small network $G'$ with the same $k$ terminals, in\nwhich the minimum cut value between every bipartition of terminals is the same\nas in $G$. This notion was introduced by Hagerup, Katajainen, Nishimura, and\nRagde [JCSS '98], who proved that such $G'$ of size at most $2^{2^k}$ always\nexists. Obviously, by having access to the smaller network $G'$, certain\ncomputations involving cuts can be carried out much more efficiently.\n  We provide several new bounds, which together narrow the previously known gap\nfrom doubly-exponential to only singly-exponential, both for planar and for\ngeneral graphs. Our first and main result is that every $k$-terminal planar\nnetwork admits a mimicking network $G'$ of size $O(k^2 2^{2k})$, which is\nmoreover a minor of $G$. On the other hand, some planar networks $G$ require\n$|E(G')| \\ge \\Omega(k^2)$. For general networks, we show that certain bipartite\ngraphs only admit mimicking networks of size $|V(G')| \\geq 2^{\\Omega(k)}$, and\nmoreover, every data structure that stores the minimum cut value between all\nbipartitions of the terminals must use $2^{\\Omega(k)}$ machine words.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 11:55:13 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Krauthgamer", "Robert", ""], ["Rika", "Inbal", ""]]}, {"id": "1207.6365", "submitter": "David Woodruff", "authors": "Kenneth L. Clarkson and David P. Woodruff", "title": "Low Rank Approximation and Regression in Input Sparsity Time", "comments": "Included optimization of subspace embedding dimension from (d/eps)^4\n  to O~(d/eps)^2 in Section 4, by more careful analysis of perfect hashing, and\n  minor improvements to regression / low rank approximation because of it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new distribution over $\\poly(r \\eps^{-1}) \\times n$ matrices $S$\nso that for any fixed $n \\times d$ matrix $A$ of rank $r$, with probability at\nleast 9/10, $\\norm{SAx}_2 = (1 \\pm \\eps)\\norm{Ax}_2$ simultaneously for all $x\n\\in \\mathbb{R}^d$. Such a matrix $S$ is called a \\emph{subspace embedding}.\nFurthermore, $SA$ can be computed in $\\nnz(A) + \\poly(d \\eps^{-1})$ time, where\n$\\nnz(A)$ is the number of non-zero entries of $A$. This improves over all\nprevious subspace embeddings, which required at least $\\Omega(nd \\log d)$ time\nto achieve this property. We call our matrices $S$ \\emph{sparse embedding\nmatrices}.\n  Using our sparse embedding matrices, we obtain the fastest known algorithms\nfor $(1+\\eps)$-approximation for overconstrained least-squares regression,\nlow-rank approximation, approximating all leverage scores, and\n$\\ell_p$-regression. The leading order term in the time complexity of our\nalgorithms is $O(\\nnz(A))$ or $O(\\nnz(A)\\log n)$.\n  We optimize the low-order $\\poly(d/\\eps)$ terms in our running times (or for\nrank-$k$ approximation, the $n*\\poly(k/eps)$ term), and show various tradeoffs.\nFor instance, we also use our methods to design new preconditioners that\nimprove the dependence on $\\eps$ in least squares regression to $\\log 1/\\eps$.\nFinally, we provide preliminary experimental results which suggest that our\nalgorithms are competitive in practice.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 18:50:00 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2012 06:21:24 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2012 07:39:45 GMT"}, {"version": "v4", "created": "Fri, 5 Apr 2013 19:09:27 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Clarkson", "Kenneth L.", ""], ["Woodruff", "David P.", ""]]}, {"id": "1207.6368", "submitter": "David Lawlor", "authors": "David Lawlor, Yang Wang, Andrew Christlieb", "title": "Adaptive sub-linear Fourier algorithms", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new deterministic algorithm for the sparse Fourier transform\nproblem, in which we seek to identify k << N significant Fourier coefficients\nfrom a signal of bandwidth N. Previous deterministic algorithms exhibit\nquadratic runtime scaling, while our algorithm scales linearly with k in the\naverage case. Underlying our algorithm are a few simple observations relating\nthe Fourier coefficients of time-shifted samples to unshifted samples of the\ninput function. This allows us to detect when aliasing between two or more\nfrequencies has occurred, as well as to determine the value of unaliased\nfrequencies. We show that empirically our algorithm is orders of magnitude\nfaster than competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 18:53:17 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Lawlor", "David", ""], ["Wang", "Yang", ""], ["Christlieb", "Andrew", ""]]}, {"id": "1207.6371", "submitter": "Arindam Khan", "authors": "Arindam Khan, Prasad Raghavendra, Prasad Tetali and L\\'aszl\\'o A.\n  V\\'egh", "title": "On Mimicking Networks Representing Minimum Terminal Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a capacitated undirected graph $G=(V,E)$ with a set of terminals $K\n\\subset V$, a mimicking network is a smaller graph $H=(V_H,E_H)$ that exactly\npreserves all the minimum cuts between the terminals. Specifically, the vertex\nset of the sparsifier $V_H$ contains the set of terminals $K$ and for every\nbipartition $U, K-U $ of the terminals $K$, the size of the minimum cut\nseparating $U$ from $K-U$ in $G$ is exactly equal to the size of the minimum\ncut separating $U$ from $K-U$ in $H$.\n  This notion of a mimicking network was introduced by Hagerup, Katajainen,\nNishimura and Ragde (1995) who also exhibited a mimicking network of size\n$2^{2^{k}}$ for every graph with $k$ terminals. The best known lower bound on\nthe size of a mimicking network is linear in the number of terminals. More\nprecisely, the best known lower bound is $k+1$ for graphs with $k$ terminals\n(Chaudhuri et al. 2000).\n  In this work, we improve both the upper and lower bounds reducing the\ndoubly-exponential gap between them to a single-exponential gap. Specifically,\nwe obtain the following upper and lower bounds on mimicking networks: 1) Given\na graph $G$, we exhibit a construction of mimicking network with at most\n$(|K|-1)$'th Dedekind number ($\\approx 2^{{(k-1)} \\choose {\\lfloor {{(k-1)}/2}\n\\rfloor}}$) of vertices (independent of size of $V$). Furthermore, we show that\nthe construction is optimal among all {\\it restricted mimicking networks} -- a\nnatural class of mimicking networks that are obtained by clustering vertices\ntogether. 2) There exists graphs with $k$ terminals that have no mimicking\nnetwork of size smaller than $2^{\\frac{k-1}{2}}$.\n  We also exhibit improved constructions of mimicking networks for trees and\ngraphs of bounded tree-width.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 19:03:25 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Khan", "Arindam", ""], ["Raghavendra", "Prasad", ""], ["Tetali", "Prasad", ""], ["V\u00e9gh", "L\u00e1szl\u00f3 A.", ""]]}, {"id": "1207.6381", "submitter": "Zolt\\'an K\\'asa", "authors": "Z. Kir\\'aly, P. Kov\\'acs", "title": "Efficient implementations of minimum-cost flow algorithms", "comments": null, "journal-ref": "Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 67-118", "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents efficient implementations of several algorithms for\nsolving the minimum-cost network flow problem. Various practical heuristics and\nother important implementation aspects are also discussed. A novel result of\nthis work is the application of Goldberg's recent partial augment-relabel\nmethod in the cost-scaling algorithm. The presented implementations are\navailable as part of the LEMON open source C++ optimization library\n(\\url{http://lemon.cs.elte.hu/}). The performance of these codes is compared to\nwell-known and efficient minimum-cost flow solvers, namely CS2, RelaxIV, MCF,\nand the corresponding method of the LEDA library. According to thorough\nexperimental analysis, the presented cost-scaling and network simplex\nimplementations turned out to be more efficient than LEDA and MCF. Furthermore,\nthe cost-scaling implementation is competitive with CS2. The RelaxIV algorithm\nis often much slower than the other codes, although it is quite efficient on\nparticular problem instances.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 19:33:22 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Kir\u00e1ly", "Z.", ""], ["Kov\u00e1cs", "P.", ""]]}, {"id": "1207.6409", "submitter": "Haitao Wang", "authors": "Danny Z. Chen, Yan Gu, Jian Li, and Haitao Wang", "title": "Algorithms on Minimizing the Maximum Sensor Movement for Barrier\n  Coverage of a Linear Domain", "comments": "This version corrected an error in the proof of Lemma 2 in the\n  previous version and the version published in DCG 2013. Lemma 2 is for\n  proving the correctness of an algorithm (see the footnote of Page 9 for why\n  the previous proof is incorrect). Everything else of the paper does not\n  change. All algorithms in the paper are exactly the same as before and their\n  time complexities do not change either", "journal-ref": "Discrete & Computational Geometry, Vol. 50(2), pages 374-408, 2013", "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of moving $n$ sensors on a line to form a\nbarrier coverage of a specified segment of the line such that the maximum\nmoving distance of the sensors is minimized. Previously, it was an open\nquestion whether this problem on sensors with arbitrary sensing ranges is\nsolvable in polynomial time. We settle this open question positively by giving\nan $O(n^2 \\log n)$ time algorithm. For the special case when all sensors have\nthe same-size sensing range, the previously best solution takes $O(n^2)$ time.\nWe present an $O(n \\log n)$ time algorithm for this case; further, if all\nsensors are initially located on the coverage segment, our algorithm takes\n$O(n)$ time. Also, we extend our techniques to the cycle version of the problem\nwhere the barrier coverage is for a simple cycle and the sensors are allowed to\nmove only along the cycle. For sensors with the same-size sensing range, we\nsolve the cycle version in $O(n)$ time, improving the previously best $O(n^2)$\ntime solution.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 20:39:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 03:39:08 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Chen", "Danny Z.", ""], ["Gu", "Yan", ""], ["Li", "Jian", ""], ["Wang", "Haitao", ""]]}, {"id": "1207.6465", "submitter": "Yann Busnel", "authors": "Emmanuelle Anceaume (IRISA), Yann Busnel (LINA)", "title": "Sketch \\star-metric: Comparing Data Streams via Sketching", "comments": "12 pages, double colonnes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating the distance between any\ntwo large data streams in small- space constraint. This problem is of utmost\nimportance in data intensive monitoring applications where input streams are\ngenerated rapidly. These streams need to be processed on the fly and accurately\nto quickly determine any deviance from nominal behavior. We present a new\nmetric, the Sketch \\star-metric, which allows to define a distance between\nupdatable summaries (or sketches) of large data streams. An important feature\nof the Sketch \\star-metric is that, given a measure on the entire initial data\nstreams, the Sketch \\star-metric preserves the axioms of the latter measure on\nthe sketch (such as the non-negativity, the identity, the symmetry, the\ntriangle inequality but also specific properties of the f-divergence).\nExtensive experiments conducted on both synthetic traces and real data allow us\nto validate the robustness and accuracy of the Sketch \\star-metric.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 06:49:09 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Anceaume", "Emmanuelle", "", "IRISA"], ["Busnel", "Yann", "", "LINA"]]}, {"id": "1207.6528", "submitter": "Henry Cohn", "authors": "Henry Cohn, Christopher Umans", "title": "Fast matrix multiplication using coherent configurations", "comments": "14 pages, Society for Industrial and Applied Mathematics", "journal-ref": "Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on\n  Discrete Algorithms (New Orleans, Louisiana, USA, January 6-8, 2013), 2013,\n  pages 1074-1087", "doi": null, "report-no": null, "categories": "math.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a relaxation of the notion of tensor rank, called s-rank, and\nshow that upper bounds on the s-rank of the matrix multiplication tensor imply\nupper bounds on the ordinary rank. In particular, if the \"s-rank exponent of\nmatrix multiplication\" equals 2, then omega = 2. This connection between the\ns-rank exponent and the ordinary exponent enables us to significantly\ngeneralize the group-theoretic approach of Cohn and Umans, from group algebras\nto general algebras. Embedding matrix multiplication into general algebra\nmultiplication yields bounds on s-rank (not ordinary rank) and, prior to this\npaper, that had been a barrier to working with general algebras.\n  We identify adjacency algebras of coherent configurations as a promising\nfamily of algebras in the generalized framework. Coherent configurations are\ncombinatorial objects that generalize groups and group actions; adjacency\nalgebras are the analogue of group algebras and retain many of their important\nfeatures. As with groups, coherent configurations support matrix multiplication\nwhen a natural combinatorial condition is satisfied, involving triangles of\npoints in their underlying geometry.\n  Finally, we prove a closure property involving symmetric powers of adjacency\nalgebras, which enables us to prove nontrivial bounds on omega using\ncommutative coherent configurations and suggests that commutative coherent\nconfigurations may be sufficient to prove omega = 2. Altogether, our results\nshow that bounds on omega can be established by embedding large matrix\nmultiplication instances into small commutative coherent configurations, while\navoiding the representation-theoretic complications that were present in the\ngroup-theoretic approach.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 12:38:22 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 22:24:39 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Cohn", "Henry", ""], ["Umans", "Christopher", ""]]}, {"id": "1207.6549", "submitter": "Vytas Zacharovas", "authors": "Cyril Banderier, Hsien-Kuei Hwang, Vlady Ravelomanana and Vytas\n  Zacharovas", "title": "Analysis of an exhaustive search algorithm in random graphs and the\n  n^{c\\log n} -asymptotics", "comments": "35 pages", "journal-ref": "SIAM J. Discrete Math., 28(1), 342-371, 2014", "doi": "10.1137/130916357", "report-no": null, "categories": "math.PR cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the cost used by a naive exhaustive search algorithm for finding a\nmaximum independent set in random graphs under the usual G_{n,p} -model where\neach possible edge appears independently with the same probability p. The\nexpected cost turns out to be of the less common asymptotic order n^{c\\log n},\nwhich we explore from several different perspectives. Also we collect many\ninstances where such an order appears, from algorithmics to analysis, from\nprobability to algebra. The limiting distribution of the cost required by the\nalgorithm under a purely idealized random model is proved to be normal. The\napproach we develop is of some generality and is amenable for other graph\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 14:04:50 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Banderier", "Cyril", ""], ["Hwang", "Hsien-Kuei", ""], ["Ravelomanana", "Vlady", ""], ["Zacharovas", "Vytas", ""]]}, {"id": "1207.6655", "submitter": "Paul Pham", "authors": "Paul Pham and Krysta M. Svore", "title": "A 2D Nearest-Neighbor Quantum Architecture for Factoring in\n  Polylogarithmic Depth", "comments": "29 pages, 14 figures, 3 tables, presented at Reversible Computation\n  Workshop 2012 in Copenhagen. Updated with numerical circuit resource upper\n  bounds and constant-depth quantum unfanout", "journal-ref": "Quantum Information & Computation 13(11 & 12): 937-962(2013)", "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute a 2D nearest-neighbor quantum architecture for Shor's algorithm\nto factor an $n$-bit number in $O(\\log^2(n))$ depth. Our implementation uses\nparallel phase estimation, constant-depth fanout and teleportation, and\nconstant-depth carry-save modular addition. We derive upper bounds on the\ncircuit resources of our architecture under a new 2D nearest-neighbor model\nwhich allows a classical controller and parallel, communicating modules. We\nalso contribute a novel constant-depth circuit for unbounded quantum unfanout\nin our new model. Finally, we provide a comparison to all previous\nnearest-neighbor factoring implementations. Our circuit results in an\nexponential improvement in nearest-neighbor circuit depth at the cost of a\npolynomial increase in circuit size and width.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 21:12:11 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 05:26:32 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Pham", "Paul", ""], ["Svore", "Krysta M.", ""]]}, {"id": "1207.6683", "submitter": "Jochen Koenemann", "authors": "Jochen Koenemann, Kate Larson, David Steiner", "title": "Network Bargaining: Using Approximate Blocking Sets to Stabilize\n  Unstable Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a network extension to the Nash bargaining game, as introduced by\nKleinberg and Tardos (STOC'08), where the set of players corresponds to\nvertices in a graph $G=(V,E)$ and each edge $ij\\in E$ represents a possible\ndeal between players $i$ and $j$. We reformulate the problem as a cooperative\ngame and study the following question: Given a game with an empty core (i.e. an\nunstable game) is it possible, through minimal changes in the underlying\nnetwork, to stabilize the game? We show that by removing edges in the network\nthat belong to a blocking set we can find a stable solution in polynomial time.\nThis motivates the problem of finding small blocking sets. While it has been\npreviously shown that finding the smallest blocking set is NP-hard\n(Biro,Kern,Paulusma, TAMC'10), we show that it is possible to efficiently find\napproximate blocking sets in sparse graphs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2012 04:56:32 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Koenemann", "Jochen", ""], ["Larson", "Kate", ""], ["Steiner", "David", ""]]}, {"id": "1207.6936", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Yves Robert, Fr\\'ed\\'eric Vivien and Dounia Zaidouni", "title": "Impact of fault prediction on checkpointing strategies", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": "INRIA Report 8023", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the impact of fault prediction techniques on\ncheckpointing strategies. We extend the classical analysis of Young and Daly in\nthe presence of a fault prediction system, which is characterized by its recall\nand its precision, and which provides either exact or window-based time\npredictions. We succeed in deriving the optimal value of the checkpointing\nperiod (thereby minimizing the waste of resource usage due to checkpoint\noverhead) in all scenarios. These results allow to analytically assess the key\nparameters that impact the performance of fault predictors at very large scale.\nIn addition, the results of this analytical evaluation are nicely corroborated\nby a comprehensive set of simulations, thereby demonstrating the validity of\nthe model and the accuracy of the results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 13:36:20 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 13:47:38 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Aupy", "Guillaume", ""], ["Robert", "Yves", ""], ["Vivien", "Fr\u00e9d\u00e9ric", ""], ["Zaidouni", "Dounia", ""]]}, {"id": "1207.6944", "submitter": "J\\\"urn Laun", "authors": "J\\\"urn Laun", "title": "Efficient algorithms for highly compressed data: The Word Problem in\n  Generalized Higman Groups is in P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues the 2012 STACS contribution by Diekert, Ushakov, and the\nauthor. We extend the results published in the proceedings in two ways.\n  First, we show that the data structure of power circuits can be generalized\nto work with arbitrary bases q>=2. This results in a data structure that can\nhold huge integers, arising by iteratively forming powers of q. We show that\nthe properties of power circuits known for q=2 translate to the general case.\nThis generalization is non-trivial and additional techniques are required to\npreserve the time bounds of arithmetic operations that were shown for the case\nq=2.\n  The extended power circuit model permits us to conduct operations in the\nBaumslag-Solitar group BS(1,q) as efficiently as in BS(1,2). This allows us to\nsolve the word problem in the generalization H_4(1,q) of Higman's group, which\nis an amalgamated product of four copies of the Baumslag-Solitar group BS(1,q)\nrather than BS(1,2) in the original form.\n  As a second result, we allow arbitrary numbers f>=4 of copies of BS(1,q),\nleading to an even more generalized notion of Higman groups H_f(1,q). We prove\nthat the word problem of the latter can still be solved within the O(n^6) time\nbound that was shown for H_4(1,2).\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 14:30:58 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2012 08:32:50 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Laun", "J\u00fcrn", ""]]}, {"id": "1207.6986", "submitter": "Fabian Lim", "authors": "Fabian Lim", "title": "Two Embedding Theorems for Data with Equivalences under Finite Group\n  Action", "comments": "10 page extended abstract plus two sets of supplementary material. 1\n  figure. Preliminary report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is recent interest in compressing data sets for non-sequential\nsettings, where lack of obvious orderings on their data space, require notions\nof data equivalences to be considered. For example, Varshney & Goyal (DCC,\n2006) considered multiset equivalences, while Choi & Szpankowski (IEEE Trans.\nIT, 2012) considered isomorphic equivalences in graphs. Here equivalences are\nconsidered under a relatively broad framework - finite-dimensional,\nnon-sequential data spaces with equivalences under group action, for which\nanalogues of two well-studied embedding theorems are derived: the Whitney\nembedding theorem and the Johnson-Lindenstrauss lemma. Only the canonical data\npoints need to be carefully embedded, each such point representing a set of\ndata points equivalent under group action. Two-step embeddings are considered.\nFirst, a group invariant is applied to account for equivalences, and then\nsecondly, a linear embedding takes it down to low-dimensions. Our results\nrequire hypotheses on discriminability of the applied invariant, such notions\nrelated to seperating invariants (Dufresne, 2008), and completeness in pattern\nrecognition (Kakarala, 1992). In the latter theorem, the embedding complexity\ndepends on the size of the canonical part, which may be significantly smaller\nthan the whole data set, up to a factor equal to the size the group.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 16:15:22 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2012 19:34:15 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Lim", "Fabian", ""]]}, {"id": "1207.7040", "submitter": "Shay Solomon", "authors": "Shay Solomon", "title": "Fault-Tolerant Spanners for Doubling Metrics: Better and Simpler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In STOC'95 Arya et al. (1995) conjectured that for any constant dimensional\n$n$-point Euclidean space, a $(1+\\eps)$-spanner with constant degree,\nhop-diameter $O(\\log n)$ and weight $O(\\log n) \\cdot \\omega(MST)$ can be built\nin $O(n \\log n)$ time. Recently Elkin and Solomon (technical report, April\n2012) proved this conjecture of Arya et al. in the affirmative. In fact, the\nproof of Elkin and Solomon is more general in two ways. First, it applies to\narbitrary doubling metrics. Second, it provides a complete tradeoff between the\nthree involved parameters that is tight (up to constant factors) in the entire\nrange.\n  Subsequently, Chan et al. (technical report, July 2012) provided another\nproof for Arya et al.'s conjecture, which is simpler than the proof of Elkin\nand Solomon. Moreover, Chan et al. (2012) also showed that one can build a\nfault-tolerant (FT) spanner with similar properties. Specifically, they showed\nthat there exists a $k$-FT $(1+\\eps)$-spanner with degree $O(k^2)$,\nhop-diameter $O(\\log n)$ and weight $O(k^3 \\cdot \\log n) \\cdot \\omega(MST)$.\nThe running time of the construction of Chan et al. was not analyzed.\n  In this work we improve the results of Chan et al., using a simpler proof.\nSpecifically, we present a simple proof which shows that a $k$-FT\n$(1+\\eps)$-spanner with degree $O(k^2)$, hop-diameter $O(\\log n)$ and weight\n$O(k^2 \\cdot \\log n) \\cdot \\omega(MST)$ can be built in $O(n \\cdot (\\log n +\nk^2))$ time. Similarly to the constructions of Elkin and Solomon and Chan et\nal., our construction applies to arbitrary doubling metrics. However, in\ncontrast to the construction of Elkin and Solomon, our construction fails to\nprovide a complete (and tight) tradeoff between the three involved parameters.\nThe construction of Chan et al. has this drawback too.\n  For random point sets in $\\mathbb R^d$, we \"shave\" a factor of $\\log n$ from\nthe weight bound.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 18:58:53 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 20:04:44 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Solomon", "Shay", ""]]}, {"id": "1207.7134", "submitter": "Gabriel Istrate", "authors": "Cosmin Bonchis and Gabriel Istrate", "title": "Improved approximation algorithms for low-density instances of the\n  Minimum Entropy Set Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of instances of the minimum entropy set cover\nproblem, parameterized by the average frequency of a random element in the\ncovering sets. We analyze an algorithm combining a greedy approach with another\none biased towards large sets. The algorithm is controled by the percentage of\nelements to which we apply the biased approach. The optimal parameter choice\nhas a phase transition around average density $e$ and leads to improved\napproximation guarantees when average element frequency is less than $e$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 23:38:52 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Bonchis", "Cosmin", ""], ["Istrate", "Gabriel", ""]]}]