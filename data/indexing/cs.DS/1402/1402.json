[{"id": "1402.0052", "submitter": "David Gamarnik", "authors": "David Gamarnik, Madhu Sudan", "title": "Performance of the Survey Propagation-guided decimation algorithm for\n  the random NAE-K-SAT problem", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.AI cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Survey Propagation-guided decimation algorithm fails to find\nsatisfying assignments on random instances of the \"Not-All-Equal-$K$-SAT\"\nproblem if the number of message passing iterations is bounded by a constant\nindependent of the size of the instance and the clause-to-variable ratio is\nabove $(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ for sufficiently large $K$. Our\nanalysis in fact applies to a broad class of algorithms described as\n\"sequential local algorithms\". Such algorithms iteratively set variables based\non some local information and then recurse on the reduced instance. Survey\nPropagation-guided as well as Belief Propagation-guided decimation algorithms -\ntwo widely studied message passing based algorithms, fall under this category\nof algorithms provided the number of message passing iterations is bounded by a\nconstant. Another well-known algorithm falling into this category is the Unit\nClause algorithm. Our work constitutes the first rigorous analysis of the\nperformance of the SP-guided decimation algorithm.\n  The approach underlying our paper is based on an intricate geometry of the\nsolution space of random NAE-$K$-SAT problem. We show that above the\n$(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ threshold, the overlap structure of\n$m$-tuples of satisfying assignments exhibit a certain clustering behavior\nexpressed in the form of constraints on distances between the $m$ assignments,\nfor appropriately chosen $m$. We further show that if a sequential local\nalgorithm succeeds in finding a satisfying assignment with probability bounded\naway from zero, then one can construct an $m$-tuple of solutions violating\nthese constraints, thus leading to a contradiction. Along with (citation), this\nresult is the first work which directly links the clustering property of random\nconstraint satisfaction problems to the computational hardness of finding\nsatisfying assignments.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 05:05:12 GMT"}, {"version": "v2", "created": "Tue, 30 Sep 2014 02:07:36 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Gamarnik", "David", ""], ["Sudan", "Madhu", ""]]}, {"id": "1402.0054", "submitter": "Amir Abboud", "authors": "Amir Abboud and Virginia Vassilevska Williams", "title": "Popular conjectures imply strong lower bounds for dynamic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several well-studied problems in dynamic algorithms and prove\nthat sufficient progress on any of them would imply a breakthrough on one of\nfive major open problems in the theory of algorithms:\n  1. Is the 3SUM problem on $n$ numbers in $O(n^{2-\\epsilon})$ time for some\n$\\epsilon>0$?\n  2. Can one determine the satisfiability of a CNF formula on $n$ variables in\n$O((2-\\epsilon)^n poly n)$ time for some $\\epsilon>0$?\n  3. Is the All Pairs Shortest Paths problem for graphs on $n$ vertices in\n$O(n^{3-\\epsilon})$ time for some $\\epsilon>0$?\n  4. Is there a linear time algorithm that detects whether a given graph\ncontains a triangle?\n  5. Is there an $O(n^{3-\\epsilon})$ time combinatorial algorithm for $n\\times\nn$ Boolean matrix multiplication?\n  The problems we consider include dynamic versions of bipartite perfect\nmatching, bipartite maximum weight matching, single source reachability, single\nsource shortest paths, strong connectivity, subgraph connectivity, diameter\napproximation and some nongraph problems such as Pagh's problem defined in a\nrecent paper by Patrascu [STOC 2010].\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 06:20:09 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Abboud", "Amir", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1402.0121", "submitter": "Alexandre Maurer", "authors": "Alexandre Maurer (EPFL), S\\'ebastien Tixeuil (LINCS, NPA), Xavier\n  D\\'efago (JAIST)", "title": "Reliable Communication in a Dynamic Network in the Presence of Byzantine\n  Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem: two nodes want to reliably communicate in\na dynamic multihop network where some nodes have been compromised, and may have\na totally arbitrary and unpredictable behavior. These nodes are called\nByzantine. We consider the two cases where cryptography is available and not\navailable. We prove the necessary and sufficient condition (that is, the\nweakest possible condition) to ensure reliable communication in this context.\nOur proof is constructive, as we provide Byzantine-resilient algorithms for\nreliable communication that are optimal with respect to our impossibility\nresults. In a second part, we investigate the impact of our conditions in three\ncase studies: participants interacting in a conference, robots moving on a grid\nand agents in the subway. Our simulations indicate a clear benefit of using our\nalgorithms for reliable communication in those contexts.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 20:01:57 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 07:53:09 GMT"}, {"version": "v3", "created": "Tue, 27 May 2014 18:55:43 GMT"}, {"version": "v4", "created": "Mon, 16 Feb 2015 17:34:12 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Maurer", "Alexandre", "", "EPFL"], ["Tixeuil", "S\u00e9bastien", "", "LINCS, NPA"], ["D\u00e9fago", "Xavier", "", "JAIST"]]}, {"id": "1402.0240", "submitter": "Stefanie Jegelka", "authors": "Stefanie Jegelka (MIT), Jeff Bilmes (University of Washington)", "title": "Graph Cuts with Interacting Edge Costs - Examples, Approximations, and\n  Algorithms", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of the classical graph cut problem, wherein we replace\nthe modular (sum of edge weights) cost function by a submodular set function\ndefined over graph edges. Special cases of this problem have appeared in\ndifferent applications in signal processing, machine learning, and computer\nvision. In this paper, we connect these applications via the generic\nformulation of \"cooperative graph cuts\", for which we study complexity,\nalgorithms, and connections to polymatroidal network flows. Finally, we compare\nthe proposed algorithms empirically.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 20:03:19 GMT"}, {"version": "v2", "created": "Sat, 8 Mar 2014 19:53:39 GMT"}, {"version": "v3", "created": "Sat, 30 Aug 2014 17:14:42 GMT"}, {"version": "v4", "created": "Sat, 26 Mar 2016 22:52:52 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Jegelka", "Stefanie", "", "MIT"], ["Bilmes", "Jeff", "", "University of Washington"]]}, {"id": "1402.0402", "submitter": "Ben Strasser", "authors": "Julian Dibbelt, Ben Strasser, Dorothea Wagner", "title": "Customizable Contraction Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quickly computing shortest paths in weighted\ngraphs given auxiliary data derived in an expensive preprocessing phase. By\nadding a fast weight-customization phase, we extend Contraction Hierarchies by\nGeisberger et al to support the three-phase workflow introduced by Delling et\nal. Our Customizable Contraction Hierarchies use nested dissection orders as\nsuggested by Bauer et al. We provide an in-depth experimental analysis on large\nroad and game maps that clearly shows that Customizable Contraction Hierarchies\nare a very practicable solution in scenarios where edge weights often change.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 15:38:27 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 12:29:17 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2014 09:37:36 GMT"}, {"version": "v4", "created": "Fri, 27 Jun 2014 08:18:28 GMT"}, {"version": "v5", "created": "Fri, 21 Aug 2015 11:25:25 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Dibbelt", "Julian", ""], ["Strasser", "Ben", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1402.0423", "submitter": "Evan Sultanik Ph.D.", "authors": "Evan A. Sultanik", "title": "A Bound on the Expected Optimality of Random Feasible Solutions to\n  Combinatorial Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates and bounds the expected solution quality of\ncombinatorial optimization problems when feasible solutions are chosen at\nrandom. Loose general bounds are discovered, as well as families of\ncombinatorial optimization problems for which random feasible solutions are\nexpected to be a constant factor of optimal. One implication of this result is\nthat, for graphical problems, if the average edge weight in a feasible solution\nis sufficiently small, then any randomly chosen feasible solution to the\nproblem will be a constant factor of optimal. For example, under certain\nwell-defined circumstances, the expected constant of approximation of a\nrandomly chosen feasible solution to the Steiner network problem is bounded\nabove by 3. Empirical analysis supports these bounds and actually suggest that\nthey might be tightened.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 16:47:04 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Sultanik", "Evan A.", ""]]}, {"id": "1402.0471", "submitter": "David Auger", "authors": "David Auger (MAGMAT), Pierre COUCHENEY (PRISM), Yann Strozecki (PRISM)", "title": "Finding Optimal Strategies of Almost Acyclic Simple Stochatic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal value computation for turned-based stochastic games with\nreachability objectives, also known as simple stochastic games, is one of the\nfew problems in $NP \\cap coNP$ which are not known to be in $P$. However, there\nare some cases where these games can be easily solved, as for instance when the\nunderlying graph is acyclic. In this work, we try to extend this tractability\nto several classes of games that can be thought as \"almost\" acyclic. We give\nsome fixed-parameter tractable or polynomial algorithms in terms of different\nparameters such as the number of cycles or the size of the minimal feedback\nvertex set.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 19:24:12 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Auger", "David", "", "MAGMAT"], ["COUCHENEY", "Pierre", "", "PRISM"], ["Strozecki", "Yann", "", "PRISM"]]}, {"id": "1402.0557", "submitter": "Eric Huang", "authors": "Eric Huang, Richard E. Korf", "title": "Optimal Rectangle Packing: An Absolute Placement Approach", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 46, pages\n  47-87, 2013", "doi": "10.1613/jair.3735", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding all enclosing rectangles of minimum area\nthat can contain a given set of rectangles without overlap. Our rectangle\npacker chooses the x-coordinates of all the rectangles before any of the\ny-coordinates. We then transform the problem into a perfect-packing problem\nwith no empty space by adding additional rectangles. To determine the\ny-coordinates, we branch on the different rectangles that can be placed in each\nempty position. Our packer allows us to extend the known solutions for a\nconsecutive-square benchmark from 27 to 32 squares. We also introduce three new\nbenchmarks, avoiding properties that make a benchmark easy, such as rectangles\nwith shared dimensions. Our third benchmark consists of rectangles of\nincreasingly high precision. To pack them efficiently, we limit the rectangles\ncoordinates and the bounding box dimensions to the set of subset sums of the\nrectangles dimensions. Overall, our algorithms represent the current\nstate-of-the-art for this problem, outperforming other algorithms by orders of\nmagnitude, depending on the benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 01:33:30 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Huang", "Eric", ""], ["Korf", "Richard E.", ""]]}, {"id": "1402.0584", "submitter": "Shaowei Cai", "authors": "Shaowei Cai, Kaile Su, Chuan Luo, Abdul Sattar", "title": "NuMVC: An Efficient Local Search Algorithm for Minimum Vertex Cover", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 46, pages\n  687-716, 2013", "doi": "10.1613/jair.3907", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Vertex Cover (MVC) problem is a prominent NP-hard combinatorial\noptimization problem of great importance in both theory and application. Local\nsearch has proved successful for this problem. However, there are two main\ndrawbacks in state-of-the-art MVC local search algorithms. First, they select a\npair of vertices to exchange simultaneously, which is time-consuming. Secondly,\nalthough using edge weighting techniques to diversify the search, these\nalgorithms lack mechanisms for decreasing the weights. To address these issues,\nwe propose two new strategies: two-stage exchange and edge weighting with\nforgetting. The two-stage exchange strategy selects two vertices to exchange\nseparately and performs the exchange in two stages. The strategy of edge\nweighting with forgetting not only increases weights of uncovered edges, but\nalso decreases some weights for each edge periodically. These two strategies\nare used in designing a new MVC local search algorithm, which is referred to as\nNuMVC. We conduct extensive experimental studies on the standard benchmarks,\nnamely DIMACS and BHOSLIB. The experiment comparing NuMVC with state-of-the-art\nheuristic algorithms show that NuMVC is at least competitive with the nearest\ncompetitor namely PLS on the DIMACS benchmark, and clearly dominates all\ncompetitors on the BHOSLIB benchmark. Also, experimental results indicate that\nNuMVC finds an optimal solution much faster than the current best exact\nalgorithm for Maximum Clique on random instances as well as some structured\nones. Moreover, we study the effectiveness of the two strategies and the\nrun-time behaviour through experimental analysis.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 01:42:48 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Cai", "Shaowei", ""], ["Su", "Kaile", ""], ["Luo", "Chuan", ""], ["Sattar", "Abdul", ""]]}, {"id": "1402.0588", "submitter": "Christer B\\\"ackstr\\\"om", "authors": "Christer B\\\"ackstr\\\"om, Peter Jonsson", "title": "A Refined View of Causal Graphs and Component Sizes: SP-Closed Graph\n  Classes and Beyond", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 47, pages\n  575-611, 2013", "doi": "10.1613/jair.3968", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal graph of a planning instance is an important tool for planning\nboth in practice and in theory. The theoretical studies of causal graphs have\nlargely analysed the computational complexity of planning for instances where\nthe causal graph has a certain structure, often in combination with other\nparameters like the domain size of the variables. Chen and Gimand#233;nez\nignored even the structure and considered only the size of the weakly connected\ncomponents. They proved that planning is tractable if the components are\nbounded by a constant and otherwise intractable. Their intractability result\nwas, however, conditioned by an assumption from parameterised complexity theory\nthat has no known useful relationship with the standard complexity classes. We\napproach the same problem from the perspective of standard complexity classes,\nand prove that planning is NP-hard for classes with unbounded components under\nan additional restriction we refer to as SP-closed. We then argue that most\nNP-hardness theorems for causal graphs are difficult to apply and, thus, prove\na more general result; even if the component sizes grow slowly and the class is\nnot densely populated with graphs, planning still cannot be tractable unless\nthe polynomial hierachy collapses. Both these results still hold when\nrestricted to the class of acyclic causal graphs. We finally give a partial\ncharacterization of the borderline between NP-hard and NP-intermediate classes,\ngiving further insight into the problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 01:44:34 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["B\u00e4ckstr\u00f6m", "Christer", ""], ["Jonsson", "Peter", ""]]}, {"id": "1402.0660", "submitter": "Guoming Wang", "authors": "Guoming Wang", "title": "Quantum Algorithm for Linear Regression", "comments": "22 pages, no figure. Final version", "journal-ref": "Phys. Rev. A 96, 012335 (2017)", "doi": "10.1103/PhysRevA.96.012335", "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quantum algorithm for fitting a linear regression model to a\ngiven data set using the least squares approach. Different from previous\nalgorithms which yield a quantum state encoding the optimal parameters, our\nalgorithm outputs these numbers in the classical form. So by running it once,\none completely determines the fitted model and then can use it to make\npredictions on new data at little cost. Moreover, our algorithm works in the\nstandard oracle model, and can handle data sets with nonsparse design matrices.\nIt runs in time $\\operatorname{poly}(\\operatorname{log}(N), d, \\kappa,\n1/\\epsilon)$, where $N$ is the size of the data set, $d$ is the number of\nadjustable parameters, $\\kappa$ is the condition number of the design matrix,\nand $\\epsilon$ is the desired precision in the output. We also show that the\npolynomial dependence on $d$ and $\\kappa$ is necessary. Thus, our algorithm\ncannot be significantly improved. Furthermore, we also give a quantum algorithm\nthat estimates the quality of the least-squares fit (without computing its\nparameters explicitly). This algorithm runs faster than the one for finding\nthis fit, and can be used to check whether the given data set qualifies for\nlinear regression in the first place.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 08:55:07 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 08:11:29 GMT"}, {"version": "v3", "created": "Wed, 2 Apr 2014 04:56:36 GMT"}, {"version": "v4", "created": "Mon, 6 Mar 2017 22:22:08 GMT"}, {"version": "v5", "created": "Wed, 12 Jul 2017 21:17:29 GMT"}, {"version": "v6", "created": "Mon, 31 Jul 2017 14:50:08 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Wang", "Guoming", ""]]}, {"id": "1402.0851", "submitter": "Ren\\'e van Bevern", "authors": "Ren\\'e van Bevern and Matthias Mnich and Rolf Niedermeier and Mathias\n  Weller", "title": "Interval scheduling and colorful independent sets", "comments": "This revision does not contain Theorem 7 of the first revision, whose\n  proof contained an error", "journal-ref": "Journal of Scheduling 18(5):449-469, 2015", "doi": "10.1007/s10951-014-0398-5", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous applications in scheduling, such as resource allocation or steel\nmanufacturing, can be modeled using the NP-hard Independent Set problem (given\nan undirected graph and an integer k, find a set of at least k pairwise\nnon-adjacent vertices). Here, one encounters special graph classes like 2-union\ngraphs (edge-wise unions of two interval graphs) and strip graphs (edge-wise\nunions of an interval graph and a cluster graph), on which Independent Set\nremains NP-hard but admits constant-ratio approximations in polynomial time. We\nstudy the parameterized complexity of Independent Set on 2-union graphs and on\nsubclasses like strip graphs. Our investigations significantly benefit from a\nnew structural \"compactness\" parameter of interval graphs and novel problem\nformulations using vertex-colored interval graphs. Our main contributions are:\n  1. We show a complexity dichotomy: restricted to graph classes closed under\ninduced subgraphs and disjoint unions, Independent Set is polynomial-time\nsolvable if both input interval graphs are cluster graphs, and is NP-hard\notherwise.\n  2. We chart the possibilities and limits of effective polynomial-time\npreprocessing (also known as kernelization).\n  3. We extend Halld\\'orsson and Karlsson (2006)'s fixed-parameter algorithm\nfor Independent Set on strip graphs parameterized by the structural parameter\n\"maximum number of live jobs\" to show that the problem (also known as Job\nInterval Selection) is fixed-parameter tractable with respect to the parameter\nk and generalize their algorithm from strip graphs to 2-union graphs.\nPreliminary experiments with random data indicate that Job Interval Selection\nwith up to fifteen jobs and 5*10^5 intervals can be solved optimally in less\nthan five minutes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 20:13:32 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 16:51:09 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["van Bevern", "Ren\u00e9", ""], ["Mnich", "Matthias", ""], ["Niedermeier", "Rolf", ""], ["Weller", "Mathias", ""]]}, {"id": "1402.1076", "submitter": "Aaron Bohy", "authors": "Aaron Bohy, V\\'eronique Bruy\\`ere and Jean-Fran\\c{c}ois Raskin", "title": "Symblicit algorithms for optimal strategy synthesis in monotonic Markov\n  decision processes (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When treating Markov decision processes (MDPs) with large state spaces, using\nexplicit representations quickly becomes unfeasible. Lately, Wimmer et al. have\nproposed a so-called symblicit algorithm for the synthesis of optimal\nstrategies in MDPs, in the quantitative setting of expected mean-payoff. This\nalgorithm, based on the strategy iteration algorithm of Howard and Veinott,\nefficiently combines symbolic and explicit data structures, and uses binary\ndecision diagrams as symbolic representation. The aim of this paper is to show\nthat the new data structure of pseudo-antichains (an extension of antichains)\nprovides another interesting alternative, especially for the class of monotonic\nMDPs. We design efficient pseudo-antichain based symblicit algorithms (with\nopen source implementations) for two quantitative settings: the expected\nmean-payoff and the stochastic shortest path. For two practical applications\ncoming from automated planning and LTL synthesis, we report promising\nexperimental results w.r.t. both the run time and the memory consumption.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 16:22:41 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2014 07:07:53 GMT"}, {"version": "v3", "created": "Fri, 20 Jun 2014 07:25:47 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Bohy", "Aaron", ""], ["Bruy\u00e8re", "V\u00e9ronique", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1402.1107", "submitter": "Arindam Pal", "authors": "Arindam Pal", "title": "Approximation Algorithms for Covering and Packing Problems on Paths", "comments": "Ph.D. thesis of Arindam Pal. 100 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing and scheduling problems are fundamental problems in combinatorial\noptimization, and also have many applications. Most variations of these\nproblems are NP-Hard, so we need to use heuristics to solve these problems on\nlarge instances, which are fast and yet come close to the optimal value. In\nthis thesis, we study the design and analysis of approximation algorithms for\nsuch problems. We focus on two important class of problems. The first is the\nUnsplittable Flow Problem and some of its variants and the second is the\nResource Allocation for Job Scheduling Problem and some of its variants. The\nfirst is a packing problem, whereas the second is a covering problem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 18:06:20 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Pal", "Arindam", ""]]}, {"id": "1402.1191", "submitter": "Xing Shi Cai", "authors": "Xing Shi Cai, Luc Devroye", "title": "The Analysis of Kademlia for random IDs", "comments": "15 pages. 2 figures", "journal-ref": null, "doi": "10.1080/15427951.2015.1051674", "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kademlia is the de facto standard searching algorithm for P2P (peer-to-peer)\nnetworks on the Internet. In our earlier work, we introduced two slightly\ndifferent models for Kademlia and studied how many steps it takes to search for\na target node by using Kademlia's searching algorithm. The first model, in\nwhich nodes of the network are labelled with deterministic IDs, had been\ndiscussed in that paper. The second one, in which nodes are labelled with\nrandom IDs, which we call the Random ID Model, was only briefly mentioned.\nRefined results with detailed proofs for this model are given in this paper.\nOur analysis shows that with high probability it takes about $c \\log n$ steps\nto locate any node, where $n$ is the total number of nodes in the network and\n$c$ is a constant that does not depend on $n$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 21:37:29 GMT"}, {"version": "v2", "created": "Tue, 12 May 2015 14:07:52 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cai", "Xing Shi", ""], ["Devroye", "Luc", ""]]}, {"id": "1402.1194", "submitter": "G\\'abor R\\'etv\\'ari", "authors": "G\\'abor R\\'etv\\'ari, J\\'anos Tapolcai, Attila K\\H{o}r\\\"osi, Andr\\'as\n  Majd\\'an, Zal\\'an Heszberger", "title": "Compressing IP Forwarding Tables: Towards Entropy Bounds and Beyond", "comments": null, "journal-ref": "ACM SIGCOMM 2013. 111-122", "doi": "10.1145/2486001.2486009", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately, there has been an upsurge of interest in compressed data structures,\naiming to pack ever larger quantities of information into constrained memory\nwithout sacrificing the efficiency of standard operations, like random access,\nsearch, or update. The main goal of this paper is to demonstrate how data\ncompression can benefit the networking community, by showing how to squeeze the\nIP Forwarding Information Base (FIB), the giant table consulted by IP routers\nto make forwarding decisions, into information-theoretical entropy bounds, with\nessentially zero cost on longest prefix match and FIB update. First, we adopt\nthe state-of-the-art in compressed data structures, yielding a static\nentropy-compressed FIB representation with asymptotically optimal lookup. Then,\nwe re-design the venerable prefix tree, used commonly for IP lookup for at\nleast 20 years in IP routers, to also admit entropy bounds and support lookup\nin optimal time and update in nearly optimal time. Evaluations on a Linux\nkernel prototype indicate that our compressors encode a FIB comprising more\nthan 440K prefixes to just about 100--400 KBytes of memory, with a threefold\nincrease in lookup throughput and no penalty on FIB updates.\n  This technical report contains a number of important corrections and\nrevisions to the original manuscript.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 21:45:26 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["R\u00e9tv\u00e1ri", "G\u00e1bor", ""], ["Tapolcai", "J\u00e1nos", ""], ["K\u0151r\u00f6si", "Attila", ""], ["Majd\u00e1n", "Andr\u00e1s", ""], ["Heszberger", "Zal\u00e1n", ""]]}, {"id": "1402.1379", "submitter": "Jin-Kao Hao", "authors": "Zhang-Hua Fu and Jin-Kao Hao", "title": "A Three-Phase Search Approach for the Quadratic Minimum Spanning Tree\n  Problem", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph with costs associated with each edge as well as\neach pair of edges, the quadratic minimum spanning tree problem (QMSTP)\nconsists of determining a spanning tree of minimum total cost. This problem can\nbe used to model many real-life network design applications, in which both\nrouting and interference costs should be considered. For this problem, we\npropose a three-phase search approach named TPS, which integrates 1) a\ndescent-based neighborhood search phase using two different move operators to\nreach a local optimum from a given starting solution, 2) a local optima\nexploring phase to discover nearby local optima within a given regional search\narea, and 3) a perturbation-based diversification phase to jump out of the\ncurrent regional search area. Additionally, we introduce dedicated techniques\nto reduce the neighborhood to explore and streamline the neighborhood\nevaluations. Computational experiments based on hundreds of representative\nbenchmarks show that TPS produces highly competitive results with respect to\nthe best performing approaches in the literature by improving the best known\nresults for 31 instances and matching the best known results for the remaining\ninstances only except two cases. Critical elements of the proposed algorithms\nare analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 15:31:49 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Fu", "Zhang-Hua", ""], ["Hao", "Jin-Kao", ""]]}, {"id": "1402.1526", "submitter": "Justin Hsu", "authors": "Marco Gaboardi, Emilio Jes\\'us Gallego Arias, Justin Hsu, Aaron Roth,\n  Zhiwei Steven Wu", "title": "Dual Query: Practical Private Query Release for High Dimensional Data", "comments": null, "journal-ref": "Journal of Privacy and Confidentiality 7(2) 53--77 (2017)", "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical, differentially private algorithm for answering a\nlarge number of queries on high dimensional datasets. Like all algorithms for\nthis task, ours necessarily has worst-case complexity exponential in the\ndimension of the data. However, our algorithm packages the computationally hard\nstep into a concisely defined integer program, which can be solved\nnon-privately using standard solvers. We prove accuracy and privacy theorems\nfor our algorithm, and then demonstrate experimentally that our algorithm\nperforms well in practice. For example, our algorithm can efficiently and\naccurately answer millions of queries on the Netflix dataset, which has over\n17,000 attributes; this is an improvement on the state of the art by multiple\norders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 23:20:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 04:36:00 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Gaboardi", "Marco", ""], ["Arias", "Emilio Jes\u00fas Gallego", ""], ["Hsu", "Justin", ""], ["Roth", "Aaron", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1402.1616", "submitter": "Jordi Pereira", "authors": "Mariona Vil\\`a, Jordi Pereira", "title": "A note on 'Exact and approximate methods for a one-dimensional minimax\n  bin-packing problem' [Annals of Operations Research (2013) 206:611-626]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Brusco, K\\\"ohn and Steinley [Ann. Oper. Res. 206:611-626\n(2013)] conjecture that the 2 bins special case of the one-dimensional minimax\nbin-packing problem with bin size constraints might be solvable in polynomial\ntime. In this note, we show that this problem is NP-hard for the special case\nand that it is strongly NP-hard for the general problem. We also propose a\npseudo-polynomial algorithm for the special case and a constructive heuristic\nfor the general problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 12:23:47 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Vil\u00e0", "Mariona", ""], ["Pereira", "Jordi", ""]]}, {"id": "1402.1726", "submitter": "Yi Li", "authors": "Anna C. Gilbert, Yi Li, Ely Porat, Martin J. Strauss", "title": "For-all Sparse Recovery in Near-Optimal Time", "comments": null, "journal-ref": "ACM Transactions on Algorithms, Vol. 13, No. 3, pp 32:1--32:26,\n  2017", "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approximate sparse recovery system in $\\ell_1$ norm consists of parameters\n$k$, $\\epsilon$, $N$, an $m$-by-$N$ measurement $\\Phi$, and a recovery\nalgorithm, $\\mathcal{R}$. Given a vector, $\\mathbf{x}$, the system approximates\n$x$ by $\\widehat{\\mathbf{x}} = \\mathcal{R}(\\Phi\\mathbf{x})$, which must satisfy\n$\\|\\widehat{\\mathbf{x}}-\\mathbf{x}\\|_1 \\leq\n(1+\\epsilon)\\|\\mathbf{x}-\\mathbf{x}_k\\|_1$. We consider the 'for all' model, in\nwhich a single matrix $\\Phi$, possibly 'constructed' non-explicitly using the\nprobabilistic method, is used for all signals $\\mathbf{x}$. The best existing\nsublinear algorithm by Porat and Strauss (SODA'12) uses $O(\\epsilon^{-3}\nk\\log(N/k))$ measurements and runs in time $O(k^{1-\\alpha}N^\\alpha)$ for any\nconstant $\\alpha > 0$.\n  In this paper, we improve the number of measurements to $O(\\epsilon^{-2} k\n\\log(N/k))$, matching the best existing upper bound (attained by super-linear\nalgorithms), and the runtime to $O(k^{1+\\beta}\\textrm{poly}(\\log\nN,1/\\epsilon))$, with a modest restriction that $\\epsilon \\leq (\\log k/\\log\nN)^{\\gamma}$, for any constants $\\beta,\\gamma > 0$. When $k\\leq \\log^c N$ for\nsome $c>0$, the runtime is reduced to $O(k\\textrm{poly}(N,1/\\epsilon))$. With\nno restrictions on $\\epsilon$, we have an approximation recovery system with $m\n= O(k/\\epsilon \\log(N/k)((\\log N/\\log k)^\\gamma + 1/\\epsilon))$ measurements.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 18:34:37 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 14:06:46 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Gilbert", "Anna C.", ""], ["Li", "Yi", ""], ["Porat", "Ely", ""], ["Strauss", "Martin J.", ""]]}, {"id": "1402.1810", "submitter": "Martin F\\\"urer", "authors": "Martin F\\\"urer", "title": "A Natural Generalization of Bounded Tree-Width and Bounded Clique-Width", "comments": "To appear in the proceedings of Latin 2014. Springer LNCS 8392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new width parameter, the fusion-width of a graph. It is a\nnatural generalization of the tree-width, yet strong enough that not only\ngraphs of bounded tree-width, but also graphs of bounded clique-width,\ntrivially have bounded fusion-width. In particular, there is no exponential\ngrowth between tree-width and fusion-width, as is the case between tree-width\nand clique-width. The new parameter gives a good intuition about the\nrelationship between tree-width and clique-width.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 01:55:12 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["F\u00fcrer", "Martin", ""]]}, {"id": "1402.1811", "submitter": "Martin F\\\"urer", "authors": "Martin F\\\"urer", "title": "How Fast Can We Multiply Large Integers on an Actual Computer?", "comments": "To appear in the proceedings of Latin 2014. Springer LNCS 8392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two complexity measures that can be used to measure the running\ntime of algorithms to compute multiplications of long integers. The random\naccess machine with unit or logarithmic cost is not adequate for measuring the\ncomplexity of a task like multiplication of long integers. The Turing machine\nis more useful here, but fails to take into account the multiplication\ninstruction for short integers, which is available on physical computing\ndevices. An interesting outcome is that the proposed refined complexity\nmeasures do not rank the well known multiplication algorithms the same way as\nthe Turing machine model.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 02:47:25 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["F\u00fcrer", "Martin", ""]]}, {"id": "1402.1881", "submitter": "Bo Chen", "authors": "Shuyu Zhou, Xiandong Zhang, Bo Chen, Steef van de Velde", "title": "Tactical Fixed Job Scheduling with Spread-Time Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the tactical fixed job scheduling problem with spread-time\nconstraints. In such a problem, there are a fixed number of classes of machines\nand a fixed number of groups of jobs. Jobs of the same group can only be\nprocessed by machines of a given set of classes. All jobs have their fixed\nstart and end times. Each machine is associated with a cost according to its\nmachine class. Machines have spread-time constraints, with which each machine\nis only available for $L$ consecutive time units from the start time of the\nearliest job assigned to it. The objective is to minimize the total cost of the\nmachines used to process all the jobs. For this strongly NP-hard problem, we\ndevelop a branch-and-price algorithm, which solves instances with up to $300$\njobs, as compared with CPLEX, which cannot solve instances of $100$ jobs. We\nfurther investigate the influence of machine flexibility by computational\nexperiments. Our results show that limited machine flexibility is sufficient in\nmost situations.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 19:30:16 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Zhou", "Shuyu", ""], ["Zhang", "Xiandong", ""], ["Chen", "Bo", ""], ["van de Velde", "Steef", ""]]}, {"id": "1402.1936", "submitter": "N. Jesper Larsson", "authors": "N. Jesper Larsson", "title": "Integer Set Compression and Statistical Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression of integer sets and sequences has been extensively studied for\nsettings where elements follow a uniform probability distribution. In addition,\nmethods exist that exploit clustering of elements in order to achieve higher\ncompression performance. In this work, we address the case where enumeration of\nelements may be arbitrary or random, but where statistics is kept in order to\nestimate probabilities of elements. We present a recursive subset-size encoding\nmethod that is able to benefit from statistics, explore the effects of\npermuting the enumeration order based on element probabilities, and discuss\ngeneral properties and possibilities for this class of compression problem.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 11:28:41 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Larsson", "N. Jesper", ""]]}, {"id": "1402.2022", "submitter": "Pawan  Tamta", "authors": "Pawan Tamta, Bhagwati Prasad Pande, H.S Dhami", "title": "Reduction of Maximum Flow Network Interdiction Problem from The Clique\n  Problem", "comments": "10 pages,3 figures. arXiv admin note: substantial text overlap with\n  arXiv:1312.6492", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Flow Network Interdiction Problem (MFNIP) is known to be strongly\nNP-hard problem. We solve a simple form of MFNIP in polynomial time. We review\nthe reduction of MFNIP from the clique problem. We propose a polynomial time\nsolution to the Clique Problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 02:48:59 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Tamta", "Pawan", ""], ["Pande", "Bhagwati Prasad", ""], ["Dhami", "H. S", ""]]}, {"id": "1402.2097", "submitter": "Avivit Levy", "authors": "Gary Benson and Avivit Levy and Riva Shalom", "title": "Longest Common Subsequence in k-length substrings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we define a new problem, motivated by computational biology,\n$LCSk$ aiming at finding the maximal number of $k$ length $substrings$,\nmatching in both input strings while preserving their order of appearance. The\ntraditional LCS definition is a special case of our problem, where $k = 1$. We\nprovide an algorithm, solving the general case in $O(n^2)$ time, where $n$ is\nthe length of the input strings, equaling the time required for the special\ncase of $k=1$. The space requirement of the algorithm is $O(kn)$. %, however,\nin order to enable %backtracking of the solution, $O(n^2)$ space is needed.\n  We also define a complementary $EDk$ distance measure and show that\n$EDk(A,B)$ can be computed in $O(nm)$ time and $O(km)$ space, where $m$, $n$\nare the lengths of the input sequences $A$ and $B$ respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 10:54:52 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Benson", "Gary", ""], ["Levy", "Avivit", ""], ["Shalom", "Riva", ""]]}, {"id": "1402.2136", "submitter": "Leo van Iersel", "authors": "Leo van Iersel, Steven Kelk, Nela Leki\\'c, Chris Whidden and Norbert\n  Zeh", "title": "Hybridization Number on Three Rooted Binary Trees is EPT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic networks are leaf-labelled directed acyclic graphs that are used\nto describe non-treelike evolutionary histories and are thus a generalization\nof phylogenetic trees. The hybridization number of a phylogenetic network is\nthe sum of all indegrees minus the number of nodes plus one. The Hybridization\nNumber problem takes as input a collection of phylogenetic trees and asks to\nconstruct a phylogenetic network that contains an embedding of each of the\ninput trees and has a smallest possible hybridization number. We present an\nalgorithm for the Hybridization Number problem on three binary trees on $n$\nleaves, which runs in time $O(c^k poly(n))$, with $k$ the hybridization number\nof an optimal network and $c$ a constant. For two trees, an algorithm with\nrunning time $O(3.18^k n)$ was proposed before whereas an algorithm with\nrunning time $O(c^k poly(n))$ had prior to this article remained elusive for\nmore than two trees. The algorithm for two trees uses the close connection to\nacyclic agreement forests to achieve a linear exponent in the running time,\nwhile previous algorithms for more than two trees (explicitly or implicitly)\nrelied on a brute force search through all possible underlying network\ntopologies, leading to running times that are not $O(c^k poly(n))$ for any $c$.\nThe connection to acyclic agreement forests is much weaker for more than two\ntrees, so even given the right agreement forest, reconstructing the network\nposes major challenges. We prove novel structural results that allow us to\nreconstruct a network without having to guess the underlying topology. Our\ntechniques generalize to more than three input trees with the exception of one\nkey lemma that maps nodes in the network to tree nodes and, thus, minimizes the\namount of guessing involved in constructing the network. The main open problem\ntherefore is to establish a similar mapping for more than three trees.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 13:24:51 GMT"}, {"version": "v2", "created": "Thu, 1 May 2014 11:56:42 GMT"}, {"version": "v3", "created": "Tue, 31 May 2016 08:11:31 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["van Iersel", "Leo", ""], ["Kelk", "Steven", ""], ["Leki\u0107", "Nela", ""], ["Whidden", "Chris", ""], ["Zeh", "Norbert", ""]]}, {"id": "1402.2137", "submitter": "Gregory Gutin", "authors": "Gregory Gutin, Mark Jones, Bin Sheng and Magnus Wahlstrom", "title": "Parameterized Directed $k$-Chinese Postman Problem and $k$ Arc-Disjoint\n  Cycles Problem on Euler Digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Directed $k$-Chinese Postman Problem ($k$-DCPP), we are given a\nconnected weighted digraph $G$ and asked to find $k$ non-empty closed directed\nwalks covering all arcs of $G$ such that the total weight of the walks is\nminimum. Gutin, Muciaccia and Yeo (Theor. Comput. Sci. 513 (2013) 124--128)\nasked for the parameterized complexity of $k$-DCPP when $k$ is the parameter.\nWe prove that the $k$-DCPP is fixed-parameter tractable.\n  We also consider a related problem of finding $k$ arc-disjoint directed\ncycles in an Euler digraph, parameterized by $k$. Slivkins (ESA 2003) showed\nthat this problem is W[1]-hard for general digraphs. Generalizing another\nresult by Slivkins, we prove that the problem is fixed-parameter tractable for\nEuler digraphs. The corresponding problem on vertex-disjoint cycles in Euler\ndigraphs remains W[1]-hard even for Euler digraphs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 13:25:18 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Sheng", "Bin", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1402.2437", "submitter": "Bartosz Walczak", "authors": "Tomasz Krawczyk, Bartosz Walczak", "title": "On-line approach to off-line coloring problems on graphs with geometric\n  representations", "comments": "Final version, minor revision", "journal-ref": null, "doi": "10.1007/s00493-016-3414-x", "report-no": null, "categories": "cs.DS cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to formalize and explore a connection between\nchromatic properties of graphs with geometric representations and competitive\nanalysis of on-line algorithms, which became apparent after the recent\nconstruction of triangle-free geometric intersection graphs with arbitrarily\nlarge chromatic number due to Pawlik et al. We show that on-line graph coloring\nproblems give rise to classes of game graphs with a natural geometric\ninterpretation. We use this concept to estimate the chromatic number of graphs\nwith geometric representations by finding, for appropriate simpler graphs,\non-line coloring algorithms using few colors or proving that no such algorithms\nexist.\n  We derive upper and lower bounds on the maximum chromatic number that\nrectangle overlap graphs, subtree overlap graphs, and interval filament graphs\n(all of which generalize interval overlap graphs) can have when their clique\nnumber is bounded. The bounds are absolute for interval filament graphs and\nasymptotic of the form $(\\log\\log n)^{f(\\omega)}$ for rectangle and subtree\noverlap graphs, where $f(\\omega)$ is a polynomial function of the clique number\nand $n$ is the number of vertices. In particular, we provide the first\nconstruction of geometric intersection graphs with bounded clique number and\nwith chromatic number asymptotically greater than $\\log\\log n$.\n  We also introduce a concept of $K_k$-free colorings and show that for some\ngeometric representations, $K_3$-free chromatic number can be bounded in terms\nof clique number although the ordinary ($K_2$-free) chromatic number cannot.\nSuch a result for segment intersection graphs would imply a well-known\nconjecture that $k$-quasi-planar geometric graphs have linearly many edges.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 10:50:08 GMT"}, {"version": "v2", "created": "Mon, 19 Jan 2015 20:58:57 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 19:08:50 GMT"}, {"version": "v4", "created": "Thu, 29 Dec 2016 16:18:51 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Krawczyk", "Tomasz", ""], ["Walczak", "Bartosz", ""]]}, {"id": "1402.2446", "submitter": "Petr  Kuznetsov", "authors": "Zohir Bouzid, Eli Gafni, Petr Kuznetsov", "title": "Strong Equivalence Relations for Iterated Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Iterated Immediate Snapshot model (IIS), due to its elegant geometrical\nrepresentation, has become standard for applying topological reasoning to\ndistributed computing. Its modular structure makes it easier to analyze than\nthe more realistic (non-iterated) read-write Atomic-Snapshot memory model (AS).\nIt is known that AS and IIS are equivalent with respect to \\emph{wait-free\ntask} computability: a distributed task is solvable in AS if and only if it\nsolvable in IIS. We observe, however, that this equivalence is not sufficient\nin order to explore solvability of tasks in \\emph{sub-models} of AS (i.e.\nproper subsets of its runs) or computability of \\emph{long-lived} objects, and\na stronger equivalence relation is needed. In this paper, we consider\n\\emph{adversarial} sub-models of AS and IIS specified by the sets of processes\nthat can be \\emph{correct} in a model run. We show that AS and IIS are\nequivalent in a strong way: a (possibly long-lived) object is implementable in\nAS under a given adversary if and only if it is implementable in IIS under the\nsame adversary. %This holds whether the object is one-shot or long-lived.\nTherefore, the computability of any object in shared memory under an\nadversarial AS scheduler can be equivalently investigated in IIS.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 11:10:39 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 16:29:29 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Bouzid", "Zohir", ""], ["Gafni", "Eli", ""], ["Kuznetsov", "Petr", ""]]}, {"id": "1402.2496", "submitter": "Pierre Fraigniaud", "authors": "L\\'elia Blin and Pierre Fraigniaud", "title": "Polynomial-Time Space-Optimal Silent Self-Stabilizing Minimum-Degree\n  Spanning Tree Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications to sensor networks, as well as to many other areas,\nthis paper studies the construction of minimum-degree spanning trees. We\nconsider the classical node-register state model, with a weakly fair scheduler,\nand we present a space-optimal \\emph{silent} self-stabilizing construction of\nminimum-degree spanning trees in this model. Computing a spanning tree with\nminimum degree is NP-hard. Therefore, we actually focus on constructing a\nspanning tree whose degree is within one from the optimal. Our algorithm uses\nregisters on $O(\\log n)$ bits, converges in a polynomial number of rounds, and\nperforms polynomial-time computation at each node. Specifically, the algorithm\nconstructs and stabilizes on a special class of spanning trees, with degree at\nmost $OPT+1$. Indeed, we prove that, unless NP $=$ coNP, there are no\nproof-labeling schemes involving polynomial-time computation at each node for\nthe whole family of spanning trees with degree at most $OPT+1$. Up to our\nknowledge, this is the first example of the design of a compact silent\nself-stabilizing algorithm constructing, and stabilizing on a subset of optimal\nsolutions to a natural problem for which there are no time-efficient\nproof-labeling schemes. On our way to design our algorithm, we establish a set\nof independent results that may have interest on their own. In particular, we\ndescribe a new space-optimal silent self-stabilizing spanning tree\nconstruction, stabilizing on \\emph{any} spanning tree, in $O(n)$ rounds, and\nusing just \\emph{one} additional bit compared to the size of the labels used to\ncertify trees. We also design a silent loop-free self-stabilizing algorithm for\ntransforming a tree into another tree. Last but not least, we provide a silent\nself-stabilizing algorithm for computing and certifying the labels of a\nNCA-labeling scheme.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 14:19:00 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Blin", "L\u00e9lia", ""], ["Fraigniaud", "Pierre", ""]]}, {"id": "1402.2508", "submitter": "Steffen G\\\"orzig", "authors": "Steffen G\\\"orzig", "title": "Data Compaction - Compression without Decompression", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data compaction is a new approach for lossless and lossy compression of\nread-only array data. The biggest advantage over existing approaches is the\npossibility to access compressed data without any decompression. This makes\ndata compaction most suitable for systems that could currently not apply\ncompression techniques due to real-time or memory constraints. This is true for\nthe majority of all computers, i.e. a wide range of embedded systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 14:48:27 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["G\u00f6rzig", "Steffen", ""]]}, {"id": "1402.2543", "submitter": "Jukka Suomela", "authors": "Juho Hirvonen, Joel Rybicki, Stefan Schmid, Jukka Suomela", "title": "Large Cuts with Local Algorithms on Triangle-Free Graphs", "comments": "1+17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding large cuts in $d$-regular triangle-free\ngraphs. In prior work, Shearer (1992) gives a randomised algorithm that finds a\ncut of expected size $(1/2 + 0.177/\\sqrt{d})m$, where $m$ is the number of\nedges. We give a simpler algorithm that does much better: it finds a cut of\nexpected size $(1/2 + 0.28125/\\sqrt{d})m$. As a corollary, this shows that in\nany $d$-regular triangle-free graph there exists a cut of at least this size.\n  Our algorithm can be interpreted as a very efficient randomised distributed\nalgorithm: each node needs to produce only one random bit, and the algorithm\nruns in one synchronous communication round. This work is also a case study of\napplying computational techniques in the design of distributed algorithms: our\nalgorithm was designed by a computer program that searched for optimal\nalgorithms for small values of $d$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 16:06:35 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Hirvonen", "Juho", ""], ["Rybicki", "Joel", ""], ["Schmid", "Stefan", ""], ["Suomela", "Jukka", ""]]}, {"id": "1402.2549", "submitter": "Jukka Suomela", "authors": "Miikka Hilke, Christoph Lenzen, Jukka Suomela", "title": "Local Approximability of Minimum Dominating Set on Planar Graphs", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is no deterministic local algorithm (constant-time\ndistributed graph algorithm) that finds a $(7-\\epsilon)$-approximation of a\nminimum dominating set on planar graphs, for any positive constant $\\epsilon$.\nIn prior work, the best lower bound on the approximation ratio has been\n$5-\\epsilon$; there is also an upper bound of $52$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 16:24:05 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Hilke", "Miikka", ""], ["Lenzen", "Christoph", ""], ["Suomela", "Jukka", ""]]}, {"id": "1402.2589", "submitter": "Ren\\'e Van Bevern", "authors": "Ren\\'e van Bevern and Robert Bredereck and Laurent Bulteau and Jiehua\n  Chen and Vincent Froese and Rolf Niedermeier and Gerhard J. Woeginger", "title": "Partitioning Perfect Graphs into Stars", "comments": "Manuscript accepted to Journal of Graph Theory", "journal-ref": "Journal of Graph Theory 85(2):297--335 (2017)", "doi": "10.1002/jgt.22062", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partition of graphs into \"nice\" subgraphs is a central algorithmic\nproblem with strong ties to matching theory. We study the partitioning of\nundirected graphs into same-size stars, a problem known to be NP-complete even\nfor the case of stars on three vertices. We perform a thorough computational\ncomplexity study of the problem on subclasses of perfect graphs and identify\nseveral polynomial-time solvable cases, for example, on interval graphs and\nbipartite permutation graphs, and also NP-complete cases, for example, on grid\ngraphs and chordal graphs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 18:14:42 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 16:36:58 GMT"}, {"version": "v3", "created": "Fri, 17 Jun 2016 00:15:55 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["van Bevern", "Ren\u00e9", ""], ["Bredereck", "Robert", ""], ["Bulteau", "Laurent", ""], ["Chen", "Jiehua", ""], ["Froese", "Vincent", ""], ["Niedermeier", "Rolf", ""], ["Woeginger", "Gerhard J.", ""]]}, {"id": "1402.2664", "submitter": "Ren\\'e van Bevern", "authors": "Ren\\'e van Bevern and Robert Bredereck and Jiehua Chen and Vincent\n  Froese and Rolf Niedermeier and Gerhard J. Woeginger", "title": "Network-Based Vertex Dissolution", "comments": "Version accepted at SIAM Journal on Discrete Mathematics", "journal-ref": "SIAM Journal on Discrete Mathematics 29(2):888-914, 2015", "doi": "10.1137/140978880", "report-no": null, "categories": "cs.DM cs.DS cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graph-theoretic vertex dissolution model that applies to a\nnumber of redistribution scenarios such as gerrymandering in political\ndistricting or work balancing in an online situation. The central aspect of our\nmodel is the deletion of certain vertices and the redistribution of their load\nto neighboring vertices in a completely balanced way.\n  We investigate how the underlying graph structure, the knowledge of which\nvertices should be deleted, and the relation between old and new vertex loads\ninfluence the computational complexity of the underlying graph problems. Our\nresults establish a clear borderline between tractable and intractable cases.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 21:12:04 GMT"}, {"version": "v2", "created": "Thu, 17 Apr 2014 16:19:03 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2015 21:21:59 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["van Bevern", "Ren\u00e9", ""], ["Bredereck", "Robert", ""], ["Chen", "Jiehua", ""], ["Froese", "Vincent", ""], ["Niedermeier", "Rolf", ""], ["Woeginger", "Gerhard J.", ""]]}, {"id": "1402.2698", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "Automated Verification, Synthesis and Correction of Concurrent Systems\n  via MSO Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide algorithmic solutions to five fundamental problems\nconcerning the verification, synthesis and correction of concurrent systems\nthat can be modeled by bounded p/t-nets. We express concurrency via partial\norders and assume that behavioral specifications are given via monadic second\norder logic. A c-partial-order is a partial order whose Hasse diagram can be\ncovered by c paths. For a finite set T of transitions, we let P(c,T,\\phi)\ndenote the set of all T-labelled c-partial-orders satisfying \\phi. If N=(P,T)\nis a p/t-net we let P(N,c) denote the set of all c-partially-ordered runs of N.\nA (b, r)-bounded p/t-net is a b-bounded p/t-net in which each place appears\nrepeated at most r times. We solve the following problems:\n  1. Verification: given an MSO formula \\phi and a bounded p/t-net N determine\nwhether P(N,c)\\subseteq P(c,T,\\phi), whether P(c,T,\\phi)\\subseteq P(N,c), or\nwhether P(N,c)\\cap P(c,T,\\phi)=\\emptyset.\n  2. Synthesis from MSO Specifications: given an MSO formula \\phi, synthesize a\nsemantically minimal (b,r)-bounded p/t-net N satisfying P(c,T,\\phi)\\subseteq\nP(N, c).\n  3. Semantically Safest Subsystem: given an MSO formula \\phi defining a set of\nsafe partial orders, and a b-bounded p/t-net N, possibly containing unsafe\nbehaviors, synthesize the safest (b,r)-bounded p/t-net N' whose behavior lies\nin between P(N,c)\\cap P(c,T,\\phi) and P(N,c).\n  4. Behavioral Repair: given two MSO formulas \\phi and \\psi, and a b-bounded\np/t-net N, synthesize a semantically minimal (b,r)-bounded p/t net N' whose\nbehavior lies in between P(N,c) \\cap P(c,T,\\phi) and P(c,T,\\psi).\n  5. Synthesis from Contracts: given an MSO formula \\phi^yes specifying a set\nof good behaviors and an MSO formula \\phi^no specifying a set of bad behaviors,\nsynthesize a semantically minimal (b,r)-bounded p/t-net N such that\nP(c,T,\\phi^yes) \\subseteq P(N,c) but P(c,T,\\phi^no ) \\cap P(N,c)=\\emptyset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 23:50:39 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1402.2701", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler, Dahlia Malkhi", "title": "Optimal Gossip with Direct Addressing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip algorithms spread information by having nodes repeatedly forward\ninformation to a few random contacts. By their very nature, gossip algorithms\ntend to be distributed and fault tolerant. If done right, they can also be fast\nand message-efficient. A common model for gossip communication is the random\nphone call model, in which in each synchronous round each node can PUSH or PULL\ninformation to or from a random other node. For example, Karp et al. [FOCS\n2000] gave algorithms in this model that spread a message to all nodes in\n$\\Theta(\\log n)$ rounds while sending only $O(\\log \\log n)$ messages per node\non average.\n  Recently, Avin and Els\\\"asser [DISC 2013], studied the random phone call\nmodel with the natural and commonly used assumption of direct addressing.\nDirect addressing allows nodes to directly contact nodes whose ID (e.g., IP\naddress) was learned before. They show that in this setting, one can \"break the\n$\\log n$ barrier\" and achieve a gossip algorithm running in $O(\\sqrt{\\log n})$\nrounds, albeit while using $O(\\sqrt{\\log n})$ messages per node.\n  We study the same model and give a simple gossip algorithm which spreads a\nmessage in only $O(\\log \\log n)$ rounds. We also prove a matching $\\Omega(\\log\n\\log n)$ lower bound which shows that this running time is best possible. In\nparticular we show that any gossip algorithm takes with high probability at\nleast $0.99 \\log \\log n$ rounds to terminate. Lastly, our algorithm can be\ntweaked to send only $O(1)$ messages per node on average with only $O(\\log n)$\nbits per message. Our algorithm therefore simultaneously achieves the optimal\nround-, message-, and bit-complexity for this setting. As all prior gossip\nalgorithms, our algorithm is also robust against failures. In particular, if in\nthe beginning an oblivious adversary fails any $F$ nodes our algorithm still,\nwith high probability, informs all but $o(F)$ surviving nodes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 00:14:58 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Malkhi", "Dahlia", ""]]}, {"id": "1402.2710", "submitter": "Rodrigo de Lamare", "authors": "L. Wang, R. C. de Lamare and M. Haardt", "title": "Direction Finding Algorithms with Joint Iterative Subspace Optimization", "comments": "11 figures, 4 tables. IEEE Transactions on Aerospace and Electronic\n  Systems, 2014", "journal-ref": null, "doi": "10.1109/TAES.2014.120395", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a reduced-rank scheme with joint iterative optimization is\npresented for direction of arrival estimation. A rank-reduction matrix and an\nauxiliary reduced-rank parameter vector are jointly optimized to calculate the\noutput power with respect to each scanning angle. Subspace algorithms to\nestimate the rank-reduction matrix and the auxiliary vector are proposed.\nSimulations are performed to show that the proposed algorithms achieve an\nenhanced performance over existing algorithms in the studied scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 01:13:12 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Wang", "L.", ""], ["de Lamare", "R. C.", ""], ["Haardt", "M.", ""]]}, {"id": "1402.2712", "submitter": "Jiamou Liu", "authors": "Jiamou Liu and Kostya Ross", "title": "Dynamic Partial Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The dynamic partial sorting problem asks for an algorithm that maintains\nlists of numbers under the link, cut and change value operations, and queries\nthe sorted sequence of the $k$ least numbers in one of the lists. We first\nsolve the problem in $O(k\\log (n))$ time for queries and $O(\\log (n))$ time for\nupdates using the tournament tree data structure, where $n$ is the number of\nelements in the lists. We then introduce a layered tournament tree data\nstructure and solve the same problem in $O(\\log_\\varphi^* (n) k\\log (k))$ time\nfor queries and $O\\left(\\log (n)\\cdot\\log^2\\log (n)\\right)$ for updates, where\n$\\varphi$ is the golden ratio and $\\log_\\varphi^*(n)$ is the iterated\nlogarithmic function with base $\\varphi$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 01:36:36 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 23:19:46 GMT"}, {"version": "v3", "created": "Fri, 18 Apr 2014 02:29:23 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Liu", "Jiamou", ""], ["Ross", "Kostya", ""]]}, {"id": "1402.2741", "submitter": "Dimitris Papamichail", "authors": "Dimitris Papamichail, Thomas Caputi, Georgios Papamichail", "title": "The Level Ancestor Problem in Practice", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Given a rooted tree T, the level ancestor problem is the problem of answering\nqueries of the form LA(v, d), which identify the level d ancestor of a node v\nin the tree. Several algorithms of varied complexity have been proposed in the\nliterature, including optimal solutions that preprocess T in linear bounded\ntime and proceed to answer queries in constant bounded time. Despite its\nsignificance and numerous applications, to date there have been no comparative\nstudies of the performance of these algorithms and no implementations are\nwidely available. In our experimental study we have implemented and compared\nseveral solutions for the level ancestor problem, including two optimal\nalgorithms, and examine their space requirements and time performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 05:37:11 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Papamichail", "Dimitris", ""], ["Caputi", "Thomas", ""], ["Papamichail", "Georgios", ""]]}, {"id": "1402.2760", "submitter": "Yoann Dieudonn\\'e", "authors": "J\\'er\\'emie Chalopin, Yoann Dieudonn\\'e, Arnaud Labourel, Andrzej Pelc", "title": "Rendezvous in Networks in Spite of Delay Faults", "comments": null, "journal-ref": "Distributed Computing 29(3) (2016) 187-205", "doi": "10.1007/s00446-015-0259-2", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents, starting from different nodes of an unknown network, have\nto meet at the same node. Agents move in synchronous rounds using a\ndeterministic algorithm. Each agent has a different label, which it can use in\nthe execution of the algorithm, but it does not know the label of the other\nagent. Agents do not know any bound on the size of the network. In each round\nan agent decides if it remains idle or if it wants to move to one of the\nadjacent nodes. Agents are subject to delay faults: if an agent incurs a fault\nin a given round, it remains in the current node, regardless of its decision.\nIf it planned to move and the fault happened, the agent is aware of it. We\nconsider three scenarios of fault distribution: random (independently in each\nround and for each agent with constant probability 0 < p < 1), unbounded adver-\nsarial (the adversary can delay an agent for an arbitrary finite number of\nconsecutive rounds) and bounded adversarial (the adversary can delay an agent\nfor at most c consecutive rounds, where c is unknown to the agents). The\nquality measure of a rendezvous algorithm is its cost, which is the total\nnumber of edge traversals. For random faults, we show an algorithm with cost\npolynomial in the size n of the network and polylogarithmic in the larger label\nL, which achieves rendezvous with very high probability in arbitrary networks.\nBy contrast, for unbounded adversarial faults we show that rendezvous is not\nfeasible, even in the class of rings. Under this scenario we give a rendezvous\nalgorithm with cost O(nl), where l is the smaller label, working in arbitrary\ntrees, and we show that \\Omega(l) is the lower bound on rendezvous cost, even\nfor the two-node tree. For bounded adversarial faults, we give a rendezvous\nalgorithm working for arbitrary networks, with cost polynomial in n, and\nlogarithmic in the bound c and in the larger label L.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 08:34:07 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 17:41:05 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Chalopin", "J\u00e9r\u00e9mie", ""], ["Dieudonn\u00e9", "Yoann", ""], ["Labourel", "Arnaud", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1402.2782", "submitter": "Roland Glantz", "authors": "Roland Glantz, Henning Meyerhenke, Christian Schulz", "title": "Tree-based Coarsening and Partitioning of Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications produce massive complex networks whose analysis would\nbenefit from parallel processing. Parallel algorithms, in turn, often require a\nsuitable network partition. For solving optimization tasks such as graph\npartitioning on large networks, multilevel methods are preferred in practice.\nYet, complex networks pose challenges to established multilevel algorithms, in\nparticular to their coarsening phase.\n  One way to specify a (recursive) coarsening of a graph is to rate its edges\nand then contract the edges as prioritized by the rating. In this paper we (i)\ndefine weights for the edges of a network that express the edges' importance\nfor connectivity, (ii) compute a minimum weight spanning tree $T^m$ with\nrespect to these weights, and (iii) rate the network edges based on the\nconductance values of $T^m$'s fundamental cuts. To this end, we also (iv)\ndevelop the first optimal linear-time algorithm to compute the conductance\nvalues of \\emph{all} fundamental cuts of a given spanning tree. We integrate\nthe new edge rating into a leading multilevel graph partitioner and equip the\nlatter with a new greedy postprocessing for optimizing the maximum\ncommunication volume (MCV). Experiments on bipartitioning frequently used\nbenchmark networks show that the postprocessing already reduces MCV by 11.3%.\nOur new edge rating further reduces MCV by 10.3% compared to the previously\nbest rating with the postprocessing in place for both ratings. In total, with a\nmodest increase in running time, our new approach reduces the MCV of complex\nnetwork partitions by 20.4%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 10:53:01 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 10:56:20 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Glantz", "Roland", ""], ["Meyerhenke", "Henning", ""], ["Schulz", "Christian", ""]]}, {"id": "1402.2801", "submitter": "Mallesh Pai", "authors": "Mallesh M. Pai, Aaron Roth and Jonathan Ullman", "title": "An Anti-Folk Theorem for Large Repeated Games with Imperfect Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study infinitely repeated games in settings of imperfect monitoring. We\nfirst prove a family of theorems that show that when the signals observed by\nthe players satisfy a condition known as $(\\epsilon, \\gamma)$-differential\nprivacy, that the folk theorem has little bite: for values of $\\epsilon$ and\n$\\gamma$ sufficiently small, for a fixed discount factor, any equilibrium of\nthe repeated game involve players playing approximate equilibria of the stage\ngame in every period. Next, we argue that in large games ($n$ player games in\nwhich unilateral deviations by single players have only a small impact on the\nutility of other players), many monitoring settings naturally lead to signals\nthat satisfy $(\\epsilon,\\gamma)$-differential privacy, for $\\epsilon$ and\n$\\gamma$ tending to zero as the number of players $n$ grows large. We conclude\nthat in such settings, the set of equilibria of the repeated game collapse to\nthe set of equilibria of the stage game.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 12:30:36 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2014 19:05:09 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1402.2812", "submitter": "Salman Parsa", "authors": "Salman Parsa", "title": "Algorithms for Dynamic Reeb Graphs", "comments": "There was a problem with the argument used in the original\n  submission. It seems that the truly dynamic nature of the problem puts it in\n  the category of problems such as dynamic graph connectivity that do not have\n  known poly-logarithmic algorihtms. To see the claims in the abstract and a\n  reduction of the problem to a dynamic graph problem refer to my PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for updating the Reeb graph under fully dynamic\nchanges of the function values. The basic event is the interchange of two\nconsecutive vertex values. The algorithm updates the Reeb graph in $O(l g{n})$\nworst-case deterministic time for each such interchange, where $l$ is an upper\nbound on the size of the star of the involved vertices, and g(n) is a\nworst-case bound for the dynamic graph connectivity problem. Moreover, we argue\nthat $O(l)$ is a lower bound for this operation in general.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 13:21:27 GMT"}, {"version": "v2", "created": "Tue, 18 Mar 2014 15:44:14 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2015 12:07:00 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Parsa", "Salman", ""]]}, {"id": "1402.2843", "submitter": "Edouard Bonnet", "authors": "Edouard Bonnet and Vangelis Th. Paschos", "title": "Sparsification and subexponential approximation", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance sparsification is well-known in the world of exact computation since\nit is very closely linked to the Exponential Time Hypothesis. In this paper, we\nextend the concept of sparsification in order to capture subexponential time\napproximation. We develop a new tool for inapproximability, called\napproximation preserving sparsification and use it in order to get strong\ninapproximability results in subexponential time for several fundamental\noptimization problems as Max Independent Set, Min Dominating Set, Min Feedback\nVertex Set, and Min Set Cover.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 15:07:50 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 17:35:33 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Bonnet", "Edouard", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1402.2852", "submitter": "Shmuel Onn", "authors": "Shmuel Onn", "title": "Robust Integer Programming", "comments": null, "journal-ref": "Operations Research Letters, 42:558-560, 2014", "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complexity classification of four variants of robust integer\nprogramming when the underlying Graver basis is given. We discuss applications\nto robust multicommodity flows and multidimensional transportation, and\ndescribe an effective parametrization of robust integer programming.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 15:34:21 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 08:45:47 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Onn", "Shmuel", ""]]}, {"id": "1402.3036", "submitter": "David Morgenthaler", "authors": "J. David Morgenthaler and T. C. Hu", "title": "Optimal Alphabetic Ternary Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm to construct optimal alphabetic ternary trees, where\nevery internal node has at most three children. This algorithm generalizes the\nclassic Hu-Tucker algorithm, though the overall computational complexity has\nyet to be determined.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 06:00:59 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Morgenthaler", "J. David", ""], ["Hu", "T. C.", ""]]}, {"id": "1402.3281", "submitter": "Christian Schulz", "authors": "Henning Meyerhenke and Peter Sanders and Christian Schulz", "title": "Partitioning Complex Networks via Size-constrained Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most commonly used method to tackle the graph partitioning problem in\npractice is the multilevel approach. During a coarsening phase, a multilevel\ngraph partitioning algorithm reduces the graph size by iteratively contracting\nnodes and edges until the graph is small enough to be partitioned by some other\nalgorithm. A partition of the input graph is then constructed by successively\ntransferring the solution to the next finer graph and applying a local search\nalgorithm to improve the current solution.\n  In this paper, we describe a novel approach to partition graphs effectively\nespecially if the networks have a highly irregular structure. More precisely,\nour algorithm provides graph coarsening by iteratively contracting\nsize-constrained clusterings that are computed using a label propagation\nalgorithm. The same algorithm that provides the size-constrained clusterings\ncan also be used during uncoarsening as a fast and simple local search\nalgorithm.\n  Depending on the algorithm's configuration, we are able to compute partitions\nof very high quality outperforming all competitors, or partitions that are\ncomparable to the best competitor in terms of quality, hMetis, while being\nnearly an order of magnitude faster on average. The fastest configuration\npartitions the largest graph available to us with 3.3 billion edges using a\nsingle machine in about ten minutes while cutting less than half of the edges\nthan the fastest competitor, kMetis.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 20:46:31 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 10:50:28 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Meyerhenke", "Henning", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1402.3364", "submitter": "Muad Abu-Ata", "authors": "Muad Abu-Ata and Feodor F. Dragan", "title": "Metric tree-like structures in real-life networks: an empirical study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on solid theoretical foundations, we present strong evidences that a\nnumber of real-life networks, taken from different domains like Internet\nmeasurements, biological data, web graphs, social and collaboration networks,\nexhibit tree-like structures from a metric point of view. We investigate few\ngraph parameters, namely, the tree-distortion and the tree-stretch, the\ntree-length and the tree-breadth, the Gromov's hyperbolicity, the\ncluster-diameter and the cluster-radius in a layering partition of a graph,\nwhich capture and quantify this phenomenon of being metrically close to a tree.\nBy bringing all those parameters together, we not only provide efficient means\nfor detecting such metric tree-like structures in large-scale networks but also\nshow how such structures can be used, for example, to efficiently and compactly\nencode approximate distance and almost shortest path information and to fast\nand accurately estimate diameters and radii of those networks. Estimating the\ndiameter and the radius of a graph or distances between its arbitrary vertices\nare fundamental primitives in many data and graph mining algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 05:06:44 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 19:49:31 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Abu-Ata", "Muad", ""], ["Dragan", "Feodor F.", ""]]}, {"id": "1402.3435", "submitter": "Jens Ma{\\ss}berg", "authors": "Jens Ma{\\ss}berg", "title": "Generalized Huffman Coding for Binary Trees with Choosable Edge Lengths", "comments": "9 pages", "journal-ref": "Information Processing Letters 115 (4), pp. 502-506 (2015)", "doi": "10.1016/j.ipl.2014.11.013", "report-no": null, "categories": "cs.IT cs.DS math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study binary trees with choosable edge lengths, in\nparticular rooted binary trees with the property that the two edges leading\nfrom every non-leaf to its two children are assigned integral lengths $l_1$ and\n$l_2$ with $l_1+l_2 =k$ for a constant $k\\in\\mathbb{N}$. The depth of a leaf is\nthe total length of the edges of the unique root-leaf-path.\n  We present a generalization of the Huffman Coding that can decide in\npolynomial time if for given values $d_1,...,d_n\\in\\mathbb{N}_{\\geq 0}$ there\nexists a rooted binary tree with choosable edge lengths with $n$ leaves having\ndepths at most $d_1,..., d_n$.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 11:13:36 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2014 19:25:56 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Ma\u00dfberg", "Jens", ""]]}, {"id": "1402.3444", "submitter": "Francesco Silvestri", "authors": "Francesco Silvestri", "title": "Subgraph Enumeration in Massive Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of enumerating all instances of a given pattern graph\nin a large data graph. Our focus is on determining the input/output (I/O)\ncomplexity of this problem. Let $E$ be the number of edges in the data graph,\n$k=O(1)$ be the number of vertices in the pattern graph, $B$ be the block\nlength, and $M$ be the main memory size. The main results of the paper are two\nalgorithms that enumerate all instances of the pattern graph. The first one is\na deterministic algorithm that exploits a suitable independent set of the\npattern graph of size $1\\leq s \\leq k/2$ and requires\n$O\\left(E^{k-s}/\\left(BM^{k-s-1}\\right)\\right)$ I/Os. The second algorithm is a\nrandomized algorithm that enumerates all instances in\n$O\\left(E^{k/2}/\\left(BM^{k/2-1}\\right)\\right)$ expected I/Os; the same bound\nalso applies with high probability under some assumptions. A lower bound shows\nthat the deterministic algorithm is optimal for some pattern graphs with\n$s=k/2$ (e.g., paths and cycles of even length, meshes of even side), while the\nrandomized algorithm is optimal for a wide class of pattern graphs, called Alon\nclass (e.g., cliques, cycles and every graph with a perfect matching).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 12:01:47 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 11:43:19 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2015 10:42:45 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Silvestri", "Francesco", ""]]}, {"id": "1402.3452", "submitter": "Markus Lohrey", "authors": "Markus Lohrey and Manfred Schmidt-Schauss", "title": "Processing Succinct Matrices and Vectors", "comments": "An extended abstract of this paper will appear in the Proceedings of\n  CSR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of algorithmic problems for matrices that are\nrepresented by multi-terminal decision diagrams (MTDD). These are a variant of\nordered decision diagrams, where the terminal nodes are labeled with arbitrary\nelements of a semiring (instead of 0 and 1). A simple example shows that the\nproduct of two MTDD-represented matrices cannot be represented by an MTDD of\npolynomial size. To overcome this deficiency, we extended MTDDs to MTDD_+ by\nallowing componentwise symbolic addition of variables (of the same dimension)\nin rules. It is shown that accessing an entry, equality checking, matrix\nmultiplication, and other basic matrix operations can be solved in polynomial\ntime for MTDD_+-represented matrices. On the other hand, testing whether the\ndeterminant of a MTDD-represented matrix vanishes PSPACE$-complete, and the\nsame problem is NP-complete for MTDD_+-represented diagonal matrices. Computing\na specific entry in a product of MTDD-represented matrices is #P-complete.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 12:44:47 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Lohrey", "Markus", ""], ["Schmidt-Schauss", "Manfred", ""]]}, {"id": "1402.3472", "submitter": "Marcin Pilipczuk", "authors": "Ivan Bliznets and Fedor V. Fomin and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk", "title": "A subexponential parameterized algorithm for Proper Interval Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Proper Interval Completion problem we are given a graph G and an\ninteger k, and the task is to turn G using at most k edge additions into a\nproper interval graph, i.e., a graph admitting an intersection model of\nequal-length intervals on a line. The study of Proper Interval Completion from\nthe viewpoint of parameterized complexity has been initiated by Kaplan, Shamir\nand Tarjan [FOCS 1994; SIAM J. Comput. 1999], who showed an algorithm for the\nproblem working in $O(16^k (n + m))$ time. In this paper we present an\nalgorithm with running time $k^{O(k^{2/3})} + O(nm(kn + m))$, which is the\nfirst subexponential parameterized algorithm for Proper Interval Completion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 20:03:41 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Bliznets", "Ivan", ""], ["Fomin", "Fedor V.", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1402.3473", "submitter": "Marcin Pilipczuk", "authors": "Ivan Bliznets and Fedor V. Fomin and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk", "title": "A subexponential parameterized algorithm for Interval Completion", "comments": "v2: An overview of the proof has been added; v3: updated introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Interval Completion problem we are given a graph G and an integer k,\nand the task is to turn G using at most k edge additions into an interval\ngraph, i.e., a graph admitting an intersection model of intervals on a line.\nMotivated by applications in sparse matrix multiplication and molecular\nbiology, Kaplan, Shamir and Tarjan [FOCS 1994; SIAM J. Comput. 1999] asked for\na fixed-parameter algorithm solving this problem. This question was answer\naffirmatively more than a decade later by Villanger at el. [STOC 2007; SIAM J.\nComput. 2009], who presented an algorithm with running time $O(k^{2k}n^3m)$. We\ngive the first subexponential parameterized algorithm solving Interval\nCompletion in time $k^{O(\\sqrt{k})} n^{O(1)}$. This adds Interval Completion to\na very small list of parameterized graph modification problems solvable in\nsubexponential time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 20:06:50 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 10:03:59 GMT"}, {"version": "v3", "created": "Mon, 10 Nov 2014 12:03:25 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Bliznets", "Ivan", ""], ["Fomin", "Fedor V.", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1402.3488", "submitter": "Artur Ziviani", "authors": "Klaus Wehmuth (LNCC / MCTI), Artur Ziviani (LNCC / MCTI), Eric Fleury\n  (ENS de Lyon / INRIA - Universit\\'e de Lyon)", "title": "A Unifying Model for Representing Time-Varying Graphs", "comments": "Also appears in the Proc. of the IEEE International Conference on\n  Data Science and Advanced Analytics (IEEE DSAA'2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based models form a fundamental aspect of data representation in Data\nSciences and play a key role in modeling complex networked systems. In\nparticular, recently there is an ever-increasing interest in modeling dynamic\ncomplex networks, i.e. networks in which the topological structure (nodes and\nedges) may vary over time. In this context, we propose a novel model for\nrepresenting finite discrete Time-Varying Graphs (TVGs), which are typically\nused to model dynamic complex networked systems. We analyze the data structures\nbuilt from our proposed model and demonstrate that, for most practical cases,\nthe asymptotic memory complexity of our model is in the order of the\ncardinality of the set of edges. Further, we show that our proposal is an\nunifying model that can represent several previous (classes of) models for\ndynamic networks found in the recent literature, which in general are unable to\nrepresent each other. In contrast to previous models, our proposal is also able\nto intrinsically model cyclic (i.e. periodic) behavior in dynamic networks.\nThese representation capabilities attest the expressive power of our proposed\nunifying model for TVGs. We thus believe our unifying model for TVGs is a step\nforward in the theoretical foundations for data analysis of complex networked\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 15:10:16 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2015 14:17:51 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Wehmuth", "Klaus", "", "LNCC / MCTI"], ["Ziviani", "Artur", "", "LNCC / MCTI"], ["Fleury", "Eric", "", "ENS de Lyon / INRIA - Universit\u00e9 de Lyon"]]}, {"id": "1402.3547", "submitter": "Meirav Zehavi", "authors": "Hadas Shachnai, Meirav Zehavi", "title": "Representative Families: A Unified Tradeoff-Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $M=(E,{\\cal I})$ be a matroid, and let $\\cal S$ be a family of subsets of\nsize $p$ of $E$. A subfamily $\\widehat{\\cal S}\\subseteq{\\cal S}$ represents\n${\\cal S}$ if for every pair of sets $X\\in{\\cal S}$ and $Y\\subseteq E\\setminus\nX$ such that $X\\cup Y\\in{\\cal I}$, there is a set $\\widehat{X}\\in\\widehat{\\cal\nS}$ disjoint from $Y$ such that $\\widehat{X}\\cup Y\\in{\\cal I}$. Fomin et al.\n(Proc. ACM-SIAM Symposium on Discrete Algorithms, 2014) introduced a powerful\ntechnique for fast computation of representative families for uniform matroids.\nIn this paper, we show that this technique leads to a unified approach for\nsubstantially improving the running times of parameterized algorithms for some\nclassic problems. This includes, among others, $k$-Partial Cover, $k$-Internal\nOut-Branching, and Long Directed Cycle. Our approach exploits an interesting\ntradeoff between running time and the size of the representative families.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 18:32:15 GMT"}, {"version": "v2", "created": "Sat, 19 Apr 2014 17:46:10 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Shachnai", "Hadas", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1402.3573", "submitter": "Ioannis Papoutsakis", "authors": "Ioannis Papoutsakis", "title": "Tree 3-spanners of diameter at most 5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree spanners approximate distances within graphs; a subtree of a graph is a\ntree $t$-spanner of the graph if and only if for every pair of vertices their\ndistance in the subtree is at most $t$ times their distance in the graph. When\na graph contains a subtree of diameter at most $t$, then trivially admits a\ntree $t$-spanner. Now, determining whether a graph admits a tree $t$-spanner of\ndiameter at most $t+1$ is an NP complete problem, when $t\\geq 4$, and it is\ntractable, when $t\\leq 3$. Although it is not known whether it is tractable to\ndecide graphs that admit a tree 3-spanner of any diameter, an efficient\nalgorithm to determine graphs that admit a tree 3-spanner of diameter at most 5\nis presented. Moreover, it is proved that if a graph of diameter at most 3\nadmits a tee 3-spanner, then it admits a tree 3-spanner of diameter at most 5.\nHence, this algorithm decides tree 3-spanner admissibility of diameter at most\n3 graphs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 20:28:20 GMT"}, {"version": "v2", "created": "Tue, 19 May 2015 17:38:24 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Papoutsakis", "Ioannis", ""]]}, {"id": "1402.3609", "submitter": "Reut Levi", "authors": "Reut Levi, Dana Ron, Ronitt Rubinfeld", "title": "Local Algorithms for Sparse Spanning Graphs", "comments": "Upper bounds for expanding graphs and minor free graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing a spanning tree of a graph is one of the most basic tasks in\ngraph theory. We consider a relaxed version of this problem in the setting of\nlocal algorithms. The relaxation is that the constructed subgraph is a sparse\nspanning subgraph containing at most $(1+\\epsilon)n$ edges (where $n$ is the\nnumber of vertices and $\\epsilon$ is a given approximation/sparsity parameter).\nIn the local setting, the goal is to quickly determine whether a given edge $e$\nbelongs to such a subgraph, without constructing the whole subgraph, but rather\nby inspecting (querying) the local neighborhood of $e$. The challenge is to\nmaintain consistency. That is, to provide answers concerning different edges\naccording to the same spanning subgraph. We first show that for general\nbounded-degree graphs, the query complexity of any such algorithm must be\n$\\Omega(\\sqrt{n})$. This lower bound holds for constant-degree graphs that have\nhigh expansion. Next we design an algorithm for (bounded-degree) graphs with\nhigh expansion, obtaining a result that roughly matches the lower bound. We\nthen turn to study graphs that exclude a fixed minor (and are hence\nnon-expanding). We design an algorithm for such graphs, which may have an\nunbounded maximum degree. The query complexity of this algorithm is\n$poly(1/\\epsilon, h)$ (independent of $n$ and the maximum degree), where $h$ is\nthe number of vertices in the excluded minor. Though our two algorithms are\ndesigned for very different types of graphs (and have very different\ncomplexities), on a high-level there are several similarities, and we highlight\nboth the similarities and the differences.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 21:36:27 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 21:40:42 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 13:57:14 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Levi", "Reut", ""], ["Ron", "Dana", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1402.3631", "submitter": "Justin Hsu", "authors": "Justin Hsu and Aaron Roth and Tim Roughgarden and Jonathan Ullman", "title": "Privately Solving Linear Programs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-43948-7_51", "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we initiate the systematic study of solving linear programs\nunder differential privacy. The first step is simply to define the problem: to\nthis end, we introduce several natural classes of private linear programs that\ncapture different ways sensitive data can be incorporated into a linear\nprogram. For each class of linear programs we give an efficient, differentially\nprivate solver based on the multiplicative weights framework, or we give an\nimpossibility result.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 00:55:46 GMT"}, {"version": "v2", "created": "Thu, 8 May 2014 19:52:34 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hsu", "Justin", ""], ["Roth", "Aaron", ""], ["Roughgarden", "Tim", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1402.3643", "submitter": "Shayan Oveis Gharan", "authors": "Mohammad Akbarpour and Shengwu Li and Shayan Oveis Gharan", "title": "Dynamic Matching Market Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple benchmark model of dynamic matching in networked\nmarkets, where agents arrive and depart stochastically and the network of\nacceptable transactions among agents forms a random graph. We analyze our model\nfrom three perspectives: waiting, optimization, and information. The main\ninsight of our analysis is that waiting to thicken the market can be\nsubstantially more important than increasing the speed of transactions, and\nthis is quite robust to the presence of waiting costs. From an optimization\nperspective, naive local algorithms, that choose the right time to match agents\nbut do not exploit global network structure, can perform very close to optimal\nalgorithms. From an information perspective, algorithms that employ even\npartial information on agents' departure times perform substantially better\nthan those that lack such information. To elicit agents' departure times, we\ndesign an incentive-compatible continuous-time dynamic mechanism without\ntransfers.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 04:30:41 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Akbarpour", "Mohammad", ""], ["Li", "Shengwu", ""], ["Gharan", "Shayan Oveis", ""]]}, {"id": "1402.3774", "submitter": "Pavel Klav\\'ik", "authors": "Ji\\v{r}\\'i Fiala, Pavel Klav\\'ik, Jan Kratochv\\'il, Roman Nedela", "title": "Algorithmic Aspects of Regular Graph Covers with Applications to Planar\n  Graphs", "comments": "The conference version accepted to ICALP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ covers a graph $H$ if there exists a locally bijective\nhomomorphism from $G$ to $H$. We deal with regular covers in which this locally\nbijective homomorphism is prescribed by an action of a subgroup of ${\\rm\nAut}(G)$. Regular covers have many applications in constructions and studies of\nbig objects all over mathematics and computer science.\n  We study computational aspects of regular covers that have not been addressed\nbefore. The decision problem RegularCover asks for two given graphs $G$ and $H$\nwhether $G$ regularly covers $H$. When $|H|=1$, this problem becomes Cayley\ngraph recognition for which the complexity is still unresolved. Another special\ncase arises for $|G| = |H|$ when it becomes the graph isomorphism problem.\nTherefore, we restrict ourselves to graph classes with polynomially solvable\ngraph isomorphism.\n  Inspired by Negami, we apply the structural results used by Babai in the\n1970's to study automorphism groups of graphs. Our main result is the following\nFPT meta-algorithm: Let $\\cal C$ be a class of graphs such that the structure\nof automorphism groups of 3-connected graphs in $\\cal C$ is simple. Then we can\nsolve RegularCover for $\\cal C$-inputs $G$ in time $O^*(2^{e(H)/2})$ where\n$e(H)$ denotes the number of the edges of $H$. As one example of $\\cal C$, this\nmeta-algorithm applies to planar graphs. In comparison, testing general graph\ncovers is known to be NP-complete for planar inputs $G$ even for small fixed\ngraphs $H$ such as $K_4$ or $K_5$. Most of our results also apply to general\ngraphs, in particular the complete structural understanding of regular covers\nfor 2-cuts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 09:04:43 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 00:17:09 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Fiala", "Ji\u0159\u00ed", ""], ["Klav\u00edk", "Pavel", ""], ["Kratochv\u00edl", "Jan", ""], ["Nedela", "Roman", ""]]}, {"id": "1402.3782", "submitter": "Vincent Chau", "authors": "Eric Angel, Evripidis Bampis, Vincent Chau, Nguyen Kim Thang", "title": "Throughput Maximization in Multiprocessor Speed-Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are given a set of $n$ jobs that have to be executed on a set of $m$\nspeed-scalable machines that can vary their speeds dynamically using the energy\nmodel introduced in [Yao et al., FOCS'95]. Every job $j$ is characterized by\nits release date $r_j$, its deadline $d_j$, its processing volume $p_{i,j}$ if\n$j$ is executed on machine $i$ and its weight $w_j$. We are also given a budget\nof energy $E$ and our objective is to maximize the weighted throughput, i.e.\nthe total weight of jobs that are completed between their respective release\ndates and deadlines. We propose a polynomial-time approximation algorithm where\nthe preemption of the jobs is allowed but not their migration. Our algorithm\nuses a primal-dual approach on a linearized version of a convex program with\nlinear constraints. Furthermore, we present two optimal algorithms for the\nnon-preemptive case where the number of machines is bounded by a fixed\nconstant. More specifically, we consider: {\\em (a)} the case of identical\nprocessing volumes, i.e. $p_{i,j}=p$ for every $i$ and $j$, for which we\npresent a polynomial-time algorithm for the unweighted version, which becomes a\npseudopolynomial-time algorithm for the weighted throughput version, and {\\em\n(b)} the case of agreeable instances, i.e. for which $r_i \\le r_j$ if and only\nif $d_i \\le d_j$, for which we present a pseudopolynomial-time algorithm. Both\nalgorithms are based on a discretization of the problem and the use of dynamic\nprogramming.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 10:15:47 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Angel", "Eric", ""], ["Bampis", "Evripidis", ""], ["Chau", "Vincent", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "1402.3796", "submitter": "Moti Medina", "authors": "Guy Even, Moti Medina, Dana Ron", "title": "Best of Two Local Models: Local Centralized and Local Distributed\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two models of computation: centralized local algorithms and local\ndistributed algorithms. Algorithms in one model are adapted to the other model\nto obtain improved algorithms.\n  Distributed vertex coloring is employed to design improved centralized local\nalgorithms for: maximal independent set, maximal matching, and an approximation\nscheme for maximum (weighted) matching over bounded degree graphs. The\nimprovement is threefold: the algorithms are deterministic, stateless, and the\nnumber of probes grows polynomially in $\\log^* n$, where $n$ is the number of\nvertices of the input graph.\n  The recursive centralized local improvement technique by Nguyen and\nOnak~\\cite{onak2008} is employed to obtain an improved distributed\napproximation scheme for maximum (weighted) matching. The improvement is\ntwofold: we reduce the number of rounds from $O(\\log n)$ to $O(\\log^*n)$ for a\nwide range of instances and, our algorithms are deterministic rather than\nrandomized.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 13:09:06 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 13:24:41 GMT"}, {"version": "v3", "created": "Tue, 11 Nov 2014 20:33:00 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Even", "Guy", ""], ["Medina", "Moti", ""], ["Ron", "Dana", ""]]}, {"id": "1402.3835", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement Canonne and Ronitt Rubinfeld", "title": "Testing probability distributions underlying aggregated data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze and study a hybrid model for testing and learning\nprobability distributions. Here, in addition to samples, the testing algorithm\nis provided with one of two different types of oracles to the unknown\ndistribution $D$ over $[n]$. More precisely, we define both the dual and\ncumulative dual access models, in which the algorithm $A$ can both sample from\n$D$ and respectively, for any $i\\in[n]$,\n  - query the probability mass $D(i)$ (query access); or\n  - get the total mass of $\\{1,\\dots,i\\}$, i.e. $\\sum_{j=1}^i D(j)$ (cumulative\naccess)\n  These two models, by generalizing the previously studied sampling and query\noracle models, allow us to bypass the strong lower bounds established for a\nnumber of problems in these settings, while capturing several interesting\naspects of these problems -- and providing new insight on the limitations of\nthe models. Finally, we show that while the testing algorithms can be in most\ncases strictly more efficient, some tasks remain hard even with this additional\npower.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 20:00:00 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Canonne", "Cl\u00e9ment", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1402.3849", "submitter": "Radha Chitta", "authors": "Radha Chitta, Rong Jin, Timothy C. Havens, Anil K. Jain", "title": "Scalable Kernel Clustering: Approximate Kernel k-means", "comments": "15 pages, 6 figures,extension of the work \"Approximate Kernel\n  k-means: Solution to large scale kernel clustering\" published in KDD 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based clustering algorithms have the ability to capture the non-linear\nstructure in real world data. Among various kernel-based clustering algorithms,\nkernel k-means has gained popularity due to its simple iterative nature and\nease of implementation. However, its run-time complexity and memory footprint\nincrease quadratically in terms of the size of the data set, and hence, large\ndata sets cannot be clustered efficiently. In this paper, we propose an\napproximation scheme based on randomization, called the Approximate Kernel\nk-means. We approximate the cluster centers using the kernel similarity between\na few sampled points and all the points in the data set. We show that the\nproposed method achieves better clustering performance than the traditional low\nrank kernel approximation based clustering schemes. We also demonstrate that\nits running time and memory requirements are significantly lower than those of\nkernel k-means, with only a small reduction in the clustering quality on\nseveral public domain large data sets. We then employ ensemble clustering\ntechniques to further enhance the performance of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 22:19:40 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Chitta", "Radha", ""], ["Jin", "Rong", ""], ["Havens", "Timothy C.", ""], ["Jain", "Anil K.", ""]]}, {"id": "1402.3851", "submitter": "Ioannis Koutis", "authors": "Ioannis Koutis", "title": "Simple parallel and distributed algorithms for spectral graph\n  sparsification", "comments": "replaces \"A simple parallel and distributed algorithm for spectral\n  sparsification\". Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple algorithm for spectral graph sparsification, based on\niterative computations of weighted spanners and uniform sampling. Leveraging\nthe algorithms of Baswana and Sen for computing spanners, we obtain the first\ndistributed spectral sparsification algorithm. We also obtain a parallel\nalgorithm with improved work and time guarantees. Combining this algorithm with\nthe parallel framework of Peng and Spielman for solving symmetric diagonally\ndominant linear systems, we get a parallel solver which is much closer to being\npractical and significantly more efficient in terms of the total work.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 22:28:54 GMT"}, {"version": "v2", "created": "Thu, 17 Apr 2014 20:45:01 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Koutis", "Ioannis", ""]]}, {"id": "1402.3909", "submitter": "Fahad Panolan", "authors": "Fedor V. Fomin, Daniel Lokshtanov, Fahad Panolan, Saket Saurabh", "title": "Representative Sets of Product Families", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.4626", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subfamily ${\\cal F}'$ of a set family ${\\cal F}$ is said to $q$-{\\em\nrepresent} ${\\cal F}$ if for every $A \\in {\\cal F}$ and $B$ of size $q$ such\nthat $A \\cap B = \\emptyset$ there exists a set $A' \\in {\\cal F}'$ such that $A'\n\\cap B = \\emptyset$. In this paper, we consider the efficient computation of\n$q$-representative sets for {\\em product} families ${\\cal F}$. A family ${\\cal\nF}$ is a product family if there exist families ${\\cal A}$ and ${\\cal B}$ such\nthat ${\\cal F} = \\{A \\cup B~:~A \\in {\\cal A}, B \\in {\\cal B}, A \\cap B =\n\\emptyset\\}$. Our main technical contribution is an algorithm which given\n${\\cal A}$, ${\\cal B}$ and $q$ computes a $q$-representative family ${\\cal F}'$\nof ${\\cal F}$. The running time of our algorithm is sublinear in $|{\\cal F}|$\nfor many choices of ${\\cal A}$, ${\\cal B}$ and $q$ which occur naturally in\nseveral dynamic programming algorithms. We also give an algorithm for the\ncomputation of $q$-representative sets for product families ${\\cal F}$ in the\nmore general setting where $q$-representation also involves independence in a\nmatroid in addition to disjointness. This algorithm considerably outperforms\nthe naive approach where one first computes ${\\cal F}$ from ${\\cal A}$ and\n${\\cal B}$, and then computes the $q$-representative family ${\\cal F}'$ from\n${\\cal F}$.\n  We give two applications of our new algorithms for computing\n$q$-representative sets for product families. The first is a\n$3.8408^{k}n^{O(1)}$ deterministic algorithm for the Multilinear Monomial\nDetection ($k$-MlD) problem. The second is a significant improvement of\ndeterministic dynamic programming algorithms for \"connectivity problems\" on\ngraphs of bounded treewidth.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 06:55:42 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""]]}, {"id": "1402.3939", "submitter": "Suqi Cheng", "authors": "Suqi Cheng, Hua-Wei Shen, Junming Huang, Wei Chen, Xue-Qi Cheng", "title": "IMRank: Influence Maximization via Finding Self-Consistent Ranking", "comments": "10 pages, 8 figures, this paper has been submitted to SIGIR2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization, fundamental for word-of-mouth marketing and viral\nmarketing, aims to find a set of seed nodes maximizing influence spread on\nsocial network. Early methods mainly fall into two paradigms with certain\nbenefits and drawbacks: (1)Greedy algorithms, selecting seed nodes one by one,\ngive a guaranteed accuracy relying on the accurate approximation of influence\nspread with high computational cost; (2)Heuristic algorithms, estimating\ninfluence spread using efficient heuristics, have low computational cost but\nunstable accuracy.\n  We first point out that greedy algorithms are essentially finding a\nself-consistent ranking, where nodes' ranks are consistent with their\nranking-based marginal influence spread. This insight motivates us to develop\nan iterative ranking framework, i.e., IMRank, to efficiently solve influence\nmaximization problem under independent cascade model. Starting from an initial\nranking, e.g., one obtained from efficient heuristic algorithm, IMRank finds a\nself-consistent ranking by reordering nodes iteratively in terms of their\nranking-based marginal influence spread computed according to current ranking.\nWe also prove that IMRank definitely converges to a self-consistent ranking\nstarting from any initial ranking. Furthermore, within this framework, a\nlast-to-first allocating strategy and a generalization of this strategy are\nproposed to improve the efficiency of estimating ranking-based marginal\ninfluence spread for a given ranking. In this way, IMRank achieves both\nremarkable efficiency and high accuracy by leveraging simultaneously the\nbenefits of greedy algorithms and heuristic algorithms. As demonstrated by\nextensive experiments on large scale real-world social networks, IMRank always\nachieves high accuracy comparable to greedy algorithms, with computational cost\nreduced dramatically, even about $10-100$ times faster than other scalable\nheuristics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 09:33:15 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Cheng", "Suqi", ""], ["Shen", "Hua-Wei", ""], ["Huang", "Junming", ""], ["Chen", "Wei", ""], ["Cheng", "Xue-Qi", ""]]}, {"id": "1402.3973", "submitter": "Sjoerd Dirksen", "authors": "Sjoerd Dirksen", "title": "Dimensionality reduction with subgaussian matrices: a unified theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theory for Euclidean dimensionality reduction with subgaussian\nmatrices which unifies several restricted isometry property and\nJohnson-Lindenstrauss type results obtained earlier for specific data sets. In\nparticular, we recover and, in several cases, improve results for sets of\nsparse and structured sparse vectors, low-rank matrices and tensors, and smooth\nmanifolds. In addition, we establish a new Johnson-Lindenstrauss embedding for\ndata sets taking the form of an infinite union of subspaces of a Hilbert space.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 11:51:15 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Dirksen", "Sjoerd", ""]]}, {"id": "1402.4037", "submitter": "Hang Zhou", "authors": "Sampath Kannan, Claire Mathieu, Hang Zhou", "title": "Near-Linear Query Complexity for Graph Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How efficiently can we find an unknown graph using distance or shortest path\nqueries between its vertices? Let $G = (V,E)$ be an unweighted, connected graph\nof bounded degree. The edge set $E$ is initially unknown, and the graph can be\naccessed using a \\emph{distance oracle}, which receives a pair of vertices\n$(u,v)$ and returns the distance between $u$ and $v$. In the\n\\emph{verification} problem, we are given a hypothetical graph $\\hat G =\n(V,\\hat E)$ and want to check whether $G$ is equal to $\\hat G$. We analyze a\nnatural greedy algorithm and prove that it uses $n^{1+o(1)}$ distance queries.\nIn the more difficult \\emph{reconstruction} problem, $\\hat G$ is not given, and\nthe goal is to find the graph $G$. If the graph can be accessed using a\n\\emph{shortest path oracle}, which returns not just the distance but an actual\nshortest path between $u$ and $v$, we show that extending the idea of greedy\ngives a reconstruction algorithm that uses $n^{1+o(1)}$ shortest path queries.\nWhen the graph has bounded treewidth, we further bound the query complexity of\nthe greedy algorithms for both problems by $\\tilde O(n)$. When the graph is\nchordal, we provide a randomized algorithm for reconstruction using $\\tilde\nO(n)$ distance queries.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 15:44:34 GMT"}, {"version": "v2", "created": "Wed, 18 Feb 2015 09:45:58 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Kannan", "Sampath", ""], ["Mathieu", "Claire", ""], ["Zhou", "Hang", ""]]}, {"id": "1402.4050", "submitter": "Diodato Ferraioli", "authors": "Vincenzo Auletta, Ioannis Caragiannis, Diodato Ferraioli, Clemente\n  Galdi, and Giuseppe Persiano", "title": "Minority Becomes Majority in Social Networks", "comments": "To appear in WINE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often observed that agents tend to imitate the behavior of their\nneighbors in a social network. This imitating behavior might lead to the\nstrategic decision of adopting a public behavior that differs from what the\nagent believes is the right one and this can subvert the behavior of the\npopulation as a whole.\n  In this paper, we consider the case in which agents express preferences over\ntwo alternatives and model social pressure with the majority dynamics: at each\nstep an agent is selected and its preference is replaced by the majority of the\npreferences of her neighbors. In case of a tie, the agent does not change her\ncurrent preference. A profile of the agents' preferences is stable if the\npreference of each agent coincides with the preference of at least half of the\nneighbors (thus, the system is in equilibrium).\n  We ask whether there are network topologies that are robust to social\npressure. That is, we ask if there are graphs in which the majority of\npreferences in an initial profile always coincides with the majority of the\npreference in all stable profiles reachable from that profile. We completely\ncharacterize the graphs with this robustness property by showing that this is\npossible only if the graph has no edge or is a clique or very close to a\nclique. In other words, except for this handful of graphs, every graph admits\nat least one initial profile of preferences in which the majority dynamics can\nsubvert the initial majority. We also show that deciding whether a graph admits\na minority that becomes majority is NP-hard when the minority size is at most\n1/4-th of the social network size.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 16:35:13 GMT"}, {"version": "v2", "created": "Fri, 25 Jul 2014 08:35:26 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 10:30:40 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2015 07:46:50 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Auletta", "Vincenzo", ""], ["Caragiannis", "Ioannis", ""], ["Ferraioli", "Diodato", ""], ["Galdi", "Clemente", ""], ["Persiano", "Giuseppe", ""]]}, {"id": "1402.4073", "submitter": "Daniel Lemire", "authors": "Owen Kaser and Daniel Lemire", "title": "Threshold and Symmetric Functions over Bitmaps", "comments": "This paper uses small fonts and colours and is only intended for\n  electronic viewing", "journal-ref": null, "doi": null, "report-no": "TR-14-001", "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitmap indexes are routinely used to speed up simple aggregate queries in\ndatabases. Set operations such as intersections, unions and complements can be\nrepresented as logical operations (AND, OR, NOT). However, less is known about\nthe application of bitmap indexes to more advanced queries. We want to extend\nthe applicability of bitmap indexes. As a starting point, we consider symmetric\nBoolean queries (e.g., threshold functions). For example, we might consider\nstores as sets of products, and ask for products that are on sale in 2 to 10\nstores. Such symmetric Boolean queries generalize intersection, union, and\nT-occurrence queries.\n  It may not be immediately obvious to an engineer how to use bitmap indexes\nfor symmetric Boolean queries. Yet, maybe surprisingly, we find that the best\nof our bitmap-based algorithms are competitive with the state-of-the-art\nalgorithms for important special cases (e.g., MergeOpt, MergeSkip, DivideSkip,\nScanCount). Moreover, unlike the competing algorithms, the result of our\ncomputation is again a bitmap which can be further processed within a bitmap\nindex.\n  We review algorithmic design issues such as the aggregation of many\ncompressed bitmaps. We conclude with a discussion on other advanced queries\nthat bitmap indexes might be able to support efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 17:22:05 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 01:59:54 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Kaser", "Owen", ""], ["Lemire", "Daniel", ""]]}, {"id": "1402.4111", "submitter": "Vincent Cohen-Addad", "authors": "Vincent Cohen-Addad, Zhentao Li, Claire Mathieu, Ioannis Millis", "title": "Energy-efficient algorithms for non-preemptive speed-scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve complexity bounds for energy-efficient speed scheduling problems\nfor both the single processor and multi-processor cases. Energy conservation\nhas become a major concern, so revisiting traditional scheduling problems to\ntake into account the energy consumption has been part of the agenda of the\nscheduling community for the past few years.\n  We consider the energy minimizing speed scaling problem introduced by Yao et\nal. where we wish to schedule a set of jobs, each with a release date, deadline\nand work volume, on a set of identical processors. The processors may change\nspeed as a function of time and the energy they consume is the $\\alpha$th power\nof its speed. The objective is then to find a feasible schedule which minimizes\nthe total energy used.\n  We show that in the setting with an arbitrary number of processors where all\nwork volumes are equal, there is a $2(1+\\varepsilon)(5(1+\\varepsilon))^{\\alpha\n-1}\\tilde{B}_{\\alpha}=O_{\\alpha}(1)$ approximation algorithm, where\n$\\tilde{B}_{\\alpha}$ is the generalized Bell number. This is the first constant\nfactor algorithm for this problem. This algorithm extends to general unequal\nprocessor-dependent work volumes, up to losing a factor of\n$(\\frac{(1+r)r}{2})^{\\alpha}$ in the approximation, where $r$ is the maximum\nratio between two work volumes. We then show this latter problem is APX-hard,\neven in the special case when all release dates and deadlines are equal and $r$\nis 4.\n  In the single processor case, we introduce a new linear programming\nformulation of speed scaling and prove that its integrality gap is at most\n$12^{\\alpha -1}$. As a corollary, we obtain a $(12(1+\\varepsilon))^{\\alpha -1}$\napproximation algorithm where there is a single processor, improving on the\nprevious best bound of $2^{\\alpha-1}(1+\\varepsilon)^{\\alpha}\\tilde{B}_{\\alpha}$\nwhen $\\alpha \\ge 25$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 20:23:04 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 17:51:58 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Li", "Zhentao", ""], ["Mathieu", "Claire", ""], ["Millis", "Ioannis", ""]]}, {"id": "1402.4178", "submitter": "Thomas Kalinowski", "authors": "Enrico Angelelli, Thomas Kalinowski, Reena Kapoor, Martin W.P.\n  Savelsbergh", "title": "A reclaimer scheduling problem arising in coal stockyard management", "comments": "26 pages", "journal-ref": "Journal of Scheduling 19(5), 563-582, 2016", "doi": "10.1007/s10951-015-0436-y", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a number of variants of an abstract scheduling problem inspired by\nthe scheduling of reclaimers in the stockyard of a coal export terminal. We\nanalyze the complexity of each of the variants, providing complexity proofs for\nsome and polynomial algorithms for others. For one, especially interesting\nvariant, we also develop a constant factor approximation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 23:23:05 GMT"}, {"version": "v2", "created": "Thu, 1 Jan 2015 22:44:35 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Angelelli", "Enrico", ""], ["Kalinowski", "Thomas", ""], ["Kapoor", "Reena", ""], ["Savelsbergh", "Martin W. P.", ""]]}, {"id": "1402.4183", "submitter": "Zizhuo Wang", "authors": "Dongdong Ge, Zizhuo Wang, Lai Wei, Jiawei Zhang", "title": "An Improved Algorithm for Fixed-Hub Single Allocation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the fixed-hub single allocation problem (FHSAP). In this\nproblem, a network consists of hub nodes and terminal nodes. Hubs are fixed and\nfully connected; each terminal node is connected to a single hub which routes\nall its traffic. The goal is to minimize the cost of routing the traffic in the\nnetwork. In this paper, we propose a linear programming (LP)-based rounding\nalgorithm. The algorithm is based on two ideas. First, we modify the LP\nrelaxation formulation introduced in Ernst and Krishnamoorthy (1996, 1999) by\nincorporating a set of validity constraints. Then, after obtaining a fractional\nsolution to the LP relaxation, we make use of a geometric rounding algorithm to\nobtain an integral solution. We show that by incorporating the validity\nconstraints, the strengthened LP often provides much tighter upper bounds than\nthe previous methods with a little more computational effort, and the solution\nobtained often has a much smaller gap with the optimal solution. We also\nformulate a robust version of the FHSAP and show that it can guard against data\nuncertainty with little cost.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 23:42:50 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Ge", "Dongdong", ""], ["Wang", "Zizhuo", ""], ["Wei", "Lai", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1402.4194", "submitter": "Shaddin Dughmi", "authors": "Shaddin Dughmi", "title": "On the Hardness of Signaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in the role of information in\nstrategic interactions. Much of this work seeks to understand how the realized\nequilibrium of a game is influenced by uncertainty in the environment and the\ninformation available to players in the game. Lurking beneath this literature\nis a fundamental, yet largely unexplored, algorithmic question: how should a\n\"market maker\" who is privy to additional information, and equipped with a\nspecified objective, inform the players in the game? This is an informational\nanalogue of the mechanism design question, and views the information structure\nof a game as a mathematical object to be designed, rather than an exogenous\nvariable.\n  We initiate a complexity-theoretic examination of the design of optimal\ninformation structures in general Bayesian games, a task often referred to as\nsignaling. We focus on one of the simplest instantiations of the signaling\nquestion: Bayesian zero-sum games, and a principal who must choose an\ninformation structure maximizing the equilibrium payoff of one of the players.\nIn this setting, we show that optimal signaling is computationally intractable,\nand in some cases hard to approximate, assuming that it is hard to recover a\nplanted clique from an Erdos-Renyi random graph. This is despite the fact that\nequilibria in these games are computable in polynomial time, and therefore\nsuggests that the hardness of optimal signaling is a distinct phenomenon from\nthe hardness of equilibrium computation. Necessitated by the non-local nature\nof information structures, en-route to our results we prove an \"amplification\nlemma\" for the planted clique problem which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 00:43:23 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 05:41:56 GMT"}, {"version": "v3", "created": "Wed, 16 Jul 2014 18:27:43 GMT"}, {"version": "v4", "created": "Sun, 20 Jul 2014 11:26:31 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Dughmi", "Shaddin", ""]]}, {"id": "1402.4343", "submitter": "Gabriel Istrate", "authors": "Cosmin Bonchi\\c{s} and Gabriel Istrate", "title": "Minimum Entropy Submodular Optimization (and Fairness in Cooperative\n  Games)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimum entropy submodular optimization, a common generalization of\nthe minimum entropy set cover problem, studied earlier by Cardinal et al., and\nthe submodular set cover problem.\n  We give a general bound of the approximation performance of the greedy\nalgorithm using an approach that can be interpreted in terms of a particular\ntype of biased network flows. As an application we rederive known results for\nthe Minimum Entropy Set Cover and Minimum Entropy Orientation problems, and\nobtain a nontrivial bound for a new problem called the Minimum Entropy Spanning\nTree problem.\n  The problem can be applied to (and is partly motivated by) the definition of\nworst-case approaches to fairness in concave cooperative games, similar to the\nnotion of price of anarchy in noncooperative settings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 14:10:19 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Bonchi\u015f", "Cosmin", ""], ["Istrate", "Gabriel", ""]]}, {"id": "1402.4346", "submitter": "Chihao Zhang", "authors": "Jingcheng Liu, Pinyan Lu and Chihao Zhang", "title": "The Complexity of Ferromagnetic Two-spin Systems with External Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of computing the partition function for\nferromagnetic two-state spin systems. The remarkable algorithm by Jerrum and\nSinclair showed that there is a fully polynomial-time randomized approximation\nscheme (FPRAS) for the special ferromagnetic Ising model with any given uniform\nexternal field. Later, Goldberg and Jerrum proved that it is #BIS-hard for\nIsing model if we allow inconsistent external fields on different nodes. In\ncontrast to these two results, we prove that for any ferromagnetic two-state\nspin systems except the Ising model, there exists a threshold for external\nfields beyond which the problem is #BIS-hard, even if the external field is\nuniform.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 14:20:54 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Liu", "Jingcheng", ""], ["Lu", "Pinyan", ""], ["Zhang", "Chihao", ""]]}, {"id": "1402.4364", "submitter": "Vincenzo Roselli", "authors": "Patrizio Angelini, Giordano Da Lozzo, Giuseppe Di Battista, Fabrizio\n  Frati, Maurizio Patrignani, Vincenzo Roselli", "title": "Morphing Planar Graph Drawings Optimally", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an algorithm for computing a planar morph between any two planar\nstraight-line drawings of any $n$-vertex plane graph in $O(n)$ morphing steps,\nthus improving upon the previously best known $O(n^2)$ upper bound. Further, we\nprove that our algorithm is optimal, that is, we show that there exist two\nplanar straight-line drawings $\\Gamma_s$ and $\\Gamma_t$ of an $n$-vertex plane\ngraph $G$ such that any planar morph between $\\Gamma_s$ and $\\Gamma_t$ requires\n$\\Omega(n)$ morphing steps.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 14:55:41 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 08:55:05 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Angelini", "Patrizio", ""], ["Da Lozzo", "Giordano", ""], ["Di Battista", "Giuseppe", ""], ["Frati", "Fabrizio", ""], ["Patrignani", "Maurizio", ""], ["Roselli", "Vincenzo", ""]]}, {"id": "1402.4370", "submitter": "Chihao Zhang", "authors": "Pinyan Lu, Menghui Wang and Chihao Zhang", "title": "FPTAS for Weighted Fibonacci Gates and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fibonacci gate problems have severed as computation primitives to solve other\nproblems by holographic algorithm and play an important role in the dichotomy\nof exact counting for Holant and CSP frameworks. We generalize them to weighted\ncases and allow each vertex function to have different parameters, which is a\nmuch boarder family and #P-hard for exactly counting. We design a fully\npolynomial-time approximation scheme (FPTAS) for this generalization by\ncorrelation decay technique. This is the first deterministic FPTAS for\napproximate counting in the general Holant framework without a degree bound. We\nalso formally introduce holographic reduction in the study of approximate\ncounting and these weighted Fibonacci gate problems serve as computation\nprimitives for approximate counting. Under holographic reduction, we obtain\nFPTAS for other Holant problems and spin problems. One important application is\ndeveloping an FPTAS for a large range of ferromagnetic two-state spin systems.\nThis is the first deterministic FPTAS in the ferromagnetic range for two-state\nspin systems without a degree bound. Besides these algorithms, we also develop\nseveral new tools and techniques to establish the correlation decay property,\nwhich are applicable in other problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 15:15:37 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Lu", "Pinyan", ""], ["Wang", "Menghui", ""], ["Zhang", "Chihao", ""]]}, {"id": "1402.4376", "submitter": "Jeremy Kun", "authors": "Jeremy Kun and Lev Reyzin", "title": "On Coloring Resilient Graphs", "comments": "Appearing in MFCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of resilience for constraint satisfaction problems,\nwith the goal of more precisely determining the boundary between NP-hardness\nand the existence of efficient algorithms for resilient instances. In\nparticular, we study $r$-resiliently $k$-colorable graphs, which are those\n$k$-colorable graphs that remain $k$-colorable even after the addition of any\n$r$ new edges. We prove lower bounds on the NP-hardness of coloring resiliently\ncolorable graphs, and provide an algorithm that colors sufficiently resilient\ngraphs. We also analyze the corresponding notion of resilience for $k$-SAT.\nThis notion of resilience suggests an array of open questions for graph\ncoloring and other combinatorial problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 15:50:15 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2014 22:20:46 GMT"}], "update_date": "2014-06-13", "authors_parsed": [["Kun", "Jeremy", ""], ["Reyzin", "Lev", ""]]}, {"id": "1402.4455", "submitter": "Marijn Heule", "authors": "Sid Mijnders and Boris de Wilde and Marijn Heule", "title": "Symbiosis of Search and Heuristics for Random 3-SAT", "comments": "Proceedings of the Third International Workshop on Logic and Search\n  (LaSh 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When combined properly, search techniques can reveal the full potential of\nsophisticated branching heuristics. We demonstrate this observation on the\nwell-known class of random 3-SAT formulae. First, a new branching heuristic is\npresented, which generalizes existing work on this class. Much smaller search\ntrees can be constructed by using this heuristic. Second, we introduce a\nvariant of discrepancy search, called ALDS. Theoretical and practical evidence\nsupport that ALDS traverses the search tree in a near-optimal order when\ncombined with the new heuristic. Both techniques, search and heuristic, have\nbeen implemented in the look-ahead solver march. The SAT 2009 competition\nresults show that march is by far the strongest complete solver on random k-SAT\nformulae.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 19:59:58 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Mijnders", "Sid", ""], ["de Wilde", "Boris", ""], ["Heule", "Marijn", ""]]}, {"id": "1402.4465", "submitter": "Marijn Heule", "authors": "Peter van der Tak and Marijn J.H. Heule and Armin Biere", "title": "Concurrent Cube-and-Conquer", "comments": "Third International Workshop on Pragmatics of SAT (PoS 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced the cube-and-conquer technique to solve hard SAT\ninstances. It partitions the search space into cubes using a lookahead solver.\nEach cube is tackled by a conflict-driven clause learning (CDCL) solver.\nCrucial for strong performance is the cutoff heuristic that decides when to\nswitch from lookahead to CDCL. Yet, this offline heuristic is far from ideal.\nIn this paper, we present a novel hybrid solver that applies the cube and\nconquer steps simultaneously. A lookahead and a CDCL solver work together on\neach cube, while communication is restricted to synchronization. Our concurrent\ncube-and-conquer solver can solve many instances faster than pure lookahead,\npure CDCL and offline cube-and-conquer, and can abort early in favor of a pure\nCDCL search if an instance is not suitable for cube-and-conquer techniques.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 20:39:30 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["van der Tak", "Peter", ""], ["Heule", "Marijn J. H.", ""], ["Biere", "Armin", ""]]}, {"id": "1402.4466", "submitter": "Daniel Lemire", "authors": "Owen Kaser and Daniel Lemire", "title": "Compressed bitmap indexes: beyond unions and intersections", "comments": "Accepted for publication in Software: Practice and Experience on\n  August 14th 2014. Note that arXiv:1402.4073 [cs:DB] is a companion to this\n  paper; while they share some text, each contains many results not in the\n  other", "journal-ref": "Software: Practice & Experience 46 (2), 2016", "doi": "10.1002/spe.2289", "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed bitmap indexes are used to speed up simple aggregate queries in\ndatabases. Indeed, set operations like intersections, unions and complements\ncan be represented as logical operations (AND,OR,NOT) that are ideally suited\nfor bitmaps. However, it is less obvious how to apply bitmaps to more advanced\nqueries. For example, we might seek products in a store that meet some, but\nmaybe not all, criteria. Such threshold queries generalize intersections and\nunions; they are often used in information-retrieval and data-mining\napplications. We introduce new algorithms that are sometimes three orders of\nmagnitude faster than a naive approach. Our work shows that bitmap indexes are\nmore broadly applicable than is commonly believed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 20:41:33 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 18:28:14 GMT"}, {"version": "v3", "created": "Fri, 15 Aug 2014 13:45:47 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Kaser", "Owen", ""], ["Lemire", "Daniel", ""]]}, {"id": "1402.4515", "submitter": "Trent Rogers", "authors": "Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers, and Scott M.\n  Summers", "title": "The Power of Duples (in Self-Assembly): It's Not So Hip To Be Square", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we define the Dupled abstract Tile Assembly Model (DaTAM),\nwhich is a slight extension to the abstract Tile Assembly Model (aTAM) that\nallows for not only the standard square tiles, but also \"duple\" tiles which are\nrectangles pre-formed by the joining of two square tiles. We show that the\naddition of duples allows for powerful behaviors of self-assembling systems at\ntemperature 1, meaning systems which exclude the requirement of cooperative\nbinding by tiles (i.e., the requirement that a tile must be able to bind to at\nleast 2 tiles in an existing assembly if it is to attach). Cooperative binding\nis conjectured to be required in the standard aTAM for Turing universal\ncomputation and the efficient self-assembly of shapes, but we show that in the\nDaTAM these behaviors can in fact be exhibited at temperature 1. We then show\nthat the DaTAM doesn't provide asymptotic improvements over the aTAM in its\nability to efficiently build thin rectangles. Finally, we present a series of\nresults which prove that the temperature-2 aTAM and temperature-1 DaTAM have\nmutually exclusive powers. That is, each is able to self-assemble shapes that\nthe other can't, and each has systems which cannot be simulated by the other.\nBeyond being of purely theoretical interest, these results have practical\nmotivation as duples have already proven to be useful in laboratory\nimplementations of DNA-based tiles.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 22:23:27 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2014 00:52:37 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Hendricks", "Jacob", ""], ["Patitz", "Matthew J.", ""], ["Rogers", "Trent A.", ""], ["Summers", "Scott M.", ""]]}, {"id": "1402.4556", "submitter": "Yitong Yin", "authors": "Yitong Yin", "title": "Spatial Mixing of Coloring Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strong spatial mixing (decay of correlation) property of proper\n$q$-colorings of random graph $G(n, d/n)$ with a fixed $d$. The strong spatial\nmixing of coloring and related models have been extensively studied on graphs\nwith bounded maximum degree. However, for typical classes of graphs with\nbounded average degree, such as $G(n, d/n)$, an easy counterexample shows that\ncolorings do not exhibit strong spatial mixing with high probability.\nNevertheless, we show that for $q\\ge\\alpha d+\\beta$ with $\\alpha>2$ and\nsufficiently large $\\beta=O(1)$, with high probability proper $q$-colorings of\nrandom graph $G(n, d/n)$ exhibit strong spatial mixing with respect to an\narbitrarily fixed vertex. This is the first strong spatial mixing result for\ncolorings of graphs with unbounded maximum degree. Our analysis of strong\nspatial mixing establishes a block-wise correlation decay instead of the\nstandard point-wise decay, which may be of interest by itself, especially for\ngraphs with unbounded degree.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 04:19:28 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Yin", "Yitong", ""]]}, {"id": "1402.4624", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and Anju Kambadur and Aurelie C. Lozano and Ronny\n  Luss", "title": "Sparse Quantile Huber Regression for Efficient and Robust Estimation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider new formulations and methods for sparse quantile regression in\nthe high-dimensional setting. Quantile regression plays an important role in\nmany applications, including outlier-robust exploratory analysis in gene\nselection. In addition, the sparsity consideration in quantile regression\nenables the exploration of the entire conditional distribution of the response\nvariable given the predictors and therefore yields a more comprehensive view of\nthe important predictors. We propose a generalized OMP algorithm for variable\nselection, taking the misfit loss to be either the traditional quantile loss or\na smooth version we call quantile Huber, and compare the resulting greedy\napproaches with convex sparsity-regularized formulations. We apply a recently\nproposed interior point methodology to efficiently solve all convex\nformulations as well as convex subproblems in the generalized OMP setting, pro-\nvide theoretical guarantees of consistent estimation, and demonstrate the\nperformance of our approach using empirical studies of simulated and genomic\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 11:18:32 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Kambadur", "Anju", ""], ["Lozano", "Aurelie C.", ""], ["Luss", "Ronny", ""]]}, {"id": "1402.4718", "submitter": "Bart M. P. Jansen", "authors": "Bart M. P. Jansen", "title": "Turing Kernelization for Finding Long Paths and Cycles in Restricted\n  Graph Classes", "comments": "39 pages, 8 figures", "journal-ref": "J. Comput. Syst. Sci. vol 85 pages 18--37, 2017", "doi": "10.1016/j.jcss.2016.10.008", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NP-complete $k$-Path problem asks whether a given undirected graph has a\n(simple) path of length at least $k$. We prove that $k$-Path has\npolynomial-size Turing kernels when restricted to planar graphs, graphs of\nbounded degree, claw-free graphs, or to $K_{3,t}$-minor-free graphs for some\nconstant $t$. This means that there is an algorithm that, given a $k$-Path\ninstance $(G,k)$ belonging to one of these graph classes, computes its answer\nin polynomial time when given access to an oracle that solves $k$-Path\ninstances of size polynomial in $k$ in a single step. The difficulty of\n$k$-Path can therefore be confined to subinstances whose size is independent of\nthe total input size, but is bounded by a polynomial in the parameter $k$\nalone. These results contrast existing superpolynomial lower bounds for the\nsizes of traditional kernels for the $k$-Path problem on these graph classes:\nthere is no polynomial-time algorithm that reduces any instance $(G,k)$ to a\nsingle, equivalent instance $(G',k')$ of size polynomial in $k$ unless $NP\n\\subseteq coNP/poly$. The same positive and negative results apply to the\n$k$-Cycle problem, which asks for the existence of a cycle of length at least\n$k$. Our kernelization schemes are based on a new methodology called\nDecompose-Query-Reduce.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 16:26:30 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 09:51:07 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Jansen", "Bart M. P.", ""]]}, {"id": "1402.4722", "submitter": "Guilherme D. da Fonseca", "authors": "Guilherme D. da Fonseca, Vin\\'icius G. Pereira de S\\'a and Celina M.\n  H. de Figueiredo", "title": "Shifting coresets: obtaining linear-time approximations for unit disk\n  graphs and other geometric intersection graphs", "comments": "An extended abstract of this paper appeared in the 12th Workshop on\n  Approximation and Online Algorithms (WAOA), part of ALGO~2014. The journal\n  version will appear at International Journal of Computational Geometry and\n  Applications", "journal-ref": "WAOA 2014, LNCS 8952:132-143, 2015", "doi": "10.1007/978-3-319-18263-6_12", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous approximation algorithms for problems on unit disk graphs have been\nproposed in the literature, exhibiting a sharp trade-off between running times\nand approximation ratios. We introduce a variation of the known shifting\nstrategy that allows us to obtain linear-time constant-factor approximation\nalgorithms for such problems. To illustrate the applicability of the proposed\nvariation, we obtain results for three well-known optimization problems. Among\nsuch results, the proposed method yields linear-time (4+eps)-approximation for\nthe maximum-weight independent set and the minimum dominating set of unit disk\ngraphs, thus bringing significant performance improvements when compared to\nprevious algorithms that achieve the same approximation ratios. Finally, we use\naxis-aligned rectangles to illustrate that the same method may be used to\nderive linear-time approximations for problems on other geometric intersection\ngraph classes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 16:30:04 GMT"}, {"version": "v2", "created": "Mon, 5 May 2014 16:29:04 GMT"}, {"version": "v3", "created": "Thu, 4 Sep 2014 09:27:54 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2015 10:30:45 GMT"}, {"version": "v5", "created": "Sat, 5 Nov 2016 11:11:18 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["da Fonseca", "Guilherme D.", ""], ["de S\u00e1", "Vin\u00edcius G. Pereira", ""], ["de Figueiredo", "Celina M. H.", ""]]}, {"id": "1402.4746", "submitter": "Ananda Theertha Suresh", "authors": "Jayadev Acharya, Ashkan Jafarpour, Alon Orlitsky, Ananda Theertha\n  Suresh", "title": "Near-optimal-sample estimators for spherical Gaussian mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical and machine-learning algorithms are frequently applied to\nhigh-dimensional data. In many of these applications data is scarce, and often\nmuch more costly than computation time. We provide the first sample-efficient\npolynomial-time estimator for high-dimensional spherical Gaussian mixtures.\n  For mixtures of any $k$ $d$-dimensional spherical Gaussians, we derive an\nintuitive spectral-estimator that uses\n$\\mathcal{O}_k\\bigl(\\frac{d\\log^2d}{\\epsilon^4}\\bigr)$ samples and runs in time\n$\\mathcal{O}_{k,\\epsilon}(d^3\\log^5 d)$, both significantly lower than\npreviously known. The constant factor $\\mathcal{O}_k$ is polynomial for sample\ncomplexity and is exponential for the time complexity, again much smaller than\nwhat was previously known. We also show that\n$\\Omega_k\\bigl(\\frac{d}{\\epsilon^2}\\bigr)$ samples are needed for any\nalgorithm. Hence the sample complexity is near-optimal in the number of\ndimensions.\n  We also derive a simple estimator for one-dimensional mixtures that uses\n$\\mathcal{O}\\bigl(\\frac{k \\log \\frac{k}{\\epsilon} }{\\epsilon^2} \\bigr)$ samples\nand runs in time\n$\\widetilde{\\mathcal{O}}\\left(\\bigl(\\frac{k}{\\epsilon}\\bigr)^{3k+1}\\right)$.\nOur other technical contributions include a faster algorithm for choosing a\ndensity estimate from a set of distributions, that minimizes the $\\ell_1$\ndistance to an unknown underlying distribution.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 17:59:55 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Acharya", "Jayadev", ""], ["Jafarpour", "Ashkan", ""], ["Orlitsky", "Alon", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1402.4855", "submitter": "Sergio Cabello", "authors": "Sergio Cabello, Miha Jej\\v{c}i\\v{c}", "title": "Shortest Paths in Intersection Graphs of Unit Disks", "comments": "An alternative approach for the unweighted case is added to the\n  Introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a unit disk graph in the plane defined by $n$ disks whose\npositions are known. For the case when $G$ is unweighted, we give a simple\nalgorithm to compute a shortest path tree from a given source in $O(n\\log n)$\ntime. For the case when $G$ is weighted, we show that a shortest path tree from\na given source can be computed in $O(n^{1+\\varepsilon})$ time, improving the\nprevious best time bound of $O(n^{4/3+\\varepsilon})$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 00:59:45 GMT"}, {"version": "v2", "created": "Mon, 17 Nov 2014 22:43:17 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Cabello", "Sergio", ""], ["Jej\u010di\u010d", "Miha", ""]]}, {"id": "1402.4892", "submitter": "Kiran Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Andrew Thangaraj, Rahul Vaze", "title": "Sub-Modularity of Waterfilling with Applications to Online Basestation\n  Allocation", "comments": "5 pages, 2 figures; submitted to the International Symposium on\n  Information Theory 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the popular water-filling algorithm for maximizing the mutual\ninformation in parallel Gaussian channels is sub-modular. The sub-modularity of\nwater-filling algorithm is then used to derive online basestation allocation\nalgorithms, where mobile users are assigned to one of many possible\nbasestations immediately and irrevocably upon arrival without knowing the\nfuture user information. The goal of the allocation is to maximize the sum-rate\nof the system under power allocation at each basestation. We present online\nalgorithms with competitive ratio of at most 2 when compared to offline\nalgorithms that have knowledge of all future user arrivals.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 05:12:00 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Thangaraj", "Andrew", ""], ["Vaze", "Rahul", ""]]}, {"id": "1402.4926", "submitter": "Amer Mouawad", "authors": "Amer E. Mouawad, Naomi Nishimura, Venkatesh Raman, Sebastian Siebertz", "title": "Vertex Cover Reconfiguration and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Vertex Cover Reconfiguration (VCR) problem, given a graph $G$,\npositive integers $k$ and $\\ell$ and two vertex covers $S$ and $T$ of $G$ of\nsize at most $k$, we determine whether $S$ can be transformed into $T$ by a\nsequence of at most $\\ell$ vertex additions or removals such that every\noperation results in a vertex cover of size at most $k$. Motivated by results\nestablishing the W[1]-hardness of VCR when parameterized by $\\ell$, we\ndelineate the complexity of the problem restricted to various graph classes. In\nparticular, we show that VCR remains W[1]-hard on bipartite graphs, is NP-hard,\nbut fixed-parameter tractable on (regular) graphs of bounded degree and more\ngenerally on nowhere dense graphs and is solvable in polynomial time on trees\nand (with some additional restrictions) on cactus graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 08:24:29 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 16:00:28 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 19:02:07 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mouawad", "Amer E.", ""], ["Nishimura", "Naomi", ""], ["Raman", "Venkatesh", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1402.4994", "submitter": "Fabian Fuchs", "authors": "Fabian Fuchs, Dorothea Wagner", "title": "Arbitrary Transmission Power in the SINR Model: Local Broadcasting,\n  Coloring and MIS", "comments": "Improved Runtime of Local Broadcasting by a factor of \\Gamma^\\alpha", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the light of energy conservation and the expansion of existing networks,\nwireless networks face the challenge of nodes with heterogeneous transmission\npower. However, for more realistic models of wireless communication only few\nalgorithmic results are known. In this paper we consider nodes with arbitrary,\npossibly variable, transmission power in the so-called physical or SINR model.\nOur first result is a bound on the probabilistic interference from all\nsimultaneously transmitting nodes on receivers. This result implies that\ncurrent local broadcasting algorithms can be generalized to the case of\nnon-uniform transmission power with minor changes. The algorithms run in\n$\\O(\\Gamma^{2} \\Delta \\log n)$ time slots if the maximal degree $\\Delta$ is\nknown, and $\\O((\\Delta + \\log n)\\Gamma^{2} \\log n)$ otherwise, where $\\Gamma$\nis the ratio between the maximal and the minimal transmission range. The broad\napplicability of our result on bounding the interference is further\nhighlighted, by generalizing a distributed coloring algorithm to this setting.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 13:37:45 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2014 16:04:23 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Fuchs", "Fabian", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1402.5003", "submitter": "Magnus M. Halldorsson", "authors": "Marijke H.L. Bodlaender and Magn\\'us M. Halld\\'orsson", "title": "Beyond Geometry : Towards Fully Realistic Wireless Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal-strength models of wireless communications capture the gradual fading\nof signals and the additivity of interference. As such, they are closer to\nreality than other models. However, nearly all theoretic work in the SINR model\ndepends on the assumption of smooth geometric decay, one that is true in free\nspace but is far off in actual environments. The challenge is to model\nrealistic environments, including walls, obstacles, reflections and anisotropic\nantennas, without making the models algorithmically impractical or analytically\nintractable.\n  We present a simple solution that allows the modeling of arbitrary static\nsituations by moving from geometry to arbitrary decay spaces. The complexity of\na setting is captured by a metricity parameter Z that indicates how far the\ndecay space is from satisfying the triangular inequality. All results that hold\nin the SINR model in general metrics carry over to decay spaces, with the\nresulting time complexity and approximation depending on Z in the same way that\nthe original results depends on the path loss term alpha. For distributed\nalgorithms, that to date have appeared to necessarily depend on the planarity,\nwe indicate how they can be adapted to arbitrary decay spaces.\n  Finally, we explore the dependence on Z in the approximability of core\nproblems. In particular, we observe that the capacity maximization problem has\nexponential upper and lower bounds in terms of Z in general decay spaces. In\nEuclidean metrics and related growth-bounded decay spaces, the performance\ndepends on the exact metricity definition, with a polynomial upper bound in\nterms of Z, but an exponential lower bound in terms of a variant parameter phi.\nOn the plane, the upper bound result actually yields the first approximation of\na capacity-type SINR problem that is subexponential in alpha.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 14:11:14 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Bodlaender", "Marijke H. L.", ""], ["Halld\u00f3rsson", "Magn\u00fas M.", ""]]}, {"id": "1402.5164", "submitter": "Justin Thaler", "authors": "Varun Kanade and Justin Thaler", "title": "Distribution-Independent Reliable Learning", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several questions in the reliable agnostic learning framework of\nKalai et al. (2009), which captures learning tasks in which one type of error\nis costlier than others. A positive reliable classifier is one that makes no\nfalse positive errors. The goal in the positive reliable agnostic framework is\nto output a hypothesis with the following properties: (i) its false positive\nerror rate is at most $\\epsilon$, (ii) its false negative error rate is at most\n$\\epsilon$ more than that of the best positive reliable classifier from the\nclass. A closely related notion is fully reliable agnostic learning, which\nconsiders partial classifiers that are allowed to predict \"unknown\" on some\ninputs. The best fully reliable partial classifier is one that makes no errors\nand minimizes the probability of predicting \"unknown\", and the goal in fully\nreliable learning is to output a hypothesis that is almost as good as the best\nfully reliable partial classifier from a class.\n  For distribution-independent learning, the best known algorithms for PAC\nlearning typically utilize polynomial threshold representations, while the\nstate of the art agnostic learning algorithms use point-wise polynomial\napproximations. We show that one-sided polynomial approximations, an\nintermediate notion between polynomial threshold representations and point-wise\npolynomial approximations, suffice for learning in the reliable agnostic\nsettings. We then show that majorities can be fully reliably learned and\ndisjunctions of majorities can be positive reliably learned, through\nconstructions of appropriate one-sided polynomial approximations. Our fully\nreliable algorithm for majorities provides the first evidence that fully\nreliable learning may be strictly easier than agnostic learning. Our algorithms\nalso satisfy strong attribute-efficiency properties, and provide smooth\ntradeoffs between sample complexity and running time.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 22:41:39 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Kanade", "Varun", ""], ["Thaler", "Justin", ""]]}, {"id": "1402.5259", "submitter": "Gattaca Lv", "authors": "Gattaca Lv", "title": "An Analysis of Rank Aggregation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank aggregation is an essential approach for aggregating the preferences of\nmultiple agents. One rule of particular interest is the Kemeny rule, which\nmaximises the number of pairwise agreements between the final ranking and the\nexisting rankings. However, Kemeny rankings are NP-hard to compute. This has\nresulted in the development of various algorithms. Fortunately, NP-hardness may\nnot reflect the difficulty of solving problems that arise in practice. As a\nresult, we aim to demonstrate that the Kemeny consensus can be computed\nefficiently when aggregating different rankings in real case. In this paper, we\nextend a dynamic programming algorithm originally for Kemeny scores. We also\nprovide details on the implementation of the algorithm. Finally, we present\nresults obtained from an empirical comparison of our algorithm and two other\npopular algorithms based on real world and randomly generated problem\ninstances. Experimental results show the usefulness and efficiency of the\nalgorithm in practical settings.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 11:25:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2014 12:00:15 GMT"}, {"version": "v3", "created": "Thu, 10 Apr 2014 05:07:10 GMT"}, {"version": "v4", "created": "Sat, 26 Apr 2014 15:16:20 GMT"}, {"version": "v5", "created": "Sun, 4 May 2014 17:35:45 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Lv", "Gattaca", ""]]}, {"id": "1402.5492", "submitter": "\\\"Ozg\\\"ur  \\\"Ozkan", "authors": "Pooya Davoodi, Jeremy T. Fineman, John Iacono, \\\"Ozg\\\"ur \\\"Ozkan", "title": "Cache-Oblivious Persistence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial persistence is a general transformation that takes a data structure\nand allows queries to be executed on any past state of the structure. The\ncache-oblivious model is the leading model of a modern multi-level memory\nhierarchy.We present the first general transformation for making\ncache-oblivious model data structures partially persistent.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 08:08:23 GMT"}, {"version": "v2", "created": "Tue, 1 Jul 2014 04:56:48 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Davoodi", "Pooya", ""], ["Fineman", "Jeremy T.", ""], ["Iacono", "John", ""], ["\u00d6zkan", "\u00d6zg\u00fcr", ""]]}, {"id": "1402.5516", "submitter": "Peng Zhang", "authors": "Peng Zhang, Wei Chen, Xiaoming Sun, Yajun Wang, Jialin Zhang", "title": "Minimizing Seed Set Selection with Probabilistic Coverage Guarantee in a\n  Social Network", "comments": "Conference version will appear in KDD 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A topic propagating in a social network reaches its tipping point if the\nnumber of users discussing it in the network exceeds a critical threshold such\nthat a wide cascade on the topic is likely to occur. In this paper, we consider\nthe task of selecting initial seed users of a topic with minimum size so that\nwith a guaranteed probability the number of users discussing the topic would\nreach a given threshold. We formulate the task as an optimization problem\ncalled seed minimization with probabilistic coverage guarantee (SM-PCG). This\nproblem departs from the previous studies on social influence maximization or\nseed minimization because it considers influence coverage with probabilistic\nguarantees instead of guarantees on expected influence coverage. We show that\nthe problem is not submodular, and thus is harder than previously studied\nproblems based on submodular function optimization. We provide an approximation\nalgorithm and show that it approximates the optimal solution with both a\nmultiplicative ratio and an additive error. The multiplicative ratio is tight\nwhile the additive error would be small if influence coverage distributions of\ncertain seed sets are well concentrated. For one-way bipartite graphs we\nanalytically prove the concentration condition and obtain an approximation\nalgorithm with an $O(\\log n)$ multiplicative ratio and an $O(\\sqrt{n})$\nadditive error, where $n$ is the total number of nodes in the social graph.\nMoreover, we empirically verify the concentration condition in real-world\nnetworks and experimentally demonstrate the effectiveness of our proposed\nalgorithm comparing to commonly adopted benchmark algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 15:24:12 GMT"}, {"version": "v2", "created": "Wed, 18 Jun 2014 17:41:41 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Zhang", "Peng", ""], ["Chen", "Wei", ""], ["Sun", "Xiaoming", ""], ["Wang", "Yajun", ""], ["Zhang", "Jialin", ""]]}, {"id": "1402.5524", "submitter": "Olga Ohrimenko", "authors": "Olga Ohrimenko, Michael T. Goodrich, Roberto Tamassia, Eli Upfal", "title": "The Melbourne Shuffle: Improving Oblivious Storage in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple, efficient, and secure data-oblivious randomized shuffle\nalgorithm. This is the first secure data-oblivious shuffle that is not based on\nsorting. Our method can be used to improve previous oblivious storage solutions\nfor network-based outsourcing of data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 16:29:22 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Ohrimenko", "Olga", ""], ["Goodrich", "Michael T.", ""], ["Tamassia", "Roberto", ""], ["Upfal", "Eli", ""]]}, {"id": "1402.5613", "submitter": "Peng Bo", "authors": "Bo Peng, Zhipeng Lu, T.C.E. Cheng", "title": "A Tabu Search/Path Relinking Algorithm to Solve the Job Shop Scheduling\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that incorporates a tabu search procedure into the\nframework of path relinking to tackle the job shop scheduling problem (JSP).\nThis tabu search/path relinking (TS/PR) algorithm comprises several\ndistinguishing features, such as a specific relinking procedure and a reference\nsolution determination method. To test the performance of TS/PR, we apply it to\ntackle almost all of the benchmark JSP instances available in the literature.\nThe test results show that TS/PR obtains competitive results compared with\nstate-of-the-art algorithms for JSP in the literature, demonstrating its\nefficacy in terms of both solution quality and computational efficiency. In\nparticular, TS/PR is able to improve the upper bounds for 49 out of the 205\ntested instances and it solves a challenging instance that has remained\nunsolved for over 20 years.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 14:46:04 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Peng", "Bo", ""], ["Lu", "Zhipeng", ""], ["Cheng", "T. C. E.", ""]]}, {"id": "1402.5769", "submitter": "Atsushi Miyauchi", "authors": "Tomomi Matsui, Noriyoshi Sukegawa, Atsushi Miyauchi", "title": "Fractional programming formulation for the vertex coloring problem", "comments": "6 pages, 5 tables", "journal-ref": "Information Processing Letters 114, 706-709 (2014)", "doi": "10.1016/j.ipl.2014.06.010", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a new formulation for the vertex coloring problem. Different from\nother formulations, decision variables are associated with the pairs of\nvertices. Consequently, colors will be distinguishable. Although the objective\nfunction is fractional, it can be replaced by a piece-wise linear convex\nfunction. Numerical experiments show that our formulation has significantly\ngood performance for dense graphs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 10:01:07 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Matsui", "Tomomi", ""], ["Sukegawa", "Noriyoshi", ""], ["Miyauchi", "Atsushi", ""]]}, {"id": "1402.5818", "submitter": "Mohammad Tofighi", "authors": "Mohammad Tofighi, Alican Bozkurt, and A. Enis Cetin", "title": "Deconvolution Using Projections Onto The Epigraph Set of a Convex Cost\n  Function", "comments": "arXiv admin note: text overlap with arXiv:1309.0700, arXiv:1402.2088", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new deconvolution algorithm based on orthogonal projections onto the\nepigraph set of a convex cost function is presented. In this algorithm, the\ndimension of the minimization problem is lifted by one and sets corresponding\nto the cost function are defined. As the utilized cost function is a convex\nfunction in $R^N$, the corresponding epigraph set is also a convex set in\n$R^{N+1}$. The deconvolution algorithm starts with an arbitrary initial\nestimate in $R^{N+1}$. At each step of the iterative algorithm, first\ndeconvolution projections are performed onto the epigraphs, later an orthogonal\nprojection is performed onto one of the constraint sets associated with the\ncost function in a sequential manner. The method provides globally optimal\nsolutions for total-variation, $\\ell_1$, $\\ell_2$, and entropic cost functions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 13:26:50 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Tofighi", "Mohammad", ""], ["Bozkurt", "Alican", ""], ["Cetin", "A. Enis", ""]]}, {"id": "1402.5904", "submitter": "Stefan Hougardy", "authors": "Stefan Hougardy", "title": "On the Integrality Ratio of the Subtour LP for Euclidean TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long standing conjecture says that the integrality ratio of the subtour LP\nfor metric TSP is $4/3$. A well known family of graphic TSP instances achieves\nthis lower bound asymptotically. For Euclidean TSP the best known lower bound\non the integrality ratio was $8/7$. We improve this value by presenting a\nfamily of Euclidean TSP instances for which the integrality ratio of the\nsubtour LP converges to 4/3.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 17:44:30 GMT"}, {"version": "v2", "created": "Thu, 6 Mar 2014 09:40:16 GMT"}, {"version": "v3", "created": "Sun, 24 Aug 2014 11:51:43 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Hougardy", "Stefan", ""]]}, {"id": "1402.6109", "submitter": "Sebastian Ordyniak", "authors": "Eun Jung Kim, Sebastian Ordyniak, Stefan Szeider", "title": "The Complexity of Repairing, Adjusting, and Aggregating of Extensions in\n  Abstract Argumentation", "comments": null, "journal-ref": "Proc. TAFA 2013, pp. 158-175, Springer LNCS", "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of problems that arise in abstract\nargumentation in the context of dynamic argumentation, minimal change, and\naggregation. In particular, we consider the following problems where always an\nargumentation framework F and a small positive integer k are given.\n  - The Repair problem asks whether a given set of arguments can be modified\ninto an extension by at most k elementary changes (i.e., the extension is of\ndistance k from the given set).\n  - The Adjust problem asks whether a given extension can be modified by at\nmost k elementary changes into an extension that contains a specified argument.\n  - The Center problem asks whether, given two extensions of distance k,\nwhether there is a \"center\" extension that is a distance at most (k-1) from\nboth given extensions.\n  We study these problems in the framework of parameterized complexity, and\ntake the distance k as the parameter. Our results covers several different\nsemantics, including admissible, complete, preferred, semi-stable and stable\nsemantics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 09:45:23 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Kim", "Eun Jung", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""]]}, {"id": "1402.6148", "submitter": "Nicolas Broutin", "authors": "Nicolas Broutin, Olivier Devillers and Ross Hemsley", "title": "Efficiently navigating a random Delaunay triangulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planar graph navigation is an important problem with significant implications\nto both point location in geometric data structures and routing in networks.\nHowever, whilst a number of algorithms and existence proofs have been proposed,\nvery little analysis is available for the properties of the paths generated and\nthe computational resources required to generate them under a random\ndistribution hypothesis for the input. In this paper we analyse a new\ndeterministic planar navigation algorithm with constant competitiveness which\nfollows vertex adjacencies in the Delaunay triangulation. We call this strategy\ncone walk. We prove that given $n$ uniform points in a smooth convex domain of\nunit area, and for any start point $z$ and query point $q$; cone walk applied\nto $z$ and $q$ will access at most $O(|zq|\\sqrt{n} +\\log^7 n)$ sites with\ncomplexity $O(|zq|\\sqrt{n} \\log \\log n + \\log^7 n)$ with probability tending to\n1 as $n$ goes to infinity. We additionally show that in this model, cone walk\nis $(\\log ^{3+\\xi} n)$-memoryless with high probability for any pair of start\nand query point in the domain, for any positive $\\xi$. We take special care\nthroughout to ensure our bounds are valid even when the query points are\narbitrarily close to the border.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 12:28:04 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Broutin", "Nicolas", ""], ["Devillers", "Olivier", ""], ["Hemsley", "Ross", ""]]}, {"id": "1402.6190", "submitter": "Andrzej Dudek", "authors": "Andrzej Dudek, Marek Karpinski, Andrzej Ruci\\'nski, and Edyta\n  Szyma\\'nska", "title": "Approximate Counting of Matchings in $(3,3)$-Hypergraphs", "comments": "We thank Michael Simkin who pointed out and fixed an error (cf. Lemma\n  3 and the proof of Claim 7) in an earlier version of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a fully polynomial time approximation scheme (FPTAS) for counting\nthe number of matchings (packings) in arbitrary 3-uniform hypergraphs of\nmaximum degree three, referred to as $(3,3)$-hypergraphs. It is the first\npolynomial time approximation scheme for that problem, which includes also, as\na special case, the 3D Matching counting problem for 3-partite\n$(3,3)$-hypergraphs. The proof technique of this paper uses the general\ncorrelation decay technique and a new combinatorial analysis of the underlying\nstructures of the intersection graphs. The proof method could be also of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 15:04:21 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 07:57:48 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 17:30:14 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Dudek", "Andrzej", ""], ["Karpinski", "Marek", ""], ["Ruci\u0144ski", "Andrzej", ""], ["Szyma\u0144ska", "Edyta", ""]]}, {"id": "1402.6239", "submitter": "Andr\\'e Nichterlein", "authors": "Sepp Hartung and Clemens Hoffmann and Andr\\'e Nichterlein", "title": "Improved Upper and Lower Bound Heuristics for Degree Anonymization in\n  Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a strongly growing interest in anonymizing social network data,\nwe investigate the NP-hard Degree Anonymization problem: given an undirected\ngraph, the task is to add a minimum number of edges such that the graph becomes\nk-anonymous. That is, for each vertex there have to be at least k-1 other\nvertices of exactly the same degree. The model of degree anonymization has been\nintroduced by Liu and Terzi [ACM SIGMOD'08], who also proposed and evaluated a\ntwo-phase heuristic. We present an enhancement of this heuristic, including new\nalgorithms for each phase which significantly improve on the previously known\ntheoretical and practical running times. Moreover, our algorithms are optimized\nfor large-scale social networks and provide upper and lower bounds for the\noptimal solution. Notably, on about 26 % of the real-world data we provide\n(provably) optimal solutions; whereas in the other cases our upper bounds\nsignificantly improve on known heuristic solutions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 16:53:32 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Hartung", "Sepp", ""], ["Hoffmann", "Clemens", ""], ["Nichterlein", "Andr\u00e9", ""]]}, {"id": "1402.6246", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "An experimental exploration of Marsaglia's xorshift generators,\n  scrambled", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marsaglia proposed recently xorshift generators as a class of very fast,\ngood-quality pseudorandom number generators. Subsequent analysis by Panneton\nand L'Ecuyer has lowered the expectations raised by Marsaglia's paper, showing\nseveral weaknesses of such generators, verified experimentally using the\nTestU01 suite. Nonetheless, many of the weaknesses of xorshift generators fade\naway if their result is scrambled by a non-linear operation (as originally\nsuggested by Marsaglia). In this paper we explore the space of possible\ngenerators obtained by multiplying the result of a xorshift generator by a\nsuitable constant. We sample generators at 100 equispaced points of their state\nspace and obtain detailed statistics that lead us to choices of parameters that\nimprove on the current ones. We then explore for the first time the space of\nhigh-dimensional xorshift generators, following another suggestion in\nMarsaglia's paper, finding choices of parameters providing periods of length\n$2^{1024} - 1$ and $2^{4096} - 1$. The resulting generators are of extremely\nhigh quality, faster than current similar alternatives, and generate\nlong-period sequences passing strong statistical tests using only eight logical\noperations, one addition and one multiplication by a constant.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 19:18:20 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 18:54:48 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2015 09:44:46 GMT"}, {"version": "v4", "created": "Sun, 3 Jan 2016 23:36:58 GMT"}, {"version": "v5", "created": "Thu, 13 Oct 2016 06:56:03 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "1402.6278", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and David Xiao", "title": "Sample Complexity Bounds on Differentially Private Learning via\n  Communication Complexity", "comments": "Extended abstract appears in Conference on Learning Theory (COLT)\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze the sample complexity of classification by\ndifferentially private algorithms. Differential privacy is a strong and\nwell-studied notion of privacy introduced by Dwork et al. (2006) that ensures\nthat the output of an algorithm leaks little information about the data point\nprovided by any of the participating individuals. Sample complexity of private\nPAC and agnostic learning was studied in a number of prior works starting with\n(Kasiviswanathan et al., 2008) but a number of basic questions still remain\nopen, most notably whether learning with privacy requires more samples than\nlearning without privacy.\n  We show that the sample complexity of learning with (pure) differential\nprivacy can be arbitrarily higher than the sample complexity of learning\nwithout the privacy constraint or the sample complexity of learning with\napproximate differential privacy. Our second contribution and the main tool is\nan equivalence between the sample complexity of (pure) differentially private\nlearning of a concept class $C$ (or $SCDP(C)$) and the randomized one-way\ncommunication complexity of the evaluation problem for concepts from $C$. Using\nthis equivalence we prove the following bounds:\n  1. $SCDP(C) = \\Omega(LDim(C))$, where $LDim(C)$ is the Littlestone's (1987)\ndimension characterizing the number of mistakes in the online-mistake-bound\nlearning model. Known bounds on $LDim(C)$ then imply that $SCDP(C)$ can be much\nhigher than the VC-dimension of $C$.\n  2. For any $t$, there exists a class $C$ such that $LDim(C)=2$ but $SCDP(C)\n\\geq t$.\n  3. For any $t$, there exists a class $C$ such that the sample complexity of\n(pure) $\\alpha$-differentially private PAC learning is $\\Omega(t/\\alpha)$ but\nthe sample complexity of the relaxed $(\\alpha,\\beta)$-differentially private\nPAC learning is $O(\\log(1/\\beta)/\\alpha)$. This resolves an open problem of\nBeimel et al. (2013b).\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 19:00:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 04:14:50 GMT"}, {"version": "v3", "created": "Tue, 27 May 2014 02:06:43 GMT"}, {"version": "v4", "created": "Sun, 13 Sep 2015 04:53:25 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Feldman", "Vitaly", ""], ["Xiao", "David", ""]]}, {"id": "1402.6310", "submitter": "Jasine Babu", "authors": "Jasine Babu and Manu Basavaraju and L Sunil Chandran and Deepak\n  Rajendraprasad and Naveen Sivadasan", "title": "Approximating the Cubicity of Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cubicity of a graph $G$ is the smallest dimension $d$, for which $G$ is a\nunit disc graph in ${\\mathbb{R}}^d$, under the $l^\\infty$ metric, i.e. $G$ can\nbe represented as an intersection graph of $d$-dimensional (axis-parallel) unit\nhypercubes. We call such an intersection representation a $d$-dimensional cube\nrepresentation of $G$. Computing cubicity is known to be inapproximable in\npolynomial time, within an $O(n^{1-\\epsilon})$ factor for any $\\epsilon >0$,\nunless NP=ZPP.\n  In this paper, we present a randomized algorithm that runs in polynomial time\nand computes cube representations of trees, of dimension within a constant\nfactor of the optimum. It is also shown that the cubicity of trees can be\napproximated within a constant factor in deterministic polynomial time, if the\ncube representation is not required to be computed. As far as we know, this is\nthe first constant factor approximation algorithm for computing the cubicity of\ntrees. It is not yet clear whether computing the cubicity of trees is NP-hard\nor not.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 20:42:16 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Babu", "Jasine", ""], ["Basavaraju", "Manu", ""], ["Chandran", "L Sunil", ""], ["Rajendraprasad", "Deepak", ""], ["Sivadasan", "Naveen", ""]]}, {"id": "1402.6485", "submitter": "Martin Vatshelle", "authors": "Sigve Hortemo S{\\ae}ther, Jan Arne Telle, Martin Vatshelle", "title": "Solving MaxSAT and #SAT on structured CNF formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a structural parameter of CNF formulas and use it to\nidentify instances of weighted MaxSAT and #SAT that can be solved in polynomial\ntime. Given a CNF formula we say that a set of clauses is precisely satisfiable\nif there is some complete assignment satisfying these clauses only. Let the\nps-value of the formula be the number of precisely satisfiable sets of clauses.\nApplying the notion of branch decompositions to CNF formulas and using ps-value\nas cut function, we define the ps-width of a formula. For a formula given with\na decomposition of polynomial ps-width we show dynamic programming algorithms\nsolving weighted MaxSAT and #SAT in polynomial time. Combining with results of\n'Belmonte and Vatshelle, Graph classes with structured neighborhoods and\nalgorithmic applications, Theor. Comput. Sci. 511: 54-65 (2013)' we get\npolynomial-time algorithms solving weighted MaxSAT and #SAT for some classes of\nstructured CNF formulas. For example, we get $O(m^2(m + n)s)$ algorithms for\nformulas $F$ of $m$ clauses and $n$ variables and size $s$, if $F$ has a linear\nordering of the variables and clauses such that for any variable $x$ occurring\nin clause $C$, if $x$ appears before $C$ then any variable between them also\noccurs in $C$, and if $C$ appears before $x$ then $x$ occurs also in any clause\nbetween them. Note that the class of incidence graphs of such formulas do not\nhave bounded clique-width.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 10:48:36 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["S\u00e6ther", "Sigve Hortemo", ""], ["Telle", "Jan Arne", ""], ["Vatshelle", "Martin", ""]]}, {"id": "1402.6779", "submitter": "Aleksandrs Slivkins", "authors": "Ashwinkumar Badanidiyuru and John Langford and Aleksandrs Slivkins", "title": "Resourceful Contextual Bandits", "comments": "This is the full version of a paper in COLT 2014. Version history:\n  (v2) Added some details to one of the proofs, (v3) a big revision following\n  comments from COLT reviewers (but no new results), (v4) edits in related\n  work, minor edits elsewhere. (v6) A correction for Theorem 3, corollary for\n  contextual dynamic pricing with discretization; updated follow-up work & open\n  questions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual bandits with ancillary constraints on resources, which\nare common in real-world applications such as choosing ads or dynamic pricing\nof items. We design the first algorithm for solving these problems that handles\nconstrained resources other than time, and improves over a trivial reduction to\nthe non-contextual case. We consider very general settings for both contextual\nbandits (arbitrary policy sets, e.g. Dudik et al. (UAI'11)) and bandits with\nresource constraints (bandits with knapsacks, Badanidiyuru et al. (FOCS'13)),\nand prove a regret guarantee with near-optimal statistical properties.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 03:17:19 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 22:00:13 GMT"}, {"version": "v3", "created": "Mon, 19 May 2014 23:01:03 GMT"}, {"version": "v4", "created": "Tue, 1 Jul 2014 14:55:01 GMT"}, {"version": "v5", "created": "Mon, 13 Jul 2015 00:12:19 GMT"}, {"version": "v6", "created": "Fri, 31 Jul 2015 18:31:27 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Badanidiyuru", "Ashwinkumar", ""], ["Langford", "John", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "1402.7224", "submitter": "Nela Lekic", "authors": "Alexander Grigoriev, Steven Kelk, Nela Lekic", "title": "On low treewidth graphs and supertrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compatibility of unrooted phylogenetic trees is a well studied problem in\nphylogenetics. It asks to determine whether for a set of k input trees there\nexists a larger tree (called a supertree) that contains the topologies of all k\ninput trees. When any such supertree exists we call the instance compatible and\notherwise incompatible. It is known that the problem is NP-hard and FPT,\nalthough a constructive FPT algorithm is not known. It has been shown that\nwhenever the treewidth of an auxiliary structure known as the display graph is\nstrictly larger than the number of input trees, the instance is incompatible.\nHere we show that whenever the treewidth of the display graph is at most 2, the\ninstance is compatible. Furthermore, we give a polynomial-time algorithm to\nconstruct a supertree in this case. Finally, we demonstrate both compatible and\nincompatible instances that have display graphs with treewidth 3, highlighting\nthat the treewidth of the display graph is (on its own) not sufficient to\ndetermine compatibility.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 12:37:40 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Grigoriev", "Alexander", ""], ["Kelk", "Steven", ""], ["Lekic", "Nela", ""]]}, {"id": "1402.7301", "submitter": "Stefan Hougardy", "authors": "Stefan Hougardy and Rasmus T. Schroeder", "title": "Edge Elimination in TSP Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling Salesman Problem is one of the best studied NP-hard problems in\ncombinatorial optimization. Powerful methods have been developed over the last\n60 years to find optimum solutions to large TSP instances. The largest TSP\ninstance so far that has been solved optimally has 85,900 vertices. Its\nsolution required more than 136 years of total CPU time using the\nbranch-and-cut based Concorde TSP code [1]. In this paper we present graph\ntheoretic results that allow to prove that some edges of a TSP instance cannot\noccur in any optimum TSP tour. Based on these results we propose a\ncombinatorial algorithm to identify such edges. The runtime of the main part of\nour algorithm is $O(n^2 \\log n)$ for an n-vertex TSP instance. By combining our\napproach with the Concorde TSP solver we are able to solve a large TSPLIB\ninstance more than 11 times faster than Concorde alone.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 16:17:43 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Hougardy", "Stefan", ""], ["Schroeder", "Rasmus T.", ""]]}, {"id": "1402.7359", "submitter": "Theodore Yoder", "authors": "Guang Hao Low, Theodore J. Yoder, Isaac L. Chuang", "title": "Quantum Inference on Bayesian Networks", "comments": "8 pages, 3 figures. Submitted to PRX", "journal-ref": "Physical Review A 2014", "doi": "10.1103/PhysRevA.89.062315", "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing exact inference on Bayesian networks is known to be #P-hard.\nTypically approximate inference techniques are used instead to sample from the\ndistribution on query variables given the values $e$ of evidence variables.\nClassically, a single unbiased sample is obtained from a Bayesian network on\n$n$ variables with at most $m$ parents per node in time\n$\\mathcal{O}(nmP(e)^{-1})$, depending critically on $P(e)$, the probability the\nevidence might occur in the first place. By implementing a quantum version of\nrejection sampling, we obtain a square-root speedup, taking\n$\\mathcal{O}(n2^mP(e)^{-\\frac12})$ time per sample. We exploit the Bayesian\nnetwork's graph structure to efficiently construct a quantum state, a q-sample,\nrepresenting the intended classical distribution, and also to efficiently apply\namplitude amplification, the source of our speedup. Thus, our speedup is\nnotable as it is unrelativized -- we count primitive operations and require no\nblackbox oracle queries.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 19:59:38 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Low", "Guang Hao", ""], ["Yoder", "Theodore J.", ""], ["Chuang", "Isaac L.", ""]]}]