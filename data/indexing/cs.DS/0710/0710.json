[{"id": "0710.0083", "submitter": "Andrew McGregor", "authors": "Stanislav Angelov, Keshav Kunal, Andrew McGregor", "title": "Sorting and Selection with Random Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  There is a growing body of work on sorting and selection in models other than\nthe unit-cost comparison model. This work is the first treatment of a natural\nstochastic variant of the problem where the cost of comparing two elements is a\nrandom variable. Each cost is chosen independently and is known to the\nalgorithm. In particular we consider the following three models: each cost is\nchosen uniformly in the range $[0,1]$, each cost is 0 with some probability $p$\nand 1 otherwise, or each cost is 1 with probability $p$ and infinite otherwise.\nWe present lower and upper bounds (optimal in most cases) for these problems.\nWe obtain our upper bounds by carefully designing algorithms to ensure that the\ncosts incurred at various stages are independent and using properties of random\npartial orders when appropriate.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2007 18:10:28 GMT"}], "update_date": "2007-10-02", "authors_parsed": [["Angelov", "Stanislav", ""], ["Kunal", "Keshav", ""], ["McGregor", "Andrew", ""]]}, {"id": "0710.0262", "submitter": "Sebastian Roch", "authors": "Elchanan Mossel and Sebastien Roch", "title": "Incomplete Lineage Sorting: Consistent Phylogeny Estimation From\n  Multiple Loci", "comments": "Added a section on more general distance-based methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH", "license": null, "abstract": "  We introduce a simple algorithm for reconstructing phylogenies from multiple\ngene trees in the presence of incomplete lineage sorting, that is, when the\ntopology of the gene trees may differ from that of the species tree. We show\nthat our technique is statistically consistent under standard stochastic\nassumptions, that is, it returns the correct tree given sufficiently many\nunlinked loci. We also show that it can tolerate moderate estimation errors.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 11:11:43 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2007 03:41:04 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}, {"id": "0710.0318", "submitter": "Alexander Tiskin", "authors": "Vladimir Deineko and Alexander Tiskin", "title": "Fast minimum-weight double-tree shortcutting for Metric TSP: Is the best\n  one good enough?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Metric Traveling Salesman Problem (TSP) is a classical NP-hard\noptimization problem. The double-tree shortcutting method for Metric TSP yields\nan exponentially-sized space of TSP tours, each of which approximates the\noptimal solution within at most a factor of 2. We consider the problem of\nfinding among these tours the one that gives the closest approximation, i.e.\\\nthe \\emph{minimum-weight double-tree shortcutting}. Burkard et al. gave an\nalgorithm for this problem, running in time $O(n^3+2^d n^2)$ and memory $O(2^d\nn^2)$, where $d$ is the maximum node degree in the rooted minimum spanning\ntree. We give an improved algorithm for the case of small $d$ (including planar\nEuclidean TSP, where $d \\leq 4$), running in time $O(4^d n^2)$ and memory\n$O(4^d n)$. This improvement allows one to solve the problem on much larger\ninstances than previously attempted. Our computational experiments suggest that\nin terms of the time-quality tradeoff, the minimum-weight double-tree\nshortcutting method provides one of the best known tour-constructing\nheuristics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 15:25:18 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2009 16:17:30 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2009 16:17:25 GMT"}], "update_date": "2009-07-16", "authors_parsed": [["Deineko", "Vladimir", ""], ["Tiskin", "Alexander", ""]]}, {"id": "0710.0539", "submitter": "Anthony A. Ruffa", "authors": "Anthony A. Ruffa", "title": "A Novel Solution to the ATT48 Benchmark Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  A solution to the benchmark ATT48 Traveling Salesman Problem (from the\nTSPLIB95 library) results from isolating the set of vertices into ten\nopen-ended zones with nine lengthwise boundaries. In each zone, a\nminimum-length Hamiltonian Path (HP) is found for each combination of boundary\nvertices, leading to an approximation for the minimum-length Hamiltonian Cycle\n(HC). Determination of the optimal HPs for subsequent zones has the effect of\nautomatically filtering out non-optimal HPs from earlier zones. Although the\noptimal HC for ATT48 involves only two crossing edges between all zones (with\none exception), adding inter-zone edges can accommodate more complex problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2007 14:26:33 GMT"}], "update_date": "2007-10-03", "authors_parsed": [["Ruffa", "Anthony A.", ""]]}, {"id": "0710.1001", "submitter": "Vitaliy Kurlin", "authors": "V. Kurlin, L. Mihaylova", "title": "Connectivity of Random 1-Dimensional Networks", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in wireless sensor networks is to find the minimal\nnumber of randomly deployed sensors making a network connected with a given\nprobability. In practice sensors are often deployed one by one along a\ntrajectory of a vehicle, so it is natural to assume that arbitrary probability\ndensity functions of distances between successive sensors in a segment are\ngiven. The paper computes the probability of connectivity and coverage of\n1-dimensional networks and gives estimates for a minimal number of sensors for\nimportant distributions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2007 12:57:34 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2009 21:01:10 GMT"}], "update_date": "2009-10-10", "authors_parsed": [["Kurlin", "V.", ""], ["Mihaylova", "L.", ""]]}, {"id": "0710.1435", "submitter": "Michael Mahoney", "authors": "Petros Drineas, Michael W. Mahoney, S. Muthukrishnan, and Tamas Sarlos", "title": "Faster Least Squares Approximation", "comments": "25 pages; minor changes from previous version; this version will\n  appear in Numerische Mathematik", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least squares approximation is a technique to find an approximate solution to\na system of linear equations that has no exact solution. In a typical setting,\none lets $n$ be the number of constraints and $d$ be the number of variables,\nwith $n \\gg d$. Then, existing exact methods find a solution vector in\n$O(nd^2)$ time. We present two randomized algorithms that provide very accurate\nrelative-error approximations to the optimal value and the solution vector of a\nleast squares approximation problem more rapidly than existing exact\nalgorithms. Both of our algorithms preprocess the data with the Randomized\nHadamard Transform. One then uniformly randomly samples constraints and solves\nthe smaller problem on those constraints, and the other performs a sparse\nrandom projection and solves the smaller problem on those projected\ncoordinates. In both cases, solving the smaller problem provides relative-error\napproximations, and, if $n$ is sufficiently larger than $d$, the approximate\nsolution can be computed in $O(nd \\log d)$ time.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2007 17:37:37 GMT"}, {"version": "v2", "created": "Mon, 25 May 2009 23:01:43 GMT"}, {"version": "v3", "created": "Mon, 3 May 2010 06:55:54 GMT"}, {"version": "v4", "created": "Sun, 26 Sep 2010 18:36:00 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Drineas", "Petros", ""], ["Mahoney", "Michael W.", ""], ["Muthukrishnan", "S.", ""], ["Sarlos", "Tamas", ""]]}, {"id": "0710.1525", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna, Paolo Boldi", "title": "Efficient Optimally Lazy Algorithms for Minimal-Interval Semantics", "comments": "24 pages, 4 figures. A preliminary (now outdated) version was\n  presented at SPIRE 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimal-interval semantics associates with each query over a document a set\nof intervals, called witnesses, that are incomparable with respect to inclusion\n(i.e., they form an antichain): witnesses define the minimal regions of the\ndocument satisfying the query. Minimal-interval semantics makes it easy to\ndefine and compute several sophisticated proximity operators, provides snippets\nfor user presentation, and can be used to rank documents. In this paper we\nprovide algorithms for computing conjunction and disjunction that are linear in\nthe number of intervals and logarithmic in the number of operands; for\nadditional operators, such as ordered conjunction and Brouwerian difference, we\nprovide linear algorithms. In all cases, space is linear in the number of\noperands. More importantly, we define a formal notion of optimal laziness, and\neither prove it, or prove its impossibility, for each algorithm. We cast our\nresults in a general framework of antichains of intervals on total orders,\nmaking our algorithms directly applicable to other domains.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2007 12:15:48 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 08:57:30 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Vigna", "Sebastiano", ""], ["Boldi", "Paolo", ""]]}, {"id": "0710.1842", "submitter": "Frank Ruskey", "authors": "Frank Ruskey and Aaron Williams", "title": "An explicit universal cycle for the (n-1)-permutations of an n-set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": null, "abstract": "  We show how to construct an explicit Hamilton cycle in the directed Cayley\ngraph Cay({\\sigma_n, sigma_{n-1}} : \\mathbb{S}_n), where \\sigma_k = (1 2 >...\nk). The existence of such cycles was shown by Jackson (Discrete Mathematics,\n149 (1996) 123-129) but the proof only shows that a certain directed graph is\nEulerian, and Knuth (Volume 4 Fascicle 2, Generating All Tuples and\nPermutations (2005)) asks for an explicit construction. We show that a simple\nrecursion describes our Hamilton cycle and that the cycle can be generated by\nan iterative algorithm that uses O(n) space. Moreover, the algorithm produces\neach successive edge of the cycle in constant time; such algorithms are said to\nbe loopless.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2007 18:06:05 GMT"}], "update_date": "2007-10-10", "authors_parsed": [["Ruskey", "Frank", ""], ["Williams", "Aaron", ""]]}, {"id": "0710.2532", "submitter": "Maxwell Young", "authors": "Valerie King, Cynthia Phillips, Jared Saia and Maxwell Young", "title": "Sleeping on the Job: Energy-Efficient Broadcast for Radio Networks", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We address the problem of minimizing power consumption when performing\nreliable broadcast on a radio network under the following popular model. Each\nnode in the network is located on a point in a two dimensional grid, and\nwhenever a node sends a message, all awake nodes within distance r receive the\nmessage. In the broadcast problem, some node wants to successfully send a\nmessage to all other nodes in the network even when up to a 1/2 fraction of the\nnodes within every neighborhood can be deleted by an adversary. The set of\ndeleted nodes is carefully chosen by the adversary to foil our algorithm and\nmoreover, the set of deleted nodes may change periodically. This models\nworst-case behavior due to mobile nodes, static nodes losing power or simply\nsome points in the grid being unoccupied. A trivial solution requires each node\nin the network to be awake roughly 1/2 the time, and a trivial lower bound\nshows that each node must be awake for at least a 1/n fraction of the time. Our\nfirst result is an algorithm that requires each node to be awake for only a\n1/sqrt(n) fraction of the time in expectation. Our algorithm achieves this\nwhile ensuring correctness with probability 1, and keeping optimal values for\nother resource costs such as latency and number of messages sent. We give a\nlower-bound that shows that this reduction in power consumption is\nasymptotically optimal when latency and number of messages sent must be\noptimal. If we can increase the latency and messages sent by only a log*n\nfactor we give a Las Vegas algorithm that requires each node to be awake for\nonly a (log*n)/n expected fraction of the time; we give a lower-bound showing\nthat this second algorithm is near optimal. Finally, we show how to ensure\nenergy-efficient broadcast in the presence of Byzantine faults.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2007 19:56:45 GMT"}], "update_date": "2007-10-15", "authors_parsed": [["King", "Valerie", ""], ["Phillips", "Cynthia", ""], ["Saia", "Jared", ""], ["Young", "Maxwell", ""]]}, {"id": "0710.3246", "submitter": "John Talbot", "authors": "David Talbot and John Talbot", "title": "Bloom maps", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": null, "abstract": "  We consider the problem of succinctly encoding a static map to support\napproximate queries. We derive upper and lower bounds on the space requirements\nin terms of the error rate and the entropy of the distribution of values over\nkeys: our bounds differ by a factor log e. For the upper bound we introduce a\nnovel data structure, the Bloom map, generalising the Bloom filter to this\nproblem. The lower bound follows from an information theoretic argument.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2007 09:35:14 GMT"}], "update_date": "2007-10-18", "authors_parsed": [["Talbot", "David", ""], ["Talbot", "John", ""]]}, {"id": "0710.3603", "submitter": "Jakub Mare\\v{c}ek", "authors": "Edmund K. Burke, Jakub Marecek, Andrew J. Parkes, and Hana Rudova", "title": "On a Clique-Based Integer Programming Formulation of Vertex Colouring\n  with Applications in Course Timetabling", "comments": null, "journal-ref": "Annals of Operations Research (2010) 179(1), 105-130", "doi": "10.1007/s10479-010-0716-z", "report-no": "NOTTCS-TR-2007-10", "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex colouring is a well-known problem in combinatorial optimisation, whose\nalternative integer programming formulations have recently attracted\nconsiderable attention. This paper briefly surveys seven known formulations of\nvertex colouring and introduces a formulation of vertex colouring using a\nsuitable clique partition of the graph. This formulation is applicable in\ntimetabling applications, where such a clique partition of the conflict graph\nis given implicitly. In contrast with some alternatives, the presented\nformulation can also be easily extended to accommodate complex performance\nindicators (``soft constraints'') imposed in a number of real-life course\ntimetabling applications. Its performance depends on the quality of the clique\npartition, but encouraging empirical results for the Udine Course Timetabling\nproblem are reported.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 21:38:37 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2007 19:03:39 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2009 19:55:23 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Burke", "Edmund K.", ""], ["Marecek", "Jakub", ""], ["Parkes", "Andrew J.", ""], ["Rudova", "Hana", ""]]}, {"id": "0710.3642", "submitter": "Florent Bouchez", "authors": "Florent Bouchez (LIP), Alain Darte (LIP), Fabrice Rastello (LIP)", "title": "On the Complexity of Spill Everywhere under SSA Form", "comments": "10 pages", "journal-ref": "ACM SIGPLAN Notices Issue 7, Volume 42 (2007) 103 - 112", "doi": "10.1145/1254766.1254782", "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  Compilation for embedded processors can be either aggressive (time consuming\ncross-compilation) or just in time (embedded and usually dynamic). The\nheuristics used in dynamic compilation are highly constrained by limited\nresources, time and memory in particular. Recent results on the SSA form open\npromising directions for the design of new register allocation heuristics for\nembedded systems and especially for embedded compilation. In particular,\nheuristics based on tree scan with two separated phases -- one for spilling,\nthen one for coloring/coalescing -- seem good candidates for designing\nmemory-friendly, fast, and competitive register allocators. Still, also because\nof the side effect on power consumption, the minimization of loads and stores\noverhead (spilling problem) is an important issue. This paper provides an\nexhaustive study of the complexity of the ``spill everywhere'' problem in the\ncontext of the SSA form. Unfortunately, conversely to our initial hopes, many\nof the questions we raised lead to NP-completeness results. We identify some\npolynomial cases but that are impractical in JIT context. Nevertheless, they\ncan give hints to simplify formulations for the design of aggressive\nallocators.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 07:24:58 GMT"}], "update_date": "2009-09-18", "authors_parsed": [["Bouchez", "Florent", "", "LIP"], ["Darte", "Alain", "", "LIP"], ["Rastello", "Fabrice", "", "LIP"]]}, {"id": "0710.3824", "submitter": "Sebastien Tixeuil", "authors": "Sylvie Dela\\\"et (LRI), Partha Sarathi Mandal (INRIA Futurs), Mariusz\n  Rokicki (LRI), S\\'ebastien Tixeuil (INRIA Futurs, LIP6)", "title": "Deterministic Secure Positioning in Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS cs.NI", "license": null, "abstract": "  Properly locating sensor nodes is an important building block for a large\nsubset of wireless sensor networks (WSN) applications. As a result, the\nperformance of the WSN degrades significantly when misbehaving nodes report\nfalse location and distance information in order to fake their actual location.\nIn this paper we propose a general distributed deterministic protocol for\naccurate identification of faking sensors in a WSN. Our scheme does \\emph{not}\nrely on a subset of \\emph{trusted} nodes that are not allowed to misbehave and\nare known to every node in the network. Thus, any subset of nodes is allowed to\ntry faking its position. As in previous approaches, our protocol is based on\ndistance evaluation techniques developed for WSN. On the positive side, we show\nthat when the received signal strength (RSS) technique is used, our protocol\nhandles at most $\\lfloor \\frac{n}{2} \\rfloor-2$ faking sensors. Also, when the\ntime of flight (ToF) technique is used, our protocol manages at most $\\lfloor\n\\frac{n}{2} \\rfloor - 3$ misbehaving sensors. On the negative side, we prove\nthat no deterministic protocol can identify faking sensors if their number is\n$\\lceil \\frac{n}{2}\\rceil -1$. Thus our scheme is almost optimal with respect\nto the number of faking sensors. We discuss application of our technique in the\ntrusted sensor model. More precisely our results can be used to minimize the\nnumber of trusted sensors that are needed to defeat faking ones.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2007 07:29:13 GMT"}], "update_date": "2007-10-23", "authors_parsed": [["Dela\u00ebt", "Sylvie", "", "LRI"], ["Mandal", "Partha Sarathi", "", "INRIA Futurs"], ["Rokicki", "Mariusz", "", "LRI"], ["Tixeuil", "S\u00e9bastien", "", "INRIA Futurs, LIP6"]]}, {"id": "0710.4410", "submitter": "Paul Zimmermann", "authors": "Richard Brent, Paul Zimmermann (INRIA Lorraine - LORIA)", "title": "A Multi-level Blocking Distinct Degree Factorization Algorithm", "comments": null, "journal-ref": "Contemporary Mathematics 461 (2008) 47-58", "doi": null, "report-no": "INRIA Tech. Report RR-6331, Oct. 2007", "categories": "cs.DS", "license": null, "abstract": "  We give a new algorithm for performing the distinct-degree factorization of a\npolynomial P(x) over GF(2), using a multi-level blocking strategy. The coarsest\nlevel of blocking replaces GCD computations by multiplications, as suggested by\nPollard (1975), von zur Gathen and Shoup (1992), and others. The novelty of our\napproach is that a finer level of blocking replaces multiplications by\nsquarings, which speeds up the computation in GF(2)[x]/P(x) of certain interval\npolynomials when P(x) is sparse. As an application we give a fast algorithm to\nsearch for all irreducible trinomials x^r + x^s + 1 of degree r over GF(2),\nwhile producing a certificate that can be checked in less time than the full\nsearch. Naive algorithms cost O(r^2) per trinomial, thus O(r^3) to search over\nall trinomials of given degree r. Under a plausible assumption about the\ndistribution of factors of trinomials, the new algorithm has complexity O(r^2\n(log r)^{3/2}(log log r)^{1/2}) for the search over all trinomials of degree r.\nOur implementation achieves a speedup of greater than a factor of 560 over the\nnaive algorithm in the case r = 24036583 (a Mersenne exponent). Using our\nprogram, we have found two new primitive trinomials of degree 24036583 over\nGF(2) (the previous record degree was 6972593).\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2007 09:18:33 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Brent", "Richard", "", "INRIA Lorraine - LORIA"], ["Zimmermann", "Paul", "", "INRIA Lorraine - LORIA"]]}, {"id": "0710.5547", "submitter": "Miguel Angel Miron C.E.", "authors": "M. Miron Bernal, H. Coyote Estrada, J. Figueroa Nazuno", "title": "Code Similarity on High Level Programs", "comments": "Proceedings of the 18th Autumn Meeting on Communications, Computers,\n  Electronics and Industrial Exposition. (IEEE - ROCC07). Acapulco, Guerrero,\n  Mexico. 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS", "license": null, "abstract": "  This paper presents a new approach for code similarity on High Level\nprograms. Our technique is based on Fast Dynamic Time Warping, that builds a\nwarp path or points relation with local restrictions. The source code is\nrepresented into Time Series using the operators inside programming languages\nthat makes possible the comparison. This makes possible subsequence detection\nthat represent similar code instructions. In contrast with other code\nsimilarity algorithms, we do not make features extraction. The experiments show\nthat two source codes are similar when their respective Time Series are\nsimilar.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2007 22:39:21 GMT"}], "update_date": "2007-10-31", "authors_parsed": [["Bernal", "M. Miron", ""], ["Estrada", "H. Coyote", ""], ["Nazuno", "J. Figueroa", ""]]}]