[{"id": "2008.00044", "submitter": "Aleksandar Nikolov", "authors": "Lily Li, Aleksandar Nikolov", "title": "On the Computational Complexity of Linear Discrepancy", "comments": "ESA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in computer science and applied mathematics require rounding a\nvector $\\mathbf{w}$ of fractional values lying in the interval $[0,1]$ to a\nbinary vector $\\mathbf{x}$ so that, for a given matrix $\\mathbf{A}$,\n$\\mathbf{A}\\mathbf{x}$ is as close to $\\mathbf{A}\\mathbf{w}$ as possible. For\nexample, this problem arises in LP rounding algorithms used to approximate\n$\\mathsf{NP}$-hard optimization problems and in the design of uniformly\ndistributed point sets for numerical integration. For a given matrix\n$\\mathbf{A}$, the worst-case error over all choices of $\\mathbf{w}$ incurred by\nthe best possible rounding is measured by the linear discrepancy of\n$\\mathbf{A}$, a quantity studied in discrepancy theory, and introduced by\nLovasz, Spencer, and Vesztergombi (EJC, 1986).\n  We initiate the study of the computational complexity of linear discrepancy.\nOur investigation proceeds in two directions: (1) proving hardness results and\n(2) finding both exact and approximate algorithms to evaluate the linear\ndiscrepancy of certain matrices. For (1), we show that linear discrepancy is\n$\\mathsf{NP}$-hard. Thus we do not expect to find an efficient exact algorithm\nfor the general case. Restricting our attention to matrices with a constant\nnumber of rows, we present a poly-time exact algorithm for matrices consisting\nof a single row and matrices with a constant number of rows and entries of\nbounded magnitude. We also present an exponential-time approximation algorithm\nfor general matrices, and an algorithm that approximates linear discrepancy to\nwithin an exponential factor.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:16:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Li", "Lily", ""], ["Nikolov", "Aleksandar", ""]]}, {"id": "2008.00270", "submitter": "Kamil Khadiev", "authors": "Ruslan Kapralov, Kamil Khadiev, Joshua Mokut, Yixin Shen, and Maxim\n  Yagafarov", "title": "Fast Classical and Quantum Algorithms for Online $k$-server Problem on\n  Trees", "comments": "ICTCS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online algorithms for the $k$-server problem on trees. Chrobak\nand Larmore proposed a $k$-competitive algorithm for this problem that has the\noptimal competitive ratio. However, a naive implementation of their algorithm\nhas $O(n)$ time complexity for processing each query, where $n$ is the number\nof nodes in the tree. We propose a new time-efficient implementation of this\nalgorithm that has $O(n\\log n)$ time complexity for preprocessing and\n$O\\left(k^2 + k\\cdot \\log n\\right)$ time for processing a query. We also\npropose a quantum algorithm for the case where the nodes of the tree are\npresented using string paths. In this case, no preprocessing is needed, and the\ntime complexity for each query is $O(k^2\\sqrt{n}\\log n)$. When the number of\nqueries is $o\\left(\\frac{\\sqrt{n}}{k^2\\log n}\\right)$, we obtain a quantum\nspeed-up on the total runtime compared to our classical algorithm.\n  We also give a simple quantum algorithm to find the first marked element in a\ncollection of $m$ objects, that works even in the presence of two-sided bounded\nerrors on the input oracle. It has worst-case complexity $O(\\sqrt{m})$. In the\nparticular case of one-sided errors on the input, it has expected time\ncomplexity $O(\\sqrt{x})$ where $x$ is the position of the first marked element.\nCompare with previous work, our algorithm can handle errors in the input\noracle.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 14:21:45 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 20:36:10 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 07:28:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kapralov", "Ruslan", ""], ["Khadiev", "Kamil", ""], ["Mokut", "Joshua", ""], ["Shen", "Yixin", ""], ["Yagafarov", "Maxim", ""]]}, {"id": "2008.00297", "submitter": "Evgenios Kornaropoulos", "authors": "Evgenios M. Kornaropoulos, Silei Ren, Roberto Tamassia", "title": "The Price of Tailoring the Index to Your Data: Poisoning Attacks on\n  Learned Index Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of learned index structures relies on the idea that the\ninput-output functionality of a database index can be viewed as a prediction\ntask and, thus, be implemented using a machine learning model instead of\ntraditional algorithmic techniques. This novel angle for a decades-old problem\nhas inspired numerous exciting results in the intersection of machine learning\nand data structures. However, the main advantage of learned index structures,\ni.e., the ability to adjust to the data at hand via the underlying ML-model,\ncan become a disadvantage from a security perspective as it could be exploited.\n  In this work, we present the first study of poisoning attacks on learned\nindex structures. The required poisoning approach is different from all\nprevious works since the model under attack is trained on a cumulative\ndistribution function (CDF) and, thus, every injection on the training set has\na cascading impact on multiple data values. We formulate the first poisoning\nattacks on linear regression models trained on the CDF, which is a basic\nbuilding block of the proposed learned index structures. We generalize our\npoisoning techniques to attack a more advanced two-stage design of learned\nindex structures called recursive model index (RMI), which has been shown to\noutperform traditional B-Trees. We evaluate our attacks on real-world and\nsynthetic datasets under a wide variety of parameterizations of the model and\nshow that the error of the RMI increases up to $300\\times$ and the error of its\nsecond-stage models increases up to $3000\\times$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:12:04 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kornaropoulos", "Evgenios M.", ""], ["Ren", "Silei", ""], ["Tamassia", "Roberto", ""]]}, {"id": "2008.00325", "submitter": "Corey Nolet", "authors": "Corey J. Nolet, Victor Lafargue, Edward Raff, Thejaswi Nanditale, Tim\n  Oates, John Zedlewski, Joshua Patterson", "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Uniform Manifold Approximation and Projection (UMAP) algorithm has become\nwidely popular for its ease of use, quality of results, and support for\nexploratory, unsupervised, supervised, and semi-supervised learning. While many\nalgorithms can be ported to a GPU in a simple and direct fashion, such efforts\nhave resulted in inefficient and inaccurate versions of UMAP. We show a number\nof techniques that can be used to make a faster and more faithful GPU version\nof UMAP, and obtain speedups of up to 100x in practice. Many of these design\nchoices/lessons are general purpose and may inform the conversion of other\ngraph and manifold learning algorithms to use GPUs. Our implementation has been\nmade publicly available as part of the open source RAPIDS cuML library\n(https://github.com/rapidsai/cuml).\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:35:56 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:27:07 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 09:15:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Nolet", "Corey J.", ""], ["Lafargue", "Victor", ""], ["Raff", "Edward", ""], ["Nanditale", "Thejaswi", ""], ["Oates", "Tim", ""], ["Zedlewski", "John", ""], ["Patterson", "Joshua", ""]]}, {"id": "2008.00332", "submitter": "Elaine Shi", "authors": "Vijaya Ramachandran and Elaine Shi", "title": "Data Oblivious Algorithms for Multicores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As secure processors such as Intel SGX (with hyperthreading) become widely\nadopted, there is a growing appetite for private analytics on big data. Most\nprior works on data-oblivious algorithms adopt the classical PRAM model to\ncapture parallelism. However, it is widely understood that PRAM does not best\ncapture realistic multicore processors, nor does it reflect parallel\nprogramming models adopted in practice.\n  In this paper, we initiate the study of parallel data oblivious algorithms on\nrealistic multicores, best captured by the binary fork-join model of\ncomputation. We first show that data-oblivious sorting can be accomplished by a\nbinary fork-join algorithm with optimal total work and optimal\n(cache-oblivious) cache complexity, and in O(log n log log n) span (i.e.,\nparallel time) that matches the best-known insecure algorithm. Using our\nsorting algorithm as a core primitive, we show how to data-obliviously simulate\ngeneral PRAM algorithms in the binary fork-join model with non-trivial\nefficiency. We also present results for several applications including list\nranking, Euler tour, tree contraction, connected components, and minimum\nspanning forest. For a subset of these applications, our data-oblivious\nalgorithms asymptotically outperform the best known insecure algorithms. For\nother applications, we show data oblivious algorithms whose performance bounds\nmatch the best known insecure algorithms.\n  Complementing these asymptotically efficient results, we present a practical\nvariant of our sorting algorithm that is self-contained and potentially\nimplementable. It has optimal caching cost, and it is only a log log n factor\noff from optimal work and about a log n factor off in terms of span; moreover,\nit achieves small constant factors in its bounds.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:14:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 23:25:52 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ramachandran", "Vijaya", ""], ["Shi", "Elaine", ""]]}, {"id": "2008.00358", "submitter": "Yuyan Wang", "authors": "Benjamin Moseley, Kirk Pruhs, Alireza Samadian, Yuyan Wang", "title": "Relational Algorithms for k-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a k-means approximation algorithm that is efficient in the\nrelational algorithms model. This is an algorithm that operates directly on a\nrelational database without performing a join to convert it to a matrix whose\nrows represent the data points. The running time is potentially exponentially\nsmaller than $N$, the number of data points to be clustered that the relational\ndatabase represents.\n  Few relational algorithms are known and this paper offers techniques for\ndesigning relational algorithms as well as characterizing their limitations. We\nshow that given two data points as cluster centers, if we cluster points\naccording to their closest centers, it is NP-Hard to approximate the number of\npoints in the clusters on a general relational input. This is trivial for\nconventional data inputs and this result exemplifies that standard algorithmic\ntechniques may not be directly applied when designing an efficient relational\nalgorithm. This paper then introduces a new method that leverages rejection\nsampling and the $k$-means++ algorithm to construct an O(1)-approximate k-means\nsolution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:21:40 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 22:18:08 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Moseley", "Benjamin", ""], ["Pruhs", "Kirk", ""], ["Samadian", "Alireza", ""], ["Wang", "Yuyan", ""]]}, {"id": "2008.00425", "submitter": "Yican Sun", "authors": "Jinyi Wang, Yican Sun, Hongfei Fu, Mingzhang Huang, Amir Kafshdar\n  Goharshady, Krishnendu Chatterjee", "title": "Concentration-Bound Analysis for Probabilistic Programs and\n  Probabilistic Recurrence Relations", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing probabilistic programs and randomized algorithms are classical\nproblems in computer science. The first basic problem in the analysis of\nstochastic processes is to consider the expectation or mean, and another basic\nproblem is to consider concentration bounds, i.e. showing that large deviations\nfrom the mean have small probability. Similarly, in the context of\nprobabilistic programs and randomized algorithms, the analysis of expected\ntermination time/running time and their concentration bounds are fundamental\nproblems.In this work, we focus on concentration bounds for probabilistic\nprograms and probabilistic recurrences of randomized algorithms. For\nprobabilistic programs, the basic technique to achieve concentration bounds is\nto consider martingales and apply the classical Azuma's inequality. For\nprobabilistic recurrences of randomized algorithms, Karp's classical \"cookbook\"\nmethod, which is similar to the master theorem for recurrences, is the standard\napproach to obtain concentration bounds. In this work, we propose a novel\napproach for deriving concentration bounds for probabilistic programs and\nprobabilistic recurrence relations through the synthesis of exponential\nsupermartingales. For probabilistic programs, we present algorithms for\nsynthesis of such supermartingales in several cases. We also show that our\napproach can derive better concentration bounds than simply applying the\nclassical Azuma's inequality over various probabilistic programs considered in\nthe literature. For probabilistic recurrences, our approach can derive tighter\nbounds than the Karp's well-established methods on classical algorithms.\nMoreover, we show that our approach could derive bounds comparable to the\noptimal bound for quicksort, proposed by McDiarmid and Hayward. We also present\na prototype implementation that can automatically infer these bounds\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 07:31:02 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 09:46:19 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 02:01:02 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wang", "Jinyi", ""], ["Sun", "Yican", ""], ["Fu", "Hongfei", ""], ["Huang", "Mingzhang", ""], ["Goharshady", "Amir Kafshdar", ""], ["Chatterjee", "Krishnendu", ""]]}, {"id": "2008.00496", "submitter": "R Jaberi", "authors": "Raed Jaberi", "title": "Minimum $2$-vertex strongly biconnected spanning directed subgraph\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A directed graph $G=(V,E)$ is strongly biconnected if $G$ is strongly\nconnected and its underlying graph is biconnected. A strongly biconnected\ndirected graph $G=(V,E)$ is called $2$-vertex-strongly biconnected if $|V|\\geq\n3$ and the induced subgraph on $V\\setminus\\left\\lbrace w\\right\\rbrace $ is\nstrongly biconnected for every vertex $w\\in V$. In this paper we study the\nfollowing problem.\n  Given a $2$-vertex-strongly biconnected directed graph $G=(V,E)$, compute an\nedge subset $E^{2sb} \\subseteq E$ of minimum size such that the subgraph\n$(V,E^{2sb})$ is $2$-vertex-strongly biconnected.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 14:50:17 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Jaberi", "Raed", ""]]}, {"id": "2008.00779", "submitter": "Bartosz Walczak", "authors": "Carla Groenland, Gwena\\\"el Joret, Wojciech Nadara, Bartosz Walczak", "title": "Approximating pathwidth for graphs of small treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a polynomial-time algorithm which, given a graph $G$ with\ntreewidth $t$, approximates the pathwidth of $G$ to within a ratio of\n$O(t\\sqrt{\\log t})$. This is the first algorithm to achieve an\n$f(t)$-approximation for some function $f$.\n  Our approach builds on the following key insight: every graph with large\npathwidth has large treewidth or contains a subdivision of a large complete\nbinary tree. Specifically, we show that every graph with pathwidth at least\n$th+2$ has treewidth at least $t$ or contains a subdivision of a complete\nbinary tree of height $h+1$. The bound $th+2$ is best possible up to a\nmultiplicative constant. This result was motivated by, and implies (with\n$c=2$), the following conjecture of Kawarabayashi and Rossman (SODA'18): there\nexists a universal constant $c$ such that every graph with pathwidth\n$\\Omega(k^c)$ has treewidth at least $k$ or contains a subdivision of a\ncomplete binary tree of height $k$.\n  Our main technical algorithm takes a graph $G$ and some (not necessarily\noptimal) tree decomposition of $G$ of width $t'$ in the input, and it computes\nin polynomial time an integer $h$, a certificate that $G$ has pathwidth at\nleast $h$, and a path decomposition of $G$ of width at most $(t'+1)h+1$. The\ncertificate is closely related to (and implies) the existence of a subdivision\nof a complete binary tree of height $h$. The approximation algorithm for\npathwidth is then obtained by combining this algorithm with the approximation\nalgorithm of Feige, Hajiaghayi, and Lee (STOC'05) for treewidth.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 11:09:54 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 10:12:46 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Groenland", "Carla", ""], ["Joret", "Gwena\u00ebl", ""], ["Nadara", "Wojciech", ""], ["Walczak", "Bartosz", ""]]}, {"id": "2008.00811", "submitter": "Leah Epstein", "authors": "Janos Balogh and Leah Epstein and Asaf Levin", "title": "Truly asymptotic lower bounds for online vector bin packing", "comments": "Submitted to SODA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider online vector bin packing. It is known that no\nalgorithm can have a competitive ratio of $o(d/\\log^2 d)$ in the absolute\nsense, though upper bounds for this problem were always shown in the asymptotic\nsense. Since variants of bin packing are traditionally studied with respect to\nthe asymptotic measure and since the two measures are different, we focus on\nthe asymptotic measure and prove new lower bounds on the asymptotic competitive\nratio. The existing lower bounds prior to this work were much smaller than $3$\neven for very large dimensions.\n  We significantly improve the best known lower bounds on the asymptotic\ncompetitive ratio (and as a byproduct, on the absolute competitive ratio) for\nonline vector packing of vectors with $d \\geq 3$ dimensions, for every such\ndimension $d$. To obtain these results, we use several different constructions,\none of which is an adaptive construction showing a lower bound of\n$\\Omega(\\sqrt{d})$. Our main result is that the lower bound of $\\Omega(d/\\log^2\nd)$ on the competitive ratio holds also in the asymptotic sense. The last\nresult requires a careful adaptation of constructions for online coloring\nrather than simple black-box reductions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:08:43 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Balogh", "Janos", ""], ["Epstein", "Leah", ""], ["Levin", "Asaf", ""]]}, {"id": "2008.01009", "submitter": "Vitaly Aksenov", "authors": "Vitaly Aksenov, Dan Alistarh, Alexandra Drozdova, Amirkeivan\n  Mohtashami", "title": "The Splay-List: A Distribution-Adaptive Concurrent Skip-List", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and implementation of efficient concurrent data structures have\nseen significant attention. However, most of this work has focused on\nconcurrent data structures providing good \\emph{worst-case} guarantees. In real\nworkloads, objects are often accessed at different rates, since access\ndistributions may be non-uniform. Efficient distribution-adaptive data\nstructures are known in the sequential case, e.g. the splay-trees; however,\nthey often are hard to translate efficiently in the concurrent case.\n  In this paper, we investigate distribution-adaptive concurrent data\nstructures and propose a new design called the splay-list. At a high level, the\nsplay-list is similar to a standard skip-list, with the key distinction that\nthe height of each element adapts dynamically to its access rate: popular\nelements ``move up,'' whereas rarely-accessed elements decrease in height. We\nshow that the splay-list provides order-optimal amortized complexity bounds for\na subset of operations while being amenable to efficient concurrent\nimplementation. Experimental results show that the splay-list can leverage\ndistribution-adaptivity to improve on the performance of classic concurrent\ndesigns, and can outperform the only previously-known distribution-adaptive\ndesign in certain settings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:45:49 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Alistarh", "Dan", ""], ["Drozdova", "Alexandra", ""], ["Mohtashami", "Amirkeivan", ""]]}, {"id": "2008.01252", "submitter": "Johannes Zink", "authors": "Ulrik Brandes, Julian Walter, Johannes Zink", "title": "Erratum: Fast and Simple Horizontal Coordinate Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out two flaws in the algorithm of Brandes and K\\\"opf (Proc. GD\n2001), which is often used for the horizontal coordinate assignment in\nSugiyama's framework for layered layouts. One of them has been noted and fixed\nmultiple times, the other has not been documented before and requires a\nnon-trivial adaptation. On the bright side, neither running time nor extensions\nof the algorithm are affected adversely.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 00:14:09 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Brandes", "Ulrik", ""], ["Walter", "Julian", ""], ["Zink", "Johannes", ""]]}, {"id": "2008.01297", "submitter": "Abhinava Sikdar", "authors": "Abhinava Sikdar, Niladri Chatterjee", "title": "An improved Bayesian TRIE based model for SMS text normalization", "comments": "7 pages, 8 figures, under review at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization of SMS text, commonly known as texting language, is being\npursued for more than a decade. A probabilistic approach based on the Trie data\nstructure was proposed in literature which was found to be better performing\nthan HMM based approaches proposed earlier in predicting the correct\nalternative for an out-of-lexicon word. However, success of the Trie based\napproach depends largely on how correctly the underlying probabilities of word\noccurrences are estimated. In this work we propose a structural modification to\nthe existing Trie-based model along with a novel training algorithm and\nprobability generation scheme. We prove two theorems on statistical properties\nof the proposed Trie and use them to claim that is an unbiased and consistent\nestimator of the occurrence probabilities of the words. We further fuse our\nmodel into the paradigm of noisy channel based error correction and provide a\nheuristic to go beyond a Damerau Levenshtein distance of one. We also run\nsimulations to support our claims and show superiority of the proposed scheme\nover previous works.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:01:23 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 17:19:31 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sikdar", "Abhinava", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2008.01573", "submitter": "Mohammad Mehdi Hosseinzadeh", "authors": "Riccardo Dondi, Pietro Hiram Guzzi, and Mohammad Mehdi Hosseinzadeh", "title": "Top-k Connected Overlapping Densest Subgraphs in Dual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are largely used for modelling and analysing data and relations\namong them. Recently, it has been shown that the use of a single network may\nnot be the optimal choice, since a single network may misses some aspects.\nConsequently, it has been proposed to use a pair of networks to better model\nall the aspects, and the main approach is referred to as dual networks (DNs).\nDNs are two related graphs (one weighted, the other unweighted) that share the\nsame set of vertices and two different edge sets. In DNs is often interesting\nto extract common subgraphs among the two networks that are maximally dense in\nthe conceptual network and connected in the physical one. The simplest instance\nof this problem is finding a common densest connected subgraph (DCS), while we\nhere focus on the detection of the Top-k Densest Connected subgraphs, i.e. a\nset k subgraphs having the largest density in the conceptual network which are\nalso connected in the physical network. We formalise the problem and then we\npropose a heuristic to find a solution, since the problem is computationally\nhard. A set of experiments on synthetic and real networks is also presented to\nsupport our approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:08:55 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dondi", "Riccardo", ""], ["Guzzi", "Pietro Hiram", ""], ["Hosseinzadeh", "Mohammad Mehdi", ""]]}, {"id": "2008.01590", "submitter": "Daniel Paulusma", "authors": "Nick Brettell, Jake Horsfield, Andrea Munaro, Daniel Paulusma", "title": "List $k$-Colouring $P_t$-Free Graphs: a Mim-width Perspective", "comments": "arXiv admin note: text overlap with arXiv:2004.05022 merge of\n  arXiv:2004.05022 and previous version of arxiv:2008.01590", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A colouring of a graph $G=(V,E)$ is a mapping $c\\colon V\\to \\{1,2,\\ldots\\}$\nsuch that $c(u)\\neq c(v)$ for every two adjacent vertices $u$ and $v$ of $G$.\nThe {\\sc List $k$-Colouring} problem is to decide whether a graph $G=(V,E)$\nwith a list $L(u)\\subseteq \\{1,\\ldots,k\\}$ for each $u\\in V$ has a colouring\n$c$ such that $c(u)\\in L(u)$ for every $u\\in V$. Let $P_t$ be the path on $t$\nvertices and let $K_{1,s}^1$ be the graph obtained from the $(s+1)$-vertex star\n$K_{1,s}$ by subdividing each of its edges exactly once.Recently, Chudnovsky,\nSpirkl and Zhong (DM 2020) proved that List $3$-Colouring is polynomial-time\nsolvable for $(K_{1,s}^1,P_t)$-free graphs for every $t\\geq 1$ and $s\\geq 1$.\nWe generalize their result to List $k$-Colouring for every $k\\geq 1$. Our\nresult also generalizes the known result that for every $k\\geq 1$ and $s\\geq\n0$, List $k$-Colouring is polynomial-time solvable for $(sP_1+P_5)$-free\ngraphs, which was proven for $s=0$ by Ho\\`ang, Kami\\'nski, Lozin, Sawada, and\nShu (Algorithmica 2010) and for every $s\\geq 1$ by Couturier, Golovach, Kratsch\nand Paulusma (Algorithmica 2015). We show our result by proving boundedness of\nan underlying width parameter. Namely, we show that for every $k\\geq 1$, $s\\geq\n1$, $t\\geq 1$, the class of $(K_k,K_{1,s}^1,P_t)$-free graphs has bounded\nmim-width and that a corresponding branch decomposition is \"quickly computable\"\nfor these graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:58:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 21:02:56 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Brettell", "Nick", ""], ["Horsfield", "Jake", ""], ["Munaro", "Andrea", ""], ["Paulusma", "Daniel", ""]]}, {"id": "2008.01616", "submitter": "Peter Zeman", "authors": "Ken-ichi Kawarabayashi and Bojan Mohar and Roman Nedela and Peter\n  Zeman", "title": "Automorphism groups of maps in linear time", "comments": "Added funding information", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By a map we mean a $2$-cell decomposition of a closed compact surface, i.e.,\nan embedding of a graph such that every face is homeomorphic to an open disc.\nAutomorphism of a map can be thought of as a permutation of the vertices which\npreserves the vertex-edge-face incidences in the embedding. When the underlying\nsurface is orientable, every automorphism of a map determines an\nangle-preserving homeomorphism of the surface. While it is conjectured that\nthere is no \"truly subquadratic\" algorithm for testing map isomorphism for\nunconstrained genus, we present a linear-time algorithm for computing the\ngenerators of the automorphism group of a map, parametrized by the genus of the\nunderlying surface. The algorithm applies a sequence of local reductions and\nproduces a uniform map, while preserving the automorphism group. The\nautomorphism group of the original map can be reconstructed from the\nautomorphism group of the uniform map in linear time. We also extend the\nalgorithm to non-orientable surfaces by making use of the antipodal\ndouble-cover.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:57:06 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 17:29:05 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Kawarabayashi", "Ken-ichi", ""], ["Mohar", "Bojan", ""], ["Nedela", "Roman", ""], ["Zeman", "Peter", ""]]}, {"id": "2008.01722", "submitter": "Kevin Tian", "authors": "Jerry Li, Aaron Sidford, Kevin Tian, Huishuai Zhang", "title": "Well-Conditioned Methods for Ill-Conditioned Systems: Linear Regression\n  with Semi-Random Noise", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical iterative algorithms for linear system solving and regression are\nbrittle to the condition number of the data matrix. Even a semi-random\nadversary, constrained to only give additional consistent information, can\narbitrarily hinder the resulting computational guarantees of existing solvers.\nWe show how to overcome this barrier by developing a framework which takes\nstate-of-the-art solvers and \"robustifies\" them to achieve comparable\nguarantees against a semi-random adversary. Given a matrix which contains an\n(unknown) well-conditioned submatrix, our methods obtain computational and\nstatistical guarantees as if the entire matrix was well-conditioned. We\ncomplement our theoretical results with preliminary experimental evidence,\nshowing that our methods are effective in practice.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:53:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Li", "Jerry", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""], ["Zhang", "Huishuai", ""]]}, {"id": "2008.01765", "submitter": "Gilad Asharov", "authors": "Gilad Asharov, T-H. Hubert Chan, Kartik Nayak, Rafael Pass, Ling Ren,\n  Elaine Shi", "title": "Bucket Oblivious Sort: An Extremely Simple Oblivious Sort", "comments": "Appears in SOSA@SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a conceptually simple oblivious sort and oblivious random\npermutation algorithms called bucket oblivious sort and bucket oblivious random\npermutation. Bucket oblivious sort uses $6n\\log n$ time (measured by the number\nof memory accesses) and $2Z$ client storage with an error probability\nexponentially small in $Z$. The above runtime is only $3\\times$ slower than a\nnon-oblivious merge sort baseline; for $2^{30}$ elements, it is $5\\times$\nfaster than bitonic sort, the de facto oblivious sorting algorithm in practical\nimplementations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:45:40 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 06:39:52 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 09:06:48 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Asharov", "Gilad", ""], ["Chan", "T-H. Hubert", ""], ["Nayak", "Kartik", ""], ["Pass", "Rafael", ""], ["Ren", "Ling", ""], ["Shi", "Elaine", ""]]}, {"id": "2008.01768", "submitter": "Sepideh Aghamolaei", "authors": "Sepideh Aghamolaei", "title": "A Data-Structure for Approximate Longest Common Subsequence of A Set of\n  Strings", "comments": "An optimal exact sketch for the LCS of two strings was already known:\n  arXiv:1810.01238 as well as an approximation algorithm with weights:\n  https://doi.org/10.1016/j.ic.2010.12.006 The edit distance of regular\n  languages was also known: https://doi.org/10.3390/a11110165 Using these\n  subroutines in any algorithm for the LCS of k strings gives a better result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $k$ strings $I$, their longest common subsequence (LCS) is the\nstring with the maximum length that is a subset of all the strings in $I$. A\ndata-structure for this problem preprocesses $I$ into a data-structure such\nthat the LCS of a set of query strings $Q$ with the strings of $I$ can be\ncomputed faster. Since the problem is NP-hard for arbitrary $k$, we allow an\nerror that allows some characters to be replaced by other characters. We define\nthe approximation version of the problem with an extra input $m$, which is the\nlength of the regular expression (regex) that describes the input, and the\napproximation factor is the logarithm of the number of possibilities in the\nregex returned by the algorithm, divided by the logarithm regex with the\nminimum number of possibilities. Then, we use a tree data-structure to achieve\nsublinear-time LCS queries. We also explain how the idea can be extended to the\nlongest increasing subsequence (LIS) problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:03:40 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:46:25 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 07:02:34 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Aghamolaei", "Sepideh", ""]]}, {"id": "2008.01961", "submitter": "Kai Sun", "authors": "Kai Sun", "title": "An Algorithm Framework for the Exact Solution and Improved Approximation\n  of the Maximum Weighted Independent Set Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum Weighted Independent Set (MWIS) problem, which considers a graph\nwith weights assigned to nodes and seeks to discover the \"heaviest\" independent\nset, that is, a set of nodes with maximum total weight so that no two nodes in\nthe set are connected by an edge. The MWIS problem arises in many application\ndomains, including the resource-constrained scheduling, error-correcting\ncoding, complex system analysis and optimization, and communication networks.\nSince solving the MWIS problem is the core function for finding the optimum\nsolution of our novel graph-based formulation of the resource-constrained\nProcess Planning and Scheduling (PPS) problem, it is essential to have\n\"good-performance\" algorithms to solve the MWIS problem. In this paper, we\npropose a Novel Hybrid Heuristic Algorithm (NHHA) framework in a\ndivide-and-conquer structure that yields optimum feasible solutions to the MWIS\nproblem. The NHHA framework is optimized to minimize the recurrence. Using the\nNHHA framework, we also solve the All Maximal Independent Sets Listing (AMISL)\nproblem, which can be seen as the subproblem of the MWIS problem. Moreover,\nbuilding composed MWIS algorithms that utilizing fast approximation algorithms\nwith the NHHA framework is an effective way to improve the accuracy of\napproximation MWIS algorithms (e.g., GWMIN and GWMIN2 (Sakai et al., 2003)).\nEight algorithms for the MWIS problem, the exact MWIS algorithm, the AMISL\nalgorithm, two approximation algorithms from the literature, and four composed\nalgorithms, are applied and tested for solving the graph-based formulation of\nthe resource-constrained PPS problem to evaluate the scalability, accuracy, and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:03:03 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 03:06:00 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 06:35:51 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sun", "Kai", ""]]}, {"id": "2008.02035", "submitter": "Sabrina Schmitz", "authors": "Christina B\\\"using and Arie M.C.A. Koster and Sabrina Schmitz", "title": "Robust Minimum Cost Flow Problem Under Consistent Flow Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust minimum cost flow problem under consistent flow constraints\n(RobMCF$\\equiv$) is a new extension of the minimum cost flow (MCF) problem. In\nthe RobMCF$\\equiv$ problem, we consider demand and supply that are subject to\nuncertainty. For all demand realizations, however, we require that the flow\nvalue on an arc needs to be equal if it is included in the predetermined arc\nset given. The objective is to find feasible flows that satisfy the equal flow\nrequirements while minimizing the maximum occurring cost among all demand\nrealizations.\n  In the case of a discrete set of scenarios, we derive structural results\nwhich point out the differences with the polynomial time solvable MCF problem\non networks with integral capacities. In particular, the Integral Flow Theorem\nof Dantzig and Fulkerson does not hold. For this reason, we require integral\nflows in the entire paper. We show that the RobMCF$\\equiv$ problem is strongly\n$\\mathcal{NP}$-hard on acyclic digraphs by a reduction from the $(3,B2)$-Sat\nproblem. Further, we demonstrate that the RobMCF$\\equiv$ problem is weakly\n$\\mathcal{NP}$-hard on series-parallel digraphs by providing a reduction from\nPartition and a pseudo-polynomial algorithm based on dynamic programming.\nFinally, we propose a special case on series-parallel digraphs for which we can\nsolve the RobMCF$\\equiv$ problem in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:22:32 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["B\u00fcsing", "Christina", ""], ["Koster", "Arie M. C. A.", ""], ["Schmitz", "Sabrina", ""]]}, {"id": "2008.02060", "submitter": "Oren Weimann", "authors": "Pawe{\\l} Gawrychowski, Shay Mozes, Oren Weimann", "title": "A Note on a Recent Algorithm for Minimum Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected edge-weighted graph $G=(V,E)$ with $m$ edges and $n$\nvertices, the minimum cut problem asks to find a subset of vertices $S$ such\nthat the total weight of all edges between $S$ and $V \\setminus S$ is\nminimized. Karger's longstanding $O(m \\log^3 n)$ time randomized algorithm for\nthis problem was very recently improved in two independent works to $O(m \\log^2\nn)$ [ICALP'20] and to $O(m \\log^2 n + n\\log^5 n)$ [STOC'20]. These two\nalgorithms use different approaches and techniques. In particular, while the\nformer is faster, the latter has the advantage that it can be used to obtain\nefficient algorithms in the cut-query and in the streaming models of\ncomputation. In this paper, we show how to simplify and improve the algorithm\nof [STOC'20] to $O(m \\log^2 n + n\\log^3 n)$. We obtain this by replacing a\nrandomized algorithm that, given a spanning tree $T$ of $G$, finds in $O(m \\log\nn+n\\log^4 n)$ time a minimum cut of $G$ that 2-respects (cuts two edges of) $T$\nwith a simple $O(m \\log n+n\\log^2 n)$ time deterministic algorithm for the same\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 11:58:20 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 07:14:08 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Mozes", "Shay", ""], ["Weimann", "Oren", ""]]}, {"id": "2008.02108", "submitter": "Simona Rombo", "authors": "Mariella Bonomo and Armando La Placa and Simona E. Rombo", "title": "Identifying the $k$ Best Targets for an Advertisement Campaign via\n  Online Social Networks", "comments": "Accepted for publication in Proceedings of the 12th International\n  Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge\n  Management (KDIR2020). arXiv admin note: text overlap with arXiv:1907.01326", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for the recommendation of possible customers\n(users) to advertisers (e.g., brands) based on two main aspects: (i) the\ncomparison between On-line Social Network profiles, and (ii) neighborhood\nanalysis on the On-line Social Network. Profile matching between users and\nbrands is considered based on bag-of-words representation of textual contents\ncoming from the social media, and measures such as the Term Frequency-Inverse\nDocument Frequency are used in order to characterize the importance of words in\nthe comparison. The approach has been implemented relying on Big Data\nTechnologies, allowing this way the efficient analysis of very large Online\nSocial Networks. Results on real datasets show that the combination of profile\nmatching and neighborhood analysis is successful in identifying the most\nsuitable set of users to be used as target for a given advertisement campaign.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:52:26 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Bonomo", "Mariella", ""], ["La Placa", "Armando", ""], ["Rombo", "Simona E.", ""]]}, {"id": "2008.02146", "submitter": "Santosh Vempala", "authors": "He Jia, Aditi Laddha, Yin Tat Lee, Santosh S. Vempala", "title": "Reducing Isotropy and Volume to KLS: An $O(n^3\\psi^2)$ Volume Algorithm", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the the volume of a convex body in ${\\mathbb R}^{n}$ in the\ngeneral membership oracle model can be computed with\n$\\widetilde{O}(n^{3}\\psi^{2}/\\varepsilon^{2})$ oracle queries, where $\\psi$ is\nthe KLS constant ($\\widetilde{O}$ suppresses polylogarithmic terms.\n$O^{*}$suppresses dependence on error parameters as well as polylogarithmic\nterms.). With the current bound of $\\psi\\lesssim n^{\\frac{1}{4}}$, this gives\nan $\\widetilde{O}(n^{3.5}/\\varepsilon^{2})$ algorithm, the first general\nimprovement on the Lov\\'{a}sz-Vempala $\\widetilde{O}(n^{4}/\\varepsilon^{2})$\nalgorithm from 2003. The main new ingredient is\\emph{ }an\n$\\widetilde{O}(n^{3}\\psi^{2})$ algorithm for isotropic transformation,\nfollowing which we can apply the $\\widetilde{O}(n^{3}/\\varepsilon^{2})$ volume\nalgorithm of Cousins and Vempala for well-rounded convex bodies. A positive\nresolution of the KLS conjecture would imply an\n$\\widetilde{O}(n^{3}/\\epsilon^{2})$ volume algorithm. We also give an efficient\nimplementation of the new algorithm for convex polytopes defined by $m$\ninequalities in ${\\mathbb R}^{n}$: polytope volume can be estimated in time\n$\\widetilde{O}(mn^{c}/\\varepsilon^{2})$ where $c<3.7$ depends on the current\nmatrix multiplication exponent and improves on the the previous best bound.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:08:16 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Jia", "He", ""], ["Laddha", "Aditi", ""], ["Lee", "Yin Tat", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "2008.02167", "submitter": "Robert Miller", "authors": "Robert Miller, Phil Maguire", "title": "GeoTree: a data structure for constant time geospatial search enabling a\n  real-time mix-adjusted median property price index", "comments": "7 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem appearing across the field of data science is $k$-NN\n($k$-nearest neighbours), particularly within the context of Geographic\nInformation Systems. In this article, we present a novel data structure, the\nGeoTree, which holds a collection of geohashes (string encodings of GPS\nco-ordinates). This enables a constant $O\\left(1\\right)$ time search algorithm\nthat returns a set of geohashes surrounding a given geohash in the GeoTree,\nrepresenting the approximate $k$-nearest neighbours of that geohash.\nFurthermore, the GeoTree data structure retains $O\\left(n\\right)$ memory\nrequirement. We apply the data structure to a property price index algorithm\nfocused on price comparison with historical neighbouring sales, demonstrating\nan enhanced performance. The results show that this data structure allows for\nthe development of a real-time property price index, and can be scaled to\nlarger datasets with ease.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:37:37 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Miller", "Robert", ""], ["Maguire", "Phil", ""]]}, {"id": "2008.02215", "submitter": "Stefan Szeider", "authors": "Johannes K. Fichte, Markus Hecher, Stefan Szeider", "title": "A Time Leap Challenge for SAT Solving", "comments": "Authors' version of a paper which is to appear in the proceedings of\n  CP'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.AR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the impact of hardware advancement and algorithm advancement for\nSAT solving over the last two decades. In particular, we compare 20-year-old\nSAT-solvers on new computer hardware with modern SAT-solvers on 20-year-old\nhardware. Our findings show that the progress on the algorithmic side has at\nleast as much impact as the progress on the hardware side.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:33:41 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Szeider", "Stefan", ""]]}, {"id": "2008.02269", "submitter": "Alexander Wein", "authors": "Tselil Schramm and Alexander S. Wein", "title": "Computational Barriers to Estimation from Low-Degree Polynomials", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental goal of high-dimensional statistics is to detect or recover\nstructure from noisy data. In many cases, the data can be faithfully modeled by\na planted structure (such as a low-rank matrix) perturbed by random noise. But\neven for these simple models, the computational complexity of estimation is\nsometimes poorly understood. A growing body of work studies low-degree\npolynomials as a proxy for computational complexity: it has been demonstrated\nin various settings that low-degree polynomials of the data can match the\nstatistical performance of the best known polynomial-time algorithms for\ndetection. While prior work has studied the power of low-degree polynomials for\nthe task of detecting the presence of hidden structures, it has failed to\naddress the estimation problem in settings where detection is qualitatively\neasier than estimation.\n  In this work, we extend the method of low-degree polynomials to address\nproblems of estimation and recovery. For a large class of \"signal plus noise\"\nproblems, we give a user-friendly lower bound for the best possible mean\nsquared error achievable by any degree-D polynomial. To our knowledge, this is\nthe first instance in which the low-degree polynomial method can establish\nlow-degree hardness of recovery problems where the associated detection problem\nis easy. As applications, we give a tight characterization of the low-degree\nminimum mean squared error for the planted submatrix and planted dense subgraph\nproblems, resolving (in the low-degree framework) open problems about the\ncomputational complexity of recovery in both cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:52:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Schramm", "Tselil", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2008.02753", "submitter": "Jugal Garg", "authors": "Bhaskar Ray Chaudhury and Jugal Garg and Peter McGlaughlin and Ruta\n  Mehta", "title": "Competitive Allocation of a Mixed Manna", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DM cs.DS cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fair division problem of allocating a mixed manna under\nadditively separable piecewise linear concave (SPLC) utilities. A mixed manna\ncontains goods that everyone likes and bads that everyone dislikes, as well as\nitems that some like and others dislike. The seminal work of Bogomolnaia et al.\n[Econometrica'17] argue why allocating a mixed manna is genuinely more\ncomplicated than a good or a bad manna, and why competitive equilibrium is the\nbest mechanism. They also provide the existence of equilibrium and establish\nits peculiar properties (e.g., non-convex and disconnected set of equilibria\neven under linear utilities), but leave the problem of computing an equilibrium\nopen. This problem remained unresolved even for only bad manna under linear\nutilities.\n  Our main result is a simplex-like algorithm based on Lemke's scheme for\ncomputing a competitive allocation of a mixed manna under SPLC utilities, a\nstrict generalization of linear. Experimental results on randomly generated\ninstances suggest that our algorithm will be fast in practice. The problem is\nknown to be PPAD-hard for the case of good manna, and we also show a similar\nresult for the case of bad manna. Given these PPAD-hardness results, designing\nsuch an algorithm is the only non-brute-force (non-enumerative) option known,\ne.g., the classic Lemke-Howson algorithm (1964) for computing a Nash\nequilibrium in a 2-player game is still one of the most widely used algorithms\nin practice.\n  Our algorithm also yields several new structural properties as simple\ncorollaries. We obtain a (constructive) proof of existence for a far more\ngeneral setting, membership of the problem in PPAD, rational-valued solution,\nand odd number of solutions property. The last property also settles the\nconjecture of Bogomolnaia et al. in the affirmative.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:38:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chaudhury", "Bhaskar Ray", ""], ["Garg", "Jugal", ""], ["McGlaughlin", "Peter", ""], ["Mehta", "Ruta", ""]]}, {"id": "2008.02769", "submitter": "Philipp Schepper", "authors": "Philipp Schepper", "title": "Fine-Grained Complexity of Regular Expression Pattern Matching and\n  Membership", "comments": "Full version of the paper accepted at ESA 2020; v2: typos and\n  reference to conference version corrected", "journal-ref": null, "doi": "10.4230/LIPIcs.ESA.2020.80", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The currently fastest algorithm for regular expression pattern matching and\nmembership improves the classical O(nm) time algorithm by a factor of about\nlog^{3/2}n. Instead of focussing on general patterns we analyse homogeneous\npatterns of bounded depth in this work. For them a classification splitting the\ntypes in easy (strongly sub-quadratic) and hard (essentially quadratic time\nunder SETH) is known. We take a very fine-grained look at the hard pattern\ntypes from this classification and show a dichotomy: few types allow\nsuper-poly-logarithmic improvements while the algorithms for the other pattern\ntypes can only be improved by a constant number of log-factors, assuming the\nFormula-SAT Hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:13:58 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 15:02:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schepper", "Philipp", ""]]}, {"id": "2008.02782", "submitter": "William Moses Jr.", "authors": "Shay Kutten, William K. Moses Jr., Gopal Pandurangan, David Peleg", "title": "Singularly Optimal Randomized Leader Election", "comments": "24 pages. Full version of paper accepted at DISC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns designing distributed algorithms that are singularly\noptimal, i.e., algorithms that are simultaneously time and message optimal, for\nthe fundamental leader election problem in networks. Our main result is a\nrandomized distributed leader election algorithm for asynchronous complete\nnetworks that is essentially (up to a polylogarithmic factor) singularly\noptimal. Our algorithm uses $O(n)$ messages with high probability and runs in\n$O(\\log^2 n)$ time (with high probability) to elect a unique leader. The $O(n)$\nmessage complexity should be contrasted with the $\\Omega(n \\log n)$ lower\nbounds for the deterministic message complexity of leader election algorithms\n(regardless of time), proven by Korach, Moran, and Zaks (TCS, 1989) for\nasynchronous algorithms and by Afek and Gafni (SIAM J. Comput., 1991) for\nsynchronous networks. Hence, our result also separates the message complexities\nof randomized and deterministic leader election. More importantly, our\n(randomized) time complexity of $O(\\log^2 n)$ for obtaining the optimal $O(n)$\nmessage complexity is significantly smaller than the long-standing\n$\\tilde{\\Theta}(n)$ time complexity obtained by Afek and Gafni and by Singh\n(SIAM J. Comput., 1997) for message optimal (deterministic) election in\nasynchronous networks.\n  In synchronous complete networks, Afek and Gafni showed an essentially\nsingularly optimal deterministic algorithm with $O(\\log n)$ time and $O(n \\log\nn)$ messages. Ramanathan et al. (Distrib. Comput. 2007) used randomization to\nimprove the message complexity, and showed a randomized algorithm with $O(n)$\nmessages and $O(\\log n)$ time (with failure probability $O(1 /\n\\log^{\\Omega(1)}n)$). Our second result is a tightly singularly optimal\nrandomized algorithm, with $O(1)$ time and $O(n)$ messages, for this setting,\nwhose time bound holds with certainty and message bound holds with high\nprobability.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:35:38 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 13:17:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kutten", "Shay", ""], ["Moses", "William K.", "Jr."], ["Pandurangan", "Gopal", ""], ["Peleg", "David", ""]]}, {"id": "2008.03006", "submitter": "Jason Altschuler", "authors": "Jason M. Altschuler and Enric Boix-Adsera", "title": "Polynomial-time algorithms for Multimarginal Optimal Transport problems\n  with decomposable structure", "comments": "38 pages, 8 figures. Improved exposition. For clarity, the hardness\n  results in Section 6 of v1 have been moved to the separate paper \"Hardness\n  Results for Multimarginal Optimal Transport problems\"; the current drafts of\n  these papers have no overlapping results. Title updated for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimarginal Optimal Transport (MOT) has recently attracted significant\ninterest due to applications in machine learning, statistics, and the sciences.\nHowever, in most applications, the success of MOT is severely limited by a lack\nof efficient algorithms. Indeed, in general, MOT requires exponential time in\nthe number of marginals k and their support sizes n.\n  This paper develops a general theory about \"structural properties\" that make\nMOT solvable in poly(n,k) time. We identify two such properties:\ndecomposability of the cost into either (i) local and simple global\ninteractions; or (ii) low-rank and sparse components. These two structures\nencompass many--if not most--current applications of MOT.\n  In addition to providing the first poly(n,k)-time algorithms for a wide range\nof MOT problems, our results also provide better algorithms for MOT problems\nthat are already known to be tractable: Our algorithms compute solutions which\nare exact and sparse. (Previous algorithms can do neither.) We demonstrate our\nresults theoretically and numerically on popular applications in machine\nlearning, statistics, and fluid dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 06:24:22 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 01:38:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Altschuler", "Jason M.", ""], ["Boix-Adsera", "Enric", ""]]}, {"id": "2008.03061", "submitter": "Svein H{\\o}gemo", "authors": "Svein H{\\o}gemo, Christophe Paul and Jan Arne Telle", "title": "Hierarchical Clusterings of Unweighted Graphs", "comments": "19 pages, 7 figures. Extended version of conference paper, to appear\n  in proceedings from MFCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of finding an optimal hierarchical clustering of an\nunweighted similarity graph under the recently introduced Dasgupta objective\nfunction. We introduce a proof technique, called the normalization procedure,\nthat takes any such clustering of a graph $G$ and iteratively improves it until\na desired target clustering of G is reached. We use this technique to show both\na negative and a positive complexity result. Firstly, we show that in general\nthe problem is NP-complete. Secondly, we consider min-well-behaved graphs,\nwhich are graphs $H$ having the property that for any $k$ the graph $H(k)$\nbeing the join of $k$ copies of $H$ has an optimal hierarchical clustering that\nsplits each copy of $H$ in the same optimal way. To optimally cluster such a\ngraph $H(k)$ we thus only need to optimally cluster the smaller graph $H$.\nCo-bipartite graphs are min-well-behaved, but otherwise they seem to be scarce.\nWe use the normalization procedure to show that also the cycle on 6 vertices is\nmin-well-behaved.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:45:46 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["H\u00f8gemo", "Svein", ""], ["Paul", "Christophe", ""], ["Telle", "Jan Arne", ""]]}, {"id": "2008.03091", "submitter": "Bernhard Haeupler", "authors": "Mohsen Ghaffari and Bernhard Haeupler", "title": "Low-Congestion Shortcuts for Graphs Excluding Dense Minors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any $n$-node graph $G$ with diameter $D$ admits shortcuts with\ncongestion $O(\\delta D \\log n)$ and dilation $O(\\delta D)$, where $\\delta$ is\nthe maximum edge-density of any minor of $G$. Our proof is simple, elementary,\nand constructive - featuring a $\\tilde{\\Theta}(\\delta D)$-round distributed\nconstruction algorithm. Our results are tight up to $\\tilde{O}(1)$ factors and\ngeneralize, simplify, unify, and strengthen several prior results. For example,\nfor graphs excluding a fixed minor, i.e., graphs with constant $\\delta$, only a\n$\\tilde{O}(D^2)$ bound was known based on a very technical proof that relies on\nthe Robertson-Seymour Graph Structure Theorem.\n  A direct consequence of our result is that many graph families, including any\nminor-excluded ones, have near-optimal $\\tilde{\\Theta}(D)$-round distributed\nalgorithms for many fundamental communication primitives and optimization\nproblems including minimum spanning tree, minimum cut, and shortest-path\napproximations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 11:23:49 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""]]}, {"id": "2008.03131", "submitter": "Raphael Yuster", "authors": "Raphael Yuster", "title": "A $2^{O(k)}n$ algorithm for $k$-cycle in minor-closed graph families", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.07.034", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\mathcal C}$ be a proper minor-closed family of graphs. We present a\nrandomized algorithm that given a graph $G \\in {\\mathcal C}$ with $n$ vertices,\nfinds a simple cycle of size $k$ in $G$ (if exists) in $2^{O(k)}n$ time. The\nalgorithm applies to both directed and undirected graphs. In previous linear\ntime algorithms for this problem, the runtime dependence on $k$ is\nsuper-exponential. The algorithm can be derandomized yielding a $2^{O(k)}n\\log\nn$ time algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:51:14 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Yuster", "Raphael", ""]]}, {"id": "2008.03325", "submitter": "Leonidas Tsepenekas", "authors": "Brian Brubach, Nathaniel Grammel, David G. Harris, Aravind Srinivasan,\n  Leonidas Tsepenekas, Anil Vullikanti", "title": "Approximating Two-Stage Stochastic Supplier Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of this paper is radius-based (supplier) clustering in the\ntwo-stage stochastic setting with recourse, where the inherent stochasticity of\nthe model comes in the form of a budget constraint. We also explore a number of\nvariants where additional constraints are imposed on the first-stage decisions,\nspecifically matroid and multi-knapsack constraints.\n  Our eventual goal is to provide results for supplier problems in the most\ngeneral distributional setting, where there is only black-box access to the\nunderlying distribution. To that end, we follow a two-step approach. First, we\ndevelop algorithms for a restricted version of each problem, in which all\npossible scenarios are explicitly provided; second, we employ a novel\n\\emph{scenario-discarding} variant of the standard \\emph{Sample Average\nApproximation (SAA)} method, in which we crucially exploit properties of the\nrestricted-case algorithms. We finally note that the scenario-discarding\nmodification to the SAA method is necessary in order to optimize over the\nradius.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:18:29 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 16:50:30 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 15:10:17 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Brubach", "Brian", ""], ["Grammel", "Nathaniel", ""], ["Harris", "David G.", ""], ["Srinivasan", "Aravind", ""], ["Tsepenekas", "Leonidas", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2008.03327", "submitter": "Joseph Cheriyan", "authors": "S.Boyd, J.Cheriyan, R.Cummings, L.Grout, S.Ibrahimpur, Z.Szigeti,\n  L.Wang", "title": "A $4/3$-Approximation Algorithm for the Minimum $2$-Edge Connected\n  Multisubgraph Problem in the Half-Integral Case", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.APPROX/RANDOM.2020.61", "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a connected undirected graph $\\bar{G}$ on $n$ vertices, and\nnon-negative edge costs $c$, the 2ECM problem is that of finding a\n$2$-edge~connected spanning multisubgraph of $\\bar{G}$ of minimum cost. The\nnatural linear program (LP) for 2ECM, which coincides with the subtour LP for\nthe Traveling Salesman Problem on the metric closure of $\\bar{G}$, gives a\nlower bound on the optimal cost. For instances where this LP is optimized by a\nhalf-integral solution $x$, Carr and Ravi (1998) showed that the integrality\ngap is at most $\\frac43$: they show that the vector $\\frac43 x$ dominates a\nconvex combination of incidence vectors of $2$-edge connected spanning\nmultisubgraphs of $\\bar{G}$.\n  We present a simpler proof of the result due to Carr and Ravi by applying an\nextension of Lov\\'{a}sz's splitting-off theorem. Our proof naturally leads to a\n$\\frac43$-approximation algorithm for half-integral instances. Given a\nhalf-integral solution $x$ to the LP for 2ECM, we give an $O(n^2)$-time\nalgorithm to obtain a $2$-edge connected spanning multisubgraph of $\\bar{G}$\nwhose cost is at most $\\frac43 c^T x$.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:20:39 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Boyd", "S.", ""], ["Cheriyan", "J.", ""], ["Cummings", "R.", ""], ["Grout", "L.", ""], ["Ibrahimpur", "S.", ""], ["Szigeti", "Z.", ""], ["Wang", "L.", ""]]}, {"id": "2008.03448", "submitter": "Yota Otachi", "authors": "R\\'emy Belmonte, Tesshu Hanaka, Masaaki Kanzaki, Masashi Kiyomi,\n  Yasuaki Kobayashi, Yusuke Kobayashi, Michael Lampis, Hirotaka Ono, Yota\n  Otachi", "title": "Parameterized Complexity of $(A,\\ell)$-Path Packing", "comments": "22pages, IWOCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G = (V,E)$, $A \\subseteq V$, and integers $k$ and $\\ell$, the\n\\textsc{$(A,\\ell)$-Path Packing} problem asks to find $k$ vertex-disjoint paths\nof length $\\ell$ that have endpoints in $A$ and internal points in $V \\setminus\nA$. We study the parameterized complexity of this problem with parameters\n$|A|$, $\\ell$, $k$, treewidth, pathwidth, and their combinations. We present\nsharp complexity contrasts with respect to these parameters. Among other\nresults, we show that the problem is polynomial-time solvable when $\\ell \\le\n3$, while it is NP-complete for constant $\\ell \\ge 4$. We also show that the\nproblem is W[1]-hard parameterized by pathwidth${}+|A|$, while it is\nfixed-parameter tractable parameterized by treewidth${}+\\ell$.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 05:39:58 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Belmonte", "R\u00e9my", ""], ["Hanaka", "Tesshu", ""], ["Kanzaki", "Masaaki", ""], ["Kiyomi", "Masashi", ""], ["Kobayashi", "Yasuaki", ""], ["Kobayashi", "Yusuke", ""], ["Lampis", "Michael", ""], ["Ono", "Hirotaka", ""], ["Otachi", "Yota", ""]]}, {"id": "2008.03556", "submitter": "Kwangjun Ahn", "authors": "Kwangjun Ahn", "title": "A simpler strong refutation of random $k$-XOR", "comments": "16 pages; presented at International Conference on Randomization and\n  Computation (RANDOM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong refutation of random CSPs is a fundamental question in theoretical\ncomputer science that has received particular attention due to the\nlong-standing gap between the information-theoretic limit and the computational\nlimit. This gap is recently bridged by Raghavendra, Rao and Schramm where they\nstudy sub-exponential algorithms for the regime between the two limits. In this\nwork, we take a simpler approach to their algorithm and analysis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 16:41:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ahn", "Kwangjun", ""]]}, {"id": "2008.03564", "submitter": "Billy Jin", "authors": "Siddhartha Banerjee, Vasilis Gkatzelis, Artur Gorokh, Billy Jin", "title": "Online Nash Social Welfare Maximization with Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of allocating a set of divisible goods to $N$ agents\nin an online manner, aiming to maximize the Nash social welfare, a widely\nstudied objective which provides a balance between fairness and efficiency. The\ngoods arrive in a sequence of $T$ periods and the value of each agent for a\ngood is adversarially chosen when the good arrives. We first observe that no\nonline algorithm can achieve a competitive ratio better than the trivial\n$O(N)$, unless it is given additional information about the agents' values.\n  Then, in line with the emerging area of \"algorithms with predictions\", we\nconsider a setting where for each agent, the online algorithm is only given a\nprediction of her monopolist utility, i.e., her utility if all goods were given\nto her alone (corresponding to the sum of her values over the $T$ periods). Our\nmain result is an online algorithm whose competitive ratio is parameterized by\nthe multiplicative errors in these predictions. The algorithm achieves a\ncompetitive ratio of $O(\\log N)$ and $O(\\log T)$ if the predictions are\nperfectly accurate. Moreover, the competitive ratio degrades smoothly with the\nerrors in the predictions, and is surprisingly robust: the logarithmic\ncompetitive ratio holds even if the predictions are very inaccurate. We\ncomplement this positive result by showing that our bounds are essentially\ntight: no online algorithm, even if provided with perfectly accurate\npredictions, can achieve a competitive ratio of $O(\\log^{1-\\epsilon} N)$ or\n$O(\\log^{1-\\epsilon} T)$ for any constant $\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 17:44:05 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 03:25:38 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Banerjee", "Siddhartha", ""], ["Gkatzelis", "Vasilis", ""], ["Gorokh", "Artur", ""], ["Jin", "Billy", ""]]}, {"id": "2008.03676", "submitter": "Shlomo Moran", "authors": "Shlomo Moran and Irad Yavneh", "title": "Adjustable Coins", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a scenario where there are several algorithms for\nsolving a given problem. Each algorithm is associated with a probability of\nsuccess and a cost, and there is also a penalty for failing to solve the\nproblem. The user may run one algorithm at a time for the specified cost, or\ngive up and pay the penalty. The probability of success may be implied by\nrandomization in the algorithm, or by assuming a probability distribution on\nthe input space, which lead to different variants of the problem. The goal is\nto minimize the expected cost of the process under the assumption that the\nalgorithms are independent. We study several variants of this problem, and\npresent possible solution strategies and a hardness result.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 06:57:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Moran", "Shlomo", ""], ["Yavneh", "Irad", ""]]}, {"id": "2008.03759", "submitter": "Elaye Karstadt", "authors": "Gal Beniamini, Nathan Cheng, Olga Holtz, Elaye Karstadt, Oded Schwartz", "title": "Sparsifying the Operators of Fast Matrix Multiplication Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast matrix multiplication algorithms may be useful, provided that their\nrunning time is good in practice. Particularly, the leading coefficient of\ntheir arithmetic complexity needs to be small. Many sub-cubic algorithms have\nlarge leading coefficients, rendering them impractical. Karstadt and Schwartz\n(SPAA'17, JACM'20) demonstrated how to reduce these coefficients by sparsifying\nan algorithm's bilinear operator. Unfortunately, the problem of finding optimal\nsparsifications is NP-Hard.\n  We obtain three new methods to this end, and apply them to existing fast\nmatrix multiplication algorithms, thus improving their leading coefficients.\nThese methods have an exponential worst case running time, but run fast in\npractice and improve the performance of many fast matrix multiplication\nalgorithms. Two of the methods are guaranteed to produce leading coefficients\nthat, under some assumptions, are optimal.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 16:45:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Beniamini", "Gal", ""], ["Cheng", "Nathan", ""], ["Holtz", "Olga", ""], ["Karstadt", "Elaye", ""], ["Schwartz", "Oded", ""]]}, {"id": "2008.03784", "submitter": "Giacomo Ortali", "authors": "Walter Didimo, Michael Kaufmann, Giuseppe Liotta, Giacomo Ortali", "title": "Rectilinear Planarity Testing of Plane Series-Parallel Graphs in Linear\n  Time", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plane graph is rectilinear planar if it admits an embedding-preserving\nstraight-line drawing where each edge is either horizontal or vertical. We\nprove that rectilinear planarity testing can be solved in optimal $O(n)$ time\nfor any plane series-parallel graph $G$ with $n$ vertices. If $G$ is\nrectilinear planar, an embedding-preserving rectilinear planar drawing of $G$\ncan be constructed in $O(n)$ time. Our result is based on a characterization of\nrectilinear planar series-parallel graphs in terms of intervals of orthogonal\nspirality that their components can have, and it leads to an algorithm that can\nbe easily implemented.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 18:44:16 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 08:05:08 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 09:25:06 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 14:15:08 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Didimo", "Walter", ""], ["Kaufmann", "Michael", ""], ["Liotta", "Giuseppe", ""], ["Ortali", "Giacomo", ""]]}, {"id": "2008.03855", "submitter": "Yusong Du", "authors": "Yusong Du, Baoying Fan, and Baodian Wei", "title": "An Improved Exact Sampling Algorithm for the Standard Normal\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2016, Karney proposed an exact sampling algorithm for the standard normal\ndistribution. In this paper, we study the computational complexity of this\nalgorithm under the random deviate model. Specifically, Karney's algorithm\nrequires the access to an infinite sequence of independently and uniformly\nrandom deviates over the range (0,1). We give an estimate of the expected\nnumber of uniform deviates used by this algorithm until outputting a sample\nvalue, and present an improved algorithm with lower uniform deviate\nconsumption. The experimental results also shows that our improved algorithm\nhas better performance than Karney's algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 01:50:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Du", "Yusong", ""], ["Fan", "Baoying", ""], ["Wei", "Baodian", ""]]}, {"id": "2008.03909", "submitter": "Laxman Dhulipala", "authors": "Laxman Dhulipala, Changwan Hong, Julian Shun", "title": "ConnectIt: A Framework for Static and Incremental Parallel Graph\n  Connectivity Algorithms", "comments": "This is an extended version of a paper in PVLDB (to be presented at\n  VLDB'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected components is a fundamental kernel in graph applications. The\nfastest existing parallel multicore algorithms for connectivity are based on\nsome form of edge sampling and/or linking and compressing trees. However, many\ncombinations of these design choices have been left unexplored. In this paper,\nwe design the ConnectIt framework, which provides different sampling strategies\nas well as various tree linking and compression schemes. ConnectIt enables us\nto obtain several hundred new variants of connectivity algorithms, most of\nwhich extend to computing spanning forest. In addition to static graphs, we\nalso extend ConnectIt to support mixes of insertions and connectivity queries\nin the concurrent setting.\n  We present an experimental evaluation of ConnectIt on a 72-core machine,\nwhich we believe is the most comprehensive evaluation of parallel connectivity\nalgorithms to date. Compared to a collection of state-of-the-art static\nmulticore algorithms, we obtain an average speedup of 12.4x (2.36x average\nspeedup over the fastest existing implementation for each graph). Using\nConnectIt, we are able to compute connectivity on the largest\npublicly-available graph (with over 3.5 billion vertices and 128 billion edges)\nin under 10 seconds using a 72-core machine, providing a 3.1x speedup over the\nfastest existing connectivity result for this graph, in any computational\nsetting. For our incremental algorithms, we show that our algorithms can ingest\ngraph updates at up to several billion edges per second. To guide the user in\nselecting the best variants in ConnectIt for different situations, we provide a\ndetailed analysis of the different strategies. Finally, we show how the\ntechniques in ConnectIt can be used to speed up two important graph\napplications: approximate minimum spanning forest and SCAN clustering.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 05:49:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 09:26:09 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 07:18:18 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Dhulipala", "Laxman", ""], ["Hong", "Changwan", ""], ["Shun", "Julian", ""]]}, {"id": "2008.04124", "submitter": "Fernando Morales", "authors": "Fernando A Morales and Jairo A Mart\\'inez", "title": "Expected Performance and Worst Case Scenario Analysis of the\n  Divide-and-Conquer Method for the 0-1 Knapsack Problem", "comments": "42 pages, 12 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we furnish quality certificates for the Divide-and-Conquer\nmethod solving the 0-1 Knapsack Problem: the worst case scenario and estimates\nfor the expected performance. The probabilistic setting is given and the main\nrandom variables are defined for the analysis of the expected performance. The\nefficiency is rigorously approximated for one iteration of the method then,\nthese values are used to derive analytic estimates for the performance of a\ngeneral Divide-and-Conquer tree. All the theoretical results are verified with\nstatistically suited numerical experiments for a wider illustration of the\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:34:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Morales", "Fernando A", ""], ["Mart\u00ednez", "Jairo A", ""]]}, {"id": "2008.04125", "submitter": "Alessandra Tappini", "authors": "Emilio Di Giacomo, Walter Didimo, Giuseppe Liotta, Fabrizio\n  Montecchiani, Alessandra Tappini", "title": "Storyline Visualizations with Ubiquitous Actors", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storyline visualizations depict the temporal dynamics of social interactions,\nas they describe how groups of actors (individuals or organizations) change\nover time. A common constraint in storyline visualizations is that an actor\ncannot belong to two different groups at the same time instant. However, this\nconstraint may be too severe in some application scenarios, thus we generalize\nthe model by allowing an actor to simultaneously belong to distinct groups at\nany point in time. We call this model Storyline with Ubiquitous Actors (SUA).\nEssential to our model is that an actor is represented as a tree rather than a\nsingle line. We describe an algorithmic pipeline to compute storyline\nvisualizations in the SUA model and discuss case studies on publication data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:35:40 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 09:57:24 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Di Giacomo", "Emilio", ""], ["Didimo", "Walter", ""], ["Liotta", "Giuseppe", ""], ["Montecchiani", "Fabrizio", ""], ["Tappini", "Alessandra", ""]]}, {"id": "2008.04148", "submitter": "Zachary Langley", "authors": "Sepehr Assadi, Aaron Bernstein, Zachary Langley", "title": "Improved Bounds for Distributed Load Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the load balancing problem, the input is an $n$-vertex bipartite graph $G\n= (C \\cup S, E)$ and a positive weight for each client $c \\in C$. The algorithm\nmust assign each client $c \\in C$ to an adjacent server $s \\in S$. The load of\na server is then the weighted sum of all the clients assigned to it, and the\ngoal is to compute an assignment that minimizes some function of the server\nloads, typically either the maximum server load (i.e., the\n$\\ell_{\\infty}$-norm) or the $\\ell_p$-norm of the server loads.\n  We study load balancing in the distributed setting. There are two existing\nresults in the CONGEST model. Czygrinow et al. [DISC 2012] showed a\n2-approximation for unweighted clients with round-complexity $O(\\Delta^5)$,\nwhere $\\Delta$ is the maximum degree of the input graph. Halld\\'orsson et al.\n[SPAA 2015] showed an $O(\\log{n}/\\log\\log{n})$-approximation for unweighted\nclients and $O(\\log^2\\!{n}/\\log\\log{n})$-approximation for weighted clients\nwith round-complexity polylog$(n)$.\n  In this paper, we show the first distributed algorithms to compute an\n$O(1)$-approximation to the load balancing problem in polylog$(n)$ rounds. In\nthe CONGEST model, we give an $O(1)$-approximation algorithm in polylog$(n)$\nrounds for unweighted clients. For weighted clients, the approximation ratio is\n$O(\\log{n})$. In the less constrained LOCAL model, we give an\n$O(1)$-approximation algorithm for weighted clients in polylog$(n)$ rounds.\n  Our approach also has implications for the standard sequential setting in\nwhich we obtain the first $O(1)$-approximation for this problem that runs in\nnear-linear time. A 2-approximation is already known, but it requires solving a\nlinear program and is hence much slower. Finally, we note that all of our\nresults simultaneously approximate all $\\ell_p$-norms, including the\n$\\ell_{\\infty}$-norm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:21:25 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 02:47:43 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Assadi", "Sepehr", ""], ["Bernstein", "Aaron", ""], ["Langley", "Zachary", ""]]}, {"id": "2008.04183", "submitter": "Ernesto Kofman", "authors": "Ernesto Kofman, Denise Marzorati and Joaqu\\'in Fern\\'andez", "title": "Connected Components in Undirected Set--Based Graphs. Applications in\n  Object--Oriented Model Manipulation", "comments": "19 pages, Manuscript submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel algorithm for finding the connected components\nof a graph where the vertices and edges are grouped into sets defining a\nSet--Based Graph. The algorithm, under certain restrictions on those sets, has\nthe remarkable property of achieving constant computational costs with the\nnumber of vertices and edges. The mentioned restrictions are related to the\npossibility of representing the sets of vertices by intension and the sets of\nedges using some particular type of maps. While these restrictions can result\nstrong in a general context, they are usually satisfied in the problem of\ntransforming connections into equations in object oriented models, which is the\nmain application of the proposed algorithm.\n  Besides describing the new algorithm and studying its computational cost, the\nwork describes its prototype implementation and shows its application in\ndifferent examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:08:48 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 14:04:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kofman", "Ernesto", ""], ["Marzorati", "Denise", ""], ["Fern\u00e1ndez", "Joaqu\u00edn", ""]]}, {"id": "2008.04270", "submitter": "Dustin Mixon", "authors": "Dustin G. Mixon, Kaiying Xie", "title": "Sketching semidefinite programs for faster clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clustering problems enjoy solutions by semidefinite programming.\nTheoretical results in this vein frequently consider data with a planted\nclustering and a notion of signal strength such that the semidefinite program\nexactly recovers the planted clustering when the signal strength is\nsufficiently large. In practice, semidefinite programs are notoriously slow,\nand so speedups are welcome. In this paper, we show how to sketch a popular\nsemidefinite relaxation of a graph clustering problem known as minimum\nbisection, and our analysis supports a meta-claim that the clustering task is\nless computationally burdensome when there is more signal.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:10:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Xie", "Kaiying", ""]]}, {"id": "2008.04303", "submitter": "Yannic Maus", "authors": "Magnus M. Halldorsson, Fabian Kuhn, Yannic Maus, Alexandre Nolin", "title": "Coloring Fast Without Learning Your Neighbors' Colors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an improved randomized CONGEST algorithm for distance-$2$ coloring\nthat uses $\\Delta^2+1$ colors and runs in $O(\\log n)$ rounds, improving the\nrecent $O(\\log \\Delta \\cdot \\log n)$-round algorithm in [Halld\\'orsson, Kuhn,\nMaus; PODC '20]. We then improve the time complexity to $O(\\log \\Delta) +\n2^{O(\\sqrt{\\log\\log n})}$.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:55:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Kuhn", "Fabian", ""], ["Maus", "Yannic", ""], ["Nolin", "Alexandre", ""]]}, {"id": "2008.04416", "submitter": "Arindam Biswas", "authors": "Arindam Biswas and Venkatesh Raman and Saket Saurabh", "title": "Approximation in (Poly-) Logarithmic Space", "comments": "MFCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop new approximation algorithms for classical graph and set problems\nin the RAM model under space constraints. As one of our main results, we devise\nan algorithm for d-Hitting Set that runs in time n^{O(d^2 + d/\\epsilon})}, uses\nO((d^2 + d/\\epsilon) log n) bits of space, and achieves an approximation ratio\nof O((d/{\\epsilon}) n^{\\epsilon}) for any positive \\epsilon \\leq 1 and any\nnatural number d. In particular, this yields a factor-O(log n) approximation\nalgorithm which runs in time n^{O(log n)} and uses O(log^2 n) bits of space\n(for constant d). As a corollary, we obtain similar bounds for Vertex Cover and\nseveral graph deletion problems.\n  For bounded-multiplicity problem instances, one can do better. We devise a\nfactor-2 approximation algorithm for Vertex Cover on graphs with maximum degree\n\\Delta, and an algorithm for computing maximal independent sets which both run\nin time n^{O(\\Delta)} and use O(\\Delta log n) bits of space. For the more\ngeneral d-Hitting Set problem, we devise a factor-d approximation algorithm\nwhich runs in time n^{O(d {\\delta}^2)} and uses O(d {\\delta}^2 log n) bits of\nspace on set families where each element appears in at most \\delta sets.\n  For Independent Set restricted to graphs with average degree d, we give a\nfactor-(2d) approximation algorithm which runs in polynomial time and uses\nO(log n) bits of space. We also devise a factor-O(d^2) approximation algorithm\nfor Dominating Set on d-degenerate graphs which runs in time n^{O(log n)} and\nuses O(log^2 n) bits of space. For d-regular graphs, we show how a known\nrandomized factor-O(log d) approximation algorithm can be derandomized to run\nin time n^{O(1)} and use O(log n) bits of space.\n  Our results use a combination of ideas from the theory of kernelization,\ndistributed algorithms and randomized algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 21:08:17 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 07:21:31 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Biswas", "Arindam", ""], ["Raman", "Venkatesh", ""], ["Saurabh", "Saket", ""]]}, {"id": "2008.04949", "submitter": "Steffen Pottel", "authors": "Steffen Pottel and Asvin Goel", "title": "Scheduling activities with time-dependent durations and resource\n  consumptions", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study time-dependent scheduling problems where activities\nconsume a resource with limited availability. Activity durations as well as\nresource consumptions are assumed to be time-dependent and the resource can be\nreplenished between activities. Because of the interaction of time-dependent\nactivity durations and resource consumptions, scheduling policies based on\nstarting all activities as early as possible may fail due to unnecessarily high\nresource consumptions. We propose a dynamic discretization discovery algorithm\nthat generates a partially time-expanded network during the search. We propose\npreloading techniques allowing to significantly reduce the computational effort\nif the approach is embedded in an iterative solution procedure that frequently\nevaluates activity sequences that start with the same activities. We evaluate\nour approaches on a case of routing a fleet of electric vehicles in which\nvehicles can recharge batteries during the route.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:30:21 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Pottel", "Steffen", ""], ["Goel", "Asvin", ""]]}, {"id": "2008.04975", "submitter": "Ping Li", "authors": "Farzin Haddadpour, Belhal Karimi, Ping Li, Xiaoyun Li", "title": "FedSKETCH: Communication-Efficient and Private Federated Learning via\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication complexity and privacy are the two key challenges in Federated\nLearning where the goal is to perform a distributed learning through a large\nvolume of devices. In this work, we introduce FedSKETCH and FedSKETCHGATE\nalgorithms to address both challenges in Federated learning jointly, where\nthese algorithms are intended to be used for homogeneous and heterogeneous data\ndistribution settings respectively. The key idea is to compress the\naccumulation of local gradients using count sketch, therefore, the server does\nnot have access to the gradients themselves which provides privacy.\nFurthermore, due to the lower dimension of sketching used, our method exhibits\ncommunication-efficiency property as well. We provide, for the aforementioned\nschemes, sharp convergence guarantees.\n  Finally, we back up our theory with various set of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:22:48 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Karimi", "Belhal", ""], ["Li", "Ping", ""], ["Li", "Xiaoyun", ""]]}, {"id": "2008.05106", "submitter": "Ray Li", "authors": "Ray Li", "title": "Settling SETH vs. Approximate Sparse Directed Unweighted Diameter (up to\n  (NU)NSETH)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several tight results on the fine-grained complexity of\napproximating the diameter of a graph. First, we prove that, for any\n$\\varepsilon>0$, assuming the Strong Exponential Time Hypothesis (SETH), there\nare no near-linear time $2-\\varepsilon$-approximation algorithms for the\nDiameter of a sparse directed graph, even in unweighted graphs. This result\nshows that a simple near-linear time 2-approximation algorithm for Diameter is\noptimal under SETH, answering a question from a survey of Rubinstein and\nVassilevska-Williams (SIGACT '19) for the case of directed graphs.\n  In the same survey, Rubinstein and Vassilevska-Williams also asked if it is\npossible to show that there are no $2-\\varepsilon$ approximation algorithms for\nDiameter in a directed graph in $O(n^{1.499})$ time. We show that, assuming a\nhypothesis called NSETH, one cannot use a deterministic SETH-based reduction to\nrule out the existence of such algorithms.\n  Extending the techniques in these two results, we characterize whether a\n$2-\\varepsilon$ approximation algorithm running in time $O(n^{1+\\delta})$ for\nthe Diameter of a sparse directed unweighted graph can be ruled out by a\ndeterministic SETH-based reduction for every $\\delta\\in(0,1)$ and essentially\nevery $\\varepsilon\\in(0,1)$, assuming NSETH. This settles the SETH-hardness of\napproximating the diameter of sparse directed unweighted graphs for\ndeterministic reductions, up to NSETH. We make the same characterization for\nrandomized SETH-based reductions, assuming another hypothesis called NUNSETH.\n  We prove additional hardness and non-reducibility results for undirected\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:43:01 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:17:17 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 22:10:03 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Ray", ""]]}, {"id": "2008.05145", "submitter": "Kasper Green Larsen", "authors": "Kasper Green Larsen, Jonathan Lindegaard Starup, Jesper Steensgaard", "title": "Further Unifying the Landscape of Cell Probe Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a landmark paper, P\\v{a}tra\\c{s}cu demonstrated how a single lower bound\nfor the static data structure problem of reachability in the butterfly graph,\ncould be used to derive a wealth of new and previous lower bounds via\nreductions. These lower bounds are tight for numerous static data structure\nproblems. Moreover, he also showed that reachability in the butterfly graph\nreduces to dynamic marked ancestor, a classic problem used to prove lower\nbounds for dynamic data structures. Unfortunately, P\\v{a}tra\\c{s}cu's reduction\nto marked ancestor loses a $\\lg \\lg n$ factor and therefore falls short of\nfully recovering all the previous dynamic data structure lower bounds that\nfollow from marked ancestor. In this paper, we revisit P\\v{a}tra\\c{s}cu's work\nand give a new lossless reduction to dynamic marked ancestor, thereby\nestablishing reachability in the butterfly graph as a single seed problem from\nwhich a range of tight static and dynamic data structure lower bounds follow.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 07:32:00 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 09:25:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Starup", "Jonathan Lindegaard", ""], ["Steensgaard", "Jesper", ""]]}, {"id": "2008.05180", "submitter": "Christian Schulz", "authors": "Alexander Gellner, Sebastian Lamm, Christian Schulz, Darren Strash,\n  Bogd\\'an Zav\\'alnij", "title": "Boosting Data Reduction for the Maximum Weight Independent Set Problem\n  Using Increasing Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a vertex-weighted graph, the maximum weight independent set problem\nasks for a pair-wise non-adjacent set of vertices such that the sum of their\nweights is maximum. The branch-and-reduce paradigm is the de facto standard\napproach to solve the problem to optimality in practice. In this paradigm, data\nreduction rules are applied to decrease the problem size. These data reduction\nrules ensure that given an optimum solution on the new (smaller) input, one can\nquickly construct an optimum solution on the original input.\n  We introduce new generalized data reduction and transformation rules for the\nproblem. A key feature of our work is that some transformation rules can\nincrease the size of the input. Surprisingly, these so-called increasing\ntransformations can simplify the problem and also open up the reduction space\nto yield even smaller irreducible graphs later throughout the algorithm. In\nexperiments, our algorithm computes significantly smaller irreducible graphs on\nall except one instance, solves more instances to optimality than previously\npossible, is up to two orders of magnitude faster than the best\nstate-of-the-art solver, and finds higher-quality solutions than heuristic\nsolvers DynWVC and HILS on many instances. While the increasing transformations\nare only efficient enough for preprocessing at this time, we see this as a\ncritical initial step towards a new branch-and-transform paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:52:50 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 05:45:23 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gellner", "Alexander", ""], ["Lamm", "Sebastian", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""], ["Zav\u00e1lnij", "Bogd\u00e1n", ""]]}, {"id": "2008.05374", "submitter": "Magnus M. Halldorsson", "authors": "Marek Cygan, Magn\\'us M. Halld\\'orsson and Guy Kortsarz", "title": "Tight Bounds on Subexponential Time Approximation of Set Cover and\n  Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Set Cover on instances with $N$ elements cannot be approximated\nwithin $(1-\\gamma)\\ln N$-factor in time exp($N^{\\gamma-\\delta})$, for any $0 <\n\\gamma < 1$ and any $\\delta > 0$, assuming the Exponential Time Hypothesis.\nThis essentially matches the best upper bound known by Cygan et al.\\ (IPL,\n2009) of $(1-\\gamma)\\ln N$-factor in time $exp(O(N^\\gamma))$.\n  The lower bound is obtained by extracting a standalone reduction from Label\nCover to Set Cover from the work of Moshkovitz (Theory of Computing, 2015), and\napplying it to a different PCP theorem than done there. We also obtain a\ntighter lower bound when conditioning on the Projection Games Conjecture.\n  We also treat three problems (Directed Steiner Tree, Submodular Cover, and\nConnected Polymatroid) that strictly generalize Set Cover. We give a\n$(1-\\gamma)\\ln N$-approximation algorithm for these problems that runs in\n$exp(\\tilde{O}(N^\\gamma))$ time, for any $1/2 \\le \\gamma < 1$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:14:57 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Cygan", "Marek", ""], ["Halld\u00f3rsson", "Magn\u00fas M.", ""], ["Kortsarz", "Guy", ""]]}, {"id": "2008.05391", "submitter": "Jing Tang", "authors": "Jing Tang, Xueyan Tang, Andrew Lim, Kai Han, Chongshou Li, Junsong\n  Yuan", "title": "Revisiting Modified Greedy Algorithm for Monotone Submodular\n  Maximization with a Knapsack Constraint", "comments": "The paper will appear in 2021 ACM SIGMETRICS conference (SIGMETRICS\n  '21), June 14-18, 2021, Beijing, China", "journal-ref": null, "doi": "10.1145/3447386", "report-no": null, "categories": "cs.DS cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotone submodular maximization with a knapsack constraint is NP-hard.\nVarious approximation algorithms have been devised to address this optimization\nproblem. In this paper, we revisit the widely known modified greedy algorithm.\nFirst, we show that this algorithm can achieve an approximation factor of\n$0.405$, which significantly improves the known factors of $0.357$ given by\nWolsey and $(1-1/\\mathrm{e})/2\\approx 0.316$ given by Khuller et al. More\nimportantly, our analysis closes a gap in Khuller et al.'s proof for the\nextensively mentioned approximation factor of $(1-1/\\sqrt{\\mathrm{e}})\\approx\n0.393$ in the literature to clarify a long-standing misconception on this\nissue. Second, we enhance the modified greedy algorithm to derive a\ndata-dependent upper bound on the optimum. We empirically demonstrate the\ntightness of our upper bound with a real-world application. The bound enables\nus to obtain a data-dependent ratio typically much higher than $0.405$ between\nthe solution value of the modified greedy algorithm and the optimum. It can\nalso be used to significantly improve the efficiency of algorithms such as\nbranch and bound.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:40:21 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 15:53:47 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Tang", "Jing", ""], ["Tang", "Xueyan", ""], ["Lim", "Andrew", ""], ["Han", "Kai", ""], ["Li", "Chongshou", ""], ["Yuan", "Junsong", ""]]}, {"id": "2008.05398", "submitter": "Gerth St{\\o}lting Brodal", "authors": "Gerth St{\\o}lting Brodal", "title": "Soft Sequence Heaps", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chazelle [JACM00] introduced the soft heap as a building block for efficient\nminimum spanning tree algorithms, and recently Kaplan et al. [SOSA2019] showed\nhow soft heaps can be applied to achieve simpler algorithms for various\nselection problems. A soft heap trades-off accuracy for efficiency, by allowing\n$\\epsilon N$ of the items in a heap to be corrupted after a total of $N$\ninsertions, where a corrupted item is an item with artificially increased key\nand $0 < \\epsilon \\leq 1/2$ is a fixed error parameter. Chazelle's soft heaps\nare based on binomial trees and support insertions in amortized\n$O(\\lg(1/\\epsilon))$ time and extract-min operations in amortized $O(1)$ time.\n  In this paper we explore the design space of soft heaps. The main\ncontribution of this paper is an alternative soft heap implementation based on\nmerging sorted sequences, with time bounds matching those of Chazelle's soft\nheaps. We also discuss a variation of the soft heap by Kaplan et al.\n[SICOMP2013], where we avoid performing insertions lazily. It is based on\nternary trees instead of binary trees and matches the time bounds of Kaplan et\nal., i.e. amortized $O(1)$ insertions and amortized $O(\\lg(1/\\epsilon))$\nextract-min. Both our data structures only introduce corruptions after\nextract-min operations which return the set of items corrupted by the\noperation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:46:04 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Brodal", "Gerth St\u00f8lting", ""]]}, {"id": "2008.05421", "submitter": "Karthik C. S.", "authors": "Karthik C. S. and Merav Parter", "title": "Deterministic Replacement Path Covering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we provide a unified and simplified approach to derandomize\ncentral results in the area of fault-tolerant graph algorithms. Given a graph\n$G$, a vertex pair $(s,t) \\in V(G)\\times V(G)$, and a set of edge faults $F\n\\subseteq E(G)$, a replacement path $P(s,t,F)$ is an $s$-$t$ shortest path in\n$G \\setminus F$. For integer parameters $L,f$, a replacement path covering\n(RPC) is a collection of subgraphs of $G$, denoted by\n$\\mathcal{G}_{L,f}=\\{G_1,\\ldots, G_r \\}$, such that for every set $F$ of at\nmost $f$ faults (i.e., $|F|\\le f$) and every replacement path $P(s,t,F)$ of at\nmost $L$ edges, there exists a subgraph $G_i\\in \\mathcal{G}_{L,f}$ that\ncontains all the edges of $P$ and does not contain any of the edges of $F$. The\ncovering value of the RPC $\\mathcal{G}_{L,f}$ is then defined to be the number\nof subgraphs in $\\mathcal{G}_{L,f}$.\n  We present efficient deterministic constructions of $(L,f)$-RPCs whose\ncovering values almost match the randomized ones, for a wide range of\nparameters. Our time and value bounds improve considerably over the previous\nconstruction of Parter (DISC 2019). We also provide an almost matching lower\nbound for the value of these coverings. A key application of our above\ndeterministic constructions is the derandomization of the algebraic\nconstruction of the distance sensitivity oracle by Weimann and Yuster (FOCS\n2010). The preprocessing and query time of the our deterministic algorithm\nnearly match the randomized bounds. This resolves the open problem of Alon,\nChechik and Cohen (ICALP 2019).\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:24:27 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 13:45:59 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["S.", "Karthik C.", ""], ["Parter", "Merav", ""]]}, {"id": "2008.05504", "submitter": "Isolde Adler", "authors": "Pierre Aboulker, Isolde Adler, Eun Jung Kim, Ni Luh Dewi Sintiari,\n  Nicolas Trotignon", "title": "On the tree-width of even-hole-free graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of all even-hole-free graphs has unbounded tree-width, as it\ncontains all complete graphs. Recently, a class of (even-hole, $K_4$)-free\ngraphs was constructed, that still has unbounded tree-width [Sintiari and\nTrotignon, 2019]. The class has unbounded degree and contains arbitrarily large\nclique-minors. We ask whether this is necessary.\n  We prove that for every graph $G$, if $G$ excludes a fixed graph $H$ as a\nminor, then $G$ either has small tree-width, or $G$ contains a large wall or\nthe line graph of a large wall as induced subgraph. This can be seen as a\nstrengthening of Robertson and Seymour's excluded grid theorem for the case of\nminor-free graphs. Our theorem implies that every class of even-hole-free\ngraphs excluding a fixed graph as a minor has bounded tree-width. In fact, our\ntheorem applies to a more general class: (theta, prism)-free graphs. This\nimplies the known result that planar even hole-free graph have bounded\ntree-width [da Silva and Linhares Sales, Discrete Applied Mathematics 2010].\n  We conjecture that even-hole-free graphs of bounded degree have bounded\ntree-width. If true, this would mean that even-hole-freeness is testable in the\nbounded-degree graph model of property testing. We prove the conjecture for\nsubcubic graphs and we give a bound on the tree-width of the class of (even\nhole, pyramid)-free graphs of degree at most 4.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:09:29 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Aboulker", "Pierre", ""], ["Adler", "Isolde", ""], ["Kim", "Eun Jung", ""], ["Sintiari", "Ni Luh Dewi", ""], ["Trotignon", "Nicolas", ""]]}, {"id": "2008.05569", "submitter": "David Harris", "authors": "David G. Harris, Fotis Iliopoulos, Vladimir Kolmogorov", "title": "A new notion of commutativity for the algorithmic Lov\\'{a}sz Local Lemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lov\\'{a}sz Local Lemma (LLL) is a powerful tool in probabilistic\ncombinatorics which can be used to establish the existence of objects that\nsatisfy certain properties. The breakthrough paper of Moser and Tardos and\nfollow-up works revealed that the LLL has intimate connections with a class of\nstochastic local search algorithms for finding such desirable objects. In\nparticular, it can be seen as a sufficient condition for this type of\nalgorithms to converge fast.\n  Besides conditions for existence of and fast convergence to desirable\nobjects, one may naturally ask further questions regarding properties of these\nalgorithms. For instance, \"are they parallelizable?\", \"how many solutions can\nthey output?\", \"what is the expected \"weight\" of a solution?\", etc. These\nquestions and more have been answered for a class of LLL-inspired algorithms\ncalled commutative. In this paper we introduce a new, very natural and more\ngeneral notion of commutativity (essentially matrix commutativity) which allows\nus to show a number of new refined properties of LLL-inspired local search\nalgorithms with significantly simpler proofs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:54:14 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 15:41:32 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 15:46:53 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Harris", "David G.", ""], ["Iliopoulos", "Fotis", ""], ["Kolmogorov", "Vladimir", ""]]}, {"id": "2008.05584", "submitter": "Abu Reyan Ahmed", "authors": "Reyan Ahmed, Felice De Luca, Sabin Devkota, Stephen Kobourov, Mingwei\n  Li", "title": "Graph Drawing via Gradient Descent, $(GD)^2$", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Readability criteria, such as distance or neighborhood preservation, are\noften used to optimize node-link representations of graphs to enable the\ncomprehension of the underlying data. With few exceptions, graph drawing\nalgorithms typically optimize one such criterion, usually at the expense of\nothers. We propose a layout approach, Graph Drawing via Gradient Descent,\n$(GD)^2$, that can handle multiple readability criteria. $(GD)^2$ can optimize\nany criterion that can be described by a smooth function. If the criterion\ncannot be captured by a smooth function, a non-smooth function for the\ncriterion is combined with another smooth function, or auto-differentiation\ntools are used for the optimization. Our approach is flexible and can be used\nto optimize several criteria that have already been considered earlier (e.g.,\nobtaining ideal edge lengths, stress, neighborhood preservation) as well as\nother criteria which have not yet been explicitly optimized in such fashion\n(e.g., vertex resolution, angular resolution, aspect ratio). We provide\nquantitative and qualitative evidence of the effectiveness of $(GD)^2$ with\nexperimental data and a functional prototype:\n\\url{http://hdc.cs.arizona.edu/~mwli/graph-drawing/}.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 21:56:51 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ahmed", "Reyan", ""], ["De Luca", "Felice", ""], ["Devkota", "Sabin", ""], ["Kobourov", "Stephen", ""], ["Li", "Mingwei", ""]]}, {"id": "2008.05594", "submitter": "Julian Pape-Lange", "authors": "Julian Pape-Lange", "title": "Cadences in Grammar-Compressed Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cadences are structurally maximal arithmetic progressions of indices\ncorresponding to equal characters in an underlying string.\n  This paper provides a polynomial time detection algorithm for 3-cadences in\ngrammar-compressed binary strings. This algorithm also translates to a linear\ntime detection algorithm for 3-cadences in uncompressed binary strings.\n  Furthermore, this paper proves that several variants of the cadence detection\nproblem are NP-complete for grammar-compressed strings. As a consequence, the\nequidistant subsequence matching problem with patterns of length three is\nNP-complete for grammar-compressed ternary strings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:51:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Pape-Lange", "Julian", ""]]}, {"id": "2008.05648", "submitter": "Antares Chen", "authors": "Antares Chen, Jonathan Shi, Luca Trevisan", "title": "Cut Sparsification of the Clique Beyond the Ramanujan Bound: A\n  Separation of Cut Versus Spectral Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a random $d$-regular graph, with high probability, is a cut\nsparsifier of the clique with approximation error at most $\\left(2\\sqrt{\\frac 2\n\\pi} + o_{n,d}(1)\\right)/\\sqrt d$, where $2\\sqrt{\\frac 2 \\pi} = 1.595\\ldots$\nand $o_{n,d}(1)$ denotes an error term that depends on $n$ and $d$ and goes to\nzero if we first take the limit $n\\rightarrow \\infty$ and then the limit $d\n\\rightarrow \\infty$.\n  This is established by analyzing linear-size cuts using techniques of\nJagannath-Sen '17 derived from ideas from statistical physics and analyzing\nsmall cuts via martingale inequalities.\n  We also prove that every spectral sparsifier of the clique having average\ndegree $d$ and a certain high \"pseudo-girth\" property has an approximation\nerror that is at least the \"Ramanujan bound\" $(2-o_{n,d}(1))/\\sqrt d$, which is\nmet by $d$-regular Ramanujan graphs, generalizing a lower bound of\nSrivastava-Trevisan '18.\n  Together, these results imply a separation between spectral sparsification\nand cut sparsification. If $G$ is a random $\\log n$-regular graph on $n$\nvertices, we show that, with high probability, $G$ admits a (weighted subgraph)\ncut sparsifier of average degree $d$ and approximation error at most\n$(1.595\\ldots + o_{n,d}(1))/\\sqrt d$, while every (weighted subgraph) spectral\nsparsifier of $G$ having average degree $d$ has approximation error at least\n$(2-o_{n,d}(1))/\\sqrt d$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:18:34 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 03:14:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chen", "Antares", ""], ["Shi", "Jonathan", ""], ["Trevisan", "Luca", ""]]}, {"id": "2008.05674", "submitter": "M.H. Khalifeh", "authors": "M. H. Khalifeh, A.-H. Esfahanian", "title": "Inset Edges Effect and Average Distance of Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An added edge to a graph is called an inset edge. Predicting k inset edges\nwhich minimize the average distance of a graph is known to be NP-Hard. When k =\n1 the complexity of the problem is polynomial. In this paper, we further find\nthe single inset edge(s) of a tree with the closest change on the average\ndistance to a given input. To do that we may require the effect of each inset\nedge for the set of inset edges. For this, we propose an algorithm with the\ntime complexity between O(m) and O(m/m) and an average of less than O(\nm.log(m)), where m stands for the number of possible inset edges. Then it takes\nup to O(log(m)) to find the target inset edges for a custom change on the\naverage distance. Using theoretical tools, the algorithm strictly avoids\nrecalculating the distances with no changes, after adding a new edge to a tree.\nThen reduces the time complexity of calculating remaining distances using some\nmatrix tools which first introduced in [8] with one additional technique. This\ngives us a dynamic time complexity and absolutely depends on the input tree\nwhich is proportion to the Wiener index of the input tree.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:48:45 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Khalifeh", "M. H.", ""], ["Esfahanian", "A. -H.", ""]]}, {"id": "2008.05800", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler (1), Noleen K\\\"ohler (1) and Pan Peng (2) ((1) University\n  of Leeds, (2) University of Sheffield)", "title": "On Testability of First-Order Properties in Bounded-Degree Graphs", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study property testing of properties that are definable in first-order\nlogic (FO) in the bounded-degree graph and relational structure models. We show\nthat any FO property that is defined by a formula with quantifier prefix\n$\\exists^*\\forall^*$ is testable (i.e., testable with constant query\ncomplexity), while there exists an FO property that is expressible by a formula\nwith quantifier prefix $\\forall^*\\exists^*$ that is not testable. In the dense\ngraph model, a similar picture is long known (Alon, Fischer, Krivelevich,\nSzegedy, Combinatorica 2000), despite the very different nature of the two\nmodels. In particular, we obtain our lower bound by a first-order formula that\ndefines a class of bounded-degree expanders, based on zig-zag products of\ngraphs. We expect this to be of independent interest. We then prove testability\nof some first-order properties that speak about isomorphism types of\nneighbourhoods, including testability of $1$-neighbourhood-freeness, and\n$r$-neighbourhood-freeness under a mild assumption on the degrees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:21:46 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 15:23:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Adler", "Isolde", ""], ["K\u00f6hler", "Noleen", ""], ["Peng", "Pan", ""]]}, {"id": "2008.05801", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler (1) and Noleen K\\\"ohler (1) ((1) University of Leeds)", "title": "An explicit construction of graphs of bounded degree that are far from\n  being Hamiltonian", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian cycles in graphs were first studied in the 1850s. Since then, an\nimpressive amount of research has been dedicated to identifying classes of\ngraphs that allow Hamiltonian cycles, and to related questions. The\ncorresponding decision problem, that asks whether a given graph is Hamiltonian\n(i.\\,e.\\ admits a Hamiltonian cycle), is one of Karp's famous NP-complete\nproblems. In this paper we study graphs of bounded degree that are \\emph{far}\nfrom being Hamiltonian, where a graph $G$ on $n$ vertices is \\emph{far} from\nbeing Hamiltonian, if modifying a constant fraction of $n$ edges is necessary\nto make $G$ Hamiltonian. We give an explicit deterministic construction of a\nclass of graphs of bounded degree that are locally Hamiltonian, but (globally)\nfar from being Hamiltonian. Here, \\emph{locally Hamiltonian} means that every\nsubgraph induced by the neighbourhood of a small vertex set appears in some\nHamiltonian graph. More precisely, we obtain graphs which differ in $\\Theta(n)$\nedges from any Hamiltonian graph, but non-Hamiltonicity cannot be detected in\nthe neighbourhood of $o(n)$ vertices. Our class of graphs yields a class of\nhard instances for one-sided error property testers with linear query\ncomplexity. It is known that any property tester (even with two-sided error)\nrequires a linear number of queries to test Hamiltonicity (Yoshida, Ito, 2010).\nThis is proved via a randomised construction of hard instances. In contrast,\nour construction is deterministic. So far only very few deterministic\nconstructions of hard instances for property testing are known. We believe that\nour construction may lead to future insights in graph theory and towards a\ncharacterisation of the properties hat are testable in the bounded-degree\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:22:53 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 17:20:56 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 10:11:01 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Adler", "Isolde", "", "University of Leeds"], ["K\u00f6hler", "Noleen", "", "University of Leeds"]]}, {"id": "2008.05844", "submitter": "Sanjeev Saxena", "authors": "Rahul Kumar Singh and Sanjeev Saxena", "title": "On seat allocation problem with multiple merit lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we present a simpler algorithm for joint seat allocation\nproblem in case there are two or more merit lists. In case of two lists (the\ncurrent situation for Engineering seats in India), the running time of the\nalgorithm is proportional to sum of running time for two separate (delinked)\nallocations. The algorithm is straight forward and natural and is not (at least\ndirectly) based on deferred acceptance algorithm of Gale and Shapley. Each\nperson can only move higher in his or her preference list. Thus, all steps of\nthe algorithm can be made public. This will improve transparency and trust in\nthe system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:07:14 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Singh", "Rahul Kumar", ""], ["Saxena", "Sanjeev", ""]]}, {"id": "2008.06101", "submitter": "Xiangyu Guo", "authors": "Xiangyu Guo, Janardhan Kulkarni, Shi Li, Jiayi Xian", "title": "Consistent $k$-Median: Simpler, Better and Robust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and study the online consistent $k$-clustering\nwith outliers problem, generalizing the non-outlier version of the problem\nstudied in [Lattanzi-Vassilvitskii, ICML17].\n  We show that a simple local-search based online algorithm can give a\nbicriteria constant approximation for the problem with $O(k^2 \\log^2 (nD))$\nswaps of medians (recourse) in total, where $D$ is the diameter of the metric.\nWhen restricted to the problem without outliers, our algorithm is simpler,\ndeterministic and gives better approximation ratio and recourse, compared to\nthat of [Lattanzi-Vassilvitskii, ICML17].\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 20:24:28 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Guo", "Xiangyu", ""], ["Kulkarni", "Janardhan", ""], ["Li", "Shi", ""], ["Xian", "Jiayi", ""]]}, {"id": "2008.06152", "submitter": "Kazuichi Oe", "authors": "Kazuichi Oe", "title": "Consideration for effectively handling parallel workloads on public\n  cloud system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We retrieved and analyzed parallel storage workloads of the FUJITSU K5 cloud\nservice to clarify how to build cost-effective hybrid storage systems. A hybrid\nstorage system consists of fast but low-capacity tier (first tier) and slow but\nhigh-capacity tier (second tier). And, it typically consists of either SSDs and\nHDDs or NVMs and SSDs. As a result, we found that 1) regions for first tier\nshould be assigned only if a workload includes large number of IO accesses for\na whole day, 2) the regions that include a large number of IO accesses should\nbe dynamically chosen and moved from second tier to first tier for a short\ninterval, and 3) if a cache hit ratio is regularly low, use of the cache for\nthe workload should be cancelled, and the whole workload region should be\nassigned to the region for first tier. These workloads already have been\nreleased from the SNIA web site.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 01:18:04 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Oe", "Kazuichi", ""]]}, {"id": "2008.06300", "submitter": "Marcel Radermacher", "authors": "Marcel Radermacher, Ignaz Rutter and Peter Stumpf", "title": "Towards a characterization of stretchable aligned graphs", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of stretching pseudolines in a planar straight-line\ndrawing to straight lines while preserving the straightness and the\ncombinatorial embedding of the drawing. We answer open questions by Mchedlidze\net al. by showing that not all instances with two pseudolines are stretchable.\nOn the positive side, for $k\\geq 2$ pseudolines intersecting in a single point,\nwe prove that in case that some edge-pseudoline intersection-patterns are\nforbidden, all instances are stretchable. For intersection-free pseudoline\narrangements we show that every aligned graph has an aligned drawing. This\nconsiderably reduces the gap between stretchable and non-stretchable instances.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:43:33 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Radermacher", "Marcel", ""], ["Rutter", "Ignaz", ""], ["Stumpf", "Peter", ""]]}, {"id": "2008.06554", "submitter": "Kuan-Yi Ho", "authors": "Kai-Min Chung, Kuan-Yi Ho, Xiaorui Sun", "title": "On the Hardness of Massively Parallel Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether there are inherent limits of parallelization in the\n(randomized) massively parallel computation (MPC) model by comparing it with\nthe (sequential) RAM model. As our main result, we show the existence of hard\nfunctions that are essentially not parallelizable in the MPC model. Based on\nthe widely-used random oracle methodology in cryptography with a cryptographic\nhash function $h:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$ computable in time $t_h$, we\nshow that there exists a function that can be computed in time $O(T\\cdot t_h)$\nand space $S$ by a RAM algorithm, but any MPC algorithm with local memory size\n$s < S/c$ for some $c>1$ requires at least $\\tilde{\\Omega}(T)$ rounds to\ncompute the function, even in the average case, for a wide range of parameters\n$n \\leq S \\leq T \\leq 2^{n^{1/4}}$. Our result is almost optimal in the sense\nthat by taking $T$ to be much larger than $t_h$, \\textit{e.g.}, $T$ to be\nsub-exponential in $t_h$, to compute the function, the round complexity of any\nMPC algorithm with small local memory size is asymptotically the same (up to a\npolylogarithmic factor) as the time complexity of the RAM algorithm. Our result\nis obtained by adapting the so-called compression argument from the data\nstructure lower bounds and cryptography literature to the context of massively\nparallel computation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:46:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chung", "Kai-Min", ""], ["Ho", "Kuan-Yi", ""], ["Sun", "Xiaorui", ""]]}, {"id": "2008.06591", "submitter": "Mina Dalirrooyfard", "authors": "Mina Dalirrooyfard, Andrea Lincoln and Virginia Vassilevska Williams", "title": "New Techniques for Proving Fine-Grained Average-Case Hardness", "comments": "To appear in FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of fine-grained cryptography strongly motivates\ndeveloping an average-case analogue of Fine-Grained Complexity (FGC).\n  This paper defines new versions of OV, $k$SUM and zero-$k$-clique that are\nboth worst-case and average-case fine-grained hard assuming the core hypotheses\nof FGC. We then use these as a basis for fine-grained hardness and average-case\nhardness of other problems. The new problems represent their inputs in a\ncertain ``factored'' form. We call them ``factored''-OV,\n``factored''-zero-$k$-clique and ``factored''-$3$SUM. We show that\nfactored-$k$-OV and factored $k$SUM are equivalent and are complete for a class\nof problems defined over Boolean functions. Factored zero-$k$-clique is also\ncomplete, for a different class of problems.\n  Our hard factored problems are also simple enough that we can reduce them to\nmany other problems, e.g.~to edit distance, $k$-LCS and versions of Max-Flow.\nWe further consider counting variants of the factored problems and give\nWCtoACFG reductions for them for a natural distribution. Through FGC reductions\nwe then get average-case hardness for well-studied problems like regular\nexpression matching from standard worst-case FGC assumptions.\n  To obtain our WCtoACFG reductions, we formalize the framework of [Boix-Adsera\net al. 2019] that was used to give a WCtoACFG reduction for counting\n$k$-cliques. We define an explicit property of problems such that if a problem\nhas that property one can use the framework on the problem to get a WCtoACFG\nself reduction. We then use the framework to slightly extend Boix-Adsera et\nal.'s average-case counting $k$-cliques result to average-case hardness for\ncounting arbitrary subgraph patterns of constant size in $k$-partite graphs...\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:21:41 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Lincoln", "Andrea", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2008.06700", "submitter": "Karthik C. S.", "authors": "Vincent Cohen-Addad, Karthik C. S., and Guillaume Lagarde", "title": "On Efficient Low Distortion Ultrametric Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic problem in unsupervised learning and data analysis is to find\nsimpler and easy-to-visualize representations of the data that preserve its\nessential properties. A widely-used method to preserve the underlying\nhierarchical structure of the data while reducing its complexity is to find an\nembedding of the data into a tree or an ultrametric. The most popular\nalgorithms for this task are the classic linkage algorithms (single, average,\nor complete). However, these methods on a data set of $n$ points in\n$\\Omega(\\log n)$ dimensions exhibit a quite prohibitive running time of\n$\\Theta(n^2)$.\n  In this paper, we provide a new algorithm which takes as input a set of\npoints $P$ in $\\mathbb{R}^d$, and for every $c\\ge 1$, runs in time\n$n^{1+\\frac{\\rho}{c^2}}$ (for some universal constant $\\rho>1$) to output an\nultrametric $\\Delta$ such that for any two points $u,v$ in $P$, we have\n$\\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between\n$u$ and $v$ in the \"best\" ultrametric representation of $P$. Here, the best\nultrametric is the ultrametric $\\tilde\\Delta$ that minimizes the maximum\ndistance distortion with respect to the $\\ell_2$ distance, namely that\nminimizes $\\underset{u,v \\in P}{\\max}\\ \\frac{\\tilde\\Delta(u,v)}{\\|u-v\\|_2}$.\n  We complement the above result by showing that under popular complexity\ntheoretic assumptions, for every constant $\\varepsilon>0$, no algorithm with\nrunning time $n^{2-\\varepsilon}$ can distinguish between inputs in\n$\\ell_\\infty$-metric that admit isometric embedding and those that incur a\ndistortion of $\\frac{3}{2}$.\n  Finally, we present empirical evaluation on classic machine learning datasets\nand show that the output of our algorithm is comparable to the output of the\nlinkage algorithms while achieving a much faster running time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 11:06:45 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["S.", "Karthik C.", ""], ["Lagarde", "Guillaume", ""]]}, {"id": "2008.06740", "submitter": "Hsueh-I Lu", "authors": "Hou-Teng Cheong and Hsueh-I Lu", "title": "Finding a Shortest Even Hole in Polynomial Time", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An even (respectively, odd) hole in a graph is an induced cycle with even\n(respectively, odd) length that is at least four. Bienstock [DM 1991 and 1992]\nproved that detecting an even (respectively, odd) hole containing a given\nvertex is NP-complete. Conforti, Chornu\\'ejols, Kappor, and Vu\\v{s}kovi\\'{c}\n[FOCS 1997] gave the first known polynomial-time algorithm to determine whether\na graph contains even holes. Chudnovsky, Kawarabayashi, and Seymour [JGT 2005]\nestimated that Conforti et al.'s algorithm runs in $O(n^{40})$ time on an\n$n$-vertex graph and reduced the required time to $O(n^{31})$. Subsequently,\nda~Silva and Vu\\v{s}kovi\\'{c}~[JCTB 2013], Chang and Lu [JCTB 2017], and Lai,\nLu, and Thorup [STOC 2020] improved the time to $O(n^{19})$, $O(n^{11})$, and\n$O(n^9)$, respectively. The tractability of determining whether a graph\ncontains odd holes has been open for decades until the algorithm of Chudnovsky,\nScott, Seymour, and Spirkl [JACM 2020] that runs in $O(n^9)$ time, which Lai et\nal. also reduced to $O(n^8)$. By extending Chudnovsky et al.'s techniques for\ndetecting odd holes, Chudnovsky, Scott, and Seymour [Combinatorica 2020 to\nappear] (respectively, [arXiv 2020]) ensured the tractability of finding a long\n(respectively, shortest) odd hole. They also ensured the NP-hardness of finding\na longest odd hole, whose reduction also works for finding a longest even hole.\nRecently, Cook and Seymour ensured the tractability of finding a long even\nhole. An intriguing missing piece is the tractability of finding a shortest\neven hole, left open for at least 15 years by, e.g., Chudnovsky et al. [JGT\n2005] and Johnson [TALG 2005]. We resolve this long-standing open problem by\ngiving the first known polynomial-time algorithm, running in $O(n^{31})$ time,\nfor finding a shortest even hole in an $n$-vertex graph that contains even\nholes.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:44:31 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Cheong", "Hou-Teng", ""], ["Lu", "Hsueh-I", ""]]}, {"id": "2008.07023", "submitter": "Oliver Serang", "authors": "Patrick Kreitzberg, Kyle Lucke, Jake Pennington, Oliver Serang", "title": "Selection on $X_1 + X_1 + \\cdots X_m$ via Cartesian product tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection on the Cartesian product is a classic problem in computer science.\nRecently, an optimal algorithm for selection on $X+Y$, based on soft heaps, was\nintroduced. By combining this approach with layer-ordered heaps (LOHs), an\nalgorithm using a balanced binary tree of $X+Y$ selections was proposed to\nperform $k$-selection on $X_1+X_2+\\cdots+X_m$ in $o(n\\cdot m + k\\cdot m)$,\nwhere $X_i$ have length $n$. Here, that $o(n\\cdot m + k\\cdot m)$ algorithm is\ncombined with a novel, optimal LOH-based algorithm for selection on $X+Y$\n(without a soft heap). Performance of algorithms for selection on\n$X_1+X_2+\\cdots+X_m$ are compared empirically, demonstrating the benefit of the\nalgorithm proposed here.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 22:59:04 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kreitzberg", "Patrick", ""], ["Lucke", "Kyle", ""], ["Pennington", "Jake", ""], ["Serang", "Oliver", ""]]}, {"id": "2008.07159", "submitter": "Chuan-Chi Lai", "authors": "Chuan-Chi Lai, Chuan-Ming Liu, Yan-Lin Chen, Li-Chun Wang", "title": "Probabilistic Skyline Query Processing over Uncertain Data Streams in\n  Edge Computing Environments", "comments": "6 pages, 5 figures, to appear in 2020 IEEE Global Communications\n  Conference: Selected Areas in Communications: Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of technology, the data generated in our lives is\ngetting faster and faster, and the amount of data that various applications\nneed to process becomes extremely huge. Therefore, we need to put more effort\ninto analyzing data and extracting valuable information. Cloud computing used\nto be a good technology to solve a large number of data analysis problems.\nHowever, in the era of the popularity of the Internet of Things (IoT),\ntransmitting sensing data back to the cloud for centralized data analysis will\nconsume a lot of wireless communication and network transmission costs. To\nsolve the above problems, edge computing has become a promising solution. In\nthis paper, we propose a new algorithm for processing probabilistic skyline\nqueries over uncertain data streams in an edge computing environment. We use\nthe concept of a second skyline set to filter data that is unlikely to be the\nresult of the skyline. Besides, the edge server only sends the information\nneeded to update the global analysis results on the cloud server, which will\ngreatly reduce the amount of data transmitted over the network. The results\nshow that our proposed method not only reduces the response time by more than\n50% compared with the brute force method on two-dimensional data but also\nmaintains the leading processing speed on high-dimensional data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:53:29 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 04:01:53 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lai", "Chuan-Chi", ""], ["Liu", "Chuan-Ming", ""], ["Chen", "Yan-Lin", ""], ["Wang", "Li-Chun", ""]]}, {"id": "2008.07216", "submitter": "Igor Semaev", "authors": "Igor Semaev", "title": "Algorithm for SIS and MultiSIS problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SIS problem has numerous applications in cryptography. Known algorithms for\nsolving that problem are exponential in complexity. A new algorithm is\nsuggested in this note, its complexity is sub-exponential for a range of\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:53:57 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Semaev", "Igor", ""]]}, {"id": "2008.07344", "submitter": "Sai Sandeep", "authors": "Venkatesan Guruswami, Sai Sandeep", "title": "Approximate Hypergraph Vertex Cover and generalized Tuza's conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous conjecture of Tuza states that the minimum number of edges needed to\ncover all the triangles in a graph is at most twice the maximum number of\nedge-disjoint triangles. This conjecture was couched in a broader setting by\nAharoni and Zerbib who proposed a hypergraph version of this conjecture, and\nalso studied its implied fractional versions. We establish the fractional\nversion of the Aharoni-Zerbib conjecture up to lower order terms. Specifically,\nwe give a factor $t/2+ O(\\sqrt{t \\log t})$ approximation based on LP rounding\nfor an algorithmic version of the hypergraph Tur\\'{a}n problem (AHTP). The\nobjective in AHTP is to pick the smallest collection of $(t-1)$-sized subsets\nof vertices of an input $t$-uniform hypergraph such that every hyperedge\ncontains one of these subsets.\n  Aharoni and Zerbib also posed whether Tuza's conjecture and its hypergraph\nversions could follow from non-trivial duality gaps between vertex covers and\nmatchings on hypergraphs that exclude certain sub-hypergraphs, for instance, a\n\"tent\" structure that cannot occur in the incidence of triangles and edges. We\ngive a strong negative answer to this question, by exhibiting tent-free\nhypergraphs, and indeed $\\mathcal{F}$-free hypergraphs for any finite family\n$\\mathcal{F}$ of excluded sub-hypergraphs, whose vertex covers must include\nalmost all the vertices.\n  The algorithmic questions arising in the above study can be phrased as\ninstances of vertex cover on simple hypergraphs, whose hyperedges can pairwise\nshare at most one vertex. We prove that the trivial factor $t$ approximation\nfor vertex cover is hard to improve for simple $t$-uniform hypergraphs.\nHowever, for set cover on simple $n$-vertex hypergraphs, the greedy algorithm\nachieves a factor $(\\ln n)/2$, better than the optimal $\\ln n$ factor for\ngeneral hypergraphs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:12:29 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 03:38:04 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sandeep", "Sai", ""]]}, {"id": "2008.07353", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Zheng Wen, Xi Chen", "title": "On the Sample Complexity of Reinforcement Learning with Policy Space\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal sample complexity in large-scale Reinforcement Learning\n(RL) problems with policy space generalization, i.e. the agent has a prior\nknowledge that the optimal policy lies in a known policy space. Existing\nresults show that without a generalization model, the sample complexity of an\nRL algorithm will inevitably depend on the cardinalities of state space and\naction space, which are intractably large in many practical problems.\n  To avoid such undesirable dependence on the state and action space sizes,\nthis paper proposes a new notion of eluder dimension for the policy space,\nwhich characterizes the intrinsic complexity of policy learning in an arbitrary\nMarkov Decision Process (MDP). Using a simulator oracle, we prove a\nnear-optimal sample complexity upper bound that only depends linearly on the\neluder dimension. We further prove a similar regret bound in deterministic\nsystems without the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:26:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mou", "Wenlong", ""], ["Wen", "Zheng", ""], ["Chen", "Xi", ""]]}, {"id": "2008.07425", "submitter": "Valia Mitsou", "authors": "R\\'emy Belmonte, Eun Jung Kim, Michael Lampis, Valia Mitsou, Yota\n  Otachi", "title": "Grundy Distinguishes Treewidth from Pathwidth", "comments": "To be published in proceedings of ESA 2020", "journal-ref": null, "doi": "10.4230/LIPIcs.ESA.2020.38", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural graph parameters, such as treewidth, pathwidth, and clique-width,\nare a central topic of study in parameterized complexity. A main aim of\nresearch in this area is to understand the \"price of generality\" of these\nwidths: as we transition from more restrictive to more general notions, which\nare the problems that see their complexity status deteriorate from\nfixed-parameter tractable to intractable? This type of question is by now very\nwell-studied, but, somewhat strikingly, the algorithmic frontier between the\ntwo (arguably) most central width notions, treewidth and pathwidth, is still\nnot understood: currently, no natural graph problem is known to be W-hard for\none but FPT for the other. Indeed, a surprising development of the last few\nyears has been the observation that for many of the most paradigmatic problems,\ntheir complexities for the two parameters actually coincide exactly, despite\nthe fact that treewidth is a much more general parameter. It would thus appear\nthat the extra generality of treewidth over pathwidth often comes \"for free\".\n  Our main contribution in this paper is to uncover the first natural example\nwhere this generality comes with a high price. We consider Grundy Coloring, a\nvariation of coloring where one seeks to calculate the worst possible coloring\nthat could be assigned to a graph by a greedy First-Fit algorithm. We show that\nthis well-studied problem is FPT parameterized by pathwidth; however, it\nbecomes significantly harder (W[1]-hard) when parameterized by treewidth.\nFurthermore, we show that Grundy Coloring makes a second complexity jump for\nmore general widths, as it becomes para-NP-hard for clique-width. Hence, Grundy\nColoring nicely captures the complexity trade-offs between the three most\nwell-studied parameters. Completing the picture, we show that Grundy Coloring\nis FPT parameterized by modular-width.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:49:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Belmonte", "R\u00e9my", ""], ["Kim", "Eun Jung", ""], ["Lampis", "Michael", ""], ["Mitsou", "Valia", ""], ["Otachi", "Yota", ""]]}, {"id": "2008.07468", "submitter": "Mikhail Raskin", "authors": "Bruno Courcelle, Ir\\`ene Durand, Michael Raskin", "title": "A unified algorithm for colouring graphs of bounded clique-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clique-width is one of the graph complexity measures leading to polynomial\nspecial-case algorithms for generally NP-complete problems, e.g. graph\ncolourability. The best two currently known algorithms for verifying\nc-colourability of graphs represented as clique-width terms are optimised\ntowards two different extreme cases, a constant number of colours and a very\nlarge number of colours. We present a way to unify these approaches in a single\nrelatively simple algorithm that achieves the state of the art complexity in\nboth cases. The unified algorithm also provides a speed-up for a large number\nof colours.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:47:53 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Courcelle", "Bruno", ""], ["Durand", "Ir\u00e8ne", ""], ["Raskin", "Michael", ""]]}, {"id": "2008.07510", "submitter": "Andr\\'e Nusser", "authors": "Karl Bringmann, Marvin K\\\"unnemann, Andr\\'e Nusser", "title": "When Lipschitz Walks Your Dog: Algorithm Engineering of the Discrete\n  Fr\\'echet Distance under Translation", "comments": "A shorter version was accepted at ESA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider the natural question of how to measure the similarity of curves in\nthe plane by a quantity that is invariant under translations of the curves.\nSuch a measure is justified whenever we aim to quantify the similarity of the\ncurves' shapes rather than their positioning in the plane, e.g., to compare the\nsimilarity of handwritten characters. Perhaps the most natural such notion is\nthe (discrete) Fr\\'echet distance under translation. Unfortunately, the\nalgorithmic literature on this problem yields a very pessimistic view: On\npolygonal curves with $n$ vertices, the fastest algorithm runs in time\n$O(n^{4.667})$ and cannot be improved below $n^{4-o(1)}$ unless the Strong\nExponential Time Hypothesis fails. Can we still obtain an implementation that\nis efficient on realistic datasets?\n  Spurred by the surprising performance of recent implementations for the\nFr\\'echet distance, we perform algorithm engineering for the Fr\\'echet distance\nunder translation. Our solution combines fast, but inexact tools from\ncontinuous optimization (specifically, branch-and-bound algorithms for global\nLipschitz optimization) with exact, but expensive algorithms from computational\ngeometry (specifically, problem-specific algorithms based on an arrangement\nconstruction). We combine these two ingredients to obtain an exact decision\nalgorithm for the Fr\\'echet distance under translation. For the related task of\ncomputing the distance value up to a desired precision, we engineer and compare\ndifferent methods. On a benchmark set involving handwritten characters and\nroute trajectories, our implementation answers a typical query for either task\nin the range of a few milliseconds up to a second on standard desktop hardware.\n  We believe that our implementation will enable the use of the Fr\\'echet\ndistance under translation in applications, whereas previous approaches would\nhave been computationally infeasible.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:55:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bringmann", "Karl", ""], ["K\u00fcnnemann", "Marvin", ""], ["Nusser", "Andr\u00e9", ""]]}, {"id": "2008.07590", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Aleksander {\\L}ukasiewicz and Przemys{\\l}aw Uzna\\'nski", "title": "Cardinality estimation using Gumbel distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality estimation is the task of approximating the number of distinct\nelements in a large dataset with possibly repeating elements. LogLog and\nHyperLogLog (c.f. Durand and Flajolet [ESA 2003], Flajolet et al. [Discrete\nMath Theor. 2007]) are small space sketching schemes for cardinality\nestimation, which have both strong theoretical guarantees of performance and\nare highly effective in practice. This makes them a highly popular solution\nwith many implementations in big-data systems (e.g. Algebird, Apache\nDataSketches, BigQuery, Presto and Redis). However, despite having simple and\nelegant formulation, both the analysis of LogLog and HyperLogLog are extremely\ninvolved -- spanning over tens of pages of analytic combinatorics and complex\nfunction analysis.\n  We propose a modification to both LogLog and HyperLogLog that replaces\ndiscrete geometric distribution with a continuous Gumbel distribution. This\nleads to a very short, simple and elementary analysis of estimation guarantees,\nand smoother behavior of the estimator.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 19:43:43 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["\u0141ukasiewicz", "Aleksander", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "2008.07633", "submitter": "Zhuo Feng", "authors": "Ying Zhang, Zhiqiang Zhao, Zhuo Feng", "title": "SF-GRASS: Solver-Free Graph Spectral Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA cs.SI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent spectral graph sparsification techniques have shown promising\nperformance in accelerating many numerical and graph algorithms, such as\niterative methods for solving large sparse matrices, spectral partitioning of\nundirected graphs, vectorless verification of power/thermal grids,\nrepresentation learning of large graphs, etc. However, prior spectral graph\nsparsification methods rely on fast Laplacian matrix solvers that are usually\nchallenging to implement in practice. This work, for the first time, introduces\na solver-free approach (SF-GRASS) for spectral graph sparsification by\nleveraging emerging spectral graph coarsening and graph signal processing (GSP)\ntechniques. We introduce a local spectral embedding scheme for efficiently\nidentifying spectrally-critical edges that are key to preserving graph spectral\nproperties, such as the first few Laplacian eigenvalues and eigenvectors. Since\nthe key kernel functions in SF-GRASS can be efficiently implemented using\nsparse-matrix-vector-multiplications (SpMVs), the proposed spectral approach is\nsimple to implement and inherently parallel friendly. Our extensive\nexperimental results show that the proposed method can produce a hierarchy of\nhigh-quality spectral sparsifiers in nearly-linear time for a variety of\nreal-world, large-scale graphs and circuit networks when compared with the\nprior state-of-the-art spectral method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 21:37:19 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhang", "Ying", ""], ["Zhao", "Zhiqiang", ""], ["Feng", "Zhuo", ""]]}, {"id": "2008.07764", "submitter": "Amyra Meidiana", "authors": "Amyra Meidiana, Seok-Hee Hong, Peter Eades", "title": "New Quality Metrics for Dynamic Graph Drawing", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present new quality metrics for dynamic graph drawings.\nNamely, we present a new framework for change faithfulness metrics for dynamic\ngraph drawings, which compare the ground truth change in dynamic graphs and the\ngeometric change in drawings. More specifically, we present two specific\ninstances, cluster change faithfulness metrics and distance change faithfulness\nmetrics. We first validate the effectiveness of our new metrics using\ndeformation experiments. Then we compare various graph drawing algorithms using\nour metrics. Our experiments confirm that the best cluster (resp. distance)\nfaithful graph drawing algorithms are also cluster (resp. distance) change\nfaithful.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:53:19 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 13:37:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Meidiana", "Amyra", ""], ["Hong", "Seok-Hee", ""], ["Eades", "Peter", ""]]}, {"id": "2008.07834", "submitter": "Giordano Da Lozzo", "authors": "Patrizio Angelini, Steven Chaplick, Sabine Cornelsen, and Giordano Da\n  Lozzo", "title": "Planar L-Drawings of Bimodal Graphs", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a planar L-drawing of a directed graph (digraph) each edge e is\nrepresented as a polyline composed of a vertical segment starting at the tail\nof e and a horizontal segment ending at the head of e. Distinct edges may\noverlap, but not cross. Our main focus is on bimodal graphs, i.e., digraphs\nadmitting a planar embedding in which the incoming and outgoing edges around\neach vertex are contiguous. We show that every plane bimodal graph without\n2-cycles admits a planar L-drawing. This includes the class of upward-plane\ngraphs. Finally, outerplanar digraphs admit a planar L-drawing - although they\ndo not always have a bimodal embedding - but not necessarily with an\nouterplanar embedding.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:10:12 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Angelini", "Patrizio", ""], ["Chaplick", "Steven", ""], ["Cornelsen", "Sabine", ""], ["Da Lozzo", "Giordano", ""]]}, {"id": "2008.07898", "submitter": "Martin Kucera", "authors": "Martin Ku\\v{c}era, Ond\\v{r}ej Such\\'y", "title": "Minimum Eccentricity Shortest Path Problem with Respect to Structural\n  Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Minimum Eccentricity Shortest Path Problem consists in finding a shortest\npath with minimum eccentricity in a given undirected graph. The problem is\nknown to be NP-complete and W[2]-hard with respect to the desired eccentricity.\nWe present fpt algorithms for the problem parameterized by the modular width,\ndistance to cluster graph, the combination of distance to disjoint paths with\nthe desired eccentricity, and maximum leaf number.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 12:56:02 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 19:58:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ku\u010dera", "Martin", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "2008.07968", "submitter": "D\\'aniel Marx", "authors": "D\\'aniel Marx", "title": "Four short stories on surprising algorithmic uses of treewidth", "comments": "17 pages", "journal-ref": null, "doi": "10.1007/978-3-030-42071-0_10", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article briefly describes four algorithmic problems where the notion of\ntreewidth is very useful. Even though the problems themselves have nothing to\ndo with treewidth, it turns out that combining known results on treewidth\nallows us to easily describe very clean and high-level algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:03:49 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Marx", "D\u00e1niel", ""]]}, {"id": "2008.08007", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Differentially Private Clustering: Tight Approximation Ratios", "comments": "60 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of differentially private clustering. For several basic\nclustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and\nk-median, we give efficient differentially private algorithms that achieve\nessentially the same approximation ratios as those that can be obtained by any\nnon-private algorithm, while incurring only small additive errors. This\nimproves upon existing efficient algorithms that only achieve some large\nconstant approximation factors.\n  Our results also imply an improved algorithm for the Sample and Aggregate\nprivacy framework. Furthermore, we show that one of the tools used in our\n1-Cluster algorithm can be employed to get a faster quantum algorithm for\nClosestPair in a moderate number of dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:22:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2008.08032", "submitter": "Talya Eden", "authors": "Talya Eden, Saleet Mossel, Ronitt Rubinfeld", "title": "Sampling Multiple Edges Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sublinear time algorithm that allows one to sample multiple\nedges from a distribution that is pointwise $\\epsilon$-close to the uniform\ndistribution, in an \\emph{amortized-efficient} fashion. We consider the\nadjacency list query model, where access to a graph $G$ is given via degree and\nneighbor queries.\n  The problem of sampling a single edge in this model has been raised by Eden\nand Rosenbaum (SOSA 18). Let $n$ and $m$ denote the number of vertices and\nedges of $G$, respectively. Eden and Rosenbaum provided upper and lower bounds\nof $\\Theta^*(n/\\sqrt m)$ for sampling a single edge in general graphs (where\n$O^*(\\cdot)$ suppresses $\\textrm{poly}(1/\\epsilon)$ and $\\textrm{poly}(\\log n)$\ndependencies). We ask whether the query complexity lower bound for sampling a\nsingle edge can be circumvented when multiple samples are required. That is,\ncan we get an improved amortized per-sample cost if we allow a preprocessing\nphase? We answer in the affirmative.\n  We present an algorithm that, if one knows the number of required samples $q$\nin advance, has an overall cost that is sublinear in $q$, namely, $O^*(\\sqrt q\n\\cdot(n/\\sqrt m))$, which is strictly preferable to $O^*(q\\cdot (n/\\sqrt m))$\ncost resulting from $q$ invocations of the algorithm by Eden and Rosenbaum.\n  Subsequent to a preliminary version of this work, T\\v{e}tek and Thorup\n(arXiv, preprint) proved that this bound is essentially optimal.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:04:26 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 19:02:43 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 03:22:32 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 19:40:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Eden", "Talya", ""], ["Mossel", "Saleet", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "2008.08071", "submitter": "Lunjia Hu", "authors": "Lunjia Hu, Omer Reingold", "title": "Robust Mean Estimation on Highly Incomplete Data with Arbitrary Outliers", "comments": "29 pages, 2 figures. Published in AISTATS 2021. More details in the\n  proof of Claim 14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly estimating the mean of a $d$-dimensional\ndistribution given $N$ examples, where most coordinates of every example may be\nmissing and $\\varepsilon N$ examples may be arbitrarily corrupted. Assuming\neach coordinate appears in a constant factor more than $\\varepsilon N$\nexamples, we show algorithms that estimate the mean of the distribution with\ninformation-theoretically optimal dimension-independent error guarantees in\nnearly-linear time $\\widetilde O(Nd)$. Our results extend recent work on\ncomputationally-efficient robust estimation to a more widely applicable\nincomplete-data setting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:53:34 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 07:50:25 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 01:13:12 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 19:39:54 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 04:25:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hu", "Lunjia", ""], ["Reingold", "Omer", ""]]}, {"id": "2008.08285", "submitter": "Stephen Ash", "authors": "Andrew Borthwick, Stephen Ash, Bin Pang, Shehzad Qureshi, Timothy\n  Jones", "title": "Scalable Blocking for Very Large Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of database deduplication, the goal is to find approximately\nmatching records within a database. Blocking is a typical stage in this process\nthat involves cheaply finding candidate pairs of records that are potential\nmatches for further processing. We present here Hashed Dynamic Blocking, a new\napproach to blocking designed to address datasets larger than those studied in\nmost prior work. Hashed Dynamic Blocking (HDB) extends Dynamic Blocking, which\nleverages the insight that rare matching values and rare intersections of\nvalues are predictive of a matching relationship. We also present a novel use\nof Locality Sensitive Hashing (LSH) to build blocking key values for huge\ndatabases with a convenient configuration to control the trade-off between\nprecision and recall. HDB achieves massive scale by minimizing data movement,\nusing compact block representation, and greedily pruning ineffective candidate\nblocks using a Count-min Sketch approximate counting data structure. We\nbenchmark the algorithm by focusing on real-world datasets in excess of one\nmillion rows, demonstrating that the algorithm displays linear time complexity\nscaling in this range. Furthermore, we execute HDB on a 530 million row\nindustrial dataset, detecting 68 billion candidate pairs in less than three\nhours at a cost of $307 on a major cloud service.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:35:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Borthwick", "Andrew", ""], ["Ash", "Stephen", ""], ["Pang", "Bin", ""], ["Qureshi", "Shehzad", ""], ["Jones", "Timothy", ""]]}, {"id": "2008.08288", "submitter": "Fabrizio Montecchiani", "authors": "Sujoy Bhore, Robert Ganian, Fabrizio Montecchiani, Martin N\\\"ollenburg", "title": "Parameterized Algorithms for Queue Layouts", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $h$-queue layout of a graph $G$ consists of a linear order of its vertices\nand a partition of its edges into $h$ queues, such that no two independent\nedges of the same queue nest. The minimum $h$ such that $G$ admits an $h$-queue\nlayout is the queue number of $G$. We present two fixed-parameter tractable\nalgorithms that exploit structural properties of graphs to compute optimal\nqueue layouts. As our first result, we show that deciding whether a graph $G$\nhas queue number $1$ and computing a corresponding layout is fixed-parameter\ntractable when parameterized by the treedepth of $G$. Our second result then\nuses a more restrictive parameter, the vertex cover number, to solve the\nproblem for arbitrary $h$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:39:25 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bhore", "Sujoy", ""], ["Ganian", "Robert", ""], ["Montecchiani", "Fabrizio", ""], ["N\u00f6llenburg", "Martin", ""]]}, {"id": "2008.08368", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Akhoondian Amiri and Julian Wargalla", "title": "Disjoint Shortest Paths with Congestion on DAGs", "comments": "New results have been added, also a new author joined the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the k-Disjoint Shortest Paths problem, a set of terminal pairs of vertices\n$\\{(s_i,t_i)\\mid 1\\le i\\le k\\}$ is given and we are asked to find paths\n$P_1,\\ldots,P_k$ such that each path $P_i$ is a shortest path from $s_i$ to\n$t_i$ and every vertex of the graph routes at most one of them. We introduce a\ngeneralization of the problem, namely, $k$-Disjoint Shortest Paths with\nCongestion-$c$ where every vertex is allowed to route up to $c$ paths.\n  We provide a simple algorithm to solve the problem in time $f(k) n^{O(k-c)}$\non DAGs. Using the techniques for DAGs, we show the problem is solvable in time\n$f(k) n^{O(k)}$ on general undirected graphs. Our algorithm for DAGs is based\non the earlier algorithm for $k$-Disjoint Paths with Congestion-$c$[IPL2019],\nbut we significantly simplify their argument.\n  Then we prove that it is not possible to improve the algorithm significantly\nby showing that for every constant $c$ the problem is W[1]-hard w.r.t.\\\nparameter $k-c$. We also consider the problem on acyclic planar graphs, but\nthis time we restrict ourselves to the edge-disjoint shortest paths problem. We\nshow that even on acyclic planar graphs there is no $f(k)n^{o(k)}$ algorithm\nfor the problem unless ETH fails.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 10:29:09 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 06:07:19 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 14:46:45 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 14:01:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["Wargalla", "Julian", ""]]}, {"id": "2008.08373", "submitter": "Meirav Zehavi", "authors": "Daniel Lokshtanov, Saket Saurabh, Meirav Zehavi", "title": "Efficient Graph Minors Theory and Parameterized Algorithms for (Planar)\n  Disjoint Paths", "comments": "Survey. Appeared in \"Treewidth, Kernels, and Algorithms - Essays\n  Dedicated to Hans L. Bodlaender on the Occasion of His 60th Birthday\", 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Disjoint Paths problem, the input consists of an $n$-vertex graph $G$\nand a collection of $k$ vertex pairs, $\\{(s_i,t_i)\\}_{i=1}^k$, and the\nobjective is to determine whether there exists a collection $\\{P_i\\}_{i=1}^k$\nof $k$ pairwise vertex-disjoint paths in $G$ where the end-vertices of $P_i$\nare $s_i$ and $t_i$. This problem was shown to admit an $f(k)n^3$-time\nalgorithm by Robertson and Seymour (Graph Minors XIII, The Disjoint Paths\nProblem, JCTB). In modern terminology, this means that Disjoint Paths is fixed\nparameter tractable (FPT) with respect to $k$. Remarkably, the above algorithm\nfor Disjoint Paths is a cornerstone of the entire Graph Minors Theory, and\nconceptually vital to the $g(k)n^3$-time algorithm for Minor Testing (given two\nundirected graphs, $G$ and $H$ on $n$ and $k$ vertices, respectively, determine\nwhether $G$ contains $H$ as a minor).\n  In this semi-survey, we will first give an exposition of the Graph Minors\nTheory with emphasis on efficiency from the viewpoint of Parameterized\nComplexity. Secondly, we will review the state of the art with respect to the\nDisjoint Paths and Planar Disjoint Paths problems. Lastly, we will discuss the\nmain ideas behind a new algorithm that combines treewidth reduction and an\nalgebraic approach to solve Planar Disjoint Paths in time\n$2^{k^{O(1)}}n^{O(1)}$ (for undirected graphs).\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 10:48:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "2008.08415", "submitter": "Shuichi Miyazaki", "authors": "Toshiya Itoh, Shuichi Miyazaki, Makoto Satake", "title": "Competitive Analysis for Two Variants of Online Metric Matching Problem", "comments": "12 pages. Update from the 1st version: The first author was added and\n  Theorems 3, 4 and 5 were improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two variants of the online metric matching problem.\nThe first problem is the online metric matching problem where all the servers\nare placed at one of two positions in the metric space. We show that a simple\ngreedy algorithm achieves the competitive ratio of 3 and give a matching lower\nbound. The second problem is the online facility assignment problem on a line,\nwhere servers have capacities, servers and requests are placed on 1-dimensional\nline, and the distances between any two consecutive servers are the same. We\nshow lower bounds $1+ \\sqrt{6}$ $(> 3.44948)$, $\\frac{4+\\sqrt{73}}{3}$\n$(>4.18133)$ and $\\frac{13}{3}$ $(>4.33333)$ on the competitive ratio when the\nnumbers of servers are 3, 4 and 5, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:07:00 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 11:44:05 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Itoh", "Toshiya", ""], ["Miyazaki", "Shuichi", ""], ["Satake", "Makoto", ""]]}, {"id": "2008.08417", "submitter": "John Iacono", "authors": "Jean Cardinal and John Iacono", "title": "Modular Subset Sum, Dynamic Strings, and Zero-Sum Sets", "comments": "To appear at the SIAM Symposium on Simplicity in Algorithms (SOSA21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modular subset sum problem consists of deciding, given a modulus $m$, a\nmultiset $S$ of $n$ integers in $0..m-1$, and a target integer $t$, whether\nthere exists a subset of $S$ with elements summing to $t \\mod m $, and to\nreport such a set if it exists. We give a simple $O(m \\log m)$-time with high\nprobability (w.h.p.) algorithm for the modular subset sum problem. This builds\non and improves on a previous $O(m \\log^7 m)$ w.h.p. algorithm from Axiotis,\nBackurs, Jin, Tzamos, and Wu (SODA 19). Our method utilizes the ADT of the\ndynamic strings structure of Gawrychowski et al. (SODA~18). However, as this\nstructure is rather complicated we present a much simpler alternative which we\ncall the Data Dependent Tree. As an application, we consider the computational\nversion of a fundamental theorem in zero-sum Ramsey theory. The\nErd\\H{o}s-Ginzburg-Ziv Theorem states that a multiset of $2n - 1$ integers\nalways contains a subset of cardinality exactly $n$ whose values sum to a\nmultiple of $n$. We give an algorithm for finding such a subset in time $O(n\n\\log n)$ w.h.p. which improves on an $O(n^2)$ algorithm due to Del Lungo,\nMarini, and Mori (Disc. Math. 09).\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:12:26 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 09:04:01 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Cardinal", "Jean", ""], ["Iacono", "John", ""]]}, {"id": "2008.08479", "submitter": "Will Rosenbaum", "authors": "Christine T. Cheng and Will Rosenbaum", "title": "Simple Counting and Sampling Algorithms for Graphs with Bounded\n  Pathwidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of counting and sampling structures in\ngraphs. We define a class of \"edge universal labeling problems\"---which include\nproper $k$-colorings, independent sets, and downsets---and describe simple\nalgorithms for counting and uniformly sampling valid labelings of graphs,\nassuming a path decomposition is given. Thus, we show that several well-studied\ncounting and sampling problems are fixed parameter tractable (FPT) when\nparameterized by the pathwidth of the input graph. We discuss connections to\ncounting and sampling problems for distributive lattices and, in particular, we\ngive a new FPT algorithm for exactly counting and uniformly sampling stable\nmatchings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:38:30 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Cheng", "Christine T.", ""], ["Rosenbaum", "Will", ""]]}, {"id": "2008.08506", "submitter": "Zsuzsanna Lipt\\'ak", "authors": "Sara Giuliani and Shunsuke Inenaga and Zsuzsanna Lipt\\'ak and Nicola\n  Prezza and Marinella Sciortino and Anna Toffanello", "title": "Novel Results on the Number of Runs of the Burrows-Wheeler-Transform", "comments": "14 pages, 2 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Burrows-Wheeler-Transform (BWT), a reversible string transformation, is\none of the fundamental components of many current data structures in string\nprocessing. It is central in data compression, as well as in efficient query\nalgorithms for sequence data, such as webpages, genomic and other biological\nsequences, or indeed any textual data. The BWT lends itself well to compression\nbecause its number of equal-letter-runs (usually referred to as $r$) is often\nconsiderably lower than that of the original string; in particular, it is well\nsuited for strings with many repeated factors. In fact, much attention has been\npaid to the $r$ parameter as measure of repetitiveness, especially to evaluate\nthe performance in terms of both space and time of compressed indexing data\nstructures.\n  In this paper, we investigate $\\rho(v)$, the ratio of $r$ and of the number\nof runs of the BWT of the reverse of $v$. Kempa and Kociumaka [FOCS 2020] gave\nthe first non-trivial upper bound as $\\rho(v) = O(\\log^2(n))$, for any string\n$v$ of length $n$. However, nothing is known about the tightness of this upper\nbound. We present infinite families of binary strings for which $\\rho(v) =\n\\Theta(\\log n)$ holds, thus giving the first non-trivial lower bound on\n$\\rho(n)$, the maximum over all strings of length $n$.\n  Our results suggest that $r$ is not an ideal measure of the repetitiveness of\nthe string, since the number of repeated factors is invariant between the\nstring and its reverse. We believe that there is a more intricate relationship\nbetween the number of runs of the BWT and the string's combinatorial\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:33:51 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Giuliani", "Sara", ""], ["Inenaga", "Shunsuke", ""], ["Lipt\u00e1k", "Zsuzsanna", ""], ["Prezza", "Nicola", ""], ["Sciortino", "Marinella", ""], ["Toffanello", "Anna", ""]]}, {"id": "2008.08575", "submitter": "Thatchaphol Saranurak", "authors": "Thatchaphol Saranurak", "title": "A Simple Deterministic Algorithm for Edge Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a deterministic algorithm for computing edge connectivity of a simple\ngraph with $m$ edges in $m^{1+o(1)}$ time. Although the fastest deterministic\nalgorithm by Henzinger, Rao, and Wang [SODA'17] has a faster running time of\n$O(m\\log^{2}m\\log\\log m)$, we believe that our algorithm is conceptually\nsimpler. The key tool for this simplication is the expander decomposition. We\nexploit it in a very straightforward way compared to how it has been previously\nused in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:57:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Saranurak", "Thatchaphol", ""]]}, {"id": "2008.08654", "submitter": "Thomas Dybdahl Ahle", "authors": "Thomas Dybdahl Ahle, Jakob Tejs B{\\ae}k Knudsen, Mikkel Thorup", "title": "The Power of Hashing with Mersenne Primes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic way of computing a $k$-universal hash function is to use a random\ndegree-$(k-1)$ polynomial over a prime field $\\mathbb Z_p$. For a fast\ncomputation of the polynomial, the prime $p$ is often chosen as a Mersenne\nprime $p=2^b-1$.\n  In this paper, we show that there are other nice advantages to using Mersenne\nprimes. Our view is that the hash function's output is a $b$-bit integer that\nis uniformly distributed in $\\{0, \\dots, 2^b-1\\}$, except that $p$ (the all\n\\texttt1s value in binary) is missing. Uniform bit strings have many nice\nproperties, such as splitting into substrings which gives us two or more hash\nfunctions for the cost of one, while preserving strong theoretical qualities.\nWe call this trick \"Two for one\" hashing, and we demonstrate it on 4-universal\nhashing in the classic Count Sketch algorithm for second-moment estimation.\n  We also provide a new fast branch-free code for division and modulus with\nMersenne primes. Contrasting our analytic work, this code generalizes to any\nPseudo-Mersenne primes $p=2^b-c$ for small $c$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:04:36 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:58:55 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ahle", "Thomas Dybdahl", ""], ["Knudsen", "Jakob Tejs B\u00e6k", ""], ["Thorup", "Mikkel", ""]]}, {"id": "2008.08739", "submitter": "Dingyu Wang", "authors": "Seth Pettie, Dingyu Wang and Longhui Yin", "title": "Non-Mergeable Sketching for Cardinality Estimation", "comments": "26 pages, 8 figures, submitted to ICALP21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality estimation is perhaps the simplest non-trivial statistical\nproblem that can be solved via sketching. Industrially-deployed sketches like\nHyperLogLog, MinHash, and PCSA are mergeable, which means that large data sets\ncan be sketched in a distributed environment, and then merged into a single\nsketch of the whole data set. In the last decade a variety of sketches have\nbeen developed that are non-mergeable, but attractive for other reasons. They\nare simpler, their cardinality estimates are strictly unbiased, and they have\nsubstantially lower variance.\n  We evaluate sketching schemes on a reasonably level playing field, in terms\nof their memory-variance product (MVP). E.g., a sketch that occupies $5m$ bits\nand whose relative variance is $2/m$ (standard error $\\sqrt{2/m}$) has an MVP\nof $10$. Our contributions are as follows.\n  Cohen and Ting independently discovered what we call the Martingale transform\nfor converting a mergeable sketch into a non-mergeable sketch. We present a\nsimpler way to analyze the limiting MVP of Martingale-type sketches.\n  We prove that the \\Martingale{} transform is optimal in the non-mergeable\nworld, and that \\Martingale{} \\fishmonger{} in particular is optimal among\nlinearizable sketches, with an MVP of $H_0/2 \\approx 1.63$. E.g., this is\ncircumstantial evidence that to achieve 1\\% standard error, we cannot do better\nthan a 2 kilobyte sketch.\n  \\Martingale{} \\fishmonger{} is neither simple nor practical. We develop a new\nmergeable sketch called \\Curtain{} that strikes a nice balance between\nsimplicity and efficiency, and prove that \\Martingale{} \\Curtain{} has limiting\n$\\MVP\\approx 2.31$. It can be updated with $O(1)$ memory accesses and it has\nlower empirical variance than \\Martingale{} \\LogLog, a practical non-mergeable\nversion of HyperLogLog.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:42:18 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 23:33:50 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Pettie", "Seth", ""], ["Wang", "Dingyu", ""], ["Yin", "Longhui", ""]]}, {"id": "2008.08748", "submitter": "Vu Hoang Nguyen Phan", "authors": "Jeffrey M. Dudek, Vu H. N. Phan, Moshe Y. Vardi", "title": "DPMC: Weighted Model Counting by Dynamic Programming on Project-Join\n  Trees", "comments": "Full version of paper at CP 2020 (26th International Conference on\n  Principles and Practice of Constraint Programming)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unifying dynamic-programming framework to compute exact\nliteral-weighted model counts of formulas in conjunctive normal form. At the\ncenter of our framework are project-join trees, which specify efficient\nproject-join orders to apply additive projections (variable eliminations) and\njoins (clause multiplications). In this framework, model counting is performed\nin two phases. First, the planning phase constructs a project-join tree from a\nformula. Second, the execution phase computes the model count of the formula,\nemploying dynamic programming as guided by the project-join tree. We\nempirically evaluate various methods for the planning phase and compare\nconstraint-satisfaction heuristics with tree-decomposition tools. We also\ninvestigate the performance of different data structures for the execution\nphase and compare algebraic decision diagrams with tensors. We show that our\ndynamic-programming model-counting framework DPMC is competitive with the\nstate-of-the-art exact weighted model counters cachet, c2d, d4, and miniC2D.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:09:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Phan", "Vu H. N.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2008.08811", "submitter": "Anjeneya Swami Kare Dr.", "authors": "Rahul Kumar Gautam, Anjeneya Swami Kare, S. Durga Bhavani", "title": "Faster Heuristics for Graph Burning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph burning is a process of information spreading through the network by an\nagent in discrete steps. The problem is to find an optimal sequence of nodes\nwhich have to be given information so that the network is covered in least\nnumber of steps. Graph burning problem is NP-Hard for which two approximation\nalgorithms and a few heuristics have been proposed in the literature. In this\nwork, we propose three heuristics, namely, Backbone Based Greedy Heuristic\n(BBGH), Improved Cutting Corners Heuristic (ICCH) and Component Based Recursive\nHeuristic (CBRH). These are mainly based on Eigenvector centrality measure.\nBBGH finds a backbone of the network and picks vertex to be burned greedily\nfrom the vertices of the backbone. ICCH is a shortest path based heuristic and\npicks vertex to burn greedily from best central nodes. The burning number\nproblem on disconnected graphs is harder than on the connected graphs. For\nexample, burning number problem is easy on a path where as it is NP-Hard on\ndisjoint paths. In practice, large networks are generally disconnected and\nmoreover even if the input graph is connected, during the burning process the\ngraph among the unburned vertices may be disconnected. For disconnected graphs,\nordering of the components is crucial. Our CBRH works well on disconnected\ngraphs as it prioritizes the components. All the heuristics have been\nimplemented and tested on several bench-mark networks including large networks\nof size more than $50$K nodes. The experimentation also includes comparison to\nthe approximation algorithms. The advantages of our algorithms are that they\nare much simpler to implement and also several orders faster than the\nheuristics proposed in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:32:32 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Gautam", "Rahul Kumar", ""], ["Kare", "Anjeneya Swami", ""], ["Bhavani", "S. Durga", ""]]}, {"id": "2008.09004", "submitter": "Daniel Paulusma", "authors": "Flavia Bonomo-Braberman and Nick Brettell and Andrea Munaro and\n  Dani\\\"el Paulusma", "title": "Solving Problems on Generalized Convex Graphs via Mim-Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bipartite graph $G=(A,B,E)$ is ${\\cal H}$-convex, for some family of graphs\n${\\cal H}$, if there exists a graph $H\\in {\\cal H}$ with $V(H)=A$ such that the\nset of neighbours in $A$ of each $b\\in B$ induces a connected subgraph of $H$.\nMany $\\mathsf{NP}$-complete problems, including problems such as Dominating\nSet, Feedback Vertex Set, Induced Matching and List $k$-Colouring, become\npolynomial-time solvable for ${\\mathcal H}$-convex graphs when ${\\mathcal H}$\nis the set of paths. In this case, the class of ${\\mathcal H}$-convex graphs is\nknown as the class of convex graphs. The underlying reason is that the class of\nconvex graphs has bounded mim-width. We extend the latter result to families of\n${\\mathcal H}$-convex graphs where (i) ${\\mathcal H}$ is the set of cycles, or\n(ii) ${\\mathcal H}$ is the set of trees with bounded maximum degree and a\nbounded number of vertices of degree at least $3$. As a consequence, we can\nre-prove and strengthen a large number of results on generalized convex graphs\nknown in the literature. To complement result (ii), we show that the mim-width\nof ${\\mathcal H}$-convex graphs is unbounded if ${\\mathcal H}$ is the set of\ntrees with arbitrarily large maximum degree or an arbitrarily large number of\nvertices of degree at least $3$. In this way we are able to determine\ncomplexity dichotomies for the aforementioned graph problems. Afterwards we\nperform a more refined width-parameter analysis, which shows even more clearly\nwhich width parameters are bounded for classes of ${\\cal H}$-convex graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:47:54 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 23:18:39 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bonomo-Braberman", "Flavia", ""], ["Brettell", "Nick", ""], ["Munaro", "Andrea", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "2008.09008", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Akhoondian Amiri", "title": "On Fine-Grained Exact Computation in Regular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is no subexponential time algorithm for computing the\nexact solution of the maximum independent set problem in d-regular graphs\nunless ETH fails. We expand our method to show that it helps to provide lower\nbounds for other covering problems such as vertex cover and clique. We utilize\nthe construction to show the NP-hardness of MIS on 5-regular planar graphs,\nclosing the exact complexity status of the problem on regular planar graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:55:57 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 10:40:10 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""]]}, {"id": "2008.09260", "submitter": "Calum MacRury", "authors": "Allan Borodin, Calum MacRury and Akash Rakheja", "title": "Greedy Approaches to Online Stochastic Matching", "comments": "Updated the paper to include a result for edge weights, and\n  generalized our results to downward-closed probing constraints. arXiv admin\n  note: text overlap with arXiv:2004.14304", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of stochastic probing with commitment, we consider the\nonline stochastic matching problem; that is, the one-sided online bipartite\nmatching problem where edges adjacent to an online node must be probed to\ndetermine if they exist based on edge probabilities that become known when an\nonline vertex arrives. If a probed edge exists, it must be used in the matching\n(if possible). We consider the competitiveness of online algorithms in both the\nadversarial order model (AOM) and the random order model (ROM). More\nspecifically, we consider a bipartite stochastic graph $G = (U,V,E)$ where $U$\nis the set of offline vertices, $V$ is the set of online vertices and $G$ has\nedge probabilities $(p_{e})_{e \\in E}$ and edge weights $(w_{e})_{e \\in E}$.\nAdditionally, $G$ has probing constraints $(\\scr{C}_{v})_{v \\in V}$, where\n$\\scr{C}_v$ indicates which sequences of edges adjacent to an online vertex $v$\ncan be probed. We assume that $U$ is known in advance, and that $\\scr{C}_v$,\ntogether with the edge probabilities and weights adjacent to an online vertex\nare only revealed when the online vertex arrives. This model generalizes the\nvarious settings of the classical bipartite matching problem, and so our main\ncontribution is in making progress towards understanding which classical\nresults extend to the stochastic probing model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 01:46:00 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 00:13:27 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Borodin", "Allan", ""], ["MacRury", "Calum", ""], ["Rakheja", "Akash", ""]]}, {"id": "2008.09299", "submitter": "Aleksandar Ilic", "authors": "Aleksandar Ilic", "title": "Optimal algorithm for computing Steiner 3-eccentricities of trees", "comments": "Merged into another paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Steiner $k$-eccentricity of a vertex $v$ of a graph $G$ is the maximum\nSteiner distance over all $k$-subsets of $V (G)$ which contain $v$. In this\nnote, we design a linear algorithm for computing the Steiner $3$-eccentricities\nand the connective Steiner $3$-eccentricity index on a tree and thus improving\na quadratic algorithm presented in [G. Yu, X. Li, \\emph{Connective Steiner\n3-eccentricity index and network similarity measure}, Appl. Math. Comput. 386\n(2020), 125446.]\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 04:17:49 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 21:03:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ilic", "Aleksandar", ""]]}, {"id": "2008.09329", "submitter": "Henry F\\\"orster", "authors": "Patrizio Angelini, Giordano Da Lozzo, Henry F\\\"orster and Thomas\n  Schneck", "title": "$2$-Layer $k$-Planar Graphs: Density, Crossing Lemma, Relationships, and\n  Pathwidth", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $2$-layer drawing model is a well-established paradigm to visualize\nbipartite graphs. Several beyond-planar graph classes have been studied under\nthis model. Surprisingly, however, the fundamental class of $k$-planar graphs\nhas been considered only for $k=1$ in this context. We provide several\ncontributions that address this gap in the literature. First, we show tight\ndensity bounds for the classes of $2$-layer $k$-planar graphs with\n$k\\in\\{2,3,4,5\\}$. Based on these results, we provide a Crossing Lemma for\n$2$-layer $k$-planar graphs, which then implies a general density bound for\n$2$-layer $k$-planar graphs. We prove this bound to be almost optimal with a\ncorresponding lower bound construction. Finally, we study relationships between\n$k$-planarity and $h$-quasiplanarity in the $2$-layer model and show that\n$2$-layer $k$-planar graphs have pathwidth at most $k+1$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 06:43:12 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Angelini", "Patrizio", ""], ["Da Lozzo", "Giordano", ""], ["F\u00f6rster", "Henry", ""], ["Schneck", "Thomas", ""]]}, {"id": "2008.09414", "submitter": "Fabrizio Frati", "authors": "Giuseppe Di Battista, Fabrizio Frati, Maurizio Patrignani, Marco Tais", "title": "Schematic Representation of Large Biconnected Graphs", "comments": "Appeared in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that a biconnected graph is given, consisting of a large component\nplus several other smaller components, each separated from the main component\nby a separation pair. We investigate the existence and the computation time of\nschematic representations of the structure of such a graph where the main\ncomponent is drawn as a disk, the vertices that take part in separation pairs\nare points on the boundary of the disk, and the small components are placed\noutside the disk and are represented as non-intersecting lunes connecting their\nseparation pairs. We consider several drawing conventions for such schematic\nrepresentations, according to different ways to account for the size of the\nsmall components. We map the problem of testing for the existence of such\nrepresentations to the one of testing for the existence of suitably constrained\n$1$-page book-embeddings and propose several polynomial-time algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:46:53 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 16:45:42 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 17:12:43 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Di Battista", "Giuseppe", ""], ["Frati", "Fabrizio", ""], ["Patrignani", "Maurizio", ""], ["Tais", "Marco", ""]]}, {"id": "2008.09465", "submitter": "Maximilian Weininger", "authors": "Jan Kretinsky and Emanuel Ramneantu and Alexander Slivinskiy and\n  Maximilian Weininger", "title": "Comparison of Algorithms for Simple Stochastic Games (Full Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple stochastic games are turn-based 2.5-player zero-sum graph games with a\nreachability objective. The problem is to compute the winning probability as\nwell as the optimal strategies of both players. In this paper, we compare the\nthree known classes of algorithms -- value iteration, strategy iteration and\nquadratic programming -- both theoretically and practically. Further, we\nsuggest several improvements for all algorithms, including the first approach\nbased on quadratic programming that avoids transforming the stochastic game to\na stopping one. Our extensive experiments show that these improvements can lead\nto significant speed-ups. We implemented all algorithms in PRISM-games 3.0,\nthereby providing the first implementation of quadratic programming for solving\nsimple stochastic games.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:24:44 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 13:06:36 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 08:30:00 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kretinsky", "Jan", ""], ["Ramneantu", "Emanuel", ""], ["Slivinskiy", "Alexander", ""], ["Weininger", "Maximilian", ""]]}, {"id": "2008.09607", "submitter": "Magnus Lie Hetland", "authors": "Magnus Lie Hetland", "title": "Optimal Metric Search Is Equivalent to the Minimum Dominating Set\n  Problem", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-60936-8_9", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In metric search, worst-case analysis is of little value, as the search\ninvariably degenerates to a linear scan for ill-behaved data. Consequently,\nmuch effort has been expended on more nuanced descriptions of what performance\nmight in fact be attainable, including heuristic baselines like the AESA\nfamily, as well as statistical proxies such as intrinsic dimensionality. This\npaper gets to the heart of the matter with an exact characterization of the\nbest performance actually achievable for any given data set and query.\nSpecifically, linear-time objective-preserving reductions are established in\nboth directions between optimal metric search and the minimum dominating set\nproblem, whose greedy approximation becomes the equivalent of an oracle-based\nAESA, repeatedly selecting the pivot that eliminates the most of the remaining\npoints. As an illustration, the AESA heuristic is adapted to downplay the role\nof previously eliminated points, yielding some modest performance improvements\nover the original, as well as its younger relative iAESA2.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:59:41 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hetland", "Magnus Lie", ""]]}, {"id": "2008.09654", "submitter": "Magnus Lie Hetland", "authors": "Magnus Lie Hetland", "title": "Metrics and Ambits and Sprawls, Oh My", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-60936-8_10", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A follow-up to my previous tutorial on metric indexing, this paper walks\nthrough the classic structures, placing them all in the context of the recently\nproposed \"sprawl of ambits\" framework. The indexes are presented as\nconfigurations of a single, more general structure, all queried using the same\nsearch procedure.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:11:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hetland", "Magnus Lie", ""]]}, {"id": "2008.09660", "submitter": "Akash Kumar", "authors": "Akash Kumar and Mithilesh Kumar", "title": "Deletion to Induced Matching", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the DELETION TO INDUCED MATCHING problem, we are given a graph $G$ on $n$\nvertices, $m$ edges and a non-negative integer $k$ and asks whether there\nexists a set of vertices $S \\subseteq V(G) $ such that $|S|\\le k$ and the size\nof any connected component in $G-S$ is exactly 2. In this paper, we provide a\nfixed-parameter tractable (FPT) algorithm of running time $O^*(1.748^{k})$ for\nthe DELETION TO INDUCED MATCHING problem using branch-and-reduce strategy and\npath decomposition. We also extend our work to the exact-exponential version of\nthe problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:30:18 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 16:51:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kumar", "Akash", ""], ["Kumar", "Mithilesh", ""]]}, {"id": "2008.09806", "submitter": "Pratibha Choudhary", "authors": "Pratibha Choudhary and Venkatesh Raman", "title": "Structural Parameterizations of Tracking Paths Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$ with source and destination vertices $s,t\\in V(G)$\nrespectively, \\textsc{Tracking Paths} asks for a minimum set of vertices\n$T\\subseteq V(G)$, such that the sequence of vertices encountered in each\nsimple path from $s$ to $t$ is unique. The problem was proven \\textsc{NP}-hard\n\\cite{tr-j} and was found to admit a quadratic kernel when parameterized by the\nsize of the desired solution \\cite{quadratic}. Following recent trends, for the\nfirst time, we study \\textsc{Tracking Paths} with respect to structural\nparameters of the input graph, parameters that measure how far the input graph\nis, from an easy instance. We prove that \\textsc{Tracking Paths} admits\nfixed-parameter tractable (\\textsc{FPT}) algorithms when parameterized by the\nsize of vertex cover, and the size of cluster vertex deletion set for the input\ngraph.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 10:54:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Choudhary", "Pratibha", ""], ["Raman", "Venkatesh", ""]]}, {"id": "2008.09822", "submitter": "Zijian Xu", "authors": "Zijian Xu, Vorapong Suppakitpaisarn", "title": "On the Size of Minimal Separators for Treedepth Decomposition", "comments": "The major changes from the first version are as follows. (1) The\n  conjecture was resolved and the upper bound was slightly improved. (2) The\n  experimental results were not correct and were removed. Specifically, there\n  was a problem in the separator enumeration when we extended SMS [Korhonen\n  2020]. In some inputs, none of the optimal top separators were computed even\n  if the upper bound was relaxed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treedepth decomposition has several practical applications and can be used to\nspeed up many parameterized algorithms. There are several works aiming to\ndesign a scalable algorithm to compute exact treedepth decompositions. Those\ninclude works based on a set of all minimal separators. In those algorithms,\nalthough a number of minimal separators are enumerated, the minimal separators\nthat are used for an optimal solution are empirically very small. Therefore,\nanalyzing the upper bound on the size of minimal separators is an important\nproblem because it has the potential to significantly reduce the computation\ntime. A minimal separator $S$ is called an optimal top separator if $td(G) =\n|S| + td(G \\backslash S)$, where $td(G)$ denotes the treedepth of $G$. Then, we\nhave two theoretical results on the size of optimal top separators. (1) For any\n$G$, there is an optimal top separator $S$ such that $|S| \\le 2tw(G)$, where\n$tw(G)$ is the treewidth of $G$. (2) For any $c < 2$, there exists a graph $G$\nsuch that any optimal top separator $S$ of $G$ have $|S| > c \\cdot tw(G)$,\ni.e., the first result gives a tight bound on the size of an optimal top\nseparator.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 12:09:55 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:25:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Xu", "Zijian", ""], ["Suppakitpaisarn", "Vorapong", ""]]}, {"id": "2008.09877", "submitter": "Yuval Gitlitz", "authors": "Michael Elkin, Yuval Gitlitz, Ofer Neiman", "title": "Improved Weighted Additive Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph spanners and emulators are sparse structures that approximately\npreserve distances of the original graph. While there has been an extensive\namount of work on additive spanners, so far little attention was given to\nweighted graphs. Only very recently [ABSKS20] extended the classical +2\n(respectively, +4) spanners for unweighted graphs of size $O(n^{3/2})$ (resp.,\n$O(n^{7/5})$) to the weighted setting, where the additive error is $+2W$\n(resp., $+4W$). This means that for every pair $u,v$, the additive stretch is\nat most $+2W_{u,v}$, where $W_{u,v}$ is the maximal edge weight on the shortest\n$u-v$ path. In addition, [ABSKS20] showed an algorithm yielding a $+8W_{max}$\nspanner of size $O(n^{4/3})$, here $W_{max}$ is the maximum edge weight in the\nentire graph.\n  In this work we improve the latter result by devising a simple deterministic\nalgorithm for a $+(6+\\varepsilon)W$ spanner for weighted graphs with size\n$O(n^{4/3})$ (for any constant $\\varepsilon>0$), thus nearly matching the\nclassical +6 spanner of size $O(n^{4/3})$ for unweighted graphs. Furthermore,\nwe show a $+(2+\\varepsilon)W$ subsetwise spanner of size $O(n\\cdot\\sqrt{|S|})$,\nimproving the $+4W_{max}$ result of [ABSKS20] (that had the same size). We also\nshow a simple randomized algorithm for a $+4W$ emulator of size\n$\\tilde{O}(n^{4/3})$.\n  In addition, we show that our technique is applicable for very sparse\nadditive spanners, that have linear size. For weighted graphs, we use a variant\nof our simple deterministic algorithm that yields a linear size\n$+\\tilde{O}(\\sqrt{n}\\cdot W)$ spanner, and we also obtain a tradeoff between\nsize and stretch.\n  Finally, generalizing the technique of [DHZ00] for unweighted graphs, we\ndevise an efficient randomized algorithm producing a $+2W$ spanner for weighted\ngraphs of size $\\tilde{O}(n^{3/2})$ in $\\tilde{O}(n^2)$ time.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:06:50 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 07:53:53 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Elkin", "Michael", ""], ["Gitlitz", "Yuval", ""], ["Neiman", "Ofer", ""]]}, {"id": "2008.09921", "submitter": "Arash Rafiey", "authors": "Jeff Kinne, Ashwin Murali, Arash Rafiey", "title": "Digraphs Homomorphism Problems with Maltsev Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of finding a homomorphism from an input digraph\n$G$ to a fixed digraph $H$, HOM($H$). In this setting, we are given an input\ndigraph $G$ together with a list function from $G$ to $2^H$. The goal is to\nfind a homomorphism from $G$ to $H$ with respect to the lists if one exists.\n  We show that if the list function is a Maltsev polymorphism then deciding\nwhether $G$ admits a homomorphism to $H$ is polynomial time solvable. In our\napproach, we only use the existence of the Maltsev polymorphism. Furthermore,\nwe show that deciding whether a relational structure $\\mathcal{R}$ admits a\nMaltsev polymorphism is a special case of finding a homormphism from a graph\n$G$ to a graph $H$ and a list function with a Maltsev polymorphism. Since the\nexistence of Maltsev is not required in our algorithm, we can decide in\npolynomial time whether the relational structure $\\mathcal{R}$ admits Maltsev\nor not.\n  We also discuss forbidden obstructions for the instances admitting Maltsev\nlist polymorphism. We have implemented our algorithm and tested on instances\narising from linear equations, and other types of instances.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 22:17:18 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 14:52:44 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kinne", "Jeff", ""], ["Murali", "Ashwin", ""], ["Rafiey", "Arash", ""]]}, {"id": "2008.10052", "submitter": "Motoki Ikeda", "authors": "Hiroshi Hirai, Motoki Ikeda", "title": "Node-Connectivity Terminal Backup, Separately-Capacitated Multiflow, and\n  Discrete Convexity", "comments": "A preliminary version of this paper was appeared in the proceedings\n  of the 47th International Colloquium on Automata, Languages and Programming\n  (ICALP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The terminal backup problems (Anshelevich and Karagiozova (2011)) form a\nclass of network design problems: Given an undirected graph with a requirement\non terminals, the goal is to find a minimum cost subgraph satisfying the\nconnectivity requirement. The node-connectivity terminal backup problem\nrequires a terminal to connect other terminals with a number of node-disjoint\npaths. This problem is not known whether is NP-hard or tractable. Fukunaga\n(2016) gave a $4/3$-approximation algorithm based on LP-rounding scheme using a\ngeneral LP-solver. In this paper, we develop a combinatorial algorithm for the\nrelaxed LP to find a half-integral optimal solution in $O(m\\log (nUA)\\cdot\n\\operatorname{MF}(kn,m+k^2n))$ time, where $n$ is the number of nodes, $m$ is\nthe number of edges, $k$ is the number of terminals, $A$ is the maximum\nedge-cost, $U$ is the maximum edge-capacity, and $\\operatorname{MF}(n',m')$ is\nthe time complexity of a max-flow algorithm in a network with $n'$ nodes and\n$m'$ edges. The algorithm implies that the $4/3$-approximation algorithm for\nthe node-connectivity terminal backup problem is also efficiently implemented.\nFor the design of algorithm, we explore a connection between the\nnode-connectivity terminal backup problem and a new type of a multiflow, called\na separately-capacitated multiflow. We show a min-max theorem which extends\nLov\\'{a}sz-Cherkassky theorem to the node-capacity setting. Our results build\non discrete convexity in the node-connectivity terminal backup problem.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 14:45:42 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Hirai", "Hiroshi", ""], ["Ikeda", "Motoki", ""]]}, {"id": "2008.10062", "submitter": "Roie Levin", "authors": "Roie Levin and David Wajc", "title": "Streaming Submodular Matching Meets the Primal-Dual Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study streaming submodular maximization subject to matching/$b$-matching\nconstraints (MSM/MSbM), and present improved upper and lower bounds for these\nproblems. On the upper bounds front, we give primal-dual algorithms achieving\nthe following approximation ratios.\n  $\\bullet$ $3+2\\sqrt{2}\\approx 5.828$ for monotone MSM, improving the previous\nbest ratio of $7.75$.\n  $\\bullet$ $4+3\\sqrt{2}\\approx 7.464$ for non-monotone MSM, improving the\nprevious best ratio of $9.899$.\n  $\\bullet$ $3+\\epsilon$ for maximum weight b-matching, improving the previous\nbest ratio of $4+\\epsilon$.\n  On the lower bounds front, we improve on the previous best lower bound of\n$\\frac{e}{e-1}\\approx 1.582$ for MSM, and show ETH-based lower bounds of\n$\\approx 1.914$ for polytime monotone MSM streaming algorithms.\n  Our most substantial contributions are our algorithmic techniques. We show\nthat the (randomized) primal-dual method, which originated in the study of\nmaximum weight matching (MWM), is also useful in the context of MSM. To our\nknowledge, this is the first use of primal-dual based analysis for streaming\nsubmodular optimization. We also show how to reinterpret previous algorithms\nfor MSM in our framework; hence, we hope our work is a step towards unifying\nold and new techniques for streaming submodular maximization, and that it paves\nthe way for further new results.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 15:58:26 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 22:11:45 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Levin", "Roie", ""], ["Wajc", "David", ""]]}, {"id": "2008.10316", "submitter": "Maximilian B\\\"other", "authors": "Thomas Bl\\\"asius and Maximilian B\\\"other and Philipp Fischbeck and\n  Tobias Friedrich and Alina Gries and Falk H\\\"uffner and Otto Ki{\\ss}ig and\n  Pascal Lenzner and Louise Molitor and Leon Schiller and Armin Wells and Simon\n  Wietheger", "title": "A Strategic Routing Framework and Algorithms for Computing Alternative\n  Paths", "comments": "19 pages, 7 figures, full version of paper accepted at ATMOS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional navigation services find the fastest route for a single driver.\nThough always using the fastest route seems desirable for every individual,\nselfish behavior can have undesirable effects such as higher energy consumption\nand avoidable congestion, even leading to higher overall and individual travel\ntimes. In contrast, strategic routing aims at optimizing the traffic for all\nagents regarding a global optimization goal. We introduce a framework to\nformalize real-world strategic routing scenarios as algorithmic problems and\nstudy one of them, which we call Single Alternative Path (SAP), in detail.\nThere, we are given an original route between a single origin--destination\npair. The goal is to suggest an alternative route to all agents that optimizes\nthe overall travel time under the assumption that the agents distribute among\nboth routes according to a psychological model, for which we introduce the\nconcept of Pareto-conformity. We show that the SAP problem is NP-complete, even\nfor such models. Nonetheless, assuming Pareto-conformity, we give multiple\nalgorithms for different variants of SAP, using multi-criteria shortest path\nalgorithms as subroutines. Moreover, we prove that several natural models are\nin fact Pareto-conform. The implementation of our algorithms serves as a proof\nof concept, showing that SAP can be solved in reasonable time even though the\nalgorithms have exponential running time in the worst case.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 10:56:41 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bl\u00e4sius", "Thomas", ""], ["B\u00f6ther", "Maximilian", ""], ["Fischbeck", "Philipp", ""], ["Friedrich", "Tobias", ""], ["Gries", "Alina", ""], ["H\u00fcffner", "Falk", ""], ["Ki\u00dfig", "Otto", ""], ["Lenzner", "Pascal", ""], ["Molitor", "Louise", ""], ["Schiller", "Leon", ""], ["Wells", "Armin", ""], ["Wietheger", "Simon", ""]]}, {"id": "2008.10336", "submitter": "Michael Bekos", "authors": "Jawaherul Md. Alam, Michael A. Bekos, Martin Gronemann, Michael\n  Kaufmann, Sergey Pupyrev", "title": "Lazy Queue Layouts of Posets", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the queue number of posets in terms of their width, that is,\nthe maximum number of pairwise incomparable elements. A long-standing\nconjecture of Heath and Pemmaraju asserts that every poset of width w has queue\nnumber at most w. The conjecture has been confirmed for posets of width w=2 via\nso-called lazy linear extension.\n  We extend and thoroughly analyze lazy linear extensions for posets of width w\n> 2. Our analysis implies an upper bound of $(w-1)^2 +1$ on the queue number of\nwidth-w posets, which is tight for the strategy and yields an improvement over\nthe previously best-known bound. Further, we provide an example of a poset that\nrequires at least w+1 queues in every linear extension, thereby disproving the\nconjecture for posets of width w > 2.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:50:13 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 08:09:50 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Alam", "Jawaherul Md.", ""], ["Bekos", "Michael A.", ""], ["Gronemann", "Martin", ""], ["Kaufmann", "Michael", ""], ["Pupyrev", "Sergey", ""]]}, {"id": "2008.10406", "submitter": "Ido Zoref", "authors": "Ido Zoref and Ariel Orda", "title": "An Efficient Algorithm for Finding Sets of Optimal Routes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several important routing contexts it is required to identify a set of\nroutes, each of which optimizes a different criterion. For instance, in the\ncontext of vehicle routing, one route would minimize the total distance\ntraveled, while other routes would also consider the total travel time or the\ntotal incurred cost, or combinations thereof. In general, providing such a set\nof diverse routes is obtained by finding optimal routes with respect to\ndifferent sets of weights on the network edges. This can be simply achieved by\nconsecutively executing a standard shortest path algorithm. However, in the\ncase of a large number of weight sets, this may require an excessively large\nnumber of executions of such an algorithm, thus incurring a prohibitively large\nrunning time.\n  We indicate that, quite often, the different edge weights reflect different\ncombinations of some \"raw\" performance metrics (e.g., delay, cost). In such\ncases, there is an inherent dependency among the different weights of the same\nedge. This may well result in some similarity among the shortest routes, each\nof which being optimal with respect to a specific set of weights. In this\nstudy, we aim to exploit such similarity in order to improve the performance of\nthe solution scheme.\n  Specifically, we contemplate edge weights that are obtained through different\nlinear combinations of some (``raw'') edge performance metrics. We establish\nand validate a novel algorithm that efficiently computes a shortest path for\neach set of edge weights. We demonstrate that, under reasonable assumptions,\nthe algorithm significantly outperforms the standard approach. Similarly to the\nstandard approach, the algorithm iteratively searches for routes, one per set\nof edge weights; however, instead of executing each iteration independently, it\nreduces the average running time by skillfully sharing information among the\niterations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:06:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zoref", "Ido", ""], ["Orda", "Ariel", ""]]}, {"id": "2008.10526", "submitter": "Saeed Ghadimi", "authors": "Krishnakumar Balasubramanian, Saeed Ghadimi, Anthony Nguyen", "title": "Stochastic Multi-level Composition Optimization Algorithms with\n  Level-Independent Convergence Rates", "comments": "Refined the convergence analysis in Section 3 under weaker\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study smooth stochastic multi-level composition\noptimization problems, where the objective function is a nested composition of\n$T$ functions. We assume access to noisy evaluations of the functions and their\ngradients, through a stochastic first-order oracle. For solving this class of\nproblems, we propose two algorithms using moving-average stochastic estimates,\nand analyze their convergence to an $\\epsilon$-stationary point of the problem.\nWe show that the first algorithm, which is a generalization of\n\\cite{GhaRuswan20} to the $T$ level case, can achieve a sample complexity of\n$\\mathcal{O}(1/\\epsilon^6)$ by using mini-batches of samples in each iteration.\nBy modifying this algorithm using linearized stochastic estimates of the\nfunction values, we improve the sample complexity to\n$\\mathcal{O}(1/\\epsilon^4)$. {\\color{black}This modification not only removes\nthe requirement of having a mini-batch of samples in each iteration, but also\nmakes the algorithm parameter-free and easy to implement}. To the best of our\nknowledge, this is the first time that such an online algorithm designed for\nthe (un)constrained multi-level setting, obtains the same sample complexity of\nthe smooth single-level setting, under standard assumptions (unbiasedness and\nboundedness of the second moments) on the stochastic first-order oracle.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:57:50 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:59:02 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 04:36:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Nguyen", "Anthony", ""]]}, {"id": "2008.10577", "submitter": "Karl Bringmann", "authors": "Kyriakos Axiotis, Arturs Backurs, Karl Bringmann, Ce Jin, Vasileios\n  Nakos, Christos Tzamos, Hongxun Wu", "title": "Fast and Simple Modular Subset Sum", "comments": "accepted at SOSA'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Subset Sum problem over the finite cyclic group $\\mathbb{Z}_m$\nfor some given integer $m$. A series of recent works has provided near-optimal\nalgorithms for this problem under the Strong Exponential Time Hypothesis.\nKoiliaris and Xu (SODA'17, TALG'19) gave a deterministic algorithm running in\ntime $\\tilde{O}(m^{5/4})$, which was later improved to $O(m \\log^7 m)$\nrandomized time by Axiotis et al. (SODA'19).\n  In this work, we present two simple algorithms for the Modular Subset Sum\nproblem running in near-linear time in $m$, both efficiently implementing\nBellman's iteration over $\\mathbb{Z}_m$. The first one is a randomized\nalgorithm running in time $O(m \\log^2 m)$, that is based solely on rolling hash\nand an elementary data-structure for prefix sums; to illustrate its simplicity\nwe provide a short and efficient implementation of the algorithm in Python. Our\nsecond solution is a deterministic algorithm running in time $O(m\\\n\\mathrm{polylog}\\ m)$, that uses dynamic data structures for string\nmanipulation.\n  We further show that the techniques developed in this work can also lead to\nsimple algorithms for the All Pairs Non-Decreasing Paths Problem (APNP) on\nundirected graphs, matching the near-optimal running time of $\\tilde{O}(n^2)$\nprovided in the recent work of Duan et al. (ICALP'19).\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:29:44 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:39:37 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 10:53:56 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Axiotis", "Kyriakos", ""], ["Backurs", "Arturs", ""], ["Bringmann", "Karl", ""], ["Jin", "Ce", ""], ["Nakos", "Vasileios", ""], ["Tzamos", "Christos", ""], ["Wu", "Hongxun", ""]]}, {"id": "2008.10582", "submitter": "Hung Le", "authors": "Hung Le and Shay Solomon", "title": "A Unified and Fine-Grained Approach for Light Spanners", "comments": "Major revision with new results, 27 figures, 82 pages, abstract\n  shorten to meet 1920 character constraint of Arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seminal works on light spanners from recent years provide near-optimal\ntradeoffs between the stretch and lightness of spanners in general graphs,\nminor-free graphs, and doubling metrics. In FOCS'19 the authors provided a\n``truly optimal'' tradeoff for Euclidean low-dimensional spaces. Some of these\npapers employ inherently different techniques than others. Moreover, the\nruntime of these constructions is rather high.\n  In this work, we present a unified and fine-grained approach for light\nspanners. Besides the obvious theoretical importance of unification, we\ndemonstrate the power of our approach in obtaining (1) stronger lightness\nbounds, and (2) faster construction times. Our results include:\n  _ $K_r$-minor-free graphs: A truly optimal spanner construction and a fast\nconstruction.\n  _ General graphs: A truly optimal spanner -- almost and a linear-time\nconstruction with near-optimal lightness.\n  _ Low dimensional Euclidean spaces: We demonstrate that Steiner points help\nin reducing the lightness of Euclidean $1+\\epsilon$-spanners almost\nquadratically for $d\\geq 3$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:46:54 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 16:15:24 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Le", "Hung", ""], ["Solomon", "Shay", ""]]}, {"id": "2008.10583", "submitter": "Johannes Zink", "authors": "Julian Walter, Johannes Zink, Joachim Baumeister, Alexander Wolff", "title": "Layered Drawing of Undirected Graphs with Generalized Port Constraints", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this research is a practical method to draw cable plans of complex\nmachines. Such plans consist of electronic components and cables connecting\nspecific ports of the components. Since the machines are configured for each\nclient individually, cable plans need to be drawn automatically. The drawings\nmust be well readable so that technicians can use them to debug the machines.\nIn order to model plug sockets, we introduce port groups; within a group, ports\ncan change their position (which we use to improve the aesthetics of the\nlayout), but together the ports of a group must form a contiguous block.\n  We approach the problem of drawing such cable plans by extending the\nwell-known Sugiyama framework such that it incorporates ports and port groups.\nSince the framework assumes directed graphs, we propose several ways to orient\nthe edges of the given undirected graph. We compare these methods\nexperimentally, both on real-world data and synthetic data that carefully\nsimulates real-world data. We measure the aesthetics of the resulting drawings\nby counting bends and crossings. Using these metrics, we compare our approach\nto Kieler [JVLC 2014], a library for drawing graphs in the presence of port\nconstraints.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:47:52 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 23:35:31 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Walter", "Julian", ""], ["Zink", "Johannes", ""], ["Baumeister", "Joachim", ""], ["Wolff", "Alexander", ""]]}, {"id": "2008.10709", "submitter": "Jonathan Tidor", "authors": "Aaron Berger, William Kuszmaul, Adam Polak, Jonathan Tidor, Nicole\n  Wein", "title": "Algorithms and Lower Bounds for the Worker-Task Assignment Problem", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of assigning workers to tasks where each task has demand\nfor a particular number of workers, and the demands are dynamically changing\nover time. Specifically, a worker-task assignment function $\\phi$ takes a\nmultiset of $w$ tasks $T \\subseteq [t]$ and produces an assignment $\\phi(T)$\nfrom the workers $1, 2, \\ldots, w$ to the tasks $T$. The assignment function\n$\\phi$ is said to have switching cost at most $k$ if, for all task multisets\n$T$, changing the contents of $T$ by one task changes $\\phi(T)$ by at most $k$\nworker assignments. The goal of the worker-task assignment problem is to\nproduce an assignment function $\\phi$ with the minimum possible switching cost.\n  Prior work on this problem (SSS'17, ICALP'20) observed a simple assignment\nfunction $\\phi$ with switching cost $\\min(w, t - 1)$, but there has been no\nsuccess in constructing $\\phi$ with sublinear switching cost. We construct the\nfirst assignment function $\\phi$ with sublinear, and in fact polylogarithmic,\nswitching cost. We give a probabilistic construction for $\\phi$ that achieves\nswitching cost $O(\\log w \\log (wt))$ and an explicit construction that achieves\nswitching cost $\\operatorname{polylog} (wt)$.\n  From the lower bounds side, prior work has used involved arguments to prove\nconstant lower bounds on switching cost, but no super-constant lower bounds are\nknown. We prove the first super-constant lower bound on switching cost. In\nparticular, we show that for any value of $w$ there exists a value of $t$ for\nwhich the optimal switching cost is $w$. That is, when $w \\ll t$, the trivial\nbound on switching cost is optimal.\n  We also consider an application of the worker-task assignment problem to a\nmetric embeddings problem. In particular, we use our results to give the first\nlow-distortion embedding from sparse binary vectors into low-dimensional\nHamming space.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:07:39 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Berger", "Aaron", ""], ["Kuszmaul", "William", ""], ["Polak", "Adam", ""], ["Tidor", "Jonathan", ""], ["Wein", "Nicole", ""]]}, {"id": "2008.10828", "submitter": "Ishita Doshi", "authors": "Ishita Doshi, Sreekalyan Sajjalla, Jayesh Choudhari, Rushi Bhatt,\n  Anirban Dasgupta", "title": "Efficient Hierarchical Clustering for Classification and Anomaly\n  Detection", "comments": "19 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of large scale real-time classification of content\nposted on social networks, along with the need to rapidly identify novel spam\ntypes. Obtaining manual labels for user-generated content using editorial\nlabeling and taxonomy development lags compared to the rate at which new\ncontent type needs to be classified. We propose a class of hierarchical\nclustering algorithms that can be used both for efficient and scalable\nreal-time multiclass classification as well as in detecting new anomalies in\nuser-generated content. Our methods have low query time, linear space usage,\nand come with theoretical guarantees with respect to a specific hierarchical\nclustering cost function (Dasgupta, 2016). We compare our solutions against a\nrange of classification techniques and demonstrate excellent empirical\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 05:48:32 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Doshi", "Ishita", ""], ["Sajjalla", "Sreekalyan", ""], ["Choudhari", "Jayesh", ""], ["Bhatt", "Rushi", ""], ["Dasgupta", "Anirban", ""]]}, {"id": "2008.10895", "submitter": "Zhaohua Chen", "authors": "Zhaohua Chen, Guang Yang", "title": "Decentralized Asset Custody Scheme with Security against Rational\n  Adversary", "comments": "40 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asset custody is a core financial service in which the custodian holds\nin-safekeeping assets on behalf of the client. Although traditional custody\nservice is typically endorsed by centralized authorities, decentralized custody\nscheme has become technically feasible since the emergence of digital assets,\nand furthermore, it is greatly needed by new applications such as blockchain\nand DeFi (Decentralized Finance).\n  In this work, we propose a framework of decentralized asset custody scheme\nthat is able to support a large number of custodians and safely hold customer\nassets of multiple times the value of the total security deposit. The proposed\ncustody scheme distributes custodians and assets into many custodian groups via\ncombinatorial designs, where each group fully controls the assigned assets.\nSince every custodian group is small, the overhead cost is significantly\nreduced. The liveness is also improved because even a single alive group would\nbe able to process transactions.\n  The security of this custody scheme is guaranteed under the rational\nadversary model, such that any adversary corrupting a bounded fraction of\ncustodians cannot move assets more than the security deposit paid. We further\nanalyze the security and performance of our constructions from both theoretical\nand experimental sides and give explicit examples with concrete numbers and\nfigures for a better understanding of our results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:08:54 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:46:24 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 09:32:41 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Zhaohua", ""], ["Yang", "Guang", ""]]}, {"id": "2008.10898", "submitter": "Zhize Li", "authors": "Zhize Li, Hongyan Bao, Xiangliang Zhang, Peter Richt\\'arik", "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for\n  Nonconvex Optimization", "comments": "25 pages; accepted by ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:11:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 18:25:41 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 21:37:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhize", ""], ["Bao", "Hongyan", ""], ["Zhang", "Xiangliang", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2008.10932", "submitter": "Kathrin Hanauer", "authors": "Kathrin Hanauer, Christian Schulz, Jonathan Trummer", "title": "O'Reach: Even Faster Reachability in Large Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental problems in computer science is the reachability\nproblem: Given a directed graph and two vertices s and t, can s reach t via a\npath? We revisit existing techniques and combine them with new approaches to\nsupport a large portion of reachability queries in constant time using a\nlinear-sized reachability index. Our new algorithm O'Reach can be easily\ncombined with previously developed solutions for the problem or run standalone.\n  In a detailed experimental study, we compare a variety of algorithms with\nrespect to their index-building and query times as well as their memory\nfootprint on a diverse set of instances. Our experiments indicate that the\nquery performance often depends strongly not only on the type of graph, but\nalso on the result, i.e., reachable or unreachable. Furthermore, we show that\nprevious algorithms are significantly sped up when combined with our new\napproach in almost all scenarios. Surprisingly, due to cache effects, a higher\ninvestment in space doesn't necessarily pay off: Reachability queries can often\nbe answered even faster than single memory accesses in a precomputed full\nreachability matrix.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:34:55 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 17:58:31 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hanauer", "Kathrin", ""], ["Schulz", "Christian", ""], ["Trummer", "Jonathan", ""]]}, {"id": "2008.11235", "submitter": "Stefan Zellmann", "authors": "Stefan Zellmann and Martin Weier and Ingo Wald", "title": "Accelerating Force-Directed Graph Drawing with RT Cores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph drawing with spring embedders employs a V x V computation phase over\nthe graph's vertex set to compute repulsive forces. Here, the efficacy of\nforces diminishes with distance: a vertex can effectively only influence other\nvertices in a certain radius around its position. Therefore, the algorithm\nlends itself to an implementation using search data structures to reduce the\nruntime complexity. NVIDIA RT cores implement hierarchical tree traversal in\nhardware. We show how to map the problem of finding graph layouts with\nforce-directed methods to a ray tracing problem that can subsequently be\nimplemented with dedicated ray tracing hardware. With that, we observe speedups\nof 4x to 13x over a CUDA software implementation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:57:54 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Zellmann", "Stefan", ""], ["Weier", "Martin", ""], ["Wald", "Ingo", ""]]}, {"id": "2008.11315", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet", "title": "Inapproximability of Diameter in super-linear time: Beyond the 5/3 ratio", "comments": "13 pages, 4 figures, expanded introduction and discussion on\n  follow-up works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show, assuming the Strong Exponential Time Hypothesis, that for every\n$\\varepsilon > 0$, approximating directed Diameter on $m$-arc graphs within\nratio $7/4 - \\varepsilon$ requires $m^{4/3 - o(1)}$ time. Our construction uses\nnonnegative edge weights but even holds for sparse digraphs, i.e., for which\nthe number of vertices $n$ and the number of arcs $m$ satisfy $m = n\n\\log^{O(1)} n$. This is the first result that conditionally rules out a\nnear-linear time $5/3$-approximation for Diameter.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 00:28:52 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 00:55:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bonnet", "\u00c9douard", ""]]}, {"id": "2008.11321", "submitter": "Maciej Besta", "authors": "Maciej Besta, Armon Carigiet, Zur Vonarburg-Shmaria, Kacper Janda,\n  Lukas Gianinazzi, Torsten Hoefler", "title": "High-Performance Parallel Graph Coloring with Strong Guarantees on Work,\n  Depth, and Quality", "comments": null, "journal-ref": "Proceedings of the ACM/IEEE International Conference on High\n  Performance Computing, Networking, Storage and Analysis (SC20), November 2020", "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the first parallel graph coloring heuristics with strong\ntheoretical guarantees on work and depth and coloring quality. The key idea is\nto design a relaxation of the vertex degeneracy order, a well-known graph\ntheory concept, and to color vertices in the order dictated by this relaxation.\nThis introduces a tunable amount of parallelism into the degeneracy ordering\nthat is otherwise hard to parallelize. This simple idea enables significant\nbenefits in several key aspects of graph coloring. For example, one of our\nalgorithms ensures polylogarithmic depth and a bound on the number of used\ncolors that is superior to all other parallelizable schemes, while maintaining\nwork-efficiency. In addition to provable guarantees, the developed algorithms\nhave competitive run-times for several real-world graphs, while almost always\nproviding superior coloring quality. Our degeneracy ordering relaxation is of\nseparate interest for algorithms outside the context of coloring.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 00:52:33 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 22:56:42 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 15:59:26 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Besta", "Maciej", ""], ["Carigiet", "Armon", ""], ["Vonarburg-Shmaria", "Zur", ""], ["Janda", "Kacper", ""], ["Gianinazzi", "Lukas", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2008.11388", "submitter": "Hiroshi Hirai", "authors": "Hiroshi Hirai and Motoki Ikeda", "title": "A cost-scaling algorithm for computing the degree of determinants", "comments": "new results (section 4) are added in version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address computation of the degree $\\mathop{\\rm deg Det} A$\nof Dieudonn\\'e determinant $\\mathop{\\rm Det} A$ of \\[ A = \\sum_{k=1}^m A_k x_k\nt^{c_k}, \\] where $A_k$ are $n \\times n$ matrices over a field $\\mathbb{K}$,\n$x_k$ are noncommutative variables, $t$ is a variable commuting with $x_k$,\n$c_k$ are integers, and the degree is considered for $t$. This problem\ngeneralizes noncommutative Edmonds' problem and fundamental combinatorial\noptimization problems including the weighted linear matroid intersection\nproblem. It was shown that $\\mathop{\\rm deg Det} A$ is obtained by a discrete\nconvex optimization on a Euclidean building. We extend this framework by\nincorporating a cost scaling technique, and show that $\\mathop{\\rm deg Det} A$\ncan be computed in time polynomial of $n,m,\\log_2 C$, where $C:= \\max_k |c_k|$.\nWe give a polyhedral interpretation of $\\mathop{\\rm deg Det}$, which says that\n$\\mathop{\\rm deg Det} A$ is given by linear optimization over an integral\npolytope with respect to objective vector $c = (c_k)$. Based on it, we show\nthat our algorithm becomes a strongly polynomial one. We apply this result to\nan algebraic combinatorial optimization problem arising from a symbolic matrix\nhaving $2 \\times 2$-submatrix structure.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 05:59:51 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 00:18:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Hirai", "Hiroshi", ""], ["Ikeda", "Motoki", ""]]}, {"id": "2008.11448", "submitter": "Georgios Kontogeorgiou", "authors": "Artur Czumaj, George Kontogeorgiou, Mike Paterson", "title": "Haystack Hunting Hints and Locker Room Communication", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to efficiently find a specific object in a large unstructured set,\nwhich we model by a random $n$-permutation, and we have to do it by revealing\njust a single element. Clearly, without any help this task is hopeless and the\nbest one can do is select the element at random, and achieve the success\nprobability $\\frac{1}{n}$. Can we do better with some small amount of advice\nabout the permutation, even without knowing the object sought? We show that by\nproviding advice of just one integer in $\\{0,1,...,n-1\\}$, one can improve the\nsuccess probability considerably, by a $\\Theta(\\frac{logn}{loglogn})$ factor.\nWe study this and related problems, and show asymptotically matching upper and\nlower bounds for their optimal probability of success.Our analysis relies on a\nclose relationship of such problems to some intrinsic properties of rendom\npermutations related to the rencontres number.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:04:35 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 09:44:14 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Czumaj", "Artur", ""], ["Kontogeorgiou", "George", ""], ["Paterson", "Mike", ""]]}, {"id": "2008.11454", "submitter": "Baris Batuhan Topal", "authors": "Arda Asik, Ibrahim Bugra Demir, Berker Demirel, Baris Batuhan Topal,\n  Kamer Kaya", "title": "Vertex Ordering Algorithms for Graph Coloring Problem", "comments": "in Turkish language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph coloring is a fundamental problem in combinatorics with many\napplications in practice. In this problem, the vertices in a given graph must\nbe colored by using the least number of colors in such a way that a vertex has\na different color than its neighbors. The problem, as well as its different\nvariants, has been proven to be NP-Hard. Therefore, there are greedy algorithms\nin the literature aiming to use a small number of colors. These algorithms\ntraverse the vertices and color them one by one. The vertex visit order has a\nsignificant impact on the number of colors used. In this work, we investigated\nif social network analytics metrics can be used to find this order. Our\nexperiments showed that when closeness centrality is used to find vertex visit\norder, a smaller number of colors is used by the greedy algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:12:19 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Asik", "Arda", ""], ["Demir", "Ibrahim Bugra", ""], ["Demirel", "Berker", ""], ["Topal", "Baris Batuhan", ""], ["Kaya", "Kamer", ""]]}, {"id": "2008.11786", "submitter": "Daniel Gibney", "authors": "Daniel Gibney, Gary Hoppenworth, Sharma V. Thankachan", "title": "Simple Reductions from Formula-SAT to Pattern Matching on Labeled Graphs\n  and Subtree Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CNF formula satisfiability problem (CNF-SAT) has been reduced to many\nfundamental problems in P to prove tight lower bounds under the Strong\nExponential Time Hypothesis (SETH). Recently, the works of Abboud, Hansen,\nVassilevska W. and Williams (STOC 16), and later, Abboud and Bringmann (ICALP\n18) have proposed basing lower bounds on the hardness of general boolean\nformula satisfiability (Formula-SAT). Reductions from Formula-SAT have two\nadvantages over the usual reductions from CNF-SAT: (1) conjectures on the\nhardness of Formula-SAT are arguably much more plausible than those of CNF-SAT,\nand (2) these reductions give consequences even for logarithmic improvements in\na problems upper bounds.\n  Here we give tight reductions from Formula-SAT to two more problems: pattern\nmatching on labeled graphs (PMLG) and subtree isomorphism. Previous reductions\nfrom Formula-SAT were to sequence alignment problems such as Edit Distance,\nLCS, and Frechet Distance and required some technical work. This paper uses\nideas similar to those used previously, but in a decidedly simpler setting,\nhelping to illustrate the most salient features of the underlying techniques.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:10:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Gibney", "Daniel", ""], ["Hoppenworth", "Gary", ""], ["Thankachan", "Sharma V.", ""]]}, {"id": "2008.11964", "submitter": "Yanjun Han", "authors": "Yanjun Han", "title": "On the High Accuracy Limitation of Adaptive Property Estimation", "comments": null, "journal-ref": "Published in AISTATS 2021", "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of adaptive (or unified) approaches\nin estimating symmetric properties of discrete distributions, where one first\nobtains a distribution estimator independent of the target property, and then\nplugs the estimator into the target property as the final estimator. Several\nsuch approaches have been proposed and proved to be adaptively optimal, i.e.\nthey achieve the optimal sample complexity for a large class of properties\nwithin a low accuracy, especially for a large estimation error $\\varepsilon\\gg\nn^{-1/3}$ where $n$ is the sample size.\n  In this paper, we characterize the high accuracy limitation, or the penalty\nfor adaptation, for all such approaches. Specifically, we show that under a\nmild assumption that the distribution estimator is close to the true sorted\ndistribution in expectation, any adaptive approach cannot achieve the optimal\nsample complexity for every $1$-Lipschitz property within accuracy $\\varepsilon\n\\ll n^{-1/3}$. In particular, this result disproves a conjecture in [Acharya et\nal. 2017] that the profile maximum likelihood (PML) plug-in approach is optimal\nin property estimation for all ranges of $\\varepsilon$, and confirms a\nconjecture in [Han and Shiragur, 2021] that their competitive analysis of the\nPML is tight.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:41:03 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 06:40:05 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Han", "Yanjun", ""]]}, {"id": "2008.12063", "submitter": "Wolfgang Garn", "authors": "Wolfgang Garn", "title": "Balanced dynamic multiple travelling salesmen: algorithms and continuous\n  approximations", "comments": "15 pages, 10 figures, 7 tables, 2 heuristics, 3 CAM models", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic routing occurs when customers are not known in advance, e.g. for\nreal-time routing. Two heuristics are proposed that solve the balanced dynamic\nmultiple travelling salesmen problem (BD-mTSP). These heuristics represent\noperational (tactical) tools for dynamic (online, real-time) routing. Several\ntypes and scopes of dynamics are proposed. Particular attention is given to\nsequential dynamics. The balanced dynamic closest vehicle heuristic (BD-CVH)\nand the balanced dynamic assignment vehicle heuristic (BD-AVH) are applied to\nthis type of dynamics. The algorithms are tested for instances in the Euclidean\nplane. Continuous approximation models for the BD-mTSP's are derived and serve\nas strategic tools for dynamic routing. The models express route lengths using\nvehicles, customers and dynamic scopes without the need of running an\nalgorithm. A machine learning approach was used to obtain regression models.\nThe mean-average-percentage error of two of these models is below 3%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:41:20 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Garn", "Wolfgang", ""]]}, {"id": "2008.12075", "submitter": "Antonios Antoniadis", "authors": "Antonios Antoniadis, S\\'andor Kisfaludi-Bak, Bundit Laekhanukit, and\n  Daniel Vaz", "title": "On the Approximability of the Traveling Salesman Problem with Line\n  Neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the variant of the Euclidean Traveling Salesman problem where\ninstead of a set of points, we are given a set of lines as input, and the goal\nis to find the shortest tour that visits each line. The best known upper and\nlower bounds for the problem in $\\mathbb{R}^d$, with $d\\ge 3$, are\n$\\mathrm{NP}$-hardness and an $O(\\log^3 n)$-approximation algorithm which is\nbased on a reduction to the group Steiner tree problem.\n  We show that TSP with lines in $\\mathbb{R}^d$ is APX-hard for any $d\\ge 3$.\nMore generally, this implies that TSP with $k$-dimensional flats does not admit\na PTAS for any $1\\le k \\leq d-2$ unless $\\mathrm{P}=\\mathrm{NP}$, which gives a\ncomplete classification of the approximability of these problems, as there are\nknown PTASes for $k=0$ (i.e., points) and $k=d-1$ (hyperplanes). We are able to\ngive a stronger inapproximability factor for $d=O(\\log n)$ by showing that TSP\nwith lines does not admit a $(2-\\epsilon)$-approximation in $d$ dimensions\nunder the unique games conjecture. On the positive side, we leverage recent\nresults on restricted variants of the group Steiner tree problem in order to\ngive an $O(\\log^2 n)$-approximation algorithm for the problem, albeit with a\nrunning time of $n^{O(\\log\\log n)}$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 12:09:22 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 18:07:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Antoniadis", "Antonios", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""], ["Laekhanukit", "Bundit", ""], ["Vaz", "Daniel", ""]]}, {"id": "2008.12110", "submitter": "Harold Nieuwboer", "authors": "Peter B\\\"urgisser, Yinan Li, Harold Nieuwboer, Michael Walter", "title": "Interior-point methods for unconstrained geometric programming and\n  scaling problems", "comments": "33 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a condition-based analysis of two interior-point methods for\nunconstrained geometric programs, a class of convex programs that arise\nnaturally in applications including matrix scaling, matrix balancing, and\nentropy maximization. Our condition numbers are natural geometric quantities\nassociated with the Newton polytope of the geometric program, and lead to\ndiameter bounds on approximate minimizers. We also provide effective bounds on\nthe condition numbers both in general and under combinatorial assumptions on\nthe Newton polytope. In this way, we generalize the iteration complexity of\nrecent interior-point methods for matrix scaling and matrix balancing.\nRecently, there has been much work on algorithms for certain optimization\nproblems on Lie groups, known as capacity and scaling problems. For commutative\ngroups, these problems reduce to unconstrained geometric programs, which serves\nas a particular source of motivation for our work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 13:38:24 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["B\u00fcrgisser", "Peter", ""], ["Li", "Yinan", ""], ["Nieuwboer", "Harold", ""], ["Walter", "Michael", ""]]}, {"id": "2008.12237", "submitter": "Alexander Wein", "authors": "Afonso S. Bandeira, Jess Banks, Dmitriy Kunisky, Cristopher Moore,\n  Alexander S. Wein", "title": "Spectral Planting and the Hardness of Refuting Cuts, Colorability, and\n  Communities in Random Graphs", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SI math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficiently refuting the k-colorability of a graph,\nor equivalently certifying a lower bound on its chromatic number. We give\nformal evidence of average-case computational hardness for this problem in\nsparse random regular graphs, showing optimality of a simple spectral\ncertificate. This evidence takes the form of a computationally-quiet planting:\nwe construct a distribution of d-regular graphs that has significantly smaller\nchromatic number than a typical regular graph drawn uniformly at random, while\nproviding evidence that these two distributions are indistinguishable by a\nlarge class of algorithms. We generalize our results to the more general\nproblem of certifying an upper bound on the maximum k-cut.\n  This quiet planting is achieved by minimizing the effect of the planted\nstructure (e.g. colorings or cuts) on the graph spectrum. Specifically, the\nplanted structure corresponds exactly to eigenvectors of the adjacency matrix.\nThis avoids the pushout effect of random matrix theory, and delays the point at\nwhich the planting becomes visible in the spectrum or local statistics. To\nillustrate this further, we give similar results for a Gaussian analogue of\nthis problem: a quiet version of the spiked model, where we plant an eigenspace\nrather than adding a generic low-rank perturbation.\n  Our evidence for computational hardness of distinguishing two distributions\nis based on three different heuristics: stability of belief propagation, the\nlocal statistics hierarchy, and the low-degree likelihood ratio. Of independent\ninterest, our results include general-purpose bounds on the low-degree\nlikelihood ratio for multi-spiked matrix models, and an improved low-degree\nanalysis of the stochastic block model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:35:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Banks", "Jess", ""], ["Kunisky", "Dmitriy", ""], ["Moore", "Cristopher", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2008.12259", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "The k-interchange-constrained diameter of a transit network: A\n  connectedness indicator that accounts for travel convenience", "comments": null, "journal-ref": "Transportation Letters The International Journal of Transportation\n  Research Transportation Letters - Volume 12, 2020 - Issue 3", "doi": "10.1080/19427867.2018.1564987", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two variants of the shortest path problem. Given an integer k, the\nk-color-constrained and the k-interchange-constrained shortest path problems,\nrespectively seek a shortest path that uses no more than k colors and one that\nmakes no more than k - 1 alternations of colors. We show that the former\nproblem is NP-hard, when the latter is tractable. The study of these problems\nis motivated by some limitations in the use of diameter-based metrics to\nevaluate the topological structure of transit networks. We notably show that\nindicators such as the diameter or directness of a transit network fail to\nadequately account for travel convenience in measuring the connectivity of a\nnetwork and propose a new network indicator, based on solving the\nk-interchange-constrained shortest path problem, that aims at alleviating these\nlimitations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:56:12 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2008.12386", "submitter": "Sandip Sinha", "authors": "Xi Chen, Anindya De, Chin Ho Lee, Rocco A. Servedio, Sandip Sinha", "title": "Polynomial-time trace reconstruction in the smoothed complexity model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\emph{trace reconstruction problem}, an unknown source string $x \\in\n\\{0,1\\}^n$ is sent through a probabilistic \\emph{deletion channel} which\nindependently deletes each bit with probability $\\delta$ and concatenates the\nsurviving bits, yielding a \\emph{trace} of $x$. The problem is to reconstruct\n$x$ given independent traces. This problem has received much attention in\nrecent years both in the worst-case setting where $x$ may be an arbitrary\nstring in $\\{0,1\\}^n$ \\cite{DOS17,NazarovPeres17,HHP18,HL18,Chase19} and in the\naverage-case setting where $x$ is drawn uniformly at random from $\\{0,1\\}^n$\n\\cite{PeresZhai17,HPP18,HL18,Chase19}.\n  This paper studies trace reconstruction in the \\emph{smoothed analysis}\nsetting, in which a ``worst-case'' string $x^{\\worst}$ is chosen arbitrarily\nfrom $\\{0,1\\}^n$, and then a perturbed version $\\bx$ of $x^{\\worst}$ is formed\nby independently replacing each coordinate by a uniform random bit with\nprobability $\\sigma$. The problem is to reconstruct $\\bx$ given independent\ntraces from it.\n  Our main result is an algorithm which, for any constant perturbation rate\n$0<\\sigma < 1$ and any constant deletion rate $0 < \\delta < 1$, uses $\\poly(n)$\nrunning time and traces and succeeds with high probability in reconstructing\nthe string $\\bx$. This stands in contrast with the worst-case version of the\nproblem, for which $\\text{exp}(O(n^{1/3}))$ is the best known time and sample\ncomplexity \\cite{DOS17,NazarovPeres17}.\n  Our approach is based on reconstructing $\\bx$ from the multiset of its short\nsubwords and is quite different from previous algorithms for either the\nworst-case or average-case versions of the problem. The heart of our work is a\nnew $\\poly(n)$-time procedure for reconstructing the multiset of all $O(\\log\nn)$-length subwords of any source string $x\\in \\{0,1\\}^n$ given access to\ntraces of $x$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 22:09:15 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Xi", ""], ["De", "Anindya", ""], ["Lee", "Chin Ho", ""], ["Servedio", "Rocco A.", ""], ["Sinha", "Sandip", ""]]}, {"id": "2008.12388", "submitter": "Matthew Jones", "authors": "Matthew Jones, Huy L\\^e Nguyen, Thy Nguyen", "title": "Differentially Private Clustering via Maximum Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of clustering in metric spaces while\npreserving the privacy of individual data. Specifically, we examine\ndifferentially private variants of the k-medians and Euclidean k-means\nproblems. We present polynomial algorithms with constant multiplicative error\nand lower additive error than the previous state-of-the-art for each problem.\nAdditionally, our algorithms use a clustering algorithm without differential\nprivacy as a black-box. This allows practitioners to control the trade-off\nbetween runtime and approximation factor by choosing a suitable clustering\nalgorithm to use.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 22:11:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Jones", "Matthew", ""], ["Nguyen", "Huy L\u00ea", ""], ["Nguyen", "Thy", ""]]}, {"id": "2008.12516", "submitter": "Rohan Garg", "authors": "Rohan Garg", "title": "Fast and Work-Optimal Parallel Algorithms for Predicate Detection", "comments": "Fixed minor bug in JLSDetect from Version 3 with new subroutine FLIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the predicate detection problem was shown to be in the parallel\ncomplexity class NC. In this paper, we give the first work-optimal parallel\nalgorithm to solve the predicate detection problem on a distributed computation\nwith $n$ processes and at most $m$ states per process. The previous best known\nparallel predicate detection algorithm, ParallelCut, has time complexity\n$O(\\log mn)$ and work complexity $O(m^3n^3\\log mn)$. We give two algorithms, a\ndeterministic algorithm with time complexity $O(mn)$ and work complexity\n$O(mn^2)$, and a randomized algorithm with time complexity $(mn)^{1/2 + o(1)}$\nand work complexity $\\tilde{O}(mn^2)$. Furthermore, our algorithms improve upon\nthe space complexity of ParallelCut. Both of our algorithms have space\ncomplexity $O(mn^2)$ whereas ParallelCut has space complexity $O(m^2n^2)$.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:25:42 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 04:40:20 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 04:14:46 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 06:01:47 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Garg", "Rohan", ""]]}, {"id": "2008.12626", "submitter": "Martin Hoefer", "authors": "Martin Hoefer and Pasin Manurangsi and Alexandros Psomas", "title": "Algorithmic Persuasion with Evidence", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a game of persuasion with evidence between a sender and a\nreceiver. The sender has private information. By presenting evidence on the\ninformation, the sender wishes to persuade the receiver to take a single action\n(e.g., hire a job candidate, or convict a defendant). The sender's utility\ndepends solely on whether or not the receiver takes the action. The receiver's\nutility depends on both the action as well as the sender's private information.\nWe study three natural variations. First, we consider sequential equilibria of\nthe game without commitment power. Second, we consider a persuasion variant,\nwhere the sender commits to a signaling scheme and then the receiver, after\nseeing the evidence, takes the action or not. Third, we study a delegation\nvariant, where the receiver first commits to taking the action if being\npresented certain evidence, and then the sender presents evidence to maximize\nthe probability the action is taken. We study these variants through the\ncomputational lens, and give hardness results, optimal approximation\nalgorithms, as well as polynomial-time algorithms for special cases. Among our\nresults is an approximation algorithm that rounds a semidefinite program that\nmight be of independent interest, since, to the best of our knowledge, it is\nthe first such approximation algorithm for a natural problem in algorithmic\neconomics.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:43:25 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 10:22:14 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hoefer", "Martin", ""], ["Manurangsi", "Pasin", ""], ["Psomas", "Alexandros", ""]]}, {"id": "2008.12776", "submitter": "Yujia Jin", "authors": "Yujia Jin and Aaron Sidford", "title": "Efficiently Solving MDPs with Stochastic Mirror Descent", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework based on primal-dual stochastic mirror descent\nfor approximately solving infinite-horizon Markov decision processes (MDPs)\ngiven a generative model. When applied to an average-reward MDP with $A_{tot}$\ntotal state-action pairs and mixing time bound $t_{mix}$ our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}(t_{mix}^2 A_{tot}\n\\epsilon^{-2})$ samples from the state-transition matrix, removing the\nergodicity dependence of prior art. When applied to a $\\gamma$-discounted MDP\nwith $A_{tot}$ total state-action pairs our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}((1-\\gamma)^{-4}\nA_{tot} \\epsilon^{-2})$ samples, matching the previous state-of-the-art up to a\n$(1-\\gamma)^{-1}$ factor. Both methods are model-free, update state values and\npolicies simultaneously, and run in time linear in the number of samples taken.\nWe achieve these results through a more general stochastic mirror descent\nframework for solving bilinear saddle-point problems with simplex and box\ndomains and we demonstrate the flexibility of this framework by providing\nfurther applications to constrained MDPs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:40 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2008.12825", "submitter": "Jay Mardia", "authors": "Jay Mardia", "title": "Is the space complexity of planted clique recovery the same as that of\n  detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the planted clique problem in which a clique of size k is planted in\nan Erd\\H{o}s-R\\'enyi graph G(n, 1/2), and one is interested in either detecting\nor recovering this planted clique. This problem is interesting because it is\nwidely believed to show a statistical-computational gap at clique size\nk=sqrt{n}, and has emerged as the prototypical problem with such a gap from\nwhich average-case hardness of other statistical problems can be deduced. It\nalso displays a tight computational connection between the detection and\nrecovery variants, unlike other problems of a similar nature. This wide\ninvestigation into the computational complexity of the planted clique problem\nhas, however, mostly focused on its time complexity. In this work, we ask-\n  Do the statistical-computational phenomena that make the planted clique an\ninteresting problem also hold when we use `space efficiency' as our notion of\ncomputational efficiency?\n  It is relatively easy to show that a positive answer to this question depends\non the existence of a O(log n) space algorithm that can recover planted cliques\nof size k = Omega(sqrt{n}). Our main result comes very close to designing such\nan algorithm. We show that for k=Omega(sqrt{n}), the recovery problem can be\nsolved in O((log*{n}-log*{k/sqrt{n}}) log n) bits of space.\n  1. If k = omega(sqrt{n}log^{(l)}n) for any constant integer l > 0, the space\nusage is O(log n) bits.\n  2.If k = Theta(sqrt{n}), the space usage is O(log*{n} log n) bits.\n  Our result suggests that there does exist an O(log n) space algorithm to\nrecover cliques of size k = Omega(sqrt{n}), since we come very close to\nachieving such parameters. This provides evidence that the\nstatistical-computational phenomena that (conjecturally) hold for planted\nclique time complexity also (conjecturally) hold for space complexity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:49:42 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 23:44:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mardia", "Jay", ""]]}, {"id": "2008.12895", "submitter": "Nafees Mansoor PhD", "authors": "Sharmin Akter, Mohammad Shahriar Rahman and Nafees Mansoor", "title": "An Efficient Routing Protocol for Secured Communication in Cognitive\n  Radio Sensor Networks", "comments": null, "journal-ref": "2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an efficient reactive routing protocol considering the\nmobility and the reliability of a node in Cognitive Radio Sensor Networks\n(CRSNs). The proposed protocol accommodates the dynamic behavior of the\nspectrum availability and selects a stable transmission path from a source node\nto the destination. Outlined as a weighted graph problem, the proposed protocol\nmeasures the weight for an edge the measuring the mobility patterns of the\nnodes and channel availability. Furthermore, the mobility pattern of a node is\ndefined in the proposed routing protocol from the viewpoint of distance, speed,\ndirection, and node's reliability. Besides, the spectrum awareness in the\nproposed protocol is measured over the number of shared common channels and the\nchannel quality. It is anticipated that the proposed protocol shows efficient\nrouting performance by selecting stable and secured paths from source to\ndestination. Simulation is carried out to assess the performance of the\nprotocol where it is witnessed that the proposed routing protocol outperforms\nexisting ones.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 02:45:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Akter", "Sharmin", ""], ["Rahman", "Mohammad Shahriar", ""], ["Mansoor", "Nafees", ""]]}, {"id": "2008.12905", "submitter": "Manas Joshi", "authors": "Manas Joshi, Arshdeep Singh, Sayan Ranu, Amitabha Bagchi, Priyank\n  Karia, Puneet Kala", "title": "Batching and Matching for Food Delivery in Dynamic Road Networks", "comments": "12 pages, 9 figures, Accepted in ICDE 2021 as Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of food orders and available delivery vehicles, how should\norders be assigned to vehicles so that the delivery time is minimized? Several\ndecisions have to be made: (1) assignment of orders to vehicles, (2) grouping\norders into batches to cope with limited vehicle availability, and (3) adapting\nto dynamic positions of delivery vehicles. We show that the minimization\nproblem is not only NP-hard but inapproximable in polynomial time. To mitigate\nthis computational bottleneck, we develop an algorithm called FoodMatch, which\nmaps the vehicle assignment problem to that of minimum weight perfect matching\non a bipartite graph. To further reduce the quadratic construction cost of the\nbipartite graph, we deploy best-first search to only compute a subgraph that is\nhighly likely to contain the minimum matching. The solution quality is further\nenhanced by reducing batching to a graph clustering problem and anticipating\ndynamic positions of vehicles through angular distance. Extensive experiments\non food-delivery data from large metropolitan cities establish that FoodMatch\nis substantially better than baseline strategies on a number of metrics, while\nbeing efficient enough to handle real-world workloads.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 03:42:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Joshi", "Manas", ""], ["Singh", "Arshdeep", ""], ["Ranu", "Sayan", ""], ["Bagchi", "Amitabha", ""], ["Karia", "Priyank", ""], ["Kala", "Puneet", ""]]}, {"id": "2008.13209", "submitter": "Tomasz Wale\\'n", "authors": "Pawe{\\l} Gawrychowski, Tomasz Kociumaka, Wojciech Rytter, Tomasz\n  Wale\\'n", "title": "Tight Bound for the Number of Distinct Palindromes in a Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an undirected tree with $n$ edges labelled by single letters, we consider\nits substrings, which are labels of the simple paths between pairs of nodes. We\nprove that there are $O(n^{1.5})$ different palindromic substrings. This solves\nan open problem of Brlek, Lafreni\\`ere, and Proven\\c{c}al (DLT 2015), who gave\na matching lower-bound construction. Hence, we settle the tight bound of\n$\\Theta(n^{1.5})$ for the maximum palindromic complexity of trees. For standard\nstrings, i.e., for paths, the palindromic complexity is $n+1$. We also propose\n$O(n^{1.5} \\log{n})$-time algorithm for reporting all distinct palindromes in\nan undirected tree with $n$ edges.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:23:28 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 06:01:46 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Kociumaka", "Tomasz", ""], ["Rytter", "Wojciech", ""], ["Wale\u0144", "Tomasz", ""]]}, {"id": "2008.13292", "submitter": "Rathish Das", "authors": "Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Pramod Ganapathi, Aaron\n  Gregory, and Mohammad Mahdi Javanmard", "title": "Low-Depth Parallel Algorithms for the Binary-Forking Model without\n  Atomics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary-forking model is a parallel computation model, formally defined by\nBlelloch et al. very recently, in which a thread can fork a concurrent child\nthread, recursively and asynchronously. The model incurs a cost of $\\Theta(\\log\nn)$ to spawn or synchronize $n$ tasks or threads. The binary-forking model\nrealistically captures the performance of parallel algorithms implemented using\nmodern multithreaded programming languages on multicore shared-memory machines.\nIn contrast, the widely studied theoretical PRAM model does not consider the\ncost of spawning and synchronizing threads, and as a result, algorithms\nachieving optimal performance bounds in the PRAM model may not be optimal in\nthe binary-forking model. Often, algorithms need to be redesigned to achieve\noptimal performance bounds in the binary-forking model and the non-constant\nsynchronization cost makes the task challenging.\n  Though the binary-forking model allows the use of atomic {\\em test-and-set}\n(TS) instructions to reduce some synchronization overhead, assuming the\navailability of such instructions puts a stronger requirement on the hardware\nand may limit the portability of the algorithms using them. In this paper, we\navoid the use of locks and atomic instructions in our algorithms except\npossibly inside the join operation which is implemented by the runtime system.\n  In this paper, we design efficient parallel algorithms in the binary-forking\nmodel without atomics for three fundamental problems: Strassen's (and\nStrassen-like) matrix multiplication (MM), comparison-based sorting, and the\nFast Fourier Transform (FFT). All our results improve over known results for\nthe corresponding problem in the binary-forking model both with and without\natomics.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 22:56:59 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 18:41:25 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ahmad", "Zafar", ""], ["Chowdhury", "Rezaul", ""], ["Das", "Rathish", ""], ["Ganapathi", "Pramod", ""], ["Gregory", "Aaron", ""], ["Javanmard", "Mohammad Mahdi", ""]]}, {"id": "2008.13556", "submitter": "Sven Gedicke", "authors": "Sven Gedicke, Annika Bonerath, Benjamin Niedermann, Jan-Henrik Haunert", "title": "Zoomless Maps: External Labeling Methods for the Interactive Exploration\n  of Dense Point Sets at a Fixed Map Scale", "comments": "accepted for IEEE INFOVIS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing spatial data on small-screen devices such as smartphones and\nsmartwatches poses new challenges in computational cartography. The current\ninterfaces for map exploration require their users to zoom in and out\nfrequently. Indeed, zooming and panning are tools suitable for choosing the map\nextent corresponding to an area of interest. They are not as suitable, however,\nfor resolving the graphical clutter caused by a high feature density since\nzooming in to a large map scale leads to a loss of context. Therefore we\npresent new external labeling methods that allow navigating through dense sets\nof points of interest while keeping the current map extent fixed. We provide a\nunified model, in which labels are placed at the boundary of the map and\nvisually associated with the corresponding features via connecting lines, which\nare called leaders. Since the screen space is limited, labeling all features at\nthe same time is impractical. Therefore, at any time, we label a subset of the\nfeatures. We offer interaction techniques to change the current selection of\nfeatures systematically and, thus, give the user access to all features. We\ndistinguish three methods, which allow the user either to slide the labels\nalong the bottom side of the map or to browse the labels based on pages or\nstacks. We present a generic algorithmic framework that provides us with the\npossibility of expressing the different variants of interaction techniques as\noptimization problems in a unified way. We propose both exact algorithms and\nfast and simple heuristics that solve the optimization problems taking into\naccount different criteria such as the ranking of the labels, the total leader\nlength and the distance between leaders. We experimentally evaluate these\nalgorithms and discuss the three variants with respect to their strengths and\nweaknesses proving the flexibility of the presented algorithmic framework.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:42:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gedicke", "Sven", ""], ["Bonerath", "Annika", ""], ["Niedermann", "Benjamin", ""], ["Haunert", "Jan-Henrik", ""]]}, {"id": "2008.13640", "submitter": "Anthony Labarre", "authors": "Anthony Labarre", "title": "Sorting by Prefix Block-Interchanges", "comments": "15 pages, to appear in ISAAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We initiate the study of sorting permutations using prefix\nblock-interchanges, which exchange any prefix of a permutation with another\nnon-intersecting interval. The goal is to transform a given permutation into\nthe identity permutation using as few such operations as possible. We give a\n2-approximation algorithm for this problem, show how to obtain improved lower\nand upper bounds on the corresponding distance, and determine the largest\npossible value for that distance.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:25:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Labarre", "Anthony", ""]]}, {"id": "2008.13648", "submitter": "Daniel Kline", "authors": "Calin Chindris, Daniel Kline", "title": "Edmonds' problem and the membership problem for orbit semigroups of\n  quiver representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in algebraic complexity, posed by J. Edmonds, asks to\ndecide if the span of a given $l$-tuple $\\V=(\\V_1, \\ldots, \\V_l)$ of $N \\times\nN$ complex matrices contains a non-singular matrix.\n  In this paper, we provide a quiver invariant theoretic approach to this\nproblem. Viewing $\\V$ as a representation of the $l$-Kronecker quiver $\\K_l$,\nEdmonds' problem can be rephrased as asking to decide if there exists a\nsemi-invariant on the representation space $(\\CC^{N\\times N})^l$ of weight\n$(1,-1)$ that does not vanish at $\\V$. In other words, Edmonds' problem is\nasking to decide if the weight $(1,-1)$ belongs to the orbit semigroup of $\\V$.\n  Let $Q$ be an arbitrary acyclic quiver and $\\V$ a representation of $Q$. We\nstudy the membership problem for the orbit semi-group of $\\V$ by focusing on\nthe so-called $\\V$-saturated weights. We first show that for any given\n$\\V$-saturated weight $\\sigma$, checking if $\\sigma$ belongs to the orbit\nsemigroup of $\\V$ can be done in deterministic polynomial time.\n  Next, let $(Q, \\R)$ be an acyclic bound quiver with bound quiver algebra\n$A=KQ/\\langle \\R \\rangle$ and assume that $\\V$ satisfies the relations in $\\R$.\nWe show that if $A/\\Ann_A(\\V)$ is a tame algebra then any weight $\\sigma$ in\nthe weight semigroup of $\\V$ is $\\V$-saturated.\n  Our results provide a systematic way of producing families of tuples of\nmatrices for which Edmonds' problem can be solved effectively.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:36:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chindris", "Calin", ""], ["Kline", "Daniel", ""]]}, {"id": "2008.13729", "submitter": "Spyros Angelopoulos", "authors": "Spyros Angelopoulos", "title": "Online Search With a Hint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear search problem, informally known as the cow path problem, is one\nof the fundamental problems in search theory. In this problem, an immobile\ntarget is hidden at some unknown position on an unbounded line, and a mobile\nsearcher, initially positioned at some specific point of the line called the\nroot, must traverse the line so as to locate the target. The objective is to\nminimize the worst-case ratio of the distance traversed by the searcher to the\ndistance of the target from the root, which is known as the competitive ratio\nof the search.\n  In this work we study this problem in a setting in which the searcher has a\nhint concerning the target. We consider three settings in regards to the nature\nof the hint: i) the hint suggests the exact position of the target on the line;\nii) the hint suggests the direction of the optimal search (i.e., to the left or\nthe right of the root); and iii) the hint is a general k-bit string that\nencodes some information concerning the target. Our objective is to study the\nPareto-efficiency of strategies in this model. Namely, we seek optimal, or\nnear-optimal tradeoffs between the searcher's performance if the hint is\ncorrect (i.e., provided by a trusted source) and if the hint is incorrect\n(i.e., provided by an adversary).\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:47:50 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:36:24 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Angelopoulos", "Spyros", ""]]}, {"id": "2008.13735", "submitter": "Jingqiu Ding", "authors": "Jingqiu Ding, Samuel B.Hopkins, David Steurer", "title": "Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding\n  Walks", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study symmetric spiked matrix models with respect to a general class of\nnoise distributions. Given a rank-1 deformation of a random noise matrix, whose\nentries are independently distributed with zero mean and unit variance, the\ngoal is to estimate the rank-1 part. For the case of Gaussian noise, the top\neigenvector of the given matrix is a widely-studied estimator known to achieve\noptimal statistical guarantees, e.g., in the sense of the celebrated BBP phase\ntransition. However, this estimator can fail completely for heavy-tailed noise.\nIn this work, we exhibit an estimator that works for heavy-tailed noise up to\nthe BBP threshold that is optimal even for Gaussian noise. We give a\nnon-asymptotic analysis of our estimator which relies only on the variance of\neach entry remaining constant as the size of the matrix grows: higher moments\nmay grow arbitrarily fast or even fail to exist. Previously, it was only known\nhow to achieve these guarantees if higher-order moments of the noises are\nbounded by a constant independent of the size of the matrix. Our estimator can\nbe evaluated in polynomial time by counting self-avoiding walks via a color\n-coding technique. Moreover, we extend our estimator to spiked tensor models\nand establish analogous results.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:57:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ding", "Jingqiu", ""], ["Hopkins", "Samuel B.", ""], ["Steurer", "David", ""]]}]