[{"id": "1609.00048", "submitter": "Joel Tropp", "authors": "Joel A. Tropp, Alp Yurtsever, Madeleine Udell, Volkan Cevher", "title": "Practical sketching algorithms for low-rank matrix approximation", "comments": null, "journal-ref": "SIAM J. Matrix Analysis and Applications, Vol. 38, num. 4, pp.\n  1454-1485, Dec. 2017", "doi": "10.1137/17M1111590", "report-no": null, "categories": "cs.NA cs.DS math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a suite of algorithms for constructing low-rank\napproximations of an input matrix from a random linear image of the matrix,\ncalled a sketch. These methods can preserve structural properties of the input\nmatrix, such as positive-semidefiniteness, and they can produce approximations\nwith a user-specified rank. The algorithms are simple, accurate, numerically\nstable, and provably correct. Moreover, each method is accompanied by an\ninformative error bound that allows users to select parameters a priori to\nachieve a given approximation quality. These claims are supported by numerical\nexperiments with real and synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 21:30:26 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 18:13:40 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Tropp", "Joel A.", ""], ["Yurtsever", "Alp", ""], ["Udell", "Madeleine", ""], ["Cevher", "Volkan", ""]]}, {"id": "1609.00090", "submitter": "Xin Huang", "authors": "Xin Huang, Laks V.S. Lakshmanan", "title": "Attribute Truss Community Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, community search over graphs has attracted significant attention\nand many algorithms have been developed for finding dense subgraphs from large\ngraphs that contain given query nodes. In applications such as analysis of\nprotein protein interaction (PPI) networks, citation graphs, and collaboration\nnetworks, nodes tend to have attributes. Unfortunately, previously developed\ncommunity search algorithms ignore these attributes and result in communities\nwith poor cohesion w.r.t. their node attributes. In this paper, we study the\nproblem of attribute-driven community search, that is, given an undirected\ngraph $G$ where nodes are associated with attributes, and an input query $Q$\nconsisting of nodes $V_q$ and attributes $W_q$, find the communities containing\n$V_q$, in which most community members are densely inter-connected and have\nsimilar attributes.\n  We formulate our problem of finding attributed truss communities (ATC), as\nfinding all connected and close k-truss subgraphs containing $V_q$, that are\nlocally maximal and have the largest attribute relevance score among such\nsubgraphs. We design a novel attribute relevance score function and establish\nits desirable properties. The problem is shown to be NP-hard. However, we\ndevelop an efficient greedy algorithmic framework, which finds a maximal\n$k$-truss containing $V_q$, and then iteratively removes the nodes with the\nleast popular attributes and shrinks the graph so as to satisfy community\nconstraints. We also build an elegant index to maintain the known $k$-truss\nstructure and attribute information, and propose efficient query processing\nalgorithms. Extensive experiments on large real-world networks with\nground-truth communities shows the efficiency and effectiveness of our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 02:19:36 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 00:30:30 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2017 18:12:53 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Huang", "Xin", ""], ["Lakshmanan", "Laks V. S.", ""]]}, {"id": "1609.00147", "submitter": "Klaus Heeger", "authors": "Klaus Heeger and Jens Vygen", "title": "Two-connected spanning subgraphs with at most $\\frac{10}{7}$OPT edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a $\\frac{10}{7}$-approximation algorithm for the minimum\ntwo-vertex-connected spanning subgraph problem.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 08:50:54 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Heeger", "Klaus", ""], ["Vygen", "Jens", ""]]}, {"id": "1609.00161", "submitter": "Frederic Prost", "authors": "Frederic Prost and Jisang Yoon", "title": "Parallel Clustering of Graphs for Anonymization and Recommender Systems", "comments": "submitted to VLDB'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is widely used in many data analysis applications. In this\npaper we propose several parallel graph clustering algorithms based on Monte\nCarlo simulations and expectation maximization in the context of stochastic\nblock models. We apply those algorithms to the specific problems of recommender\nsystems and social network anonymization. We compare the experimental results\nto previous propositions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 09:43:29 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 08:06:38 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Prost", "Frederic", ""], ["Yoon", "Jisang", ""]]}, {"id": "1609.00265", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Elena Grigorescu, Siyao Guo, Akash Kumar, Karl\n  Wimmer", "title": "Testing $k$-Monotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Boolean $k$-monotone function defined over a finite poset domain ${\\cal D}$\nalternates between the values $0$ and $1$ at most $k$ times on any ascending\nchain in ${\\cal D}$. Therefore, $k$-monotone functions are natural\ngeneralizations of the classical monotone functions, which are the $1$-monotone\nfunctions. Motivated by the recent interest in $k$-monotone functions in the\ncontext of circuit complexity and learning theory, and by the central role that\nmonotonicity testing plays in the context of property testing, we initiate a\nsystematic study of $k$-monotone functions, in the property testing model. In\nthis model, the goal is to distinguish functions that are $k$-monotone (or are\nclose to being $k$-monotone) from functions that are far from being\n$k$-monotone. Our results include the following:\n  - We demonstrate a separation between testing $k$-monotonicity and testing\nmonotonicity, on the hypercube domain $\\{0,1\\}^d$, for $k\\geq 3$;\n  - We demonstrate a separation between testing and learning on $\\{0,1\\}^d$,\nfor $k=\\omega(\\log d)$: testing $k$-monotonicity can be performed with\n$2^{O(\\sqrt d \\cdot \\log d\\cdot \\log{1/\\varepsilon})}$ queries, while learning\n$k$-monotone functions requires $2^{\\Omega(k\\cdot \\sqrt\nd\\cdot{1/\\varepsilon})}$ queries (Blais et al. (RANDOM 2015)).\n  - We present a tolerant test for functions $f\\colon[n]^d\\to \\{0,1\\}$ with\ncomplexity independent of $n$, which makes progress on a problem left open by\nBerman et al. (STOC 2014).\n  Our techniques exploit the testing-by-learning paradigm, use novel\napplications of Fourier analysis on the grid $[n]^d$, and draw connections to\ndistribution testing techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 15:11:52 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 18:53:51 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Grigorescu", "Elena", ""], ["Guo", "Siyao", ""], ["Kumar", "Akash", ""], ["Wimmer", "Karl", ""]]}, {"id": "1609.00368", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis, Christos Tzamos, Manolis Zampetakis", "title": "Ten Steps of EM Suffice for Mixtures of Two Gaussians", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is a widely used method for\nmaximum likelihood estimation in models with latent variables. For estimating\nmixtures of Gaussians, its iteration can be viewed as a soft version of the\nk-means clustering algorithm. Despite its wide use and applications, there are\nessentially no known convergence guarantees for this method. We provide global\nconvergence guarantees for mixtures of two Gaussians with known covariance\nmatrices. We show that the population version of EM, where the algorithm is\ngiven access to infinitely many samples from the mixture, converges\ngeometrically to the correct mean vectors, and provide simple, closed-form\nexpressions for the convergence rate. As a simple illustration, we show that,\nin one dimension, ten steps of the EM algorithm initialized at infinity result\nin less than 1\\% error estimation of the means. In the finite sample regime, we\nshow that, under a random initialization, $\\tilde{O}(d/\\epsilon^2)$ samples\nsuffice to compute the unknown vectors to within $\\epsilon$ in Mahalanobis\ndistance, where $d$ is the dimension. In particular, the error rate of the EM\nbased estimator is $\\tilde{O}\\left(\\sqrt{d \\over n}\\right)$ where $n$ is the\nnumber of samples, which is optimal up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 19:57:26 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2016 19:55:11 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 17:59:27 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 00:55:32 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 07:53:53 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1609.00512", "submitter": "Adrian Kosowski", "authors": "Adrian Kosowski (GANG), Laurent Viennot (GANG)", "title": "Beyond Highway Dimension: Small Distance Labels Using Tree Skeletons", "comments": "SODA 2017 - 28th ACM-SIAM Symposium on Discrete Algorithms, Jan 2017,\n  Barcelona, Spain. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a hub-based distance labeling scheme for a network G = (V, E) is\nto assign a small subset S(u) $\\subseteq$ V to each node u $\\in$ V, in such a\nway that for any pair of nodes u, v, the intersection of hub sets S(u) $\\cap$\nS(v) contains a node on the shortest uv-path. The existence of small hub sets,\nand consequently efficient shortest path processing algorithms, for road\nnetworks is an empirical observation. A theoretical explanation for this\nphenomenon was proposed by Abraham et al. (SODA 2010) through a network\nparameter they called highway dimension, which captures the size of a hitting\nset for a collection of shortest paths of length at least r intersecting a\ngiven ball of radius 2r. In this work, we revisit this explanation, introducing\na more tractable (and directly comparable) parameter based solely on the\nstructure of shortest-path spanning trees, which we call skeleton dimension. We\nshow that skeleton dimension admits an intuitive definition for both directed\nand undirected graphs, provides a way of computing labels more efficiently than\nby using highway dimension, and leads to comparable or stronger theoretical\nbounds on hub set size.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 09:15:19 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 14:28:43 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Kosowski", "Adrian", "", "GANG"], ["Viennot", "Laurent", "", "GANG"]]}, {"id": "1609.00544", "submitter": "Georgios Stamoulis", "authors": "Leo van Iersel, Steven Kelk, Georgios Stamoulis, Leen Stougie and\n  Olivier Boes", "title": "On unrooted and root-uncertain variants of several well-known\n  phylogenetic network problems", "comments": "28 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hybridization number problem requires us to embed a set of binary rooted\nphylogenetic trees into a binary rooted phylogenetic network such that the\nnumber of nodes with indegree two is minimized. However, from a biological\npoint of view accurately inferring the root location in a phylogenetic tree is\nnotoriously difficult and poor root placement can artificially inflate the\nhybridization number. To this end we study a number of relaxed variants of this\nproblem. We start by showing that the fundamental problem of determining\nwhether an \\emph{unrooted} phylogenetic network displays (i.e. embeds) an\n\\emph{unrooted} phylogenetic tree, is NP-hard. On the positive side we show\nthat this problem is FPT in reticulation number. In the rooted case the\ncorresponding FPT result is trivial, but here we require more subtle\nargumentation. Next we show that the hybridization number problem for unrooted\nnetworks (when given two unrooted trees) is equivalent to the problem of\ncomputing the Tree Bisection and Reconnect (TBR) distance of the two unrooted\ntrees. In the third part of the paper we consider the \"root uncertain\" variant\nof hybridization number. Here we are free to choose the root location in each\nof a set of unrooted input trees such that the hybridization number of the\nresulting rooted trees is minimized. On the negative side we show that this\nproblem is APX-hard. On the positive side, we show that the problem is FPT in\nthe hybridization number, via kernelization, for any number of input trees.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 10:52:41 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["van Iersel", "Leo", ""], ["Kelk", "Steven", ""], ["Stamoulis", "Georgios", ""], ["Stougie", "Leen", ""], ["Boes", "Olivier", ""]]}, {"id": "1609.00750", "submitter": "Charalampos Tsourakakis", "authors": "Michael Mitzenmacher, Charalampos E. Tsourakakis", "title": "Predicting Signed Edges with $O(n^{1+o(1)} \\log{n})$ Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks and interactions in social media involve both positive and\nnegative relationships. Signed graphs capture both types of relationships:\npositive edges correspond to pairs of \"friends\", and negative edges to pairs of\n\"foes\". The {\\em edge sign prediction problem}, which aims to predict whether\nan interaction between a pair of nodes will be positive or negative, is an\nimportant graph mining task for which many heuristics have recently been\nproposed \\cite{leskovec2010predicting,leskovec2010signed}.\n  Motivated by social balance theory, we model the edge sign prediction problem\nas a noisy correlation clustering problem with two clusters. We are allowed to\nquery each pair of nodes whether they belong to the same cluster or not, but\nthe answer to the query is corrupted with some probability $0<q<\\frac{1}{2}$.\nLet $c=\\frac{1}{2}-q$ be the gap. We provide an algorithm that recovers the\nclustering with high probability in the presence of noise for any constant gap\n$c$ with $O(n^{1+\\tfrac{1}{\\log\\log{n}}}\\log{n})$ queries. Our algorithm uses\nsimple breadth first search as its main algorithmic primitive. Finally, we\nprovide a novel generalization to $k \\geq 3$ clusters and prove that our\ntechniques can recover the clustering if the gap is constant in this\ngeneralized setting.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 21:24:22 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 17:23:11 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1609.00755", "submitter": "Konstantinos Kakoulis G", "authors": "Ioannis G. Tollis and Konstantinos G. Kakoulis", "title": "Algorithms for Visualizing Phylogenetic Networks", "comments": "Appears in the Proceedings of the 24th International Symposium on\n  Graph Drawing and Network Visualization (GD 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of visualizing phylogenetic networks, which are\nextensions of the Tree of Life in biology. We use a space filling visualization\nmethod, called DAGmaps, in order to obtain clear visualizations using limited\nspace. In this paper, we restrict our attention to galled trees and galled\nnetworks and present linear time algorithms for visualizing them as DAGmaps.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 21:50:48 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Tollis", "Ioannis G.", ""], ["Kakoulis", "Konstantinos G.", ""]]}, {"id": "1609.00790", "submitter": "Charalampos Tsourakakis", "authors": "Ahmad Mahmoody, Charalampos E. Tsourakakis, Eli Upfal", "title": "Scalable Betweenness Centrality Maximization via Sampling", "comments": "Accepted in KDD 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness centrality is a fundamental centrality measure in social network\nanalysis. Given a large-scale network, how can we find the most central nodes?\nThis question is of key importance to numerous important applications that rely\non betweenness centrality, including community detection and understanding\ngraph vulnerability. Despite the large amount of work on designing scalable\napproximation algorithms for betweenness centrality, estimating it on\nlarge-scale networks remains a computational challenge.\n  In this paper, we study the Betweenness Centrality Maximization problem:\ngiven a graph $G=(V,E)$ and a positive integer $k$, find a set $S^* \\subseteq\nV$ that maximizes betweenness centrality subject to the cardinality constraint\n$|S^*| \\leq k$. We present an efficient randomized algorithm that provides a\n$(1-1/e-\\epsilon)$-approximation with high probability, where $\\epsilon>0$. Our\nresults improve the current state-of-the-art result by\nYoshida~\\cite{yoshida2014almost}. Furthermore, we provide theoretical evidence\nfor the validity of a crucial assumption in the literature of betweenness\ncentrality estimation, namely that in real-world networks $O(|V|^2)$ shortest\npaths pass through the top-$k$ central nodes, where $k$ is a constant. On the\nexperimental side, we perform an extensive experimental analysis of our method\non real-world networks, demonstrate its accuracy and scalability, and study\ndifferent properties of central nodes. Finally, we provide three graph mining\napplications of our method.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 04:09:00 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Mahmoody", "Ahmad", ""], ["Tsourakakis", "Charalampos E.", ""], ["Upfal", "Eli", ""]]}, {"id": "1609.00810", "submitter": "Yatao Bian", "authors": "Yatao Bian, Alexey Gronskiy, Joachim M. Buhmann", "title": "Greedy MAXCUT Algorithms and their Information Content", "comments": "This is a longer version of the paper published in 2015 IEEE\n  Information Theory Workshop (ITW)", "journal-ref": null, "doi": "10.1109/ITW.2015.7133122", "report-no": null, "categories": "cs.DS cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAXCUT defines a classical NP-hard problem for graph partitioning and it\nserves as a typical case of the symmetric non-monotone Unconstrained Submodular\nMaximization (USM) problem. Applications of MAXCUT are abundant in machine\nlearning, computer vision and statistical physics. Greedy algorithms to\napproximately solve MAXCUT rely on greedy vertex labelling or on an edge\ncontraction strategy. These algorithms have been studied by measuring their\napproximation ratios in the worst case setting but very little is known to\ncharacterize their robustness to noise contaminations of the input data in the\naverage case. Adapting the framework of Approximation Set Coding, we present a\nmethod to exactly measure the cardinality of the algorithmic approximation sets\nof five greedy MAXCUT algorithms. Their information contents are explored for\ngraph instances generated by two different noise models: the edge reversal\nmodel and Gaussian edge weights model. The results provide insights into the\nrobustness of different greedy heuristics and techniques for MAXCUT, which can\nbe used for algorithm design of general USM problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 10:14:59 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Bian", "Yatao", ""], ["Gronskiy", "Alexey", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1609.00831", "submitter": "Marcin Bienkowski", "authors": "Marcin Bienkowski and Jaroslaw Byrka and Marcin Mucha", "title": "Dynamic beats fixed: On phase-based algorithms for file migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a deterministic 4-competitive algorithm for the online file\nmigration problem, beating the currently best 20-year-old, 4.086-competitive\nMTLM algorithm by Bartal et al. (SODA 1997). Like MTLM, our algorithm also\noperates in phases, but it adapts their lengths dynamically depending on the\ngeometry of requests seen so far. The improvement was obtained by carefully\nanalyzing a linear model (factor-revealing LP) of a single phase of the\nalgorithm. We also show that if an online algorithm operates in phases of fixed\nlength and the adversary is able to modify the graph between phases, then the\ncompetitive ratio is at least 4.086.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 14:18:05 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 23:43:56 GMT"}, {"version": "v3", "created": "Tue, 25 Apr 2017 15:03:53 GMT"}, {"version": "v4", "created": "Sat, 8 Dec 2018 08:37:23 GMT"}, {"version": "v5", "created": "Thu, 20 Jun 2019 22:23:19 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Bienkowski", "Marcin", ""], ["Byrka", "Jaroslaw", ""], ["Mucha", "Marcin", ""]]}, {"id": "1609.00896", "submitter": "Zhao Song", "authors": "Eric Price, Zhao Song", "title": "A Robust Sparse Fourier Transform in the Continuous Setting", "comments": "FOCS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a number of works have studied methods for computing the\nFourier transform in sublinear time if the output is sparse. Most of these have\nfocused on the discrete setting, even though in many applications the input\nsignal is continuous and naive discretization significantly worsens the\nsparsity level.\n  We present an algorithm for robustly computing sparse Fourier transforms in\nthe continuous setting. Let $x(t) = x^*(t) + g(t)$, where $x^*$ has a\n$k$-sparse Fourier transform and $g$ is an arbitrary noise term. Given sample\naccess to $x(t)$ for some duration $T$, we show how to find a\n$k$-Fourier-sparse reconstruction $x'(t)$ with\n  $$\\frac{1}{T}\\int_0^T |x'(t) - x(t) |^2 \\mathrm{d} t \\lesssim\n\\frac{1}{T}\\int_0^T | g(t)|^2 \\mathrm{d}t.$$\n  The sample complexity is linear in $k$ and logarithmic in the signal-to-noise\nratio and the frequency resolution. Previous results with similar sample\ncomplexities could not tolerate an infinitesimal amount of i.i.d. Gaussian\nnoise, and even algorithms with higher sample complexities increased the noise\nby a polynomial factor. We also give new results for how precisely the\nindividual frequencies of $x^*$ can be recovered.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 06:07:40 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Price", "Eric", ""], ["Song", "Zhao", ""]]}, {"id": "1609.01184", "submitter": "Alexander M\\\"acker", "authors": "Alexander M\\\"acker, Manuel Malatyali, Friedhelm Meyer auf der Heide,\n  S\\\"oren Riechers", "title": "Cost-efficient Scheduling on Machines from the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scheduling problem where machines need to be rented from the\ncloud in order to process jobs. There are two types of machines available which\ncan be rented for machine-type dependent prices and for arbitrary durations.\nHowever, a machine-type dependent setup time is required before a machine is\navailable for processing. Jobs arrive online over time, have machine-type\ndependent sizes and have individual deadlines. The objective is to rent\nmachines and schedule jobs so as to meet all deadlines while minimizing the\nrental cost.\n  Since we observe the slack of jobs to have a fundamental influence on the\ncompetitiveness, we study the model when instances are parameterized by their\n(minimum) slack. An instance is called to have a slack of $\\beta$ if, for all\njobs, the difference between the job's release time and the latest point in\ntime at which it needs to be started is at least $\\beta$. While for $\\beta < s$\nno finite competitiveness is possible, our main result is an\n$O(\\frac{c}{\\varepsilon} + \\frac{1}{\\varepsilon^3})$-competitive online\nalgorithm for $\\beta = (1+\\varepsilon)s$ with $\\frac{1}{s} \\leq \\varepsilon\n\\leq 1$, where $s$ and $c$ denotes the largest setup time and the cost ratio of\nthe machine-types, respectively. It is complemented by a lower bound of\n$\\Omega(\\frac{c}{\\varepsilon})$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:44:29 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 09:08:59 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["M\u00e4cker", "Alexander", ""], ["Malatyali", "Manuel", ""], ["der Heide", "Friedhelm Meyer auf", ""], ["Riechers", "S\u00f6ren", ""]]}, {"id": "1609.01361", "submitter": "Zhao Song", "authors": "Xue Chen, Daniel M. Kane, Eric Price, Zhao Song", "title": "Fourier-sparse interpolation without a frequency gap", "comments": "FOCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of estimating a Fourier-sparse signal from noisy\nsamples, where the sampling is done over some interval $[0, T]$ and the\nfrequencies can be \"off-grid\". Previous methods for this problem required the\ngap between frequencies to be above 1/T, the threshold required to robustly\nidentify individual frequencies. We show the frequency gap is not necessary to\nestimate the signal as a whole: for arbitrary $k$-Fourier-sparse signals under\n$\\ell_2$ bounded noise, we show how to estimate the signal with a constant\nfactor growth of the noise and sample complexity polynomial in $k$ and\nlogarithmic in the bandwidth and signal-to-noise ratio.\n  As a special case, we get an algorithm to interpolate degree $d$ polynomials\nfrom noisy measurements, using $O(d)$ samples and increasing the noise by a\nconstant factor in $\\ell_2$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 01:14:30 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Chen", "Xue", ""], ["Kane", "Daniel M.", ""], ["Price", "Eric", ""], ["Song", "Zhao", ""]]}, {"id": "1609.01373", "submitter": "Yuya Higashikawa", "authors": "Binay Bhattacharya, Mordecai J. Golin, Yuya Higashikawa, Tsunehiko\n  Kameda and Naoki Katoh", "title": "Improved Algorithms for Computing $k$-Sink on Dynamic Path Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to finding the $k$-sink on dynamic path networks\nwith general edge capacities. Our first algorithm runs in $O(n \\log n + k^2\n\\log^4 n)$ time, where $n$ is the number of vertices on the given path, and our\nsecond algorithm runs in $O(n \\log^3 n)$ time. Together, they improve upon the\npreviously most efficient $O(kn \\log^2 n)$ time algorithm due to Arumugam et\nal. for all values of $k$. In the case where all the edges have the same\ncapacity, we again present two algorithms that run in $O(n + k^2 \\log^2n)$ time\nand $O(n \\log n)$ time, respectively, and they together improve upon the\npreviously best $O(kn)$ time algorithm due to Higashikawa et al. for all values\nof $k$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 02:19:29 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Bhattacharya", "Binay", ""], ["Golin", "Mordecai J.", ""], ["Higashikawa", "Yuya", ""], ["Kameda", "Tsunehiko", ""], ["Katoh", "Naoki", ""]]}, {"id": "1609.01400", "submitter": "Dekel Tsur", "authors": "Dekel Tsur", "title": "Succinct data-structure for nearest colored node in a tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a succinct data-structure that stores a tree with colors on the\nnodes. Given a node x and a color alpha, the structure finds the nearest node\nto x with color alpha. This results improves the $O(n\\log n)$-bits structure of\nGawrychowski et al.~[CPM 2016].\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 05:57:44 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2016 11:35:48 GMT"}, {"version": "v3", "created": "Sat, 18 Feb 2017 10:05:01 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Tsur", "Dekel", ""]]}, {"id": "1609.01517", "submitter": "Carlo Comin", "authors": "Carlo Comin and Romeo Rizzi", "title": "Faster O(|V|^2|E|W)-Time Energy Algorithms for Optimal Strategy\n  Synthesis in Mean Payoff Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study strengthens the links between Mean Payoff Games (\\MPG{s}) and\nEnergy Games (EG{s}). Firstly, we offer a faster $O(|V|^2|E|W)$\npseudo-polynomial time and $\\Theta(|V|+|E|)$ space deterministic algorithm for\nsolving the Value Problem and Optimal Strategy Synthesis in \\MPG{s}. This\nimproves the best previously known estimates on the pseudo-polynomial time\ncomplexity to: \\[ O(|E|\\log |V|) + \\Theta\\Big(\\sum_{v\\in\nV}\\texttt{deg}_{\\Gamma}(v)\\cdot\\ell_{\\Gamma}(v)\\Big) = O(|V|^2|E|W), \\] where\n$\\ell_{\\Gamma}(v)$ counts the number of times that a certain energy-lifting\noperator $\\delta(\\cdot, v)$ is applied to any $v\\in V$, along a certain\nsequence of Value-Iterations on reweighted \\EG{s}; and\n$\\texttt{deg}_{\\Gamma}(v)$ is the degree of $v$. This improves significantly\nover a previously known pseudo-polynomial time estimate, i.e.\n$\\Theta\\big(|V|^2|E|W + \\sum_{v\\in\nV}\\texttt{deg}_{\\Gamma}(v)\\cdot\\ell_{\\Gamma}(v)\\big)$ \\citep{CR15, CR16}, as\nthe pseudo-polynomiality is now confined to depend solely on $\\ell_\\Gamma$.\nSecondly, we further explore on the relationship between Optimal Positional\nStrategies (OPSs) in \\MPG{s} and Small Energy-Progress Measures (SEPMs) in\nreweighted \\EG{s}. It is observed that the space of all OPSs,\n$\\texttt{opt}_{\\Gamma}\\Sigma^M_0$, admits a unique complete decomposition in\nterms of extremal-SEPM{s} in reweighted EG{s}. This points out what we called\nthe \"Energy-Lattice $\\mathcal{X}^*_{\\Gamma}$ associated to\n$\\texttt{opt}_{\\Gamma}\\Sigma^M_0$\". Finally, it is offered a pseudo-polynomial\ntotal-time recursive procedure for enumerating (w/o repetitions) all the\nelements of $\\mathcal{X}^*_{\\Gamma}$, and for computing the corresponding\npartitioning of $\\texttt{opt}_{\\Gamma}\\Sigma^M_0$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 12:39:43 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Comin", "Carlo", ""], ["Rizzi", "Romeo", ""]]}, {"id": "1609.01600", "submitter": "Imdad Sardharwalla", "authors": "Imdad S. B. Sardharwalla, Sergii Strelchuk, Richard Jozsa", "title": "Quantum conditional query complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a new type of quantum oracle, the quantum conditional\noracle, which provides oracle access to the conditional probabilities\nassociated with an underlying distribution. Amongst other properties, we (a)\nobtain speed-ups over the best known quantum algorithms for identity testing,\nequivalence testing and uniformity testing of probability distributions; (b)\nstudy the power of these oracles for testing properties of boolean functions,\nand obtain an algorithm for checking whether an $n$-input $m$-output boolean\nfunction is balanced or $\\epsilon$-far from balanced; and (c) give a sub-linear\nalgorithm, requiring $\\tilde{O}(n^{3/4}/\\epsilon)$ queries, for testing whether\nan $n$-dimensional quantum state is maximally mixed or not.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:21:54 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Sardharwalla", "Imdad S. B.", ""], ["Strelchuk", "Sergii", ""], ["Jozsa", "Richard", ""]]}, {"id": "1609.01634", "submitter": "Sahar Bsaybes", "authors": "Sahar Bsaybes, Alain Quilliot and Annegret K. Wagler", "title": "Fleet management for autonomous vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VIPAFLEET project consists in developing models and algorithms for man-\naging a fleet of Individual Public Autonomous Vehicles (VIPA). Hereby, we\nconsider a fleet of cars distributed at specified stations in an industrial\narea to supply internal transportation, where the cars can be used in different\nmodes of circulation (tram mode, elevator mode, taxi mode). One goal is to\ndevelop and implement suitable algorithms for each mode in order to satisfy all\nthe requests under an economic point of view by minimizing the total tour\nlength or the makespan. The innovative idea and challenge of the project is to\ndevelop and install a dynamic fleet management system that allows the operator\nto switch between the differ- ent modes within the different periods of the day\naccording to the dynamic transportation demands of the users. We model the\nunderlying online transportation system and propose an according fleet\nmanagement framework, to handle modes, demands and commands. We propose for\neach mode appropriate online algorithms and evaluate their performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 16:18:00 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Bsaybes", "Sahar", ""], ["Quilliot", "Alain", ""], ["Wagler", "Annegret K.", ""]]}, {"id": "1609.01755", "submitter": "Ulf R\\\"uegg", "authors": "Adalat Jabrayilov, Sven Mallach, Petra Mutzel, Ulf R\\\"uegg, and\n  Reinhard von Hanxleden", "title": "Compact Layered Drawings of General Directed Graphs", "comments": "Appears in the Proceedings of the 24th International Symposium on\n  Graph Drawing and Network Visualization (GD 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of layering general directed graphs under height and\npossibly also width constraints. Given a directed graph G = (V,A) and a maximal\nheight, we propose a layering approach that minimizes a weighted sum of the\nnumber of reversed arcs, the arc lengths, and the width of the drawing. We call\nthis the Compact Generalized Layering Problem (CGLP). Here, the width of a\ndrawing is defined as the maximum sum of the number of vertices placed on a\nlayer and the number of dummy vertices caused by arcs traversing the layer. The\nCGLP is NP-hard. We present two MIP models for this problem. The first one\n(EXT) is our extension of a natural formulation for directed acyclic graphs as\nsuggested by Healy and Nikolov. The second one (CGL) is a new formulation based\non partial orderings. Our computational experiments on two benchmark sets show\nthat the CGL formulation can be solved much faster than EXT using standard\ncommercial MIP solvers. Moreover, we suggest a variant of CGL, called MML, that\ncan be seen as a heuristic approach. In our experiments, MML clearly improves\non CGL in terms of running time while it does not considerably increase the\naverage arc lengths and widths of the layouts although it solves a slightly\ndifferent problem where the dummy vertices are not taken into account.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2016 22:09:37 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Jabrayilov", "Adalat", ""], ["Mallach", "Sven", ""], ["Mutzel", "Petra", ""], ["R\u00fcegg", "Ulf", ""], ["von Hanxleden", "Reinhard", ""]]}, {"id": "1609.01817", "submitter": "Jeremy Alm", "authors": "Jeremy F. Alm", "title": "401 and beyond: improved bounds and algorithms for the Ramsey algebra\n  search", "comments": null, "journal-ref": "Journal of Integer Sequences, Vol. 17, 2017", "doi": null, "report-no": null, "categories": "math.NT cs.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss an improvement of an algorithm to search for primes\n$p$ and coset-partitions of Z/pZ* that yield Ramsey algebras over Z/pZ. We also\nprove an upper bound on the modulus p in terms of the number of cosets. We\nhave, as a corollary, that there is no prime $p$ for which there exists a\npartition of Z/pZ* into 13 cosets that yields a 13-color Ramsey algebra. Thus\nA263308(13) = 0.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 03:24:33 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 20:52:40 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Alm", "Jeremy F.", ""]]}, {"id": "1609.01870", "submitter": "Sumit Kumar Jha", "authors": "Sumit Kumar Jha", "title": "Revisiting calculation of moments of number of comparisons used by the\n  randomized quick sort algorithm", "comments": null, "journal-ref": "Discrete Math, Algorithms and Appications. 9(1): 1-6 (2017)", "doi": "10.1142/S179383091750001X", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the method of Kirschenhofer, Prodinger and Tichy to calculate the\nmoments of comparisons used by the quick sort algorithm. We reemphasize that\nthis approach helps in calculating these quantities with less computation. We\nalso point out that as observed by Knuth this method also gives moments for\ntotal path length of a binary search tree built over a random set of n keys.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 08:16:36 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 00:47:07 GMT"}, {"version": "v3", "created": "Sun, 18 Sep 2016 10:05:35 GMT"}, {"version": "v4", "created": "Thu, 29 Sep 2016 09:53:13 GMT"}, {"version": "v5", "created": "Sun, 9 Oct 2016 13:30:54 GMT"}, {"version": "v6", "created": "Fri, 21 Oct 2016 14:57:21 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Jha", "Sumit Kumar", ""]]}, {"id": "1609.02063", "submitter": "Jakob Witzig", "authors": "Isabel Beckenbach, Leon Eifler, Konstantin Fackeldey, Ambros Gleixner,\n  Andreas Grever, Marcus Weber, Jakob Witzig", "title": "Mixed-Integer Programming for Cycle Detection in Non-reversible Markov\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": "ZIB-Report 16-39", "categories": "cs.DS math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new, optimization-based method to exhibit cyclic\nbehavior in non-reversible stochastic processes. While our method is general,\nit is strongly motivated by discrete simulations of ordinary differential\nequations representing non-reversible biological processes, in particular\nmolecular simulations. Here, the discrete time steps of the simulation are\noften very small compared to the time scale of interest, i.e., of the whole\nprocess. In this setting, the detection of a global cyclic behavior of the\nprocess becomes difficult because transitions between individual states may\nappear almost reversible on the small time scale of the simulation. We address\nthis difficulty using a mixed-integer programming model that allows us to\ncompute a cycle of clusters with maximum net flow, i.e., large forward and\nsmall backward probability. For a synthetic genetic regulatory network\nconsisting of a ring-oscillator with three genes, we show that this approach\ncan detect the most productive overall cycle, outperforming classical spectral\nanalysis methods. Our method applies to general non-equilibrium steady state\nsystems such as catalytic reactions, for which the objective value computes the\neffectiveness of the catalyst.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 07:34:42 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Beckenbach", "Isabel", ""], ["Eifler", "Leon", ""], ["Fackeldey", "Konstantin", ""], ["Gleixner", "Ambros", ""], ["Grever", "Andreas", ""], ["Weber", "Marcus", ""], ["Witzig", "Jakob", ""]]}, {"id": "1609.02094", "submitter": "Jelani Nelson", "authors": "Kasper Green Larsen, Jelani Nelson", "title": "Optimality of the Johnson-Lindenstrauss Lemma", "comments": "v2: simplified proof, also added reference to Lev83", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CG cs.DS math.FA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any integers $d, n \\geq 2$ and $1/({\\min\\{n,d\\}})^{0.4999} <\n\\varepsilon<1$, we show the existence of a set of $n$ vectors $X\\subset\n\\mathbb{R}^d$ such that any embedding $f:X\\rightarrow \\mathbb{R}^m$ satisfying\n$$ \\forall x,y\\in X,\\ (1-\\varepsilon)\\|x-y\\|_2^2\\le \\|f(x)-f(y)\\|_2^2 \\le\n(1+\\varepsilon)\\|x-y\\|_2^2 $$ must have $$ m = \\Omega(\\varepsilon^{-2} \\lg n).\n$$ This lower bound matches the upper bound given by the Johnson-Lindenstrauss\nlemma [JL84]. Furthermore, our lower bound holds for nearly the full range of\n$\\varepsilon$ of interest, since there is always an isometric embedding into\ndimension $\\min\\{d, n\\}$ (either the identity map, or projection onto\n$\\mathop{span}(X)$).\n  Previously such a lower bound was only known to hold against linear maps $f$,\nand not for such a wide range of parameters $\\varepsilon, n, d$ [LN16]. The\nbest previously known lower bound for general $f$ was $m =\n\\Omega(\\varepsilon^{-2}\\lg n/\\lg(1/\\varepsilon))$ [Wel74, Lev83, Alo03], which\nis suboptimal for any $\\varepsilon = o(1)$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 18:00:16 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 04:22:35 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Nelson", "Jelani", ""]]}, {"id": "1609.02121", "submitter": "Michael Hamann", "authors": "Christian L. Staudt, Michael Hamann, Alexander Gutfraind, Ilya Safro,\n  and Henning Meyerhenke", "title": "Generating realistic scaled complex networks", "comments": "26 pages, 13 figures, extended version, a preliminary version of the\n  paper was presented at the 5th International Workshop on Complex Networks and\n  their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on generative models is a central project in the emerging field of\nnetwork science, and it studies how statistical patterns found in real networks\ncould be generated by formal rules. Output from these generative models is then\nthe basis for designing and evaluating computational methods on networks, and\nfor verification and simulation studies. During the last two decades, a variety\nof models has been proposed with an ultimate goal of achieving comprehensive\nrealism for the generated networks. In this study, we (a) introduce a new\ngenerator, termed ReCoN; (b) explore how ReCoN and some existing models can be\nfitted to an original network to produce a structurally similar replica, (c)\nuse ReCoN to produce networks much larger than the original exemplar, and\nfinally (d) discuss open problems and promising research directions. In a\ncomparative experimental study, we find that ReCoN is often superior to many\nother state-of-the-art network generation methods. We argue that ReCoN is a\nscalable and effective tool for modeling a given network while preserving\nimportant properties at both micro- and macroscopic scales, and for scaling the\nexemplar data by orders of magnitude in size.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 19:19:47 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 08:47:18 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Staudt", "Christian L.", ""], ["Hamann", "Michael", ""], ["Gutfraind", "Alexander", ""], ["Safro", "Ilya", ""], ["Meyerhenke", "Henning", ""]]}, {"id": "1609.02305", "submitter": "Klaus-Tycho Foerster", "authors": "Klaus-Tycho Foerster, Stefan Schmid, Stefano Vissicchio", "title": "Survey of Consistent Software-Defined Network Updates", "comments": null, "journal-ref": "IEEE Communications Surveys & Tutorials 2019", "doi": "10.1109/COMST.2018.2876749", "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer networks have become a critical infrastructure. In fact, networks\nshould not only meet strict requirements in terms of correctness, availability,\nand performance, but they should also be very flexible and support fast\nupdates, e.g., due to policy changes, increasing traffic, or failures. This\npaper presents a structured survey of mechanism and protocols to update\ncomputer networks in a fast and consistent manner. In particular, we identify\nand discuss the different desirable consistency properties that should be\nprovided throughout a network update, the algorithmic techniques which are\nneeded to meet these consistency properties, and the implications on the speed\nand costs at which updates can be performed. We also explain the relationship\nbetween consistent network update problems and classic algorithmic optimization\nones. While our survey is mainly motivated by the advent of Software-Defined\nNetworks (SDNs) and their primary need for correct and efficient update\ntechniques, the fundamental underlying problems are not new, and we provide a\nhistorical perspective of the subject as well.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 07:34:39 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 15:42:18 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 13:33:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Foerster", "Klaus-Tycho", ""], ["Schmid", "Stefan", ""], ["Vissicchio", "Stefano", ""]]}, {"id": "1609.02443", "submitter": "Martin N\\\"ollenburg", "authors": "Yifan Hu and Martin N\\\"ollenburg", "title": "Proceedings of the 24th International Symposium on Graph Drawing and\n  Network Visualization (GD 2016)", "comments": "Electronic self-archived proceedings. Proceedings are also published\n  by Springer as volume 9801 of the series Lecture Notes in Computer Science", "journal-ref": null, "doi": "10.1007/978-3-319-50106-2", "report-no": null, "categories": "cs.CG cs.DM cs.DS cs.HC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the arXiv index for the electronic proceedings of the 24th\nInternational Symposium on Graph Drawing and Network Visualization (GD 2016),\nwhich was held in Athens, Greece, September 19-21 2016. It contains the\npeer-reviewed and revised accepted papers with an optional appendix.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 14:21:20 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 16:46:36 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Hu", "Yifan", ""], ["N\u00f6llenburg", "Martin", ""]]}, {"id": "1609.02668", "submitter": "Peter Kling", "authors": "Neal Barcelo, Peter Kling, Michael Nugent and Kirk Pruhs", "title": "Optimal Speed Scaling with a Solar Cell", "comments": "extended abstract to appear at COCOA'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of a sensor that consists of a speed-scalable\nprocessor, a battery, and a solar cell that harvests energy from its\nenvironment at a time-invariant recharge rate. The processor must process a\ncollection of jobs of various sizes. Jobs arrive at different times and have\ndifferent deadlines. The objective is to minimize the *recharge rate*, which is\nthe rate at which the device has to harvest energy in order to feasibly\nschedule all jobs. The main result is a polynomial-time combinatorial algorithm\nfor processors with a natural set of discrete speed/power pairs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 06:51:25 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Barcelo", "Neal", ""], ["Kling", "Peter", ""], ["Nugent", "Michael", ""], ["Pruhs", "Kirk", ""]]}, {"id": "1609.02694", "submitter": "Antonella Del Pozzo", "authors": "Silvia Bonomi (DIAG), Antonella Del Pozzo (DIAG, NPA), Maria\n  Potop-Butucaru (NPA), S\\'ebastien Tixeuil (NPA, IUF, LINCS)", "title": "Optimal Self-Stabilizing Mobile Byzantine-Tolerant Regular Register with\n  bounded timestamp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first implementation of a self-stabilizing regular\nregister emulated by $n$ servers that is tolerant to both mobile Byzantine\nagents, and \\emph{transient failures} in a round-free synchronous model.\nDifferently from existing Mobile Byzantine tolerant register implementations,\nthis paper considers a more powerful adversary where (i) the message delay\n(i.e., $\\delta$) and the period of mobile Byzantine agents movement (i.e.,\n$\\Delta$) are completely decoupled and (ii) servers are not aware of their\nstate i.e., they do not know if they have been corrupted or not by a mobile\nByzantine agent.The proposed protocol tolerates \\emph{(i)} any number of\ntransient failures, and \\emph{(ii)} up to $f$ Mobile Byzantine agents. In\naddition, our implementation uses bounded timestamps from the\n$\\mathcal{Z}\\_{13}$ domain and it is optimal with respect to the number of\nservers needed to tolerate $f$ mobile Byzantine agents in the given model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 08:34:31 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 06:36:50 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bonomi", "Silvia", "", "DIAG"], ["Del Pozzo", "Antonella", "", "DIAG, NPA"], ["Potop-Butucaru", "Maria", "", "NPA"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1609.02901", "submitter": "Oren Mangoubi", "authors": "Oren Mangoubi and Aaron Smith", "title": "Rapid Mixing of Geodesic Walks on Manifolds with Positive Curvature", "comments": "To appear in the Annals of Applied Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS math.DG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Markov chain for sampling from the uniform distribution on a\nRiemannian manifold $\\mathcal{M}$, which we call the $\\textit{geodesic walk}$.\nWe prove that the mixing time of this walk on any manifold with positive\nsectional curvature $C_{x}(u,v)$ bounded both above and below by $0 <\n\\mathfrak{m}_{2} \\leq C_{x}(u,v) \\leq \\mathfrak{M}_2 < \\infty$ is\n$\\mathcal{O}^*\\left(\\frac{\\mathfrak{M}_2}{\\mathfrak{m}_2}\\right)$. In\nparticular, this bound on the mixing time does not depend explicitly on the\ndimension of the manifold. In the special case that $\\mathcal{M}$ is the\nboundary of a convex body, we give an explicit and computationally tractable\nalgorithm for approximating the exact geodesic walk. As a consequence, we\nobtain an algorithm for sampling uniformly from the surface of a convex body\nthat has running time bounded solely in terms of the curvature of the body.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 19:34:15 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 22:28:40 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Mangoubi", "Oren", ""], ["Smith", "Aaron", ""]]}, {"id": "1609.02957", "submitter": "Kevin Deweese", "authors": "Kevin Deweese, John R. Gilbert, Gary Miller, Richard Peng, Hao Ran Xu,\n  Shen Chen Xu", "title": "An Empirical Study of Cycle Toggling Based Laplacian Solvers", "comments": "SIAM CSC Workshop 2016 pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of linear solvers for graph Laplacians based on the\ncombinatorial cycle adjustment methodology proposed by\n[Kelner-Orecchia-Sidford-Zhu STOC-13]. The approach finds a dual flow solution\nto this linear system through a sequence of flow adjustments along cycles. We\nstudy both data structure oriented and recursive methods for handling these\nadjustments.\n  The primary difficulty faced by this approach, updating and querying long\ncycles, motivated us to study an important special case: instances where all\ncycles are formed by fundamental cycles on a length $n$ path. Our methods\ndemonstrate significant speedups over previous implementations, and are\ncompetitive with standard numerical routines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 22:10:03 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Deweese", "Kevin", ""], ["Gilbert", "John R.", ""], ["Miller", "Gary", ""], ["Peng", "Richard", ""], ["Xu", "Hao Ran", ""], ["Xu", "Shen Chen", ""]]}, {"id": "1609.03000", "submitter": "Diptarama Hendrian", "authors": "Shintaro Narisada, Diptarama Hendrian, Kazuyuki Narisawa, Shunsuke\n  Inenaga, Ayumi Shinohara", "title": "Efficient computation of longest single-arm-gapped palindromes in a\n  string", "comments": "19 pages, 11 figures", "journal-ref": "Theoretical Computer Science, 2019", "doi": "10.1016/j.tcs.2019.10.025", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce new types of approximate palindromes called\nsingle-arm-gapped palindromes (shortly SAGPs). A SAGP contains a gap in either\nits left or right arm, which is in the form of either $wguc u^R w^R$ or $wuc\nu^Rgw^R$, where $w$ and $u$ are non-empty strings, $w^R$ and $u^R$ are\nrespectively the reversed strings of $w$ and $u$, $g$ is a string called a gap,\nand $c$ is either a single character or the empty string. Here we call $wu$ and\n$u^R w^R$ the arm of the SAGP, and $|uv|$ the length of the arm. We classify\nSAGPs into two groups: those which have $ucu^R$ as a maximal palindrome\n(type-1), and the others (type-2). We propose several algorithms to compute\ntype-1 SAGPs with longest arms occurring in a given string, based on suffix\narrays. Then, we propose a linear-time algorithm to compute all type-1 SAGPs\nwith longest arms, based on suffix trees. Also, we show how to compute type-2\nSAGPs with longest arms in linear time. We also perform some preliminary\nexperiments to show practical performances of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 05:03:01 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 06:51:16 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 03:38:57 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 01:53:01 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 05:54:12 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Narisada", "Shintaro", ""], ["Hendrian", "Diptarama", ""], ["Narisawa", "Kazuyuki", ""], ["Inenaga", "Shunsuke", ""], ["Shinohara", "Ayumi", ""]]}, {"id": "1609.03136", "submitter": "Teruaki Kitasuka", "authors": "Teruaki Kitasuka and Masahiro Iida", "title": "A Heuristic Method of Generating Diameter 3 Graphs for Order/Degree\n  Problem", "comments": "Proceedings of 10th IEEE/ACM International Symposium on\n  Networks-on-Chip, Nara, Japan, Aug. 2016", "journal-ref": null, "doi": "10.1109/NOCS.2016.7579334", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a heuristic method that generates a graph for order/degree\nproblem. Target graphs of our heuristics have large order (> 4000) and diameter\n3. We describe the ob- servation of smaller graphs and basic structure of our\nheuristics. We also explain an evaluation function of each edge for efficient\n2-opt local search. Using them, we found the best solutions for several graphs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 08:56:02 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Kitasuka", "Teruaki", ""], ["Iida", "Masahiro", ""]]}, {"id": "1609.03251", "submitter": "Jaewoo Lee", "authors": "Jaewoo Lee and Daniel Kifer", "title": "Postprocessing for Iterative Differentially Private Algorithms", "comments": "5 pages, TPDP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative algorithms for differential privacy run for a fixed number of\niterations, where each iteration learns some information from data and produces\nan intermediate output. However, the algorithm only releases the output of the\nlast iteration, and from which the accuracy of algorithm is judged. In this\npaper, we propose a post-processing algorithm that seeks to improve the\naccuracy by incorporating the knowledge on the data contained in intermediate\noutputs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 02:16:07 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Lee", "Jaewoo", ""], ["Kifer", "Daniel", ""]]}, {"id": "1609.03261", "submitter": "Lihua Lei", "authors": "Lihua Lei and Michael I. Jordan", "title": "Less than a Single Pass: Stochastically Controlled Stochastic Gradient\n  Method", "comments": "Add Lemma B.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and analyze a procedure for gradient-based optimization that we\nrefer to as stochastically controlled stochastic gradient (SCSG). As a member\nof the SVRG family of algorithms, SCSG makes use of gradient estimates at two\nscales, with the number of updates at the faster scale being governed by a\ngeometric random variable. Unlike most existing algorithms in this family, both\nthe computation cost and the communication cost of SCSG do not necessarily\nscale linearly with the sample size $n$; indeed, these costs are independent of\n$n$ when the target accuracy is low. An experimental evaluation on real\ndatasets confirms the effectiveness of SCSG.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 03:35:29 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 00:25:50 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 04:18:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Lei", "Lihua", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1609.03545", "submitter": "Hayko Riemenschneider", "authors": "Julien Weissenberg and Hayko Riemenschneider and Ralf Dragon and Luc\n  Van Gool", "title": "Dilemma First Search for Effortless Optimization of NP-Hard Problems", "comments": "To be published at ICPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To tackle the exponentiality associated with NP-hard problems, two paradigms\nhave been proposed. First, Branch & Bound, like Dynamic Programming, achieve\nefficient exact inference but requires extensive information and analysis about\nthe problem at hand. Second, meta-heuristics are easier to implement but\ncomparatively inefficient. As a result, a number of problems have been left\nunoptimized and plain greedy solutions are used. We introduce a theoretical\nframework and propose a powerful yet simple search method called Dilemma First\nSearch (DFS). DFS exploits the decision heuristic needed for the greedy\nsolution for further optimization. DFS is useful when it is hard to design\nefficient exact inference. We evaluate DFS on two problems: First, the Knapsack\nproblem, for which efficient algorithms exist, serves as a toy example. Second,\nDecision Tree inference, where state-of-the-art algorithms rely on the greedy\nor randomness-based solutions. We further show that decision trees benefit from\noptimizations that are performed in a fraction of the iterations required by a\nrandom-based search.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 19:36:02 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Weissenberg", "Julien", ""], ["Riemenschneider", "Hayko", ""], ["Dragon", "Ralf", ""], ["Van Gool", "Luc", ""]]}, {"id": "1609.03645", "submitter": "EPTCS", "authors": "Johannes Waldmann", "title": "Efficient Completion of Weighted Automata", "comments": "In Proceedings TERMGRAPH 2016, arXiv:1609.03014", "journal-ref": "EPTCS 225, 2016, pp. 55-62", "doi": "10.4204/EPTCS.225.8", "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider directed graphs with edge labels from a semiring. We present an\nalgorithm that allows efficient execution of queries for existence and weights\nof paths, and allows updates of the graph: adding nodes and edges, and changing\nweights of existing edges.\n  We apply this method in the construction of matchbound certificates for\nautomatically proving termination of string rewriting. We re-implement the\ndecomposition/completion algorithm of Endrullis et al. (2006) in our framework,\nand achieve comparable performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 00:17:43 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Waldmann", "Johannes", ""]]}, {"id": "1609.03668", "submitter": "Yohei Ueki", "authors": "Yohei Ueki, Diptarama, Masatoshi Kurihara, Yoshiaki Matsuoka, Kazuyuki\n  Narisawa, Ryo Yoshinaka, Hideo Bannai, Shunsuke Inenaga, Ayumi Shinohara", "title": "Longest Common Subsequence in at Least $k$ Length Order-Isomorphic\n  Substrings", "comments": "14 pages, 7 figures, contains erratum to Springer's version (SOFSEM\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the longest common subsequence (LCS) problem with the restriction\nthat the common subsequence is required to consist of at least $k$ length\nsubstrings. First, we show an $O(mn)$ time algorithm for the problem which\ngives a better worst-case running time than existing algorithms, where $m$ and\n$n$ are lengths of the input strings. Furthermore, we mainly consider the LCS\nin at least $k$ length order-isomorphic substrings problem. We show that the\nproblem can also be solved in $O(mn)$ worst-case time by an easy-to-implement\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 03:54:52 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2016 15:41:58 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 05:43:08 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Ueki", "Yohei", ""], ["Diptarama", "", ""], ["Kurihara", "Masatoshi", ""], ["Matsuoka", "Yoshiaki", ""], ["Narisawa", "Kazuyuki", ""], ["Yoshinaka", "Ryo", ""], ["Bannai", "Hideo", ""], ["Inenaga", "Shunsuke", ""], ["Shinohara", "Ayumi", ""]]}, {"id": "1609.03769", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Alessandro Lazaric and Michal Valko", "title": "Analysis of Kelner and Levin graph sparsification algorithm for a\n  streaming setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new proof to show that the incremental resparsification algorithm\nproposed by Kelner and Levin (2013) produces a spectral sparsifier in high\nprobability. We rigorously take into account the dependencies across subsequent\nresparsifications using martingale inequalities, fixing a flaw in the original\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 11:18:03 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Calandriello", "Daniele", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""]]}, {"id": "1609.03932", "submitter": "Michael Mahoney", "authors": "David Lawlor and Tam\\'as Budav\\'ari and Michael W. Mahoney", "title": "Mapping the Similarities of Spectra: Global and Locally-biased\n  Approaches to SDSS Galaxy Data", "comments": "34 pages. A modified version of this paper has been accepted to The\n  Astrophysical Journal", "journal-ref": null, "doi": "10.3847/0004-637X/833/1/26", "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a novel spectral graph technique, that of locally-biased\nsemi-supervised eigenvectors, to study the diversity of galaxies. This\ntechnique permits us to characterize empirically the natural variations in\nobserved spectra data, and we illustrate how this approach can be used in an\nexploratory manner to highlight both large-scale global as well as small-scale\nlocal structure in Sloan Digital Sky Survey (SDSS) data. We use this method in\na way that simultaneously takes into account the measurements of spectral lines\nas well as the continuum shape. Unlike Principal Component Analysis, this\nmethod does not assume that the Euclidean distance between galaxy spectra is a\ngood global measure of similarity between all spectra, but instead it only\nassumes that local difference information between similar spectra is reliable.\nMoreover, unlike other nonlinear dimensionality methods, this method can be\nused to characterize very finely both small-scale local as well as large-scale\nglobal properties of realistic noisy data. The power of the method is\ndemonstrated on the SDSS Main Galaxy Sample by illustrating that the derived\nembeddings of spectra carry an unprecedented amount of information. By using a\nstraightforward global or unsupervised variant, we observe that the main\nfeatures correlate strongly with star formation rate and that they clearly\nseparate active galactic nuclei. Computed parameters of the method can be used\nto describe line strengths and their interdependencies. By using a\nlocally-biased or semi-supervised variant, we are able to focus on typical\nvariations around specific objects of astronomical interest. We present several\nexamples illustrating that this approach can enable new discoveries in the data\nas well as a detailed understanding of very fine local structure that would\notherwise be overwhelmed by large-scale noise and global trends in the data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 16:46:51 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Lawlor", "David", ""], ["Budav\u00e1ri", "Tam\u00e1s", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1609.03993", "submitter": "Markus Wagner", "authors": "Tobias Friedrich, Timo K\\\"otzing, Markus Wagner", "title": "A Generic Bet-and-run Strategy for Speeding Up Traveling Salesperson and\n  Minimum Vertex Cover", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy for improving optimization algorithms is to restart the\nalgorithm when it is believed to be trapped in an inferior part of the search\nspace. However, while specific restart strategies have been developed for\nspecific problems (and specific algorithms), restarts are typically not\nregarded as a general tool to speed up an optimization algorithm. In fact, many\noptimization algorithms do not employ restarts at all.\n  Recently, \"bet-and-run\" was introduced in the context of mixed-integer\nprogramming, where first a number of short runs with randomized initial\nconditions is made, and then the most promising run of these is continued. In\nthis article, we consider two classical NP-complete combinatorial optimization\nproblems, traveling salesperson and minimum vertex cover, and study the\neffectiveness of different bet-and-run strategies. In particular, our restart\nstrategies do not take any problem knowledge into account, nor are tailored to\nthe optimization algorithm. Therefore, they can be used off-the-shelf. We\nobserve that state-of-the-art solvers for these problems can benefit\nsignificantly from restarts on standard benchmark instances.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 19:36:45 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Friedrich", "Tobias", ""], ["K\u00f6tzing", "Timo", ""], ["Wagner", "Markus", ""]]}, {"id": "1609.04029", "submitter": "Zhi-Zhong Chen", "authors": "Zhi-Zhong Chen, Eita Machida, Lusheng Wang", "title": "A Cubic-Time 2-Approximation Algorithm for rSPR Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to hybridization events in evolution, studying two different genes of a\nset of species may yield two related but different phylogenetic trees for the\nset of species. In this case, we want to measure the dissimilarity of the two\ntrees. The rooted subtree prune and regraft (rSPR) distance of the two trees\nhas been used for this purpose. The problem of computing the rSPR distance of\ntwo given trees has many applications but is unfortunately NP-hard. The\npreviously best approximation algorithm for rSPR distance achieves a ratio of\n2.5 and it was open whether a better approximation algorithm for rSPR distance\nexists. In this paper, we answer this question in the affirmative by presenting\na cubic-time approximation algorithm for rSPR distance that achieves a ratio of\n2. Our algorithm is based on the new notion of key and a number of new\nstructural lemmas. The algorithm is fairly simple and the proof of its\ncorrectness is intuitively understandable albeit complicated.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 20:10:00 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 14:23:42 GMT"}, {"version": "v3", "created": "Sat, 4 Mar 2017 09:33:45 GMT"}, {"version": "v4", "created": "Sun, 2 Apr 2017 09:03:55 GMT"}, {"version": "v5", "created": "Sun, 2 Jul 2017 07:35:17 GMT"}, {"version": "v6", "created": "Thu, 27 Jul 2017 01:46:06 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Chen", "Zhi-Zhong", ""], ["Machida", "Eita", ""], ["Wang", "Lusheng", ""]]}, {"id": "1609.04051", "submitter": "Nika Haghtalab", "authors": "Avrim Blum, Ioannis Caragiannis, Nika Haghtalab, Ariel D. Procaccia,\n  Eviatar B. Procaccia, Rohit Vaish", "title": "Opting Into Optimal Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of designing optimal, individually rational matching\nmechanisms (in a general sense, allowing for cycles in directed graphs), where\neach player --- who is associated with a subset of vertices --- matches as many\nof his own vertices when he opts into the matching mechanism as when he opts\nout. We offer a new perspective on this problem by considering an arbitrary\ngraph, but assuming that vertices are associated with players at random. Our\nmain result asserts that, under certain conditions, any fixed optimal matching\nis likely to be individually rational up to lower-order terms. We also show\nthat a simple and practical mechanism is (fully) individually rational, and\nlikely to be optimal up to lower-order terms. We discuss the implications of\nour results for market design in general, and kidney exchange in particular.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 21:04:31 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Blum", "Avrim", ""], ["Caragiannis", "Ioannis", ""], ["Haghtalab", "Nika", ""], ["Procaccia", "Ariel D.", ""], ["Procaccia", "Eviatar B.", ""], ["Vaish", "Rohit", ""]]}, {"id": "1609.04087", "submitter": "EPTCS", "authors": "Massimo Benerecetti (Universit\\`a degli Studi di Napoli Federico II),\n  Daniele Dell'Erba (Universit\\`a degli Studi di Napoli Federico II), Fabio\n  Mogavero (University of Oxford)", "title": "A Delayed Promotion Policy for Parity Games", "comments": "In Proceedings GandALF 2016, arXiv:1609.03648", "journal-ref": "EPTCS 226, 2016, pp. 30-45", "doi": "10.4204/EPTCS.226.3", "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity games are two-player infinite-duration games on graphs that play a\ncrucial role in various fields of theoretical computer science. Finding\nefficient algorithms to solve these games in practice is widely acknowledged as\na core problem in formal verification, as it leads to efficient solutions of\nthe model-checking and satisfiability problems of expressive temporal logics,\ne.g., the modal muCalculus. Their solution can be reduced to the problem of\nidentifying sets of positions of the game, called dominions, in each of which a\nplayer can force a win by remaining in the set forever. Recently, a novel\ntechnique to compute dominions, called priority promotion, has been proposed,\nwhich is based on the notions of quasi dominion, a relaxed form of dominion,\nand dominion space. The underlying framework is general enough to accommodate\ndifferent instantiations of the solution procedure, whose correctness is\nensured by the nature of the space itself. In this paper we propose a new such\ninstantiation, called delayed promotion, that tries to reduce the possible\nexponential behaviours exhibited by the original method in the worst case. The\nresulting procedure not only often outperforms the original priority promotion\napproach, but so far no exponential worst case is known.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 00:57:52 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Benerecetti", "Massimo", "", "Universit\u00e0 degli Studi di Napoli Federico II"], ["Dell'Erba", "Daniele", "", "Universit\u00e0 degli Studi di Napoli Federico II"], ["Mogavero", "Fabio", "", "University of Oxford"]]}, {"id": "1609.04347", "submitter": "Ramanujan M. S.", "authors": "Daniel Lokshtanov, M. S. Ramanujan, Saket Saurabh", "title": "A Linear Time Parameterized Algorithm for Directed Feedback Vertex Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Directed Feedback Vertex Set (DFVS) problem, the input is a directed\ngraph $D$ on $n$ vertices and $m$ edges, and an integer $k$. The objective is\nto determine whether there exists a set of at most $k$ vertices intersecting\nevery directed cycle of $D$. Whether or not DFVS admits a fixed parameter\ntractable (FPT) algorithm was considered the most important open problem in\nparameterized complexity until Chen, Liu, Lu, O'Sullivan and Razgon [JACM 2008]\nanswered the question in the affirmative. They gave an algorithm for the\nproblem with running time $O(k!4^kk^4nm)$. Since then, no faster algorithm for\nthe problem has been found. In this paper, we give an algorithm for DFVS with\nrunning time $O(k!4^kk^5(n+m))$. Our algorithm is the first algorithm for DFVS\nwith linear dependence on input size. Furthermore, the asymptotic dependence of\nthe running time of our algorithm on the parameter $k$ matches up to a factor\n$k$ the algorithm of Chen, Liu, Lu, O'Sullivan and Razgon.\n  On the way to designing our algorithm for DFVS, we give a general methodology\nto shave off a factor of $n$ from iterative-compression based algorithms for a\nfew other well-studied covering problems in parameterized complexity. We\ndemonstrate the applicability of this technique by speeding up by a factor of\n$n$, the current best FPT algorithms for Multicut [STOC 2011, SICOMP 2014] and\nDirected Subset Feedback Vertex Set [ICALP 2012, TALG 2014].\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 17:03:19 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Ramanujan", "M. S.", ""], ["Saurabh", "Saket", ""]]}, {"id": "1609.04350", "submitter": "Haishuai Wang", "authors": "Haishuai Wang", "title": "Time-Variant Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are commonly used to represent objects, such as images and text, for\npattern classification. In a dynamic world, an object may continuously evolve\nover time, and so does the graph extracted from the underlying object. These\nchanges in graph structure with respect to the temporal order present a new\nrepresentation of the graph, in which an object corresponds to a set of\ntime-variant graphs. In this paper, we formulate a novel time-variant graph\nclassification task and propose a new graph feature, called a graph-shapelet\npattern, for learning and classifying time-variant graphs. Graph-shapelet\npatterns are compact and discriminative graph transformation subsequences. A\ngraph-shapelet pattern can be regarded as a graphical extension of a shapelet\n-- a class of discriminative features designed for vector-based temporal data\nclassification. To discover graph-shapelet patterns, we propose to convert a\ntime-variant graph sequence into time-series data and use the discovered\nshapelets to find graph transformation subsequences as graph-shapelet patterns.\nBy converting each graph-shapelet pattern into a unique tokenized graph\ntransformation sequence, we can measure the similarity between two\ngraph-shapelet patterns and therefore classify time-variant graphs. Experiments\non both synthetic and real-world data demonstrate the superior performance of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 17:13:36 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 19:15:51 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Wang", "Haishuai", ""]]}, {"id": "1609.04471", "submitter": "Hantao Zhang Dr.", "authors": "Hantao Zhang, Baoluo Meng, Yiwen Liang", "title": "Sort Race", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting is one of the oldest computing problems and is still very important\nin the age of big data. Various algorithms and implementation techniques have\nbeen proposed. In this study, we focus on comparison based, internal sorting\nalgorithms. We created 12 data types of various sizes for experiments and\ntested extensively various implementations in a single setting. Using some\neffective techniques, we discovered that quicksort is adaptive to nearly sorted\ninputs and is still the best overall sorting algorithm. We also identified\nwhich techniques are effective in timsort, one of the most popular and\nefficient sorting method based on natural mergesort, and created our version of\nmergesort, which runs faster than timsort on nearly sorted instances. Our\nimplementations of quicksort and mergesort are different from other\nimplementations reported in all textbooks or research articles, faster than any\nversion of the C library qsort functions, not only for randomly generated data,\nbut also for various types of nearly sorted data. This experiment can help the\nuser to choose the best sorting algorithm for the hard sorting job at hand.\nThis work provides a platform for anyone to test their own sorting algorithm\nagainst the best in the field.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 22:54:31 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Zhang", "Hantao", ""], ["Meng", "Baoluo", ""], ["Liang", "Yiwen", ""]]}, {"id": "1609.04512", "submitter": "William Devanny", "authors": "Juan Jos\\'e Besa Vial, William E. Devanny, David Eppstein, Michael T.\n  Goodrich", "title": "Scheduling Autonomous Vehicle Platoons Through an Unregulated\n  Intersection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various versions of the problem of scheduling platoons of autonomous\nvehicles through an unregulated intersection, where an algorithm must schedule\nwhich platoons should wait so that others can go through, so as to minimize the\nmaximum delay for any vehicle. We provide polynomial-time algorithms for\nconstructing such schedules for a $k$-way merge intersection, for constant $k$,\nand for a crossing intersection involving two-way traffic. We also show that\nthe more general problem of scheduling autonomous platoons through an\nintersection that includes both a $k$-way merge, for non-constant $k$, and a\ncrossing of two-way traffic is NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 05:09:24 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Vial", "Juan Jos\u00e9 Besa", ""], ["Devanny", "William E.", ""], ["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""]]}, {"id": "1609.04541", "submitter": "Johann Bengua", "authors": "Johann A. Bengua and Ho N. Phien and Hoang D. Tuan and Minh N. Do", "title": "Matrix Product State for Higher-Order Tensor Compression and\n  Classification", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TSP.2017.2703882", "report-no": null, "categories": "stat.ML cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces matrix product state (MPS) decomposition as a new and\nsystematic method to compress multidimensional data represented by higher-order\ntensors. It solves two major bottlenecks in tensor compression: computation and\ncompression quality. Regardless of tensor order, MPS compresses tensors to\nmatrices of moderate dimension which can be used for classification. Mainly\nbased on a successive sequence of singular value decompositions (SVD), MPS is\nquite simple to implement and arrives at the global optimal matrix, bypassing\nlocal alternating optimization, which is not only computationally expensive but\ncannot yield the global solution. Benchmark results show that MPS can achieve\nbetter classification performance with favorable computation cost compared to\nother tensor compression methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 09:04:25 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Bengua", "Johann A.", ""], ["Phien", "Ho N.", ""], ["Tuan", "Hoang D.", ""], ["Do", "Minh N.", ""]]}, {"id": "1609.04618", "submitter": "Giovanni Manzini", "authors": "Giovanni Manzini", "title": "From H&M to Gap for Lightweight BWT Merging", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Holt and McMillan [Bionformatics 2014, ACM-BCB 2014] have proposed\na simple and elegant algorithm to merge the Burrows-Wheeler transforms of a\nfamily of strings. In this paper we show that the H&M algorithm can be improved\nso that, in addition to merging the BWTs, it can also merge the Longest Common\nPrefix (LCP) arrays. The new algorithm, called Gap because of how it operates,\nhas the same asymptotic cost as the H&M algorithm and requires additional space\nonly for storing the LCP values.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 13:03:52 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Manzini", "Giovanni", ""]]}, {"id": "1609.04661", "submitter": "Alessandro Perelli", "authors": "Alessandro Perelli, Michael Lexa, Ali Can, Mike E. Davies", "title": "Compressive Computed Tomography Reconstruction through Denoising\n  Approximate Message Passing", "comments": "38 pages, 16 figures, to be published in SIAM Journal on Imaging\n  Sciences", "journal-ref": "SIAM Journal on Imaging Sciences, vol. 13, n. 4, pp. 1860-1897,\n  2020", "doi": "10.1137/19M1310013", "report-no": null, "categories": "cs.DS math.OC physics.comp-ph physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray Computed Tomography (CT) reconstruction from a sparse number of views\nis a useful way to reduce either the radiation dose or the acquisition time,\nfor example in fixed-gantry CT systems, however this results in an ill-posed\ninverse problem whose solution is typically computationally demanding.\nApproximate Message Passing (AMP) techniques represent the state of the art for\nsolving under-sampling Compressed Sensing problems with random linear\nmeasurements but there are still not clear solutions on how AMP should be\nmodified and how it performs with real world problems. This paper investigates\nthe question of whether we can employ an AMP framework for real sparse view CT\nimaging? The proposed algorithm for approximate inference in tomographic\nreconstruction incorporates a number of advances from within the AMP community,\nresulting in the Denoising Generalized Approximate Message Passing CT algorithm\n(D-GAMP-CT). Specifically, this exploits the use of sophisticated image\ndenoisers to regularize the reconstruction. While in order to reduce the\nprobability of divergence the (Radon) system and Poisson non-linear noise model\nare treated separately, exploiting the existence of efficient preconditioners\nfor the former and the generalized noise modelling in GAMP for the latter.\nExperiments with simulated and real CT baggage scans confirm that the\nperformance of the proposed algorithm outperforms statistical CT optimization\nsolvers.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 14:15:10 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 15:35:38 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 18:00:38 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Perelli", "Alessandro", ""], ["Lexa", "Michael", ""], ["Can", "Ali", ""], ["Davies", "Mike E.", ""]]}, {"id": "1609.04722", "submitter": "Zhiwei Lin", "authors": "Zhiwei Lin and Hui Wang and Cees H. Elzinga", "title": "Concordance and the Smallest Covering Set of Preference Orderings", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.GT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference orderings are orderings of a set of items according to the\npreferences (of judges). Such orderings arise in a variety of domains,\nincluding group decision making, consumer marketing, voting and machine\nlearning. Measuring the mutual information and extracting the common patterns\nin a set of preference orderings are key to these areas. In this paper we deal\nwith the representation of sets of preference orderings, the quantification of\nthe degree to which judges agree on their ordering of the items (i.e. the\nconcordance), and the efficient, meaningful description of such sets.\n  We propose to represent the orderings in a subsequence-based feature space\nand present a new algorithm to calculate the size of the set of all common\nsubsequences - the basis of a quantification of concordance, not only for pairs\nof orderings but also for sets of orderings. The new algorithm is fast and\nstorage efficient with a time complexity of only $O(Nn^2)$ for the orderings of\n$n$ items by $N$ judges and a space complexity of only $O(\\min\\{Nn,n^2\\})$.\n  Also, we propose to represent the set of all $N$ orderings through a smallest\nset of covering preferences and present an algorithm to construct this smallest\ncovering set.\n  The source code for the algorithms is available at\nhttps://github.com/zhiweiuu/secs\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 16:24:45 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 13:37:23 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2016 07:58:02 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Lin", "Zhiwei", ""], ["Wang", "Hui", ""], ["Elzinga", "Cees H.", ""]]}, {"id": "1609.04723", "submitter": "James Newling", "authors": "James Newling and Fran\\c{c}ois Fleuret", "title": "K-Medoids For K-Means Seeding", "comments": "v1: (24 pages, 9 figures) v2: not at 33-rd ICML: forgot to modify\n  .sty file. Reordered sections. Simplified to be specific to K-means seeding.\n  New experiments. v3: (22 pages, 10 figures) Modified .sty file. Minor\n  cosmetic changes. v4: added references and disussion of 2 related works v5:\n  NIPS camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We run experiments showing that algorithm clarans (Ng et al., 2005) finds\nbetter K-medoids solutions than the Voronoi iteration algorithm. This finding,\nalong with the similarity between the Voronoi iteration algorithm and Lloyd's\nK-means algorithm, suggests that clarans may be an effective K-means\ninitializer. We show that this is the case, with clarans outperforming other\nseeding algorithms on 23/23 datasets with a mean decrease over K-means++ of 30%\nfor initialization mse and 3% or final mse. We describe how the complexity and\nruntime of clarans can be improved, making it a viable initialization scheme\nfor large datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 16:25:37 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2017 16:21:58 GMT"}, {"version": "v3", "created": "Thu, 12 Jan 2017 17:00:46 GMT"}, {"version": "v4", "created": "Wed, 31 May 2017 13:40:01 GMT"}, {"version": "v5", "created": "Sat, 4 Nov 2017 13:10:41 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Newling", "James", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "1609.04735", "submitter": "Bruno Silvestre", "authors": "Vinicius N. Medeiros, Douglas V. Santana, Bruno Silvestre, Vinicius da\n  C. M. Borges", "title": "RALL - Routing-Aware Of Path Length, Link Quality, And Traffic Load For\n  Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3019612.3019730", "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to the enormous variety of application scenarios and ubiquity,Internet of\nThings (IoT) brought a new perspective of applications for the current and\nfuture Internet. The Wireless Sensor Networks provide key devices for\ndeveloping the IoT communication paradigm, such as the sensors collecting\nvarious kind of information and the routing and MAC protocols. However, this\ntype of network has strong power consumption and transmission capacity\nrestrictions (low speed wireless links and subject to interference). In this\ncontext, it is necessary to develop solutions that enable a more efficient\ncommunication based on the optimized utilization of the network resources. This\npapers aims to present a multi-objective routing algorithm, named Routing-Aware\nof path Length, Link quality, and traffic Load (RALL), that seeks to balance\nthree objectives: to minimize bottlenecks, to minimize path length, and to\navoid links with low quality. RALL results in good performance when taking into\nconsideration delivery rate, overhead, delay, and power consumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 16:59:05 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Medeiros", "Vinicius N.", ""], ["Santana", "Douglas V.", ""], ["Silvestre", "Bruno", ""], ["Borges", "Vinicius da C. M.", ""]]}, {"id": "1609.04918", "submitter": "Jimmy Wu", "authors": "Alex Khodaverdian, Benjamin Weitz, Jimmy Wu, Nir Yosef", "title": "Steiner Network Problems on Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a temporal Steiner network problem in which a graph, as well as\nchanges to its edges and/or vertices over a set of discrete times, are given as\ninput; the goal is to find a minimal subgraph satisfying a set of $k$\ntime-sensitive connectivity demands. We show that this problem, $k$-Temporal\nSteiner Network ($k$-TSN), is NP-hard to approximate to a factor of $k -\n\\epsilon$, for every fixed $k \\geq 2$ and $\\epsilon > 0$. This bound is tight,\nas certified by a trivial approximation algorithm. Conceptually this\ndemonstrates, in contrast to known results for traditional Steiner problems,\nthat a time dimension adds considerable complexity even when the problem is\noffline.\n  We also discuss special cases of $k$-TSN in which the graph changes satisfy a\nmonotonicity property. We show approximation-preserving reductions from\nmonotonic $k$-TSN to well-studied problems such as Priority Steiner Tree and\nDirected Steiner Tree, implying improved approximation algorithms.\n  Lastly, $k$-TSN and its variants arise naturally in computational biology; to\nfacilitate such applications, we devise an integer linear program for $k$-TSN\nbased on network flows.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 06:49:22 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 03:30:55 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Khodaverdian", "Alex", ""], ["Weitz", "Benjamin", ""], ["Wu", "Jimmy", ""], ["Yosef", "Nir", ""]]}, {"id": "1609.04951", "submitter": "Florian Sikora", "authors": "Riccardo Dondi, Florian Sikora", "title": "Finding Disjoint Paths on Edge-Colored Graphs: More Tractability Results", "comments": "Journal version in JOCO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding the maximum number of vertex-disjoint uni-color paths\nin an edge-colored graph (called MaxCDP) has been recently introduced in\nliterature, motivated by applications in social network analysis. In this paper\nwe investigate how the complexity of the problem depends on graph parameters\n(namely the number of vertices to remove to make the graph a collection of\ndisjoint paths and the size of the vertex cover of the graph), which makes\nsense since graphs in social networks are not random and have structure. The\nproblem was known to be hard to approximate in polynomial time and not\nfixed-parameter tractable (FPT) for the natural parameter. Here, we show that\nit is still hard to approximate, even in FPT-time. Finally, we introduce a new\nvariant of the problem, called MaxCDDP, whose goal is to find the maximum\nnumber of vertex-disjoint and color-disjoint uni-color paths. We extend some of\nthe results of MaxCDP to this new variant, and we prove that unlike MaxCDP,\nMaxCDDP is already hard on graphs at distance two from disjoint paths.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 08:44:58 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 12:16:28 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Dondi", "Riccardo", ""], ["Sikora", "Florian", ""]]}, {"id": "1609.05110", "submitter": "Florent Foucaud", "authors": "Cristina Bazgan, Florent Foucaud, Florian Sikora", "title": "Parameterized and Approximation Complexity of Partial VC Dimension", "comments": "24 pages, 2 figures", "journal-ref": "Theoretical Computer Science 766:1-15, 2019", "doi": "10.1016/j.tcs.2018.09.013", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem Partial VC Dimension that asks, given a hypergraph\n$H=(X,E)$ and integers $k$ and $\\ell$, whether one can select a set $C\\subseteq\nX$ of $k$ vertices of $H$ such that the set $\\{e\\cap C, e\\in E\\}$ of distinct\nhyperedge-intersections with $C$ has size at least $\\ell$. The sets $e\\cap C$\ndefine equivalence classes over $E$. Partial VC Dimension is a generalization\nof VC Dimension, which corresponds to the case $\\ell=2^k$, and of\nDistinguishing Transversal, which corresponds to the case $\\ell=|E|$ (the\nlatter is also known as Test Cover in the dual hypergraph). We also introduce\nthe associated fixed-cardinality maximization problem Max Partial VC Dimension\nthat aims at maximizing the number of equivalence classes induced by a solution\nset of $k$ vertices. We study the algorithmic complexity of Partial VC\nDimension and Max Partial VC Dimension both on general hypergraphs and on more\nrestricted instances, in particular, neighborhood hypergraphs of graphs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 15:42:43 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 08:54:37 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 09:53:04 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bazgan", "Cristina", ""], ["Foucaud", "Florent", ""], ["Sikora", "Florian", ""]]}, {"id": "1609.05137", "submitter": "Corrie Jacobien Carstens", "authors": "Corrie Jacobien Carstens and Annabell Berger and Giovanni Strona", "title": "A unifying framework for fast randomization of ecological networks with\n  fixed (node) degrees", "comments": null, "journal-ref": "Corrie Jacobien Carstens, Annabell Berger, Giovanni Strona, A\n  unifying framework for fast randomization of ecological networks with fixed\n  (node) degrees, MethodsX, Volume 5, 2018, Pages 773-780", "doi": "10.1016/j.mex.2018.06.018", "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The switching model is a Markov chain approach to sample graphs with fixed\ndegree sequence uniformly at random. The recently invented Curveball algorithm\nfor bipartite graphs applies several switches simultaneously (`trades'). Here,\nwe introduce Curveball algorithms for simple (un)directed graphs which use\nsingle or simultaneous trades. We show experimentally that these algorithms\nconverge magnitudes faster than the corresponding switching models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 16:52:03 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 12:18:26 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 14:31:38 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Carstens", "Corrie Jacobien", ""], ["Berger", "Annabell", ""], ["Strona", "Giovanni", ""]]}, {"id": "1609.05191", "submitter": "Tengyu Ma", "authors": "Moritz Hardt, Tengyu Ma, Benjamin Recht", "title": "Gradient Descent Learns Linear Dynamical Systems", "comments": "updated with more experimental results and references to prior work;\n  published in JMLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that stochastic gradient descent efficiently converges to the global\noptimizer of the maximum likelihood objective of an unknown linear\ntime-invariant dynamical system from a sequence of noisy observations generated\nby the system. Even though the objective function is non-convex, we provide\npolynomial running time and sample complexity bounds under strong but natural\nassumptions. Linear systems identification has been studied for many decades,\nyet, to the best of our knowledge, these are the first polynomial guarantees\nfor the problem we consider.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 19:42:34 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 16:55:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Hardt", "Moritz", ""], ["Ma", "Tengyu", ""], ["Recht", "Benjamin", ""]]}, {"id": "1609.05537", "submitter": "Fernando Brandao", "authors": "Fernando G.S.L. Brandao and Krysta Svore", "title": "Quantum Speed-ups for Semidefinite Programming", "comments": "24 pages. v2: modification of input model 2 and minor revisions v3:\n  several errors corrected, v4: more corrections and clarifications, v5:\n  published version, Proceedings FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quantum algorithm for solving semidefinite programs (SDPs). It has\nworst-case running time $n^{\\frac{1}{2}} m^{\\frac{1}{2}} s^2\n\\text{poly}(\\log(n), \\log(m), R, r, 1/\\delta)$, with $n$ and $s$ the dimension\nand row-sparsity of the input matrices, respectively, $m$ the number of\nconstraints, $\\delta$ the accuracy of the solution, and $R, r$ a upper bounds\non the size of the optimal primal and dual solutions. This gives a square-root\nunconditional speed-up over any classical method for solving SDPs both in $n$\nand $m$. We prove the algorithm cannot be substantially improved (in terms of\n$n$ and $m$) giving a $\\Omega(n^{\\frac{1}{2}}+m^{\\frac{1}{2}})$ quantum lower\nbound for solving semidefinite programs with constant $s, R, r$ and $\\delta$.\n  The quantum algorithm is constructed by a combination of quantum Gibbs\nsampling and the multiplicative weight method. In particular it is based on a\nclassical algorithm of Arora and Kale for approximately solving SDPs. We\npresent a modification of their algorithm to eliminate the need for solving an\ninner linear program which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 20:13:50 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 17:01:24 GMT"}, {"version": "v3", "created": "Sun, 16 Oct 2016 17:53:24 GMT"}, {"version": "v4", "created": "Thu, 20 Apr 2017 21:52:51 GMT"}, {"version": "v5", "created": "Sun, 24 Sep 2017 02:03:23 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Brandao", "Fernando G. S. L.", ""], ["Svore", "Krysta", ""]]}, {"id": "1609.05573", "submitter": "Alexander Wein", "authors": "Amelia Perry and Alexander S. Wein and Afonso S. Bandeira and Ankur\n  Moitra", "title": "Optimality and Sub-optimality of PCA for Spiked Random Matrices and\n  Synchronization", "comments": "58 pages, 5 figures. This version adds improved results for the\n  Wishart model", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem of random matrix theory is to understand the eigenvalues of\nspiked random matrix models, in which a prominent eigenvector is planted into a\nrandom matrix. These distributions form natural statistical models for\nprincipal component analysis (PCA) problems throughout the sciences. Baik, Ben\nArous and P\\'ech\\'e showed that the spiked Wishart ensemble exhibits a sharp\nphase transition asymptotically: when the signal strength is above a critical\nthreshold, it is possible to detect the presence of a spike based on the top\neigenvalue, and below the threshold the top eigenvalue provides no information.\nSuch results form the basis of our understanding of when PCA can detect a\nlow-rank signal in the presence of noise.\n  However, not all the information about the spike is necessarily contained in\nthe spectrum. We study the fundamental limitations of statistical methods,\nincluding non-spectral ones. Our results include:\n  I) For the Gaussian Wigner ensemble, we show that PCA achieves the optimal\ndetection threshold for a variety of benign priors for the spike. We extend\nprevious work on the spherically symmetric and i.i.d. Rademacher priors through\nan elementary, unified analysis.\n  II) For any non-Gaussian Wigner ensemble, we show that PCA is always\nsuboptimal for detection. However, a variant of PCA achieves the optimal\nthreshold (for benign priors) by pre-transforming the matrix entries according\nto a carefully designed function. This approach has been stated before, and we\ngive a rigorous and general analysis.\n  III) For both the Gaussian Wishart ensemble and various synchronization\nproblems over groups, we show that inefficient procedures can work below the\nthreshold where PCA succeeds, whereas no known efficient algorithm achieves\nthis. This conjectural gap between what is statistically possible and what can\nbe done efficiently remains open.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 00:25:43 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 08:11:18 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""], ["Moitra", "Ankur", ""]]}, {"id": "1609.05626", "submitter": "Naveen Sivadasan", "authors": "Naveen Sivadasan, Rajgopal Srinivasan, Kshama Goyal", "title": "Kmerlight: fast and accurate k-mer abundance estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-mers (nucleotide strings of length k) form the basis of several algorithms\nin computational genomics. In particular, k-mer abundance information in\nsequence data is useful in read error correction, parameter estimation for\ngenome assembly, digital normalization etc. We give a streaming algorithm\nKmerlight for computing the k-mer abundance histogram from sequence data. Our\nalgorithm is fast and uses very small memory footprint. We provide analytical\nbounds on the error guarantees of our algorithm. Kmerlight can efficiently\nprocess genome scale and metagenome scale data using standard desktop machines.\nFew applications of abundance histograms computed by Kmerlight are also shown.\nWe use abundance histogram for de novo estimation of repetitiveness in the\ngenome based on a simple probabilistic model that we propose. We also show\nestimation of k-mer error rate in the sampling using abundance histogram. Our\nalgorithm can also be used for abundance estimation in a general streaming\nsetting. The Kmerlight tool is written in C++ and is available for download and\nuse from https://github.com/nsivad/kmerlight.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 08:01:16 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Sivadasan", "Naveen", ""], ["Srinivasan", "Rajgopal", ""], ["Goyal", "Kshama", ""]]}, {"id": "1609.05715", "submitter": "Roee Litman", "authors": "Roee Litman, Alex Bronstein", "title": "SpectroMeter: Amortized Sublinear Spectral Approximation of Distance on\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a method to approximate pairwise distance on a graph, having an\namortized sub-linear complexity in its size. The proposed method follows the so\ncalled heat method due to Crane et al. The only additional input are the values\nof the eigenfunctions of the graph Laplacian at a subset of the vertices. Using\nthese values we estimate a random walk from the source points, and normalize\nthe result into a unit gradient function. The eigenfunctions are then used to\nsynthesize distance values abiding by these constraints at desired locations.\nWe show that this method works in practice on different types of inputs ranging\nfrom triangular meshes to general graphs. We also demonstrate that the\nresulting approximate distance is accurate enough to be used as the input to a\nrecent method for intrinsic shape correspondence computation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 19:05:21 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Litman", "Roee", ""], ["Bronstein", "Alex", ""]]}, {"id": "1609.05867", "submitter": "Shang-En Huang", "authors": "Shang-En Huang, Dawei Huang, Tsvi Kopelowitz, Seth Pettie", "title": "Fully Dynamic Connectivity in $O(\\log n(\\log\\log n)^2)$ Amortized\n  Expected Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic connectivity is one of the most fundamental problems in dynamic graph\nalgorithms. We present a new randomized dynamic connectivity structure with\n$O(\\log n (\\log\\log n)^2)$ amortized expected update time and $O(\\log\nn/\\log\\log\\log n)$ query time, which comes within an $O((\\log\\log n)^2)$ factor\nof a lower bound due to \\Patrascu{} and Demaine. The new structure is based on\na dynamic connectivity algorithm proposed by Thorup in an extended abstract at\nSTOC 2000, which left out some important details.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 18:56:06 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Huang", "Shang-En", ""], ["Huang", "Dawei", ""], ["Kopelowitz", "Tsvi", ""], ["Pettie", "Seth", ""]]}, {"id": "1609.05885", "submitter": "Lin Yang", "authors": "Vladimir Braverman, Stephen R. Chestnut, Robert Krauthgamer, Yi Li,\n  David P. Woodruff, Lin F. Yang", "title": "Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order", "comments": "Merged works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in data streams is to characterize which functions of an\nunderlying frequency vector can be approximated efficiently. Recently there has\nbeen considerable effort in extending this problem to that of estimating\nfunctions of a matrix that is presented as a data-stream. This setting\ngeneralizes classical problems to the analogous ones for matrices. For example,\ninstead of estimating frequent-item counts, we now wish to estimate\n\"frequent-direction\" counts. A related example is to estimate norms, which now\ncorrespond to estimating a vector norm on the singular values of the matrix.\nDespite recent efforts, the current understanding for such matrix problems is\nconsiderably weaker than that for vector problems.\n  We study a number of aspects of estimating matrix norms in a stream that have\nnot previously been considered: (1) multi-pass algorithms, (2) algorithms that\nsee the underlying matrix one row at a time, and (3) time-efficient algorithms.\nOur multi-pass and row-order algorithms use less memory than what is provably\nrequired in the single-pass and entrywise-update models, and thus give\nseparations between these models (in terms of memory). Moreover, all of our\nalgorithms are considerably faster than previous ones. We also prove a number\nof lower bounds, and obtain for instance, a near-complete characterization of\nthe memory required of row-order algorithms for estimating Schatten $p$-norms\nof sparse matrices.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 19:49:45 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 17:03:08 GMT"}, {"version": "v3", "created": "Thu, 2 Nov 2017 00:50:14 GMT"}, {"version": "v4", "created": "Wed, 24 Oct 2018 04:18:12 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Braverman", "Vladimir", ""], ["Chestnut", "Stephen R.", ""], ["Krauthgamer", "Robert", ""], ["Li", "Yi", ""], ["Woodruff", "David P.", ""], ["Yang", "Lin F.", ""]]}, {"id": "1609.06156", "submitter": "David Harris", "authors": "David G. Harris", "title": "Derandomized concentration bounds for polynomials, and hypergraph\n  maximal independent set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parallel algorithm for maximal independent set (MIS) in hypergraphs has\nbeen a long-standing algorithmic challenge, dating back nearly 30 years to a\nsurvey of Karp & Ramachandran (1990). The best randomized parallel algorithm\nfor hypergraphs of fixed rank $r$ was developed by Beame & Luby (1990) and\nKelsen (1992), running in time roughly $(\\log n)^{r!}$.\n  We improve the randomized algorithm of Kelsen, reducing the runtime to\nroughly $(\\log n)^{2^r}$ and simplifying the analysis through the use of\nmore-modern concentration inequalities. We also give a method for derandomizing\nconcentration bounds for low-degree polynomials, which are the key technical\ntool used to analyze that algorithm. This leads to a deterministic PRAM\nalgorithm also running in $(\\log n)^{2^{r+3}}$ time and $\\text{poly}(m,n)$\nprocessors. This is the first deterministic algorithm with sub-polynomial\nruntime for hypergraphs of rank $r > 3$.\n  Our analysis can also apply when $r$ is slowly growing; using this in\nconjunction with a strategy of Bercea et al. (2015) gives a deterministic MIS\nalgorithm running in time $\\exp(O( \\frac{\\log (mn)}{\\log \\log (mn)}))$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 13:26:08 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 16:42:32 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 15:35:29 GMT"}, {"version": "v4", "created": "Mon, 27 Feb 2017 16:08:10 GMT"}, {"version": "v5", "created": "Fri, 30 Jun 2017 22:55:53 GMT"}, {"version": "v6", "created": "Mon, 16 Oct 2017 12:42:38 GMT"}, {"version": "v7", "created": "Tue, 19 Mar 2019 21:11:19 GMT"}, {"version": "v8", "created": "Mon, 13 May 2019 21:08:30 GMT"}, {"version": "v9", "created": "Thu, 23 May 2019 18:42:41 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Harris", "David G.", ""]]}, {"id": "1609.06327", "submitter": "Darren Strash", "authors": "Lukas Barth, Benjamin Niedermann, Martin N\\\"ollenburg, Darren Strash", "title": "Temporal Map Labeling: A New Unified Framework with Experiments", "comments": "23 pages, 15 figures; extended version of a paper appearing at the\n  24th ACM SIGSPATIAL International Conference on Advances in Geographic\n  Information Systems (ACM SIGSPATIAL 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability of interactive maps on the Internet and on\npersonal mobile devices has created new challenges in computational cartography\nand, in particular, for label placement in maps. Operations like rotation,\nzoom, and translation dynamically change the map over time and make a\nconsistent adaptation of the map labeling necessary.\n  In this paper, we consider map labeling for the case that a map undergoes a\nsequence of operations over a specified time span. We unify and generalize\nseveral preceding models for dynamic map labeling into one versatile and\nflexible model. In contrast to previous research, we completely abstract from\nthe particular operations (e.g., zoom, rotation, etc.) and express the labeling\nproblem as a set of time intervals representing the labels' presences,\nactivities, and conflicts. The model's strength is manifested in its simplicity\nand broad range of applications. In particular, it supports label selection\nboth for map features with fixed position as well as for moving entities (e.g.,\nfor tracking vehicles in logistics or air traffic control).\n  Through extensive experiments on OpenStreetMap data, we evaluate our model\nusing algorithms of varying complexity as a case study for navigation systems.\nOur experiments show that even simple (and thus, fast) algorithms achieve\nnear-optimal solutions in our model with respect to an intuitive objective\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 20:00:47 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Barth", "Lukas", ""], ["Niedermann", "Benjamin", ""], ["N\u00f6llenburg", "Martin", ""], ["Strash", "Darren", ""]]}, {"id": "1609.06378", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui, Fabio Cunial, Juha K\\\"arkk\\\"ainen, and Veli\n  M\\\"akinen", "title": "Linear-time string indexing and analysis in small space", "comments": "Journal submission (52 pages, 2 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of succinct data structures has flourished over the last 16 years.\nStarting from the compressed suffix array (CSA) by Grossi and Vitter (STOC\n2000) and the FM-index by Ferragina and Manzini (FOCS 2000), a number of\ngeneralizations and applications of string indexes based on the Burrows-Wheeler\ntransform (BWT) have been developed, all taking an amount of space that is\nclose to the input size in bits. In many large-scale applications, the\nconstruction of the index and its usage need to be considered as one unit of\ncomputation. Efficient string indexing and analysis in small space lies also at\nthe core of a number of primitives in the data-intensive field of\nhigh-throughput DNA sequencing. We report the following advances in string\nindexing and analysis. We show that the BWT of a string $T\\in\n\\{1,\\ldots,\\sigma\\}^n$ can be built in deterministic $O(n)$ time using just\n$O(n\\log{\\sigma})$ bits of space, where $\\sigma \\leq n$. Within the same time\nand space budget, we can build an index based on the BWT that allows one to\nenumerate all the internal nodes of the suffix tree of $T$. Many fundamental\nstring analysis problems can be mapped to such enumeration, and can thus be\nsolved in deterministic $O(n)$ time and in $O(n\\log{\\sigma})$ bits of space\nfrom the input string. We also show how to build many of the existing indexes\nbased on the BWT, such as the CSA, the compressed suffix tree (CST), and the\nbidirectional BWT index, in randomized $O(n)$ time and in $O(n\\log{\\sigma})$\nbits of space. The previously fastest construction algorithms for BWT, CSA and\nCST, which used $O(n\\log{\\sigma})$ bits of space, took $O(n\\log{\\log{\\sigma}})$\ntime for the first two structures, and $O(n\\log^{\\epsilon}n)$ time for the\nthird, where $\\epsilon$ is any positive constant. Contrary to the state of the\nart, our bidirectional BWT index supports every operation in constant time per\nelement in its output.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:51:19 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Cunial", "Fabio", ""], ["K\u00e4rkk\u00e4inen", "Juha", ""], ["M\u00e4kinen", "Veli", ""]]}, {"id": "1609.06403", "submitter": "Elizaveta Guseva", "authors": "Anton V. Bernatskiy and Elizaveta A. Guseva", "title": "Exact rule-based stochastic simulations for systems with unlimited\n  number of molecular species", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce expandable partial propensity direct method (EPDM) - a new exact\nstochastic simulation algorithm suitable for systems involving many interacting\nmolecular species. The algorithm is especially efficient for sparsely populated\nsystems, where the number of species that may potentially be generated is much\ngreater than the number of species actually present in the system at any given\ntime. The number of operations per reaction scales linearly with the number of\nspecies, but only those which have one or more molecules. To achieve this kind\nof performance we are employing a data structure which allows to add and remove\nspecies and their interactions on the fly. When a new specie is added, its\ninteractions with every other specie are generated dynamically by a set of\nuser-defined rules. By removing the records involving the species with zero\nmolecules, we keep the number of species as low as possible. This enables\nsimulations of systems for which listing all species is not practical. The\nalgorithm is based on partial propensities direct method (PDM) by Ramaswamy et\nal. for sampling trajectories of the chemical master equation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 02:11:07 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 17:16:45 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Bernatskiy", "Anton V.", ""], ["Guseva", "Elizaveta A.", ""]]}, {"id": "1609.06430", "submitter": "Shrisha Rao", "authors": "Pragati Agrawal, Shrisha Rao", "title": "Energy-Efficient Scheduling: Classification, Bounds, and Algorithms", "comments": "41 pages", "journal-ref": "S{\\a}dhan{\\a} (2021) 46:46", "doi": "10.1007/s12046-021-01564-w", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of attaining energy efficiency in distributed systems is of\nimportance, but a general, non-domain-specific theory of energy-minimal\nscheduling is far from developed. In this paper, we classify the problems of\nenergy-minimal scheduling and present theoretical foundations of the same. We\nderive results concerning energy-minimal scheduling of independent jobs in a\ndistributed system with functionally similar machines with different working\nand idle power ratings. The machines considered in our system can have\nidentical as well as different speeds. If the jobs can be divided into\narbitrary parts, we show that the minimum-energy schedule can be generated in\nlinear time and give exact scheduling algorithms. For the cases where jobs are\nnon-divisible, we prove that the scheduling problems are NP-hard and also give\napproximation algorithms for the same along with their bounds.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 06:43:20 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 11:27:16 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Agrawal", "Pragati", ""], ["Rao", "Shrisha", ""]]}, {"id": "1609.06522", "submitter": "Johanna E. Prei{\\ss}er", "authors": "Johanna E. Prei{\\ss}er, Jens M. Schmidt", "title": "Computing Vertex-Disjoint Paths using MAOs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G be a graph with minimum degree $\\delta$. It is well-known that maximal\nadjacency orderings (MAOs) compute a vertex set S such that every pair of S is\nconnected by at least $\\delta$ internally vertex-disjoint paths in G.\n  We present an algorithm that, given any pair of S, computes these $\\delta$\npaths in linear time O(n+m). This improves the previously best solutions for\nthese special vertex pairs, which were flow-based. Our algorithm simplifies a\nproof about pendant pairs of Mader and makes a purely existential proof of\nNagamochi algorithmic.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 12:22:49 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Prei\u00dfer", "Johanna E.", ""], ["Schmidt", "Jens M.", ""]]}, {"id": "1609.06641", "submitter": "Andrew Thompson", "authors": "Andrew Thompson", "title": "The Cascading Haar Wavelet algorithm for computing the Walsh-Hadamard\n  Transform", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2017.2705247", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for computing the Walsh-Hadamard Transform (WHT)\nwhich consists entirely of Haar wavelet transforms. We prove that the\nalgorithm, which we call the Cascading Haar Wavelet (CHW) algorithm, shares\nprecisely the same serial complexity as the popular divide-and-conquer\nalgorithm for the WHT. We also propose a natural way of parallelizing the\nalgorithm which has a number of attractive features.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 17:10:16 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Thompson", "Andrew", ""]]}, {"id": "1609.06736", "submitter": "Oded Lachish Dr", "authors": "Eldar Fischer and Oded Lachish and Yadu Vasudev", "title": "Improving and extending the testing of distributions for\n  shape-restricted properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution testing deals with what information can be deduced about an\nunknown distribution over $\\{1,\\ldots,n\\}$, where the algorithm is only allowed\nto obtain a relatively small number of independent samples from the\ndistribution. In the extended conditional sampling model, the algorithm is also\nallowed to obtain samples from the restriction of the original distribution on\nsubsets of $\\{1,\\ldots,n\\}$.\n  In 2015, Canonne, Diakonikolas, Gouleakis and Rubinfeld unified several\nprevious results, and showed that for any property of distributions satisfying\na \"decomposability\" criterion, there exists an algorithm (in the basic model)\nthat can distinguish with high probability distributions satisfying the\nproperty from distributions that are far from it in the variation distance.\n  We present here a more efficient yet simpler algorithm for the basic model,\nas well as very efficient algorithms for the conditional model, which until now\nwas not investigated under the umbrella of decomposable properties.\nAdditionally, we provide an algorithm for the conditional model that handles a\nmuch larger class of properties.\n  Our core mechanism is a way of efficiently producing an interval-partition of\n$\\{1,\\ldots,n\\}$ that satisfies a \"fine-grain\" quality. We show that with such\na partition at hand we can directly move forward with testing individual\nintervals, instead of first searching for the \"correct\" partition of\n$\\{1,\\ldots,n\\}$.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 20:15:14 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Fischer", "Eldar", ""], ["Lachish", "Oded", ""], ["Vasudev", "Yadu", ""]]}, {"id": "1609.06841", "submitter": "Volker Turau", "authors": "Gerry Siegemund and Volker Turau", "title": "PSVR - Self-stabilizing Publish/Subscribe Communication for Ad-hoc\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the novel routing algorithm PSVR for pub/sub systems in\nad-hoc networks. Its focus is on scenarios where communications links are\nunstable and nodes frequently change subscriptions. PSVR presents a compromise\nof size and maintenance effort for routing tables due to sub- and\nunsubscriptions and the length of routing paths. Designed in a self-stabilizing\nmanner it scales well with network size. The evaluation reveals that PSVR only\nneeds slightly more messages than a close to optimal routing structure for\npublication delivery, and creates shorter routing paths than an existing\nself-stabilizing algorithm. A real world deployment shows the usability of the\napproach\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 07:12:43 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Siegemund", "Gerry", ""], ["Turau", "Volker", ""]]}, {"id": "1609.07056", "submitter": "Mohit Singh", "authors": "Nima Anari, Shayan Oveis Gharan, Amin Saberi, Mohit Singh", "title": "Nash Social Welfare, Matrix Permanent, and Stable Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of allocating $m$ items to $n$ agents subject to\nmaximizing the Nash social welfare (NSW) objective. We write a novel convex\nprogramming relaxation for this problem, and we show that a simple randomized\nrounding algorithm gives a $1/e$ approximation factor of the objective.\n  Our main technical contribution is an extension of Gurvits's lower bound on\nthe coefficient of the square-free monomial of a degree $m$-homogeneous stable\npolynomial on $m$ variables to all homogeneous polynomials. We use this\nextension to analyze the expected welfare of the allocation returned by our\nrandomized rounding algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 16:35:59 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 03:29:42 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Anari", "Nima", ""], ["Gharan", "Shayan Oveis", ""], ["Saberi", "Amin", ""], ["Singh", "Mohit", ""]]}, {"id": "1609.07134", "submitter": "Michal Wlodarczyk", "authors": "Micha{\\l} W{\\l}odarczyk", "title": "Clifford algebras meet tree decompositions", "comments": "This work was presented at International Symposium on Parameterized\n  and Exact Computation (IPEC) 2016", "journal-ref": null, "doi": "10.1007/s00453-018-0489-3", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Non-commutative Subset Convolution - a convolution of\nfunctions useful when working with determinant-based algorithms. In order to\ncompute it efficiently, we take advantage of Clifford algebras, a\ngeneralization of quaternions used mainly in the quantum field theory.\n  We apply this tool to speed up algorithms counting subgraphs parameterized by\nthe treewidth of a graph. We present an $O^*((2^\\omega + 1)^{tw})$-time\nalgorithm for counting Steiner trees and an $O^*((2^\\omega + 2)^{tw})$-time\nalgorithm for counting Hamiltonian cycles, both of which improve the previously\nknown upper bounds. The result for Steiner Tree also translates into a\ndeterministic algorithm for Feedback Vertex Set. All of these constitute the\nbest known running times of deterministic algorithms for decision versions of\nthese problems and they match the best obtained running times for pathwidth\nparameterization under assumption $\\omega = 2$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 19:58:52 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["W\u0142odarczyk", "Micha\u0142", ""]]}, {"id": "1609.07239", "submitter": "Siddharth Gupta", "authors": "M T Goodrich, Siddharth Gupta, Manuel R. Torres", "title": "A Topological Algorithm for Determining How Road Networks Evolve Over\n  Time", "comments": null, "journal-ref": null, "doi": "10.1145/2996913.2996976", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an efficient algorithm for determining how a road network has\nevolved over time, given two snapshot instances from different dates. To allow\nfor such determinations across different databases and even against hand drawn\nmaps, we take a strictly topological approach in this paper, so that we compare\nroad networks based strictly on graph-theoretic properties. Given two road\nnetworks of same region from two different dates, our approach allows one to\nmatch road network portions that remain intact and also point out added or\nremoved portions. We analyze our algorithm both theoretically, showing that it\nruns in polynomial time for non-degenerate road networks even though a related\nproblem is NP-complete, and experimentally, using dated road networks from the\nTIGER/Line archive of the U.S. Census Bureau.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 05:57:06 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Goodrich", "M T", ""], ["Gupta", "Siddharth", ""], ["Torres", "Manuel R.", ""]]}, {"id": "1609.07288", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises, Toshiya Itoh", "title": "Random Popular Matchings with Incomplete Preference Lists", "comments": "A shortened version of this paper has appeared at WALCOM 2018", "journal-ref": "Journal of Graph Algorithms and Applications, 23(5): 815-835\n  (2019)", "doi": "10.7155/jgaa.00513", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $A$ of $n$ people and a set $B$ of $m \\geq n$ items, with each\nperson having a list that ranks his/her preferred items in order of preference,\nwe want to match every person with a unique item. A matching $M$ is called\npopular if for any other matching $M'$, the number of people who prefer $M$ to\n$M'$ is not less than the number of those who prefer $M'$ to $M$. For given $n$\nand $m$, consider the probability of existence of a popular matching when each\nperson's preference list is independently and uniformly generated at random.\nPreviously, Mahdian showed that when people's preference lists are strict\n(containing no ties) and complete (containing all items in $B$), if $\\alpha =\nm/n > \\alpha_*$, where $\\alpha_* \\approx 1.42$ is the root of equation $x^2 =\ne^{1/x}$, then a popular matching exists with probability $1-o(1)$; and if\n$\\alpha < \\alpha_*$, then a popular matching exists with probability $o(1)$,\ni.e. a phase transition occurs at $\\alpha_*$. In this paper, we investigate\nphase transitions in the case that people's preference lists are strict but not\ncomplete. We show that in the case where every person has a preference list\nwith length of a constant $k \\geq 4$, a similar phase transition occurs at\n$\\alpha_k$, where $\\alpha_k \\geq 1$ is the root of equation $x e^{-1/2x} =\n1-(1-e^{-1/x})^{k-1}$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 09:38:24 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 14:53:52 GMT"}, {"version": "v3", "created": "Wed, 4 Oct 2017 12:07:37 GMT"}, {"version": "v4", "created": "Fri, 15 Dec 2017 15:49:07 GMT"}, {"version": "v5", "created": "Thu, 5 Jul 2018 02:14:47 GMT"}, {"version": "v6", "created": "Wed, 26 Sep 2018 15:23:08 GMT"}, {"version": "v7", "created": "Wed, 23 Oct 2019 07:22:51 GMT"}, {"version": "v8", "created": "Sat, 26 Oct 2019 09:47:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ruangwises", "Suthee", ""], ["Itoh", "Toshiya", ""]]}, {"id": "1609.07354", "submitter": "Shrisha Rao", "authors": "Mohammed Haroon Dupty, Pragati Agrawal, Shrisha Rao", "title": "Scheduling Under Power and Energy Constraints", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a system model where machines have distinct speeds and power ratings\nbut are otherwise compatible, we consider various problems of scheduling under\nresource constraints on the system which place the restriction that not all\nmachines can be run at once. These can be power, energy, or makespan\nconstraints on the system. Given such constraints, there are problems with\ndivisible as well as non-divisible jobs. In the setting where there is a\nconstraint on power, we show that the problem of minimizing makespan for a set\nof divisible jobs is NP-hard by reduction to the knapsack problem. We then show\nthat scheduling to minimize energy with power constraints is also NP-hard. We\nthen consider scheduling with energy and makespan constraints with divisible\njobs and show that these can be solved in polynomial time, and the problems\nwith non-divisible jobs are NP-hard. We give exact and approximation algorithms\nfor these problems as required.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 18:04:15 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 11:59:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Dupty", "Mohammed Haroon", ""], ["Agrawal", "Pragati", ""], ["Rao", "Shrisha", ""]]}, {"id": "1609.07450", "submitter": "Miguel Raggi", "authors": "Miguel Raggi", "title": "Finding long simple paths in a weighted digraph using pseudo-topological\n  orderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a weighted digraph D, finding the longest simple path is well known to\nbe NP-hard. Furthermore, even giving an approximation algorithm is known to be\nNP-hard. In this paper we describe an efficient heuristic algorithm for finding\nlong simple paths, using an hybrid approach of DFS and pseudo-topological\norders, a a generalization of topological orders to non acyclic graphs, via a\nprocess we call \"opening edges\". An implementation of this algorithm won the\nOracle MDC 2015 coding competition.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 18:02:36 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 03:14:24 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 18:52:22 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Raggi", "Miguel", ""]]}, {"id": "1609.07630", "submitter": "Renato J Cintra", "authors": "P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A.\n  Madanayake, V. A. Coutinho", "title": "Low-complexity Image and Video Coding Based on an Approximate Discrete\n  Tchebichef Transform", "comments": "Fixed diagonal matrix, 11 pages, 5 figures, 4 tables", "journal-ref": null, "doi": "10.1109/TCSVT.2016.2515378", "report-no": null, "categories": "cs.MM cs.CV cs.DS stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of linear transformations has great relevance for data\ndecorrelation applications, like image and video compression. In that sense,\nthe discrete Tchebichef transform (DTT) possesses useful coding and\ndecorrelation properties. The DTT transform kernel does not depend on the input\ndata and fast algorithms can be developed to real time applications. However,\nthe DTT fast algorithm presented in literature possess high computational\ncomplexity. In this work, we introduce a new low-complexity approximation for\nthe DTT. The fast algorithm of the proposed transform is multiplication-free\nand requires a reduced number of additions and bit-shifting operations. Image\nand video compression simulations in popular standards shows good performance\nof the proposed transform. Regarding hardware resource consumption for FPGA\nshows 43.1% reduction of configurable logic blocks and ASIC place and route\nrealization shows 57.7% reduction in the area-time figure when compared with\nthe 2-D version of the exact DTT.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 14:49:31 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 21:18:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 17:05:20 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Oliveira", "P. A. M.", ""], ["Cintra", "R. J.", ""], ["Bayer", "F. M.", ""], ["Kulasekera", "S.", ""], ["Madanayake", "A.", ""], ["Coutinho", "V. A.", ""]]}, {"id": "1609.07650", "submitter": "Amit Rawat", "authors": "Meghana Nasre, Amit Rawat", "title": "Popularity in the generalized Hospital Residents Setting", "comments": "fixed typos, added references, fixed a subtle bug in the proof of\n  structural characterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of computing popular matchings in a bipartite graph G\n= (R U H, E) where R and H denote a set of residents and a set of hospitals\nrespectively. Each hospital h has a positive capacity denoting the number of\nresidents that can be matched to h. The residents and the hospitals specify\nstrict preferences over each other. This is the well-studied Hospital Residents\n(HR) problem which is a generalization of the Stable Marriage (SM) problem. The\ngoal is to assign residents to hospitals optimally while respecting the\ncapacities of the hospitals. Stability is a well-accepted notion of optimality\nin such problems. However, motivated by the need for larger cardinality\nmatchings, alternative notions of optimality like popularity have been\ninvestigated in the SM setting. In this paper, we consider a generalized HR\nsetting -- namely the Laminar Classified Stable Matchings (LCSM+) problem.\nHere, additionally, hospitals can specify classifications over residents in\ntheir preference lists and classes have upper quotas. We show the following new\nresults: We define a notion of popularity and give a structural\ncharacterization of popular matchings for the LCSM+ problem. Assume n = |R| +\n|H| and m = |E|. We give an O(mn) time algorithm for computing a maximum\ncardinality popular matching in an LCSM+ instance. We give an O(mn^2) time\nalgorithm for computing a matching that is popular amongst the maximum\ncardinality matchings in an LCSM+ instance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 17:35:29 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 13:45:19 GMT"}, {"version": "v3", "created": "Sun, 18 Dec 2016 13:05:20 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Nasre", "Meghana", ""], ["Rawat", "Amit", ""]]}, {"id": "1609.07676", "submitter": "Jo\\~ao Pedro Pedroso", "authors": "Jo\\~ao Pedro Pedroso and Jo\\~ao Nuno Tavares and Jorge Leite", "title": "A Practical Algorithm for Packing Tubes and Boxes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": "DCC-2016-02", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a method for packing tubes and boxes in containers.\nEach container is divided into parts (holders) which are allocated to subsets\nof objects. The method consists of a recursive procedure which, based on a\npredefined order for dealing with tubes and boxes, determines the dimensions\nand position of each holder. Characteristics of the objects to pack and rules\nlimiting their placement make this problem unique. The method devised provides\ntimely and practical solutions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 21:07:32 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Pedroso", "Jo\u00e3o Pedro", ""], ["Tavares", "Jo\u00e3o Nuno", ""], ["Leite", "Jorge", ""]]}, {"id": "1609.07766", "submitter": "Shimin Li", "authors": "Shimin Li and Haitao Wang", "title": "Separating Overlapped Intervals on a Line", "comments": "36 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ intervals on a line $\\ell$, we consider the problem of moving these\nintervals on $\\ell$ such that no two intervals overlap and the maximum moving\ndistance of the intervals is minimized. The difficulty for solving the problem\nlies in determining the order of the intervals in an optimal solution. By\ninteresting observations, we show that it is sufficient to consider at most $n$\n\"candidate\" lists of ordered intervals. Further, although explicitly\nmaintaining these lists takes $\\Omega(n^2)$ time and space, by more\nobservations and a pruning technique, we present an algorithm that can compute\nan optimal solution in $O(n\\log n)$ time and $O(n)$ space. We also prove an\n$\\Omega(n\\log n)$ time lower bound for solving the problem, which implies the\noptimality of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 16:10:01 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 02:26:08 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Li", "Shimin", ""], ["Wang", "Haitao", ""]]}, {"id": "1609.07780", "submitter": "Jean-Florent Raymond", "authors": "Archontia C. Giannopoulou, Micha{\\l} Pilipczuk, Dimitrios M. Thilikos,\n  Jean-Florent Raymond, and Marcin Wrochna", "title": "Linear kernels for edge deletion problems to immersion-closed graph\n  classes", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $\\mathcal{F}$ is a finite family of graphs. We consider the following\nmeta-problem, called $\\mathcal{F}$-Immersion Deletion: given a graph $G$ and\ninteger $k$, decide whether the deletion of at most $k$ edges of $G$ can result\nin a graph that does not contain any graph from $\\mathcal{F}$ as an immersion.\nThis problem is a close relative of the $\\mathcal{F}$-Minor Deletion problem\nstudied by Fomin et al. [FOCS 2012], where one deletes vertices in order to\nremove all minor models of graphs from $\\mathcal{F}$.\n  We prove that whenever all graphs from $\\mathcal{F}$ are connected and at\nleast one graph of $\\mathcal{F}$ is planar and subcubic, then the\n$\\mathcal{F}$-Immersion Deletion problem admits: a constant-factor\napproximation algorithm running in time $O(m^3 \\cdot n^3 \\cdot \\log m)$; a\nlinear kernel that can be computed in time $O(m^4 \\cdot n^3 \\cdot \\log m)$; and\na $O(2^{O(k)} + m^4 \\cdot n^3 \\cdot \\log m)$-time fixed-parameter algorithm,\nwhere $n,m$ count the vertices and edges of the input graph.\n  These results mirror the findings of Fomin et al. [FOCS 2012], who obtained a\nsimilar set of algorithmic results for $\\mathcal{F}$-Minor Deletion, under the\nassumption that at least one graph from $\\mathcal{F}$ is planar. An important\ndifference is that we are able to obtain a linear kernel for\n$\\mathcal{F}$-Immersion Deletion, while the exponent of the kernel of Fomin et\nal. for $\\mathcal{F}$-Minor Deletion depends heavily on the family\n$\\mathcal{F}$. In fact, this dependence is unavoidable under plausible\ncomplexity assumptions, as proven by Giannopoulou et al. [ICALP 2015]. This\nreveals that the kernelization complexity of $\\mathcal{F}$-Immersion Deletion\nis quite different than that of $\\mathcal{F}$-Minor Deletion.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 18:03:00 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Pilipczuk", "Micha\u0142", ""], ["Thilikos", "Dimitrios M.", ""], ["Raymond", "Jean-Florent", ""], ["Wrochna", "Marcin", ""]]}, {"id": "1609.07924", "submitter": "Rita Gitik", "authors": "Rita Gitik", "title": "On Intersection of Conjugate Subgoups", "comments": "arXiv admin note: text overlap with arXiv:1512.09185", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give several algorithms addressing computations of intersections of\nconjugate subgroups.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 11:28:16 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gitik", "Rita", ""]]}, {"id": "1609.07983", "submitter": "Maryam Fanaeepour", "authors": "Maryam Fanaeepour, Benjamin I. P. Rubinstein", "title": "Differentially-Private Counting of Users' Spatial Regions", "comments": "27 pages, 14 figures", "journal-ref": "Knowl.Inf.Syst 54 (2018) 5-32", "doi": "10.1007/s10115-017-1113-6", "report-no": null, "categories": "cs.DB cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining of spatial data is an enabling technology for mobile services,\nInternet-connected cars, and the Internet of Things. But the very\ndistinctiveness of spatial data that drives utility, can cost user privacy.\nPast work has focused upon points and trajectories for differentially-private\nrelease. In this work, we continue the tradition of privacy-preserving spatial\nanalytics, focusing not on point or path data, but on planar spatial regions.\nSuch data represents the area of a user's most frequent visitation---such as\n\"around home and nearby shops\". Specifically we consider the\ndifferentially-private release of data structures that support range queries\nfor counting users' spatial regions. Counting planar regions leads to unique\nchallenges not faced in existing work. A user's spatial region that straddles\nmultiple data structure cells can lead to duplicate counting at query time. We\nprovably avoid this pitfall by leveraging the Euler characteristic for the\nfirst time with differential privacy. To address the increased sensitivity of\nrange queries to spatial region data, we calibrate privacy-preserving noise\nusing bounded user region size and a constrained inference that uses robust\nleast absolute deviations. Our novel constrained inference reduces noise and\npromotes covertness by (privately) imposing consistency. We provide a full\nend-to-end theoretical analysis of both differential privacy and\nhigh-probability utility for our approach using concentration bounds. A\ncomprehensive experimental study on several real-world datasets establishes\npractical validity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 14:24:53 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 20:17:15 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Fanaeepour", "Maryam", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "1609.07994", "submitter": "Takuya Akiba", "authors": "Takuya Akiba, Kenko Nakamura, Taro Takaguchi", "title": "Fractality of Massive Graphs: Scalable Analysis with Sketch-Based\n  Box-Covering Algorithm", "comments": "Short version will appear at ICDM'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis and modeling of networked objects are fundamental pieces of modern\ndata mining. Most real-world networks, from biological to social ones, are\nknown to have common structural properties. These properties allow us to model\nthe growth processes of networks and to develop useful algorithms. One\nremarkable example is the fractality of networks, which suggests the\nself-similar organization of global network structure. To determine the\nfractality of a network, we need to solve the so-called box-covering problem,\nwhere preceding algorithms are not feasible for large-scale networks. The lack\nof an efficient algorithm prevents us from investigating the fractal nature of\nlarge-scale networks. To overcome this issue, we propose a new box-covering\nalgorithm based on recently emerging sketching techniques. We theoretically\nshow that it works in near-linear time with a guarantee of solution accuracy.\nIn experiments, we have confirmed that the algorithm enables us to study the\nfractality of million-scale networks for the first time. We have observed that\nits outputs are sufficiently accurate and that its time and space requirements\nare orders of magnitude smaller than those of previous algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 14:44:48 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Akiba", "Takuya", ""], ["Nakamura", "Kenko", ""], ["Takaguchi", "Taro", ""]]}, {"id": "1609.08095", "submitter": "Ignasi Sau", "authors": "Marin Bougeret, Ignasi Sau", "title": "How much does a treedepth modulator help to obtain polynomial kernels\n  beyond sparse graphs?", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, kernelization with structural parameters has been an\nactive area of research within the field of parameterized complexity. As a\nrelevant example, Gajarsk{\\`y} et al. [ESA 2013] proved that every graph\nproblem satisfying a property called finite integer index admits a linear\nkernel on graphs of bounded expansion and an almost linear kernel on nowhere\ndense graphs, parameterized by the size of a $c$-treedepth modulator, which is\na vertex set whose removal results in a graph of treedepth at most $c$, where\n$c \\geq 1$ is a fixed integer. The authors left as further research to\ninvestigate this parameter on general graphs, and in particular to find\nproblems that, while admitting polynomial kernels on sparse graphs, behave\ndifferently on general graphs.\n  In this article we answer this question by finding two very natural such\nproblems: we prove that Vertex Cover admits a polynomial kernel on general\ngraphs for any integer $c \\geq 1$, and that Dominating Set does not for any\ninteger $c \\geq 2$ even on degenerate graphs, unless $\\text{NP} \\subseteq\n\\text{coNP}/\\text{poly}$. For the positive result, we build on the techniques\nof Jansen and Bodlaender [STACS 2011], and for the negative result we use a\npolynomial parameter transformation for $c\\geq 3$ and an OR-cross-composition\nfor $c = 2$. As existing results imply that Dominating Set admits a polynomial\nkernel on degenerate graphs for $c = 1$, our result provides a dichotomy about\nthe existence of polynomial kernels for Dominating Set on degenerate graphs\nwith this parameter.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:41:03 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 10:44:14 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Bougeret", "Marin", ""], ["Sau", "Ignasi", ""]]}, {"id": "1609.08253", "submitter": "David J. Rosenbaum", "authors": "Fran\\c{c}ois Le Gall and David J. Rosenbaum", "title": "On the Group and Color Isomorphism Problems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove results on the relationship between the complexity of\nthe group and color isomorphism problems. The difficulty of color isomorphism\nproblems is known to be closely linked to the the composition factors of the\npermutation group involved. Previous works are primarily concerned with\napplying color isomorphism to bou nded degree graph isomorphism, and have\ntherefore focused on the alternating composit ion factors, since those are the\nbottleneck in the case of graph isomorphism.\n  We consider the color isomorphism problem with composition factors restricted\nto those other than the alternating group, show that group isomorphism reduces\nin n^(O(log log n)) time to this problem, and, conversely, that a special case\nof this color isomorphism problem reduces to a slight generalization of group\nisomorphism. We then sharpen our results by identifying the projective special\nlinear group as the main obstacle to faster algorithms for group isomorphism\nand prove that the aforementioned reduc tion from group isomorphism to color\nisomorphism in fact produces only cyclic and projective special linear factors.\nOur results demonstrate that, just as the alternatin g group was a barrier to\nfaster algorithms for graph isomorphism for three decades, the projective\nspecial linear group is an obstacle to faster algorithms for group isomorphism.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 04:10:44 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Rosenbaum", "David J.", ""]]}, {"id": "1609.08349", "submitter": "Luca Martino", "authors": "Jesse Read, Luca Martino, Jaakko Hollm\\'en", "title": "Multi-label Methods for Prediction with Sequential Data", "comments": null, "journal-ref": "Pattern Recognition, Volume 63, Pages 45-55, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of methods available for classification of multi-label data has\nincreased rapidly over recent years, yet relatively few links have been made\nwith the related task of classification of sequential data. If labels indices\nare considered as time indices, the problems can often be seen as equivalent.\nIn this paper we detect and elaborate on connections between multi-label\nmethods and Markovian models, and study the suitability of multi-label methods\nfor prediction in sequential data. From this study we draw upon the most\nsuitable techniques from the area and develop two novel competitive approaches\nwhich can be applied to either kind of data. We carry out an empirical\nevaluation investigating performance on real-world sequential-prediction tasks:\nelectricity demand, and route prediction. As well as showing that several\npopular multi-label algorithms are in fact easily applicable to sequencing\ntasks, our novel approaches, which benefit from a unified view of these areas,\nprove very competitive against established methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 10:53:37 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 09:02:28 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Read", "Jesse", ""], ["Martino", "Luca", ""], ["Hollm\u00e9n", "Jaakko", ""]]}, {"id": "1609.08403", "submitter": "Jacob Evald", "authors": "S{\\o}ren Dahlgaard, Jacob Evald", "title": "Tight Hardness Results for Distance and Centrality Problems in Constant\n  Degree Graphs", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding important nodes in a graph and measuring their importance is a\nfundamental problem in the analysis of social networks, transportation\nnetworks, biological systems, etc. Among popular such metrics are graph\ncentrality, betweenness centrality (BC), and reach centrality (RC). These\nmeasures are also very related to classic notions like diameter and radius.\nRoditty and Vassilevska Williams~[STOC'13] showed that no algorithm can compute\na (3/2-\\delta)-approximation of the diameter in sparse and unweighted graphs\nfaster that n^{2-o(1)} time unless the widely believed strong exponential time\nhypothesis (SETH) is false. Abboud et al.~[SODA'15] and [SODA'16] further\nanalyzed these problems under the recent line of research on hardness in P.\nThey showed that in sparse and unweighted graphs (weighted for BC) none of\nthese problems can be solved faster than n^{2-o(1)} unless some popular\nconjecture is false. Furthermore they ruled out a (2-\\delta)-approximation for\nRC, a (3/2-\\delta)-approximation for Radius and a (5/3-\\delta)-approximation\nfor computing all eccentricities of a graph for any \\delta > 0. We extend these\nresults to the case of unweighted graphs with constant maximum degree. Through\nnew graph constructions we are able to obtain the same approximation and time\nbounds as for sparse graphs even in unweighted bounded-degree graphs. We show\nthat no (3/2-\\delta) approximation of Radius or Diameter,\n(2-\\delta)-approximation of RC, (5/3-\\delta)-approximation of all\neccentricities or exact algorithm for BC exists in time n^{2-o(1)} for such\ngraphs and any \\delta > 0. This strengthens the result for BC of Abboud et\nal.~[SODA'16] by showing a hardness result for unweighted graphs, and follows\nin the footsteps of Abboud et al.~[SODA'16] and Abboud and Dahlgaard~[FOCS'16]\nin showing conditional lower bounds for restricted but realistic graph classes.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:20:49 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 11:43:23 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Dahlgaard", "S\u00f8ren", ""], ["Evald", "Jacob", ""]]}, {"id": "1609.08484", "submitter": "Gregor Joss\\'e", "authors": "Gregor Joss\\'e, Ying Lu, Tobias Emrich, Matthias Renz, Cyrus Shahabi,\n  Ugur Demiryurek, Matthias Schubert", "title": "Scenic Routes Now: Efficiently Solving the Time-Dependent Arc\n  Orienteering Problem", "comments": "13 pages, 11 figures, 1 table, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the Arc Orienteering Problem (AOP) to large road networks\nwith time-dependent travel times and time-dependent value gain, termed Twofold\nTime-Dependent AOP or 2TD-AOP for short. In its original definition, the\nNP-hard Orienteering Problem (OP) asks to find a path from a source to a\ndestination maximizing the accumulated value while not exceeding a cost budget.\nVariations of the OP and AOP have many practical applications such as mobile\ncrowdsourcing tasks (e.g., repairing and maintenance or dispatching field\nworkers), diverse logistics problems (e.g., crowd control or controlling\nwildfires) as well as several tourist guidance problems (e.g., generating trip\nrecommendations or navigating through theme parks). In the proposed 2TD-AOP,\ntravel times and value functions are assumed to be time-dependent. The dynamic\nvalues model, for instance, varying rewards in crowdsourcing tasks or varying\nurgency levels in damage control tasks. We discuss this novel problem, prove\nthe benefit of time-dependence empirically and present an efficient\napproximative solution, optimized for fast response systems. Our approach is\nthe first time-dependent variant of the AOP to be evaluated on a large scale,\nfine-grained, real-world road network. We show that optimal solutions are\ninfeasible and solutions to the static problem are often invalid. We propose an\napproximate dynamic programming solution which produces valid paths and is\norders of magnitude faster than any optimal solution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 14:50:15 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Joss\u00e9", "Gregor", ""], ["Lu", "Ying", ""], ["Emrich", "Tobias", ""], ["Renz", "Matthias", ""], ["Shahabi", "Cyrus", ""], ["Demiryurek", "Ugur", ""], ["Schubert", "Matthias", ""]]}, {"id": "1609.08486", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang, Tsvi Kopelowitz, Seth Pettie, Ruosong Wang, Wei Zhan", "title": "Exponential Separations in the Energy Complexity of Leader Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy is often the most constrained resource for battery-powered wireless\ndevices and the lion's share of energy is often spent on transceiver usage\n(sending/receiving packets), not on computation. In this paper we study the\nenergy complexity of LeaderElection and ApproximateCounting in several models\nof wireless radio networks. It turns out that energy complexity is very\nsensitive to whether the devices can generate random bits and their ability to\ndetect collisions. We consider four collision-detection models: Strong-CD (in\nwhich transmitters and listeners detect collisions), Sender-CD and Receiver-CD\n(in which only transmitters or only listeners detect collisions), and No-CD (in\nwhich no one detects collisions.)\n  The take-away message of our results is quite surprising. For randomized\nLeaderElection algorithms, there is an exponential gap between the energy\ncomplexity of Sender-CD and Receiver-CD, and for deterministic LeaderElection\nalgorithms there is another exponential gap, but in the reverse direction.\n  In particular, the randomized energy complexity of LeaderElection is\n$\\Theta(\\log^* n)$ in Sender-CD but $\\Theta(\\log(\\log^* n))$ in Receiver-CD,\nwhere $n$ is the (unknown) number of devices. Its deterministic complexity is\n$\\Theta(\\log N)$ in Receiver-CD but $\\Theta(\\log\\log N)$ in Sender-CD, where\n$N$ is the (known) size of the devices' ID space.\n  There is a tradeoff between time and energy. We give a new upper bound on the\ntime-energy tradeoff curve for randomized LeaderElection and\nApproximateCounting. A critical component of this algorithm is a new\ndeterministic LeaderElection algorithm for dense instances, when $n=\\Theta(N)$,\nwith inverse-Ackermann-type ($O(\\alpha(N))$) energy complexity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 14:58:35 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 14:05:57 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 19:34:48 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Kopelowitz", "Tsvi", ""], ["Pettie", "Seth", ""], ["Wang", "Ruosong", ""], ["Zhan", "Wei", ""]]}, {"id": "1609.08513", "submitter": "Sebastian Wild", "authors": "Markus E. Nebel, Elisabeth Neumann, Sebastian Wild", "title": "Median-of-k Jumplists and Dangling-Min BSTs", "comments": "appears in ANALCO 2019", "journal-ref": null, "doi": "10.1137/1.9781611975505.8", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend randomized jumplists introduced by Br\\\"onnimann et al. (STACS 2003)\nto choose jump-pointer targets as median of a small sample for better search\ncosts, and present randomized algorithms with expected $O(\\log n)$ time\ncomplexity that maintain the probability distribution of jump pointers upon\ninsertions and deletions. We analyze the expected costs to search, insert and\ndelete a random element, and we show that omitting jump pointers in small\nsublists hardly affects search costs, but significantly reduces the memory\nconsumption.\n  We use a bijection between jumplists and \"dangling-min BSTs\", a variant of\n(fringe-balanced) binary search trees for the analysis. Despite their\nsimilarities, some standard analysis techniques for search trees fail for\ndangling-min trees (and hence for jumplists).\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 16:05:10 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2016 08:59:31 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 15:01:46 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Nebel", "Markus E.", ""], ["Neumann", "Elisabeth", ""], ["Wild", "Sebastian", ""]]}, {"id": "1609.08588", "submitter": "Xiaohu Wu", "authors": "Xiaohu Wu and Patrick Loiseau", "title": "Efficient Algorithms for Scheduling Moldable Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of scheduling $n$ independent moldable tasks on $m$\nprocessors that arises in large-scale parallel computations where $m$ is large.\nA classic assumption is that every task is monotonic: its execution time\ndecreases but its workload increases with the number $p$ of assigned\nprocessors. With $m$ independent of $n$, the best known result is a\n$(\\frac{3}{2}+\\epsilon)$-approximation algorithm for makespan minimization with\na complexity linear in $n$ and polynomial in $\\log{m}$ and $\\frac{1}{\\epsilon}$\nwhere $\\epsilon$ is arbitrarily small. Motivated by benchmark studies, we\nintroduce the notion of $(\\delta, k)$-monotonic tasks: the speedup is linear\nwhen $p$ is small (up to a threshold $\\delta$) while it may begin to decline\nwhen $p$ ranges in $[\\delta, k]$; typically, $\\delta\\geq 25$; the bound $k$\nindicates an unacceptable overhead when parallelizing on too many processors.\nWith $m$ independent of $n$, we propose a $\\frac{1}{\\theta(\\delta)}\n(1+\\epsilon)$-approximation algorithm for makespan minimization with a\ncomplexity $\\mathcal{O}(n\\log{\\frac{n}{\\epsilon}})$ where $\\theta(\\delta) =\nr(\\delta)-\\mathcal{O}(\\frac{1}{m})$ and $r(\\delta)\\geq \\frac{6}{7}$ when\n$\\delta\\geq 25$. The main result of this paper is an algorithm whose\napproximation ratio is close to $\\frac{7}{6}$ when $\\delta\\geq 25$ and\n$\\frac{1}{r(\\delta)}$ for an arbitrary value of $\\delta$. Moreover,\n$r(\\delta)\\in (0, 1)$ is non-decreasing in $\\delta$ and its value can be\nobtained by a simple computation, e.g., when $\\delta=150$,\n$\\frac{1}{r(\\delta)}$ equals $\\frac{16}{15}\\approx 1.067$ and is close to 1. As\na by-product, we also propose a $\\theta(\\delta)$-approximation algorithm for\nthroughput maximization with a common deadline with a complexity\n$\\mathcal{O}(n^{2})$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 19:26:58 GMT"}, {"version": "v10", "created": "Thu, 29 Jul 2021 07:00:48 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 11:45:15 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 20:16:38 GMT"}, {"version": "v4", "created": "Mon, 19 Dec 2016 09:56:08 GMT"}, {"version": "v5", "created": "Sun, 3 Sep 2017 08:53:54 GMT"}, {"version": "v6", "created": "Tue, 24 Oct 2017 09:59:43 GMT"}, {"version": "v7", "created": "Mon, 26 Feb 2018 10:34:51 GMT"}, {"version": "v8", "created": "Sat, 28 Jul 2018 21:26:22 GMT"}, {"version": "v9", "created": "Wed, 25 Mar 2020 09:19:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wu", "Xiaohu", ""], ["Loiseau", "Patrick", ""]]}, {"id": "1609.08723", "submitter": "Takuya Akiba", "authors": "Takuya Akiba, Yoichi Iwata, Yosuke Sameshima, Naoto Mizuno, Yosuke\n  Yano", "title": "Cut Tree Construction from Massive Graphs", "comments": "Short version will appear at ICDM'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of cut trees (also known as Gomory-Hu trees) for a given\ngraph enables the minimum-cut size of the original graph to be obtained for any\npair of vertices. Cut trees are a powerful back-end for graph management and\nmining, as they support various procedures related to the minimum cut, maximum\nflow, and connectivity. However, the crucial drawback with cut trees is the\ncomputational cost of their construction. In theory, a cut tree is built by\napplying a maximum flow algorithm for $n$ times, where $n$ is the number of\nvertices. Therefore, naive implementations of this approach result in cubic\ntime complexity, which is obviously too slow for today's large-scale graphs. To\naddress this issue, in the present study, we propose a new cut-tree\nconstruction algorithm tailored to real-world networks. Using a series of\nexperiments, we demonstrate that the proposed algorithm is several orders of\nmagnitude faster than previous algorithms and it can construct cut trees for\nbillion-scale graphs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 01:49:46 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Akiba", "Takuya", ""], ["Iwata", "Yoichi", ""], ["Sameshima", "Yosuke", ""], ["Mizuno", "Naoto", ""], ["Yano", "Yosuke", ""]]}, {"id": "1609.08767", "submitter": "Jenny Lam", "authors": "Shahram Ghandeharizadeh, Sandy Irani, Jenny Lam", "title": "The Subset Assignment Problem for Data Placement in Caches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the subset assignment problem in which items of varying sizes\nare placed in a set of bins with limited capacity. Items can be replicated and\nplaced in any subset of the bins. Each (item, subset) pair has an associated\ncost. Not assigning an item to any of the bins is not free in general and can\npotentially be the most expensive option. The goal is to minimize the total\ncost of assigning items to subsets without exceeding the bin capacities. This\nproblem is motivated by the design of caching systems composed of banks of\nmemory with varying cost/performance specifications. The ability to replicate a\ndata item in more than one memory bank can benefit the overall performance of\nthe system with a faster recovery time in the event of a memory failure. For\nthis setting, the number $n$ of data objects (items) is very large and the\nnumber $d$ of memory banks (bins) is a small constant (on the order of $3$ or\n$4$). Therefore, the goal is to determine an optimal assignment in time that\nminimizes dependence on $n$. The integral version of this problem is NP-hard\nsince it is a generalization of the knapsack problem. We focus on an efficient\nsolution to the LP relaxation as the number of fractionally assigned items will\nbe at most $d$. If the data objects are small with respect to the size of the\nmemory banks, the effect of excluding the fractionally assigned data items from\nthe cache will be small. We give an algorithm that solves the LP relaxation and\nruns in time $O({3^d \\choose d+1} \\text{poly}(d) n \\log(n) \\log(nC) \\log(Z))$,\nwhere $Z$ is the maximum item size and $C$ the maximum storage cost.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 04:47:32 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 06:38:10 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Ghandeharizadeh", "Shahram", ""], ["Irani", "Sandy", ""], ["Lam", "Jenny", ""]]}, {"id": "1609.08801", "submitter": "Arnold Filtser", "authors": "Yair Bartal, Arnold Filtser, Ofer Neiman", "title": "On Notions of Distortion and an Almost Minimum Spanning Tree with\n  Constant Average Distortion", "comments": "Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes two main contributions: The first is the construction of a\nnear-minimum spanning tree with constant average distortion. The second is a\ngeneral equivalence theorem relating two refined notions of distortion: scaling\ndistortion and prioritized distortion.\n  Minimum Spanning Trees of weighted graphs are fundamental objects in numerous\napplications. In particular in distributed networks, the minimum spanning tree\nof the network is often used to route messages between network nodes.\nUnfortunately, while being most efficient in the total cost of connecting all\nnodes, minimum spanning trees fail miserably in the desired property of\napproximately preserving distances between pairs. While known lower bounds\nexclude the possibility of the worst case distortion of a tree being small, it\nwas shown in [ABN15] that there exists a spanning tree with constant average\ndistortion. Yet, the weight of such a tree may be significantly larger than\nthat of the MST. In this paper, we show that any weighted undirected graph\nadmits a {\\em spanning tree} whose weight is at most $(1+\\rho)$ times that of\nthe MST, providing {\\em constant average distortion} $O(1/\\rho)$. Our result\nexhibits the best possible tradeoff of this type.\n  This result makes use of a general equivalence theorem relating two recently\ndeveloped notions of distortion for metric embedding. The first is the notion\nof scaling distortion, which provides improved distortion for $1-\\epsilon$\nfractions of the pairs, for all $\\epsilon$ simultaneously. A stronger version\ncalled coarse scaling distortion, has improved distortion guarantees for the\nfurthest pairs. The second notion is that of prioritized distortion, a property\nallowing to prioritize the nodes whose associated distortions will be improved.\nWe show that prioritized distortion is essentially equivalent to coarse scaling\ndistortion via a general transformation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 07:12:58 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 21:21:46 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Bartal", "Yair", ""], ["Filtser", "Arnold", ""], ["Neiman", "Ofer", ""]]}, {"id": "1609.08827", "submitter": "Mehdi Kaytoue", "authors": "Guillaume Bosc, Jean-Fran\\c{c}ois Boulicaut, Chedy Ra\\\"issi, Mehdi\n  Kaytoue", "title": "Anytime Discovery of a Diverse Set of Patterns with Monte Carlo Tree\n  Search", "comments": "This article has been accepted for publication in the journal\n  \\textit{Data Mining and Knowledge Discovery} (December 5th, 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of patterns that accurately discriminate one class label from\nanother remains a challenging data mining task. Subgroup discovery (SD) is one\nof the frameworks that enables to elicit such interesting hypotheses from\nlabeled data. A question remains fairly open: How to select an accurate\nheuristic search technique when exhaustive enumeration of the pattern space is\ninfeasible? Existing approaches make use of beam-search, sampling and genetic\nalgorithms for discovering a pattern set that is non-redundant and of high\nquality w.r.t. a pattern quality measure. We argue that such approaches produce\npattern sets that lack of diversity: Only few patterns of high quality, and\ndifferent enough, are discovered. Our main contribution is then to formally\ndefine pattern mining as a game and to solve it with Monte Carlo tree search\n(MCTS). It can be seen as an exhaustive search guided by random simulations\nwhich can be stopped early (limited budget) by virtue of its best-first search\nproperty. We show through a comprehensive set of experiments how MCTS enables\nthe anytime discovery of a diverse pattern set of high quality. It outperforms\nother approaches when dealing with a large pattern search space and for\ndifferent quality measures. Thanks to its genericity, our MCTS settings can be\nused for SD but also for many other pattern mining tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 08:58:12 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 16:49:31 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 10:39:27 GMT"}, {"version": "v4", "created": "Wed, 28 Jun 2017 12:49:58 GMT"}, {"version": "v5", "created": "Wed, 6 Dec 2017 08:26:03 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Bosc", "Guillaume", ""], ["Boulicaut", "Jean-Fran\u00e7ois", ""], ["Ra\u00efssi", "Chedy", ""], ["Kaytoue", "Mehdi", ""]]}, {"id": "1609.08879", "submitter": "Andr\\'e Nichterlein", "authors": "George B. Mertzios, Andr\\'e Nichterlein, Rolf Niedermeier", "title": "The Power of Data Reduction for Matching", "comments": "Available as 'Online First' in Algorithmica", "journal-ref": null, "doi": "10.1007/s00453-020-00736-0", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding maximum-cardinality matchings in undirected graphs is arguably one of\nthe most central graph primitives. For $m$-edge and $n$-vertex graphs, it is\nwell-known to be solvable in $O(m\\sqrt{n})$ time; however, for several\napplications this running time is still too slow. We investigate how\nlinear-time (and almost linear-time) data reduction (used as preprocessing) can\nalleviate the situation. More specifically, we focus on (almost) linear-time\nkernelization. We start a deeper and systematic study both for general graphs\nand for bipartite graphs. Our data reduction algorithms easily comply (in form\nof preprocessing) with every solution strategy (exact, approximate, heuristic),\nthus making them attractive in various settings.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 12:16:53 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 13:07:48 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 15:40:29 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mertzios", "George B.", ""], ["Nichterlein", "Andr\u00e9", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "1609.09000", "submitter": "Till Sch\\\"afer", "authors": "Till Sch\\\"afer and Petra Mutzel", "title": "StruClus: Structural Clustering of Large-Scale Graph Databases", "comments": "10 pages, experimental evaluation, big data, subgraph mining,\n  clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a structural clustering algorithm for large-scale datasets of\nsmall labeled graphs, utilizing a frequent subgraph sampling strategy. A set of\nrepresentatives provides an intuitive description of each cluster, supports the\nclustering process, and helps to interpret the clustering results. The\nprojection-based nature of the clustering approach allows us to bypass\ndimensionality and feature extraction problems that arise in the context of\ngraph datasets reduced to pairwise distances or feature vectors. While\nachieving high quality and (human) interpretable clusterings, the runtime of\nthe algorithm only grows linearly with the number of graphs. Furthermore, the\napproach is easy to parallelize and therefore suitable for very large datasets.\nOur extensive experimental evaluation on synthetic and real world datasets\ndemonstrates the superiority of our approach over existing structural and\nsubspace clustering algorithms, both, from a runtime and quality point of view.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 16:43:12 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Sch\u00e4fer", "Till", ""], ["Mutzel", "Petra", ""]]}, {"id": "1609.09031", "submitter": "Tetsuya Araki", "authors": "Tetsuya Araki, Koji M. Kobayashi", "title": "A tight analysis of Kierstead-Trotter algorithm for online unit interval\n  coloring", "comments": "4 pages", "journal-ref": null, "doi": "10.1587/transfun.E99.A.1885", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kierstead and Trotter (Congressus Numerantium 33, 1981) proved that their\nalgorithm is an optimal online algorithm for the online interval coloring\nproblem. In this paper, for online unit interval coloring, we show that the\nnumber of colors used by the Kierstead-Trotter algorithm is at most $3\n\\omega(G) - 3$, where $\\omega(G)$ is the size of the maximum clique in a given\ngraph $G$, and it is the best possible.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 18:32:07 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Araki", "Tetsuya", ""], ["Kobayashi", "Koji M.", ""]]}, {"id": "1609.09068", "submitter": "Christopher Engstr\\\"om", "authors": "Christopher Engstr\\\"om, Sergei Silvestrov", "title": "Graph partitioning and a componentwise PageRank algorithm", "comments": "25 pages, 7 figues (10 including subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we will present a graph partitioning algorithm which\npartitions a graph into two different types of components: the well-known\n`strongly connected components' as well as another type of components we call\n`connected acyclic component'. We will give an algorithm based on Tarjan's\nalgorithm for finding strongly connected components used to find such a\npartitioning. We will also show that the partitioning given by the algorithm is\nunique and that the underlying graph can be represented as a directed acyclic\ngraph (similar to a pure strongly connected component partitioning).\n  In the second part we will show how such an partitioning of a graph can be\nused to calculate PageRank of a graph effectively by calculating PageRank for\ndifferent components on the same `level' in parallel as well as allowing for\nthe use of different types of PageRank algorithms for different types of\ncomponents.\n  To evaluate the method we have calculated PageRank on four large example\ngraphs and compared it with a basic approach, as well as our algorithm in a\nserial as well as parallel implementation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 14:21:24 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Engstr\u00f6m", "Christopher", ""], ["Silvestrov", "Sergei", ""]]}, {"id": "1609.09179", "submitter": "Lucas Assun\\c{c}\\~ao", "authors": "Lucas Assun\\c{c}\\~ao, Thiago F. Noronha, Andr\\'ea Cynthia Santos,\n  Rafael Andrade", "title": "A linear programming based heuristic framework for min-max regret\n  combinatorial optimization problems with interval costs", "comments": null, "journal-ref": null, "doi": "10.1016/j.cor.2016.12.010", "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with a class of problems under interval data uncertainty,\nnamely interval robust-hard problems, composed of interval data min-max regret\ngeneralizations of classical NP-hard combinatorial problems modeled as 0-1\ninteger linear programming problems. These problems are more challenging than\nother interval data min-max regret problems, as solely computing the cost of\nany feasible solution requires solving an instance of an NP-hard problem. The\nstate-of-the-art exact algorithms in the literature are based on the generation\nof a possibly exponential number of cuts. As each cut separation involves the\nresolution of an NP-hard classical optimization problem, the size of the\ninstances that can be solved efficiently is relatively small. To smooth this\nissue, we present a modeling technique for interval robust-hard problems in the\ncontext of a heuristic framework. The heuristic obtains feasible solutions by\nexploring dual information of a linearly relaxed model associated with the\nclassical optimization problem counterpart. Computational experiments for\ninterval data min-max regret versions of the restricted shortest path problem\nand the set covering problem show that our heuristic is able to find optimal or\nnear-optimal solutions and also improves the primal bounds obtained by a\nstate-of-the-art exact algorithm and a 2-approximation procedure for interval\ndata min-max regret problems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 02:32:29 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Assun\u00e7\u00e3o", "Lucas", ""], ["Noronha", "Thiago F.", ""], ["Santos", "Andr\u00e9a Cynthia", ""], ["Andrade", "Rafael", ""]]}, {"id": "1609.09304", "submitter": "Bart M. P. Jansen", "authors": "Bart M.P. Jansen and Jules J.H.M. Wulms", "title": "Lower Bounds for Protrusion Replacement by Counting Equivalence Classes", "comments": "An extended abstract of this work appeared in the proceedings of the\n  11th International Symposium on Parameterized and Exact Computation (IPEC\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Garnero et al. [SIAM J. Discrete Math. 2015, 29(4):1864--1894] recently\nintroduced a framework based on dynamic programming to make applications of the\nprotrusion replacement technique constructive and to obtain explicit upper\nbounds on the involved constants. They show that for several graph problems,\nfor every boundary size $t$ one can find an explicit set $\\mathcal{R}_t$ of\nrepresentatives. Any subgraph $H$ with a boundary of size $t$ can be replaced\nwith a representative $H' \\in \\mathcal{R}_t$ such that the effect of this\nreplacement on the optimum can be deduced from $H$ and $H'$ alone. Their upper\nbounds on the size of the graphs in $\\mathcal{R}_t$ grow triple-exponentially\nwith $t$. In this paper we complement their results by lower bounds on the\nsizes of representatives, in terms of the boundary size $t$. For example, we\nshow that each set of planar representatives $\\mathcal{R}_t$ for Independent\nSet or Dominating Set contains a graph with $\\Omega(2^t / \\sqrt{4t})$ vertices.\nThis lower bound even holds for sets that only represent the planar subgraphs\nof bounded pathwidth. To obtain our results we provide a lower bound on the\nnumber of equivalence classes of the canonical equivalence relation for\nIndependent Set on $t$-boundaried graphs. We also find an elegant\ncharacterization of the number of equivalence classes in general graphs, in\nterms of the number of monotone functions of a certain kind. Our results show\nthat the number of equivalence classes is at most $2^{2^t}$, improving on\nearlier bounds of the form $(t+1)^{2^t}$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 11:50:46 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Wulms", "Jules J. H. M.", ""]]}, {"id": "1609.09433", "submitter": "Charis Papadopoulos", "authors": "Athanasios Konstantinidis and Charis Papadopoulos", "title": "Maximizing the Strong Triadic Closure in Split Graphs and Proper\n  Interval Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social networks the {\\sc Strong Triadic Closure} is an assignment of the\nedges with strong or weak labels such that any two vertices that have a common\nneighbor with a strong edge are adjacent. The problem of maximizing the number\nof strong edges that satisfy the strong triadic closure was recently shown to\nbe NP-complete for general graphs. Here we initiate the study of graph classes\nfor which the problem is solvable. We show that the problem admits a\npolynomial-time algorithm for two unrelated classes of graphs: proper interval\ngraphs and trivially-perfect graphs. To complement our result, we show that the\nproblem remains NP-complete on split graphs, and consequently also on chordal\ngraphs. Thus we contribute to define the first border between graph classes on\nwhich the problem is polynomially solvable and on which it remains NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 17:25:14 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 11:37:56 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Konstantinidis", "Athanasios", ""], ["Papadopoulos", "Charis", ""]]}, {"id": "1609.09525", "submitter": "Yoann Isaac", "authors": "Yoann Isaac, Quentin Barth\\'elemy, C\\'edric Gouy-Pailler, Mich\\`ele\n  Sebag, Jamal Atif", "title": "Multi-dimensional signal approximation with sparse structured priors\n  using split Bregman iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the structurally-constrained sparse decomposition of\nmulti-dimensional signals onto overcomplete families of vectors, called\ndictionaries. The contribution of the paper is threefold. Firstly, a generic\nspatio-temporal regularization term is designed and used together with the\nstandard $\\ell_1$ regularization term to enforce a sparse decomposition\npreserving the spatio-temporal structure of the signal. Secondly, an\noptimization algorithm based on the split Bregman approach is proposed to\nhandle the associated optimization problem, and its convergence is analyzed.\nOur well-founded approach yields same accuracy as the other algorithms at the\nstate-of-the-art, with significant gains in terms of convergence speed.\nThirdly, the empirical validation of the approach on artificial and real-world\nproblems demonstrates the generality and effectiveness of the method. On\nartificial problems, the proposed regularization subsumes the Total Variation\nminimization and recovers the expected decomposition. On the real-world problem\nof electro-encephalography brainwave decomposition, the approach outperforms\nsimilar approaches in terms of P300 evoked potentials detection, using\nstructured spatial priors to guide the decomposition.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 20:50:16 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Isaac", "Yoann", ""], ["Barth\u00e9lemy", "Quentin", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Sebag", "Mich\u00e8le", ""], ["Atif", "Jamal", ""]]}, {"id": "1609.09548", "submitter": "Vaggos Chatziafratis", "authors": "Moses Charikar and Vaggos Chatziafratis", "title": "Approximate Hierarchical Clustering via Sparsest Cut and Spreading\n  Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dasgupta recently introduced a cost function for the hierarchical clustering\nof a set of points given pairwise similarities between them. He showed that\nthis function is NP-hard to optimize, but a top-down recursive partitioning\nheuristic based on an alpha_n-approximation algorithm for uniform sparsest cut\ngives an approximation of O(alpha_n log n) (the current best algorithm has\nalpha_n=O(sqrt{log n})). We show that the aforementioned sparsest cut heuristic\nin fact obtains an O(alpha_n)-approximation for hierarchical clustering. The\nalgorithm also applies to a generalized cost function studied by Dasgupta.\nMoreover, we obtain a strong inapproximability result, showing that the\nhierarchical clustering objective is hard to approximate to within any constant\nfactor assuming the Small-Set Expansion (SSE) Hypothesis. Finally, we discuss\napproximation algorithms based on convex relaxations. We present a spreading\nmetric SDP relaxation for the problem and show that it has integrality gap at\nmost O(sqrt{log n}). The advantage of the SDP relative to the sparsest cut\nheuristic is that it provides an explicit lower bound on the optimal solution\nand could potentially yield an even better approximation for hierarchical\nclustering. In fact our analysis of this SDP served as the inspiration for our\nimproved analysis of the sparsest cut heuristic. We also show that a spreading\nmetric LP relaxation gives an O(log n)-approximation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 23:35:34 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Charikar", "Moses", ""], ["Chatziafratis", "Vaggos", ""]]}, {"id": "1609.09654", "submitter": "Matev\\v{z} Jekovec", "authors": "Matev\\v{z} Jekovec, Andrej Brodnik", "title": "ERA Revisited: Theoretical and Experimental Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient construction of the suffix tree given an input text is an active\narea of research from the time it was first introduced. Both theoretical\ncomputer scientists and engineers tackled the problem. In this paper we focus\non the fastest practical suffix tree construction algorithm to date, ERA. We\nfirst provide a theoretical analysis of the algorithm assuming the uniformly\nrandom text as an input and using the PEM model of computation with respect to\nthe lower bounds. Secondly, we empirically confirm the theoretical results in\ndifferent test scenarios exposing the critical terms. Thirdly, we discuss the\nfundamental characteristics of the input text where the fastest suffix tree\nconstruction algorithms in practice fail. This paper serves as a foundation for\nfurther research in the parallel text indexing area.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 09:51:36 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Jekovec", "Matev\u017e", ""], ["Brodnik", "Andrej", ""]]}, {"id": "1609.09679", "submitter": "Patrizio Angelini", "authors": "Patrizio Angelini and Giordano Da Lozzo", "title": "Clustered Planarity with Pipes", "comments": "19 pages, 9 figures, extended version of the paper appeared at ISAAC\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the version of the C-Planarity problem in which edges connecting the\nsame pair of clusters must be grouped into pipes, which generalizes the Strip\nPlanarity problem. We give algorithms to decide several families of instances\nfor the two variants in which the order of the pipes around each cluster is\ngiven as part of the input or can be chosen by the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 11:44:55 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Angelini", "Patrizio", ""], ["Da Lozzo", "Giordano", ""]]}, {"id": "1609.09840", "submitter": "Daniel Lemire", "authors": "Dmytro Ivanchykhin, Sergey Ignatchenko, Daniel Lemire", "title": "Regular and almost universal hashing: an efficient implementation", "comments": "accepted for publication in Software: Practice and Experience in\n  September 2016", "journal-ref": "Software: Practice and Experience 47 (10), 2017", "doi": "10.1002/spe.2461", "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random hashing can provide guarantees regarding the performance of data\nstructures such as hash tables---even in an adversarial setting. Many existing\nfamilies of hash functions are universal: given two data objects, the\nprobability that they have the same hash value is low given that we pick hash\nfunctions at random. However, universality fails to ensure that all hash\nfunctions are well behaved. We further require regularity: when picking data\nobjects at random they should have a low probability of having the same hash\nvalue, for any fixed hash function. We present the efficient implementation of\na family of non-cryptographic hash functions (PM+) offering good running times,\ngood memory usage as well as distinguishing theoretical guarantees: almost\nuniversality and component-wise regularity. On a variety of platforms, our\nimplementations are comparable to the state of the art in performance. On\nrecent Intel processors, PM+ achieves a speed of 4.7 bytes per cycle for 32-bit\noutputs and 3.3 bytes per cycle for 64-bit outputs. We review vectorization\nthrough SIMD instructions (e.g., AVX2) and optimizations for superscalar\nexecution.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 18:01:25 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 18:54:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ivanchykhin", "Dmytro", ""], ["Ignatchenko", "Sergey", ""], ["Lemire", "Daniel", ""]]}, {"id": "1609.09864", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen", "title": "Technical Report: Graph-Structured Sparse Optimization for Connected\n  Subgraph Detection", "comments": "11 pages in 2016 IEEE International Conference of Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured sparse optimization is an important and challenging problem for\nanalyzing high-dimensional data in a variety of applications such as\nbioinformatics, medical imaging, social networks, and astronomy. Although a\nnumber of structured sparsity models have been explored, such as trees, groups,\nclusters, and paths, connected subgraphs have been rarely explored in the\ncurrent literature. One of the main technical challenges is that there is no\nstructured sparsity-inducing norm that can directly model the space of\nconnected subgraphs, and there is no exact implementation of a projection\noracle for connected subgraphs due to its NP-hardness. In this paper, we\nexplore efficient approximate projection oracles for connected subgraphs, and\npropose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to\noptimize a generic nonlinear objective function subject to connectivity\nconstraint on the support of the variables. Our proposed algorithms enjoy\nstrong guarantees analogous to several current methods for sparsity-constrained\noptimization, such as Projected Gradient Descent (PGD), Approximate Model\nIterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit\n(GHTP) with respect to convergence rate and approximation accuracy. We apply\nour proposed algorithms to optimize several well-known graph scan statistics in\nseveral applications of connected subgraph detection as a case study, and the\nexperimental results demonstrate that our proposed algorithms outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 19:26:26 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""]]}]