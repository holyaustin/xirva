[{"id": "1006.0234", "submitter": "Manuel Gomez Rodriguez", "authors": "Manuel Gomez-Rodriguez, Jure Leskovec, Andreas Krause", "title": "Inferring Networks of Diffusion and Influence", "comments": "Short version appeared in ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD), 2010. Long version submitted to\n  ACM Transactions on Knowledge Discovery from Data (TKDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information diffusion and virus propagation are fundamental processes taking\nplace in networks. While it is often possible to directly observe when nodes\nbecome infected with a virus or adopt the information, observing individual\ntransmissions (i.e., who infects whom, or who influences whom) is typically\nvery difficult. Furthermore, in many applications, the underlying network over\nwhich the diffusions and propagations spread is actually unobserved. We tackle\nthese challenges by developing a method for tracing paths of diffusion and\ninfluence through networks and inferring the networks over which contagions\npropagate. Given the times when nodes adopt pieces of information or become\ninfected, we identify the optimal network that best explains the observed\ninfection times. Since the optimization problem is NP-hard to solve exactly, we\ndevelop an efficient approximation algorithm that scales to large datasets and\nfinds provably near-optimal networks.\n  We demonstrate the effectiveness of our approach by tracing information\ndiffusion in a set of 170 million blogs and news articles over a one year\nperiod to infer how information flows through the online media space. We find\nthat the diffusion network of news for the top 1,000 media sites and blogs\ntends to have a core-periphery structure with a small set of core media sites\nthat diffuse information to the rest of the Web. These sites tend to have\nstable circles of influence with more general news media sites acting as\nconnectors between them.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2010 20:02:31 GMT"}, {"version": "v2", "created": "Tue, 7 Dec 2010 20:35:08 GMT"}, {"version": "v3", "created": "Sun, 23 Oct 2011 18:56:10 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Gomez-Rodriguez", "Manuel", ""], ["Leskovec", "Jure", ""], ["Krause", "Andreas", ""]]}, {"id": "1006.0405", "submitter": "EPTCS", "authors": "Thomas Steinke, Raazesh Sainudiin", "title": "A Rigorous Extension of the Sch\\\"onhage-Strassen Integer Multiplication\n  Algorithm Using Complex Interval Arithmetic", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 151-159", "doi": "10.4204/EPTCS.24.19", "report-no": null, "categories": "cs.NA cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplication of n-digit integers by long multiplication requires O(n^2)\noperations and can be time-consuming. In 1970 A. Schoenhage and V. Strassen\npublished an algorithm capable of performing the task with only O(n log(n))\narithmetic operations over the complex field C; naturally, finite-precision\napproximations to C are used and rounding errors need to be accounted for.\nOverall, using variable-precision fixed-point numbers, this results in an\nO(n(log(n))^(2+Epsilon))-time algorithm. However, to make this algorithm more\nefficient and practical we need to make use of hardware-based floating-point\nnumbers. How do we deal with rounding errors? and how do we determine the\nlimits of the fixed-precision hardware? Our solution is to use interval\narithmetic to guarantee the correctness of results and determine the hardware's\nlimits. We examine the feasibility of this approach and are able to report that\n75,000-digit base-256 integers can be handled using double-precision\ncontainment sets. This clearly demonstrates that our approach has practical\npotential; however, at this stage, our implementation does not yet compete with\ncommercial ones, but we are able to demonstrate the feasibility of this\ntechnique.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:31:02 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Steinke", "Thomas", ""], ["Sainudiin", "Raazesh", ""]]}, {"id": "1006.0407", "submitter": "Anastasios Zouzias", "authors": "Petros Drineas and Anastasios Zouzias", "title": "A Note on Element-wise Matrix Sparsification via a Matrix-valued\n  Bernstein Inequality", "comments": "8 pages", "journal-ref": null, "doi": "10.1016/j.ipl.2011.01.010", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an n x n matrix A, we present a simple, element-wise sparsification\nalgorithm that zeroes out all sufficiently small elements of A and then retains\nsome of the remaining elements with probabilities proportional to the square of\ntheir magnitudes. We analyze the approximation accuracy of the proposed\nalgorithm using a recent, elegant non-commutative Bernstein inequality, and\ncompare our bounds with all existing (to the best of our knowledge)\nelement-wise matrix sparsification algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:39:17 GMT"}, {"version": "v2", "created": "Thu, 13 Jan 2011 19:25:20 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Drineas", "Petros", ""], ["Zouzias", "Anastasios", ""]]}, {"id": "1006.0773", "submitter": "Shmuel Onn", "authors": "Jon Lee, Shmuel Onn, Lyubov Romanchuk, Robert Weismantel", "title": "The Quadratic Graver Cone, Quadratic Integer Minimization, and\n  Extensions", "comments": null, "journal-ref": "Mathematical Programming, 136:301--323, 2012", "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the nonlinear integer programming problem of minimizing a\nquadratic function over the integer points in variable dimension satisfying a\nsystem of linear inequalities. We show that when the Graver basis of the matrix\ndefining the system is given, and the quadratic function lies in a suitable\n{\\em dual Graver cone}, the problem can be solved in polynomial time. We\ndiscuss the relation between this cone and the cone of positive semidefinite\nmatrices, and show that none contains the other. So we can minimize in\npolynomial time some non-convex and some (including all separable) convex\nquadrics.\n  We conclude by extending our results to efficient integer minimization of\nmultivariate polynomial functions of arbitrary degree lying in suitable cones.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2010 02:55:25 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Lee", "Jon", ""], ["Onn", "Shmuel", ""], ["Romanchuk", "Lyubov", ""], ["Weismantel", "Robert", ""]]}, {"id": "1006.0809", "submitter": "Szymon Grabowski", "authors": "Szymon Grabowski, Wojciech Bieniecki", "title": "Tight and simple Web graph compression", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing Web graphs has applications in determining page ranks, fighting Web\nspam, detecting communities and mirror sites, and more. This study is however\nhampered by the necessity of storing a major part of huge graphs in the\nexternal memory, which prevents efficient random access to edge (hyperlink)\nlists. A number of algorithms involving compression techniques have thus been\npresented, to represent Web graphs succinctly but also providing random access.\nThose techniques are usually based on differential encodings of the adjacency\nlists, finding repeating nodes or node regions in the successive lists, more\ngeneral grammar-based transformations or 2-dimensional representations of the\nbinary matrix of the graph. In this paper we present two Web graph compression\nalgorithms. The first can be seen as engineering of the Boldi and Vigna (2004)\nmethod. We extend the notion of similarity between link lists, and use a more\ncompact encoding of residuals. The algorithm works on blocks of varying size\n(in the number of input lines) and sacrifices access time for better\ncompression ratio, achieving more succinct graph representation than other\nalgorithms reported in the literature. The second algorithm works on blocks of\nthe same size, in the number of input lines, and its key mechanism is merging\nthe block into a single ordered list. This method achieves much more attractive\nspace-time tradeoffs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2010 08:41:22 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2011 12:46:56 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Grabowski", "Szymon", ""], ["Bieniecki", "Wojciech", ""]]}, {"id": "1006.0849", "submitter": "Nicholas Fyson", "authors": "Nick Fyson, Tijl De Bie and Nello Cristianini", "title": "Reconstruction of Causal Networks by Set Covering", "comments": "Under consideration for the ECML PKDD 2010 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for the reconstruction of networks, based on the order of\nnodes visited by a stochastic branching process. Our algorithm reconstructs a\nnetwork of minimal size that ensures consistency with the data. Crucially, we\nshow that global consistency with the data can be achieved through purely local\nconsiderations, inferring the neighbourhood of each node in turn. The\noptimisation problem solved for each individual node can be reduced to a Set\nCovering Problem, which is known to be NP-hard but can be approximated well in\npractice. We then extend our approach to account for noisy data, based on the\nMinimum Description Length principle. We demonstrate our algorithms on\nsynthetic data, generated by an SIR-like epidemiological model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2010 10:33:49 GMT"}], "update_date": "2010-06-07", "authors_parsed": [["Fyson", "Nick", ""], ["De Bie", "Tijl", ""], ["Cristianini", "Nello", ""]]}, {"id": "1006.1003", "submitter": "Lionel Levine", "authors": "Tobias Friedrich and Lionel Levine", "title": "Fast simulation of large-scale growth models", "comments": "27 pages, 9 figures. To appear in Random Structures & Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm that computes the final state of certain growth models\nwithout computing all intermediate states. Our technique is based on a \"least\naction principle\" which characterizes the odometer function of the growth\nprocess. Starting from an approximation for the odometer, we successively\ncorrect under- and overestimates and provably arrive at the correct final\nstate.\n  Internal diffusion-limited aggregation (IDLA) is one of the models amenable\nto our technique. The boundary fluctuations in IDLA were recently proved to be\nat most logarithmic in the size of the growth cluster, but the constant in\nfront of the logarithm is still not known. As an application of our method, we\ncalculate the size of fluctuations over two orders of magnitude beyond previous\nsimulations, and use the results to estimate this constant.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2010 22:41:43 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2012 02:28:43 GMT"}], "update_date": "2012-03-30", "authors_parsed": [["Friedrich", "Tobias", ""], ["Levine", "Lionel", ""]]}, {"id": "1006.1104", "submitter": "Jenny Blight", "authors": "Jacqueline E. Rice and Kenneth B. Kent", "title": "Systolic Array Technique for Determining Common Approximate Substrings", "comments": "Submitted to Journal of Computer Science and Engineering, see\n  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010", "journal-ref": "Journal of Computer Science and Engineering, Volume 1, Issue 1,\n  p1-9, May 2010", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A technique using a systolic array structure is proposed for solving the\ncommon approximate substring (CAS) problem. This approach extends the technique\nintroduced in earlier work from the computation of the edit-distance between\ntwo strings to the more encompassing CAS problem. A comparison to existing work\nis given, and the technique presented is validated and analyzed based on\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2010 14:11:59 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Rice", "Jacqueline E.", ""], ["Kent", "Kenneth B.", ""]]}, {"id": "1006.1117", "submitter": "Hagai Cohen", "authors": "Hagai Cohen and Ely Porat", "title": "On the hardness of distance oracle for sparse graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that set-intersection is harder than distance oracle on\nsparse graphs. Given a collection of total size n which consists of m sets\ndrawn from universe U, the set-intersection problem is to build a data\nstructure which can answer whether two sets have any intersection. A distance\noracle is a data structure which can answer distance queries on a given graph.\nWe show that if one can build distance oracle for sparse graph G=(V,E), which\nrequires s(|V|,|E|) space and answers a (2-\\epsilon,c)-approximate distance\nquery in time t(|V|,|E|) where (2-\\epsilon) is a multiplicative error and c is\na constant additive error, then, set-intersection can be solved in t(m+|U|,n)\ntime using s(m+|U|,n) space.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2010 17:03:09 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Cohen", "Hagai", ""], ["Porat", "Ely", ""]]}, {"id": "1006.1231", "submitter": "Nikolaos Fountoulakis", "authors": "Nikolaos Fountoulakis, Konstantinos Panagiotou and Angelika Steger", "title": "On the Insertion Time of Cuckoo Hashing", "comments": "27 pages, final version accepted by the SIAM Journal on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cuckoo hashing is an efficient technique for creating large hash tables with\nhigh space utilization and guaranteed constant access times. There, each item\ncan be placed in a location given by any one out of k different hash functions.\nIn this paper we investigate further the random walk heuristic for inserting in\nan online fashion new items into the hash table. Provided that k > 2 and that\nthe number of items in the table is below (but arbitrarily close) to the\ntheoretically achievable load threshold, we show a polylogarithmic bound for\nthe maximum insertion time that holds with high probability.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2010 11:15:01 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 16:37:57 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2013 18:58:29 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Fountoulakis", "Nikolaos", ""], ["Panagiotou", "Konstantinos", ""], ["Steger", "Angelika", ""]]}, {"id": "1006.1307", "submitter": "Sraban Mohanty", "authors": "Sraban Kumar Mohanty", "title": "I/O Efficient Algorithms for Matrix Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse some QR decomposition algorithms, and show that the I/O complexity\nof the tile based algorithm is asymptotically the same as that of matrix\nmultiplication. This algorithm, we show, performs the best when the tile size\nis chosen so that exactly one tile fits in the main memory. We propose a\nconstant factor improvement, as well as a new recursive cache oblivious\nalgorithm with the same asymptotic I/O complexity. We design Hessenberg,\ntridiagonal, and bidiagonal reductions that use banded intermediate forms, and\nperform only asymptotically optimal numbers of I/Os; these are the first I/O\noptimal algorithms for these problems. In particular, we show that known slab\nbased algorithms for two sided reductions all have suboptimal asymptotic I/O\nperformances, even though they have been reported to do better than the\ntraditional algorithms on the basis of empirical evidence.\n  We propose new tile based variants of multishift QR and QZ algorithms that\nunder certain conditions on the number of shifts, have better seek and I/O\ncomplexities than all known variants.\n  We show that techniques like rescheduling of computational steps, appropriate\nchoosing of the blocking parameters and incorporating of more matrix-matrix\noperations, can be used to improve the I/O and seek complexities of matrix\ncomputations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2010 17:42:53 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Mohanty", "Sraban Kumar", ""]]}, {"id": "1006.1405", "submitter": "EPTCS", "authors": "Lubo\\v{s} Brim (Masaryk University), Jakub Chaloupka (Masaryk\n  University)", "title": "Using Strategy Improvement to Stay Alive", "comments": null, "journal-ref": "EPTCS 25, 2010, pp. 40-54", "doi": "10.4204/EPTCS.25.8", "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a novel algorithm for solving Mean-Payoff Games (MPGs). Besides\nsolving an MPG in the usual sense, our algorithm computes more information\nabout the game, information that is important with respect to applications. The\nweights of the edges of an MPG can be thought of as a gained/consumed energy --\ndepending on the sign. For each vertex, our algorithm computes the minimum\namount of initial energy that is sufficient for player Max to ensure that in a\nplay starting from the vertex, the energy level never goes below zero. Our\nalgorithm is not the first algorithm that computes the minimum sufficient\ninitial energies, but according to our experimental study it is the fastest\nalgorithm that computes them. The reason is that it utilizes the strategy\nimprovement technique which is very efficient in practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:42:39 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Brim", "Lubo\u0161", "", "Masaryk University"], ["Chaloupka", "Jakub", "", "Masaryk\n  University"]]}, {"id": "1006.1409", "submitter": "EPTCS", "authors": "Oliver Friedmann (University of Munich), Martin Lange (University of\n  Kassel)", "title": "Local Strategy Improvement for Parity Game Solving", "comments": null, "journal-ref": "EPTCS 25, 2010, pp. 118-131", "doi": "10.4204/EPTCS.25.13", "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of solving a parity game is at the core of many problems in model\nchecking, satisfiability checking and program synthesis. Some of the best\nalgorithms for solving parity game are strategy improvement algorithms. These\nare global in nature since they require the entire parity game to be present at\nthe beginning. This is a distinct disadvantage because in many applications one\nonly needs to know which winning region a particular node belongs to, and a\nwitnessing winning strategy may cover only a fractional part of the entire game\ngraph.\n  We present a local strategy improvement algorithm which explores the game\ngraph on-the-fly whilst performing the improvement steps. We also compare it\nempirically with existing global strategy improvement algorithms and the\ncurrently only other local algorithm for solving parity games. It turns out\nthat local strategy improvement can outperform these others by several orders\nof magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:42:58 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Friedmann", "Oliver", "", "University of Munich"], ["Lange", "Martin", "", "University of\n  Kassel"]]}, {"id": "1006.1431", "submitter": "EPTCS", "authors": "Vedran Dunjko, Elham Kashefi", "title": "Algebraic characterisation of one-way patterns", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 85-100", "doi": "10.4204/EPTCS.26.8", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a complete structural characterisation of the map the positive branch\nof a one-way pattern implements. We start with the representation of the\npositive branch in terms of the phase map decomposition, which is then further\nanalysed to obtain the primary structure of the matrix M, representing the\nphase map decomposition in the computational basis. Using this approach we\nobtain some preliminary results on the connection between the columns structure\nof a given unitary and the angles of measurements in a pattern that implements\nit. We believe this work is a step forward towards a full characterisation of\nthose unitaries with an efficient one-way model implementation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 01:16:41 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Dunjko", "Vedran", ""], ["Kashefi", "Elham", ""]]}, {"id": "1006.1443", "submitter": "Tobias Friedrich", "authors": "Tobias Friedrich, Thomas Sauerwald, Dan Vilenchik", "title": "Smoothed Analysis of Balancing Networks", "comments": "26 pages, to appear in Random Structures and Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a balancing network each processor has an initial collection of unit-size\njobs (tokens) and in each round, pairs of processors connected by balancers\nsplit their load as evenly as possible. An excess token (if any) is placed\naccording to some predefined rule. As it turns out, this rule crucially affects\nthe performance of the network. In this work we propose a model that studies\nthis effect. We suggest a model bridging the uniformly-random assignment rule,\nand the arbitrary one (in the spirit of smoothed-analysis). We start with an\narbitrary assignment of balancer directions and then flip each assignment with\nprobability $\\alpha$ independently. For a large class of balancing networks our\nresult implies that after $\\Oh(\\log n)$ rounds the discrepancy is $\\Oh(\n(1/2-\\alpha) \\log n + \\log \\log n)$ with high probability. This matches and\ngeneralizes known upper bounds for $\\alpha=0$ and $\\alpha=1/2$. We also show\nthat a natural network matches the upper bound for any $\\alpha$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 03:16:18 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Friedrich", "Tobias", ""], ["Sauerwald", "Thomas", ""], ["Vilenchik", "Dan", ""]]}, {"id": "1006.1921", "submitter": "Michael Goodrich", "authors": "Matthew T. Dickerson, David Eppstein, Michael T. Goodrich", "title": "Cloning Voronoi Diagrams via Retroactive Data Structures", "comments": "More complete version of paper appearing in 2010 European Symposium\n  on Algorithms (ESA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of replicating a Voronoi diagram $V(S)$ of a planar\npoint set $S$ by making proximity queries, which are of three possible (in\ndecreasing order of information content): 1. the exact location of the nearest\nsite(s) in $S$; 2. the distance to and label(s) of the nearest site(s) in $S$;\n3. a unique label for every nearest site in $S$. We provide algorithms showing\nhow queries of Type 1 and Type 2 allow an exact cloning of $V(S)$ with $O(n)$\nqueries and $O(n \\log^2 n)$ processing time. We also prove that queries of Type\n3 can never exactly clone $V(S)$, but we show that with $O(n\n\\log\\frac{1}{\\epsilon})$ queries we can construct an $\\epsilon$-approximate\ncloning of $V(S)$. In addition to showing the limits of nearest-neighbor\ndatabase security, our methods also provide one of the first natural\nalgorithmic applications of retroactive data structures.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 22:38:03 GMT"}], "update_date": "2010-06-11", "authors_parsed": [["Dickerson", "Matthew T.", ""], ["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""]]}, {"id": "1006.1923", "submitter": "Kanat Tangwongsan", "authors": "Guy E. Blelloch and Kanat Tangwongsan", "title": "Parallel Approximation Algorithms for Facility-Location Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design and analysis of parallel approximation\nalgorithms for facility-location problems, including $\\NC$ and $\\RNC$\nalgorithms for (metric) facility location, $k$-center, $k$-median, and\n$k$-means. These problems have received considerable attention during the past\ndecades from the approximation algorithms community, concentrating primarily on\nimproving the approximation guarantees. In this paper, we ask, is it possible\nto parallelize some of the beautiful results from the sequential setting?\n  Our starting point is a small, but diverse, subset of results in\napproximation algorithms for facility-location problems, with a primary goal of\ndeveloping techniques for devising their efficient parallel counterparts. We\nfocus on giving algorithms with low depth, near work efficiency (compared to\nthe sequential versions), and low cache complexity. Common in algorithms we\npresent is the idea that instead of picking only the most cost-effective\nelement, we make room for parallelism by allowing a small slack (e.g., a\n$(1+\\vareps)$ factor) in what can be selected---then, we use a clean-up step to\nensure that the behavior does not deviate too much from the sequential steps.\nAll the algorithms we developed are ``cache efficient'' in that the cache\ncomplexity is bounded by $O(w/B)$, where $w$ is the work in the EREW model and\n$B$ is the block size.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 22:54:18 GMT"}], "update_date": "2010-06-11", "authors_parsed": [["Blelloch", "Guy E.", ""], ["Tangwongsan", "Kanat", ""]]}, {"id": "1006.1990", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov", "title": "Minimizing a sum of submodular functions", "comments": "accepted to \"Discrete Applied Mathematics\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a function represented as a sum of\nsubmodular terms. We assume each term allows an efficient computation of {\\em\nexchange capacities}. This holds, for example, for terms depending on a small\nnumber of variables, or for certain cardinality-dependent terms.\n  A naive application of submodular minimization algorithms would not exploit\nthe existence of specialized exchange capacity subroutines for individual\nterms. To overcome this, we cast the problem as a {\\em submodular flow} (SF)\nproblem in an auxiliary graph, and show that applying most existing SF\nalgorithms would rely only on these subroutines.\n  We then explore in more detail Iwata's capacity scaling approach for\nsubmodular flows (Math. Programming, 76(2):299--308, 1997). In particular, we\nshow how to improve its complexity in the case when the function contains\ncardinality-dependent terms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2010 10:18:36 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2012 08:38:34 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Kolmogorov", "Vladimir", ""]]}, {"id": "1006.1998", "submitter": "Mikko Koivisto", "authors": "Mikko Koivisto, Valentin Polishchuk", "title": "Geodesic diameter of a polygonal domain in O(n^4 log n) time", "comments": "NOTE: It has turned out that, unfortunately, Lemma 2 does not hold,\n  which renders the main result incorrect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the geodesic diameter of a polygonal domain with n vertices can\nbe computed in O(n^4 log n) time by considering O(n^3) candidate diameter\nendpoints; the endpoints are a subset of vertices of the overlay of shortest\npath maps from vertices of the domain.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2010 10:47:19 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 06:53:32 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Koivisto", "Mikko", ""], ["Polishchuk", "Valentin", ""]]}, {"id": "1006.2218", "submitter": "Carlos Barr\\'on-Romero", "authors": "Carlos Barron-Romero", "title": "The Complexity Of The NP-Class", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS physics.atm-clus", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel and straight formulation, and gives a complete\ninsight towards the understanding of the complexity of the problems of the so\ncalled NP-Class. In particular, this paper focuses in the Searching of the\nOptimal Geometrical Structures and the Travelling Salesman Problems. The main\nresults are the polynomial reduction procedure and the solution to the Noted\nConjecture of the NP-Class.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2010 07:56:52 GMT"}], "update_date": "2010-06-14", "authors_parsed": [["Barron-Romero", "Carlos", ""]]}, {"id": "1006.2269", "submitter": "Stefan Engblom", "authors": "Stefan Engblom", "title": "On well-separated sets and fast multipole methods", "comments": null, "journal-ref": "Appl. Numer. Math. 61(10):1096--1102, 2011", "doi": "10.1016/j.apnum.2011.06.011", "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of well-separated sets is crucial in fast multipole methods as the\nmain idea is to approximate the interaction between such sets via cluster\nexpansions. We revisit the one-parameter multipole acceptance criterion in a\ngeneral setting and derive a relative error estimate. This analysis benefits\nasymmetric versions of the method, where the division of the multipole boxes is\nmore liberal than in conventional codes. Such variants offer a particularly\nelegant implementation with a balanced multipole tree, a feature which might be\nvery favorable on modern computer architectures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2010 11:45:07 GMT"}, {"version": "v2", "created": "Tue, 8 Feb 2011 17:30:52 GMT"}, {"version": "v3", "created": "Wed, 10 Aug 2011 07:53:15 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Engblom", "Stefan", ""]]}, {"id": "1006.2307", "submitter": "Carlos Rodriguez-Caso", "authors": "Joaqu\\'in Go\\~ni, Bernat Corominas-Murtra, Ricard V. Sol\\'e and Carlos\n  Rodr\\'iguez-Caso", "title": "Exploring the randomness of Directed Acyclic Networks", "comments": "13 pages, 5 figures and 5 tables", "journal-ref": null, "doi": "10.1103/PhysRevE.82.066115", "report-no": null, "categories": "physics.soc-ph cond-mat.soft cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The feed-forward relationship naturally observed in time-dependent processes\nand in a diverse number of real systems -such as some food-webs and electronic\nand neural wiring- can be described in terms of so-called directed acyclic\ngraphs (DAGs). An important ingredient of the analysis of such networks is a\nproper comparison of their observed architecture against an ensemble of\nrandomized graphs, thereby quantifying the {\\em randomness} of the real systems\nwith respect to suitable null models. This approximation is particularly\nrelevant when the finite size and/or large connectivity of real systems make\ninadequate a comparison with the predictions obtained from the so-called {\\em\nconfiguration model}. In this paper we analyze four methods of DAG\nrandomization as defined by the desired combination of topological invariants\n(directed and undirected degree sequence and component distributions) aimed to\nbe preserved. A highly ordered DAG, called \\textit{snake}-graph and a\nErd\\:os-R\\'enyi DAG were used to validate the performance of the algorithms.\nFinally, three real case studies, namely, the \\textit{C. elegans} cell lineage\nnetwork, a PhD student-advisor network and the Milgram's citation network were\nanalyzed using each randomization method. Results show how the interpretation\nof degree-degree relations in DAGs respect to their randomized ensembles depend\non the topological invariants imposed. In general, real DAGs provide disordered\nvalues, lower than the expected by chance when the directedness of the links is\nnot preserved in the randomization process. Conversely, if the direction of the\nlinks is conserved throughout the randomization process, disorder indicators\nare close to the obtained from the null-model ensemble, although some\ndeviations are observed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2010 13:39:02 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Go\u00f1i", "Joaqu\u00edn", ""], ["Corominas-Murtra", "Bernat", ""], ["Sol\u00e9", "Ricard V.", ""], ["Rodr\u00edguez-Caso", "Carlos", ""]]}, {"id": "1006.2361", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez and Peter Neubauer", "title": "Constructions from Dots and Lines", "comments": "In press with the Bulletin of the American Society for Information\n  Science and Technology", "journal-ref": "Bulletin of the American Society for Information Science and\n  Technology, American Society for Information Science and Technology, 36,(6),\n  pp. 35-41, ISSN:1550-8366, August 2010", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is a data structure composed of dots (i.e. vertices) and lines (i.e.\nedges). The dots and lines of a graph can be organized into intricate\narrangements. The ability for a graph to denote objects and their relationships\nto one another allow for a surprisingly large number of things to be modeled as\na graph. From the dependencies that link software packages to the wood beams\nthat provide the framing to a house, most anything has a corresponding graph\nrepresentation. However, just because it is possible to represent something as\na graph does not necessarily mean that its graph representation will be useful.\nIf a modeler can leverage the plethora of tools and algorithms that store and\nprocess graphs, then such a mapping is worthwhile. This article explores the\nworld of graphs in computing and exposes situations in which graphical models\nare beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2010 18:16:10 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Neubauer", "Peter", ""]]}, {"id": "1006.2461", "submitter": "Praveen Manjunatha", "authors": "M. Praveen", "title": "Does Treewidth Help in Modal Satisfiability?", "comments": "Full version of the paper appearing in MFCS 2010. Change from v1:\n  improved section 5 to avoid exponential blow-up in formula size", "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_51", "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tractable algorithms for solving the Constraint Satisfaction Problem\n(CSP) have been developed using the notion of the treewidth of some graph\nderived from the input CSP instance. In particular, the incidence graph of the\nCSP instance is one such graph. We introduce the notion of an incidence graph\nfor modal logic formulae in a certain normal form. We investigate the\nparameterized complexity of modal satisfiability with the modal depth of the\nformula and the treewidth of the incidence graph as parameters. For various\ncombinations of Euclidean, reflexive, symmetric and transitive models, we show\neither that modal satisfiability is FPT, or that it is W[1]-hard. In\nparticular, modal satisfiability in general models is FPT, while it is\nW[1]-hard in transitive models. As might be expected, modal satisfiability in\ntransitive and Euclidean models is FPT.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2010 12:25:17 GMT"}, {"version": "v2", "created": "Tue, 11 Jan 2011 11:10:15 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Praveen", "M.", ""]]}, {"id": "1006.2880", "submitter": "Bahman Bahmani", "authors": "Bahman Bahmani, Abdur Chowdhury, Ashish Goel", "title": "Fast Incremental and Personalized PageRank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the efficiency of Monte Carlo methods for\nincremental computation of PageRank, personalized PageRank, and similar random\nwalk based methods (with focus on SALSA), on large-scale dynamically evolving\nsocial networks. We assume that the graph of friendships is stored in\ndistributed shared memory, as is the case for large social networks such as\nTwitter.\n  For global PageRank, we assume that the social network has $n$ nodes, and $m$\nadversarially chosen edges arrive in a random order. We show that with a reset\nprobability of $\\epsilon$, the total work needed to maintain an accurate\nestimate (using the Monte Carlo method) of the PageRank of every node at all\ntimes is $O(\\frac{n\\ln m}{\\epsilon^{2}})$. This is significantly better than\nall known bounds for incremental PageRank. For instance, if we naively\nrecompute the PageRanks as each edge arrives, the simple power iteration method\nneeds $\\Omega(\\frac{m^2}{\\ln(1/(1-\\epsilon))})$ total time and the Monte Carlo\nmethod needs $O(mn/\\epsilon)$ total time; both are prohibitively expensive.\nFurthermore, we also show that we can handle deletions equally efficiently.\n  We then study the computation of the top $k$ personalized PageRanks starting\nfrom a seed node, assuming that personalized PageRanks follow a power-law with\nexponent $\\alpha < 1$. We show that if we store $R>q\\ln n$ random walks\nstarting from every node for large enough constant $q$ (using the approach\noutlined for global PageRank), then the expected number of calls made to the\ndistributed social network database is $O(k/(R^{(1-\\alpha)/\\alpha}))$.\n  We also present experimental results from the social networking site,\nTwitter, verifying our assumptions and analyses. The overall result is that\nthis algorithm is fast enough for real-time queries over a dynamic social\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 03:37:51 GMT"}, {"version": "v2", "created": "Tue, 31 Aug 2010 14:17:30 GMT"}], "update_date": "2010-09-01", "authors_parsed": [["Bahmani", "Bahman", ""], ["Chowdhury", "Abdur", ""], ["Goel", "Ashish", ""]]}, {"id": "1006.2897", "submitter": "David Doty", "authors": "Nathaniel Bryans, Ehsan Chiniforooshan, David Doty, Lila Kari, and\n  Shinnosuke Seki", "title": "The Power of Nondeterminism in Self-Assembly", "comments": "Accepted to SODA 2011. The previous version of this paper (which\n  appears in the SODA proceedings) had open questions about computing the\n  minimum number of tile types to weakly self-assemble a set. The answer to\n  these questions is \"no\", by a very simple imitation of the proof that\n  Kolmogorov complexity is uncomputable based on the Berry paradox. These open\n  questions have been removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the role of nondeterminism in Winfree's abstract Tile Assembly\nModel (aTAM), which was conceived to model artificial molecular self-assembling\nsystems constructed from DNA. Of particular practical importance is to find\ntile systems that minimize resources such as the number of distinct tile types,\neach of which corresponds to a set of DNA strands that must be\ncustom-synthesized in actual molecular implementations of the aTAM. We seek to\nidentify to what extent the use of nondeterminism in tile systems affects the\nresources required by such molecular shape-building algorithms.\n  We first show a \"molecular computability theoretic\" result: there is an\ninfinite shape S that is uniquely assembled by a tile system but not by any\ndeterministic tile system. We then show an analogous phenomenon in the finitary\n\"molecular complexity theoretic\" case: there is a finite shape S that is\nuniquely assembled by a tile system with c tile types, but every deterministic\ntile system that uniquely assembles S has more than c tile types. In fact we\nextend the technique to derive a stronger (classical complexity theoretic)\nresult, showing that the problem of finding the minimum number of tile types\nthat uniquely assemble a given finite shape is Sigma-P-2-complete. In contrast,\nthe problem of finding the minimum number of deterministic tile types that\nuniquely assemble a shape was shown to be NP-complete by Adleman, Cheng, Goel,\nHuang, Kempe, Moisset de Espan\\'es, and Rothemund (Combinatorial Optimization\nProblems in Self-Assembly, STOC 2002).\n  The conclusion is that nondeterminism confers extra power to assemble a shape\nfrom a small tile system, but unless the polynomial hierarchy collapses, it is\ncomputationally more difficult to exploit this power by finding the size of the\nsmallest tile system, compared to finding the size of the smallest\ndeterministic tile system.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 06:24:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2010 21:19:07 GMT"}, {"version": "v3", "created": "Thu, 25 Nov 2010 17:26:11 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Bryans", "Nathaniel", ""], ["Chiniforooshan", "Ehsan", ""], ["Doty", "David", ""], ["Kari", "Lila", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1006.2926", "submitter": "Shakhar Smorodinsky", "authors": "Elad Horev and Roi Krakovski and Shakhar Smorodinsky", "title": "Conflict-Free Coloring Made Stronger", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-13731-0_11", "report-no": null, "categories": "math.CO cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In FOCS 2002, Even et al. showed that any set of $n$ discs in the plane can\nbe Conflict-Free colored with a total of at most $O(\\log n)$ colors. That is,\nit can be colored with $O(\\log n)$ colors such that for any (covered) point $p$\nthere is some disc whose color is distinct from all other colors of discs\ncontaining $p$. They also showed that this bound is asymptotically tight. In\nthis paper we prove the following stronger results:\n  \\begin{enumerate} \\item [(i)] Any set of $n$ discs in the plane can be\ncolored with a total of at most $O(k \\log n)$ colors such that (a) for any\npoint $p$ that is covered by at least $k$ discs, there are at least $k$\ndistinct discs each of which is colored by a color distinct from all other\ndiscs containing $p$ and (b) for any point $p$ covered by at most $k$ discs,\nall discs covering $p$ are colored distinctively. We call such a coloring a\n{\\em $k$-Strong Conflict-Free} coloring. We extend this result to pseudo-discs\nand arbitrary regions with linear union-complexity.\n  \\item [(ii)] More generally, for families of $n$ simple closed Jordan regions\nwith union-complexity bounded by $O(n^{1+\\alpha})$, we prove that there exists\na $k$-Strong Conflict-Free coloring with at most $O(k n^\\alpha)$ colors.\n  \\item [(iii)] We prove that any set of $n$ axis-parallel rectangles can be\n$k$-Strong Conflict-Free colored with at most $O(k \\log^2 n)$ colors.\n  \\item [(iv)] We provide a general framework for $k$-Strong Conflict-Free\ncoloring arbitrary hypergraphs. This framework relates the notion of $k$-Strong\nConflict-Free coloring and the recently studied notion of $k$-colorful\ncoloring. \\end{enumerate}\n  All of our proofs are constructive. That is, there exist polynomial time\nalgorithms for computing such colorings.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 08:51:35 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Horev", "Elad", ""], ["Krakovski", "Roi", ""], ["Smorodinsky", "Shakhar", ""]]}, {"id": "1006.2955", "submitter": "Dinesh Dash", "authors": "Dinesh Dash and Arijit Bishnu and Arobinda Gupta and Subhas C. Nandy", "title": "Approximation Algorithm for Line Segment Coverage for Wireless Sensor\n  Network", "comments": "16 pages, 5 figures,", "journal-ref": "Wireless Networks 19(5): 857-870 (2013)", "doi": "10.1007/s11276-012-0506-4", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coverage problem in wireless sensor networks deals with the problem of\ncovering a region or parts of it with sensors. In this paper, we address the\nproblem of covering a set of line segments in sensor networks. A line segment `\nis said to be covered if it intersects the sensing regions of at least one\nsensor distributed in that region. We show that the problem of finding the\nminimum number of sensors needed to cover each member in a given set of line\nsegments in a rectangular area is NP-hard. Next, we propose a constant factor\napproximation algorithm for the problem of covering a set of axis-parallel line\nsegments. We also show that a PTAS exists for this problem.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 10:51:44 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Dash", "Dinesh", ""], ["Bishnu", "Arijit", ""], ["Gupta", "Arobinda", ""], ["Nandy", "Subhas C.", ""]]}, {"id": "1006.3009", "submitter": "Stephane Rovedakis", "authors": "L\\'elia Blin (IBISC), Maria Potop-Butucaru (LIP6, INRIA Rocquencourt),\n  Stephane Rovedakis (IBISC), S\\'ebastien Tixeuil (LIP6)", "title": "Universal Loop-Free Super-Stabilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an univesal scheme to design loop-free and super-stabilizing\nprotocols for constructing spanning trees optimizing any tree metrics (not only\nthose that are isomorphic to a shortest path tree). Our scheme combines a novel\nsuper-stabilizing loop-free BFS with an existing self-stabilizing spanning tree\nthat optimizes a given metric. The composition result preserves the best\nproperties of both worlds: super-stabilization, loop-freedom, and optimization\nof the original metric without any stabilization time penalty. As case study we\napply our composition mechanism to two well known metric-dependent spanning\ntrees: the maximum-flow tree and the minimum degree spanning tree.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 15:17:23 GMT"}], "update_date": "2010-07-28", "authors_parsed": [["Blin", "L\u00e9lia", "", "IBISC"], ["Potop-Butucaru", "Maria", "", "LIP6, INRIA Rocquencourt"], ["Rovedakis", "Stephane", "", "IBISC"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "1006.3020", "submitter": "James Nastos", "authors": "James Nastos and Yong Gao", "title": "Bounded Search Tree Algorithms for Parameterized Cograph Deletion:\n  Efficient Branching Rules by Exploiting Structures of Special Graph Classes", "comments": "23 pages. Accepted in Discrete Mathematics, Algorithms and\n  Applications (DMAA)", "journal-ref": null, "doi": "10.1007/978-3-642-17461-2_27", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fixed-parameter tractable algorithms using a bounded search tree have\nbeen repeatedly improved, often by describing a larger number of branching\nrules involving an increasingly complex case analysis. We introduce a novel and\ngeneral search strategy that branches on the forbidden subgraphs of a graph\nclass relaxation. By using the class of $P_4$-sparse graphs as the relaxed\ngraph class, we obtain efficient bounded search tree algorithms for several\nparameterized deletion problems. We give the first non-trivial bounded search\ntree algorithms for the cograph edge-deletion problem and the trivially perfect\nedge-deletion problems. For the cograph vertex deletion problem, a refined\nanalysis of the runtime of our simple bounded search algorithm gives a faster\nexponential factor than those algorithms designed with the help of complicated\ncase distinctions and non-trivial running time analysis [21] and computer-aided\nbranching rules [11].\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 16:03:13 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2011 22:46:08 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Nastos", "James", ""], ["Gao", "Yong", ""]]}, {"id": "1006.3046", "submitter": "Matthew Patitz", "authors": "Matthew J. Patitz and Scott M. Summers", "title": "Identifying Shapes Using Self-Assembly (extended abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the following problem in the theory of\nalgorithmic self-assembly: given an input shape as the seed of a tile-based\nself-assembly system, design a finite tile set that can, in some sense,\nuniquely identify whether or not the given input shape--drawn from a very\ngeneral class of shapes--matches a particular target shape. We first study the\ncomplexity of correctly identifying squares. Then we investigate the complexity\nassociated with the identification of a considerably more general class of\nnon-square, hole-free shapes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 18:31:40 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""]]}, {"id": "1006.3122", "submitter": "Mike Steel Prof.", "authors": "Leo van Iersel, Charles Semple, Mike Steel", "title": "Locating a tree in a phylogenetic network", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic trees and networks are leaf-labelled graphs that are used to\ndescribe evolutionary histories of species. The Tree Containment problem asks\nwhether a given phylogenetic tree is embedded in a given phylogenetic network.\nGiven a phylogenetic network and a cluster of species, the Cluster Containment\nproblem asks whether the given cluster is a cluster of some phylogenetic tree\nembedded in the network. Both problems are known to be NP-complete in general.\nIn this article, we consider the restriction of these problems to several\nwell-studied classes of phylogenetic networks. We show that Tree Containment is\npolynomial-time solvable for normal networks, for binary tree-child networks,\nand for level-$k$ networks. On the other hand, we show that, even for\ntree-sibling, time-consistent, regular networks, both Tree Containment and\nCluster Containment remain NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 01:44:33 GMT"}], "update_date": "2010-06-17", "authors_parsed": [["van Iersel", "Leo", ""], ["Semple", "Charles", ""], ["Steel", "Mike", ""]]}, {"id": "1006.3141", "submitter": "Stephane Rovedakis", "authors": "L\\'elia Blin (IBISC), Shlomi Dolev, Maria Potop-Butucaru (LIP6, INRIA\n  Rocquencourt), Stephane Rovedakis (IBISC)", "title": "Fast Self-Stabilizing Minimum Spanning Tree Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel self-stabilizing algorithm for minimum spanning tree (MST)\nconstruction. The space complexity of our solution is $O(\\log^2n)$ bits and it\nconverges in $O(n^2)$ rounds. Thus, this algorithm improves the convergence\ntime of all previously known self-stabilizing asynchronous MST algorithms by a\nmultiplicative factor $\\Theta(n)$, to the price of increasing the best known\nspace complexity by a factor $O(\\log n)$. The main ingredient used in our\nalgorithm is the design, for the first time in self-stabilizing settings, of a\nlabeling scheme for computing the nearest common ancestor with only\n$O(\\log^2n)$ bits.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 06:59:36 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2010 08:33:40 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Blin", "L\u00e9lia", "", "IBISC"], ["Dolev", "Shlomi", "", "LIP6, INRIA\n  Rocquencourt"], ["Potop-Butucaru", "Maria", "", "LIP6, INRIA\n  Rocquencourt"], ["Rovedakis", "Stephane", "", "IBISC"]]}, {"id": "1006.3302", "submitter": "Tobias Friedrich", "authors": "Tobias Friedrich and Martin Gairing and Thomas Sauerwald", "title": "Quasirandom Load Balancing", "comments": "25 pages", "journal-ref": "SIAM Journal on Computing, Vol. 41, No. 4, pp. 747-771, 2012", "doi": "10.1137/100799216", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple distributed algorithm for balancing indivisible tokens on\ngraphs. The algorithm is completely deterministic, though it tries to imitate\n(and enhance) a random algorithm by keeping the accumulated rounding errors as\nsmall as possible.\n  Our new algorithm surprisingly closely approximates the idealized process\n(where the tokens are divisible) on important network topologies. On\nd-dimensional torus graphs with n nodes it deviates from the idealized process\nonly by an additive constant. In contrast to that, the randomized rounding\napproach of Friedrich and Sauerwald (2009) can deviate up to Omega(polylog(n))\nand the deterministic algorithm of Rabani, Sinclair and Wanka (1998) has a\ndeviation of Omega(n^{1/d}). This makes our quasirandom algorithm the first\nknown algorithm for this setting which is optimal both in time and achieved\nsmoothness. We further show that also on the hypercube our algorithm has a\nsmaller deviation from the idealized process than the previous algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 19:41:17 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2013 15:04:12 GMT"}], "update_date": "2013-04-22", "authors_parsed": [["Friedrich", "Tobias", ""], ["Gairing", "Martin", ""], ["Sauerwald", "Thomas", ""]]}, {"id": "1006.3368", "submitter": "Yuichi Yoshida", "authors": "Yuichi Yoshida", "title": "Optimal Constant-Time Approximation Algorithms and (Unconditional)\n  Inapproximability Results for Every Bounded-Degree CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raghavendra (STOC 2008) gave an elegant and surprising result: if Khot's\nUnique Games Conjecture (STOC 2002) is true, then for every constraint\nsatisfaction problem (CSP), the best approximation ratio is attained by a\ncertain simple semidefinite programming and a rounding scheme for it. In this\npaper, we show that similar results hold for constant-time approximation\nalgorithms in the bounded-degree model. Specifically, we present the\nfollowings: (i) For every CSP, we construct an oracle that serves an access, in\nconstant time, to a nearly optimal solution to a basic LP relaxation of the\nCSP. (ii) Using the oracle, we give a constant-time rounding scheme that\nachieves an approximation ratio coincident with the integrality gap of the\nbasic LP. (iii) Finally, we give a generic conversion from integrality gaps of\nbasic LPs to hardness results. All of those results are \\textit{unconditional}.\nTherefore, for every bounded-degree CSP, we give the best constant-time\napproximation algorithm among all. A CSP instance is called $\\epsilon$-far from\nsatisfiability if we must remove at least an $\\epsilon$-fraction of constraints\nto make it satisfiable. A CSP is called testable if there is a constant-time\nalgorithm that distinguishes satisfiable instances from $\\epsilon$-far\ninstances with probability at least $2/3$. Using the results above, we also\nderive, under a technical assumption, an equivalent condition under which a CSP\nis testable in the bounded-degree model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2010 04:38:53 GMT"}, {"version": "v2", "created": "Fri, 29 Oct 2010 01:52:21 GMT"}], "update_date": "2010-11-01", "authors_parsed": [["Yoshida", "Yuichi", ""]]}, {"id": "1006.3442", "submitter": "Amparo F\\'uster-Sabater", "authors": "Amparo F\\'uster-Sabater and J.M. Guill\\'en", "title": "New modelling technique for aperiodic-sampling linear systems", "comments": "19 pages, 0 figures", "journal-ref": "International Journal of Control, Volume 45, Issue 3 March 1987,\n  pages 951 - 968", "doi": "10.1080/00207178708933780", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general input-output modelling technique for aperiodic-sampling linear\nsystems has been developed. The procedure describes the dynamics of the system\nand includes the sequence of sampling periods among the variables to be\nhandled. Some restrictive conditions on the sampling sequence are imposed in\norder to guarantee the validity of the model. The particularization to the\nperiodic case represents an alternative to the classic methods of\ndiscretization of continuous systems without using the Z-transform. This kind\nof representation can be used largely for identification and control purposes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2010 12:17:11 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["F\u00faster-Sabater", "Amparo", ""], ["Guill\u00e9n", "J. M.", ""]]}, {"id": "1006.3541", "submitter": "Guilherme D. da Fonseca", "authors": "Vin\\'icius G. P. de S\\'a, Guilherme D. da Fonseca, Raphael Machado,\n  Celina M. H. de Figueiredo", "title": "Complexity dichotomy on partial grid recognition", "comments": null, "journal-ref": "Theoretical Computer Science, 412(22):2370-2379, 2011", "doi": "10.1016/j.tcs.2011.01.018", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding whether a graph can be embedded in a grid using only unit-length\nedges is NP-complete, even when restricted to binary trees. However, it is not\ndifficult to devise a number of graph classes for which the problem is\npolynomial, even trivial. A natural step, outstanding thus far, was to provide\na broad classification of graphs that make for polynomial or NP-complete\ninstances. We provide such a classification based on the set of allowed vertex\ndegrees in the input graphs, yielding a full dichotomy on the complexity of the\nproblem. As byproducts, the previous NP-completeness result for binary trees\nwas strengthened to strictly binary trees, and the three-dimensional version of\nthe problem was for the first time proven to be NP-complete. Our results were\nmade possible by introducing the concepts of consistent orientations and robust\ngadgets, and by showing how the former allows NP-completeness proofs by local\nreplacement even in the absence of the latter.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2010 18:30:09 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["de S\u00e1", "Vin\u00edcius G. P.", ""], ["da Fonseca", "Guilherme D.", ""], ["Machado", "Raphael", ""], ["de Figueiredo", "Celina M. H.", ""]]}, {"id": "1006.3585", "submitter": "Jelani Nelson", "authors": "Daniel M. Kane, Jelani Nelson", "title": "A Derandomized Sparse Johnson-Lindenstrauss Transform", "comments": "v3: Improved seed length, alternative proof of JL row optimality,\n  other minor changes; v2: Improved presentation. Added a warmup section,\n  Section 4, which gives a short proof of the JL lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work of [Dasgupta-Kumar-Sarlos, STOC 2010] gave a sparse\nJohnson-Lindenstrauss transform and left as a main open question whether their\nconstruction could be efficiently derandomized. We answer their question\naffirmatively by giving an alternative proof of their result requiring only\nbounded independence hash functions. Furthermore, the sparsity bound obtained\nin our proof is improved. The main ingredient in our proof is a spectral moment\nbound for quadratic forms that was recently used in [Diakonikolas-Kane-Nelson,\nFOCS 2010].\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 01:39:18 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2010 18:05:08 GMT"}, {"version": "v3", "created": "Tue, 7 Dec 2010 18:40:07 GMT"}], "update_date": "2010-12-08", "authors_parsed": [["Kane", "Daniel M.", ""], ["Nelson", "Jelani", ""]]}, {"id": "1006.3601", "submitter": "Alexandre d'Aspremont", "authors": "Francis Bach, Selin Damla Ahipasaoglu, Alexandre d'Aspremont", "title": "Convex Relaxations for Subset Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use convex relaxation techniques to produce lower bounds on the optimal\nvalue of subset selection problems and generate good approximate solutions. We\nthen explicitly bound the quality of these relaxations by studying the\napproximation ratio of sparse eigenvalue relaxations. Our results are used to\nimprove the performance of branch-and-bound algorithms to produce exact\nsolutions to subset selection problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 03:51:53 GMT"}], "update_date": "2010-06-21", "authors_parsed": [["Bach", "Francis", ""], ["Ahipasaoglu", "Selin Damla", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "1006.3651", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "Quantum algorithms for formula evaluation", "comments": "11 pages, survey for NATO ARW \"Quantum Cryptography and Computing\",\n  Gdansk, September 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the recent sequence of algorithms for evaluating Boolean formulas\nconsisting of NAND gates.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 09:43:01 GMT"}], "update_date": "2010-06-21", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1006.3715", "submitter": "Karim Douieb", "authors": "Prosenjit Bose and Karim Dou\\\"ieb", "title": "Should Static Search Trees Ever Be Unbalanced?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the question of whether or not a static search tree\nshould ever be unbalanced. We present several methods to restructure an\nunbalanced k-ary search tree $T$ into a new tree $R$ that preserves many of the\nproperties of $T$ while having a height of $\\log_k n +1$ which is one unit off\nof the optimal height. More specifically, we show that it is possible to ensure\nthat the depth of the elements in $R$ is no more than their depth in $T$ plus\nat most $\\log_k \\log_k n +2$. At the same time it is possible to guarantee that\nthe average access time $P(R)$ in tree $R$ is no more than the average access\ntime $P(T)$ in tree $T$ plus $O(\\log_k P(T))$. This suggests that for most\napplications, a balanced tree is always a better option than an unbalanced one\nsince the balanced tree has similar average access time and much better worst\ncase access time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 15:08:28 GMT"}], "update_date": "2010-06-21", "authors_parsed": [["Bose", "Prosenjit", ""], ["Dou\u00efeb", "Karim", ""]]}, {"id": "1006.3779", "submitter": "Daniel Cranston", "authors": "Daniel W. Cranston and Gexin Yu", "title": "A New Lower Bound on the Density of Vertex Identifying Codes for the\n  Infinite Hexagonal Grid", "comments": "16 pages, 10 figures", "journal-ref": "Electronic J. of Combinatorics, R113, Volume 16(1), 2009", "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$, an identifying code $C \\subseteq V(G)$ is a vertex set\nsuch that for any two distinct vertices $v_1,v_2\\in V(G)$, the sets $N[v_1]\\cap\nC$ and $N[v_2]\\cap C$ are distinct and nonempty (here $N[v]$ denotes a vertex\n$v$ and its neighbors). We study the case when $G$ is the infinite hexagonal\ngrid $H$. Cohen et.al. constructed two identifying codes for $H$ with density\n$3/7$ and proved that any identifying code for $H$ must have density at least\n$16/39\\approx0.410256$. Both their upper and lower bounds were best known until\nnow. Here we prove a lower bound of $12/29\\approx0.413793$.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 19:26:36 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Cranston", "Daniel W.", ""], ["Yu", "Gexin", ""]]}, {"id": "1006.3913", "submitter": "Chamberlain Fong", "authors": "Chamberlain Fong", "title": "Methods for Accelerating Conway's Doomsday Algorithm (part 1)", "comments": "added references to Lewis Carroll's early work on a perpetual\n  calendar algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification of a key component in the Doomsday Algorithm for\ncalculating the day of the week of any calendar date. In particular, we propose\nto replace the calculation of the required term: \\lfloor \\frac{x}{12} \\rfloor +\nx \\bmod 12 + \\lfloor \\frac{x \\bmod 12}{4} \\rfloor with the term 2y + 10 \\, (y\n\\bmod 2) + z + \\lfloor \\frac{2 \\, (y \\bmod 2) + z}{4} \\rfloor where x is an\ninput 2-digit year; y is the tens digit of x; z is the ones digit of x; We\nargue the fact that our modification operates on individual base-10 digits\nmakes the algorithm easier to calculate mentally.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2010 06:43:53 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2010 01:39:36 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2010 04:59:22 GMT"}, {"version": "v4", "created": "Thu, 15 Jul 2010 05:45:11 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2010 00:18:40 GMT"}, {"version": "v6", "created": "Mon, 20 Sep 2010 00:04:01 GMT"}, {"version": "v7", "created": "Tue, 5 Oct 2010 04:42:20 GMT"}, {"version": "v8", "created": "Thu, 27 Jan 2011 03:12:00 GMT"}], "update_date": "2011-01-28", "authors_parsed": [["Fong", "Chamberlain", ""]]}, {"id": "1006.3968", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Nicolae Tapus", "title": "Practical Range Aggregation, Selection and Set Maintenance Techniques", "comments": null, "journal-ref": "Politehnica University of Bucharest (UPB) Scientific Bulletin,\n  Series C - Electrical Engineering and Computer Science, vol. 72, issue 2, pp.\n  3-16, 2010. (ISSN: 1454-234X)", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present several new and very practical methods and\ntechniques for range aggregation and selection problems in multidimensional\ndata structures and other types of sets of values. We also present some new\nextensions and applications for some fundamental set maintenance problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2010 23:23:07 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1006.3970", "submitter": "Eden Chlamtac", "authors": "Eden Chlamtac, Robert Krauthgamer, Prasad Raghavendra", "title": "Approximating Sparsest Cut in Graphs of Bounded Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first constant-factor approximation algorithm for Sparsest Cut\nwith general demands in bounded treewidth graphs. In contrast to previous\nalgorithms, which rely on the flow-cut gap and/or metric embeddings, our\napproach exploits the Sherali-Adams hierarchy of linear programming\nrelaxations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 00:15:00 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2010 14:27:08 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Chlamtac", "Eden", ""], ["Krauthgamer", "Robert", ""], ["Raghavendra", "Prasad", ""]]}, {"id": "1006.3993", "submitter": "Cyril Prissette", "authors": "Cyril Prissette (LSEET)", "title": "An Algorithm to List All the Fixed-Point Free Involutions on a Finite\n  Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An involution on a finite set is a bijection such as I(I(e))=e for all the\nelement of the set. A fixed-point free involution on a finite set is an\ninvolution such as I(e)=e for none element of the set. In this article, the\nfixed-point free involutions are represented as partitions of the set and some\nproperties linked to this representation are exhibited. Then an optimal\nalgorithm to list all the fixed-point free involutions is presented. Its\nsoundness relies on the representation of the fixed-point free involutions as\npartitions. Finally, an implementation of the algorithm is proposed, with an\neffective data representation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 06:38:46 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Prissette", "Cyril", "", "LSEET"]]}, {"id": "1006.4014", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "New Developments in Quantum Algorithms", "comments": "11 pages, 1 figure, to appear as an invited survey talk at MFCS'2010", "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_1", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we describe two recent developments in quantum algorithms.\n  The first new development is a quantum algorithm for evaluating a Boolean\nformula consisting of AND and OR gates of size N in time O(\\sqrt{N}). This\nprovides quantum speedups for any problem that can be expressed via Boolean\nformulas. This result can be also extended to span problems, a generalization\nof Boolean formulas. This provides an optimal quantum algorithm for any Boolean\nfunction in the black-box query model.\n  The second new development is a quantum algorithm for solving systems of\nlinear equations. In contrast with traditional algorithms that run in time\nO(N^{2.37...}) where N is the size of the system, the quantum algorithm runs in\ntime O(\\log^c N). It outputs a quantum state describing the solution of the\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 08:57:04 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1006.4093", "submitter": "Yakov Nekrich", "authors": "Yakov Nekrich", "title": "Dynamic Range Reporting in External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a dynamic external memory data structure that\nsupports range reporting queries in three dimensions in $O(\\log_B^2 N +\n\\frac{k}{B})$ I/O operations, where $k$ is the number of points in the answer\nand $B$ is the block size. This is the first dynamic data structure that\nanswers three-dimensional range reporting queries in $\\log_B^{O(1)} N +\nO(\\frac{k}{B})$ I/Os.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 15:26:40 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Nekrich", "Yakov", ""]]}, {"id": "1006.4136", "submitter": "Martin Milani\\v{c}", "authors": "Ferdinando Cicalese, Travis Gagie, Eduardo Laber, Martin Milanic", "title": "Competitive Boolean Function Evaluation: Beyond Monotonicity, and the\n  Symmetric Case", "comments": "15 pages, 1 figure, to appear in Discrete Applied Mathematics", "journal-ref": "Discrete Applied Mathematics 159 (2011) 1070--1078", "doi": "10.1016/j.dam.2010.05.016", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the extremal competitive ratio of Boolean function evaluation. We\nprovide the first non-trivial lower and upper bounds for classes of Boolean\nfunctions which are not included in the class of monotone Boolean functions.\nFor the particular case of symmetric functions our bounds are matching and we\nexactly characterize the best possible competitiveness achievable by a\ndeterministic algorithm. Our upper bound is obtained by a simple polynomial\ntime algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 19:07:52 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Cicalese", "Ferdinando", ""], ["Gagie", "Travis", ""], ["Laber", "Eduardo", ""], ["Milanic", "Martin", ""]]}, {"id": "1006.4147", "submitter": "Kamran Karimi", "authors": "Kamran Karimi, Neil G. Dickson, Firas Hamze, M.H.S. Amin, Marshall\n  Drew-Brook, Fabian A. Chudak, Paul I. Bunyk, William G. Macready, Geordie\n  Rose", "title": "Investigating the Performance of an Adiabatic Quantum Optimization\n  Processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adiabatic quantum optimization offers a new method for solving hard\noptimization problems. In this paper we calculate median adiabatic times (in\nseconds) determined by the minimum gap during the adiabatic quantum\noptimization for an NP-hard Ising spin glass instance class with up to 128\nbinary variables. Using parameters obtained from a realistic superconducting\nadiabatic quantum processor, we extract the minimum gap and matrix elements\nusing high performance Quantum Monte Carlo simulations on a large-scale\nInternet-based computing platform. We compare the median adiabatic times with\nthe median running times of two classical solvers and find that, for the\nconsidered problem sizes, the adiabatic times for the simulated processor\narchitecture are about 4 and 6 orders of magnitude shorter than the two\nclassical solvers' times. This shows that if the adiabatic time scale were to\ndetermine the computation time, adiabatic quantum optimization would be\nsignificantly superior to those classical solvers for median spin glass\nproblems of at least up to 128 qubits. We also discuss important additional\nconstraints that affect the performance of a realistic system.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 19:46:03 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2010 19:11:08 GMT"}, {"version": "v3", "created": "Mon, 27 Sep 2010 23:20:48 GMT"}, {"version": "v4", "created": "Thu, 27 Jan 2011 21:41:58 GMT"}], "update_date": "2011-01-31", "authors_parsed": [["Karimi", "Kamran", ""], ["Dickson", "Neil G.", ""], ["Hamze", "Firas", ""], ["Amin", "M. H. S.", ""], ["Drew-Brook", "Marshall", ""], ["Chudak", "Fabian A.", ""], ["Bunyk", "Paul I.", ""], ["Macready", "William G.", ""], ["Rose", "Geordie", ""]]}, {"id": "1006.4173", "submitter": "Rasmus Pagh", "authors": "Rasmus Resen Amossen and Andrea Campagna and Rasmus Pagh", "title": "Better size estimation for sparse matrix products", "comments": "Corrected a number of mistakes and typos in the first version (also\n  present in the version published at RANDOM 2010). Most importantly, the lower\n  bound on the error epsilon is now a function of z rather than n", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of doing fast and reliable estimation of the number\nof non-zero entries in a sparse boolean matrix product. This problem has\napplications in databases and computer algebra. Let n denote the total number\nof non-zero entries in the input matrices. We show how to compute a 1 +-\nepsilon approximation (with small probability of error) in expected time O(n)\nfor any epsilon > 4/\\sqrt[4]{z}. The previously best estimation algorithm, due\nto Cohen (JCSS 1997), uses time O(n/epsilon^2). We also present a variant using\nO(sort(n)) I/Os in expectation in the cache-oblivious model. In contrast to\nthese results, the currently best algorithms for computing a sparse boolean\nmatrix product use time omega(n^{4/3}) (resp. omega(n^{4/3}/B) I/Os), even if\nthe result matrix has only z=O(n) nonzero entries. Our algorithm combines the\nsize estimation technique of Bar-Yossef et al. (RANDOM 2002) with a particular\nclass of pairwise independent hash functions that allows the sketch of a set of\nthe form A x C to be computed in expected time O(|A|+|C|) and O(sort(|A|+|C|))\nI/Os. We then describe how sampling can be used to maintain (independent)\nsketches of matrices that allow estimation to be performed in time o(n) if z is\nsufficiently large. This gives a simpler alternative to the sketching technique\nof Ganguly et al. (PODS 2005), and matches a space lower bound shown in that\npaper. Finally, we present experiments on real-world data sets that show the\naccuracy of both our methods to be significantly better than the worst-case\nanalysis predicts.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 20:47:46 GMT"}, {"version": "v2", "created": "Tue, 22 Feb 2011 19:26:15 GMT"}], "update_date": "2011-02-23", "authors_parsed": [["Amossen", "Rasmus Resen", ""], ["Campagna", "Andrea", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1006.4339", "submitter": "MohammadHossein Bateni", "authors": "MohammadHossein Bateni and MohammadTaghi Hajiaghayi and D\\'aniel Marx", "title": "Prize-collecting Network Design on Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reduce Prize-Collecting Steiner TSP (PCTSP),\nPrize-Collecting Stroll (PCS), Prize-Collecting Steiner Tree (PCST),\nPrize-Collecting Steiner Forest (PCSF) and more generally Submodular\nPrize-Collecting Steiner Forest (SPCSF) on planar graphs (and more generally\nbounded-genus graphs) to the same problems on graphs of bounded treewidth. More\nprecisely, we show any $\\alpha$-approximation algorithm for these problems on\ngraphs of bounded treewidth gives an $(\\alpha + \\epsilon)$-approximation\nalgorithm for these problems on planar graphs (and more generally bounded-genus\ngraphs), for any constant $\\epsilon > 0$. Since PCS, PCTSP, and PCST can be\nsolved exactly on graphs of bounded treewidth using dynamic programming, we\nobtain PTASs for these problems on planar graphs and bounded-genus graphs. In\ncontrast, we show PCSF is APX-hard to approximate on series-parallel graphs,\nwhich are planar graphs of treewidth at most 2. This result is interesting on\nits own because it gives the first provable hardness separation between\nprize-collecting and non-prize-collecting (regular) versions of the problems:\nregular Steiner Forest is known to be polynomially solvable on series-parallel\ngraphs and admits a PTAS on graphs of bounded treewidth. An analogous hardness\nresult can be shown for Euclidian PCSF. This ends the common belief that\nprize-collecting variants should not add any new hardness to the problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 17:45:07 GMT"}], "update_date": "2010-06-23", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1006.4349", "submitter": "Ali Civril", "authors": "Ali Civril and Malik Magdon-Ismail", "title": "Exponential Inapproximability of Selecting a Maximum Volume Sub-matrix", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a matrix $A \\in \\mathbb{R}^{m \\times n}$ ($n$ vectors in $m$\ndimensions), and a positive integer $k < n$, we consider the problem of\nselecting $k$ column vectors from $A$ such that the volume of the\nparallelepiped they define is maximum over all possible choices. We prove that\nthere exists $\\delta<1$ and $c>0$ such that this problem is not approximable\nwithin $2^{-ck}$ for $k = \\delta n$, unless $P=NP$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 19:09:02 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 13:03:54 GMT"}, {"version": "v3", "created": "Tue, 23 Aug 2011 18:26:11 GMT"}, {"version": "v4", "created": "Wed, 12 Oct 2011 11:26:22 GMT"}], "update_date": "2011-10-13", "authors_parsed": [["Civril", "Ali", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1006.4357", "submitter": "Nitish Korula", "authors": "Chandra Chekuri and Alina Ene and Nitish Korula", "title": "Prize-Collecting Steiner Tree and Forest in Planar Graphs", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain polynomial-time approximation-preserving reductions (up to a factor\nof 1 + \\epsilon) from the prize-collecting Steiner tree and prize-collecting\nSteiner forest problems in planar graphs to the corresponding problems in\ngraphs of bounded treewidth. We also give an exact algorithm for the\nprize-collecting Steiner tree problem that runs in polynomial time for graphs\nof bounded treewidth. This, combined with our reductions, yields a PTAS for the\nprize-collecting Steiner tree problem in planar graphs and generalizes the PTAS\nof Borradaile, Klein and Mathieu for the Steiner tree problem in planar graphs.\nOur results build upon the ideas of Borradaile, Klein and Mathieu and the work\nof Bateni, Hajiaghayi and Marx on a PTAS for the Steiner forest problem in\nplanar graphs. Our main technical result is on the properties of primal-dual\nalgorithms for Steiner tree and forest problems in general graphs when they are\nrun with scaled up penalties.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 19:53:58 GMT"}], "update_date": "2010-06-23", "authors_parsed": [["Chekuri", "Chandra", ""], ["Ene", "Alina", ""], ["Korula", "Nitish", ""]]}, {"id": "1006.4396", "submitter": "Warren Schudy", "authors": "Marek Karpinski and Warren Schudy", "title": "Faster Algorithms for Feedback Arc Set Tournament, Kemeny Rank\n  Aggregation and Betweenness Tournament", "comments": "14 pages. Version 1 of arXiv:0911.2214 includes a preliminary version\n  of this work; version 2 does not", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fixed parameter algorithms for three problems: Kemeny rank\naggregation, feedback arc set tournament, and betweenness tournament. For\nKemeny rank aggregation we give an algorithm with runtime O*(2^O(sqrt{OPT})),\nwhere n is the number of candidates, OPT is the cost of the optimal ranking,\nand O* hides polynomial factors. This is a dramatic improvement on the\npreviously best known runtime of O*(2^O(OPT)). For feedback arc set tournament\nwe give an algorithm with runtime O*(2^O(sqrt{OPT})), an improvement on the\npreviously best known O*(OPT^O(sqrt{OPT})) (Alon, Lokshtanov and Saurabh 2009).\nFor betweenness tournament we give an algorithm with runtime\nO*(2^O(sqrt{OPT/n})), where n is the number of vertices and OPT is the optimal\ncost. This improves on the previously known O*(OPT^O(OPT^{1/3}))$ (Saurabh\n2009), especially when OPT is small. Unusually we can solve instances with OPT\nas large as n (log n)^2 in polynomial time!\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 00:06:59 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Karpinski", "Marek", ""], ["Schudy", "Warren", ""]]}, {"id": "1006.4536", "submitter": "Shi Li", "authors": "Moses Charikar, Tom Leighton, Shi Li, Ankur Moitra", "title": "Vertex Sparsifiers and Abstract Rounding Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of vertex sparsification is introduced in \\cite{M}, where it was\nshown that for any graph $G = (V, E)$ and a subset of $k$ terminals $K \\subset\nV$, there is a polynomial time algorithm to construct a graph $H = (K, E_H)$ on\njust the terminal set so that simultaneously for all cuts $(A, K-A)$, the value\nof the minimum cut in $G$ separating $A$ from $K -A$ is approximately the same\nas the value of the corresponding cut in $H$.\n  We give the first super-constant lower bounds for how well a cut-sparsifier\n$H$ can simultaneously approximate all minimum cuts in $G$. We prove a lower\nbound of $\\Omega(\\log^{1/4} k)$ -- this is polynomially-related to the known\nupper bound of $O(\\log k/\\log \\log k)$. This is an exponential improvement on\nthe $\\Omega(\\log \\log k)$ bound given in \\cite{LM} which in fact was for a\nstronger vertex sparsification guarantee, and did not apply to cut sparsifiers.\n  Despite this negative result, we show that for many natural problems, we do\nnot need to incur a multiplicative penalty for our reduction. We obtain optimal\n$O(\\log k)$-competitive Steiner oblivious routing schemes, which generalize the\nresults in \\cite{R}. We also demonstrate that for a wide range of graph packing\nproblems (which includes maximum concurrent flow, maximum multiflow and\nmulticast routing, among others, as a special case), the integrality gap of the\nlinear program is always at most $O(\\log k)$ times the integrality gap\nrestricted to trees. This result helps to explain the ubiquity of the $O(\\log\nk)$ guarantees for such problems.\n  Lastly, we use our ideas to give an efficient construction for\nvertex-sparsifiers that match the current best existential results -- this was\npreviously open. Our algorithm makes novel use of Earth-mover constraints.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 14:44:07 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Charikar", "Moses", ""], ["Leighton", "Tom", ""], ["Li", "Shi", ""], ["Moitra", "Ankur", ""]]}, {"id": "1006.4586", "submitter": "Anupam Gupta", "authors": "Matthias Englert, Anupam Gupta, Robert Krauthgamer, Harald Raecke,\n  Inbal Talgam, Kunal Talwar", "title": "Vertex Sparsifiers: New Results from Old Techniques", "comments": "An extended abstract appears in the 13th International Workshop on\n  Approximation Algorithms for Combinatorial Optimization Problems (APPROX),\n  2010. Final version to appear in SIAM J. Computing", "journal-ref": null, "doi": "10.1137/130908440", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a capacitated graph $G = (V,E)$ and a set of terminals $K \\subseteq V$,\nhow should we produce a graph $H$ only on the terminals $K$ so that every\n(multicommodity) flow between the terminals in $G$ could be supported in $H$\nwith low congestion, and vice versa? (Such a graph $H$ is called a\nflow-sparsifier for $G$.) What if we want $H$ to be a \"simple\" graph? What if\nwe allow $H$ to be a convex combination of simple graphs?\n  Improving on results of Moitra [FOCS 2009] and Leighton and Moitra [STOC\n2010], we give efficient algorithms for constructing: (a) a flow-sparsifier $H$\nthat maintains congestion up to a factor of $O(\\log k/\\log \\log k)$, where $k =\n|K|$, (b) a convex combination of trees over the terminals $K$ that maintains\ncongestion up to a factor of $O(\\log k)$, and (c) for a planar graph $G$, a\nconvex combination of planar graphs that maintains congestion up to a constant\nfactor. This requires us to give a new algorithm for the 0-extension problem,\nthe first one in which the preimages of each terminal are connected in $G$.\nMoreover, this result extends to minor-closed families of graphs.\n  Our improved bounds immediately imply improved approximation guarantees for\nseveral terminal-based cut and ordering problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 16:43:47 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2010 18:32:56 GMT"}, {"version": "v3", "created": "Wed, 23 Apr 2014 00:59:39 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Englert", "Matthias", ""], ["Gupta", "Anupam", ""], ["Krauthgamer", "Robert", ""], ["Raecke", "Harald", ""], ["Talgam", "Inbal", ""], ["Talwar", "Kunal", ""]]}, {"id": "1006.4607", "submitter": "Yury Makarychev", "authors": "Konstantin Makarychev and Yury Makarychev", "title": "Metric Extension Operators, Vertex Sparsifiers and Lipschitz\n  Extendability", "comments": "Appeared at FOCS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study vertex cut and flow sparsifiers that were recently introduced by\nMoitra, and Leighton and Moitra. We improve and generalize their results. We\ngive a new polynomial-time algorithm for constructing O(log k / log log k) cut\nand flow sparsifiers, matching the best existential upper bound on the quality\nof a sparsifier, and improving the previous algorithmic upper bound of O(log^2\nk / log log k). We show that flow sparsifiers can be obtained from linear\noperators approximating minimum metric extensions. We introduce the notion of\n(linear) metric extension operators, prove that they exist, and give an exact\npolynomial-time algorithm for finding optimal operators.\n  We then establish a direct connection between flow and cut sparsifiers and\nLipschitz extendability of maps in Banach spaces, a notion studied in\nfunctional analysis since 1930s. Using this connection, we prove a lower bound\nof Omega(sqrt{log k/log log k}) for flow sparsifiers and a lower bound of\nOmega(sqrt{log k}/log log k) for cut sparsifiers. We show that if a certain\nopen question posed by Ball in 1992 has a positive answer, then there exist\n\\tilde O(sqrt{log k}) cut sparsifiers. On the other hand, any lower bound on\ncut sparsifiers better than \\tilde Omega(sqrt{log k}) would imply a negative\nanswer to this question.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 18:43:33 GMT"}, {"version": "v2", "created": "Thu, 9 Dec 2010 01:42:35 GMT"}], "update_date": "2010-12-10", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""]]}, {"id": "1006.4608", "submitter": "Mukkai Krishnamoorthy", "authors": "Anurat Chapanond, Mukkai S. Krishnamoorthy, G. M. Prabhu and J. Punin", "title": "Evolving Graph Representation and Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The study of evolution of networks has received increased interest with the\nrecent discovery that many real-world networks possess many things in common,\nin particular the manner of evolution of such networks. By adding a dimension\nof time to graph analysis, evolving graphs present opportunities and challenges\nto extract valuable information. This paper introduces the Evolving Graph\nMarkup Language (EGML), an XML application for representing evolving graphs and\nrelated results. Along with EGML, a software tool is provided for the study of\nevolving graphs. New evolving graph drawing techniques based on the\nforce-directed graph layout algorithm are also explored. Our evolving graph\ntechniques reduce vertex movements between graph instances, so that an evolving\ngraph can be viewed with smooth transitions\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 18:43:46 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Chapanond", "Anurat", ""], ["Krishnamoorthy", "Mukkai S.", ""], ["Prabhu", "G. M.", ""], ["Punin", "J.", ""]]}, {"id": "1006.4661", "submitter": "Robert Hildebrand", "authors": "Robert Hildebrand and Matthias K\\\"oppe", "title": "A new Lenstra-type Algorithm for Quasiconvex Polynomial Integer\n  Minimization with Complexity 2^O(n log n)", "comments": "28 pages, 10 figures", "journal-ref": "Discrete Optimization 10 (2013), no. 1, 69-84", "doi": "10.1016/j.disopt.2012.11.003", "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the integer minimization of a quasiconvex polynomial with\nquasiconvex polynomial constraints. We propose a new algorithm that is an\nimprovement upon the best known algorithm due to Heinz (Journal of Complexity,\n2005). This improvement is achieved by applying a new modern Lenstra-type\nalgorithm, finding optimal ellipsoid roundings, and considering sparse\nencodings of polynomials. For the bounded case, our algorithm attains a\ntime-complexity of s (r l M d)^{O(1)} 2^{2n log_2(n) + O(n)} when M is a bound\non the number of monomials in each polynomial and r is the binary encoding\nlength of a bound on the feasible region. In the general case, s l^{O(1)}\nd^{O(n)} 2^{2n log_2(n) +O(n)}. In each we assume d>= 2 is a bound on the total\ndegree of the polynomials and l bounds the maximum binary encoding size of the\ninput.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 22:56:22 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2011 19:37:52 GMT"}, {"version": "v3", "created": "Thu, 19 Jan 2012 08:59:52 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Hildebrand", "Robert", ""], ["K\u00f6ppe", "Matthias", ""]]}, {"id": "1006.4828", "submitter": "Vamsi Kundeti", "authors": "Vamsi Kundeti and Sanguthevar Rajasekaran and Hieu Dinh", "title": "An Efficient Algorithm For Chinese Postman Walk on Bi-directed de Bruijn\n  Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-17458-2_16", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence assembly from short reads is an important problem in biology. It is\nknown that solving the sequence assembly problem exactly on a bi-directed de\nBruijn graph or a string graph is intractable. However finding a Shortest\nDouble stranded DNA string (SDDNA) containing all the k-long words in the reads\nseems to be a good heuristic to get close to the original genome. This problem\nis equivalent to finding a cyclic Chinese Postman (CP) walk on the underlying\nun-weighted bi-directed de Bruijn graph built from the reads. The Chinese\nPostman walk Problem (CPP) is solved by reducing it to a general bi-directed\nflow on this graph which runs in O(|E|2 log2(|V |)) time. In this paper we show\nthat the cyclic CPP on bi-directed graphs can be solved without reducing it to\nbi-directed flow. We present a ?(p(|V | + |E|) log(|V |) + (dmaxp)3) time\nalgorithm to solve the cyclic CPP on a weighted bi-directed de Bruijn graph,\nwhere p = max{|{v|din(v) - dout(v) > 0}|, |{v|din(v) - dout(v) < 0}|} and dmax\n= max{|din(v) - dout(v)}. Our algorithm performs asymptotically better than the\nbidirected flow algorithm when the number of imbalanced nodes p is much less\nthan the nodes in the bi-directed graph. From our experimental results on\nvarious datasets, we have noticed that the value of p/|V | lies between 0.08%\nand 0.13% with 95% probability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2010 16:35:47 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kundeti", "Vamsi", ""], ["Rajasekaran", "Sanguthevar", ""], ["Dinh", "Hieu", ""]]}, {"id": "1006.5038", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Nicolae Tapus", "title": "Algorithmic Solutions for Several Offline Constrained Resource\n  Processing and Data Transfer Multicriteria Optimization Problems", "comments": null, "journal-ref": "Scalable Computing: Practice and Experience, vol. 11, no. 1, pp.\n  1-17, 2010. (ISSN: 1895-1767)", "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present novel algorithmic solutions for several resource\nprocessing and data transfer multicriteria optimization problems. The results\nof most of the presented techniques are strategies which solve the considered\nproblems (almost) optimally. Thus, the developed algorithms construct\nintelligent strategies which can be implemented by agents in specific\nsituations. All the described solutions make use of the properties of the\nconsidered problems and, thus, they are not applicable to a very general class\nof problems. However, by considering the specific details of each problem, we\nwere able to obtain very efficient results.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2010 18:44:59 GMT"}], "update_date": "2010-06-28", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1006.5235", "submitter": "Matteo Riondato", "authors": "Andrea Pietracaprina, Matteo Riondato, Eli Upfal, Fabio Vandin", "title": "Mining Top-K Frequent Itemsets Through Progressive Sampling", "comments": "16 pages, 2 figures, accepted for presentation at ECML PKDD 2010 and\n  publication in the ECML PKDD 2010 special issue of the Data Mining and\n  Knowledge Discovery journal", "journal-ref": null, "doi": "10.1007/s10618-010-0185-7", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of sampling for efficiently mining the top-K frequent\nitemsets of cardinality at most w. To this purpose, we define an approximation\nto the top-K frequent itemsets to be a family of itemsets which includes\n(resp., excludes) all very frequent (resp., very infrequent) itemsets, together\nwith an estimate of these itemsets' frequencies with a bounded error. Our first\nresult is an upper bound on the sample size which guarantees that the top-K\nfrequent itemsets mined from a random sample of that size approximate the\nactual top-K frequent itemsets, with probability larger than a specified value.\nWe show that the upper bound is asymptotically tight when w is constant. Our\nmain algorithmic contribution is a progressive sampling approach, combined with\nsuitable stopping conditions, which on appropriate inputs is able to extract\napproximate top-K frequent itemsets from samples whose sizes are smaller than\nthe general upper bound. In order to test the stopping conditions, this\napproach maintains the frequency of all itemsets encountered, which is\npractical only for small w. However, we show how this problem can be mitigated\nby using a variation of Bloom filters. A number of experiments conducted on\nboth synthetic and real bench- mark datasets show that using samples\nsubstantially smaller than the original dataset (i.e., of size defined by the\nupper bound or reached through the progressive sampling approach) enable to\napproximate the actual top-K frequent itemsets with accuracy much higher than\nwhat analytically proved.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2010 20:38:39 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Pietracaprina", "Andrea", ""], ["Riondato", "Matteo", ""], ["Upfal", "Eli", ""], ["Vandin", "Fabio", ""]]}, {"id": "1006.5354", "submitter": "Alessio Orlandi", "authors": "Roberto Grossi and Alessio Orlandi and Rajeev Raman", "title": "Optimal Trade-Off for Succinct String Indexes", "comments": "Accepted at ICALP 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let s be a string whose symbols are solely available through access(i), a\nread-only operation that probes s and returns the symbol at position i in s.\nMany compressed data structures for strings, trees, and graphs, require two\nkinds of queries on s: select(c, j), returning the position in s containing the\njth occurrence of c, and rank(c, p), counting how many occurrences of c are\nfound in the first p positions of s. We give matching upper and lower bounds\nfor this problem, improving the lower bounds given by Golynski [Theor. Comput.\nSci. 387 (2007)] [PhD thesis] and the upper bounds of Barbay et al. [SODA\n2007]. We also present new results in another model, improving on Barbay et al.\n[SODA 2007] and matching a lower bound of Golynski [SODA 2009]. The main\ncontribution of this paper is to introduce a general technique for proving\nlower bounds on succinct data structures, that is based on the access patterns\nof the supported operations, abstracting from the particular operations at\nhand. For this, it may find application to other interesting problems on\nsuccinct data structures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2010 14:05:05 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Grossi", "Roberto", ""], ["Orlandi", "Alessio", ""], ["Raman", "Rajeev", ""]]}, {"id": "1006.5440", "submitter": "Darren Strash", "authors": "David Eppstein, Maarten L\\\"offler, Darren Strash", "title": "Listing All Maximal Cliques in Sparse Graphs in Near-optimal Time", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degeneracy of an $n$-vertex graph $G$ is the smallest number $d$ such\nthat every subgraph of $G$ contains a vertex of degree at most $d$. We show\nthat there exists a nearly-optimal fixed-parameter tractable algorithm for\nenumerating all maximal cliques, parametrized by degeneracy. To achieve this\nresult, we modify the classic Bron--Kerbosch algorithm and show that it runs in\ntime $O(dn3^{d/3})$. We also provide matching upper and lower bounds showing\nthat the largest possible number of maximal cliques in an $n$-vertex graph with\ndegeneracy $d$ (when $d$ is a multiple of 3 and $n\\ge d+3$) is $(n-d)3^{d/3}$.\nTherefore, our algorithm matches the $\\Theta(d(n-d)3^{d/3})$ worst-case output\nsize of the problem whenever $n-d=\\Omega(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2010 19:29:00 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Eppstein", "David", ""], ["L\u00f6ffler", "Maarten", ""], ["Strash", "Darren", ""]]}]