[{"id": "1206.0150", "submitter": "Bernhard Haeupler", "authors": "Yehuda Afek and Noga Alon and Ziv Bar-Joseph and Alejandro Cornejo and\n  Bernhard Haeupler and Fabian Kuhn", "title": "Beeping a Maximal Independent Set", "comments": "arXiv admin note: substantial text overlap with arXiv:1108.1926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing a maximal independent set (MIS) in an\nextremely harsh broadcast model that relies only on carrier sensing. The model\nconsists of an anonymous broadcast network in which nodes have no knowledge\nabout the topology of the network or even an upper bound on its size.\nFurthermore, it is assumed that an adversary chooses at which time slot each\nnode wakes up. At each time slot a node can either beep, that is, emit a\nsignal, or be silent. At a particular time slot, beeping nodes receive no\nfeedback, while silent nodes can only differentiate between none of its\nneighbors beeping, or at least one of its neighbors beeping.\n  We start by proving a lower bound that shows that in this model, it is not\npossible to locally converge to an MIS in sub-polynomial time. We then study\nfour different relaxations of the model which allow us to circumvent the lower\nbound and find an MIS in polylogarithmic time. First, we show that if a\npolynomial upper bound on the network size is known, it is possible to find an\nMIS in O(log^3 n) time. Second, if we assume sleeping nodes are awoken by\nneighboring beeps, then we can also find an MIS in O(log^3 n) time. Third, if\nin addition to this wakeup assumption we allow sender-side collision detection,\nthat is, beeping nodes can distinguish whether at least one neighboring node is\nbeeping concurrently or not, we can find an MIS in O(log^2 n) time. Finally, if\ninstead we endow nodes with synchronous clocks, it is also possible to find an\nMIS in O(log^2 n) time.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 11:23:30 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Afek", "Yehuda", ""], ["Alon", "Noga", ""], ["Bar-Joseph", "Ziv", ""], ["Cornejo", "Alejandro", ""], ["Haeupler", "Bernhard", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1206.0154", "submitter": "Mohsen Ghaffari", "authors": "Mohsen Ghaffari and Bernhard Haeupler and Nancy Lynch and Calvin\n  Newport", "title": "Bounds on Contention Management in Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local broadcast problem assumes that processes in a wireless network are\nprovided messages, one by one, that must be delivered to their neighbors. In\nthis paper, we prove tight bounds for this problem in two well-studied wireless\nnetwork models: the classical model, in which links are reliable and collisions\nconsistent, and the more recent dual graph model, which introduces unreliable\nedges. Our results prove that the Decay strategy, commonly used for local\nbroadcast in the classical setting, is optimal. They also establish a\nseparation between the two models, proving that the dual graph setting is\nstrictly harder than the classical setting, with respect to this primitive.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 11:38:47 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 16:15:43 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""], ["Lynch", "Nancy", ""], ["Newport", "Calvin", ""]]}, {"id": "1206.0411", "submitter": "Henrik B\\\"a\\\"arnhielm", "authors": "Henrik B\\\"a\\\"arnhielm", "title": "Recognising the small Ree groups in their natural representations", "comments": null, "journal-ref": "J. Algebra 416, 139-166, 2014", "doi": "10.1016/j.jalgebra.2014.06.017", "report-no": null, "categories": "math.GR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Las Vegas algorithms for constructive recognition and constructive\nmembership testing of the Ree groups 2G_2(q) = Ree(q), where q = 3^{2m + 1} for\nsome m > 0, in their natural representations of degree 7. The input is a\ngenerating set X.\n  The constructive recognition algorithm is polynomial time given a discrete\nlogarithm oracle. The constructive membership testing consists of a\npre-processing step, that only needs to be executed once for a given X, and a\nmain step. The latter is polynomial time, and the former is polynomial time\ngiven a discrete logarithm oracle.\n  Implementations of the algorithms are available for the computer algebra\nsystem MAGMA.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2012 00:07:49 GMT"}, {"version": "v2", "created": "Sun, 8 Jun 2014 14:27:39 GMT"}, {"version": "v3", "created": "Thu, 28 Aug 2014 12:39:08 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["B\u00e4\u00e4rnhielm", "Henrik", ""]]}, {"id": "1206.0580", "submitter": "Sergey Podolsky", "authors": "Sergey Podolsky, Yuri Zorin", "title": "O(1) Delta Component Computation Technique for the Quadratic Assignment\n  Problem", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes a novel technique that allows to reduce by half the\nnumber of delta values that were required to be computed with complexity O(N)\nin most of the heuristics for the quadratic assignment problem. Using the\ncorrelation between the old and new delta values, obtained in this work, a new\nformula of complexity O(1) is proposed. Found result leads up to 25%\nperformance increase in such well-known algorithms as Robust Tabu Search and\nothers based on it.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 11:06:27 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Podolsky", "Sergey", ""], ["Zorin", "Yuri", ""]]}, {"id": "1206.0594", "submitter": "Edo Liberty", "authors": "Edo Liberty", "title": "Simple and Deterministic Matrix Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt a well known streaming algorithm for approximating item frequencies\nto the matrix sketching setting. The algorithm receives the rows of a large\nmatrix $A \\in \\R^{n \\times m}$ one after the other in a streaming fashion. It\nmaintains a sketch matrix $B \\in \\R^ {1/\\eps \\times m}$ such that for any unit\nvector $x$ [\\|Ax\\|^2 \\ge \\|Bx\\|^2 \\ge \\|Ax\\|^2 - \\eps \\|A\\|_{f}^2 \\.] Sketch\nupdates per row in $A$ require $O(m/\\eps^2)$ operations in the worst case. A\nslight modification of the algorithm allows for an amortized update time of\n$O(m/\\eps)$ operations per row. The presented algorithm stands out in that it\nis: deterministic, simple to implement, and elementary to prove. It also\nexperimentally produces more accurate sketches than widely used approaches\nwhile still being computationally competitive.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 12:16:07 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 14:36:22 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2012 14:36:41 GMT"}, {"version": "v4", "created": "Thu, 7 Jun 2012 08:04:09 GMT"}, {"version": "v5", "created": "Tue, 10 Jul 2012 06:35:08 GMT"}, {"version": "v6", "created": "Wed, 11 Jul 2012 07:49:18 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Liberty", "Edo", ""]]}, {"id": "1206.0629", "submitter": "Michele Coscia", "authors": "Michele Coscia, Giulio Rossetti, Fosca Giannotti, Dino Pedreschi", "title": "DEMON: a Local-First Discovery Method for Overlapping Communities", "comments": "9 pages; Proceedings of the 18th ACM SIGKDD International Conference\n  on Knowledge Discovery and Data Mining, Beijing, China, August 12-16, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community discovery in complex networks is an interesting problem with a\nnumber of applications, especially in the knowledge extraction task in social\nand information networks. However, many large networks often lack a particular\ncommunity organization at a global level. In these cases, traditional graph\npartitioning algorithms fail to let the latent knowledge embedded in modular\nstructure emerge, because they impose a top-down global view of a network. We\npropose here a simple local-first approach to community discovery, able to\nunveil the modular organization of real complex networks. This is achieved by\ndemocratically letting each node vote for the communities it sees surrounding\nit in its limited view of the global system, i.e. its ego neighborhood, using a\nlabel propagation algorithm; finally, the local communities are merged into a\nglobal collection. We tested this intuition against the state-of-the-art\noverlapping and non-overlapping community discovery methods, and found that our\nnew method clearly outperforms the others in the quality of the obtained\ncommunities, evaluated by using the extracted communities to predict the\nmetadata about the nodes of several real world networks. We also show how our\nmethod is deterministic, fully incremental, and has a limited time complexity,\nso that it can be used on web-scale real networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 14:22:10 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Coscia", "Michele", ""], ["Rossetti", "Giulio", ""], ["Giannotti", "Fosca", ""], ["Pedreschi", "Dino", ""]]}, {"id": "1206.0985", "submitter": "Ilias Diakonikolas", "authors": "Anindya De, Ilias Diakonikolas, Vitaly Feldman, Rocco A. Servedio", "title": "Nearly optimal solutions for the Chow Parameters Problem and low-weight\n  approximation of halfspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{Chow parameters} of a Boolean function $f: \\{-1,1\\}^n \\to \\{-1,1\\}$\nare its $n+1$ degree-0 and degree-1 Fourier coefficients. It has been known\nsince 1961 (Chow, Tannenbaum) that the (exact values of the) Chow parameters of\nany linear threshold function $f$ uniquely specify $f$ within the space of all\nBoolean functions, but until recently (O'Donnell and Servedio) nothing was\nknown about efficient algorithms for \\emph{reconstructing} $f$ (exactly or\napproximately) from exact or approximate values of its Chow parameters. We\nrefer to this reconstruction problem as the \\emph{Chow Parameters Problem.}\n  Our main result is a new algorithm for the Chow Parameters Problem which,\ngiven (sufficiently accurate approximations to) the Chow parameters of any\nlinear threshold function $f$, runs in time $\\tilde{O}(n^2)\\cdot\n(1/\\eps)^{O(\\log^2(1/\\eps))}$ and with high probability outputs a\nrepresentation of an LTF $f'$ that is $\\eps$-close to $f$. The only previous\nalgorithm (O'Donnell and Servedio) had running time $\\poly(n) \\cdot\n2^{2^{\\tilde{O}(1/\\eps^2)}}.$\n  As a byproduct of our approach, we show that for any linear threshold\nfunction $f$ over $\\{-1,1\\}^n$, there is a linear threshold function $f'$ which\nis $\\eps$-close to $f$ and has all weights that are integers at most $\\sqrt{n}\n\\cdot (1/\\eps)^{O(\\log^2(1/\\eps))}$. This significantly improves the best\nprevious result of Diakonikolas and Servedio which gave a $\\poly(n) \\cdot\n2^{\\tilde{O}(1/\\eps^{2/3})}$ weight bound, and is close to the known lower\nbound of $\\max\\{\\sqrt{n},$ $(1/\\eps)^{\\Omega(\\log \\log (1/\\eps))}\\}$ (Goldberg,\nServedio). Our techniques also yield improved algorithms for related problems\nin learning theory.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 16:39:29 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["De", "Anindya", ""], ["Diakonikolas", "Ilias", ""], ["Feldman", "Vitaly", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1206.1113", "submitter": "Guanhong Pei", "authors": "Maleq Khan, V.S. Anil Kumar, Gopal Pandurangan, Guanhong Pei", "title": "A Fast Distributed Approximation Algorithm for Minimum Spanning Trees in\n  the SINR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in wireless networks is the \\emph{minimum spanning\ntree} (MST) problem: given a set $V$ of wireless nodes, compute a spanning tree\n$T$, so that the total cost of $T$ is minimized. In recent years, there has\nbeen a lot of interest in the physical interference model based on SINR\nconstraints. Distributed algorithms are especially challenging in the SINR\nmodel, because of the non-locality of the model.\n  In this paper, we develop a fast distributed approximation algorithm for MST\nconstruction in an SINR based distributed computing model. For an $n$-node\nnetwork, our algorithm's running time is $O(D\\log{n}+\\mu\\log{n})$ and produces\na spanning tree whose cost is within $O(\\log n)$ times the optimal (MST cost),\nwhere $D$ denotes the diameter of the disk graph obtained by using the maximum\npossible transmission range, and $\\mu=\\log{\\frac{d_{max}}{d_{min}}}$ denotes\nthe \"distance diversity\" w.r.t. the largest and smallest distances between two\nnodes. (When $\\frac{d_{max}}{d_{min}}$ is $n$-polynomial, $\\mu = O(\\log n)$.)\nOur algorithm's running time is essentially optimal (upto a logarithmic\nfactor), since computing {\\em any} spanning tree takes $\\Omega(D)$ time; thus\nour algorithm produces a low cost spanning tree in time only a logarithmic\nfactor more than the time to compute a spanning tree. The distributed\nscheduling complexity of the spanning tree resulted from our algorithm is\n$O(\\mu \\log n)$. Our algorithmic design techniques can be useful in designing\nefficient distributed algorithms for related \"global\" problems in wireless\nnetworks in the SINR model.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 03:08:41 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Khan", "Maleq", ""], ["Kumar", "V. S. Anil", ""], ["Pandurangan", "Gopal", ""], ["Pei", "Guanhong", ""]]}, {"id": "1206.1522", "submitter": "Peter Robinson", "authors": "Gopal Pandurangan, Peter Robinson, Amitabh Trehan", "title": "DEX: Self-healing Expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully-distributed self-healing algorithm DEX, that maintains a\nconstant degree expander network in a dynamic setting. To the best of our\nknowledge, our algorithm provides the first efficient distributed construction\nof expanders --- whose expansion properties hold {\\em deterministically} ---\nthat works even under an all-powerful adaptive adversary that controls the\ndynamic changes to the network (the adversary has unlimited computational power\nand knowledge of the entire network state, can decide which nodes join and\nleave and at what time, and knows the past random choices made by the\nalgorithm). Previous distributed expander constructions typically provide only\n{\\em probabilistic} guarantees on the network expansion which {\\em rapidly\ndegrade} in a dynamic setting; in particular, the expansion properties can\ndegrade even more rapidly under {\\em adversarial} insertions and deletions.\n  Our algorithm provides efficient maintenance and incurs a low overhead per\ninsertion/deletion by an adaptive adversary: only $O(\\log n)$ rounds and\n$O(\\log n)$ messages are needed with high probability ($n$ is the number of\nnodes currently in the network). The algorithm requires only a constant number\nof topology changes. Moreover, our algorithm allows for an efficient\nimplementation and maintenance of a distributed hash table (DHT) on top of DEX,\nwith only a constant additional overhead.\n  Our results are a step towards implementing efficient self-healing networks\nthat have \\emph{guaranteed} properties (constant bounded degree and expansion)\ndespite dynamic changes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 15:24:32 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 09:27:50 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2013 17:34:31 GMT"}, {"version": "v4", "created": "Mon, 21 Oct 2013 11:10:13 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1206.1623", "submitter": "Jason Lee", "authors": "Jason D. Lee, Yuekai Sun, Michael A. Saunders", "title": "Proximal Newton-type methods for minimizing composite functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize Newton-type methods for minimizing smooth functions to handle a\nsum of two convex functions: a smooth function and a nonsmooth function with a\nsimple proximal mapping. We show that the resulting proximal Newton-type\nmethods inherit the desirable convergence behavior of Newton-type methods for\nminimizing smooth functions, even when search directions are computed\ninexactly. Many popular methods tailored to problems arising in bioinformatics,\nsignal processing, and statistical learning are special cases of proximal\nNewton-type methods, and our analysis yields new convergence results for some\nof these methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 21:31:23 GMT"}, {"version": "v10", "created": "Thu, 16 May 2013 15:30:05 GMT"}, {"version": "v11", "created": "Mon, 3 Jun 2013 16:19:20 GMT"}, {"version": "v12", "created": "Wed, 25 Dec 2013 19:55:21 GMT"}, {"version": "v13", "created": "Mon, 17 Mar 2014 22:08:25 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 15:14:21 GMT"}, {"version": "v3", "created": "Sun, 14 Oct 2012 21:54:57 GMT"}, {"version": "v4", "created": "Sun, 11 Nov 2012 19:21:12 GMT"}, {"version": "v5", "created": "Mon, 15 Apr 2013 18:28:57 GMT"}, {"version": "v6", "created": "Tue, 16 Apr 2013 16:38:48 GMT"}, {"version": "v7", "created": "Wed, 17 Apr 2013 17:40:34 GMT"}, {"version": "v8", "created": "Mon, 22 Apr 2013 16:24:55 GMT"}, {"version": "v9", "created": "Mon, 29 Apr 2013 18:57:33 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Lee", "Jason D.", ""], ["Sun", "Yuekai", ""], ["Saunders", "Michael A.", ""]]}, {"id": "1206.1775", "submitter": "Holger Dell Holger Dell", "authors": "Holger Dell, Thore Husfeldt, D\\'aniel Marx, Nina Taslaman, Martin\n  W\\'ahlen", "title": "Exponential Time Complexity of the Permanent and the Tutte Polynomial", "comments": null, "journal-ref": "ACM Trans. Algorithms 10(4): 21:1-21:32 (2014)", "doi": "10.1145/2635812", "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show conditional lower bounds for well-studied #P-hard problems:\n  (a) The number of satisfying assignments of a 2-CNF formula with n variables\ncannot be counted in time exp(o(n)), and the same is true for computing the\nnumber of all independent sets in an n-vertex graph.\n  (b) The permanent of an n x n matrix with entries 0 and 1 cannot be computed\nin time exp(o(n)).\n  (c) The Tutte polynomial of an n-vertex multigraph cannot be computed in time\nexp(o(n)) at most evaluation points (x,y) in the case of multigraphs, and it\ncannot be computed in time exp(o(n/polylog n)) in the case of simple graphs.\n  Our lower bounds are relative to (variants of) the Exponential Time\nHypothesis (ETH), which says that the satisfiability of n-variable 3-CNF\nformulas cannot be decided in time exp(o(n)). We relax this hypothesis by\nintroducing its counting version #ETH, namely that the satisfying assignments\ncannot be counted in time exp(o(n)). In order to use #ETH for our lower bounds,\nwe transfer the sparsification lemma for d-CNF formulas to the counting\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 14:29:52 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Dell", "Holger", ""], ["Husfeldt", "Thore", ""], ["Marx", "D\u00e1niel", ""], ["Taslaman", "Nina", ""], ["W\u00e1hlen", "Martin", ""]]}, {"id": "1206.1837", "submitter": "Cedric Chauve", "authors": "Cedric Chauve, Tamon Stephen and Maria Tamayo", "title": "Efficient Algorithms for Finding Tucker Patterns", "comments": "15 pages. Preliminary version This paper had been withdrawn due to\n  some missing cases in Algorithms 2 and 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Consecutive Ones Property is an important notion for binary matrices,\nboth from a theoretical and applied point of view. Tucker gave in 1972 a\ncharacterization of matrices that do not satisfy the Consecutive Ones Property\nin terms of forbidden submatrices, the Tucker patterns. We describe here a\nlinear time algorithm to find a Tucker pattern in a non-C1P binary matrix,\nwhich allows to extract in linear time a certificate for the non-C1P. We also\ndescribe an output-sensitive algorithm to enumerate all Tucker patterns of a\nnon-C1P binary matrix.\n  This paper had been withdrawn due to some missing cases in Algorithms 2 and\n3.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 18:54:33 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2012 05:18:12 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Chauve", "Cedric", ""], ["Stephen", "Tamon", ""], ["Tamayo", "Maria", ""]]}, {"id": "1206.1877", "submitter": "Riccardo Dondi", "authors": "Riccardo Dondi, Nadia El-Mabrouk", "title": "On the Complexity of Minimum Labeling Alignment of Two Genomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we investigate the complexity of the Minimum Label Alignment\nproblem and we show that such a problem is APX-hard.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 21:01:03 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Dondi", "Riccardo", ""], ["El-Mabrouk", "Nadia", ""]]}, {"id": "1206.2082", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Ashish Goel", "title": "Dimension Independent Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a suite of algorithms for Dimension Independent Similarity\nComputation (DISCO) to compute all pairwise similarities between very high\ndimensional sparse vectors. All of our results are provably independent of\ndimension, meaning apart from the initial cost of trivially reading in the\ndata, all subsequent operations are independent of the dimension, thus the\ndimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard\nsimilarity measures. For Jaccard similiarity we include an improved version of\nMinHash. Our results are geared toward the MapReduce framework. We empirically\nvalidate our theorems at large scale using data from the social networking site\nTwitter. At time of writing, our algorithms are live in production at\ntwitter.com.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 02:19:27 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 04:40:52 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2013 03:54:28 GMT"}, {"version": "v4", "created": "Thu, 23 May 2013 07:56:18 GMT"}], "update_date": "2013-05-24", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Goel", "Ashish", ""]]}, {"id": "1206.2269", "submitter": "Michael Kapralov", "authors": "Michael Kapralov", "title": "Better bounds for matchings in the streaming model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present improved bounds for approximating maximum matchings\nin bipartite graphs in the streaming model. First, we consider the question of\nhow well maximum matching can be approximated in a single pass over the input\nusing $\\tilde O(n)$ space, where $n$ is the number of vertices in the input\ngraph. Two natural variants of this problem have been considered in the\nliterature: (1) the edge arrival setting, where edges arrive in the stream and\n(2) the vertex arrival setting, where vertices on one side of the graph arrive\nin the stream together with all their incident edges. The latter setting has\nalso been studied extensively in the context of online algorithms, where each\narriving vertex has to either be matched irrevocably or discarded upon arrival.\nIn the online setting, the celebrated algorithm of Karp-Vazirani-Vazirani\nachieves a $1-1/e$ approximation. Despite the fact that the streaming model is\nless restrictive in that the algorithm is not constrained to match vertices\nirrevocably upon arrival, the best known approximation in the streaming model\nwith vertex arrivals and $\\tilde O(n)$ space is the same factor of $1-1/e$.\n  We show that no single pass streaming algorithm that uses $\\tilde O(n)$ space\ncan achieve a better than $1-1/e$ approximation to maximum matching, even in\nthe vertex arrival setting. This leads to the striking conclusion that no\nsingle pass streaming algorithm can do better than online algorithms unless it\nuses significantly more than $\\tilde O(n)$ space. Additionally, our bound\nyields the best known impossibility result for approximating matchings in the\nedge arrival model.\n  We also give a simple algorithm that achieves approximation ratio\n$1-e^{-k}k^{k-1}/(k-1)!=1-\\frac1{\\sqrt{2\\pi k}}+o(1/k)$ in $k$ passes in the\nvertex arrival model using linear space, improving upon previously best known\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 16:01:45 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2012 11:57:32 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 16:11:23 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Kapralov", "Michael", ""]]}, {"id": "1206.2510", "submitter": "David Novak", "authors": "David Novak, Petr Volny, Pavel Zezula", "title": "Generic Subsequence Matching Framework: Modularity, Flexibility,\n  Efficiency", "comments": "This is an extended version of a paper published on DEXA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsequence matching has appeared to be an ideal approach for solving many\nproblems related to the fields of data mining and similarity retrieval. It has\nbeen shown that almost any data class (audio, image, biometrics, signals) is or\ncan be represented by some kind of time series or string of symbols, which can\nbe seen as an input for various subsequence matching approaches. The variety of\ndata types, specific tasks and their partial or full solutions is so wide that\nthe choice, implementation and parametrization of a suitable solution for a\ngiven task might be complicated and time-consuming; a possibly fruitful\ncombination of fragments from different research areas may not be obvious nor\neasy to realize. The leading authors of this field also mention the\nimplementation bias that makes difficult a proper comparison of competing\napproaches. Therefore we present a new generic Subsequence Matching Framework\n(SMF) that tries to overcome the aforementioned problems by a uniform frame\nthat simplifies and speeds up the design, development and evaluation of\nsubsequence matching related systems. We identify several relatively separate\nsubtasks solved differently over the literature and SMF enables to combine them\nin straightforward manner achieving new quality and efficiency. This framework\ncan be used in many application domains and its components can be reused\neffectively. Its strictly modular architecture and openness enables also\ninvolvement of efficient solutions from different fields, for instance\nefficient metric-based indexes. This is an extended version of a paper\npublished on DEXA 2012.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 12:39:04 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Novak", "David", ""], ["Volny", "Petr", ""], ["Zezula", "Pavel", ""]]}, {"id": "1206.2523", "submitter": "Gabriele Fici", "authors": "Golnaz Badkobeh, Gabriele Fici, Steve Kroon, Zsuzsanna Lipt\\'ak", "title": "Binary Jumbled String Matching for Highly Run-Length Compressible Texts", "comments": "v2: only small cosmetic changes; v3: new title, weakened conjectures\n  on size of Corner Index (we no longer conjecture it to be always linear in\n  size of RLE); removed experimental part on random strings (these are valid\n  but limited in their predictive power w.r.t. general strings); v3 published\n  in IPL", "journal-ref": "Information Processing Letters, 113: 604-608 (2013)", "doi": "10.1016/j.ipl.2013.05.007", "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Jumbled String Matching problem is defined as: Given a string $s$\nover $\\{a,b\\}$ of length $n$ and a query $(x,y)$, with $x,y$ non-negative\nintegers, decide whether $s$ has a substring $t$ with exactly $x$ $a$'s and $y$\n$b$'s. Previous solutions created an index of size O(n) in a pre-processing\nstep, which was then used to answer queries in constant time. The fastest\nalgorithms for construction of this index have running time $O(n^2/\\log n)$\n[Burcsi et al., FUN 2010; Moosa and Rahman, IPL 2010], or $O(n^2/\\log^2 n)$ in\nthe word-RAM model [Moosa and Rahman, JDA 2012]. We propose an index\nconstructed directly from the run-length encoding of $s$. The construction time\nof our index is $O(n+\\rho^2\\log \\rho)$, where O(n) is the time for computing\nthe run-length encoding of $s$ and $\\rho$ is the length of this encoding---this\nis no worse than previous solutions if $\\rho = O(n/\\log n)$ and better if $\\rho\n= o(n/\\log n)$. Our index $L$ can be queried in $O(\\log \\rho)$ time. While\n$|L|= O(\\min(n, \\rho^{2}))$ in the worst case, preliminary investigations have\nindicated that $|L|$ may often be close to $\\rho$. Furthermore, the algorithm\nfor constructing the index is conceptually simple and easy to implement. In an\nattempt to shed light on the structure and size of our index, we characterize\nit in terms of the prefix normal forms of $s$ introduced in [Fici and Lipt\\'ak,\nDLT 2011].\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 13:33:32 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 21:38:40 GMT"}, {"version": "v3", "created": "Fri, 31 May 2013 17:32:12 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Badkobeh", "Golnaz", ""], ["Fici", "Gabriele", ""], ["Kroon", "Steve", ""], ["Lipt\u00e1k", "Zsuzsanna", ""]]}, {"id": "1206.2691", "submitter": "Muddassar Sindhu", "authors": "Muddassar A. Sindhu, Karl Meinke", "title": "IDS: An Incremental Learning Algorithm for Finite Automata", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm IDS for incremental learning of deterministic\nfinite automata (DFA). This algorithm is based on the concept of distinguishing\nsequences introduced in (Angluin81). We give a rigorous proof that two versions\nof this learning algorithm correctly learn in the limit. Finally we present an\nempirical performance analysis that compares these two algorithms, focussing on\nlearning times and different types of learning queries. We conclude that IDS is\nan efficient algorithm for software engineering applications of automata\nlearning, such as testing and model inference.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 00:27:36 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Sindhu", "Muddassar A.", ""], ["Meinke", "Karl", ""]]}, {"id": "1206.3204", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Or Sheffet", "title": "Improved Spectral-Norm Bounds for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming to unify known results about clustering mixtures of distributions\nunder separation conditions, Kumar and Kannan[2010] introduced a deterministic\ncondition for clustering datasets. They showed that this single deterministic\ncondition encompasses many previously studied clustering assumptions. More\nspecifically, their proximity condition requires that in the target\n$k$-clustering, the projection of a point $x$ onto the line joining its cluster\ncenter $\\mu$ and some other center $\\mu'$, is a large additive factor closer to\n$\\mu$ than to $\\mu'$. This additive factor can be roughly described as $k$\ntimes the spectral norm of the matrix representing the differences between the\ngiven (known) dataset and the means of the (unknown) target clustering.\nClearly, the proximity condition implies center separation -- the distance\nbetween any two centers must be as large as the above mentioned bound.\n  In this paper we improve upon the work of Kumar and Kannan along several\naxes. First, we weaken the center separation bound by a factor of $\\sqrt{k}$,\nand secondly we weaken the proximity condition by a factor of $k$. Using these\nweaker bounds we still achieve the same guarantees when all points satisfy the\nproximity condition. We also achieve better guarantees when only\n$(1-\\epsilon)$-fraction of the points satisfy the weaker proximity condition.\nThe bulk of our analysis relies only on center separation under which one can\nproduce a clustering which (i) has low error, (ii) has low $k$-means cost, and\n(iii) has centers very close to the target centers.\n  Our improved separation condition allows us to match the results of the\nPlanted Partition Model of McSherry[2001], improve upon the results of\nOstrovsky et al[2006], and improve separation results for mixture of Gaussian\nmodels in a particular setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 18:23:46 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2012 18:11:27 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Sheffet", "Or", ""]]}, {"id": "1206.3234", "submitter": "Umut A. Acar", "authors": "Umut A. Acar, Alexander T. Ihler, Ramgopal Mettu, Ozgur Sumer", "title": "Adaptive Inference on General Graphical Models", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-1-8", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms and applications involve repeatedly solving variations of the\nsame inference problem; for example we may want to introduce new evidence to\nthe model or perform updates to conditional dependencies. The goal of adaptive\ninference is to take advantage of what is preserved in the model and perform\ninference more rapidly than from scratch. In this paper, we describe techniques\nfor adaptive inference on general graphs that support marginal computation and\nupdates to the conditional probabilities and dependencies in logarithmic time.\nWe give experimental results for an implementation of our algorithm, and\ndemonstrate its potential performance benefit in the study of protein\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:16:36 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Acar", "Umut A.", ""], ["Ihler", "Alexander T.", ""], ["Mettu", "Ramgopal", ""], ["Sumer", "Ozgur", ""]]}, {"id": "1206.3236", "submitter": "Vincent Auvray", "authors": "Vincent Auvray, Louis Wehenkel", "title": "Learning Inclusion-Optimal Chordal Graphs", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-18-25", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chordal graphs can be used to encode dependency models that are representable\nby both directed acyclic and undirected graphs. This paper discusses a very\nsimple and efficient algorithm to learn the chordal structure of a\nprobabilistic model from data. The algorithm is a greedy hill-climbing search\nalgorithm that uses the inclusion boundary neighborhood over chordal graphs. In\nthe limit of a large sample size and under appropriate hypotheses on the\nscoring criterion, we prove that the algorithm will find a structure that is\ninclusion-optimal when the dependency model of the data-generating distribution\ncan be represented exactly by an undirected graph. The algorithm is evaluated\non simulated datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:17:24 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Auvray", "Vincent", ""], ["Wehenkel", "Louis", ""]]}, {"id": "1206.3240", "submitter": "Venkat Chandrasekaran", "authors": "Venkat Chandrasekaran, Nathan Srebro, Prahladh Harsha", "title": "Complexity of Inference in Graphical Models", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-70-78", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that inference in graphical models is hard in the worst\ncase, but tractable for models with bounded treewidth. We ask whether treewidth\nis the only structural criterion of the underlying graph that enables tractable\ninference. In other words, is there some class of structures with unbounded\ntreewidth in which inference is tractable? Subject to a combinatorial\nhypothesis due to Robertson et al. (1994), we show that low treewidth is indeed\nthe only structural restriction that can ensure tractability. Thus, even for\nthe \"best case\" graph structure, there is no inference algorithm with\ncomplexity polynomial in the treewidth.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:01:35 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Chandrasekaran", "Venkat", ""], ["Srebro", "Nathan", ""], ["Harsha", "Prahladh", ""]]}, {"id": "1206.3288", "submitter": "David Sontag", "authors": "David Sontag, Talya Meltzer, Amir Globerson, Tommi S. Jaakkola, Yair\n  Weiss", "title": "Tightening LP Relaxations for MAP using Message Passing", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-503-510", "categories": "cs.DS cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Programming (LP) relaxations have become powerful tools for finding\nthe most probable (MAP) configuration in graphical models. These relaxations\ncan be solved efficiently using message-passing algorithms such as belief\npropagation and, when the relaxation is tight, provably find the MAP\nconfiguration. The standard LP relaxation is not tight enough in many\nreal-world problems, however, and this has lead to the use of higher order\ncluster-based LP relaxations. The computational cost increases exponentially\nwith the size of the clusters and limits the number and type of clusters we can\nuse. We propose to solve the cluster selection problem monotonically in the\ndual LP, iteratively selecting clusters with guaranteed improvement, and\nquickly re-solving with the added clusters by reusing the existing solution.\nOur dual message-passing algorithm finds the MAP configuration in protein\nsidechain placement, protein design, and stereo problems, in cases where the\nstandard LP relaxation fails.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:46:00 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Sontag", "David", ""], ["Meltzer", "Talya", ""], ["Globerson", "Amir", ""], ["Jaakkola", "Tommi S.", ""], ["Weiss", "Yair", ""]]}, {"id": "1206.3334", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Avrim Blum, Jamie Morgenstern, Or Sheffet", "title": "Additive Approximation for Near-Perfect Phylogeny Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of constructing phylogenetic trees for a given set of\nspecies. The problem is formulated as that of finding a minimum Steiner tree on\n$n$ points over the Boolean hypercube of dimension $d$. It is known that an\noptimal tree can be found in linear time if the given dataset has a perfect\nphylogeny, i.e. cost of the optimal phylogeny is exactly $d$. Moreover, if the\ndata has a near-perfect phylogeny, i.e. the cost of the optimal Steiner tree is\n$d+q$, it is known that an exact solution can be found in running time which is\npolynomial in the number of species and $d$, yet exponential in $q$. In this\nwork, we give a polynomial-time algorithm (in both $d$ and $q$) that finds a\nphylogenetic tree of cost $d+O(q^2)$. This provides the best guarantees known -\nnamely, a $(1+o(1))$-approximation - for the case $\\log(d) \\ll q \\ll \\sqrt{d}$,\nbroadening the range of settings for which near-optimal solutions can be\nefficiently found. We also discuss the motivation and reasoning for studying\nsuch additive approximations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 21:38:01 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Blum", "Avrim", ""], ["Morgenstern", "Jamie", ""], ["Sheffet", "Or", ""]]}, {"id": "1206.3437", "submitter": "Jean-Guillaume Fages", "authors": "Jean-Guillaume Fages and Xavier Lorca", "title": "Improving the Asymmetric TSP by Considering Graph Structure", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": "12/4/INFO", "categories": "cs.DM cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on cost based relaxations have improved Constraint Programming\n(CP) models for the Traveling Salesman Problem (TSP). We provide a short survey\nover solving asymmetric TSP with CP. Then, we suggest new implied propagators\nbased on general graph properties. We experimentally show that such implied\npropagators bring robustness to pathological instances and highlight the fact\nthat graph structure can significantly improve search heuristics behavior.\nFinally, we show that our approach outperforms current state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 12:15:31 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Fages", "Jean-Guillaume", ""], ["Lorca", "Xavier", ""]]}, {"id": "1206.3483", "submitter": "Ioannis Koutis", "authors": "Ioannis Koutis", "title": "Constrained multilinear detection for faster functional motif discovery", "comments": null, "journal-ref": null, "doi": "10.1016/j.ipl.2012.08.008", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GRAPH MOTIF problem asks whether a given multiset of colors appears on a\nconnected subgraph of a vertex-colored graph. The fastest known parameterized\nalgorithm for this problem is based on a reduction to the $k$-Multilinear\nDetection (k-MlD) problem: the detection of multilinear terms of total degree k\nin polynomials presented as circuits. We revisit k-MLD and define k-CMLD, a\nconstrained version of it which reflects GRAPH MOTIF more faithfully. We then\ngive a fast algorithm for k-CMLD. As a result we obtain faster parameterized\nalgorithms for GRAPH MOTIF and variants of it.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 14:40:31 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2012 01:49:40 GMT"}], "update_date": "2012-08-24", "authors_parsed": [["Koutis", "Ioannis", ""]]}, {"id": "1206.3511", "submitter": "Panu Horsmalahti", "authors": "Panu Horsmalahti", "title": "Comparison of Bucket Sort and RADIX Sort", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Bucket sort and RADIX sort are two well-known integer sorting algorithms.\nThis paper measures empirically what is the time usage and memory consumption\nfor different kinds of input sequences. The algorithms are compared both from a\ntheoretical standpoint but also on how well they do in six different use cases\nusing randomized sequences of numbers. The measurements provide data on how\ngood they are in different real-life situations.\n  It was found that bucket sort was faster than RADIX sort, but that bucket\nsort uses more memory in most cases. The sorting algorithms performed faster\nwith smaller integers. The RADIX sort was not quicker with already sorted\ninputs, but the bucket sort was.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 16:39:51 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Horsmalahti", "Panu", ""]]}, {"id": "1206.3520", "submitter": "Sebastian Roch", "authors": "Sebastien Roch and Sagi Snir", "title": "Recovering the tree-like trend of evolution despite extensive lateral\n  genetic transfer: A probabilistic analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lateral gene transfer (LGT) is a common mechanism of non-vertical evolution\nwhere genetic material is transferred between two more or less distantly\nrelated organisms. It is particularly common in bacteria where it contributes\nto adaptive evolution with important medical implications. In evolutionary\nstudies, LGT has been shown to create widespread discordance between gene trees\nas genomes become mosaics of gene histories. In particular, the Tree of Life\nhas been questioned as an appropriate representation of bacterial evolutionary\nhistory. Nevertheless a common hypothesis is that prokaryotic evolution is\nprimarily tree-like, but that the underlying trend is obscured by LGT.\nExtensive empirical work has sought to extract a common tree-like signal from\nconflicting gene trees. Here we give a probabilistic perspective on the problem\nof recovering the tree-like trend despite LGT. Under a model of randomly\ndistributed LGT, we show that the species phylogeny can be reconstructed even\nin the presence of surprisingly many (almost linear number of) LGT events per\ngene tree. Our results, which are optimal up to logarithmic factors, are based\non the analysis of a robust, computationally efficient reconstruction method\nand provides insight into the design of such methods. Finally we show that our\nresults have implications for the discovery of highways of gene sharing.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 17:19:42 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Roch", "Sebastien", ""], ["Snir", "Sagi", ""]]}, {"id": "1206.3552", "submitter": "Michele Coscia", "authors": "Michele Coscia, Fosca Giannotti, Dino Pedreschi", "title": "A Classification for Community Discovery Methods in Complex Networks", "comments": "Published in the Statistical Analysis and Data Mining journal,\n  Special Issue: Networks. Volume 4, Issue 5, pages 512-546, October 2011", "journal-ref": "Statistical Analysis and Data Mining journal, Special Issue:\n  Networks. Volume 4, Issue 5, pages 512-546, October 2011", "doi": "10.1002/sam.10133", "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years many real-world networks have been found to show a\nso-called community structure organization. Much effort has been devoted in the\nliterature to develop methods and algorithms that can efficiently highlight\nthis hidden structure of the network, traditionally by partitioning the graph.\nSince network representation can be very complex and can contain different\nvariants in the traditional graph model, each algorithm in the literature\nfocuses on some of these properties and establishes, explicitly or implicitly,\nits own definition of community. According to this definition it then extracts\nthe communities that are able to reflect only some of the features of real\ncommunities. The aim of this survey is to provide a manual for the community\ndiscovery problem. Given a meta definition of what a community in a social\nnetwork is, our aim is to organize the main categories of community discovery\nbased on their own definition of community. Given a desired definition of\ncommunity and the features of a problem (size of network, direction of edges,\nmultidimensionality, and so on) this review paper is designed to provide a set\nof approaches that researchers could focus on.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 19:22:43 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Coscia", "Michele", ""], ["Giannotti", "Fosca", ""], ["Pedreschi", "Dino", ""]]}, {"id": "1206.3555", "submitter": "Andreas Stuhlm\\\"uller", "authors": "Andreas Stuhlm\\\"uller, Noah D. Goodman", "title": "A Dynamic Programming Algorithm for Inference in Recursive Probabilistic\n  Programs", "comments": "Second Statistical Relational AI workshop at UAI 2012 (StaRAI-12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a dynamic programming algorithm for computing the marginal\ndistribution of discrete probabilistic programs. This algorithm takes a\nfunctional interpreter for an arbitrary probabilistic programming language and\nturns it into an efficient marginalizer. Because direct caching of\nsub-distributions is impossible in the presence of recursion, we build a graph\nof dependencies between sub-distributions. This factored sum-product network\nmakes (potentially cyclic) dependencies between subproblems explicit, and\ncorresponds to a system of equations for the marginal distribution. We solve\nthese equations by fixed-point iteration in topological order. We illustrate\nthis algorithm on examples used in teaching probabilistic models, computational\ncognitive science research, and game theory.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 19:44:02 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2012 22:00:30 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Stuhlm\u00fcller", "Andreas", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1206.3603", "submitter": "Yury Makarychev", "authors": "Konstantin Makarychev and Yury Makarychev", "title": "Approximation Algorithm for Non-Boolean MAX k-CSP", "comments": "The conference version of this paper will appear in the Proceedings\n  of APPROX 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a randomized polynomial-time approximation\nalgorithm for k-CSPd. In k-CSPd, we are given a set of predicates of arity k\nover an alphabet of size d. Our goal is to find an assignment that maximizes\nthe number of satisfied constraints.\n  Our algorithm has approximation factor Omega(kd/d^k) (when k > \\Omega(log\nd)). This bound is asymptotically optimal assuming the Unique Games Conjecture.\nThe best previously known algorithm has approximation factor Omega(k log\nd/d^k).\n  We also give an approximation algorithm for the boolean MAX k-CSP2 problem\nwith a slightly improved approximation guarantee.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 22:40:40 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""]]}, {"id": "1206.3628", "submitter": "Mirela Damian", "authors": "Matthew Bauer and Mirela Damian", "title": "An Infinite Class of Sparse-Yao Spanners", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for any integer k > 5, the Sparse-Yao graph YY_{6k} (also known\nas Yao-Yao) is a spanner with stretch factor 11.67. The stretch factor drops\ndown to 4.75 for k > 7.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 03:47:34 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Bauer", "Matthew", ""], ["Damian", "Mirela", ""]]}, {"id": "1206.3634", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Balls into Bins: strict Capacities and Edge Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a novel theoretical model for studying the performance of\ndistributed storage management systems where the data-centers have limited\ncapacities (as compared to storage space requested by the users). Prior schemes\nsuch as Balls-into-bins (used for load balancing) neither consider bin\n(consumer) capacities (multiple balls into a bin) nor the future performance of\nthe system after, balls (producer requests) are allocated to bins and restrict\nnumber of balls as a function of the number of bins. Our problem consists of\nfinding an optimal assignment of the online producer requests to consumers (via\nweighted edges) in a complete bipartite graph while ensuring that the total\nsize of request assigned on a consumer is limited by its capacity. The metric\nused to measure the performance in this model is the (minimization of) weighted\nsum of the requests assigned on the edges (loads) and their corresponding\nweights. We first explore the optimal offline algorithms followed by\ncompetitive analysis of different online techniques. Using oblivious adversary.\nLP and Primal-Dual algorithms are used for calculating the optimal offline\nsolution in O(r*n) time (where r and n are the number of requests and consumers\nrespectively) while randomized algorithms are used for the online case.\n  For the simplified model with equal consumer capacities an average-case\ncompetitive ratio of AVG(d) / MIN(d) (where d is the edge weight / distance) is\nachieved using an algorithm that has equal probability for selecting any of the\navailable edges with a running time of $O(r)$. In the extending the model to\narbitrary consumer capacities we show an average case competitive ratio of\nAVG(d*c) / (AVG(c) *MIN(d)).\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 07:33:30 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1206.3718", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvoss", "title": "A simpler proof for O(congestion + dilation) packet routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the store-and-forward routing problem, packets have to be routed along\ngiven paths such that the arrival time of the latest packet is minimized. A\ngroundbreaking result of Leighton, Maggs and Rao says that this can always be\ndone in time O(congestion + dilation), where the congestion is the maximum\nnumber of paths using an edge and the dilation is the maximum length of a path.\nHowever, the analysis is quite arcane and complicated and works by iteratively\nimproving an infeasible schedule. Here, we provide a more accessible analysis\nwhich is based on conditional expectations. Like [LMR94], our easier analysis\nalso guarantees that constant size edge buffers suffice.\n  Moreover, it was an open problem stated e.g. by Wiese, whether there is any\ninstance where all schedules need at least (1 + epsilon)*(congestion +\ndilation) steps, for a constant epsilon > 0. We answer this question\naffirmatively by making use of a probabilistic construction.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 03:03:57 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 22:25:56 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Rothvoss", "Thomas", ""]]}, {"id": "1206.3768", "submitter": "Edoardo Di Napoli", "authors": "Edoardo Di Napoli (1) and Mario Berljafa (2) ((1) JSC,\n  Forschungszentrum Juelich) ((2) Dept. of Mathematics, Univ. of Zagreb)", "title": "Block Iterative Eigensolvers for Sequences of Correlated Eigenvalue\n  Problems", "comments": "12 Pages, 5 figures. Accepted for publication on Computer Physics\n  Communications", "journal-ref": null, "doi": "10.1016/j.cpc.2013.06.017", "report-no": "AICES-2012/12-1", "categories": "cs.DS cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Density Functional Theory simulations based on the LAPW method, each\nself-consistent field cycle comprises dozens of large dense generalized\neigenproblems. In contrast to real-space methods, eigenpairs solving for\nproblems at distinct cycles have either been believed to be independent or at\nmost very loosely connected. In a recent study [7], it was demonstrated that,\ncontrary to belief, successive eigenproblems in a sequence are strongly\ncorrelated with one another. In particular, by monitoring the subspace angles\nbetween eigenvectors of successive eigenproblems, it was shown that these\nangles decrease noticeably after the first few iterations and become close to\ncollinear. This last result suggests that we can manipulate the eigenvectors,\nsolving for a specific eigenproblem in a sequence, as an approximate solution\nfor the following eigenproblem. In this work we present results that are in\nline with this intuition. We provide numerical examples where opportunely\nselected block iterative eigensolvers benefit from the reuse of eigenvectors by\nachieving a substantial speed-up. The results presented will eventually open\nthe way to a widespread use of block iterative eigensolvers in ab initio\nelectronic structure codes based on the LAPW approach.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 17:03:24 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 16:49:51 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2013 12:24:16 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Di Napoli", "Edoardo", "", "Dept. of Mathematics, Univ. of Zagreb"], ["Berljafa", "Mario", "", "Dept. of Mathematics, Univ. of Zagreb"]]}, {"id": "1206.3789", "submitter": "Yann Ponty", "authors": "Philippe Rinaudo (LRI, INRIA Saclay - Ile de France, PRISM), Yann\n  Ponty (INRIA Saclay - Ile de France, LIX), Dominique Barth (PRISM), Alain\n  Denise (LRI, INRIA Saclay - Ile de France, IGM)", "title": "Tree decomposition and parameterized algorithms for RNA\n  structure-sequence alignment including tertiary interactions and pseudoknots", "comments": "(2012)", "journal-ref": "WABI - 12th Workshop on Algorithms in Bioinformatics - 2012 (2012)", "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general setting for structure-sequence comparison in a large\nclass of RNA structures that unifies and generalizes a number of recent works\non specific families on structures. Our approach is based on tree decomposition\nof structures and gives rises to a general parameterized algorithm, where the\nexponential part of the complexity depends on the family of structures. For\neach of the previously studied families, our algorithm has the same complexity\nas the specific algorithm that had been given before.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 20:04:20 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Rinaudo", "Philippe", "", "LRI, INRIA Saclay - Ile de France, PRISM"], ["Ponty", "Yann", "", "INRIA Saclay - Ile de France, LIX"], ["Barth", "Dominique", "", "PRISM"], ["Denise", "Alain", "", "LRI, INRIA Saclay - Ile de France, IGM"]]}, {"id": "1206.3877", "submitter": "Gregory Kucherov", "authors": "Gregory Kucherov, Lilla T\\'othm\\'er\\'esz, St\\'ephane Vialette", "title": "On the combinatorics of suffix arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several combinatorial properties of suffix arrays, including a\ncharacterization of suffix arrays through a bijection with a certain\nwell-defined class of permutations. Our approach is based on the\ncharacterization of Burrows-Wheeler arrays given in [1], that we apply by\nreducing suffix sorting to cyclic shift sorting through the use of an\nadditional sentinel symbol. We show that the characterization of suffix arrays\nfor a special case of binary alphabet given in [2] easily follows from our\ncharacterization. Based on our results, we also provide simple proofs for the\nenumeration results for suffix arrays, obtained in [3]. Our approach to\ncharacterizing suffix arrays is the first that exploits their relationship with\nBurrows-Wheeler permutations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 10:30:02 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Kucherov", "Gregory", ""], ["T\u00f3thm\u00e9r\u00e9sz", "Lilla", ""], ["Vialette", "St\u00e9phane", ""]]}, {"id": "1206.3999", "submitter": "C\\'edric Bentz", "authors": "C\\'edric Bentz", "title": "A polynomial-time algorithm for planar multicuts with few source-sink\n  pairs", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an edge-weighted undirected graph and a list of k source-sink pairs of\nvertices, the well-known minimum multicut problem consists in selecting a\nminimum-weight set of edges whose removal leaves no path between every source\nand its corresponding sink. We give the first polynomial-time algorithm to\nsolve this problem in planar graphs, when k is fixed. Previously, this problem\nwas known to remain NP-hard in general graphs with fixed k, and in trees with\narbitrary k; the most noticeable tractable case known so far was in planar\ngraphs with fixed k and sources and sinks lying on the outer face.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 17:32:34 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Bentz", "C\u00e9dric", ""]]}, {"id": "1206.4164", "submitter": "Ilya Razenshteyn", "authors": "Ilya Razenshteyn", "title": "On Epsilon-Nets, Distance Oracles, and Metric Embeddings", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give two new applications of an observation from \\cite{ADFGW11}. The first\nis an almost linear sized constant time data structure for reporting very large\ndistances in undirected graphs. The second is a generic transformation of\nresults about $\\ell_1$-embeddability of metrics to a setting, where we are\ninterested in preservation of large distances only.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 09:58:20 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Razenshteyn", "Ilya", ""]]}, {"id": "1206.4192", "submitter": "Eliyahu Osherovich", "authors": "Eliyahu Osherovich", "title": "Designing Incoherent Dictionaries for Compressed Sensing: Algorithm\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method presented for design of incoherent dictionaries.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 12:36:53 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Osherovich", "Eliyahu", ""]]}, {"id": "1206.4300", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "Quasi-Succinct Indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed inverted indices in use today are based on the idea of gap\ncompression: documents pointers are stored in increasing order, and the gaps\nbetween successive document pointers are stored using suitable codes which\nrepresent smaller gaps using less bits. Additional data such as counts and\npositions is stored using similar techniques. A large body of research has been\nbuilt in the last 30 years around gap compression, including theoretical\nmodeling of the gap distribution, specialized instantaneous codes suitable for\ngap encoding, and ad hoc document reorderings which increase the efficiency of\ninstantaneous codes. This paper proposes to represent an index using a\ndifferent architecture based on quasi-succinct representation of monotone\nsequences. We show that, besides being theoretically elegant and simple, the\nnew index provides expected constant-time operations and, in practice,\nsignificant performance improvements on conjunctive, phrasal and proximity\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 19:47:12 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "1206.4366", "submitter": "Vijay  Vazirani", "authors": "Leonard J. Schulman and Vijay V. Vazirani", "title": "Allocation of Divisible Goods under Lexicographic Preferences", "comments": null, "journal-ref": "Proc. FSTTCS 543-559, 2015", "doi": "10.4230/LIPIcs.FSTTCS.2015.543", "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and natural non-pricing mechanism for allocating\ndivisible goods among strategic agents having lexicographic preferences. Our\nmechanism has favorable properties of incentive compatibility\n(strategy-proofness), Pareto efficiency, envy-freeness, and time efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 01:05:11 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2012 05:50:56 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2012 16:50:34 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2015 16:18:23 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Schulman", "Leonard J.", ""], ["Vazirani", "Vijay V.", ""]]}, {"id": "1206.4377", "submitter": "Anish Das Sarma", "authors": "Foto N. Afrati, Anish Das Sarma, Semih Salihoglu, Jeffrey D. Ullman", "title": "Upper and Lower Bounds on the Cost of a Map-Reduce Computation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the tradeoff between parallelism and communication\ncost in a map-reduce computation. For any problem that is not \"embarrassingly\nparallel,\" the finer we partition the work of the reducers so that more\nparallelism can be extracted, the greater will be the total communication\nbetween mappers and reducers. We introduce a model of problems that can be\nsolved in a single round of map-reduce computation. This model enables a\ngeneric recipe for discovering lower bounds on communication cost as a function\nof the maximum number of inputs that can be assigned to one reducer. We use the\nmodel to analyze the tradeoff for three problems: finding pairs of strings at\nHamming distance $d$, finding triangles and other patterns in a larger graph,\nand matrix multiplication. For finding strings of Hamming distance 1, we have\nupper and lower bounds that match exactly. For triangles and many other graphs,\nwe have upper and lower bounds that are the same to within a constant factor.\nFor the problem of matrix multiplication, we have matching upper and lower\nbounds for one-round map-reduce algorithms. We are also able to explore\ntwo-round map-reduce algorithms for matrix multiplication and show that these\nnever have more communication, for a given reducer size, than the best\none-round algorithm, and often have significantly less.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 02:46:27 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Afrati", "Foto N.", ""], ["Sarma", "Anish Das", ""], ["Salihoglu", "Semih", ""], ["Ullman", "Jeffrey D.", ""]]}, {"id": "1206.4555", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Optimal compression of hash-origin prefix trees", "comments": "13 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DB cs.DS math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a common problem of operating on hash values of elements of some\ndatabase. In this paper there will be analyzed informational content of such\ngeneral task and how to practically approach such found lower boundaries.\nMinimal prefix tree which distinguish elements turns out to require\nasymptotically only about 2.77544 bits per element, while standard approaches\nuse a few times more. While being certain of working inside the database, the\ncost of distinguishability can be reduced further to about 2.33275 bits per\nelements. Increasing minimal depth of nodes to reduce probability of false\npositives leads to simple relation with average depth of such random tree,\nwhich is asymptotically larger by about 1.33275 bits than lg(n) of the perfect\nbinary tree. This asymptotic case can be also seen as a way to optimally encode\nn large unordered numbers - saving lg(n!) bits of information about their\nordering, which can be the major part of contained information. This ability\nitself allows to reduce memory requirements even to about 0.693 of required in\nBloom filter for the same false positive probability.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 16:53:04 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2012 15:27:48 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2012 12:06:42 GMT"}, {"version": "v4", "created": "Sun, 8 Jul 2012 15:05:35 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1206.4605", "submitter": "Jiabing Wang", "authors": "Jiabing Wang (South China University of Tech), Jiaye Chen (South China\n  University of Technology)", "title": "Clustering to Maximize the Ratio of Split to Diameter", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a weighted and complete graph G = (V, E), V denotes the set of n\nobjects to be clustered, and the weight d(u, v) associated with an edge (u, v)\nbelonging to E denotes the dissimilarity between objects u and v. The diameter\nof a cluster is the maximum dissimilarity between pairs of objects in the\ncluster, and the split of a cluster is the minimum dissimilarity between\nobjects within the cluster and objects outside the cluster. In this paper, we\npropose a new criterion for measuring the goodness of clusters: the ratio of\nthe minimum split to the maximum diameter, and the objective is to maximize the\nratio. For k = 2, we present an exact algorithm. For k >= 3, we prove that the\nproblem is NP-hard and present a factor of 2 approximation algorithm on the\nprecondition that the weights associated with E satisfy the triangle\ninequality. The worst-case runtime of both algorithms is O(n^3). We compare the\nproposed algorithms with the Normalized Cut by applying them to image\nsegmentation. The experimental results on both natural and synthetic images\ndemonstrate the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:42:47 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Wang", "Jiabing", "", "South China University of Tech"], ["Chen", "Jiaye", "", "South China\n  University of Technology"]]}, {"id": "1206.4608", "submitter": "Soeren Laue", "authors": "Soeren Laue (Friedrich-Schiller-University)", "title": "A Hybrid Algorithm for Convex Semidefinite Optimization", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hybrid algorithm for optimizing a convex, smooth function over\nthe cone of positive semidefinite matrices. Our algorithm converges to the\nglobal optimal solution and can be used to solve general large-scale\nsemidefinite programs and hence can be readily applied to a variety of machine\nlearning problems. We show experimental results on three machine learning\nproblems (matrix completion, metric learning, and sparse PCA) . Our approach\noutperforms state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:44:28 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Laue", "Soeren", "", "Friedrich-Schiller-University"]]}, {"id": "1206.4642", "submitter": "Daisuke Kimura", "authors": "Daisuke Kimura (The University of Tokyo), Hisashi Kashima (The\n  University of Tokyo)", "title": "Fast Computation of Subpath Kernel for Trees", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel method is a potential approach to analyzing structured data such\nas sequences, trees, and graphs; however, unordered trees have not been\ninvestigated extensively. Kimura et al. (2011) proposed a kernel function for\nunordered trees on the basis of their subpaths, which are vertical\nsubstructures of trees responsible for hierarchical information in them. Their\nkernel exhibits practically good performance in terms of accuracy and speed;\nhowever, linear-time computation is not guaranteed theoretically, unlike the\ncase of the other unordered tree kernel proposed by Vishwanathan and Smola\n(2003). In this paper, we propose a theoretically guaranteed linear-time kernel\ncomputation algorithm that is practically fast, and we present an efficient\nprediction algorithm whose running time depends only on the size of the input\ntree. Experimental results show that the proposed algorithms are quite\nefficient in practice.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:18:51 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Kimura", "Daisuke", "", "The University of Tokyo"], ["Kashima", "Hisashi", "", "The\n  University of Tokyo"]]}, {"id": "1206.4657", "submitter": "Elad Hazan", "authors": "Elad Hazan (Technion), Satyen Kale (IBM T.J. Watson Research Center)", "title": "Projection-free Online Learning", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational bottleneck in applying online learning to massive data sets\nis usually the projection step. We present efficient online learning algorithms\nthat eschew projections in favor of much more efficient linear optimization\nsteps using the Frank-Wolfe technique. We obtain a range of regret bounds for\nonline convex optimization, with better bounds for specific cases such as\nstochastic online smooth convex optimization.\n  Besides the computational advantage, other desirable features of our\nalgorithms are that they are parameter-free in the stochastic case and produce\nsparse decisions. We apply our algorithms to computationally intensive\napplications of collaborative filtering, and show the theoretical improvements\nto be clearly visible on standard datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:26:34 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Hazan", "Elad", "", "Technion"], ["Kale", "Satyen", "", "IBM T.J. Watson Research Center"]]}, {"id": "1206.4668", "submitter": "Andrew McGregor", "authors": "Mark McCartin-Lim (University of Massachusetts), Andrew McGregor\n  (University of Massachusetts), Rui Wang (University of Massachusetts)", "title": "Approximate Principal Direction Trees", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new spatial data structure for high dimensional data called\nthe \\emph{approximate principal direction tree} (APD tree) that adapts to the\nintrinsic dimension of the data. Our algorithm ensures vector-quantization\naccuracy similar to that of computationally-expensive PCA trees with similar\ntime-complexity to that of lower-accuracy RP trees.\n  APD trees use a small number of power-method iterations to find splitting\nplanes for recursively partitioning the data. As such they provide a natural\ntrade-off between the running-time and accuracy achieved by RP and PCA trees.\nOur theoretical results establish a) strong performance guarantees regardless\nof the convergence rate of the power-method and b) that $O(\\log d)$ iterations\nsuffice to establish the guarantee of PCA trees when the intrinsic dimension is\n$d$. We demonstrate this trade-off and the efficacy of our data structure on\nboth the CPU and GPU.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:33:25 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["McCartin-Lim", "Mark", "", "University of Massachusetts"], ["McGregor", "Andrew", "", "University of Massachusetts"], ["Wang", "Rui", "", "University of Massachusetts"]]}, {"id": "1206.4674", "submitter": "Stratis Ioannidis", "authors": "Amin Karbasi (EPFL), Stratis Ioannidis (Technicolor), laurent\n  Massoulie (Technicolor)", "title": "Comparison-Based Learning with Rank Nets", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of search through comparisons, where a user is\npresented with two candidate objects and reveals which is closer to her\nintended target. We study adaptive strategies for finding the target, that\nrequire knowledge of rank relationships but not actual distances between\nobjects. We propose a new strategy based on rank nets, and show that for target\ndistributions with a bounded doubling constant, it finds the target in a number\nof comparisons close to the entropy of the target distribution and, hence, of\nthe optimum. We extend these results to the case of noisy oracles, and compare\nthis strategy to prior art over multiple datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:36:16 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Karbasi", "Amin", "", "EPFL"], ["Ioannidis", "Stratis", "", "Technicolor"], ["Massoulie", "laurent", "", "Technicolor"]]}, {"id": "1206.4854", "submitter": "D\\'aniel Marx", "authors": "Andrei A. Bulatov, D\\'aniel Marx", "title": "Constraint satisfaction parameterized by solution size", "comments": "To appear in SICOMP. Conference version in ICALP 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the constraint satisfaction problem (CSP) corresponding to a constraint\nlanguage (i.e., a set of relations) $\\Gamma$, the goal is to find an assignment\nof values to variables so that a given set of constraints specified by\nrelations from $\\Gamma$ is satisfied. The complexity of this problem has\nreceived substantial amount of attention in the past decade. In this paper we\nstudy the fixed-parameter tractability of constraint satisfaction problems\nparameterized by the size of the solution in the following sense: one of the\npossible values, say 0, is \"free,\" and the number of variables allowed to take\nother, \"expensive,\" values is restricted. A size constraint requires that\nexactly $k$ variables take nonzero values. We also study a more refined version\nof this restriction: a global cardinality constraint prescribes how many\nvariables have to be assigned each particular value. We study the parameterized\ncomplexity of these types of CSPs where the parameter is the required number\n$k$ of nonzero variables. As special cases, we can obtain natural and\nwell-studied parameterized problems such as Independent Set, Vertex Cover,\nd-Hitting Set, Biclique, etc.\n  In the case of constraint languages closed under substitution of constants,\nwe give a complete characterization of the fixed-parameter tractable cases of\nCSPs with size constraints, and we show that all the remaining problems are\nW[1]-hard. For CSPs with cardinality constraints, we obtain a similar\nclassification, but for some of the problems we are only able to show that they\nare Biclique-hard. The exact parameterized complexity of the Biclique problem\nis a notorious open problem, although it is believed to be W[1]-hard.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 12:35:28 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2014 20:59:09 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Bulatov", "Andrei A.", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1206.4898", "submitter": "Yury Makarychev", "authors": "Yury Makarychev and Anastasios Sidiropoulos", "title": "Planarizing an Unknown Surface", "comments": "The conference version of this paper will appear in the Proceedings\n  of APPROX 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been recently shown that any graph of genus g>0 can be stochastically\nembedded into a distribution over planar graphs, with distortion Olog (g+1))\n[Sidiropoulos, FOCS 2010]. This embedding can be computed in polynomial time,\nprovided that a drawing of the input graph into a genus-g surface is given.\n  We show how to compute the above embedding without having such a drawing.\nThis implies a general reduction for solving problems on graphs of small genus,\neven when the drawing into a small genus surface is unknown. To the best of our\nknowledge, this is the first result of this type.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 14:38:30 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Makarychev", "Yury", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1206.4912", "submitter": "Bart M. P. Jansen", "authors": "Fedor V. Fomin and Bart M. P. Jansen and Michal Pilipczuk", "title": "Preprocessing Subgraph and Minor Problems: When Does a Small Vertex\n  Cover Help?", "comments": "To appear in the Journal of Computer and System Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a number of results around kernelization of problems parameterized\nby the size of a given vertex cover of the input graph. We provide three sets\nof simple general conditions characterizing problems admitting kernels of\npolynomial size. Our characterizations not only give generic explanations for\nthe existence of many known polynomial kernels for problems like q-Coloring,\nOdd Cycle Transversal, Chordal Deletion, Eta Transversal, or Long Path,\nparameterized by the size of a vertex cover, but also imply new polynomial\nkernels for problems like F-Minor-Free Deletion, which is to delete at most k\nvertices to obtain a graph with no minor from a fixed finite set F.\n  While our characterization captures many interesting problems, the\nkernelization complexity landscape of parameterizations by vertex cover is much\nmore involved. We demonstrate this by several results about induced subgraph\nand minor containment testing, which we find surprising. While it was known\nthat testing for an induced complete subgraph has no polynomial kernel unless\nNP is in coNP/poly, we show that the problem of testing if a graph contains a\ncomplete graph on t vertices as a minor admits a polynomial kernel. On the\nother hand, it was known that testing for a path on t vertices as a minor\nadmits a polynomial kernel, but we show that testing for containment of an\ninduced path on t vertices is unlikely to admit a polynomial kernel.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 15:19:54 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2013 11:53:46 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2013 12:16:57 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Jansen", "Bart M. P.", ""], ["Pilipczuk", "Michal", ""]]}, {"id": "1206.5253", "submitter": "Allen Chang", "authors": "Allen Chang, Eyal Amir", "title": "Reachability Under Uncertainty", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-41-48", "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new network reachability problem where the goal\nis to find the most reliable path between two nodes in a network, represented\nas a directed acyclic graph. Individual edges within this network may fail\naccording to certain probabilities, and these failure probabilities may depend\non the values of one or more hidden variables. This problem may be viewed as a\ngeneralization of shortest-path problems for finding minimum cost paths or\nViterbi-type problems for finding highest-probability sequences of states,\nwhere the addition of the hidden variables introduces correlations that are not\nhandled by previous algorithms. We give theoretical results characterizing this\nproblem including an NP-hardness proof. We also give an exact algorithm and a\nmore efficient approximation algorithm for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:57:25 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Chang", "Allen", ""], ["Amir", "Eyal", ""]]}, {"id": "1206.5259", "submitter": "Purnamrita Sarkar", "authors": "Purnamrita Sarkar, Andrew Moore", "title": "A Tractable Approach to Finding Closest Truncated-commute-time Neighbors\n  in Large Graphs", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-335-343", "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been much interest in graph-based learning, with\napplications in collaborative filtering for recommender networks, link\nprediction for social networks and fraud detection. These networks can consist\nof millions of entities, and so it is very important to develop highly\nefficient techniques. We are especially interested in accelerating random walk\napproaches to compute some very interesting proximity measures of these kinds\nof graphs. These measures have been shown to do well empirically (Liben-Nowell\n& Kleinberg, 2003; Brand, 2005). We introduce a truncated variation on a\nwell-known measure, namely commute times arising from random walks on graphs.\nWe present a very novel algorithm to compute all interesting pairs of\napproximate nearest neighbors in truncated commute times, without computing it\nbetween all pairs. We show results on both simulated and real graphs of size up\nto 100; 000 entities, which indicate near-linear scaling in computation time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:00:16 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Sarkar", "Purnamrita", ""], ["Moore", "Andrew", ""]]}, {"id": "1206.5335", "submitter": "Sayandeep Khan", "authors": "Sayandeep Khan", "title": "The McDougal Cave and Counting issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.GM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper I investigate the problem of tagging elements of a set, and the\nelements of those elements, uniquely, when they admit an order, and two\nboundary elements are tagged. A heuristic sorting algorithm is also\ninvestigated. (Updated grammar and spellings.)\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 22:42:22 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2012 19:49:14 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Khan", "Sayandeep", ""]]}, {"id": "1206.5336", "submitter": "J\\'er\\'emy Barbay", "authors": "J\\'er\\'emy Barbay and Ankur Gupta and S. Srinivasa Rao and Jonathan\n  Sorenson", "title": "Near-Optimal Online Multiselection in Internal and External Memory", "comments": null, "journal-ref": null, "doi": "10.1016/j.jda.2015.11.001", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online version of the multiselection problem, in which q\nselection queries are requested on an unsorted array of n elements. We provide\nthe first online algorithm that is 1-competitive with Kaligosi et al. [ICALP\n2005] in terms of comparison complexity. Our algorithm also supports online\nsearch queries efficiently.\n  We then extend our algorithm to the dynamic setting, while retaining online\nfunctionality, by supporting arbitrary insertions and deletions on the array.\nAssuming that the insertion of an element is immediately preceded by a search\nfor that element, we show that our dynamic online algorithm performs an optimal\nnumber of comparisons, up to lower order terms and an additive O(n) term.\n  For the external memory model, we describe the first online multiselection\nalgorithm that is O(1)-competitive. This result improves upon the work of\nSibeyn [Journal of Algorithms 2006] when q > m, where m is the number of blocks\nthat can be stored in main memory. We also extend it to support searches,\ninsertions, and deletions of elements efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 22:53:21 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2012 01:54:36 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2013 15:45:44 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["Gupta", "Ankur", ""], ["Rao", "S. Srinivasa", ""], ["Sorenson", "Jonathan", ""]]}, {"id": "1206.5343", "submitter": "Behrouz Touri", "authors": "Farzad Farnoud (Hassanzadeh) and Behrouz Touri and Olgica Milenkovic", "title": "Nonuniform Vote Aggregation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of non-uniform vote aggregation, and in particular,\nthe algorithmic aspects associated with the aggregation process. For a novel\nclass of weighted distance measures on votes, we present two different\naggregation methods. The first algorithm is based on approximating the weighted\ndistance measure by Spearman's footrule distance, with provable constant\napproximation guarantees. The second algorithm is based on a non-uniform Markov\nchain method inspired by PageRank, for which currently only heuristic\nguarantees are known. We illustrate the performance of the proposed algorithms\non a number of distance measures for which the optimal solution may be easily\ncomputed.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 00:14:04 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Farnoud", "Farzad", "", "Hassanzadeh"], ["Touri", "Behrouz", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1206.5349", "submitter": "Rong Ge", "authors": "Sanjeev Arora, Rong Ge, Ankur Moitra, Sushant Sachdeva", "title": "Provable ICA with Unknown Gaussian Noise, and Implications for Gaussian\n  Mixtures and Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for Independent Component Analysis (ICA) which has\nprovable performance guarantees. In particular, suppose we are given samples of\nthe form $y = Ax + \\eta$ where $A$ is an unknown $n \\times n$ matrix and $x$ is\na random variable whose components are independent and have a fourth moment\nstrictly less than that of a standard Gaussian random variable and $\\eta$ is an\n$n$-dimensional Gaussian random variable with unknown covariance $\\Sigma$: We\ngive an algorithm that provable recovers $A$ and $\\Sigma$ up to an additive\n$\\epsilon$ and whose running time and sample complexity are polynomial in $n$\nand $1 / \\epsilon$. To accomplish this, we introduce a novel \"quasi-whitening\"\nstep that may be useful in other contexts in which the covariance of Gaussian\nnoise is not known in advance. We also give a general framework for finding all\nlocal optima of a function (given an oracle for approximately finding just one)\nand this is a crucial step in our algorithm, one that has been overlooked in\nprevious attempts, and allows us to control the accumulation of error when we\nfind the columns of $A$ one by one via local search.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 01:33:37 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2012 01:42:37 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Moitra", "Ankur", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1206.5392", "submitter": "Ashish Chiplunkar", "authors": "Ashish Chiplunkar, Sundar Vishwanathan", "title": "Metrical Service Systems with Multiple Servers", "comments": "18 pages; accepted for publication at COCOON 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of metrical service systems with multiple servers\n(MSSMS), which generalizes two well-known problems -- the $k$-server problem,\nand metrical service systems. The MSSMS problem is to service requests, each of\nwhich is an $l$-point subset of a metric space, using $k$ servers, with the\nobjective of minimizing the total distance traveled by the servers.\n  Feuerstein initiated a study of this problem by proving upper and lower\nbounds on the deterministic competitive ratio for uniform metric spaces. We\nimprove Feuerstein's analysis of the upper bound and prove that his algorithm\nachieves a competitive ratio of $k({{k+l}\\choose{l}}-1)$. In the randomized\nonline setting, for uniform metric spaces, we give an algorithm which achieves\na competitive ratio $\\mathcal{O}(k^3\\log l)$, beating the deterministic lower\nbound of ${{k+l}\\choose{l}}-1$. We prove that any randomized algorithm for\nMSSMS on uniform metric spaces must be $\\Omega(\\log kl)$-competitive. We then\nprove an improved lower bound of ${{k+2l-1}\\choose{k}}-{{k+l-1}\\choose{k}}$ on\nthe competitive ratio of any deterministic algorithm for $(k,l)$-MSSMS, on\ngeneral metric spaces. In the offline setting, we give a pseudo-approximation\nalgorithm for $(k,l)$-MSSMS on general metric spaces, which achieves an\napproximation ratio of $l$ using $kl$ servers. We also prove a matching\nhardness result, that a pseudo-approximation with less than $kl$ servers is\nunlikely, even for uniform metric spaces. For general metric spaces, we\nhighlight the limitations of a few popular techniques, that have been used in\nalgorithm design for the $k$-server problem and metrical service systems.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 13:21:29 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 15:45:22 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Chiplunkar", "Ashish", ""], ["Vishwanathan", "Sundar", ""]]}, {"id": "1206.5725", "submitter": "Jelani Nelson", "authors": "Jelani Nelson and Huy Nguyen and David P. Woodruff", "title": "On Deterministic Sketching and Streaming for Sparse Recovery and Norm\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study classic streaming and sparse recovery problems using deterministic\nlinear sketches, including l1/l1 and linf/l1 sparse recovery problems (the\nlatter also being known as l1-heavy hitters), norm estimation, and approximate\ninner product. We focus on devising a fixed matrix A in R^{m x n} and a\ndeterministic recovery/estimation procedure which work for all possible input\nvectors simultaneously. Our results improve upon existing work, the following\nbeing our main contributions:\n  * A proof that linf/l1 sparse recovery and inner product estimation are\nequivalent, and that incoherent matrices can be used to solve both problems.\nOur upper bound for the number of measurements is m=O(eps^{-2}*min{log n, (log\nn / log(1/eps))^2}). We can also obtain fast sketching and recovery algorithms\nby making use of the Fast Johnson-Lindenstrauss transform. Both our running\ntimes and number of measurements improve upon previous work. We can also obtain\nbetter error guarantees than previous work in terms of a smaller tail of the\ninput vector.\n  * A new lower bound for the number of linear measurements required to solve\nl1/l1 sparse recovery. We show Omega(k/eps^2 + klog(n/k)/eps) measurements are\nrequired to recover an x' with |x - x'|_1 <= (1+eps)|x_{tail(k)}|_1, where\nx_{tail(k)} is x projected onto all but its largest k coordinates in magnitude.\n  * A tight bound of m = Theta(eps^{-2}log(eps^2 n)) on the number of\nmeasurements required to solve deterministic norm estimation, i.e., to recover\n|x|_2 +/- eps|x|_1.\n  For all the problems we study, tight bounds are already known for the\nrandomized complexity from previous work, except in the case of l1/l1 sparse\nrecovery, where a nearly tight bound is known. Our work thus aims to study the\ndeterministic complexities of these problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 16:10:55 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Nelson", "Jelani", ""], ["Nguyen", "Huy", ""], ["Woodruff", "David P.", ""]]}, {"id": "1206.5941", "submitter": "Stefan Kratsch", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Kernelization Lower Bounds By Cross-Composition", "comments": "A preliminary version appeared in the proceedings of the 28th\n  International Symposium on Theoretical Aspects of Computer Science (STACS\n  2011) under the title \"Cross-Composition: A New Technique for Kernelization\n  Lower Bounds\". Several results have been strengthened compared to the\n  preliminary version (http://arxiv.org/abs/1011.4224). 29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the cross-composition framework for proving kernelization lower\nbounds. A classical problem L AND/OR-cross-composes into a parameterized\nproblem Q if it is possible to efficiently construct an instance of Q with\npolynomially bounded parameter value that expresses the logical AND or OR of a\nsequence of instances of L. Building on work by Bodlaender et al. (ICALP 2008)\nand using a result by Fortnow and Santhanam (STOC 2008) with a refinement by\nDell and van Melkebeek (STOC 2010), we show that if an NP-hard problem\nOR-cross-composes into a parameterized problem Q then Q does not admit a\npolynomial kernel unless NP \\subseteq coNP/poly and the polynomial hierarchy\ncollapses. Similarly, an AND-cross-composition for Q rules out polynomial\nkernels for Q under Bodlaender et al.'s AND-distillation conjecture.\n  Our technique generalizes and strengthens the recent techniques of using\ncomposition algorithms and of transferring the lower bounds via polynomial\nparameter transformations. We show its applicability by proving kernelization\nlower bounds for a number of important graphs problems with structural\n(non-standard) parameterizations, e.g., Clique, Chromatic Number, Weighted\nFeedback Vertex Set, and Weighted Odd Cycle Transversal do not admit polynomial\nkernels with respect to the vertex cover number of the input graphs unless the\npolynomial hierarchy collapses, contrasting the fact that these problems are\ntrivially fixed-parameter tractable for this parameter.\n  After learning of our results, several teams of authors have successfully\napplied the cross-composition framework to different parameterized problems.\nFor completeness, our presentation of the framework includes several extensions\nbased on this follow-up work. For example, we show how a relaxed version of\nOR-cross-compositions may be used to give lower bounds on the degree of the\npolynomial in the kernel size.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 10:06:37 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1206.5959", "submitter": "David Adjiashvili", "authors": "David Adjiashvili and Marco Senatore", "title": "The Online Replacement Path Problem", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a natural online variant of the replacement path problem. The\n\\textit{replacement path problem} asks to find for a given graph $G = (V,E)$,\ntwo designated vertices $s,t\\in V$ and a shortest $s$-$t$ path $P$ in $G$, a\n\\textit{replacement path} $P_e$ for every edge $e$ on the path $P$. The\nreplacement path $P_e$ is simply a shortest $s$-$t$ path in the graph, which\navoids the \\textit{failed} edge $e$. We adapt this problem to deal with the\nnatural scenario, that the edge which failed is not known at the time of\nsolution implementation. Instead, our problem assumes that the identity of the\nfailed edge only becomes available when the routing mechanism tries to cross\nthe edge. This situation is motivated by applications in distributed networks,\nwhere information about recent changes in the network is only stored locally,\nand fault-tolerant optimization, where an adversary tries to delay the\ndiscovery of the materialized scenario as much as possible. Consequently, we\ndefine the \\textit{online replacement path problem}, which asks to find a\nnominal $s$-$t$ path $Q$ and detours $Q_e$ for every edge on the path $Q$, such\nthat the worst-case arrival time at the destination is minimized. Our main\ncontribution is a label setting algorithm, which solves the problem in\nundirected graphs in time $O(m \\log n)$ and linear space for all sources and a\nsingle destination. We also present algorithms for extensions of the model to\nany bounded number of failed edges.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 11:38:44 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Adjiashvili", "David", ""], ["Senatore", "Marco", ""]]}, {"id": "1206.6185", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Shiba Prasad Dash, Burle Sharma, Sangita Patel", "title": "Performance Evaluation of A Proposed Variant of Frequency Count (VFC)\n  List Accessing Algorithm", "comments": "4 pages, Proceedings of International Conference on Recent Advances\n  in Engineering and Technology, Hyderabad, India, April, 2012", "journal-ref": "International Journal of Systems, Algorithms and Applications, may\n  2012", "doi": null, "report-no": "Special Issue, May 2012", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency Count (FC) algorithm is considered as the static optimal algorithm\nfor the list accessing problem. In this paper, we have made a study of FC\nalgorithm and explore its limitation. Using the concept of weak look ahead, we\nhave proposed a novel Variant of Frequency Count (VFC) list accessing\nalgorithm. We have evaluated the performance of FC and our proposed VFC\nalgorithm experimentally using input data set from Calgary Corpus. Our\nexperiments show that for all request sequences and list generated from the\nabove data set VFC performs better than FC.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 07:00:10 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Dash", "Shiba Prasad", ""], ["Sharma", "Burle", ""], ["Patel", "Sangita", ""]]}, {"id": "1206.6187", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Sangita Patel, Shiba Prasad Dash, Burle Sharma", "title": "Some Novel Results From Analysis of Move To Front (MTF) List Accessing\n  Algorithm", "comments": "5 pages, Proceedings of the International Conference on Recent\n  Advances in Engineering and Technology, ICRAET, Hyderabad, India, April 2012", "journal-ref": "International Journal of Systems, Algorithms and Applications, May\n  2012", "doi": null, "report-no": "Special Issue, May 15, 2012", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  List accessing problem has been studied as a problem of significant\ntheoretical and practical interest in the context of linear search. Various\nlist accessing algorithms have been proposed in the literature and their\nperformances have been analyzed theoretically and experimentally.\nMove-To-Front(MTF),Transpose (TRANS) and Frequency Count (FC) are the three\nprimitive and widely used list accessing algorithms. Most of the other list\naccessing algorithms are the variants of these three algorithms. As mentioned\nin the literature as an open problem, direct bounds on the behavior and\nperformance of these list accessing algorithms are needed to allow realistic\ncomparisons. MTF has been proved to be the best performing online algorithm\ntill date in the literature for real life inputs with locality of reference.\nMotivated by the above challenging research issue, in this paper, we have\ngenerated four types of input request sequences corresponding to real life\ninputs without locality of reference. Using these types of request sequences,\nwe have made an analytical study for evaluating the performance of MTF list\naccessing algorithm to obtain some novel and interesting theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 07:13:16 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Patel", "Sangita", ""], ["Dash", "Shiba Prasad", ""], ["Sharma", "Burle", ""]]}, {"id": "1206.6193", "submitter": "Wolfgang Mulzer", "authors": "Bernard Chazelle, Wolfgang Mulzer", "title": "Data Structures on Event Graphs", "comments": "15 pages, 7 figures, a preliminary version appeared in Proc. 20th ESA", "journal-ref": "Algorithmica, 71(4), 2015, pp. 1007-1020", "doi": "10.1007/s00453-013-9838-4", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of data structures when the input and operations\nare generated by an event graph. This model is inspired by Markov chains. We\nare given a fixed graph G, whose nodes are annotated with operations of the\ntype insert, delete and query. The algorithm responds to the requests as it\nencounters them during a (random or adversarial) walk in G. We study the limit\nbehavior of such a walk and give an efficient algorithm for recognizing which\nstructures can be generated. We also give a near-optimal algorithm for\nsuccessor searching if the event graph is a cycle and the walk is adversarial.\nFor a random walk, the algorithm becomes optimal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 07:26:07 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2013 22:30:44 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Chazelle", "Bernard", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "1206.6202", "submitter": "Yushi Uno", "authors": "Takeaki Uno and Yushi Uno", "title": "Mining Preserving Structures in a Graph Sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent research of data mining, frequent structures in a sequence of\ngraphs have been studied intensively, and one of the main concern is changing\nstructures along a sequence of graphs that can capture dynamic properties of\ndata. On the contrary, we newly focus on \"preserving structures\" in a graph\nsequence that satisfy a given property for a certain period, and mining such\nstructures is studied. As for an onset, we bring up two structures, a connected\nvertex subset and a clique that exist for a certain period. We consider the\nproblem of enumerating these structures. and present polynomial delay\nalgorithms for the problems. Their running time may depend on the size of the\nrepresentation, however, if each edge has at most one time interval in the\nrepresentation, the running time is O(|V||E|^3) for connected vertex subsets\nand O(min{\\Delta^5, |E|^2\\Delta}) for cliques, where the input graph is G =\n(V,E) with maximum degree \\Delta. To the best of our knowledge, this is the\nfirst approach to the treatment of this notion, namely, preserving structures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 08:32:56 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Uno", "Takeaki", ""], ["Uno", "Yushi", ""]]}, {"id": "1206.6474", "submitter": "Pierre-Andre Savalle", "authors": "Emile Richard (ENS Cachan), Pierre-Andre Savalle (Ecole Centrale de\n  Paris), Nicolas Vayatis (ENS Cachan)", "title": "Estimation of Simultaneously Sparse and Low Rank Matrices", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a penalized matrix estimation procedure aiming at\nsolutions which are sparse and low-rank at the same time. Such structures arise\nin the context of social networks or protein interactions where underlying\ngraphs have adjacency matrices which are block-diagonal in the appropriate\nbasis. We introduce a convex mixed penalty which involves $\\ell_1$-norm and\ntrace norm simultaneously. We obtain an oracle inequality which indicates how\nthe two effects interact according to the nature of the target matrix. We bound\ngeneralization error in the link prediction problem. We also develop proximal\ndescent strategies to solve the optimization problem efficiently and evaluate\nperformance on synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Richard", "Emile", "", "ENS Cachan"], ["Savalle", "Pierre-Andre", "", "Ecole Centrale de\n  Paris"], ["Vayatis", "Nicolas", "", "ENS Cachan"]]}, {"id": "1206.6825", "submitter": "Chris Bartels", "authors": "Chris Bartels, Jeff A. Bilmes", "title": "Non-Minimal Triangulations for Mixed Stochastic/Deterministic Graphical\n  Models", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-15-22", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that certain large-clique graph triangulations can be useful to\nreduce both computational and space requirements when making queries on mixed\nstochastic/deterministic graphical models. We demonstrate that many of these\nlarge-clique triangulations are non-minimal and are thus unattainable via the\nvariable elimination algorithm. We introduce ancestral pairs as the basis for\nnovel triangulation heuristics and prove that no more than the addition of\nedges between ancestral pairs need be considered when searching for state space\noptimal triangulations in such graphs. Empirical results on random and real\nworld graphs show that the resulting triangulations that yield significant\nspeedups are almost always non-minimal. We also give an algorithm and\ncorrectness proof for determining if a triangulation can be obtained via\nelimination, and we show that the decision problem associated with finding\noptimal state space triangulations in this mixed stochastic/deterministic\nsetting is NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:41:21 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Bartels", "Chris", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1206.6899", "submitter": "Antoine Thomas", "authors": "Antoine Thomas, A\\\"ida Ouangraoua, Jean-St\\'ephane Varr\\'e", "title": "Tandem halving problems by DCJ", "comments": "This paper has been withdrawn by the author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by the author.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 20:43:14 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2012 00:14:04 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Thomas", "Antoine", ""], ["Ouangraoua", "A\u00efda", ""], ["Varr\u00e9", "Jean-St\u00e9phane", ""]]}, {"id": "1206.6940", "submitter": "Bjarke Hammersholt Roune", "authors": "Bjarke Hammersholt Roune and Michael Stillman", "title": "Practical Groebner Basis Computation", "comments": "Full online version including appendices, 17 pages; Proceedings of\n  the International Symposium on Symbolic and Algebraic Computation (ISSAC)\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experiences exploring state of the art Groebner basis\ncomputation. We investigate signature based algorithms in detail. We also\nintroduce new practical data structures and computational techniques for use in\nboth signature based Groebner basis algorithms and more traditional variations\nof the classic Buchberger algorithm. Our conclusions are based on experiments\nusing our new freely available open source standalone C++ library.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 05:15:19 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Roune", "Bjarke Hammersholt", ""], ["Stillman", "Michael", ""]]}, {"id": "1206.6982", "submitter": "Yakov Nekrich", "authors": "Gonzalo Navarro, Yakov Nekrich", "title": "Optimal Dynamic Sequence Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a data structure that supports access, rank and select queries,\nas well as symbol insertions and deletions, on a string $S[1,n]$ over alphabet\n$[1..\\sigma]$ in time $O(\\lg n/\\lg\\lg n)$, which is optimal even on binary\nsequences and in the amortized sense. Our time is worst-case for the queries\nand amortized for the updates. This complexity is better than the best previous\nones by a $\\Theta(1+\\lg\\sigma/\\lg\\lg n)$ factor. We also design a variant where\ntimes are worst-case, yet rank and updates take $O(\\lg n)$ time. Our structure\nuses $nH_0(S)+o(n\\lg\\sigma) + O(\\sigma\\lg n)$ bits, where $H_0(S)$ is the\nzero-order entropy of $S$. Finally, we pursue various extensions and\napplications of the result.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 10:43:34 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 16:15:43 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Navarro", "Gonzalo", ""], ["Nekrich", "Yakov", ""]]}, {"id": "1206.7105", "submitter": "Erik Jan van Leeuwen", "authors": "Danny Hermelin and Matthias Mnich and Erik Jan van Leeuwen", "title": "Parameterized Complexity of Induced Graph Matching on Claw-Free Graphs", "comments": "Conference version appeared in ESA 2012. This version is a\n  substantial revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Induced Graph Matching problem asks to find k disjoint induced subgraphs\nisomorphic to a given graph H in a given graph G such that there are no edges\nbetween vertices of different subgraphs. This problem generalizes the classical\nIndependent Set and Induced Matching problems, among several other problems. We\nshow that Induced Graph Matching is fixed-parameter tractable in k on claw-free\ngraphs when H is a fixed connected graph, and even admits a polynomial kernel\nwhen H is a complete graph. Both results rely on a new, strong, and generic\nalgorithmic structure theorem for claw-free graphs.\n  Complementing the above positive results, we prove W[1]-hardness of Induced\nGraph Matching on graphs excluding K_1,4 as an induced subgraph, for any fixed\ncomplete graph H. In particular, we show that Independent Set is W[1]-hard on\nK_1,4-free graphs.\n  Finally, we consider the complexity of Induced Graph Matching on a large\nsubclass of claw-free graphs, namely on proper circular-arc graphs. We show\nthat the problem is either polynomial-time solvable or NP-complete, depending\non the connectivity of H and the structure of G.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 19:09:32 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 13:23:16 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Hermelin", "Danny", ""], ["Mnich", "Matthias", ""], ["van Leeuwen", "Erik Jan", ""]]}]