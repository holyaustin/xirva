[{"id": "1906.00013", "submitter": "Bryan O'Gorman", "authors": "Bryan O'Gorman", "title": "Parameterization of tensor network contraction", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.TQC.2019.10", "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a conceptually clear and algorithmically useful framework for\nparameterizing the costs of tensor network contraction. Our framework is\ncompletely general, applying to tensor networks with arbitrary bond dimensions,\nopen legs, and hyperedges. The fundamental objects of our framework are rooted\nand unrooted contraction trees, which represent classes of contraction orders.\nProperties of a contraction tree correspond directly and precisely to the time\nand space costs of tensor network contraction. The properties of rooted\ncontraction trees give the costs of parallelized contraction algorithms. We\nshow how contraction trees relate to existing tree-like objects in the graph\ntheory literature, bringing to bear a wide range of graph algorithms and tools\nto tensor network contraction. Independent of tensor networks, we show that the\nedge congestion of a graph is almost equal to the branchwidth of its line\ngraph.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:00:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["O'Gorman", "Bryan", ""]]}, {"id": "1906.00074", "submitter": "Federico Cor\\`o", "authors": "Ruben Becker, Federico Cor\\`o, Gianlorenzo D'Angelo, Hugo Gilbert", "title": "Balancing spreads of influence in a social network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personalization of our news consumption on social media has a tendency to\nreinforce our pre-existing beliefs instead of balancing our opinions. This\nfinding is a concern for the health of our democracies which rely on an access\nto information providing diverse viewpoints. To tackle this issue from a\ncomputational perspective, Garimella et al. (NIPS'17) modeled the spread of\nthese viewpoints, also called campaigns, using the well-known independent\ncascade model and studied an optimization problem that aims at balancing\ninformation exposure in a social network when two opposing campaigns propagate\nin the network. The objective in their $NP$-hard optimization problem is to\nmaximize the number of people that are exposed to either both or none of the\nviewpoints. For two different settings, one corresponding to a model where\ncampaigns spread in a correlated manner, and a second one, where the two\ncampaigns spread in a heterogeneous manner, they provide constant ratio\napproximation algorithms. In this paper, we investigate a more general\nformulation of this problem. That is, we assume that $\\mu$ different campaigns\npropagate in a social network and we aim to maximize the number of people that\nare exposed to either $\\nu$ or none of the campaigns, where $\\mu\\ge\\nu\\ge2$. We\nprovide dedicated approximation algorithms for both the correlated and\nheterogeneous settings. Interestingly, for the heterogeneous setting with\n$\\nu\\ge 3$, we give a reduction leading to several approximation hardness\nresults. Maybe most importantly, we obtain that the problem cannot be\napproximated within a factor of $n^{-g(n)}$ for any $g(n)=o(1)$ assuming\nGap-ETH, denoting with $n$ the number of nodes in the social network. For $\\nu\n\\ge 4$, there is no $n^{-\\epsilon}$-approximation algorithm if a certain class\nof one-way functions exists, where $\\epsilon > 0$ is a given constant which\ndepends on $\\nu$.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:46:30 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Becker", "Ruben", ""], ["Cor\u00f2", "Federico", ""], ["D'Angelo", "Gianlorenzo", ""], ["Gilbert", "Hugo", ""]]}, {"id": "1906.00140", "submitter": "Xin Huang", "authors": "Soroush Ebadian, Xin Huang", "title": "Fast Algorithm for K-Truss Discovery on Public-Private Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public-private graphs, users share one public graph and have their own\nprivate graphs. A private graph consists of personal private contacts that only\ncan be visible to its owner, e.g., hidden friend lists on Facebook and secret\nfollowing on Sina Weibo. However, existing public-private analytic algorithms\nhave not yet investigated the dense subgraph discovery of k-truss, where each\nedge is contained in at least k-2 triangles. This paper aims at finding k-truss\nefficiently in public-private graphs. The core of our solution is a novel\nalgorithm to update k-truss with node insertions. We develop a\nclassification-based hybrid strategy of node insertions and edge insertions to\nincrementally compute k-truss in public-private graphs. Extensive experiments\nvalidate the superiority of our proposed algorithms against state-of-the-art\nmethods on real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:31:06 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ebadian", "Soroush", ""], ["Huang", "Xin", ""]]}, {"id": "1906.00211", "submitter": "Boris Landa", "authors": "Boris Landa and Yoel Shkolnisky", "title": "Multi-reference factor analysis: low-rank covariance estimation under\n  unknown translations", "comments": null, "journal-ref": null, "doi": "10.1093/imaiai/iaaa019", "report-no": null, "categories": "math.ST cs.DS cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the covariance matrix of a random\nsignal observed through unknown translations (modeled by cyclic shifts) and\ncorrupted by noise. Solving this problem allows to discover low-rank structures\nmasked by the existence of translations (which act as nuisance parameters),\nwith direct application to Principal Components Analysis (PCA). We assume that\nthe underlying signal is of length $L$ and follows a standard factor model with\nmean zero and $r$ normally-distributed factors. To recover the covariance\nmatrix in this case, we propose to employ the second- and fourth-order\nshift-invariant moments of the signal known as the $\\textit{power spectrum}$\nand the $\\textit{trispectrum}$. We prove that they are sufficient for\nrecovering the covariance matrix (under a certain technical condition) when\n$r<\\sqrt{L}$. Correspondingly, we provide a polynomial-time procedure for\nestimating the covariance matrix from many (translated and noisy) observations,\nwhere no explicit knowledge of $r$ is required, and prove the procedure's\nstatistical consistency. While our results establish that covariance estimation\nis possible from the power spectrum and the trispectrum for low-rank covariance\nmatrices, we prove that this is not the case for full-rank covariance matrices.\nWe conduct numerical experiments that corroborate our theoretical findings, and\ndemonstrate the favorable performance of our algorithms in various settings,\nincluding in high levels of noise.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 12:12:50 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:10:41 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Landa", "Boris", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "1906.00298", "submitter": "Xing Hu", "authors": "Vassos Hadzilacos and Xing Hu and Sam Toueg", "title": "On Atomic Registers and Randomized Consensus in M&M Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent distributed systems technology, Aguilera et al.\nintroduced a hybrid model of distributed computing, called message-and-memory\nmodel or m&m model for short [1]. In this model, processes can communicate by\nmessage passing and also by accessing some shared memory (e.g., through some\nRDMA connections). We first consider the basic problem of implementing an\natomic single-writer multi-reader (SWMR) register shared by all the processes\nin m&m systems. Specifically, we give an algorithm that implements such a\nregister in m&m systems and show that it is optimal in the number of process\ncrashes that it can tolerate. This generalizes the well-known implementation of\nan atomic SWMR register in a pure message-passing system [5]. We then combine\nour register implementation for m&m systems with the well-known randomized\nconsensus algorithm of Aspnes and Herlihy [4], and obtain a randomized\nconsensus algorithm for m&m systems that is also optimal in the number of\nprocess crashes that it can tolerate. Finally, we determine the minimum number\nof RDMA connections that is sufficient to implement a SWMR register, or solve\nrandomized consensus, in an m&m system with t process crashes, for any given t.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:49:56 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 23:15:32 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 18:26:17 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 22:50:59 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hadzilacos", "Vassos", ""], ["Hu", "Xing", ""], ["Toueg", "Sam", ""]]}, {"id": "1906.00339", "submitter": "Tal Wagner", "authors": "Piotr Indyk, Ali Vakilian, Tal Wagner, David Woodruff", "title": "Sample-Optimal Low-Rank Approximation of Distance Matrices", "comments": "COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distance matrix $A \\in \\mathbb R^{n \\times m}$ represents all pairwise\ndistances, $A_{ij}=\\mathrm{d}(x_i,y_j)$, between two point sets $x_1,...,x_n$\nand $y_1,...,y_m$ in an arbitrary metric space $(\\mathcal Z, \\mathrm{d})$. Such\nmatrices arise in various computational contexts such as learning image\nmanifolds, handwriting recognition, and multi-dimensional unfolding.\n  In this work we study algorithms for low-rank approximation of distance\nmatrices. Recent work by Bakshi and Woodruff (NeurIPS 2018) showed it is\npossible to compute a rank-$k$ approximation of a distance matrix in time\n$O((n+m)^{1+\\gamma}) \\cdot \\mathrm{poly}(k,1/\\epsilon)$, where $\\epsilon>0$ is\nan error parameter and $\\gamma>0$ is an arbitrarily small constant. Notably,\ntheir bound is sublinear in the matrix size, which is unachievable for general\nmatrices.\n  We present an algorithm that is both simpler and more efficient. It reads\nonly $O((n+m) k/\\epsilon)$ entries of the input matrix, and has a running time\nof $O(n+m) \\cdot \\mathrm{poly}(k,1/\\epsilon)$. We complement the sample\ncomplexity of our algorithm with a matching lower bound on the number of\nentries that must be read by any algorithm. We provide experimental results to\nvalidate the approximation quality and running time of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 04:15:17 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Indyk", "Piotr", ""], ["Vakilian", "Ali", ""], ["Wagner", "Tal", ""], ["Woodruff", "David", ""]]}, {"id": "1906.00417", "submitter": "Euiwoong Lee", "authors": "Anupam Gupta, Euiwoong Lee, Jason Li", "title": "The Number of Minimum $k$-Cuts: Improving the Karger-Stein Bound", "comments": "30 pages. To appear in STOC '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an edge-weighted graph, how many minimum $k$-cuts can it have? This is\na fundamental question in the intersection of algorithms, extremal\ncombinatorics, and graph theory. It is particularly interesting in that the\nbest known bounds are algorithmic: they stem from algorithms that compute the\nminimum $k$-cut.\n  In 1994, Karger and Stein obtained a randomized contraction algorithm that\nfinds a minimum $k$-cut in $O(n^{(2-o(1))k})$ time. It can also enumerate all\nsuch $k$-cuts in the same running time, establishing a corresponding extremal\nbound of $O(n^{(2-o(1))k})$. Since then, the algorithmic side of the minimum\n$k$-cut problem has seen much progress, leading to a deterministic algorithm\nbased on a tree packing result of Thorup, which enumerates all minimum $k$-cuts\nin the same asymptotic running time, and gives an alternate proof of the\n$O(n^{(2-o(1))k})$ bound. However, beating the Karger--Stein bound, even for\ncomputing a single minimum $k$-cut, has remained out of reach.\n  In this paper, we give an algorithm to enumerate all minimum $k$-cuts in\n$O(n^{(1.981+o(1))k})$ time, breaking the algorithmic and extremal barriers for\nenumerating minimum $k$-cuts. To obtain our result, we combine ideas from both\nthe Karger--Stein and Thorup results, and draw a novel connection between\nminimum $k$-cut and extremal set theory. In particular, we give and use tighter\nbounds on the size of set systems with bounded dual VC-dimension, which may be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:59:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gupta", "Anupam", ""], ["Lee", "Euiwoong", ""], ["Li", "Jason", ""]]}, {"id": "1906.00476", "submitter": "Omar Shehab", "authors": "Omar Shehab, Isaac H. Kim, Nhung H. Nguyen, Kevin Landsman, Cinthia H.\n  Alderete, Daiwei Zhu, C. Monroe, Norbert M. Linke", "title": "Noise reduction using past causal cones in variational quantum\n  algorithms", "comments": "Added data availability statement, additional affiliation and grant\n  acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to improve the accuracy and reduce the sample\ncomplexity of near term quantum-classical algorithms. We construct a simpler\ninitial parameterized quantum state, or ansatz, based on the past causal cone\nof each observable, generally yielding fewer qubits and gates. We implement\nthis protocol on a trapped ion quantum computer and demonstrate improvement in\naccuracy and time-to-solution at an arbitrary point in the variational search\nspace. We report a $\\sim 27\\%$ improvement in the accuracy of the calculation\nof the deuteron binding energy and $\\sim 40\\%$ improvement in the accuracy of\nthe quantum approximate optimization of the MAXCUT problem applied to the\ndragon graph $T_{3,2}$. When the time-to-solution is prioritized over accuracy,\nthe former requires $\\sim 71\\%$ fewer measurements and the latter requires\n$\\sim 78\\%$ fewer measurements.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 20:27:10 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 18:54:32 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 18:16:23 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shehab", "Omar", ""], ["Kim", "Isaac H.", ""], ["Nguyen", "Nhung H.", ""], ["Landsman", "Kevin", ""], ["Alderete", "Cinthia H.", ""], ["Zhu", "Daiwei", ""], ["Monroe", "C.", ""], ["Linke", "Norbert M.", ""]]}, {"id": "1906.00482", "submitter": "Fabian Kuhn", "authors": "Mohsen Ghaffari and Fabian Kuhn", "title": "On the Use of Randomness in Local Distributed Graph Algorithms", "comments": "21 pages, conference version in ACM Symp. on Principles of\n  Distributed Computing (PODC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attempt to better understand randomization in local distributed graph\nalgorithms by exploring how randomness is used and what we can gain from it: -\nWe first ask the question of how much randomness is needed to obtain efficient\nrandomized algorithms. We show that for all locally checkable problems for\nwhich polylog $n$-time randomized algorithms exist, there are such algorithms\neven if either (I) there is a only a single (private) independent random bit in\neach polylog $n$-neighborhood of the graph, (II) the (private) bits of\nrandomness of different nodes are only polylog $n$-wise independent, or (III)\nthere are only polylog $n$ bits of global shared randomness (and no private\nrandomness). - Second, we study how much we can improve the error probability\nof randomized algorithms. For all locally checkable problems for which polylog\n$n$-time randomized algorithms exist, we show that there are such algorithms\nthat succeed with probability $1-n^{-2^{\\varepsilon(\\log\\log n)^2}}$ and more\ngenerally $T$-round algorithms, for $T\\geq$ polylog $n$, that succeed with\nprobability $1-n^{-2^{\\varepsilon\\log^2T}}$. We also show that polylog $n$-time\nrandomized algorithms with success probability $1-2^{-2^{\\log^\\varepsilon n}}$\nfor some $\\varepsilon>0$ can be derandomized to polylog $n$-time deterministic\nalgorithms. Both of the directions mentioned above, reducing the amount of\nrandomness and improving the success probability, can be seen as partial\nderandomization of existing randomized algorithms. In all the above cases, we\nalso show that any significant improvement of our results would lead to a major\nbreakthrough, as it would imply significantly more efficient deterministic\ndistributed algorithms for a wide class of problems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 20:51:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1906.00563", "submitter": "Hideo Bannai", "authors": "Noriki Fujisato, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai,\n  Masayuki Takeda", "title": "Direct Linear Time Construction of Parameterized Suffix and LCP Arrays\n  for Constant Alphabets", "comments": "submitted to SPIRE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first worst-case linear time algorithm that directly computes\nthe parameterized suffix and LCP arrays for constant sized alphabets. Previous\nalgorithms either required quadratic time or the parameterized suffix tree to\nbe built first. More formally, for a string over static alphabet $\\Sigma$ and\nparameterized alphabet $\\Pi$, our algorithm runs in $O(n\\pi)$ time and $O(n)$\nwords of space, where $\\pi$ is the number of distinct symbols of $\\Pi$ in the\nstring.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:17:38 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fujisato", "Noriki", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""]]}, {"id": "1906.00618", "submitter": "Kevin Tian", "authors": "Arun Jambulapati, Aaron Sidford, Kevin Tian", "title": "A Direct $\\tilde{O}(1/\\epsilon)$ Iteration Parallel Algorithm for\n  Optimal Transport", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transportation, or computing the Wasserstein or ``earth mover's''\ndistance between two distributions, is a fundamental primitive which arises in\nmany learning and statistical settings. We give an algorithm which solves this\nproblem to additive $\\epsilon$ with $\\tilde{O}(1/\\epsilon)$ parallel depth, and\n$\\tilde{O}\\left(n^2/\\epsilon\\right)$ work. Barring a breakthrough on a\nlong-standing algorithmic open problem, this is optimal for first-order\nmethods. Blanchet et. al. '18, Quanrud '19 obtained similar runtimes through\nreductions to positive linear programming and matrix scaling. However, these\nreduction-based algorithms use complicated subroutines which may be deemed\nimpractical due to requiring solvers for second-order iterations (matrix\nscaling) or non-parallelizability (positive LP). The fastest practical\nalgorithms run in time $\\tilde{O}(\\min(n^2 / \\epsilon^2, n^{2.5} / \\epsilon))$\n(Dvurechensky et. al. '18, Lin et. al. '19). We bridge this gap by providing a\nparallel, first-order, $\\tilde{O}(1/\\epsilon)$ iteration algorithm without\nworse dependence on dimension, and provide preliminary experimental evidence\nthat our algorithm may enjoy improved practical performance. We obtain this\nruntime via a primal-dual extragradient method, motivated by recent theoretical\nimprovements to maximum flow (Sherman '17).\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:58:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jambulapati", "Arun", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "1906.00809", "submitter": "Travis Gagie", "authors": "Travis Gagie, Tomohiro I, Giovanni Manzini, Gonzalo Navarro, Hiroshi\n  Sakamoto and Yoshimasa Takabatake", "title": "Rpair: Rescaling RePair with Rsync", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data compression is a powerful tool for managing massive but repetitive\ndatasets, especially schemes such as grammar-based compression that support\ncomputation over the data without decompressing it. In the best case such a\nscheme takes a dataset so big that it must be stored on disk and shrinks it\nenough that it can be stored and processed in internal memory. Even then,\nhowever, the scheme is essentially useless unless it can be built on the\noriginal dataset reasonably quickly while keeping the dataset on disk. In this\npaper we show how we can preprocess such datasets with context-triggered\npiecewise hashing such that afterwards we can apply RePair and other\ngrammar-based compressors more easily. We first give our algorithm, then show\nhow a variant of it can be used to approximate the LZ77 parse, then leverage\nthat to prove theoretical bounds on compression, and finally give experimental\nevidence that our approach is competitive in practice.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:45:43 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gagie", "Travis", ""], ["I", "Tomohiro", ""], ["Manzini", "Giovanni", ""], ["Navarro", "Gonzalo", ""], ["Sakamoto", "Hiroshi", ""], ["Takabatake", "Yoshimasa", ""]]}, {"id": "1906.01050", "submitter": "Edoardo Galimberti", "authors": "Edoardo Galimberti", "title": "Cores and Other Dense Structures in Complex Networks", "comments": "arXiv admin note: text overlap with arXiv:1812.08712", "journal-ref": "WWW '19 Companion, May 13-17, 2019, San Francisco, CA, USA", "doi": "10.1145/3308560.3314190", "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are a powerful paradigm to model complex systems. Specific\nnetwork models, e.g., multilayer networks, temporal networks, and signed\nnetworks, enrich the standard network representation with additional\ninformation to better capture real-world phenomena. Despite the keen interest\nin a variety of problems, algorithms, and analysis methods for these types of\nnetwork, the problem of extracting cores and dense structures still has\nunexplored facets. In this work, we present advancements to the state of the\nart by the introduction of novel definitions and algorithms for the extraction\nof dense structures from complex networks, mainly cores. At first, we define\ncore decomposition in multilayer networks together with a series of\napplications built on top of it, i.e., the extraction of maximal multilayer\ncores only, densest subgraph in multilayer networks, the speed-up of the\nextraction of frequent cross-graph quasi-cliques, and the generalization of\ncommunity search to the multilayer setting. Then, we introduce the concept of\ncore decomposition in temporal networks; also in this case, we are interested\nin the extraction of maximal temporal cores only. Finally, in the context of\ndiscovering polarization in large-scale online data, we study the problem of\nidentifying polarized communities in signed networks. The proposed\nmethodologies are evaluated on a large variety of real-world networks against\nna\\\"{\\i}ve approaches, non-trivial baselines, and competing methods. In all\ncases, they show effectiveness, efficiency, and scalability. Moreover, we\nshowcase the usefulness of our definitions in concrete applications and case\nstudies, i.e., the temporal analysis of contact networks, and the\nidentification of polarization in debate networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:56:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Galimberti", "Edoardo", ""]]}, {"id": "1906.01056", "submitter": "Asish Mukhopadhyay", "authors": "Md. Zamilur Rahman, Asish Mukhopadhyay and Yash P. Aneja", "title": "A separator-based method for generating weakly chordal graphs", "comments": "14 pages and 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for generating a weakly chordal graph on n vertices with\nm edges. In this method, we first construct a tree and then generate an\northogonal layout (which is a weakly chordal graph on the n vertices) based on\nthis tree. In the next and final step, we insert additional edges to give us a\nweakly chordal graph on m edges. Our algorithm ensures that the graph remains\nweakly chordal after each edge is inserted. The time complexity of an insertion\nquery is O(n^3) time and an insertion takes constant time. On the other hand, a\ngeneration algorithm based on finding a 2-pair takes O(nm) time using the\nalgorithm of Arikati and Rangan [1].\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:11:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Rahman", "Md. Zamilur", ""], ["Mukhopadhyay", "Asish", ""], ["Aneja", "Yash P.", ""]]}, {"id": "1906.01114", "submitter": "Darren Strash", "authors": "Hee-Kap Ahn, Eunjin Oh, Lena Schlipf, Fabian Stehn, Darren Strash", "title": "On Romeo and Juliet Problems: Minimizing Distance-to-Sight", "comments": "12 pages, 8 figures; appeared in Proc. 16th Scandinavian Symposium\n  and Workshops on Algorithm Theory (SWAT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the watchman route problem, which we call the\nquickest pair-visibility problem. Given two persons standing at points $s$ and\n$t$ in a simple polygon $P$ with no holes, we want to minimize the distance\nthey travel in order to see each other in $P$. We solve two variants of this\nproblem, one minimizing the longer distance the two persons travel (min-max)\nand one minimizing the total travel distance (min-sum), optimally in linear\ntime. We also consider a query version of this problem for the min-max variant.\nWe can preprocess a simple $n$-gon in linear time so that the minimum of the\nlonger distance the two persons travel can be computed in $O(\\log^2 n)$ time\nfor any two query positions $s,t$ where the two persons start.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:47:57 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ahn", "Hee-Kap", ""], ["Oh", "Eunjin", ""], ["Schlipf", "Lena", ""], ["Stehn", "Fabian", ""], ["Strash", "Darren", ""]]}, {"id": "1906.01228", "submitter": "Piyush Srivastava", "authors": "Jingcheng Liu and Alistair Sinclair and Piyush Srivastava", "title": "Correlation decay and partition function zeros: Algorithms and phase\n  transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore connections between the phenomenon of correlation decay and the\nlocation of Lee-Yang and Fisher zeros for various spin systems. In particular\nwe show that, in many instances, proofs showing that weak spatial mixing on the\nBethe lattice (infinite $\\Delta$-regular tree) implies strong spatial mixing on\nall graphs of maximum degree $\\Delta$ can be lifted to the complex plane,\nestablishing the absence of zeros of the associated partition function in a\ncomplex neighborhood of the region in parameter space corresponding to strong\nspatial mixing. This allows us to give unified proofs of several recent results\nof this kind, including the resolution by Peters and Regts of the Sokal\nconjecture for the partition function of the hard core lattice gas. It also\nallows us to prove new results on the location of Lee-Yang zeros of the\nanti-ferromagnetic Ising model.\n  We show further that our methods extend to the case when weak spatial mixing\non the Bethe lattice is not known to be equivalent to strong spatial mixing on\nall graphs. In particular, we show that results on strong spatial mixing in the\nanti-ferromagnetic Potts model can be lifted to the complex plane to give new\nzero-freeness results for the associated partition function. This extension\nallows us to give the first deterministic FPTAS for counting the number of\n$q$-colorings of a graph of maximum degree $\\Delta$ provided only that $q\\ge\n2\\Delta$. This matches the natural bound for randomized algorithms obtained by\na straightforward application of Markov chain Monte Carlo. We also give an\nimproved version of this result for triangle-free graphs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:52:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 16:05:20 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 15:31:51 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 23:28:32 GMT"}, {"version": "v5", "created": "Wed, 9 Dec 2020 19:26:06 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Liu", "Jingcheng", ""], ["Sinclair", "Alistair", ""], ["Srivastava", "Piyush", ""]]}, {"id": "1906.01437", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Michael I. Jordan", "title": "On the Efficiency of the Sinkhorn and Greenkhorn Algorithms and Their\n  Acceleration for Optimal Transport", "comments": "A preliminary version [arXiv:1901.06482] of this paper, with a subset\n  of the results that are presented here, was presented at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new complexity results for several algorithms that approximately\nsolve the regularized optimal transport (OT) problem between two discrete\nprobability measures with at most $n$ atoms. First, we show that a greedy\nvariant of the classical Sinkhorn algorithm, known as the \\textit{Greenkhorn}\nalgorithm, achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$, which improves the best known\nbound $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-3})$. Notably, this matches the\nbest known complexity bound of the Sinkhorn algorithm and explains the superior\nperformance of the Greenkhorn algorithm in practice. Furthermore, we generalize\nan adaptive primal-dual accelerated gradient descent (APDAGD) algorithm with\nmirror mapping $\\phi$ and show that the resulting \\textit{adaptive primal-dual\naccelerated mirror descent} (APDAMD) algorithm achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\sqrt{\\delta}\\varepsilon^{-1})$ where $\\delta>0$\ndepends on $\\phi$. We point out that an existing complexity bound for the\nAPDAGD algorithm is not valid in general using a simple counterexample and then\nestablish the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{5/2}\\varepsilon^{-1})$ by exploiting the connection\nbetween the APDAMD and APDAGD algorithms. Moreover, we introduce accelerated\nSinkhorn and Greenkhorn algorithms that achieve the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{7/3}\\varepsilon^{-1})$, which improves on the\ncomplexity bounds $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$ of Sinkhorn\nand Greenkhorn algorithms in terms of $\\varepsilon$. Experimental results on\nsynthetic and real datasets demonstrate the favorable performance of new\nalgorithms in practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 05:33:05 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 07:16:49 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2019 04:21:58 GMT"}, {"version": "v4", "created": "Sun, 4 Aug 2019 18:15:07 GMT"}, {"version": "v5", "created": "Thu, 17 Oct 2019 23:25:15 GMT"}, {"version": "v6", "created": "Tue, 24 Mar 2020 02:50:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.01666", "submitter": "Will Perkins", "authors": "Sarah Cannon and Will Perkins", "title": "Counting independent sets in unbalanced bipartite graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an FPTAS for approximating the partition function of the hard-core\nmodel for bipartite graphs when there is sufficient imbalance in the degrees or\nfugacities between the sides $(L,R)$ of the bipartition. This includes, among\nothers, the biregular case when $\\lambda=1$ (approximating the number of\nindependent sets of $G$) and $\\Delta_R \\geq 7\\Delta_L \\log(\\Delta_L)$. Our\napproximation algorithm is based on truncating the cluster expansion of a\npolymer model partition function that expresses the hard-core partition\nfunction in terms of deviations from independent sets that are empty on one\nside of the bipartition. As a consequence of the method, we also prove that the\nhard-core model on such graphs exhibits exponential decay of correlations by\nutilizing connections between the cluster expansion and joint cumulants.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:15:50 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Cannon", "Sarah", ""], ["Perkins", "Will", ""]]}, {"id": "1906.01693", "submitter": "Michael Matheny", "authors": "Michael Matheny, Dong Xie, Jeff M. Phillips", "title": "Scalable Spatial Scan Statistics for Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define several new models for how to define anomalous regions among\nenormous sets of trajectories. These are based on spatial scan statistics, and\nidentify a geometric region which captures a subset of trajectories which are\nsignificantly different in a measured characteristic from the background\npopulation. The model definition depends on how much a geometric region is\ncontributed to by some overlapping trajectory. This contribution can be the\nfull trajectory, proportional to the time spent in the spatial region, or\ndependent on the flux across the boundary of that spatial region. Our methods\nare based on and significantly extend a recent two-level sampling approach\nwhich provides high accuracy at enormous scales of data. We support these new\nmodels and algorithms with extensive experiments on millions of trajectories\nand also theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:27:30 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Matheny", "Michael", ""], ["Xie", "Dong", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "1906.01859", "submitter": "Francesco Silvestri", "authors": "Martin Aum\\\"uller and Rasmus Pagh and Francesco Silvestri", "title": "Fair Near Neighbor Search: Independent Range Sampling in High Dimensions", "comments": "Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on\n  Principles of Database Systems (PODS), Pages 191-204, June 2020", "journal-ref": null, "doi": "10.1145/3375395.3387648", "report-no": null, "categories": "cs.DS cs.CG cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is a fundamental algorithmic primitive, widely used in many\ncomputer science disciplines. There are several variants of the similarity\nsearch problem, and one of the most relevant is the $r$-near neighbor ($r$-NN)\nproblem: given a radius $r>0$ and a set of points $S$, construct a data\nstructure that, for any given query point $q$, returns a point $p$ within\ndistance at most $r$ from $q$. In this paper, we study the $r$-NN problem in\nthe light of fairness. We consider fairness in the sense of equal opportunity:\nall points that are within distance $r$ from the query should have the same\nprobability to be returned. In the low-dimensional case, this problem was first\nstudied by Hu, Qiao, and Tao (PODS 2014). Locality sensitive hashing (LSH), the\ntheoretically strongest approach to similarity search in high dimensions, does\nnot provide such a fairness guarantee. To address this, we propose efficient\ndata structures for $r$-NN where all points in $S$ that are near $q$ have the\nsame probability to be selected and returned by the query. Specifically, we\nfirst propose a black-box approach that, given any LSH scheme, constructs a\ndata structure for uniformly sampling points in the neighborhood of a query.\nThen, we develop a data structure for fair similarity search under inner\nproduct that requires nearly-linear space and exploits locality sensitive\nfilters. The paper concludes with an experimental evaluation that highlights\n(un)fairness in a recommendation setting on real-world datasets and discusses\nthe inherent unfairness introduced by solving other variants of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:27:48 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:13:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Pagh", "Rasmus", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1906.01993", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi, MohammadHossein Bateni, Vahab Mirrokni", "title": "Distributed Weighted Matching via Randomized Composable Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum weight matching is one of the most fundamental combinatorial\noptimization problems with a wide range of applications in data mining and\nbioinformatics. Developing distributed weighted matching algorithms is\nchallenging due to the sequential nature of efficient algorithms for this\nproblem. In this paper, we develop a simple distributed algorithm for the\nproblem on general graphs with approximation guarantee of $2+\\varepsilon$ that\n(nearly) matches that of the sequential greedy algorithm. A key advantage of\nthis algorithm is that it can be easily implemented in only two rounds of\ncomputation in modern parallel computation frameworks such as MapReduce. We\nalso demonstrate the efficiency of our algorithm in practice on various graphs\n(some with half a trillion edges) by achieving objective values always close to\nwhat is achievable in the centralized setting.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 12:43:16 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Assadi", "Sepehr", ""], ["Bateni", "MohammadHossein", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1906.02164", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis, Vijay Keswani, Nisheeth K. Vishnoi", "title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data containing human or social attributes may over- or under-represent\ngroups with respect to salient social attributes such as gender or race, which\ncan lead to biases in downstream applications. This paper presents an\nalgorithmic framework that can be used as a data preprocessing method towards\nmitigating such bias. Unlike prior work, it can efficiently learn distributions\nover large domains, controllably adjust the representation rates of protected\ngroups and achieve target fairness metrics such as statistical parity, yet\nremains close to the empirical distribution induced by the given dataset. Our\napproach leverages the principle of maximum entropy - amongst all distributions\nsatisfying a given set of constraints, we should choose the one closest in\nKL-divergence to a given prior. While maximum entropy distributions can\nsuccinctly encode distributions over large domains, they can be difficult to\ncompute. Our main contribution is an instantiation of this framework for our\nset of constraints and priors, which encode our bias mitigation goals, and that\nruns in time polynomial in the dimension of the data. Empirically, we observe\nthat samples from the learned distribution have desired representation rates\nand statistical rates, and when used for training a classifier incurs only a\nslight loss in accuracy while maintaining fairness properties.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:54:00 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:07:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.02229", "submitter": "Pooya Ronagh", "authors": "Pooya Ronagh", "title": "The Problem of Dynamic Programming on a Quantum Computer", "comments": "We were not able to amend the proof of Theorem III.5 of the previous\n  version (v2) of this manuscript. Therefore, we have hereby withdrawn the\n  query complexity upper bound claims that were stated in our earlier\n  submission;", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of finite-horizon dynamic programming (DP) on a\nquantum computer. We introduce a query model for studying quantum and classical\nalgorithms for solving DP problems, and provide example oracle constructions\nfor the travelling salesperson problem, the minimum set-cover problem, and the\nedit distance problem. We formulate open questions regarding quadratic quantum\nspeedups for DP and discuss their implications. We then prove lower bounds for\nthe query complexity of quantum algorithms and classical randomized algorithms\nfor DP, and show that no greater-than-quadratic speedup can be achieved for\nsolving DP problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:12:56 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 17:58:08 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 03:22:19 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ronagh", "Pooya", ""]]}, {"id": "1906.02315", "submitter": "Alan Kuhnle", "authors": "Alan Kuhnle", "title": "A Note on Submodular Maximization over Independence Systems", "comments": "A previous version of this manuscript used an incorrect definition of\n  $p$-system to claim the inapproximability result held for $1$-systems, which\n  was incorrect. The corrected hardness statement is in the Abstract. 8 pages,\n  0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the maximization of submodular functions\nconstrained by independence systems. Because of the wide applicability of\nsubmodular functions, this problem has been extensively studied in the\nliterature, on specialized independence systems. For general independence\nsystems, even when all of the bases of the independence system have the same\nsize, we show that for any $\\epsilon > 0$, the problem is hard to approximate\nwithin $(2/n)^{1-\\epsilon}$, where $n$ is the size of the ground set. In the\nsame context, we show the greedy algorithm does obtain a ratio of $2/n$ under\nan additional mild additional assumption. Finally, we provide the first nearly\nlinear-time algorithm for maximization of non-monotone submodular functions\nover $p$-extendible independence systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 21:20:34 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 20:50:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Kuhnle", "Alan", ""]]}, {"id": "1906.02640", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Sepideh Mahabadi", "title": "Near Neighbor: Who is the Fairest of Them All?", "comments": "To appear in NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\ball}{\\mathbb{B}}\\newcommand{\\dsQ}{{\\mathcal{Q}}}\\newcommand{\\dsS}{{\\mathcal{S}}}$In\nthis work we study a fair variant of the near neighbor problem. Namely, given a\nset of $n$ points $P$ and a parameter $r$, the goal is to preprocess the\npoints, such that given a query point $q$, any point in the $r$-neighborhood of\nthe query, i.e., $\\ball(q,r)$, have the same probability of being reported as\nthe near neighbor.\n  We show that LSH based algorithms can be made fair, without a significant\nloss in efficiency. Specifically, we show an algorithm that reports a point in\nthe $r$-neighborhood of a query $q$ with almost uniform probability. The query\ntime is proportional to $O\\bigl( \\mathrm{dns}(q.r) \\dsQ(n,c) \\bigr)$, and its\nspace is $O(\\dsS(n,c))$, where $\\dsQ(n,c)$ and $\\dsS(n,c)$ are the query time\nand space of an LSH algorithm for $c$-approximate near neighbor, and\n$\\mathrm{dns}(q,r)$ is a function of the local density around $q$.\n  Our approach works more generally for sampling uniformly from a\nsub-collection of sets of a given collection and can be used in a few other\napplications. Finally, we run experiments to show performance of our approach\non real data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:18:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:53:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mahabadi", "Sepideh", ""]]}, {"id": "1906.02830", "submitter": "Thomas Steinke", "authors": "Mark Bun, Thomas Steinke", "title": "Average-Case Averages: Private Algorithms for Smooth Sensitivity and\n  Mean Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simplest and most widely applied method for guaranteeing differential\nprivacy is to add instance-independent noise to a statistic of interest that is\nscaled to its global sensitivity. However, global sensitivity is a worst-case\nnotion that is often too conservative for realized dataset instances. We\nprovide methods for scaling noise in an instance-dependent way and demonstrate\nthat they provide greater accuracy under average-case distributional\nassumptions.\n  Specifically, we consider the basic problem of privately estimating the mean\nof a real distribution from i.i.d.~samples. The standard empirical mean\nestimator can have arbitrarily-high global sensitivity. We propose the trimmed\nmean estimator, which interpolates between the mean and the median, as a way of\nattaining much lower sensitivity on average while losing very little in terms\nof statistical accuracy.\n  To privately estimate the trimmed mean, we revisit the smooth sensitivity\nframework of Nissim, Raskhodnikova, and Smith (STOC 2007), which provides a\nframework for using instance-dependent sensitivity. We propose three new\nadditive noise distributions which provide concentrated differential privacy\nwhen scaled to smooth sensitivity. We provide theoretical and experimental\nevidence showing that our noise distributions compare favorably to others in\nthe literature, in particular, when applied to the mean estimation problem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:55:02 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Bun", "Mark", ""], ["Steinke", "Thomas", ""]]}, {"id": "1906.03113", "submitter": "Paul Burkhardt", "authors": "Paul Burkhardt", "title": "Optimal algebraic Breadth-First Search for sparse graphs", "comments": "Will appear in ACM Transactions on Knowledge Discovery from Data,\n  Vol. 15, No. 5, 2021", "journal-ref": "ACM Transactions on Knowledge Discovery from Data, 15(5):1-19,\n  2021", "doi": "10.1145/3446216", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rise in the popularity of algebraic methods for graph\nalgorithms given the development of the GraphBLAS library and other sparse\nmatrix methods. An exemplar for these approaches is Breadth-First Search (BFS).\nThe algebraic BFS algorithm is simply a recurrence of matrix-vector\nmultiplications with the $n \\times n$ adjacency matrix, but the many redundant\noperations over nonzeros ultimately lead to suboptimal performance. Therefore\nan optimal algebraic BFS should be of keen interest especially if it is easily\nintegrated with existing matrix methods.\n  Current methods, notably in the GraphBLAS, use a Sparse Matrix masked-Sparse\nVector (SpMmSpV) multiplication in which the input vector is kept in a sparse\nrepresentation in each step of the BFS, and nonzeros in the vector are masked\nin subsequent steps. This has been an area of recent research in GraphBLAS and\nother libraries. While in theory these masking methods are asymptotically\noptimal on sparse graphs, many add work that leads to suboptimal runtime. We\ngive a new optimal, algebraic BFS for sparse graphs, thus closing a gap in the\nliterature.\n  Our method multiplies progressively smaller submatrices of the adjacency\nmatrix at each step. Let $n$ and $m$ refer to the number of vertices and edges,\nrespectively. On a sparse graph, our method takes $O(n)$ algebraic operations\nas opposed to $O(m)$ operations needed by theoretically optimal sparse matrix\napproaches. Thus for sparse graphs it matches the bounds of the best-known\nsequential algorithm and on a Parallel Random Access Machine (PRAM) it is\nwork-optimal. Our result holds for both directed and undirected graphs.\nCompared to a leading GraphBLAS library our method achieves up to 24x faster\nsequential time and for parallel computation it can be 17x faster on large\ngraphs and 12x faster on large-diameter graphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:06:23 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 14:43:59 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 19:33:26 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 21:52:38 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Burkhardt", "Paul", ""]]}, {"id": "1906.03242", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Levi H. S. Lelis, Tor Lattimore", "title": "Zooming Cautiously: Linear-Memory Heuristic Search With Node Expansion\n  Guarantees", "comments": "This paper and another independent IJCAI 2019 submission have been\n  merged into a single paper that subsumes both of them (Helmert et. al.,\n  2019). This paper is placed here only for historical context. Please only\n  cite the subsuming paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze two parameter-free linear-memory tree search\nalgorithms. Under mild assumptions we prove our algorithms are guaranteed to\nperform only a logarithmic factor more node expansions than A* when the search\nspace is a tree. Previously, the best guarantee for a linear-memory algorithm\nunder similar assumptions was achieved by IDA*, which in the worst case expands\nquadratically more nodes than in its last iteration. Empirical results support\nthe theory and demonstrate the practicality and robustness of our algorithms.\nFurthermore, they are fast and easy to implement.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:04:16 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Orseau", "Laurent", ""], ["Lelis", "Levi H. S.", ""], ["Lattimore", "Tor", ""]]}, {"id": "1906.03310", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Yizhen Wang, Kamalika Chaudhuri", "title": "Robustness for Non-Parametric Classification: A Generic Attack and\n  Defense", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially robust machine learning has received much recent attention.\nHowever, prior attacks and defenses for non-parametric classifiers have been\ndeveloped in an ad-hoc or classifier-specific basis. In this work, we take a\nholistic look at adversarial examples for non-parametric classifiers, including\nnearest neighbors, decision trees, and random forests. We provide a general\ndefense method, adversarial pruning, that works by preprocessing the dataset to\nbecome well-separated. To test our defense, we provide a novel attack that\napplies to a wide range of non-parametric classifiers. Theoretically, we derive\nan optimally robust classifier, which is analogous to the Bayes Optimal. We\nshow that adversarial pruning can be viewed as a finite sample approximation to\nthis optimal classifier. We empirically show that our defense and attack are\neither better than or competitive with prior work on non-parametric\nclassifiers. Overall, our results provide a strong and broadly-applicable\nbaseline for future work on robust non-parametrics. Code available at\nhttps://github.com/yangarbiter/adversarial-nonparametrics/ .\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:45:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 23:12:27 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Wang", "Yizhen", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1906.03752", "submitter": "S. S. Ravi", "authors": "Daniel J. Rosenkrantz, Madhav V. Marathe, S. S. Ravi and Richard E.\n  Stearns", "title": "Symmetry Properties of Nested Canalyzing Functions", "comments": "17 pages", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 21 no.\n  4, Discrete Algorithms (November 26, 2019) dmtcs:5920", "doi": "10.23638/DMTCS-21-4-19", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers have studied symmetry properties of various Boolean\nfunctions. A class of Boolean functions, called nested canalyzing functions\n(NCFs), has been used to model certain biological phenomena. We identify some\ninteresting relationships between NCFs, symmetric Boolean functions and a\ngeneralization of symmetric Boolean functions, which we call $r$-symmetric\nfunctions (where $r$ is the symmetry level). Using a normalized representation\nfor NCFs, we develop a characterization of when two variables of an NCF are\nsymmetric. Using this characterization, we show that the symmetry level of an\nNCF $f$ can be easily computed given a standard representation of $f$. We also\npresent an algorithm for testing whether a given $r$-symmetric function is an\nNCF. Further, we show that for any NCF $f$ with $n$ variables, the notion of\nstrong asymmetry considered in the literature is equivalent to the property\nthat $f$ is $n$-symmetric. We use this result to derive a closed form\nexpression for the number of $n$-variable Boolean functions that are NCFs and\nstrongly asymmetric. We also identify all the Boolean functions that are NCFs\nand symmetric.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:04:42 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 15:55:50 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 14:54:43 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Rosenkrantz", "Daniel J.", ""], ["Marathe", "Madhav V.", ""], ["Ravi", "S. S.", ""], ["Stearns", "Richard E.", ""]]}, {"id": "1906.04062", "submitter": "Yutaro Yamaguchi", "authors": "Yoichi Iwata and Yutaro Yamaguchi", "title": "Finding a Shortest Non-zero Path in Group-Labeled Graphs", "comments": "A preliminary version appeared in SODA 2020; 22 pages, 7 figures", "journal-ref": null, "doi": "10.1137/1.9781611975994.118", "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a constrained shortest path problem in group-labeled graphs with\nnonnegative edge length, called the shortest non-zero path problem. Depending\non the group in question, this problem includes two types of tractable variants\nin undirected graphs: one is the parity-constrained shortest path/cycle\nproblem, and the other is computing a shortest noncontractible cycle in\nsurface-embedded graphs.\n  For the shortest non-zero path problem with respect to finite abelian groups,\nKobayashi and Toyooka (2017) proposed a randomized, pseudopolynomial-time\nalgorithm via permanent computation. For a slightly more general class of\ngroups, Yamaguchi (2016) showed a reduction of the problem to the weighted\nlinear matroid parity problem. In particular, some cases are solved in strongly\npolynomial time via the reduction with the aid of a deterministic,\npolynomial-time algorithm for the weighted linear matroid parity problem\ndeveloped by Iwata and Kobayashi (2021), which generalizes a well-known fact\nthat the parity-constrained shortest path problem is solved via weighted\nmatching.\n  In this paper, as the first general solution independent of the group, we\npresent a rather simple, deterministic, and strongly polynomial-time algorithm\nfor the shortest non-zero path problem. The algorithm is based on Dijkstra's\nalgorithm for the unconstrained shortest path problem and Edmonds' blossom\nshrinking technique in matching algorithms, which is inspired by Derigs' faster\nalgorithm (1985) for the parity-constrained shortest path problem via a\nreduction to weighted matching. Furthermore, we improve our algorithm so that\nit does not require explicit blossom shrinking, and make the computational time\nmatch Derigs' one. In the speeding-up step, a dual linear programming\nformulation of the equivalent problem based on potential maximization for the\nunconstrained shortest path problem plays a key role.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:06:29 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 10:32:04 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 13:10:27 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 16:00:43 GMT"}, {"version": "v5", "created": "Mon, 24 May 2021 06:49:34 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Iwata", "Yoichi", ""], ["Yamaguchi", "Yutaro", ""]]}, {"id": "1906.04120", "submitter": "Kanat Tangwongsan", "authors": "Kanat Tangwongsan, Srikanta Tirthapura", "title": "Parallel Streaming Random Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates parallel random sampling from a potentially-unending\ndata stream whose elements are revealed in a series of element sequences\n(minibatches). While sampling from a stream was extensively studied\nsequentially, not much has been explored in the parallel context, with prior\nparallel random-sampling algorithms focusing on the static batch model. We\npresent parallel algorithms for minibatch-stream sampling in two settings: (1)\nsliding window, which draws samples from a prespecified number of most-recently\nobserved elements, and (2) infinite window, which draws samples from all the\nelements received. Our algorithms are computationally and memory efficient:\ntheir work matches the fastest sequential counterpart, their parallel depth is\nsmall (polylogarithmic), and their memory usage matches the best known.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:53:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tangwongsan", "Kanat", ""], ["Tirthapura", "Srikanta", ""]]}, {"id": "1906.04213", "submitter": "Noam Nisan", "authors": "Noam Nisan", "title": "The Demand Query Model for Bipartite Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a `concrete complexity' model for studying algorithms for\nmatching in bipartite graphs. The model is based on the \"demand query\" model\nused for combinatorial auctions. Most (but not all) known algorithms for\nbipartite matching seem to be translatable into this model including exact,\napproximate, sequential, parallel, and online ones. A perfect matching in a\nbipartite graph can be found in this model with O(n^{3/2}) demand queries (in a\nbipartite graph with n vertices on each side) and our main open problem is to\neither improve the upper bound or prove a lower bound. An improved upper bound\ncould yield \"normal\" algorithms whose running time is better than the fastest\nones known, while a lower bound would rule out a faster algorithm for bipartite\nmatching from within a large class of algorithms. Our main result is a lower\nbound for finding an approximately maximum size matching in parallel: A\ndeterministic algorithm that runs in n^{o(1)} rounds, where each round can make\nat most n^{1.99} demand queries cannot find a matching whose size is within\nn^{o(1)} factor of the maximum. This is in contrast to randomized algorithms\nthat can find a matching whose size is $99\\%$ of the maximum in O(\\log n)\nrounds, each making n demand queries.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:17:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Nisan", "Noam", ""]]}, {"id": "1906.04270", "submitter": "Christian Coester", "authors": "Christian Coester, James R. Lee", "title": "Pure entropic regularization for metrical task systems", "comments": "COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that on every $n$-point HST metric, there is a randomized online\nalgorithm for metrical task systems (MTS) that is $1$-competitive for service\ncosts and $O(\\log n)$-competitive for movement costs. In general, these refined\nguarantees are optimal up to the implicit constant. While an $O(\\log\nn)$-competitive algorithm for MTS on HST metrics was developed by Bubeck et al.\n(SODA 2019), that approach could only establish an $O((\\log n)^2)$-competitive\nratio when the service costs are required to be $O(1)$-competitive. Our\nalgorithm can be viewed as an instantiation of online mirror descent with the\nregularizer derived from a multiscale conditional entropy.\n  In fact, our algorithm satisfies a set of even more refined guarantees; we\nare able to exploit this property to combine it with known random embedding\ntheorems and obtain, for any $n$-point metric space, a randomized algorithm\nthat is $1$-competitive for service costs and $O((\\log n)^2)$-competitive for\nmovement costs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 20:53:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 00:07:06 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 13:28:44 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Coester", "Christian", ""], ["Lee", "James R.", ""]]}, {"id": "1906.04304", "submitter": "Jack Rae", "authors": "Jack W Rae, Sergey Bartunov, Timothy P Lillicrap", "title": "Meta-Learning Neural Bloom Filters", "comments": "International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent trend in training neural networks to replace data\nstructures that have been crafted by hand, with an aim for faster execution,\nbetter accuracy, or greater compression. In this setting, a neural data\nstructure is instantiated by training a network over many epochs of its inputs\nuntil convergence. In applications where inputs arrive at high throughput, or\nare ephemeral, training a network from scratch is not practical. This motivates\nthe need for few-shot neural data structures. In this paper we explore the\nlearning of approximate set membership over a set of data in one-shot via\nmeta-learning. We propose a novel memory architecture, the Neural Bloom Filter,\nwhich is able to achieve significant compression gains over classical Bloom\nFilters and existing memory-augmented neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 22:23:14 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Rae", "Jack W", ""], ["Bartunov", "Sergey", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1906.04356", "submitter": "Tavor Baharav", "authors": "Tavor Z. Baharav, David N. Tse", "title": "Ultra Fast Medoid Identification via Correlated Sequential Halving", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medoid of a set of n points is the point in the set that minimizes the\nsum of distances to other points. It can be determined exactly in O(n^2) time\nby computing the distances between all pairs of points. Previous works show\nthat one can significantly reduce the number of distance computations needed by\nadaptively querying distances. The resulting randomized algorithm is obtained\nby a direct conversion of the computation problem to a multi-armed bandit\nstatistical inference problem. In this work, we show that we can better exploit\nthe structure of the underlying computation problem by modifying the\ntraditional bandit sampling strategy and using it in conjunction with a\nsuitably chosen multi-armed bandit algorithm. Four to five orders of magnitude\ngains over exact computation are obtained on real data, in terms of both number\nof distance computations needed and wall clock time. Theoretical results are\nobtained to quantify such gains in terms of data parameters. Our code is\npublicly available online at\nhttps://github.com/TavorB/Correlated-Sequential-Halving.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:32:29 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:22:11 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Baharav", "Tavor Z.", ""], ["Tse", "David N.", ""]]}, {"id": "1906.04449", "submitter": "Moran Feldman", "authors": "Moran Feldman and Ran Haba", "title": "Almost Optimal Semi-streaming Maximization for k-Extendible Systems", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of finding a maximum weight set subject\nto a $k$-extendible constraint in the data stream model. The only non-trivial\nalgorithm known for this problem to date---to the best of our knowledge---is a\nsemi-streaming $k^2(1 + \\varepsilon)$-approximation algorithm (Crouch and\nStubbs, 2014), but semi-streaming $O(k)$-approximation algorithms are known for\nmany restricted cases of this general problem. In this paper, we close most of\nthis gap by presenting a semi-streaming $O(k \\log k)$-approximation algorithm\nfor the general problem, which is almost the best possible even in the offline\nsetting (Feldman et al., 2017).\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:01:09 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Feldman", "Moran", ""], ["Haba", "Ran", ""]]}, {"id": "1906.04468", "submitter": "Jonathan Klawitter", "authors": "Remie Janssen, Jonathan Klawitter", "title": "Rearrangement operations on unrooted phylogenetic networks", "comments": "34 pages, 17 figures, published version", "journal-ref": "Theory and Applications of Graphs, Vol. 6 Iss. 2 Article 6. (2019)", "doi": "10.20429/tag.2019.060206", "report-no": null, "categories": "math.CO cs.DS q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rearrangement operations transform a phylogenetic tree into another one and\nhence induce a metric on the space of phylogenetic trees. Popular operations\nfor unrooted phylogenetic trees are NNI (nearest neighbour interchange), SPR\n(subtree prune and regraft), and TBR (tree bisection and reconnection).\nRecently, these operations have been extended to unrooted phylogenetic\nnetworks, which are generalisations of phylogenetic trees that can model\nreticulated evolutionary relationships. Here, we study global and local\nproperties of spaces of phylogenetic networks under these three operations. In\nparticular, we prove connectedness and asymptotic bounds on the diameters of\nspaces of different classes of phylogenetic networks, including tree-based and\nlevel-k networks. We also examine the behaviour of shortest TBR-sequence\nbetween two phylogenetic networks in a class, and whether the TBR-distance\nchanges if intermediate networks from other classes are allowed: for example,\nthe space of phylogenetic trees is an isometric subgraph of the space of\nphylogenetic networks under TBR. Lastly, we show that computing the\nTBR-distance and the PR-distance of two phylogenetic networks is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:57:41 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 00:50:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Janssen", "Remie", ""], ["Klawitter", "Jonathan", ""]]}, {"id": "1906.04523", "submitter": "Michael Cary", "authors": "Michael Cary", "title": "A Linear Algorithm for Minimum Dominator Colorings of Orientations of\n  Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an algorithm for finding a minimum dominator\ncoloring of orientations of paths. To date this is the first algorithm for\ndominator colorings of digraphs in any capacity. We prove that the algorithm\nalways provides a minimum dominator coloring of an oriented path and show that\nit runs in $\\mathcal{O}(n)$ time. The algorithm is available at\nhttps://github.com/cat-astrophic/MDC-orientations_of_paths/.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:19:14 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 17:46:28 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Cary", "Michael", ""]]}, {"id": "1906.04572", "submitter": "Rodrigo de Lamare", "authors": "M. Kaloorazi and R. C. de Lamare", "title": "Study of Compressed Randomized UTV Decompositions for Low-Rank Matrix\n  Approximations in Data Science", "comments": "7 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1810.07323", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a novel rank-revealing matrix decomposition algorithm termed\nCompressed Randomized UTV (CoR-UTV) decomposition along with a CoR-UTV variant\naided by the power method technique is proposed. CoR-UTV computes an\napproximation to a low-rank input matrix by making use of random sampling\nschemes. Given a large and dense matrix of size $m\\times n$ with numerical rank\n$k$, where $k \\ll \\text{min} \\{m,n\\}$, CoR-UTV requires a few passes over the\ndata, and runs in $O(mnk)$ floating-point operations. Furthermore, CoR-UTV can\nexploit modern computational platforms and can be optimized for maximum\nefficiency. CoR-UTV is also applied for solving robust principal component\nanalysis problems. Simulations show that CoR-UTV outperform existing\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 02:41:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Kaloorazi", "M.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1906.04661", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge, David Woodruff", "title": "Faster Algorithms for High-Dimensional Robust Covariance Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the covariance matrix of a\nhigh-dimensional distribution when a small constant fraction of the samples can\nbe arbitrarily corrupted. Recent work gave the first polynomial time algorithms\nfor this problem with near-optimal error guarantees for several natural\nstructured distributions. Our main contribution is to develop faster algorithms\nfor this problem whose running time nearly matches that of computing the\nempirical covariance.\n  Given $N = \\tilde{\\Omega}(d^2/\\epsilon^2)$ samples from a $d$-dimensional\nGaussian distribution, an $\\epsilon$-fraction of which may be arbitrarily\ncorrupted, our algorithm runs in time\n$\\tilde{O}(d^{3.26})/\\mathrm{poly}(\\epsilon)$ and approximates the unknown\ncovariance matrix to optimal error up to a logarithmic factor. Previous robust\nalgorithms with comparable error guarantees all have runtimes\n$\\tilde{\\Omega}(d^{2 \\omega})$ when $\\epsilon = \\Omega(1)$, where $\\omega$ is\nthe exponent of matrix multiplication. We also provide evidence that improving\nthe running time of our algorithm may require new algorithmic techniques.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:41:44 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""], ["Woodruff", "David", ""]]}, {"id": "1906.04709", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Daniel M. Kane and\n  Sankeerth Rao", "title": "Communication and Memory Efficient Testing of Discrete Distributions", "comments": "Full version of COLT 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distribution testing with communication and memory constraints in\nthe following computational models: (1) The {\\em one-pass streaming model}\nwhere the goal is to minimize the sample complexity of the protocol subject to\na memory constraint, and (2) A {\\em distributed model} where the data samples\nreside at multiple machines and the goal is to minimize the communication cost\nof the protocol. In both these models, we provide efficient algorithms for\nuniformity/identity testing (goodness of fit) and closeness testing (two sample\ntesting). Moreover, we show nearly-tight lower bounds on (1) the sample\ncomplexity of any one-pass streaming tester for uniformity, subject to the\nmemory constraint, and (2) the communication cost of any uniformity testing\nprotocol, in a restricted `one-pass' model of communication.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:26:21 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Kane", "Daniel M.", ""], ["Rao", "Sankeerth", ""]]}, {"id": "1906.04832", "submitter": "Tobias Z\\\"undorf", "authors": "Moritz Baum, Valentin Buchhold, Jonas Sauer, Dorothea Wagner, and\n  Tobias Z\\\"undorf", "title": "UnLimited TRAnsfers for Multi-Modal Route Planning: An Efficient\n  Solution", "comments": "16 pages, 4 figures", "journal-ref": "27th Annual European Symposium on Algorithms (ESA 2019) (Leibniz\n  International Proceedings in Informatics (LIPIcs)), Vol. 144, 14:1-14:16", "doi": "10.4230/LIPIcs.ESA.2019.14", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-modal route planning scenario consisting of a public transit\nnetwork and a transfer graph representing a secondary transportation mode\n(e.g., walking or taxis). The objective is to compute all journeys that are\nPareto-optimal with respect to arrival time and the number of required\ntransfers. While various existing algorithms can efficiently compute optimal\njourneys in either a pure public transit network or a pure transfer graph,\ncombining the two increases running times significantly. As a result, even\nwalking between stops is typically limited by a maximal duration or distance,\nor by requiring the transfer graph to be transitively closed. To overcome these\nshortcomings, we propose a novel preprocessing technique called ULTRA\n(UnLimited TRAnsfers): Given a complete transfer graph (without any\nlimitations, representing an arbitrary non-schedule-based mode of\ntransportation), we compute a small number of transfer shortcuts that are\nprovably sufficient for computing all Pareto-optimal journeys. We demonstrate\nthe practicality of our approach by showing that these transfer shortcuts can\nbe integrated into a variety of state-of-the-art public transit algorithms,\nestablishing the ULTRA-Query algorithm family. Our extensive experimental\nevaluation shows that ULTRA is able to improve these algorithms from limited to\nunlimited transfers without sacrificing query speed, yielding the fastest known\nalgorithms for multi-modal routing. This is true not just for walking, but also\nfor other transfer modes such as cycling or driving.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:33:21 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 16:03:23 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Baum", "Moritz", ""], ["Buchhold", "Valentin", ""], ["Sauer", "Jonas", ""], ["Wagner", "Dorothea", ""], ["Z\u00fcndorf", "Tobias", ""]]}, {"id": "1906.04840", "submitter": "Matthieu Latapy", "authors": "Matthieu Latapy and Cl\\'emence Magnien and Tiphaine Viard", "title": "Weighted, Bipartite, or Directed Stream Graphs for the Modeling of\n  Temporal Networks", "comments": null, "journal-ref": "In: Holme P., Saram\\\"aki J. (eds) Temporal Network Theory.\n  Computational Social Sciences. Springer, 2019", "doi": "10.1007/978-3-030-23495-9_3", "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently introduced a formalism for the modeling of temporal networks,\nthat we call stream graphs. It emphasizes the streaming nature of data and\nallows rigorous definitions of many important concepts generalizing classical\ngraphs. This includes in particular size, density, clique, neighborhood,\ndegree, clustering coefficient, and transitivity. In this contribution, we show\nthat, like graphs, stream graphs may be extended to cope with bipartite\nstructures, with node and link weights, or with link directions. We review the\nmain bipartite, weighted or directed graph concepts proposed in the literature,\nwe generalize them to the cases of bipartite, weighted, or directed stream\ngraphs, and we show that obtained concepts are consistent with graph and stream\ngraph ones. This provides a formal ground for an accurate modeling of the many\ntemporal networks that have one or several of these features.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:08:38 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Latapy", "Matthieu", ""], ["Magnien", "Cl\u00e9mence", ""], ["Viard", "Tiphaine", ""]]}, {"id": "1906.04842", "submitter": "Johan von Tangen Sivertsen M.Sc", "authors": "Johan von Tangen Sivertsen", "title": "Similarity Problems in High Dimensions", "comments": "Dissertation, Univ Copenhagen (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this dissertation is the introduction of new or\nimproved approximation algorithms and data structures for several similarity\nsearch problems. We examine the furthest neighbor query, the annulus query,\ndistance sensitive membership, nearest neighbor preserving embeddings and set\nsimilarity queries in the large-scale, high-dimensional setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:13:43 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Sivertsen", "Johan von Tangen", ""]]}, {"id": "1906.04845", "submitter": "Edo Liberty", "authors": "Zohar Karnin and Edo Liberty", "title": "Discrepancy, Coresets, and Sketches in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines the notion of class discrepancy for families of functions.\nIt shows that low discrepancy classes admit small offline and streaming\ncoresets. We provide general techniques for bounding the class discrepancy of\nmachine learning problems. As corollaries of the general technique we bound the\ndiscrepancy (and therefore coreset complexity) of logistic regression, sigmoid\nactivation loss, matrix covariance, kernel density and any analytic function of\nthe dot product or the squared distance. Our results prove the existence of\nepsilon-approximation O(sqrt{d}/epsilon) sized coresets for the above problems.\nThis resolves the long-standing open problem regarding the coreset complexity\nof Gaussian kernel density estimation. We provide two more related but\nindependent results. First, an exponential improvement of the widely used\nmerge-and-reduce trick which gives improved streaming sketches for any low\ndiscrepancy problem. Second, an extremely simple deterministic algorithm for\nfinding low discrepancy sequences (and therefore coresets) for any positive\nsemi-definite kernel. This paper establishes some explicit connections between\nclass discrepancy, coreset complexity, learnability, and streaming algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:21:19 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Karnin", "Zohar", ""], ["Liberty", "Edo", ""]]}, {"id": "1906.04897", "submitter": "Md. Khaledur Rahman", "authors": "Md. Khaledur Rahman, M. Sohel Rahman", "title": "Prefix Block-Interchanges on Binary and Ternary Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The genome rearrangement problem computes the minimum number of operations\nthat are required to sort all elements of a permutation. A block-interchange\noperation exchanges two blocks of a permutation which are not necessarily\nadjacent and in a prefix block-interchange, one block is always the prefix of\nthat permutation. In this paper, we focus on applying prefix block-interchanges\non binary and ternary strings. We present upper bounds to group and sort a\ngiven binary/ternary string. We also provide upper bounds for a different\nversion of the block-interchange operation which we refer to as the `restricted\nprefix block-interchange'. We observe that our obtained upper bound for\nrestricted prefix block-interchange operations on binary strings is better than\nthat of other genome rearrangement operations to group fully normalized binary\nstrings. Consequently, we provide a linear-time algorithm to solve the problem\nof grouping binary normalized strings by restricted prefix block-interchanges.\nWe also provide a polynomial time algorithm to group normalized ternary strings\nby prefix block-interchange operations. Finally, we provide a classification\nfor ternary strings based on the required number of prefix block-interchange\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 01:53:05 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Rahman", "Md. Khaledur", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "1906.04899", "submitter": "Jackie Baek", "authors": "Jackie Baek, Will Ma", "title": "Prophet Inequalities on the Intersection of a Matroid and a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider prophet inequalities in a setting where agents correspond to both\nelements in a matroid and vertices in a graph. A set of agents is feasible if\nthey form both an independent set in the matroid and an independent set in the\ngraph. Our main result is an ex-ante 1/(2d+2)-prophet inequality, where d is a\ngraph parameter upper-bounded by the maximum size of an independent set in the\nneighborhood of any vertex.\n  We establish this result through a framework that sets both dynamic prices\nfor elements in the matroid (using the method of balanced thresholds), and\nstatic but discriminatory prices for vertices in the graph (motivated by recent\ndevelopments in approximate dynamic programming). The threshold for accepting\nan agent is then the sum of these two prices.\n  We show that for graphs induced by a certain family of interval-scheduling\nconstraints, the value of d is 1. Our framework thus provides the first\nconstant-factor prophet inequality when there are both matroid-independence\nconstraints and interval-scheduling constraints. It also unifies and improves\nseveral results from the literature, leading to a 1/2-prophet inequality when\nagents have XOS valuation functions over a set of items and use them for a\nfinite interval duration, and more generally, a 1/(d+1)-prophet inequality when\nthese items each require a bundle of d resources to procure.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:34:09 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 22:59:26 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Baek", "Jackie", ""], ["Ma", "Will", ""]]}, {"id": "1906.05005", "submitter": "Ishay Haviv", "authors": "Ishay Haviv", "title": "Approximating the Orthogonality Dimension of Graphs and Hypergraphs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $t$-dimensional orthogonal representation of a hypergraph is an assignment\nof nonzero vectors in $\\mathbb{R}^t$ to its vertices, such that every hyperedge\ncontains two vertices whose vectors are orthogonal. The orthogonality dimension\nof a hypergraph $H$, denoted by $\\overline{\\xi}(H)$, is the smallest integer\n$t$ for which there exists a $t$-dimensional orthogonal representation of $H$.\nIn this paper we study computational aspects of the orthogonality dimension of\ngraphs and hypergraphs. We prove that for every $k \\geq 4$, it is\n$\\mathsf{NP}$-hard (resp. quasi-$\\mathsf{NP}$-hard) to distinguish $n$-vertex\n$k$-uniform hypergraphs $H$ with $\\overline{\\xi}(H) \\leq 2$ from those\nsatisfying $\\overline{\\xi}(H) \\geq \\Omega(\\log^\\delta n)$ for some constant\n$\\delta>0$ (resp. $\\overline{\\xi}(H) \\geq \\Omega(\\log^{1-o(1)} n)$). For\ngraphs, we relate the $\\mathsf{NP}$-hardness of approximating the orthogonality\ndimension to a variant of a long-standing conjecture of Stahl. We also consider\nthe algorithmic problem in which given a graph $G$ with $\\overline{\\xi}(G) \\leq\n3$ the goal is to find an orthogonal representation of $G$ of as low dimension\nas possible, and provide a polynomial time approximation algorithm based on\nsemidefinite programming.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 08:42:58 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Haviv", "Ishay", ""]]}, {"id": "1906.05208", "submitter": "Jieming Mao", "authors": "Mark Braverman, Jieming Mao, Yuval Peres", "title": "Sorted Top-k in Rounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the sorted top-$k$ problem whose goal is to recover the top-$k$\nitems with the correct order out of $n$ items using pairwise comparisons. In\nmany applications, multiple rounds of interaction can be costly. We restrict\nour attention to algorithms with a constant number of rounds $r$ and try to\nminimize the sample complexity, i.e. the number of comparisons.\n  When the comparisons are noiseless, we characterize how the optimal sample\ncomplexity depends on the number of rounds (up to a polylogarithmic factor for\ngeneral $r$ and up to a constant factor for $r=1$ or 2). In particular, the\nsample complexity is $\\Theta(n^2)$ for $r=1$, $\\Theta(n\\sqrt{k} + n^{4/3})$ for\n$r=2$ and $\\tilde{\\Theta}\\left(n^{2/r} k^{(r-1)/r} + n\\right)$ for $r \\geq 3$.\n  We extend our results of sorted top-$k$ to the noisy case where each\ncomparison is correct with probability $2/3$. When $r=1$ or 2, we show that the\nsample complexity gets an extra $\\Theta(\\log(k))$ factor when we transition\nfrom the noiseless case to the noisy case.\n  We also prove new results for top-$k$ and sorting in the noisy case. We\nbelieve our techniques can be generally useful for understanding the trade-off\nbetween round complexities and sample complexities of rank aggregation\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:24:07 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Braverman", "Mark", ""], ["Mao", "Jieming", ""], ["Peres", "Yuval", ""]]}, {"id": "1906.05266", "submitter": "Manuel Lafond", "authors": "Manuel Lafond, Binhai Zhu, Peng Zou", "title": "The Tandem Duplication Distance is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational biology, tandem duplication is an important biological\nphenomenon which can occur either at the genome or at the DNA level. A tandem\nduplication takes a copy of a genome segment and inserts it right after the\nsegment - this can be represented as the string operation $AXB \\Rightarrow\nAXXB$. For example, Tandem exon duplications have been found in many species\nsuch as human, fly or worm, and have been largely studied in computational\nbiology. The Tandem Duplication (TD) distance problem we investigate in this\npaper is defined as follows: given two strings $S$ and $T$ over the same\nalphabet, compute the smallest sequence of tandem duplications required to\nconvert $S$ to $T$. The natural question of whether the TD distance can be\ncomputed in polynomial time was posed in 2004 by Leupold et al. and had\nremained open, despite the fact that tandem duplications have received much\nattention ever since. In this paper, we prove that this problem is NP-hard. We\nfurther show that this hardness holds even if all characters of $S$ are\ndistinct. This is known as the exemplar TD distance, which is of special\nrelevance in bioinformatics. One of the tools we develop for the reduction is a\nnew problem called the Cost-Effective Subgraph, for which we obtain\nW[1]-hardness results that might be of independent interest. We finally show\nthat computing the exemplar TD distance between $S$ and $T$ is fixed-parameter\ntractable. Our results open the door to many other questions, and we conclude\nwith several open problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:47:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lafond", "Manuel", ""], ["Zhu", "Binhai", ""], ["Zou", "Peng", ""]]}, {"id": "1906.05384", "submitter": "Shoupu Wan", "authors": "Shoupu Wan", "title": "Loop Programming Practices that Simplify Quicksort Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quicksort algorithm with Hoare's partition scheme is traditionally\nimplemented with nested loops. In this article, we present loop programming and\nrefactoring techniques that lead to simplified implementation for Hoare's\nquicksort algorithm consisting of a single loop. We believe that the techniques\nare beneficial for general programming and may be used for the discovery of\nmore novel algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:28:51 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Wan", "Shoupu", ""]]}, {"id": "1906.05422", "submitter": "Danil Sagunov", "authors": "Ivan Bliznets and Danil Sagunov", "title": "Lower Bounds for the Happy Coloring Problems", "comments": "Accepted to COCOON 2019; fixed statement of the problem BRDS; fixed\n  references and affiliations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Maximum Happy Vertices and the Maximum Happy\nEdges problems (MHV and MHE for short). Very recently, the problems attracted a\nlot of attention and were studied in Agrawal '17, Aravind et al. '16, Choudhari\nand Reddy '18, Misra and Reddy '17. Main focus of our work is lower bounds on\nthe computational complexity of these problems. Established lower bounds can be\ndivided into the following groups: NP-hardness of the above guarantee\nparameterization, kernelization lower bounds (answering questions of Misra and\nReddy '17), exponential lower bounds under the Set Cover Conjecture and the\nExponential Time Hypothesis, and inapproximability results. Moreover, we\npresent an $\\mathcal{O}^*(\\ell^k)$ randomized algorithm for MHV and an\n$\\mathcal{O}^*(2^k)$ algorithm for MHE, where $\\ell$ is the number of colors\nused and $k$ is the number of required happy vertices or edges. These\nalgorithms cannot be improved to subexponential taking proved lower bounds into\naccount.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 23:28:07 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 09:30:21 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 16:57:06 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bliznets", "Ivan", ""], ["Sagunov", "Danil", ""]]}, {"id": "1906.05458", "submitter": "Arijit Ghosh", "authors": "Arijit Bishnu and Arijit Ghosh and Sudeshna Kolay and Gopinath Mishra\n  and Saket Saurabh", "title": "Structural Parameterization for Graph Deletion Problems over Data\n  Streams", "comments": "Title and introduction changed to better reflect the content of the\n  paper; 27 pages; 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of parameterized streaming complexity on graph problems was\ninitiated by Fafianie et al. (MFCS'14) and Chitnis et al. (SODA'15 and\nSODA'16). Simply put, the main goal is to design streaming algorithms for\nparameterized problems such that $O\\left(f(k)\\log^{O(1)}n\\right)$ space is\nenough, where $f$ is an arbitrary computable function depending only on the\nparameter $k$. However, in the past few years, very few positive results have\nbeen established. Most of the graph problems that do have streaming algorithms\nof the above nature are ones where localized checking is required, like Vertex\nCover or Maximum Matching parameterized by the size $k$ of the solution we are\nseeking. Many important parameterized problems that form the backbone of\ntraditional parameterized complexity are known to require $\\Omega(n)$ bits for\nany streaming algorithm; e.g., Feedback Vertex Set, Even/Odd Cycle Transversal,\nTriangle Deletion or the more general ${\\cal F}$-Subgraph Deletion when\nparameterized by solution size $k$.\n  Our main conceptual contribution is to overcome the obstacles to efficient\nparameterized streaming algorithms by utilizing the power of parameterization.\nTo the best of our knowledge, this is the first work in parameterized streaming\ncomplexity that considers structural parameters instead of the solution size as\na parameter. We focus on the vertex cover size $K$ as the parameter for the\nparameterized graph deletion problems we consider. At the same time, most of\nthe previous work in parameterized streaming complexity was restricted to the\nEA (edge arrival) or DEA (dynamic edge arrival) models. In this work, we\nconsider the above mentioned graph deletion problems in the four most\nwell-studied streaming models, i.e., the EA, DEA, VA (vertex arrival) and AL\n(adjacency list) models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 02:24:36 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:30:54 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bishnu", "Arijit", ""], ["Ghosh", "Arijit", ""], ["Kolay", "Sudeshna", ""], ["Mishra", "Gopinath", ""], ["Saurabh", "Saket", ""]]}, {"id": "1906.05486", "submitter": "Hideo Bannai", "authors": "Kazuki Kai, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai, Masayuki\n  Takeda, Tomasz Kociumaka", "title": "On Longest Common Property Preserved Substring Queries", "comments": "minor change from version submitted to SPIRE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of longest common property preserving substring\nqueries introduced by~Ayad et al. (SPIRE 2018, arXiv 2018). We consider a\ngeneralized and unified on-line setting, where we are given a set $X$ of $k$\nstrings of total length $n$ that can be pre-processed so that, given a query\nstring $y$ and a positive integer $k'\\leq k$, we can determine the longest\nsubstring of $y$ that satisfies some specific property and is common to at\nleast $k'$ strings in $X$. Ayad et al. considered the longest square-free\nsubstring in an on-line setting and the longest periodic and palindromic\nsubstring in an off-line setting. In this paper, we give efficient solutions in\nthe on-line setting for finding the longest common square, periodic,\npalindromic, and Lyndon substrings. More precisely, we show that $X$ can be\npre-processed in $O(n)$ time resulting in a data structure of $O(n)$ size that\nanswers queries in $O(|y|\\log\\sigma)$ time and $O(1)$ working space, where\n$\\sigma$ is the size of the alphabet, and the common substring must be a\nsquare, a periodic substring, a palindrome, or a Lyndon word.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:24:44 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kai", "Kazuki", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""], ["Kociumaka", "Tomasz", ""]]}, {"id": "1906.05565", "submitter": "Huib Donkers", "authors": "Huib Donkers, Bart M.P. Jansen", "title": "A Turing Kernelization Dichotomy for Structural Parameterizations of\n  $\\mathcal{F}$-Minor-Free Deletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a fixed finite family of graphs $\\mathcal{F}$, the\n$\\mathcal{F}$-Minor-Free Deletion problem takes as input a graph $G$ and an\ninteger $\\ell$ and asks whether there exists a set $X \\subseteq V(G)$ of size\nat most $\\ell$ such that $G-X$ is $\\mathcal{F}$-minor-free. For\n$\\mathcal{F}=\\{K_2\\}$ and $\\mathcal{F}=\\{K_3\\}$ this encodes Vertex Cover and\nFeedback Vertex Set respectively. When parameterized by the feedback vertex\nnumber of $G$ these two problems are known to admit a polynomial kernelization.\nSuch a polynomial kernelization also exists for any $\\mathcal{F}$ containing a\nplanar graph but no forests. In this paper we show that\n$\\mathcal{F}$-Minor-Free Deletion parameterized by the feedback vertex number\nis MK[2]-hard for $\\mathcal{F} = \\{P_3\\}$. This rules out the existence of a\npolynomial kernel assuming $NP \\subseteq coNP/poly$, and also gives evidence\nthat the problem does not admit a polynomial Turing kernel. Our hardness result\ngeneralizes to any $\\mathcal{F}$ not containing a $P_3$-subgraph-free graph,\nusing as parameter the vertex-deletion distance to treewidth\n$mintw(\\mathcal{F})$, where $mintw(\\mathcal{F})$ denotes the minimum treewidth\nof the graphs in $\\mathcal{F}$. For the other case, where $\\mathcal{F}$\ncontains a $P_3$-subgraph-free graph, we present a polynomial Turing\nkernelization. Our results extend to $\\mathcal{F}$-Subgraph-Free Deletion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:32:52 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 10:52:04 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Donkers", "Huib", ""], ["Jansen", "Bart M. P.", ""]]}, {"id": "1906.05669", "submitter": "Alexander Litvinenko", "authors": "Mike Espig, Wolfgang Hackbusch, Alexander Litvinenko, Hermann G.\n  Matthies, Elmar Zander", "title": "Post-Processing of High-Dimensional Data", "comments": "32 pages, 2 figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific computations or measurements may result in huge volumes of data.\nOften these can be thought of representing a real-valued function on a\nhigh-dimensional domain, and can be conceptually arranged in the format of a\ntensor of high degree in some truncated or lossy compressed format. We look at\nsome common post-processing tasks which are not obvious in the compressed\nformat, as such huge data sets can not be stored in their entirety, and the\nvalue of an element is not readily accessible through simple look-up. The tasks\nwe consider are finding the location of maximum or minimum, or minimum and\nmaximum of a function of the data, or finding the indices of all elements in\nsome interval --- i.e. level sets, the number of elements with a value in such\na level set, the probability of an element being in a particular level set, and\nthe mean and variance of the total collection.\n  The algorithms to be described are fixed point iterations of particular\nfunctions of the tensor, which will then exhibit the desired result. For this,\nthe data is considered as an element of a high degree tensor space, although in\nan abstract sense, the algorithms are independent of the representation of the\ndata as a tensor. All that we require is that the data can be considered as an\nelement of an associative, commutative algebra with an inner product. Such an\nalgebra is isomorphic to a commutative sub-algebra of the usual matrix algebra,\nallowing the use of matrix algorithms to accomplish the mentioned tasks. We\nallow the actual computational representation to be a lossy compression, and we\nallow the algebra operations to be performed in an approximate fashion, so as\nto maintain a high compression level. One such example which we address\nexplicitly is the representation of data as a tensor with compression in the\nform of a low-rank representation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:33:09 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 07:38:37 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 14:34:03 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Espig", "Mike", ""], ["Hackbusch", "Wolfgang", ""], ["Litvinenko", "Alexander", ""], ["Matthies", "Hermann G.", ""], ["Zander", "Elmar", ""]]}, {"id": "1906.05736", "submitter": "Jialin Zhang", "authors": "Xiaoming Sun, David P. Woodruff, Guang Yang, Jialin Zhang", "title": "Querying a Matrix through Matrix-Vector Products", "comments": "28 pages, to appear in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider algorithms with access to an unknown matrix $M\\in\\mathbb{F}^{n\n\\times d}$ via matrix-vector products, namely, the algorithm chooses vectors\n$\\mathbf{v}^1, \\ldots, \\mathbf{v}^q$, and observes $M\\mathbf{v}^1,\\ldots,\nM\\mathbf{v}^q$. Here the $\\mathbf{v}^i$ can be randomized as well as chosen\nadaptively as a function of $ M\\mathbf{v}^1,\\ldots,M\\mathbf{v}^{i-1}$.\nMotivated by applications of sketching in distributed computation, linear\nalgebra, and streaming models, as well as connections to areas such as\ncommunication complexity and property testing, we initiate the study of the\nnumber $q$ of queries needed to solve various fundamental problems. We study\nproblems in three broad categories, including linear algebra, statistics\nproblems, and graph problems. For example, we consider the number of queries\nrequired to approximate the rank, trace, maximum eigenvalue, and norms of a\nmatrix $M$; to compute the AND/OR/Parity of each column or row of $M$, to\ndecide whether there are identical columns or rows in $M$ or whether $M$ is\nsymmetric, diagonal, or unitary; or to compute whether a graph defined by $M$\nis connected or triangle-free. We also show separations for algorithms that are\nallowed to obtain matrix-vector products only by querying vectors on the right,\nversus algorithms that can query vectors on both the left and the right. We\nalso show separations depending on the underlying field the matrix-vector\nproduct occurs in. For graph problems, we show separations depending on the\nform of the matrix (bipartite adjacency versus signed edge-vertex incidence\nmatrix) to represent the graph.\n  Surprisingly, this fundamental model does not appear to have been studied on\nits own, and we believe a thorough investigation of problems in this model\nwould be beneficial to a number of different application areas.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:55:50 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 01:14:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Sun", "Xiaoming", ""], ["Woodruff", "David P.", ""], ["Yang", "Guang", ""], ["Zhang", "Jialin", ""]]}, {"id": "1906.05832", "submitter": "Ruosong Wang", "authors": "Santosh S. Vempala and Ruosong Wang and David P. Woodruff", "title": "The Communication Complexity of Optimization", "comments": "To appear in SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the communication complexity of a number of distributed\noptimization problems. We start with the problem of solving a linear system.\nSuppose there is a coordinator together with $s$ servers $P_1, \\ldots, P_s$,\nthe $i$-th of which holds a subset $A^{(i)} x = b^{(i)}$ of $n_i$ constraints\nof a linear system in $d$ variables, and the coordinator would like to output\n$x \\in \\mathbb{R}^d$ for which $A^{(i)} x = b^{(i)}$ for $i = 1, \\ldots, s$. We\nassume each coefficient of each constraint is specified using $L$ bits. We\nfirst resolve the randomized and deterministic communication complexity in the\npoint-to-point model of communication, showing it is $\\tilde{\\Theta}(d^2L +\nsd)$ and $\\tilde{\\Theta}(sd^2L)$, respectively. We obtain similar results for\nthe blackboard model.\n  When there is no solution to the linear system, a natural alternative is to\nfind the solution minimizing the $\\ell_p$ loss. While this problem has been\nstudied, we give improved upper or lower bounds for every value of $p \\ge 1$.\nOne takeaway message is that sampling and sketching techniques, which are\ncommonly used in earlier work on distributed optimization, are neither optimal\nin the dependence on $d$ nor on the dependence on the approximation $\\epsilon$,\nthus motivating new techniques from optimization to solve these problems.\n  Towards this end, we consider the communication complexity of optimization\ntasks which generalize linear systems. For linear programming, we first resolve\nthe communication complexity when $d$ is constant, showing it is\n$\\tilde{\\Theta}(sL)$ in the point-to-point model. For general $d$ and in the\npoint-to-point model, we show an $\\tilde{O}(sd^3 L)$ upper bound and an\n$\\tilde{\\Omega}(d^2 L + sd)$ lower bound. We also show if one perturbs the\ncoefficients randomly by numbers as small as $2^{-\\Theta(L)}$, then the upper\nbound is $\\tilde{O}(sd^2 L) + \\textrm{poly}(dL)$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:29:56 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 03:46:29 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Vempala", "Santosh S.", ""], ["Wang", "Ruosong", ""], ["Woodruff", "David P.", ""]]}, {"id": "1906.05996", "submitter": "Felice De Luca", "authors": "Felice De Luca, Iqbal Hossain, Kathryn Gray, Stephen Kobourov, Katy\n  B\\\"orner", "title": "Multi-level tree based approach for interactive graph visualization with\n  semantic zoom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human subject studies that map-like visualizations are as good or better than\nstandard node-link representations of graphs, in terms of task performance,\nmemorization and recall of the underlying data, and engagement [SSKB14,\nSSKB15]. With this in mind, we propose the Zoomable Multi-Level Tree (ZMLT)\nalgorithm for multi-level tree-based, map-like visualization of large graphs.\nWe propose seven desirable properties that such visualization should maintain\nand an algorithm that accomplishes them. (1) The abstract trees represent the\nunderlying graph appropriately at different level of details; (2) The embedded\ntrees represent the underlying graph appropriately at different levels of\ndetails; (3) At every level of detail we show real vertices and real paths from\nthe underlying graph; (4) If any node or edge appears in a given level, then\nthey also appear in all deeper levels; (5) All nodes at the current level and\nhigher levels are labeled and there are no label overlaps; (6) There are no\nedge crossings on any level; (7) The drawing area is proportional to the total\narea of the labels. This algorithm is implemented and we have a functional\nprototype for the interactive interface in a web browser.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 02:58:17 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 18:05:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["De Luca", "Felice", ""], ["Hossain", "Iqbal", ""], ["Gray", "Kathryn", ""], ["Kobourov", "Stephen", ""], ["B\u00f6rner", "Katy", ""]]}, {"id": "1906.05998", "submitter": "Hanna Sumita", "authors": "Daisuke Hatano, Yuko Kuroki, Yasushi Kawase, Hanna Sumita, Naonori\n  Kakimura, Ken-ichi Kawarabayashi", "title": "Non-zero-sum Stackelberg Budget Allocation Game for Computational\n  Advertising", "comments": "Accepted for PRICAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational advertising has been studied to design efficient marketing\nstrategies that maximize the number of acquired customers. In an increased\ncompetitive market, however, a market leader (a leader) requires the\nacquisition of new customers as well as the retention of her loyal customers\nbecause there often exists a competitor (a follower) who tries to attract\ncustomers away from the market leader. In this paper, we formalize a new model\ncalled the Stackelberg budget allocation game with a bipartite influence model\nby extending a budget allocation problem over a bipartite graph to a\nStackelberg game. To find a strong Stackelberg equilibrium, a standard solution\nconcept of the Stackelberg game, we propose two algorithms: an approximation\nalgorithm with provable guarantees and an efficient heuristic algorithm. In\naddition, for a special case where customers are disjoint, we propose an exact\nalgorithm based on linear programming. Our experiments using real-world\ndatasets demonstrate that our algorithms outperform a baseline algorithm even\nwhen the follower is a powerful competitor.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 03:06:12 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 01:08:41 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Hatano", "Daisuke", ""], ["Kuroki", "Yuko", ""], ["Kawase", "Yasushi", ""], ["Sumita", "Hanna", ""], ["Kakimura", "Naonori", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1906.06015", "submitter": "Shunsuke Kanda", "authors": "Shunsuke Kanda, Dominik K\\\"oppl, Yasuo Tabei, Kazuhiro Morita and\n  Masao Fuketa", "title": "Dynamic Path-Decomposed Tries", "comments": "Accepted by ACM Journal of Experimental Algorithmics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A keyword dictionary is an associative array whose keys are strings. Recent\napplications handling massive keyword dictionaries in main memory have a need\nfor a space-efficient implementation. When limited to static applications,\nthere are a number of highly-compressed keyword dictionaries based on the\nadvancements of practical succinct data structures. However, as most succinct\ndata structures are only efficient in the static case, it is still difficult to\nimplement a keyword dictionary that is space efficient and dynamic. In this\narticle, we propose such a keyword dictionary. Our main idea is to embrace the\npath decomposition technique, which was proposed for constructing\ncache-friendly tries. To store the path-decomposed trie in small memory, we\ndesign data structures based on recent compact hash trie representations.\nExperiments on real-world datasets reveal that our dynamic keyword dictionary\nneeds up to 68% less space than the existing smallest ones, while achieving a\nrelevant space-time tradeoff.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 04:31:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:28:39 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kanda", "Shunsuke", ""], ["K\u00f6ppl", "Dominik", ""], ["Tabei", "Yasuo", ""], ["Morita", "Kazuhiro", ""], ["Fuketa", "Masao", ""]]}, {"id": "1906.06361", "submitter": "Siddhartha Banerjee", "authors": "Alberto Vera, Siddhartha Banerjee, Itai Gurvich", "title": "Online Allocation and Pricing: Constant Regret via Bellman Inequalities", "comments": "To appear in Operations Research, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for designing simple and efficient policies for a\nfamily of online allocation and pricing problems, that includes online packing,\nbudget-constrained probing, dynamic pricing, and online contextual bandits with\nknapsacks. In each case, we evaluate the performance of our policies in terms\nof their regret (i.e., additive gap) relative to an offline controller that is\nendowed with more information than the online controller. Our framework is\nbased on Bellman Inequalities, which decompose the loss of an algorithm into\ntwo distinct sources of error: (1) arising from computational tractability\nissues, and (2) arising from estimation/prediction of random trajectories.\nBalancing these errors guides the choice of benchmarks, and leads to policies\nthat are both tractable and have strong performance guarantees. In particular,\nin all our examples, we demonstrate constant-regret policies that only require\nre-solving an LP in each period, followed by a simple greedy action-selection\nrule; thus, our policies are practical as well as provably near optimal.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 18:24:24 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 22:53:03 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Vera", "Alberto", ""], ["Banerjee", "Siddhartha", ""], ["Gurvich", "Itai", ""]]}, {"id": "1906.06393", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer", "title": "A Unified Framework of Constrained Robust Submodular Optimization with\n  Applications", "comments": "V2, Match 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization is becoming increasingly important in machine learning\napplications. In this paper, we study a unified framework of robust submodular\noptimization. We study this problem both from a minimization and maximization\nperspective (previous work has only focused on variants of robust submodular\nmaximization). We do this under a broad range of combinatorial constraints\nincluding cardinality, knapsack, matroid as well as graph-based constraints\nsuch as cuts, paths, matchings and trees. Furthermore, we also study robust\nsubmodular minimization and maximization under multiple submodular upper and\nlower bound constraints. We show that all these problems are motivated by\nimportant machine learning applications including robust data subset selection,\nrobust co-operative cuts and robust co-operative matchings. In each case, we\nprovide scalable approximation algorithms and also study hardness bounds.\nFinally, we empirically demonstrate the utility of our algorithms on synthetic\ndata, and real-world applications of robust cooperative matchings for image\ncorrespondence, robust data subset selection for speech recognition, and image\ncollection summarization with multiple queries.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:33:41 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 23:26:09 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Iyer", "Rishabh", ""]]}, {"id": "1906.06431", "submitter": "Yury Maximov", "authors": "Valerii Likhosherstov, Yury Maximov and Michael Chertkov", "title": "A New Family of Tractable Ising Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cond-mat.stat-mech physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new family of zero-field Ising models over N binary\nvariables/spins obtained by consecutive \"gluing\" of planar and $O(1)$-sized\ncomponents along with subsets of at most three vertices into a tree. The\npolynomial time algorithm of the dynamic programming type for solving exact\ninference (partition function computation) and sampling consists of a\nsequential application of an efficient (for planar) or brute-force (for\n$O(1)$-sized) inference and sampling to the components as a black box. To\nillustrate the utility of the new family of tractable graphical models, we\nfirst build an $O(N^{3/2})$ algorithm for inference and sampling of the\nK5-minor-free zero-field Ising models - an extension of the planar zero-field\nIsing models - which is neither genus- nor treewidth-bounded. Second, we\ndemonstrate empirically an improvement in the approximation quality of the\nNP-hard problem of the square-grid Ising model (with non-zero field) inference.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:15:35 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Likhosherstov", "Valerii", ""], ["Maximov", "Yury", ""], ["Chertkov", "Michael", ""]]}, {"id": "1906.06432", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Nesreen K. Ahmed, Eunyee Koh, and Sungchul Kim", "title": "Linear-time Hierarchical Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in graphs has many important and fundamental applications\nincluding in distributed systems, compression, image segmentation,\ndivide-and-conquer graph algorithms such as nested dissection, document and\nword clustering, circuit design, among many others. Finding these densely\nconnected regions of graphs remains an important and challenging problem. Most\nwork has focused on scaling up existing methods to handle large graphs. These\nmethods often partition the graph into two or more communities. In this work,\nwe focus on the problem of hierarchical community detection (i.e., finding a\nhierarchy of dense community structures going from the lowest granularity to\nthe largest) and describe an approach that runs in linear time with respect to\nthe number of edges and thus fast and efficient for large-scale networks. The\nexperiments demonstrate the effectiveness of the approach quantitatively.\nFinally, we show an application of it for visualizing large networks with\nhundreds of thousands of nodes/links.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:29:37 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""], ["Koh", "Eunyee", ""], ["Kim", "Sungchul", ""]]}, {"id": "1906.06595", "submitter": "Surbhi Goel", "authors": "Surbhi Goel", "title": "Learning Restricted Boltzmann Machines with Arbitrary External Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning graphical models with latent variables. We\ngive the first algorithm for learning locally consistent (ferromagnetic or\nantiferromagnetic) Restricted Boltzmann Machines (or RBMs) with {\\em arbitrary}\nexternal fields. Our algorithm has optimal dependence on dimension in the\nsample complexity and run time however it suffers from a sub-optimal dependency\non the underlying parameters of the RBM.\n  Prior results have been established only for {\\em ferromagnetic} RBMs with\n{\\em consistent} external fields (signs must be\nsame)\\cite{bresler2018learning}. The proposed algorithm strongly relies on the\nconcavity of magnetization which does not hold in our setting. We show the\nfollowing key structural property: even in the presence of arbitrary external\nfield, for any two observed nodes that share a common latent neighbor, the\ncovariance is high. This enables us to design a simple greedy algorithm that\nmaximizes covariance to iteratively build the neighborhood of each vertex.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:46:19 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Goel", "Surbhi", ""]]}, {"id": "1906.06732", "submitter": "Sidhanth Mohanty", "authors": "Sidhanth Mohanty, Ryan O'Donnell, Pedro Paredes", "title": "The SDP value for random two-eigenvalue CSPs", "comments": "50 pages excluding title page and table of contents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We precisely determine the SDP value (equivalently, quantum value) of large\nrandom instances of certain kinds of constraint satisfaction problems,\n``two-eigenvalue 2CSPs''. We show this SDP value coincides with the spectral\nrelaxation value, possibly indicating a computational threshold. Our analysis\nextends the previously resolved cases of random regular $\\mathsf{2XOR}$ and\n$\\textsf{NAE-3SAT}$, and includes new cases such as random $\\mathsf{Sort}_4$\n(equivalently, $\\mathsf{CHSH}$) and $\\mathsf{Forrelation}$ CSPs. Our techniques\ninclude new generalizations of the nonbacktracking operator, the Ihara--Bass\nFormula, and the Friedman/Bordenave proof of Alon's Conjecture.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 17:30:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mohanty", "Sidhanth", ""], ["O'Donnell", "Ryan", ""], ["Paredes", "Pedro", ""]]}, {"id": "1906.06750", "submitter": "Thibaut Vidal", "authors": "Thibaut Vidal, Gilbert Laporte, Piotr Matl", "title": "A concise guide to existing and emerging vehicle routing problem\n  variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle routing problems have been the focus of extensive research over the\npast sixty years, driven by their economic importance and their theoretical\ninterest. The diversity of applications has motivated the study of a myriad of\nproblem variants with different attributes. In this article, we provide a\nconcise overview of existing and emerging problem variants. Models are\ntypically refined along three lines: considering more relevant objectives and\nperformance metrics, integrating vehicle routing evaluations with other\ntactical decisions, and capturing fine-grained yet essential aspects of modern\nsupply chains. We organize the main problem attributes within this structured\nframework. We discuss recent research directions and pinpoint current\nshortcomings, recent successes, and emerging challenges.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 18:50:18 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:08:07 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Vidal", "Thibaut", ""], ["Laporte", "Gilbert", ""], ["Matl", "Piotr", ""]]}, {"id": "1906.06851", "submitter": "Sheng Yang", "authors": "Mosharaf Chowdhury, Samir Khuller, Manish Purohit, Sheng Yang, Jie You", "title": "Near Optimal Coflow Scheduling in Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3323165.3323179", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coflow scheduling problem has emerged as a popular abstraction in the\nlast few years to study data communication problems within a data center. In\nthis basic framework, each coflow has a set of communication demands and the\ngoal is to schedule many coflows in a manner that minimizes the total weighted\ncompletion time. A coflow is said to complete when all its communication needs\nare met. This problem has been extremely well studied for the case of complete\nbipartite graphs that model a data center with full bisection bandwidth and\nseveral approximation algorithms and effective heuristics have been proposed\nrecently.\n  In this work, we study a slightly different model of coflow scheduling in\ngeneral graphs (to capture traffic between data centers) and develop practical\nand efficient approximation algorithms for it. Our main result is a randomized\n2 approximation algorithm for the single path and free path model,\nsignificantly improving prior work. In addition, we demonstrate via extensive\nexperiments that the algorithm is practical, easy to implement and performs\nwell in practice.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:51:33 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Chowdhury", "Mosharaf", ""], ["Khuller", "Samir", ""], ["Purohit", "Manish", ""], ["Yang", "Sheng", ""], ["You", "Jie", ""]]}, {"id": "1906.06965", "submitter": "Markus Schmid", "authors": "Florin Manea, Markus L. Schmid", "title": "Matching Patterns with Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pattern p (i.e., a string of variables and terminals) matches a word w, if\nw can be obtained by uniformly replacing the variables of p by terminal words.\nThe respective matching problem, i.e., deciding whether or not a given pattern\nmatches a given word, is generally NP-complete, but can be solved in\npolynomial-time for classes of patterns with restricted structure. In this\npaper we overview a series of recent results related to efficient matching for\npatterns with variables, as well as a series of extensions of this problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:38:42 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 14:45:41 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Manea", "Florin", ""], ["Schmid", "Markus L.", ""]]}, {"id": "1906.07105", "submitter": "Adones Rukundo Mr", "authors": "Adones Rukundo, Aras Atalar and Philippas Tsigas", "title": "Monotonically relaxing concurrent data-structure semantics for\n  performance: An efficient 2D design framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a significant amount of work in the literature proposing\nsemantic relaxation of concurrent data structures for improving scalability and\nperformance. By relaxing the semantics of a data structure, a bigger design\nspace, that allows weaker synchronization and more useful parallelism, is\nunveiled. Investigating new data structure designs, capable of trading\nsemantics for achieving better performance in a monotonic way, is a major\nchallenge in the area. We algorithmically address this challenge in this paper.\nWe present an efficient, lock-free, concurrent data structure design framework\nfor out-of-order semantic relaxation. Our framework introduces a new two\ndimensional algorithmic design, that uses multiple instances of a given data\nstructure. The first dimension of our design is the number of data structure\ninstances operations are spread to, in order to benefit from parallelism\nthrough disjoint memory access. The second dimension is the number of\nconsecutive operations that try to use the same data structure instance in\norder to benefit from data locality. Our design can flexibly explore this\ntwo-dimensional space to achieve the property of monotonically relaxing\nconcurrent data structure semantics for achieving better throughput performance\nwithin a tight deterministic relaxation bound, as we prove in the paper. We\nshow how our framework can instantiate lock-free out-of-order queues, stacks,\ncounters and dequeues. We provide implementations of these relaxed data\nstructures and evaluate their performance and behaviour on two parallel\narchitectures. Experimental evaluation shows that our two-dimensional data\nstructures significantly outperform the respected previous proposed ones with\nrespect to scalability and throughput performance. Moreover, their throughput\nincreases monotonically as relaxation increases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:13:15 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Rukundo", "Adones", ""], ["Atalar", "Aras", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1906.07115", "submitter": "Yuan Su", "authors": "Dominic W. Berry, Andrew M. Childs, Yuan Su, Xin Wang, and Nathan\n  Wiebe", "title": "Time-dependent Hamiltonian simulation with $L^1$-norm scaling", "comments": "40 pages, 1 figure", "journal-ref": "Quantum 4, 254 (2020)", "doi": "10.22331/q-2020-04-20-254", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.DS physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The difficulty of simulating quantum dynamics depends on the norm of the\nHamiltonian. When the Hamiltonian varies with time, the simulation complexity\nshould only depend on this quantity instantaneously. We develop quantum\nsimulation algorithms that exploit this intuition. For sparse Hamiltonian\nsimulation, the gate complexity scales with the $L^1$ norm\n$\\int_{0}^{t}\\mathrm{d}\\tau\\left\\lVert H(\\tau)\\right\\lVert_{\\max}$, whereas the\nbest previous results scale with $t\\max_{\\tau\\in[0,t]}\\left\\lVert\nH(\\tau)\\right\\lVert_{\\max}$. We also show analogous results for Hamiltonians\nthat are linear combinations of unitaries. Our approaches thus provide an\nimprovement over previous simulation algorithms that can be substantial when\nthe Hamiltonian varies significantly. We introduce two new techniques: a\nclassical sampler of time-dependent Hamiltonians and a rescaling principle for\nthe Schr\\\"{o}dinger equation. The rescaled Dyson-series algorithm is nearly\noptimal with respect to all parameters of interest, whereas the sampling-based\napproach is easier to realize for near-term simulation. These algorithms could\npotentially be applied to semi-classical simulations of scattering processes in\nquantum chemistry.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:31:56 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 18:00:12 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Berry", "Dominic W.", ""], ["Childs", "Andrew M.", ""], ["Su", "Yuan", ""], ["Wang", "Xin", ""], ["Wiebe", "Nathan", ""]]}, {"id": "1906.07430", "submitter": "Leo van Iersel", "authors": "Katharina T. Huber, Leo van Iersel, Remie Janssen, Mark Jones, Vincent\n  Moulton, Yukihiro Murakami and Charles Semple", "title": "Rooting for phylogenetic networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the relationship between undirected (unrooted) and\ndirected (rooted) phylogenetic networks. We describe a polynomial-time\nalgorithm for deciding whether an undirected binary phylogenetic network, given\nthe locations of the root and reticulation vertices, can be oriented as a\ndirected phylogenetic network. Moreover, we give a mathematical\ncharacterization of when this is the case and show that this directed\nphylogenetic network is then always unique. These results are generalized to\nthe nonbinary case. In addition, we describe an algorithm for deciding whether\nan undirected binary phylogenetic network can be oriented as a directed\nphylogenetic network of a certain class. The algorithm is fixed-parameter\ntractable (FPT) when the parameter is the level of the network and is\napplicable to a wide range of network classes, including tree-child,\ntree-based, stack-free and orchard networks. It can also be used to decide\nwhether an undirected phylogenetic network is tree-based and whether a\npartly-directed phylogenetic network can be oriented as a directed phylogenetic\nnetwork. Finally, we show that, in general, it is NP-hard to decide whether an\nundirected network can be oriented as a tree-based network.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 08:04:10 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Huber", "Katharina T.", ""], ["van Iersel", "Leo", ""], ["Janssen", "Remie", ""], ["Jones", "Mark", ""], ["Moulton", "Vincent", ""], ["Murakami", "Yukihiro", ""], ["Semple", "Charles", ""]]}, {"id": "1906.07673", "submitter": "Samuel Gunn", "authors": "Sam Gunn and Niels Kornerup", "title": "Review of a Quantum Algorithm for Betti Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We looked into the algorithm for calculating Betti numbers presented by\nLloyd, Garnerone, and Zanardi (LGZ). We present a new algorithm in the same\nspirit as LGZ with the intent of clarifying quantum algorithms for computing\nBetti numbers. Our algorithm is simpler and slightly more efficient than that\npresented by LGZ. We present a thorough analysis of our algorithm, pointing out\nreasons that both our algorithm and that presented by LGZ do not run in\npolynomial time for most inputs. However, the algorithms do run in polynomial\ntime for calculating an approximation of the Betti number to polynomial\nmultiplicative error, when applied to some class of graphs for which the Betti\nnumber is exponentially large.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:25:46 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 01:54:56 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 22:39:15 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gunn", "Sam", ""], ["Kornerup", "Niels", ""]]}, {"id": "1906.07754", "submitter": "Patrick O'Hara", "authors": "Patrick O'Hara, M.S. Ramanujan, Theodoros Damoulas", "title": "On the Constrained Least-cost Tour Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Constrained Least-cost Tour (CLT) problem: given an\nundirected graph with weight and cost functions on the edges, minimise the\ntotal cost of a tour rooted at a start vertex such that the total weight lies\nwithin a given range. CLT is related to the family of Travelling Salesman\nProblems with Profits, but differs by defining the weight function on edges\ninstead of vertices, and by requiring the total weight to be within a range\ninstead of being at least some quota. We prove CLT is $\\mathcal{NP}$-hard, even\nin the simple case when the input graph is a path. We derive an informative\nlower bound by relaxing the integrality of edges and propose a heuristic\nmotivated by this relaxation. For the case that requires the tour to be a\nsimple cycle, we develop two heuristics which exploit Suurballe's algorithm to\nfind low-cost, weight-feasible cycles. We demonstrate our algorithms by\naddressing a real-world problem that affects urban populations: finding routes\nthat minimise air pollution exposure for walking, running and cycling in the\ncity of London.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:28:17 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["O'Hara", "Patrick", ""], ["Ramanujan", "M. S.", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "1906.07781", "submitter": "Pavel Kolev", "authors": "Enrico Facca, Andreas Karrenbauer, Pavel Kolev, Kurt Mehlhorn", "title": "Convergence of the Non-Uniform Directed Physarum Model", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.01.034", "report-no": null, "categories": "math.DS cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The directed Physarum dynamics is known to solve positive linear programs:\nminimize $c^T x$ subject to $Ax = b$ and $x \\ge 0$ for a positive cost vector\n$c$. The directed Physarum dynamics evolves a positive vector $x$ according to\nthe dynamics $\\dot{x} = q(x) - x$. Here $q(x)$ is the solution to $Af = b$ that\nminimizes the \"energy\" $\\sum_i c_i f_i^2/x_i$.\n  In this paper, we study the non-uniform directed dynamics $\\dot{x} = D(q(x) -\nx)$, where $D$ is a positive diagonal matrix. The non-uniform dynamics is more\ncomplex than the uniform dynamics (with $D$ being the identity matrix), as it\nallows each component of $x$ to react with different speed to the differences\nbetween $q(x)$ and $x$. Our contribution is to show that the non-uniform\ndirected dynamics solves positive linear programs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 19:37:42 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 11:36:22 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Facca", "Enrico", ""], ["Karrenbauer", "Andreas", ""], ["Kolev", "Pavel", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1906.07871", "submitter": "Sankardeep Chakraborty", "authors": "Sankardeep Chakraborty, Kunihiko Sadakane", "title": "Indexing Graph Search Trees and Applications", "comments": "23 pages, Preliminary version of this paper will appear in MFCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of compactly representing the Depth First Search\n(DFS) tree of a given undirected or directed graph having $n$ vertices and $m$\nedges while supporting various DFS related queries efficiently in the RAM with\nlogarithmic word size. We study this problem in two well-known models: {\\it\nindexing} and {\\it encoding} models. While most of these queries can be\nsupported easily in constant time using $O(n \\lg n)$ bits\\footnote{We use $\\lg$\nto denote logarithm to the base $2$.} of extra space, our goal here is, more\nspecifically, to beat this trivial $O(n \\lg n)$ bit space bound, yet not\ncompromise too much on the running time of these queries. In the {\\it indexing}\nmodel, the space bound of our solution involves the quantity $m$, hence, we\nobtain different bounds for sparse and dense graphs respectively. In the {\\it\nencoding} model, we first give a space lower bound, followed by an almost\noptimal data structure with extremely fast query time. Central to our algorithm\nis a partitioning of the DFS tree into connected subtrees, and a compact way to\nstore these connections. Finally, we also apply these techniques to compactly\nindex the shortest path structure, biconnectivity structures among others.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:34:47 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chakraborty", "Sankardeep", ""], ["Sadakane", "Kunihiko", ""]]}, {"id": "1906.07874", "submitter": "Sankardeep Chakraborty", "authors": "Sankardeep Chakraborty, Anish Mukherjee, Srinivasa Rao Satti", "title": "Space Efficient Algorithms for Breadth-Depth Search", "comments": "12 pages, This work will appear in FCT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuing the recent trend, in this article we design several\nspace-efficient algorithms for two well-known graph search methods. Both these\nsearch methods share the same name {\\it breadth-depth search} (henceforth {\\sf\nBDS}), although they work entirely in different fashion. The classical\nimplementation for these graph search methods takes $O(m+n)$ time and $O(n \\lg\nn)$ bits of space in the standard word RAM model (with word size being\n$\\Theta(\\lg n)$ bits), where $m$ and $n$ denotes the number of edges and\nvertices of the input graph respectively. Our goal here is to beat the space\nbound of the classical implementations, and design $o(n \\lg n)$ space\nalgorithms for these search methods by paying little to no penalty in the\nrunning time. Note that our space bounds (i.e., with $o(n \\lg n)$ bits of\nspace) do not even allow us to explicitly store the required information to\nimplement the classical algorithms, yet our algorithms visits and reports all\nthe vertices of the input graph in correct order.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:45:10 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chakraborty", "Sankardeep", ""], ["Mukherjee", "Anish", ""], ["Satti", "Srinivasa Rao", ""]]}, {"id": "1906.07887", "submitter": "Kedar Tatwawadi", "authors": "Kedar Tatwawadi, Shubham Chandak", "title": "Tutorial on algebraic deletion correction codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deletion channel is known to be a notoriously diffcult channel to design\nerror-correction codes for. In spite of this difficulty, there are some\nbeautiful code constructions which give some intuition about the channel and\nabout what good deletion codes look like. In this tutorial we will take a look\nat some of them. This document is a transcript of my talk at the coding theory\nreading group on some interesting works on deletion channel. It is not intended\nto be an exhaustive survey of works on deletion channel, but more as a tutorial\nto some of the important and cute ideas in this area. For a comprehensive\nsurvey, we refer the reader to the cited sources and surveys.\n  We also provide an implementation of VT codes that correct single\ninsertion/deletion errors for general alphabets at\nhttps://github.com/shubhamchandak94/VT_codes/.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 02:56:11 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Tatwawadi", "Kedar", ""], ["Chandak", "Shubham", ""]]}, {"id": "1906.08320", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Rasmus Pagh, Ameya Velingker", "title": "Scalable and Differentially Private Distributed Aggregation in the\n  Shuffled Model", "comments": "17 pages, 1 figure, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning promises to make machine learning feasible on distributed,\nprivate datasets by implementing gradient descent using secure aggregation\nmethods. The idea is to compute a global weight update without revealing the\ncontributions of individual users. Current practical protocols for secure\naggregation work in an \"honest but curious\" setting where a curious adversary\nobserving all communication to and from the server cannot learn any private\ninformation assuming the server is honest and follows the protocol. A more\nscalable and robust primitive for privacy-preserving protocols is shuffling of\nuser data, so as to hide the origin of each data item. Highly scalable and\nsecure protocols for shuffling, so-called mixnets, have been proposed as a\nprimitive for privacy-preserving analytics in the Encode-Shuffle-Analyze\nframework by Bittau et al., which was later analytically studied by Erlingsson\net al. and Cheu et al.. The recent papers by Cheu et al., and Balle et al. have\ngiven protocols for secure aggregation that achieve differential privacy\nguarantees in this \"shuffled model\". Their protocols come at a cost, though:\nEither the expected aggregation error or the amount of communication per user\nscales as a polynomial $n^{\\Omega(1)}$ in the number of users $n$. In this\npaper we propose simple and more efficient protocol for aggregation in the\nshuffled model, where communication as well as error increases only\npolylogarithmically in $n$. Our new technique is a conceptual \"invisibility\ncloak\" that makes users' data almost indistinguishable from random noise while\nintroducing zero distortion on the sum.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:30:05 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 17:21:17 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:53:21 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ghazi", "Badih", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1906.08371", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Karolina Okrasa, Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Fine-grained complexity of the graph homomorphism problem for\n  bounded-treewidth graphs", "comments": "An extended abstract of this paper appeared on SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs $G$ and $H$, a \\emph{homomorphism} from $G$ to $H$ is an\nedge-preserving mapping from the vertex set of $G$ to the vertex set of $H$.\nFor a fixed graph $H$, by \\textsc{Hom($H$)} we denote the computational problem\nwhich asks whether a given graph $G$ admits a homomorphism to $H$. If $H$ is a\ncomplete graph with $k$ vertices, then \\textsc{Hom($H$)} is equivalent to the\n$k$-\\textsc{Coloring} problem, so graph homomorphisms can be seen as\ngeneralizations of colorings. It is known that \\textsc{Hom($H$)} is\npolynomial-time solvable if $H$ is bipartite or has a vertex with a loop, and\nNP-complete otherwise [Hell and Ne\\v{s}et\\v{r}il, JCTB 1990]. In this paper we\nare interested in the complexity of the problem, parameterized by the treewidth\nof the input graph $G$. If $G$ has $n$ vertices and is given along with its\ntree decomposition of width $\\mathrm{tw}(G)$, then the problem can be solved in\ntime $|V(H)|^{\\mathrm{tw}(G)} \\cdot n^{\\mathcal{O}(1)}$, using a\nstraightforward dynamic programming. We explore whether this bound can be\nimproved. We show that if $H$ is a \\emph{projective core}, then the existence\nof such a faster algorithm is unlikely: assuming the Strong Exponential Time\nHypothesis (SETH), the \\textsc{Hom($H$)} problem cannot be solved in time\n$(|V(H)|-\\epsilon)^{\\mathrm{tw}(G)} \\cdot n^{\\mathcal{O}(1)}$, for any\n$\\epsilon > 0$. This result provides a full complexity characterization for a\nlarge class of graphs $H$, as almost all graphs are projective cores. We also\nnotice that the naive algorithm can be improved for some graphs $H$, and show a\ncomplexity classification for all graphs $H$, assuming two conjectures from\nalgebraic graph theory. In particular, there are no known graphs $H$ which are\nnot covered by our result. In order to prove our results, we bring together\nsome tools and techniques from algebra and from fine-grained complexity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:41:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 14:09:29 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 23:36:24 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Okrasa", "Karolina", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1906.08448", "submitter": "Siu-Wing Cheng", "authors": "Siu-Wing Cheng and Kai Jin and Lie Yan", "title": "Extensions of Self-Improving Sorters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ailon et al. (SICOMP 2011) proposed a self-improving sorter that tunes its\nperformance to an unknown input distribution in a training phase. The input\nnumbers $x_1,x_2,\\ldots,x_n$ come from a product distribution, that is, each\n$x_i$ is drawn independently from an arbitrary distribution ${\\cal D}_i$. We\nstudy two relaxations of this requirement. The first extension models hidden\nclasses in the input. We consider the case that numbers in the same class are\ngoverned by linear functions of the same hidden random parameter. The second\nextension considers a hidden mixture of product distributions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 05:27:37 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Jin", "Kai", ""], ["Yan", "Lie", ""]]}, {"id": "1906.08484", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, Shaofeng H.-C. Jiang, Nisheeth K. Vishnoi", "title": "Coresets for Clustering with Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work, [19] studied the following \"fair\" variants of classical\nclustering problems such as $k$-means and $k$-median: given a set of $n$ data\npoints in $\\mathbb{R}^d$ and a binary type associated to each data point, the\ngoal is to cluster the points while ensuring that the proportion of each type\nin each cluster is roughly the same as its underlying proportion. Subsequent\nwork has focused on either extending this setting to when each data point has\nmultiple, non-disjoint sensitive types such as race and gender [6], or to\naddress the problem that the clustering algorithms in the above work do not\nscale well. The main contribution of this paper is an approach to clustering\nwith fairness constraints that involve multiple, non-disjoint types, that is\nalso scalable. Our approach is based on novel constructions of coresets: for\nthe $k$-median objective, we construct an $\\varepsilon$-coreset of size\n$O(\\Gamma k^2 \\varepsilon^{-d})$ where $\\Gamma$ is the number of distinct\ncollections of groups that a point may belong to, and for the $k$-means\nobjective, we show how to construct an $\\varepsilon$-coreset of size $O(\\Gamma\nk^3\\varepsilon^{-d-1})$. The former result is the first known coreset\nconstruction for the fair clustering problem with the $k$-median objective, and\nthe latter result removes the dependence on the size of the full dataset as in\n[39] and generalizes it to multiple, non-disjoint types. Plugging our coresets\ninto existing algorithms for fair clustering such as [5] results in the fastest\nalgorithms for several cases. Empirically, we assess our approach over the\n\\textbf{Adult}, \\textbf{Bank}, \\textbf{Diabetes} and \\textbf{Athlete} dataset,\nand show that the coreset sizes are much smaller than the full dataset. We also\nachieve a speed-up to recent fair clustering algorithms [5,6] by incorporating\nour coreset construction.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:00:39 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:22:18 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 14:02:48 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 16:52:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Huang", "Lingxiao", ""], ["Jiang", "Shaofeng H. -C.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.08656", "submitter": "Haoyu Zhao", "authors": "Haoyu Zhao, Wei Chen", "title": "Stochastic One-Sided Full-Information Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the stochastic version of the one-sided full\ninformation bandit problem, where we have $K$ arms $[K] = \\{1, 2, \\ldots, K\\}$,\nand playing arm $i$ would gain reward from an unknown distribution for arm $i$\nwhile obtaining reward feedback for all arms $j \\ge i$. One-sided full\ninformation bandit can model the online repeated second-price auctions, where\nthe auctioneer could select the reserved price in each round and the bidders\nonly reveal their bids when their bids are higher than the reserved price. In\nthis paper, we present an elimination-based algorithm to solve the problem. Our\nelimination based algorithm achieves distribution independent regret upper\nbound $O(\\sqrt{T\\cdot\\log (TK)})$, and distribution dependent bound $O((\\log T\n+ \\log K)f(\\Delta))$, where $T$ is the time horizon, $\\Delta$ is a vector of\ngaps between the mean reward of arms and the mean reward of the best arm, and\n$f(\\Delta)$ is a formula depending on the gap vector that we will specify in\ndetail. Our algorithm has the best theoretical regret upper bound so far. We\nalso validate our algorithm empirically against other possible alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:19:28 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zhao", "Haoyu", ""], ["Chen", "Wei", ""]]}, {"id": "1906.08971", "submitter": "Laurent Viennot", "authors": "Duc-Minh Phan, Laurent Viennot (GANG, IRIF, LINCS, UPD7)", "title": "Fast Public Transit Routing with Unrestricted Walking through Hub\n  Labeling", "comments": null, "journal-ref": "Special Event on Analysis of Experimental Algorithms (SEA2), Jun\n  2019, Kalamata, Greece", "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel technique for answering routing queries in public\ntransportation networks that allows unrestricted walking. We consider several\ntypes of queries: earliest arrival time, Pareto-optimal journeys regarding\narrival time, number of transfers and walking time, and profile, i.e. finding\nall Pareto-optimal journeys regarding travel time and arrival time in a given\ntime interval. Our techniques uses hub labeling to represent unlimited foot\ntransfers and can be adapted to both classical algorithms RAPTOR and CSA. We\nobtain significant speedup compared to the state-of-the-art approach based on\ncontraction hierarchies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 06:25:10 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Phan", "Duc-Minh", "", "GANG, IRIF, LINCS, UPD7"], ["Viennot", "Laurent", "", "GANG, IRIF, LINCS, UPD7"]]}, {"id": "1906.09047", "submitter": "Carsten Witt", "authors": "Hsien-Kuei Hwang and Carsten Witt", "title": "Sharp Bounds on the Runtime of the (1+1) EA via Drift Analysis and\n  Analytic Combinatorial Tools", "comments": "33 pages; preprint of a paper that will be published in the\n  proceedings of FOGA 2019; v2: minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected running time of the classical (1+1) EA on the OneMax benchmark\nfunction has recently been determined by Hwang et al. (2018) up to additive\nerrors of $O((\\log n)/n)$. The same approach proposed there also leads to a\nfull asymptotic expansion with errors of the form $O(n^{-K}\\log n)$ for any\n$K>0$. This precise result is obtained by matched asymptotics with rigorous\nerror analysis (or by solving asymptotically the underlying recurrences via\ninductive approximation arguments), ideas radically different from\nwell-established techniques for the running time analysis of evolutionary\ncomputation such as drift analysis. This paper revisits drift analysis for the\n(1+1) EA on OneMax and obtains that the expected running time $E(T)$, starting\nfrom $\\lceil n/2\\rceil$ one-bits, is determined by the sum of inverse drifts up\nto logarithmic error terms, more precisely $$\\sum_{k=1}^{\\lfloor\nn/2\\rfloor}\\frac{1}{\\Delta(k)} - c_1\\log n \\le E(T) \\le \\sum_{k=1}^{\\lfloor\nn/2\\rfloor}\\frac{1}{\\Delta(k)} - c_2\\log n,$$ where $\\Delta(k)$ is the drift\n(expected increase of the number of one-bits from the state of $n-k$ ones) and\n$c_1,c_2 >0$ are explicitly computed constants. This improves the previous\nasymptotic error known for the sum of inverse drifts from $\\tilde{O}(n^{2/3})$\nto a logarithmic error and gives for the first time a non-asymptotic error\nbound. Using standard asymptotic techniques, the difference between $E(T)$ and\nthe sum of inverse drifts is found to be $(e/2)\\log n+O(1)$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:25:39 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 06:51:25 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Hwang", "Hsien-Kuei", ""], ["Witt", "Carsten", ""]]}, {"id": "1906.09050", "submitter": "Kate Donahue", "authors": "Kate Donahue, Jon Kleinberg", "title": "Fairness and Utilization in Allocating Resources with Uncertain Demand", "comments": "Accepted for presentation and archival submission at FAT* 2020.\n  Accepted for oral presentation at MD4SG 2019", "journal-ref": null, "doi": "10.1145/3351095.3372847", "report-no": null, "categories": "cs.DS cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation problems are a fundamental domain in which to evaluate\nthe fairness properties of algorithms. The trade-offs between fairness and\nutilization have a long history in this domain. A recent line of work has\nconsidered fairness questions for resource allocation when the demands for the\nresource are distributed across multiple groups and drawn from probability\ndistributions. In such cases, a natural fairness requirement is that\nindividuals from different groups should have (approximately) equal\nprobabilities of receiving the resource. A largely open question in this area\nhas been to bound the gap between the maximum possible utilization of the\nresource and the maximum possible utilization subject to this fairness\ncondition.\n  Here, we obtain some of the first provable upper bounds on this gap. We\nobtain an upper bound for arbitrary distributions, as well as much stronger\nupper bounds for specific families of distributions that are typically used to\nmodel levels of demand. In particular, we find - somewhat surprisingly - that\nthere are natural families of distributions (including Exponential and Weibull)\nfor which the gap is non-existent: it is possible to simultaneously achieve\nmaximum utilization and the given notion of fairness. Finally, we show that for\npower-law distributions, there is a non-trivial gap between the solutions, but\nthis gap can be bounded by a constant factor independent of the parameters of\nthe distribution.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:35:23 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 19:34:35 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Donahue", "Kate", ""], ["Kleinberg", "Jon", ""]]}, {"id": "1906.09180", "submitter": "Felix Reidl", "authors": "Carl Einarson, Felix Reidl", "title": "Domination above r-independence: does sparseness help?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the potential of improving tractability via gap- or\nabove-guarantee parametrisations, we investigate the complexity of Dominating\nSet when given a suitable lower-bound witness. Concretely, we consider being\nprovided with a maximal r-independent set X (a set in which all vertices have\npairwise distance at least r + 1) along the input graph G which, for r >= 2,\nlower-bounds the minimum size of any dominating set of G. In the spirit of\ngap-parameters, we consider a parametrisation by the size of the 'residual' set\nR := V (G) \\ N [X]. Our work aims to answer two questions: How does the\nconstant r affect the tractability of the problem and does the restriction to\nsparse graph classes help here? For the base case r = 2, we find that the\nproblem is paraNP -complete even in apex- and bounded-degree graphs. For r = 3,\nthe problem is W[2]-hard for general graphs but in FPT for nowhere dense\nclasses and it admits a linear kernel for bounded expansion classes. For r >=\n4, the parametrisation becomes essentially equivalent to the natural parameter,\nthe size of the dominating set.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:04:16 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Einarson", "Carl", ""], ["Reidl", "Felix", ""]]}, {"id": "1906.09213", "submitter": "Radovan \\v{C}erven\\'y", "authors": "Radovan \\v{C}erven\\'y and Ond\\v{r}ej Such\\'y", "title": "Faster FPT Algorithm for 5-Path Vertex Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of $d$-Path Vertex Cover, $d$-PVC lies in determining a subset\n$F$ of vertices of a given graph $G=(V,E)$ such that $G \\setminus F$ does not\ncontain a path on $d$ vertices. The paths we aim to cover need not to be\ninduced. It is known that the $d$-PVC problem is NP-complete for any $d \\ge 2$.\nWhen parameterized by the size of the solution $k$, 5-PVC has direct trivial\nalgorithm with $\\mathcal{O}(5^kn^{\\mathcal{O}(1)})$ running time and, since\n$d$-PVC is a special case of $d$-Hitting Set, an algorithm running in\n$\\mathcal{O}(4.0755^kn^{\\mathcal{O}(1)})$ time is known. In this paper we\npresent an iterative compression algorithm that solves the 5-PVC problem in\n$\\mathcal{O}(4^kn^{\\mathcal{O}(1)})$ time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:57:04 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["\u010cerven\u00fd", "Radovan", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "1906.09224", "submitter": "Giacomo Ortali", "authors": "Giacomo Ortali (1) and Ioannis G. Tollis (2) ((1) University of\n  Perugia, (2) Computer Science Department, University of Crete, Heraklion,\n  Crete, Greece and Tom Sawyer Software, Inc. Berkeley, CA, U.S.A.)", "title": "Multidimensional Dominance Drawings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a DAG with $n$ vertices and $m$ edges. Two vertices $u,v$ are\nincomparable if $u$ doesn't reach $v$ and vice versa. We denote by \\emph{width}\nof a DAG $G$, $w_G$, the maximum size of a set of incomparable vertices of $G$.\nIn this paper we present an algorithm that computes a dominance drawing of a\nDAG G in $k$ dimensions, where $w_G \\le k \\le \\frac{n}{2}$. The time required\nby the algorithm is $O(kn)$, with a precomputation time of $O(km)$, needed to\ncompute a \\emph{compressed transitive closure} of $G$, and extra $O(n^2w_G)$ or\n$O(n^3)$ time, if we want $k=w_G$. Our algorithm gives a tighter bound to the\ndominance dimension of a DAG. As corollaries, a new family of graphs having a\n2-dimensional dominance drawing and a new upper bound to the dimension of a\npartial order are obtained. We also introduce the concept of transitive module\nand dimensional neck, $w_N$, of a DAG $G$ and we show how to improve the\nresults given previously using these concepts.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:13:17 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ortali", "Giacomo", ""], ["Tollis", "Ioannis G.", ""]]}, {"id": "1906.09226", "submitter": "Marcelo Arenas", "authors": "Marcelo Arenas, Luis Alberto Croquevielle, Rajesh Jayaram, Cristian\n  Riveros", "title": "$\\text{#NFA}$ admits an FPRAS: Efficient Enumeration, Counting, and\n  Uniform Generation for Logspace Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study two simple yet general complexity classes, based on\nlogspace Turing machines, which provide a unifying framework for efficient\nquery evaluation in areas like information extraction and graph databases,\namong others. We investigate the complexity of three fundamental algorithmic\nproblems for these classes: enumeration, counting and uniform generation of\nsolutions, and show that they have several desirable properties in this\nrespect.\n  Both complexity classes are defined in terms of non-deterministic logspace\ntransducers (NL transducers). For the first class, we consider the case of\nunambiguous NL transducers, and we prove constant delay enumeration, and both\ncounting and uniform generation of solutions in polynomial time. For the second\nclass, we consider unrestricted NL transducers, and we obtain polynomial delay\nenumeration, approximate counting in polynomial time, and polynomial-time\nrandomized algorithms for uniform generation. More specifically, we show that\neach problem in this second class admits a fully polynomial-time randomized\napproximation scheme (FPRAS) and a polynomial-time Las Vegas algorithm for\nuniform generation. Interestingly, the key idea to prove these results is to\nshow that the fundamental problem $\\text{#NFA}$ admits an FPRAS, where\n$\\text{#NFA}$ is the problem of counting the number of strings of length $n$\n(given in unary) accepted by a non-deterministic finite automaton (NFA). While\nthis problem is known to be $\\text{#P}$-complete and, more precisely,\n$\\text{SpanL}$-complete, it was open whether this problem admits an FPRAS. In\nthis work, we solve this open problem, and obtain as a welcome corollary that\nevery function in $\\text{SpanL}$ admits an FPRAS.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:22:53 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 17:49:06 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 01:26:48 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 16:25:32 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Arenas", "Marcelo", ""], ["Croquevielle", "Luis Alberto", ""], ["Jayaram", "Rajesh", ""], ["Riveros", "Cristian", ""]]}, {"id": "1906.09372", "submitter": "Tongwen Wu", "authors": "Tongwen Wu, Zizhen Zhang, Yanzhi Li, Jiahai Wang", "title": "Collective Mobile Sequential Recommendation: A Recommender System for\n  Multiple Taxicabs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sequential recommendation was originally designed to find a promising\nroute for a single taxicab. Directly applying it for multiple taxicabs may\ncause an excessive overlap of recommended routes. The multi-taxicab\nrecommendation problem is challenging and has been less studied. In this paper,\nwe first formalize a collective mobile sequential recommendation problem based\non a classic mathematical model, which characterizes time-varying influence\namong competing taxicabs. Next, we propose a new evaluation metric for a\ncollection of taxicab routes aimed to minimize the sum of potential travel\ntime. We then develop an efficient algorithm to calculate the metric and design\na greedy recommendation method to approximate the solution. Finally, numerical\nexperiments show the superiority of our methods. In trace-driven simulation,\nthe set of routes recommended by our method significantly outperforms those\nobtained by conventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 02:51:50 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wu", "Tongwen", ""], ["Zhang", "Zizhen", ""], ["Li", "Yanzhi", ""], ["Wang", "Jiahai", ""]]}, {"id": "1906.09430", "submitter": "Tobias Christiani", "authors": "Tobias Christiani", "title": "Algorithms for Similarity Search and Pseudorandomness", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximate near neighbor (ANN) search and show the\nfollowing results:\n  - An improved framework for solving the ANN problem using locality-sensitive\nhashing, reducing the number of evaluations of locality-sensitive hash\nfunctions and the word-RAM complexity compared to the standard framework.\n  - A framework for solving the ANN problem with space-time tradeoffs as well\nas tight upper and lower bounds for the space-time tradeoff of framework\nsolutions to the ANN problem under cosine similarity.\n  - A novel approach to solving the ANN problem on sets along with a matching\nlower bound, improving the state of the art.\n  - A self-tuning version of the algorithm is shown through experiments to\noutperform existing similarity join algorithms.\n  - Tight lower bounds for asymmetric locality-sensitive hashing which has\napplications to the approximate furthest neighbor problem, orthogonal vector\nsearch, and annulus queries.\n  - A proof of the optimality of a well-known Boolean locality-sensitive\nhashing scheme.\n  We study the problem of efficient algorithms for producing high-quality\npseudorandom numbers and obtain the following results:\n  - A deterministic algorithm for generating pseudorandom numbers of\narbitrarily high quality in constant time using near-optimal space.\n  - A randomized construction of a family of hash functions that outputs\npseudorandom numbers of arbitrarily high quality with space usage and running\ntime nearly matching known cell-probe lower bounds.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 10:53:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Christiani", "Tobias", ""]]}, {"id": "1906.09501", "submitter": "Vasiliki Velona", "authors": "G\\'abor Lugosi, Jakub Truszkowski, Vasiliki Velona, Piotr Zwiernik", "title": "Structure learning in graphical models by covariance queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering the structure underlying large Gaussian\ngraphical models or, more generally, partial correlation graphs. In\nhigh-dimensional problems it is often too costly to store the entire sample\ncovariance matrix. We propose a new input model in which one can query single\nentries of the covariance matrix. We prove that it is possible to recover the\nsupport of the inverse covariance matrix with low query and computational\ncomplexity. Our algorithms work in a regime when this support is represented by\ntree-like graphs and, more generally, for graphs of small treewidth. Our\nresults demonstrate that for large classes of graphs, the structure of the\ncorresponding partial correlation graphs can be determined much faster than\neven computing the empirical covariance matrix.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 20:44:52 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 11:05:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Truszkowski", "Jakub", ""], ["Velona", "Vasiliki", ""], ["Zwiernik", "Piotr", ""]]}, {"id": "1906.09595", "submitter": "Morteza Monemizadeh", "authors": "Morteza Monemizadeh", "title": "Dynamic Maximal Independent Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream $\\mathcal{S}$ of insertions and deletions of edges of an\nunderlying graph $G$ (with fixed vertex set $V$ where $n=|V|$ is the number of\nvertices of $G$), we propose a dynamic algorithm that maintains a maximal\nindependent set (MIS) of $G$ (at any time $t$ of the stream $\\mathcal{S}$) with\namortized update time $O(\\log^3 n)$.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 13:19:05 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Monemizadeh", "Morteza", ""]]}, {"id": "1906.09680", "submitter": "Kazuhiro Kurita", "authors": "Kazuhiro Kurita, Kunihiro Wasa, Hiroki Arimura, and Takeaki Uno", "title": "Constant Amortized Time Enumeration of Independent Sets for Graphs with\n  Bounded Clique Number", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2021.05.008", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we address the independent set enumeration problem. Although\nseveral efficient enumeration algorithms and careful analyses have been\nproposed for maximal independent sets, no fine-grained analysis has been given\nfor the non-maximal variant. From the main result, we propose an algorithm\n$\\texttt{EIS}$ for the non-maximal variant that runs in $O(q)$ amortized time\nand linear space, where $q$ is the clique number, i.e., the maximum size of a\nclique in an input graph. Note that $\\texttt{EIS}$ works correctly even if the\nexact value of $q$ is unknown. Despite its simplicity, $\\texttt{EIS}$ is\noptimal for graphs with a bounded clique number, such as, triangle-free graphs,\nplanar graphs, bounded degenerate graphs, locally bounded expansion graphs, and\n$F$-free graphs for any fixed graph $F$, where a $F$-free graph is a graph that\nhas no copy of $F$ as a subgraph.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:00:05 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 15:39:09 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Kurita", "Kazuhiro", ""], ["Wasa", "Kunihiro", ""], ["Arimura", "Hiroki", ""], ["Uno", "Takeaki", ""]]}, {"id": "1906.09732", "submitter": "Amihood Amir", "authors": "Amihood Amir and Itai Boneh", "title": "Dynamic Palindrome Detection", "comments": "arXiv admin note: text overlap with arXiv:1806.02718 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately, there is a growing interest in dynamic string matching problems.\nSpecifically, the dynamic Longest Common Factor problem has been researched and\nsome interesting results has been reached. In this paper we examine another\nclassic string problem in a dynamic setting - finding the longest palindrome\nsubstring of a given string. We show that the longest palindrome can be\nmaintained in poly-logarithmic time per symbol edit.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 05:33:41 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Amir", "Amihood", ""], ["Boneh", "Itai", ""]]}, {"id": "1906.09783", "submitter": "Arnold Filtser", "authors": "Arnold Filtser", "title": "On Strong Diameter Padded Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a weighted graph $G=(V,E,w)$, a partition of $V$ is $\\Delta$-bounded if\nthe diameter of each cluster is bounded by $\\Delta$. A distribution over\n$\\Delta$-bounded partitions is a $\\beta$-padded decomposition if every ball of\nradius $\\gamma\\Delta$ is contained in a single cluster with probability at\nleast $e^{-\\beta\\cdot\\gamma}$. The weak diameter of a cluster $C$ is measured\nw.r.t. distances in $G$, while the strong diameter is measured w.r.t. distances\nin the induced graph $G[C]$. The decomposition is weak/strong according to the\ndiameter guarantee.\n  Formerly, it was proven that $K_r$ free graphs admit weak decompositions with\npadding parameter $O(r)$, while for strong decompositions only $O(r^2)$ padding\nparameter was known. Furthermore, for the case of a graph $G$, for which the\ninduced shortest path metric $d_G$ has doubling dimension $d$, a weak\n$O(d)$-padded decomposition was constructed, which is also known to be tight.\nFor the case of strong diameter, nothing was known.\n  We construct strong $O(r)$-padded decompositions for $K_r$ free graphs,\nmatching the state of the art for weak decompositions. Similarly, for graphs\nwith doubling dimension $d$ we construct a strong $O(d)$-padded decomposition,\nwhich is also tight. We use this decomposition to construct\n$(O(d),\\tilde{O}(d))$-sparse cover scheme for such graphs. Our new\ndecompositions and cover have implications to approximating unique games, the\nconstruction of light and sparse spanners, and for path reporting distance\noracles.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:41:08 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Filtser", "Arnold", ""]]}, {"id": "1906.10012", "submitter": "Dekel Tsur", "authors": "Dekel Tsur", "title": "Algorithms for deletion problems on split graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Split to Block Vertex Deletion and Split to Threshold Vertex Deletion\nproblems the input is a split graph $G$ and an integer $k$, and the goal is to\ndecide whether there is a set $S$ of at most $k$ vertices such that $G-S$ is a\nblock graph and $G-S$ is a threshold graph, respectively. In this paper we give\nalgorithms for these problems whose running times are $O^*(2.076^k)$ and\n$O^*(2.733^k)$, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:06:40 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 15:07:32 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 04:57:06 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Tsur", "Dekel", ""]]}, {"id": "1906.10075", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Christos Tzamos", "title": "Distribution-Independent PAC Learning of Halfspaces with Massart Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of {\\em distribution-independent} PAC learning of\nhalfspaces in the presence of Massart noise. Specifically, we are given a set\nof labeled examples $(\\mathbf{x}, y)$ drawn from a distribution $\\mathcal{D}$\non $\\mathbb{R}^{d+1}$ such that the marginal distribution on the unlabeled\npoints $\\mathbf{x}$ is arbitrary and the labels $y$ are generated by an unknown\nhalfspace corrupted with Massart noise at noise rate $\\eta<1/2$. The goal is to\nfind a hypothesis $h$ that minimizes the misclassification error\n$\\mathbf{Pr}_{(\\mathbf{x}, y) \\sim \\mathcal{D}} \\left[ h(\\mathbf{x}) \\neq y\n\\right]$.\n  We give a $\\mathrm{poly}\\left(d, 1/\\epsilon \\right)$ time algorithm for this\nproblem with misclassification error $\\eta+\\epsilon$. We also provide evidence\nthat improving on the error guarantee of our algorithm might be computationally\nhard. Prior to our work, no efficient weak (distribution-independent) learner\nwas known in this model, even for the class of disjunctions. The existence of\nsuch an algorithm for halfspaces (or even disjunctions) has been posed as an\nopen question in various works, starting with Sloan (1988), Cohen (1997), and\nwas most recently highlighted in Avrim Blum's FOCS 2003 tutorial.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:54:46 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:46:00 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Tzamos", "Christos", ""]]}, {"id": "1906.10275", "submitter": "Abusayeed Saifullah", "authors": "Abusayeed Saifullah", "title": "2-Edge-Connectivity and 2-Vertex-Connectivity of an Asynchronous\n  Distributed Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-stabilization for non-masking fault-tolerant distributed system has\nreceived considerable research interest over the last decade. In this paper, we\npropose a self-stabilizing algorithm for 2-edge-connectivity and\n2-vertex-connectivity of an asynchronous distributed computer network. It is\nbased on a self-stabilizing depth-first search, and is not a composite\nalgorithm in the sense that it is not composed of a number of self-stabilizing\nalgorithms that run concurrently. The time and space complexities of the\nalgorithm are the same as those of the underlying self-stabilizing depth-first\nsearch algorithm which are O(dn\\Delta) rounds and O(n\\log \\Delta) bits per\nprocessor, respectively, where \\Delta (<= n) is an upper bound on the degree of\na node, d (<= n) is the diameter of the graph, and n is the number of nodes in\nthe network.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 20:55:18 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Saifullah", "Abusayeed", ""]]}, {"id": "1906.10340", "submitter": "Richard Peng", "authors": "Rasmus Kyng, Richard Peng, Sushant Sachdeva, Di Wang", "title": "Flows in Almost Linear Time via Adaptive Preconditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for solving a large class of flow and regression\nproblems on unit weighted graphs to $(1 + 1 / poly(n))$ accuracy in\nalmost-linear time. These problems include $\\ell_p$-norm minimizing flow for\n$p$ large ($p \\in [\\omega(1), o(\\log^{2/3} n) ]$), and their duals,\n$\\ell_p$-norm semi-supervised learning for $p$ close to $1$.\n  As $p$ tends to infinity, $\\ell_p$-norm flow and its dual tend to max-flow\nand min-cut respectively. Using this connection and our algorithms, we give an\nalternate approach for approximating undirected max-flow, and the first\nalmost-linear time approximations of discretizations of total variation\nminimization objectives.\n  This algorithm demonstrates that many tools previous viewed as limited to\nlinear systems are in fact applicable to a much wider range of convex\nobjectives. It is based on the the routing-based solver for Laplacian linear\nsystems by Spielman and Teng (STOC '04, SIMAX '14), but require several new\ntools: adaptive non-linear preconditioning, tree-routing based\nultra-sparsification for mixed $\\ell_2$ and $\\ell_p$ norm objectives, and\ndecomposing graphs into uniform expanders.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 06:34:40 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Kyng", "Rasmus", ""], ["Peng", "Richard", ""], ["Sachdeva", "Sushant", ""], ["Wang", "Di", ""]]}, {"id": "1906.10375", "submitter": "Ashley Montanaro", "authors": "Ashley Montanaro", "title": "Quantum speedup of branch-and-bound algorithms", "comments": "11 pages, 5 figures", "journal-ref": "Phys. Rev. Research 2, 013056 (2020)", "doi": "10.1103/PhysRevResearch.2.013056", "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch-and-bound is a widely used technique for solving combinatorial\noptimisation problems where one has access to two procedures: a branching\nprocedure that splits a set of potential solutions into subsets, and a cost\nprocedure that determines a lower bound on the cost of any solution in a given\nsubset. Here we describe a quantum algorithm that can accelerate classical\nbranch-and-bound algorithms near-quadratically in a very general setting. We\nshow that the quantum algorithm can find exact ground states for most instances\nof the Sherrington-Kirkpatrick model in time $O(2^{0.226n})$, which is\nsubstantially more efficient than Grover's algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 08:27:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Montanaro", "Ashley", ""]]}, {"id": "1906.10523", "submitter": "Dekel Tsur", "authors": "Dekel Tsur", "title": "l-path vertex cover is easier than l-hitting set for small l", "comments": "arXiv admin note: text overlap with arXiv:1901.07609", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $l$-path vertex cover problem the input is an undirected graph $G$ and\nan integer $k$. The goal is to decide whether there is a set of vertices $S$ of\nsize at most $k$ such that $G-S$ does not contain a path with $l$ vertices. In\nthis paper we give parameterized algorithms for $l$-path vertex cover for $l =\n5,6,7$, whose time complexities are $O^*(3.945^k)$, $O^*(4.947^k)$, and\n$O^*(5.951^k)$, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 20:10:54 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Tsur", "Dekel", ""]]}, {"id": "1906.10530", "submitter": "Gramoz Goranci", "authors": "David Durfee, Yu Gao, Gramoz Goranci, Richard Peng", "title": "Fully Dynamic Spectral Vertex Sparsifiers and Applications", "comments": "STOC 2019. arXiv admin note: text overlap with arXiv:1804.04038", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study \\emph{dynamic} algorithms for maintaining spectral vertex\nsparsifiers of graphs with respect to a set of terminals $T$ of our choice.\nSuch objects preserve pairwise resistances, solutions to systems of linear\nequations, and energy of electrical flows between the terminals in $T$. We give\na data structure that supports insertions and deletions of edges, and terminal\nadditions, all in sublinear time. Our result is then applied to the following\nproblems.\n  (1) A data structure for maintaining solutions to Laplacian systems\n$\\mathbf{L} \\mathbf{x} = \\mathbf{b}$, where $\\mathbf{L}$ is the Laplacian\nmatrix and $\\mathbf{b}$ is a demand vector. For a bounded degree, unweighted\ngraph, we support modifications to both $\\mathbf{L}$ and $\\mathbf{b}$ while\nproviding access to $\\epsilon$-approximations to the energy of routing an\nelectrical flow with demand $\\mathbf{b}$, as well as query access to entries of\na vector $\\tilde{\\mathbf{x}}$ such that $\\left\\lVert\n\\tilde{\\mathbf{x}}-\\mathbf{L}^{\\dagger} \\mathbf{b} \\right\\rVert_{\\mathbf{L}}\n\\leq \\epsilon \\left\\lVert \\mathbf{L}^{\\dagger} \\mathbf{b}\n\\right\\rVert_{\\mathbf{L}}$ in $\\tilde{O}(n^{11/12}\\epsilon^{-5})$ expected\namortized update and query time.\n  (2) A data structure for maintaining All-Pairs Effective Resistance. For an\nintermixed sequence of edge insertions, deletions, and resistance queries, our\ndata structure returns $(1 \\pm \\epsilon)$-approximation to all the resistance\nqueries against an oblivious adversary with high probability. Its expected\namortized update and query times are $\\tilde{O}(\\min(m^{3/4},n^{5/6}\n\\epsilon^{-2}) \\epsilon^{-4})$ on an unweighted graph, and\n$\\tilde{O}(n^{5/6}\\epsilon^{-6})$ on weighted graphs.\n  These results represent the first data structures for maintaining key\nprimitives from the Laplacian paradigm for graph algorithms in sublinear time\nwithout assumptions on the underlying graph topologies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:06:15 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Durfee", "David", ""], ["Gao", "Yu", ""], ["Goranci", "Gramoz", ""], ["Peng", "Richard", ""]]}, {"id": "1906.10615", "submitter": "Assaf Naor", "authors": "Ronen Eldan and Assaf Naor", "title": "Krivine diffusions attain the Goemans--Williamson approximation ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering a question of Abbasi-Zadeh, Bansal, Guruganesh, Nikolov, Schwartz\nand Singh (2018), we prove the existence of a slowed-down sticky Brownian\nmotion whose induced rounding for MAXCUT attains the Goemans--Williamson\napproximation ratio. This is an especially simple particular case of the\ngeneral rounding framework of Krivine diffusions that we investigate elsewhere.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:45:56 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Eldan", "Ronen", ""], ["Naor", "Assaf", ""]]}, {"id": "1906.10655", "submitter": "Aaron Sidford", "authors": "S\\'ebastien Bubeck, Qijia Jiang, Yin Tat Lee, Yuanzhi Li, Aaron\n  Sidford", "title": "Complexity of Highly Parallel Non-Smooth Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A landmark result of non-smooth convex optimization is that gradient descent\nis an optimal algorithm whenever the number of computed gradients is smaller\nthan the dimension $d$. In this paper we study the extension of this result to\nthe parallel optimization setting. Namely we consider optimization algorithms\ninteracting with a highly parallel gradient oracle, that is one that can answer\n$\\mathrm{poly}(d)$ gradient queries in parallel. We show that in this case\ngradient descent is optimal only up to $\\tilde{O}(\\sqrt{d})$ rounds of\ninteractions with the oracle. The lower bound improves upon a decades old\nconstruction by Nemirovski which proves optimality only up to $d^{1/3}$ rounds\n(as recently observed by Balkanski and Singer), and the suboptimality of\ngradient descent after $\\sqrt{d}$ rounds was already observed by Duchi,\nBartlett and Wainwright. In the latter regime we propose a new method with\nimproved complexity, which we conjecture to be optimal. The analysis of this\nnew method is based upon a generalized version of the recent results on optimal\nacceleration for highly smooth convex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:51:42 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 06:36:05 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Jiang", "Qijia", ""], ["Lee", "Yin Tat", ""], ["Li", "Yuanzhi", ""], ["Sidford", "Aaron", ""]]}, {"id": "1906.10801", "submitter": "Mingyu Xiao", "authors": "Mingyu Xiao", "title": "Upper and Lower Bounds on Approximating Weighted Mixed Domination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixed dominating set of a graph $G = (V, E)$ is a mixed set $D$ of vertices\nand edges, such that for every edge or vertex, if it is not in $D$, then it is\nadjacent or incident to at least one vertex or edge in $D$. The mixed\ndomination problem is to find a mixed dominating set with a minimum\ncardinality. It has applications in system control and some other scenarios and\nit is $NP$-hard to compute an optimal solution. This paper studies\napproximation algorithms and hardness of the weighted mixed dominating set\nproblem. The weighted version is a generalization of the unweighted version,\nwhere all vertices are assigned the same nonnegative weight $w_v$ and all edges\nare assigned the same nonnegative weight $w_e$, and the question is to find a\nmixed dominating set with a minimum total weight. Although the mixed dominating\nset problem has a simple 2-approximation algorithm, few approximation results\nfor the weighted version are known. The main contributions of this paper\ninclude: [1.] for $w_e\\geq w_v$, a 2-approximation algorithm; [2.] for $w_e\\geq\n2w_v$, inapproximability within ratio 1.3606 unless $P=NP$ and within ratio 2\nunder UGC; [3.] for $2w_v > w_e\\geq w_v$, inapproximability within ratio 1.1803\nunless $P=NP$ and within ratio 1.5 under UGC; [4.] for $w_e< w_v$,\ninapproximability within ratio $(1-\\epsilon)\\ln |V|$ unless $P=NP$ for any\n$\\epsilon >0$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 01:15:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Xiao", "Mingyu", ""]]}, {"id": "1906.10860", "submitter": "Adam Lev-Libfeld", "authors": "Adam Lev-Libfeld", "title": "Lawn: an Unbound Low Latency Timer Data Structure for Large Scale, High\n  Throughput Systems", "comments": "6 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demand for Real-Time applications rises among the general public, the\nimportance of enabling large-scale, unbound algorithms to solve conventional\nproblems with low to no latency is critical for product viability. Timer\nalgorithms are prevalent in the core mechanisms behind operating systems,\nnetwork protocol implementation, stream processing, and several database\ncapabilities. This paper presents a field-tested algorithm for low latency,\nunbound range timer structure, based upon the well excepted Timing Wheel\nalgorithm. Using a set of queues hashed by TTL, the algorithm allows for a\nsimpler implementation, minimal overhead no overflow and no performance\ndegradation in comparison to the current state of the algorithms under typical\nuse cases.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 06:16:13 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:50:24 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lev-Libfeld", "Adam", ""]]}, {"id": "1906.10982", "submitter": "Stefan Kratsch", "authors": "Fabrizio Grandoni, Stefan Kratsch, Andreas Wiese", "title": "Parameterized Approximation Schemes for Independent Set of Rectangles\n  and Geometric Knapsack", "comments": "Abstract shortened", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of parameterized approximation seeks to combine approximation and\nparameterized algorithms to obtain, e.g., (1+eps)-approximations in\nf(k,eps)n^{O(1)} time where k is some parameter of the input. We obtain the\nfollowing results on parameterized approximability: 1) In the maximum\nindependent set of rectangles problem (MISR) we are given a collection of n\naxis parallel rectangles in the plane. Our goal is to select a\nmaximum-cardinality subset of pairwise non-overlapping rectangles. This problem\nis NP-hard and also W[1]-hard [Marx, ESA'05]. The best-known polynomial-time\napproximation factor is O(loglog n) [Chalermsook and Chuzhoy, SODA'09] and it\nadmits a QPTAS [Adamaszek and Wiese, FOCS'13; Chuzhoy and Ene, FOCS'16]. Here\nwe present a parameterized approximation scheme (PAS) for MISR, i.e. an\nalgorithm that, for any given constant eps>0 and integer k>0, in time\nf(k,eps)n^{g(eps)}, either outputs a solution of size at least k/(1+eps), or\ndeclares that the optimum solution has size less than k. 2) In the\n(2-dimensional) geometric knapsack problem (TDK) we are given an axis-aligned\nsquare knapsack and a collection of axis-aligned rectangles in the plane\n(items). Our goal is to translate a maximum cardinality subset of items into\nthe knapsack so that the selected items do not overlap. In the version of TDK\nwith rotations (TDKR), we are allowed to rotate items by 90 degrees. Both\nvariants are NP-hard, and the best-known polynomial-time approximation factors\nare 558/325+eps and 4/3+eps, resp. [Galvez et al., FOCS'17]. These problems\nadmit a QPTAS for polynomially bounded item sizes [Adamaszek and Wiese,\nSODA'15]. We show that both variants are W[1]-hard. Furthermore, we present a\nPAS for TDKR. For all considered problems, getting time f(k,eps)n^{O(1)},\nrather than f(k,eps)n^{g(eps)}, would give FPT time f'(k)n^{O(1)} exact\nalgorithms using eps=1/(k+1), contradicting W[1]-hardness.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:33:22 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Grandoni", "Fabrizio", ""], ["Kratsch", "Stefan", ""], ["Wiese", "Andreas", ""]]}, {"id": "1906.11030", "submitter": "Solon Pissis", "authors": "Giulia Bernardini, Huiping Chen, Alessio Conte, Roberto Grossi,\n  Grigorios Loukides, Nadia Pisanti, Solon P. Pissis, Giovanna Rosone, Michelle\n  Sweering", "title": "Combinatorial Algorithms for String Sanitization", "comments": "Extended version of a paper accepted to ECML/PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  String data are often disseminated to support applications such as\nlocation-based service provision or DNA sequence analysis. This dissemination,\nhowever, may expose sensitive patterns that model confidential knowledge. In\nthis paper, we consider the problem of sanitizing a string by concealing the\noccurrences of sensitive patterns, while maintaining data utility, in two\nsettings that are relevant to many common string processing tasks.\n  In the first setting, we aim to generate the minimal-length string that\npreserves the order of appearance and frequency of all non-sensitive patterns.\nSuch a string allows accurately performing tasks based on the sequential nature\nand pattern frequencies of the string. To construct such a string, we propose a\ntime-optimal algorithm, TFS-ALGO. We also propose another time-optimal\nalgorithm, PFS-ALGO, which preserves a partial order of appearance of\nnon-sensitive patterns but produces a much shorter string that can be analyzed\nmore efficiently. The strings produced by either of these algorithms are\nconstructed by concatenating non-sensitive parts of the input string. However,\nit is possible to detect the sensitive patterns by ``reversing'' the\nconcatenation operations. In response, we propose a heuristic, MCSR-ALGO, which\nreplaces letters in the strings output by the algorithms with carefully\nselected letters, so that sensitive patterns are not reinstated, implausible\npatterns are not introduced, and occurrences of spurious patterns are\nprevented. In the second setting, we aim to generate a string that is at\nminimal edit distance from the original string, in addition to preserving the\norder of appearance and frequency of all non-sensitive patterns. To construct\nsuch a string, we propose an algorithm, ETFS-ALGO, based on solving specific\ninstances of approximate regular expression matching.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:34:14 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 13:33:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Bernardini", "Giulia", ""], ["Chen", "Huiping", ""], ["Conte", "Alessio", ""], ["Grossi", "Roberto", ""], ["Loukides", "Grigorios", ""], ["Pisanti", "Nadia", ""], ["Pissis", "Solon P.", ""], ["Rosone", "Giovanna", ""], ["Sweering", "Michelle", ""]]}, {"id": "1906.11062", "submitter": "Thomas Heinis", "authors": "Thomas Heinis", "title": "Survey of Information Encoding Techniques for DNA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DB cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key to DNA storage is encoding the information to a sequence of nucleotides\nbefore it can be synthesised for storage. Definition of such an encoding or\nmapping must adhere to multiple design restrictions. First, not all possible\nsequences of nucleotides can be synthesised. Homopolymers, e.g., sequences of\nthe same nucleotide, of a length of more than two, for example, cannot be\nsynthesised without potential errors. Similarly, the G-C content of the\nresulting sequences should be higher than 50\\%. Second, given that synthesis is\nexpensive, the encoding must map as many bits as possible to one nucleotide.\nThird, the synthesis (as well as the sequencing) is error prone, leading to\nsubstitutions, deletions and insertions. An encoding must therefore be designed\nto be resilient to errors through error correction codes or replication.\nFourth, for the purpose of computation and selective retrieval, encodings\nshould result in substantially different sequences across all data, even for\nvery similar data. In the following we discuss the history and evolution of\nencodings.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 18:57:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Heinis", "Thomas", ""]]}, {"id": "1906.11185", "submitter": "Ueverton Souza", "authors": "Claudson F. Bornstein and Martin Charles Golumbic and Tanilson D.\n  Santos and U\\'everton S. Souza and Jayme L. Szwarcfiter", "title": "The Complexity of Helly-$B_{1}$ EPG Graph Recognition", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 22 no.\n  1, Graph Theory (June 4, 2020) dmtcs:6506", "doi": "10.23638/DMTCS-22-1-19", "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Golumbic, Lipshteyn, and Stern defined in 2009 the class of EPG graphs, the\nintersection graph class of edge paths on a grid. An EPG graph $G$ is a graph\nthat admits a representation where its vertices correspond to paths in a grid\n$Q$, such that two vertices of $G$ are adjacent if and only if their\ncorresponding paths in $Q$ have a common edge. If the paths in the\nrepresentation have at most $k$ bends, we say that it is a $B_k$-EPG\nrepresentation. A collection $C$ of sets satisfies the Helly property when\nevery sub-collection of $C$ that is pairwise intersecting has at least one\ncommon element. In this paper, we show that given a graph $G$ and an integer\n$k$, the problem of determining whether $G$ admits a $B_k$-EPG representation\nwhose edge-intersections of paths satisfy the Helly property, so-called\nHelly-$B_k$-EPG representation, is in NP, for every $k$ bounded by a polynomial\nfunction of $|V(G)|$. Moreover, we show that the problem of recognizing\nHelly-$B_1$-EPG graphs is NP-complete, and it remains NP-complete even when\nrestricted to 2-apex and 3-degenerate graphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 16:06:16 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 14:38:39 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 16:44:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bornstein", "Claudson F.", ""], ["Golumbic", "Martin Charles", ""], ["Santos", "Tanilson D.", ""], ["Souza", "U\u00e9verton S.", ""], ["Szwarcfiter", "Jayme L.", ""]]}, {"id": "1906.11237", "submitter": "Moran Feldman", "authors": "Naor Alaluf and Moran Feldman", "title": "Making a Sieve Random: Improved Semi-Streaming Algorithm for Submodular\n  Maximization under a Cardinality Constraint", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of maximizing a non-negative submodular\nfunction subject to a cardinality constraint in the data stream model.\nPreviously, the best known algorithm for this problem was a\n$5.828$-approximation semi-streaming algorithm based on a local search\ntechnique (Feldman et al., 2018). For the special case of this problem in which\nthe objective function is also monotone, the state-of-the-art semi-streaming\nalgorithm is an algorithm known as Sieve-Streaming, which is based on a\ndifferent technique (Badanidiyuru, 2014). Adapting the technique of\nSieve-Streaming to non-monotone objective functions has turned out to be a\nchallenging task, which has so far prevented an improvement over the local\nsearch based $5.828$-approximation. In this work, we overcome the above\nchallenge, and manage to adapt Sieve-Streaming to non-monotone objective\nfunctions by introducing a \"just right\" amount of randomness into it.\nConsequently, we get a semi-streaming polynomial time $4.282$-approximation\nalgorithm for non-monotone objectives. Moreover, if one allows our algorithm to\nrun in super-polynomial time, then its approximation ratio can be further\nimproved to $3 + \\varepsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 17:59:15 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Alaluf", "Naor", ""], ["Feldman", "Moran", ""]]}, {"id": "1906.11327", "submitter": "Omri Ben-Eliezer", "authors": "Omri Ben-Eliezer and Eylon Yogev", "title": "The Adversarial Robustness of Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random sampling is a fundamental primitive in modern algorithms, statistics,\nand machine learning, used as a generic method to obtain a small yet\n\"representative\" subset of the data. In this work, we investigate the\nrobustness of sampling against adaptive adversarial attacks in a streaming\nsetting: An adversary sends a stream of elements from a universe $U$ to a\nsampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with the\ngoal of making the sample \"very unrepresentative\" of the underlying data\nstream. The adversary is fully adaptive in the sense that it knows the exact\ncontent of the sample at any given point along the stream, and can choose which\nelement to send next accordingly, in an online manner.\n  Well-known results in the static setting indicate that if the full stream is\nchosen in advance (non-adaptively), then a random sample of size $\\Omega(d /\n\\varepsilon^2)$ is an $\\varepsilon$-approximation of the full data with good\nprobability, where $d$ is the VC-dimension of the underlying set system\n$(U,R)$. Does this sample size suffice for robustness against an adaptive\nadversary? The simplistic answer is \\emph{negative}: We demonstrate a set\nsystem where a constant sample size (corresponding to VC-dimension $1$)\nsuffices in the static setting, yet an adaptive adversary can make the sample\nvery unrepresentative, as long as the sample size is (strongly) sublinear in\nthe stream length, using a simple and easy-to-implement attack.\n  However, this attack is \"theoretical only\", requiring the set system size to\n(essentially) be exponential in the stream length. This is not a coincidence:\nWe show that to make Bernoulli or reservoir sampling robust against adaptive\nadversaries, the modification required is solely to replace the VC-dimension\nterm $d$ in the sample size with the cardinality term $\\log |R|$. This nearly\nmatches the bound imposed by the attack.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:15:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Yogev", "Eylon", ""]]}, {"id": "1906.11366", "submitter": "Jerry Li", "authors": "Yihe Dong, Samuel B. Hopkins, Jerry Li", "title": "Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved\n  Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two problems in high-dimensional robust statistics: \\emph{robust\nmean estimation} and \\emph{outlier detection}. In robust mean estimation the\ngoal is to estimate the mean $\\mu$ of a distribution on $\\mathbb{R}^d$ given\n$n$ independent samples, an $\\varepsilon$-fraction of which have been corrupted\nby a malicious adversary. In outlier detection the goal is to assign an\n\\emph{outlier score} to each element of a data set such that elements more\nlikely to be outliers are assigned higher scores. Our algorithms for both\nproblems are based on a new outlier scoring method we call QUE-scoring based on\n\\emph{quantum entropy regularization}. For robust mean estimation, this yields\nthe first algorithm with optimal error rates and nearly-linear running time\n$\\widetilde{O}(nd)$ in all parameters, improving on the previous fastest\nrunning time $\\widetilde{O}(\\min(nd/\\varepsilon^6, nd^2))$. For outlier\ndetection, we evaluate the performance of QUE-scoring via extensive experiments\non synthetic and real data, and demonstrate that it often performs better than\npreviously proposed algorithms. Code for these experiments is available at\nhttps://github.com/twistedcubic/que-outlier-detection .\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 22:23:14 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Dong", "Yihe", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""]]}, {"id": "1906.11385", "submitter": "Ray Li", "authors": "Ray Li, Percy Liang, Stephen Mussmann", "title": "A Tight Analysis of Greedy Yields Subexponential Time Approximation for\n  Uniform Decision Tree", "comments": "40 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision Tree is a classic formulation of active learning: given $n$\nhypotheses with nonnegative weights summing to 1 and a set of tests that each\npartition the hypotheses, output a decision tree using the provided tests that\nuniquely identifies each hypothesis and has minimum (weighted) average depth.\nPrevious works showed that the greedy algorithm achieves a $O(\\log n)$\napproximation ratio for this problem and it is NP-hard beat a $O(\\log n)$\napproximation, settling the complexity of the problem.\n  However, for Uniform Decision Tree, i.e. Decision Tree with uniform weights,\nthe story is more subtle. The greedy algorithm's $O(\\log n)$ approximation\nratio was the best known, but the largest approximation ratio known to be\nNP-hard is $4-\\varepsilon$. We prove that the greedy algorithm gives a\n$O(\\frac{\\log n}{\\log C_{OPT}})$ approximation for Uniform Decision Tree, where\n$C_{OPT}$ is the cost of the optimal tree and show this is best possible for\nthe greedy algorithm. As a corollary, we resolve a conjecture of Kosaraju,\nPrzytycka, and Borgstrom. Leveraging this result, for all $\\alpha\\in(0,1)$, we\nexhibit a $\\frac{9.01}{\\alpha}$ approximation algorithm to Uniform Decision\nTree running in subexponential time $2^{\\tilde O(n^\\alpha)}$. As a corollary,\nachieving any super-constant approximation ratio on Uniform Decision Tree is\nnot NP-hard, assuming the Exponential Time Hypothesis. This work therefore adds\napproximating Uniform Decision Tree to a small list of natural problems that\nhave subexponential time algorithms but no known polynomial time algorithms.\nAll our results hold for Decision Tree with weights not too far from uniform. A\nkey technical contribution of our work is showing a connection between greedy\nalgorithms for Uniform Decision Tree and for Min Sum Set Cover.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:34:46 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:56:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Li", "Ray", ""], ["Liang", "Percy", ""], ["Mussmann", "Stephen", ""]]}, {"id": "1906.11423", "submitter": "EPTCS", "authors": "Marco T. Moraz\\'an (Seton Hall University)", "title": "Vector Programming Using Generative Recursion", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757. arXiv admin note: text\n  overlap with arXiv:1805.05124", "journal-ref": "EPTCS 295, 2019, pp. 35-51", "doi": "10.4204/EPTCS.295.3", "report-no": null, "categories": "cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector programming is an important topic in many Introduction to Computer\nScience courses. Despite the importance of vectors, learning vector programming\nis a source of frustration for many students. Much of the frustration is rooted\nin discovering the source of bugs that are manifested as out-of-bounds\nindexing. The problem is that such bugs are, sometimes, rooted in incorrectly\ncomputing an index. Other times, however, these errors are rooted in mistaken\nreasoning about how to correctly process a vector. Unfortunately, either way,\nall too often beginners are left adrift to resolve indexing errors on their\nown. This article extends the work done on vector programming using vector\nintervals and structural recursion to using generative recursion. As for\nproblems solved using structural recursion, vector intervals provide beginners\nwith a useful framework for designing code that properly indexes vectors. This\narticle presents the methodology and concrete examples that others may use to\nbuild their own CS1 modules involving vector programming using any programming\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:33:23 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Moraz\u00e1n", "Marco T.", "", "Seton Hall University"]]}, {"id": "1906.11524", "submitter": "Seri Khoury", "authors": "Ken-ichi Kawarabayashi, Seri Khoury, Aaron Schild, and Gregory\n  Schwartzman", "title": "Improved Distributed Approximations for Maximum Independent Set", "comments": "This version contains improved results compared to the previous one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present improved results for approximating maximum-weight independent set\n($\\MaxIS$) in the CONGEST and LOCAL models of distributed computing. Given an\ninput graph, let $n$ and $\\Delta$ be the number of nodes and maximum degree,\nrespectively, and let $\\MIS(n,\\Delta)$ be the the running time of finding a\n\\emph{maximal} independent set ($\\MIS$) in the CONGEST model. Bar-Yehuda et al.\n[PODC 2017] showed that there is an algorithm in the CONGEST model that finds a\n$\\Delta$-approximation for $\\MaxIS$ in $O(\\MIS(n,\\Delta)\\log W)$ rounds, where\n$W$ is the maximum weight of a node in the graph, which can be as high as\n$\\poly (n)$. Whether their algorithm is deterministic or randomized depends on\nthe $\\MIS$ algorithm that is used as a black-box.\n  Our main result in this work is a randomized $(\\poly(\\log\\log\nn)/\\epsilon)$-round algorithm that finds, with high probability, a\n$(1+\\epsilon)\\Delta$-approximation for $\\MaxIS$ in the CONGEST model. That is,\nby sacrificing only a tiny fraction of the approximation guarantee, we achieve\nan \\emph{exponential} speed-up in the running time over the previous best known\nresult. Due to a lower bound of $\\Omega(\\sqrt{\\log n/\\log \\log n})$ that was\ngiven by Kuhn, Moscibroda and Wattenhofer [JACM, 2016] on the number of rounds\nfor any (possibly randomized) algorithm that finds a maximal independent set\n(even in the LOCAL model) this result implies that finding a\n$(1+\\epsilon)\\Delta$-approximation for $\\MaxIS$ is exponentially easier than\n$\\MIS$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:52:02 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 05:06:30 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Kawarabayashi", "Ken-ichi", ""], ["Khoury", "Seri", ""], ["Schild", "Aaron", ""], ["Schwartzman", "Gregory", ""]]}, {"id": "1906.11700", "submitter": "Daniel Tang", "authors": "Daniel Tang", "title": "Efficient algorithms for modifying and sampling from a categorical\n  distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic programming languages and other machine learning applications\noften require samples to be generated from a categorical distribution where the\nprobability of each one of $n$ categories is specified as a parameter. If the\nparameters are hyper-parameters then they need to be modified, however, current\nimplementations of categorical distributions take $\\mathcal{O}(n)$ time to\nmodify a parameter. If $n$ is large and the parameters are being frequently\nmodified, this can become prohibitive. Here we present the insight that a\nHuffman tree is an efficient data structure for representing categorical\ndistributions and present algorithms to generate samples as well as add, delete\nand modify categories in $\\mathcal{O}(\\log(n))$ time. We demonstrate that the\ntime to sample from the distribution remains, in practice, within a few percent\nof the theoretical optimal value. The same algorithm may also be useful in the\ncontext of adaptive Huffman coding where computational efficiency is important.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:48:40 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Tang", "Daniel", ""]]}, {"id": "1906.11710", "submitter": "David Dewhurst", "authors": "David Rushing Dewhurst, Thayer Alshaabi, Dilan Kiley, Michael V.\n  Arnold, Joshua R. Minot, Christopher M. Danforth, and Peter Sheridan Dodds", "title": "The shocklet transform: A decomposition method for the identification of\n  local, mechanism-driven dynamics in sociotechnical time series", "comments": "29 pages (20 body, 9 appendix), 20 figures (13 body, 7 appendix),\n  three online appendices available at http://compstorylab.org/shocklets/ (two\n  displaying interactive visualizations and one containing over 10,000\n  figures), open-source implementation of STAR algorithm and discrete shocklet\n  transform available at\n  https://gitlab.com/compstorylab/discrete-shocklet-transform", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DS eess.SP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a qualitative, shape-based, timescale-independent time-domain\ntransform used to extract local dynamics from sociotechnical time\nseries---termed the Discrete Shocklet Transform (DST)---and an associated\nsimilarity search routine, the Shocklet Transform And Ranking (STAR) algorithm,\nthat indicates time windows during which panels of time series display\nqualitatively-similar anomalous behavior. After distinguishing our algorithms\nfrom other methods used in anomaly detection and time series similarity search,\nsuch as the matrix profile, seasonal-hybrid ESD, and discrete wavelet\ntransform-based procedures, we demonstrate the DST's ability to identify\nmechanism-driven dynamics at a wide range of timescales and its relative\ninsensitivity to functional parameterization. As an application, we analyze a\nsociotechnical data source (usage frequencies for a subset of words on Twitter)\nand highlight our algorithms' utility by using them to extract both a typology\nof mechanistic local dynamics and a data-driven narrative of socially-important\nevents as perceived by English-language Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:58:18 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 22:31:19 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 17:11:17 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Dewhurst", "David Rushing", ""], ["Alshaabi", "Thayer", ""], ["Kiley", "Dilan", ""], ["Arnold", "Michael V.", ""], ["Minot", "Joshua R.", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "1906.11750", "submitter": "Ayan Dutta", "authors": "Ayan Dutta and Gokarna Sharma", "title": "A Constant-Factor Approximation Algorithm for Online Coverage Path\n  Planning with Energy Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of coverage planning by a mobile robot\nwith a limited energy budget. The objective of the robot is to cover every\npoint in the environment while minimizing the traveled path length. The\nenvironment is initially unknown to the robot. Therefore, it needs to avoid the\nobstacles in the environment on-the-fly during the exploration. As the robot\nhas a specific energy budget, it might not be able to cover the complete\nenvironment in one traversal. Instead, it will need to visit a static charging\nstation periodically in order to recharge its energy. To solve the stated\nproblem, we propose a budgeted depth-first search (DFS)-based exploration\nstrategy that helps the robot to cover any unknown planar environment while\nbounding the maximum path length to a constant-factor of the shortest-possible\npath length. Our $O(1)$-approximation guarantee advances the state-of-the-art\nof log-approximation for this problem. Simulation results show that our\nproposed algorithm outperforms the current state-of-the-art algorithm both in\nterms of the traveled path length and run time in all the tested environments\nwith concave and convex obstacles.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:53:33 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Dutta", "Ayan", ""], ["Sharma", "Gokarna", ""]]}, {"id": "1906.11811", "submitter": "Michael Hamann", "authors": "Lars Gottesb\\\"uren, Michael Hamann, Tim Niklas Uhl and Dorothea Wagner", "title": "Faster and Better Nested Dissection Orders for Customizable Contraction\n  Hierarchies", "comments": "18 pages, 8 tables; v2: re-run experiments of competing algorithms", "journal-ref": null, "doi": "10.3390/a12090196", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph partitioning has many applications. We consider the acceleration of\nshortest path queries in road networks using Customizable Contraction\nHierarchies (CCH). It is based on computing a nested dissection order by\nrecursively dividing the road network into parts. Recently, with FlowCutter and\nInertial Flow, two flow-based graph bipartitioning algorithms have been\nproposed for road networks. While FlowCutter achieves high-quality results and\nthus fast query times, it is rather slow. Inertial Flow is particularly fast\ndue to the use of geographical information while still achieving decent query\ntimes. We combine the techniques of both algorithms to achieve more than six\ntimes faster preprocessing times than FlowCutter and even faster queries on the\nEurope road network. We show that using 16 cores of a shared-memory machine,\nthis preprocessing needs four minutes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 17:37:37 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:50:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gottesb\u00fcren", "Lars", ""], ["Hamann", "Michael", ""], ["Uhl", "Tim Niklas", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1906.11985", "submitter": "Nimit Sohoni", "authors": "Oliver Hinder and Aaron Sidford and Nimit Sharad Sohoni", "title": "Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide near-optimal accelerated first-order methods for\nminimizing a broad class of smooth nonconvex functions that are strictly\nunimodal on all lines through a minimizer. This function class, which we call\nthe class of smooth quasar-convex functions, is parameterized by a constant\n$\\gamma \\in (0,1]$, where $\\gamma = 1$ encompasses the classes of smooth convex\nand star-convex functions, and smaller values of $\\gamma$ indicate that the\nfunction can be \"more nonconvex.\" We develop a variant of accelerated gradient\ndescent that computes an $\\epsilon$-approximate minimizer of a smooth\n$\\gamma$-quasar-convex function with at most $O(\\gamma^{-1} \\epsilon^{-1/2}\n\\log(\\gamma^{-1} \\epsilon^{-1}))$ total function and gradient evaluations. We\nalso derive a lower bound of $\\Omega(\\gamma^{-1} \\epsilon^{-1/2})$ on the\nnumber of gradient evaluations required by any deterministic first-order method\nin the worst case, showing that, up to a logarithmic factor, no deterministic\nfirst-order algorithm can improve upon ours.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:39:35 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Hinder", "Oliver", ""], ["Sidford", "Aaron", ""], ["Sohoni", "Nimit Sharad", ""]]}, {"id": "1906.12053", "submitter": "Louxin Zhang", "authors": "Louxin Zhang", "title": "Generating Normal Networks via Leaf Insertion and Nearest Neighbor\n  Interchange", "comments": "4 figures and 13 pages", "journal-ref": "RECOMBCG, 2019", "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Galled trees are studied as a recombination model in theoretic population\ngenetics. This class of phylogenetic networks has been generalized to\ntree-child networks, normal networks and tree-based networks by relaxing a\nstructural condition. Although these networks are simple, their topological\nstructures have yet to be fully understood. It is well-known that all\nphylogenetic trees on $n$ taxa can be generated by the insertion of the $n$-th\ntaxa to each edge of all the phylogenetic trees on $n-1$ taxa. We prove that\nall tree-child networks with $k$ reticulate nodes on $n$ taxa can be uniquely\ngenerated via three operations from all the tree-child networks with $k-1$ or\n$k$ reticulate nodes on $n-1$ taxa . An application of this result is found in\ncounting tree-child networks and normal networks. In particular, a simple\nformula is given for the number of rooted phylogenetic networks with one\nreticulate node.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 06:13:56 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 01:20:53 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 12:00:28 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Zhang", "Louxin", ""]]}, {"id": "1906.12211", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller, Tobias Christiani, Rasmus Pagh, Michael Vesterli", "title": "PUFFINN: Parameterless and Universally Fast FInding of Nearest Neighbors", "comments": "Extended version of the ESA 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PUFFINN, a parameterless LSH-based index for solving the\n$k$-nearest neighbor problem with probabilistic guarantees. By parameterless we\nmean that the user is only required to specify the amount of memory the index\nis supposed to use and the result quality that should be achieved. The index\ncombines several heuristic ideas known in the literature. By small adaptions to\nthe query algorithm, we make heuristics rigorous. We perform experiments on\nreal-world and synthetic inputs to evaluate implementation choices and show\nthat the implementation satisfies the quality guarantees while being\ncompetitive with other state-of-the-art approaches to nearest neighbor search.\n  We describe a novel synthetic data set that is difficult to solve for almost\nall existing nearest neighbor search approaches, and for which PUFFINN\nsignificantly outperform previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:33:17 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Christiani", "Tobias", ""], ["Pagh", "Rasmus", ""], ["Vesterli", "Michael", ""]]}, {"id": "1906.12215", "submitter": "Matthias Troffaes", "authors": "Nawapon Nakharutai and Matthias C. M. Troffaes and Camila C. S. Caiado", "title": "Improving and benchmarking of algorithms for decision making with lower\n  previsions", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.ijar.2019.06.008", "report-no": null, "categories": "math.OC cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximality, interval dominance, and E-admissibility are three well-known\ncriteria for decision making under severe uncertainty using lower previsions.\nWe present a new fast algorithm for finding maximal gambles. We compare its\nperformance to existing algorithms, one proposed by Troffaes and Hable (2014),\nand one by Jansen, Augustin, and Schollmeyer (2017). To do so, we develop a new\nmethod for generating random decision problems with pre-specified ratios of\nmaximal and interval dominant gambles. Based on earlier work, we present\nefficient ways to find common feasible starting points in these algorithms. We\nthen exploit these feasible starting points to develop early stopping criteria\nfor the primal-dual interior point method, further improving efficiency. We\nfind that the primal-dual interior point method works best. We also investigate\nthe use of interval dominance to eliminate non-maximal gambles. This can make\nthe problem smaller, and we observe that this benefits Jansen et al.'s\nalgorithm, but perhaps surprisingly, not the other two algorithms. We find that\nour algorithm, without using interval dominance, outperforms all other\nalgorithms in all scenarios in our benchmarking.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:42:32 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Nakharutai", "Nawapon", ""], ["Troffaes", "Matthias C. M.", ""], ["Caiado", "Camila C. S.", ""]]}, {"id": "1906.12298", "submitter": "Jason Li", "authors": "Jason Li, Jesper Nederlof", "title": "Detecting Feedback Vertex Sets of Size $k$ in $O^\\star(2.7^k)$ Time", "comments": "SODA 2020, 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Feedback Vertex Set problem, one is given an undirected graph $G$ and\nan integer $k$, and one needs to determine whether there exists a set of $k$\nvertices that intersects all cycles of $G$ (a so-called feedback vertex set).\nFeedback Vertex Set is one of the most central problems in parameterized\ncomplexity: It served as an excellent test bed for many important algorithmic\ntechniques in the field such as Iterative Compression~[Guo et al. (JCSS'06)],\nRandomized Branching~[Becker et al. (J. Artif. Intell. Res'00)] and\nCut\\&Count~[Cygan et al. (FOCS'11)]. In particular, there has been a long race\nfor the smallest dependence $f(k)$ in run times of the type $O^\\star(f(k))$,\nwhere the $O^\\star$ notation omits factors polynomial in $n$. This race seemed\nto be run in 2011, when a randomized algorithm $O^\\star(3^k)$ time algorithm\nbased on Cut\\&Count was introduced.\n  In this work, we show the contrary and give a $O^\\star(2.7^k)$ time\nrandomized algorithm. Our algorithm combines all mentioned techniques with\nsubstantial new ideas: First, we show that, given a feedback vertex set of size\n$k$ of bounded average degree, a tree decomposition of width $(1-\\Omega(1))k$\ncan be found in polynomial time. Second, we give a randomized branching\nstrategy inspired by the one from~[Becker et al. (J. Artif. Intell. Res'00)] to\nreduce to the aforementioned bounded average degree setting. Third, we obtain\nsignificant run time improvements by employing fast matrix multiplication.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:40:40 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 19:35:22 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Li", "Jason", ""], ["Nederlof", "Jesper", ""]]}, {"id": "1906.12334", "submitter": "Fan Zhang", "authors": "Zhongxin Zhou, Fan Zhang, Xuemin Lin, Wenjie Zhang, Chen Chen", "title": "K-Core Maximization through Edge Additions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A popular model to measure the stability of a network is k-core - the maximal\ninduced subgraph in which every vertex has at least k neighbors. Many studies\nmaximize the number of vertices in k-core to improve the stability of a\nnetwork. In this paper, we study the edge k-core problem: Given a graph G, an\ninteger k and a budget b, add b edges to non-adjacent vertex pairs in G such\nthat the k-core is maximized. We prove the problem is NP-hard and APX-hard. A\nheuristic algorithm is proposed on general graphs with effective optimization\ntechniques. Comprehensive experiments on 9 real-life datasets demonstrate the\neffectiveness and the efficiency of our proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 05:31:38 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Zhou", "Zhongxin", ""], ["Zhang", "Fan", ""], ["Lin", "Xuemin", ""], ["Zhang", "Wenjie", ""], ["Chen", "Chen", ""]]}]