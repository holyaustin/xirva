[{"id": "1102.0041", "submitter": "Giovanni Battaglia", "authors": "Giovanni Battaglia, Roberto Grossi and Noemi Scutell\\`a", "title": "Consecutive Ones Property and PQ-Trees for Multisets: Hardness of\n  Counting Their Orderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary matrix satisfies the consecutive ones property (COP) if its columns\ncan be permuted such that the ones in each row of the resulting matrix are\nconsecutive. Equivalently, a family of sets F = {Q_1,..,Q_m}, where Q_i is\nsubset of R for some universe R, satisfies the COP if the symbols in R can be\npermuted such that the elements of each set Q_i occur consecutively, as a\ncontiguous segment of the permutation of R's symbols. We consider the COP\nversion on multisets and prove that counting its solutions is difficult\n(#P-complete). We prove completeness results also for counting the frontiers of\nPQ-trees, which are typically used for testing the COP on sets, thus showing\nthat a polynomial algorithm is unlikely to exist when dealing with multisets.\nWe use a combinatorial approach based on parsimonious reductions from the\nHamiltonian path problem, showing that the decisional version of our problems\nis therefore NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 23:59:40 GMT"}, {"version": "v2", "created": "Tue, 22 Mar 2011 21:04:12 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Battaglia", "Giovanni", ""], ["Grossi", "Roberto", ""], ["Scutell\u00e0", "Noemi", ""]]}, {"id": "1102.0309", "submitter": "Katharina Huber", "authors": "A.W.M. Dress, K.T. Huber, M. Steel", "title": "`Lassoing' a phylogenetic tree I: Basic properties, shellings, and\n  covers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical result, fundamental to evolutionary biology, states that an\nedge-weighted tree $T$ with leaf set $X$, positive edge weights, and no\nvertices of degree 2 can be uniquely reconstructed from the set of leaf-to-leaf\ndistances between any two elements of $X$. In biology, $X$ corresponds to a set\nof taxa (e.g. extant species), the tree $T$ describes their phylogenetic\nrelationships, the edges correspond to earlier species evolving for a time\nuntil splitting in two or more species by some speciation/bifurcation event,\nand their length corresponds to the genetic change accumulating over that time\nin such a species. In this paper, we investigate which subsets of\n$\\binom{X}{2}$ suffice to determine (`lasso') a tree from the leaf-to-leaf\ndistances induced by that tree. The question is particularly topical since\nreliable estimates of genetic distance - even (if not in particular) by modern\nmass-sequencing methods - are, in general, available only for certain\ncombinations of taxa.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 21:59:40 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 10:45:04 GMT"}, {"version": "v3", "created": "Thu, 14 Jul 2011 16:17:14 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["Dress", "A. W. M.", ""], ["Huber", "K. T.", ""], ["Steel", "M.", ""]]}, {"id": "1102.0395", "submitter": "Johannes Fischer", "authors": "Johannes Fischer", "title": "Combined Data Structure for Previous- and Next-Smaller-Values", "comments": "to appear in Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a static array storing $n$ elements from a totally ordered set. We\npresent a data structure of optimal size at most $n\\log_2(3+2\\sqrt{2})+o(n)$\nbits that allows us to answer the following queries on $A$ in constant time,\nwithout accessing $A$: (1) previous smaller value queries, where given an index\n$i$, we wish to find the first index to the left of $i$ where $A$ is strictly\nsmaller than at $i$, and (2) next smaller value queries, which search to the\nright of $i$. As an additional bonus, our data structure also allows to answer\na third kind of query: given indices $i<j$, find the position of the minimum in\n$A[i..j]$. Our data structure has direct consequences for the space-efficient\nstorage of suffix trees.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 10:20:58 GMT"}], "update_date": "2011-02-03", "authors_parsed": [["Fischer", "Johannes", ""]]}, {"id": "1102.0471", "submitter": "Elena Ishkova", "authors": "Sergey Ishkov and Elena Ishkova", "title": "Matrix method for the multi salesmen problem (TSP) with several vehicles", "comments": "10 pages with 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper discussed procedure of separation of the original problem with\nseveral vehicles to a number of simpler problems with one vehicle which based\non the matrix approach.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 11:56:13 GMT"}, {"version": "v2", "created": "Thu, 3 Feb 2011 10:54:47 GMT"}], "update_date": "2011-02-04", "authors_parsed": [["Ishkov", "Sergey", ""], ["Ishkova", "Elena", ""]]}, {"id": "1102.0588", "submitter": "J\\\"org L\\\"assig", "authors": "J\\\"org L\\\"assig and Dirk Sudholt", "title": "Adaptive Population Models for Offspring Populations and Parallel\n  Evolutionary Algorithms", "comments": "26 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two adaptive schemes for dynamically choosing the number of\nparallel instances in parallel evolutionary algorithms. This includes the\nchoice of the offspring population size in a (1+$\\lambda$) EA as a special\ncase. Our schemes are parameterless and they work in a black-box setting where\nno knowledge on the problem is available. Both schemes double the number of\ninstances in case a generation ends without finding an improvement. In a\nsuccessful generation, the first scheme resets the system to one instance,\nwhile the second scheme halves the number of instances. Both schemes provide\nnear-optimal speed-ups in terms of the parallel time. We give upper bounds for\nthe asymptotic sequential time (i.e., the total number of function evaluations)\nthat are not larger than upper bounds for a corresponding non-parallel\nalgorithm derived by the fitness-level method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 23:39:57 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 12:19:16 GMT"}], "update_date": "2011-03-03", "authors_parsed": [["L\u00e4ssig", "J\u00f6rg", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1102.0805", "submitter": "Andrew King", "authors": "Andrew D. King and Bruce Reed", "title": "Asymptotics of the chromatic number for quasi-line graphs", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As proved by Kahn, the chromatic number and fractional chromatic number of a\nline graph agree asymptotically. That is, for any line graph $G$ we have\n$\\chi(G) \\leq (1+o(1))\\chi_f(G)$. We extend this result to quasi-line graphs,\nan important subclass of claw-free graphs. Furthermore we prove that we can\nconstruct a colouring that achieves this bound in polynomial time, giving us an\nasymptotic approximation algorithm for the chromatic number of quasi-line\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 22:33:39 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["King", "Andrew D.", ""], ["Reed", "Bruce", ""]]}, {"id": "1102.0908", "submitter": "Somnath Sikdar", "authors": "Alexander Langer and Peter Rossmanith and Somnath Sikdar", "title": "Linear-Time Algorithms for Graphs of Bounded Rankwidth: A Fresh Look\n  Using Game Theory", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative proof of a theorem by Courcelle, Makowski and\nRotics which states that problems expressible in MSO are solvable in linear\ntime for graphs of bounded rankwidth. Our proof uses a game-theoretic approach\nand has the advantage of being self-contained, intuitive, and fairly easy to\nfollow. In particular, our presentation does not assume any background in logic\nor automata theory. We believe that it is good to have alternative proofs of\nthis important result. Moreover our approach can be generalized to prove other\nresults of a similar flavor, for example, that of Courcelle's Theorem for\ntreewidth.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 13:28:09 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Langer", "Alexander", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1102.1003", "submitter": "Rasmus Pagh", "authors": "Rasmus Resen Amossen and Rasmus Pagh", "title": "A New Data Layout For Set Intersection on GPUs", "comments": "A version of this paper appears in Proceedings of IPDPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set intersection is the core in a variety of problems, e.g. frequent itemset\nmining and sparse boolean matrix multiplication. It is well-known that large\nspeed gains can, for some computational problems, be obtained by using a\ngraphics processing unit (GPU) as a massively parallel computing device.\nHowever, GPUs require highly regular control flow and memory access patterns,\nand for this reason previous GPU methods for intersecting sets have used a\nsimple bitmap representation. This representation requires excessive space on\nsparse data sets. In this paper we present a novel data layout, \"BatMap\", that\nis particularly well suited for parallel processing, and is compact even for\nsparse data.\n  Frequent itemset mining is one of the most important applications of set\nintersection. As a case-study on the potential of BatMaps we focus on frequent\npair mining, which is a core special case of frequent itemset mining. The main\nfinding is that our method is able to achieve speedups over both Apriori and\nFP-growth when the number of distinct items is large, and the density of the\nproblem instance is above 1%. Previous implementations of frequent itemset\nmining on GPU have not been able to show speedups over the best single-threaded\nimplementations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 19:47:41 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Amossen", "Rasmus Resen", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1102.1006", "submitter": "Bhaskar DasGupta", "authors": "Mary Ashley and Tanya Berger-Wolf and Piotr Berman and Wanpracha\n  Chaovalitwongse and Bhaskar DasGupta and Ming-Yang Kao", "title": "On Approximating Four Covering and Packing Problems", "comments": "25 pages", "journal-ref": "Journal of Computer and System Sciences, 75, 287-302, 2009", "doi": "10.1016/j.jcss.2009.01.002", "report-no": null, "categories": "cs.CC cs.DM cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider approximability issues of the following four\nproblems: triangle packing, full sibling reconstruction, maximum profit\ncoverage and 2-coverage. All of them are generalized or specialized versions of\nset-cover and have applications in biology ranging from full-sibling\nreconstructions in wild populations to biomolecular clusterings; however, as\nthis paper shows, their approximability properties differ considerably. Our\ninapproximability constant for the triangle packing problem improves upon the\nprevious results; this is done by directly transforming the inapproximability\ngap of Haastad for the problem of maximizing the number of satisfied equations\nfor a set of equations over GF(2) and is interesting in its own right. Our\napproximability results on the full siblings reconstruction problems answers\nquestions originally posed by Berger-Wolf et al. and our results on the maximum\nprofit coverage problem provides almost matching upper and lower bounds on the\napproximation ratio, answering a question posed by Hassin and Or.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 19:59:12 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Ashley", "Mary", ""], ["Berger-Wolf", "Tanya", ""], ["Berman", "Piotr", ""], ["Chaovalitwongse", "Wanpracha", ""], ["DasGupta", "Bhaskar", ""], ["Kao", "Ming-Yang", ""]]}, {"id": "1102.1123", "submitter": "Golnaz Ghasemiesfeh", "authors": "Golnaz Ghasemiesfeh", "title": "Algorithms for Silver Coloring of Generalized Petersen Graphs", "comments": "This paper has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 04:52:29 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 00:17:03 GMT"}, {"version": "v3", "created": "Sun, 27 Feb 2011 18:49:39 GMT"}, {"version": "v4", "created": "Wed, 2 Mar 2011 00:42:33 GMT"}, {"version": "v5", "created": "Thu, 3 Mar 2011 02:10:29 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Ghasemiesfeh", "Golnaz", ""]]}, {"id": "1102.1124", "submitter": "Golnaz Ghasemiesfeh", "authors": "Golnaz Ghasemiesfeh, Hanieh Mirzaei, Yahya Tabesh", "title": "A Polynomial Time Algorithm for a Special Case of Linear Integer\n  Programming", "comments": "This article has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article has been withdrawn.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 04:53:31 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 00:16:36 GMT"}, {"version": "v3", "created": "Mon, 28 Feb 2011 05:22:44 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Ghasemiesfeh", "Golnaz", ""], ["Mirzaei", "Hanieh", ""], ["Tabesh", "Yahya", ""]]}, {"id": "1102.1140", "submitter": "Carola Winzen", "authors": "Benjamin Doerr, Carola Winzen", "title": "Ranking-Based Black-Box Complexity", "comments": "This is an extended version of our CSR 2011 paper. 31 pages. The\n  journal version is to appear in Algorithmica, DOI: 10.1007/s00453-012-9684-9", "journal-ref": null, "doi": "10.1007/s00453-012-9684-9", "report-no": null, "categories": "cs.NE cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized search heuristics such as evolutionary algorithms, simulated\nannealing, and ant colony optimization are a broadly used class of\ngeneral-purpose algorithms. Analyzing them via classical methods of theoretical\ncomputer science is a growing field. While several strong runtime analysis\nresults have appeared in the last 20 years, a powerful complexity theory for\nsuch algorithms is yet to be developed. We enrich the existing notions of\nblack-box complexity by the additional restriction that not the actual\nobjective values, but only the relative quality of the previously evaluated\nsolutions may be taken into account by the black-box algorithm. Many randomized\nsearch heuristics belong to this class of algorithms.\n  We show that the new ranking-based model gives more realistic complexity\nestimates for some problems. For example, the class of all binary-value\nfunctions has a black-box complexity of $O(\\log n)$ in the previous black-box\nmodels, but has a ranking-based complexity of $\\Theta(n)$.\n  For the class of all OneMax functions, we present a ranking-based black-box\nalgorithm that has a runtime of $\\Theta(n / \\log n)$, which shows that the\nOneMax problem does not become harder with the additional ranking-basedness\nrestriction.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 11:13:25 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 22:14:26 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2012 08:10:26 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Doerr", "Benjamin", ""], ["Winzen", "Carola", ""]]}, {"id": "1102.1161", "submitter": "Frederic Magniez", "authors": "Frederic Magniez and Michel de Rougemont and Miklos Santha and Xavier\n  Zeitoun", "title": "The complexity of approximate Nash equilibrium in congestion games with\n  negative delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the study of the complexity of finding an $\\eps$-approximate Nash\nequilibrium in congestion games from the case of positive delay functions to\ndelays of arbitrary sign. We first prove that in symmetric games with\n$\\alpha$-bounded jump the $\\eps$-Nash dynamic converges in polynomial time when\nall delay functions are negative, similarly to the case of positive delays. We\nthen establish a hardness result for symmetric games with $\\alpha$-bounded jump\nand with arbitrary delay functions: in that case finding an $\\eps$-Nash\nequilibrium becomes $\\PLS$-complete.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 15:46:36 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["Magniez", "Frederic", ""], ["de Rougemont", "Michel", ""], ["Santha", "Miklos", ""], ["Zeitoun", "Xavier", ""]]}, {"id": "1102.1273", "submitter": "{\\L}ukasz Je\\.z", "authors": "{\\L}ukasz Je\\.z", "title": "One to Rule Them All: a General Randomized Algorithm for Buffer\n  Management with Bounded Delay", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a memoryless scale-invariant randomized algorithm for the Buffer\nManagement with Bounded Delay problem that is e/(e-1)-competitive against an\nadaptive adversary, together with better performance guarantees for many\nrestricted variants, including the s-bounded instances. In particular, our\nalgorithm attains the optimum competitive ratio of 4/3 on 2-bounded instances.\n  Both the algorithm and its analysis are applicable to a more general problem,\ncalled Collecting Items, in which only the relative order between packets'\ndeadlines is known. Our algorithm is the optimal randomized memoryless\nalgorithm against adaptive adversary for that problem in a strong sense.\n  While some of provided upper bounds were already known, in general, they were\nattained by several different algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Feb 2011 11:09:34 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["Je\u017c", "\u0141ukasz", ""]]}, {"id": "1102.1472", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran, Richard Karp, Erick Moreno-Centeno,\n  Santosh Vempala", "title": "Algorithms for Implicit Hitting Set Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hitting set for a collection of sets is a set that has a non-empty\nintersection with each set in the collection; the hitting set problem is to\nfind a hitting set of minimum cardinality. Motivated by instances of the\nhitting set problem where the number of sets to be hit is large, we introduce\nthe notion of implicit hitting set problems. In an implicit hitting set problem\nthe collection of sets to be hit is typically too large to list explicitly;\ninstead, an oracle is provided which, given a set H, either determines that H\nis a hitting set or returns a set that H does not hit. We show a number of\nexamples of classic implicit hitting set problems, and give a generic algorithm\nfor solving such problems optimally. The main contribution of this paper is to\nshow that this framework is valuable in developing approximation algorithms. We\nillustrate this methodology by presenting a simple on-line algorithm for the\nminimum feedback vertex set problem on random graphs. In particular our\nalgorithm gives a feedback vertex set of size n-(1/p)\\log{np}(1-o(1)) with\nprobability at least 3/4 for the random graph G_{n,p} (the smallest feedback\nvertex set is of size n-(2/p)\\log{np}(1+o(1))). We also consider a planted\nmodel for the feedback vertex set in directed random graphs. Here we show that\na hitting set for a polynomial-sized subset of cycles is a hitting set for the\nplanted random graph and this allows us to exactly recover the planted feedback\nvertex set.\n", "versions": [{"version": "v1", "created": "Mon, 7 Feb 2011 23:40:58 GMT"}], "update_date": "2011-02-09", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Karp", "Richard", ""], ["Moreno-Centeno", "Erick", ""], ["Vempala", "Santosh", ""]]}, {"id": "1102.1544", "submitter": "Jasine Babu", "authors": "Abhijin Adiga and Jasine Babu and L. Sunil Chandran", "title": "A Constant Factor Approximation Algorithm for Boxicity of Circular Arc\n  Graphs", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boxicity of a graph $G(V,E)$ is the minimum integer $k$ such that $G$ can be\nrepresented as the intersection graph of $k$-dimensional axis parallel\nrectangles in $\\mathbf{R}^k$. Equivalently, it is the minimum number of\ninterval graphs on the vertex set $V$ such that the intersection of their edge\nsets is $E$. It is known that boxicity cannot be approximated even for graph\nclasses like bipartite, co-bipartite and split graphs below $O(n^{0.5 -\n\\epsilon})$-factor, for any $\\epsilon >0$ in polynomial time unless $NP=ZPP$.\nTill date, there is no well known graph class of unbounded boxicity for which\neven an $n^\\epsilon$-factor approximation algorithm for computing boxicity is\nknown, for any $\\epsilon <1$. In this paper, we study the boxicity problem on\nCircular Arc graphs - intersection graphs of arcs of a circle. We give a\n$(2+\\frac{1}{k})$-factor polynomial time approximation algorithm for computing\nthe boxicity of any circular arc graph along with a corresponding box\nrepresentation, where $k \\ge 1$ is its boxicity. For Normal Circular Arc(NCA)\ngraphs, with an NCA model given, this can be improved to an additive 2-factor\napproximation algorithm. The time complexity of the algorithms to approximately\ncompute the boxicity is $O(mn+n^2)$ in both these cases and in $O(mn+kn^2)=\nO(n^3)$ time we also get their corresponding box representations, where $n$ is\nthe number of vertices of the graph and $m$ is its number of edges. The\nadditive 2-factor algorithm directly works for any Proper Circular Arc graph,\nsince computing an NCA model for it can be done in polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 09:27:24 GMT"}], "update_date": "2011-02-09", "authors_parsed": [["Adiga", "Abhijin", ""], ["Babu", "Jasine", ""], ["Chandran", "L. Sunil", ""]]}, {"id": "1102.1745", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Restructuring in Combinatorial Optimization", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses a new class of combinatorial problems which consist in\nrestructuring of solutions (as structures) in combinatorial optimization. Two\nmain features of the restructuring process are examined: (i) a cost of the\nrestructuring, (ii) a closeness to a goal solution. This problem corresponds to\nredesign (improvement, upgrade) of modular systems or solutions. The\nrestructuring approach is described and illustrated for the following\ncombinatorial optimization problems: knapsack problem, multiple choice problem,\nassignment problem, spanning tree problems. Examples illustrate the\nrestructuring processes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 23:05:59 GMT"}], "update_date": "2011-02-10", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1102.1746", "submitter": "Zsuzsanna Lipt\\'ak", "authors": "P\\'eter Burcsi, Ferdinando Cicalese, Gabriele Fici and Zsuzsanna\n  Lipt\\'ak", "title": "Algorithms for Jumbled Pattern Matching in Strings", "comments": "18 pages, 9 figures; article accepted for publication in the\n  International Journal of Foundations of Computer Science", "journal-ref": "Int. J. Found. Comput. Sci. 23(2): 357-374 (2012)", "doi": "10.1142/S0129054112400175", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Parikh vector p(s) of a string s is defined as the vector of\nmultiplicities of the characters. Parikh vector q occurs in s if s has a\nsubstring t with p(t)=q. We present two novel algorithms for searching for a\nquery q in a text s. One solves the decision problem over a binary text in\nconstant time, using a linear size index of the text. The second algorithm, for\na general finite alphabet, finds all occurrences of a given Parikh vector q and\nhas sub-linear expected time complexity; we present two variants, which both\nuse a linear size index of the text.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 23:11:17 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Burcsi", "P\u00e9ter", ""], ["Cicalese", "Ferdinando", ""], ["Fici", "Gabriele", ""], ["Lipt\u00e1k", "Zsuzsanna", ""]]}, {"id": "1102.1747", "submitter": "Maria Polukarov", "authors": "Thomas D. Voice, Maria Polukarov, Nicholas R. Jennings", "title": "Graph Coalition Structure Generation", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first analysis of the computational complexity of {\\it coalition\nstructure generation over graphs}. Given an undirected graph $G=(N,E)$ and a\nvaluation function $v:2^N\\rightarrow\\RR$ over the subsets of nodes, the problem\nis to find a partition of $N$ into connected subsets, that maximises the sum of\nthe components' values. This problem is generally NP--complete; in particular,\nit is hard for a defined class of valuation functions which are {\\it\nindependent of disconnected members}---that is, two nodes have no effect on\neach other's marginal contribution to their vertex separator. Nonetheless, for\nall such functions we provide bounds on the complexity of coalition structure\ngeneration over general and minor free graphs. Our proof is constructive and\nyields algorithms for solving corresponding instances of the problem.\nFurthermore, we derive polynomial time bounds for acyclic, $K_{2,3}$ and $K_4$\nminor free graphs. However, as we show, the problem remains NP--complete for\nplanar graphs, and hence, for any $K_k$ minor free graphs where $k\\geq 5$.\nMoreover, our hardness result holds for a particular subclass of valuation\nfunctions, termed {\\it edge sum}, where the value of each subset of nodes is\nsimply determined by the sum of given weights of the edges in the induced\nsubgraph.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 23:13:58 GMT"}], "update_date": "2011-02-10", "authors_parsed": [["Voice", "Thomas D.", ""], ["Polukarov", "Maria", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1102.1783", "submitter": "Mihai Patrascu", "authors": "Mihai Patrascu and Mikkel Thorup", "title": "Don't Rush into a Union: Take Time to Find Your Roots", "comments": "To appear in STOC'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new threshold phenomenon in data structure lower bounds where\nslightly reduced update times lead to exploding query times. Consider\nincremental connectivity, letting t_u be the time to insert an edge and t_q be\nthe query time. For t_u = Omega(t_q), the problem is equivalent to the\nwell-understood union-find problem: InsertEdge(s,t) can be implemented by\nUnion(Find(s), Find(t)). This gives worst-case time t_u = t_q = O(lg n / lglg\nn) and amortized t_u = t_q = O(alpha(n)).\n  By contrast, we show that if t_u = o(lg n / lglg n), the query time explodes\nto t_q >= n^{1-o(1)}. In other words, if the data structure doesn't have time\nto find the roots of each disjoint set (tree) during edge insertion, there is\nno effective way to organize the information!\n  For amortized complexity, we demonstrate a new inverse-Ackermann type\ntrade-off in the regime t_u = o(t_q).\n  A similar lower bound is given for fully dynamic connectivity, where an\nupdate time of o(\\lg n) forces the query time to be n^{1-o(1)}. This lower\nbound allows for amortization and Las Vegas randomization, and comes close to\nthe known O(lg n * poly(lglg n)) upper bound.\n", "versions": [{"version": "v1", "created": "Wed, 9 Feb 2011 05:07:47 GMT"}, {"version": "v2", "created": "Sun, 27 Mar 2011 17:20:00 GMT"}], "update_date": "2011-03-29", "authors_parsed": [["Patrascu", "Mihai", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1102.2075", "submitter": "Ulrike von Luxburg", "authors": "Markus Maier and Ulrike von Luxburg and Matthias Hein", "title": "How the result of graph clustering methods depends on the construction\n  of the graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the scenario of graph-based clustering algorithms such as spectral\nclustering. Given a set of data points, one first has to construct a graph on\nthe data points and then apply a graph clustering algorithm to find a suitable\npartition of the graph. Our main question is if and how the construction of the\ngraph (choice of the graph, choice of parameters, choice of weights) influences\nthe outcome of the final clustering result. To this end we study the\nconvergence of cluster quality measures such as the normalized cut or the\nCheeger cut on various kinds of random geometric graphs as the sample size\ntends to infinity. It turns out that the limit values of the same objective\nfunction are systematically different on different types of graphs. This\nimplies that clustering results systematically depend on the graph and can be\nvery different for different types of graph. We provide examples to illustrate\nthe implications on spectral clustering.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 10:44:42 GMT"}], "update_date": "2011-02-11", "authors_parsed": [["Maier", "Markus", ""], ["von Luxburg", "Ulrike", ""], ["Hein", "Matthias", ""]]}, {"id": "1102.2524", "submitter": "Mark Levin", "authors": "Mark Sh. Levin, Rustem I. Nuriakhmetov", "title": "Multicriteria Steiner Tree Problem for Communication Network", "comments": "11 pages, 7 figures", "journal-ref": "Information Processes 9(3) (2009) 199-209", "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses combinatorial optimization scheme for solving the\nmulticriteria Steiner tree problem for communication network topology design\n(e.g., wireless mesh network). The solving scheme is based on several models:\nmulticriteria ranking, clustering, minimum spanning tree, and minimum Steiner\ntree problem. An illustrative numerical example corresponds to designing a\ncovering long-distance Wi-Fi network (static Ad-Hoc network). The set of\ncriteria (i.e., objective functions) involves the following: total cost, total\nedge length, overall throughput (capacity), and estimate of QoS. Obtained\ncomputing results show the suggested solving scheme provides good network\ntopologies which can be compared with minimum spanning trees.\n", "versions": [{"version": "v1", "created": "Sat, 12 Feb 2011 15:37:19 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Levin", "Mark Sh.", ""], ["Nuriakhmetov", "Rustem I.", ""]]}, {"id": "1102.2541", "submitter": "Nicolas Broutin", "authors": "Nicolas Broutin, Cecilia Holmgren", "title": "The total path length of split trees", "comments": "Published in at http://dx.doi.org/10.1214/11-AAP812 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 5, 1745-1777", "doi": "10.1214/11-AAP812", "report-no": "IMS-AAP-AAP812", "categories": "math.PR cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of random trees introduced by Devroye [SIAM J. Comput.\n28 (1999) 409-432]. The model encompasses many important randomized algorithms\nand data structures. The pieces of data (items) are stored in a randomized\nfashion in the nodes of a tree. The total path length (sum of depths of the\nitems) is a natural measure of the efficiency of the algorithm/data structure.\nUsing renewal theory, we prove convergence in distribution of the total path\nlength toward a distribution characterized uniquely by a fixed point equation.\nOur result covers, using a unified approach, many data structures such as\nbinary search trees, m-ary search trees, quad trees, median-of-(2k+1) trees,\nand simplex trees.\n", "versions": [{"version": "v1", "created": "Sat, 12 Feb 2011 22:26:27 GMT"}, {"version": "v2", "created": "Wed, 18 May 2011 05:29:19 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2012 07:52:05 GMT"}], "update_date": "2012-11-05", "authors_parsed": [["Broutin", "Nicolas", ""], ["Holmgren", "Cecilia", ""]]}, {"id": "1102.2551", "submitter": "Santiago Balseiro", "authors": "Santiago Balseiro and Jon Feldman and Vahab Mirrokni and S.\n  Muthukrishnan", "title": "Yield Optimization of Display Advertising with Ad Exchange", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In light of the growing market of Ad Exchanges for the real-time sale of\nadvertising slots, publishers face new challenges in choosing between the\nallocation of contract-based reservation ads and spot market ads. In this\nsetting, the publisher should take into account the tradeoff between short-term\nrevenue from an Ad Exchange and quality of allocating reservation ads. In this\npaper, we formalize this combined optimization problem as a stochastic control\nproblem and derive an efficient policy for online ad allocation in settings\nwith general joint distribution over placement quality and exchange bids. We\nprove asymptotic optimality of this policy in terms of any trade-off between\nquality of delivered reservation ads and revenue from the exchange, and provide\na rigorous bound for its convergence rate to the optimal policy. We also give\nexperimental results on data derived from real publisher inventory, showing\nthat our policy can achieve any pareto-optimal point on the quality vs. revenue\ncurve. Finally, we study a parametric training-based algorithm in which instead\nof learning the dual variables from a sample data (as is done in non-parametric\ntraining-based algorithms), we learn the parameters of the distribution and\nconstruct those dual variables from the learned parameter values. We compare\nparametric and non-parametric ways to estimate from data both analytically and\nexperimentally in the special case without the ad exchange, and show that\nthough both methods converge to the optimal policy as the sample size grows,\nour parametric method converges faster, and thus performs better on smaller\nsamples.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 01:51:43 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2012 21:07:20 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Balseiro", "Santiago", ""], ["Feldman", "Jon", ""], ["Mirrokni", "Vahab", ""], ["Muthukrishnan", "S.", ""]]}, {"id": "1102.2602", "submitter": "Mohammad Javad Emadi", "authors": "Farhad Shirani Chaharsooghi, Mohammad Javad Emadi, Mahdi Zamanighomi\n  and Mohammad Reza Aref", "title": "A New Method for Variable Elimination in Systems of Inequations", "comments": "5 Pages, 0 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new method for variable elimination in systems of\ninequations which is much faster than the Fourier-Motzkin Elimination (FME)\nmethod. In our method, a linear Diophantine problem is introduced which is dual\nto our original problem. The new Diophantine system is then solved, and the\nfinal result is calculated by finding the dual inequations system. Our new\nmethod uses the algorithm Normaliz to find the Hilbert basis of the solution\nspace of the given Diophantine problem. We introduce a problem in the\ninterference channel with multiple nodes and solve it with our new method.\nNext, we generalize our method to all problems involving FME and in the end we\ncompare our method with the previous method. We show that our method has many\nadvantages in comparison to the previous method. It does not produce many of\nthe redundant answers of the FME method. It also solves the whole problem in\none step whereas the previous method uses a step by step approach in\neliminating each auxiliary variable.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 15:10:10 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Chaharsooghi", "Farhad Shirani", ""], ["Emadi", "Mohammad Javad", ""], ["Zamanighomi", "Mahdi", ""], ["Aref", "Mohammad Reza", ""]]}, {"id": "1102.2825", "submitter": "Marjan Baghaie", "authors": "Marjan Baghaie, Bhaskar Krishnamachari, and Andreas F. Molisch", "title": "Algorithmic Aspects of Energy-Delay Tradeoff in Multihop Cooperative\n  Wireless Networks", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of energy-efficient transmission in delay constrained\ncooperative multihop wireless networks. The combinatorial nature of cooperative\nmultihop schemes makes it difficult to design efficient polynomial-time\nalgorithms for deciding which nodes should take part in cooperation, and when\nand with what power they should transmit. In this work, we tackle this problem\nin memoryless networks with or without delay constraints, i.e., quality of\nservice guarantee. We analyze a wide class of setups, including unicast,\nmulticast, and broadcast, and two main cooperative approaches, namely: energy\naccumulation (EA) and mutual information accumulation (MIA). We provide a\ngeneralized algorithmic formulation of the problem that encompasses all those\ncases. We investigate the similarities and differences of EA and MIA in our\ngeneralized formulation. We prove that the broadcast and multicast problems\nare, in general, not only NP hard but also o(log(n)) inapproximable. We break\nthese problems into three parts: ordering, scheduling and power control, and\npropose a novel algorithm that, given an ordering, can optimally solve the\njoint power allocation and scheduling problems simultaneously in polynomial\ntime. We further show empirically that this algorithm used in conjunction with\nan ordering derived heuristically using the Dijkstra's shortest path algorithm\nyields near-optimal performance in typical settings. For the unicast case, we\nprove that although the problem remains NP hard with MIA, it can be solved\noptimally and in polynomial time when EA is used. We further use our algorithm\nto study numerically the trade-off between delay and power-efficiency in\ncooperative broadcast and compare the performance of EA vs MIA as well as the\nperformance of our cooperative algorithm with a smart noncooperative algorithm\nin a broadcast setting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 16:43:15 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2011 04:34:37 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Baghaie", "Marjan", ""], ["Krishnamachari", "Bhaskar", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "1102.2853", "submitter": "Wesley Pegden", "authors": "Wesley Pegden", "title": "An extension of the Moser-Tardos algorithmic local lemma", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent theorem of Bissacot, et al. proved using results about the cluster\nexpansion in statistical mechanics extends the Lov\\'asz Local Lemma by\nweakening the conditions under which its conclusions holds. In this note, we\nprove an algorithmic analog of this result, extending Moser and Tardos's recent\nalgorithmic Local Lemma, and providing an alternative proof of the theorem of\nBissacot, et al. applicable in the Moser-Tardos algorithmic framework.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 18:41:29 GMT"}, {"version": "v2", "created": "Sat, 12 Mar 2011 23:21:02 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Pegden", "Wesley", ""]]}, {"id": "1102.2878", "submitter": "Dongryeol Lee", "authors": "Dongryeol Lee, Alexander G. Gray, and Andrew W. Moore", "title": "Dual-Tree Fast Gauss Transforms", "comments": "Extended version of a conference paper. Submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel density estimation (KDE) is a popular statistical technique for\nestimating the underlying density distribution with minimal assumptions.\nAlthough they can be shown to achieve asymptotic estimation optimality for any\ninput distribution, cross-validating for an optimal parameter requires\nsignificant computation dominated by kernel summations. In this paper we\npresent an improvement to the dual-tree algorithm, the first practical kernel\nsummation algorithm for general dimension. Our extension is based on the\nseries-expansion for the Gaussian kernel used by fast Gauss transform. First,\nwe derive two additional analytical machinery for extending the original\nalgorithm to utilize a hierarchical data structure, demonstrating the first\ntruly hierarchical fast Gauss transform. Second, we show how to integrate the\nseries-expansion approximation within the dual-tree approach to compute kernel\nsummations with a user-controllable relative error bound. We evaluate our\nalgorithm on real-world datasets in the context of optimal bandwidth selection\nin kernel density estimation. Our results demonstrate that our new algorithm is\nthe only one that guarantees a hard relative error bound and offers fast\nperformance across a wide range of bandwidths evaluated in cross validation\nprocedures.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 20:24:01 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Lee", "Dongryeol", ""], ["Gray", "Alexander G.", ""], ["Moore", "Andrew W.", ""]]}, {"id": "1102.2906", "submitter": "Danupon Nanongkai", "authors": "Danupon Nanongkai, Atish Das Sarma, Gopal Pandurangan", "title": "A Tight Lower Bound on Distributed Random Walk Computation", "comments": "PODC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing a random walk in a distributed network.\nGiven bandwidth constraints, the goal of the problem is to minimize the number\nof rounds required to obtain a random walk sample. Das Sarma et al. [PODC'10]\nshow that a random walk of length $\\ell$ on a network of diameter $D$ can be\nperformed in $\\tilde O(\\sqrt{\\ell D}+D)$ time. A major question left open is\nwhether there exists a faster algorithm, especially whether the multiplication\nof $\\sqrt{\\ell}$ and $\\sqrt{D}$ is necessary.\n  In this paper, we show a tight unconditional lower bound on the time\ncomplexity of distributed random walk computation. Specifically, we show that\nfor any $n$, $D$, and $D\\leq \\ell \\leq (n/(D^3\\log n))^{1/4}$, performing a\nrandom walk of length $\\Theta(\\ell)$ on an $n$-node network of diameter $D$\nrequires $\\Omega(\\sqrt{\\ell D}+D)$ time. This bound is {\\em unconditional},\ni.e., it holds for any (possibly randomized) algorithm. To the best of our\nknowledge, this is the first lower bound that the diameter plays a role of\nmultiplicative factor. Our bound shows that the algorithm of Das Sarma et al.\nis time optimal.\n  Our proof technique introduces a new connection between {\\em bounded-round}\ncommunication complexity and distributed algorithm lower bounds with $D$ as a\ntrade-off parameter, strengthening the previous study by Das Sarma et al.\n[STOC'11]. In particular, we make use of the bounded-round communication\ncomplexity of the pointer chasing problem. Our technique can be of independent\ninterest and may be useful in showing non-trivial lower bounds on the\ncomplexity of other fundamental distributed computing problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 21:32:54 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2011 17:27:18 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Nanongkai", "Danupon", ""], ["Sarma", "Atish Das", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1102.2915", "submitter": "Filippo Utro", "authors": "Filippo Utro", "title": "Algorithms for Internal Validation Clustering Measures in the Post\n  Genomic Era", "comments": null, "journal-ref": "PhD Thesis, University of Palermo, Italy, 2011", "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring cluster structure in microarray datasets is a fundamental task for\nthe -omic sciences. A fundamental question in Statistics, Data Analysis and\nClassification, is the prediction of the number of clusters in a dataset,\nusually established via internal validation measures. Despite the wealth of\ninternal measures available in the literature, new ones have been recently\nproposed, some of them specifically for microarray data. In this dissertation,\na study of internal validation measures is given, paying particular attention\nto the stability based ones. Indeed, this class of measures is particularly\nprominent and promising in order to have a reliable estimate the number of\nclusters in a dataset. For those measures, a new general algorithmic paradigm\nis proposed here that highlights the richness of measures in this class and\naccounts for the ones already available in the literature. Moreover, some of\nthe most representative validation measures are also considered. Experiments on\n12 benchmark datasets are performed in order to assess both the intrinsic\nability of a measure to predict the correct number of clusters in a dataset and\nits merit relative to the other measures. The main result is a hierarchy of\ninternal validation measures in terms of precision and speed, highlighting some\nof their merits and limitations not reported before in the literature. This\nhierarchy shows that the faster the measure, the less accurate it is. In order\nto reduce the time performance gap between the fastest and the most precise\nmeasures, the technique of designing fast approximation algorithms is\nsystematically applied. The end result is a speed-up of many of the measures\nstudied here that brings the gap between the fastest and the most precise\nwithin one order of magnitude in time, with no degradation in their prediction\npower. Prior to this work, the time gap was at least two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 22:13:47 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Utro", "Filippo", ""]]}, {"id": "1102.3029", "submitter": "Gerhard Woeginger", "authors": "Christian Eggermont, Alexander Schrijver, Gerhard J. Woeginger", "title": "Analysis of multi-stage open shop processing systems", "comments": "19 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithmic problems in multi-stage open shop processing systems\nthat are centered around reachability and deadlock detection questions. We\ncharacterize safe and unsafe system states. We show that it is easy to\nrecognize system states that can be reached from the initial state (where the\nsystem is empty), but that in general it is hard to decide whether one given\nsystem state is reachable from another given system state. We show that the\nproblem of identifying reachable deadlock states is hard in general open shop\nsystems, but is easy in the special case where no job needs processing on more\nthan two machines (by linear programming and matching theory), and in the\nspecial case where all machines have capacity one (by graph-theoretic\narguments).\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 10:30:42 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Eggermont", "Christian", ""], ["Schrijver", "Alexander", ""], ["Woeginger", "Gerhard J.", ""]]}, {"id": "1102.3165", "submitter": "Anil Maheshwari", "authors": "Lyudmil Aleksandrov and Hristo Djidjev and Anil Maheshwari and\n  Joerg-Rudiger Sack", "title": "An Approximation Algorithm for Computing Shortest Paths in Weighted 3-d\n  Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first polynomial time approximation algorithm for computing\nshortest paths in weighted three-dimensional domains. Given a polyhedral domain\n$\\D$, consisting of $n$ tetrahedra with positive weights, and a real number\n$\\eps\\in(0,1)$, our algorithm constructs paths in $\\D$ from a fixed source\nvertex to all vertices of $\\D$, whose costs are at most $1+\\eps$ times the\ncosts of (weighted) shortest paths, in\n$O(\\C(\\D)\\frac{n}{\\eps^{2.5}}\\log\\frac{n}{\\eps}\\log^3\\frac{1}{\\eps})$ time,\nwhere $\\C(\\D)$ is a geometric parameter related to the aspect ratios of\ntetrahedra. The efficiency of the proposed algorithm is based on an in-depth\nstudy of the local behavior of geodesic paths and additive Voronoi diagrams in\nweighted three-dimensional domains, which are of independent interest. The\npaper extends the results of Aleksandrov, Maheshwari and Sack [JACM 2005] to\nthree dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 19:50:45 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Aleksandrov", "Lyudmil", ""], ["Djidjev", "Hristo", ""], ["Maheshwari", "Anil", ""], ["Sack", "Joerg-Rudiger", ""]]}, {"id": "1102.3204", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler and Muriel M\\'edard", "title": "One Packet Suffices - Highly Efficient Packetized Network Coding With\n  Finite Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Linear Network Coding (RLNC) has emerged as a powerful tool for robust\nhigh-throughput multicast. Projection analysis - a recently introduced\ntechnique - shows that the distributed packetized RLNC protocol achieves\n(order) optimal and perfectly pipelined information dissemination in many\nsettings. In the original approach to RNLC intermediate nodes code together all\navailable information. This requires intermediate nodes to keep considerable\ndata available for coding. Moreover, it results in a coding complexity that\ngrows linearly with the size of this data. While this has been identified as a\nproblem, approaches that combine queuing theory and network coding have\nheretofore not provided a succinct representation of the memory needs of\nnetwork coding at intermediates nodes.\n  This paper shows the surprising result that, in all settings with a\ncontinuous stream of data, network coding continues to perform optimally even\nif only one packet per node is kept in active memory and used for computations.\nThis leads to an extremely simple RLNC protocol variant with drastically\nreduced requirements on computational and memory resources. By extending the\nprojection analysis, we show that in all settings in which the RLNC protocol\nwas proven to be optimal its finite memory variant performs equally well. In\nthe same way as the original projection analysis, our technique applies in a\nwide variety of network models, including highly dynamic topologies that can\nchange completely at any time in an adversarial fashion.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 23:07:30 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Haeupler", "Bernhard", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "1102.3245", "submitter": "Swapnoneel  Roy", "authors": "Swapnoneel Roy", "title": "On Sorting by Bounded Block Interchanges", "comments": "This paper has been withdrawn by the author due to a bug in the\n  reduction. Would be available again after it is fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a restricted case of the well studied Sorting by\nBlock Interchanges problem. We put an upper bound k on the length of the blocks\n(substrings) to be interchanged at each step. We call the problem Sorting by\nk-Block Interchanges. We show the problem to be NP-Hard for k=1. The problem is\neasy for k=n-1, where n is the length of the permutation (the unbounded case).\nSorting by Block Interchanges is a very important and widely studied problem\nwith applications in comparative genomics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 05:45:04 GMT"}, {"version": "v2", "created": "Fri, 18 Feb 2011 05:24:15 GMT"}, {"version": "v3", "created": "Tue, 1 Mar 2011 22:37:48 GMT"}, {"version": "v4", "created": "Sun, 6 Mar 2011 20:00:05 GMT"}, {"version": "v5", "created": "Wed, 5 Oct 2011 04:01:20 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Roy", "Swapnoneel", ""]]}, {"id": "1102.3306", "submitter": "Dennis Luxen", "authors": "Christian Jung, Daniel Karch, Sebastian Knopp, Dennis Luxen, and Peter\n  Sanders", "title": "Efficient Error-Correcting Geocoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of resolving a perhaps misspelled address of a location\ninto geographic coordinates of latitude and longitude. Our data structure\nsolves this problem within a few milliseconds even for misspelled and\nfragmentary queries. Compared to major geographic search engines such as Google\nor Bing we achieve results of significantly better quality.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 11:16:51 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Jung", "Christian", ""], ["Karch", "Daniel", ""], ["Knopp", "Sebastian", ""], ["Luxen", "Dennis", ""], ["Sanders", "Peter", ""]]}, {"id": "1102.3340", "submitter": "Atish Das Sarma", "authors": "Amita Gajewar, Atish Das Sarma", "title": "Multi-skill Collaborative Teams based on Densest Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying a team of skilled individuals for\ncollaboration, in the presence of a social network. Each node in the social\nnetwork may be an expert in one or more skills. Edge weights specify affinity\nor collaborative compatibility between respective nodes. Given a project that\nrequires a set of specified number of skilled individuals in each area of\nexpertise, the goal is to identify a team that maximizes the collaborative\ncompatibility. For example, the requirement may be to form a team that has at\nleast three databases experts and at least two theory experts. We explore team\nformation where the collaborative compatibility objective is measured as the\ndensity of the induced subgraph on selected nodes. The problem of maximizing\ndensity is NP-hard even when the team requires individuals of only one skill.\nWe present a 3-approximation algorithm that improves upon a naive extension of\nthe previously known algorithm for densest at least $k$ subgraph problem. We\nfurther show how the same approximation can be extended to a special case of\nmultiple skills. Our problem generalizes the formulation studied by Lappas et\nal. [KDD '09] who measure team compatibility in terms of diameter or spanning\ntree costs. Experiments are performed on a crawl of the DBLP graph where\nindividuals can be skilled in at most four areas - theory, databases, data\nmining, and artificial intelligence. In addition to our main algorithm, we also\npresent heuristic extensions to trade off between the size of the solution and\nits induced density. These density-based algorithms outperform the\ndiameter-based objective on several metrics for assessing the collaborative\ncompatibility of teams. The solutions suggested are also intuitively meaningful\nand scale well with the increase in the number of skilled individuals required.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 02:06:39 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Gajewar", "Amita", ""], ["Sarma", "Atish Das", ""]]}, {"id": "1102.3393", "submitter": "{\\L}ukasz Je\\.z", "authors": "Marek Chrobak, {\\L}ukasz Je\\.z, Ji\\v{r}\\'i Sgall", "title": "Better Bounds for Incremental Frequency Allocation in Bipartite Graphs", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study frequency allocation in wireless networks. A wireless network is\nmodeled by an undirected graph, with vertices corresponding to cells. In each\nvertex we have a certain number of requests, and each of those requests must be\nassigned a different frequency. Edges represent conflicts between cells,\nmeaning that frequencies in adjacent vertices must be different as well. The\nobjective is to minimize the total number of used frequencies.\n  The offline version of the problem is known to be NP-hard. In the incremental\nversion, requests for frequencies arrive over time and the algorithm is\nrequired to assign a frequency to a request as soon as it arrives. Competitive\nincremental algorithms have been studied for several classes of graphs. For\npaths, the optimal (asymptotic) ratio is known to be 4/3, while for\nhexagonal-cell graphs it is between 1.5 and 1.9126. For k-colorable graphs, the\nratio of (k+1)/2 can be achieved.\n  In this paper, we prove nearly tight bounds on the asymptotic competitive\nratio for bipartite graphs, showing that it is between 1.428 and 1.433. This\nimproves the previous lower bound of 4/3 and upper bound of 1.5. Our proofs are\nbased on reducing the incremental problem to a purely combinatorial\n(equivalent) problem of constructing set families with certain intersection\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 18:32:07 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Chrobak", "Marek", ""], ["Je\u017c", "\u0141ukasz", ""], ["Sgall", "Ji\u0159\u00ed", ""]]}, {"id": "1102.3420", "submitter": "Wouter Kuijper", "authors": "Wouter Kuijper, Michael Weber", "title": "Generic Programming of Reusable, High Performance Container Types using\n  Automatic Type Hierarchy Inference and Bidirectional Antichain Typing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new compile-time notion of type subsumption based on type\nsimulation. We show how to apply this static subsumption relation to support a\nmore intuitive, object oriented approach to generic programming of reusable,\nhigh performance container types. As a first step towards an efficient\nimplementation of the resulting type system in a compiler we present a novel\nalgorithm for bidirectional type inference over arbitrary syntax graphs. The\nalgorithm uses the new static type subsumption relation to compress the data\nthat has to be stored for each node in the typeflow graph. During typeflow\nanalysis this means that the set of types for a given node can be symbolically\nrepresented using antichains instead of using bitvectors or some other explicit\nset representation. This results in a typing algorithm that is both flexible\nand precise and shows good performance on representative instances.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 20:34:21 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Kuijper", "Wouter", ""], ["Weber", "Michael", ""]]}, {"id": "1102.3491", "submitter": "Jos\\'e Soto", "authors": "Jos\\'e A. Soto", "title": "A simple PTAS for Weighted Matroid Matching on Strongly Base Orderable\n  Matroids", "comments": "8 pages, 3 figures. To appear in LAGOS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple polynomial time approximation scheme for the weighted\nmatroid matching problem on strongly base orderable matroids. We also show that\neven the unweighted version of this problem is NP-complete and not in\noracle-coNP.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 04:22:13 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Soto", "Jos\u00e9 A.", ""]]}, {"id": "1102.3537", "submitter": "Ariel Shiftan", "authors": "Guy Feigenblat, Ely Porat, Ariel Shiftan", "title": "Even Better Framework for min-wise Based Algorithms", "comments": "10 pages + appendix. 15 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper from SODA11 \\cite{kminwise} the authors introduced a\ngeneral framework for exponential time improvement of \\minwise based algorithms\nby defining and constructing almost \\kmin independent family of hash functions.\nHere we take it a step forward and reduce the space and the independent needed\nfor representing the functions, by defining and constructing a \\dkmin\nindependent family of hash functions. Surprisingly, for most cases only 8-wise\nindependent is needed for exponential time and space improvement. Moreover, we\nbypass the $O(\\log{\\frac{1}{\\epsilon}})$ independent lower bound for\napproximately \\minwise functions \\cite{patrascu10kwise-lb}, as we use\nalternative definition. In addition, as the independent's degree is a small\nconstant it can be implemented efficiently.\n  Informally, under this definition, all subsets of size $d$ of any fixed set\n$X$ have an equal probability to have hash values among the minimal $k$ values\nin $X$, where the probability is over the random choice of hash function from\nthe family. This property measures the randomness of the family, as choosing a\ntruly random function, obviously, satisfies the definition for $d=k=|X|$. We\ndefine and give an efficient time and space construction of approximately\n\\dkmin independent family of hash functions. The degree of independent required\nis optimal, i.e. only $O(d)$ for $2 \\le d < k=O(\\frac{d}{\\epsilon^2})$, where\n$\\epsilon \\in (0,1)$ is the desired error bound. This construction can be used\nto improve many \\minwise based algorithms, such as\n\\cite{sizeEstimationFramework,Datar02estimatingrarity,NearDuplicate,SimilaritySearch,DBLP:conf/podc/CohenK07},\nas will be discussed here. To our knowledge such definitions, for hash\nfunctions, were never studied and no construction was given before.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 09:43:17 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Feigenblat", "Guy", ""], ["Porat", "Ely", ""], ["Shiftan", "Ariel", ""]]}, {"id": "1102.3569", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler and MinJi Kim and Muriel M\\'edard", "title": "Optimality of Network Coding in Packet Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve the question of optimality for a well-studied packetized\nimplementation of random linear network coding, called PNC. In PNC, in contrast\nto the classical memoryless setting, nodes store received information in memory\nto later produce coded packets that reflect this information. PNC is known to\nachieve order optimal stopping times for the many-to-all multicast problem in\nmany settings.\n  We give a reduction that captures exactly how PNC and other network coding\nprotocols use the memory of the nodes. More precisely, we show that any such\nprotocol implementation induces a transformation which maps an execution of the\nprotocol to an instance of the classical memoryless setting. This allows us to\nprove that, for any (non-adaptive dynamic) network, PNC converges with high\nprobability in optimal time. In other words, it stops at exactly the first time\nin which in hindsight it was possible to route information from the sources to\neach receiver individually.\n  Our technique also applies to variants of PNC, in which each node uses only a\nfinite buffer. We show that, even in this setting, PNC stops exactly within the\ntime in which in hindsight it was possible to route packets given the memory\nconstraint, i.e., that the memory used at each node never exceeds its buffer\nsize. This shows that PNC, even without any feedback or explicit memory\nmanagement, allows to keep minimal buffer sizes while maintaining its capacity\nachieving performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 12:08:30 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Kim", "MinJi", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "1102.3635", "submitter": "Ross Kang", "authors": "Magnus Bordewich, Ross J. Kang", "title": "Rapid mixing of subset Glauber dynamics on graphs of bounded tree-width", "comments": "18 pages", "journal-ref": "Electron. J. Combin. 21(4): #P4.19 (26 pp.), 2014", "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the `subgraphs world' view of the ferromagnetic Ising model, we\ndevelop a general approach to studying mixing times of Glauber dynamics based\non subset expansion expressions for a class of graph polynomials. With a\ncanonical paths argument, we demonstrate that the chains defined within this\nframework mix rapidly upon graphs of bounded tree-width. This extends known\nresults on rapid mixing for the Tutte polynomial, the adjacency-rank\n($R_2$-)polynomial and the interlace polynomial.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 17:01:59 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Bordewich", "Magnus", ""], ["Kang", "Ross J.", ""]]}, {"id": "1102.3643", "submitter": "Paul Bonsma", "authors": "Paul Bonsma, Jens Schulz, and Andreas Wiese", "title": "A Constant Factor Approximation Algorithm for Unsplittable Flow on Paths", "comments": "37 pages, 5 figures Version 2 contains the same results as version 1,\n  but the presentation has been greatly revised and improved. References have\n  been added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the unsplittable flow problem on a path, we are given a capacitated path\n$P$ and $n$ tasks, each task having a demand, a profit, and start and end\nvertices. The goal is to compute a maximum profit set of tasks, such that for\neach edge $e$ of $P$, the total demand of selected tasks that use $e$ does not\nexceed the capacity of $e$. This is a well-studied problem that has been\nstudied under alternative names, such as resource allocation, bandwidth\nallocation, resource constrained scheduling, temporal knapsack and interval\npacking.\n  We present a polynomial time constant-factor approximation algorithm for this\nproblem. This improves on the previous best known approximation ratio of\n$O(\\log n)$. The approximation ratio of our algorithm is $7+\\epsilon$ for any\n$\\epsilon>0$.\n  We introduce several novel algorithmic techniques, which might be of\nindependent interest: a framework which reduces the problem to instances with a\nbounded range of capacities, and a new geometrically inspired dynamic program\nwhich solves a special case of the maximum weight independent set of rectangles\nproblem to optimality. In the setting of resource augmentation, wherein the\ncapacities can be slightly violated, we give a $(2+\\epsilon)$-approximation\nalgorithm. In addition, we show that the problem is strongly NP-hard even if\nall edge capacities are equal and all demands are either~1,~2, or~3.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 17:43:08 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2012 16:21:01 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bonsma", "Paul", ""], ["Schulz", "Jens", ""], ["Wiese", "Andreas", ""]]}, {"id": "1102.3749", "submitter": "Ravishankar Krishnaswamy", "authors": "Anupam Gupta, Ravishankar Krishnaswamy, Marco Molinaro and R. Ravi", "title": "Approximation Algorithms for Correlated Knapsacks and Non-Martingale\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the stochastic knapsack problem, we are given a knapsack of size B, and a\nset of jobs whose sizes and rewards are drawn from a known probability\ndistribution. However, we know the actual size and reward only when the job\ncompletes. How should we schedule jobs to maximize the expected total reward?\nWe know O(1)-approximations when we assume that (i) rewards and sizes are\nindependent random variables, and (ii) we cannot prematurely cancel jobs. What\ncan we say when either or both of these assumptions are changed?\n  The stochastic knapsack problem is of interest in its own right, but\ntechniques developed for it are applicable to other stochastic packing\nproblems. Indeed, ideas for this problem have been useful for budgeted learning\nproblems, where one is given several arms which evolve in a specified\nstochastic fashion with each pull, and the goal is to pull the arms a total of\nB times to maximize the reward obtained. Much recent work on this problem focus\non the case when the evolution of the arms follows a martingale, i.e., when the\nexpected reward from the future is the same as the reward at the current state.\nWhat can we say when the rewards do not form a martingale?\n  In this paper, we give constant-factor approximation algorithms for the\nstochastic knapsack problem with correlations and/or cancellations, and also\nfor budgeted learning problems where the martingale condition is not satisfied.\nIndeed, we can show that previously proposed LP relaxations have large\nintegrality gaps. We propose new time-indexed LP relaxations, and convert the\nfractional solutions into distributions over strategies, and then use the LP\nvalues and the time ordering information from these strategies to devise a\nrandomized adaptive scheduling algorithm. We hope our LP formulation and\ndecomposition methods may provide a new way to address other correlated bandit\nproblems with more general contexts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 04:05:21 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Gupta", "Anupam", ""], ["Krishnaswamy", "Ravishankar", ""], ["Molinaro", "Marco", ""], ["Ravi", "R.", ""]]}, {"id": "1102.3766", "submitter": "Masaki Yamamoto", "authors": "Kazuhisa Makino, Suguru Tamaki, Masaki Yamamoto", "title": "Derandomizing HSSW Algorithm for 3-SAT", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a (full) derandomization of HSSW algorithm for 3-SAT, proposed by\nHofmeister, Sch\\\"oning, Schuler, and Watanabe in [STACS'02]. Thereby, we obtain\nan O(1.3303^n)-time deterministic algorithm for 3-SAT, which is currently\nfastest.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 07:18:36 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Makino", "Kazuhisa", ""], ["Tamaki", "Suguru", ""], ["Yamamoto", "Masaki", ""]]}, {"id": "1102.3813", "submitter": "Takeaki Uno", "authors": "Keisuke Murakami and Takeaki Uno", "title": "Efficient Algorithms for Dualizing Large-Scale Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hypergraph ${\\cal F}$ is a set family defined on vertex set $V$. The dual\nof ${\\cal F}$ is the set of minimal subsets $H$ of $V$ such that $F\\cap H \\ne\n\\emptyset$ for any $F\\in {\\cal F}$. The computation of the dual is equivalent\nto many problems, such as minimal hitting set enumeration of a subset family,\nminimal set cover enumeration, and the enumeration of hypergraph transversals.\nAlthough many algorithms have been proposed for solving the problem, to the\nbest of our knowledge, none of them can work on large-scale input with a large\nnumber of output minimal hitting sets. This paper focuses on developing time-\nand space-efficient algorithms for solving the problem. We propose two new\nalgorithms with new search methods, new pruning methods, and fast techniques\nfor the minimality check. The computational experiments show that our\nalgorithms are quite fast even for large-scale input for which existing\nalgorithms do not terminate in a practical time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 11:51:28 GMT"}, {"version": "v2", "created": "Tue, 22 Feb 2011 12:43:56 GMT"}], "update_date": "2011-02-23", "authors_parsed": [["Murakami", "Keisuke", ""], ["Uno", "Takeaki", ""]]}, {"id": "1102.3930", "submitter": "Adam Lipowski", "authors": "Adam Lipowski and Dorota Lipowska", "title": "Diffusive behavior of a greedy traveling salesman", "comments": "accepted in Phys. Rev. E", "journal-ref": "Physical Review E 83, 061115 (2011)", "doi": "10.1103/PhysRevE.83.061115", "report-no": null, "categories": "cond-mat.stat-mech cs.DS physics.soc-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Monte Carlo simulations we examine the diffusive properties of the\ngreedy algorithm in the d-dimensional traveling salesman problem. Our results\nshow that for d=3 and 4 the average squared distance from the origin <r^2> is\nproportional to the number of steps t. In the d=2 case such a scaling is\nmodified with some logarithmic corrections, which might suggest that d=2 is the\ncritical dimension of the problem. The distribution of lengths also shows\nmarked differences between d=2 and d>2 versions. A simple strategy adopted by\nthe salesman might resemble strategies chosen by some foraging and hunting\nanimals, for which anomalous diffusive behavior has recently been reported and\ninterpreted in terms of Levy flights. Our results suggest that broad and\nLevy-like distributions in such systems might appear due to dimension-dependent\nproperties of a search space.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 22:20:53 GMT"}, {"version": "v2", "created": "Mon, 23 May 2011 16:36:40 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Lipowski", "Adam", ""], ["Lipowska", "Dorota", ""]]}, {"id": "1102.3975", "submitter": "Abhimanyu Das", "authors": "Abhimanyu Das and David Kempe", "title": "Submodular meets Spectral: Greedy Algorithms for Subset Selection,\n  Sparse Approximation and Dictionary Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of selecting a subset of k random variables from a large\nset, in order to obtain the best linear prediction of another variable of\ninterest. This problem can be viewed in the context of both feature selection\nand sparse approximation. We analyze the performance of widely used greedy\nheuristics, using insights from the maximization of submodular functions and\nspectral analysis. We introduce the submodularity ratio as a key quantity to\nhelp understand why greedy algorithms perform well even when the variables are\nhighly correlated. Using our techniques, we obtain the strongest known\napproximation guarantees for this problem, both in terms of the submodularity\nratio and the smallest k-sparse eigenvalue of the covariance matrix. We further\ndemonstrate the wide applicability of our techniques by analyzing greedy\nalgorithms for the dictionary selection problem, and significantly improve the\npreviously known guarantees. Our theoretical analysis is complemented by\nexperiments on real-world and synthetic data sets; the experiments show that\nthe submodularity ratio is a stronger predictor of the performance of greedy\nalgorithms than other spectral parameters.\n", "versions": [{"version": "v1", "created": "Sat, 19 Feb 2011 07:25:00 GMT"}, {"version": "v2", "created": "Fri, 25 Feb 2011 01:12:26 GMT"}], "update_date": "2011-02-28", "authors_parsed": [["Das", "Abhimanyu", ""], ["Kempe", "David", ""]]}, {"id": "1102.4005", "submitter": "Bhaskar DasGupta", "authors": "Piotr Berman and Bhaskar DasGupta", "title": "Approximating the Online Set Multicover Problems Via Randomized\n  Winnowing", "comments": "22 pages", "journal-ref": "Theoretical Computer Science, 393 (1-3), 54-71, 2008", "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the weighted online set k-multicover problem. In\nthis problem, we have a universe V of elements, a family S of subsets of V with\na positive real cost for every set in S and a \"coverage factor\" (positive\ninteger) k. A subset of elements are presented online in an arbitrary order.\nWhen each element, say i, is presented, we are also told the collection of all\n(at least k) sets and their costs to which i belongs and we need to select\nadditional sets from these sets containing i, if necessary, such that our\ncollection of selected sets contains at least k sets that contain the element\ni. The goal is to minimize the total cost of the selected sets (our algorithm\nand competitive ratio bounds can be extended to the case when a set can be\nselected at most a pre-specified number of times instead of just once; we do\nnot report these extensions for simplicity and also because they have no\nrelevance to the biological applications that motivated our work). In this\npaper, we describe a new randomized algorithm for the online multicover problem\nbased on a randomized version of the winnowing approach of Littlestone. This\nalgorithm generalizes and improves some earlier results by N. Alon, B.\nAwerbuch, Y. Azar, N. Buchbinder, and J. Naor. We also discuss lower bounds on\ncompetitive ratios for deterministic algorithms for general $k$.\n", "versions": [{"version": "v1", "created": "Sat, 19 Feb 2011 17:11:56 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Berman", "Piotr", ""], ["DasGupta", "Bhaskar", ""]]}, {"id": "1102.4016", "submitter": "Gunnar W. Klau", "authors": "Sandro Andreotti, Gunnar W. Klau, Knut Reinert", "title": "Antilope - A Lagrangian Relaxation Approach to the de novo Peptide\n  Sequencing Problem", "comments": null, "journal-ref": null, "doi": "10.1109/TCBB.2011.59", "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peptide sequencing from mass spectrometry data is a key step in proteome\nresearch. Especially de novo sequencing, the identification of a peptide from\nits spectrum alone, is still a challenge even for state-of-the-art algorithmic\napproaches. In this paper we present Antilope, a new fast and flexible approach\nbased on mathematical programming. It builds on the spectrum graph model and\nworks with a variety of scoring schemes. Antilope combines Lagrangian\nrelaxation for solving an integer linear programming formulation with an\nadaptation of Yen's k shortest paths algorithm. It shows a significant\nimprovement in running time compared to mixed integer optimization and performs\nat the same speed like other state-of-the-art tools. We also implemented a\ngeneric probabilistic scoring scheme that can be trained automatically for a\ndataset of annotated spectra and is independent of the mass spectrometer type.\nEvaluations on benchmark data show that Antilope is competitive to the popular\nstate-of-the-art programs PepNovo and NovoHMM both in terms of run time and\naccuracy. Furthermore, it offers increased flexibility in the number of\nconsidered ion types. Antilope will be freely available as part of the open\nsource proteomics library OpenMS.\n", "versions": [{"version": "v1", "created": "Sat, 19 Feb 2011 19:36:34 GMT"}], "update_date": "2011-03-29", "authors_parsed": [["Andreotti", "Sandro", ""], ["Klau", "Gunnar W.", ""], ["Reinert", "Knut", ""]]}, {"id": "1102.4129", "submitter": "Swapnoneel  Roy", "authors": "Swapnoneel Roy and Atri Rudra", "title": "An FPTAS for the Lead-Based Multiple Video Transmission LMVT Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lead-Based Multiple Video Transmission (LMVT) problem is motivated by\napplications in managing the quality of experience (QoE) of video streaming for\nmobile clients. In an earlier work, the LMVT problem has been shown to be\nNP-hard for a specific bit-to-lead conversion function $\\phi$. In this work, we\nshow the problem to be NP-hard even if the function $\\phi$ is linear. We then\ndesign a fully polynomial time approximation scheme (FPTAS) for the problem.\nThis problem is exactly equivalent to the Santa Clause Problem on which there\nhas been a lot of work done off-late.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 04:21:32 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 19:58:08 GMT"}, {"version": "v3", "created": "Wed, 5 Oct 2011 03:57:51 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Roy", "Swapnoneel", ""], ["Rudra", "Atri", ""]]}, {"id": "1102.4240", "submitter": "Vincent Gripon", "authors": "Vincent Gripon and Claude Berrou", "title": "Sparse neural networks with large learning diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coded recurrent neural networks with three levels of sparsity are introduced.\nThe first level is related to the size of messages, much smaller than the\nnumber of available neurons. The second one is provided by a particular coding\nrule, acting as a local constraint in the neural activity. The third one is a\ncharacteristic of the low final connection density of the network after the\nlearning phase. Though the proposed network is very simple since it is based on\nbinary neurons and binary connections, it is able to learn a large number of\nmessages and recall them, even in presence of strong erasures. The performance\nof the network is assessed as a classifier and as an associative memory.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 14:48:20 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Gripon", "Vincent", ""], ["Berrou", "Claude", ""]]}, {"id": "1102.4311", "submitter": "Ray Maleh", "authors": "Ray Maleh", "title": "Improved RIP Analysis of Orthogonal Matching Pursuit", "comments": "Submitted to ACHA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal Matching Pursuit (OMP) has long been considered a powerful\nheuristic for attacking compressive sensing problems; however, its theoretical\ndevelopment is, unfortunately, somewhat lacking. This paper presents an\nimproved Restricted Isometry Property (RIP) based performance guarantee for\nT-sparse signal reconstruction that asymptotically approaches the conjectured\nlower bound given in Davenport et al. We also further extend the\nstate-of-the-art by deriving reconstruction error bounds for the case of\ngeneral non-sparse signals subjected to measurement noise. We then generalize\nour results to the case of K-fold Orthogonal Matching Pursuit (KOMP). We finish\nby presenting an empirical analysis suggesting that OMP and KOMP outperform\nother compressive sensing algorithms in average case scenarios. This turns out\nto be quite surprising since RIP analysis (i.e. worst case scenario) suggests\nthat these matching pursuits should perform roughly T^0.5 times worse than\nconvex optimization, CoSAMP, and Iterative Thresholding.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 19:19:45 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Maleh", "Ray", ""]]}, {"id": "1102.4480", "submitter": "Yasuo Tabei", "authors": "Yasuo Tabei, Daisuke Okanohara, Shuichi Hirose, and Koji Tsuda", "title": "LGM: Mining Frequent Subgraphs from Linear Graphs", "comments": "This paper is going to be published in proceedings of 15th\n  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A linear graph is a graph whose vertices are totally ordered. Biological and\nlinguistic sequences with interactions among symbols are naturally represented\nas linear graphs. Examples include protein contact maps, RNA secondary\nstructures and predicate-argument structures. Our algorithm, linear graph miner\n(LGM), leverages the vertex order for efficient enumeration of frequent\nsubgraphs. Based on the reverse search principle, the pattern space is\nsystematically traversed without expensive duplication checking. Disconnected\nsubgraph patterns are particularly important in linear graphs due to their\nsequential nature. Unlike conventional graph mining algorithms detecting\nconnected patterns only, LGM can detect disconnected patterns as well. The\nutility and efficiency of LGM are demonstrated in experiments on protein\ncontact maps.\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 12:20:18 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 02:12:40 GMT"}, {"version": "v3", "created": "Sat, 5 Mar 2011 06:42:43 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Tabei", "Yasuo", ""], ["Okanohara", "Daisuke", ""], ["Hirose", "Shuichi", ""], ["Tsuda", "Koji", ""]]}, {"id": "1102.4498", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Digraph description of k-interchange technique for optimization over\n  permutations and adaptive algorithm system", "comments": "11 pages, 6 figures", "journal-ref": "Foundations of Computing and Decision Sciences 26(3) (2001)\n  225-235", "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes a general glance to the use of element exchange\ntechniques for optimization over permutations. A multi-level description of\nproblems is proposed which is a fundamental to understand nature and complexity\nof optimization problems over permutations (e.g., ordering, scheduling,\ntraveling salesman problem). The description is based on permutation\nneighborhoods of several kinds (e.g., by improvement of an objective function).\nOur proposed operational digraph and its kinds can be considered as a way to\nunderstand convexity and polynomial solvability for combinatorial optimization\nproblems over permutations. Issues of an analysis of problems and a design of\nhierarchical heuristics are discussed. The discussion leads to a multi-level\nadaptive algorithm system which analyzes an individual problem and\nselects/designs a solving strategy (trajectory).\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 13:27:40 GMT"}], "update_date": "2011-02-23", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1102.4523", "submitter": "Manoj Gupta", "authors": "Navin Goyal, Manoj Gupta", "title": "On Dynamic Optimality for Binary Search Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does there exist O(1)-competitive (self-adjusting) binary search tree (BST)\nalgorithms? This is a well-studied problem. A simple offline BST algorithm\nGreedyFuture was proposed independently by Lucas and Munro, and they\nconjectured it to be O(1)-competitive. Recently, Demaine et al. gave a\ngeometric view of the BST problem. This view allowed them to give an online\nalgorithm GreedyArb with the same cost as GreedyFuture. However, no\no(n)-competitive ratio was known for GreedyArb. In this paper we make progress\ntowards proving O(1)-competitive ratio for GreedyArb by showing that it is\nO(\\log n)-competitive.\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 14:47:19 GMT"}], "update_date": "2011-02-23", "authors_parsed": [["Goyal", "Navin", ""], ["Gupta", "Manoj", ""]]}, {"id": "1102.4842", "submitter": "Ioannis Koutis", "authors": "Ioannis Koutis and Gary Miller and Richard Peng", "title": "A nearly-mlogn time solver for SDD linear systems", "comments": "to appear in FOCS11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved algorithm for solving symmetrically diagonally\ndominant linear systems. On input of an $n\\times n$ symmetric diagonally\ndominant matrix $A$ with $m$ non-zero entries and a vector $b$ such that\n$A\\bar{x} = b$ for some (unknown) vector $\\bar{x}$, our algorithm computes a\nvector $x$ such that $||{x}-\\bar{x}||_A < \\epsilon ||\\bar{x}||_A $\n{$||\\cdot||_A$ denotes the A-norm} in time $${\\tilde O}(m\\log n \\log\n(1/\\epsilon)).$$\n  The solver utilizes in a standard way a `preconditioning' chain of\nprogressively sparser graphs. To claim the faster running time we make a\ntwo-fold improvement in the algorithm for constructing the chain. The new chain\nexploits previously unknown properties of the graph sparsification algorithm\ngiven in [Koutis,Miller,Peng, FOCS 2010], allowing for stronger preconditioning\nproperties. We also present an algorithm of independent interest that\nconstructs nearly-tight low-stretch spanning trees in time\n$\\tilde{O}(m\\log{n})$, a factor of $O(\\log{n})$ faster than the algorithm in\n[Abraham,Bartal,Neiman, FOCS 2008]. This speedup directly reflects on the\nconstruction time of the preconditioning chain.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 20:53:03 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2011 13:42:40 GMT"}, {"version": "v3", "created": "Thu, 14 Apr 2011 18:34:13 GMT"}, {"version": "v4", "created": "Fri, 19 Aug 2011 02:59:12 GMT"}], "update_date": "2011-08-22", "authors_parsed": [["Koutis", "Ioannis", ""], ["Miller", "Gary", ""], ["Peng", "Richard", ""]]}, {"id": "1102.4866", "submitter": "Shay Solomon", "authors": "Shay Solomon", "title": "The MST of Symmetric Disk Graphs (in Arbitrary Metrics) is Light", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an n-point metric M = (V,delta), and a transmission range assignment\nr: V \\rightarrow \\mathbb R^+ that maps each point v in V to the disk of radius\nr(v) around it. The {symmetric disk graph} (henceforth, SDG) that corresponds\nto M and r is the undirected graph over V whose edge set includes an edge (u,v)\nif both r(u) and r(v) are no smaller than delta(u,v). SDGs are often used to\nmodel wireless communication networks.\n  Abu-Affash, Aschner, Carmi and Katz (SWAT 2010, \\cite{AACK10}) showed that\nfor any {2-dimensional Euclidean} n-point metric M, the weight of the MST of\nevery {connected} SDG for M is O(log n) w(MST(M)), and that this bound is\ntight. However, the upper bound proof of \\cite{AACK10} relies heavily on basic\ngeometric properties of 2-dimensional Euclidean metrics, and does not extend to\nhigher dimensions. A natural question that arises is whether this surprising\nupper bound of \\cite{AACK10} can be generalized for wider families of metrics,\nsuch as 3-dimensional Euclidean metrics.\n  In this paper we generalize the upper bound of Abu-Affash et al.\n\\cite{AACK10} for Euclidean metrics of any dimension. Furthermore, our upper\nbound extends to {arbitrary metrics} and, in particular, it applies to any of\nthe normed spaces ell_p. Specifically, we demonstrate that for {any} n-point\nmetric M, the weight of the MST of every connected SDG for M is O(log n)\nw(MST(M)).\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 22:30:53 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Solomon", "Shay", ""]]}, {"id": "1102.4884", "submitter": "Kyle Fox", "authors": "Kyle Fox", "title": "Upper Bounds for Maximally Greedy Binary Search Trees", "comments": "To appear, WADS 2011. rev 1: Fixed accidental upload of out-of-date\n  Fig. 1; rev 2: Added figures and made updates based on reviewer comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At SODA 2009, Demaine et al. presented a novel connection between binary\nsearch trees (BSTs) and subsets of points on the plane. This connection was\nindependently discovered by Derryberry et al. As part of their results, Demaine\net al. considered GreedyFuture, an offline BST algorithm that greedily\nrearranges the search path to minimize the cost of future searches. They showed\nthat GreedyFuture is actually an online algorithm in their geometric view, and\nthat there is a way to turn GreedyFuture into an online BST algorithm with only\na constant factor increase in total search cost. Demaine et al. conjectured\nthis algorithm was dynamically optimal, but no upper bounds were given in their\npaper. We prove the first non-trivial upper bounds for the cost of search\noperations using GreedyFuture including giving an access lemma similar to that\nfound in Sleator and Tarjan's classic paper on splay trees.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 00:19:46 GMT"}, {"version": "v2", "created": "Fri, 25 Feb 2011 19:28:23 GMT"}, {"version": "v3", "created": "Fri, 29 Apr 2011 18:50:33 GMT"}], "update_date": "2011-05-02", "authors_parsed": [["Fox", "Kyle", ""]]}, {"id": "1102.4981", "submitter": "Maria Potop-Butucaru", "authors": "Taisuke Izumi, Maria Potop-Butucaru (LIP6, INRIA Rocquencourt),\n  Mathieu Valero (LIP6, INRIA Rocquencourt)", "title": "Physical expander in Virtual Tree Overlay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new construction of constantdegree expanders\nmotivated by their application in P2P overlay networks and in particular in the\ndesign of robust trees overlay. Our key result can be stated as follows.\nConsider a complete binary tree T and construct a random pairing {\\Pi} between\nleaf nodes and internal nodes. We prove that the graph G\\Pi obtained from T by\ncontracting all pairs (leaf-internal nodes) achieves a constant node expansion\nwith high probability. The use of our result in improving the robustness of\ntree overlays is straightforward. That is, if each physical node participating\nto the overlay manages a random pair that couples one virtual internal node and\none virtual leaf node then the physical-node layer exhibits a constant\nexpansion with high probability. We encompass the difficulty of obtaining this\nrandom tree virtualization by proposing a local, selforganizing and churn\nresilient uniformly-random pairing algorithm with O(log2 n) running time. Our\nalgorithm has the merit to not modify the original tree virtual overlay (we\njust control the mapping between physical nodes and virtual nodes). Therefore,\nour scheme is general and can be applied to a large number of tree overlay\nimplementations. We validate its performances in dynamic environments via\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 13:17:17 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Izumi", "Taisuke", "", "LIP6, INRIA Rocquencourt"], ["Potop-Butucaru", "Maria", "", "LIP6, INRIA Rocquencourt"], ["Valero", "Mathieu", "", "LIP6, INRIA Rocquencourt"]]}, {"id": "1102.5105", "submitter": "Marek Cygan", "authors": "Marek Cygan, Fabrizio Grandoni, Stefano Leonardi, Marcin Mucha, Marcin\n  Pilipczuk, Piotr Sankowski", "title": "Approximation Algorithms for Union and Intersection Covering Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a classical covering problem, we are given a set of requests that we need\nto satisfy (fully or partially), by buying a subset of items at minimum cost.\nFor example, in the k-MST problem we want to find the cheapest tree spanning at\nleast k nodes of an edge-weighted graph. Here nodes and edges represent\nrequests and items, respectively.\n  In this paper, we initiate the study of a new family of multi-layer covering\nproblems. Each such problem consists of a collection of h distinct instances of\na standard covering problem (layers), with the constraint that all layers share\nthe same set of requests. We identify two main subfamilies of these problems: -\nin a union multi-layer problem, a request is satisfied if it is satisfied in at\nleast one layer; - in an intersection multi-layer problem, a request is\nsatisfied if it is satisfied in all layers. To see some natural applications,\nconsider both generalizations of k-MST. Union k-MST can model a problem where\nwe are asked to connect a set of users to at least one of two communication\nnetworks, e.g., a wireless and a wired network. On the other hand, intersection\nk-MST can formalize the problem of connecting a subset of users to both\nelectricity and water.\n  We present a number of hardness and approximation results for union and\nintersection versions of several standard optimization problems: MST, Steiner\ntree, set cover, facility location, TSP, and their partial covering variants.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 21:33:20 GMT"}], "update_date": "2011-02-28", "authors_parsed": [["Cygan", "Marek", ""], ["Grandoni", "Fabrizio", ""], ["Leonardi", "Stefano", ""], ["Mucha", "Marcin", ""], ["Pilipczuk", "Marcin", ""], ["Sankowski", "Piotr", ""]]}, {"id": "1102.5146", "submitter": "Graham Cormode", "authors": "Edith Cohen, Graham Cormode, Nick Duffield", "title": "Structure-Aware Sampling: Flexible and Accurate Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In processing large quantities of data, a fundamental problem is to obtain a\nsummary which supports approximate query answering. Random sampling yields\nflexible summaries which naturally support subset-sum queries with unbiased\nestimators and well-understood confidence bounds.\n  Classic sample-based summaries, however, are designed for arbitrary subset\nqueries and are oblivious to the structure in the set of keys. The particular\nstructure, such as hierarchy, order, or product space (multi-dimensional),\nmakes range queries much more relevant for most analysis of the data.\n  Dedicated summarization algorithms for range-sum queries have also been\nextensively studied. They can outperform existing sampling schemes in terms of\naccuracy on range queries per summary size. Their accuracy, however, rapidly\ndegrades when, as is often the case, the query spans multiple ranges. They are\nalso less flexible - being targeted for range sum queries alone - and are often\nquite costly to build and use.\n  In this paper we propose and evaluate variance optimal sampling schemes that\nare structure-aware. These summaries improve over the accuracy of existing\nstructure-oblivious sampling schemes on range queries while retaining the\nbenefits of sample-based summaries: flexible summaries, with high accuracy on\nboth range queries and arbitrary subset queries.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 03:39:45 GMT"}], "update_date": "2011-02-28", "authors_parsed": [["Cohen", "Edith", ""], ["Cormode", "Graham", ""], ["Duffield", "Nick", ""]]}, {"id": "1102.5266", "submitter": "Michael Burr", "authors": "Michael Burr and Felix Krahmer", "title": "SqFreeEVAL: An (almost) optimal real-root isolation algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let f be a univariate polynomial with real coefficients, f in R[X].\nSubdivision algorithms based on algebraic techniques (e.g., Sturm or Descartes\nmethods) are widely used for isolating the real roots of f in a given interval.\nIn this paper, we consider a simple subdivision algorithm whose primitives are\npurely numerical (e.g., function evaluation). The complexity of this algorithm\nis adaptive because the algorithm makes decisions based on local data. The\ncomplexity analysis of adaptive algorithms (and this algorithm in particular)\nis a new challenge for computer science. In this paper, we compute the size of\nthe subdivision tree for the SqFreeEVAL algorithm.\n  The SqFreeEVAL algorithm is an evaluation-based numerical algorithm which is\nwell-known in several communities. The algorithm itself is simple, but prior\nattempts to compute its complexity have proven to be quite technical and have\nyielded sub-optimal results. Our main result is a simple O(d(L+ln d)) bound on\nthe size of the subdivision tree for the SqFreeEVAL algorithm on the benchmark\nproblem of isolating all real roots of an integer polynomial f of degree d and\nwhose coefficients can be written with at most L bits.\n  Our proof uses two amortization-based techniques: First, we use the algebraic\namortization technique of the standard Mahler-Davenport root bounds to\ninterpret the integral in terms of d and L. Second, we use a continuous\namortization technique based on an integral to bound the size of the\nsubdivision tree. This paper is the first to use the novel analysis technique\nof continuous amortization to derive state of the art complexity bounds.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 15:13:13 GMT"}], "update_date": "2011-02-28", "authors_parsed": [["Burr", "Michael", ""], ["Krahmer", "Felix", ""]]}, {"id": "1102.5309", "submitter": "Jeremy Hurwitz", "authors": "Jeremy Hurwitz", "title": "A Nearly-Quadratic Gap Between Adaptive and Non-Adaptive Property\n  Testers", "comments": "Keywords: Sublinear-Time Algorithms, Property Testing, Dense-Graph\n  Model, Adaptive vs Nonadaptive Queries, Hierarchy Theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for all integers $t\\geq 8$ and arbitrarily small $\\epsilon>0$,\nthere exists a graph property $\\Pi$ (which depends on $\\epsilon$) such that\n$\\epsilon$-testing $\\Pi$ has non-adaptive query complexity\n$Q=\\~{\\Theta}(q^{2-2/t})$, where $q=\\~{\\Theta}(\\epsilon^{-1})$ is the adaptive\nquery complexity. This resolves the question of how beneficial adaptivity is,\nin the context of proximity-dependent properties\n(\\cite{benefits-of-adaptivity}). This also gives evidence that the canonical\ntransformation of Goldreich and Trevisan (\\cite{canonical-testers}) is\nessentially optimal when converting an adaptive property tester to a\nnon-adaptive property tester.\n  To do so, we provide optimal adaptive and non-adaptive testers for the\ncombined property of having maximum degree $O(\\epsilon N)$ and being a\n\\emph{blow-up collection} of an arbitrary base graph $H$.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 18:54:33 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 23:51:50 GMT"}, {"version": "v3", "created": "Fri, 24 Jun 2011 18:46:54 GMT"}], "update_date": "2011-06-27", "authors_parsed": [["Hurwitz", "Jeremy", ""]]}, {"id": "1102.5425", "submitter": "Christoph Lenzen", "authors": "Christoph Lenzen and Roger Wattenhofer", "title": "Tight Bounds for Parallel Randomized Load Balancing", "comments": "39 pages, 2 figures. Extended abstract will be published at STOC'11", "journal-ref": null, "doi": null, "report-no": "TIK report number 324", "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the fundamental limits of distributed balls-into-bins algorithms.\nWe present an adaptive symmetric algorithm that achieves a bin load of two in\nlog* n+O(1) communication rounds using O(n) messages in total. Larger bin loads\ncan be traded in for smaller time complexities. We prove a matching lower bound\nof (1-o(1))log* n on the time complexity of symmetric algorithms that guarantee\nsmall bin loads at an asymptotically optimal message complexity of O(n). For\neach assumption of the lower bound, we provide an algorithm violating it, in\nturn achieving a constant maximum bin load in constant time.\n  As an application, we consider the following problem. Given a fully connected\ngraph of n nodes, where each node needs to send and receive up to n messages,\nand in each round each node may send one message over each link, deliver all\nmessages as quickly as possible to their destinations. We give a simple and\nrobust algorithm of time complexity O(log* n) for this task and provide a\ngeneralization to the case where all nodes initially hold arbitrary sets of\nmessages. A less practical algorithm terminates within asymptotically optimal\nO(1) rounds. All these bounds hold with high probability.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 15:45:45 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Lenzen", "Christoph", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1102.5433", "submitter": "Oliver Kullmann", "authors": "Tanbir Ahmed and Oliver Kullmann and Hunter Snevily", "title": "On the van der Waerden numbers w(2;3,t)", "comments": "Second version 25 pages, updates of numerical data, improved\n  formulations, and extended discussions on SAT. Third version 42 pages, with\n  SAT solver data (especially for new SAT solver) and improved representation.\n  Fourth version 47 pages, with updates and added explanations", "journal-ref": "Discrete Applied Mathematics 174: 27-51 (2014)", "doi": "10.1016/j.dam.2014.05.007", "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present results and conjectures on the van der Waerden numbers w(2;3,t)\nand on the new palindromic van der Waerden numbers pdw(2;3,t). We have computed\nthe new number w(2;3,19) = 349, and we provide lower bounds for 20 <= t <= 39,\nwhere for t <= 30 we conjecture these lower bounds to be exact. The lower\nbounds for 24 <= t <= 30 refute the conjecture that w(2;3,t) <= t^2, and we\npresent an improved conjecture. We also investigate regularities in the good\npartitions (certificates) to better understand the lower bounds.\n  Motivated by such reglarities, we introduce *palindromic van der Waerden\nnumbers* pdw(k; t_0,...,t_{k-1}), defined as ordinary van der Waerden numbers\nw(k; t_0,...,t_{k-1}), however only allowing palindromic solutions (good\npartitions), defined as reading the same from both ends. Different from the\nsituation for ordinary van der Waerden numbers, these \"numbers\" need actually\nto be pairs of numbers. We compute pdw(2;3,t) for 3 <= t <= 27, and we provide\nlower bounds, which we conjecture to be exact, for t <= 35.\n  All computations are based on SAT solving, and we discuss the various\nrelations between SAT solving and Ramsey theory. Especially we introduce a\nnovel (open-source) SAT solver, the tawSolver, which performs best on the SAT\ninstances studied here, and which is actually the original DLL-solver, but with\nan efficient implementation and a modern heuristic typical for look-ahead\nsolvers (applying the theory developed in the SAT handbook article of the\nsecond author).\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 18:30:11 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2011 16:44:59 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2013 21:23:19 GMT"}, {"version": "v4", "created": "Wed, 5 Mar 2014 23:53:26 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Ahmed", "Tanbir", ""], ["Kullmann", "Oliver", ""], ["Snevily", "Hunter", ""]]}, {"id": "1102.5438", "submitter": "Jaros{\\l}aw Grytczuk", "authors": "Jaros{\\l}aw Grytczuk, Jakub Kozik, Marcin Witkowski", "title": "Nonrepetitive sequences on arithmetic progressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequence $S=s_{1}s_{2}..._{n}$ is \\emph{nonrepetitive} if no two adjacent\nblocks of $S$ are identical. In 1906 Thue proved that there exist arbitrarily\nlong nonrepetitive sequences over 3-element set of symbols. We study a\ngeneralization of nonrepetitive sequences involving arithmetic progressions. We\nprove that for every $k\\geqslant 1$ and every $c\\geqslant 1$ there exist\narbitrarily long sequences over at most $(1+\\frac{1}{c})k+18k^{c/c+1}$ symbols\nwhose subsequences indexed by arithmetic progressions with common differences\nfrom the set $\\{1,2,...,k\\}$ are nonrepetitive. This improves a previous bound\nobtained in \\cite{Grytczuk Rainbow}. Our approach is based on a technique\nintroduced recently in \\cite{GrytczukKozikMicek}, which was originally inspired\nby a constructive proof of the Lov\\'{a}sz Local Lemma due to Moser and Tardos\n\\cite{MoserTardos}. We also discuss some related problems that can be\nsuccessfully attacked by this method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 19:16:17 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2011 11:23:39 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Grytczuk", "Jaros\u0142aw", ""], ["Kozik", "Jakub", ""], ["Witkowski", "Marcin", ""]]}, {"id": "1102.5441", "submitter": "Pim van 't Hof", "authors": "Pinar Heggernes, Pim van 't Hof, Daniel Lokshtanov, and Christophe\n  Paul", "title": "Obtaining a Bipartite Graph by Contracting Few Edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of the Bipartite Contraction problem from the\nperspective of parameterized complexity. In this problem we are given a graph\n$G$ and an integer $k$, and the task is to determine whether we can obtain a\nbipartite graph from $G$ by a sequence of at most $k$ edge contractions. Our\nmain result is an $f(k) n^{O(1)}$ time algorithm for Bipartite Contraction.\nDespite a strong resemblance between Bipartite Contraction and the classical\nOdd Cycle Transversal (OCT) problem, the methods developed to tackle OCT do not\nseem to be directly applicable to Bipartite Contraction. Our algorithm is based\non a novel combination of the irrelevant vertex technique, introduced by\nRobertson and Seymour, and the concept of important separators. Both techniques\nhave previously been used as key components of algorithms for fundamental\nproblems in parameterized complexity. However, to the best of our knowledge,\nthis is the first time the two techniques are applied in unison.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 20:07:27 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2011 19:49:20 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Heggernes", "Pinar", ""], ["Hof", "Pim van 't", ""], ["Lokshtanov", "Daniel", ""], ["Paul", "Christophe", ""]]}, {"id": "1102.5450", "submitter": "Viswanath Nagarajan", "authors": "Inge Li Goertz and Viswanath Nagarajan and R. Ravi", "title": "Minimum Makespan Multi-vehicle Dial-a-Ride", "comments": "22 pages, 1 figure. Preliminary version appeared in ESA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dial a ride problems consist of a metric space (denoting travel time between\nvertices) and a set of m objects represented as source-destination pairs, where\neach object requires to be moved from its source to destination vertex. We\nconsider the multi-vehicle Dial a ride problem, with each vehicle having\ncapacity k and its own depot-vertex, where the objective is to minimize the\nmaximum completion time (makespan) of the vehicles. We study the \"preemptive\"\nversion of the problem, where an object may be left at intermediate vertices\nand transported by more than one vehicle, while being moved from source to\ndestination. Our main results are an O(log^3 n)-approximation algorithm for\npreemptive multi-vehicle Dial a ride, and an improved O(log t)-approximation\nfor its special case when there is no capacity constraint. We also show that\nthe approximation ratios improve by a log-factor when the underlying metric is\ninduced by a fixed-minor-free graph.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 21:37:08 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Goertz", "Inge Li", ""], ["Nagarajan", "Viswanath", ""], ["Ravi", "R.", ""]]}, {"id": "1102.5463", "submitter": "Michael Burr", "authors": "Michael Burr and Sung Woo Choi and Ben Galehouse and Chee Yap", "title": "Complete Subdivision Algorithms, II: Isotopic Meshing of Singular\n  Algebraic Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a real valued function f(X,Y), a box region B_0 in R^2 and a positive\nepsilon, we want to compute an epsilon-isotopic polygonal approximation to the\nrestriction of the curve S=f^{-1}(0)={p in R^2: f(p)=0} to B_0. We focus on\nsubdivision algorithms because of their adaptive complexity and ease of\nimplementation. Plantinga and Vegter gave a numerical subdivision algorithm\nthat is exact when the curve S is bounded and non-singular. They used a\ncomputational model that relied only on function evaluation and interval\narithmetic. We generalize their algorithm to any bounded (but possibly\nnon-simply connected) region that does not contain singularities of S. With\nthis generalization as a subroutine, we provide a method to detect isolated\nalgebraic singularities and their branching degree. This appears to be the\nfirst complete purely numerical method to compute isotopic approximations of\nalgebraic curves with isolated singularities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 00:49:36 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Burr", "Michael", ""], ["Choi", "Sung Woo", ""], ["Galehouse", "Ben", ""], ["Yap", "Chee", ""]]}, {"id": "1102.5471", "submitter": "Bhaskar DasGupta", "authors": "Mary V. Ashley and Tanya Y. Berger-Wolf and Wanpracha Chaovalitwongse\n  and Bhaskar DasGupta and Ashfaq Khokhar and Saad Sheikh", "title": "An Implicit Cover Problem in Wild Population Study", "comments": "11 pages", "journal-ref": "Discrete Mathematics, Algorithms and Applications, 2 (2), 21-31,\n  2010", "doi": null, "report-no": null, "categories": "cs.CC cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an implicit combinatorial optimization problem, the constraints are not\nenumerated explicitly but rather stated implicitly through equations, other\nconstraints or auxiliary algorithms. An important subclass of such problems is\nthe implicit set cover (or, equivalently, hitting set) problem in which the\nsets are not given explicitly but rather defined implicitly For example, the\nwell-known minimum feedback arc set problem is such a problem. In this paper,\nwe consider such a cover problem that arises in the study of wild populations\nin biology in which the sets are defined implicitly via the Mendelian\nconstraints and prove approximability results for this problem.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 03:53:59 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Ashley", "Mary V.", ""], ["Berger-Wolf", "Tanya Y.", ""], ["Chaovalitwongse", "Wanpracha", ""], ["DasGupta", "Bhaskar", ""], ["Khokhar", "Ashfaq", ""], ["Sheikh", "Saad", ""]]}, {"id": "1102.5478", "submitter": "Arindam Pal", "authors": "Arindam Pal", "title": "Minimum multicuts and Steiner forests for Okamura-Seymour graphs", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding minimum multicuts for an undirected planar\ngraph, where all the terminal vertices are on the boundary of the outer face.\nThis is known as an Okamura-Seymour instance. We show that for such an\ninstance, the minimum multicut problem can be reduced to the minimum-cost\nSteiner forest problem on a suitably defined dual graph. The minimum-cost\nSteiner forest problem has a 2-approximation algorithm. Hence, the minimum\nmulticut problem has a 2-approximation algorithm for an Okamura-Seymour\ninstance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 06:55:32 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Pal", "Arindam", ""]]}, {"id": "1102.5511", "submitter": "Sean Lip", "authors": "Sean Z.W. Lip", "title": "A Fast Algorithm for the Discrete Core/Periphery Bipartitioning Problem", "comments": "7 pages, no figures. Submitted to Social Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods have been proposed in the literature to determine an optimal\npartitioning of the set of actors in a network into core and periphery subsets.\nHowever, these methods either work only for relatively small input sizes, or do\nnot guarantee an optimal answer. In this paper, we propose a new algorithm to\nsolve this problem. This algorithm is efficient and exact, allowing the optimal\npartitioning for networks of several thousand actors to be computed in under a\nsecond. We also show that the optimal core can be characterized as a set\ncontaining the actors with the highest degrees in the original network.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 14:40:20 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Lip", "Sean Z. W.", ""]]}, {"id": "1102.5538", "submitter": "Andrei Romashchenko", "authors": "Andrei Romashchenko", "title": "Pseudo-random graphs and bit probe schemes with one-sided error", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic bit-probe schemes for the membership problem. Given a\nset A of at most n elements from the universe of size m we organize such a\nstructure that queries of type \"Is x in A?\" can be answered very quickly.\nH.Buhrman, P.B.Miltersen, J.Radhakrishnan, and S.Venkatesh proposed a bit-probe\nscheme based on expanders. Their scheme needs space of $O(n\\log m)$ bits, and\nrequires to read only one randomly chosen bit from the memory to answer a\nquery. The answer is correct with high probability with two-sided errors. In\nthis paper we show that for the same problem there exists a bit-probe scheme\nwith one-sided error that needs space of $O(n\\log^2 m+\\poly(\\log m))$ bits. The\ndifference with the model of Buhrman, Miltersen, Radhakrishnan, and Venkatesh\nis that we consider a bit-probe scheme with an auxiliary word. This means that\nin our scheme the memory is split into two parts of different size: the main\nstorage of $O(n\\log^2 m)$ bits and a short word of $\\log^{O(1)}m$ bits that is\npre-computed once for the stored set A and `cached'. To answer a query \"Is x in\nA?\" we allow to read the whole cached word and only one bit from the main\nstorage. For some reasonable values of parameters our space bound is better\nthan what can be achieved by any scheme without cached data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 19:24:32 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 20:50:58 GMT"}, {"version": "v3", "created": "Thu, 3 Mar 2011 08:05:56 GMT"}, {"version": "v4", "created": "Thu, 15 Sep 2011 10:57:54 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Romashchenko", "Andrei", ""]]}, {"id": "1102.5540", "submitter": "Justin Thaler", "authors": "Michael Mitzenmacher, Thomas Steinke, Justin Thaler", "title": "Hierarchical Heavy Hitters with the Space Saving Algorithm", "comments": "22 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Heavy Hitters problem extends the notion of frequent items\nto data arranged in a hierarchy. This problem has applications to network\ntraffic monitoring, anomaly detection, and DDoS detection. We present a new\nstreaming approximation algorithm for computing Hierarchical Heavy Hitters that\nhas several advantages over previous algorithms. It improves on the worst-case\ntime and space bounds of earlier algorithms, is conceptually simple and\nsubstantially easier to implement, offers improved accuracy guarantees, is\neasily adopted to a distributed or parallel setting, and can be efficiently\nimplemented in commodity hardware such as ternary content addressable memory\n(TCAMs). We present experimental results showing that for parameters of primary\npractical interest, our two-dimensional algorithm is superior to existing\nalgorithms in terms of speed and accuracy, and competitive in terms of space,\nwhile our one-dimensional algorithm is also superior in terms of speed and\naccuracy for a more limited range of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 19:31:05 GMT"}, {"version": "v2", "created": "Tue, 9 Aug 2011 15:03:08 GMT"}], "update_date": "2011-08-10", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Steinke", "Thomas", ""], ["Thaler", "Justin", ""]]}]