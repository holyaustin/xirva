[{"id": "0902.0140", "submitter": "Kook Jin Ahn", "authors": "Kook Jin Ahn, Sudipto Guha", "title": "Graph Sparsification in the Semi-streaming Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing massive data sets has been one of the key motivations for studying\nstreaming algorithms. In recent years, there has been significant progress in\nanalysing distributions in a streaming setting, but the progress on graph\nproblems has been limited. A main reason for this has been the existence of\nlinear space lower bounds for even simple problems such as determining the\nconnectedness of a graph. However, in many new scenarios that arise from social\nand other interaction networks, the number of vertices is significantly less\nthan the number of edges. This has led to the formulation of the semi-streaming\nmodel where we assume that the space is (near) linear in the number of vertices\n(but not necessarily the edges), and the edges appear in an arbitrary (and\npossibly adversarial) order.\n  In this paper we focus on graph sparsification, which is one of the major\nbuilding blocks in a variety of graph algorithms. There has been a long history\nof (non-streaming) sampling algorithms that provide sparse graph approximations\nand it a natural question to ask if the sparsification can be achieved using a\nsmall space, and in addition using a single pass over the data? The question is\ninteresting from the standpoint of both theory and practice and we answer the\nquestion in the affirmative, by providing a one pass\n$\\tilde{O}(n/\\epsilon^{2})$ space algorithm that produces a sparsification that\napproximates each cut to a $(1+\\epsilon)$ factor. We also show that $\\Omega(n\n\\log \\frac1\\epsilon)$ space is necessary for a one pass streaming algorithm to\napproximate the min-cut, improving upon the $\\Omega(n)$ lower bound that arises\nfrom lower bounds for testing connectivity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2009 16:50:53 GMT"}, {"version": "v2", "created": "Tue, 5 May 2009 20:44:32 GMT"}], "update_date": "2009-05-05", "authors_parsed": [["Ahn", "Kook Jin", ""], ["Guha", "Sudipto", ""]]}, {"id": "0902.0353", "submitter": "Vahab Mirrokni", "authors": "Jon Lee, Vahab Mirrokni, Viswanath Nagarjan, Maxim Sviridenko", "title": "Non-monotone submodular maximization under matroid and knapsack\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function maximization is a central problem in combinatorial\noptimization, generalizing many important problems including Max Cut in\ndirected/undirected graphs and in hypergraphs, certain constraint satisfaction\nproblems, maximum entropy sampling, and maximum facility location problems.\nUnlike submodular minimization, submodular maximization is NP-hard. For the\nproblem of maximizing a non-monotone submodular function, Feige, Mirrokni, and\nVondr\\'ak recently developed a $2\\over 5$-approximation algorithm \\cite{FMV07},\nhowever, their algorithms do not handle side constraints.} In this paper, we\ngive the first constant-factor approximation algorithm for maximizing any\nnon-negative submodular function subject to multiple matroid or knapsack\nconstraints. We emphasize that our results are for {\\em non-monotone}\nsubmodular functions. In particular, for any constant $k$, we present a\n$({1\\over k+2+{1\\over k}+\\epsilon})$-approximation for the submodular\nmaximization problem under $k$ matroid constraints, and a $({1\\over\n5}-\\epsilon)$-approximation algorithm for this problem subject to $k$ knapsack\nconstraints ($\\epsilon>0$ is any constant). We improve the approximation\nguarantee of our algorithm to ${1\\over k+1+{1\\over k-1}+\\epsilon}$ for $k\\ge 2$\npartition matroid constraints. This idea also gives a $({1\\over\nk+\\epsilon})$-approximation for maximizing a {\\em monotone} submodular function\nsubject to $k\\ge 2$ partition matroids, which improves over the previously best\nknown guarantee of $\\frac{1}{k+1}$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2009 20:36:59 GMT"}], "update_date": "2009-02-03", "authors_parsed": [["Lee", "Jon", ""], ["Mirrokni", "Vahab", ""], ["Nagarjan", "Viswanath", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "0902.1038", "submitter": "Wadie Guizani", "authors": "J\\'er\\'emy Barbay (DCC), Gonzalo Navarro (DCC)", "title": "Compressed Representations of Permutations, and Applications", "comments": null, "journal-ref": "STACS 2009 (2009) 111-122", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore various techniques to compress a permutation $\\pi$ over n\nintegers, taking advantage of ordered subsequences in $\\pi$, while supporting\nits application $\\pi$(i) and the application of its inverse $\\pi^{-1}(i)$ in\nsmall time. Our compression schemes yield several interesting byproducts, in\nmany cases matching, improving or extending the best existing results on\napplications such as the encoding of a permutation in order to support iterated\napplications $\\pi^k(i)$ of it, of integer functions, and of inverted lists and\nsuffix arrays.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 09:48:32 GMT"}], "update_date": "2009-02-09", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", "", "DCC"], ["Navarro", "Gonzalo", "", "DCC"]]}, {"id": "0902.1043", "submitter": "Glencora Borradaile", "authors": "Glencora Borradaile, Erik D. Demaine (MIT), Siamak Tazari", "title": "Polynomial-Time Approximation Schemes for Subset-Connectivity Problems\n  in Bounded-Genus Graphs", "comments": "Updated version from the conference (STACS) version", "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 171-182", "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first polynomial-time approximation schemes (PTASes) for the\nfollowing subset-connectivity problems in edge-weighted graphs of bounded\ngenus: Steiner tree, low-connectivity survivable-network design, and subset\nTSP. The schemes run in O(n log n) time for graphs embedded on both orientable\nand non-orientable surfaces. This work generalizes the PTAS frameworks of\nBorradaile, Klein, and Mathieu from planar graphs to bounded-genus graphs: any\nfuture problems shown to admit the required structure theorem for planar graphs\nwill similarly extend to bounded-genus graphs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 09:53:53 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2011 20:00:50 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Borradaile", "Glencora", "", "MIT"], ["Demaine", "Erik D.", "", "MIT"], ["Tazari", "Siamak", ""]]}, {"id": "0902.1048", "submitter": "Wadie Guizani", "authors": "Fr\\'ed\\'erique Bassino (LIPN), Julien David (IGM), Cyril Nicaud (IGM)", "title": "On the Average Complexity of Moore's State Minimization Algorithm", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 123-134", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, for any arbitrary finite alphabet and for the uniform\ndistribution over deterministic and accessible automata with n states, the\naverage complexity of Moore's state minimization algorithm is in O(n log n).\nMoreover this bound is tight in the case of unary utomata.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 10:13:52 GMT"}], "update_date": "2009-02-09", "authors_parsed": [["Bassino", "Fr\u00e9d\u00e9rique", "", "LIPN"], ["David", "Julien", "", "IGM"], ["Nicaud", "Cyril", "", "IGM"]]}, {"id": "0902.1254", "submitter": "Wadie Guizani", "authors": "Mahdi Cheraghchi (EPFL), Amin Shokrollahi (EPFL)", "title": "Almost-Uniform Sampling of Points on High-Dimensional Algebraic\n  Varieties", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 277-288", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of uniform sampling of points on an algebraic\nvariety. Specifically, we develop a randomized algorithm that, given a small\nset of multivariate polynomials over a sufficiently large finite field,\nproduces a common zero of the polynomials almost uniformly at random. The\nstatistical distance between the output distribution of the algorithm and the\nuniform distribution on the set of common zeros is polynomially small in the\nfield size, and the running time of the algorithm is polynomial in the\ndescription of the polynomials and their degrees provided that the number of\nthe polynomials is a constant.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2009 17:56:02 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Cheraghchi", "Mahdi", "", "EPFL"], ["Shokrollahi", "Amin", "", "EPFL"]]}, {"id": "0902.1260", "submitter": "Wadie Guizani", "authors": "Ho-Leung Chan, Jeff Edmonds, Tak-Wah Lam, Lap-Kei Lee, Alberto\n  Marchetti-Spaccamela, Kirk Pruhs", "title": "Nonclairvoyant Speed Scaling for Flow and Energy", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 255-264", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online nonclairvoyant speed scaling to minimize total flow time plus\nenergy. We first consider the traditional model where the power function is P\n(s) = s\\^\\propto. We give a nonclairvoyant algorithm that is shown to be\nO(\\propto\\^3)-competitive. We then show an \\Omega(\\propto\\^(1/3-\\epsilon))\nlower bound on the competitive ratio of any nonclairvoyant algorithm. We also\nshow that there are power functions for which no nonclairvoyant algorithm can\nbe O(1)-competitive.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2009 18:02:32 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Chan", "Ho-Leung", ""], ["Edmonds", "Jeff", ""], ["Lam", "Tak-Wah", ""], ["Lee", "Lap-Kei", ""], ["Marchetti-Spaccamela", "Alberto", ""], ["Pruhs", "Kirk", ""]]}, {"id": "0902.1261", "submitter": "Wadie Guizani", "authors": "Victor Chepoi (LIF), M. Seston (LIF)", "title": "An Approximation Algorithm for l\\infty-Fitting Robinson Structures to\n  Distances", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 265-276", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a factor 16 approximation algorithm for the\nfollowing NP-hard distance fitting problem: given a finite set X and a distance\nd on X, find a Robinsonian distance dR on X minimizing the l\\infty-error ||d -\ndR||\\infty = maxx,y\\epsilonX {|d(x, y) - dR(x, y)|}. A distance dR on a finite\nset X is Robinsonian if its matrix can be symmetrically permuted so that its\nelements do not decrease when moving away from the main diagonal along any row\nor column. Robinsonian distances generalize ultrametrics, line distances and\noccur in the seriation problems and in classification.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2009 18:03:11 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Chepoi", "Victor", "", "LIF"], ["Seston", "M.", "", "LIF"]]}, {"id": "0902.1278", "submitter": "Salah A. Aly", "authors": "Salah A. Aly, Zhenning Kong, Emina Soljanin", "title": "Fountain Codes Based Distributed Storage Algorithms for Large-scale\n  Wireless Sensor Networks", "comments": "A method to estimate the total number of nodes in a graph is\n  presented in this 12 pages", "journal-ref": "Proc. IEEE/ACM IPSN 2008, pp 171-182", "doi": "10.1109/IPSN.2008.64", "report-no": null, "categories": "cs.IT cs.DS cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider large-scale sensor networks with n nodes, out of which k are in\npossession, (e.g., have sensed or collected in some other way) k information\npackets. In the scenarios in which network nodes are vulnerable because of, for\nexample, limited energy or a hostile environment, it is desirable to\ndisseminate the acquired information throughout the network so that each of the\nn nodes stores one (possibly coded) packet and the original k source packets\ncan be recovered later in a computationally simple way from any (1 + \\epsilon)k\nnodes for some small \\epsilon > 0.\n  We developed two distributed algorithms for solving this problem based on\nsimple random walks and Fountain codes. Unlike all previously developed\nschemes, our solution is truly distributed, that is, nodes do not know n, k or\nconnectivity in the network, except in their own neighborhoods, and they do not\nmaintain any routing tables. In the first algorithm, all the sensors have the\nknowledge of n and k. In the second algorithm, each sensor estimates these\nparameters through the random walk dissemination. We present analysis of the\ncommunication/transmission and encoding/decoding complexity of these two\nalgorithms, and provide extensive simulation results as well\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2009 07:49:20 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Aly", "Salah A.", ""], ["Kong", "Zhenning", ""], ["Soljanin", "Emina", ""]]}, {"id": "0902.1378", "submitter": "Pierre Fraigniaud", "authors": "Yuval Emek, Pierre Fraigniaud, Amos Korman, Adi Rosen", "title": "On the Additive Constant of the k-server Work Function Algorithm", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Work Function Algorithm for the k-server problem. We show\nthat if the Work Function Algorithm is c-competitive, then it is also strictly\n(2c)-competitive. As a consequence of [Koutsoupias and Papadimitriou, JACM\n1995] this also shows that the Work Function Algorithm is strictly\n(4k-2)-competitive.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2009 07:47:19 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Emek", "Yuval", ""], ["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""], ["Rosen", "Adi", ""]]}, {"id": "0902.1604", "submitter": "Wadie Guizani", "authors": "Eda Baykan (EPFL), Monika Henzinger (EPFL), Stefan F. Keller,\n  Sebastian De Castelberg, Markus Kinzler", "title": "A Comparison of Techniques for Sampling Web Pages", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 13-30", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the World Wide Web is growing rapidly, it is getting increasingly\nchallenging to gather representative information about it. Instead of crawling\nthe web exhaustively one has to resort to other techniques like sampling to\ndetermine the properties of the web. A uniform random sample of the web would\nbe useful to determine the percentage of web pages in a specific language, on a\ntopic or in a top level domain. Unfortunately, no approach has been shown to\nsample the web pages in an unbiased way. Three promising web sampling\nalgorithms are based on random walks. They each have been evaluated\nindividually, but making a comparison on different data sets is not possible.\nWe directly compare these algorithms in this paper. We performed three random\nwalks on the web under the same conditions and analyzed their outcomes in\ndetail. We discuss the strengths and the weaknesses of each algorithm and\npropose improvements based on experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 08:44:14 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Baykan", "Eda", "", "EPFL"], ["Henzinger", "Monika", "", "EPFL"], ["Keller", "Stefan F.", ""], ["De Castelberg", "Sebastian", ""], ["Kinzler", "Markus", ""]]}, {"id": "0902.1605", "submitter": "Wadie Guizani", "authors": "Nicole Schweikardt", "title": "Lower Bounds for Multi-Pass Processing of Multiple Data Streams", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 51-62", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a brief overview of computation models for data stream\nprocessing, and it introduces a new model for multi-pass processing of multiple\nstreams, the so-called mp2s-automata. Two algorithms for solving the set\ndisjointness problem wi th these automata are presented. The main technical\ncontribution of this paper is the proof of a lower bound on the size of memory\nand the number of heads that are required for solvin g the set disjointness\nproblem with mp2s-automata.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 08:46:27 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Schweikardt", "Nicole", ""]]}, {"id": "0902.1617", "submitter": "Ashish Goel", "authors": "Ashish Goel and Michael Kapralov and Sanjeev Khanna", "title": "Perfect Matchings in \\~O(n^{1.5}) Time in Regular Bipartite Graphs", "comments": "Added analysis of the Hopcroft-Karp algorithm on the subsampled graph", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the well-studied problem of finding a perfect matching in\n$d$-regular bipartite graphs with $2n$ vertices and $m = nd$ edges. While the\nbest-known algorithm for general bipartite graphs (due to Hopcroft and Karp)\ntakes $O(m \\sqrt{n})$ time, in regular bipartite graphs, a perfect matching is\nknown to be computable in $O(m)$ time. Very recently, the $O(m)$ bound was\nimproved to $O(\\min\\{m, \\frac{n^{2.5}\\ln n}{d}\\})$ expected time, an expression\nthat is bounded by $\\tilde{O}(n^{1.75})$. In this paper, we further improve\nthis result by giving an $O(\\min\\{m, \\frac{n^2\\ln^3 n}{d}\\})$ expected time\nalgorithm for finding a perfect matching in regular bipartite graphs; as a\nfunction of $n$ alone, the algorithm takes expected time $O((n\\ln n)^{1.5})$.\n  To obtain this result, we design and analyze a two-stage sampling scheme that\nreduces the problem of finding a perfect matching in a regular bipartite graph\nto the same problem on a subsampled bipartite graph with $O(n\\ln n)$ edges that\nhas a perfect matching with high probability. The matching is then recovered\nusing the Hopcroft-Karp algorithm. While the standard analysis of Hopcroft-Karp\ngives us an $\\tilde{O}(n^{1.5})$ running time, we present a tighter analysis\nfor our special case that results in the stronger $\\tilde{O}(\\min\\{m,\n\\frac{n^2}{d} \\})$ time mentioned earlier.\n  Our proof of correctness of this sampling scheme uses a new correspondence\ntheorem between cuts and Hall's theorem ``witnesses'' for a perfect matching in\na bipartite graph that we prove. We believe this theorem may be of independent\ninterest; as another example application, we show that a perfect matching in\nthe support of an $n \\times n$ doubly stochastic matrix with $m$ non-zero\nentries can be found in expected time $\\tilde{O}(m + n^{1.5})$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 09:45:27 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2009 01:57:21 GMT"}], "update_date": "2009-07-30", "authors_parsed": [["Goel", "Ashish", ""], ["Kapralov", "Michael", ""], ["Khanna", "Sanjeev", ""]]}, {"id": "0902.1661", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and Marcin Pilipczuk", "title": "Even Faster Exact Bandwidth", "comments": "Paper submitted to Transaction on Algorithms on 5th Nov 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with exact algorithms for Bandwidth, a long studied NP-hard problem.\nFor a long time nothing better than the trivial O*(n!) exhaustive search was\nknown. In 2000, Feige an Kilian came up with a O*(10^n)-time algorithm.\nRecently we presented algorithm that runs in O*(5^n) time and O*(2^n) space..\n  In this paper we present a major modification to our algorithm which makes it\nrun in O(4.83^n) time with the cost of O*(4^n) space complexity. This\nmodification allowed us to perform Measure & Conquer analysis for the time\ncomplexity which was not used for such types of problems before.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 14:51:57 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Cygan", "Marek", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "0902.1693", "submitter": "Christian Hoffmann", "authors": "Markus Bl\\\"aser, Christian Hoffmann", "title": "Fast Evaluation of Interlace Polynomials on Graphs of Bounded Treewidth", "comments": "v4: Minor error in Lemma 5.5 fixed, Section 6.6 added, minor\n  improvements. 44 pages, 14 figures", "journal-ref": "Algorithmica, 61(1):3-35, 2011", "doi": "10.1007/s00453-010-9439-4", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multivariate interlace polynomial introduced by Courcelle\n(2008), which generalizes several interlace polynomials defined by Arratia,\nBollobas, and Sorkin (2004) and by Aigner and van der Holst (2004). We present\nan algorithm to evaluate the multivariate interlace polynomial of a graph with\nn vertices given a tree decomposition of the graph of width k. The best\npreviously known result (Courcelle 2008) employs a general logical framework\nand leads to an algorithm with running time f(k)*n, where f(k) is doubly\nexponential in k. Analyzing the GF(2)-rank of adjacency matrices in the context\nof tree decompositions, we give a faster and more direct algorithm. Our\nalgorithm uses 2^{3k^2+O(k)}*n arithmetic operations and can be efficiently\nimplemented in parallel.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 16:41:35 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2009 12:21:47 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2009 11:53:59 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2010 09:19:49 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Hoffmann", "Christian", ""]]}, {"id": "0902.1700", "submitter": "Pierre Charbit", "authors": "Pierre Charbit, Fabien de Montgolfier, Mathieu Raffinot", "title": "Linear Time Split Decomposition Revisited", "comments": "18 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a family F of subsets of a ground set V, its orthogonal is defined to\nbe the family of subsets that do not overlap any element of F.\n  Using this tool we revisit the problem of designing a simple linear time\nalgorithm for undirected graph split (also known as 1-join) decomposition.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 17:16:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2009 12:34:36 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2010 16:22:02 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Charbit", "Pierre", ""], ["de Montgolfier", "Fabien", ""], ["Raffinot", "Mathieu", ""]]}, {"id": "0902.1735", "submitter": "Publications Loria", "authors": "Robert Els\\\"asser, Thomas Sauerwald", "title": "Cover Time and Broadcast Time", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 373-384", "doi": null, "report-no": null, "categories": "cs.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new technique for bounding the cover time of random walks by\nrelating it to the runtime of randomized broadcast. In particular, we strongly\nconfirm for dense graphs the intuition of Chandra et al. \\cite{CRRST97} that\n\"the cover time of the graph is an appropriate metric for the performance of\ncertain kinds of randomized broadcast algorithms\". In more detail, our results\nare as follows: For any graph $G=(V,E)$ of size $n$ and minimum degree\n$\\delta$, we have $\\mathcal{R}(G)= \\Oh(\\frac{|E|}{\\delta} \\cdot \\log n)$, where\n$\\mathcal{R}(G)$ denotes the quotient of the cover time and broadcast time.\nThis bound is tight for binary trees and tight up to logarithmic factors for\nmany graphs including hypercubes, expanders and lollipop graphs. For any\n$\\delta$-regular (or almost $\\delta$-regular) graph $G$ it holds that\n$\\mathcal{R}(G) = \\Omega(\\frac{\\delta^2}{n} \\cdot \\frac{1}{\\log n})$. Together\nwith our upper bound on $\\mathcal{R}(G)$, this lower bound strongly confirms\nthe intuition of Chandra et al. for graphs with minimum degree $\\Theta(n)$,\nsince then the cover time equals the broadcast time multiplied by $n$\n(neglecting logarithmic factors). Conversely, for any $\\delta$ we construct\nalmost $\\delta$-regular graphs that satisfy $\\mathcal{R}(G) = \\Oh(\\max\n\\{\\sqrt{n},\\delta \\} \\cdot \\log^2 n)$. Since any regular expander satisfies\n$\\mathcal{R}(G) = \\Theta(n)$, the strong relationship given above does not hold\nif $\\delta$ is polynomially smaller than $n$. Our bounds also demonstrate that\nthe relationship between cover time and broadcast time is much stronger than\nthe known relationships between any of them and the mixing time (or the closely\nrelated spectral gap).\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 20:32:11 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Els\u00e4sser", "Robert", ""], ["Sauerwald", "Thomas", ""]]}, {"id": "0902.1737", "submitter": "Publications Loria", "authors": "Gianni Franceschini, Roberto Grossi, S. Muthukrishnan", "title": "Optimal cache-aware suffix selection", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science - STACS 2009 (2009) 457-468", "doi": null, "report-no": null, "categories": "cs.DS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given string $S[1..N]$ and integer $k$, the {\\em suffix selection} problem is\nto determine the $k$th lexicographically smallest amongst the suffixes $S[i...\nN]$, $1 \\leq i \\leq N$. We study the suffix selection problem in the\ncache-aware model that captures two-level memory inherent in computing systems,\nfor a \\emph{cache} of limited size $M$ and block size $B$. The complexity of\ninterest is the number of block transfers. We present an optimal suffix\nselection algorithm in the cache-aware model, requiring $\\Thetah{N/B}$ block\ntransfers, for any string $S$ over an unbounded alphabet (where characters can\nonly be compared), under the common tall-cache assumption (i.e.\n$M=\\Omegah{B^{1+\\epsilon}}$, where $\\epsilon<1$). Our algorithm beats the\nbottleneck bound for permuting an input array to the desired output array,\nwhich holds for nearly any nontrivial problem in hierarchical memory models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2009 20:33:06 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Franceschini", "Gianni", ""], ["Grossi", "Roberto", ""], ["Muthukrishnan", "S.", ""]]}, {"id": "0902.1792", "submitter": "Shipra Agrawal", "authors": "Shipra Agrawal, Yichuan Ding, Amin Saberi, Yinyu Ye", "title": "Correlation Robust Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust model proposed by Scarf, 1958, for stochastic\noptimization when only the marginal probabilities of (binary) random variables\nare given, and the correlation between the random variables is unknown. In the\nrobust model, the objective is to minimize expected cost against worst possible\njoint distribution with those marginals. We introduce the concept of\ncorrelation gap to compare this model to the stochastic optimization model that\nignores correlations and minimizes expected cost under independent Bernoulli\ndistribution. We identify a class of functions, using concepts of summable cost\nsharing schemes from game theory, for which the correlation gap is well-bounded\nand the robust model can be approximated closely by the independent\ndistribution model. As a result, we derive efficient approximation factors for\nmany popular cost functions, like submodular functions, facility location, and\nSteiner tree. As a byproduct, our analysis also yields some new results in the\nareas of social welfare maximization and existence of Walrasian equilibria,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 01:51:42 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2009 23:58:09 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2009 05:54:01 GMT"}], "update_date": "2009-10-11", "authors_parsed": [["Agrawal", "Shipra", ""], ["Ding", "Yichuan", ""], ["Saberi", "Amin", ""], ["Ye", "Yinyu", ""]]}, {"id": "0902.1834", "submitter": "Sebastien Tixeuil", "authors": "St\\'ephane Devismes (VERIMAG - IMAG), Franck Petit (LIP, INRIA\n  Rh\\^one-Alpes / LIP Laboratoire de l'Informatique du Parall\\'elisme),\n  S\\'ebastien Tixeuil (LIP6)", "title": "Optimal Probabilistic Ring Exploration by Asynchronous Oblivious Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6838", "categories": "cs.DS cs.CC cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a team of $k$ identical, oblivious, asynchronous mobile robots\nthat are able to sense (\\emph{i.e.}, view) their environment, yet are unable to\ncommunicate, and evolve on a constrained path. Previous results in this weak\nscenario show that initial symmetry yields high lower bounds when problems are\nto be solved by \\emph{deterministic} robots. In this paper, we initiate\nresearch on probabilistic bounds and solutions in this context, and focus on\nthe \\emph{exploration} problem of anonymous unoriented rings of any size. It is\nknown that $\\Theta(\\log n)$ robots are necessary and sufficient to solve the\nproblem with $k$ deterministic robots, provided that $k$ and $n$ are coprime.\nBy contrast, we show that \\emph{four} identical probabilistic robots are\nnecessary and sufficient to solve the same problem, also removing the coprime\nconstraint. Our positive results are constructive.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 10:18:32 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Devismes", "St\u00e9phane", "", "VERIMAG - IMAG"], ["Petit", "Franck", "", "LIP, INRIA\n  Rh\u00f4ne-Alpes / LIP Laboratoire de l'Informatique du Parall\u00e9lisme"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0902.1868", "submitter": "Publications Loria", "authors": "Fabian Kuhn (CSAIL)", "title": "Local Multicoloring Algorithms: Computing a Nearly-Optimal TDMA Schedule\n  in Constant Time", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 613-624", "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The described multicoloring problem has direct applications in the context of\nwireless ad hoc and sensor networks. In order to coordinate the access to the\nshared wireless medium, the nodes of such a network need to employ some medium\naccess control (MAC) protocol. Typical MAC protocols control the access to the\nshared channel by time (TDMA), frequency (FDMA), or code division multiple\naccess (CDMA) schemes. Many channel access schemes assign a fixed set of time\nslots, frequencies, or (orthogonal) codes to the nodes of a network such that\nnodes that interfere with each other receive disjoint sets of time slots,\nfrequencies, or code sets. Finding a valid assignment of time slots,\nfrequencies, or codes hence directly corresponds to computing a multicoloring\nof a graph $G$. The scarcity of bandwidth, energy, and computing resources in\nad hoc and sensor networks, as well as the often highly dynamic nature of these\nnetworks require that the multicoloring can be computed based on as little and\nas local information as possible.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 12:42:21 GMT"}], "update_date": "2009-02-12", "authors_parsed": [["Kuhn", "Fabian", "", "CSAIL"]]}, {"id": "0902.1871", "submitter": "Kaninda Musumbu", "authors": "Kaninda Musumbu (LaBRI)", "title": "Abstraction and Refinement in Static Model-Checking", "comments": null, "journal-ref": "IEEE-Computer Society International Conference on Computer Science\n  and Information Technology, ICCSIT-2008 (2008) 107 - 112", "doi": null, "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  interpretation is a general methodology for building static analyses of\nprograms. It was introduced by P. and R. Cousot in \\cite{cc}. We present, in\nthis paper, an application of a generic abstract interpretation to domain of\nmodel-checking. Dynamic checking are usually easier to use, because the concept\nare establishe d and wide well know. But they are usually limited to systems\nwhose states space is finite. In an other part, certain faults cannot be\ndetected dynamically, even by keeping track of the history of the states\nspace.Indeed, the classical problem of finding the right test cases is far from\ntrivial and limit the abilities of dynamic checkers further. Static checking\nhave the advantage that they work on a more abstract level than dynamic checker\nand can verify system properties for all inputs. Problem, it is hard to\nguarantee that a violation of a modeled property corresponds to a fault in the\nconcrete system. We propose an approach, in which we generate counter-examples\ndynamically using the abstract interpretation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2009 12:46:17 GMT"}], "update_date": "2009-02-12", "authors_parsed": [["Musumbu", "Kaninda", "", "LaBRI"]]}, {"id": "0902.2149", "submitter": "Publications Loria", "authors": "Michael R. Fellows, Jiong Guo, Hannes Moser, Rolf Niedermeier", "title": "A Generalization of Nemhauser and Trotter's Local Optimization Theorem", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 409-420", "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nemhauser-Trotter local optimization theorem applies to the NP-hard\nVertex Cover problem and has applications in approximation as well as\nparameterized algorithmics. We present a framework that generalizes Nemhauser\nand Trotter's result to vertex deletion and graph packing problems, introducing\nnovel algorithmic strategies based on purely combinatorial arguments (not\nreferring to linear programming as the Nemhauser-Trotter result originally\ndid). We exhibit our framework using a generalization of Vertex Cover, called\nBounded- Degree Deletion, that has promise to become an important tool in the\nanalysis of gene and other biological networks. For some fixed d \\geq 0,\nBounded-Degree Deletion asks to delete as few vertices as possible from a graph\nin order to transform it into a graph with maximum vertex degree at most d.\nVertex Cover is the special case of d = 0. Our generalization of the\nNemhauser-Trotter theorem implies that Bounded-Degree Deletion has a problem\nkernel with a linear number of vertices for every constant d. We also outline\nan application of our extremal combinatorial approach to the problem of packing\nstars with a bounded number of leaves. Finally, charting the border between\n(parameterized) tractability and intractability for Bounded-Degree Deletion, we\nprovide a W[2]-hardness result for Bounded-Degree Deletion in case of unbounded\nd-values.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 16:22:54 GMT"}], "update_date": "2009-02-13", "authors_parsed": [["Fellows", "Michael R.", ""], ["Guo", "Jiong", ""], ["Moser", "Hannes", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "0902.2150", "submitter": "Publications Loria", "authors": "Babak Farzad, Lap Chi Lau, Van Bang Le, Nguyen Ngoc Tuy", "title": "Computing Graph Roots Without Short Cycles", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 397-408", "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph G is the square of graph H if two vertices x, y have an edge in G if\nand only if x, y are of distance at most two in H. Given H it is easy to\ncompute its square H2, however Motwani and Sudan proved that it is NP-complete\nto determine if a given graph G is the square of some graph H (of girth 3). In\nthis paper we consider the characterization and recognition problems of graphs\nthat are squares of graphs of small girth, i.e. to determine if G = H2 for some\ngraph H of small girth. The main results are the following. - There is a graph\ntheoretical characterization for graphs that are squares of some graph of girth\nat least 7. A corollary is that if a graph G has a square root H of girth at\nleast 7 then H is unique up to isomorphism. - There is a polynomial time\nalgorithm to recognize if G = H2 for some graph H of girth at least 6. - It is\nNP-complete to recognize if G = H2 for some graph H of girth 4. These results\nalmost provide a dichotomy theorem for the complexity of the recognition\nproblem in terms of girth of the square roots. The algorithmic and graph\ntheoretical results generalize previous results on tree square roots, and\nprovide polynomial time algorithms to compute a graph square root of small\ngirth if it exists. Some open questions and conjectures will also be discussed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 16:20:33 GMT"}], "update_date": "2009-02-13", "authors_parsed": [["Farzad", "Babak", ""], ["Lau", "Lap Chi", ""], ["Le", "Van Bang", ""], ["Tuy", "Nguyen Ngoc", ""]]}, {"id": "0902.2209", "submitter": "Christoph Durr", "authors": "Christoph Durr, Lukasz Jez and Nguyen Kim Thang", "title": "Online Scheduling of Bounded Length Jobs to Maximize Throughput", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online scheduling problem, motivated by the issues present at\nthe joints of networks using ATM and TCP/IP. Namely, IP packets have to broken\ndown to small ATM cells and sent out before their deadlines, but cells\ncorresponding to different packets can be interwoven. More formally, we\nconsider the online scheduling problem with preemptions, where each job j is\nrevealed at release time r_j, has processing time p_j, deadline d_j and weight\nw_j. A preempted job can be resumed at any time. The goal is to maximize the\ntotal weight of all jobs completed on time. Our main result are as follows: we\nprove that if all jobs have processing time exactly k, the deterministic\ncompetitive ratio is between 2.598 and 5, and when the processing times are at\nmost k, the deterministic competitive ratio is Theta(k/log k).\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 21:24:57 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2009 22:42:34 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2009 06:56:50 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Durr", "Christoph", ""], ["Jez", "Lukasz", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "0902.2399", "submitter": "Amit Chakrabarti", "authors": "Joshua Brody and Amit Chakrabarti", "title": "A Multi-Round Communication Lower Bound for Gap Hamming and Some\n  Consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gap-Hamming-Distance problem arose in the context of proving space lower\nbounds for a number of key problems in the data stream model. In this problem,\nAlice and Bob have to decide whether the Hamming distance between their $n$-bit\ninput strings is large (i.e., at least $n/2 + \\sqrt n$) or small (i.e., at most\n$n/2 - \\sqrt n$); they do not care if it is neither large nor small. This\n$\\Theta(\\sqrt n)$ gap in the problem specification is crucial for capturing the\napproximation allowed to a data stream algorithm.\n  Thus far, for randomized communication, an $\\Omega(n)$ lower bound on this\nproblem was known only in the one-way setting. We prove an $\\Omega(n)$ lower\nbound for randomized protocols that use any constant number of rounds.\n  As a consequence we conclude, for instance, that $\\epsilon$-approximately\ncounting the number of distinct elements in a data stream requires\n$\\Omega(1/\\epsilon^2)$ space, even with multiple (a constant number of) passes\nover the input stream. This extends earlier one-pass lower bounds, answering a\nlong-standing open question. We obtain similar results for approximating the\nfrequency moments and for approximating the empirical entropy of a data stream.\n  In the process, we also obtain tight $n - \\Theta(\\sqrt{n}\\log n)$ lower and\nupper bounds on the one-way deterministic communication complexity of the\nproblem. Finally, we give a simple combinatorial proof of an $\\Omega(n)$ lower\nbound on the one-way randomized communication complexity.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2009 21:42:52 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2009 13:52:13 GMT"}], "update_date": "2009-02-17", "authors_parsed": [["Brody", "Joshua", ""], ["Chakrabarti", "Amit", ""]]}, {"id": "0902.2501", "submitter": "Amitabh Trehan", "authors": "Tom Hayes and Jared Saia and Amitabh Trehan", "title": "The Forgiving Graph: A distributed data structure for low stretch under\n  adversarial attack", "comments": "Submitted to Principles of Distributed Computing (PODC) 2009", "journal-ref": "Distributed Computing, 2012, Volume 25, Number 4, Pages 261-278", "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of self-healing in peer-to-peer networks that are\nunder repeated attack by an omniscient adversary. We assume that, over a\nsequence of rounds, an adversary either inserts a node with arbitrary\nconnections or deletes an arbitrary node from the network. The network responds\nto each such change by quick \"repairs,\" which consist of adding or deleting a\nsmall number of edges.\n  These repairs essentially preserve closeness of nodes after adversarial\ndeletions, without increasing node degrees by too much, in the following sense.\nAt any point in the algorithm, nodes $v$ and $w$ whose distance would have been\n$\\ell$ in the graph formed by considering only the adversarial insertions (not\nthe adversarial deletions), will be at distance at most $\\ell \\log n$ in the\nactual graph, where $n$ is the total number of vertices seen so far. Similarly,\nat any point, a node $v$ whose degree would have been $d$ in the graph with\nadversarial insertions only, will have degree at most 3d in the actual graph.\nOur algorithm is completely distributed and has low latency and bandwidth\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2009 22:35:35 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Hayes", "Tom", ""], ["Saia", "Jared", ""], ["Trehan", "Amitabh", ""]]}, {"id": "0902.2537", "submitter": "Oded Schwartz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Oded Schwartz", "title": "Communication-optimal Parallel and Sequential Cholesky Decomposition", "comments": "29 pages, 2 tables, 6 figures", "journal-ref": "SIAM J. Sci. Comput. 32, (2010) pp. 3495-3523", "doi": "10.1137/090760969", "report-no": null, "categories": "cs.NA cs.CC cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical algorithms have two kinds of costs: arithmetic and communication,\nby which we mean either moving data between levels of a memory hierarchy (in\nthe sequential case) or over a network connecting processors (in the parallel\ncase). Communication costs often dominate arithmetic costs, so it is of\ninterest to design algorithms minimizing communication. In this paper we first\nextend known lower bounds on the communication cost (both for bandwidth and for\nlatency) of conventional (O(n^3)) matrix multiplication to Cholesky\nfactorization, which is used for solving dense symmetric positive definite\nlinear systems. Second, we compare the costs of various Cholesky decomposition\nimplementations to these lower bounds and identify the algorithms and data\nstructures that attain them. In the sequential case, we consider both the\ntwo-level and hierarchical memory models. Combined with prior results in [13,\n14, 15], this gives a set of communication-optimal algorithms for O(n^3)\nimplementations of the three basic factorizations of dense linear algebra: LU\nwith pivoting, QR and Cholesky. But it goes beyond this prior work on\nsequential LU by optimizing communication for any number of levels of memory\nhierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2009 11:41:55 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2009 12:50:08 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2010 16:59:02 GMT"}], "update_date": "2011-02-02", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Schwartz", "Oded", ""]]}, {"id": "0902.2648", "submitter": "Publications Loria", "authors": "Roberto Grossi, Alessio Orlandi, Rajeev Raman, S. Srinivasa Rao", "title": "More Haste, Less Waste: Lowering the Redundancy in Fully Indexable\n  Dictionaries", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science STACS 2009 (2009) 517-528", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of representing, in a compressed format, a bit-vector\n$S$ of $m$ bits with $n$ 1s, supporting the following operations, where $b \\in\n\\{0, 1 \\}$: $rank_b(S,i)$ returns the number of occurrences of bit $b$ in the\nprefix $S[1..i]$; $select_b(S,i)$ returns the position of the $i$th occurrence\nof bit $b$ in $S$. Such a data structure is called \\emph{fully indexable\ndictionary (FID)} [Raman et al.,2007], and is at least as powerful as\npredecessor data structures. Our focus is on space-efficient FIDs on the\n\\textsc{ram} model with word size $\\Theta(\\lg m)$ and constant time for all\noperations, so that the time cost is independent of the input size. Given the\nbitstring $S$ to be encoded, having length $m$ and containing $n$ ones, the\nminimal amount of information that needs to be stored is $B(n,m) = \\lceil \\log\n{{m}\\choose{n}} \\rceil$. The state of the art in building a FID for $S$ is\ngiven in [Patrascu,2008] using $B(m,n)+O(m / ((\\log m/ t) ^t)) + O(m^{3/4}) $\nbits, to support the operations in $O(t)$ time. Here, we propose a parametric\ndata structure exhibiting a time/space trade-off such that, for any real\nconstants $0 < \\delta \\leq 1/2$, $0 < \\eps \\leq 1$, and integer $s > 0$, it\nuses \\[ B(n,m) + O(n^{1+\\delta} + n (\\frac{m}{n^s})^\\eps) \\] bits and performs\nall the operations in time $O(s\\delta^{-1} + \\eps^{-1})$. The improvement is\ntwofold: our redundancy can be lowered parametrically and, fixing $s = O(1)$,\nwe get a constant-time FID whose space is $B(n,m) + O(m^\\eps/\\poly{n})$ bits,\nfor sufficiently large $m$. This is a significant improvement compared to the\nprevious bounds for the general case.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2009 10:14:08 GMT"}], "update_date": "2009-02-17", "authors_parsed": [["Grossi", "Roberto", ""], ["Orlandi", "Alessio", ""], ["Raman", "Rajeev", ""], ["Rao", "S. Srinivasa", ""]]}, {"id": "0902.2649", "submitter": "Publications Loria", "authors": "Danny Hermelin, Gad M. Landau, Shir Landau, Oren Weimann (CSAIL)", "title": "A Unified Algorithm for Accelerating Edit-Distance Computation via\n  Text-Compression", "comments": null, "journal-ref": "26th International Symposium on Theoretical Aspects of Computer\n  Science - STACS 2009 (2009) 529-540", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for accelerating edit-distance computation\nbetween two compressible strings using straight-line programs. For two strings\nof total length $N$ having straight-line program representations of total size\n$n$, we provide an algorithm running in $O(n^{1.4}N^{1.2})$ time for computing\nthe edit-distance of these two strings under any rational scoring function, and\nan $O(n^{1.34}N^{1.34})$ time algorithm for arbitrary scoring functions. This\nimproves on a recent algorithm of Tiskin that runs in $O(nN^{1.5})$ time, and\nworks only for rational scoring functions. Also, in the last part of the paper,\nwe show how the classical four-russians technique can be incorporated into our\nSLP edit-distance scheme, giving us a simple $\\Omega(\\lg N)$ speed-up in the\ncase of arbitrary scoring functions, for any pair of strings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2009 10:14:51 GMT"}], "update_date": "2009-02-17", "authors_parsed": [["Hermelin", "Danny", "", "CSAIL"], ["Landau", "Gad M.", "", "CSAIL"], ["Landau", "Shir", "", "CSAIL"], ["Weimann", "Oren", "", "CSAIL"]]}, {"id": "0902.2795", "submitter": "Nitish Korula", "authors": "Chandra Chekuri and Nitish Korula", "title": "A Graph Reduction Step Preserving Element-Connectivity and Applications", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph G=(V,E) and subset of terminals T \\subseteq V, the\nelement-connectivity of two terminals u,v \\in T is the maximum number of u-v\npaths that are pairwise disjoint in both edges and non-terminals V \\setminus T\n(the paths need not be disjoint in terminals). Element-connectivity is more\ngeneral than edge-connectivity and less general than vertex-connectivity. Hind\nand Oellermann gave a graph reduction step that preserves the global\nelement-connectivity of the graph. We show that this step also preserves local\nconnectivity, that is, all the pairwise element-connectivities of the\nterminals. We give two applications of this reduction step to connectivity and\nnetwork design problems:\n  1. Given a graph G and disjoint terminal sets T_1, T_2, ..., T_m, we seek a\nmaximum number of element-disjoint Steiner forests where each forest connects\neach T_i. We prove that if each T_i is k-element-connected then there exist\n\\Omega(\\frac{k}{\\log h \\log m}) element-disjoint Steiner forests, where h =\n|\\bigcup_i T_i|. If G is planar (or more generally, has fixed genus), we show\nthat there exist \\Omega(k) Steiner forests. Our proofs are constructive, giving\npoly-time algorithms to find these forests; these are the first non-trivial\nalgorithms for packing element-disjoint Steiner Forests.\n  2. We give a very short and intuitive proof of a spider-decomposition theorem\nof Chuzhoy and Khanna in the context of the single-sink k-vertex-connectivity\nproblem; this yields a simple and alternative analysis of an O(k \\log n)\napproximation.\n  Our results highlight the effectiveness of the element-connectivity reduction\nstep; we believe it will find more applications in the future.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2009 21:29:26 GMT"}], "update_date": "2009-02-18", "authors_parsed": [["Chekuri", "Chandra", ""], ["Korula", "Nitish", ""]]}, {"id": "0902.3081", "submitter": "Pierre Fraigniaud", "authors": "Pierre Fraigniaud and Amos Korman", "title": "Compact Ancestry Labeling Schemes for Trees of Small Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An {\\em ancestry labeling scheme} labels the nodes of any tree in such a way\nthat ancestry queries between any two nodes in a tree can be answered just by\nlooking at their corresponding labels. The common measure to evaluate the\nquality of an ancestry labeling scheme is by its {\\em label size}, that is the\nmaximal number of bits stored in a label, taken over all $n$-node trees. The\ndesign of ancestry labeling schemes finds applications in XML search engines.\nIn the context of these applications, even small improvements in the label size\nare important. In fact, the literature about this topic is interested in the\nexact label size rather than just its order of magnitude. As a result,\nfollowing the proposal of an original scheme of size $2\\log n$ bits, a\nconsiderable amount of work was devoted to improve the bound on the label size.\nThe current state of the art upper bound is $\\log n + O(\\sqrt{\\log n})$ bits\nwhich is still far from the known $\\log n + \\Omega(\\log\\log n)$ lower bound.\nMoreover, the hidden constant factor in the additive $O(\\sqrt{\\log n})$ term is\nlarge, which makes this term dominate the label size for typical current XML\ntrees.\n  In attempt to provide good performances for real XML data, we rely on the\nobservation that the depth of a typical XML tree is bounded from above by a\nsmall constant. Having this in mind, we present an ancestry labeling scheme of\nsize $\\log n+2\\log d +O(1)$, for the family of trees with at most $n$ nodes and\ndepth at most $d$. In addition to our main result, we prove a result that may\nbe of independent interest concerning the existence of a linear {\\em universal\ngraph} for the family of forests with trees of bounded depth.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 09:49:42 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""]]}, {"id": "0902.3121", "submitter": "Christian Artigues", "authors": "Bernat Gacias (LAAS), Christian Artigues (LAAS), Pierre Lopez (LAAS)", "title": "Parallel machine scheduling with precedence constraints and setup times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents different methods for solving parallel machine scheduling\nproblems with precedence constraints and setup times between the jobs. Limited\ndiscrepancy search methods mixed with local search principles, dominance\nconditions and specific lower bounds are proposed. The proposed methods are\nevaluated on a set of randomly generated instances and compared with previous\nresults from the literature and those obtained with an efficient commercial\nsolver. We conclude that our propositions are quite competitive and our results\neven outperform other approaches in most cases.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 14:00:16 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Gacias", "Bernat", "", "LAAS"], ["Artigues", "Christian", "", "LAAS"], ["Lopez", "Pierre", "", "LAAS"]]}, {"id": "0902.3208", "submitter": "Ilya Safro", "authors": "Dorit Ron, Ilya Safro, Achi Brandt", "title": "A Fast Multigrid Algorithm for Energy Minimization Under Planar Density\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-dimensional layout optimization problem reinforced by the efficient\nspace utilization demand has a wide spectrum of practical applications.\nFormulating the problem as a nonlinear minimization problem under planar\nequality and/or inequality density constraints, we present a linear time\nmultigrid algorithm for solving correction to this problem. The method is\ndemonstrated on various graph drawing (visualization) instances.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 17:59:47 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Ron", "Dorit", ""], ["Safro", "Ilya", ""], ["Brandt", "Achi", ""]]}, {"id": "0902.3223", "submitter": "Jose Brito", "authors": "Jose Brito, Mauricio Lila, Flavio Montenegro, Nelson Maculan", "title": "An Exact Algorithm for the Stratification Problem with Proportional\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a new optimal resolution for the statistical stratification problem\nunder proportional sampling allocation among strata. Consider a finite\npopulation of N units, a random sample of n units selected from this population\nand a number L of strata. Thus, we have to define which units belong to each\nstratum so as to minimize the variance of a total estimator for one desired\nvariable of interest in each stratum,and consequently reduce the overall\nvariance for such quantity. In order to solve this problem, an exact algorithm\nbased on the concept of minimal path in a graph is proposed and assessed.\nComputational results using real data from IBGE (Brazilian Central Statistical\nOffice) are provided.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 19:12:59 GMT"}], "update_date": "2009-02-24", "authors_parsed": [["Brito", "Jose", ""], ["Lila", "Mauricio", ""], ["Montenegro", "Flavio", ""], ["Maculan", "Nelson", ""]]}, {"id": "0902.3485", "submitter": "Aneesh Sharma", "authors": "David Arthur, Rajeev Motwani, Aneesh Sharma, Ying Xu", "title": "Pricing strategies for viral marketing on Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study the use of viral marketing strategies on social networks to maximize\nrevenue from the sale of a single product. We propose a model in which the\ndecision of a buyer to buy the product is influenced by friends that own the\nproduct and the price at which the product is offered. The influence model we\nanalyze is quite general, naturally extending both the Linear Threshold model\nand the Independent Cascade model, while also incorporating price information.\nWe consider sales proceeding in a cascading manner through the network, i.e. a\nbuyer is offered the product via recommendations from its neighbors who own the\nproduct. In this setting, the seller influences events by offering a cashback\nto recommenders and by setting prices (via coupons or discounts) for each buyer\nin the social network.\n  Finding a seller strategy which maximizes the expected revenue in this\nsetting turns out to be NP-hard. However, we propose a seller strategy that\ngenerates revenue guaranteed to be within a constant factor of the optimal\nstrategy in a wide variety of models. The strategy is based on an\ninfluence-and-exploit idea, and it consists of finding the right trade-off at\neach time step between: generating revenue from the current user versus\noffering the product for free and using the influence generated from this sale\nlater in the process. We also show how local search can be used to improve the\nperformance of this technique in practice.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 00:06:42 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Arthur", "David", ""], ["Motwani", "Rajeev", ""], ["Sharma", "Aneesh", ""], ["Xu", "Ying", ""]]}, {"id": "0902.3517", "submitter": "John Augustine", "authors": "John Augustine, Qi Han, Philip Loden, Sachin Lodha and Sasanka Roy", "title": "Energy-Efficient Shortest Path Algorithms for Convergecast in Sensor\n  Networks", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the capacitated vehicle routing problem that is\nencountered in sensor networks for scientific data collection. Consider an\nundirected graph $G=(V \\cup \\{\\mathbf{sink}\\},E)$. Each vertex $v \\in V$ holds\na constant-sized reading normalized to 1 byte that needs to be communicated to\nthe $\\mathbf{sink}$. The communication protocol is defined such that readings\ntravel in packets. The packets have a capacity of $k$ bytes. We define a {\\em\npacket hop} to be the communication of a packet from a vertex to its neighbor.\nEach packet hop drains one unit of energy and therefore, we need to communicate\nthe readings to the $\\mathbf{sink}$ with the fewest number of hops.\n  We show this problem to be NP-hard and counter it with a simple distributed\n$(2-\\frac{3}{2k})$-approximation algorithm called {\\tt SPT} that uses the\nshortest path tree rooted at the $\\mathbf{sink}$. We also show that {\\tt SPT}\nis absolutely optimal when $G$ is a tree and asymptotically optimal when $G$ is\na grid. Furthermore, {\\tt SPT} has two nice properties. Firstly, the readings\nalways travel along a shortest path toward the $\\mathbf{sink}$, which makes it\nan appealing solution to the convergecast problem as it fits the natural\nintuition. Secondly, each node employs a very elementary packing strategy.\nGiven all the readings that enter into the node, it sends out as many fully\npacked packets as possible followed by at most 1 partial packet. We show that\nany solution that has either one of the two properties cannot be a\n$(2-\\epsilon)$-approximation, for any fixed $\\epsilon > 0$. This makes \\spt\noptimal for the class of algorithms that obey either one of those properties.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 06:42:45 GMT"}], "update_date": "2009-02-23", "authors_parsed": [["Augustine", "John", ""], ["Han", "Qi", ""], ["Loden", "Philip", ""], ["Lodha", "Sachin", ""], ["Roy", "Sasanka", ""]]}, {"id": "0902.3528", "submitter": "Stephane Rovedakis", "authors": "L\\'elia Blin (IBISC), Maria Gradinariu Potop-Butucaru (LIP6), Stephane\n  Rovedakis (IBISC)", "title": "A Superstabilizing $\\log(n)$-Approximation Algorithm for Dynamic Steiner\n  Trees", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-05118-0_10", "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we design and prove correct a fully dynamic distributed\nalgorithm for maintaining an approximate Steiner tree that connects via a\nminimum-weight spanning tree a subset of nodes of a network (referred as\nSteiner members or Steiner group) . Steiner trees are good candidates to\nefficiently implement communication primitives such as publish/subscribe or\nmulticast, essential building blocks for the new emergent networks (e.g. P2P,\nsensor or adhoc networks). The cost of the solution returned by our algorithm\nis at most $\\log |S|$ times the cost of an optimal solution, where $S$ is the\ngroup of members. Our algorithm improves over existing solutions in several\nways. First, it tolerates the dynamism of both the group members and the\nnetwork. Next, our algorithm is self-stabilizing, that is, it copes with nodes\nmemory corruption. Last but not least, our algorithm is\n\\emph{superstabilizing}. That is, while converging to a correct configuration\n(i.e., a Steiner tree) after a modification of the network, it keeps offering\nthe Steiner tree service during the stabilization time to all members that have\nnot been affected by this modification.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2009 07:40:44 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Blin", "L\u00e9lia", "", "IBISC"], ["Potop-Butucaru", "Maria Gradinariu", "", "LIP6"], ["Rovedakis", "Stephane", "", "IBISC"]]}, {"id": "0902.3780", "submitter": "D\\'aniel Marx", "authors": "D\\'aniel Marx (1), Barry O'Sullivan (2), Igor Razgon (2) ((1) Budapest\n  University of Technology and Economics, (2) Cork Constraint Computation\n  Centre, University College Cork)", "title": "Treewidth reduction for constrained separation and bipartization\n  problems", "comments": "STACS final version of our result. For the complete description of\n  the result please see version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a method for reducing the treewidth of a graph while preserving\nall the minimal $s-t$ separators. This technique turns out to be very useful\nfor establishing the fixed-parameter tractability of constrained separation and\nbipartization problems. To demonstrate the power of this technique, we prove\nthe fixed-parameter tractability of a number of well-known separation and\nbipartization problems with various additional restrictions (e.g., the vertices\nbeing removed from the graph form an independent set). These results answer a\nnumber of open questions in the area of parameterized complexity.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2009 09:02:26 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2010 18:21:23 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 14:42:40 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["O'Sullivan", "Barry", ""], ["Razgon", "Igor", ""]]}]