[{"id": "0911.0086", "submitter": "Gwena\\\"el Joret", "authors": "Jean Cardinal, Samuel Fiorini, Gwena\\\"el Joret, Rapha\\\"el Jungers and\n  J. Ian Munro", "title": "Sorting under Partial Information (without the Ellipsoid Algorithm)", "comments": "v3: Minor changes. A preliminary version appeared in the proceedings\n  of the 42th ACM Symposium on Theory of Computing (STOC 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the well-known problem of sorting under partial information: sort\na finite set given the outcomes of comparisons between some pairs of elements.\nThe input is a partially ordered set P, and solving the problem amounts to\ndiscovering an unknown linear extension of P, using pairwise comparisons. The\ninformation-theoretic lower bound on the number of comparisons needed in the\nworst case is log e(P), the binary logarithm of the number of linear extensions\nof P. In a breakthrough paper, Jeff Kahn and Jeong Han Kim (J. Comput. System\nSci. 51 (3), 390-399, 1995) showed that there exists a polynomial-time\nalgorithm for the problem achieving this bound up to a constant factor. Their\nalgorithm invokes the ellipsoid algorithm at each iteration for determining the\nnext comparison, making it impractical.\n  We develop efficient algorithms for sorting under partial information. Like\nKahn and Kim, our approach relies on graph entropy. However, our algorithms\ndiffer in essential ways from theirs. Rather than resorting to convex\nprogramming for computing the entropy, we approximate the entropy, or make sure\nit is computed only once, in a restricted class of graphs, permitting the use\nof a simpler algorithm. Specifically, we present:\n  - an O(n^2) algorithm performing O(log n log e(P)) comparisons;\n  - an O(n^2.5) algorithm performing at most (1+ epsilon) log e(P) + O_epsilon\n(n) comparisons;\n  - an O(n^2.5) algorithm performing O(log e(P)) comparisons.\n  All our algorithms can be implemented in such a way that their computational\nbottleneck is confined in a preprocessing phase, while the sorting phase is\ncompleted in O(q) + O(n) time, where q denotes the number of comparisons\nperformed.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2009 14:36:36 GMT"}, {"version": "v2", "created": "Tue, 21 Sep 2010 12:58:11 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2013 13:56:44 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Cardinal", "Jean", ""], ["Fiorini", "Samuel", ""], ["Joret", "Gwena\u00ebl", ""], ["Jungers", "Rapha\u00ebl", ""], ["Munro", "J. Ian", ""]]}, {"id": "0911.0174", "submitter": "Rdv Ijcsis", "authors": "Muhammad Aasim Qureshi, Dr. Fadzil B. Hassan, Sohail Safdar, Rehan\n  Akbar", "title": "A O(E) Time Shortest Path Algorithm For Non Negative Weighted Undirected\n  Graphs", "comments": "7 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 1, pp. 040-046, October 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most of the shortest path problems like vehicle routing problems and\nnetwork routing problems, we only need an efficient path between two points\nsource and destination, and it is not necessary to calculate the shortest path\nfrom source to all other nodes. This paper concentrates on this very idea and\npresents an algorithm for calculating shortest path for (i) nonnegative\nweighted undirected graphs (ii) unweighted undirected graphs. The algorithm\ncompletes its execution in O(E) for all graphs except few in which longer path\n(in terms of number of edges) from source to some node makes it best selection\nfor that node. The main advantage of the algorithms is its simplicity and it\ndoes not need complex data structures for implementations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 20:24:05 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Qureshi", "Muhammad Aasim", ""], ["Hassan", "Dr. Fadzil B.", ""], ["Safdar", "Sohail", ""], ["Akbar", "Rehan", ""]]}, {"id": "0911.0397", "submitter": "Rdv Ijcsis", "authors": "Keehang Kwon, Hong Pyo Ha", "title": "Algorithm as Defining Dynamic Systems", "comments": "3 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 1, pp. 026-028, October 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new view to algorithms, Algorithms as defining dynamic\nsystems. This view extends the traditional, deterministic view that an\nalgorithm is a step by step procedure with nondeterminism. As a dynamic system\ncan be designed by a set of its defining laws, it is also desirable to design\nan algorithm by a (possibly nondeterministic) set of defining laws. This\nobservation requires some changes to algorithm development. We propose a two\nstep approach, the first step is to design an algorithm via a set of defining\nlaws of dynamic system. The second step is to translate these laws (written in\na natural language) into a formal language such as linear logic.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 20:01:19 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Kwon", "Keehang", ""], ["Ha", "Hong Pyo", ""]]}, {"id": "0911.0577", "submitter": "Philip Bille", "authors": "Philip Bille and Inge Li Goertz", "title": "Fast Arc-Annotated Subsequence Matching in Linear Space", "comments": "To appear in Algoritmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An arc-annotated string is a string of characters, called bases, augmented\nwith a set of pairs, called arcs, each connecting two bases. Given\narc-annotated strings $P$ and $Q$ the arc-preserving subsequence problem is to\ndetermine if $P$ can be obtained from $Q$ by deleting bases from $Q$. Whenever\na base is deleted any arc with an endpoint in that base is also deleted.\nArc-annotated strings where the arcs are ``nested'' are a natural model of RNA\nmolecules that captures both the primary and secondary structure of these. The\narc-preserving subsequence problem for nested arc-annotated strings is basic\nprimitive for investigating the function of RNA molecules. Gramm et al. [ACM\nTrans. Algorithms 2006] gave an algorithm for this problem using $O(nm)$ time\nand space, where $m$ and $n$ are the lengths of $P$ and $Q$, respectively. In\nthis paper we present a new algorithm using $O(nm)$ time and $O(n + m)$ space,\nthereby matching the previous time bound while significantly reducing the space\nfrom a quadratic term to linear. This is essential to process large RNA\nmolecules where the space is likely to be a bottleneck. To obtain our result we\nintroduce several novel ideas which may be of independent interest for related\nproblems on arc-annotated strings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2009 13:35:41 GMT"}, {"version": "v2", "created": "Wed, 8 Sep 2010 19:16:42 GMT"}], "update_date": "2010-09-09", "authors_parsed": [["Bille", "Philip", ""], ["Goertz", "Inge Li", ""]]}, {"id": "0911.0801", "submitter": "D\\'aniel Marx", "authors": "D\\'aniel Marx", "title": "Tractable hypergraph properties for constraint satisfaction and\n  conjunctive queries", "comments": "Extended abstract appeared in STOC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important question in the study of constraint satisfaction problems (CSP)\nis understanding how the graph or hypergraph describing the incidence structure\nof the constraints influences the complexity of the problem. For binary CSP\ninstances (i.e., where each constraint involves only two variables), the\nsituation is well understood: the complexity of the problem essentially depends\non the treewidth of the graph of the constraints. However, this is not the\ncorrect answer if constraints with unbounded number of variables are allowed,\nand in particular, for CSP instances arising from query evaluation problems in\ndatabase theory. Formally, if H is a class of hypergraphs, then let CSP(H) be\nCSP restricted to instances whose hypergraph is in H. Our goal is to\ncharacterize those classes of hypergraphs for which CSP(H) is polynomial-time\nsolvable or fixed-parameter tractable, parameterized by the number of\nvariables. Note that in the applications related to database query evaluation,\nwe usually assume that the number of variables is much smaller than the size of\nthe instance, thus parameterization by the number of variables is a meaningful\nquestion. The most general known property of H that makes CSP(H)\npolynomial-time solvable is bounded fractional hypertree width. Here we\nintroduce a new hypergraph measure called submodular width, and show that\nbounded submodular width of H implies that CSP(H) is fixed-parameter tractable.\nIn a matching hardness result, we show that if H has unbounded submodular\nwidth, then CSP(H) is not fixed-parameter tractable, unless the Exponential\nTime Hypothesis fails.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2009 14:07:38 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2010 09:35:29 GMT"}, {"version": "v3", "created": "Tue, 6 Dec 2011 15:12:49 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Marx", "D\u00e1niel", ""]]}, {"id": "0911.1174", "submitter": "Aleksandrs Slivkins", "authors": "Robert Kleinberg and Aleksandrs Slivkins", "title": "Sharp Dichotomies for Regret Minimization in Metric Spaces", "comments": "Full version of a paper in ACM-SIAM SODA 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lipschitz multi-armed bandit (MAB) problem generalizes the classical\nmulti-armed bandit problem by assuming one is given side information consisting\nof a priori upper bounds on the difference in expected payoff between certain\npairs of strategies. Classical results of (Lai and Robbins 1985) and (Auer et\nal. 2002) imply a logarithmic regret bound for the Lipschitz MAB problem on\nfinite metric spaces. Recent results on continuum-armed bandit problems and\ntheir generalizations imply lower bounds of $\\sqrt{t}$, or stronger, for many\ninfinite metric spaces such as the unit interval. Is this dichotomy universal?\nWe prove that the answer is yes: for every metric space, the optimal regret of\na Lipschitz MAB algorithm is either bounded above by any $f\\in \\omega(\\log t)$,\nor bounded below by any $g\\in o(\\sqrt{t})$. Perhaps surprisingly, this\ndichotomy does not coincide with the distinction between finite and infinite\nmetric spaces; instead it depends on whether the completion of the metric space\nis compact and countable. Our proof connects upper and lower bound techniques\nin online learning with classical topological notions such as perfect sets and\nthe Cantor-Bendixson theorem. Among many other results, we show a similar\ndichotomy for the \"full-feedback\" (a.k.a., \"best-expert\") version.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 03:52:56 GMT"}], "update_date": "2009-11-09", "authors_parsed": [["Kleinberg", "Robert", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "0911.1346", "submitter": "Pushkar Tripathi", "authors": "Gagan Goel, Pushkar Tripathi, Lei Wang", "title": "Optimal Approximation Algorithms for Multi-agent Combinatorial Problems\n  with Discounted Price Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are an important class of functions in combinatorial\noptimization which satisfy the natural properties of decreasing marginal costs.\nThe study of these functions has led to strong structural properties with\napplications in many areas. Recently, there has been significant interest in\nextending the theory of algorithms for optimizing combinatorial problems (such\nas network design problem of spanning tree) over submodular functions.\nUnfortunately, the lower bounds under the general class of submodular functions\nare known to be very high for many of the classical problems.\n  In this paper, we introduce and study an important subclass of submodular\nfunctions, which we call discounted price functions. These functions are\nsuccinctly representable and generalize linear cost functions. In this paper we\nstudy the following fundamental combinatorial optimization problems: Edge\nCover, Spanning Tree, Perfect Matching and Shortest Path, and obtain tight\nupper and lower bounds for these problems.\n  The main technical contribution of this paper is designing novel adaptive\ngreedy algorithms for the above problems. These algorithms greedily build the\nsolution whist rectifying mistakes made in the previous steps.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 20:29:10 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Goel", "Gagan", ""], ["Tripathi", "Pushkar", ""], ["Wang", "Lei", ""]]}, {"id": "0911.1419", "submitter": "Yusuke Watanabe", "authors": "Yusuke Watanabe and Michael Chertkov", "title": "Belief Propagation and Loop Calculus for the Permanent of a Non-Negative\n  Matrix", "comments": "11 pages; submitted to Journal of Physics A: Mathematical Theoretical", "journal-ref": null, "doi": "10.1088/1751-8113/43/24/242002", "report-no": null, "categories": "cs.DS cond-mat.stat-mech cs.DM cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider computation of permanent of a positive $(N\\times N)$ non-negative\nmatrix, $P=(P_i^j|i,j=1,\\cdots,N)$, or equivalently the problem of weighted\ncounting of the perfect matchings over the complete bipartite graph $K_{N,N}$.\nThe problem is known to be of likely exponential complexity. Stated as the\npartition function $Z$ of a graphical model, the problem allows exact Loop\nCalculus representation [Chertkov, Chernyak '06] in terms of an interior\nminimum of the Bethe Free Energy functional over non-integer doubly stochastic\nmatrix of marginal beliefs, $\\beta=(\\beta_i^j|i,j=1,\\cdots,N)$, also\ncorrespondent to a fixed point of the iterative message-passing algorithm of\nthe Belief Propagation (BP) type. Our main result is an explicit expression of\nthe exact partition function (permanent) in terms of the matrix of BP\nmarginals, $\\beta$, as $Z=\\mbox{Perm}(P)=Z_{BP}\n\\mbox{Perm}(\\beta_i^j(1-\\beta_i^j))/\\prod_{i,j}(1-\\beta_i^j)$, where $Z_{BP}$\nis the BP expression for the permanent stated explicitly in terms if $\\beta$.\nWe give two derivations of the formula, a direct one based on the Bethe Free\nEnergy and an alternative one combining the Ihara graph-$\\zeta$ function and\nthe Loop Calculus approaches. Assuming that the matrix $\\beta$ of the Belief\nPropagation marginals is calculated, we provide two lower bounds and one\nupper-bound to estimate the multiplicative term. Two complementary lower bounds\nare based on the Gurvits-van der Waerden theorem and on a relation between the\nmodified permanent and determinant respectively.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2009 04:15:01 GMT"}, {"version": "v2", "created": "Sun, 2 May 2010 15:58:46 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Watanabe", "Yusuke", ""], ["Chertkov", "Michael", ""]]}, {"id": "0911.1626", "submitter": "Marek Cygan", "authors": "Marek Cygan, Lukasz Kowalik, Marcin Mucha, Marcin Pilipczuk, Piotr\n  Sankowski", "title": "Fast Approximation in Subspaces by Doubling Metric Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and study a new complexity model for approximation\nalgorithms. The main motivation are practical problems over large data sets\nthat need to be solved many times for different scenarios, e.g., many multicast\ntrees that need to be constructed for different groups of users. In our model\nwe allow a preprocessing phase, when some information of the input graph\n$G=(V,E)$ is stored in a limited size data structure. Next, the data structure\nenables processing queries of the form ``solve problem A for an input\n$S\\subseteq V$''. We consider problems like {\\sc Steiner Forest}, {\\sc Facility\nLocation}, {\\sc $k$-Median}, {\\sc $k$-Center} and {\\sc TSP} in the case when\nthe graph induces a doubling metric. Our main results are data structures of\nnear-linear size that are able to answer queries in time close to linear in\n$|S|$. This improves over typical worst case reuniting time of approximation\nalgorithms in the classical setting which is $\\Omega(|E|)$ independently of the\nquery size. In most cases, our approximation guarantees are arbitrarily close\nto those in the classical setting. Additionally, we present the first fully\ndynamic algorithm for the Steiner tree problem.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 10:29:49 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2010 08:01:58 GMT"}], "update_date": "2010-06-18", "authors_parsed": [["Cygan", "Marek", ""], ["Kowalik", "Lukasz", ""], ["Mucha", "Marcin", ""], ["Pilipczuk", "Marcin", ""], ["Sankowski", "Piotr", ""]]}, {"id": "0911.1765", "submitter": "Ion Mandoiu", "authors": "Justin Kennedy, Ion I. Mandoiu, and Bogdan Pasaniuc", "title": "GEDI: Scalable Algorithms for Genotype Error Detection and Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genome-wide association studies generate very large datasets that require\nscalable analysis algorithms. In this report we describe the GEDI software\npackage, which implements efficient algorithms for performing several common\ntasks in the analysis of population genotype data, including genotype error\ndetection and correction, imputation of both randomly missing and untyped\ngenotypes, and genotype phasing. Experimental results show that GEDI achieves\nhigh accuracy with a runtime scaling linearly with the number of markers and\nsamples. The open source C++ code of GEDI, released under the GNU General\nPublic License, is available for download at\nhttp://dna.engr.uconn.edu/software/GEDI/\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 23:35:41 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Kennedy", "Justin", ""], ["Mandoiu", "Ion I.", ""], ["Pasaniuc", "Bogdan", ""]]}, {"id": "0911.1813", "submitter": "Aaron Roth", "authors": "Aaron Roth, Tim Roughgarden", "title": "Interactive Privacy via the Median Mechanism", "comments": "Appeared in STOC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new interactive differentially private mechanism -- the median\nmechanism -- for answering arbitrary predicate queries that arrive online.\nRelative to fixed accuracy and privacy constraints, this mechanism can answer\nexponentially more queries than the previously best known interactive privacy\nmechanism (the Laplace mechanism, which independently perturbs each query\nresult). Our guarantee is almost the best possible, even for non-interactive\nprivacy mechanisms. Conceptually, the median mechanism is the first privacy\nmechanism capable of identifying and exploiting correlations among queries in\nan interactive setting.\n  We also give an efficient implementation of the median mechanism, with\nrunning time polynomial in the number of queries, the database size, and the\ndomain size. This efficient implementation guarantees privacy for all input\ndatabases, and accurate query results for almost all input databases. The\ndependence of the privacy on the number of queries in this mechanism improves\nover that of the best previously known efficient mechanism by a\nsuper-polynomial factor, even in the non-interactive setting.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 03:55:44 GMT"}, {"version": "v2", "created": "Wed, 19 Jan 2011 16:09:18 GMT"}], "update_date": "2011-01-20", "authors_parsed": [["Roth", "Aaron", ""], ["Roughgarden", "Tim", ""]]}, {"id": "0911.1900", "submitter": "Daniel Raible", "authors": "Daniel Raible, Henning Fernau", "title": "A Faster Exact Algorithm for the Directed Maximum Leaf Spanning Tree\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a directed graph $G=(V,A)$, the Directed Maximum Leaf Spanning Tree\nproblem asks to compute a directed spanning tree (i.e., an out-branching) with\nas many leaves as possible. By designing a Branch-and-Reduced algorithm\ncombined with the Measure & Conquer technique for running time analysis, we\nshow that the problem can be solved in time $\\Oh^*(1.9043^n)$ using polynomial\nspace. Hitherto, there have been only few examples. Provided exponential space\nthis run time upper bound can be lowered to $\\Oh^*(1.8139^n)$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 12:50:07 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 14:12:27 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Raible", "Daniel", ""], ["Fernau", "Henning", ""]]}, {"id": "0911.2214", "submitter": "Warren Schudy", "authors": "Marek Karpinski and Warren Schudy", "title": "Approximation Schemes for the Betweenness Problem in Tournaments and\n  Related Ranking Problems", "comments": "15 pages. Minor changes to presentation from version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design the first polynomial time approximation schemes (PTASs) for the\nMinimum Betweenness problem in tournaments and some related higher arity\nranking problems. This settles the approximation status of the Betweenness\nproblem in tournaments along with other ranking problems which were open for\nsome time now. The results depend on a new technique of dealing with fragile\nranking constraints and could be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2009 20:36:49 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2010 00:25:34 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2010 00:13:29 GMT"}], "update_date": "2010-07-12", "authors_parsed": [["Karpinski", "Marek", ""], ["Schudy", "Warren", ""]]}, {"id": "0911.2233", "submitter": "Zhi Xu", "authors": "Ehsan Chiniforooshan, Lila Kari and Zhi Xu", "title": "Pseudo-Power Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repetition avoidance has been studied since Thue's work. In this paper, we\nconsidered another type of repetition, which is called pseudo-power. This\nconcept is inspired by Watson-Crick complementarity in DNA sequence and is\ndefined over an antimorphic involution $\\phi$. We first classify the alphabet\n$\\Sigma$ and the antimorphic involution $\\phi$, under which there exists\nsufficiently long pseudo-$k$th-power-free words. Then we present algorithms to\ntest whether a finite word $w$ is pseudo-$k$th-power-free.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2009 21:07:36 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Chiniforooshan", "Ehsan", ""], ["Kari", "Lila", ""], ["Xu", "Zhi", ""]]}, {"id": "0911.2280", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji, Rapha\\\"el M. Jungers, and Vincent D.\n  Blondel", "title": "PageRank Optimization by Edge Selection", "comments": "30 pages, 3 figures", "journal-ref": "Discrete Applied Mathematics, Volume 169, 2014, Pages 73-87", "doi": "10.1016/j.dam.2014.01.007", "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of a node in a directed graph can be measured by its PageRank.\nThe PageRank of a node is used in a number of application contexts - including\nranking websites - and can be interpreted as the average portion of time spent\nat the node by an infinite random walk. We consider the problem of maximizing\nthe PageRank of a node by selecting some of the edges from a set of edges that\nare under our control. By applying results from Markov decision theory, we show\nthat an optimal solution to this problem can be found in polynomial time. Our\ncore solution results in a linear programming formulation, but we also provide\nan alternative greedy algorithm, a variant of policy iteration, which runs in\npolynomial time, as well. Finally, we show that, under the slight modification\nfor which we are given mutually exclusive pairs of edges, the problem of\nPageRank optimization becomes NP-hard.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 12:57:09 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2012 09:09:34 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Jungers", "Rapha\u00ebl M.", ""], ["Blondel", "Vincent D.", ""]]}, {"id": "0911.2322", "submitter": "EPTCS", "authors": "Amin Coja-Oghlan", "title": "Random Constraint Satisfaction Problems", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 32-37", "doi": "10.4204/EPTCS.9.4", "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random instances of constraint satisfaction problems such as k-SAT provide\nchallenging benchmarks. If there are m constraints over n variables there is\ntypically a large range of densities r=m/n where solutions are known to exist\nwith probability close to one due to non-constructive arguments. However, no\nalgorithms are known to find solutions efficiently with a non-vanishing\nprobability at even much lower densities. This fact appears to be related to a\nphase transition in the set of all solutions. The goal of this extended\nabstract is to provide a perspective on this phenomenon, and on the\ncomputational challenge that it poses.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 08:42:42 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Coja-Oghlan", "Amin", ""]]}, {"id": "0911.2567", "submitter": "Christoph Durr", "authors": "Marek Chrobak, Christoph Durr, Flavio Guinez, Antoni Lozano, Nguyen\n  Kim Thang", "title": "Tile Packing Tomography is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete tomography deals with reconstructing finite spatial objects from\nlower dimensional projections and has applications for example in timetable\ndesign. In this paper we consider the problem of reconstructing a tile packing\nfrom its row and column projections. It consists of disjoint copies of a fixed\ntile, all contained in some rectangular grid. The projections tell how many\ncells are covered by a tile in each row and column. How difficult is it to\nconstruct a tile packing satisfying given projections? It was known to be\nsolvable by a greedy algorithm for bars (tiles of width or height 1), and\nNP-hardness results were known for some specific tiles. This paper shows that\nthe problem is NP-hard whenever the tile is not a bar.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2009 08:54:27 GMT"}, {"version": "v2", "created": "Tue, 21 Dec 2010 09:43:49 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Chrobak", "Marek", ""], ["Durr", "Christoph", ""], ["Guinez", "Flavio", ""], ["Lozano", "Antoni", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "0911.2801", "submitter": "Olivier Bodini", "authors": "Olivier Bodini (LIP6), Alice Jacquot (LIP6)", "title": "Boltzmann Samplers for Colored Combinatorial Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a general framework for the Boltzmann generation of\ncolored objects belonging to combinatorial constructible classes. We propose an\nintuitive notion called profiled objects which allows the sampling of\nsize-colored objects (and also of k-colored objects) although the corresponding\nclass cannot be described by an analytic ordinary generating function.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2009 20:03:10 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Bodini", "Olivier", "", "LIP6"], ["Jacquot", "Alice", "", "LIP6"]]}, {"id": "0911.2802", "submitter": "Olivier Bodini", "authors": "Olivier Bodini (LIP6), Alice Jacquot (LIP6)", "title": "Boltzmann Samplers for v-balanced Colored Necklaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the random generation of particular colored\nnecklaces for which the number of beads of a given color is constrained (these\nnecklaces are called v-balanced). We propose an efficient sampler (its expected\ntime complexity is linear) which satisfies the Boltzmann model principle\nintroduced by Duchon, Flajolet, Louchard and Schaeffer. Our main motivation is\nto show that the absence of a decomposable specification can be circumvented by\nmixing the Boltzmann samplers with other types of samplers.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2009 20:09:30 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Bodini", "Olivier", "", "LIP6"], ["Jacquot", "Alice", "", "LIP6"]]}, {"id": "0911.2804", "submitter": "Thomas Fernique", "authors": "Olivier Bodini, Thomas Fernique, Michael Rao, Eric Remila", "title": "Distances on Rhombus Tilings", "comments": "18 pages, 9 figures, submitted to Theoretical Computer Science\n  (special issue of DGCI'09)", "journal-ref": "Theor. Comput. Sci. 412(36): 4787-4794 (2011)", "doi": "10.1016/j.tcs.2011.04.015", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rhombus tilings of a simply connected domain of the Euclidean plane are\nknown to form a flip-connected space (a flip is the elementary operation on\nrhombus tilings which rotates 180{\\deg} a hexagon made of three rhombi).\nMotivated by the study of a quasicrystal growth model, we are here interested\nin better understanding how \"tight\" rhombus tiling spaces are flip-connected.\nWe introduce a lower bound (Hamming-distance) on the minimal number of flips to\nlink two tilings (flip-distance), and we investigate whether it is sharp. The\nanswer depends on the number n of different edge directions in the tiling:\npositive for n=3 (dimer tilings) or n=4 (octogonal tilings), but possibly\nnegative for n=5 (decagonal tilings) or greater values of n. A standard proof\nis provided for the n=3 and n=4 cases, while the complexity of the n=5 case led\nto a computer-assisted proof (whose main result can however be easily checked\nby hand).\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2009 20:29:27 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2011 16:53:33 GMT"}], "update_date": "2011-12-07", "authors_parsed": [["Bodini", "Olivier", ""], ["Fernique", "Thomas", ""], ["Rao", "Michael", ""], ["Remila", "Eric", ""]]}, {"id": "0911.2805", "submitter": "Olivier Bodini", "authors": "Olivier Bodini (LIP6), J\\'er\\'emie Lumbroso (LIP6)", "title": "Optimal Partial Tiling of Manhattan Polyominoes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an efficient optimal partial tiling algorithm is still an open\nproblem. We have worked on a special case, the tiling of Manhattan polyominoes\nwith dominoes, for which we give an algorithm linear in the number of columns.\nSome techniques are borrowed from traditional graph optimisation problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2009 20:32:22 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Bodini", "Olivier", "", "LIP6"], ["Lumbroso", "J\u00e9r\u00e9mie", "", "LIP6"]]}, {"id": "0911.2924", "submitter": "Mika G\\\"o\\\"os", "authors": "Mika G\\\"o\\\"os and Pekka Orponen", "title": "Synthesizing Minimal Tile Sets for Patterned DNA Self-Assembly", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pattern self-Assembly Tile set Synthesis (PATS) problem is to determine a\nset of coloured tiles that self-assemble to implement a given rectangular\ncolour pattern. We give an exhaustive branch-and-bound algorithm to find tile\nsets of minimum cardinality for the PATS problem. Our algorithm makes use of a\nsearch tree in the lattice of partitions of the ambient rectangular grid, and\nan efficient bounding function to prune this search tree. Empirical data on the\nperformance of the algorithm shows that it compares favourably to previously\npresented heuristic solutions to the problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 07:43:41 GMT"}, {"version": "v2", "created": "Sat, 14 Aug 2010 19:25:16 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Orponen", "Pekka", ""]]}, {"id": "0911.2974", "submitter": "Zizhuo Wang", "authors": "Shipra Agrawal, Zizhuo Wang, Yinyu Ye", "title": "A Dynamic Near-Optimal Algorithm for Online Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural optimization model that formulates many online resource allocation\nand revenue management problems is the online linear program (LP) in which the\nconstraint matrix is revealed column by column along with the corresponding\nobjective coefficient. In such a model, a decision variable has to be set each\ntime a column is revealed without observing the future inputs and the goal is\nto maximize the overall objective function. In this paper, we provide a\nnear-optimal algorithm for this general class of online problems under the\nassumption of random order of arrival and some mild conditions on the size of\nthe LP right-hand-side input. Specifically, our learning-based algorithm works\nby dynamically updating a threshold price vector at geometric time intervals,\nwhere the dual prices learned from the revealed columns in the previous period\nare used to determine the sequential decisions in the current period. Due to\nthe feature of dynamic learning, the competitiveness of our algorithm improves\nover the past study of the same problem. We also present a worst-case example\nshowing that the performance of our algorithm is near-optimal.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 16:39:33 GMT"}, {"version": "v2", "created": "Sat, 4 May 2013 20:10:14 GMT"}, {"version": "v3", "created": "Wed, 9 Apr 2014 03:44:37 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Agrawal", "Shipra", ""], ["Wang", "Zizhuo", ""], ["Ye", "Yinyu", ""]]}, {"id": "0911.3110", "submitter": "David Harvey", "authors": "David Harvey", "title": "Faster exponentials of power series", "comments": "3 pages, requires algorithm2e package", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new algorithm for computing exp(f) where f is a power series in\nC[[x]]. If M(n) denotes the cost of multiplying polynomials of degree n, the\nnew algorithm costs (2.1666... + o(1)) M(n) to compute exp(f) to order n. This\nimproves on the previous best result, namely (2.333... + o(1)) M(n).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 18:22:48 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Harvey", "David", ""]]}, {"id": "0911.3195", "submitter": "Danupon Nanongkai", "authors": "Atish Das Sarma, Danupon Nanongkai, Gopal Pandurangan, Prasad Tetali", "title": "Efficient Distributed Random Walks with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of performing random walks efficiently in a\ndistributed network. Given bandwidth constraints, the goal is to minimize the\nnumber of rounds required to obtain a random walk sample. We first present a\nfast sublinear time distributed algorithm for performing random walks whose\ntime complexity is sublinear in the length of the walk. Our algorithm performs\na random walk of length $\\ell$ in $\\tilde{O}(\\sqrt{\\ell D})$ rounds (with high\nprobability) on an undirected network, where $D$ is the diameter of the\nnetwork. This improves over the previous best algorithm that ran in\n$\\tilde{O}(\\ell^{2/3}D^{1/3})$ rounds (Das Sarma et al., PODC 2009). We further\nextend our algorithms to efficiently perform $k$ independent random walks in\n$\\tilde{O}(\\sqrt{k\\ell D} + k)$ rounds. We then show that there is a\nfundamental difficulty in improving the dependence on $\\ell$ any further by\nproving a lower bound of $\\Omega(\\sqrt{\\frac{\\ell}{\\log \\ell}} + D)$ under a\ngeneral model of distributed random walk algorithms. Our random walk algorithms\nare useful in speeding up distributed algorithms for a variety of applications\nthat use random walks as a subroutine. We present two main applications. First,\nwe give a fast distributed algorithm for computing a random spanning tree (RST)\nin an arbitrary (undirected) network which runs in $\\tilde{O}(\\sqrt{m}D)$\nrounds (with high probability; here $m$ is the number of edges). Our second\napplication is a fast decentralized algorithm for estimating mixing time and\nrelated parameters of the underlying network. Our algorithm is fully\ndecentralized and can serve as a building block in the design of\ntopologically-aware networks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 00:57:01 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2010 13:34:11 GMT"}], "update_date": "2010-03-03", "authors_parsed": [["Sarma", "Atish Das", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""], ["Tetali", "Prasad", ""]]}, {"id": "0911.3291", "submitter": "Frederic Magniez", "authors": "F. Magniez, C. Mathieu, A. Nayak", "title": "Recognizing well-parenthesized expressions in the streaming model", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a concrete problem and with the goal of understanding the sense\nin which the complexity of streaming algorithms is related to the complexity of\nformal languages, we investigate the problem Dyck(s) of checking matching\nparentheses, with $s$ different types of parenthesis.\n  We present a one-pass randomized streaming algorithm for Dyck(2) with space\n$\\Order(\\sqrt{n}\\log n)$, time per letter $\\polylog (n)$, and one-sided error.\nWe prove that this one-pass algorithm is optimal, up to a $\\polylog n$ factor,\neven when two-sided error is allowed. For the lower bound, we prove a direct\nsum result on hard instances by following the \"information cost\" approach, but\nwith a few twists. Indeed, we play a subtle game between public and private\ncoins. This mixture between public and private coins results from a balancing\nact between the direct sum result and a combinatorial lower bound for the base\ncase.\n  Surprisingly, the space requirement shrinks drastically if we have access to\nthe input stream in reverse. We present a two-pass randomized streaming\nalgorithm for Dyck(2) with space $\\Order((\\log n)^2)$, time $\\polylog (n)$ and\none-sided error, where the second pass is in the reverse direction. Both\nalgorithms can be extended to Dyck(s) since this problem is reducible to\nDyck(2) for a suitable notion of reduction in the streaming model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 12:42:11 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Magniez", "F.", ""], ["Mathieu", "C.", ""], ["Nayak", "A.", ""]]}, {"id": "0911.3318", "submitter": "Francisco Claude", "authors": "Francisco Claude, Antonio Farina and Gonzalo Navarro", "title": "Re-Pair Compression of Inverted Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression of inverted lists with methods that support fast intersection\noperations is an active research topic. Most compression schemes rely on\nencoding differences between consecutive positions with techniques that favor\nsmall numbers. In this paper we explore a completely different alternative: We\nuse Re-Pair compression of those differences. While Re-Pair by itself offers\nfast decompression at arbitrary positions in main and secondary memory, we\nintroduce variants that in addition speed up the operations required for\ninverted list intersection. We compare the resulting data structures with\nseveral recent proposals under various list intersection algorithms, to\nconclude that our Re-Pair variants offer an interesting time/space tradeoff for\nthis problem, yet further improvements are required for it to improve upon the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 14:39:36 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Claude", "Francisco", ""], ["Farina", "Antonio", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "0911.3355", "submitter": "Zhi Xu", "authors": "Zhi Xu", "title": "A Minimal Periods Algorithm with Applications", "comments": "14 pages", "journal-ref": null, "doi": "10.1007/978-3-642-13509-5_6", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kosaraju in ``Computation of squares in a string'' briefly described a\nlinear-time algorithm for computing the minimal squares starting at each\nposition in a word. Using the same construction of suffix trees, we generalize\nhis result and describe in detail how to compute in O(k|w|)-time the minimal\nk-th power, with period of length larger than s, starting at each position in a\nword w for arbitrary exponent $k\\geq2$ and integer $s\\geq0$. We provide the\ncomplete proof of correctness of the algorithm, which is somehow not completely\nclear in Kosaraju's original paper. The algorithm can be used as a sub-routine\nto detect certain types of pseudo-patterns in words, which is our original\nintention to study the generalization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 17:34:23 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Xu", "Zhi", ""]]}, {"id": "0911.3950", "submitter": "Hariharan Narayanan", "authors": "Hariharan Narayanan", "title": "Randomized Interior Point methods for Sampling and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Markov chain (Dikin walk) for sampling from a convex body\nequipped with a self-concordant barrier, whose mixing time from a \"central\npoint\" is strongly polynomial in the description of the convex set. The mixing\ntime of this chain is invariant under affine transformations of the convex set,\nthus eliminating the need for first placing the body in an isotropic position.\nThis recovers and extends previous results of from polytopes to more general\nconvex sets. On every convex set of dimension $n$, there exists a\nself-concordant barrier whose \"complexity\" is polynomially bounded.\nConsequently, a rapidly mixing Markov chain of the kind we describe can be\ndefined on any convex set. We use these results to design an algorithm\nconsisting of a single random walk for optimizing a linear function on a convex\nset. We show that this random walk reaches an approximately optimal point in\npolynomial time with high probability and that the corresponding objective\nvalues converge with probability 1 to the optimal objective value as the number\nof steps tends to infinity. One technical contribution is a family of lower\nbounds for the isoperimetric constants of (weighted) Riemannian manifolds on\nwhich, interior point methods perform a kind of steepest descent. Using results\nof Barthe \\cite{barthe} and Bobkov and Houdr\\'e, on the isoperimetry of\nproducts of (weighted) Riemannian manifolds, we obtain sharper upper bounds on\nthe mixing time of Dikin walk on products of convex sets than the bounds\nobtained from a direct application of the Localization Lemma, on which, since\n(Lov\\'asz and Simonovits), the analyses of all random walks on convex sets have\nrelied.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2009 02:46:03 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2010 22:56:34 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2015 13:26:54 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2015 21:48:56 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Narayanan", "Hariharan", ""]]}, {"id": "0911.4191", "submitter": "Shmuel Onn", "authors": "Shmuel Onn", "title": "Theory and Applications of N-Fold Integer Programming", "comments": "IMA Volume on Mixed Integer Nonlinear Programming, Frontier Series,\n  Springer, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We overview our recently introduced theory of n-fold integer programming\nwhich enables the polynomial time solution of fundamental linear and nonlinear\ninteger programming problems in variable dimension. We demonstrate its power by\nobtaining the first polynomial time algorithms in several application areas\nincluding multicommodity flows and privacy in statistical databases.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2009 16:32:32 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2009 19:05:49 GMT"}], "update_date": "2010-06-07", "authors_parsed": [["Onn", "Shmuel", ""]]}, {"id": "0911.4238", "submitter": "Chia-Mu Yu", "authors": "Chia-Mu Yu, Chun-Shien Lu, and Sy-Yen Kuo", "title": "Secure Multidimensional Queries in Tiered Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, aiming at securing range query, top-k query, and skyline query\nin tiered sensor networks, we propose the Secure Range Query (SRQ), Secure\nTop-$k$ Query (STQ), and Secure Skyline Query (SSQ) schemes, respectively. In\nparticular, SRQ, by using our proposed \\emph{prime aggregation} technique, has\nthe lowest communication overhead among prior works, while STQ and SSQ, to our\nknowledge, are the first proposals in tiered sensor networks for securing\ntop-$k$ and skyline queries, respectively. Moreover, the relatively unexplored\nissue of the security impact of sensor node compromises on multidimensional\nqueries is studied; two attacks incurred from the sensor node compromises,\n\\emph{collusion attack} and \\emph{false-incrimination attack}, are investigated\nin this paper. After developing a novel technique called \\emph{subtree\nsampling}, we also explore methods of efficiently mitigating the threat of\nsensor node compromises. Performance analyses regarding the probability for\ndetecting incomplete query-results and communication cost of the proposed\nschemes are also studied.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2009 08:36:13 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2009 15:46:53 GMT"}], "update_date": "2009-12-16", "authors_parsed": [["Yu", "Chia-Mu", ""], ["Lu", "Chun-Shien", ""], ["Kuo", "Sy-Yen", ""]]}, {"id": "0911.4239", "submitter": "Chia-Mu Yu", "authors": "Chia-Mu Yu, Chun-Shien Lu, and Sy-Yen Kuo", "title": "Constrained Function Based En-Route Filtering for Sensor Networks", "comments": "26 pages, single column, extension from a preliminary version\n  appeared in IEEE WCNC 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor networks are vulnerable to \\emph{false data injection attack} and\n\\emph{path-based DoS} (PDoS) attack. While conventional authentication schemes\nare insufficient for solving these security conflicts, an \\emph{en-route\nfiltering} scheme acts as a defense against these two attacks. To construct an\nefficient en-route filtering scheme, this paper first presents a Constrained\nFunction based message Authentication (CFA) scheme, which can be thought of as\na hash function directly supporting the en-route filtering functionality.\nTogether with the \\emph{redundancy property} of sensor networks, which means\nthat an event can be simultaneously observed by multiple sensor nodes, the\ndevised CFA scheme is used to construct a CFA-based en-route filtering (CFAEF)\nscheme. In contrast to most of the existing methods, which rely on complicated\nsecurity associations among sensor nodes, our design, which directly exploits\nan en-route filtering hash function, appears to be novel. We examine the CFA\nand CFAEF schemes from both the theoretical and numerical aspects to\ndemonstrate their efficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2009 08:56:07 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Yu", "Chia-Mu", ""], ["Lu", "Chun-Shien", ""], ["Kuo", "Sy-Yen", ""]]}, {"id": "0911.4366", "submitter": "Gwena\\\"el Joret", "authors": "Samuel Fiorini, Gwena\\\"el Joret, Ugo Pietropaoli", "title": "Hitting Diamonds and Growing Cacti", "comments": "v2: several minor changes.", "journal-ref": null, "doi": "10.1007/978-3-642-13036-6_15", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following NP-hard problem: in a weighted graph, find a\nminimum cost set of vertices whose removal leaves a graph in which no two\ncycles share an edge. We obtain a constant-factor approximation algorithm,\nbased on the primal-dual method. Moreover, we show that the integrality gap of\nthe natural LP relaxation of the problem is \\Theta(\\log n), where n denotes the\nnumber of vertices in the graph.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 11:14:06 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2010 21:03:38 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Fiorini", "Samuel", ""], ["Joret", "Gwena\u00ebl", ""], ["Pietropaoli", "Ugo", ""]]}, {"id": "0911.4384", "submitter": "Magnus Lie Hetland", "authors": "Magnus Lie Hetland", "title": "Ptolemaic Indexing", "comments": null, "journal-ref": "Journ. of Comp. Geom., JoCG, vol 6, no 1 (2015) 165-184", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a new family of bounds for use in similarity search,\nrelated to those used in metric indexing, but based on Ptolemy's inequality,\nrather than the metric axioms. Ptolemy's inequality holds for the well-known\nEuclidean distance, but is also shown here to hold for quadratic form metrics\nin general, with Mahalanobis distance as an important special case. The\ninequality is examined empirically on both synthetic and real-world data sets\nand is also found to hold approximately, with a very low degree of error, for\nimportant distances such as the angular pseudometric and several Lp norms.\nIndexing experiments demonstrate a highly increased filtering power compared to\nexisting, triangular methods. It is also shown that combining the Ptolemaic and\ntriangular filtering can lead to better results than using either approach on\nits own.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 12:16:15 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2009 21:57:13 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2015 11:57:30 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Hetland", "Magnus Lie", ""]]}, {"id": "0911.4544", "submitter": "Anand Louis", "authors": "Anand Louis, Nisheeth Vishnoi", "title": "Improved Algorithm for Degree Bounded Survivable Network Design Problem", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-13731-0_38", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Degree-Bounded Survivable Network Design Problem: the\nobjective is to find a minimum cost subgraph satisfying the given connectivity\nrequirements as well as the degree bounds on the vertices. If we denote the\nupper bound on the degree of a vertex v by b(v), then we present an algorithm\nthat finds a solution whose cost is at most twice the cost of the optimal\nsolution while the degree of a degree constrained vertex v is at most 2b(v) +\n2. This improves upon the results of Lau and Singh and that of Lau, Naor,\nSalavatipour and Singh.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2009 05:27:19 GMT"}], "update_date": "2010-07-08", "authors_parsed": [["Louis", "Anand", ""], ["Vishnoi", "Nisheeth", ""]]}, {"id": "0911.4732", "submitter": "Qi Ge", "authors": "Qi Ge, Daniel Stefankovic", "title": "A graph polynomial for independent sets of bipartite graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new graph polynomial that encodes interesting properties of\ngraphs, for example, the number of matchings and the number of perfect\nmatchings. Most importantly, for bipartite graphs the polynomial encodes the\nnumber of independent sets (#BIS).\n  We analyze the complexity of exact evaluation of the polynomial at rational\npoints and show that for most points exact evaluation is #P-hard (assuming the\ngeneralized Riemann hypothesis) and for the rest of the points exact evaluation\nis trivial.\n  We conjecture that a natural Markov chain can be used to approximately\nevaluate the polynomial for a range of parameters. The conjecture, if true,\nwould imply an approximate counting algorithm for #BIS, a problem shown, by\n[Dyer et al. 2004], to be complete (with respect to, so called, AP-reductions)\nfor a rich logically defined sub-class of #P. We give a mild support for our\nconjecture by proving that the Markov chain is rapidly mixing on trees. As a\nby-product we show that the \"single bond flip\" Markov chain for the random\ncluster model is rapidly mixing on constant tree-width graphs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2009 21:46:56 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2010 05:11:34 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2010 20:21:21 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2010 16:25:22 GMT"}], "update_date": "2010-02-10", "authors_parsed": [["Ge", "Qi", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "0911.4940", "submitter": "Sebastian F. Walter", "authors": "Sebastian F. Walter", "title": "Efficient Higher Order Derivatives of Objective Functions Composed of\n  Matrix Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the efficient evaluation of higher-order\nderivatives of functions $f$ that are composed of matrix operations. I.e., we\nwant to compute the $D$-th derivative tensor $\\nabla^D f(X) \\in \\mathbb\nR^{N^D}$, where $f:\\mathbb R^{N} \\to \\mathbb R$ is given as an algorithm that\nconsists of many matrix operations. We propose a method that is a combination\nof two well-known techniques from Algorithmic Differentiation (AD): univariate\nTaylor propagation on scalars (UTPS) and first-order forward and reverse on\nmatrices. The combination leads to a technique that we would like to call\nunivariate Taylor propagation on matrices (UTPM). The method inherits many\ndesirable properties: It is easy to implement, it is very efficient and it\nreturns not only $\\nabla^D f$ but yields in the process also the derivatives\n$\\nabla^d f$ for $d \\leq D$. As performance test we compute the gradient\n$\\nabla f(X)$ % and the Hessian $\\nabla_A^2 f(A)$ by a combination of forward\nand reverse mode of $f(X) = \\trace (X^{-1})$ in the reverse mode of AD for $X\n\\in \\mathbb R^{n \\times n}$. We observe a speedup of about 100 compared to\nUTPS. Due to the nature of the method, the memory footprint is also small and\ntherefore can be used to differentiate functions that are not accessible by\nstandard methods due to limited physical memory.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2009 20:05:24 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Walter", "Sebastian F.", ""]]}, {"id": "0911.4981", "submitter": "Gonzalo Navarro", "authors": "Jeremy Barbay, Francisco Claude, Travis Gagie, Gonzalo Navarro and\n  Yakov Nekrich", "title": "Efficient Fully-Compressed Sequence Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data structure that stores a sequence $s[1..n]$ over alphabet\n$[1..\\sigma]$ in $n\\Ho(s) + o(n)(\\Ho(s){+}1)$ bits, where $\\Ho(s)$ is the\nzero-order entropy of $s$. This structure supports the queries \\access, \\rank\\\nand \\select, which are fundamental building blocks for many other compressed\ndata structures, in worst-case time $\\Oh{\\lg\\lg\\sigma}$ and average time\n$\\Oh{\\lg \\Ho(s)}$. The worst-case complexity matches the best previous results,\nyet these had been achieved with data structures using $n\\Ho(s)+o(n\\lg\\sigma)$\nbits. On highly compressible sequences the $o(n\\lg\\sigma)$ bits of the\nredundancy may be significant compared to the the $n\\Ho(s)$ bits that encode\nthe data. Our representation, instead, compresses the redundancy as well.\nMoreover, our average-case complexity is unprecedented. Our technique is based\non partitioning the alphabet into characters of similar frequency. The\nsubsequence corresponding to each group can then be encoded using fast\nuncompressed representations without harming the overall compression ratios,\neven in the redundancy. The result also improves upon the best current\ncompressed representations of several other data structures. For example, we\nachieve $(i)$ compressed redundancy, retaining the best time complexities, for\nthe smallest existing full-text self-indexes; $(ii)$ compressed permutations\n$\\pi$ with times for $\\pi()$ and $\\pii()$ improved to loglogarithmic; and\n$(iii)$ the first compressed representation of dynamic collections of disjoint\nsets. We also point out various applications to inverted indexes, suffix\narrays, binary relations, and data compressors. ...\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2009 23:31:23 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2010 02:04:43 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2010 03:33:21 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2012 02:12:43 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Barbay", "Jeremy", ""], ["Claude", "Francisco", ""], ["Gagie", "Travis", ""], ["Navarro", "Gonzalo", ""], ["Nekrich", "Yakov", ""]]}, {"id": "0911.5031", "submitter": "Shihabur Rahman Chowdhury", "authors": "Shihabur Rahman Chowdhury, Masud Hasan, Sumaiya Iqbal, M. Sohel Rahman", "title": "An $O(n^2)$ Algorithm for Computing Longest Common Cyclic Subsequence", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\em longest common subsequence (LCS)} problem is a classic and\nwell-studied problem in computer science. LCS is a central problem in\nstringology and finds broad applications in text compression, error-detecting\ncodes and biological sequence comparison. However, in numerous contexts, words\nrepresent cyclic sequences of symbols and LCS must be generalized to consider\nall circular shifts of the strings. This occurs especially in computational\nbiology when genetic material is sequenced form circular DNA or RNA molecules.\nThis initiates the problem of {\\em longest common cyclic subsequence (LCCS)}\nwhich finds the longest subsequence between all circular shifts of two strings.\nIn this paper, we give an $O(n^2)$ algorithm for solving LCCS problem where $n$\nis the number of symbols in the strings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2009 08:49:48 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2010 15:53:33 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Chowdhury", "Shihabur Rahman", ""], ["Hasan", "Masud", ""], ["Iqbal", "Sumaiya", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "0911.5094", "submitter": "Uriel Feige", "authors": "Uriel Feige", "title": "Faster FAST(Feedback Arc Set in Tournaments)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that finds a feedback arc set of size $k$ in a\ntournament in time $n^{O(1)}2^{O(\\sqrt{k})}$. This is asymptotically faster\nthan the running time of previously known algorithms for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2009 14:43:31 GMT"}], "update_date": "2009-11-30", "authors_parsed": [["Feige", "Uriel", ""]]}, {"id": "0911.5143", "submitter": "MohammadHossein Bateni", "authors": "MohammadHossein Bateni and MohammadTaghi Hajiaghayi and D\\'aniel Marx", "title": "Approximation Schemes for Steiner Forest on Planar Graphs and Graphs of\n  Bounded Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time approximation scheme (PTAS) for the Steiner\nforest problem on planar graphs and, more generally, on graphs of bounded\ngenus. As a first step, we show how to build a Steiner forest spanner for such\ngraphs. The crux of the process is a clustering procedure called\nprize-collecting clustering that breaks down the input instance into separate\nsubinstances which are easier to handle; moreover, the terminals in different\nsubinstances are far from each other. Each subinstance has a relatively\ninexpensive Steiner tree connecting all its terminals, and the subinstances can\nbe solved (almost) separately. Another building block is a PTAS for Steiner\nforest on graphs of bounded treewidth. Surprisingly, Steiner forest is NP-hard\neven on graphs of treewidth 3. Therefore, our PTAS for bounded treewidth graph\nneeds a nontrivial combination of approximation arguments and dynamic\nprogramming on the tree decomposition. We further show that Steiner forest can\nbe solved in polynomial time for series-parallel graphs (graphs of treewidth at\nmost two) by a novel combination of dynamic programming and minimum cut\ncomputations, completing our thorough complexity study of Steiner forest in the\nrange of bounded treewidth graphs, planar graphs, and bounded genus graphs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2009 19:19:53 GMT"}], "update_date": "2009-11-30", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "0911.5384", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin and Mark Jones", "title": "Note on Max Lin-2 above Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Max Lin-2 problem we are given a system $S$ of $m$ linear equations in\n$n$ variables over $\\mathbb{F}_2$ in which Equation $j$ is assigned a positive\nintegral weight $w_j$ for each $j$. We wish to find an assignment of values to\nthe variables which maximizes the total weight of satisfied equations. This\nproblem generalizes Max Cut. The expected weight of satisfied equations is\n$W/2$, where $W=w_1+... +w_m$; $W/2$ is a tight lower bound on the optimal\nsolution of Max Lin-2.\n  Mahajan et al. (J. Comput. Syst. Sci. 75, 2009) stated the following\nparameterized version of Max Lin-2: decide whether there is an assignment of\nvalues to the variables that satisfies equations of total weight at least\n$W/2+k$, where $k$ is the parameter. They asked whether this parameterized\nproblem is fixed-parameter tractable, i.e., can be solved in time\n$f(k)(nm)^{O(1)}$, where $f(k)$ is an arbitrary computable function in $k$\nonly. Their question remains open, but using some probabilistic inequalities\nand, in one case, a Fourier analysis inequality, Gutin et al. (IWPEC 2009)\nproved that the problem is fixed-parameter tractable in three special cases.\n  In this paper we significantly extend two of the three special cases using\nonly tools from combinatorics. We show that one of our results can be used to\nobtain a combinatorial proof that another problem from Mahajan et al. (J.\nComput. Syst. Sci. 75, 2009), Max $r$-SAT above the Average, is fixed-parameter\ntractable for each $r\\ge 2.$ Note that Max $r$-SAT above the Average has been\nalready shown to be fixed-parameter tractable by Alon et al. (SODA 2010), but\nthe paper used the approach of Gutin et al. (IWPEC 2009).\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 15:59:51 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""]]}, {"id": "0911.5526", "submitter": "Moritz Hardt", "authors": "Boaz Barak, Moritz Hardt, Thomas Holenstein, David Steurer", "title": "Subsampling Mathematical Relaxations and Average-case Complexity", "comments": "Includes several more general results that subsume the previous\n  version of the paper.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of when the value of mathematical relaxations such as\nlinear and semidefinite programs for constraint satisfaction problems (CSPs) is\napproximately preserved when restricting the instance to a sub-instance induced\nby a small random subsample of the variables. Let $C$ be a family of CSPs such\nas 3SAT, Max-Cut, etc., and let $\\Pi$ be a relaxation for $C$, in the sense\nthat for every instance $P\\in C$, $\\Pi(P)$ is an upper bound the maximum\nfraction of satisfiable constraints of $P$. Loosely speaking, we say that\nsubsampling holds for $C$ and $\\Pi$ if for every sufficiently dense instance $P\n\\in C$ and every $\\epsilon>0$, if we let $P'$ be the instance obtained by\nrestricting $P$ to a sufficiently large constant number of variables, then\n$\\Pi(P') \\in (1\\pm \\epsilon)\\Pi(P)$. We say that weak subsampling holds if the\nabove guarantee is replaced with $\\Pi(P')=1-\\Theta(\\gamma)$ whenever\n$\\Pi(P)=1-\\gamma$. We show: 1. Subsampling holds for the BasicLP and BasicSDP\nprograms. BasicSDP is a variant of the relaxation considered by Raghavendra\n(2008), who showed it gives an optimal approximation factor for every CSP under\nthe unique games conjecture. BasicLP is the linear programming analog of\nBasicSDP. 2. For tighter versions of BasicSDP obtained by adding additional\nconstraints from the Lasserre hierarchy, weak subsampling holds for CSPs of\nunique games type. 3. There are non-unique CSPs for which even weak subsampling\nfails for the above tighter semidefinite programs. Also there are unique CSPs\nfor which subsampling fails for the Sherali-Adams linear programming hierarchy.\nAs a corollary of our weak subsampling for strong semidefinite programs, we\nobtain a polynomial-time algorithm to certify that random geometric graphs (of\nthe type considered by Feige and Schechtman, 2002) of max-cut value $1-\\gamma$\nhave a cut value at most $1-\\gamma/10$.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2009 23:23:38 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2010 21:35:23 GMT"}], "update_date": "2010-05-03", "authors_parsed": [["Barak", "Boaz", ""], ["Hardt", "Moritz", ""], ["Holenstein", "Thomas", ""], ["Steurer", "David", ""]]}, {"id": "0911.5660", "submitter": "Katarzyna Paluch", "authors": "Katarzyna Paluch", "title": "Faster and simpler approximation of stable matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a 3/2-approximation algorithm for stable matchings that runs in\n$O(m)$ time. The previously best known algorithm by McDermid has the same\napproximation ratio but runs in $O(n^{3/2}m)$ time, where $n$ denotes the\nnumber of people and $m$ is the total length of the preference lists in a given\ninstance. Also the algorithm and the analysis are much simpler. We also give\nthe extension of the algorithm for the many-to-many setting.\n  (This is the version of the paper from March 2011)\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 14:44:35 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2010 18:19:04 GMT"}, {"version": "v3", "created": "Thu, 31 Mar 2011 18:39:52 GMT"}, {"version": "v4", "created": "Fri, 1 Jul 2011 15:51:41 GMT"}, {"version": "v5", "created": "Fri, 4 Apr 2014 07:43:22 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["Paluch", "Katarzyna", ""]]}]