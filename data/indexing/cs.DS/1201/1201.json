[{"id": "1201.0066", "submitter": "Muhammad Jawaherul Alam", "authors": "Md. Jawaherul Alam, Therese Biedl, Stefan Felsner, Michael Kaufmann,\n  Stephen G. Kobourov and Torsten Ueckerdt", "title": "Computing Cartograms with Optimal Complexity", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a rectilinear dual of a planar graph vertices are represented by simple\nrectilinear polygons and edges are represented by side-contact between the\ncorresponding polygons. A rectilinear dual is called a cartogram if the area of\neach region is equal to a pre-specified weight of the corresponding vertex. The\ncomplexity of a cartogram is determined by the maximum number of corners (or\nsides) required for any polygon. In a series of papers the polygonal complexity\nof such representations for maximal planar graphs has been reduced from the\ninitial 40 to 34, then to 12 and very recently to the currently best known 10.\nHere we describe a construction with 8-sided polygons, which is optimal in\nterms of polygonal complexity as 8-sided polygons are sometimes necessary.\nSpecifically, we show how to compute the combinatorial structure and how to\nrefine the representation into an area-universal rectangular layout in linear\ntime. The exact cartogram can be computed from the area-universal rectangular\nlayout with numerical iteration, or can be approximated with a hill-climbing\nheuristic.\n  We also describe an alternative construction for Hamiltonian maximal planar\ngraphs, which allows us to directly compute the cartograms in linear time.\nMoreover, we prove that even for Hamiltonian graphs 8-sided rectilinear\npolygons are necessary, by constructing a non-trivial lower bound example. The\ncomplexity of the cartograms can be reduced to 6 if the Hamiltonian path has\nthe extra property that it is one-legged, as in outer-planar graphs. Thus, we\nhave optimal representations (in terms of both polygonal complexity and running\ntime) for Hamiltonian maximal planar and maximal outer-planar graphs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 05:44:30 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Alam", "Md. Jawaherul", ""], ["Biedl", "Therese", ""], ["Felsner", "Stefan", ""], ["Kaufmann", "Michael", ""], ["Kobourov", "Stephen G.", ""], ["Ueckerdt", "Torsten", ""]]}, {"id": "1201.0073", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis", "title": "On Truncated-SVD-like Sparse Solutions to Least-Squares Problems of\n  Arbitrary Dimensions", "comments": "This paper has been withdrawn by the author. This article has been\n  replaced by another submission: arXiv:1312.7499", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two algorithms for computing a sparse solution to a least-squares\nproblem where the coefficient matrix can have arbitrary dimensions. We show\nthat the solution vector obtained by our algorithms is close to the solution\nvector obtained via the truncated SVD approach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 06:38:56 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 19:43:25 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Boutsidis", "Christos", ""]]}, {"id": "1201.0127", "submitter": "Christos Boutsidis", "authors": "Haim Avron, Christos Boutsidis", "title": "Faster Subset Selection for Matrices and Applications", "comments": "To appear in SIAM Journal on Matrix Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study subset selection for matrices defined as follows: given a matrix\n$\\matX \\in \\R^{n \\times m}$ ($m > n$) and an oversampling parameter $k$ ($n \\le\nk \\le m$), select a subset of $k$ columns from $\\matX$ such that the\npseudo-inverse of the subsampled matrix has as smallest norm as possible. In\nthis work, we focus on the Frobenius and the spectral matrix norms. We describe\nseveral novel (deterministic and randomized) approximation algorithms for this\nproblem with approximation bounds that are optimal up to constant factors.\nAdditionally, we show that the combinatorial problem of finding a low-stretch\nspanning tree in an undirected graph corresponds to subset selection, and\ndiscuss various implications of this reduction.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 13:54:29 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 16:52:43 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2012 20:53:05 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2013 21:05:56 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Avron", "Haim", ""], ["Boutsidis", "Christos", ""]]}, {"id": "1201.0253", "submitter": "Sumit Ganguly", "authors": "Sumit Ganguly", "title": "A Lower Bound for Estimating High Moments of a Data Stream", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an improved lower bound for the Fp estimation problem in a data\nstream setting for p>2. A data stream is a sequence of items from the domain\n[n] with possible repetitions. The frequency vector x is an n-dimensional\nnon-negative integer vector x such that x(i) is the number of occurrences of i\nin the sequence. Given an accuracy parameter Omega(n^{-1/p}) < \\epsilon < 1,\nthe problem of estimating Fp is to estimate \\norm{x}_p^p = \\sum_{i \\in [n]}\n\\abs{x(i)}^p correctly to within a relative accuracy of 1\\pm \\epsilon with high\nconstant probability in an online fashion and using as little space as\npossible. The current space lower bound for this problem is Omega(n^{1-2/p}\n\\epsilon^{-2/p}+ n^{1-2/p}\\epsilon^{-4/p}/ \\log^{O(1)}(n)+ (\\epsilon^{-2} +\n\\log (n))). The first term in the lower bound expression was proved in\n\\cite{B-YJKS:stoc02,cks:ccc03}, the second in \\cite{wz:arxiv11} and the third\nin \\cite{wood:soda04}. In this note, we show an Omega(p^2 n^{1-2/p}\n\\epsilon^{-2}/\\log (n)) bits space bound, for Omega(pn^{-1/p}) \\le \\epsilon \\le\n1/10.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2011 12:56:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Ganguly", "Sumit", ""]]}, {"id": "1201.0365", "submitter": "Anthony Labarre", "authors": "Anthony Labarre", "title": "Lower bounding edit distances between permutations", "comments": null, "journal-ref": "SIAM Journal on Discrete Mathematics 27 (3), 1410-1428 (2013)", "doi": "10.1137/13090897X", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of fields, including the study of genome rearrangements and the\ndesign of interconnection networks, deal with the connected problems of sorting\npermutations in \"as few moves as possible\", using a given set of allowed\noperations, or computing the number of moves the sorting process requires,\noften referred to as the \\emph{distance} of the permutation. These operations\noften act on just one or two segments of the permutation, e.g. by reversing one\nsegment or exchanging two segments. The \\emph{cycle graph} of the permutation\nto sort is a fundamental tool in the theory of genome rearrangements, and has\nproved useful in settling the complexity of many variants of the above\nproblems. In this paper, we present an algebraic reinterpretation of the cycle\ngraph of a permutation $\\pi$ as an even permutation $\\bar{\\pi}$, and show how\nto reformulate our sorting problems in terms of particular factorisations of\nthe latter permutation. Using our framework, we recover known results in a\nsimple and unified way, and obtain a new lower bound on the \\emph{prefix\ntransposition distance} (where a \\emph{prefix transposition} displaces the\ninitial segment of a permutation), which is shown to outperform previous\nresults. Moreover, we use our approach to improve the best known lower bound on\nthe \\emph{prefix transposition diameter} from $2n/3$ to $\\lfloor3n/4\\rfloor$,\nand investigate a few relations between some statistics on $\\pi$ and\n$\\bar{\\pi}$.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 17:38:06 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Labarre", "Anthony", ""]]}, {"id": "1201.0432", "submitter": "Haris Aziz", "authors": "Haris Aziz and Markus Brill and Paul Harrenstein", "title": "Testing Substitutability of Weak Preferences", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many-to-many matching models, substitutable preferences constitute the\nlargest domain for which a pairwise stable matching is guaranteed to exist. In\nthis note, we extend the recently proposed algorithm of Hatfield et al. [3] to\ntest substitutability of weak preferences. Interestingly, the algorithm is\nfaster than the algorithm of Hatfield et al. by a linear factor on the domain\nof strict preferences.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 07:06:30 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Aziz", "Haris", ""], ["Brill", "Markus", ""], ["Harrenstein", "Paul", ""]]}, {"id": "1201.0749", "submitter": "Gary McGuire", "authors": "Gary McGuire, Bastian Tugemann, Gilles Civario", "title": "There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues\n  Problem", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sudoku minimum number of clues problem is the following question: what is\nthe smallest number of clues that a sudoku puzzle can have? For several years\nit had been conjectured that the answer is 17. We have performed an exhaustive\ncomputer search for 16-clue sudoku puzzles, and did not find any, thus proving\nthat the answer is indeed 17. In this article we describe our method and the\nactual search. As a part of this project we developed a novel way for\nenumerating hitting sets. The hitting set problem is computationally hard; it\nis one of Karp's 21 classic NP-complete problems. A standard backtracking\nalgorithm for finding hitting sets would not be fast enough to search for a\n16-clue sudoku puzzle exhaustively, even at today's supercomputer speeds. To\nmake an exhaustive search possible, we designed an algorithm that allowed us to\nefficiently enumerate hitting sets of a suitable size.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 19:04:10 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2013 16:43:56 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["McGuire", "Gary", ""], ["Tugemann", "Bastian", ""], ["Civario", "Gilles", ""]]}, {"id": "1201.0940", "submitter": "Mathilde Bouvel", "authors": "Mathilde Bouvel, Cedric Chauve, Marni Mishna, Dominique Rossin", "title": "Average-case analysis of perfect sorting by reversals (Journal Version)", "comments": "A preliminary version of this work appeared in the proceedings of\n  Combinatorial Pattern Matching (CPM) 2009. See arXiv:0901.2847; Discrete\n  Mathematics, Algorithms and Applications, vol. 3(3), 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perfect sorting by reversals, a problem originating in computational\ngenomics, is the process of sorting a signed permutation to either the identity\nor to the reversed identity permutation, by a sequence of reversals that do not\nbreak any common interval. B\\'erard et al. (2007) make use of strong interval\ntrees to describe an algorithm for sorting signed permutations by reversals.\nCombinatorial properties of this family of trees are essential to the algorithm\nanalysis. Here, we use the expected value of certain tree parameters to prove\nthat the average run-time of the algorithm is at worst, polynomial, and\nadditionally, for sufficiently long permutations, the sorting algorithm runs in\npolynomial time with probability one. Furthermore, our analysis of the subclass\nof commuting scenarios yields precise results on the average length of a\nreversal, and the average number of reversals.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 17:28:57 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Bouvel", "Mathilde", ""], ["Chauve", "Cedric", ""], ["Mishna", "Marni", ""], ["Rossin", "Dominique", ""]]}, {"id": "1201.1157", "submitter": "Krasimir Yordzhev", "authors": "Krasimir Yordzhev and Ana Markovska", "title": "Method of the Multidimensional Sieve in the Practical Realization of\n  some Combinatorial Algorithms", "comments": null, "journal-ref": "International scientific conference \"UNITECH 07\", Gabrovo,\n  Bulgaria, vol. II, 2007, 451-456", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some difficulties regarding the application of the well-known sieve method\nare considered in the case when a practical (program) realization of selecting\nelements, having a particular property among the elements of a set with a\nsufficiently great cardinal number(cardinality). In this paper the problem has\nbeen resolved by using a modified version of the method, utilizing\nmultidimensional arrays. As a theoretical illustration of the method of the\nmultidimensional sieve, the problem of obtaining a single representative of\neach equivalence class with respect to a given relation of equivalence and\nobtaining the cardinality of the respective factor set is considered with\nrelevant mathematical proofs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 12:54:30 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Yordzhev", "Krasimir", ""], ["Markovska", "Ana", ""]]}, {"id": "1201.1214", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, Ying\n  Xiao", "title": "Statistical Algorithms and a Lower Bound for Detecting Planted Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for proving lower bounds on computational problems\nover distributions against algorithms that can be implemented using access to a\nstatistical query oracle. For such algorithms, access to the input distribution\nis limited to obtaining an estimate of the expectation of any given function on\na sample drawn randomly from the input distribution, rather than directly\naccessing samples. Most natural algorithms of interest in theory and in\npractice, e.g., moments-based methods, local search, standard iterative methods\nfor convex optimization, MCMC and simulated annealing can be implemented in\nthis framework. Our framework is based on, and generalizes, the statistical\nquery model in learning theory (Kearns, 1998).\n  Our main application is a nearly optimal lower bound on the complexity of any\nstatistical query algorithm for detecting planted bipartite clique\ndistributions (or planted dense subgraph distributions) when the planted clique\nhas size $O(n^{1/2-\\delta})$ for any constant $\\delta > 0$. The assumed\nhardness of variants of these problems has been used to prove hardness of\nseveral other problems and as a guarantee for security in cryptographic\napplications. Our lower bounds provide concrete evidence of hardness, thus\nsupporting these assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 16:39:21 GMT"}, {"version": "v2", "created": "Wed, 9 May 2012 19:34:30 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2013 03:54:58 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2013 15:08:58 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2015 17:38:56 GMT"}, {"version": "v6", "created": "Mon, 15 Aug 2016 01:17:38 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Feldman", "Vitaly", ""], ["Grigorescu", "Elena", ""], ["Reyzin", "Lev", ""], ["Vempala", "Santosh", ""], ["Xiao", "Ying", ""]]}, {"id": "1201.1363", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla and Gopal Pandurangan", "title": "Near-Optimal Random Walk Sampling in Distributed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing random walks in networks is a fundamental primitive that has found\nnumerous applications in communication networks such as token management, load\nbalancing, network topology discovery and construction, search, and\npeer-to-peer membership management. While several such algorithms are\nubiquitous, and use numerous random walk samples, the walks themselves have\nalways been performed naively.\n  In this paper, we focus on the problem of performing random walk sampling\nefficiently in a distributed network. Given bandwidth constraints, the goal is\nto minimize the number of rounds and messages required to obtain several random\nwalk samples in a continuous online fashion. We present the first round and\nmessage optimal distributed algorithms that present a significant improvement\non all previous approaches. The theoretical analysis and comprehensive\nexperimental evaluation of our algorithms show that they perform very well in\ndifferent types of networks of differing topologies.\n  In particular, our results show how several random walks can be performed\ncontinuously (when source nodes are provided only at runtime, i.e., online),\nsuch that each walk of length $\\ell$ can be performed exactly in just\n$\\tilde{O}(\\sqrt{\\ell D})$ rounds, (where $D$ is the diameter of the network),\nand $O(\\ell)$ messages. This significantly improves upon both, the naive\ntechnique that requires $O(\\ell)$ rounds and $O(\\ell)$ messages, and the\nsophisticated algorithm of [DasSarma et al. PODC 2010] that has the same round\ncomplexity as this paper but requires $\\Omega(m\\sqrt{\\ell})$ messages (where\n$m$ is the number of edges in the network). Our theoretical results are\ncorroborated through extensive experiments on various topological data sets.\nOur algorithms are fully decentralized, lightweight, and easily implementable,\nand can serve as building blocks in the design of topologically-aware networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 08:16:45 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2012 16:32:42 GMT"}], "update_date": "2012-01-12", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1201.1465", "submitter": "Krasimir Yordzhev", "authors": "Krasimir Yordzhev and Hristina Kostadinova", "title": "Mathematical Modeling of the Weaving Structure Design", "comments": "Proceedings of the Thirty Ninth Spring Conference of the Union of\n  Bulgarian Mathematicians, Albena, April 6-10, 2010", "journal-ref": "Mathematics and education in mathematics, v. 39, 2010, 212-220", "doi": null, "report-no": null, "categories": "math.RT cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An equivalence relation in the set of all square binary matrices is described\nin this work. It is discussed a combinatoric problem about finding the cardinal\nnumber and the elements of the factor set according to this relation. We\nexamine the possibility to get some special elements of this factor set. We\npropose an algorithm, which solves these problems. The results we have received\nare used to describe the topology of the different weaving structures.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 18:29:11 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Yordzhev", "Krasimir", ""], ["Kostadinova", "Hristina", ""]]}, {"id": "1201.1530", "submitter": "Ali Pinar", "authors": "Richard Li-Yang Chen, Amy Cohn, Neng Fan, Ali Pinar", "title": "N-k-e Survivable Power System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing (or augmenting) an electric power system\nsuch that it satisfies the N-k-e survivability criterion while minimizing total\ncost. The survivability criterion requires that at least (1-e) fraction of the\ntotal demand can still be met even if any k (or fewer) of the system components\nfail. We formulate this problem, taking into account both transmission and\ngeneration expansion planning, as a mixed-integer program. Two algorithms are\ndesigned and tested on modified instances from the IEEE-30-Bus and IEEE- 57-Bus\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jan 2012 04:33:37 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Chen", "Richard Li-Yang", ""], ["Cohn", "Amy", ""], ["Fan", "Neng", ""], ["Pinar", "Ali", ""]]}, {"id": "1201.1707", "submitter": "James Chappell", "authors": "James M. Chappell, M. A. Lohe, Lorenz von Smekal, Azhar Iqbal and\n  Derek Abbot", "title": "An improved formalism for the Grover search algorithm", "comments": "15 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grover search algorithm is one of the two key algorithms in the field of\nquantum computing, and hence it is of significant interest to describe it in\nthe most efficient mathematical formalism. We show firstly, that Clifford's\nformalism of geometric algebra, provides a significantly more efficient\nrepresentation than the conventional Bra-ket notation, and secondly, that the\nbasis defined by the states of maximum and minimum weight in the Grover search\nspace, allows a simple visualization of the Grover search as the precession of\na spin-1/2 particle. Using this formalism we efficiently solve the exact search\nproblem, as well as easily representing more general search situations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 08:28:21 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Chappell", "James M.", ""], ["Lohe", "M. A.", ""], ["von Smekal", "Lorenz", ""], ["Iqbal", "Azhar", ""], ["Abbot", "Derek", ""]]}, {"id": "1201.1784", "submitter": "Stephane Martin", "authors": "St\\'ephane Martin (INRIA Lorraine - LORIA), Mehdi Ahmed-Nacer (INRIA\n  Lorraine - LORIA), Pascal Urso (INRIA Lorraine - LORIA)", "title": "Abstract unordered and ordered trees CRDT", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7825", "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trees are fundamental data structure for many areas of computer science and\nsystem engineering. In this report, we show how to ensure eventual consistency\nof optimistically replicated trees. In optimistic replication, the different\nreplicas of a distributed system are allowed to diverge but should eventually\nreach the same value if no more mutations occur. A new method to ensure\neventual consistency is to design Conflict-free Replicated Data Types (CRDT).\nIn this report, we design a collection of tree CRDT using existing set CRDTs.\nThe remaining concurrency problems particular to tree data structure are\nresolved using one or two layers of correction algorithm. For each of these\nlayer, we propose different and independent policies. Any combination of set\nCRDT and policies can be constructed, giving to the distributed application\nprogrammer the entire control of the behavior of the shared data in face of\nconcurrent mutations. We also propose to order these trees by adding a\npositioning layer which is also independent to obtain a collection of ordered\ntree CRDTs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 14:42:45 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Martin", "St\u00e9phane", "", "INRIA Lorraine - LORIA"], ["Ahmed-Nacer", "Mehdi", "", "INRIA\n  Lorraine - LORIA"], ["Urso", "Pascal", "", "INRIA Lorraine - LORIA"]]}, {"id": "1201.1869", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and Marcin Pilipczuk and Micha{\\l} Pilipczuk and Jakub\n  Onufry Wojtaszczyk", "title": "Sitting closer to friends than enemies, revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed graphs, i.e., undirected graphs with edges labelled with a plus or\nminus sign, are commonly used to model relationships in social networks.\nRecently, Kermarrec and Thraves initiated the study of the problem of\nappropriately visualising the network: They asked whether any signed graph can\nbe embedded into the metric space R^l in such a manner that every vertex is\ncloser to all its friends (neighbours via positive edges) than to all its\nenemies (neighbours via negative edges). Interestingly, embeddability into R^1\ncan be expressed as a purely combinatorial problem. In this paper we pursue a\ndeeper study of this particular case, answering several questions posed by\nKermarrec and Thraves.\n  First, we refine the approach of Kermarrec and Thraves for the case of\ncomplete signed graphs by showing that the problem is closely related to the\nrecognition of proper interval graphs. Second, we prove that the general case,\nwhose polynomial-time tractability remained open, is in fact NP-complete.\nFinally, we provide lower and upper bounds for the time complexity of the\ngeneral case: we prove that the existence of a subexponential time (in the\nnumber of vertices and edges of the input signed graph) algorithm would violate\nthe Exponential Time Hypothesis, whereas a simple dynamic programming approach\ngives a running time single-exponential in the number of vertices.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 18:45:36 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Cygan", "Marek", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Wojtaszczyk", "Jakub Onufry", ""]]}, {"id": "1201.1870", "submitter": "Andr\\'as Seb\\H{o}", "authors": "Andr\\'as Seb\\H{o} and Jens Vygen", "title": "Shorter Tours by Nicer Ears: 7/5-approximation for graphic TSP, 3/2 for\n  the path version, and 4/3 for two-edge-connected subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new results for approximating the graphic TSP and some related\nproblems. We obtain polynomial-time algorithms with improved approximation\nguarantees.\n  For the graphic TSP itself, we improve the approximation ratio to 7/5. For a\ngeneralization, the connected-$T$-join problem, we obtain the first nontrivial\napproximation algorithm, with ratio 3/2. This contains the graphic\n$s$-$t$-path-TSP as a special case. Our improved approximation guarantee for\nfinding a smallest 2-edge-connected spanning subgraph is 4/3.\n  The key new ingredient of all our algorithms is a special kind of\near-decomposition optimized using forest representations of hypergraphs. The\nsame methods also provide the lower bounds (arising from LP relaxations) that\nwe use to deduce the approximation ratios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 18:51:39 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2012 14:31:14 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2012 09:50:46 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Seb\u0151", "Andr\u00e1s", ""], ["Vygen", "Jens", ""]]}, {"id": "1201.2000", "submitter": "Ondrej Moris", "authors": "Petr Hlineny, Ondrej Moris", "title": "Dynamic Scope-Based Dijkstra's Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We briefly report on the current state of a new dynamic algorithm for the\nroute planning problem based on a concept of scope (the static variant\npresented at ESA'11, HM2011A). We first motivate dynamization of the concept of\nscope admissibility, and then we briefly describe a modification of the\nscope-aware query algorithm of HM2011A to dynamic road networks. Finally, we\noutline our future work on this concept.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 10:11:11 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Hlineny", "Petr", ""], ["Moris", "Ondrej", ""]]}, {"id": "1201.2116", "submitter": "David Harvey", "authors": "Edgar Costa, David Harvey", "title": "Faster deterministic integer factorization", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best known unconditional deterministic complexity bound for computing the\nprime factorization of an integer N is O(M_int(N^(1/4) log N)), where M_int(k)\ndenotes the cost of multiplying k-bit integers. This result is due to\nBostan--Gaudry--Schost, following the Pollard--Strassen approach. We show that\nthis bound can be improved by a factor of (log log N)^(1/2).\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 17:19:03 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Costa", "Edgar", ""], ["Harvey", "David", ""]]}, {"id": "1201.2261", "submitter": "Dan Petrovic", "authors": "Dan Petrovic", "title": "Relationships in Large-Scale Graph Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In 2009 Grzegorz Czajkowski from Google's system infrastructure team has\npublished an article which didn't get much attention in the SEO community at\nthe time. It was titled \"Large-scale graph computing at Google\" and gave an\nexcellent insight into the future of Google's search. This article highlights\nsome of the little known facts which lead to transformation of Google's\nalgorithm in the last two years.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 08:37:50 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Petrovic", "Dan", ""]]}, {"id": "1201.2474", "submitter": "Yibei Ling", "authors": "Yibei Ling, Scott Alexander, Richard Lau", "title": "On Quantification of Anchor Placement", "comments": "infocom 1012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to answer a question: for a given traversal area, how to\nquantify the geometric impact of anchor placement on localization performance.\nWe present a theoretical framework for quantifying the anchor placement impact.\nAn experimental study, as well as the field test using a UWB ranging\ntechnology, is presented. These experimental results validate the theoretical\nanalysis. As a byproduct, we propose a two-phase localization method (TPLM) and\nshow that TPLM outperforms the least-square method in localization accuracy by\na huge margin. TPLM performs much faster than the gradient descent method and\nslightly better than the gradient descent method in localization accuracy. Our\nfield test suggests that TPLM is more robust against noise than the\nleast-square and gradient descent methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 04:20:46 GMT"}], "update_date": "2012-01-13", "authors_parsed": [["Ling", "Yibei", ""], ["Alexander", "Scott", ""], ["Lau", "Richard", ""]]}, {"id": "1201.2501", "submitter": "Eric Price", "authors": "Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price", "title": "Nearly Optimal Sparse Fourier Transform", "comments": "28 pages, appearing at STOC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider the problem of computing the k-sparse approximation to the\ndiscrete Fourier transform of an n-dimensional signal. We show:\n  * An O(k log n)-time randomized algorithm for the case where the input signal\nhas at most k non-zero Fourier coefficients, and\n  * An O(k log n log(n/k))-time randomized algorithm for general input signals.\n  Both algorithms achieve o(n log n) time, and thus improve over the Fast\nFourier Transform, for any k = o(n). They are the first known algorithms that\nsatisfy this property. Also, if one assumes that the Fast Fourier Transform is\noptimal, the algorithm for the exactly k-sparse case is optimal for any k =\nn^{\\Omega(1)}.\n  We complement our algorithmic results by showing that any algorithm for\ncomputing the sparse Fourier transform of a general signal must use at least\n\\Omega(k log(n/k)/ log log n) signal samples, even if it is allowed to perform\nadaptive sampling.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 08:34:46 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2012 17:18:56 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Hassanieh", "Haitham", ""], ["Indyk", "Piotr", ""], ["Katabi", "Dina", ""], ["Price", "Eric", ""]]}, {"id": "1201.2702", "submitter": "Spyros Sioutas SS", "authors": "Gerth St{\\o}lting Brodal, Alexis C. Kaporis, Apostolos N.\n  Papadopoulos, Spyros Sioutas, Konstantinos Tsakalidis, Kostas Tsichlas", "title": "Dynamic 3-sided Planar Range Queries with Expected Doubly Logarithmic\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of 2-dimensional searching for the 3-sided\nrange query of the form $[a, b]\\times (-\\infty, c]$ in both main and external\nmemory, by considering a variety of input distributions. We present three sets\nof solutions each of which examines the 3-sided problem in both RAM and I/O\nmodel respectively. The presented data structures are deterministic and the\nexpectation is with respect to the input distribution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 23:00:21 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Brodal", "Gerth St\u00f8lting", ""], ["Kaporis", "Alexis C.", ""], ["Papadopoulos", "Apostolos N.", ""], ["Sioutas", "Spyros", ""], ["Tsakalidis", "Konstantinos", ""], ["Tsichlas", "Kostas", ""]]}, {"id": "1201.2703", "submitter": "Rachit Agarwal", "authors": "Rachit Agarwal, P. Brighten Godfrey, Sariel Har-Peled", "title": "Faster Approximate Distance Queries and Compact Routing in Sparse Graphs", "comments": "20 pages, an earlier version appeared in INFOCOM 2011, this version\n  presents data structures with improved space/query-time trade-off", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distance oracle is a compact representation of the shortest distance matrix\nof a graph. It can be queried to approximate shortest paths between any pair of\nvertices. Any distance oracle that returns paths of worst-case stretch (2k-1)\nmust require space $\\Omega(n^{1 + 1/k})$ for graphs of n nodes. The hard cases\nthat enforce this lower bound are, however, rather dense graphs with average\ndegree \\Omega(n^{1/k}).\n  We present distance oracles that, for sparse graphs, substantially break the\nlower bound barrier at the expense of higher query time. For any 1 \\leq \\alpha\n\\leq n, our distance oracles can return stretch 2 paths using O(m + n^2/\\alpha)\nspace and stretch 3 paths using O(m + n^2/\\alpha^2) space, at the expense of\nO(\\alpha m/n) query time. By setting appropriate values of \\alpha, we get the\nfirst distance oracles that have size linear in the size of the graph, and\nreturn constant stretch paths in non-trivial query time. The query time can be\nfurther reduced to O(\\alpha), by using an additional O(m \\alpha) space for all\nour distance oracles, or at the cost of a small constant additive stretch.\n  We use our stretch 2 distance oracle to present the first compact routing\nscheme with worst-case stretch 2. Any compact routing scheme with stretch less\nthan 2 must require linear memory at some nodes even for sparse graphs; our\nscheme, hence, achieves the optimal stretch with non-trivial memory\nrequirements. Moreover, supported by large-scale simulations on graphs\nincluding the AS-level Internet graph, we argue that our stretch-2 scheme would\nbe simple and efficient to implement as a distributed compact routing protocol.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 23:03:18 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Agarwal", "Rachit", ""], ["Godfrey", "P. Brighten", ""], ["Har-Peled", "Sariel", ""]]}, {"id": "1201.2715", "submitter": "He Sun", "authors": "Thomas Sauerwald and He Sun", "title": "Tight Bounds for Randomized Load Balancing on Arbitrary Network\n  Topologies", "comments": "74 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of balancing load items (tokens) in networks.\nStarting with an arbitrary load distribution, we allow nodes to exchange tokens\nwith their neighbors in each round. The goal is to achieve a distribution where\nall nodes have nearly the same number of tokens.\n  For the continuous case where tokens are arbitrarily divisible, most load\nbalancing schemes correspond to Markov chains, whose convergence is fairly\nwell-understood in terms of their spectral gap. However, in many applications,\nload items cannot be divided arbitrarily, and we need to deal with the discrete\ncase where the load is composed of indivisible tokens. This discretization\nentails a non-linear behavior due to its rounding errors, which makes this\nanalysis much harder than in the continuous case.\n  We investigate several randomized protocols for different communication\nmodels in the discrete case. As our main result, we prove that for any regular\nnetwork in the matching model, all nodes have the same load up to an additive\nconstant in (asymptotically) the same number of rounds as required in the\ncontinuous case. This generalizes and tightens the previous best result, which\nonly holds for expander graphs, and demonstrates that there is almost no\ndifference between the discrete and continuous cases. Our results also provide\na positive answer to the question of how well discrete load balancing can be\napproximated by (continuous) Markov chains, which has been posed by many\nresearchers.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 00:25:54 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 21:28:27 GMT"}, {"version": "v3", "created": "Mon, 10 Nov 2014 18:49:42 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Sauerwald", "Thomas", ""], ["Sun", "He", ""]]}, {"id": "1201.2739", "submitter": "Andrew Shallue", "authors": "Andrew Shallue", "title": "Division algorithms for the fixed weight subset sum problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given positive integers $a_1,..., a_n, t$, the fixed weight subset sum\nproblem is to find a subset of the $a_i$ that sum to $t$, where the subset has\na prescribed number of elements. It is this problem that underlies the security\nof modern knapsack cryptosystems, and solving the problem results directly in a\nmessage attack. We present new exponential algorithms that do not rely on\nlattices, and hence will be applicable when lattice basis reduction algorithms\nfail. These algorithms rely on a generalization of the notion of splitting\nsystem given by Stinson. In particular, if the problem has length $n$ and\nweight $\\ell$ then for constant $k$ a power of two less than $n$ we apply a\n$k$-set birthday algorithm to the splitting system of the problem. This\nrandomized algorithm has time and space complexity that satisfies $T \\cdot\nS^{\\log{k}} = O({n \\choose \\ell})$ (where the constant depends uniformly on\n$k$). In addition to using space efficiently, the algorithm is highly\nparallelizable.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 03:52:02 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Shallue", "Andrew", ""]]}, {"id": "1201.2780", "submitter": "Somnath Sikdar", "authors": "Alexander Langer and Felix Reidl and Peter Rossmanith and Somnath\n  Sikdar", "title": "Linear Kernels on Graphs Excluding Topological Minors", "comments": "19 pages. A simpler proof of the results of this paper appears in\n  http://arxiv.org/abs/1207.0835. This new paper contains additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that problems which have finite integer index and satisfy a\nrequirement we call treewidth-bounding admit linear kernels on the class of\n$H$-topological-minor free graphs, for an arbitrary fixed graph $H$. This\nbuilds on earlier results by Fomin et al.\\ on linear kernels for $H$-minor-free\ngraphs and by Bodlaender et al.\\ on graphs of bounded genus. Our framework\nencompasses several problems, the prominent ones being Chordal Vertex Deletion,\nFeedback Vertex Set and Edge Dominating Set.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 09:42:53 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 09:30:06 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2012 09:15:33 GMT"}, {"version": "v4", "created": "Fri, 13 Jul 2012 07:26:15 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Langer", "Alexander", ""], ["Reidl", "Felix", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1201.2892", "submitter": "Amir Ali Ahmadi", "authors": "Amir Ali Ahmadi", "title": "Algebraic Relaxations and Hardness Results in Polynomial Optimization\n  and Lyapunov Analysis", "comments": "PhD Thesis, MIT, September, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis settles a number of questions related to computational complexity\nand algebraic, semidefinite programming based relaxations in optimization and\ncontrol.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 16:34:57 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Ahmadi", "Amir Ali", ""]]}, {"id": "1201.2934", "submitter": "Qiao Li", "authors": "Qiao Li, Tao Cui, Yang Weng, Rohit Negi, Franz Franchetti, Marija D.\n  Ilic", "title": "An Information-Theoretic Approach to PMU Placement in Electric Power\n  Systems", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an information-theoretic approach to address the phasor\nmeasurement unit (PMU) placement problem in electric power systems. Different\nfrom the conventional 'topological observability' based approaches, this paper\nadvocates a much more refined, information-theoretic criterion, namely the\nmutual information (MI) between the PMU measurements and the power system\nstates. The proposed MI criterion can not only include the full system\nobservability as a special case, but also can rigorously model the remaining\nuncertainties in the power system states with PMU measurements, so as to\ngenerate highly informative PMU configurations. Further, the MI criterion can\nfacilitate robust PMU placement by explicitly modeling probabilistic PMU\noutages. We propose a greedy PMU placement algorithm, and show that it achieves\nan approximation ratio of (1-1/e) for any PMU placement budget. We further show\nthat the performance is the best that one can achieve in practice, in the sense\nthat it is NP-hard to achieve any approximation ratio beyond (1-1/e). Such\nperformance guarantee makes the greedy algorithm very attractive in the\npractical scenario of multi-stage installations for utilities with limited\nbudgets. Finally, simulation results demonstrate near-optimal performance of\nthe proposed PMU placement algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 20:57:20 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Li", "Qiao", ""], ["Cui", "Tao", ""], ["Weng", "Yang", ""], ["Negi", "Rohit", ""], ["Franchetti", "Franz", ""], ["Ilic", "Marija D.", ""]]}, {"id": "1201.2936", "submitter": "Stanley Tzeng", "authors": "Stanley Tzeng and John D. Owens", "title": "Finding Convex Hulls Using Quickhull on the GPU", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convex hull algorithm that is accelerated on commodity graphics\nhardware. We analyze and identify the hurdles of writing a recursive divide and\nconquer algorithm on the GPU and divise a framework for representing this class\nof problems. Our framework transforms the recursive splitting step into a\npermutation step that is well-suited for graphics hardware. Our convex hull\nalgorithm of choice is Quickhull. Our parallel Quickhull implementation (for\nboth 2D and 3D cases) achieves an order of magnitude speedup over standard\ncomputational geometry libraries.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 17:48:47 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Tzeng", "Stanley", ""], ["Owens", "John D.", ""]]}, {"id": "1201.2969", "submitter": "Ghazi Al-Naymat", "authors": "Ghazi Al-Naymat, Sanjay Chawla and Javid Taheri", "title": "SparseDTW: A Novel Approach to Speed up Dynamic Time Warping", "comments": "17 pages", "journal-ref": "Al-Naymat, G., S. Chawla, and J. Taheri, \"SparseDTW: A Novel\n  Approach to Speed up Dynamic Time Warping\", The 2009 Australasian Data\n  Mining, vol. 101, Melbourne, Australia, ACM Digital Library, pp. 117-127,\n  12/2009", "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a new space-efficient approach, (SparseDTW), to compute the\nDynamic Time Warping (DTW) distance between two time series that always yields\nthe optimal result. This is in contrast to other known approaches which\ntypically sacrifice optimality to attain space efficiency. The main idea behind\nour approach is to dynamically exploit the existence of similarity and/or\ncorrelation between the time series. The more the similarity between the time\nseries the less space required to compute the DTW between them. To the best of\nour knowledge, all other techniques to speedup DTW, impose apriori constraints\nand do not exploit similarity characteristics that may be present in the data.\nWe conduct experiments and demonstrate that SparseDTW outperforms previous\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 23:26:27 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Al-Naymat", "Ghazi", ""], ["Chawla", "Sanjay", ""], ["Taheri", "Javid", ""]]}, {"id": "1201.3011", "submitter": "Stephen G. Kobourov", "authors": "Stephen G. Kobourov", "title": "Spring Embedders and Force Directed Graph Drawing Algorithms", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Force-directed algorithms are among the most flexible methods for calculating\nlayouts of simple undirected graphs. Also known as spring embedders, such\nalgorithms calculate the layout of a graph using only information contained\nwithin the structure of the graph itself, rather than relying on\ndomain-specific knowledge. Graphs drawn with these algorithms tend to be\naesthetically pleasing, exhibit symmetries, and tend to produce crossing-free\nlayouts for planar graphs. In this survey we consider several classical\nalgorithms, starting from Tutte's 1963 barycentric method, and including recent\nscalable multiscale methods for large and dynamic graphs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2012 12:49:31 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Kobourov", "Stephen G.", ""]]}, {"id": "1201.3077", "submitter": "Joseph Gil", "authors": "Joseph Yossi Gil and David Allen Scott", "title": "A Bijective String Sorting Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a string of characters, the Burrows-Wheeler Transform rearranges the\ncharacters in it so as to produce another string of the same length which is\nmore amenable to compression techniques such as move to front, run-length\nencoding, and entropy encoders. We present a variant of the transform which\ngives rise to similar or better compression value, but, unlike the original,\nthe transform we present is bijective, in that the inverse transformation\nexists for all strings. Our experiments indicate that using our variant of the\ntransform gives rise to better compression ratio than the original\nBurrows-Wheeler transform. We also show that both the transform and its inverse\ncan be computed in linear time and consuming linear storage.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 10:17:36 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Gil", "Joseph Yossi", ""], ["Scott", "David Allen", ""]]}, {"id": "1201.3091", "submitter": "Robert Ganian", "authors": "Robert Ganian", "title": "Using Neighborhood Diversity to Solve Hard Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized algorithms are a very useful tool for dealing with NP-hard\nproblems on graphs. Yet, to properly utilize parameterized algorithms it is\nnecessary to choose the right parameter based on the type of problem and\nproperties of the target graph class. Tree-width is an example of a very\nsuccessful graph parameter, however it cannot be used on dense graph classes\nand there also exist problems which are hard even on graphs of bounded\ntree-width. Such problems can be tackled by using vertex cover as a parameter,\nhowever this places severe restrictions on admissible graph classes.\n  Michael Lampis has recently introduced neighborhood diversity, a new graph\nparameter which generalizes vertex cover to dense graphs. Among other results,\nhe has shown that simple parameterized algorithms exist for a few problems on\ngraphs of bounded neighborhood diversity. Our article further studies this area\nand provides new algorithms parameterized by neighborhood diversity for the\np-Vertex-Disjoint Paths, Graph Motif and Precoloring Extension problems -- the\nlatter two being hard even on graphs of bounded tree-width.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 14:52:50 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2012 13:13:47 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Ganian", "Robert", ""]]}, {"id": "1201.3184", "submitter": "Peng Zhang", "authors": "Peng Zhang", "title": "Partial Degree Bounded Edge Packing Problem", "comments": "9 pages. Being reviewed in FAW 2012. A model of edge packing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [1], whether a target binary string s can be represented from a boolean\nformula with operands chosen from a set of binary strings W was studied. In\nthis paper, we first examine selecting a maximum subset X from W, so that for\nany string t in X, t is not representable by X\\{t}. We rephrase this problem as\ngraph, and surprisingly find it give rise to a broad model of edge packing\nproblem, which itself falls into the model of forbidden subgraph problem.\nSpecifically, given a graph G(V;E) and a constant c, the problem asks to choose\nas many as edges to form a subgraph G'. So that in G', for each edge, at least\none of its endpoints has degree no more than c. We call such G' partial c\ndegree bounded. When c = 1, it turns out to be the complement of dominating\nset. We present several results about hardness, approximation for the general\ngraph and efficient exact algorithm on trees. This edge packing problem model\nalso has a direct interpretation in resource allocation. There are n types of\nresources and m jobs. Each job needs two types of resources. A job can be\naccomplished if either one of its necessary resources is shared by no more than\nc other jobs. The problem then asks to nish as many jobs as possible. We\nbelieve this partial degree bounded graph problem merits more attention.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 09:29:41 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Zhang", "Peng", ""]]}, {"id": "1201.3307", "submitter": "Erwan Le Martelot", "authors": "Erwan Le Martelot and Chris Hankin", "title": "Multi-scale Community Detection using Stability Optimisation within\n  Greedy Algorithms", "comments": "This paper is an extension of the paper named \"Multi-scale Community\n  Detection using Stability as Optimisation Criterion in a Greedy Algorithm\" by\n  the same authors published in Proc. of the 2011 Int. Conf. on Knowledge\n  Discovery and Information Retrieval (KDIR 2011), SciTePress, 2011, 216-225", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real systems can be represented as networks whose analysis can be very\ninformative regarding the original system's organisation. In the past decade\ncommunity detection received a lot of attention and is now an active field of\nresearch. Recently stability was introduced as a new measure for partition\nquality. This work investigates stability as an optimisation criterion that\nexploits a Markov process view of networks to enable multi-scale community\ndetection. Several heuristics and variations of an algorithm optimising\nstability are presented as well as an application to overlapping communities.\nExperiments show that the method enables accurate multi-scale network analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:25:09 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Martelot", "Erwan Le", ""], ["Hankin", "Chris", ""]]}, {"id": "1201.3318", "submitter": "Marcin Kik", "authors": "Marcin Kik", "title": "Notes on Bit-reversal Broadcast Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report contains revision and extension of some results about RBO\n[arXiv:1108.5095]. RBO is a simple and efficient broadcast scheduling of $n =\n2^k$ uniform frames for battery powered radio receivers. Each frame contains a\nkey from some arbitrary linearly ordered universe. The broadcast cycle -- a\nsequence of frames sorted by the keys and permuted by $k$-bit reversal -- is\ntransmitted in a round robin fashion by the broadcaster. At arbitrary time\nduring the transmission, the receiver may start a simple protocol that reports\nto him all the frames with the keys that are contained in a specified interval\nof the key values $[K', K\"]$. RBO receives at most $2 k + 1$ other frames' keys\nbefore receiving the first key from $[K', K\"]$ or noticing that there are no\nsuch keys in the broadcast cycle. As a simple corollary, $4 k + 2$ is upper\nbound the number of keys outside $[K', K\"]$ that will ever be received. In\nunreliable network the expected number of efforts to receive such frames is\nbounded by $(8 k + 4) / p + 2 (1 - p) / p^2$, where $p$ is probability of\nsuccessful reception, and the reception rate of the requested frames is $p$ --\nthe highest possible. The receiver's protocol state consists of the values $k$,\n$K'$ and $K\"$, one wake-up timer and two other $k$-bit variables. Its only\nnontrivial computation -- the computation of the next wake-up time slot -- can\nbe performed in $O (k)$ simple operations, such as arithmetic/bit-wise\noperations on $k$-bit numbers, using only constant number of $k$-bit variables.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:56:45 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Kik", "Marcin", ""]]}, {"id": "1201.3602", "submitter": "Francisco Claude", "authors": "J\\'er\\'emy Barbay, Francisco Claude, Gonzalo Navarro", "title": "Compact Binary Relation Representations with Rich Functionality", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Binary relations are an important abstraction arising in many data\nrepresentation problems. The data structures proposed so far to represent them\nsupport just a few basic operations required to fit one particular application.\nWe identify many of those operations arising in applications and generalize\nthem into a wide set of desirable queries for a binary relation representation.\nWe also identify reductions among those operations. We then introduce several\nnovel binary relation representations, some simple and some quite\nsophisticated, that not only are space-efficient but also efficiently support a\nlarge subset of the desired queries.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 19:57:11 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["Claude", "Francisco", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1201.3722", "submitter": "Hadi Poormohammadi", "authors": "Hadi Poormohammadi, Changiz Eslahchi, and Ruzbeh Tusserkani", "title": "TripNet: A Heuristic Algorithm for Constructing Rooted Phylogenetic\n  Networks from Triplets", "comments": "20 pages, 5 figures, Regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing an optimal rooted phylogenetic network from a set\nof rooted triplets is an NP-hard problem. In this paper, we present a heuristic\nalgorithm called TripNet which tries to construct an optimal rooted\nphylogenetic network from an arbitrary set of triplets. We prove some theorems\nto justify the performance of the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 08:39:02 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Poormohammadi", "Hadi", ""], ["Eslahchi", "Changiz", ""], ["Tusserkani", "Ruzbeh", ""]]}, {"id": "1201.3778", "submitter": "Francesco Versaci", "authors": "Francesco Versaci and Keshav Pingali", "title": "Processor Allocation for Optimistic Parallelization of Irregular\n  Programs", "comments": "12 pages, 3 figures, extended version of SPAA 2011 brief announcement", "journal-ref": "LNCS 7333/2012", "doi": "10.1007/978-3-642-31125-3_1", "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimistic parallelization is a promising approach for the parallelization of\nirregular algorithms: potentially interfering tasks are launched dynamically,\nand the runtime system detects conflicts between concurrent activities,\naborting and rolling back conflicting tasks. However, parallelism in irregular\nalgorithms is very complex. In a regular algorithm like dense matrix\nmultiplication, the amount of parallelism can usually be expressed as a\nfunction of the problem size, so it is reasonably straightforward to determine\nhow many processors should be allocated to execute a regular algorithm of a\ncertain size (this is called the processor allocation problem). In contrast,\nparallelism in irregular algorithms can be a function of input parameters, and\nthe amount of parallelism can vary dramatically during the execution of the\nirregular algorithm. Therefore, the processor allocation problem for irregular\nalgorithms is very difficult.\n  In this paper, we describe the first systematic strategy for addressing this\nproblem. Our approach is based on a construct called the conflict graph, which\n(i) provides insight into the amount of parallelism that can be extracted from\nan irregular algorithm, and (ii) can be used to address the processor\nallocation problem for irregular algorithms. We show that this problem is\nrelated to a generalization of the unfriendly seating problem and, by extending\nTur\\'an's theorem, we obtain a worst-case class of problems for optimistic\nparallelization, which we use to derive a lower bound on the exploitable\nparallelism. Finally, using some theoretically derived properties and some\nexperimental facts, we design a quick and stable control strategy for solving\nthe processor allocation problem heuristically.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 13:16:57 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 13:07:46 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Versaci", "Francesco", ""], ["Pingali", "Keshav", ""]]}, {"id": "1201.3802", "submitter": "Krasimir Yordzhev", "authors": "Hristina Kostadinova, Krasimir Yordzhev", "title": "An Entertaining Example for the Usage of Bitwise Operations in\n  Programming", "comments": "Proceedings of the Fourth International Scientific Conference -\n  FMNS2011, 8 - 11 June, 2011", "journal-ref": "Mathematics and natural science, v. 1, SWU \"N. Rilski\", 2011,\n  159-168", "doi": null, "report-no": null, "categories": "cs.OH cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study is meant to fill in some information gaps occurring in the\nmost widespread and well-known educational and reference literature about\nprogramming. The stress is laid on a very useful instrument - the bitwise\noperations, topic which is, unfortunately, seldom dealt with in most of the\nwell-known books on programming. In addition, the research is very useful as\nregards the topic of overloading operators in any Object-oriented programming\ncourse. Given some appropriate examples, with the emphasis being laid on some\nparticular and data structures language constructions, the results are quite\ninteresting. The algorithm of solving the popular Sudoku puzzle is one such\nentertaining example.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 09:11:18 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Kostadinova", "Hristina", ""], ["Yordzhev", "Krasimir", ""]]}, {"id": "1201.3955", "submitter": "David B. Wilson", "authors": "Claire Mathieu and David B. Wilson", "title": "The min mean-weight cycle in a random network", "comments": "21 pages, 1 figure", "journal-ref": "Combinatorics, Probability & Computing 22(5):763-782, 2013", "doi": "10.1017/S0963548313000229", "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean weight of a cycle in an edge-weighted graph is the sum of the\ncycle's edge weights divided by the cycle's length. We study the minimum\nmean-weight cycle on the complete graph on n vertices, with random i.i.d. edge\nweights drawn from an exponential distribution with mean 1. We show that the\nprobability of the min mean weight being at most c/n tends to a limiting\nfunction of c which is analytic for c<=1/e, discontinuous at c=1/e, and equal\nto 1 for c>1/e. We further show that if the min mean weight is <=1/(en), then\nthe length of the relevant cycle is Theta_p(1) (i.e., it has a limiting\nprobability distribution which does not scale with n), but that if the min mean\nweight is >1/(en), then the relevant cycle almost always has mean weight\n(1+o(1))/(en) and length at least (2/pi^2-o(1)) log^2 n log log n.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 01:05:45 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2013 19:32:16 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Mathieu", "Claire", ""], ["Wilson", "David B.", ""]]}, {"id": "1201.4054", "submitter": "Asaf Cohen", "authors": "Asaf Cohen, Shlomi Dolav and Guy Leshem", "title": "Sensor Networks: from Dependence Analysis Via Matroid Bases to Online\n  Synthesis", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the two related problems of sensor selection and sensor fusion. In\nthe first, given a set of sensors, one wishes to identify a subset of the\nsensors, which while small in size, captures the essence of the data gathered\nby the sensors. In the second, one wishes to construct a fused sensor, which\nutilizes the data from the sensors (possibly after discarding dependent ones)\nin order to create a single sensor which is more reliable than each of the\nindividual ones. In this work, we rigorously define the dependence among\nsensors in terms of joint empirical measures and incremental parsing. We show\nthat these measures adhere to a polymatroid structure, which in turn\nfacilitates the application of efficient algorithms for sensor selection. We\nsuggest both a random and a greedy algorithm for sensor selection. Given an\nindependent set, we then turn to the fusion problem, and suggest a novel\nvariant of the exponential weighting algorithm. In the suggested algorithm, one\ncompetes against an augmented set of sensors, which allows it to converge to\nthe best fused sensor in a family of sensors, without having any prior data on\nthe sensors' performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 13:13:14 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Cohen", "Asaf", ""], ["Dolav", "Shlomi", ""], ["Leshem", "Guy", ""]]}, {"id": "1201.4206", "submitter": "Ragesh Jaiswal", "authors": "Ragesh Jaiswal, Amit Kumar, Sandeep Sen", "title": "A simple D^2-sampling based PTAS for k-means and other Clustering\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of points $P \\subset \\mathbb{R}^d$, the $k$-means clustering\nproblem is to find a set of $k$ {\\em centers} $C = \\{c_1,...,c_k\\}, c_i \\in\n\\mathbb{R}^d,$ such that the objective function $\\sum_{x \\in P} d(x,C)^2$,\nwhere $d(x,C)$ denotes the distance between $x$ and the closest center in $C$,\nis minimized. This is one of the most prominent objective functions that have\nbeen studied with respect to clustering.\n  $D^2$-sampling \\cite{ArthurV07} is a simple non-uniform sampling technique\nfor choosing points from a set of points. It works as follows: given a set of\npoints $P \\subseteq \\mathbb{R}^d$, the first point is chosen uniformly at\nrandom from $P$. Subsequently, a point from $P$ is chosen as the next sample\nwith probability proportional to the square of the distance of this point to\nthe nearest previously sampled points.\n  $D^2$-sampling has been shown to have nice properties with respect to the\n$k$-means clustering problem. Arthur and Vassilvitskii \\cite{ArthurV07} show\nthat $k$ points chosen as centers from $P$ using $D^2$-sampling gives an\n$O(\\log{k})$ approximation in expectation. Ailon et. al. \\cite{AJMonteleoni09}\nand Aggarwal et. al. \\cite{AggarwalDK09} extended results of \\cite{ArthurV07}\nto show that $O(k)$ points chosen as centers using $D^2$-sampling give $O(1)$\napproximation to the $k$-means objective function with high probability. In\nthis paper, we further demonstrate the power of $D^2$-sampling by giving a\nsimple randomized $(1 + \\epsilon)$-approximation algorithm that uses the\n$D^2$-sampling in its core.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 05:01:48 GMT"}], "update_date": "2012-01-23", "authors_parsed": [["Jaiswal", "Ragesh", ""], ["Kumar", "Amit", ""], ["Sen", "Sandeep", ""]]}, {"id": "1201.4459", "submitter": "Fatemeh Keshavarz-Kohjerdi", "authors": "Fatemeh Keshavarz-Kohjerdi and Alireza Bagheri", "title": "An efficient parallel algorithm for the longest path problem in meshes", "comments": "23page, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, first we give a sequential linear-time algorithm for the\nlongest path problem in meshes. This algorithm can be considered as an\nimprovement of [13]. Then based on this sequential algorithm, we present a\nconstant-time parallel algorithm for the problem which can be run on every\nparallel machine.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 10:39:34 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Keshavarz-Kohjerdi", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1201.4603", "submitter": "Charalampos Tsourakakis", "authors": "Alan Frieze, Charalampos E. Tsourakakis", "title": "Rainbow Connectivity of Sparse Random Graphs", "comments": "17 pages, 4 figures Accepted at APPROX-RANDOM'12", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An edge colored graph $G$ is rainbow edge connected if any two vertices are\nconnected by a path whose edges have distinct colors. The rainbow connectivity\nof a connected graph $G$, denoted by $rc(G)$, is the smallest number of colors\nthat are needed in order to make $G$ rainbow connected.\n  In this work we study the rainbow connectivity of binomial random graphs at\nthe connectivity threshold $p=\\frac{\\log n+\\om}{n}$ where $\\om=\\om(n)\\to\\infty$\nand ${\\om}=o(\\log{n})$ and of random $r$-regular graphs where $r \\geq 3$ is a\nfixed integer. Specifically, we prove that the rainbow connectivity $rc(G)$ of\n$G=G(n,p)$ satisfies $rc(G) \\sim \\max\\set{Z_1,diameter(G)}$ with high\nprobability (\\whp). Here $Z_1$ is the number of vertices in $G$ whose degree\nequals 1 and the diameter of $G$ is asymptotically equal to $\\diam$ \\whp.\nFinally, we prove that the rainbow connectivity $rc(G)$ of the random\n$r$-regular graph $G=G(n,r)$ satisfies $rc(G) =O(\\log^2{n})$ \\whp.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2012 21:22:33 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 16:32:33 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2012 13:09:46 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Frieze", "Alan", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1201.4764", "submitter": "Robert Kleinberg", "authors": "Robert Kleinberg and S. Matthew Weinberg", "title": "Matroid Prophet Inequalities", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a gambler who observes a sequence of independent, non-negative\nrandom numbers and is allowed to stop the sequence at any time, claiming a\nreward equal to the most recent observation. The famous prophet inequality of\nKrengel, Sucheston, and Garling asserts that a gambler who knows the\ndistribution of each random variable can achieve at least half as much reward,\nin expectation, as a \"prophet\" who knows the sampled values of each random\nvariable and can choose the largest one. We generalize this result to the\nsetting in which the gambler and the prophet are allowed to make more than one\nselection, subject to a matroid constraint. We show that the gambler can still\nachieve at least half as much reward as the prophet; this result is the best\npossible, since it is known that the ratio cannot be improved even in the\noriginal prophet inequality, which corresponds to the special case of rank-one\nmatroids. Generalizing the result still further, we show that under an\nintersection of p matroid constraints, the prophet's reward exceeds the\ngambler's by a factor of at most O(p), and this factor is also tight.\n  Beyond their interest as theorems about pure online algorithms or optimal\nstopping rules, these results also have applications to mechanism design. Our\nresults imply improved bounds on the ability of sequential posted-price\nmechanisms to approximate Bayesian optimal mechanisms in both single-parameter\nand multi-parameter settings. In particular, our results imply the first\nefficiently computable constant-factor approximations to the Bayesian optimal\nrevenue in certain multi-parameter settings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 16:54:52 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Kleinberg", "Robert", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1201.4899", "submitter": "Maria Florina Balcan", "authors": "Maria-Florina Balcan, Christian Borgs, Mark Braverman, Jennifer\n  Chayes, Shang-Hua Teng", "title": "Finding Endogenously Formed Communities", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in e-commerce is determining overlapping communities among\nindividuals or objects in the absence of external identification or tagging. We\naddress this problem by introducing a framework that captures the notion of\ncommunities or clusters determined by the relative affinities among their\nmembers. To this end we define what we call an affinity system, which is a set\nof elements, each with a vector characterizing its preference for all other\nelements in the set. We define a natural notion of (potentially overlapping)\ncommunities in an affinity system, in which the members of a given community\ncollectively prefer each other to anyone else outside the community. Thus these\ncommunities are endogenously formed in the affinity system and are\n\"self-determined\" or \"self-certified\" by its members.\n  We provide a tight polynomial bound on the number of self-determined\ncommunities as a function of the robustness of the community. We present a\npolynomial-time algorithm for enumerating these communities. Moreover, we\nobtain a local algorithm with a strong stochastic performance guarantee that\ncan find a community in time nearly linear in the of size the community.\n  Social networks fit particularly naturally within the affinity system\nframework -- if we can appropriately extract the affinities from the relatively\nsparse yet rich information from social networks, our analysis then yields a\nset of efficient algorithms for enumerating self-determined communities in\nsocial networks. In the context of social networks we also connect our analysis\nwith results about $(\\alpha,\\beta)$-clusters introduced by Mishra, Schreiber,\nStanton, and Tarjan \\cite{msst}. In contrast with the polynomial bound we prove\non the number of communities in the affinity system model, we show that there\nexists a family of networks with superpolynomial number of\n$(\\alpha,\\beta)$-clusters.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 00:40:37 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 02:37:39 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Borgs", "Christian", ""], ["Braverman", "Mark", ""], ["Chayes", "Jennifer", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "1201.5030", "submitter": "Moti Medina", "authors": "Guy Even and Moti Medina", "title": "Online Multi-Commodity Flow with High Demands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of computing, in an online fashion, a\nmaximum benefit multi-commodity flow (\\ONMCF), where the flow demands may be\nbigger than the edge capacities of the network.\n  We present an online, deterministic, centralized, all-or-nothing, bi-criteria\nalgorithm. The competitive ratio of the algorithm is constant, and the\nalgorithm augments the capacities by at most a logarithmic factor.\n  The algorithm can handle two types of flow requests: (i) low demand requests\nthat must be routed along a path, and (ii) high demand requests that may be\nrouted using a multi-path flow.\n  Two extensions are discussed: requests with known durations and machine\nscheduling.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 16:11:45 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 13:16:51 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2012 15:08:05 GMT"}, {"version": "v4", "created": "Sun, 22 Apr 2012 20:14:50 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Even", "Guy", ""], ["Medina", "Moti", ""]]}, {"id": "1201.5135", "submitter": "Richard Peng", "authors": "Richard Peng, Kanat Tangwongsan, Peng Zhang", "title": "Faster and Simpler Width-Independent Parallel Algorithms for Positive\n  Semidefinite Programming", "comments": "Fixed a mistake in the runtime analyses of previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of finding an $(1+\\epsilon)$-approximate\nsolution to positive semidefinite programs. These are semidefinite programs in\nwhich all matrices in the constraints and objective are positive semidefinite\nand all scalars are non-negative.\n  We present a simpler \\NC parallel algorithm that on input with $n$ constraint\nmatrices, requires $O(\\frac{1}{\\epsilon^3} log^3 n)$ iterations, each of which\ninvolves only simple matrix operations and computing the trace of the product\nof a matrix exponential and a positive semidefinite matrix. Further, given a\npositive SDP in a factorized form, the total work of our algorithm is\nnearly-linear in the number of non-zero entries in the factorization.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 21:36:00 GMT"}, {"version": "v2", "created": "Wed, 13 Aug 2014 15:47:51 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 04:54:54 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Peng", "Richard", ""], ["Tangwongsan", "Kanat", ""], ["Zhang", "Peng", ""]]}, {"id": "1201.5154", "submitter": "Robert McKilliam", "authors": "Robby McKilliam and Alex Grant", "title": "Finding short vectors in a lattice of Voronoi's first kind", "comments": "submitted to the 2012 International Symposium on Information Theory\n  (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for those lattices of Voronoi's first kind, a vector of shortest\nnonzero Euclidean length can computed in polynomial time by computing a minimum\ncut in a graph.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 23:17:18 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["McKilliam", "Robby", ""], ["Grant", "Alex", ""]]}, {"id": "1201.5513", "submitter": "Mathieu Raffinot", "authors": "Aida Ouangraoua and Mathieu Raffinot", "title": "Faster and Simpler Minimal Conflicting Set Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let C be a finite set of N elements and R = r_1,r_2,..., r_m a family of M\nsubsets of C. A subset X of R verifies the Consecutive Ones Property (C1P) if\nthere exists a permutation P of C such that each r_i in X is an interval of P.\nA Minimal Conflicting Set (MCS) S is a subset of R that does not verify the\nC1P, but such that any of its proper subsets does. In this paper, we present a\nnew simpler and faster algorithm to decide if a given element r in R belongs to\nat least one MCS. Our algorithm runs in O(N^2M^2 + NM^7), largely improving the\ncurrent O(M^6N^5 (M+N)^2 log(M+N)) fastest algorithm of [Blin {\\em et al}, CSR\n2011]. The new algorithm is based on an alternative approach considering\nminimal forbidden induced subgraphs of interval graphs instead of Tucker\nmatrices.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 13:35:33 GMT"}], "update_date": "2012-01-27", "authors_parsed": [["Ouangraoua", "Aida", ""], ["Raffinot", "Mathieu", ""]]}, {"id": "1201.5603", "submitter": "Igor Nesiolovskiy", "authors": "Igor Nesiolovskiy, Artem Nesiolovskiy", "title": "BIN@ERN: Binary-Ternary Compressing Data Coding", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new method of data encoding which may be used in\nvarious modern digital, computer and telecommunication systems and devices. The\nmethod permits the compression of data for storage or transmission, allowing\nthe exact original data to be reconstructed without any loss of content. The\nmethod is characterized by the simplicity of implementation, as well as high\nspeed and compression ratio. The method is based on a unique scheme of\nbinary-ternary prefix-free encoding of characters of the original data. This\nscheme does not require the transmission of the code tables from encoder to\ndecoder; allows for the linear presentation of the code lists; permits the\nusage of computable indexes of the prefix codes in a linear list for decoding;\nmakes it possible to estimate the compression ratio prior to encoding; makes\nthe usage of multiplication and division operations, as well as operations with\nthe floating point unnecessary; proves to be effective for static as well as\nadaptive coding; applicable to character sets of any size; allows for repeated\ncompression to improve the ratio.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 18:53:00 GMT"}], "update_date": "2012-01-27", "authors_parsed": [["Nesiolovskiy", "Igor", ""], ["Nesiolovskiy", "Artem", ""]]}, {"id": "1201.5821", "submitter": "Richard Schmied", "authors": "Marek Karpinski and Richard Schmied", "title": "On Approximation Lower Bounds for TSP with Bounded Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for proving explicit approximation lower bounds for\nTSP problems with bounded metrics improving on the best up to now known bounds.\nThey almost match the best known bounds for unbounded metric TSP problems. In\nparticular, we prove the best known lower bound for TSP with bounded metrics\nfor the metric bound equal to 4.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 16:31:43 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 12:33:40 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Karpinski", "Marek", ""], ["Schmied", "Richard", ""]]}, {"id": "1201.5824", "submitter": "Sebastien Tixeuil", "authors": "Alexandre Maurer (LIP6, LINCS), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "Limiting Byzantien Influence in Multihop Asynchronous Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reliably broadcasting information in a multihop\nasyn- chronous network that is subject to Byzantine failures. That is, some\nnodes of the network can exhibit arbitrary (and potentially malicious)\nbehavior. Existing solutions provide de- terministic guarantees for\nbroadcasting between all correct nodes, but require that the communication\nnetwork is highly-connected (typically, 2k + 1 connectivity is required, where\nk is the total number of Byzantine nodes in the network). In this paper, we\ninvestigate the possibility of Byzantine tolerant reliable broadcast be- tween\nmost correct nodes in low-connectivity networks (typically, networks with\nconstant connectivity). In more details, we propose a new broadcast protocol\nthat is specifically designed for low-connectivity networks. We provide\nsufficient conditions for correct nodes using our protocol to reliably\ncommunicate despite Byzantine participants. We present experimental results\nthat show that our approach is especially effective in low-connectivity\nnetworks when Byzantine nodes are randomly distributed.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 16:36:50 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Maurer", "Alexandre", "", "LIP6, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1201.5958", "submitter": "Jasine Babu", "authors": "Abhijin Adiga and Jasine Babu and L. Sunil Chandran", "title": "Parameterized and Approximation Algorithms for Boxicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boxicity of a graph $G(V,$ $E)$, denoted by $box(G)$, is the minimum integer\n$k$ such that $G$ can be represented as the intersection graph of axis parallel\nboxes in $\\mathbb{R}^k$. The problem of computing boxicity is inapproximable\neven for graph classes like bipartite, co-bipartite and split graphs within\n$O(n^{1 - \\epsilon})$-factor, for any $\\epsilon >0$ in polynomial time unless\n$NP=ZPP$. We give FPT approximation algorithms for computing the boxicity of\ngraphs, where the parameter used is the vertex or edge edit distance of the\ngiven graph from families of graphs of bounded boxicity. This can be seen as a\ngeneralization of the parameterizations discussed in \\cite{Adiga2}.\n  Extending the same idea in one of our algorithms, we also get an\n$O\\left(\\frac{n\\sqrt{\\log \\log n}}{\\sqrt{\\log n}}\\right)$ factor approximation\nalgorithm for computing boxicity and an $O\\left(\\frac{n {(\\log \\log\nn)}^{\\frac{3}{2}}}{\\sqrt{\\log n}}\\right)$ factor approximation algorithm for\ncomputing the cubicity. These seem to be the first $o(n)$ factor approximation\nalgorithms known for both boxicity and cubicity. As a consequence of this\nresult, a $o(n)$ factor approximation algorithm for computing the partial order\ndimension of finite posets and a $o(n)$ factor approximation algorithm for\ncomputing the threshold dimension of split graphs would follow.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 13:17:23 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 09:57:44 GMT"}, {"version": "v3", "created": "Wed, 5 Mar 2014 14:18:36 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Adiga", "Abhijin", ""], ["Babu", "Jasine", ""], ["Chandran", "L. Sunil", ""]]}, {"id": "1201.5972", "submitter": "Daniel Dadush", "authors": "Daniel Dadush and Santosh Vempala", "title": "Near-Optimal Deterministic Algorithms for Volume Computation and Lattice\n  Problems via M-Ellipsoids", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1203863110", "report-no": null, "categories": "cs.CC cs.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a deterministic 2^{O(n)} algorithm for computing an M-ellipsoid of a\nconvex body, matching a known lower bound. This has several interesting\nconsequences including improved deterministic algorithms for volume estimation\nof convex bodies and the shortest and closest lattice vector problems under\ngeneral norms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 16:58:45 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 13:08:16 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Dadush", "Daniel", ""], ["Vempala", "Santosh", ""]]}, {"id": "1201.5985", "submitter": "Jean-Francois Lalande", "authors": "Pascal Berthom\\'e (LIFO), Jean-Fran\\c{c}ois Lalande (LIFO), Vincent\n  Levorato (LIFO)", "title": "Implementation of exponential and parametrized algorithms in the AGAPE\n  project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes the implementation of exact and parametrized\nexponential algorithms, developed during the French ANR Agape during 2010-2012.\nThe developed algorithms are distributed under the CeCILL license and have been\nwritten in Java using the Jung graph library.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 20:08:26 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Berthom\u00e9", "Pascal", "", "LIFO"], ["Lalande", "Jean-Fran\u00e7ois", "", "LIFO"], ["Levorato", "Vincent", "", "LIFO"]]}, {"id": "1201.6090", "submitter": "Rahul Jain", "authors": "Rahul Jain and Penghui Yao", "title": "A parallel approximation algorithm for mixed packing and covering\n  semidefinite programs", "comments": "8 pages, version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel approximation algorithm for a class of mixed packing\nand covering semidefinite programs which generalize on the class of positive\nsemidefinite programs as considered by Jain and Yao [2011]. As a corollary we\nget a faster approximation algorithm for positive semidefinite programs with\nbetter dependence of the parallel running time on the approximation factor, as\ncompared to that of Jain and Yao [2011]. Our algorithm and analysis is on\nsimilar lines as that of Young [2001] who considered analogous linear programs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2012 23:00:30 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Jain", "Rahul", ""], ["Yao", "Penghui", ""]]}, {"id": "1201.6162", "submitter": "Michalis Christou", "authors": "Michalis Christou, Maxime Crochemore and Costas Iliopoulos", "title": "Quasiperiodicities in Fibonacci strings", "comments": "In Local Proceedings of \"The 38th International Conference on Current\n  Trends in Theory and Practice of Computer Science\" (SOFSEM 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding quasiperiodicities in a Fibonacci string.\nA factor u of a string y is a cover of y if every letter of y falls within some\noccurrence of u in y. A string v is a seed of y, if it is a cover of a\nsuperstring of y. A left seed of a string y is a prefix of y that it is a cover\nof a superstring of y. Similarly a right seed of a string y is a suffix of y\nthat it is a cover of a superstring of y. In this paper, we present some\ninteresting results regarding quasiperiodicities in Fibonacci strings, we\nidentify all covers, left/right seeds and seeds of a Fibonacci string and all\ncovers of a circular Fibonacci string.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 10:43:59 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Christou", "Michalis", ""], ["Crochemore", "Maxime", ""], ["Iliopoulos", "Costas", ""]]}, {"id": "1201.6174", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall", "title": "A Time-Efficient Output-Sensitive Quantum Algorithm for Boolean Matrix\n  Multiplication", "comments": "v2: slight modification of the title, addition of Theorem 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a quantum algorithm that computes the product of two\n$n\\times n$ Boolean matrices in $\\tilde O(n\\sqrt{\\ell}+\\ell\\sqrt{n})$ time,\nwhere $\\ell$ is the number of non-zero entries in the product. This improves\nthe previous output-sensitive quantum algorithms for Boolean matrix\nmultiplication in the time complexity setting by Buhrman and \\v{S}palek\n(SODA'06) and Le Gall (SODA'12). We also show that our approach cannot be\nfurther improved unless a breakthrough is made: we prove that any significant\nimprovement would imply the existence of an algorithm based on quantum search\nthat multiplies two $n\\times n$ Boolean matrices in $O(n^{5/2-\\varepsilon})$\ntime, for some constant $\\varepsilon>0$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 11:30:38 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2012 03:41:38 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1201.6207", "submitter": "Ton Kloks", "authors": "T. Kloks", "title": "k-Probe DH-graphs", "comments": "We are working on an improved description of these results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let k be a natural number. Let G be a graph and let N_1,...,N_k be k\nindependent sets in G. The graph G is k-probe distance hereditary if G can be\nembedded into a DH-graph by adding edges between vertices that are contained in\nthe same independent set. We show that there exists a polynomial-time algorithm\nto check if a graph G is k-probe distance hereditary.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 13:51:10 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2012 04:20:47 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Kloks", "T.", ""]]}, {"id": "1201.6358", "submitter": "Ming-Yang Kao", "authors": "Ming-Yang Kao, Henry C. M. Leung, He Sun, Yong Zhang", "title": "Deterministic Polynomial-Time Algorithms for Designing Short DNA Words", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing short DNA words is a problem of constructing a set (i.e., code) of\nn DNA strings (i.e., words) with the minimum length such that the Hamming\ndistance between each pair of words is at least k and the n words satisfy a set\nof additional constraints. This problem has applications in, e.g., DNA\nself-assembly and DNA arrays. Previous works include those that extended\nresults from coding theory to obtain bounds on code and word sizes for\nbiologically motivated constraints and those that applied heuristic local\nsearches, genetic algorithms, and randomized algorithms. In particular, Kao,\nSanghi, and Schweller (2009) developed polynomial-time randomized algorithms to\nconstruct n DNA words of length within a multiplicative constant of the\nsmallest possible word length (e.g., 9 max{log n, k}) that satisfy various sets\nof constraints with high probability. In this paper, we give deterministic\npolynomial-time algorithms to construct DNA words based on derandomization\ntechniques. Our algorithms can construct n DNA words of shorter length (e.g.,\n2.1 log n + 6.28 k) and satisfy the same sets of constraints as the words\nconstructed by the algorithms of Kao et al. Furthermore, we extend these new\nalgorithms to construct words that satisfy a larger set of constraints for\nwhich the algorithms of Kao et al. do not work.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 18:31:15 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Kao", "Ming-Yang", ""], ["Leung", "Henry C. M.", ""], ["Sun", "He", ""], ["Zhang", "Yong", ""]]}, {"id": "1201.6421", "submitter": "Ton Kloks", "authors": "Ton Kloks", "title": "The black-and-white coloring problem on permutation graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph G and integers b and w. The black-and-white coloring problem\nasks if there exist disjoint sets of vertices B and W with |B|=b and |W|=w such\nthat no vertex in B is adjacent to any vertex in W. In this paper we show that\nthe problem is polynomial when restricted to permutation graphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 02:40:54 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Kloks", "Ton", ""]]}, {"id": "1201.6444", "submitter": "James Allen Fill", "authors": "Patrick Bindjeme, James Allen Fill", "title": "The limiting distribution for the number of symbol comparisons used by\n  QuickSort is nondegenerate (extended abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a continuous-time setting, Fill (2010) proved, for a large class of\nprobabilistic sources, that the number of symbol comparisons used by QuickSort,\nwhen centered by subtracting the mean and scaled by dividing by time, has a\nlimiting distribution, but proved little about that limiting random variable Y\n-- not even that it is nondegenerate. We establish the nondegeneracy of Y. The\nproof is perhaps surprisingly difficult.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 04:56:31 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Bindjeme", "Patrick", ""], ["Fill", "James Allen", ""]]}, {"id": "1201.6445", "submitter": "James Allen Fill", "authors": "Patrick Bindjeme, James Allen Fill", "title": "Exact L^2-distance from the limit for QuickSort key comparisons\n  (extended abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a recursive approach, we obtain a simple exact expression for the\nL^2-distance from the limit in R\\'egnier's (1989) classical limit theorem for\nthe number of key comparisons required by QuickSort. A previous study by Fill\nand Janson (2002) using a similar approach found that the d_2-distance is of\norder between n^{-1} log n and n^{-1/2}, and another by Neininger and\nRuschendorf (2002) found that the Zolotarev zeta_3-distance is of exact order\nn^{-1} log n. Our expression reveals that the L^2-distance is asymptotically\nequivalent to (2 n^{-1} ln n)^{1/2}.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 04:59:04 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Bindjeme", "Patrick", ""], ["Fill", "James Allen", ""]]}, {"id": "1201.6488", "submitter": "Christian Schulz", "authors": "Ilya Safro, Peter Sanders, Christian Schulz", "title": "Advanced Coarsening Schemes for Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph partitioning problem is widely used and studied in many practical\nand theoretical applications. The multilevel strategies represent today one of\nthe most effective and efficient generic frameworks for solving this problem on\nlarge-scale graphs. Most of the attention in designing the multilevel\npartitioning frameworks has been on the refinement phase. In this work we focus\non the coarsening phase, which is responsible for creating structurally similar\nto the original but smaller graphs. We compare different matching- and\nAMG-based coarsening schemes, experiment with the algebraic distance between\nnodes, and demonstrate computational results on several classes of graphs that\nemphasize the running time and quality advantages of different coarsenings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 09:50:18 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2012 13:17:20 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Safro", "Ilya", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}]