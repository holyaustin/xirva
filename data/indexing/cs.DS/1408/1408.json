[{"id": "1408.0114", "submitter": "Magnus Lie Hetland", "authors": "Magnus Lie Hetland and Ola Martin Lykkja", "title": "A Real-Time Spatial Index for In-Vehicle Units", "comments": "In Proc. of the 26th Norwegian Informatics Conference, NIK, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a spatial indexing solution for the highly constrained\nenvironment of an in-vehicle unit in a distributed vehicle tolling scheme based\non satellite navigation (GNSS). We show that an immutable, purely functional\nimplementation of a high-fanout quadtree is a simple, practical solution that\nsatisfies all the requirements of such a system.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 09:42:45 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Hetland", "Magnus Lie", ""], ["Lykkja", "Ola Martin", ""]]}, {"id": "1408.0272", "submitter": "Fr\\'ed\\'eric Meunier", "authors": "Axel Parmentier and Fr\\'ed\\'eric Meunier", "title": "Stochastic Shortest Paths and Risk Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three shortest path problems in directed graphs with random arc\nlengths. For the first and the second problems, a risk measure is involved.\nWhile the first problem consists in finding a path minimizing this risk\nmeasure, the second one consists in finding a path minimizing a deterministic\ncost, while satisfying a constraint on the risk measure. We propose algorithms\nsolving these problems for a wide range of risk measures, which includes among\nseveral others the $CVaR$ and the probability of being late. Their performances\nare evaluated through experiments. One of the key elements in these algorithms\nis the use of stochastic lower bounds that allow to discard partial solutions.\nGood stochastic lower bounds are provided by the so-called Stochastic Ontime\nArrival Problem. This latter problem is the third one studied in this paper and\nwe propose a new and very efficient algorithm solving it. Complementary\ndiscussions on the complexity of the problems are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 19:20:58 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 16:38:46 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Parmentier", "Axel", ""], ["Meunier", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1408.0393", "submitter": "Jeremy Kepner", "authors": "Tim Mattson (Intel Corporation), David Bader (Georgia Institute of\n  Technology), Jon Berry (Sandia National Laboratory), Aydin Buluc (Lawrence\n  Berkeley National Laboratory), Jack Dongarra (University of Tennessee),\n  Christos Faloutsos (Carnegie Melon University), John Feo (Pacific Northwest\n  National Laboratory), John Gilbert (University of California at Santa\n  Barbara), Joseph Gonzalez (University of California at Berkeley), Bruce\n  Hendrickson (Sandia National Laboratory), Jeremy Kepner (Massachusetts\n  Institute of Technology), Charles Leiserson (Massachusetts Institute of\n  Technology), Andrew Lumsdaine (Indiana University), David Padua (University\n  of Illinois at Urbana-Champaign), Stephen Poole (Oak Ridge National\n  Laboratory), Steve Reinhardt (Cray Corporation), Mike Stonebraker\n  (Massachusetts Institute of Technology), Steve Wallach (Convey Corporation),\n  Andrew Yoo (Lawrence Livermore National Laboratory)", "title": "Standards for Graph Algorithm Primitives", "comments": "2 pages, IEEE HPEC 2013", "journal-ref": null, "doi": "10.1109/HPEC.2013.6670338", "report-no": null, "categories": "cs.MS cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is our view that the state of the art in constructing a large collection\nof graph algorithms in terms of linear algebraic operations is mature enough to\nsupport the emergence of a standard set of primitive building blocks. This\npaper is a position paper defining the problem and announcing our intention to\nlaunch an open effort to define this standard.\n", "versions": [{"version": "v1", "created": "Sat, 2 Aug 2014 16:17:40 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Mattson", "Tim", "", "Intel Corporation"], ["Bader", "David", "", "Georgia Institute of\n  Technology"], ["Berry", "Jon", "", "Sandia National Laboratory"], ["Buluc", "Aydin", "", "Lawrence\n  Berkeley National Laboratory"], ["Dongarra", "Jack", "", "University of Tennessee"], ["Faloutsos", "Christos", "", "Carnegie Melon University"], ["Feo", "John", "", "Pacific Northwest\n  National Laboratory"], ["Gilbert", "John", "", "University of California at Santa\n  Barbara"], ["Gonzalez", "Joseph", "", "University of California at Berkeley"], ["Hendrickson", "Bruce", "", "Sandia National Laboratory"], ["Kepner", "Jeremy", "", "Massachusetts\n  Institute of Technology"], ["Leiserson", "Charles", "", "Massachusetts Institute of\n  Technology"], ["Lumsdaine", "Andrew", "", "Indiana University"], ["Padua", "David", "", "University\n  of Illinois at Urbana-Champaign"], ["Poole", "Stephen", "", "Oak Ridge National\n  Laboratory"], ["Reinhardt", "Steve", "", "Cray Corporation"], ["Stonebraker", "Mike", "", "Massachusetts Institute of Technology"], ["Wallach", "Steve", "", "Convey Corporation"], ["Yoo", "Andrew", "", "Lawrence Livermore National Laboratory"]]}, {"id": "1408.0395", "submitter": "Matthias Feldotto", "authors": "Matthias Feldotto and Christian Scheideler and Kalman Graffi", "title": "HSkip+: A Self-Stabilizing Overlay Network for Nodes with Heterogeneous\n  Bandwidths", "comments": "This is a long version of a paper published by IEEE in the\n  Proceedings of the 14-th IEEE International Conference on Peer-to-Peer\n  Computing", "journal-ref": null, "doi": "10.1109/P2P.2014.6934300", "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present and analyze HSkip+, a self-stabilizing overlay\nnetwork for nodes with arbitrary heterogeneous bandwidths. HSkip+ has the same\ntopology as the Skip+ graph proposed by Jacob et al. [PODC 2009] but its\nself-stabilization mechanism significantly outperforms the self-stabilization\nmechanism proposed for Skip+. Also, the nodes are now ordered according to\ntheir bandwidths and not according to their identifiers. Various other\nsolutions have already been proposed for overlay networks with heterogeneous\nbandwidths, but they are not self-stabilizing. In addition to HSkip+ being\nself-stabilizing, its performance is on par with the best previous bounds on\nthe time and work for joining or leaving a network of peers of logarithmic\ndiameter and degree and arbitrary bandwidths. Also, the dilation and congestion\nfor routing messages is on par with the best previous bounds for such networks,\nso that HSkip+ combines the advantages of both worlds. Our theoretical\ninvestigations are backed by simulations demonstrating that HSkip+ is indeed\nperforming much better than Skip+ and working correctly under high churn rates.\n", "versions": [{"version": "v1", "created": "Sat, 2 Aug 2014 16:51:56 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 14:08:54 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Feldotto", "Matthias", ""], ["Scheideler", "Christian", ""], ["Graffi", "Kalman", ""]]}, {"id": "1408.0409", "submitter": "Parter Merav", "authors": "Merav Parter", "title": "Vertex Fault Tolerant Additive Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A {\\em fault-tolerant} structure for a network is required to continue\nfunctioning following the failure of some of the network's edges or vertices.\nIn this paper, we address the problem of designing a {\\em fault-tolerant}\nadditive spanner, namely, a subgraph $H$ of the network $G$ such that\nsubsequent to the failure of a single vertex, the surviving part of $H$ still\ncontains an \\emph{additive} spanner for (the surviving part of) $G$, satisfying\n$dist(s,t,H\\setminus \\{v\\}) \\leq dist(s,t,G\\setminus \\{v\\})+\\beta$ for every\n$s,t,v \\in V$. Recently, the problem of constructing fault-tolerant additive\nspanners resilient to the failure of up to $f$ \\emph{edges} has been considered\nby Braunschvig et. al. The problem of handling \\emph{vertex} failures was left\nopen therein. In this paper we develop new techniques for constructing additive\nFT-spanners overcoming the failure of a single vertex in the graph. Our first\nresult is an FT-spanner with additive stretch $2$ and $\\widetilde{O}(n^{5/3})$\nedges. Our second result is an FT-spanner with additive stretch $6$ and\n$\\widetilde{O}(n^{3/2})$ edges. The construction algorithm consists of two main\ncomponents: (a) constructing an FT-clustering graph and (b) applying a modified\npath-buying procedure suitably adopted to failure prone settings. Finally, we\nalso describe two constructions for {\\em fault-tolerant multi-source additive\nspanners}, aiming to guarantee a bounded additive stretch following a vertex\nfailure, for every pair of vertices in $S \\times V$ for a given subset of\nsources $S\\subseteq V$. The additive stretch bounds of our constructions are 4\nand 8 (using a different number of edges).\n", "versions": [{"version": "v1", "created": "Sat, 2 Aug 2014 19:51:30 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Parter", "Merav", ""]]}, {"id": "1408.0467", "submitter": "Yasuo Tabei", "authors": "Yoshimasa Takabatake, Yasuo Tabei, Hiroshi Sakamoto", "title": "Online Pattern Matching for String Edit Distance with Moves", "comments": "This paper has been accepted to the 21st edition of the International\n  Symposium on String Processing and Information Retrieval (SPIRE2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edit distance with moves (EDM) is a string-to-string distance measure that\nincludes substring moves in addition to ordinal editing operations to turn one\nstring to the other. Although optimizing EDM is intractable, it has many\napplications especially in error detections. Edit sensitive parsing (ESP) is an\nefficient parsing algorithm that guarantees an upper bound of parsing\ndiscrepancies between different appearances of the same substrings in a string.\nESP can be used for computing an approximate EDM as the L1 distance between\ncharacteristic vectors built by node labels in parsing trees. However, ESP is\nnot applicable to a streaming text data where a whole text is unknown in\nadvance. We present an online ESP (OESP) that enables an online pattern\nmatching for EDM. OESP builds a parse tree for a streaming text and computes\nthe L1 distance between characteristic vectors in an online manner. For the\nspace-efficient computation of EDM, OESP directly encodes the parse tree into a\nsuccinct representation by leveraging the idea behind recent results of a\ndynamic succinct tree. We experimentally test OESP on the ability to compute\nEDM in an online manner on benchmark datasets, and we show OESP's efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 3 Aug 2014 07:48:52 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 05:56:42 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Takabatake", "Yoshimasa", ""], ["Tabei", "Yasuo", ""], ["Sakamoto", "Hiroshi", ""]]}, {"id": "1408.0488", "submitter": "Sandeep Sen", "authors": "Sandeep Sen", "title": "Improved Randomized Rounding using Random Walks", "comments": "The primary result claimed in this submission doesn't hold for random\n  0-1 matrices of size $n^2 \\times n$ which can be proved by a probabilistic\n  method. For such matrices, the RT bound is tight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel algorithm for rounding packing integer programs based on\nmultidimensional Brownian motion in $\\mathbb{R}^n$. Starting from an optimal\nfractional feasible solution $\\bar{x}$, the procedure converges in polynomial\ntime to a distribution over (possibly infeasible) point set $P \\subset {\\{0,1\n\\}}^n$ such that the expected value of any linear objective function over $P$\nequals the value at $\\bar{x}$. This is an alternate approach to the classical\nrandomized rounding method of Raghavan and Thompson \\cite{RT:87}.\n  Our procedure is very general and in conjunction with discrepancy based\narguments, yield efficient alternate methods for rounding other optimization\nproblems that can be expressed as packing ILPs including disjoint path problems\nand MISR.\n", "versions": [{"version": "v1", "created": "Sun, 3 Aug 2014 12:10:32 GMT"}, {"version": "v2", "created": "Sat, 9 Aug 2014 18:31:47 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Sen", "Sandeep", ""]]}, {"id": "1408.0531", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Viresh Patel", "title": "Parameterized TSP: Beating the Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Travelling Salesman Problem (TSP), we are given a complete graph $K_n$\ntogether with an integer weighting $w$ on the edges of $K_n$, and we are asked\nto find a Hamilton cycle of $K_n$ of minimum weight. Let $h(w)$ denote the\naverage weight of a Hamilton cycle of $K_n$ for the weighting $w$. Vizing\n(1973) asked whether there is a polynomial-time algorithm which always finds a\nHamilton cycle of weight at most $h(w)$. He answered this question in the\naffirmative and subsequently Rublineckii (1973) and others described several\nother TSP heuristics satisfying this property. In this paper, we prove a\nconsiderable generalisation of Vizing's result: for each fixed $k$, we give an\nalgorithm that decides whether, for any input edge weighting $w$ of $K_n$,\nthere is a Hamilton cycle of $K_n$ of weight at most $h(w)-k$ (and constructs\nsuch a cycle if it exists). For $k$ fixed, the running time of the algorithm is\npolynomial in $n$, where the degree of the polynomial does not depend on $k$\n(i.e., the generalised Vizing problem is fixed-parameter tractable with respect\nto the parameter $k$).\n", "versions": [{"version": "v1", "created": "Sun, 3 Aug 2014 19:34:59 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Gutin", "Gregory", ""], ["Patel", "Viresh", ""]]}, {"id": "1408.0557", "submitter": "Hsin-Hao Su", "authors": "Danupon Nanongkai, Hsin-Hao Su", "title": "Almost-Tight Distributed Minimum Cut Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computing the minimum cut in a weighted distributed\nmessage-passing networks (the CONGEST model). Let $\\lambda$ be the minimum cut,\n$n$ be the number of nodes in the network, and $D$ be the network diameter. Our\nalgorithm can compute $\\lambda$ exactly in $O((\\sqrt{n} \\log^{*} n+D)\\lambda^4\n\\log^2 n)$ time. To the best of our knowledge, this is the first paper that\nexplicitly studies computing the exact minimum cut in the distributed setting.\nPreviously, non-trivial sublinear time algorithms for this problem are known\nonly for unweighted graphs when $\\lambda\\leq 3$ due to Pritchard and\nThurimella's $O(D)$-time and $O(D+n^{1/2}\\log^* n)$-time algorithms for\ncomputing $2$-edge-connected and $3$-edge-connected components.\n  By using the edge sampling technique of Karger's, we can convert this\nalgorithm into a $(1+\\epsilon)$-approximation $O((\\sqrt{n}\\log^{*}\nn+D)\\epsilon^{-5}\\log^3 n)$-time algorithm for any $\\epsilon>0$. This improves\nover the previous $(2+\\epsilon)$-approximation $O((\\sqrt{n}\\log^{*}\nn+D)\\epsilon^{-5}\\log^2 n\\log\\log n)$-time algorithm and\n$O(\\epsilon^{-1})$-approximation $O(D+n^{\\frac{1}{2}+\\epsilon}\n\\mathrm{poly}\\log n)$-time algorithm of Ghaffari and Kuhn. Due to the lower\nbound of $\\Omega(D+n^{1/2}/\\log n)$ by Das Sarma et al. which holds for any\napproximation algorithm, this running time is tight up to a $ \\mathrm{poly}\\log\nn$ factor.\n  To get the stated running time, we developed an approximation algorithm which\ncombines the ideas of Thorup's algorithm and Matula's contraction algorithm. It\nsaves an $\\epsilon^{-9}\\log^{7} n$ factor as compared to applying Thorup's tree\npacking theorem directly. Then, we combine Kutten and Peleg's tree partitioning\nalgorithm and Karger's dynamic programming to achieve an efficient distributed\nalgorithm that finds the minimum cut when we are given a spanning tree that\ncrosses the minimum cut exactly once.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 00:23:28 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Nanongkai", "Danupon", ""], ["Su", "Hsin-Hao", ""]]}, {"id": "1408.0596", "submitter": "Bert Besser", "authors": "Bert Besser", "title": "Approximation Bounds For Minimum Degree Matching", "comments": "% CHANGELOG % rev 1 2014-12-02 % - Show that the class APV contains\n  many prominent greedy matching algorithms. % - Adapt inapproximability bound\n  for APV-algorithms to a priori knowledge on |V|. % rev 2 2015-10-31 % -\n  improve performance guarantee of MINGREEDY to be tight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the MINGREEDY strategy for Maximum Cardinality Matching.\nMINGREEDY repeatedly selects an edge incident with a node of minimum degree.\nFor graphs of degree at most $\\Delta$ we show that MINGREEDY achieves\napproximation ratio at least $ \\frac{\\Delta-1}{2\\Delta-3} $ in the worst case\nand that this performance is optimal among adaptive priority algorithms in the\nvertex model, which include many prominent greedy matching heuristics. Even\nwhen considering expected approximation ratios of randomized greedy strategies,\nno better worst case bounds are known for graphs of small degrees.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 06:38:45 GMT"}, {"version": "v2", "created": "Tue, 2 Dec 2014 14:42:56 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2015 14:58:04 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Besser", "Bert", ""]]}, {"id": "1408.0751", "submitter": "Amirali Abdullah", "authors": "Amirali Abdullah, Alexandr Andoni, Ravindran Kannan, Robert\n  Krauthgamer", "title": "Spectral Approaches to Nearest Neighbor Search", "comments": "Accepted in the proceedings of FOCS 2014. 30 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study spectral algorithms for the high-dimensional Nearest Neighbor Search\nproblem (NNS). In particular, we consider a semi-random setting where a dataset\n$P$ in $\\mathbb{R}^d$ is chosen arbitrarily from an unknown subspace of low\ndimension $k\\ll d$, and then perturbed by fully $d$-dimensional Gaussian noise.\nWe design spectral NNS algorithms whose query time depends polynomially on $d$\nand $\\log n$ (where $n=|P|$) for large ranges of $k$, $d$ and $n$. Our\nalgorithms use a repeated computation of the top PCA vector/subspace, and are\neffective even when the random-noise magnitude is {\\em much larger} than the\ninterpoint distances in $P$. Our motivation is that in practice, a number of\nspectral NNS algorithms outperform the random-projection methods that seem\notherwise theoretically optimal on worst case datasets. In this paper we aim to\nprovide theoretical justification for this disparity.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 17:51:17 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Abdullah", "Amirali", ""], ["Andoni", "Alexandr", ""], ["Kannan", "Ravindran", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1408.0965", "submitter": "Thang Nguyen Kim", "authors": "Nguyen Kim Thang", "title": "Lagrangian Duality based Algorithms in Online Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Lagrangian duality based approaches to design and analyze\nalgorithms for online energy-efficient scheduling. First, we present a\nprimal-dual framework. Our approach makes use of the Lagrangian weak duality\nand convexity to derive dual programs for problems which could be formulated as\nconvex assignment problems. The duals have intuitive structures as the ones in\nlinear programming. The constraints of the duals explicitly indicate the online\ndecisions and naturally lead to competitive algorithms. Second, we use a\ndual-fitting approach, which also based on the weak duality, to study problems\nwhich are unlikely to admit convex relaxations. Through the analysis, we show\nan interesting feature in which primal-dual gives idea for designing algorithms\nwhile the analysis is done by dual-fitting.\n  We illustrate the advantages and the flexibility of the approaches through\nproblems in different setting: from single machine to unrelated machine\nenvironments, from typical competitive analysis to the one with resource\naugmentation, from convex relaxations to non-convex relaxations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 13:37:57 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Thang", "Nguyen Kim", ""]]}, {"id": "1408.1000", "submitter": "Himanshu Tyagi", "authors": "Jayadev Acharya, Alon Orlitsky, Ananda Theertha Suresh, and Himanshu\n  Tyagi", "title": "Estimating Renyi Entropy of Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently shown that estimating the Shannon entropy $H({\\rm p})$ of a\ndiscrete $k$-symbol distribution ${\\rm p}$ requires $\\Theta(k/\\log k)$ samples,\na number that grows near-linearly in the support size. In many applications\n$H({\\rm p})$ can be replaced by the more general R\\'enyi entropy of order\n$\\alpha$, $H_\\alpha({\\rm p})$. We determine the number of samples needed to\nestimate $H_\\alpha({\\rm p})$ for all $\\alpha$, showing that $\\alpha < 1$\nrequires a super-linear, roughly $k^{1/\\alpha}$ samples, noninteger $\\alpha>1$\nrequires a near-linear $k$ samples, but, perhaps surprisingly, integer\n$\\alpha>1$ requires only $\\Theta(k^{1-1/\\alpha})$ samples. Furthermore,\ndeveloping on a recently established connection between polynomial\napproximation and estimation of additive functions of the form $\\sum_{x} f({\\rm\np}_x)$, we reduce the sample complexity for noninteger values of $\\alpha$ by a\nfactor of $\\log k$ compared to the empirical estimator. The estimators\nachieving these bounds are simple and run in time linear in the number of\nsamples. Our lower bounds provide explicit constructions of distributions with\ndifferent R\\'enyi entropies that are hard to distinguish.\n", "versions": [{"version": "v1", "created": "Sat, 2 Aug 2014 18:52:52 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 10:50:49 GMT"}, {"version": "v3", "created": "Thu, 10 Mar 2016 08:35:51 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Acharya", "Jayadev", ""], ["Orlitsky", "Alon", ""], ["Suresh", "Ananda Theertha", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1408.1011", "submitter": "Faegheh Hasibi", "authors": "Faegheh Hasibi, Svein Erik Bratsberg", "title": "Non-hierarchical Structures: How to Model and Index Overlaps?", "comments": "The paper has been accepted at the Balisage 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap is a common phenomenon seen when structural components of a digital\nobject are neither disjoint nor nested inside each other. Overlapping\ncomponents resist reduction to a structural hierarchy, and tree-based indexing\nand query processing techniques cannot be used for them. Our solution to this\ndata modeling problem is TGSA (Tree-like Graph for Structural Annotations), a\nnovel extension of the XML data model for non-hierarchical structures. We\nintroduce an algorithm for constructing TGSA from annotated documents; the\nalgorithm can efficiently process non-hierarchical structures and is associated\nwith formal proofs, ensuring that transformation of the document to the data\nmodel is valid. To enable high performance query analysis in large data\nrepositories, we further introduce an extension of XML pre-post indexing for\nnon-hierarchical structures, which can process both reachability and\noverlapping relationships.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 16:07:11 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 23:12:12 GMT"}, {"version": "v3", "created": "Sat, 8 Oct 2016 06:46:54 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Hasibi", "Faegheh", ""], ["Bratsberg", "Svein Erik", ""]]}, {"id": "1408.1211", "submitter": "Vasilis Syrgkanis", "authors": "Uriel Feige, Michal Feldman, Nicole Immorlica, Rani Izsak, Brendan\n  Lucier, Vasilis Syrgkanis", "title": "A Unifying Hierarchy of Valuations with Complements and Substitutes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new hierarchy over monotone set functions, that we refer to as\n$\\mathcal{MPH}$ (Maximum over Positive Hypergraphs). Levels of the hierarchy\ncorrespond to the degree of complementarity in a given function. The highest\nlevel of the hierarchy, $\\mathcal{MPH}$-$m$ (where $m$ is the total number of\nitems) captures all monotone functions. The lowest level, $\\mathcal{MPH}$-$1$,\ncaptures all monotone submodular functions, and more generally, the class of\nfunctions known as $\\mathcal{XOS}$. Every monotone function that has a positive\nhypergraph representation of rank $k$ (in the sense defined by Abraham,\nBabaioff, Dughmi and Roughgarden [EC 2012]) is in $\\mathcal{MPH}$-$k$. Every\nmonotone function that has supermodular degree $k$ (in the sense defined by\nFeige and Izsak [ITCS 2013]) is in $\\mathcal{MPH}$-$(k+1)$. In both cases, the\nconverse direction does not hold, even in an approximate sense. We present\nadditional results that demonstrate the expressiveness power of\n$\\mathcal{MPH}$-$k$.\n  One can obtain good approximation ratios for some natural optimization\nproblems, provided that functions are required to lie in low levels of the\n$\\mathcal{MPH}$ hierarchy. We present two such applications. One shows that the\nmaximum welfare problem can be approximated within a ratio of $k+1$ if all\nplayers hold valuation functions in $\\mathcal{MPH}$-$k$. The other is an upper\nbound of $2k$ on the price of anarchy of simultaneous first price auctions.\n  Being in $\\mathcal{MPH}$-$k$ can be shown to involve two requirements -- one\nis monotonicity and the other is a certain requirement that we refer to as\n$\\mathcal{PLE}$ (Positive Lower Envelope). Removing the monotonicity\nrequirement, one obtains the $\\mathcal{PLE}$ hierarchy over all non-negative\nset functions (whether monotone or not), which can be fertile ground for\nfurther research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 08:37:36 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Feige", "Uriel", ""], ["Feldman", "Michal", ""], ["Immorlica", "Nicole", ""], ["Izsak", "Rani", ""], ["Lucier", "Brendan", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1408.1265", "submitter": "Gustavo Sacomoto", "authors": "Rui Ferreira, Roberto Grossi, Romeo Rizzi, Gustavo Sacomoto and\n  Marie-France Sagot", "title": "Amortized $\\tilde{O}(|V|)$-Delay Algorithm for Listing Chordless Cycles\n  in Undirected Graphs", "comments": "Accepted in ESA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chordless cycles are very natural structures in undirected graphs, with an\nimportant history and distinguished role in graph theory. Motivated also by\nprevious work on the classical problem of listing cycles, we study how to list\nchordless cycles. The best known solution to list all the $C$ chordless cycles\ncontained in an undirected graph $G = (V,E)$ takes $O(|E|^2 +|E|\\cdot C)$ time.\nIn this paper we provide an algorithm taking $\\tilde{O}(|E| + |V |\\cdot C)$\ntime. We also show how to obtain the same complexity for listing all the $P$\nchordless $st$-paths in $G$ (where $C$ is replaced by $P$ ).\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 12:51:02 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Ferreira", "Rui", ""], ["Grossi", "Roberto", ""], ["Rizzi", "Romeo", ""], ["Sacomoto", "Gustavo", ""], ["Sagot", "Marie-France", ""]]}, {"id": "1408.1340", "submitter": "Marvin K\\\"unnemann", "authors": "Karl Bringmann and Marvin K\\\"unnemann", "title": "Improved approximation for Fr\\'echet distance on c-packed curves\n  matching conditional lower bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fr\\'echet distance is a well-studied and very popular measure of\nsimilarity of two curves. The best known algorithms have quadratic time\ncomplexity, which has recently been shown to be optimal assuming the Strong\nExponential Time Hypothesis (SETH) [Bringmann FOCS'14].\n  To overcome the worst-case quadratic time barrier, restricted classes of\ncurves have been studied that attempt to capture realistic input curves. The\nmost popular such class are c-packed curves, for which the Fr\\'echet distance\nhas a $(1+\\epsilon)$-approximation in time $\\tilde{O}(c n /\\epsilon)$ [Driemel\net al. DCG'12]. In dimension $d \\ge 5$ this cannot be improved to\n$O((cn/\\sqrt{\\epsilon})^{1-\\delta})$ for any $\\delta > 0$ unless SETH fails\n[Bringmann FOCS'14].\n  In this paper, exploiting properties that prevent stronger lower bounds, we\npresent an improved algorithm with runtime $\\tilde{O}(cn/\\sqrt{\\epsilon})$.\nThis is optimal in high dimensions apart from lower order factors unless SETH\nfails. Our main new ingredients are as follows: For filling the classical\nfree-space diagram we project short subcurves onto a line, which yields\none-dimensional separated curves with roughly the same pairwise distances\nbetween vertices. Then we tackle this special case in near-linear time by\ncarefully extending a greedy algorithm for the Fr\\'echet distance of\none-dimensional separated curves.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 16:15:54 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Bringmann", "Karl", ""], ["K\u00fcnnemann", "Marvin", ""]]}, {"id": "1408.1376", "submitter": "Aleksandar Nikolov", "authors": "Jiri Matousek, Aleksandar Nikolov, Kunal Talwar", "title": "Factorization Norms and Hereditary Discrepancy", "comments": "This is an expanded and simplified version, which also mostly\n  subsumes arXiv:1311.6204. The \"ellipsoid infinity norm\" terminology is\n  replaced by the standard factorization norm terminology", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\gamma_2$ norm of a real $m\\times n$ matrix $A$ is the minimum number\n$t$ such that the column vectors of $A$ are contained in a $0$-centered\nellipsoid $E\\subseteq\\mathbb{R}^m$ which in turn is contained in the hypercube\n$[-t, t]^m$. We prove that this classical quantity approximates the\n\\emph{hereditary discrepancy} $\\mathrm{herdisc}\\ A$ as follows: $\\gamma_2(A) =\n{O(\\log m)}\\cdot \\mathrm{herdisc}\\ A$ and $\\mathrm{herdisc}\\ A = O(\\sqrt{\\log\nm}\\,)\\cdot\\gamma_2(A) $. Since $\\gamma_2$ is polynomial-time computable, this\ngives a polynomial-time approximation algorithm for hereditary discrepancy.\nBoth inequalities are shown to be asymptotically tight.\n  We then demonstrate on several examples the power of the $\\gamma_2$ norm as a\ntool for proving lower and upper bounds in discrepancy theory. Most notably, we\nprove a new lower bound of $\\Omega(\\log^{d-1} n)$ for the \\emph{$d$-dimensional\nTusn\\'ady problem}, asking for the combinatorial discrepancy of an $n$-point\nset in $\\mathbb{R}^d$ with respect to axis-parallel boxes. For $d>2$, this\nimproves the previous best lower bound, which was of order approximately\n$\\log^{(d-1)/2}n$, and it comes close to the best known upper bound of\n$O(\\log^{d+1/2}n)$, for which we also obtain a new, very simple proof.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 18:59:10 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 00:28:28 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Matousek", "Jiri", ""], ["Nikolov", "Aleksandar", ""], ["Talwar", "Kunal", ""]]}, {"id": "1408.1429", "submitter": "Umang Bhaskar", "authors": "Umang Bhaskar, Katrina Ligett, Leonard J. Schulman, Chaitanya Swamy", "title": "Achieving Target Equilibria in Network Routing Games without Knowing the\n  Latency Functions", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of network routing games typically assumes, right at the onset,\nprecise and detailed information about the latency functions. Such information\nmay, however, be unavailable or difficult to obtain. Moreover, one is often\nprimarily interested in enforcing a desired target flow as the equilibrium by\nsuitably influencing player behavior in the routing game. We ask whether one\ncan achieve target flows as equilibria without knowing the underlying latency\nfunctions.\n  Our main result gives a crisp positive answer to this question. We show that,\nunder fairly general settings, one can efficiently compute edge tolls that\ninduce a given target multicommodity flow in a nonatomic routing game using a\npolynomial number of queries to an oracle that takes candidate tolls as input\nand returns the resulting equilibrium flow. This result is obtained via a novel\napplication of the ellipsoid method. Our algorithm extends easily to many other\nsettings, such as (i) when certain edges cannot be tolled or there is an upper\nbound on the total toll paid by a user, and (ii) general nonatomic congestion\ngames. We obtain tighter bounds on the query complexity for series-parallel\nnetworks, and single-commodity routing games with linear latency functions, and\ncomplement these with a query-complexity lower bound. We also obtain strong\npositive results for Stackelberg routing to achieve target equilibria in\nseries-parallel graphs.\n  Our results build upon various new techniques that we develop pertaining to\nthe computation of, and connections between, different notions of approximate\nequilibrium; properties of multicommodity flows and tolls in series-parallel\ngraphs; and sensitivity of equilibrium flow with respect to tolls. Our results\ndemonstrate that one can indeed circumvent the potentially-onerous task of\nmodeling latency functions, and yet obtain meaningful results for the\nunderlying routing game.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 21:34:50 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Bhaskar", "Umang", ""], ["Ligett", "Katrina", ""], ["Schulman", "Leonard J.", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1408.1431", "submitter": "Katarzyna Paluch", "authors": "Katarzyna Paluch", "title": "Maximum ATSP with Weights Zero and One via Half-Edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast combinatorial $3/4$-approximation algorithm for the maximum\nasymmetric TSP with weights zero and one. The approximation factor of this\nalgorithm matches the currently best one given by Bl\\\"aser in 2004 and based on\nlinear programming. Our algorithm first computes a maximum size matching and a\nmaximum weight cycle cover without certain cycles of length two but possibly\nwith {\\em half-edges} - a half-edge of a given edge $e$ is informally speaking\na half of $e$ that contains one of the endpoints of $e$. Then from the computed\nmatching and cycle cover it extracts a set of paths, whose weight is large\nenough to be able to construct a traveling salesman tour with the claimed\nguarantee.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 21:37:56 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Paluch", "Katarzyna", ""]]}, {"id": "1408.1461", "submitter": "Arash Rafiey", "authors": "Pavol Hell, Bojan Mohar and Arash Rafiey", "title": "Ordering without forbidden patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F be a set of ordered patterns, i.e., graphs whose vertices are linearly\nordered. An F-free ordering of the vertices of a graph H is a linear ordering\nof V(H) such that none of patterns in F occurs as an induced ordered subgraph.\nWe denote by ORD(F) the decision problem asking whether an input graph admits\nan F-free ordering; we also use ORD(F) to denote the class of graphs that do\nadmit an F-free ordering. It was observed by Damaschke (and others) that many\nnatural graph classes can be described as ORD(F) for sets F of small patterns\n(with three or four vertices). Damaschke also noted that for many sets F\nconsisting of patterns with three vertices, ORD(F) is polynomial-time solvable\nby known algorithms or their simple modifications. We complete the picture by\nproving that all these problems can be solved in polynomial time. In fact, we\nprovide a single master algorithm, i.e., we solve in polynomial time the\nproblem $ORD_3$ in which the input is a set F of patterns with at most three\nvertices and a graph H, and the problem is to decide whether or not H admits an\nF-free ordering of the vertices. Our algorithm certifies non-membership by a\nforbidden substructure, and thus provides a single forbidden structure\ncharacterization for all the graph classes described by some ORD(F) with F\nconsisting of patterns with at most three vertices. Many of the problems ORD(F)\nwith F consisting of larger patterns have been shown to be NP-complete by\nDuffus, Ginn, and Rodl, and we add two simple examples.\n  We also discuss a bipartite version of the problem, BORD(F), in which the\ninput is a bipartite graph H with a fixed bipartition of the vertices, and we\nare given a set F of bipartite patterns. We also describe some examples of\ndigraph ordering problems and algorithms. We conjecture that for every set F of\nforbidden patterns, ORD(F) is either polynomial or NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 01:57:54 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Hell", "Pavol", ""], ["Mohar", "Bojan", ""], ["Rafiey", "Arash", ""]]}, {"id": "1408.1467", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler", "title": "Interactive Channel Capacity Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first capacity approaching coding schemes that robustly\nsimulate any interactive protocol over an adversarial channel that corrupts any\n$\\epsilon$ fraction of the transmitted symbols. Our coding schemes achieve a\ncommunication rate of $1 - O(\\sqrt{\\epsilon \\log \\log 1/\\epsilon})$ over any\nadversarial channel. This can be improved to $1 - O(\\sqrt{\\epsilon})$ for\nrandom, oblivious, and computationally bounded channels, or if parties have\nshared randomness unknown to the channel.\n  Surprisingly, these rates exceed the $1 - \\Omega(\\sqrt{H(\\epsilon)}) = 1 -\n\\Omega(\\sqrt{\\epsilon \\log 1/\\epsilon})$ interactive channel capacity bound\nwhich [Kol and Raz; STOC'13] recently proved for random errors. We conjecture\n$1 - \\Theta(\\sqrt{\\epsilon \\log \\log 1/\\epsilon})$ and $1 -\n\\Theta(\\sqrt{\\epsilon})$ to be the optimal rates for their respective settings\nand therefore to capture the interactive channel capacity for random and\nadversarial errors.\n  In addition to being very communication efficient, our randomized coding\nschemes have multiple other advantages. They are computationally efficient,\nextremely natural, and significantly simpler than prior (non-capacity\napproaching) schemes. In particular, our protocols do not employ any coding but\nallow the original protocol to be performed as-is, interspersed only by short\nexchanges of hash values. When hash values do not match, the parties backtrack.\nOur approach is, as we feel, by far the simplest and most natural explanation\nfor why and how robust interactive communication in a noisy environment is\npossible.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 02:32:15 GMT"}, {"version": "v2", "created": "Mon, 3 Nov 2014 10:59:59 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Haeupler", "Bernhard", ""]]}, {"id": "1408.1483", "submitter": "Ann Becker", "authors": "Ann Becker, Reuven Bar-Yehuada, Dan Geiger", "title": "Random Algorithms for the Loop Cutset Problem", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-49-56", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to find a minimum loop cutset in a Bayesian network with high\nprobability. Finding such a loop cutset is the first step in Pearl's method of\nconditioning for inference. Our random algorithm for finding a loop cutset,\ncalled \"Repeated WGuessI\", outputs a minimum loop cutset, after O(c 6^k k n)\nsteps, with probability at least 1-(1 over{6^k})^{c 6^k}), where c>1 is a\nconstant specified by the user, k is the size of a minimum weight loop cutset,\nand n is the number of vertices. We also show empirically that a variant of\nthis algorithm, called WRA, often finds a loop cutset that is closer to the\nminimum loop cutset than the ones found by the best deterministic algorithms\nknown.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 06:25:05 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Becker", "Ann", ""], ["Bar-Yehuada", "Reuven", ""], ["Geiger", "Dan", ""]]}, {"id": "1408.1577", "submitter": "Kurt Mehlhorn", "authors": "Khaled Elbassioni and Kurt Mehlhorn and Fahimeh Ramezani", "title": "Towards More Practical Linear Programming-based Techniques for\n  Algorithmic Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R. Lavy and C. Swamy (FOCS 2005, J. ACM 2011) introduced a general method for\nobtaining truthful-in-expectation mechanisms from linear programming based\napproximation algorithms. Due to the use of the Ellipsoid method, a direct\nimplementation of the method is unlikely to be efficient in practice. We\npropose to use the much simpler and usually faster multiplicative weights\nupdate method instead. The simplification comes at the cost of slightly weaker\napproximation and truthfulness guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 13:11:33 GMT"}, {"version": "v2", "created": "Tue, 5 May 2015 21:01:45 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2015 04:13:23 GMT"}, {"version": "v4", "created": "Tue, 14 Jun 2016 09:59:46 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Elbassioni", "Khaled", ""], ["Mehlhorn", "Kurt", ""], ["Ramezani", "Fahimeh", ""]]}, {"id": "1408.1655", "submitter": "Jonathan Ullman", "authors": "Moritz Hardt and Jonathan Ullman", "title": "Preventing False Discovery in Interactive Data Analysis is Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, under a standard hardness assumption, there is no\ncomputationally efficient algorithm that given $n$ samples from an unknown\ndistribution can give valid answers to $n^{3+o(1)}$ adaptively chosen\nstatistical queries. A statistical query asks for the expectation of a\npredicate over the underlying distribution, and an answer to a statistical\nquery is valid if it is \"close\" to the correct expectation over the\ndistribution.\n  Our result stands in stark contrast to the well known fact that exponentially\nmany statistical queries can be answered validly and efficiently if the queries\nare chosen non-adaptively (no query may depend on the answers to previous\nqueries). Moreover, a recent work by Dwork et al. shows how to accurately\nanswer exponentially many adaptively chosen statistical queries via a\ncomputationally inefficient algorithm; and how to answer a quadratic number of\nadaptive queries via a computationally efficient algorithm. The latter result\nimplies that our result is tight up to a linear factor in $n.$\n  Conceptually, our result demonstrates that achieving statistical validity\nalone can be a source of computational intractability in adaptive settings. For\nexample, in the modern large collaborative research environment, data analysts\ntypically choose a particular approach based on previous findings. False\ndiscovery occurs if a research finding is supported by the data but not by the\nunderlying distribution. While the study of preventing false discovery in\nStatistics is decades old, to the best of our knowledge our result is the first\nto demonstrate a computational barrier. In particular, our result suggests that\nthe perceived difficulty of preventing false discovery in today's collaborative\nresearch environment may be inherent.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 17:39:56 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Hardt", "Moritz", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1408.1681", "submitter": "Ankur Moitra", "authors": "Ankur Moitra", "title": "Super-resolution, Extremal Functions and the Condition Number of\n  Vandermonde Matrices", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Super-resolution is a fundamental task in imaging, where the goal is to\nextract fine-grained structure from coarse-grained measurements. Here we are\ninterested in a popular mathematical abstraction of this problem that has been\nwidely studied in the statistics, signal processing and machine learning\ncommunities. We exactly resolve the threshold at which noisy super-resolution\nis possible. In particular, we establish a sharp phase transition for the\nrelationship between the cutoff frequency ($m$) and the separation ($\\Delta$).\nIf $m > 1/\\Delta + 1$, our estimator converges to the true values at an inverse\npolynomial rate in terms of the magnitude of the noise. And when $m <\n(1-\\epsilon) /\\Delta$ no estimator can distinguish between a particular pair of\n$\\Delta$-separated signals even if the magnitude of the noise is exponentially\nsmall.\n  Our results involve making novel connections between {\\em extremal functions}\nand the spectral properties of Vandermonde matrices. We establish a sharp phase\ntransition for their condition number which in turn allows us to give the first\nnoise tolerance bounds for the matrix pencil method. Moreover we show that our\nmethods can be interpreted as giving preconditioners for Vandermonde matrices,\nand we use this observation to design faster algorithms for super-resolution.\nWe believe that these ideas may have other applications in designing faster\nalgorithms for other basic tasks in signal processing.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 18:54:19 GMT"}, {"version": "v2", "created": "Fri, 8 Aug 2014 12:42:01 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2015 20:35:47 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2015 02:18:44 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Moitra", "Ankur", ""]]}, {"id": "1408.1693", "submitter": "Timothy Hunter", "authors": "Timothy Hunter, Ahmed El Alaoui, Alexandre Bayen", "title": "Computing the log-determinant of symmetric, diagonally dominant matrices\n  in near-linear time", "comments": "Submitted to the SIAM Journal on Computing (SICOMP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for computing the log-determinant of symmetric,\ndiagonally dominant matrices. Existing algorithms run with cubic complexity\nwith respect to the size of the matrix in the worst case. Our algorithm\ncomputes an approximation of the log-determinant in time near-linear with\nrespect to the number of non-zero entries and with high probability. This\nalgorithm builds upon the utra-sparsifiers introduced by Spielman and Teng for\nLaplacian matrices and ultimately uses their refined versions introduced by\nKoutis, Miller and Peng in the context of solving linear systems. We also\npresent simpler algorithms that compute upper and lower bounds and that may be\nof more immediate practical interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Aug 2014 05:15:37 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Hunter", "Timothy", ""], ["Alaoui", "Ahmed El", ""], ["Bayen", "Alexandre", ""]]}, {"id": "1408.1816", "submitter": "Ashley Montanaro", "authors": "Ashley Montanaro", "title": "Quantum pattern matching fast on average", "comments": "22 pages, 2 figures; v3: further minor changes, essentially published\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $d$-dimensional pattern matching problem is to find an occurrence of a\npattern of length $m \\times \\dots \\times m$ within a text of length $n \\times\n\\dots \\times n$, with $n \\ge m$. This task models various problems in text and\nimage processing, among other application areas. This work describes a quantum\nalgorithm which solves the pattern matching problem for random patterns and\ntexts in time $\\widetilde{O}((n/m)^{d/2} 2^{O(d^{3/2}\\sqrt{\\log m})})$. For\nlarge $m$ this is super-polynomially faster than the best possible classical\nalgorithm, which requires time $\\widetilde{\\Omega}( (n/m)^d + n^{d/2} )$. The\nalgorithm is based on the use of a quantum subroutine for finding hidden shifts\nin $d$ dimensions, which is a variant of algorithms proposed by Kuperberg.\n", "versions": [{"version": "v1", "created": "Fri, 8 Aug 2014 11:03:35 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2015 16:13:42 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2015 05:25:00 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Montanaro", "Ashley", ""]]}, {"id": "1408.1847", "submitter": "Marc Heinrich", "authors": "Marc Heinrich and Alexander Munteanu and Christian Sohler", "title": "Asymptotically exact streaming algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new computational model for data streams: asymptotically exact\nstreaming algorithms. These algorithms have an approximation ratio that tends\nto one as the length of the stream goes to infinity while the memory used by\nthe algorithm is restricted to polylog(n) size. Thus, the output of the\nalgorithm is optimal in the limit. We show positive results in our model for a\nseries of important problems that have been discussed in the streaming\nliterature. These include computing the frequency moments, clustering problems\nand least squares regression. Our results also include lower bounds for\nproblems, which have streaming algorithms in the ordinary setting but do not\nallow for sublinear space algorithms in our model.\n", "versions": [{"version": "v1", "created": "Fri, 8 Aug 2014 13:27:31 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Heinrich", "Marc", ""], ["Munteanu", "Alexander", ""], ["Sohler", "Christian", ""]]}, {"id": "1408.2157", "submitter": "Tobias Christiani", "authors": "Tobias Christiani and Rasmus Pagh", "title": "Generating k-independent variables in constant time", "comments": "Accepted to The 55th Annual Symposium on Foundations of Computer\n  Science (FOCS 2014). Copyright IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of pseudorandom elements over finite fields is fundamental to\nthe time, space and randomness complexity of randomized algorithms and data\nstructures. We consider the problem of generating $k$-independent random values\nover a finite field $\\mathbb{F}$ in a word RAM model equipped with constant\ntime addition and multiplication in $\\mathbb{F}$, and present the first\nnontrivial construction of a generator that outputs each value in constant\ntime, not dependent on $k$. Our generator has period length\n$|\\mathbb{F}|\\,\\mbox{poly} \\log k$ and uses $k\\,\\mbox{poly}(\\log k) \\log\n|\\mathbb{F}|$ bits of space, which is optimal up to a $\\mbox{poly} \\log k$\nfactor. We are able to bypass Siegel's lower bound on the time-space tradeoff\nfor $k$-independent functions by a restriction to sequential evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 9 Aug 2014 21:42:05 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Christiani", "Tobias", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1408.2159", "submitter": "Roozbeh Ebrahimi", "authors": "Roozbeh Ebrahimi, Jie Gao, Golnaz Ghasemiesfeh, Grant Schoenebeck", "title": "Complex Contagions in Kleinberg's Small World Model", "comments": "arXiv admin note: text overlap with arXiv:1404.2668", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex contagions describe diffusion of behaviors in a social network in\nsettings where spreading requires the influence by two or more neighbors. In a\n$k$-complex contagion, a cluster of nodes are initially infected, and\nadditional nodes become infected in the next round if they have at least $k$\nalready infected neighbors. It has been argued that complex contagions better\nmodel behavioral changes such as adoption of new beliefs, fashion trends or\nexpensive technology innovations. This has motivated rigorous understanding of\nspreading of complex contagions in social networks. Despite simple contagions\n($k=1$) that spread fast in all small world graphs, how complex contagions\nspread is much less understood. Previous work~\\cite{Ghasemiesfeh:2013:CCW}\nanalyzes complex contagions in Kleinberg's small world\nmodel~\\cite{kleinberg00small} where edges are randomly added according to a\nspatial distribution (with exponent $\\gamma$) on top of a two dimensional grid\nstructure. It has been shown in~\\cite{Ghasemiesfeh:2013:CCW} that the speed of\ncomplex contagions differs exponentially when $\\gamma=0$ compared to when\n$\\gamma=2$.\n  In this paper, we fully characterize the entire parameter space of $\\gamma$\nexcept at one point, and provide upper and lower bounds for the speed of\n$k$-complex contagions. We study two subtly different variants of Kleinberg's\nsmall world model and show that, with respect to complex contagions, they\nbehave differently. For each model and each $k \\geq 2$, we show that there is\nan intermediate range of values, such that when $\\gamma$ takes any of these\nvalues, a $k$-complex contagion spreads quickly on the corresponding graph, in\na polylogarithmic number of rounds. However, if $\\gamma$ is outside this range,\nthen a $k$-complex contagion requires a polynomial number of rounds to spread\nto the entire network.\n", "versions": [{"version": "v1", "created": "Sat, 9 Aug 2014 22:18:05 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Ebrahimi", "Roozbeh", ""], ["Gao", "Jie", ""], ["Ghasemiesfeh", "Golnaz", ""], ["Schoenebeck", "Grant", ""]]}, {"id": "1408.2270", "submitter": "Sida Wang", "authors": "Roy Frostig, Sida I. Wang", "title": "A sub-constant improvement in approximating the positive semidefinite\n  Grothendieck problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite relaxations are a powerful tool for approximately solving\ncombinatorial optimization problems such as MAX-CUT and the Grothendieck\nproblem. By exploiting a bounded rank property of extreme points in the\nsemidefinite cone, we make a sub-constant improvement in the approximation\nratio of one such problem. Precisely, we describe a polynomial-time algorithm\nfor the positive semidefinite Grothendieck problem -- based on rounding from\nthe standard relaxation -- that achieves a ratio of $2/\\pi + \\Theta(1/{\\sqrt\nn})$, whereas the previous best is $2/\\pi + \\Theta(1/n)$. We further show a\ncorresponding integrality gap of $2/\\pi+\\tilde{O}(1/n^{1/3})$.\n", "versions": [{"version": "v1", "created": "Sun, 10 Aug 2014 20:14:27 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Frostig", "Roy", ""], ["Wang", "Sida I.", ""]]}, {"id": "1408.2279", "submitter": "Tsvi Kopelowitz", "authors": "Amihood Amir, Oren Kapah, Tsvi Kopelowitz, Moni Naor, Ely Porat", "title": "The Family Holiday Gathering Problem or Fair and Periodic Scheduling of\n  Independent Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and examine the {\\em Holiday Gathering Problem} which models the\ndifficulty that couples have when trying to decide with which parents should\nthey spend the holiday. Our goal is to schedule the family gatherings so that\nthe parents that will be {\\em happy}, i.e.\\ all their children will be home\n{\\em simultaneously} for the holiday festivities, while minimizing the number\nof consecutive holidays in which parents are not happy.\n  The holiday gathering problem is closely related to several classical\nproblems in computer science, such as the {\\em dining philosophers problem} on\na general graph and periodic scheduling,and has applications in scheduling of\ntransmissions made by cellular radios. We also show interesting connections\nbetween periodic scheduling, coloring, and universal prefix free encodings.\n  The combinatorial definition of the Holiday Gathering Problem is: given a\ngraph $G$, find an infinite sequence of independent-sets of $G$. The objective\nfunction is to minimize, for every node $v$, the maximal gap between two\nappearances of $v$. In good solutions this gap depends on local properties of\nthe node (i.e., its degree) and the the solution should be periodic, i.e.\\ a\nnode appears every fixed number of periods. We show a coloring-based\nconstruction where the period of each node colored with the $c$ is at most\n$2^{1+\\log^*c}\\cdot\\prod_{i=0}^{\\log^*c} \\log^{(i)}c$ (where $\\log^{(i)}$ means\niterating the $\\log$ function $i$ times). This is achieved via a connection\nwith {\\it prefix-free encodings}. We prove that this is the best possible for\ncoloring-based solutions. We also show a construction with period at most $2d$\nfor a node of degree $d$.\n", "versions": [{"version": "v1", "created": "Sun, 10 Aug 2014 23:04:15 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Amir", "Amihood", ""], ["Kapah", "Oren", ""], ["Kopelowitz", "Tsvi", ""], ["Naor", "Moni", ""], ["Porat", "Ely", ""]]}, {"id": "1408.2292", "submitter": "Jingwei Sun", "authors": "Jingwei Sun, Guangzhong Sun", "title": "SPLZ: An Efficient Algorithm for Single Source Shortest Path Problem\n  Using Compression Method", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient solution of the single source shortest path (SSSP) problem on road\nnetworks is an important requirement for numerous real-world applications. This\npaper introduces an algorithm for the SSSP problem using compression method.\nOwning to precomputing and storing all-pairs shortest path (APSP), the process\nof solving SSSP problem is a simple lookup of a little data from precomputed\nAPSP and decompression. APSP without compression needs at least 1TB memory for\na road network with one million vertices. Our algorithm can compress such an\nAPSP into several GB, and ensure a good performance of decompression. In our\nexperiment on a dataset about Northwest USA (with 1.2 millions vertices), our\nmethod can achieve about three orders of magnitude faster than Dijkstra\nalgorithm based on binary heap.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 01:40:00 GMT"}, {"version": "v2", "created": "Sun, 11 Jan 2015 11:57:32 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Sun", "Jingwei", ""], ["Sun", "Guangzhong", ""]]}, {"id": "1408.2350", "submitter": "Braha Riva Shalom", "authors": "Amihood Amir, Avivit Levy, Ely Porat, B. Riva Shalom", "title": "Dictionary Matching with One Gap", "comments": "A preliminary version was published at CPM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dictionary matching with gaps problem is to preprocess a dictionary $D$\nof $d$ gapped patterns $P_1,\\ldots,P_d$ over alphabet $\\Sigma$, where each\ngapped pattern $P_i$ is a sequence of subpatterns separated by bounded\nsequences of don't cares. Then, given a query text $T$ of length $n$ over\nalphabet $\\Sigma$, the goal is to output all locations in $T$ in which a\npattern $P_i\\in D$, $1\\leq i\\leq d$, ends. There is a renewed current interest\nin the gapped matching problem stemming from cyber security. In this paper we\nsolve the problem where all patterns in the dictionary have one gap with at\nleast $\\alpha$ and at most $\\beta$ don't cares, where $\\alpha$ and $\\beta$ are\ngiven parameters. Specifically, we show that the dictionary matching with a\nsingle gap problem can be solved in either $O(d\\log d + |D|)$ time and\n$O(d\\log^{\\varepsilon} d + |D|)$ space, and query time $O(n(\\beta -\\alpha\n)\\log\\log d \\log ^2 \\min \\{ d, \\log |D| \\} + occ)$, where $occ$ is the number\nof patterns found, or preprocessing time and space: $O(d^2 + |D|)$, and query\ntime $O(n(\\beta -\\alpha ) + occ)$, where $occ$ is the number of patterns found.\nAs far as we know, this is the best solution for this setting of the problem,\nwhere many overlaps may exist in the dictionary.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 08:35:29 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Amir", "Amihood", ""], ["Levy", "Avivit", ""], ["Porat", "Ely", ""], ["Shalom", "B. Riva", ""]]}, {"id": "1408.2425", "submitter": "Anand Louis", "authors": "Anand Louis", "title": "Hypergraph Markov Operators, Eigenvalues and Approximation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Cheeger's Inequality \\cite{am85,a86} establishes a bound on\nthe expansion of a graph via its spectrum. This inequality is central to a rich\nspectral theory of graphs, based on studying the eigenvalues and eigenvectors\nof the adjacency matrix (and other related matrices) of graphs. It has remained\nopen to define a suitable spectral model for hypergraphs whose spectra can be\nused to estimate various combinatorial properties of the hypergraph.\n  In this paper we introduce a new hypergraph Laplacian operator (generalizing\nthe Laplacian matrix of graphs)and study its spectra. We prove a Cheeger-type\ninequality for hypergraphs, relating the second smallest eigenvalue of this\noperator to the expansion of the hypergraph. We bound other hypergraph\nexpansion parameters via higher eigenvalues of this operator. We give bounds on\nthe diameter of the hypergraph as a function of the second smallest eigenvalue\nof the Laplacian operator. The Markov process underlying the Laplacian operator\ncan be viewed as a dispersion process on the vertices of the hypergraph that\nmight be of independent interest. We bound the {\\em Mixing-time} of this\nprocess as a function of the second smallest eigenvalue of the Laplacian\noperator. All these results are generalizations of the corresponding results\nfor graphs.\n  We show that there can be no linear operator for hypergraphs whose spectra\ncaptures hypergraph expansion in a Cheeger-like manner. For any $k$, we give a\npolynomial time algorithm to compute an approximation to the $k^{th}$ smallest\neigenvalue of the operator. We show that this approximation factor is optimal\nunder the SSE hypothesis (introduced by \\cite{rs10}) for constant values of\n$k$.\n  Finally, using the factor preserving reduction from vertex expansion in\ngraphs to hypergraph expansion, we show that all our results for hypergraphs\nextend to vertex expansion in graphs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 14:39:56 GMT"}, {"version": "v2", "created": "Thu, 30 Oct 2014 17:17:56 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Louis", "Anand", ""]]}, {"id": "1408.2504", "submitter": "Ping Li", "authors": "Ping Li and Cun-Hui Zhang", "title": "Compressed Sensing with Very Sparse Gaussian Random Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of very sparse random projections for compressed sensing\n(sparse signal recovery) when the signal entries can be either positive or\nnegative. In our setting, the entries of a Gaussian design matrix are randomly\nsparsified so that only a very small fraction of the entries are nonzero. Our\nproposed decoding algorithm is simple and efficient in that the major cost is\none linear scan of the coordinates. We have developed two estimators: (i) the\n{\\em tie estimator}, and (ii) the {\\em absolute minimum estimator}. Using only\nthe tie estimator, we are able to recover a $K$-sparse signal of length $N$\nusing $1.551 eK \\log K/\\delta$ measurements (where $\\delta\\leq 0.05$ is the\nconfidence). Using only the absolute minimum estimator, we can detect the\nsupport of the signal using $eK\\log N/\\delta$ measurements. For a particular\ncoordinate, the absolute minimum estimator requires fewer measurements (i.e.,\nwith a constant $e$ instead of $1.551e$). Thus, the two estimators can be\ncombined to form an even more practical decoding framework.\n  Prior studies have shown that existing one-scan (or roughly one-scan)\nrecovery algorithms using sparse matrices would require substantially more\n(e.g., one order of magnitude) measurements than L1 decoding by linear\nprogramming, when the nonzero entries of signals can be either negative or\npositive. In this paper, following a known experimental setup, we show that, at\nthe same number of measurements, the recovery accuracies of our proposed method\nare (at least) similar to the standard L1 decoding.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 19:55:11 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Li", "Ping", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1408.2595", "submitter": "Fabrizio Frati", "authors": "Markus Chimani, Giuseppe Di Battista, Fabrizio Frati and Karsten Klein", "title": "Advances on Testing C-Planarity of Embedded Flat Clustered Graphs", "comments": "Accepted at GD '14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a polynomial-time algorithm for testing c-planarity of embedded flat\nclustered graphs with at most two vertices per cluster on each face.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 01:05:40 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Chimani", "Markus", ""], ["Di Battista", "Giuseppe", ""], ["Frati", "Fabrizio", ""], ["Klein", "Karsten", ""]]}, {"id": "1408.2604", "submitter": "Alan Roytman", "authors": "Vladimir Braverman, Rafail Ostrovsky, Alan Roytman", "title": "Universal Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of data, a typical approach in streaming algorithms is to\ndesign a sophisticated algorithm with small memory that computes a specific\nstatistic over the streaming data. Usually, if one wants to compute a different\nstatistic after the stream is gone, it is impossible. But what if we want to\ncompute a different statistic after the fact? In this paper, we consider the\nfollowing fascinating possibility: can we collect some small amount of specific\ndata during the stream that is \"universal,\" i.e., where we do not know anything\nabout the statistics we will want to later compute, other than the guarantee\nthat had we known the statistic ahead of time, it would have been possible to\ndo so with small memory? In other words, is it possible to collect some data in\nsmall space during the stream, such that any other statistic that can be\ncomputed with comparable space can be computed after the fact? This is indeed\nwhat we introduce (and show) in this paper with matching upper and lower\nbounds: we show that it is possible to collect universal statistics of\npolylogarithmic size, and prove that these universal statistics allow us after\nthe fact to compute all other statistics that are computable with similar\namounts of memory. We show that this is indeed possible, both for the standard\nunbounded streaming model and the sliding window streaming model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 02:37:12 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Braverman", "Vladimir", ""], ["Ostrovsky", "Rafail", ""], ["Roytman", "Alan", ""]]}, {"id": "1408.2782", "submitter": "Will Rosenbaum", "authors": "Rafail Ostrovsky, Will Rosenbaum", "title": "Fast distributed almost stable marriages", "comments": "Various improvements in version 2: algorithms for general (not just\n  \"almost regular\") preferences; deterministic variant of the algorithm;\n  streamlined proof of approximation guarantee", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their seminal work on the Stable Marriage Problem, Gale and Shapley\ndescribe an algorithm which finds a stable matching in $O(n^2)$ communication\nrounds. Their algorithm has a natural interpretation as a distributed algorithm\nwhere each player is represented by a single processor. In this distributed\nmodel, Floreen, Kaski, Polishchuk, and Suomela recently showed that for bounded\npreference lists, terminating the Gale-Shapley algorithm after a constant\nnumber of rounds results in an almost stable matching. In this paper, we\ndescribe a new deterministic distributed algorithm which finds an almost stable\nmatching in $O(\\log^5 n)$ communication rounds for arbitrary preferences. We\nalso present a faster randomized variant which requires $O(\\log^2 n)$ rounds.\nThis run-time can be improved to $O(1)$ rounds for \"almost regular\" (and in\nparticular complete) preferences. To our knowledge, these are the first\nsub-polynomial round distributed algorithms for any variant of the stable\nmarriage problem with unbounded preferences.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 17:26:00 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 05:33:36 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Ostrovsky", "Rafail", ""], ["Rosenbaum", "Will", ""]]}, {"id": "1408.2858", "submitter": "Francesco Silvestri", "authors": "Matteo Ceccarello and Francesco Silvestri", "title": "Experimental Evaluation of Multi-Round Matrix Multiplication on\n  MapReduce", "comments": "Proc. of 17th Meeting on Algorithm Engineering and Experiments\n  (ALENEX), 2015. The code is publicly available at http://www.dei.unipd.it/m3", "journal-ref": null, "doi": "10.1137/1.9781611973754.11", "report-no": null, "categories": "cs.DC cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach in the design of MapReduce algorithms is to minimize the\nnumber of rounds. Indeed, there are many examples in the literature of\nmonolithic MapReduce algorithms, which are algorithms requiring just one or two\nrounds. However, we claim that the design of monolithic algorithms may not be\nthe best approach in cloud systems. Indeed, multi-round algorithms may exploit\nsome features of cloud platforms by suitably setting the round number according\nto the execution context. In this paper we carry out an experimental study of\nmulti-round MapReduce algorithms aiming at investigating the performance of the\nmulti-round approach. We use matrix multiplication as a case study. We first\npropose a scalable Hadoop library, named M$_3$, for matrix multiplication in\nthe dense and sparse cases which allows to tradeoff round number with the\namount of data shuffled in each round and the amount of memory required by\nreduce functions. Then, we present an extensive study of this library on an\nin-house cluster and on Amazon Web Services aiming at showing its performance\nand at comparing monolithic and multi-round approaches. The experiments show\nthat, even without a low level optimization, it is possible to design\nmulti-round algorithms with a small running time overhead.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 21:23:11 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 22:25:08 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Ceccarello", "Matteo", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1408.2927", "submitter": "Jingdong Wang", "authors": "Jingdong Wang, Heng Tao Shen, Jingkuan Song, and Jianqiu Ji", "title": "Hashing for Similarity Search: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search (nearest neighbor search) is a problem of pursuing the data\nitems whose distances to a query item are the smallest from a large database.\nVarious methods have been developed to address this problem, and recently a lot\nof efforts have been devoted to approximate search. In this paper, we present a\nsurvey on one of the main solutions, hashing, which has been widely studied\nsince the pioneering work locality sensitive hashing. We divide the hashing\nalgorithms two main categories: locality sensitive hashing, which designs hash\nfunctions without exploring the data distribution and learning to hash, which\nlearns hash functions according the data distribution, and review them from\nvarious aspects, including hash function design and distance measure and search\nscheme in the hash coding space.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 07:29:12 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Wang", "Jingdong", ""], ["Shen", "Heng Tao", ""], ["Song", "Jingkuan", ""], ["Ji", "Jianqiu", ""]]}, {"id": "1408.3044", "submitter": "Benjamin Albrecht", "authors": "Benjamin Albrecht", "title": "Computing Hybridization Networks for Multiple Rooted Binary Phylogenetic\n  Trees by Maximum Acyclic Agreement Forests", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a known fact that, given two rooted binary phylogenetic trees, the\nconcept of maximum acyclic agreement forests is sufficient to compute\nhybridization networks with minimum hybridization number. In this work, we\ndemonstrate by first presenting an algorithm and then showing its correctness,\nthat this concept is also sufficient in the case of multiple input trees. More\nprecisely, we show that for computing minimum hybridization networks for\nmultiple rooted binary phylogenetic trees on the same set of taxa it suffices\nto take only maximum acyclic agreement forests into account. Moreover, this\narticle contains a proof showing that the minimum hybridization number for a\nset of rooted binary phylogenetic trees on the same set of taxa can be also\ncomputed by solving subproblems referring to common clusters of the input\ntrees.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 16:15:09 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2015 16:42:43 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2015 16:39:30 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Albrecht", "Benjamin", ""]]}, {"id": "1408.3045", "submitter": "Mikkel Thorup", "authors": "Mihai Patrascu and Mikkel Thorup", "title": "Dynamic Integer Sets with Optimal Rank, Select, and Predecessor Search", "comments": "Presented with different formatting in Proceedings of the 55nd IEEE\n  Symposium on Foundations of Computer Science (FOCS), 2014, pp. 166--175. The\n  new version fixes a bug in one of the bounds stated for predecessor search,\n  pointed out to me by Djamal Belazzougui", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data structure representing a dynamic set S of w-bit integers on\na w-bit word RAM. With |S|=n and w > log n and space O(n), we support the\nfollowing standard operations in O(log n / log w) time:\n  - insert(x) sets S = S + {x}. - delete(x) sets S = S - {x}. - predecessor(x)\nreturns max{y in S | y< x}. - successor(x) returns min{y in S | y >= x}. -\nrank(x) returns #{y in S | y< x}. - select(i) returns y in S with rank(y)=i, if\nany.\n  Our O(log n/log w) bound is optimal for dynamic rank and select, matching a\nlower bound of Fredman and Saks [STOC'89]. When the word length is large, our\ntime bound is also optimal for dynamic predecessor, matching a static lower\nbound of Beame and Fich [STOC'99] whenever log n/log w=O(log w/loglog w).\n  Technically, the most interesting aspect of our data structure is that it\nsupports all the above operations in constant time for sets of size n=w^{O(1)}.\nThis resolves a main open problem of Ajtai, Komlos, and Fredman [FOCS'83].\nAjtai et al. presented such a data structure in Yao's abstract cell-probe model\nwith w-bit cells/words, but pointed out that the functions used could not be\nimplemented. As a partial solution to the problem, Fredman and Willard\n[STOC'90] introduced a fusion node that could handle queries in constant time,\nbut used polynomial time on the updates. We call our small set data structure a\ndynamic fusion node as it does both queries and updates in constant time.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 16:17:21 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 12:53:32 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Patrascu", "Mihai", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1408.3093", "submitter": "Simon Puglisi", "authors": "Djamal Belazzougui, Simon J. Puglisi and Yasuo Tabei", "title": "Rank, select and access in grammar-compressed strings", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a string $S$ of length $N$ on a fixed alphabet of $\\sigma$ symbols, a\ngrammar compressor produces a context-free grammar $G$ of size $n$ that\ngenerates $S$ and only $S$. In this paper we describe data structures to\nsupport the following operations on a grammar-compressed string:\n$\\mbox{rank}_c(S,i)$ (return the number of occurrences of symbol $c$ before\nposition $i$ in $S$); $\\mbox{select}_c(S,i)$ (return the position of the $i$th\noccurrence of $c$ in $S$); and $\\mbox{access}(S,i,j)$ (return substring\n$S[i,j]$). For rank and select we describe data structures of size\n$O(n\\sigma\\log N)$ bits that support the two operations in $O(\\log N)$ time. We\npropose another structure that uses $O(n\\sigma\\log (N/n)(\\log N)^{1+\\epsilon})$\nbits and that supports the two queries in $O(\\log N/\\log\\log N)$, where\n$\\epsilon>0$ is an arbitrary constant. To our knowledge, we are the first to\nstudy the asymptotic complexity of rank and select in the grammar-compressed\nsetting, and we provide a hardness result showing that significantly improving\nthe bounds we achieve would imply a major breakthrough on a hard\ngraph-theoretical problem. Our main result for access is a method that requires\n$O(n\\log N)$ bits of space and $O(\\log N+m/\\log_\\sigma N)$ time to extract\n$m=j-i+1$ consecutive symbols from $S$. Alternatively, we can achieve $O(\\log\nN/\\log\\log N+m/\\log_\\sigma N)$ query time using $O(n\\log (N/n)(\\log\nN)^{1+\\epsilon})$ bits of space. This matches a lower bound stated by Verbin\nand Yu for strings where $N$ is polynomially related to $n$.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 19:18:36 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2014 15:20:57 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Puglisi", "Simon J.", ""], ["Tabei", "Yasuo", ""]]}, {"id": "1408.3310", "submitter": "Giovanni Paolini", "authors": "Giovanni Paolini", "title": "An algorithm for canonical forms of finite subsets of $\\mathbb{Z}^d$ up\n  to affinities", "comments": null, "journal-ref": "Discrete & Computational Geometry 58 (2), pp. 293-312 (2017)", "doi": "10.1007/s00454-017-9895-6", "report-no": null, "categories": "cs.DS cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an algorithm for the computation of canonical forms\nof finite subsets of $\\mathbb{Z}^d$, up to affinities over $\\mathbb{Z}$. For\nfixed dimension $d$, this algorithm has worst-case asymptotic complexity $O(n\n\\log^2 n \\, s\\,\\mu(s))$, where $n$ is the number of points in the given subset,\n$s$ is an upper bound to the size of the binary representation of any of the\n$n$ points, and $\\mu(s)$ is an upper bound to the number of operations required\nto multiply two $s$-bit numbers. In particular, the problem is fixed-parameter\ntractable with respect to the dimension $d$. This problem arises e.g. in the\ncontext of computation of invariants of finitely presented groups with\nabelianized group isomorphic to $\\mathbb{Z}^d$. In that context one needs to\ndecide whether two Laurent polynomials in $d$ indeterminates, considered as\nelements of the group ring over the abelianized group, are equivalent with\nrespect to a change of basis.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 15:02:40 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 13:35:23 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2016 21:48:12 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 06:32:57 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Paolini", "Giovanni", ""]]}, {"id": "1408.3325", "submitter": "Philipp Kindermann", "authors": "Michael A. Bekos and Thomas C. van Dijk and Philipp Kindermann and\n  Alexander Wolff", "title": "Simultaneous Drawing of Planar Graphs with Right-Angle Crossings and Few\n  Bends", "comments": null, "journal-ref": "J. Graph Algorithms Appl. 20(1): 133-158 (2016)", "doi": "10.7155/jgaa.00388", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two planar graphs that are defined on the same set of vertices, a RAC\nsimultaneous drawing is one in which each graph is drawn planar, there are no\nedge overlaps and the crossings between the two graphs form right angles. The\ngeometric version restricts the problem to straight-line drawings. It is known,\nhowever, that there exists a wheel and a matching which do not admit a\ngeometric RAC simultaneous drawing.\n  In order to enlarge the class of graphs that admit RAC simultaneous drawings,\nwe allow bends in the resulting drawings. We prove that two planar graphs\nalways admit a RAC simultaneous drawing with six bends per edge each, in\nquadratic area. For more restricted classes of planar graphs (i.e., matchings,\npaths, cycles, outerplanar graphs and subhamiltonian graphs), we manage to\nsignificantly reduce the required number of bends per edge, while keeping the\narea quadratic.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 16:02:49 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 17:11:01 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Bekos", "Michael A.", ""], ["van Dijk", "Thomas C.", ""], ["Kindermann", "Philipp", ""], ["Wolff", "Alexander", ""]]}, {"id": "1408.3374", "submitter": "Arthur Flajolet", "authors": "Arthur Flajolet and Sebastien Blandin and Patrick Jaillet", "title": "Robust Adaptive Routing Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding an optimal history-dependent routing\nstrategy on a directed graph weighted by stochastic arc costs when the\nobjective is to minimize the risk of spending more than a prescribed budget. To\nhelp mitigate the impact of the lack of information on the arc cost probability\ndistributions, we introduce a robust counterpart where the distributions are\nonly known through confidence intervals on some statistics such as the mean,\nthe mean absolute deviation, and any quantile. Leveraging recent results in\ndistributionally robust optimization, we develop a general-purpose algorithm to\ncompute an approximate optimal strategy. To illustrate the benefits of the\nrobust approach, we run numerical experiments with field data from the\nSingapore road network.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 18:19:20 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 19:11:31 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Flajolet", "Arthur", ""], ["Blandin", "Sebastien", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1408.3590", "submitter": "Roland Mark\\'o", "authors": "Marek Karpinski and Roland Mark\\'o", "title": "Complexity of Nondeterministic Graph Parameter Testing", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of nondeterministically testable graph\nparameters and improve existing bounds on it by several orders of magnitude.\nThe technique used would be also of independent interest. We also discuss the\nspecial case of weak nondeterministic testing for uniform hypergraphs of\narbitrary order.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 17:13:13 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 14:13:45 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Karpinski", "Marek", ""], ["Mark\u00f3", "Roland", ""]]}, {"id": "1408.3977", "submitter": "Sadagopan Narasimhan", "authors": "Vandhana.C and S.Hima Bindhu and P.Renjith and N.Sadagopan and\n  B.Supraja", "title": "Spanning Tree Enumeration in 2-trees: Sequential and Parallel\n  Perspective", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a connected graph, a vertex separator is a set of vertices whose removal\ncreates at least two components. A vertex separator $S$ is minimal if it\ncontains no other separator as a strict subset and a minimum vertex separator\nis a minimal vertex separator of least cardinality. A {\\em clique} is a set of\nmutually adjacent vertices. A 2-tree is a connected graph in which every\nmaximal clique is of size three and every minimal vertex separator is of size\ntwo. A spanning tree of a graph $G$ is a connected and an acyclic subgraph of\n$G$. In this paper, we focus our attention on two enumeration problems, both\nfrom sequential and parallel perspective. In particular, we consider listing\nall possible spanning trees of a 2-tree and listing all perfect elimination\norderings of a chordal graph. As far as enumeration of spanning trees is\nconcerned, our approach is incremental in nature and towards this end, we work\nwith the construction order of the 2-tree, i.e. enumeration of $n$-vertex trees\nare from $n-1$ vertex trees, $n \\geq 4$. Further, we also present a parallel\nalgorithm for spanning tree enumeration using $O(2^n)$ processors. To our\nknowledge, this paper makes the first attempt in designing a parallel algorithm\nfor this problem. We conclude this paper by presenting a sequential and\nparallel algorithm for enumerating all Perfect Elimination Orderings of a\nchordal graph.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 11:19:02 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["C", "Vandhana.", ""], ["Bindhu", "S. Hima", ""], ["Renjith", "P.", ""], ["Sadagopan", "N.", ""], ["Supraja", "B.", ""]]}, {"id": "1408.4045", "submitter": "Soledad Villar", "authors": "Pranjal Awasthi, Afonso S. Bandeira, Moses Charikar, Ravishankar\n  Krishnaswamy, Soledad Villar, Rachel Ward", "title": "Relax, no need to round: integrality of clustering formulations", "comments": "30 pages, ITCS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exact recovery conditions for convex relaxations of point cloud\nclustering problems, focusing on two of the most common optimization problems\nfor unsupervised clustering: $k$-means and $k$-median clustering. Motivations\nfor focusing on convex relaxations are: (a) they come with a certificate of\noptimality, and (b) they are generic tools which are relatively parameter-free,\nnot tailored to specific assumptions over the input. More precisely, we\nconsider the distributional setting where there are $k$ clusters in\n$\\mathbb{R}^m$ and data from each cluster consists of $n$ points sampled from a\nsymmetric distribution within a ball of unit radius. We ask: what is the\nminimal separation distance between cluster centers needed for convex\nrelaxations to exactly recover these $k$ clusters as the optimal integral\nsolution? For the $k$-median linear programming relaxation we show a tight\nbound: exact recovery is obtained given arbitrarily small pairwise separation\n$\\epsilon > 0$ between the balls. In other words, the pairwise center\nseparation is $\\Delta > 2+\\epsilon$. Under the same distributional model, the\n$k$-means LP relaxation fails to recover such clusters at separation as large\nas $\\Delta = 4$. Yet, if we enforce PSD constraints on the $k$-means LP, we get\nexact cluster recovery at center separation $\\Delta > 2\\sqrt2(1+\\sqrt{1/m})$.\nIn contrast, common heuristics such as Lloyd's algorithm (a.k.a. the $k$-means\nalgorithm) can fail to recover clusters in this setting; even with arbitrarily\nlarge cluster separation, k-means++ with overseeding by any constant factor\nfails with high probability at exact cluster recovery. To complement the\ntheoretical analysis, we provide an experimental study of the recovery\nguarantees for these various methods, and discuss several open problems which\nthese experiments suggest.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 15:42:16 GMT"}, {"version": "v2", "created": "Tue, 7 Oct 2014 18:37:34 GMT"}, {"version": "v3", "created": "Wed, 10 Dec 2014 18:07:10 GMT"}, {"version": "v4", "created": "Tue, 10 Feb 2015 16:11:36 GMT"}, {"version": "v5", "created": "Wed, 15 Apr 2015 02:11:54 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Bandeira", "Afonso S.", ""], ["Charikar", "Moses", ""], ["Krishnaswamy", "Ravishankar", ""], ["Villar", "Soledad", ""], ["Ward", "Rachel", ""]]}, {"id": "1408.4048", "submitter": "Pasin Manurangsi", "authors": "Pasin Manurangsi and Dana Moshkovitz", "title": "Improved Approximation Algorithms for Projection Games", "comments": "41 pages, 2 figure", "journal-ref": null, "doi": "10.1007/s00453-015-0088-5", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The projection games (aka Label-Cover) problem is of great importance to the\nfield of approximation algorithms, since most of the NP-hardness of\napproximation results we know today are reductions from Label-Cover. In this\npaper we design several approximation algorithms for projection games: 1. A\npolynomial-time approximation algorithm that improves on the previous best\napproximation by Charikar, Hajiaghayi and Karloff. 2. A sub-exponential time\nalgorithm with much tighter approximation for the case of smooth projection\ngames. 3. A polynomial-time approximation scheme (PTAS) for projection games on\nplanar graphs and a tight running time lower bound for such approximation\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 15:48:53 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 08:30:08 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Manurangsi", "Pasin", ""], ["Moshkovitz", "Dana", ""]]}, {"id": "1408.4072", "submitter": "Eugene Wu", "authors": "Leilani Battle, Edward Benson, Aditya Parameswaran, Eugene Wu", "title": "Indexing Cost Sensitive Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are often used for real-time decision making. However,\ntypical machine learning techniques ignore feature evaluation cost, and focus\nsolely on the accuracy of the machine learning models obtained utilizing all\nthe features available. We develop algorithms and indexes to support\ncost-sensitive prediction, i.e., making decisions using machine learning models\ntaking feature evaluation cost into account. Given an item and a online\ncomputation cost (i.e., time) budget, we present two approaches to return an\nappropriately chosen machine learning model that will run within the specified\ntime on the given item. The first approach returns the optimal machine learning\nmodel, i.e., one with the highest accuracy, that runs within the specified\ntime, but requires significant up-front precomputation time. The second\napproach returns a possibly sub- optimal machine learning model, but requires\nlittle up-front precomputation time. We study these two algorithms in detail\nand characterize the scenarios (using real and synthetic data) in which each\nperforms well. Unlike prior work that focuses on a narrow domain or a specific\nalgorithm, our techniques are very general: they apply to any cost-sensitive\nprediction scenario on any machine learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 07:21:48 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Battle", "Leilani", ""], ["Benson", "Edward", ""], ["Parameswaran", "Aditya", ""], ["Wu", "Eugene", ""]]}, {"id": "1408.4113", "submitter": "Costas Constantinou Ph.D.", "authors": "Costas K. Constantinou, Georgios Ellinas, Christos Panayiotou and\n  Marios Polycarpou", "title": "Fast Shortest Path Routing in Transportation Networks with\n  Time-Dependent Road Speeds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper deals with the subject of shortest path routing in\ntransportation networks (in terms of travelling time), where the speed in\nseveral of the network's roads is a function of the time interval. The main\ncontribution of the paper is a procedure that is faster compared to the\nconventional approaches, that derives the road's traversal time according to\nthe time instant of departure, for the case where the road's speed has a\nconstant value inside each time interval (in general, different value for each\ntime interval). Furthermore, the case where the road's speed is a linear\nfunction of time inside each time interval (in general, different linear\nfunction for each time interval) is investigated. A procedure that derives the\nroad's traversal time according to the time instant of departure is proposed\nfor this case as well. The proposed procedures are combined with Dijkstra's\nalgorithm and the resulting algorithms, that are practically applicable and of\nlow complexity, provide optimal shortest path routing in the networks under\ninvestigation.\n", "versions": [{"version": "v1", "created": "Sun, 17 Aug 2014 18:07:08 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 14:11:22 GMT"}, {"version": "v3", "created": "Mon, 8 Sep 2014 14:32:53 GMT"}, {"version": "v4", "created": "Wed, 24 Sep 2014 09:22:30 GMT"}, {"version": "v5", "created": "Tue, 5 May 2015 12:17:58 GMT"}, {"version": "v6", "created": "Thu, 7 Jan 2016 00:36:34 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Constantinou", "Costas K.", ""], ["Ellinas", "Georgios", ""], ["Panayiotou", "Christos", ""], ["Polycarpou", "Marios", ""]]}, {"id": "1408.4156", "submitter": "Shahin Kamali", "authors": "Shahin Kamali and Alejandro L\\'opez-Ortiz", "title": "Efficient Online Strategies for Renting Servers in the Cloud", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cloud systems, we often deal with jobs that arrive and depart in an online\nmanner. Upon its arrival, a job should be assigned to a server. Each job has a\nsize which defines the amount of resources that it needs. Servers have uniform\ncapacity and, at all times, the total size of jobs assigned to a server should\nnot exceed the capacity. This setting is closely related to the classic bin\npacking problem. The difference is that, in bin packing, the objective is to\nminimize the total number of used servers. In the Cloud, however, the charge\nfor each server is proportional to the length of the time interval it is rented\nfor, and the goal is to minimize the cost involved in renting all used servers.\nRecently, certain bin packing strategies were considered for renting servers in\nthe Cloud [Li et al. SPAA'14]. There, it is proved that all Any-Fit bin packing\nstrategy has a competitive ratio of at least $\\mu$, where $\\mu$ is the max/min\ninterval length ratio of jobs. It is also shown that First Fit has a\ncompetitive ratio of $2\\mu + 13$ while Best Fit is not competitive at all. We\nobserve that the lower bound of $\\mu$ extends to all online algorithms. We also\nprove that, surprisingly, Next Fit algorithm has competitive ratio of at most\n$2 \\mu +1$. We also show that a variant of Next Fit achieves a competitive\nratio of $K \\times max\\{1,\\mu/(K-1)\\}+1$, where $K$ is a parameter of the\nalgorithm. In particular, if the value of $\\mu$ is known, the algorithm has a\ncompetitive ratio of $\\mu+2$; this improves upon the existing upper bound of\n$\\mu+8$. Finally, we introduce a simple algorithm called Move To Front (MTF)\nwhich has a competitive ratio of at most $6\\mu + 7$ and also promising\naverage-case performance. We experimentally study the average-case performance\nof different algorithms and observe that the typical behaviour of MTF is\ndistinctively better than other algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 20:53:39 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Kamali", "Shahin", ""], ["L\u00f3pez-Ortiz", "Alejandro", ""]]}, {"id": "1408.4230", "submitter": "Shiva Manne", "authors": "Shiva Manne and Manjish Pal", "title": "Fast Approximate Matrix Multiplication by Solving Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, we present novel deterministic algorithms for multiplying two\n$n \\times n$ matrices approximately. Given two matrices $A,B$ we return a\nmatrix $C'$ which is an \\emph{approximation} to $C = AB$. We consider the\nnotion of approximate matrix multiplication in which the objective is to make\nthe Frobenius norm of the error matrix $C-C'$ arbitrarily small. Our main\ncontribution is to first reduce the matrix multiplication problem to solving a\nset of linear equations and then use standard techniques to find an approximate\nsolution to that system in $\\tilde{O}(n^2)$ time. To the best of our knowledge\nthis the first examination into designing quadratic time deterministic\nalgorithms for approximate matrix multiplication which guarantee arbitrarily\nlow \\emph{absolute error} w.r.t. Frobenius norm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 07:03:32 GMT"}, {"version": "v2", "created": "Wed, 20 Aug 2014 09:51:15 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Manne", "Shiva", ""], ["Pal", "Manjish", ""]]}, {"id": "1408.4263", "submitter": "Robert Ganian", "authors": "Simone Bova, Robert Ganian, Stefan Szeider", "title": "Quantified Conjunctive Queries on Partially Ordered Sets", "comments": "Accepted at IPEC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational problem of checking whether a quantified\nconjunctive query (a first-order sentence built using only conjunction as\nBoolean connective) is true in a finite poset (a reflexive, antisymmetric, and\ntransitive directed graph). We prove that the problem is already NP-hard on a\ncertain fixed poset, and investigate structural properties of posets yielding\nfixed-parameter tractability when the problem is parameterized by the query.\nOur main algorithmic result is that model checking quantified conjunctive\nqueries on posets of bounded width is fixed-parameter tractable (the width of a\nposet is the maximum size of a subset of pairwise incomparable elements). We\ncomplement our algorithmic result by complexity results with respect to classes\nof finite posets in a hierarchy of natural poset invariants, establishing its\ntightness in this sense.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 09:36:39 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Bova", "Simone", ""], ["Ganian", "Robert", ""], ["Szeider", "Stefan", ""]]}, {"id": "1408.4389", "submitter": "Jincheng Mei", "authors": "Jincheng Mei, Kang Zhao and Bao-Liang Lu", "title": "On Unconstrained Quasi-Submodular Function Optimization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the extensive application of submodularity, its generalizations are\nconstantly being proposed. However, most of them are tailored for special\nproblems. In this paper, we focus on quasi-submodularity, a universal\ngeneralization, which satisfies weaker properties than submodularity but still\nenjoys favorable performance in optimization. Similar to the diminishing return\nproperty of submodularity, we first define a corresponding property called the\n{\\em single sub-crossing}, then we propose two algorithms for unconstrained\nquasi-submodular function minimization and maximization, respectively. The\nproposed algorithms return the reduced lattices in $\\mathcal{O}(n)$ iterations,\nand guarantee the objective function values are strictly monotonically\nincreased or decreased after each iteration. Moreover, any local and global\noptima are definitely contained in the reduced lattices. Experimental results\nverify the effectiveness and efficiency of the proposed algorithms on lattice\nreduction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 16:43:49 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 11:02:41 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Mei", "Jincheng", ""], ["Zhao", "Kang", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1408.4424", "submitter": "Hu Fu", "authors": "Shuchi Chawla, Hu Fu, Anna Karlin", "title": "Approximate Revenue Maximization in Interdependent Value Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study revenue maximization in settings where agents' values are\ninterdependent: each agent receives a signal drawn from a correlated\ndistribution and agents' values are functions of all of the signals. We\nintroduce a variant of the generalized VCG auction with reserve prices and\nrandom admission, and show that this auction gives a constant approximation to\nthe optimal expected revenue in matroid environments. Our results do not\nrequire any assumptions on the signal distributions, however, they require the\nvalue functions to satisfy a standard single-crossing property and a\nconcavity-type condition.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 18:45:26 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Chawla", "Shuchi", ""], ["Fu", "Hu", ""], ["Karlin", "Anna", ""]]}, {"id": "1408.4490", "submitter": "Mehrdad Niknami", "authors": "Mehrdad Niknami, Samitha Samaranayake", "title": "Tractable Pathfinding for the Stochastic On-Time Arrival Problem", "comments": "Submission accepted by the International Symposium on Experimental\n  Algorithms 2016 and published by Springer in the Lecture Notes in Computer\n  Science series on June 1, 2016. Includes typographical corrections and\n  modifications to pre-processing made after the initial submission to SODA'15\n  (July 7, 2014)", "journal-ref": "LNCS 9685 (SEA 2016) 231-245", "doi": "10.1007/978-3-319-38851-9_16", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new and more efficient technique for computing the route that\nmaximizes the probability of on-time arrival in stochastic networks, also known\nas the path-based stochastic on-time arrival (SOTA) problem. Our primary\ncontribution is a pathfinding algorithm that uses the solution to the\npolicy-based SOTA problem---which is of pseudo-polynomial-time complexity in\nthe time budget of the journey---as a search heuristic for the optimal path. In\nparticular, we show that this heuristic can be exceptionally efficient in\npractice, effectively making it possible to solve the path-based SOTA problem\nas quickly as the policy-based SOTA problem. Our secondary contribution is the\nextension of policy-based preprocessing to path-based preprocessing for the\nSOTA problem. In the process, we also introduce Arc-Potentials, a more\nefficient generalization of Stochastic Arc-Flags that can be used for both\npolicy- and path-based SOTA. After developing the pathfinding and preprocessing\nalgorithms, we evaluate their performance on two different real-world networks.\nTo the best of our knowledge, these techniques provide the most efficient\ncomputation strategy for the path-based SOTA problem for general probability\ndistributions, both with and without preprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 21:57:57 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 21:07:41 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Niknami", "Mehrdad", ""], ["Samaranayake", "Samitha", ""]]}, {"id": "1408.4900", "submitter": "Nathan Lindzey", "authors": "Nathan Lindzey", "title": "Speeding Up Graph Algorithms via Switching Classes", "comments": "To appear in IWOCA 2014: 25th International Workshop on Combinatorial\n  Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$, a vertex switch of $v \\in V(G)$ results in a new graph\nwhere neighbors of $v$ become nonneighbors and vice versa. This operation gives\nrise to an equivalence relation over the set of labeled digraphs on $n$\nvertices. The equivalence class of $G$ with respect to the switching operation\nis commonly referred to as $G$'s switching class. The algebraic and\ncombinatorial properties of switching classes have been studied in depth;\nhowever, they have not been studied as thoroughly from an algorithmic point of\nview. The intent of this work is to further investigate the algorithmic\nproperties of switching classes. In particular, we show that switching classes\ncan be used to asymptotically speed up several super-linear unweighted graph\nalgorithms. The current techniques for speeding up graph algorithms are all\nsomewhat involved insofar that they employ sophisticated pre-processing,\ndata-structures, or use \"word tricks\" on the RAM model to achieve at most a\n$O(\\log(n))$ speed up for sufficiently dense graphs. Our methods are much\nsimpler and can result in super-polylogarithmic speedups. In particular, we\nachieve better bounds for diameter, transitive closure, bipartite maximum\nmatching, and general maximum matching.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 06:52:18 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Lindzey", "Nathan", ""]]}, {"id": "1408.4942", "submitter": "Shri Prakash Dwivedi", "authors": "Shri Prakash Dwivedi", "title": "Computing Multiplicative Order and Primitive Root in Finite Cyclic Group", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/IC3.2014.6897161", "report-no": null, "categories": "cs.SC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplicative order of an element $a$ of group $G$ is the least positive\ninteger $n$ such that $a^n=e$, where $e$ is the identity element of $G$. If the\norder of an element is equal to $|G|$, it is called generator or primitive\nroot. This paper describes the algorithms for computing multiplicative order\nand primitive root in $\\mathbb{Z}^*_{p}$, we also present a logarithmic\nimprovement over classical algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 10:36:15 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Dwivedi", "Shri Prakash", ""]]}, {"id": "1408.4944", "submitter": "Neelima Gupta", "authors": "Neelima Gupta and Shubham Gupta", "title": "Approximation algorithms for Capacitated Facility Location Problem with\n  Penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of capacitated facility location\nproblem with penalties (CapFLPP) paid per unit of unserved demand. In case of\nuncapacitated FLP with penalties demands of a client are either entirely met or\nare entirely rejected and penalty is paid. In the uncapacitated case, there is\nno reason to serve a client partially. Whereas, in case of CapFLPP, it may be\nbeneficial to serve a client partially instead of not serving at all and, pay\nthe penalty for the unmet demand. Charikar et. al.\n\\cite{charikar2001algorithms}, Jain et. al. \\cite{jain2003greedy} and Xu- Xu\n\\cite{xu2009improved} gave $3$, $2$ and $1.8526$ approximation, respectively,\nfor the uncapacitated case . We present $(5.83 + \\epsilon)$ factor for the case\nof uniform capacities and $(8.532 + \\epsilon)$ factor for non-uniform\ncapacities.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 10:42:50 GMT"}, {"version": "v2", "created": "Mon, 25 Aug 2014 16:12:40 GMT"}, {"version": "v3", "created": "Wed, 3 Sep 2014 06:17:09 GMT"}, {"version": "v4", "created": "Fri, 12 Sep 2014 16:23:45 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Gupta", "Neelima", ""], ["Gupta", "Shubham", ""]]}, {"id": "1408.5096", "submitter": "Stephen Chestnut", "authors": "Vladimir Braverman and Stephen R. Chestnut", "title": "Universal sketches for the frequency negative moments and other\n  decreasing streaming sums", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream with frequencies $f_d$, for $d\\in[n]$, we characterize the\nspace necessary for approximating the frequency negative moments $F_p=\\sum\n|f_d|^p$, where $p<0$ and the sum is taken over all items $d\\in[n]$ with\nnonzero frequency, in terms of $n$, $\\epsilon$, and $m=\\sum |f_d|$. To\naccomplish this, we actually prove a much more general result. Given any\nnonnegative and nonincreasing function $g$, we characterize the space necessary\nfor any streaming algorithm that outputs a $(1\\pm\\epsilon)$-approximation to\n$\\sum g(|f_d|)$, where again the sum is over items with nonzero frequency. The\nstorage required is expressed in the form of the solution to a relatively\nsimple nonlinear optimization problem, and the algorithm is universal for\n$(1\\pm\\epsilon)$-approximations to any such sum where the applied function is\nnonnegative, nonincreasing, and has the same or smaller space complexity as\n$g$. This partially answers an open question of Nelson (IITK Workshop Kanpur,\n2009).\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 18:24:10 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 19:22:09 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Braverman", "Vladimir", ""], ["Chestnut", "Stephen R.", ""]]}, {"id": "1408.5099", "submitter": "Cameron Musco", "authors": "Michael B. Cohen, Yin Tat Lee, Cameron Musco, Christopher Musco,\n  Richard Peng, Aaron Sidford", "title": "Uniform Sampling for Matrix Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random sampling has become a critical tool in solving massive matrix\nproblems. For linear regression, a small, manageable set of data rows can be\nrandomly selected to approximate a tall, skinny data matrix, improving\nprocessing time significantly. For theoretical performance guarantees, each row\nmust be sampled with probability proportional to its statistical leverage\nscore. Unfortunately, leverage scores are difficult to compute.\n  A simple alternative is to sample rows uniformly at random. While this often\nworks, uniform sampling will eliminate critical row information for many\nnatural instances. We take a fresh look at uniform sampling by examining what\ninformation it does preserve. Specifically, we show that uniform sampling\nyields a matrix that, in some sense, well approximates a large fraction of the\noriginal. While this weak form of approximation is not enough for solving\nlinear regression directly, it is enough to compute a better approximation.\n  This observation leads to simple iterative row sampling algorithms for matrix\napproximation that run in input-sparsity time and preserve row structure and\nsparsity at all intermediate steps. In addition to an improved understanding of\nuniform sampling, our main proof introduces a structural result of independent\ninterest: we show that every matrix can be made to have low coherence by\nreweighting a small subset of its rows.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 18:32:00 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Cohen", "Michael B.", ""], ["Lee", "Yin Tat", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Peng", "Richard", ""], ["Sidford", "Aaron", ""]]}, {"id": "1408.5108", "submitter": "Robin Houston", "authors": "Robin Houston", "title": "Tackling the Minimal Superpermutation Problem", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A superpermutation on $n$ symbols is a string that contains each of the $n!$\npermutations of the $n$ symbols as a contiguous substring. The shortest\nsuperpermutation on $n$ symbols was conjectured to have length $\\sum_{i=1}^n\ni!$. The conjecture had been verified for $n \\leq 5$. We disprove it by\nexhibiting an explicit counterexample for $n=6$. This counterexample was found\nby encoding the problem as an instance of the (asymmetric) Traveling Salesman\nProblem, and searching for a solution using a powerful heuristic solver.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 18:52:00 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Houston", "Robin", ""]]}, {"id": "1408.5412", "submitter": "Michaela Rombach", "authors": "Christopher Purcell and M. Puck Rombach", "title": "On the Complexity of Role Colouring Planar Graphs, Trees and Cographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several results about the complexity of the role colouring problem.\nA role colouring of a graph $G$ is an assignment of colours to the vertices of\n$G$ such that two vertices of the same colour have identical sets of colours in\ntheir neighbourhoods. We show that the problem of finding a role colouring with\n$1< k <n$ colours is NP-hard for planar graphs. We show that restricting the\nproblem to trees yields a polynomially solvable case, as long as $k$ is either\nconstant or has a constant difference with $n$, the number of vertices in the\ntree. Finally, we prove that cographs are always $k$-role-colourable for\n$1<k\\leq n$ and construct such a colouring in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 16:33:49 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Purcell", "Christopher", ""], ["Rombach", "M. Puck", ""]]}, {"id": "1408.5422", "submitter": "Igor Stassiy", "authors": "Igor Stassiy", "title": "Analysis of String Sorting using Heapsort", "comments": "Master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this master thesis we analyze the complexity of sorting a set of strings.\nIt was shown that the complexity of sorting strings can be naturally expressed\nin terms of the prefix trie induced by the set of strings. The model of\ncomputation takes into account symbol comparisons and not just comparisons\nbetween the strings. The analysis of upper and lower bounds for some classical\nalgorithms such as Quicksort and Mergesort in terms of such a model was shown.\nHere we extend the analysis to another classical algorithm - Heapsort. We also\ngive analysis for the version of the algorithm that uses Binomial heaps as a\nheap implementation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 11:40:01 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Stassiy", "Igor", ""]]}, {"id": "1408.5518", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui", "title": "Faster construction of asymptotically good unit-cost error correcting\n  codes in the RAM model", "comments": "Manuscript (5 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming we are in a Word-RAM model with word size $w$, we show that we can\nconstruct in $o(w)$ time an error correcting code with a constant relative\npositive distance that maps numbers of $w$ bits into $\\Theta(w)$-bit numbers,\nand such that the application of the error-correcting code on any given number\n$x\\in[0,2^w-1]$ takes constant time. Our result improves on a previously\nproposed error-correcting code with the same properties whose construction time\nwas exponential in $w$.\n", "versions": [{"version": "v1", "created": "Sat, 23 Aug 2014 18:28:32 GMT"}, {"version": "v2", "created": "Sun, 14 Sep 2014 18:27:56 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Belazzougui", "Djamal", ""]]}, {"id": "1408.5530", "submitter": "Dan He", "authors": "Dan He, Zhanyong Wang, Laxmi Parida, Eleazar Eskin", "title": "IPED2: Inheritance Path based Pedigree Reconstruction Algorithm for\n  Complicated Pedigrees", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of family trees, or pedigree reconstruction, for a group of\nindividuals is a fundamental problem in genetics. The problem is known to be\nNP-hard even for datasets known to only contain siblings. Some recent methods\nhave been developed to accurately and efficiently reconstruct pedigrees. These\nmethods, however, still consider relatively simple pedigrees, for example, they\nare not able to handle half-sibling situations where a pair of individuals only\nshare one parent. In this work, we propose an efficient method, IPED2, based on\nour previous work, which specifically targets reconstruction of complicated\npedigrees that include half-siblings. We note that the presence of\nhalf-siblings makes the reconstruction problem significantly more challenging\nwhich is why previous methods exclude the possibility of half-siblings. We\nproposed a novel model as well as an efficient graph algorithm and experiments\nshow that our algorithm achieves relatively accurate reconstruction. To our\nknowledge, this is the first method that is able to handle pedigree\nreconstruction based on genotype data only when half-sibling exists in any\ngeneration of the pedigree.\n", "versions": [{"version": "v1", "created": "Sat, 23 Aug 2014 21:01:50 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["He", "Dan", ""], ["Wang", "Zhanyong", ""], ["Parida", "Laxmi", ""], ["Eskin", "Eleazar", ""]]}, {"id": "1408.5920", "submitter": "Michael Bekos", "authors": "Michael A. Bekos, Martin Gronemann, Michael Kaufmann, and Robert Krug", "title": "Planar Octilinear Drawings with One Bend Per Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In octilinear drawings of planar graphs, every edge is drawn as an\nalternating sequence of horizontal, vertical and diagonal ($45^\\circ$)\nline-segments. In this paper, we study octilinear drawings of low edge\ncomplexity, i.e., with few bends per edge. A $k$-planar graph is a planar graph\nin which each vertex has degree less or equal to $k$. In particular, we prove\nthat every 4-planar graph admits a planar octilinear drawing with at most one\nbend per edge on an integer grid of size $O(n^2) \\times O(n)$. For 5-planar\ngraphs, we prove that one bend per edge still suffices in order to construct\nplanar octilinear drawings, but in super-polynomial area. However, for 6-planar\ngraphs we give a class of graphs whose planar octilinear drawings require at\nleast two bends per edge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 20:26:34 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Bekos", "Michael A.", ""], ["Gronemann", "Martin", ""], ["Kaufmann", "Michael", ""], ["Krug", "Robert", ""]]}, {"id": "1408.5939", "submitter": "Glencora Borradaile", "authors": "Glencora Borradaile, David Eppstein, Pingan Zhu", "title": "Planar Induced Subgraphs of Sparse Graphs", "comments": "Accepted by Graph Drawing 2014. To appear in Journal of Graph\n  Algorithms and Applications", "journal-ref": "J. Graph Algorithms & Applications 19(1): 281-297, 2015", "doi": "10.7155/jgaa.00358", "report-no": null, "categories": "cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every graph has an induced pseudoforest of at least $n-m/4.5$\nvertices, an induced partial 2-tree of at least $n-m/5$ vertices, and an\ninduced planar subgraph of at least $n-m/5.2174$ vertices. These results are\nconstructive, implying linear-time algorithms to find the respective induced\nsubgraphs. We also show that the size of the largest $K_h$-minor-free graph in\na given graph can sometimes be at most $n-m/6+o(m)$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 22:20:51 GMT"}, {"version": "v2", "created": "Tue, 12 May 2015 22:36:06 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Borradaile", "Glencora", ""], ["Eppstein", "David", ""], ["Zhu", "Pingan", ""]]}, {"id": "1408.5995", "submitter": "Minming Li", "authors": "Minming Li, Frances F. Yao, Hao Yuan", "title": "An $O(n^2)$ Algorithm for Computing Optimal Continuous Voltage Schedules", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Voltage Scaling techniques allow the processor to set its speed\ndynamically in order to reduce energy consumption. In the continuous model, the\nprocessor can run at any speed, while in the discrete model, the processor can\nonly run at finite number of speeds given as input. The current best algorithm\nfor computing the optimal schedules for the continuous model runs at $O(n^2\\log\nn)$ time for scheduling $n$ jobs. In this paper, we improve the running time to\n$O(n^2)$ by speeding up the calculation of s-schedules using a more refined\ndata structure. For the discrete model, we improve the computation of the\noptimal schedule from the current best $O(dn\\log n)$ to $O(n\\log \\max\\{d,n\\})$\nwhere $d$ is the number of allowed speeds.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 03:23:05 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Li", "Minming", ""], ["Yao", "Frances F.", ""], ["Yuan", "Hao", ""]]}, {"id": "1408.6157", "submitter": "Tomasz Kociumaka", "authors": "Marek Cygan, Tomasz Kociumaka", "title": "Approximating Upper Degree-Constrained Partial Orientations", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Upper Degree-Constrained Partial Orientation problem we are given an\nundirected graph $G=(V,E)$, together with two degree constraint functions\n$d^-,d^+ : V \\to \\mathbb{N}$. The goal is to orient as many edges as possible,\nin such a way that for each vertex $v \\in V$ the number of arcs entering $v$ is\nat most $d^-(v)$, whereas the number of arcs leaving $v$ is at most $d^+(v)$.\nThis problem was introduced by Gabow [SODA'06], who proved it to be MAXSNP-hard\n(and thus APX-hard). In the same paper Gabow presented an LP-based iterative\nrounding $4/3$-approximation algorithm.\n  Since the problem in question is a special case of the classic 3-Dimensional\nMatching, which in turn is a special case of the $k$-Set Packing problem, it is\nreasonable to ask whether recent improvements in approximation algorithms for\nthe latter two problems [Cygan, FOCS'13; Sviridenko & Ward, ICALP'13] allow for\nan improved approximation for Upper Degree-Constrained Partial Orientation. We\nfollow this line of reasoning and present a polynomial-time local search\nalgorithm with approximation ratio $5/4+\\varepsilon$. Our algorithm uses a\ncombination of two types of rules: improving sets of bounded pathwidth from the\nrecent $4/3+\\varepsilon$-approximation algorithm for 3-Set Packing [Cygan,\nFOCS'13], and a simple rule tailor-made for the setting of partial\norientations. In particular, we exploit the fact that one can check in\npolynomial time whether it is possible to orient all the edges of a given graph\n[Gy\\'arf\\'as & Frank, Combinatorics'76].\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 15:32:19 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 08:45:19 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Cygan", "Marek", ""], ["Kociumaka", "Tomasz", ""]]}, {"id": "1408.6182", "submitter": "Tomasz Kociumaka", "authors": "Maxim Babenko, Pawe{\\l} Gawrychowski, Tomasz Kociumaka, Tatiana\n  Starikovskaya", "title": "Wavelet Trees Meet Suffix Trees", "comments": "33 pages, 5 figures; preliminary version published at SODA 2015", "journal-ref": null, "doi": "10.1137/1.9781611973730.39", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved wavelet tree construction algorithm and discuss its\napplications to a number of rank/select problems for integer keys and strings.\n  Given a string of length n over an alphabet of size $\\sigma\\leq n$, our\nmethod builds the wavelet tree in $O(n \\log \\sigma/ \\sqrt{\\log{n}})$ time,\nimproving upon the state-of-the-art algorithm by a factor of $\\sqrt{\\log n}$.\nAs a consequence, given an array of n integers we can construct in $O(n\n\\sqrt{\\log n})$ time a data structure consisting of $O(n)$ machine words and\ncapable of answering rank/select queries for the subranges of the array in\n$O(\\log n / \\log \\log n)$ time. This is a $\\log \\log n$-factor improvement in\nquery time compared to Chan and P\\u{a}tra\\c{s}cu and a $\\sqrt{\\log n}$-factor\nimprovement in construction time compared to Brodal et al.\n  Next, we switch to stringological context and propose a novel notion of\nwavelet suffix trees. For a string w of length n, this data structure occupies\n$O(n)$ words, takes $O(n \\sqrt{\\log n})$ time to construct, and simultaneously\ncaptures the combinatorial structure of substrings of w while enabling\nefficient top-down traversal and binary search. In particular, with a wavelet\nsuffix tree we are able to answer in $O(\\log |x|)$ time the following two\nnatural analogues of rank/select queries for suffixes of substrings: for\nsubstrings x and y of w count the number of suffixes of x that are\nlexicographically smaller than y, and for a substring x of w and an integer k,\nfind the k-th lexicographically smallest suffix of x.\n  We further show that wavelet suffix trees allow to compute a\nrun-length-encoded Burrows-Wheeler transform of a substring x of w in $O(s \\log\n|x|)$ time, where s denotes the length of the resulting run-length encoding.\nThis answers a question by Cormode and Muthukrishnan, who considered an\nanalogous problem for Lempel-Ziv compression.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 16:44:53 GMT"}, {"version": "v2", "created": "Fri, 29 Aug 2014 15:37:54 GMT"}, {"version": "v3", "created": "Mon, 13 Oct 2014 10:58:04 GMT"}, {"version": "v4", "created": "Fri, 15 May 2015 17:17:18 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Babenko", "Maxim", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Kociumaka", "Tomasz", ""], ["Starikovskaya", "Tatiana", ""]]}, {"id": "1408.6196", "submitter": "Mingyu Xiao", "authors": "Mingyu Xiao and Hiroshi Nagamochi", "title": "Exact Algorithms for Dominating Induced Matching Based on Graph\n  Partition", "comments": null, "journal-ref": "Discrete Applied Mathematics 190-191: 147-162 (2015)", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dominating induced matching, also called an efficient edge domination, of a\ngraph $G=(V,E)$ with $n=|V|$ vertices and $m=|E|$ edges is a subset $F\n\\subseteq E$ of edges in the graph such that no two edges in $F$ share a common\nendpoint and each edge in $E\\setminus F$ is incident with exactly one edge in\n$F$. It is NP-hard to decide whether a graph admits a dominating induced\nmatching or not. In this paper, we design a $1.1467^nn^{O(1)}$-time exact\nalgorithm for this problem, improving all previous results. This problem can be\nredefined as a partition problem that is to partition the vertex set of a graph\ninto two parts $I$ and $F$, where $I$ induces an independent set (a 0-regular\ngraph) and $F$ induces a perfect matching (a 1-regular graph). After giving\nseveral structural properties of the problem, we show that the problem always\ncontains some \"good vertices\", branching on which by including them to either\n$I$ or $F$ we can effectively reduce the graph. This leads to a fast exact\nalgorithm to this problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 18:10:49 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Xiao", "Mingyu", ""], ["Nagamochi", "Hiroshi", ""]]}, {"id": "1408.6198", "submitter": "Laurent No\\'e", "authors": "Gregory Kucherov and Laurent No\\'e and Mikhail Roytberg", "title": "Subset seed automaton", "comments": "12 pages, 2 figures, 2 tables, CIAA 2007,\n  http://hal.inria.fr/inria-00170414/en/", "journal-ref": "LNCS 4783 (2007), pp 180-191", "doi": "10.1007/978-3-540-76336-9_18", "report-no": null, "categories": "cs.FL cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the pattern matching automaton introduced in (A unifying framework\nfor seed sensitivity and its application to subset seeds) for the purpose of\nseed-based similarity search. We show that our definition provides a compact\nautomaton, much smaller than the one obtained by applying the Aho-Corasick\nconstruction. We study properties of this automaton and present an efficient\nimplementation of the automaton construction. We also present some experimental\nresults and show that this automaton can be successfully applied to more\ngeneral situations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 12:49:43 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Kucherov", "Gregory", ""], ["No\u00e9", "Laurent", ""], ["Roytberg", "Mikhail", ""]]}, {"id": "1408.6252", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Zhenfu Cao and Lihua Liu", "title": "Remarks on Quantum Modular Exponentiation and Some Experimental\n  Demonstrations of Shor's Algorithm", "comments": "12 pages,5 figures. The original version has 6 pages. It did not\n  point out the reason that some researchers took for granted that quantum\n  modlar exponentiation is in polynomial time. In the new version, we indicate\n  the reason and analyze some experimental demonstrations of Shor's algorithm.\n  Besides, the author Zhenfu Cao is added to the version for his contribution.\n  arXiv admin note: text overlap with arXiv:1409.7352", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient quantum modular exponentiation method is indispensible for\nShor's factoring algorithm. But we find that all descriptions presented by\nShor, Nielsen and Chuang, Markov and Saeedi, et al., are flawed. We also remark\nthat some experimental demonstrations of Shor's algorithm are misleading,\nbecause they violate the necessary condition that the selected number $q=2^s$,\nwhere $s$ is the number of qubits used in the first register, must satisfy $n^2\n\\leq q < 2n^2$, where $n$ is the large number to be factored.\n", "versions": [{"version": "v1", "created": "Sun, 24 Aug 2014 14:48:57 GMT"}, {"version": "v2", "created": "Wed, 8 Oct 2014 13:31:23 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Cao", "Zhengjun", ""], ["Cao", "Zhenfu", ""], ["Liu", "Lihua", ""]]}, {"id": "1408.6282", "submitter": "Thomas Pajor", "authors": "Edith Cohen, Daniel Delling, Thomas Pajor, Renato F. Werneck", "title": "Sketch-based Influence Maximization and Computation: Scaling up with\n  Guarantees", "comments": "10 pages, 5 figures. Appeared at the 23rd Conference on Information\n  and Knowledge Management (CIKM 2014) in Shanghai, China", "journal-ref": null, "doi": "10.1145/2661829.2662077", "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propagation of contagion through networks is a fundamental process. It is\nused to model the spread of information, influence, or a viral infection.\nDiffusion patterns can be specified by a probabilistic model, such as\nIndependent Cascade (IC), or captured by a set of representative traces.\n  Basic computational problems in the study of diffusion are influence queries\n(determining the potency of a specified seed set of nodes) and Influence\nMaximization (identifying the most influential seed set of a given size).\nAnswering each influence query involves many edge traversals, and does not\nscale when there are many queries on very large graphs. The gold standard for\nInfluence Maximization is the greedy algorithm, which iteratively adds to the\nseed set a node maximizing the marginal gain in influence. Greedy has a\nguaranteed approximation ratio of at least (1-1/e) and actually produces a\nsequence of nodes, with each prefix having approximation guarantee with respect\nto the same-size optimum. Since Greedy does not scale well beyond a few million\nedges, for larger inputs one must currently use either heuristics or\nalternative algorithms designed for a pre-specified small seed set size.\n  We develop a novel sketch-based design for influence computation. Our greedy\nSketch-based Influence Maximization (SKIM) algorithm scales to graphs with\nbillions of edges, with one to two orders of magnitude speedup over the best\ngreedy methods. It still has a guaranteed approximation ratio, and in practice\nits quality nearly matches that of exact greedy. We also present influence\noracles, which use linear-time preprocessing to generate a small sketch for\neach node, allowing the influence of any seed set to be quickly answered from\nthe sketches of its nodes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 23:48:19 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Cohen", "Edith", ""], ["Delling", "Daniel", ""], ["Pajor", "Thomas", ""], ["Werneck", "Renato F.", ""]]}, {"id": "1408.6321", "submitter": "Michael Bannister", "authors": "Michael J. Bannister and David Eppstein", "title": "Crossing Minimization for 1-page and 2-page Drawings of Graphs with\n  Bounded Treewidth", "comments": "Graph Drawing 2014", "journal-ref": "J. Graph Algorithms & Applications 22 (4): 577-606, 2018", "doi": "10.7155/jgaa.00479", "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate crossing minimization for 1-page and 2-page book drawings. We\nshow that computing the 1-page crossing number is fixed-parameter tractable\nwith respect to the number of crossings, that testing 2-page planarity is\nfixed-parameter tractable with respect to treewidth, and that computing the\n2-page crossing number is fixed-parameter tractable with respect to the sum of\nthe number of crossings and the treewidth of the input graph. We prove these\nresults via Courcelle's theorem on the fixed-parameter tractability of\nproperties expressible in monadic second order logic for graphs of bounded\ntreewidth.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 06:13:02 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bannister", "Michael J.", ""], ["Eppstein", "David", ""]]}, {"id": "1408.6378", "submitter": "Ueli  Peter", "authors": "Meier Florian and Peter Ueli", "title": "Push is Fast on Sparse Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical push broadcast process on a large class of sparse\nrandom multigraphs that includes random power law graphs and multigraphs. Our\nanalysis shows that for every $\\varepsilon>0$, whp $O(\\log n)$ rounds are\nsufficient to inform all but an $\\varepsilon$-fraction of the vertices.\n  It is not hard to see that, e.g. for random power law graphs, the push\nprocess needs whp $n^{\\Omega(1)}$ rounds to inform all vertices. Fountoulakis,\nPanagiotou and Sauerwald proved that for random graphs that have power law\ndegree sequences with $\\beta>3$, the push-pull protocol needs $\\Omega(\\log n)$\nto inform all but $\\varepsilon n$ vertices whp. Our result demonstrates that,\nfor such random graphs, the pull mechanism does not (asymptotically) improve\nthe running time. This is surprising as it is known that, on random power law\ngraphs with $2<\\beta<3$, push-pull is exponentially faster than pull.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 10:31:54 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Florian", "Meier", ""], ["Ueli", "Peter", ""]]}, {"id": "1408.6388", "submitter": "Ignasi Sau", "authors": "Valentin Garnero, Ignasi Sau, Dimitrios M. Thilikos", "title": "A Linear Kernel for Planar Red-Blue Dominating Set", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Red-Blue Dominating Set problem, we are given a bipartite graph $G =\n(V_B \\cup V_R,E)$ and an integer $k$, and asked whether $G$ has a subset $D\n\\subseteq V_B$ of at most $k$ \"blue\" vertices such that each \"red\" vertex from\n$V_R$ is adjacent to a vertex in $D$. We provide the first explicit linear\nkernel for this problem on planar graphs, of size at most $43k$.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 11:52:58 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2015 11:26:24 GMT"}, {"version": "v3", "created": "Fri, 28 Apr 2017 22:37:23 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Garnero", "Valentin", ""], ["Sau", "Ignasi", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1408.6485", "submitter": "Ciaran McCreesh", "authors": "Ciaran McCreesh and Patrick Prosser", "title": "Finding Maximum k-Cliques Faster using Lazy Global Domination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A clique in a graph is a set of vertices, each of which is adjacent to every\nother vertex in this set. A k-clique relaxes this requirement, requiring\nvertices to be within a distance k of each other, rather than directly\nadjacent. In theory, a maximum clique algorithm can easily be adapted to solve\nthe maximum k-clique problem. We use a state of the art maximum clique\nalgorithm to show that this is feasible in practice, and introduce a lazy\nglobal domination rule which sometimes vastly reduces the search space. We\ninclude experimental results for a range of real-world and benchmark graphs,\nand a detailed look at random graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 18:07:29 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["McCreesh", "Ciaran", ""], ["Prosser", "Patrick", ""]]}, {"id": "1408.6771", "submitter": "David Eppstein", "authors": "Zachary Abel, Erik D. Demaine, Martin L. Demaine, David Eppstein, Anna\n  Lubiw and Ryuhei Uehara", "title": "Flat Foldings of Plane Graphs with Prescribed Angles and Edge Lengths", "comments": "21 pages, 10 figures", "journal-ref": "J. Computational Geometry 9 (1): 71-91, 2018", "doi": "10.20382/jocg.v9i1", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When can a plane graph with prescribed edge lengths and prescribed angles\n(from among $\\{0,180^\\circ, 360^\\circ$\\}) be folded flat to lie in an\ninfinitesimally thin line, without crossings? This problem generalizes the\nclassic theory of single-vertex flat origami with prescribed mountain-valley\nassignment, which corresponds to the case of a cycle graph. We characterize\nsuch flat-foldable plane graphs by two obviously necessary but also sufficient\nconditions, proving a conjecture made in 2001: the angles at each vertex should\nsum to $360^\\circ$, and every face of the graph must itself be flat foldable.\nThis characterization leads to a linear-time algorithm for testing flat\nfoldability of plane graphs with prescribed edge lengths and angles, and a\npolynomial-time algorithm for counting the number of distinct folded states.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 16:25:49 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 20:23:21 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Abel", "Zachary", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Eppstein", "David", ""], ["Lubiw", "Anna", ""], ["Uehara", "Ryuhei", ""]]}, {"id": "1408.6812", "submitter": "Jean-Lou De Carufel", "authors": "Prosenjit Bose and Jean-Lou De Carufel", "title": "Towards a General Framework for Searching on a Line and Searching on $m$\n  Rays", "comments": "Submitted to ACM-SIAM Symposium on Discrete Algorithms (SODA 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following classical search problem: given a target point $p\\in\n\\Re$, starting at the origin, find $p$ with minimum cost, where cost is defined\nas the distance travelled. Let $D$ be the distance of $p$ from the origin. When\nno lower bound on $D$ is given, no competitive search strategy exists. Demaine,\nFekete and Gal (Online searching with turn cost, Theor. Comput. Sci.,\n361(2-3):342-355, 2006) considered the situation where no lower bound on $D$ is\ngiven but a fixed \\emph{turn cost} $t>0$ is charged every time the searcher\nchanges direction. When the total cost is expressed as $c D+\\phi$, where $c$\nand $\\phi$ are positive constants, they showed that if $c$ is set to $9$, then\nthe optimal search strategy has a cost of $9D+2t$. Although their strategy is\noptimal for $c=9$, we prove that the minimum cost in their framework is\n$5D+t+2\\sqrt{2D(2D+t)} < 9D+2t$. Note that the minimum cost requires knowledge\nof $D$. However, given $D$, the optimal strategy has a smaller cost of $3D+t$.\nTherefore, this problem cannot be solved optimally and exactly when no lower\nbound on $D$ is given.\n  To resolve this issue, we introduce a general framework where the cost of\nmoving distance $x$ away from the origin is $\\alpha_1 x+\\beta_1$ and the cost\nof moving distance $y$ towards the origin is $\\alpha_2 y+\\beta_2$ for constants\n$\\alpha_1,\\alpha_2,\\beta_1,\\beta_2$. Given a lower bound $\\lambda$ on $D$, we\nprovide a provably optimal competitive search strategy when\n$\\alpha_1,\\alpha_2,\\beta_1,\\beta_2 \\geq 0$ and $\\alpha_1+\\alpha_2 > 0$.\nFinally, we address the problem of searching for a target lying on one of $m$\nrays extending from the origin where the cost is measured as the total distance\ntravelled plus $t \\geq 0$ times the number of turns. We provide a search\nstrategy and compute its cost. We prove our strategy is optimal for small\nvalues of $t$ and conjecture it is always optimal.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 19:15:18 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 20:06:22 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Bose", "Prosenjit", ""], ["De Carufel", "Jean-Lou", ""]]}, {"id": "1408.6821", "submitter": "Alan Frieze", "authors": "Alan Frieze, Wesley Pegden", "title": "Looking for vertex number one", "comments": "As accepted for AAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an instance of the preferential attachment graph $G_n=([n],E_n)$, we\nwould like to find vertex 1, using only 'local' information about the graph;\nthat is, by exploring the neighborhoods of small sets of vertices. Borgs et. al\ngave an an algorithm which runs in time $O(\\log^4 n)$, which is local in the\nsense that at each step, it needs only to search the neighborhood of a set of\nvertices of size $O(\\log^4 n)$. We give an algorithm to find vertex 1, which\nw.h.p. runs in time $O(\\omega\\log n)$ and which is local in the strongest sense\nof operating only on neighborhoods of single vertices. Here $\\omega=\\omega(n)$\nis any function that goes to infinity with $n$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 19:38:18 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 20:54:37 GMT"}, {"version": "v3", "created": "Thu, 19 May 2016 16:36:10 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Frieze", "Alan", ""], ["Pegden", "Wesley", ""]]}, {"id": "1408.7033", "submitter": "Jesper W. Mikkelsen", "authors": "Joan Boyar, Lene M. Favrholdt, Christian Kudahl and Jesper W.\n  Mikkelsen", "title": "The Advice Complexity of a Class of Hard Online Problems", "comments": "Full paper to appear in Theory of Computing Systems. A preliminary\n  version appeared in STACS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advice complexity of an online problem is a measure of how much knowledge\nof the future an online algorithm needs in order to achieve a certain\ncompetitive ratio. Using advice complexity, we define the first online\ncomplexity class, AOC. The class includes independent set, vertex cover,\ndominating set, and several others as complete problems. AOC-complete problems\nare hard, since a single wrong answer by the online algorithm can have\ndevastating consequences. For each of these problems, we show that\n$\\log\\left(1+(c-1)^{c-1}/c^{c}\\right)n=\\Theta (n/c)$ bits of advice are\nnecessary and sufficient (up to an additive term of $O(\\log n)$) to achieve a\ncompetitive ratio of $c$.\n  The results are obtained by introducing a new string guessing problem related\nto those of Emek et al. (TCS 2011) and B\\\"ockenhauer et al. (TCS 2014). It\nturns out that this gives a powerful but easy-to-use method for providing both\nupper and lower bounds on the advice complexity of an entire class of online\nproblems, the AOC-complete problems.\n  Previous results of Halld\\'orsson et al. (TCS 2002) on online independent\nset, in a related model, imply that the advice complexity of the problem is\n$\\Theta (n/c)$. Our results improve on this by providing an exact formula for\nthe higher-order term. For online disjoint path allocation, B\\\"ockenhauer et\nal. (ISAAC 2009) gave a lower bound of $\\Omega (n/c)$ and an upper bound of\n$O((n\\log c)/c)$ on the advice complexity. We improve on the upper bound by a\nfactor of $\\log c$. For the remaining problems, no bounds on their advice\ncomplexity were previously known.\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 14:28:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2015 08:55:18 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 11:10:18 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Boyar", "Joan", ""], ["Favrholdt", "Lene M.", ""], ["Kudahl", "Christian", ""], ["Mikkelsen", "Jesper W.", ""]]}, {"id": "1408.7114", "submitter": "Michael Emmerich", "authors": "Iris Hupkens and Michael Emmerich and Andr\\'e Deutz", "title": "Faster Computation of Expected Hypervolume Improvement", "comments": "LIACS Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected improvement algorithm (or efficient global optimization) aims\nfor global continuous optimization with a limited budget of black-box function\nevaluations. It is based on a statistical model of the function learned from\nprevious evaluations and an infill criterion - the expected improvement - used\nto find a promising point for a new evaluation. The `expected improvement'\ninfill criterion takes into account the mean and variance of a predictive\nmultivariate Gaussian distribution.\n  The expected improvement algorithm has recently been generalized to\nmultiobjective optimization. In order to measure the improvement of a Pareto\nfront quantitatively the gain in dominated (hyper-)volume is used. The\ncomputation of the expected hypervolume improvement (EHVI) is a\nmultidimensional integration of a step-wise defined non-linear function related\nto the Gaussian probability density function over an intersection of boxes.\nThis paper provides a new algorithm for the exact computation of the expected\nimprovement to more than two objective functions. For the bicriteria case it\nhas a time complexity in $O(n^2)$ with $n$ denoting the number of points in the\ncurrent best Pareto front approximation. It improves previously known\nalgorithms with time complexity $O(n^3 \\log n)$. For tricriteria optimization\nwe devise an algorithm with time complexity of $O(n^3)$. Besides discussing the\nnew time complexity bounds the speed of the new algorithm is also tested\nempirically on test data. It is shown that further improvements in speed can be\nachieved by reusing data structures built up in previous iterations. The\nresulting numerical algorithms can be readily used in existing implementations\nof hypervolume-based expected improvement algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 19:43:41 GMT"}], "update_date": "2014-09-01", "authors_parsed": [["Hupkens", "Iris", ""], ["Emmerich", "Michael", ""], ["Deutz", "Andr\u00e9", ""]]}]