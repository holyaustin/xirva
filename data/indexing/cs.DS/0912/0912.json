[{"id": "0912.0134", "submitter": "Swan Dubois", "authors": "Swan Dubois (LIP6, INRIA Rocquencourt), Maria Gradinariu\n  Potop-Butucaru (LIP6, INRIA Rocquencourt), Mikhail Nesterenko, S\\'ebastien\n  Tixeuil (LIP6)", "title": "Self-Stabilizing Byzantine Asynchronous Unison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore asynchronous unison in the presence of systemic transient and\npermanent Byzantine faults in shared memory. We observe that the problem is not\nsolvable under less than strongly fair scheduler or for system topologies with\nmaximum node degree greater than two. We present a self-stabilizing\nByzantine-tolerant solution to asynchronous unison for chain and ring\ntopologies. Our algorithm has minimum possible containment radius and optimal\nstabilization time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 12:09:17 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Dubois", "Swan", "", "LIP6, INRIA Rocquencourt"], ["Potop-Butucaru", "Maria Gradinariu", "", "LIP6, INRIA Rocquencourt"], ["Nesterenko", "Mikhail", "", "LIP6"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0912.0226", "submitter": "Paul Bonsma", "authors": "Paul Bonsma", "title": "Max-Leaves Spanning Tree is APX-hard for Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a spanning tree with maximum number of\nleaves (MaxLeaf). A 2-approximation algorithm is known for this problem, and a\n3/2-approximation algorithm when restricted to graphs where every vertex has\ndegree 3 (cubic graphs). MaxLeaf is known to be APX-hard in general, and\nNP-hard for cubic graphs. We show that the problem is also APX-hard for cubic\ngraphs. The APX-hardness of the related problem Minimum Connected Dominating\nSet for cubic graphs follows.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 18:26:53 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["Bonsma", "Paul", ""]]}, {"id": "0912.0229", "submitter": "Anna Gilbert", "authors": "Anna C. Gilbert, Yi Li, Ely Porat, Martin J. Strauss", "title": "Approximate Sparse Recovery: Optimizing Time and Measurements", "comments": null, "journal-ref": "SIAM J. Comput. 41(2), pp. 436-453, 2012", "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approximate sparse recovery system consists of parameters $k,N$, an\n$m$-by-$N$ measurement matrix, $\\Phi$, and a decoding algorithm, $\\mathcal{D}$.\nGiven a vector, $x$, the system approximates $x$ by $\\widehat x\n=\\mathcal{D}(\\Phi x)$, which must satisfy $\\| \\widehat x - x\\|_2\\le C \\|x -\nx_k\\|_2$, where $x_k$ denotes the optimal $k$-term approximation to $x$. For\neach vector $x$, the system must succeed with probability at least 3/4. Among\nthe goals in designing such systems are minimizing the number $m$ of\nmeasurements and the runtime of the decoding algorithm, $\\mathcal{D}$.\n  In this paper, we give a system with $m=O(k \\log(N/k))$\nmeasurements--matching a lower bound, up to a constant factor--and decoding\ntime $O(k\\log^c N)$, matching a lower bound up to $\\log(N)$ factors.\n  We also consider the encode time (i.e., the time to multiply $\\Phi$ by $x$),\nthe time to update measurements (i.e., the time to multiply $\\Phi$ by a\n1-sparse $x$), and the robustness and stability of the algorithm (adding noise\nbefore and after the measurements). Our encode and update times are optimal up\nto $\\log(N)$ factors.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 18:47:24 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Gilbert", "Anna C.", ""], ["Li", "Yi", ""], ["Porat", "Ely", ""], ["Strauss", "Martin J.", ""]]}, {"id": "0912.0250", "submitter": "Ryan O'Donnell", "authors": "Ryan O'Donnell, Yi Wu, Yuan Zhou", "title": "Optimal lower bounds for locality sensitive hashing (except when q is\n  tiny)", "comments": "9 pages + abstract and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study lower bounds for Locality Sensitive Hashing (LSH) in the strongest\nsetting: point sets in {0,1}^d under the Hamming distance. Recall that here H\nis said to be an (r, cr, p, q)-sensitive hash family if all pairs x, y in\n{0,1}^d with dist(x,y) at most r have probability at least p of collision under\na randomly chosen h in H, whereas all pairs x, y in {0,1}^d with dist(x,y) at\nleast cr have probability at most q of collision. Typically, one considers d\ntending to infinity, with c fixed and q bounded away from 0.\n  For its applications to approximate nearest neighbor search in high\ndimensions, the quality of an LSH family H is governed by how small its \"rho\nparameter\" rho = ln(1/p)/ln(1/q) is as a function of the parameter c. The\nseminal paper of Indyk and Motwani showed that for each c, the extremely simple\nfamily H = {x -> x_i : i in d} achieves rho at most 1/c. The only known lower\nbound, due to Motwani, Naor, and Panigrahy, is that rho must be at least .46/c\n(minus o_d(1)).\n  In this paper we show an optimal lower bound: rho must be at least 1/c (minus\no_d(1)). This lower bound for Hamming space yields a lower bound of 1/c^2 for\nEuclidean space (or the unit sphere) and 1/c for the Jaccard distance on sets;\nboth of these match known upper bounds. Our proof is simple; the essence is\nthat the noise stability of a boolean function at e^{-t} is a log-convex\nfunction of t.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 20:34:12 GMT"}], "update_date": "2009-12-02", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Wu", "Yi", ""], ["Zhou", "Yuan", ""]]}, {"id": "0912.0287", "submitter": "Rasmus Pagh", "authors": "Martin Dietzfelbinger, Andreas Goerdt, Michael Mitzenmacher, Andrea\n  Montanari, Rasmus Pagh, and Michael Rink", "title": "Tight Thresholds for Cuckoo Hashing via XORSAT", "comments": "Revision 3 contains missing details of proofs, as appendix D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We settle the question of tight thresholds for offline cuckoo hashing. The\nproblem can be stated as follows: we have n keys to be hashed into m buckets\neach capable of holding a single key. Each key has k >= 3 (distinct) associated\nbuckets chosen uniformly at random and independently of the choices of other\nkeys. A hash table can be constructed successfully if each key can be placed\ninto one of its buckets. We seek thresholds alpha_k such that, as n goes to\ninfinity, if n/m <= alpha for some alpha < alpha_k then a hash table can be\nconstructed successfully with high probability, and if n/m >= alpha for some\nalpha > alpha_k a hash table cannot be constructed successfully with high\nprobability. Here we are considering the offline version of the problem, where\nall keys and hash values are given, so the problem is equivalent to previous\nmodels of multiple-choice hashing. We find the thresholds for all values of k >\n2 by showing that they are in fact the same as the previously known thresholds\nfor the random k-XORSAT problem. We then extend these results to the setting\nwhere keys can have differing number of choices, and provide evidence in the\nform of an algorithm for a conjecture extending this result to cuckoo hash\ntables that store multiple keys in a bucket.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 22:23:48 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2010 21:45:36 GMT"}, {"version": "v3", "created": "Tue, 21 Dec 2010 14:53:26 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Dietzfelbinger", "Martin", ""], ["Goerdt", "Andreas", ""], ["Mitzenmacher", "Michael", ""], ["Montanari", "Andrea", ""], ["Pagh", "Rasmus", ""], ["Rink", "Michael", ""]]}, {"id": "0912.0322", "submitter": "Shaddin Dughmi", "authors": "Shaddin Dughmi", "title": "Submodular Functions: Extensions, Distributions, and Algorithms. A\n  Survey", "comments": "This revision corrects an error in definition 2.2, as well as\n  provides additional intuition regarding the definitions of convex closure and\n  concave closure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodularity is a fundamental phenomenon in combinatorial optimization.\nSubmodular functions occur in a variety of combinatorial settings such as\ncoverage problems, cut problems, welfare maximization, and many more.\nTherefore, a lot of work has been concerned with maximizing or minimizing a\nsubmodular function, often subject to combinatorial constraints. Many of these\nalgorithmic results exhibit a common structure. Namely, the function is\nextended to a continuous, usually non-linear, function on a convex domain.\nThen, this relaxation is solved, and the fractional solution rounded to yield\nan integral solution. Often, the continuous extension has a natural\ninterpretation in terms of distributions on subsets of the ground set. This\ninterpretation is often crucial to the results and their analysis. The purpose\nof this survey is to highlight this connection between extensions,\ndistributions, relaxations, and optimization in the context of submodular\nfunctions. We also present the first constant factor approximation algorithm\nfor minimizing symmetric submodular functions subject to a cardinality\nconstraint.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2009 02:02:27 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2009 19:09:36 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2009 19:47:08 GMT"}, {"version": "v4", "created": "Sun, 6 Nov 2011 22:23:46 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Dughmi", "Shaddin", ""]]}, {"id": "0912.0368", "submitter": "Riccardo Dondi", "authors": "Paola Bonizzoni, Gianluca Della Vedova, Riccardo Dondi, Yuri Pirola", "title": "Variants of Constrained Longest Common Subsequence", "comments": null, "journal-ref": "Information Processing Letters 110.20 (2010) 877-881", "doi": "10.1016/j.ipl.2010.07.015", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a variant of the classical Longest Common\nSubsequence problem called Doubly-Constrained Longest Common Subsequence\n(DC-LCS). Given two strings s1 and s2 over an alphabet A, a set C_s of strings,\nand a function Co from A to N, the DC-LCS problem consists in finding the\nlongest subsequence s of s1 and s2 such that s is a supersequence of all the\nstrings in Cs and such that the number of occurrences in s of each symbol a in\nA is upper bounded by Co(a). The DC-LCS problem provides a clear mathematical\nformulation of a sequence comparison problem in Computational Biology and\ngeneralizes two other constrained variants of the LCS problem: the Constrained\nLCS and the Repetition-Free LCS. We present two results for the DC-LCS problem.\nFirst, we illustrate a fixed-parameter algorithm where the parameter is the\nlength of the solution. Secondly, we prove a parameterized hardness result for\nthe Constrained LCS problem when the parameter is the number of the constraint\nstrings and the size of the alphabet A. This hardness result also implies the\nparameterized hardness of the DC-LCS problem (with the same parameters) and its\nNP-hardness when the size of the alphabet is constant.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2009 09:14:54 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Bonizzoni", "Paola", ""], ["Della Vedova", "Gianluca", ""], ["Dondi", "Riccardo", ""], ["Pirola", "Yuri", ""]]}, {"id": "0912.0681", "submitter": "Michael Mahoney", "authors": "Michael W. Mahoney, Lorenzo Orecchia, Nisheeth K. Vishnoi", "title": "A Local Spectral Method for Graphs: with Applications to Improving Graph\n  Partitions and Exploring Data Graphs Locally", "comments": "24 pages. Completely rewritten; substance is still the same, but the\n  presentation is reworked", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The second eigenvalue of the Laplacian matrix and its associated eigenvector\nare fundamental features of an undirected graph, and as such they have found\nwidespread use in scientific computing, machine learning, and data analysis. In\nmany applications, however, graphs that arise have several \\emph{local} regions\nof interest, and the second eigenvector will typically fail to provide\ninformation fine-tuned to each local region. In this paper, we introduce a\nlocally-biased analogue of the second eigenvector, and we demonstrate its\nusefulness at highlighting local properties of data graphs in a semi-supervised\nmanner. To do so, we first view the second eigenvector as the solution to a\nconstrained optimization problem, and we incorporate the local information as\nan additional constraint; we then characterize the optimal solution to this new\nproblem and show that it can be interpreted as a generalization of a\nPersonalized PageRank vector; and finally, as a consequence, we show that the\nsolution can be computed in nearly-linear time. In addition, we show that this\nlocally-biased vector can be used to compute an approximation to the best\npartition \\emph{near} an input seed set in a manner analogous to the way in\nwhich the second eigenvector of the Laplacian can be used to obtain an\napproximation to the best partition in the entire input graph. Such a primitive\nis useful for identifying and refining clusters locally, as it allows us to\nfocus on a local region of interest in a semi-supervised manner. Finally, we\nprovide a detailed empirical evaluation of our method by showing how it can\napplied to finding locally-biased sparse cuts around an input vertex seed set\nin social and information networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 15:20:59 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2011 14:30:57 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2011 03:18:01 GMT"}], "update_date": "2011-10-24", "authors_parsed": [["Mahoney", "Michael W.", ""], ["Orecchia", "Lorenzo", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "0912.0685", "submitter": "Matthias M\\\"uller-Hannemann", "authors": "Annabell Berger and Matthias M\\\"uller-Hannemann", "title": "Uniform sampling of undirected and directed graphs with a fixed degree\n  sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications in network analysis require algorithms to sample uniformly\nat random from the set of all graphs with a prescribed degree sequence. We\npresent a Markov chain based approach which converges to the uniform\ndistribution of all realizations for both the directed and undirected case. It\nremains an open challenge whether these Markov chains are rapidly mixing.\n  For the case of directed graphs, we also explain in this paper that a popular\nswitching algorithm fails in general to sample uniformly at random because the\nstate graph of the Markov chain decomposes into different isomorphic\ncomponents. We call degree sequences for which the state graph is strongly\nconnected arc swap sequences. To handle arbitrary degree sequences, we develop\ntwo different solutions. The first uses an additional operation (a\nreorientation of induced directed 3-cycles) which makes the state graph\nstrongly connected, the second selects randomly one of the isomorphic\ncomponents and samples inside it. Our main contribution is a precise\ncharacterization of arc swap sequences, leading to an efficient recognition\nalgorithm. Finally, we point out some interesting consequences for network\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 15:46:31 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2009 16:39:13 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2010 15:38:10 GMT"}], "update_date": "2010-03-05", "authors_parsed": [["Berger", "Annabell", ""], ["M\u00fcller-Hannemann", "Matthias", ""]]}, {"id": "0912.0750", "submitter": "Aran Nayebi", "authors": "Aran Nayebi", "title": "Fast matrix multiplication techniques based on the Adleman-Lipton model", "comments": "To appear in the International Journal of Computer Engineering\n  Research. Minor changes made to make the preprint as similar as possible to\n  the published version", "journal-ref": "International Journal of Computer Engineering Research,\n  3(1):10-19, January 2012", "doi": "10.5897/IJCER10.016", "report-no": null, "categories": "q-bio.QM cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On distributed memory electronic computers, the implementation and\nassociation of fast parallel matrix multiplication algorithms has yielded\nastounding results and insights. In this discourse, we use the tools of\nmolecular biology to demonstrate the theoretical encoding of Strassen's fast\nmatrix multiplication algorithm with DNA based on an $n$-moduli set in the\nresidue number system, thereby demonstrating the viability of computational\nmathematics with DNA. As a result, a general scalable implementation of this\nmodel in the DNA computing paradigm is presented and can be generalized to the\napplication of \\emph{all} fast matrix multiplication algorithms on a DNA\ncomputer. We also discuss the practical capabilities and issues of this\nscalable implementation. Fast methods of matrix computations with DNA are\nimportant because they also allow for the efficient implementation of other\nalgorithms (i.e. inversion, computing determinants, and graph theory) with DNA.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 23:04:18 GMT"}, {"version": "v2", "created": "Sun, 5 Sep 2010 16:43:23 GMT"}, {"version": "v3", "created": "Wed, 16 Feb 2011 15:44:55 GMT"}, {"version": "v4", "created": "Sat, 28 May 2011 16:25:32 GMT"}, {"version": "v5", "created": "Mon, 19 Dec 2011 04:17:30 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Nayebi", "Aran", ""]]}, {"id": "0912.0803", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Nicolae Tapus", "title": "New Algorithmic Approaches for Computing Optimal Network Paths with\n  Several Types of QoS Constraints", "comments": null, "journal-ref": "Proceedings of the 8th RoEduNet International Conference, pp.\n  7-12, Galati, Romania, 3-4 December, 2009. (ISBN: 978-606-8085-15-9)", "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of efficiently delivering data within networks is very important\nnowadays, especially in the context of the large volumes of data which are\nbeing produced each year and of the increased data access needs of the users.\nEfficient data delivery strategies must satisfy several types of Quality of\nService (QoS) constraints which are imposed by the data consumers. One\npossibility of achieving this goal (particularly in the case of in-order data\ntransfers) is to choose a satisfactory network delivery path. In this paper we\npresent novel algorithmic approaches for computing optimal network paths which\nsatisfy several types of (QoS) constraints.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 09:53:40 GMT"}], "update_date": "2009-12-07", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tapus", "Nicolae", ""]]}, {"id": "0912.0807", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Nicolae Tapus", "title": "Practical Algorithmic Techniques for Several String Processing Problems", "comments": null, "journal-ref": "Proceedings of the 8th RoEduNet International Conference, pp.\n  136-141, Galati, Romania, 3-4 December, 2009. (ISBN: 978-606-8085-15-9)", "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domains of data mining and knowledge discovery make use of large amounts\nof textual data, which need to be handled efficiently. Specific problems, like\nfinding the maximum weight ordered common subset of a set of ordered sets or\nsearching for specific patterns within texts, occur frequently in this context.\nIn this paper we present several novel and practical algorithmic techniques for\nprocessing textual data (strings) in order to efficiently solve multiple\nproblems. Our techniques make use of efficient string algorithms and data\nstructures, like KMP, suffix arrays, tries and deterministic finite automata.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 10:04:16 GMT"}], "update_date": "2009-12-07", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tapus", "Nicolae", ""]]}, {"id": "0912.0850", "submitter": "Travis Gagie", "authors": "Travis Gagie and Pawel Gawrychowski", "title": "Grammar-Based Compression in a Streaming Model", "comments": "Section on recent work added, sketching how to improve bounds and\n  support random access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, given a string $s$ of length $n$, with constant memory and\nlogarithmic passes over a constant number of streams we can build a\ncontext-free grammar that generates $s$ and only $s$ and whose size is within\nan $\\Oh{\\min (g \\log g, \\sqrt{n \\log g})}$-factor of the minimum $g$. This\nstands in contrast to our previous result that, with polylogarithmic memory and\npolylogarithmic passes over a single stream, we cannot build such a grammar\nwhose size is within any polynomial of $g$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 13:17:22 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2010 20:33:55 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 20:05:17 GMT"}, {"version": "v4", "created": "Sat, 6 Feb 2010 02:09:00 GMT"}], "update_date": "2010-02-06", "authors_parsed": [["Gagie", "Travis", ""], ["Gawrychowski", "Pawel", ""]]}, {"id": "0912.0975", "submitter": "Julian McAuley", "authors": "Julian J. McAuley, Tib\\'erio S. Caetano", "title": "An expected-case sub-cubic solution to the all-pairs shortest path\n  problem in R", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown by Alon et al. that the so-called 'all-pairs shortest-path'\nproblem can be solved in O((MV)^2.688 * log^3(V)) for graphs with V vertices,\nwith integer distances bounded by M. We solve the more general problem for\ngraphs in R (assuming no negative cycles), with expected-case running time\nO(V^2.5 * log(V)). While our result appears to violate the Omega(V^3)\nrequirement of \"Funny Matrix Multiplication\" (due to Kerr), we find that it has\na sub-cubic expected time solution subject to reasonable conditions on the data\ndistribution. The expected time solution arises when certain sub-problems are\nuncorrelated, though we can do better/worse than the expected-case under\npositive/negative correlation (respectively). Whether we observe\npositive/negative correlation depends on the statistics of the graph in\nquestion. In practice, our algorithm is significantly faster than\nFloyd-Warshall, even for dense graphs.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 03:31:07 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["McAuley", "Julian J.", ""], ["Caetano", "Tib\u00e9rio S.", ""]]}, {"id": "0912.1045", "submitter": "Viswanath Nagarajan", "authors": "Anupam Gupta, Viswanath Nagarajan, R. Ravi", "title": "Thresholded Covering Algorithms for Robust and Max-Min Optimization", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general problem of robust optimization is this: one of several possible\nscenarios will appear tomorrow, but things are more expensive tomorrow than\nthey are today. What should you anticipatorily buy today, so that the\nworst-case cost (summed over both days) is minimized? Feige et al. and\nKhandekar et al. considered the k-robust model where the possible outcomes\ntomorrow are given by all demand-subsets of size k, and gave algorithms for the\nset cover problem, and the Steiner tree and facility location problems in this\nmodel, respectively.\n  In this paper, we give the following simple and intuitive template for\nk-robust problems: \"having built some anticipatory solution, if there exists a\nsingle demand whose augmentation cost is larger than some threshold, augment\nthe anticipatory solution to cover this demand as well, and repeat\". In this\npaper we show that this template gives us improved approximation algorithms for\nk-robust Steiner tree and set cover, and the first approximation algorithms for\nk-robust Steiner forest, minimum-cut and multicut. All our approximation ratios\n(except for multicut) are almost best possible.\n  As a by-product of our techniques, we also get algorithms for max-min\nproblems of the form: \"given a covering problem instance, which k of the\nelements are costliest to cover?\".\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 19:04:49 GMT"}, {"version": "v2", "created": "Tue, 21 Dec 2010 19:11:39 GMT"}, {"version": "v3", "created": "Thu, 24 Feb 2011 19:39:07 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""], ["Ravi", "R.", ""]]}, {"id": "0912.1050", "submitter": "Panos Giannopoulos", "authors": "M. Fellows, P. Giannopoulos, C. Knauer, C. Paul, F. Rosamond, S.\n  Whitesides, N. Yu", "title": "Abstract Milling with Turn Costs", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Abstract Milling problem is a natural and quite general graph-theoretic\nmodel for geometric milling problems. Given a graph, one asks for a walk that\ncovers all its vertices with a minimum number of turns, as specified in the\ngraph model by a 0/1 turncost function fx at each vertex x giving, for each\nordered pair of edges (e,f) incident at x, the turn cost at x of a walk that\nenters the vertex on edge e and departs on edge f. We describe an initial study\nof the parameterized complexity of the problem. Our main positive result shows\nthat Abstract Milling, parameterized by: number of turns, treewidth and maximum\ndegree, is fixed-parameter tractable, We also show that Abstract Milling\nparameterized by (only) the number of turns and the pathwidth, is hard for W[1]\n-- one of the few parameterized intractability results for bounded pathwidth.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 20:15:21 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Fellows", "M.", ""], ["Giannopoulos", "P.", ""], ["Knauer", "C.", ""], ["Paul", "C.", ""], ["Rosamond", "F.", ""], ["Whitesides", "S.", ""], ["Yu", "N.", ""]]}, {"id": "0912.1137", "submitter": "MohammadHossein Bateni", "authors": "MohammadHossein Bateni and MohammadTaghi Hajiaghayi", "title": "Euclidean Prize-collecting Steiner Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider Steiner forest and its generalizations,\nprize-collecting Steiner forest and k-Steiner forest, when the vertices of the\ninput graph are points in the Euclidean plane and the lengths are Euclidean\ndistances. First, we present a simpler analysis of the polynomial-time\napproximation scheme (PTAS) of Borradaile et al. [12] for the Euclidean Steiner\nforest problem. This is done by proving a new structural property and modifying\nthe dynamic programming by adding a new piece of information to each dynamic\nprogramming state. Next we develop a PTAS for a well-motivated case, i.e., the\nmultiplicative case, of prize-collecting and budgeted Steiner forest. The ideas\nused in the algorithm may have applications in design of a broad class of\nbicriteria PTASs. At the end, we demonstrate why PTASs for these problems can\nbe hard in the general Euclidean case (and thus for PTASs we cannot go beyond\nthe multiplicative case).\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2009 21:15:49 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Hajiaghayi", "MohammadTaghi", ""]]}, {"id": "0912.1200", "submitter": "Shine S", "authors": "S. Shine, K. Murali Krishnan", "title": "Extending Karger's randomized min-cut Algorithm for a Synchronous\n  Distributed setting", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A min-cut that seperates vertices s and t in a network is an edge set of\nminimum weight whose removal will disconnect s and t. This problem is the dual\nof the well known s-t max-flow problem. Several algorithms for the min-cut\nproblem are based on max-flow computation although the fastest known min-cut\nalgorithms are not flow based. The well known Karger's randomized algorithm for\nmin-cut is a non-flow based method for solving the (global) min-cut problem of\nfinding the min s-t cut over all pair of vertices s,t in a weighted undirected\ngraph. This paper presents an adaptation of Karger's algorithm for a\nsynchronous distributed setting where each node is allowed to perform only\nlocal computations. The paper essentially addresses the technicalities involved\nin circumventing the limitations imposed by a distributed setting to the\nworking of Karger's algorithm. While the correctness proof follows directly\nfrom Karger's algorithm, the complexity analysis differs significantly. The\nalgorithm achieves the same probability of success as the original algorithm\nwith O(mn^{2}) message complexity and O(n^{2}) time complexity, where n and m\ndenote the number of vertices and edges in the graph.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2009 10:50:50 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2010 08:06:19 GMT"}], "update_date": "2010-01-01", "authors_parsed": [["Shine", "S.", ""], ["Krishnan", "K. Murali", ""]]}, {"id": "0912.1329", "submitter": "Jian Li", "authors": "Samir Kuller, Jian Li, Barna Saha", "title": "Energy Efficient Scheduling via Partial Shutdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by issues of saving energy in data centers we define a collection\nof new problems referred to as \"machine activation\" problems. The central\nframework we introduce considers a collection of $m$ machines (unrelated or\nrelated) with each machine $i$ having an {\\em activation cost} of $a_i$. There\nis also a collection of $n$ jobs that need to be performed, and $p_{i,j}$ is\nthe processing time of job $j$ on machine $i$. We assume that there is an\nactivation cost budget of $A$ -- we would like to {\\em select} a subset $S$ of\nthe machines to activate with total cost $a(S) \\le A$ and {\\em find} a schedule\nfor the $n$ jobs on the machines in $S$ minimizing the makespan (or any other\nmetric).\n  For the general unrelated machine activation problem, our main results are\nthat if there is a schedule with makespan $T$ and activation cost $A$ then we\ncan obtain a schedule with makespan $\\makespanconstant T$ and activation cost\n$\\costconstant A$, for any $\\epsilon >0$. We also consider assignment costs for\njobs as in the generalized assignment problem, and using our framework, provide\nalgorithms that minimize the machine activation and the assignment cost\nsimultaneously. In addition, we present a greedy algorithm which only works for\nthe basic version and yields a makespan of $2T$ and an activation cost $A\n(1+\\ln n)$.\n  For the uniformly related parallel machine scheduling problem, we develop a\npolynomial time approximation scheme that outputs a schedule with the property\nthat the activation cost of the subset of machines is at most $A$ and the\nmakespan is at most $(1+\\epsilon) T$ for any $\\epsilon >0$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2009 20:24:24 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Kuller", "Samir", ""], ["Li", "Jian", ""], ["Saha", "Barna", ""]]}, {"id": "0912.1403", "submitter": "Madhur Tulsiani", "authors": "Amit Deshpande, Kasturi Varadarajan, Madhur Tulsiani, Nisheeth K.\n  Vishnoi", "title": "Algorithms and Hardness for Subspace Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subspace approximation problem Subspace($k$,$p$) asks for a\n$k$-dimensional linear subspace that fits a given set of points optimally,\nwhere the error for fitting is a generalization of the least squares fit and\nuses the $\\ell_{p}$ norm instead. Most of the previous work on subspace\napproximation has focused on small or constant $k$ and $p$, using coresets and\nsampling techniques from computational geometry.\n  In this paper, extending another line of work based on convex relaxation and\nrounding, we give a polynomial time algorithm, \\emph{for any $k$ and any $p\n\\geq 2$}, with the approximation guarantee roughly $\\gamma_{p} \\sqrt{2 -\n\\frac{1}{n-k}}$, where $\\gamma_{p}$ is the $p$-th moment of a standard normal\nrandom variable N(0,1). We show that the convex relaxation we use has an\nintegrality gap (or \"rank gap\") of $\\gamma_{p} (1 - \\epsilon)$, for any\nconstant $\\epsilon > 0$. Finally, we show that assuming the Unique Games\nConjecture, the subspace approximation problem is hard to approximate within a\nfactor better than $\\gamma_{p} (1 - \\epsilon)$, for any constant $\\epsilon >\n0$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2009 04:54:17 GMT"}, {"version": "v2", "created": "Thu, 30 Dec 2010 12:34:41 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Deshpande", "Amit", ""], ["Varadarajan", "Kasturi", ""], ["Tulsiani", "Madhur", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "0912.1457", "submitter": "Christophe Paul", "authors": "Michel Habib and Christophe Paul", "title": "A survey on algorithmic aspects of modular decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modular decomposition is a technique that applies but is not restricted\nto graphs. The notion of module naturally appears in the proofs of many graph\ntheoretical theorems. Computing the modular decomposition tree is an important\npreprocessing step to solve a large number of combinatorial optimization\nproblems. Since the first polynomial time algorithm in the early 70's, the\nalgorithmic of the modular decomposition has known an important development.\nThis paper survey the ideas and techniques that arose from this line of\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2009 10:54:03 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2009 08:43:21 GMT"}], "update_date": "2009-12-10", "authors_parsed": [["Habib", "Michel", ""], ["Paul", "Christophe", ""]]}, {"id": "0912.1523", "submitter": "Franklin Marquezino", "authors": "G. Abal, R. Donangelo, F.L. Marquezino, A.C. Oliveira, R. Portugal", "title": "Decoherence in Search Algorithms", "comments": "14 pages, presented at 36th Seminar on Software and Hardware\n  (SEMISH), XXIX Brazilian Computer Society Congress, Bento Concalves, Brazil", "journal-ref": "Proceedings of the XXIX Brazilian Computer Society Congress\n  (SEMISH), 2009, pages 293-306", "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several quantum search algorithms based on quantum walks were\nproposed. Those algorithms differ from Grover's algorithm in many aspects. The\ngoal is to find a marked vertex in a graph faster than classical algorithms.\nSince the implementation of those new algorithms in quantum computers or in\nother quantum devices is error-prone, it is important to analyze their\nrobustness under decoherence. In this work we analyze the impact of decoherence\non quantum search algorithms implemented on two-dimensional grids and on\nhypercubes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2009 15:32:26 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Abal", "G.", ""], ["Donangelo", "R.", ""], ["Marquezino", "F. L.", ""], ["Oliveira", "A. C.", ""], ["Portugal", "R.", ""]]}, {"id": "0912.1664", "submitter": "Dzung Phan", "authors": "William Hager, Dzung Phan, Hongchao Zhang", "title": "An exact algorithm for graph partitioning", "comments": "20 pages, submitted to Mathematical Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exact algorithm is presented for solving edge weighted graph partitioning\nproblems. The algorithm is based on a branch and bound method applied to a\ncontinuous quadratic programming formulation of the problem. Lower bounds are\nobtained by decomposing the objective function into convex and concave parts\nand replacing the concave part by an affine underestimate. It is shown that the\nbest affine underestimate can be expressed in terms of the center and the\nradius of the smallest sphere containing the feasible set. The concave term is\nobtained either by a constant diagonal shift associated with the smallest\neigenvalue of the objective function Hessian, or by a diagonal shift obtained\nby solving a semidefinite programming problem. Numerical results show that the\nproposed algorithm is competitive with state-of-the-art graph partitioning\ncodes.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2009 04:26:11 GMT"}], "update_date": "2009-12-10", "authors_parsed": [["Hager", "William", ""], ["Phan", "Dzung", ""], ["Zhang", "Hongchao", ""]]}, {"id": "0912.1832", "submitter": "Vishal Goyal", "authors": "Dr.A. K. Ojha and K. K. Biswal", "title": "Lexicographic Multi-objective Geometric Programming Problems", "comments": "International Journal of Computer Science Issues, IJCSI Volume 6,\n  Issue 2, pp20-24, November 2009", "journal-ref": "Dr.A. K. Ojha and K. K. Biswal, \"Lexicographic Multi-objective\n  Geometric Programming Problems\", International Journal of Computer Science\n  Issues, IJCSI, Volume 6, Issue 2, pp20-24, November 2009", "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Geometric programming (GP) is a type of mathematical problem characterized\nby objective and constraint functions that have a special form. Many methods\nhave been developed to solve large scale engineering design GP problems. In\nthis paper GP technique has been used to solve multi-objective GP problem as a\nvector optimization problem. The duality theory for lexicographic geometric\nprogramming has been developed to solve the problems with posynomial in\nobjectives and constraints.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2009 18:46:01 GMT"}], "update_date": "2009-12-10", "authors_parsed": [["Ojha", "Dr. A. K.", ""], ["Biswal", "K. K.", ""]]}, {"id": "0912.2047", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica", "title": "Efficient Gaussian Elimination on a 2D SIMD Array of Processors without\n  Column Broadcasts", "comments": null, "journal-ref": "Politehnica University of Bucharest (UPB) Scientific Bulletin,\n  Series C - Electrical Engineering and Computer Science, vol. 71, issue 4, pp.\n  83-98, 2009. (ISSN: 1454-234X)", "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient method for implementing the Gaussian\nelimination technique for an nxm (m>=n) matrix, using a 2D SIMD array of nxm\nprocessors. The described algorithm consists of 2xn-1=O(n) iterations, which\nprovides an optimal speed-up over the serial version. A particularity of the\nalgorithm is that it only requires broadcasts on the rows of the processor\nmatrix and not on its columns. The paper also presents several extensions and\napplications of the Gaussian elimination algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2009 16:50:05 GMT"}], "update_date": "2009-12-11", "authors_parsed": [["Andreica", "Mugurel Ionut", ""]]}, {"id": "0912.2174", "submitter": "Svante Janson", "authors": "Svante Janson", "title": "Renewal theory in analysis of tries and strings", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a survey of a number of simple applications of renewal theory to\nproblems on random strings and tries: insertion depth, size, insertion mode and\nimbalance of tries; variations for b-tries and Patricia tries; Khodak and\nTunstall codes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 16:30:13 GMT"}], "update_date": "2009-12-14", "authors_parsed": [["Janson", "Svante", ""]]}, {"id": "0912.2269", "submitter": "Charles Sauerbier", "authors": "Charles Sauerbier", "title": "Computing a Discrete Logarithm in O(n^3)", "comments": "5 pages, 0 figures, example source code in c#; v2 expanded to include\n  computation without projection into real number field; v3 edits to more\n  explicitly make the association with periodic functions of a specific form;\n  v4 edits correct y periodic aside and to clarify loop identification, note\n  respective difference expression and modular exponentiation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a means with time complexity of at worst O(n^3) to\ncompute the discrete logarithm on cyclic finite groups of integers modulo p.\nThe algorithm makes use of reduction of the problem to that of finding the\nconcurrent zeros of two periodic functions in the real numbers. The problem is\ntreated as an analog to a form of analog rotor-code computed cipher.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 16:07:20 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2009 17:02:06 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2009 17:10:16 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2009 18:34:59 GMT"}], "update_date": "2009-12-29", "authors_parsed": [["Sauerbier", "Charles", ""]]}, {"id": "0912.2371", "submitter": "Fedor Fomin", "authors": "Fedor V. Fomin, Daniel Lokshtanov, Venkatesh Raman, B. V. Raghavendra\n  Rao, Saket Saurabh", "title": "Faster Algorithms for Finding and Counting Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a natural generalization of both {\\sc $k$-Path} and\n{\\sc $k$-Tree} problems, namely, the {\\sc Subgraph Isomorphism} problem.\n  In the {\\sc Subgraph Isomorphism} problem we are given two graphs $F$ and $G$\non $k$ and $n$ vertices respectively as an input, and the question is whether\nthere exists a subgraph of $G$ isomorphic to $F$. We show that if the treewidth\nof $F$ is at most $t$, then there is a randomized algorithm for the {\\sc\nSubgraph Isomorphism} problem running in time $\\cO^*(2^k n^{2t})$. To do so, we\nassociate a new multivariate {Homomorphism polynomial} of degree at most $k$\nwith the {\\sc Subgraph Isomorphism} problem and construct an arithmetic circuit\nof size at most $n^{\\cO(t)}$ for this polynomial. Using this polynomial, we\nalso give a deterministic algorithm to count the number of homomorphisms from\n$F$ to $G$ that takes $n^{\\cO(t)}$ time and uses polynomial space. For the\ncounting version of the {\\sc Subgraph Isomorphism} problem, where the objective\nis to count the number of distinct subgraphs of $G$ that are isomorphic to $F$,\nwe give a deterministic algorithm running in time and space $\\cO^*({n \\choose\nk/2}n^{2p})$ or ${n\\choose k/2}n^{\\cO(t \\log k)}$. We also give an algorithm\nrunning in time $\\cO^{*}(2^{k}{n \\choose k/2}n^{5p})$ and taking space\npolynomial in $n$. Here $p$ and $t$ denote the pathwidth and the treewidth of\n$F$, respectively. Thus our work not only improves on known results on {\\sc\nSubgraph Isomorphism} but it also extends and generalize most of the known\nresults on {\\sc $k$-Path} and {\\sc $k$-Tree}.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 22:19:59 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Raman", "Venkatesh", ""], ["Rao", "B. V. Raghavendra", ""], ["Saurabh", "Saket", ""]]}, {"id": "0912.2404", "submitter": "Shaddin Dughmi", "authors": "Ioannis Antonellis, Anish Das Sarma, Shaddin Dughmi", "title": "Succinct Coverage Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify a fundamental algorithmic problem that we term\nsuccinct dynamic covering (SDC), arising in many modern-day web applications,\nincluding ad-serving and online recommendation systems in eBay and Netflix.\nRoughly speaking, SDC applies two restrictions to the well-studied Max-Coverage\nproblem: Given an integer k, X={1,2,...,n} and I={S_1, ..., S_m}, S_i a subset\nof X, find a subset J of I, such that |J| <= k and the union of S in J is as\nlarge as possible. The two restrictions applied by SDC are: (1) Dynamic: At\nquery-time, we are given a query Q, a subset of X, and our goal is to find J\nsuch that the intersection of Q with the union of S in J is as large as\npossible; (2) Space-constrained: We don't have enough space to store (and\nprocess) the entire input; specifically, we have o(mn), and maybe as little as\nO((m+n)polylog(mn)) space. The goal of SDC is to maintain a small data\nstructure so as to answer most dynamic queries with high accuracy. We call such\na scheme a Coverage Oracle.\n  We present algorithms and complexity results for coverage oracles. We present\ndeterministic and probabilistic near-tight upper and lower bounds on the\napproximation ratio of SDC as a function of the amount of space available to\nthe oracle. Our lower bound results show that to obtain constant-factor\napproximations we need Omega(mn) space. Fortunately, our upper bounds present\nan explicit tradeoff between space and approximation ratio, allowing us to\ndetermine the amount of space needed to guarantee certain accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2009 07:36:52 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2010 06:12:46 GMT"}], "update_date": "2010-04-09", "authors_parsed": [["Antonellis", "Ioannis", ""], ["Sarma", "Anish Das", ""], ["Dughmi", "Shaddin", ""]]}, {"id": "0912.2550", "submitter": "EPTCS", "authors": "Stefan Blom (University of Twente), Jaco van de Pol (University of\n  Twente)", "title": "Distributed Branching Bisimulation Minimization by Inductive Signatures", "comments": null, "journal-ref": "EPTCS 14, 2009, pp. 32-46", "doi": "10.4204/EPTCS.14.3", "report-no": null, "categories": "cs.LO cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new distributed algorithm for state space minimization modulo\nbranching bisimulation. Like its predecessor it uses signatures for refinement,\nbut the refinement process and the signatures have been optimized to exploit\nthe fact that the input graph contains no tau-loops.\n  The optimization in the refinement process is meant to reduce both the number\nof iterations needed and the memory requirements. In the former case we cannot\nprove that there is an improvement, but our experiments show that in many cases\nthe number of iterations is smaller. In the latter case, we can prove that the\nworst case memory use of the new algorithm is linear in the size of the state\nspace, whereas the old algorithm has a quadratic upper bound.\n  The paper includes a proof of correctness of the new algorithm and the\nresults of a number of experiments that compare the performance of the old and\nthe new algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2009 23:59:14 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Blom", "Stefan", "", "University of Twente"], ["van de Pol", "Jaco", "", "University of\n  Twente"]]}, {"id": "0912.2561", "submitter": "Jens M. Schmidt", "authors": "Jens M. Schmidt", "title": "Construction Sequences and Certifying 3-Connectedness", "comments": "to be published in STACS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tutte proved that every 3-connected graph on more than 4 nodes has a\ncontractible edge. Barnette and Gruenbaum proved the existence of a removable\nedge in the same setting. We show that the sequence of contractions and the\nsequence of removals from G to the K_4 can be computed in O(|V|^2) time by\nextending Barnette and Gruenbaum's theorem. As an application, we derive a\ncertificate for the 3-connectedness of graphs that can be easily computed and\nverified.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 01:35:50 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 14:01:36 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Schmidt", "Jens M.", ""]]}, {"id": "0912.2577", "submitter": "Sebastian Roch", "authors": "Alexandr Andoni and Constantinos Daskalakis and Avinatan Hassidim and\n  Sebastien Roch", "title": "Global Alignment of Molecular Sequences via Ancestral State\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS math.ST q-bio.PE q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular phylogenetic techniques do not generally account for such common\nevolutionary events as site insertions and deletions (known as indels). Instead\ntree building algorithms and ancestral state inference procedures typically\nrely on substitution-only models of sequence evolution. In practice these\nmethods are extended beyond this simplified setting with the use of heuristics\nthat produce global alignments of the input sequences--an important problem\nwhich has no rigorous model-based solution. In this paper we consider a new\nversion of the multiple sequence alignment in the context of stochastic indel\nmodels. More precisely, we introduce the following {\\em trace reconstruction\nproblem on a tree} (TRPT): a binary sequence is broadcast through a tree\nchannel where we allow substitutions, deletions, and insertions; we seek to\nreconstruct the original sequence from the sequences received at the leaves of\nthe tree. We give a recursive procedure for this problem with strong\nreconstruction guarantees at low mutation rates, providing also an alignment of\nthe sequences at the leaves of the tree. The TRPT problem without indels has\nbeen studied in previous work (Mossel 2004, Daskalakis et al. 2006) as a\nbootstrapping step towards obtaining optimal phylogenetic reconstruction\nmethods. The present work sets up a framework for extending these works to\nevolutionary models with indels.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 05:37:42 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Andoni", "Alexandr", ""], ["Daskalakis", "Constantinos", ""], ["Hassidim", "Avinatan", ""], ["Roch", "Sebastien", ""]]}, {"id": "0912.2813", "submitter": "Dai Tri Man Le", "authors": "Dai Tri Man Le", "title": "Combining Partial Order Alignment and Progressive Near-Optimal Alignment", "comments": "Since the draft was too sketchy to be useful, I has decided to\n  withdraw.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I proposed to utilize partial-order alignment technique as a\nheuristic method to cope with the state-space explosion problem in progressive\nnear-optimal alignment. The key idea of my approach is a formal treatment of\nprogressive partial order alignment based on the graph product construction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2009 07:21:33 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2010 16:38:01 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Le", "Dai Tri Man", ""]]}, {"id": "0912.2815", "submitter": "Liam Roditty", "authors": "David Peleg, Liam Roditty", "title": "Relaxed spanners for directed disk graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Let $(V,\\delta)$ be a finite metric space, where $V$ is a set of $n$ points\nand $\\delta$ is a distance function defined for these points. Assume that\n$(V,\\delta)$ has a constant doubling dimension $d$ and assume that each point\n$p\\in V$ has a disk of radius $r(p)$ around it. The disk graph that corresponds\nto $V$ and $r(\\cdot)$ is a \\emph{directed} graph $I(V,E,r)$, whose vertices are\nthe points of $V$ and whose edge set includes a directed edge from $p$ to $q$\nif $\\delta(p,q)\\leq r(p)$. In \\cite{PeRo08} we presented an algorithm for\nconstructing a $(1+\\eps)$-spanner of size $O(n/\\eps^d \\log M)$, where $M$ is\nthe maximal radius $r(p)$. The current paper presents two results. The first\nshows that the spanner of \\cite{PeRo08} is essentially optimal, i.e., for\nmetrics of constant doubling dimension it is not possible to guarantee a\nspanner whose size is independent of $M$. The second result shows that by\nslightly relaxing the requirements and allowing a small perturbation of the\nradius assignment, considerably better spanners can be constructed. In\nparticular, we show that if it is allowed to use edges of the disk graph\n$I(V,E,r_{1+\\eps})$, where $r_{1+\\eps}(p) = (1+\\eps)\\cdot r(p)$ for every $p\\in\nV$, then it is possible to get a $(1+\\eps)$-spanner of size $O(n/\\eps^d)$ for\n$I(V,E,r)$. Our algorithm is simple and can be implemented efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2009 07:31:51 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 13:45:25 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Peleg", "David", ""], ["Roditty", "Liam", ""]]}, {"id": "0912.3188", "submitter": "Shiri Chechik", "authors": "Shiri Chechik and David Peleg", "title": "Robust Fault Tolerant uncapacitated facility location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the uncapacitated facility location problem, given a graph, a set of\ndemands and opening costs, it is required to find a set of facilities R, so as\nto minimize the sum of the cost of opening the facilities in R and the cost of\nassigning all node demands to open facilities. This paper concerns the robust\nfault-tolerant version of the uncapacitated facility location problem (RFTFL).\nIn this problem, one or more facilities might fail, and each demand should be\nsupplied by the closest open facility that did not fail. It is required to find\na set of facilities R, so as to minimize the sum of the cost of opening the\nfacilities in R and the cost of assigning all node demands to open facilities\nthat did not fail, after the failure of up to \\alpha facilities. We present a\npolynomial time algorithm that yields a 6.5-approximation for this problem with\nat most one failure and a 1.5 + 7.5\\alpha-approximation for the problem with at\nmost \\alpha > 1 failures. We also show that the RFTFL problem is NP-hard even\non trees, and even in the case of a single failure.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2009 16:46:55 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:13:09 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Chechik", "Shiri", ""], ["Peleg", "David", ""]]}, {"id": "0912.3563", "submitter": "Petr Sulc", "authors": "P. Sulc, L. Zdeborova", "title": "Belief propagation for graph partitioning", "comments": "16 pages, 4 figures", "journal-ref": "J. Phys. A: Math. Theor. 43 (2010) 285003", "doi": "10.1088/1751-8113/43/28/285003", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the belief propagation algorithm for the graph bi-partitioning\nproblem, i.e. the ground state of the ferromagnetic Ising model at a fixed\nmagnetization. Application of a message passing scheme to a model with a fixed\nglobal parameter is not banal and we show that the magnetization can in fact be\nfixed in a local way within the belief propagation equations. Our method\nprovides the full phase diagram of the bi-partitioning problem on random\ngraphs, as well as an efficient heuristic solver that we anticipate to be\nuseful in a wide range of application of the partitioning problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 16:53:39 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Sulc", "P.", ""], ["Zdeborova", "L.", ""]]}, {"id": "0912.3912", "submitter": "Hector J. Garcia", "authors": "Hector J. Garcia, Igor L. Markov", "title": "High-performance Energy Minimization with Applications to Adiabatic\n  Quantum Computing", "comments": "9 pages, 1 table, 10 figures", "journal-ref": "Proc. Design Autom. and Test in Europe Conf. (DATE), pp. 160 -\n  165, March 2010", "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.DS cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy minimization of Ising spin-glasses has played a central role in\nstatistical and solid-state physics, facilitating studies of phase transitions\nand magnetism. Recent proposals suggest using Ising spin-glasses for\nnon-traditional computing as a way to harness the nature's ability to find\nmin-energy configurations, and to take advantage of quantum tunneling to boost\ncombinatorial optimization. Laboratory demonstrations have been unconvincing so\nfar and lack a non-quantum baseline for definitive comparisons. In this work we\n(i) design and evaluate new computational techniques to simulate natural energy\nminimization in spin glasses and (ii) explore their application to study design\nalternatives in quantum adiabatic computers. Unlike previous work, our\nalgorithms are not limited to planar Ising topologies. In one CPU-day, our\nbranch-and-bound algorithm finds ground states on 100 spins, while our local\nsearch approximates ground states on 1, 000, 000 spins. We use this\ncomputational tool as a simulator to study the significance of hyper-couplings\nin the context of recently implemented adiabatic quantum computers.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2009 17:46:45 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2010 17:18:57 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2013 19:38:30 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Garcia", "Hector J.", ""], ["Markov", "Igor L.", ""]]}, {"id": "0912.3925", "submitter": "Vamsi Kundeti", "authors": "Vamsi K. Kundeti", "title": "A Simplified Proof For The Application Of Freivalds' Technique to Verify\n  Matrix Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprinting is a well known technique, which is often used in designing\nMonte Carlo algorithms for verifying identities involving ma- trices, integers\nand polynomials. The book by Motwani and Raghavan [1] shows how this technique\ncan be applied to check the correctness of matrix multiplication -- check if AB\n= C where A, B and C are three nxn matrices. The result is a Monte Carlo\nalgorithm running in time $Theta(n^2)$ with an exponentially decreasing error\nprobability after each indepen- dent iteration. In this paper we give a simple\nalternate proof addressing the same problem. We also give further\ngeneralizations and relax various assumptions made in the proof.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2009 18:54:20 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2010 00:34:35 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Kundeti", "Vamsi K.", ""]]}, {"id": "0912.3927", "submitter": "William Jackson", "authors": "A. K. Ojha, C. Mallick, D. Mallick", "title": "Logarithmic Barrier Optimization Problem Using Neural Network", "comments": null, "journal-ref": "Journal of Computing, Volume 1, Issue 1, pp 12-19, December 2009", "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combinatorial optimization problem is one of the important applications\nin neural network computation. The solutions of linearly constrained continuous\noptimization problems are difficult with an exact algorithm, but the algorithm\nfor the solution of such problems is derived by using logarithm barrier\nfunction. In this paper we have made an attempt to solve the linear constrained\noptimization problem by using general logarithm barrier function to get an\napproximate solution. In this case the barrier parameters behave as temperature\ndecreasing to zero from sufficiently large positive number satisfying convexity\nof the barrier function. We have developed an algorithm to generate decreasing\nsequence of solution converging to zero limit.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2009 18:59:22 GMT"}], "update_date": "2009-12-22", "authors_parsed": [["Ojha", "A. K.", ""], ["Mallick", "C.", ""], ["Mallick", "D.", ""]]}, {"id": "0912.3963", "submitter": "William Jackson", "authors": "Hani M. AL-Matari, Sattar J. Aboud, Nidal F. Shilbayeh", "title": "Fast Fraction-Integer Method for Computing Multiplicative Inverse", "comments": null, "journal-ref": "Journal of Computing, Volume 1, Issue 1, pp 131-135, December 2009", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplicative inverse is a crucial operation in public key cryptography, and\nbeen widely used in cryptography. Public key cryptography has given rise to\nsuch a need, in which we need to generate a related public and private pair of\nnumbers, each of which is the inverse of the other. The basic method to find\nmultiplicative inverses is Extended-Euclidean method. In this paper we will\npropose a new algorithm for computing the inverse, based on continues subtract\nfraction from integer and divide by fraction to obtain integer that will be\nused to compute the inverse d. The authors claim that the proposed method more\nefficient and faster than the existed methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2009 02:32:42 GMT"}], "update_date": "2009-12-22", "authors_parsed": [["AL-Matari", "Hani M.", ""], ["Aboud", "Sattar J.", ""], ["Shilbayeh", "Nidal F.", ""]]}, {"id": "0912.4084", "submitter": "Charles Sauerbier", "authors": "Charles Sauerbier", "title": "Computing an Integer Prime Factoring in O(n^2.5)", "comments": "This paper has been withdrawn by the author. Paper is withdrawn. On\n  review the paper contributes nothing of significance. The runtime analysis of\n  the algorithms presented, while correct in terms of number of operations,\n  does not represent the complexity of the algorithms in terms of \"bits input\".\n  A naive mistake in reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper is withdrawn. On review the paper contributes little of significance.\nThe runtime analysis of the algorithms presented, while correct in terms of\nnumber of operations, does not represent the complexity of the algorithms in\nterms of \"bits input\". A naive mistake in reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2009 06:10:33 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2010 22:42:51 GMT"}, {"version": "v3", "created": "Thu, 28 Jul 2011 14:07:24 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Sauerbier", "Charles", ""]]}, {"id": "0912.4196", "submitter": "Tamon Stephen", "authors": "Cedric Chauve, Utz-Uwe Haus, Tamon Stephen, Vivija P. You", "title": "Minimal Conflicting Sets for the Consecutive Ones Property in ancestral\n  genome reconstruction", "comments": "20 pages, 3 figures", "journal-ref": "J Comput Biol. 2010 Sep;17(9):1167-81", "doi": "10.1089/cmb.2010.0113", "report-no": null, "categories": "q-bio.GN cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary matrix has the Consecutive Ones Property (C1P) if its columns can be\nordered in such a way that all 1's on each row are consecutive. A Minimal\nConflicting Set is a set of rows that does not have the C1P, but every proper\nsubset has the C1P. Such submatrices have been considered in comparative\ngenomics applications, but very little is known about their combinatorial\nstructure and efficient algorithms to compute them. We first describe an\nalgorithm that detects rows that belong to Minimal Conflicting Sets. This\nalgorithm has a polynomial time complexity when the number of 1's in each row\nof the considered matrix is bounded by a constant. Next, we show that the\nproblem of computing all Minimal Conflicting Sets can be reduced to the joint\ngeneration of all minimal true clauses and maximal false clauses for some\nmonotone boolean function. We use these methods on simulated data related to\nancestral genome reconstruction to show that computing Minimal Conflicting Set\nis useful in discriminating between true positive and false positive ancestral\nsyntenies. We also study a dataset of yeast genomes and address the reliability\nof an ancestral genome proposal of the Saccahromycetaceae yeasts.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2009 16:03:06 GMT"}], "update_date": "2011-10-13", "authors_parsed": [["Chauve", "Cedric", ""], ["Haus", "Utz-Uwe", ""], ["Stephen", "Tamon", ""], ["You", "Vivija P.", ""]]}, {"id": "0912.4226", "submitter": "Andreas Gaiser", "authors": "Javier Esparza, Andreas Gaiser, Stefan Kiefer", "title": "Computing Least Fixed Points of Probabilistic Systems of Polynomials", "comments": "Published in the Proceedings of the 27th International Symposium on\n  Theoretical Aspects of Computer Science (STACS). Technical Report is also\n  available via arxiv.org", "journal-ref": "Proceedings of the 27th International Symposium on Theoretical\n  Aspects of Computer Science (STACS) 2010", "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study systems of equations of the form X1 = f1(X1, ..., Xn), ..., Xn =\nfn(X1, ..., Xn), where each fi is a polynomial with nonnegative coefficients\nthat add up to 1. The least nonnegative solution, say mu, of such equation\nsystems is central to problems from various areas, like physics, biology,\ncomputational linguistics and probabilistic program verification. We give a\nsimple and strongly polynomial algorithm to decide whether mu=(1, ..., 1)\nholds. Furthermore, we present an algorithm that computes reliable sequences of\nlower and upper bounds on mu, converging linearly to mu. Our algorithm has\nthese features despite using inexact arithmetic for efficiency. We report on\nexperiments that show the performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2009 19:14:12 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 09:06:34 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Esparza", "Javier", ""], ["Gaiser", "Andreas", ""], ["Kiefer", "Stefan", ""]]}, {"id": "0912.4389", "submitter": "Tim Evans", "authors": "T.S.Evans, R.Lambiotte", "title": "Line Graphs of Weighted Networks for Overlapping Communities", "comments": "8 Pages. New title and text revisions to emphasise differences from\n  earlier papers", "journal-ref": "Eur. Phys. J. B 77 (2010) 265-272", "doi": "10.1140/epjb/e2010-00261-8", "report-no": "Imperial/TP/09/TSE/3", "categories": "physics.data-an cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop the idea to partition the edges of a weighted graph\nin order to uncover overlapping communities of its nodes. Our approach is based\non the construction of different types of weighted line graphs, i.e. graphs\nwhose nodes are the links of the original graph, that encapsulate differently\nthe relations between the edges. Weighted line graphs are argued to provide an\nalternative, valuable representation of the system's topology, and are shown to\nhave important applications in community detection, as the usual node partition\nof a line graph naturally leads to an edge partition of the original graph.\nThis identification allows us to use traditional partitioning methods in order\nto address the long-standing problem of the detection of overlapping\ncommunities. We apply it to the analysis of different social and geographical\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2009 12:34:29 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2010 11:00:35 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Evans", "T. S.", ""], ["Lambiotte", "R.", ""]]}, {"id": "0912.4569", "submitter": "Ho Leung Chan", "authors": "Ho-Leung Chan, Tak-Wah Lam, Lap-Kei Lee, and Hing-Fung Ting", "title": "Continuous Monitoring of Distributed Data Streams over a Time-based\n  Sliding Window", "comments": "12 pages, to appear in the 27th International Symposium on\n  Theoretical Aspects of Computer Science (STACS), 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has witnessed many interesting algorithms for maintaining\nstatistics over a data stream. This paper initiates a theoretical study of\nalgorithms for monitoring distributed data streams over a time-based sliding\nwindow (which contains a variable number of items and possibly out-of-order\nitems). The concern is how to minimize the communication between individual\nstreams and the root, while allowing the root, at any time, to be able to\nreport the global statistics of all streams within a given error bound. This\npaper presents communication-efficient algorithms for three classical\nstatistics, namely, basic counting, frequent items and quantiles. The\nworst-case communication cost over a window is $O(\\frac{k} {\\epsilon} \\log\n\\frac{\\epsilon N}{k})$ bits for basic counting and $O(\\frac{k}{\\epsilon} \\log\n\\frac{N}{k})$ words for the remainings, where $k$ is the number of distributed\ndata streams, $N$ is the total number of items in the streams that arrive or\nexpire in the window, and $\\epsilon < 1$ is the desired error bound. Matching\nand nearly matching lower bounds are also obtained.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 09:56:50 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:11:41 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Chan", "Ho-Leung", ""], ["Lam", "Tak-Wah", ""], ["Lee", "Lap-Kei", ""], ["Ting", "Hing-Fung", ""]]}, {"id": "0912.4798", "submitter": "Ratthachat Chatpatanasiri", "authors": "Ratthachat Chatpatanasiri and Thavivongse Sriburi", "title": "Demand-Supply Optimization with Risk Management for a Multi-Connection\n  Water Reservoir Network", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework to solve a demand-supply optimization\nproblem of long-term water resource allocation on a multi-connection reservoir\nnetwork which, in two aspects, is different to the problem considered in\nprevious works. First, while all previous works consider a problem where each\nreservoir can transfer water to only one fixed reservoir, we consider a\nmulti-connection network being constructed in Thailand in which each reservoir\ncan transfer water to many reservoirs in one period of time. Second, a\ndemand-supply plan considered here is static, in contrast to a dynamic policy\nconsidered in previous works. Moreover, in order to efficiently develop a\nlong-term static plan, a severe loss (a risk) is taken into account, i.e. a\nrisk occurs if the real amount of water stored in each reservoir in each time\nperiod is less than what planned by the optimizer. The multi-connection\nfunction and the risk make the problem rather complex such that traditional\nstochastic dynamic programming and deterministic/heuristic approaches are\ninappropriate. Our framework is based on a novel convex programming formulation\nin which stochastic information can be naturally taken into account and an\noptimal solution is guaranteed to be found efficiently. Extensive experimental\nresults show promising results of the framework.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2009 06:04:15 GMT"}], "update_date": "2009-12-25", "authors_parsed": [["Chatpatanasiri", "Ratthachat", ""], ["Sriburi", "Thavivongse", ""]]}, {"id": "0912.4941", "submitter": "Michael Lampis", "authors": "Antonis Achilleos, Michael Lampis, Valia Mitsou", "title": "Parameterized Modal Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameterized computational complexity of the\nsatisfiability problem for modal logic and attempt to pinpoint relevant\nstructural parameters which cause the problem's combinatorial explosion, beyond\nthe number of propositional variables v. To this end we study the modality\ndepth, a natural measure which has appeared in the literature, and show that,\neven though modal satisfiability parameterized by v and the modality depth is\nFPT, the running time's dependence on the parameters is a tower of exponentials\n(unless P=NP). To overcome this limitation we propose several possible\nalternative parameters, namely diamond dimension, box dimension and modal\nwidth. We show fixed-parameter tractability results using these measures where\nthe exponential dependence on the parameters is much milder than in the case of\nmodality depth thus leading to FPT algorithms for modal satisfiability with\nmuch more reasonable running times.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2009 05:31:25 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Achilleos", "Antonis", ""], ["Lampis", "Michael", ""], ["Mitsou", "Valia", ""]]}, {"id": "0912.5182", "submitter": "Jeff M Phillips", "authors": "Pankaj K. Agarwal and Jeff M. Phillips and Bardia Sadri", "title": "Lipschitz Unimodal and Isotonic Regression on Paths and Trees", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithms for finding the regression of t, a sequence of values,\nto the closest sequence s by mean squared error, so that s is always increasing\n(isotonicity) and so the values of two consecutive points do not increase by\ntoo much (Lipschitz). The isotonicity constraint can be replaced with a\nunimodular constraint, where there is exactly one local maximum in s. These\nalgorithm are generalized from sequences of values to trees of values. For each\nscenario we describe near-linear time algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2009 15:39:01 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Phillips", "Jeff M.", ""], ["Sadri", "Bardia", ""]]}, {"id": "0912.5424", "submitter": "Yuriy Arbitman", "authors": "Yuriy Arbitman, Moni Naor and Gil Segev", "title": "Backyard Cuckoo Hashing: Constant Worst-Case Operations with a Succinct\n  Representation", "comments": "FOCS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a dynamic dictionary is measured mainly by its update\ntime, lookup time, and space consumption. In terms of update time and lookup\ntime there are known constructions that guarantee constant-time operations in\nthe worst case with high probability, and in terms of space consumption there\nare known constructions that use essentially optimal space. However, although\nthe first analysis of a dynamic dictionary dates back more than 45 years ago\n(when Knuth analyzed linear probing in 1963), the trade-off between these\naspects of performance is still not completely understood. In this paper we\nsettle two fundamental open problems: - We construct the first dynamic\ndictionary that enjoys the best of both worlds: it stores n elements using\n(1+epsilon)n memory words, and guarantees constant-time operations in the worst\ncase with high probability. Specifically, for any epsilon = \\Omega((\\log\\log n\n/ \\log n)^{1/2} ) and for any sequence of polynomially many operations, with\nhigh probability over the randomness of the initialization phase, all\noperations are performed in constant time which is independent of epsilon. The\nconstruction is a two-level variant of cuckoo hashing, augmented with a\n\"backyard\" that handles a large fraction of the elements, together with a\nde-amortized perfect hashing scheme for eliminating the dependency on epsilon.\n- We present a variant of the above construction that uses only (1+o(1))B bits,\nwhere B is the information-theoretic lower bound for representing a set of size\nn taken from a universe of size u, and guarantees constant-time operations in\nthe worst case with high probability, as before. This problem was open even in\nthe amortized setting. One of the main ingredients of our construction is a\npermutation-based variant of cuckoo hashing, which significantly improves the\nspace consumption of cuckoo hashing when dealing with a rather small universe.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 07:55:20 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2010 07:54:49 GMT"}, {"version": "v3", "created": "Mon, 16 Aug 2010 10:28:02 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Arbitman", "Yuriy", ""], ["Naor", "Moni", ""], ["Segev", "Gil", ""]]}, {"id": "0912.5449", "submitter": "Artur Ferreira", "authors": "Artur Ferreira, Arlindo Oliveira, Mario Figueiredo", "title": "Time and Memory Efficient Lempel-Ziv Compression Using Suffix Arrays", "comments": "10 pages, submitted to DCC2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known dictionary-based algorithms of the Lempel-Ziv (LZ) 77 family\nare the basis of several universal lossless compression techniques. These\nalgorithms are asymmetric regarding encoding/decoding time and memory\nrequirements, with the former being much more demanding. In the past years,\nconsiderable attention has been devoted to the problem of finding efficient\ndata structures to support these searches, aiming at optimizing the encoders in\nterms of speed and memory. Hash tables, binary search trees and suffix trees\nhave been widely used for this purpose, as they allow fast search at the\nexpense of memory. Some recent research has focused on suffix arrays (SA), due\nto their low memory requirements and linear construction algorithms. Previous\nwork has shown how the LZ77 decomposition can be computed using a single SA or\nan SA with an auxiliary array with the longest common prefix information. The\nSA-based algorithms use less memory than the tree-based encoders, allocating\nthe strictly necessary amount of memory, regardless of the contents of the text\nto search/encode. In this paper, we improve on previous work by proposing\nfaster SA-based algorithms for LZ77 encoding and sub-string search, keeping\ntheir low memory requirements. For some compression settings, on a large set of\nbenchmark files, our low-memory SA-based encoders are also faster than\ntree-based encoders. This provides time and memory efficient LZ77 encoding,\nbeing a possible replacement for trees on well known encoders like LZMA. Our\nalgorithm is also suited for text classification, because it provides a compact\nway to describe text in a bag-of-words representation, as well as a fast\nindexing mechanism that allows to quickly find all the sets of words that start\nwith a given symbol, over a static dictionary.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 11:45:44 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Ferreira", "Artur", ""], ["Oliveira", "Arlindo", ""], ["Figueiredo", "Mario", ""]]}, {"id": "0912.5468", "submitter": "Bernard Lidick\\'y", "authors": "Jiri Fiala, Marcin Kaminski, Bernard Lidicky and Daniel Paulusma", "title": "The k-in-a-path problem for claw-free graphs", "comments": "12 pages, 1 figure, STACS 2010", "journal-ref": null, "doi": "10.1007/s00453-010-9468-z", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Testing whether there is an induced path in a graph spanning k given vertices\nis already NP-complete in general graphs when k=3. We show how to solve this\nproblem in polynomial time on claw-free graphs, when k is not part of the input\nbut an arbitrarily fixed integer.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 18:46:27 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 10:58:00 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Fiala", "Jiri", ""], ["Kaminski", "Marcin", ""], ["Lidicky", "Bernard", ""], ["Paulusma", "Daniel", ""]]}, {"id": "0912.5473", "submitter": "Gerald Paul", "authors": "Gerald Paul", "title": "A Variable Depth Sequential Search Heuristic for the Quadratic\n  Assignment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a variable depth search heuristic for the quadratic assignment\nproblem. The heuristic is based on sequential changes in assignments analogous\nto the Lin-Kernighan sequential edge moves for the traveling salesman problem.\nWe treat unstructured problem instances of sizes 60 to 400. When the heuristic\nis used in conjunction with robust tabu search, we measure performance\nimprovements of up to a factor of 15 compared to the use of robust tabu alone.\nThe performance improvement increases as the problem size increases.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 14:42:30 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Paul", "Gerald", ""]]}]