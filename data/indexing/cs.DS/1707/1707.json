[{"id": "1707.00080", "submitter": "Aubrey Alston", "authors": "Aubrey Alston", "title": "Corpus-compressed Streaming and the Spotify Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a problem which we refer to as the \\textbf{Spotify\nproblem} and explore a potential solution in the form of what we call\ncorpus-compressed streaming schemes.\n  Inspired by the problem of constrained bandwidth during use of the popular\nSpotify application on mobile networks, the Spotify problem applies in any\nnumber of practical domains where devices may be periodically expected to\nexperience degraded communication or storage capacity. One obvious solution\ncandidate which comes to mind immediately is standard compression. Though\nobviously applicable, standard compression does not in any way exploit all\ncharacteristics of the problem; in particular, standard compression is\noblivious to the fact that a decoder has a period of virtually unrestrained\ncommunication. Towards applying compression in a manner which attempts to\nstretch the benefit of periods of higher communication capacity into periods of\nrestricted capacity, we introduce as a solution the idea of a corpus-compressed\nstreaming scheme.\n  This report begins with a formal definition of a corpus-compressed streaming\nscheme. Following a discussion of how such schemes apply to the Spotify\nproblem, we then give a survey of specific corpus-compressed scheming schemes\nguided by an exploration of different measures of description complexity within\nthe Chomsky hierarchy of languages.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 01:27:29 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Alston", "Aubrey", ""]]}, {"id": "1707.00106", "submitter": "Rani M R", "authors": "M R Rani, R Subashini and Mohith Jagalmohanan", "title": "Simultaneous Consecutive Ones Submatrix and Editing Problems : Classical\n  Complexity \\& Fixed-Parameter Tractable Results", "comments": "A preliminary version of this paper appeared in the proceedings of\n  the 12th International Frontiers of Algorithmics Workshop (FAW 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary matrix $M$ has the consecutive ones property ($C1P$) for rows (resp.\ncolumns) if there is a permutation of its columns (resp. rows) that arranges\nthe ones consecutively in all the rows (resp. columns). If $M$ has the $C1P$\nfor rows and columns, then $M$ is said to have the simultaneous consecutive\nones property ($SC1P$). In this article, we consider the classical complexity\nand fixed-parameter tractability of $(a)$ Simultaneous Consecutive Ones\nSubmatrix ($SC1S$) and $(b)$ Simultaneous Consecutive Ones Editing ($SC1E$)\n[Oswald et al., Theoretical Comp. Sci. 410(21-23):1986-1992,\n\\hyperref[references]{2009}] problems. We show that the decision versions of\n$SC1S$ and $SC1E$ problems are NP-complete. We consider the parameterized\nversions of $SC1S$ and $SC1E$ problems with $d$, being the solution size, as\nthe parameter. Given a binary matrix $M$ and a positive integer $d$,\n$d$-$SC1S$-$R$, $d$-$SC1S$-$C$, and $d$-$SC1S$-$RC$ problems decide whether\nthere exists a set of rows, columns, and rows as well as columns, respectively,\nof size at most $d$, whose deletion results in a matrix with the $SC1P$. The\n$d$-$SC1P$-$0E$, $d$-$SC1P$-$1E$, and $d$-$SC1P$-$01E$ problems decide whether\nthere exists a set of $0$-entries, $1$-entries, and $0$-entries as well as\n$1$-entries, respectively, of size at most $d$, whose flipping results in a\nmatrix with the \\vspace{0.095 in} $SC1P$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 07:39:26 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 09:28:15 GMT"}, {"version": "v3", "created": "Thu, 8 Feb 2018 04:44:10 GMT"}, {"version": "v4", "created": "Mon, 12 Nov 2018 11:33:50 GMT"}, {"version": "v5", "created": "Tue, 13 Nov 2018 03:08:51 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Rani", "M R", ""], ["Subashini", "R", ""], ["Jagalmohanan", "Mohith", ""]]}, {"id": "1707.00165", "submitter": "Henning Sulzbach", "authors": "Rafik Aguech, Anis Amri, Henning Sulzbach", "title": "On weighted depths in random binary search trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the model introduced by Aguech, Lasmar and Mahmoud [Probab. Engrg.\nInform. Sci. 21 (2007) 133-141], the weighted depth of a node in a labelled\nrooted tree is the sum of all labels on the path connecting the node to the\nroot. We analyze weighted depths of nodes with given labels, the last inserted\nnode, nodes ordered as visited by the depth first search process, the weighted\npath length and the weighted Wiener index in a random binary search tree. We\nestablish three regimes of nodes depending on whether the second order\nbehaviour of their weighted depths follows from fluctuations of the keys on the\npath, the depth of the nodes, or both. Finally, we investigate a random\ndistribution function on the unit interval arising as scaling limit for\nweighted depths of nodes with at most one child.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 15:03:22 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Aguech", "Rafik", ""], ["Amri", "Anis", ""], ["Sulzbach", "Henning", ""]]}, {"id": "1707.00349", "submitter": "Christopher Umans", "authors": "Chloe Ching-Yun Hsu and Chris Umans", "title": "A new algorithm for fast generalized DFTs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an new arithmetic algorithm to compute the generalized Discrete\nFourier Transform (DFT) over finite groups $G$. The new algorithm uses\n$O(|G|^{\\omega/2 + o(1)})$ operations to compute the generalized DFT over\nfinite groups of Lie type, including the linear, orthogonal, and symplectic\nfamilies and their variants, as well as all finite simple groups of Lie type.\nHere $\\omega$ is the exponent of matrix multiplication, so the exponent\n$\\omega/2$ is optimal if $\\omega = 2$. Previously, \"exponent one\" algorithms\nwere known for supersolvable groups and the symmetric and alternating groups.\nNo exponent one algorithms were known (even under the assumption $\\omega = 2$)\nfor families of linear groups of fixed dimension, and indeed the previous\nbest-known algorithm for $SL_2(F_q)$ had exponent $4/3$ despite being the focus\nof significant effort. We unconditionally achieve exponent at most $1.19$ for\nthis group, and exponent one if $\\omega = 2$. Our algorithm also yields an\nimproved exponent for computing the generalized DFT over general finite groups\n$G$, which beats the longstanding previous best upper bound, for any $\\omega$.\nIn particular, assuming $\\omega = 2$, we achieve exponent $\\sqrt{2}$, while the\nprevious best was $3/2$.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 20:41:10 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 21:19:30 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2018 05:20:15 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Hsu", "Chloe Ching-Yun", ""], ["Umans", "Chris", ""]]}, {"id": "1707.00351", "submitter": "Minyar Sassi", "authors": "Rania Mkhinini Gahar, Olfa Arfaoui, Minyar Sassi Hidri, Nejib Ben-Hadj\n  Alouane", "title": "Dimensionality reduction with missing values imputation", "comments": "6 pages, 2 figures, The first Computer science University of Tunis El\n  Manar, PhD Symposium (CUPS'17), Tunisia, May 22-25, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a new statical approach for high-dimensionality\nreduction of heterogenous data that limits the curse of dimensionality and\ndeals with missing values. To handle these latter, we propose to use the Random\nForest imputation's method. The main purpose here is to extract useful\ninformation and so reducing the search space to facilitate the data exploration\nprocess. Several illustrative numeric examples, using data coming from publicly\navailable machine learning repositories are also included. The experimental\ncomponent of the study shows the efficiency of the proposed analytical\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 20:47:11 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Gahar", "Rania Mkhinini", ""], ["Arfaoui", "Olfa", ""], ["Hidri", "Minyar Sassi", ""], ["Alouane", "Nejib Ben-Hadj", ""]]}, {"id": "1707.00362", "submitter": "Josh Alman", "authors": "Josh Alman, Matthias Mnich, Virginia Vassilevska Williams", "title": "Dynamic Parameterized Problems and Algorithms", "comments": "40 pages, appears in ICALP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-parameter algorithms and kernelization are two powerful methods to\nsolve $\\mathsf{NP}$-hard problems. Yet, so far those algorithms have been\nlargely restricted to static inputs.\n  In this paper we provide fixed-parameter algorithms and kernelizations for\nfundamental $\\mathsf{NP}$-hard problems with dynamic inputs. We consider a\nvariety of parameterized graph and hitting set problems which are known to have\n$f(k)n^{1+o(1)}$ time algorithms on inputs of size $n$, and we consider the\nquestion of whether there is a data structure that supports small updates (such\nas edge/vertex/set/element insertions and deletions) with an update time of\n$g(k)n^{o(1)}$; such an update time would be essentially optimal. Update and\nquery times independent of $n$ are particularly desirable. Among many other\nresults, we show that Feedback Vertex Set and $k$-Path admit dynamic algorithms\nwith $f(k)\\log^{O(1)}n$ update and query times for some function $f$ depending\non the solution size $k$ only.\n  We complement our positive results by several conditional and unconditional\nlower bounds. For example, we show that unlike their undirected counterparts,\nDirected Feedback Vertex Set and Directed $k$-Path do not admit dynamic\nalgorithms with $n^{o(1)}$ update and query times even for constant solution\nsizes $k\\leq 3$, assuming popular hardness hypotheses. We also show that\nunconditionally, in the cell probe model, Directed Feedback Vertex Set cannot\nbe solved with update time that is purely a function of $k$.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 22:34:51 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Alman", "Josh", ""], ["Mnich", "Matthias", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1707.00469", "submitter": "Simone Faro", "authors": "Domenico Cantone, Simone Faro and Arianna Pavone", "title": "Speeding Up String Matching by Weak Factor Recognition", "comments": "11 pages, appeared in proceedings of the Prague Stringology\n  Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String matching is the problem of finding all the substrings of a text which\nmatch a given pattern. It is one of the most investigated problems in computer\nscience, mainly due to its very diverse applications in several fields.\nRecently, much research in the string matching field has focused on the\nefficiency and flexibility of the searching procedure and quite effective\ntechniques have been proposed for speeding up the existing solutions. In this\ncontext, algorithms based on factors recognition are among the best solutions.\nIn this paper, we present a simple and very efficient algorithm for string\nmatching based on a weak factor recognition and hashing. Our algorithm has a\nquadratic worst-case running time. However, despite its quadratic complexity,\nexperimental results show that our algorithm obtains in most cases the best\nrunning times when compared, under various conditions, against the most\neffective algorithms present in literature. In the case of small alphabets and\nlong patterns, the gain in running times reaches 28%. This makes our proposed\nalgorithm one of the most flexible solutions in practical cases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 10:03:35 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Cantone", "Domenico", ""], ["Faro", "Simone", ""], ["Pavone", "Arianna", ""]]}, {"id": "1707.00496", "submitter": "Sara Nicoloso", "authors": "Tiziano Bacci and Sara Nicoloso", "title": "A heuristic algorithm for the Bin Packing Problem with Conflicts on\n  Interval Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the Bin Packing Problem with Conflicts on interval\ngraphs: given an interval graph, a nonnegative integer weight for each vertex,\nand a nonnegative integer B, find a partition of the vertex set of the graph\ninto k subsets such that the sum of the weights of the vertices assigned to\nsame subset is less than or equal to B, two vertices connected by an edge do\nnot belong to the same subset, and k is minimum. We design a heuristic\nalgorithm, and propose a new random interval graph generator which builds\ninterval conflict graphs with desired edge density. We test the algorithm on a\nhuge test bed, and compare the results with existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 12:05:32 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 10:03:34 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Bacci", "Tiziano", ""], ["Nicoloso", "Sara", ""]]}, {"id": "1707.00826", "submitter": "Marc Khoury", "authors": "Nicholas J. Cavanna, Marc Khoury, Donald R. Sheehy", "title": "Supporting Ruled Polygons", "comments": "Canadian Conference on Computational Geometry 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore several problems related to ruled polygons. Given a ruling of a\npolygon $P$, we consider the Reeb graph of $P$ induced by the ruling. We define\nthe Reeb complexity of $P$, which roughly equates to the minimum number of\npoints necessary to support $P$. We give asymptotically tight bounds on the\nReeb complexity that are also tight up to a small additive constant. When\nrestricted to the set of parallel rulings, we show that the Reeb complexity can\nbe computed in polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 06:33:28 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Cavanna", "Nicholas J.", ""], ["Khoury", "Marc", ""], ["Sheehy", "Donald R.", ""]]}, {"id": "1707.00904", "submitter": "Ken-ichiro Ishikawa", "authors": "Ken-ichiro Ishikawa", "title": "Sequential Checking: Reallocation-Free Data-Distribution Algorithm for\n  Scale-out Storage", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using tape or optical devices for scale-out storage is one option for storing\na vast amount of data. However, it is impossible or almost impossible to\nrewrite data with such devices. Thus, scale-out storage using such devices\ncannot use standard data-distribution algorithms because they rewrite data for\nmoving between servers constituting the scale-out storage when the server\nconfiguration is changed. Although using rewritable devices for scale-out\nstorage, when server capacity is huge, rewriting data is very hard when server\nconstitution is changed. In this paper, a data-distribution algorithm called\nSequential Checking is proposed, which can be used for scale-out storage\ncomposed of devices that are hardly able to rewrite data. Sequential Checking\n1) does not need to move data between servers when the server configuration is\nchanged, 2) distribute data, the amount of which depends on the server's\nvolume, 3) select a unique server when datum is written, and 4) select servers\nwhen datum is read (there are few such server(s) in most cases) and find out a\nunique server that stores the newest datum from them. These basic\ncharacteristics were confirmed through proofs and simulations. Data can be read\nby accessing 1.98 servers on average from a storage comprising 256 servers\nunder a realistic condition. And it is confirmed by evaluations in real\nenvironment that access time is acceptable. Sequential Checking makes selecting\nscale-out storage using tape or optical devices or using huge capacity servers\nrealistic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 10:52:39 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Ishikawa", "Ken-ichiro", ""]]}, {"id": "1707.00943", "submitter": "Jonathan Weed", "authors": "Amelia Perry, Jonathan Weed, Afonso S. Bandeira, Philippe Rigollet,\n  Amit Singer", "title": "The sample complexity of multi-reference alignment", "comments": "To appear in SIAM Journal on Mathematics of Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing role of data-driven approaches to scientific discovery has\nunveiled a large class of models that involve latent transformations with a\nrigid algebraic constraint. Three-dimensional molecule reconstruction in\nCryo-Electron Microscopy (cryo-EM) is a central problem in this class. Despite\ndecades of algorithmic and software development, there is still little\ntheoretical understanding of the sample complexity of this problem, that is,\nnumber of images required for 3-D reconstruction. Here we consider\nmulti-reference alignment (MRA), a simple model that captures fundamental\naspects of the statistical and algorithmic challenges arising in cryo-EM and\nrelated problems. In MRA, an unknown signal is subject to two types of\ncorruption: a latent cyclic shift and the more traditional additive white\nnoise. The goal is to recover the signal at a certain precision from\nindependent samples. While at high signal-to-noise ratio (SNR), the number of\nobservations needed to recover a generic signal is proportional to\n$1/\\mathrm{SNR}$, we prove that it rises to a surprising $1/\\mathrm{SNR}^3$ in\nthe low SNR regime. This precise phenomenon was observed empirically more than\ntwenty years ago for cryo-EM but has remained unexplained to date. Furthermore,\nour techniques can easily be extended to the heterogeneous MRA model where the\nsamples come from a mixture of signals, as is often the case in applications\nsuch as cryo-EM, where molecules may have different conformations. This\nprovides a first step towards a statistical theory for heterogeneous cryo-EM.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 12:42:46 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:36:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Perry", "Amelia", ""], ["Weed", "Jonathan", ""], ["Bandeira", "Afonso S.", ""], ["Rigollet", "Philippe", ""], ["Singer", "Amit", ""]]}, {"id": "1707.01037", "submitter": "Amer Mouawad", "authors": "Daniel Lokshtanov, Amer E. Mouawad, Saket Saurabh, and Meirav Zehavi", "title": "Packing Cycles Faster Than Erd\\H{o}s-P\\'osa", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cycle Packing problem asks whether a given undirected graph $G=(V,E)$\ncontains $k$ vertex-disjoint cycles. Since the publication of the classic\nErd\\H{o}s-P\\'osa theorem in 1965, this problem received significant scientific\nattention in the fields of Graph Theory and Algorithm Design. In particular,\nthis problem is one of the first problems studied in the framework of\nParameterized Complexity. The non-uniform fixed-parameter tractability of Cycle\nPacking follows from the Robertson-Seymour theorem, a fact already observed by\nFellows and Langston in the 1980s. In 1994, Bodlaender showed that Cycle\nPacking can be solved in time $2^{\\mathcal{O}(k^2)}\\cdot |V|$ using exponential\nspace. In case a solution exists, Bodlaender's algorithm also outputs a\nsolution (in the same time). It has later become common knowledge that Cycle\nPacking admits a $2^{\\mathcal{O}(k\\log^2k)}\\cdot |V|$-time (deterministic)\nalgorithm using exponential space, which is a consequence of the\nErd\\H{o}s-P\\'osa theorem. Nowadays, the design of this algorithm is given as an\nexercise in textbooks on Parameterized Complexity. Yet, no algorithm that runs\nin time $2^{o(k\\log^2k)}\\cdot |V|^{\\mathcal{O}(1)}$, beating the bound\n$2^{\\mathcal{O}(k\\log^2k)}\\cdot |V|^{\\mathcal{O}(1)}$, has been found. In light\nof this, it seems natural to ask whether the $2^{\\mathcal{O}(k\\log^2k)}\\cdot\n|V|^{\\mathcal{O}(1)}$ bound is essentially optimal. In this paper, we answer\nthis question negatively by developing a\n$2^{\\mathcal{O}(\\frac{k\\log^2k}{\\log\\log k})}\\cdot |V|$-time (deterministic)\nalgorithm for Cycle Packing. In case a solution exists, our algorithm also\noutputs a solution (in the same time). Moreover, apart from beating the bound\n$2^{\\mathcal{O}(k\\log^2k)}\\cdot |V|^{\\mathcal{O}(1)}$, our algorithm runs in\ntime linear in $|V|$, and its space complexity is polynomial in the input size.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 15:29:17 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Mouawad", "Amer E.", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1707.01047", "submitter": "Vasilis Syrgkanis", "authors": "Robert Chen, Brendan Lucier, Yaron Singer, Vasilis Syrgkanis", "title": "Robust Optimization for Non-Convex Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust optimization problems, where the goal is to optimize in\nthe worst case over a class of objective functions. We develop a reduction from\nrobust improper optimization to Bayesian optimization: given an oracle that\nreturns $\\alpha$-approximate solutions for distributions over objectives, we\ncompute a distribution over solutions that is $\\alpha$-approximate in the worst\ncase. We show that de-randomizing this solution is NP-hard in general, but can\nbe done for a broad class of statistical learning tasks. We apply our results\nto robust neural network training and submodular optimization. We evaluate our\napproach experimentally on corrupted character classification, and robust\ninfluence maximization in networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 15:56:42 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Chen", "Robert", ""], ["Lucier", "Brendan", ""], ["Singer", "Yaron", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1707.01182", "submitter": "Rolf Fagerberg", "authors": "Prosenjit Bose, Rolf Fagerberg, John Howat, Pat Morin", "title": "Biased Predecessor Search", "comments": "Also appeared at LATIN'14", "journal-ref": "Algorithmica 76(4): 1097-1105 (2016)", "doi": "10.1007/s00453-016-0146-7", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing predecessor searches in a bounded\nuniverse while achieving query times that depend on the distribution of\nqueries. We obtain several data structures with various properties: in\nparticular, we give data structures that achieve expected query times\nlogarithmic in the entropy of the distribution of queries but with space\nbounded in terms of universe size, as well as data structures that use only\nlinear space but with query times that are higher (but still sublinear)\nfunctions of the entropy. For these structures, the distribution is assumed to\nbe known. We also consider individual query times on universe elements with\ngeneral weights, as well as the case when the distribution is not known in\nadvance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 23:23:34 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Bose", "Prosenjit", ""], ["Fagerberg", "Rolf", ""], ["Howat", "John", ""], ["Morin", "Pat", ""]]}, {"id": "1707.01187", "submitter": "Maor Ganz", "authors": "Dorit Aharonov, Maor Ganz, Loick Magnin", "title": "Dining Philosophers, Leader Election and Ring Size problems, in the\n  quantum setting", "comments": "28 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first quantum (exact) protocol for the Dining Philosophers\nproblem (DP), a central problem in distributed algorithms. It is well known\nthat the problem cannot be solved exactly in the classical setting. We then use\nour DP protocol to provide a new quantum protocol for the tightly related\nproblem of exact leader election (LE) on a ring, improving significantly in\nboth time and memory complexity over the known LE protocol by Tani et. al. To\ndo this, we show that in some sense the exact DP and exact LE problems are\nequivalent; interestingly, in the classical non-exact setting they are not.\nHopefully, the results will lead to exact quantum protocols for other important\ndistributed algorithmic questions; in particular, we discuss interesting\nconnections to the ring size problem, as well as to a physically motivated\nquestion of breaking symmetry in 1D translationally invariant systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 23:57:46 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 18:06:56 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Aharonov", "Dorit", ""], ["Ganz", "Maor", ""], ["Magnin", "Loick", ""]]}, {"id": "1707.01242", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "Learning Geometric Concepts with Nasty Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the efficient learnability of geometric concept classes -\nspecifically, low-degree polynomial threshold functions (PTFs) and\nintersections of halfspaces - when a fraction of the data is adversarially\ncorrupted. We give the first polynomial-time PAC learning algorithms for these\nconcept classes with dimension-independent error guarantees in the presence of\nnasty noise under the Gaussian distribution. In the nasty noise model, an\nomniscient adversary can arbitrarily corrupt a small fraction of both the\nunlabeled data points and their labels. This model generalizes well-studied\nnoise models, including the malicious noise model and the agnostic (adversarial\nlabel noise) model. Prior to our work, the only concept class for which\nefficient malicious learning algorithms were known was the class of\norigin-centered halfspaces.\n  Specifically, our robust learning algorithm for low-degree PTFs succeeds\nunder a number of tame distributions -- including the Gaussian distribution\nand, more generally, any log-concave distribution with (approximately) known\nlow-degree moments. For LTFs under the Gaussian distribution, we give a\npolynomial-time algorithm that achieves error $O(\\epsilon)$, where $\\epsilon$\nis the noise rate. At the core of our PAC learning results is an efficient\nalgorithm to approximate the low-degree Chow-parameters of any bounded function\nin the presence of nasty noise. To achieve this, we employ an iterative\nspectral method for outlier detection and removal, inspired by recent work in\nrobust unsupervised learning. Our aforementioned algorithm succeeds for a range\nof distributions satisfying mild concentration bounds and moment assumptions.\nThe correctness of our robust learning algorithm for intersections of\nhalfspaces makes essential use of a novel robust inverse independence lemma\nthat may be of broader interest.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 07:41:40 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1707.01245", "submitter": "Lalla Mouatadid", "authors": "Michel Habib, Lalla Mouatadid", "title": "Maximum Induced Matching Algorithms via Vertex Ordering\n  Characterizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximum induced matching problem on a graph g. Induced matchings\ncorrespond to independent sets in L2(g), the square of the line graph of g. The\nproblem is NP-complete on bipartite graphs. In this work, we show that for a\nnumber of graph families with forbidden vertex orderings, almost all forbidden\npatterns on three vertices are preserved when taking the square of the line\ngraph. These orderings can be computed in linear time in the size of the input\ngraph. In particular, given a graph class G characterized by a vertex ordering,\nand a graph g = (V, E) in G with a corresponding vertex ordering \\sigma of V ,\none can produce (in linear time in the size of g) an ordering on the vertices\nof L2(g), that shows that L2(g) in G - for a number of graph classes G -\nwithout computing the line graph or the square of the line graph of g. These\nresults generalize and unify previous ones on showing closure under L2(.) for\nvarious graph families. Furthermore, these orderings on L2(g) can be exploited\nalgorithmically to compute a maximum induced matching on G faster. We\nillustrate this latter fact in the second half of the paper where we focus on\ncocomparability graphs, a large graph class that includes interval,\npermutation, trapezoid graphs, and co-graphs, and we present the first O(mn)\ntime algorithm to compute a maximum weighted induced matching on\ncocomparability graphs; an improvement from the best known O(n4) time algorithm\nfor the unweighted case.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 07:49:22 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 21:57:25 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Habib", "Michel", ""], ["Mouatadid", "Lalla", ""]]}, {"id": "1707.01470", "submitter": "Arkadiusz Socala", "authors": "Marthe Bonamy, {\\L}ukasz Kowalik, Jesper Nederlof, Micha{\\l}\n  Pilipczuk, Arkadiusz Soca{\\l}a, Marcin Wrochna", "title": "On Directed Feedback Vertex Set parameterized by treewidth", "comments": "20p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Directed Feedback Vertex Set problem parameterized by the\ntreewidth of the input graph. We prove that unless the Exponential Time\nHypothesis fails, the problem cannot be solved in time $2^{o(t\\log t)}\\cdot\nn^{\\mathcal{O}(1)}$ on general directed graphs, where $t$ is the treewidth of\nthe underlying undirected graph. This is matched by a dynamic programming\nalgorithm with running time $2^{\\mathcal{O}(t\\log t)}\\cdot n^{\\mathcal{O}(1)}$.\nOn the other hand, we show that if the input digraph is planar, then the\nrunning time can be improved to $2^{\\mathcal{O}(t)}\\cdot n^{\\mathcal{O}(1)}$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:07:50 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 19:48:39 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Bonamy", "Marthe", ""], ["Kowalik", "\u0141ukasz", ""], ["Nederlof", "Jesper", ""], ["Pilipczuk", "Micha\u0142", ""], ["Soca\u0142a", "Arkadiusz", ""], ["Wrochna", "Marcin", ""]]}, {"id": "1707.01487", "submitter": "Guru Guruganesh", "authors": "Guru Guruganesh, Jennifer Iglesias, R. Ravi, and Laura Sanit\\`a", "title": "Single-sink Fractionally Subadditive Network Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the Steiner tree problem, where we are given a\nweighted network $G$ together with a collection of $k$ subsets of its vertices\nand a root $r$. We wish to construct a minimum cost network such that the\nnetwork supports one unit of flow to the root from every node in a subset\nsimultaneously. The network constructed does not need to support flows from all\nthe subsets simultaneously.\n  We settle an open question regarding the complexity of this problem for\n$k=2$, and give a $\\frac{3}{2}$-approximation algorithm that improves over a\n(trivial) known 2-approximation. Furthermore, we prove some structural results\nthat prevent many well-known techniques from doing better than the known\n$O(\\log n)$-approximation. Despite these obstacles, we conjecture that this\nproblem should have an $O(1)$-approximation. We also give an approximation\nresult for a variant of the problem where the solution is required to be a\npath.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:36:38 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 01:57:51 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Guruganesh", "Guru", ""], ["Iglesias", "Jennifer", ""], ["Ravi", "R.", ""], ["Sanit\u00e0", "Laura", ""]]}, {"id": "1707.01728", "submitter": "Leah Epstein", "authors": "J\\'anos Balogh, J\\'ozsef B\\'ek\\'esi, Gy\\\"orgy D\\'osa, Leah Epstein,\n  Asaf Levin", "title": "A new and improved algorithm for online bin packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic online bin packing problem. In this problem, items of\npositive sizes no larger than 1 are presented one by one to be packed into\nsubsets called \"bins\" of total sizes no larger than 1, such that every item is\nassigned to a bin before the next item is presented. We use online partitioning\nof items into classes based on sizes, as in previous work, but we also apply a\nnew method where items of one class can be packed into more than two types of\nbins, where a bin type is defined according to the number of such items grouped\ntogether. Additionally, we allow the smallest class of items to be packed in\nmultiple kinds of bins, and not only into their own bins. We combine this with\nthe approach of packing of sufficiently big items according to their exact\nsizes. Finally, we simplify the analysis of such algorithms, allowing the\nanalysis to be based on the most standard weight functions. This simplified\nanalysis allows us to study the algorithm which we defined based on all these\nideas. This leads us to the design and analysis of the first algorithm of\nasymptotic competitive ratio strictly below 1.58, specifically, we break this\nbarrier and provide an algorithm AH (Advanced Harmonic) whose asymptotic\ncompetitive ratio does not exceed 1.5783.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 10:55:12 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Balogh", "J\u00e1nos", ""], ["B\u00e9k\u00e9si", "J\u00f3zsef", ""], ["D\u00f3sa", "Gy\u00f6rgy", ""], ["Epstein", "Leah", ""], ["Levin", "Asaf", ""]]}, {"id": "1707.01743", "submitter": "Gonzalo Navarro", "authors": "J. Ian Munro, Gonzalo Navarro, Yakov Nekrich", "title": "Fast Compressed Self-Indexes with Deterministic Linear-Time Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a compressed suffix array representation that, on a text $T$ of\nlength $n$ over an alphabet of size $\\sigma$, can be built in $O(n)$\ndeterministic time, within $O(n\\log\\sigma)$ bits of working space, and counts\nthe number of occurrences of any pattern $P$ in $T$ in time $O(|P| + \\log\\log_w\n\\sigma)$ on a RAM machine of $w=\\Omega(\\log n)$-bit words. This new index\noutperforms all the other compressed indexes that can be built in linear\ndeterministic time, and some others. The only faster indexes can be built in\nlinear time only in expectation, or require $\\Theta(n\\log n)$ bits. We also\nshow that, by using $O(n\\log\\sigma)$ bits, we can build in linear time an index\nthat counts in time $O(|P|/\\log_\\sigma n + \\log n(\\log\\log n)^2)$, which is\nRAM-optimal for $w=\\Theta(\\log n)$ and sufficiently long patterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 12:15:45 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 20:00:56 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 18:34:23 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Munro", "J. Ian", ""], ["Navarro", "Gonzalo", ""], ["Nekrich", "Yakov", ""]]}, {"id": "1707.01797", "submitter": "Marcin Wrochna", "authors": "Bart M. P. Jansen, Marcin Pilipczuk, Marcin Wrochna", "title": "Turing Kernelization for Finding Long Paths in Graph Classes Excluding a\n  Topological Minor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of Turing kernelization investigates whether a polynomial-time\nalgorithm can solve an NP-hard problem, when it is aided by an oracle that can\nbe queried for the answers to bounded-size subproblems. One of the main open\nproblems in this direction is whether k-Path admits a polynomial Turing kernel:\ncan a polynomial-time algorithm determine whether an undirected graph has a\nsimple path of length k, using an oracle that answers queries of size poly(k)?\n  We show this can be done when the input graph avoids a fixed graph H as a\ntopological minor, thereby significantly generalizing an earlier result for\nbounded-degree and $K_{3,t}$-minor-free graphs. Moreover, we show that k-Path\neven admits a polynomial Turing kernel when the input graph is not\nH-topological-minor-free itself, but contains a known vertex modulator of size\nbounded polynomially in the parameter, whose deletion makes it so. To obtain\nour results, we build on the graph minors decomposition to show that any\nH-topological-minor-free graph that does not contain a k-path, has a separation\nthat can safely be reduced after communication with the oracle.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 14:00:17 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Pilipczuk", "Marcin", ""], ["Wrochna", "Marcin", ""]]}, {"id": "1707.01898", "submitter": "Shiyu Ji", "authors": "Shiyu Ji, Kun Wan", "title": "Adaptive Modular Exponentiation Methods v.s. Python's Power Function", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use Python to implement two efficient modular exponentiation\nmethods: the adaptive m-ary method and the adaptive sliding-window method of\nwindow size k, where both m's are adaptively chosen based on the length of\nexponent. We also conduct the benchmark for both methods. Evaluation results\nshow that compared to the industry-standard efficient implementations of\nmodular power function in CPython and Pypy, our algorithms can reduce 1-5%\ncomputing time for exponents with more than 3072 bits.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 04:12:25 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Ji", "Shiyu", ""], ["Wan", "Kun", ""]]}, {"id": "1707.01899", "submitter": "Jingyuan Liu", "authors": "Jingyuan Liu", "title": "On Calculation of Bounds for Greedy Algorithms when Applied to Sensor\n  Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of studying the performance of greedy algorithm on\nsensor selection problem for stable linear systems with Kalman Filter.\nSpecifically, the objective is to find the system parameters that affects the\nperformance of greedy algorithms and conditions where greedy algorithm always\nproduces optimal solutions. In this paper, we developed an upper bound for\nperformance ratio of greedy algorithm, which is based on the work of Dr.Zhang\n\\cite{Sundaram} and offers valuable insight into the system parameters that\naffects the performance of greedy algorithm. We also proposes a set of\nconditions where greedy algorithm will always produce the optimal solution. We\nthen show in simulations how the system parameters mentioned by the performance\nratio bound derived in this work affects the performance of greedy algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 04:59:34 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Liu", "Jingyuan", ""]]}, {"id": "1707.02000", "submitter": "Kamesh Madduri", "authors": "Humayun Kabir, Kamesh Madduri", "title": "Shared-memory Graph Truss Decomposition", "comments": "10 pages, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PKT, a new shared-memory parallel algorithm and OpenMP\nimplementation for the truss decomposition of large sparse graphs. A k-truss is\na dense subgraph definition that can be considered a relaxation of a clique.\nTruss decomposition refers to a partitioning of all the edges in the graph\nbased on their k-truss membership. The truss decomposition of a graph has many\napplications. We show that our new approach PKT consistently outperforms other\ntruss decomposition approaches for a collection of large sparse graphs and on a\n24-core shared-memory server. PKT is based on a recently proposed algorithm for\nk-core decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 00:09:09 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Kabir", "Humayun", ""], ["Madduri", "Kamesh", ""]]}, {"id": "1707.02033", "submitter": "Xiaohui Bei", "authors": "Xiaohui Bei, Youming Qiao, Shengyu Zhang", "title": "Networked Fairness in Cake Cutting", "comments": "A preliminary version of this paper appears at IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graphical framework for fair division in cake cutting, where\ncomparisons between agents are limited by an underlying network structure. We\ngeneralize the classical fairness notions of envy-freeness and proportionality\nto this graphical setting. Given a simple undirected graph G, an allocation is\nenvy-free on G if no agent envies any of her neighbor's share, and is\nproportional on G if every agent values her own share no less than the average\namong her neighbors, with respect to her own measure. These generalizations\nopen new research directions in developing simple and efficient algorithms that\ncan produce fair allocations under specific graph structures.\n  On the algorithmic frontier, we first propose a moving-knife algorithm that\noutputs an envy-free allocation on trees. The algorithm is significantly\nsimpler than the discrete and bounded envy-free algorithm recently designed by\nAziz and Mackenzie for complete graphs. Next, we give a discrete and bounded\nalgorithm for computing a proportional allocation on descendant graphs, a class\nof graphs by taking a rooted tree and connecting all its ancestor-descendant\npairs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 04:31:33 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Bei", "Xiaohui", ""], ["Qiao", "Youming", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1707.02190", "submitter": "Marcin Pilipczuk", "authors": "D\\'aniel Marx and Marcin Pilipczuk and Micha{\\l} Pilipczuk", "title": "On subexponential parameterized algorithms for Steiner Tree and Directed\n  Subset TSP on planar graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are numerous examples of the so-called square root phenomenon in the\nfield of parameterized algorithms: many of the most fundamental graph problems,\nparameterized by some natural parameter $k$, become significantly simpler when\nrestricted to planar graphs and in particular the best possible running time is\nexponential in $O(\\sqrt{k})$ instead of $O(k)$ (modulo standard complexity\nassumptions). We consider two classic optimization problems parameterized by\nthe number of terminals. The Steiner Tree problem asks for a minimum-weight\ntree connecting a given set of terminals T in an edge-weighted graph. In the\nSubset Traveling Salesman problem we are asked to visit all the terminals $T$\nby a minimum-weight closed walk. We investigate the parameterized complexity of\nthese problems in planar graphs, where the number $k = |T|$ of terminals is\nregarded as the parameter. Our results are the following: (1) Subset TSP can be\nsolved in time $2^{O(\\sqrt{k} \\log k)} \\cdot n^{O(1)}$ even on edge-weighted\ndirected planar graphs. (2) Assuming the Exponential-Time Hypothesis, Steiner\nTree on undirected planar graphs cannot be solved in time $2^{o(k)} \\cdot\nn^{O(1)}$, even in the unit-weight setting. (3) Steiner Tree can be solved in\ntime $n^{O(\\sqrt{k})} \\cdot W$ on undirected planar graphs with maximum edge\nweight $W$. A direct corollary of the combination of our results for Steiner\nTree is that this problem does not admit a parameter-preserving polynomial\nkernel on planar graphs unless ETH fails.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 14:17:33 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1707.02211", "submitter": "Riccardo Fellegara", "authors": "Riccardo Fellegara and Kenneth Weiss and Leila De Floriani", "title": "The Stellar tree: a Compact Representation for Simplicial Complexes and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Stellar decomposition, a model for efficient topological\ndata structures over a broad range of simplicial and cell complexes. A Stellar\ndecomposition of a complex is a collection of regions indexing the complex's\nvertices and cells such that each region has sufficient information to locally\nreconstruct the star of its vertices, i.e., the cells incident in the region's\nvertices. Stellar decompositions are general in that they can compactly\nrepresent and efficiently traverse arbitrary complexes with a manifold or\nnon-manifold domain They are scalable to complexes in high dimension and of\nlarge size, and they enable users to easily construct tailored\napplication-dependent data structures using a fraction of the memory required\nby the corresponding topological data structure on the global complex.\n  As a concrete realization of this model for spatially embedded complexes, we\nintroduce the Stellar tree, which combines a nested spatial tree with a simple\ntuning parameter to control the number of vertices in a region. Stellar trees\nexploit the complex's spatial locality by reordering vertex and cell indices\naccording to the spatial decomposition and by compressing sequential ranges of\nindices. Stellar trees are competitive with state-of-the-art topological data\nstructures for manifold simplicial complexes and offer significant improvements\nfor cell complexes and non-manifold simplicial complexes. As a proxy for larger\napplications, we describe how Stellar trees can be used to generate existing\nstate-of-the-art topological data structures. In addition to faster generation\ntimes, the reduced memory requirements of a Stellar tree enable generating\nthese data structures over large and high-dimensional complexes even on\nmachines with limited resources.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:01:46 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 20:03:35 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Fellegara", "Riccardo", ""], ["Weiss", "Kenneth", ""], ["De Floriani", "Leila", ""]]}, {"id": "1707.02229", "submitter": "Michele Scquizzato", "authors": "Gianfranco Bilardi, Michele Scquizzato, Francesco Silvestri", "title": "A Lower Bound Technique for Communication in BSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a major factor determining the performance of algorithms on\ncurrent computing systems; it is therefore valuable to provide tight lower\nbounds on the communication complexity of computations. This paper presents a\nlower bound technique for the communication complexity in the bulk-synchronous\nparallel (BSP) model of a given class of DAG computations. The derived bound is\nexpressed in terms of the switching potential of a DAG, that is, the number of\npermutations that the DAG can realize when viewed as a switching network. The\nproposed technique yields tight lower bounds for the fast Fourier transform\n(FFT), and for any sorting and permutation network. A stronger bound is also\nderived for the periodic balanced sorting network, by applying this technique\nto suitable subnetworks. Finally, we demonstrate that the switching potential\ncaptures communication requirements even in computational models different from\nBSP, such as the I/O model and the LPRAM.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:31:16 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 16:27:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Bilardi", "Gianfranco", ""], ["Scquizzato", "Michele", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1707.02260", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis and Nisheeth K. Vishnoi", "title": "Fair Personalization", "comments": "To appear at FAT/ML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as, when combined with\nlearning, it leads to higher efficiency and revenue by allowing the most\nrelevant content to be served to each user. However, recent studies suggest\nthat such personalization can propagate societal or systemic biases, which has\nled to calls for regulatory mechanisms and algorithms to combat inequality.\nHere we propose a rigorous algorithmic framework that allows for the\npossibility to control biased or discriminatory personalization with respect to\nsensitive attributes of users without losing all of the benefits of\npersonalization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 16:40:06 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Celis", "L. Elisa", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1707.02362", "submitter": "Eduar Castrillo Velilla", "authors": "Eduar Castrillo, Elizabeth Le\\'on, Jonatan G\\'omez", "title": "Fast Heuristic Algorithm for Multi-scale Hierarchical Community\n  Detection", "comments": "8 Pages, 9 figures, 3 tables, Full-paper accepted, international\n  symposium FAB 2017 (co-located event to ASONAM 2017)", "journal-ref": null, "doi": "10.1145/3110025.3110125", "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks constitute the backbones of many complex systems such as\nsocial networks. Detecting the community structure in a complex network is both\na challenging and a computationally expensive task. In this paper, we present\nthe HAMUHI-CODE, a novel fast heuristic algorithm for multi-scale hierarchical\ncommunity detection inspired on an agglomerative hierarchical clustering\ntechnique. We define a new structural similarity of vertices based on the\nclassical cosine similarity by removing some vertices in order to increase the\nprobability of identifying inter-cluster edges. Then we use the proposed\nstructural similarity in a new agglomerative hierarchical algorithm that does\nnot merge only clusters with maximal similarity as in the classical approach,\nbut merges any cluster that does not meet a parameterized community definition\nwith its most similar adjacent cluster. The algorithm computes all the similar\nclusters at the same time is checking if each cluster meets the parameterized\ncommunity definition. It is done in linear time complexity in terms of the\nnumber of cluster in the iteration. Since a complex network is a sparse graph,\nour approach HAMUHI-CODE has a super-linear time complexity with respect to the\nsize of the input in the worst-case scenario (if the clusters merge in pairs),\nmaking it suitable to be applied on large-scale complex networks. To test the\nproperties and the efficiency of our algorithm we have conducted extensive\nexperiments on real world and synthetic benchmark networks by comparing it to\nseveral baseline state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 21:19:01 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Castrillo", "Eduar", ""], ["Le\u00f3n", "Elizabeth", ""], ["G\u00f3mez", "Jonatan", ""]]}, {"id": "1707.02414", "submitter": "Itay Laish", "authors": "Itay Laish and Shay Mozes", "title": "Efficient Dynamic Approximate Distance Oracles for Vertex-Labeled Planar\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a graph where each vertex is associated with a label. A\nVertex-Labeled Approximate Distance Oracle is a data structure that, given a\nvertex $v$ and a label $\\lambda$, returns a $(1+\\varepsilon)$-approximation of\nthe distance from $v$ to the closest vertex with label $\\lambda$ in $G$. Such\nan oracle is dynamic if it also supports label changes. In this paper we\npresent three different dynamic approximate vertex-labeled distance oracles for\nplanar graphs, all with polylogarithmic query and update times, and nearly\nlinear space requirements.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 08:22:23 GMT"}, {"version": "v2", "created": "Sun, 27 Aug 2017 18:46:52 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Laish", "Itay", ""], ["Mozes", "Shay", ""]]}, {"id": "1707.02577", "submitter": "Dariusz Leniowski", "authors": "Monika Henzinger, Dariusz Leniowski, Claire Mathieu", "title": "Dynamic clustering to minimize the sum of radii", "comments": "10 pages, ESA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of opening centers to cluster a set of\nclients in a metric space so as to minimize the sum of the costs of the centers\nand of the cluster radii, in a dynamic environment where clients arrive and\ndepart, and the solution must be updated efficiently while remaining\ncompetitive with respect to the current optimal solution. We call this dynamic\nsum-of-radii clustering problem.\n  We present a data structure that maintains a solution whose cost is within a\nconstant factor of the cost of an optimal solution in metric spaces with\nbounded doubling dimension and whose worst-case update time is logarithmic in\nthe parameters of the problem.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 13:16:15 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Henzinger", "Monika", ""], ["Leniowski", "Dariusz", ""], ["Mathieu", "Claire", ""]]}, {"id": "1707.02650", "submitter": "Qingyu Liu", "authors": "Qingyu Liu, Lei Deng, Haibo Zeng, Minghua Chen", "title": "On the Min-Max-Delay Problem: NP-completeness, Algorithm, and\n  Integrality Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study a delay-sensitive information flow problem where a source streams\ninformation to a sink over a directed graph G(V,E) at a fixed rate R possibly\nusing multiple paths to minimize the maximum end-to-end delay, denoted as the\nMin-Max-Delay problem. Transmission over an edge incurs a constant delay within\nthe capacity. We prove that Min-Max-Delay is weakly NP-complete, and\ndemonstrate that it becomes strongly NP-complete if we require integer flow\nsolution. We propose an optimal pseudo-polynomial time algorithm for\nMin-Max-Delay, with time complexity O(\\log (Nd_{\\max}) (N^5d_{\\max}^{2.5})(\\log\nR+N^2d_{\\max}\\log(N^2d_{\\max}))), where N = \\max\\{|V|,|E|\\} and d_{\\max} is the\nmaximum edge delay. Besides, we show that the integrality gap, which is defined\nas the ratio of the maximum delay of an optimal integer flow to the maximum\ndelay of an optimal fractional flow, could be arbitrarily large.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 22:34:44 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 14:32:42 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 22:01:59 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 21:42:27 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Liu", "Qingyu", ""], ["Deng", "Lei", ""], ["Zeng", "Haibo", ""], ["Chen", "Minghua", ""]]}, {"id": "1707.02670", "submitter": "Peng Xu", "authors": "Christopher De Sa, Bryan He, Ioannis Mitliagkas, Christopher R\\'e,\n  Peng Xu", "title": "Accelerated Stochastic Power Iteration", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is one of the most powerful tools in\nmachine learning. The simplest method for PCA, the power iteration, requires\n$\\mathcal O(1/\\Delta)$ full-data passes to recover the principal component of a\nmatrix with eigen-gap $\\Delta$. Lanczos, a significantly more complex method,\nachieves an accelerated rate of $\\mathcal O(1/\\sqrt{\\Delta})$ passes. Modern\napplications, however, motivate methods that only ingest a subset of available\ndata, known as the stochastic setting. In the online stochastic setting, simple\nalgorithms like Oja's iteration achieve the optimal sample complexity $\\mathcal\nO(\\sigma^2/\\Delta^2)$. Unfortunately, they are fully sequential, and also\nrequire $\\mathcal O(\\sigma^2/\\Delta^2)$ iterations, far from the $\\mathcal\nO(1/\\sqrt{\\Delta})$ rate of Lanczos. We propose a simple variant of the power\niteration with an added momentum term, that achieves both the optimal sample\nand iteration complexity. In the full-pass setting, standard analysis shows\nthat momentum achieves the accelerated rate, $\\mathcal O(1/\\sqrt{\\Delta})$. We\ndemonstrate empirically that naively applying momentum to a stochastic method,\ndoes not result in acceleration. We perform a novel, tight variance analysis\nthat reveals the \"breaking-point variance\" beyond which this acceleration does\nnot occur. By combining this insight with modern variance reduction techniques,\nwe construct stochastic PCA algorithms, for the online and offline setting,\nthat achieve an accelerated iteration complexity $\\mathcal O(1/\\sqrt{\\Delta})$.\nDue to the embarassingly parallel nature of our methods, this acceleration\ntranslates directly to wall-clock time if deployed in a parallel environment.\nOur approach is very general, and applies to many non-convex optimization\nproblems that can now be accelerated using the same technique.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 01:13:33 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["De Sa", "Christopher", ""], ["He", "Bryan", ""], ["Mitliagkas", "Ioannis", ""], ["R\u00e9", "Christopher", ""], ["Xu", "Peng", ""]]}, {"id": "1707.02740", "submitter": "Kazuhiro Kurita", "authors": "Kazuhiro Kurita, Kunihiro Wasa, Takeaki Uno, and Hiroki Arimura", "title": "Efficient Enumeration of Induced Matchings in a Graph without Cycles\n  with Length Four", "comments": null, "journal-ref": null, "doi": "10.1587/transfun.E101.A.1383", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the induced matching enumeration problem. An edge set $M$ is an\ninduced matching of a graph $G =(V,E)$. The enumeration of matchings are widely\nstudied in literature, but the induced matching has not been paid much\nattention. A straightforward algorithm takes $O(|V|)$ time for each solution,\nthat is coming from the time to generate a subproblem. We investigated local\nstructures that enables us to generate subproblems in short time, and proved\nthat the time complexity will be $O(1)$ if the input graph is $C_4$-free. A\n$C_4$-free graph is a graph any whose subgraph is not a cycle of length four.\nFinally, we show the fixed parameter tractability of counting induced matchings\nfor graphs with bounded tree-width and planar graphs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 08:27:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Kurita", "Kazuhiro", ""], ["Wasa", "Kunihiro", ""], ["Uno", "Takeaki", ""], ["Arimura", "Hiroki", ""]]}, {"id": "1707.02753", "submitter": "Melanie Schmidt", "authors": "Martin Gro{\\ss} and Anupam Gupta and Amit Kumar and Jannik Matuschke\n  and Daniel R. Schmidt and Melanie Schmidt and Jos\\'e Verschae", "title": "A Local-Search Algorithm for Steiner Forest", "comments": "46 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Steiner Forest problem, we are given a graph and a collection of\nsource-sink pairs, and the goal is to find a subgraph of minimum total length\nsuch that all pairs are connected. The problem is APX-Hard and can be\n2-approximated by, e.g., the elegant primal-dual algorithm of Agrawal, Klein,\nand Ravi from 1995.\n  We give a local-search-based constant-factor approximation for the problem.\nLocal search brings in new techniques to an area that has for long not seen any\nimprovements and might be a step towards a combinatorial algorithm for the more\ngeneral survivable network design problem. Moreover, local search was an\nessential tool to tackle the dynamic MST/Steiner Tree problem, whereas dynamic\nSteiner Forest is still wide open.\n  It is easy to see that any constant factor local search algorithm requires\nsteps that add/drop many edges together. We propose natural local moves which,\nat each step, either (a) add a shortest path in the current graph and then drop\na bunch of inessential edges, or (b) add a set of edges to the current\nsolution. This second type of moves is motivated by the potential function we\nuse to measure progress, combining the cost of the solution with a penalty for\neach connected component. Our carefully-chosen local moves and potential\nfunction work in tandem to eliminate bad local minima that arise when using\nmore traditional local moves.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 08:54:22 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Gro\u00df", "Martin", ""], ["Gupta", "Anupam", ""], ["Kumar", "Amit", ""], ["Matuschke", "Jannik", ""], ["Schmidt", "Daniel R.", ""], ["Schmidt", "Melanie", ""], ["Verschae", "Jos\u00e9", ""]]}, {"id": "1707.02757", "submitter": "Damian Straszak", "authors": "Javad B. Ebrahimi and Damian Straszak and Nisheeth K. Vishnoi", "title": "Subdeterminant Maximization via Nonconvex Relaxations and\n  Anti-concentration", "comments": "in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several fundamental problems that arise in optimization and computer science\ncan be cast as follows: Given vectors $v_1,\\ldots,v_m \\in \\mathbb{R}^d$ and a\nconstraint family ${\\cal B}\\subseteq 2^{[m]}$, find a set $S \\in \\cal{B}$ that\nmaximizes the squared volume of the simplex spanned by the vectors in $S$. A\nmotivating example is the data-summarization problem in machine learning where\none is given a collection of vectors that represent data such as documents or\nimages. The volume of a set of vectors is used as a measure of their diversity,\nand partition or matroid constraints over $[m]$ are imposed in order to ensure\nresource or fairness constraints. Recently, Nikolov and Singh presented a\nconvex program and showed how it can be used to estimate the value of the most\ndiverse set when ${\\cal B}$ corresponds to a partition matroid. This result was\nrecently extended to regular matroids in works of Straszak and Vishnoi, and\nAnari and Oveis Gharan. The question of whether these estimation algorithms can\nbe converted into the more useful approximation algorithms -- that also output\na set -- remained open.\n  The main contribution of this paper is to give the first approximation\nalgorithms for both partition and regular matroids. We present novel\nformulations for the subdeterminant maximization problem for these matroids;\nthis reduces them to the problem of finding a point that maximizes the absolute\nvalue of a nonconvex function over a Cartesian product of probability\nsimplices. The technical core of our results is a new anti-concentration\ninequality for dependent random variables that allows us to relate the optimal\nvalue of these nonconvex functions to their value at a random point. Unlike\nprior work on the constrained subdeterminant maximization problem, our proofs\ndo not rely on real-stability or convexity and could be of independent interest\nboth in algorithms and complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 09:04:51 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 12:13:21 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ebrahimi", "Javad B.", ""], ["Straszak", "Damian", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1707.02759", "submitter": "Guillermo de Bernardo", "authors": "Sandra Alvarez-Garcia, Guillermo de Bernardo, Nieves R. Brisaboa,\n  Gonzalo Navarro", "title": "A succinct data structure for self-indexing ternary relations", "comments": "This research has received funding from the European Union's Horizon\n  2020 research and innovation programme under the Marie Sk{\\l}odowska-Curie\n  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941, Journal of Discrete\n  Algorithms (2017)", "journal-ref": null, "doi": "10.1016/j.jda.2016.10.002", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of binary relations has been intensively studied and many\ndifferent theoretical and practical representations have been proposed to\nanswer the usual queries in multiple domains. However, ternary relations have\nnot received as much attention, even though many real-world applications\nrequire the processing of ternary relations. In this paper we present a new\ncompressed and self-indexed data structure that we call Interleaved $K^2$-tree\n(I$K^2$-tree), designed to compactly represent and efficiently query general\nternary relations. The I$K^2$-tree is an evolution of an existing data\nstructure, the $K^2$-tree, initially designed to represent Web graphs and later\napplied to other domains. The I$K^2$-tree is able to extend the $K^2$-tree to\nrepresent a ternary relation, based on the idea of decomposing it into a\ncollection of binary relations but providing indexing capabilities in all the\nthree dimensions. We present different ways to use I$K^2$-tree to model\ndifferent types of ternary relations using as reference two typical domains:\nRDF and Temporal Graphs. We also experimentally evaluate our representations\ncomparing them in space usage and performance with other solutions of the state\nof the art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 09:06:19 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Alvarez-Garcia", "Sandra", ""], ["de Bernardo", "Guillermo", ""], ["Brisaboa", "Nieves R.", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1707.02769", "submitter": "Guillermo de Bernardo", "authors": "Nieves R. Brisaboa, Ana Cerdeira-Pena, Guillermo de Bernardo, Gonzalo\n  Navarro", "title": "Compressed Representation of Dynamic Binary Relations with Applications", "comments": "This research has received funding from the European Union's Horizon\n  2020 research and innovation programme under the Marie Sk{\\l}odowska-Curie\n  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941, Information Systems (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dynamic data structure for the compact representation of\nbinary relations $\\mathcal{R} \\subseteq A \\times B$. The data structure is a\ndynamic variant of the k$^2$-tree, a static compact representation that takes\nadvantage of clustering in the binary relation to achieve compression. Our\nstructure can efficiently check whether two objects $(a,b) \\in A \\times B$ are\nrelated, and list the objects of $B$ related to some $a \\in A$ and vice versa.\nAdditionally, our structure allows inserting and deleting pairs $(a,b)$ in the\nrelation, as well as modifying the base sets $A$ and $B$. We test our dynamic\ndata structure in different contexts, including the representation of Web\ngraphs and RDF databases. Our experiments show that our dynamic data structure\nachieves good compression ratios and fast query times, close to those of a\nstatic representation, while also providing efficient support for updates in\nthe represented binary relation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 09:26:15 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Brisaboa", "Nieves R.", ""], ["Cerdeira-Pena", "Ana", ""], ["de Bernardo", "Guillermo", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1707.03303", "submitter": "Felix Joos", "authors": "Felix Joos, Jaehoon Kim, Daniela K\\\"uhn and Deryk Osthus", "title": "A characterization of testable hypergraph properties", "comments": "82 pages; extended abstract of this paper appears in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a combinatorial characterization of all testable properties of\n$k$-graphs (i.e. $k$-uniform hypergraphs). Here, a $k$-graph property\n$\\mathbf{P}$ is testable if there is a randomized algorithm which makes a\nbounded number of edge queries and distinguishes with probability $2/3$ between\n$k$-graphs that satisfy $\\mathbf{P}$ and those that are far from satisfying\n$\\mathbf{P}$. For the $2$-graph case, such a combinatorial characterization was\nobtained by Alon, Fischer, Newman and Shapira. Our results for the $k$-graph\nsetting are in contrast to those of Austin and Tao, who showed that for the\nsomewhat stronger concept of local repairability, the testability results for\ngraphs do not extend to the $3$-graph setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 14:35:22 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Joos", "Felix", ""], ["Kim", "Jaehoon", ""], ["K\u00fchn", "Daniela", ""], ["Osthus", "Deryk", ""]]}, {"id": "1707.03387", "submitter": "Marta Cavaleiro", "authors": "Marta Cavaleiro and Farid Alizadeh", "title": "A branch-and-bound algorithm for the minimum radius $k$-enclosing ball\n  problem", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum $k$-enclosing ball problem seeks the ball with smallest radius\nthat contains at least~$k$ of~$m$ given points in a general $n$-dimensional\nEuclidean space. This problem is NP-hard. We present a branch-and-bound\nalgorithm on the tree of the subsets of~$k$ points to solve this problem. The\nnodes on the tree are ordered in a suitable way, which, complemented with a\nlast-in-first-out search strategy, allows for only a small fraction of nodes to\nbe explored. Additionally, an efficient dual algorithm to solve the subproblems\nat each node is employed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 17:51:23 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Cavaleiro", "Marta", ""], ["Alizadeh", "Farid", ""]]}, {"id": "1707.03478", "submitter": "Slobodan Mitrovi\\'c", "authors": "Artur Czumaj, Jakub {\\L}\\k{a}cki, Aleksander M\\k{a}dry, Slobodan\n  Mitrovi\\'c, Krzysztof Onak, Piotr Sankowski", "title": "Round Compression for Parallel Matching Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade now we have been witnessing the success of {\\em massive\nparallel computation} (MPC) frameworks, such as MapReduce, Hadoop, Dryad, or\nSpark. One of the reasons for their success is the fact that these frameworks\nare able to accurately capture the nature of large-scale computation. In\nparticular, compared to the classic distributed algorithms or PRAM models,\nthese frameworks allow for much more local computation. The fundamental\nquestion that arises in this context is though: can we leverage this additional\npower to obtain even faster parallel algorithms?\n  A prominent example here is the {\\em maximum matching} problem---one of the\nmost classic graph problems. It is well known that in the PRAM model one can\ncompute a 2-approximate maximum matching in $O(\\log{n})$ rounds. However, the\nexact complexity of this problem in the MPC framework is still far from\nunderstood. Lattanzi et al. showed that if each machine has $n^{1+\\Omega(1)}$\nmemory, this problem can also be solved $2$-approximately in a constant number\nof rounds. These techniques, as well as the approaches developed in the follow\nup work, seem though to get stuck in a fundamental way at roughly $O(\\log{n})$\nrounds once we enter the near-linear memory regime. It is thus entirely\npossible that in this regime, which captures in particular the case of sparse\ngraph computations, the best MPC round complexity matches what one can already\nget in the PRAM model, without the need to take advantage of the extra local\ncomputation power.\n  In this paper, we finally refute that perplexing possibility. That is, we\nbreak the above $O(\\log n)$ round complexity bound even in the case of {\\em\nslightly sublinear} memory per machine. In fact, our improvement here is {\\em\nalmost exponential}: we are able to deliver a $(2+\\epsilon)$-approximation to\nmaximum matching, for any fixed constant $\\epsilon>0$, in $O((\\log \\log n)^2)$\nrounds.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 22:10:43 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 18:13:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Czumaj", "Artur", ""], ["\u0141\u0105cki", "Jakub", ""], ["M\u0105dry", "Aleksander", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Onak", "Krzysztof", ""], ["Sankowski", "Piotr", ""]]}, {"id": "1707.03584", "submitter": "Benjamin Bergougnoux", "authors": "Benjamin Bergougnoux and Mamadou Moustapha Kant\\'e", "title": "Fast exact algorithms for some connectivity problems parametrized by\n  clique-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a clique-width $k$-expression of a graph $G$, we provide $2^{O(k)}\\cdot\nn$ time algorithms for connectivity constraints on locally checkable properties\nsuch as Node-Weighted Steiner Tree, Connected Dominating Set, or Connected\nVertex Cover. We also propose a $2^{O(k)}\\cdot n$ time algorithm for Feedback\nVertex Set. The best running times for all the considered cases were either\n$2^{O(k\\cdot \\log(k))}\\cdot n^{O(1)}$ or worse.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 07:59:47 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:07:47 GMT"}, {"version": "v3", "created": "Sat, 18 Aug 2018 08:50:34 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Bergougnoux", "Benjamin", ""], ["Kant\u00e9", "Mamadou Moustapha", ""]]}, {"id": "1707.03648", "submitter": "Steven Kelk", "authors": "Steven Kelk, Fabio Pardi, Celine Scornavacca, Leo van Iersel", "title": "Finding the most parsimonious or likely tree in a network with respect\n  to an alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic networks are often constructed by merging multiple conflicting\nphylogenetic signals into a directed acyclic graph. It is interesting to\nexplore whether a network constructed in this way induces biologically-relevant\nphylogenetic signals that were not present in the input. Here we show that,\ngiven a multiple alignment A for a set of taxa X and a rooted phylogenetic\nnetwork N whose leaves are labelled by X, it is NP-hard to locate the most\nparsimonious phylogenetic tree displayed by N (with respect to A) even when the\nlevel of N - the maximum number of reticulation nodes within a biconnected\ncomponent - is 1 and A contains only 2 distinct states. (If, additionally, gaps\nare allowed the problem becomes APX-hard.) We also show that under the same\nconditions, and assuming a simple binary symmetric model of character\nevolution, finding the most likely tree displayed by the network is NP-hard.\nThese negative results contrast with earlier work on parsimony in which it is\nshown that if A consists of a single column the problem is fixed parameter\ntractable in the level. We conclude with a discussion of why, despite the\nNP-hardness, both the parsimony and likelihood problem can likely be\nwell-solved in practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 11:23:41 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Kelk", "Steven", ""], ["Pardi", "Fabio", ""], ["Scornavacca", "Celine", ""], ["van Iersel", "Leo", ""]]}, {"id": "1707.03914", "submitter": "Khaled Elbassioni", "authors": "Khaled Elbassioni and Kazuhisa Makino", "title": "Enumerating Vertices of $0/1$-Polyhedra associated with $0/1$-Totally\n  Unimodular Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an incremental polynomial time algorithm for enumerating the vertices\nof any polyhedron $\\mathcal{P}(A,\\mathbf{1})=\\{x\\in\\RR^n \\mid Ax\\geq \\b1,~x\\geq\n\\b0\\}$, when $A$ is a totally unimodular matrix. Our algorithm is based on\ndecomposing the hypergraph transversal problem for unimodular hypergraphs using\nSeymour's decomposition of totally unimodular matrices, and may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 21:13:08 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Elbassioni", "Khaled", ""], ["Makino", "Kazuhisa", ""]]}, {"id": "1707.03992", "submitter": "Vera Traub", "authors": "Vera Traub, Jens Vygen", "title": "Approaching $\\frac{3}{2}$ for the $s$-$t$-path TSP", "comments": "Final version for Journal of the ACM", "journal-ref": "Journal of the ACM 66 (2019), Article 14", "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is a polynomial-time algorithm with approximation\nguarantee $\\frac{3}{2}+\\epsilon$ for the $s$-$t$-path TSP, for any fixed\n$\\epsilon>0$. It is well known that Wolsey's analysis of Christofides'\nalgorithm also works for the $s$-$t$-path TSP with its natural LP relaxation\nexcept for the narrow cuts (in which the LP solution has value less than two).\nA fixed optimum tour has either a single edge in a narrow cut (then call the\nedge and the cut lonely) or at least three (then call the cut busy). Our\nalgorithm \"guesses\" (by dynamic programming) lonely cuts and edges. Then we\npartition the instance into smaller instances and strengthen the LP, requiring\nvalue at least three for busy cuts. By setting up a $k$-stage recursive dynamic\nprogram, we can compute a spanning tree $(V,S)$ and an LP solution $y$ such\nthat $(\\frac{1}{2}+O(2^{-k}))y$ is in the $T$-join polyhedron, where $T$ is the\nset of vertices whose degree in $S$ has the wrong parity.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 07:01:48 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 17:45:42 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 12:35:38 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 12:59:50 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Traub", "Vera", ""], ["Vygen", "Jens", ""]]}, {"id": "1707.04020", "submitter": "Yutaro Yamaguchi", "authors": "Takanori Maehara and Yutaro Yamaguchi", "title": "Stochastic Packing Integer Programs with Few Queries", "comments": "The final draft of a paper published in Mathematical Programming\n  (Series A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic variant of the packing-type integer linear\nprogramming problem, which contains random variables in the objective vector.\nWe are allowed to reveal each entry of the objective vector by conducting a\nquery, and the task is to find a good solution by conducting a small number of\nqueries. We propose a general framework of adaptive and non-adaptive algorithms\nfor this problem, and provide a unified methodology for analyzing the\nperformance of those algorithms. We also demonstrate our framework by applying\nit to a variety of stochastic combinatorial optimization problems such as\nmatching, matroid, and stable set problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 08:13:46 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 15:29:33 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 10:45:10 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Maehara", "Takanori", ""], ["Yamaguchi", "Yutaro", ""]]}, {"id": "1707.04220", "submitter": "Marin Bougeret", "authors": "St\\'ephane Bessy, Marin Bougeret, Jocelyn Thiebaut", "title": "Triangle packing in (sparse) tournaments: approximation and\n  kernelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a tournament T and a positive integer k, the C_3-Pakcing-T problem asks\nif there exists a least k (vertex-)disjoint directed 3-cycles in T. This is the\ndual problem in tournaments of the classical minimal feedback vertex set\nproblem. Surprisingly C_3-Pakcing-T did not receive a lot of attention in the\nliterature. We show that it does not admit a PTAS unless P=NP, even if we\nrestrict the considered instances to sparse tournaments, that is tournaments\nwith a feedback arc set (FAS) being a matching. Focusing on sparse tournaments\nwe provide a (1+6/(c-1)) approximation algorithm for sparse tournaments having\na linear representation where all the backward arcs have \"length\" at least c.\nConcerning kernelization, we show that C_3-Pakcing-T admits a kernel with O(m)\nvertices, where m is the size of a given feedback arc set. In particular, we\nderive a O(k) vertices kernel for C_3-Pakcing-T when restricted to sparse\ninstances. On the negative size, we show that C_3-Pakcing-T does not admit a\nkernel of (total bit) size O(k^{2-\\epsilon}) unless NP is a subset of coNP /\nPoly. The existence of a kernel in O(k) vertices for C_3-Pakcing-T remains an\nopen question.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 16:49:03 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Bessy", "St\u00e9phane", ""], ["Bougeret", "Marin", ""], ["Thiebaut", "Jocelyn", ""]]}, {"id": "1707.04233", "submitter": "Amirbehshad Shahrasbi", "authors": "Bernhard Haeupler, Amirbehshad Shahrasbi, Ellen Vitercik", "title": "Synchronization Strings: Channel Simulations and Interactive Coding for\n  Insertions and Deletions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present many new results related to reliable (interactive) communication\nover insertion-deletion channels. Synchronization errors, such as insertions\nand deletions, strictly generalize the usual symbol corruption errors and are\nmuch harder to protect against.\n  We show how to hide the complications of synchronization errors in many\napplications by introducing very general channel simulations which efficiently\ntransform an insertion-deletion channel into a regular symbol corruption\nchannel with an error rate larger by a constant factor and a slightly smaller\nalphabet. We generalize synchronization string based methods which were\nrecently introduced as a tool to design essentially optimal error correcting\ncodes for insertion-deletion channels. Our channel simulations depend on the\nfact that, at the cost of increasing the error rate by a constant factor,\nsynchronization strings can be decoded in a streaming manner that preserves\nlinearity of time. We also provide a lower bound showing that this constant\nfactor cannot be improved to $1+\\epsilon$, in contrast to what is achievable\nfor error correcting codes. Our channel simulations drastically generalize the\napplicability of synchronization strings.\n  We provide new interactive coding schemes which simulate any interactive\ntwo-party protocol over an insertion-deletion channel. Our results improve over\nthe interactive coding schemes of Braverman et al. [TransInf 2017] and Sherstov\nand Wu [FOCS 2017], which achieve a small constant rate and require exponential\ntime computations, with respect to computational and communication\ncomplexities. We provide the first computationally efficient interactive coding\nschemes for synchronization errors, the first coding scheme with a rate\napproaching one for small noise rates, and also the first coding scheme that\nworks over arbitrarily small alphabet sizes.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 17:31:06 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 23:48:34 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Shahrasbi", "Amirbehshad", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1707.04282", "submitter": "Miguel Mosteiro", "authors": "Dariusz R. Kowalski and Miguel A. Mosteiro", "title": "Polynomial Counting in Anonymous Dynamic Networks with Applications to\n  Anonymous Dynamic Algebraic Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with Michail, Chatzigiannakis, and Spirakis work, the problem of\nCounting the number of nodes in Anonymous Dynamic Networks has attracted a lot\nof attention. The problem is challenging because nodes are indistinguishable\n(they lack identifiers and execute the same program) and the topology may\nchange arbitrarily from round to round of communication, as long as the network\nis connected in each round. The problem is central in distributed computing as\nthe number of participants is frequently needed to make important decisions,\nsuch as termination, agreement, synchronization, and many others. A variety of\nalgorithms built on top of mass-distribution techniques have been presented,\nanalyzed, and also experimentally evaluated; some of them assumed additional\nknowledge of network characteristics, such as bounded degree or given upper\nbound on the network size. However, the question of whether Counting can be\nsolved deterministically in sub-exponential time remained open. In this work,\nwe answer this question positively by presenting Methodical Counting, which\nruns in polynomial time and requires no knowledge of network characteristics.\nMoreover, we also show how to extend Methodical Counting to compute the sum of\ninput values and more complex functions without extra cost. Our analysis\nleverages previous work on random walks in evolving graphs, combined with\ncarefully chosen alarms in the algorithm that control the process and its\nparameters. To the best of our knowledge, our Counting algorithm and its\nextensions to other algebraic and Boolean functions are the first that can be\nimplemented in practice with worst-case guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 18:54:49 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1707.04295", "submitter": "Mohammad Salavatipour", "authors": "Zachary Friggstad, Kamyar Khodamoradi, Mohsen Rezapour, Mohammad R.\n  Salavatipour", "title": "Approximation Schemes for Clustering with Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering problems are well-studied in a variety of fields such as data\nscience, operations research, and computer science. Such problems include\nvariants of centre location problems, $k$-median, and $k$-means to name a few.\nIn some cases, not all data points need to be clustered; some may be discarded\nfor various reasons.\n  We study clustering problems with outliers. More specifically, we look at\nUncapacitated Facility Location (UFL), $k$-Median, and $k$-Means. In UFL with\noutliers, we have to open some centres, discard up to $z$ points of $\\cal X$\nand assign every other point to the nearest open centre, minimizing the total\nassignment cost plus centre opening costs. In $k$-Median and $k$-Means, we have\nto open up to $k$ centres but there are no opening costs. In $k$-Means, the\ncost of assigning $j$ to $i$ is $\\delta^2(j,i)$. We present several results.\nOur main focus is on cases where $\\delta$ is a doubling metric or is the\nshortest path metrics of graphs from a minor-closed family of graphs. For\nuniform-cost UFL with outliers on such metrics we show that a multiswap simple\nlocal search heuristic yields a PTAS. With a bit more work, we extend this to\nbicriteria approximations for the $k$-Median and $k$-Means problems in the same\nmetrics where, for any constant $\\epsilon > 0$, we can find a solution using\n$(1+\\epsilon)k$ centres whose cost is at most a $(1+\\epsilon)$-factor of the\noptimum and uses at most $z$ outliers. We also show that natural local search\nheuristics that do not violate the number of clusters and outliers for\n$k$-Median (or $k$-Means) will have unbounded gap even in Euclidean metrics.\nFurthermore, we show how our analysis can be extended to general metrics for\n$k$-Means with outliers to obtain a $(25+\\epsilon,1+\\epsilon)$ bicriteria.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:08:24 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Friggstad", "Zachary", ""], ["Khodamoradi", "Kamyar", ""], ["Rezapour", "Mohsen", ""], ["Salavatipour", "Mohammad R.", ""]]}, {"id": "1707.04310", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Charles Paperman", "title": "Topological Sorting under Regular Constraints", "comments": "45 pages, 31 references in the main text. This is the full version\n  with proofs of the ICALP'18 paper, and is the same as the ICALP proceedings\n  version up to minor publisher-dependent changes. Several important changes\n  with respect to version 1, including fixing some errors. Title changed with\n  respect to version 2", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2018.115", "report-no": null, "categories": "cs.DS cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the constrained topological sorting problem (CTS): given a\nregular language K and a directed acyclic graph G with labeled vertices,\ndetermine if G has a topological sort that forms a word in K. This natural\nproblem applies to several settings, e.g., scheduling with costs or verifying\nconcurrent programs. We consider the problem CTS[K] where the target language K\nis fixed, and study its complexity depending on K. We show that CTS[K] is\ntractable when K falls in several language families, e.g., unions of monomials,\nwhich can be used for pattern matching. However, we show that CTS[K] is NP-hard\nfor K = (ab)^* and introduce a shuffle reduction technique to show hardness for\nmore languages. We also study the special case of the constrained shuffle\nproblem (CSh), where the input graph is a disjoint union of strings, and show\nthat CSh[K] is additionally tractable when K is a group language or a union of\ndistrict group monomials. We conjecture that a dichotomy should hold on the\ncomplexity of CTS[K] or CSh[K] depending on K, and substantiate this by proving\na coarser dichotomy under a different problem phrasing which ensures that\ntractable languages are closed under common operators.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:35:48 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 10:40:29 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 18:57:06 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Amarilli", "Antoine", ""], ["Paperman", "Charles", ""]]}, {"id": "1707.04312", "submitter": "Guillaume Lagarde", "authors": "Guillaume Lagarde, Sylvain Perifel", "title": "Lempel-Ziv: a \"one-bit catastrophe\" but not a tragedy", "comments": "42 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The so-called \"one-bit catastrophe\" for the compression algorithm LZ'78 asks\nwhether the compression ratio of an infinite word can change when a single bit\nis added in front of it. We answer positively this open question raised by Lutz\nand others: we show that there exists an infinite word $w$ such that\n$\\rho_{sup}(w)=0$ but $\\rho_{inf}(0w)>0$, where $\\rho_{sup}$ and $\\rho_{inf}$\nare respectively the $\\limsup$ and the $\\liminf$ of the compression ratios\n$\\rho$ of the prefixes. To that purpose we explore the behaviour of LZ'78 on\nfinite words and show the following results:\n  - There is a constant $C>0$ such that, for any finite word $w$ and any letter\n$a$, $\\rho(aw)\\leq C\\sqrt{\\rho(w)\\log|w|}$. Thus, sufficiently compressible\nwords ($\\rho(w)=o(1/\\log|w|)$) remain compressible with a letter in front;\n  - The previous result is tight up to a multiplicative constant for any\ncompression ratio $\\rho(w)=O(1/\\log|w|)$. In particular, there are infinitely\nmany words $w$ satisfying $\\rho(w)=O(1/\\log|w|)$ but $\\rho(0w)=\\Omega(1)$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:37:25 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 10:17:02 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Lagarde", "Guillaume", ""], ["Perifel", "Sylvain", ""]]}, {"id": "1707.04316", "submitter": "Jiehua Chen", "authors": "Jiehua Chen and Danny Hermelin and Manuel Sorge and Harel Yedidsion", "title": "How hard is it to satisfy (almost) all roommates?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic Stable Roommates problem (which is the non-bipartite\ngeneralization of the well-known Stable Marriage problem) asks whether there is\na stable matching for a given set of agents, i.e. a partitioning of the agents\ninto disjoint pairs such that no two agents induce a blocking pair. Herein,\neach agent has a preference list denoting who it prefers to have as a partner,\nand two agents are blocking if they prefer to be with each other rather than\nwith their assigned partners. Since stable matchings may not be unique, we\nstudy an NP-hard optimization variant of Stable Roommates, called Egal Stable\nRoommates, which seeks to find a stable matching with a minimum egalitarian\ncost {\\gamma}, i.e. the sum of the dissatisfaction of the agents is minimum.\nThe dissatisfaction of an agent is the number of agents that this agent prefers\nover its partner if it is matched; otherwise it is the length of its preference\nlist. We also study almost stable matchings, called Min-Block-Pair Stable\nRoommates, which seeks to find a matching with a minimum number {\\beta} of\nblocking pairs. Our main result is that Egal Stable Roommates parameterized by\n{\\gamma} is fixed-parameter tractable, while Min-Block-Pair Stable Roommates\nparameterized by {\\beta} is W[1]-hard, even if the length of each preference\nlist is at most five.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:53:33 GMT"}, {"version": "v2", "created": "Sat, 2 Dec 2017 20:28:44 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 10:02:28 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Chen", "Jiehua", ""], ["Hermelin", "Danny", ""], ["Sorge", "Manuel", ""], ["Yedidsion", "Harel", ""]]}, {"id": "1707.04331", "submitter": "Sungjin Im", "authors": "Sungjin Im and Manish Purohit", "title": "A Tight Approximation for Co-flow Scheduling for Minimizing Total\n  Weighted Completion Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-flows model a modern scheduling setting that is commonly found in a\nvariety of applications in distributed and cloud computing. In co-flow\nscheduling, there are $m$ input ports and $m$ output ports. Each co-flow $j \\in\nJ$ can be represented by a bipartite graph between the input and output ports,\nwhere each edge $(i,o)$ with demand $d_{i,o}^j$ means that $d_{i,o}^j$ units of\npackets must be delivered from port $i$ to port $o$. To complete co-flow $j$,\nwe must satisfy all of its demands. Due to capacity constraints, a port can\nonly transmit (or receive) one unit of data in unit time. A feasible schedule\nat each time $t$ must therefore be a bipartite matching.\n  We consider co-flow scheduling and seek to optimize the popular objective of\ntotal weighted completion time. Our main result is a\n$(2+\\epsilon)$-approximation for this problem, which is essentially tight, as\nthe problem is hard to approximate within a factor of $(2 - \\epsilon)$. This\nimproves upon the previous best known 4-approximation. Further, our result\nholds even when jobs have release times without any loss in the approximation\nguarantee. The key idea of our approach is to construct a continuous-time\nschedule using a configuration linear program and interpret each job's\ncompletion time therein as the job's deadline. The continuous-time schedule\nserves as a witness schedule meeting the discovered deadlines, which allows us\nto reduce the problem to a deadline-constrained scheduling problem.\n  * This result is flawed; see the first page for the details.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 21:28:44 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 06:27:20 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Im", "Sungjin", ""], ["Purohit", "Manish", ""]]}, {"id": "1707.04347", "submitter": "Lin Chen", "authors": "Lin Chen, Moran Feldman, Amin Karbasi", "title": "Weakly Submodular Maximization Beyond Cardinality Constraints: Does\n  Randomization Help Greedy?", "comments": "Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are a broad class of set functions, which naturally\narise in diverse areas. Many algorithms have been suggested for the\nmaximization of these functions. Unfortunately, once the function deviates from\nsubmodularity, the known algorithms may perform arbitrarily poorly. Amending\nthis issue, by obtaining approximation results for set functions generalizing\nsubmodular functions, has been the focus of recent works.\n  One such class, known as weakly submodular functions, has received a lot of\nattention. A key result proved by Das and Kempe (2011) showed that the\napproximation ratio of the greedy algorithm for weakly submodular maximization\nsubject to a cardinality constraint degrades smoothly with the distance from\nsubmodularity. However, no results have been obtained for maximization subject\nto constraints beyond cardinality. In particular, it is not known whether the\ngreedy algorithm achieves any non-trivial approximation ratio for such\nconstraints.\n  In this paper, we prove that a randomized version of the greedy algorithm\n(previously used by Buchbinder et al. (2014) for a different problem) achieves\nan approximation ratio of $(1 + 1/\\gamma)^{-2}$ for the maximization of a\nweakly submodular function subject to a general matroid constraint, where\n$\\gamma$ is a parameter measuring the distance of the function from\nsubmodularity. Moreover, we also experimentally compare the performance of this\nversion of the greedy algorithm on real world problems against natural\nbenchmarks, and show that the algorithm we study performs well also in\npractice. To the best of our knowledge, this is the first algorithm with a\nnon-trivial approximation guarantee for maximizing a weakly submodular function\nsubject to a constraint other than the simple cardinality constraint. In\nparticular, it is the first algorithm with such a guarantee for the important\nand broad class of matroid constraints.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 22:48:43 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Chen", "Lin", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "1707.04428", "submitter": "Jugal Garg", "authors": "Jugal Garg, Martin Hoefer, Kurt Mehlhorn", "title": "Satiation in Fisher Markets and Approximation of Nash Social Welfare", "comments": "Restructured the paper with improved lower bound", "journal-ref": "Conference version in SODA 2018", "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study linear Fisher markets with satiation. In these markets, sellers have\nearning limits and buyers have utility limits. Beyond natural applications in\neconomics, these markets arise in the context of maximizing Nash social welfare\nwhen allocating indivisible items to agents. In contrast to markets with either\nearning or utility limits, markets with both limits have not been studied\nbefore. They turn out to have fundamentally different properties.\n  In general, the existence of competitive equilibria is not guaranteed. We\nidentify a natural property of markets (termed money clearing) that implies\nexistence. We show that the set of equilibria is not always convex, answering a\nquestion of Cole et al. [EC'17]. We design an FPTAS to compute an approximate\nequilibrium and prove that the problem of computing an exact equilibrium lies\nin the intersection of complexity classes PLS and PPAD. For a constant number\nof buyers or goods, we give a polynomial-time algorithm to compute an exact\nequilibrium.\n  We show how (approximate) equilibria can be rounded and provide the first\nconstant-factor approximation algorithm (with a factor of 2.404) for maximizing\nNash social welfare when agents have budget-additive valuations. Finally, we\nsignificantly improve the approximation hardness for additive valuations to\n\\sqrt{8/7} > 1.069 (over 1.00008 by Lee [IPL'17]).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 09:18:01 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 04:08:02 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 01:21:25 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Garg", "Jugal", ""], ["Hoefer", "Martin", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1707.04519", "submitter": "Grigorios Koumoutsos", "authors": "Nikhil Bansal, Marek Elias, Grigorios Koumoutsos, Jesper Nederlof", "title": "Competitive Algorithms for Generalized k-Server in Uniform Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized k-server problem is a far-reaching extension of the k-server\nproblem with several applications. Here, each server $s_i$ lies in its own\nmetric space $M_i$. A request is a k-tuple $r = (r_1,r_2,\\dotsc,r_k)$ and to\nserve it, we need to move some server $s_i$ to the point $r_i \\in M_i$, and the\ngoal is to minimize the total distance traveled by the servers. Despite much\nwork, no f(k)-competitive algorithm is known for the problem for k > 2 servers,\neven for special cases such as uniform metrics and lines.\n  Here, we consider the problem in uniform metrics and give the first\nf(k)-competitive algorithms for general k. In particular, we obtain\ndeterministic and randomized algorithms with competitive ratio $O(k 2^k)$ and\n$O(k^3 \\log k)$ respectively. Our deterministic bound is based on a novel\napplication of the polynomial method to online algorithms, and essentially\nmatches the long-known lower bound of $2^k-1$. We also give a\n$2^{2^{O(k)}}$-competitive deterministic algorithm for weighted uniform\nmetrics, which also essentially matches the recent doubly exponential lower\nbound for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 14:19:26 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 15:38:23 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Bansal", "Nikhil", ""], ["Elias", "Marek", ""], ["Koumoutsos", "Grigorios", ""], ["Nederlof", "Jesper", ""]]}, {"id": "1707.04609", "submitter": "Holger Dell", "authors": "Holger Dell and John Lapinskas", "title": "Fine-grained reductions from approximate counting to decision", "comments": "An extended abstract was presented at STOC 2018", "journal-ref": null, "doi": "10.1145/3188745.3188920", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we introduce a general framework for fine-grained reductions\nof approximate counting problems to their decision versions. (Thus we use an\noracle that decides whether any witness exists to multiplicatively approximate\nthe number of witnesses with minimal overhead.) This mirrors a foundational\nresult of Sipser (STOC 1983) and Stockmeyer (SICOMP 1985) in the\npolynomial-time setting, and a similar result of M\\\"uller (IWPEC 2006) in the\nFPT setting. Using our framework, we obtain such reductions for some of the\nmost important problems in fine-grained complexity: the Orthogonal Vectors\nproblem, 3SUM, and the Negative-Weight Triangle problem (which is closely\nrelated to All-Pairs Shortest Path).\n  We also provide a fine-grained reduction from approximate #SAT to SAT.\nSuppose the Strong Exponential Time Hypothesis (SETH) is false, so that for\nsome $1<c<2$ and all $k$ there is an $O(c^n)$-time algorithm for k-SAT. Then we\nprove that for all $k$, there is an $O((c+o(1))^n)$-time algorithm for\napproximate #$k$-SAT. In particular, our result implies that the Exponential\nTime Hypothesis (ETH) is equivalent to the seemingly-weaker statement that\nthere is no algorithm to approximate #3-SAT to within a factor of $1+\\epsilon$\nin time $2^{o(n)}/\\epsilon^2$ (taking $\\epsilon > 0$ as part of the input).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 19:02:42 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 12:56:27 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 19:42:20 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dell", "Holger", ""], ["Lapinskas", "John", ""]]}, {"id": "1707.04683", "submitter": "Hsien-Chih Chang", "authors": "Hsien-Chih Chang, Marcos Cossarini, Jeff Erickson", "title": "Lower Bounds for Electrical Reduction on Surfaces", "comments": "23 pages, 11 figures. Conference version appears in SOCG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We strengthen the connections between electrical transformations and homotopy\nfrom the planar setting---observed and studied since Steinitz---to arbitrary\nsurfaces with punctures. As a result, we improve our earlier lower bound on the\nnumber of electrical transformations required to reduce an $n$-vertex graph on\nsurface in the worst case [SOCG 2016] in two different directions. Our previous\n$\\Omega(n^{3/2})$ lower bound applies only to facial electrical transformations\non plane graphs with no terminals. First we provide a stronger $\\Omega(n^2)$\nlower bound when the planar graph has two or more terminals, which follows from\na quadratic lower bound on the number of homotopy moves in the annulus. Our\nsecond result extends our earlier $\\Omega(n^{3/2})$ lower bound to the wider\nclass of planar electrical transformations, which preserve the planarity of the\ngraph but may delete cycles that are not faces of the given embedding. This new\nlower bound follows from the observation that the defect of the medial graph of\na planar graph is the same for all its planar embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 02:56:13 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 19:11:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Chang", "Hsien-Chih", ""], ["Cossarini", "Marcos", ""], ["Erickson", "Jeff", ""]]}, {"id": "1707.04766", "submitter": "Uri Stemmer", "authors": "Kobbi Nissim, Uri Stemmer", "title": "Clustering Algorithms for the Centralized and Local Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of finding a minimum enclosing ball with differential\nprivacy: Given a set of $n$ points in the Euclidean space $\\mathbb{R}^d$ and an\ninteger $t\\leq n$, the goal is to find a ball of the smallest radius $r_{opt}$\nenclosing at least $t$ input points. The problem is motivated by its various\napplications to differential privacy, including the sample and aggregate\ntechnique, private data exploration, and clustering.\n  Without privacy concerns, minimum enclosing ball has a polynomial time\napproximation scheme (PTAS), which computes a ball of radius almost $r_{opt}$\n(the problem is NP-hard to solve exactly). In contrast, under differential\nprivacy, until this work, only a $O(\\sqrt{\\log n})$-approximation algorithm was\nknown.\n  We provide new constructions of differentially private algorithms for minimum\nenclosing ball achieving constant factor approximation to $r_{opt}$ both in the\ncentralized model (where a trusted curator collects the sensitive information\nand analyzes it with differential privacy) and in the local model (where each\nrespondent randomizes her answers to the data curator to protect her privacy).\n  We demonstrate how to use our algorithms as a building block for\napproximating $k$-means in both models.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 17:39:12 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1707.04858", "submitter": "Talya Eden", "authors": "Talya Eden, Dana Ron, C. Seshadhri", "title": "On Approximating the Number of $k$-cliques in Sublinear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the number of $k$-cliques in a graph\nwhen given query access to the graph.\n  We consider the standard query model for general graphs via (1) degree\nqueries, (2) neighbor queries and (3) pair queries. Let $n$ denote the number\nof vertices in the graph, $m$ the number of edges, and $C_k$ the number of\n$k$-cliques. We design an algorithm that outputs a\n$(1+\\varepsilon)$-approximation (with high probability) for $C_k$, whose\nexpected query complexity and running time are\n$O\\left(\\frac{n}{C_k^{1/k}}+\\frac{m^{k/2}}{C_k}\\right)\\poly(\\log\nn,1/\\varepsilon,k)$.\n  Hence, the complexity of the algorithm is sublinear in the size of the graph\nfor $C_k = \\omega(m^{k/2-1})$. Furthermore, we prove a lower bound showing that\nthe query complexity of our algorithm is essentially optimal (up to the\ndependence on $\\log n$, $1/\\varepsilon$ and $k$).\n  The previous results in this vein are by Feige (SICOMP 06) and by Goldreich\nand Ron (RSA 08) for edge counting ($k=2$) and by Eden et al. (FOCS 2015) for\ntriangle counting ($k=3$). Our result matches the complexities of these\nresults.\n  The previous result by Eden et al. hinges on a certain amortization technique\nthat works only for triangle counting, and does not generalize for larger\ncliques. We obtain a general algorithm that works for any $k\\geq 3$ by\ndesigning a procedure that samples each $k$-clique incident to a given set $S$\nof vertices with approximately equal probability. The primary difficulty is in\nfinding cliques incident to purely high-degree vertices, since random sampling\nwithin neighbors has a low success probability. This is achieved by an\nalgorithm that samples uniform random high degree vertices and a careful\ntradeoff between estimating cliques incident purely to high-degree vertices and\nthose that include a low-degree vertex.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 11:01:10 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 21:35:18 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Eden", "Talya", ""], ["Ron", "Dana", ""], ["Seshadhri", "C.", ""]]}, {"id": "1707.04864", "submitter": "Reut Levi", "authors": "Talya Eden, Reut Levi, Dana Ron", "title": "Testing bounded arboricity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of testing whether a graph has bounded\narboricity. The family of graphs with bounded arboricity includes, among\nothers, bounded-degree graphs, all minor-closed graph classes (e.g. planar\ngraphs, graphs with bounded treewidth) and randomly generated preferential\nattachment graphs. Graphs with bounded arboricity have been studied extensively\nin the past, in particular since for many problems they allow for much more\nefficient algorithms and/or better approximation ratios.\n  We present a tolerant tester in the sparse-graphs model. The sparse-graphs\nmodel allows access to degree queries and neighbor queries, and the distance is\ndefined with respect to the actual number of edges. More specifically, our\nalgorithm distinguishes between graphs that are $\\epsilon$-close to having\narboricity $\\alpha$ and graphs that $c \\cdot \\epsilon$-far from having\narboricity $3\\alpha$, where $c$ is an absolute small constant. The query\ncomplexity and running time of the algorithm are\n$\\tilde{O}\\left(\\frac{n}{\\sqrt{m}}\\cdot \\frac{\\log(1/\\epsilon)}{\\epsilon} +\n\\frac{n\\cdot \\alpha}{m} \\cdot\n\\left(\\frac{1}{\\epsilon}\\right)^{O(\\log(1/\\epsilon))}\\right)$ where $n$ denotes\nthe number of vertices and $m$ denotes the number of edges. In terms of the\ndependence on $n$ and $m$ this bound is optimal up to poly-logarithmic factors\nsince $\\Omega(n/\\sqrt{m})$ queries are necessary (and $\\alpha = O(\\sqrt{m}))$.\n  We leave it as an open question whether the dependence on $1/\\epsilon$ can be\nimproved from quasi-polynomial to polynomial. Our techniques include an\nefficient local simulation for approximating the outcome of a global (almost)\nforest-decomposition algorithm as well as a tailored procedure of edge\nsampling.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 11:19:04 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 16:57:55 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Eden", "Talya", ""], ["Levi", "Reut", ""], ["Ron", "Dana", ""]]}, {"id": "1707.04867", "submitter": "Diptarka Chakraborty", "authors": "Diptarka Chakraborty and Debarati Das", "title": "Near Optimal Sized Weight Tolerant Subgraph for Single Source Shortest\n  Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of computing a sparse subgraph of a\nweighted directed graph such that the exact distances from a designated source\nvertex to all other vertices are preserved under bounded weight increment.\nFinding a small sized subgraph that preserves distances between any pair of\nvertices is a well studied problem. Since in the real world any network is\nprone to failures, it is natural to study the fault tolerant version of the\nabove problem. Unfortunately, it turns out that there may not always exist such\na sparse subgraph even under single edge failure [Demetrescu \\emph{et al.}\n'08]. However in real applications it is not always the case that a link (edge)\nin a network becomes completely faulty. Instead, it can happen that some links\nbecome more congested which can easily be captured by increasing weight on the\ncorresponding edges. Thus it makes sense to try to construct a sparse distance\npreserving subgraph under the above weight increment model. To the best of our\nknowledge this problem has not been studied so far. In this paper we show that\ngiven any weighted directed graph with $n$ vertices and a source vertex, one\ncan construct a subgraph that contains at most $e \\cdot (k-1)!2^kn$ many edges\nsuch that it preserves distances between the source and all other vertices as\nlong as the total weight increment is bounded by $k$ and we are allowed to have\nonly integer valued (can be negative) weight on each edge and also weight of an\nedge can only be increased by some positive integer. Next we show a lower bound\nof $c\\cdot 2^kn$, for some constant $c \\ge 5/4$, on the size of the subgraph.\nWe also argue that restriction of integer valued weight and integer valued\nweight increment are actually essential by showing that if we remove any one of\nthese two restrictions we may need to store $\\Omega(n^2)$ edges to preserve\ndistances.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 11:32:16 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Das", "Debarati", ""]]}, {"id": "1707.04875", "submitter": "Daniel Hsu", "authors": "Alexandr Andoni and Javad Ghaderi and Daniel Hsu and Dan Rubenstein\n  and Omri Weinstein", "title": "Coding sets with asymmetric information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following one-way asymmetric transmission problem, also a\nvariant of model-based compressed sensing: a resource-limited encoder has to\nreport a small set $S$ from a universe of $N$ items to a more powerful decoder\n(server). The distinguishing feature is asymmetric information: the subset $S$\nis comprised of i.i.d. samples from a prior distribution $\\mu$, and $\\mu$ is\nonly known to the decoder. The goal for the encoder is to encode $S$\nobliviously, while achieving the information-theoretic bound of $|S| \\cdot\nH(\\mu)$, i.e., the Shannon entropy bound.\n  We first show that any such compression scheme must be {\\em randomized}, if\nit gains non-trivially from the prior $\\mu$. This stands in contrast to the\nsymmetric case (when both the encoder and decoder know $\\mu$), where the\nHuffman code provides a near-optimal deterministic solution. On the other hand,\na rather simple argument shows that, when $|S|=k$, a random linear code\nachieves near-optimal communication rate of about $k\\cdot H(\\mu)$ bits. Alas,\nthe resulting scheme has prohibitive decoding time: about ${N\\choose k} \\approx\n(N/k)^k$.\n  Our main result is a computationally efficient and linear coding scheme,\nwhich achieves an $O(\\lg\\lg N)$-competitive communication ratio compared to the\noptimal benchmark, and runs in $\\text{poly}(N,k)$ time. Our \"multi-level\"\ncoding scheme uses a combination of hashing and syndrome-decoding of\nReed-Solomon codes, and relies on viewing the (unknown) prior $\\mu$ as a rather\nsmall convex combination of uniform (\"flat\") distributions.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 12:51:42 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 01:15:33 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Andoni", "Alexandr", ""], ["Ghaderi", "Javad", ""], ["Hsu", "Daniel", ""], ["Rubenstein", "Dan", ""], ["Weinstein", "Omri", ""]]}, {"id": "1707.04908", "submitter": "Meirav Zehavi", "authors": "Akanksha Agrawal, Daniel Lokshtanov, Pranabendu Misra, Saket Saurabh,\n  Meirav Zehavi", "title": "Polylogarithmic Approximation Algorithms for\n  Weighted-$\\mathcal{F}$-Deletion Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a family of graphs $\\cal F$, the canonical Weighted $\\cal F$ Vertex\nDeletion problem is defined as follows: given an $n$-vertex undirected graph\n$G$ and a weight function $w: V(G)\\rightarrow\\mathbb{R}$, find a minimum weight\nsubset $S\\subseteq V(G)$ such that $G-S$ belongs to $\\cal F$. We devise a\nrecursive scheme to obtain $O(\\log^{O(1)}n)$-approximation algorithms for such\nproblems, building upon the classic technique of finding balanced separators in\na graph. Roughly speaking, our scheme applies to problems where an optimum\nsolution $S$, together with a well-structured set $X$, form a balanced\nseparator of $G$. We obtain the first $O(\\log^{O(1)}n)$-approximation\nalgorithms for the following problems.\n  * We give an $O(\\log^2n)$-factor approximation algorithm for Weighted Chordal\nVertex Deletion (WCVD), the vertex deletion problem to the family of chordal\ngraphs. On the way, we also obtain a constant factor approximation algorithm\nfor Multicut on chordal graphs.\n  * We give an $O(\\log^3n)$-factor approximation algorithm for Weighted\nDistance Hereditary Vertex Deletion (WDHVD). This is the vertex deletion\nproblem to the family of distance hereditary graphs, or equivalently, the\nfamily of graphs of rankwidth 1.\n  Our methods also allow us to obtain in a clean fashion a\n$O(\\log^{1.5}n)$-approximation algorithm for the Weighted $\\cal F$ Vertex\nDeletion problem when $\\cal F$ is a minor closed family excluding at least one\nplanar graph. For the unweighted version of the problem constant factor\napproximation algorithms are were known~[Fomin et al., FOCS~2012], while for\nthe weighted version considered here an $O(\\log n \\log\\log n)$-approximation\nalgorithm follows from~[Bansal et al., SODA~2017]. We believe that our\nrecursive scheme can be applied to obtain $O(\\log^{O(1)}n)$-approximation\nalgorithms for many other problems as well.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 16:49:03 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Lokshtanov", "Daniel", ""], ["Misra", "Pranabendu", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1707.04917", "submitter": "Meirav Zehavi", "authors": "Akanksha Agrawal, Daniel Lokshtanov, Pranabendu Misra, Saket Saurabh,\n  Meirav Zehavi", "title": "Feedback Vertex Set Inspired Kernel for Chordal Vertex Deletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$ and a parameter $k$, the Chordal Vertex Deletion (CVD)\nproblem asks whether there exists a subset $U\\subseteq V(G)$ of size at most\n$k$ that hits all induced cycles of size at least 4. The existence of a\npolynomial kernel for CVD was a well-known open problem in the field of\nParameterized Complexity. Recently, Jansen and Pilipczuk resolved this question\naffirmatively by designing a polynomial kernel for CVD of size\n$O(k^{161}\\log^{58}k)$, and asked whether one can design a kernel of size\n$O(k^{10})$. While we do not completely resolve this question, we design a\nsignificantly smaller kernel of size $O(k^{12}\\log^{10}k)$, inspired by the\n$O(k^2)$-size kernel for Feedback Vertex Set. Furthermore, we introduce the\nnotion of the independence degree of a vertex, which is our main conceptual\ncontribution.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 17:22:08 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Lokshtanov", "Daniel", ""], ["Misra", "Pranabendu", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1707.04929", "submitter": "Efe Onaran", "authors": "Efe Onaran and Soledad Villar", "title": "Projected Power Iteration for Network Alignment", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network alignment problem asks for the best correspondence between two\ngiven graphs, so that the largest possible number of edges are matched. This\nproblem appears in many scientific problems (like the study of protein-protein\ninteractions) and it is very closely related to the quadratic assignment\nproblem which has graph isomorphism, traveling salesman and minimum bisection\nproblems as particular cases. The graph matching problem is NP-hard in general.\nHowever, under some restrictive models for the graphs, algorithms can\napproximate the alignment efficiently. In that spirit the recent work by Feizi\nand collaborators introduce EigenAlign, a fast spectral method with convergence\nguarantees for Erd\\H{o}s-Reny\\'i graphs. In this work we propose the algorithm\nProjected Power Alignment, which is a projected power iteration version of\nEigenAlign. We numerically show it improves the recovery rates of EigenAlign\nand we describe the theory that may be used to provide performance guarantees\nfor Projected Power Alignment.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 19:02:31 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Onaran", "Efe", ""], ["Villar", "Soledad", ""]]}, {"id": "1707.04942", "submitter": "Christian Fries", "authors": "Christian P. Fries", "title": "Automatic Backward Differentiation for American Monte-Carlo Algorithms\n  (Conditional Expectation)", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we derive the backward (automatic) differentiation (adjoint\n[automatic] differentiation) for an algorithm containing a conditional\nexpectation operator. As an example we consider the backward algorithm as it is\nused in Bermudan product valuation, but the method is applicable in full\ngenerality.\n  The method relies on three simple properties: 1) a forward or backward\n(automatic) differentiation of an algorithm containing a conditional\nexpectation operator results in a linear combination of the conditional\nexpectation operators; 2) the differential of an expectation is the expectation\nof the differential $\\frac{d}{dx} E(Y) = E(\\frac{d}{dx}Y)$; 3) if we are only\ninterested in the expectation of the final result (as we are in all valuation\nproblems), we may use $E(A \\cdot E(B\\vert\\mathcal{F})) = E(E(A\\vert\\mathcal{F})\n\\cdot B)$, i.e., instead of applying the (conditional) expectation operator to\na function of the underlying random variable (continuation values), it may be\napplied to the adjoint differential. \\end{enumerate}\n  The methodology not only allows for a very clean and simple implementation,\nbut also offers the ability to use different conditional expectation estimators\nin the valuation and the differentiation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 20:35:28 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Fries", "Christian P.", ""]]}, {"id": "1707.04982", "submitter": "Uri Stemmer", "authors": "Raef Bassily, Kobbi Nissim, Uri Stemmer, Abhradeep Thakurta", "title": "Practical Locally Private Heavy Hitters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new practical local differentially private heavy hitters\nalgorithms achieving optimal or near-optimal worst-case error and running time\n-- TreeHist and Bitstogram. In both algorithms, server running time is $\\tilde\nO(n)$ and user running time is $\\tilde O(1)$, hence improving on the prior\nstate-of-the-art result of Bassily and Smith [STOC 2015] requiring $O(n^{5/2})$\nserver time and $O(n^{3/2})$ user time. With a typically large number of\nparticipants in local algorithms ($n$ in the millions), this reduction in time\ncomplexity, in particular at the user side, is crucial for making locally\nprivate heavy hitters algorithms usable in practice. We implemented Algorithm\nTreeHist to verify our theoretical analysis and compared its performance with\nthe performance of Google's RAPPOR code.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 02:34:55 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Bassily", "Raef", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1707.05016", "submitter": "Guillaume Ducoffe", "authors": "David Coudert (1), Guillaume Ducoffe (1,2), Alexandru Popa ((1) COATI,\n  (2) ICI Bucharest)", "title": "Fully polynomial FPT algorithms for some classes of bounded clique-width\n  graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized complexity theory has enabled a refined classification of the\ndifficulty of NP-hard optimization problems on graphs with respect to key\nstructural properties, and so to a better understanding of their true\ndifficulties. More recently, hardness results for problems in P were achieved\nusing reasonable complexity theoretic assumptions such as: Strong Exponential\nTime Hypothesis (SETH), 3SUM and All-Pairs Shortest-Paths (APSP). According to\nthese assumptions, many graph theoretic problems do not admit truly\nsubquadratic algorithms, nor even truly subcubic algorithms (Williams and\nWilliams, FOCS 2010 and Abboud, Grandoni, Williams, SODA 2015). A central\ntechnique used to tackle the difficulty of the above mentioned problems is\nfixed-parameter algorithms for polynomial-time problems with polynomial\ndependency in the fixed parameter (P-FPT). This technique was introduced by\nAbboud, Williams and Wang in SODA 2016 and continued by Husfeldt (IPEC 2016)\nand Fomin et al. (SODA 2017), using the treewidth as a parameter. Applying this\ntechnique to clique-width, another important graph parameter, remained to be\ndone. In this paper we study several graph theoretic problems for which\nhardness results exist such as cycle problems (triangle detection, triangle\ncounting, girth, diameter), distance problems (diameter, eccentricities, Gromov\nhyperbolicity, betweenness centrality) and maximum matching. We provide\nhardness results and fully polynomial FPT algorithms, using clique-width and\nsome of its upper-bounds as parameters (split-width, modular-width and\n$P\\_4$-sparseness). We believe that our most important result is an ${\\cal\nO}(k^4 \\cdot n + m)$-time algorithm for computing a maximum matching where $k$\nis either the modular-width or the $P\\_4$-sparseness. The latter generalizes\nmany algorithms that have been introduced so far for specific subclasses such\nas cographs, $P\\_4$-lite graphs, $P\\_4$-extendible graphs and $P\\_4$-tidy\ngraphs. Our algorithms are based on preprocessing methods using modular\ndecomposition, split decomposition and primeval decomposition. Thus they can\nalso be generalized to some graph classes with unbounded clique-width.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 06:57:27 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 12:37:56 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Coudert", "David", ""], ["Ducoffe", "Guillaume", ""], ["Popa", "Alexandru", ""]]}, {"id": "1707.05065", "submitter": "L\\'aszl\\'o V\\'egh", "authors": "Daniel Dadush and L\\'aszl\\'o A. V\\'egh and Giacomo Zambelli", "title": "Geometric Rescaling Algorithms for Submodular Function Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new class of polynomial-time algorithms for submodular function\nminimization (SFM), as well as a unified framework to obtain strongly\npolynomial SFM algorithms. Our algorithms are based on simple iterative methods\nfor the minimum-norm problem, such as the conditional gradient and\nFujishige-Wolfe algorithms. We exhibit two techniques to turn simple iterative\nmethods into polynomial-time algorithms.\n  Firstly, we adapt the geometric rescaling technique, which has recently\ngained attention in linear programming, to SFM and obtain a weakly polynomial\nbound $O(({n}^4\\cdot \\textrm{EO} + {n}^5)\\log ({n} L))$.\n  Secondly, we exhibit a general combinatorial black-box approach to turn\n$\\varepsilon L$-approximate SFM oracles into strongly polynomial exact SFM\nalgorithms. This framework can be applied to a wide range of combinatorial and\ncontinuous algorithms, including pseudo-polynomial ones. In particular, we can\nobtain strongly polynomial algorithms by a repeated application of the\nconditional gradient or of the Fujishige-Wolfe algorithm. Combined with the\ngeometric rescaling technique, the black-box approach provides an\n$O(({n}^5\\cdot \\textrm{EO} +{n}^6)\\log^2{n})$ algorithm.\n  Finally, we show that one of the techniques we develop in the paper can also\nbe combined with the cutting-plane method of Lee, Sidford, and Wong \\cite{LSW},\nyielding a simplified variant of their $O(n^3 \\log^2 n \\cdot \\textrm{EO} +\nn^4\\log^{O(1)} n)$ algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 09:54:05 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 12:16:43 GMT"}, {"version": "v3", "created": "Mon, 20 Aug 2018 09:26:40 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 13:42:43 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Dadush", "Daniel", ""], ["V\u00e9gh", "L\u00e1szl\u00f3 A.", ""], ["Zambelli", "Giacomo", ""]]}, {"id": "1707.05095", "submitter": "Barna Saha", "authors": "Karl Bringmann, Fabrizio Grandoni, Barna Saha, Virginia Vassilevska\n  Williams", "title": "Truly Sub-cubic Algorithms for Language Edit Distance and RNA Folding\n  via Fast Bounded-Difference Min-Plus Product", "comments": "Full version of the conference paper, appeared in FOCS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a major open problem whether the $(\\min,+)$-product of two $n\\times n$\nmatrices has a truly sub-cubic (i.e. $O(n^{3-\\epsilon})$ for $\\epsilon>0$) time\nalgorithm, in particular since it is equivalent to the famous\nAll-Pairs-Shortest-Paths problem (APSP) in $n$-vertex graphs. Some restrictions\nof the $(\\min,+)$-product to special types of matrices are known to admit truly\nsub-cubic algorithms, each giving rise to a special case of APSP that can be\nsolved faster. In this paper we consider a new, different and powerful\nrestriction in which all matrix entries are integers and one matrix can be\narbitrary, as long as the other matrix has \"bounded differences\" in either its\ncolumns or rows, i.e. any two consecutive entries differ by only a small\namount. We obtain the first truly sub-cubic algorithm for this\nbounded-difference $(\\min,+)$-product (answering an open problem of Chan and\nLewenstein).\n  Our new algorithm, combined with a strengthening of an approach of L.~Valiant\nfor solving context-free grammar parsing with matrix multiplication, yields the\nfirst truly sub-cubic algorithms for the following problems: Language Edit\nDistance (a major problem in the parsing community), RNA-folding (a major\nproblem in bioinformatics) and Optimum Stack Generation (answering an open\nproblem of Tarjan).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 11:13:16 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Bringmann", "Karl", ""], ["Grandoni", "Fabrizio", ""], ["Saha", "Barna", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1707.05123", "submitter": "Tianyi Zhang", "authors": "Ran Duan and Tianyi Zhang", "title": "Purely Combinatorial Algorithms for Approximate Directed Minimum Degree\n  Spanning Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a directed graph $G$ on $n$ vertices with a special vertex $s$, the\ndirected minimum degree spanning tree problem requires computing a incoming\nspanning tree rooted at $s$ whose maximum tree in-degree is the smallest among\nall such trees. The problem is known to be NP-hard, since it generalizes the\nHamiltonian path problem. The best LP-based polynomial time algorithm can\nachieve an approximation of $\\Delta^*+2$ [Bansal et al, 2009], where $\\Delta^*$\ndenotes the optimal maximum tree in-degree. As for purely combinatorial\nalgorithms (algorithms that do not use LP), the best approximation is\n$O(\\Delta^*+\\log n)$ [Krishnan and Raghavachari, 2001] but the running time is\nquasi-polynomial. In this paper, we focus on purely combinatorial algorithms\nand try to bridge the gap between LP-based approaches and purely combinatorial\napproaches. As a result, we propose a purely combinatorial polynomial time\nalgorithm that also achieves an $O(\\Delta^* + \\log n)$ approximation. Then we\nimprove this algorithm to obtain a $(1+\\epsilon)\\Delta^* + O(\\frac{\\log\nn}{\\log\\log n})$ for any constant $0<\\epsilon<1$ approximation in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 12:47:39 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 06:28:56 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 11:36:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Duan", "Ran", ""], ["Zhang", "Tianyi", ""]]}, {"id": "1707.05124", "submitter": "Manuela Fischer", "authors": "Manuela Fischer and Andreas Noever", "title": "Tight Analysis of Randomized Greedy MIS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a tight analysis which settles the round complexity of the\nwell-studied parallel randomized greedy MIS algorithm, thus answering the main\nopen question of Blelloch, Fineman, and Shun [SPAA'12].\n  The parallel/distributed randomized greedy Maximal Independent Set (MIS)\nalgorithm works as follows. An order of the vertices is chosen uniformly at\nrandom. Then, in each round, all vertices that appear before their neighbors in\nthe order are added to the independent set and removed from the graph along\nwith their neighbors. The main question of interest is the number of rounds it\ntakes until the graph is empty. This algorithm has been studied since 1987,\ninitiated by Coppersmith, Raghavan, and Tompa [FOCS'87], and the previously\nbest known bounds were $O(\\log n)$ rounds in expectation for\nErd\\H{o}s-R\\'{e}nyi random graphs by Calkin and Frieze [Random Struc. \\& Alg.\n'90] and $O(\\log^2 n)$ rounds with high probability for general graphs by\nBlelloch, Fineman, and Shun [SPAA'12].\n  We prove a high probability upper bound of $O(\\log n)$ on the round\ncomplexity of this algorithm in general graphs, and that this bound is tight.\nThis also shows that parallel randomized greedy MIS is as fast as the\ncelebrated algorithm of Luby [STOC'85, JALG'86].\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 12:49:20 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 08:10:24 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 09:56:23 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Fischer", "Manuela", ""], ["Noever", "Andreas", ""]]}, {"id": "1707.05128", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Ziteng Sun, Huanyu Zhang", "title": "Differentially Private Testing of Identity and Closeness of Discrete\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problems of identity testing (goodness of fit), and\ncloseness testing (two sample test) of distributions over $k$ elements, under\ndifferential privacy. While the problems have a long history in statistics,\nfinite sample bounds for these problems have only been established recently.\n  In this work, we derive upper and lower bounds on the sample complexity of\nboth the problems under $(\\varepsilon, \\delta)$-differential privacy. We\nprovide optimal sample complexity algorithms for identity testing problem for\nall parameter ranges, and the first results for closeness testing. Our\ncloseness testing bounds are optimal in the sparse regime where the number of\nsamples is at most $k$.\n  Our upper bounds are obtained by privatizing non-private estimators for these\nproblems. The non-private estimators are chosen to have small sensitivity. We\npropose a general framework to establish lower bounds on the sample complexity\nof statistical tasks under differential privacy. We show a bound on\ndifferentially private algorithms in terms of a coupling between the two\nhypothesis classes we aim to test. By constructing carefully chosen priors over\nthe hypothesis classes, and using Le Cam's two point theorem we provide a\ngeneral mechanism for proving lower bounds. We believe that the framework can\nbe used to obtain strong lower bounds for other statistical tasks under\nprivacy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 13:00:13 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 03:24:09 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 04:37:01 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "1707.05135", "submitter": "Giacomo Scornavacca", "authors": "Andrea E. F. Clementi, Luciano Gual\\`a, Francesco Pasquale, Giacomo\n  Scornavacca, Emanuele Natale, Mohsen Ghaffari", "title": "A Tight Analysis of the Parallel Undecided-State Dynamics with Two\n  Colors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{Undecided-State Dynamics} is a well-known protocol for distributed\nconsensus. We analyze it in the parallel \\pull\\ communication model on the\ncomplete graph for the \\emph{binary} case (every node can either support one of\n\\emph{two} possible colors, or be in the undecided state).\n  An interesting open question is whether this dynamics \\emph{always} (i.e.,\nstarting from an arbitrary initial configuration) reaches consensus\n\\emph{quickly} (i.e., within a polylogarithmic number of rounds) in a complete\ngraph with $n$ nodes. Previous work in this setting only considers initial\ncolor configurations with no undecided nodes and a large \\emph{bias} (i.e.,\n$\\Theta(n)$) towards the majority color.\n  In this paper we present an \\textit{unconditional} analysis of the\nUndecided-State Dynamics that answers to the above question in the affirmative.\nWe prove that, starting from \\textit{any} initial configuration, the process\nreaches a monochromatic configuration within $O(\\log n)$ rounds, with high\nprobability. This bound turns out to be tight. Our analysis also shows that, if\nthe initial configuration has bias $\\Omega(\\sqrt{n\\log n})$, then the dynamics\nconverges toward the initial majority color, with high probability.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 13:10:52 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 08:28:03 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 15:53:54 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Clementi", "Andrea E. F.", ""], ["Gual\u00e0", "Luciano", ""], ["Pasquale", "Francesco", ""], ["Scornavacca", "Giacomo", ""], ["Natale", "Emanuele", ""], ["Ghaffari", "Mohsen", ""]]}, {"id": "1707.05141", "submitter": "Wajih Halim Boukaram", "authors": "Wajih Halim Boukaram, George Turkiyyah, Hatem Ltaief and David E.\n  Keyes", "title": "Batched QR and SVD Algorithms on GPUs with Applications in Hierarchical\n  Matrix Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present high performance implementations of the QR and the singular value\ndecomposition of a batch of small matrices hosted on the GPU with applications\nin the compression of hierarchical matrices. The one-sided Jacobi algorithm is\nused for its simplicity and inherent parallelism as a building block for the\nSVD of low rank blocks using randomized methods. We implement multiple kernels\nbased on the level of the GPU memory hierarchy in which the matrices can reside\nand show substantial speedups against streamed cuSOLVER SVDs. The resulting\nbatched routine is a key component of hierarchical matrix compression, opening\nup opportunities to perform H-matrix arithmetic efficiently on GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 12:25:52 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Boukaram", "Wajih Halim", ""], ["Turkiyyah", "George", ""], ["Ltaief", "Hatem", ""], ["Keyes", "David E.", ""]]}, {"id": "1707.05170", "submitter": "Tanmay Inamdar", "authors": "Sayan Bandyapadhyay, Santanu Bhowmick, Tanmay Inamdar, and Kasturi\n  Varadarajan", "title": "Capacitated Covering Problems in Geometric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the following capacitated covering problem. We\nare given a set $P$ of $n$ points and a set $\\mathcal{B}$ of balls from some\nmetric space, and a positive integer $U$ that represents the capacity of each\nof the balls in $\\mathcal{B}$. We would like to compute a subset $\\mathcal{B}'\n\\subseteq \\mathcal{B}$ of balls and assign each point in $P$ to some ball in\n$\\mathcal{B}$ that contains it, such that the number of points assigned to any\nball is at most $U$. The objective function that we would like to minimize is\nthe cardinality of $\\mathcal{B}$.\n  We consider this problem in arbitrary metric spaces as well as Euclidean\nspaces of constant dimension. In the metric setting, even the uncapacitated\nversion of the problem is hard to approximate to within a logarithmic factor.\nIn the Euclidean setting, the best known approximation guarantee in dimensions\n$3$ and higher is logarithmic in the number of points. Thus we focus on\nobtaining \"bi-criteria\" approximations. In particular, we are allowed to expand\nthe balls in our solution by some factor, but optimal solutions do not have\nthat flexibility. Our main result is that allowing constant factor expansion of\nthe input balls suffices to obtain constant approximations for these problems.\nIn fact, in the Euclidean setting, only $(1+\\epsilon)$ factor expansion is\nsufficient for any $\\epsilon > 0$, with the approximation factor being a\npolynomial in $1/\\epsilon$. We obtain these results using a unified scheme for\nrounding the natural LP relaxation; this scheme may be useful for other\ncapacitated covering problems. We also complement these bi-criteria\napproximations by obtaining hardness of approximation results that shed light\non our understanding of these problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:04:17 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 17:08:05 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Bandyapadhyay", "Sayan", ""], ["Bhowmick", "Santanu", ""], ["Inamdar", "Tanmay", ""], ["Varadarajan", "Kasturi", ""]]}, {"id": "1707.05179", "submitter": "Danial Dervovic", "authors": "Danial Dervovic and Simone Severini", "title": "Weak Modular Product of Bipartite Graphs, Bicliques and Isomorphism", "comments": "Algorithm 1 (IvBE) is irreparably flawed. Moreover, Theorem 2,\n  concerning perfection of weak modular products of balanced, bipartite graphs\n  is incorrect. Thank you to an anonymous reviewer for pointing out these flaws\n  in the paper. We have now enumerated all perfect product graphs in the work\n  at arXiv:1809.09939", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 1978 theorem of Kozen states that two graphs on $n$ vertices are isomorphic\nif and only if there is a clique of size $n$ in the weak modular product\nbetween the two graphs. Restricting to bipartite graphs and considering\ncomplete bipartite subgraphs (bicliques) therein, we study the combinatorics of\nthe weak modular product. We identify cases where isomorphism is tractable\nusing this approach, which we call Isomorphism via Biclique Enumeration (IvBE).\nWe find that IvBE is polynomial for bipartite $2K_2$-free graphs and\nquasi-polynomial for families of bipartite graphs, where the largest induced\nmatching and largest induced crown graph grows slowly in $n$, that is,\n$O(\\mathrm{polylog }\\, n)$. Furthermore, as expected a straightforward\ncorollary of Kozen's theorem and Lov\\'{a}sz's sandwich theorem is if the weak\nmodular product between two graphs is perfect, then checking if the graphs are\nisomorphic is polynomial in $n$. However, we show that for balanced, bipartite\ngraphs this is only true in a few trivial cases. In doing so we define a new\ngraph product on bipartite graphs, the very weak modular product. The results\npertaining to bicliques in bipartite graphs proved here may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:25:48 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 10:20:10 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Dervovic", "Danial", ""], ["Severini", "Simone", ""]]}, {"id": "1707.05186", "submitter": "Guus Regts", "authors": "Viresh Patel and Guus Regts", "title": "Computing the number of induced copies of a fixed graph in a bounded\n  degree graph", "comments": "In this version we have improved the running time from $O(c^m\\cdot\n  n^2)$ to $O(c^m\\cdot n)$. To incorporate this, we had to apply some minor\n  changes, mostly in Section 2, leaving the overall approach essentially\n  unaffected. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that for any graph $H$ of order $m$ and any graph $G$\nof order $n$ and maximum degree $\\Delta$ one can compute the number of subsets\n$S$ of $V(G)$ that induces a graph isomorphic to $H $in time $O(c^m\\cdot n)$\nfor some constant $c = c(\\Delta) > 0$. This is essentially best possible.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 11:27:17 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 15:13:08 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Patel", "Viresh", ""], ["Regts", "Guus", ""]]}, {"id": "1707.05240", "submitter": "Jennifer Iglesias", "authors": "Jennifer Iglesias and R. Ravi", "title": "Coloring Down: $3/2$-approximation for special cases of the weighted\n  tree augmentation problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the weighted tree augmentation problem (TAP),\nwhere the goal is to augment a tree with a minimum cost set of edges such that\nthe graph becomes two edge connected. First we show that in weighted TAP, we\ncan restrict our attention to trees which are binary and where all the non-tree\nedges go between two leaves of the tree. We then give two different top-down\ncoloring algorithms. Both algorithms differ from known techniques for a\n3/2-approximation in unweighted TAP and current attempts to reach a\n3/2-approximation for weighted TAP.\n  The first algorithm we describe always gives a 2-approximation for any\nfeasible fractional solution to the natural edge cover LP. When the fractional\nsolution is such that all the edges with non-zero weight are at least $\\alpha$,\nthen this algorithm achieves a $2/(1+\\alpha)$-approximation. We propose a new\nconjecture on extreme points of LP relaxations for the problem, which if true,\nwill lead to a constructive proof of an integrality gap of at most 3/2 for\nweighted TAP. In the second algorithm, we introduce simple valid constraints to\nthe edge cover LP. In this algorithm, we focus on deficient edges, edges\ncovered to an extent less than 4/3 in the fractional solution. We show that for\nfractional feasible solutions, deficient edges occur in node-disjoint paths in\nthe tree. When the number of such paths is at most two, we give a top-down\ncoloring algorithm which decomposes 3/2 times the fractional solution into a\nconvex combination of integer solutions. We believe our algorithms will be\nuseful in eventually resolving the integrality gap of linear programming\nformulations for TAP.\n  We also investigate a variant of TAP where each edge in the solution must be\ncovered by a cycle of length three. We give a $\\Theta(\\log n)$-approximation\nalgorithm for this problem in the weighted case and a 4-approximation in the\nunweighted case.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 15:42:38 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Iglesias", "Jennifer", ""], ["Ravi", "R.", ""]]}, {"id": "1707.05387", "submitter": "Arash Haddadan", "authors": "Arash Haddadan, Alantha Newman, R. Ravi", "title": "Shorter tours and longer detours: Uniform covers and a bit beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the well known four-thirds conjecture for the traveling salesman\nproblem (TSP), we study the problem of {\\em uniform covers}. A graph $G=(V,E)$\nhas an $\\alpha$-uniform cover for TSP (2EC, respectively) if the everywhere\n$\\alpha$ vector (i.e. $\\{\\alpha\\}^{E}$) dominates a convex combination of\nincidence vectors of tours (2-edge-connected spanning multigraphs,\nrespectively). The polyhedral analysis of Christofides' algorithm directly\nimplies that a 3-edge-connected, cubic graph has a 1-uniform cover for TSP.\nSeb\\H{o} asked if such graphs have $(1-\\epsilon)$-uniform covers for TSP for\nsome $\\epsilon > 0$. Indeed, the four-thirds conjecture implies that such\ngraphs have 8/9-uniform covers. We show that these graphs have 18/19-uniform\ncovers for TSP. We also study uniform covers for 2EC and show that the\neverywhere 15/17 vector can be efficiently written as a convex combination of\n2-edge-connected spanning multigraphs.\n  For a weighted, 3-edge-connected, cubic graph, our results show that if the\neverywhere 2/3 vector is an optimal solution for the subtour linear programming\nrelaxation, then a tour with weight at most 27/19 times that of an optimal tour\ncan be found efficiently. Node-weighted, 3-edge-connected, cubic graphs fall\ninto this category. In this special case, we can apply our tools to obtain an\neven better approximation guarantee.\n  To extend our approach to input graphs that are 2-edge-connected, we present\na procedure to decompose an optimal solution for the subtour relaxation for TSP\ninto spanning, connected multigraphs that cover each 2-edge cut an even number\nof times. Using this decomposition, we obtain a 17/12-approximation algorithm\nfor minimum weight 2-edge-connected spanning subgraphs on subcubic,\nnode-weighted graphs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 20:30:21 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 15:58:47 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 18:59:16 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 01:27:27 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Haddadan", "Arash", ""], ["Newman", "Alantha", ""], ["Ravi", "R.", ""]]}, {"id": "1707.05404", "submitter": "Sushmita Gupta", "authors": "Sushmita Gupta, Saket Saurabh and Meirav Zehavi", "title": "On Treewidth and Stable Marriage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable Marriage is a fundamental problem to both computer science and\neconomics. Four well-known NP-hard optimization versions of this problem are\nthe Sex-Equal Stable Marriage (SESM), Balanced Stable Marriage (BSM),\nmax-Stable Marriage with Ties (max-SMT) and min-Stable Marriage with Ties\n(min-SMT) problems. In this paper, we analyze these problems from the viewpoint\nof Parameterized Complexity. We conduct the first study of these problems with\nrespect to the parameter treewidth. First, we study the treewidth $\\mathtt{tw}$\nof the primal graph. We establish that all four problems are W[1]-hard. In\nparticular, while it is easy to show that all four problems admit algorithms\nthat run in time $n^{O(\\mathtt{tw})}$, we prove that all of these algorithms\nare likely to be essentially optimal. Next, we study the treewidth\n$\\mathtt{tw}$ of the rotation digraph. In this context, the max-SMT and min-SMT\nare not defined. For both SESM and BSM, we design (non-trivial) algorithms that\nrun in time $2^{\\mathtt{tw}}n^{O(1)}$. Then, for both SESM and BSM, we also\nprove that unless SETH is false, algorithms that run in time\n$(2-\\epsilon)^{\\mathtt{tw}}n^{O(1)}$ do not exist for any fixed $\\epsilon>0$.\nWe thus present a comprehensive, complete picture of the behavior of central\noptimization versions of Stable Marriage with respect to treewidth.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 22:13:53 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Gupta", "Sushmita", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1707.05491", "submitter": "Marcin Pilipczuk", "authors": "Andrzej Grzesik, Tereza Klimo\\v{s}ov\\'a, Marcin Pilipczuk and\n  Micha{\\l} Pilipczuk", "title": "Polynomial-time algorithm for Maximum Weight Independent Set on\n  $P_6$-free graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic Maximum Weight Independent Set problem we are given a graph\n$G$ with a nonnegative weight function on vertices, and the goal is to find an\nindependent set in $G$ of maximum possible weight. While the problem is NP-hard\nin general, we give a polynomial-time algorithm working on any $P_6$-free\ngraph, that is, a graph that has no path on $6$ vertices as an induced\nsubgraph. This improves the polynomial-time algorithm on $P_5$-free graphs of\nLokshtanov et al. (SODA 2014), and the quasipolynomial-time algorithm on\n$P_6$-free graphs of Lokshtanov et al (SODA 2016). The main technical\ncontribution leading to our main result is enumeration of a polynomial-size\nfamily $\\mathcal{F}$ of vertex subsets with the following property: for every\nmaximal independent set $I$ in the graph, $\\mathcal{F}$ contains all maximal\ncliques of some minimal chordal completion of $G$ that does not add any edge\nincident to a vertex of $I$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 06:34:08 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 11:19:12 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 11:48:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Grzesik", "Andrzej", ""], ["Klimo\u0161ov\u00e1", "Tereza", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1707.05497", "submitter": "Maryam Aliakbarpour", "authors": "Maryam Aliakbarpour, Ilias Diakonikolas, Ronitt Rubinfeld", "title": "Differentially Private Identity and Closeness Testing of Discrete\n  Distributions", "comments": "Submitted, May 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problems of identity and closeness testing over a discrete\npopulation from random samples. Our goal is to develop efficient testers while\nguaranteeing Differential Privacy to the individuals of the population. We\ndescribe an approach that yields sample-efficient differentially private\ntesters for these problems. Our theoretical results show that there exist\nprivate identity and closeness testers that are nearly as sample-efficient as\ntheir non-private counterparts. We perform an experimental evaluation of our\nalgorithms on synthetic data. Our experiments illustrate that our private\ntesters achieve small type I and type II errors with sample size sublinear in\nthe domain size of the underlying distributions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 06:51:31 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Diakonikolas", "Ilias", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1707.05527", "submitter": "Seeun William Umboh", "authors": "Nikhil Bansal, Martin B\\\"ohm, Marek Eli\\'a\\v{s}, Grigorios Koumoutsos\n  and Seeun William Umboh", "title": "Nested Convex Bodies are Chaseable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Convex Body Chasing problem, we are given an initial point $v_0$ in\n$R^d$ and an online sequence of $n$ convex bodies $F_1, ..., F_n$. When we\nreceive $F_i$, we are required to move inside $F_i$. Our goal is to minimize\nthe total distance travelled. This fundamental online problem was first studied\nby Friedman and Linial (DCG 1993). They proved an $\\Omega(\\sqrt{d})$ lower\nbound on the competitive ratio, and conjectured that a competitive ratio\ndepending only on d is possible. However, despite much interest in the problem,\nthe conjecture remains wide open.\n  We consider the setting in which the convex bodies are nested: $F_1 \\supset\n... \\supset F_n$. The nested setting is closely related to extending the online\nLP framework of Buchbinder and Naor (ESA 2005) to arbitrary linear constraints.\nMoreover, this setting retains much of the difficulty of the general setting\nand captures an essential obstacle in resolving Friedman and Linial's\nconjecture. In this work, we give the first $f(d)$-competitive algorithm for\nchasing nested convex bodies in $R^d$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 08:56:28 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Bansal", "Nikhil", ""], ["B\u00f6hm", "Martin", ""], ["Eli\u00e1\u0161", "Marek", ""], ["Koumoutsos", "Grigorios", ""], ["Umboh", "Seeun William", ""]]}, {"id": "1707.05613", "submitter": "Rodrigo Canovas", "authors": "Rodrigo Canovas, Bastien Cazaux and Eric Rivals", "title": "The Compressed Overlap Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For analysing text algorithms, for computing superstrings, or for testing\nrandom number generators, one needs to compute all overlaps between any pairs\nof words in a given set. The positions of overlaps of a word onto itself, or of\ntwo words, are needed to compute the absence probability of a word in a random\ntext, or the numbers of common words shared by two random texts. In all these\ncontexts, one needs to compute or to query overlaps between pairs of words in a\ngiven set. For this sake, we designed COvI, a compressed overlap index that\nsupports multiple queries on overlaps: like computing the correlation of two\nwords, or listing pairs of words whose longest overlap is maximal among all\npossible pairs. COvI stores overlaps in a hierarchical and non-redundant\nmanner. We propose an implementation that can handle datasets of millions of\nwords and still answer queries efficiently. Comparison with a baseline solution\n- called FullAC - relying on the Aho-Corasick automaton shows that COvI\nprovides significant advantages. For similar construction times, COvI requires\nhalf the memory FullAC, and still solves complex queries much faster.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 13:52:49 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Canovas", "Rodrigo", ""], ["Cazaux", "Bastien", ""], ["Rivals", "Eric", ""]]}, {"id": "1707.05629", "submitter": "William Moses Jr.", "authors": "John Augustine, William K. Moses Jr", "title": "Dispersion of Mobile Robots: A Study of Memory-Time Trade-offs", "comments": "18 pages, conference version appeared in ICDCN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem in the domain of mobile robots, which we term\ndispersion. In this problem, $n$ robots are placed in an $n$ node graph\narbitrarily and must coordinate with each other to reach a final configuration\nsuch that exactly one robot is at each node. We study this problem through the\nlenses of minimizing the memory required by each robot and of minimizing the\nnumber of rounds required to achieve dispersion.\n  Dispersion is of interest due to its relationship to the problems of\nscattering on a graph, exploration using mobile robots, and load balancing on a\ngraph. Additionally, dispersion has an immediate real world application due to\nits relationship to the problem of recharging electric cars, as each car can be\nconsidered a robot and recharging stations and the roads connecting them nodes\nand edges of a graph respectively. Since recharging is a costly affair relative\nto traveling, we want to distribute these cars amongst the various available\nrecharge points where communication should be limited to car-to-car\ninteractions.\n  We provide lower bounds on both the memory required for robots to achieve\ndispersion and the minimum running time to achieve dispersion on any type of\ngraph. We then analyze the trade-offs between time and memory for various types\nof graphs. We provide time optimal and memory optimal algorithms for several\ntypes of graphs and show the power of a little memory in terms of running time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 14:11:02 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 15:56:36 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 13:56:47 GMT"}, {"version": "v4", "created": "Tue, 17 Jul 2018 10:49:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Augustine", "John", ""], ["Moses", "William K.", "Jr"]]}, {"id": "1707.05662", "submitter": "Vasilis Kontonis", "authors": "Dimitris Fotakis, Vasilis Kontonis, Piotr Krysta, and Paul Spirakis", "title": "Learning Powers of Poisson Binomial Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of simultaneously learning all powers of a Poisson\nBinomial Distribution (PBD). A PBD of order $n$ is the distribution of a sum of\n$n$ mutually independent Bernoulli random variables $X_i$, where\n$\\mathbb{E}[X_i] = p_i$. The $k$'th power of this distribution, for $k$ in a\nrange $[m]$, is the distribution of $P_k = \\sum_{i=1}^n X_i^{(k)}$, where each\nBernoulli random variable $X_i^{(k)}$ has $\\mathbb{E}[X_i^{(k)}] = (p_i)^k$.\nThe learning algorithm can query any power $P_k$ several times and succeeds in\nlearning all powers in the range, if with probability at least $1- \\delta$:\ngiven any $k \\in [m]$, it returns a probability distribution $Q_k$ with total\nvariation distance from $P_k$ at most $\\epsilon$. We provide almost matching\nlower and upper bounds on query complexity for this problem. We first show a\nlower bound on the query complexity on PBD powers instances with many distinct\nparameters $p_i$ which are separated, and we almost match this lower bound by\nexamining the query complexity of simultaneously learning all the powers of a\nspecial class of PBD's resembling the PBD's of our lower bound. We study the\nfundamental setting of a Binomial distribution, and provide an optimal\nalgorithm which uses $O(1/\\epsilon^2)$ samples. Diakonikolas, Kane and Stewart\n[COLT'16] showed a lower bound of $\\Omega(2^{1/\\epsilon})$ samples to learn the\n$p_i$'s within error $\\epsilon$. The question whether sampling from powers of\nPBDs can reduce this sampling complexity, has a negative answer since we show\nthat the exponential number of samples is inevitable. Having sampling access to\nthe powers of a PBD we then give a nearly optimal algorithm that learns its\n$p_i$'s. To prove our two last lower bounds we extend the classical minimax\nrisk definition from statistics to estimating functions of sequences of\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 15:02:43 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Kontonis", "Vasilis", ""], ["Krysta", "Piotr", ""], ["Spirakis", "Paul", ""]]}, {"id": "1707.05867", "submitter": "Tom Morgan", "authors": "Michael Mitzenmacher and Tom Morgan", "title": "Reconciling Graphs and Sets of Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a generalization of set reconciliation, where the goal is to\nreconcile sets of sets. Alice and Bob each have a parent set consisting of $s$\nchild sets, each containing at most $h$ elements from a universe of size $u$.\nThey want to reconcile their sets of sets in a scenario where the total number\nof differences between all of their child sets (under the minimum difference\nmatching between their child sets) is $d$. We give several algorithms for this\nproblem, and discuss applications to reconciliation problems on graphs,\ndatabases, and collections of documents. We specifically focus on graph\nreconciliation, providing protocols based on set of sets reconciliation for\nrandom graphs from $G(n,p)$ and for forests of rooted trees.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 21:32:11 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 15:40:48 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Morgan", "Tom", ""]]}, {"id": "1707.05945", "submitter": "Martin Grohe", "authors": "Martin Grohe and Nicole Schweikardt", "title": "First-Order Query Evaluation with Cardinality Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of first-order logic that allows to express cardinality\nconditions in a similar way as SQL's COUNT operator. The corresponding logic\nFOC(P) was introduced by Kuske and Schweikardt (LICS'17), who showed that query\nevaluation for this logic is fixed-parameter tractable on classes of structures\n(or databases) of bounded degree. In the present paper, we first show that the\nfixed-parameter tractability of FOC(P) cannot even be generalised to very\nsimple classes of structures of unbounded degree such as unranked trees or\nstrings with a linear order relation.\n  Then we identify a fragment FOC1(P) of FOC(P) which is still sufficiently\nstrong to express standard applications of SQL's COUNT operator. Our main\nresult shows that query evaluation for FOC1(P) is fixed-parameter tractable\nwith almost linear running time on nowhere dense classes of structures. As a\ncorollary, we also obtain a fixed-parameter tractable algorithm for counting\nthe number of tuples satisfying a query over nowhere dense classes of\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 06:12:34 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Grohe", "Martin", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "1707.05994", "submitter": "Andreas Schmid", "authors": "Andreas Schmid and Jens M. Schmidt", "title": "Computing Tutte Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tutte paths are one of the most successful tools for attacking Hamiltonicity\nproblems in planar graphs. Unfortunately, results based on them are\nnon-constructive, as their proofs inherently use an induction on overlapping\nsubgraphs and these overlaps hinder to bound the running time to a polynomial.\nFor special cases however, computational results of Tutte paths are known: For\n4-connected planar graphs, Tutte paths are in fact Hamiltonian paths and Chiba\nand Nishizeki showed how to compute such paths in linear time. For 3-connected\nplanar graphs, Tutte paths have a more complicated structure, and it has only\nrecently been shown that they can be computed in polynomial time. However,\nTutte paths are defined for general 2-connected planar graphs and this is what\nmost applications need. Unfortunately, no computational results are known. We\ngive the first efficient algorithm that computes a Tutte path (for the general\ncase of 2-connected planar graphs). One of the strongest existence results\nabout such Tutte paths is due to Sanders, which allows to prescribe the end\nvertices and an intermediate edge of the desired path. Encompassing and\nstrengthening all previous computational results on Tutte paths, we show how to\ncompute this special Tutte path efficiently. Our method refines both, the\nresults of Thomassen and Sanders, and avoids overlapping subgraphs by using a\nnovel iterative decomposition along 2-separators. Finally, we show that our\nalgorithm runs in quadratic time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 09:43:06 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Schmid", "Andreas", ""], ["Schmidt", "Jens M.", ""]]}, {"id": "1707.06011", "submitter": "Pawel Gawrychowski", "authors": "Pawe{\\l} Gawrychowski and Jakub {\\L}opusza\\'nski", "title": "Better Labeling Schemes for Nearest Common Ancestors through\n  Minor-Universal Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A labeling scheme for nearest common ancestors assigns a distinct binary\nstring, called the label, to every node of a tree, so that given the labels of\ntwo nodes (and no further information about the topology of the tree) we can\ncompute the label of their nearest common ancestor. The goal is to make the\nlabels as short as possible. Alstrup, Gavoille, Kaplan, and Rauhe [Theor.\nComput. Syst. 37(3):441-456 2004] showed that $O(\\log n)$-bit labels are\nenough. More recently, Alstrup, Halvorsen, and Larsen [SODA 2014] refined this\nto only $2.772\\log n$, and provided a lower bound of $1.008\\log n$.\n  We connect designing a labeling scheme for nearest common ancestors to the\nexistence of a tree, called a minor-universal tree, that contains every tree on\n$n$ nodes as a topological minor. Even though it is not clear if a labeling\nscheme must be based on such a notion, we argue that the existing schemes can\nbe reformulated as such, and it allows us to obtain clean and good bounds on\nthe length of the labels. As the main upper bound, we show that $2.318\\log\nn$-bit labels are enough. Surprisingly, the notion of a minor-universal tree\nfor binary trees on $n$ nodes has been already used in a different context by\nHrubes et al. [CCC 2010], and Young, Chu, and Wong [J. ACM 46(3):416-435, 1999]\nintroduced a closely related notion of a universal tree. On the lower bound\nside, we show that the size of any minor-universal tree for trees on $n$ nodes\nis $\\Omega(n^{2.174})$. This highlights a natural limitation for all approaches\nbased on such trees. Our lower bound technique also implies that the size of\nany universal tree in the sense of Young et al. is $\\Omega(n^{2.185})$, thus\ndramatically improves their lower bound of $\\Omega(n\\log n)$. We complement the\nexistential results with a generic transformation that decreases the query time\nto constant in any scheme based on a minor-universal tree.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 10:45:41 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["\u0141opusza\u0144ski", "Jakub", ""]]}, {"id": "1707.06063", "submitter": "Jacob Holm", "authors": "Aaron Bernstein, Jacob Holm, Eva Rotenberg", "title": "Online Bipartite Matching with Amortized $O(\\log^2 n)$ Replacements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online bipartite matching problem with replacements, all the vertices\non one side of the bipartition are given, and the vertices on the other side\narrive one by one with all their incident edges. The goal is to maintain a\nmaximum matching while minimizing the number of changes (replacements) to the\nmatching. We show that the greedy algorithm that always takes the shortest\naugmenting path from the newly inserted vertex (denoted the SAP protocol) uses\nat most amortized $O(\\log^2 n)$ replacements per insertion, where $n$ is the\ntotal number of vertices inserted. This is the first analysis to achieve a\npolylogarithmic number of replacements for \\emph{any} replacement strategy,\nalmost matching the $\\Omega(\\log n)$ lower bound. The previous best strategy\nknown achieved amortized $O(\\sqrt{n})$ replacements [Bosek, Leniowski,\nSankowski, Zych, FOCS 2014]. For the SAP protocol in particular, nothing better\nthan then trivial $O(n)$ bound was known except in special cases.\n  Our analysis immediately implies the same upper bound of $O(\\log^2 n)$\nreassignments for the capacitated assignment problem, where each vertex on the\nstatic side of the bipartition is initialized with the capacity to serve a\nnumber of vertices.\n  We also analyze the problem of minimizing the maximum server load. We show\nthat if the final graph has maximum server load $L$, then the SAP protocol\nmakes amortized $O( \\min\\{L \\log^2 n , \\sqrt{n}\\log n\\})$ reassignments. We\nalso show that this is close to tight because $\\Omega(\\min\\{L, \\sqrt{n}\\})$\nreassignments can be necessary.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 13:03:10 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 13:47:25 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 22:05:30 GMT"}, {"version": "v4", "created": "Fri, 4 May 2018 08:23:21 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Bernstein", "Aaron", ""], ["Holm", "Jacob", ""], ["Rotenberg", "Eva", ""]]}, {"id": "1707.06068", "submitter": "Anton Eremeev", "authors": "Anton V. Eremeev, Alexander V. Kelmanov, Artem V. Pyatkin and Igor A.\n  Ziegler", "title": "On Finding Maximum Cardinality Subset of Vectors with a Constraint on\n  Normalized Squared Length of Vectors Sum", "comments": "To appear in Proceedings of the 6th International Conference on\n  Analysis of Images, Social Networks, and Texts (AIST'2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of finding a maximum cardinality\nsubset of vectors, given a constraint on the normalized squared length of\nvectors sum. This problem is closely related to Problem 1 from (Eremeev,\nKel'manov, Pyatkin, 2016). The main difference consists in swapping the\nconstraint with the optimization criterion.\n  We prove that the problem is NP-hard even in terms of finding a feasible\nsolution. An exact algorithm for solving this problem is proposed. The\nalgorithm has a pseudo-polynomial time complexity in the special case of the\nproblem, where the dimension of the space is bounded from above by a constant\nand the input data are integer. A computational experiment is carried out,\nwhere the proposed algorithm is compared to COINBONMIN solver, applied to a\nmixed integer quadratic programming formulation of the problem. The results of\nthe experiment indicate superiority of the proposed algorithm when the\ndimension of Euclidean space is low, while the COINBONMIN has an advantage for\nlarger dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 13:05:46 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Eremeev", "Anton V.", ""], ["Kelmanov", "Alexander V.", ""], ["Pyatkin", "Artem V.", ""], ["Ziegler", "Igor A.", ""]]}, {"id": "1707.06114", "submitter": "Piotr Micek", "authors": "Stefan Felsner, Tam\\'as M\\'esz\\'aros and Piotr Micek", "title": "Boolean dimension and tree-width", "comments": "one more reference added; paper revised along the suggestion of three\n  reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dimension is a key measure of complexity of partially ordered sets. Small\ndimension allows succinct encoding. Indeed if $P$ has dimension $d$, then to\nknow whether $x \\leq y$ in $P$ it is enough to check whether $x\\leq y$ in each\nof the $d$ linear extensions of a witnessing realizer. Focusing on the encoding\naspect Ne\\v{s}et\\v{r}il and Pudl\\'{a}k defined a more expressive version of\ndimension. A poset $P$ has boolean dimension at most $d$ if it is possible to\ndecide whether $x \\leq y$ in $P$ by looking at the relative position of $x$ and\n$y$ in only $d$ permutations of the elements of $P$. We prove that posets with\ncover graphs of bounded tree-width have bounded boolean dimension. This stays\nin contrast with the fact that there are posets with cover graphs of tree-width\nthree and arbitrarily large dimension. This result might be a step towards a\nresolution of the long-standing open problem: Do planar posets have bounded\nboolean dimension?\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 14:28:50 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 14:00:50 GMT"}, {"version": "v3", "created": "Mon, 20 Aug 2018 18:13:58 GMT"}, {"version": "v4", "created": "Tue, 24 Sep 2019 16:11:07 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 16:26:20 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Felsner", "Stefan", ""], ["M\u00e9sz\u00e1ros", "Tam\u00e1s", ""], ["Micek", "Piotr", ""]]}, {"id": "1707.06126", "submitter": "Hendrik Fichtenberger", "authors": "Hendrik Fichtenberger, Reut Levi, Yadu Vasudev, Maximilian W\\\"otzel", "title": "A Sublinear Tester for Outerplanarity (and Other Forbidden Minors) With\n  One-Sided Error", "comments": "extended to testing outerplanarity, full version of ICALP paper", "journal-ref": "45th International Colloquium on Automata, Languages, and\n  Programming (ICALP), pages 52:1-52:14, 2018", "doi": "10.4230/LIPIcs.ICALP.2018.52", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider one-sided error property testing of $\\mathcal{F}$-minor freeness\nin bounded-degree graphs for any finite family of graphs $\\mathcal{F}$ that\ncontains a minor of $K_{2,k}$, the $k$-circus graph, or the $(k\\times 2)$-grid\nfor any $k\\in\\mathbb{N}$. This includes, for instance, testing whether a graph\nis outerplanar or a cactus graph. The query complexity of our algorithm in\nterms of the number of vertices in the graph, $n$, is $\\tilde{O}(n^{2/3} /\n\\epsilon^5)$. Czumaj et~al.\\ showed that cycle-freeness and $C_k$-minor\nfreeness can be tested with query complexity $\\tilde{O}(\\sqrt{n})$ by using\nrandom walks, and that testing $H$-minor freeness for any $H$ that contains a\ncycles requires $\\Omega(\\sqrt{n})$ queries. In contrast to these results, we\nanalyze the structure of the graph and show that either we can find a subgraph\nof sublinear size that includes the forbidden minor $H$, or we can find a pair\nof disjoint subsets of vertices whose edge-cut is large, which induces an\n$H$-minor.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 14:44:55 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 12:31:46 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 12:16:38 GMT"}, {"version": "v4", "created": "Wed, 8 Aug 2018 08:07:45 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Levi", "Reut", ""], ["Vasudev", "Yadu", ""], ["W\u00f6tzel", "Maximilian", ""]]}, {"id": "1707.06212", "submitter": "Martin N\\\"agele", "authors": "Martin N\\\"agele, Benny Sudakov and Rico Zenklusen", "title": "Submodular Minimization Under Congruency Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function minimization (SFM) is a fundamental and efficiently\nsolvable problem class in combinatorial optimization with a multitude of\napplications in various fields. Surprisingly, there is only very little known\nabout constraint types under which SFM remains efficiently solvable. The\narguably most relevant non-trivial constraint class for which polynomial SFM\nalgorithms are known are parity constraints, i.e., optimizing only over sets of\nodd (or even) cardinality. Parity constraints capture classical combinatorial\noptimization problems like the odd-cut problem, and they are a key tool in a\nrecent technique to efficiently solve integer programs with a constraint matrix\nwhose subdeterminants are bounded by two in absolute value.\n  We show that efficient SFM is possible even for a significantly larger class\nthan parity constraints, by introducing a new approach that combines techniques\nfrom Combinatorial Optimization, Combinatorics, and Number Theory. In\nparticular, we can show that efficient SFM is possible over all sets (of any\ngiven lattice) of cardinality r mod m, as long as m is a constant prime power.\nThis covers generalizations of the odd-cut problem with open complexity status,\nand with relevance in the context of integer programming with higher\nsubdeterminants. To obtain our results, we establish a connection between the\ncorrectness of a natural algorithm, and the inexistence of set systems with\nspecific combinatorial properties. We introduce a general technique to disprove\nthe existence of such set systems, which allows for obtaining extensions of our\nresults beyond the above-mentioned setting. These extensions settle two open\nquestions raised by Geelen and Kapadia [Combinatorica, 2017] in the context of\ncomputing the girth and cogirth of certain types of binary matroids.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:30:23 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 22:28:04 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["N\u00e4gele", "Martin", ""], ["Sudakov", "Benny", ""], ["Zenklusen", "Rico", ""]]}, {"id": "1707.06311", "submitter": "Jacob Holm", "authors": "Jacob Holm, Eva Rotenberg, Mikkel Thorup", "title": "Dynamic Bridge-Finding in $\\tilde{O}(\\log ^2 n)$ Amortized Time", "comments": "v1 Submitted to SODA'18 v2 Added note about improvement to\n  biconnectivity v3 Small changes. Drop unproven claim about finding first k\n  bridges in O(k) additional time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic fully-dynamic data structure for maintaining\ninformation about the bridges in a graph. We support updates in\n$\\tilde{O}((\\log n)^2)$ amortized time, and can find a bridge in the component\nof any given vertex, or a bridge separating any two given vertices, in $O(\\log\nn / \\log \\log n)$ worst case time. Our bounds match the current best for bounds\nfor deterministic fully-dynamic connectivity up to $\\log\\log n$ factors. The\nprevious best dynamic bridge finding was an $\\tilde{O}((\\log n)^3)$ amortized\ntime algorithm by Thorup [STOC2000], which was a bittrick-based improvement on\nthe $O((\\log n)^4)$ amortized time algorithm by Holm et al.[STOC98, JACM2001].\n  Our approach is based on a different and purely combinatorial improvement of\nthe algorithm of Holm et al., which by itself gives a new combinatorial\n$\\tilde{O}((\\log n)^3)$ amortized time algorithm. Combining it with Thorup's\nbittrick, we get down to the claimed $\\tilde{O}((\\log n)^2)$ amortized time.\n  Essentially the same new trick can be applied to the biconnectivity data\nstructure from [STOC98, JACM2001], improving the amortized update time to\n$\\tilde{O}((\\log n)^3)$.\n  We also offer improvements in space. We describe a general trick which\napplies to both of our new algorithms, and to the old ones, to get down to\nlinear space, where the previous best use $O(m + n\\log n\\log\\log n)$. Finally,\nwe show how to obtain $O(\\log n/\\log \\log n)$ query time, matching the optimal\ntrade-off between update and query time.\n  Our result yields an improved running time for deciding whether a unique\nperfect matching exists in a static graph.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 22:16:51 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 14:06:23 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 12:36:18 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Holm", "Jacob", ""], ["Rotenberg", "Eva", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1707.06343", "submitter": "Quanquan Liu", "authors": "Erik D. Demaine, Quanquan C. Liu", "title": "Inapproximability of the Standard Pebble Game and Hard to Pebble Graphs", "comments": "Preliminary version in WADS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pebble games are single-player games on DAGs involving placing and moving\npebbles on nodes of the graph according to a certain set of rules. The goal is\nto pebble a set of target nodes using a minimum number of pebbles. In this\npaper, we present a possibly simpler proof of the result in [CLNV15] and\nstrengthen the result to show that it is PSPACE-hard to determine the minimum\nnumber of pebbles to an additive $n^{1/3-\\epsilon}$ term for all $\\epsilon >\n0$, which improves upon the currently known additive constant hardness of\napproximation [CLNV15] in the standard pebble game. We also introduce a family\nof explicit, constant indegree graphs with $n$ nodes where there exists a graph\nin the family such that using constant $k$ pebbles requires $\\Omega(n^k)$ moves\nto pebble in both the standard and black-white pebble games. This independently\nanswers an open question summarized in [Nor15] of whether a family of DAGs\nexists that meets the upper bound of $O(n^k)$ moves using constant $k$ pebbles\nwith a different construction than that presented in [AdRNV17].\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 02:18:28 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Demaine", "Erik D.", ""], ["Liu", "Quanquan C.", ""]]}, {"id": "1707.06364", "submitter": "Nikhil Srivastava", "authors": "Nikhil Srivastava and Luca Trevisan", "title": "An Alon-Boppana Type Bound for Weighted Graphs and Lowerbounds for\n  Spectral Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the following Alon-Boppana type theorem for general (not necessarily\nregular) weighted graphs: if $G$ is an $n$-node weighted undirected graph of\naverage combinatorial degree $d$ (that is, $G$ has $dn/2$ edges) and girth $g>\n2d^{1/8}+1$, and if $\\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\lambda_n$ are the\neigenvalues of the (non-normalized) Laplacian of $G$, then \\[ \\frac\n{\\lambda_n}{\\lambda_2} \\geq 1 + \\frac 4{\\sqrt d} - O \\left( \\frac 1{d^{\\frac\n58} }\\right) \\] (The Alon-Boppana theorem implies that if $G$ is unweighted and\n$d$-regular, then $\\frac {\\lambda_n}{\\lambda_2} \\geq 1 + \\frac 4{\\sqrt d} -\nO\\left( \\frac 1 d \\right)$ if the diameter is at least $d^{1.5}$.)\n  Our result implies a lower bound for spectral sparsifiers. A graph $H$ is a\nspectral $\\epsilon$-sparsifier of a graph $G$ if \\[ L(G) \\preceq L(H) \\preceq\n(1+\\epsilon) L(G) \\] where $L(G)$ is the Laplacian matrix of $G$ and $L(H)$ is\nthe Laplacian matrix of $H$. Batson, Spielman and Srivastava proved that for\nevery $G$ there is an $\\epsilon$-sparsifier $H$ of average degree $d$ where\n$\\epsilon \\approx \\frac {4\\sqrt 2}{\\sqrt d}$ and the edges of $H$ are a\n(weighted) subset of the edges of $G$. Batson, Spielman and Srivastava also\nshow that the bound on $\\epsilon$ cannot be reduced below $\\approx \\frac\n2{\\sqrt d}$ when $G$ is a clique; our Alon-Boppana-type result implies that\n$\\epsilon$ cannot be reduced below $\\approx \\frac 4{\\sqrt d}$ when $G$ comes\nfrom a family of expanders of super-constant degree and super-constant girth.\n  The method of Batson, Spielman and Srivastava proves a more general result,\nabout sparsifying sums of rank-one matrices, and their method applies to an\n\"online\" setting. We show that for the online matrix setting the $4\\sqrt 2 /\n\\sqrt d$ bound is tight, up to lower order terms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 03:46:36 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Srivastava", "Nikhil", ""], ["Trevisan", "Luca", ""]]}, {"id": "1707.06374", "submitter": "Gonzalo Navarro", "authors": "Gonzalo Navarro", "title": "Document Listing on Repetitive Collections with Guaranteed Performance", "comments": "Extended version of CPM'17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider document listing on string collections, that is, finding in which\nstrings a given pattern appears. In particular, we focus on repetitive\ncollections: a collection of size $N$ over alphabet $[1,\\sigma]$ is composed of\n$D$ copies of a string of size $n$, and $s$ edits are applied on ranges of\ncopies. We introduce the first document listing index with size\n$\\tilde{O}(n+s)$, precisely $O((n\\log\\sigma+s\\log^2 N)\\log D)$ bits, and with\nuseful worst-case time guarantees: Given a pattern of length $m$, the index\nreports the $\\ndoc>0$ strings where it appears in time $O(m\\log^{1+\\epsilon} N\n\\cdot \\ndoc)$, for any constant $\\epsilon>0$ (and tells in time $O(m\\log N)$ if\n$\\ndoc=0$). Our technique is to augment a range data structure that is commonly\nused on grammar-based indexes, so that instead of retrieving all the pattern\noccurrences, it computes useful summaries on them. We show that the idea has\nindependent interest: we introduce the first grammar-based index that, on a\ntext $T[1,N]$ with a grammar of size $r$, uses $O(r\\log N)$ bits and counts the\nnumber of occurrences of a pattern $P[1,m]$ in time $O(m^2 + m\\log^{2+\\epsilon}\nr)$, for any constant $\\epsilon>0$. We also give the first index using\n$O(z\\log(N/z)\\log N)$ bits, where $T$ is parsed by Lempel-Ziv into $z$ phrases,\ncounting occurrences in time $O(m\\log^{2+\\epsilon} N)$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 05:01:22 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 22:33:45 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 17:28:02 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Navarro", "Gonzalo", ""]]}, {"id": "1707.06391", "submitter": "William Moses Jr.", "authors": "Ankush Agarwalla, John Augustine, William K. Moses Jr., Madhav Sankar\n  K., Arvind Krishna Sridhar", "title": "Deterministic Dispersion of Mobile Robots in Dynamic Rings", "comments": "21 pages, 10 figures, concise version of paper to appear in ICDCN\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of dispersion of mobile robots on dynamic\nrings. The problem of dispersion of $n$ robots on an $n$ node graph, introduced\nby Augustine and Moses Jr. [1], requires robots to coordinate with each other\nand reach a configuration where exactly one robot is present on each node. This\nproblem has real world applications and applies whenever we want to minimize\nthe total cost of $n$ agents sharing $n$ resources, located at various places,\nsubject to the constraint that the cost of an agent moving to a different\nresource is comparatively much smaller than the cost of multiple agents sharing\na resource (e.g. smart electric cars sharing recharge stations). The study of\nthis problem also provides indirect benefits to the study of scattering on\ngraphs, the study of exploration by mobile robots, and the study of load\nbalancing on graphs.\n  We solve the problem of dispersion in the presence of two types of dynamism\nin the underlying graph: (i) vertex permutation and (ii) 1-interval\nconnectivity. We introduce the notion of vertex permutation dynamism and have\nit mean that for a given set of nodes, in every round, the adversary ensures a\nring structure is maintained, but the connections between the nodes may change.\nWe use the idea of 1-interval connectivity from Di Luna et al. [10], where for\na given ring, in each round, the adversary chooses at most one edge to remove.\n  We assume robots have full visibility and present asymptotically time optimal\nalgorithms to achieve dispersion in the presence of both types of dynamism when\nrobots have chirality. When robots do not have chirality, we present\nasymptotically time optimal algorithms to achieve dispersion subject to certain\nconstraints. Finally, we provide impossibility results for dispersion when\nrobots have no visibility.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 06:46:15 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 03:29:44 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 13:50:46 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Agarwalla", "Ankush", ""], ["Augustine", "John", ""], ["Moses", "William K.", "Jr."], ["K.", "Madhav Sankar", ""], ["Sridhar", "Arvind Krishna", ""]]}, {"id": "1707.06499", "submitter": "Andreas Emil Feldmann", "authors": "Rajesh Chitnis, Andreas Emil Feldmann, Pasin Manurangsi", "title": "Parameterized Approximation Algorithms for Bidirected Steiner Network\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Directed Steiner Network (DSN) problem takes as input a directed\nedge-weighted graph $G=(V,E)$ and a set $\\mathcal{D}\\subseteq V\\times V$ of $k$\ndemand pairs. The aim is to compute the cheapest network $N\\subseteq G$ for\nwhich there is an $s\\to t$ path for each $(s,t)\\in\\mathcal{D}$. It is known\nthat this problem is notoriously hard as there is no\n$k^{1/4-o(1)}$-approximation algorithm under Gap-ETH, even when parametrizing\nthe runtime by $k$ [Dinur & Manurangsi, ITCS 2018]. In light of this, we\nsystematically study several special cases of DSN and determine their\nparameterized approximability for the parameter $k$.\n  For the bi-DSN$_\\text{Planar}$ problem, the aim is to compute a solution\n$N\\subseteq G$ whose cost is at most that of an optimum planar solution in a\nbidirected graph $G$, i.e., for every edge $uv$ of $G$ the reverse edge $vu$\nexists and has the same weight. This problem is a generalization of several\nwell-studied special cases. Our main result is that this problem admits a\nparameterized approximation scheme (PAS) for $k$. We also prove that our result\nis tight in the sense that (a) the runtime of our PAS cannot be significantly\nimproved, and (b) it is unlikely that a PAS exists for any generalization of\nbi-DSN$_\\text{Planar}$, unless FPT=W[1].\n  One important special case of DSN is the Strongly Connected Steiner Subgraph\n(SCSS) problem, for which the solution network $N\\subseteq G$ needs to strongly\nconnect a given set of $k$ terminals. It has been observed before that for SCSS\na parameterized $2$-approximation exists when parameterized by $k$ [Chitnis et\nal., IPEC 2013]. We give a tight inapproximability result by showing that for\n$k$ no parameterized $(2-\\varepsilon)$-approximation algorithm exists under\nGap-ETH. Additionally we show that when restricting the input of SCSS to\nbidirected graphs, the problem remains NP-hard but becomes FPT for $k$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 13:33:43 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 12:01:14 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 15:46:39 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 18:07:04 GMT"}, {"version": "v5", "created": "Wed, 2 Sep 2020 13:08:58 GMT"}, {"version": "v6", "created": "Wed, 13 Jan 2021 12:46:55 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Feldmann", "Andreas Emil", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1707.06503", "submitter": "Gregory Gutin", "authors": "Bin Sheng, Ruijuan Li, Gregory Gutin", "title": "The Euler and Chinese Postman Problems on 2-Arc-Colored Digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous Chinese Postman Problem (CPP) is polynomial time solvable on both\nundirected and directed graphs. Gutin et al. [Discrete Applied Math 217 (2016)]\ngeneralized these results by proving that CPP on $c$-edge-colored graphs is\npolynomial time solvable for every $c\\geq 2$. In CPP on weighted edge-colored\ngraphs $G$, we wish to find a minimum weight properly colored closed walk\ncontaining all edges of $G$ (a walk is properly colored if every two\nconsecutive edges are of different color, including the last and first edges in\na closed walk). In this paper, we consider CPP on arc-colored digraphs (for\nproperly colored closed directed walks), and provide a polynomial-time\nalgorithm for the problem on weighted 2-arc-colored digraphs. This is a\nsomewhat surprising result since it is NP-complete to decide whether a\n2-arc-colored digraph has a properly colored directed cycle [Gutin et al.,\nDiscrete Math 191 (1998)]. To obtain the polynomial-time algorithm, we\ncharacterize 2-arc-colored digraphs containing properly colored Euler trails.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 13:45:36 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Sheng", "Bin", ""], ["Li", "Ruijuan", ""], ["Gutin", "Gregory", ""]]}, {"id": "1707.06606", "submitter": "Tatiana Starikovskaya", "authors": "Eldar Fischer, Fr\\'ed\\'eric Magniez, Tatiana Starikovskaya", "title": "Improved bounds for testing Dyck languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of deciding membership in Dyck\nlanguages, a fundamental family of context-free languages, comprised of\nwell-balanced strings of parentheses. In this problem we are given a string of\nlength $n$ in the alphabet of parentheses of $m$ types and must decide if it is\nwell-balanced. We consider this problem in the property testing setting, where\none would like to make the decision while querying as few characters of the\ninput as possible.\n  Property testing of strings for Dyck language membership for $m=1$, with a\nnumber of queries independent of the input size $n$, was provided in [Alon,\nKrivelevich, Newman and Szegedy, SICOMP 2001]. Property testing of strings for\nDyck language membership for $m \\ge 2$ was first investigated in [Parnas, Ron\nand Rubinfeld, RSA 2003]. They showed an upper bound and a lower bound for\ndistinguishing strings belonging to the language from strings that are far (in\nterms of the Hamming distance) from the language, which are respectively (up to\npolylogarithmic factors) the $2/3$ power and the $1/11$ power of the input size\n$n$.\n  Here we improve the power of $n$ in both bounds. For the upper bound, we\nintroduce a recursion technique, that together with a refinement of the methods\nin the original work provides a test for any power of $n$ larger than $2/5$.\nFor the lower bound, we introduce a new problem called Truestring Equivalence,\nwhich is easily reducible to the $2$-type Dyck language property testing\nproblem. For this new problem, we show a lower bound of $n$ to the power of\n$1/5$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:56:54 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Fischer", "Eldar", ""], ["Magniez", "Fr\u00e9d\u00e9ric", ""], ["Starikovskaya", "Tatiana", ""]]}, {"id": "1707.06631", "submitter": "Pavel Kolev", "authors": "Ruben Becker, Vincenzo Bonifaci, Andreas Karrenbauer, Pavel Kolev,\n  Kurt Mehlhorn", "title": "Two Results on Slime Mold Computations", "comments": null, "journal-ref": "Theoretical Computer Science, 773:79-106, 2019", "doi": "10.1016/j.tcs.2018.08.027", "report-no": null, "categories": "cs.DS math.DS math.OC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two results on slime mold computations. In wet-lab experiments\n(Nature'00) by Nakagaki et al. the slime mold Physarum polycephalum\ndemonstrated its ability to solve shortest path problems. Biologists proposed a\nmathematical model, a system of differential equations, for the slime's\nadaption process (J. Theoretical Biology'07). It was shown that the process\nconvergences to the shortest path (J. Theoretical Biology'12) for all graphs.\nWe show that the dynamics actually converges for a much wider class of\nproblems, namely undirected linear programs with a non-negative cost vector.\n  Combinatorial optimization researchers took the dynamics describing slime\nbehavior as an inspiration for an optimization method and showed that its\ndiscretization can $\\varepsilon$-approximately solve linear programs with\npositive cost vector (ITCS'16). Their analysis requires a feasible starting\npoint, a step size depending linearly on $\\varepsilon$, and a number of steps\nwith quartic dependence on $\\mathrm{opt}/(\\varepsilon\\Phi)$, where $\\Phi$ is\nthe difference between the smallest cost of a non-optimal basic feasible\nsolution and the optimal cost ($\\mathrm{opt}$).\n  We give a refined analysis showing that the dynamics initialized with any\nstrongly dominating point converges to the set of optimal solutions. Moreover,\nwe strengthen the convergence rate bounds and prove that the step size is\nindependent of $\\varepsilon$, and the number of steps depends logarithmically\non $1/\\varepsilon$ and quadratically on $\\mathrm{opt}/\\Phi$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 17:43:38 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 12:21:01 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 19:32:01 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Becker", "Ruben", ""], ["Bonifaci", "Vincenzo", ""], ["Karrenbauer", "Andreas", ""], ["Kolev", "Pavel", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1707.06665", "submitter": "Sergey Pupyrev", "authors": "Igor Kabiljo and Brian Karrer and Mayank Pundir and Sergey Pupyrev and\n  Alon Shalita and Alessandro Presta and Yaroslav Akhremtsev", "title": "Social Hash Partitioner: A Scalable Distributed Hypergraph Partitioner", "comments": "Proceedings of the VLDB Endowment 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and implement a distributed algorithm for balanced $k$-way\nhypergraph partitioning that minimizes fanout, a fundamental hypergraph\nquantity also known as the communication volume and ($k-1$)-cut metric, by\noptimizing a novel objective called probabilistic fanout. This choice allows a\nsimple local search heuristic to achieve comparable solution quality to the\nbest existing hypergraph partitioners.\n  Our algorithm is arbitrarily scalable due to a careful design that controls\ncomputational complexity, space complexity, and communication. In practice, we\ncommonly process hypergraphs with billions of vertices and hyperedges in a few\nhours. We explain how the algorithm's scalability, both in terms of hypergraph\nsize and bucket count, is limited only by the number of machines available. We\nperform an extensive comparison to existing distributed hypergraph partitioners\nand find that our approach is able to optimize hypergraphs roughly $100$ times\nbigger on the same set of machines.\n  We call the resulting tool Social Hash Partitioner (SHP), and accompanying\nthis paper, we open-source the most scalable version based on recursive\nbisection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 18:17:36 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Kabiljo", "Igor", ""], ["Karrer", "Brian", ""], ["Pundir", "Mayank", ""], ["Pupyrev", "Sergey", ""], ["Shalita", "Alon", ""], ["Presta", "Alessandro", ""], ["Akhremtsev", "Yaroslav", ""]]}, {"id": "1707.06778", "submitter": "Ran Ben Basat", "authors": "Ran Ben Basat, Gil Einziger, Roy Friedman, Marcelo Caggiani Luizelli,\n  Erez Waisbard", "title": "Constant Time Updates in Hierarchical Heavy Hitters", "comments": "To appear in ACM SIGCOMM 2017", "journal-ref": null, "doi": "10.1145/3098822.3098832", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring tasks, such as anomaly and DDoS detection, require identifying\nfrequent flow aggregates based on common IP prefixes. These are known as\n\\emph{hierarchical heavy hitters} (HHH), where the hierarchy is determined\nbased on the type of prefixes of interest in a given application. The per\npacket complexity of existing HHH algorithms is proportional to the size of the\nhierarchy, imposing significant overheads.\n  In this paper, we propose a randomized constant time algorithm for HHH. We\nprove probabilistic precision bounds backed by an empirical evaluation. Using\nfour real Internet packet traces, we demonstrate that our algorithm indeed\nobtains comparable accuracy and recall as previous works, while running up to\n62 times faster. Finally, we extended Open vSwitch (OVS) with our algorithm and\nshowed it is able to handle 13.8 million packets per second. In contrast,\nincorporating previous works in OVS only obtained 2.5 times lower throughput.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 07:16:42 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Basat", "Ran Ben", ""], ["Einziger", "Gil", ""], ["Friedman", "Roy", ""], ["Luizelli", "Marcelo Caggiani", ""], ["Waisbard", "Erez", ""]]}, {"id": "1707.06779", "submitter": "Yongjie Yang", "authors": "Wenjun Li, Huan Peng and Yongjie Yang", "title": "Improved Kernels and Algorithms for Claw and Diamond Free Edge Deletion\n  Based on Refined Observations", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the {claw, diamond}-free edge deletion problem, we are given a graph $G$\nand an integer $k>0$, the question is whether there are at most $k$ edges whose\ndeletion results in a graph without claws and diamonds as induced graphs. Based\non some refined observations, we propose a kernel of $O(k^3)$ vertices and\n$O(k^4)$ edges, significantly improving the previous kernel of $O(k^{12})$\nvertices and $O(k^{24})$ edges. In addition, we derive an $O^*(3.792^k)$-time\nalgorithm for the {claw, diamond}-free edge deletion problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 07:19:03 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 12:48:43 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Wenjun", ""], ["Peng", "Huan", ""], ["Yang", "Yongjie", ""]]}, {"id": "1707.06808", "submitter": "Andreas Emil Feldmann", "authors": "Andreas Emil Feldmann and Daniel Marx", "title": "The Complexity Landscape of Fixed-Parameter Directed Steiner Network\n  Problems", "comments": "Appeared at the 43rd International Colloquium on Automata, Languages,\n  and Programming (ICALP 2016)", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2016.27", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a directed graph $G$ and a list $(s_1,t_1),\\dots,(s_d,t_d)$ of terminal\npairs, the Directed Steiner Network problem asks for a minimum-cost subgraph of\n$G$ that contains a directed $s_i\\to t_i$ path for every $1\\le i \\le k$. The\nspecial case Directed Steiner Tree (when we ask for paths from a root $r$ to\nterminals $t_1,\\dots,t_d$) is known to be fixed-parameter tractable\nparameterized by the number of terminals, while the special case Strongly\nConnected Steiner Subgraph (when we ask for a path from every $t_i$ to every\nother $t_j$) is known to be W[1]-hard. We systematically explore the complexity\nlandscape of directed Steiner problems to fully understand which other special\ncases are FPT or W[1]-hard. Formally, if $\\mathcal{H}$ is a class of directed\ngraphs, then we look at the special case of Directed Steiner Network where the\nlist $(s_1,t_1),\\dots,(s_d,t_d)$ of requests form a directed graph that is a\nmember of $\\mathcal{H}$. Our main result is a complete characterization of the\nclasses $\\mathcal{H}$ resulting in fixed-parameter tractable special cases: we\nshow that if every pattern in $\\mathcal{H}$ has the combinatorial property of\nbeing \"transitively equivalent to a bounded-length caterpillar with a bounded\nnumber of extra edges,\" then the problem is FPT, and it is W[1]-hard for every\nrecursively enumerable $\\mathcal{H}$ not having this property. This complete\ndichotomy unifies and generalizes the known results showing that Directed\nSteiner Tree is FPT [Dreyfus and Wagner, Networks 1971], $q$-Root Steiner Tree\nis FPT for constant $q$ [Such\\'y, WG 2016], Strongly Connected Steiner Subgraph\nis W[1]-hard [Guo et al., SIAM J. Discrete Math. 2011], and Directed Steiner\nNetwork is solvable in polynomial-time for constant number of terminals\n[Feldman and Ruhl, SIAM J. Comput. 2006], and moreover reveals a large\ncontinent of tractable cases that were not known before.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 09:11:13 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 15:40:31 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 09:07:20 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 11:26:12 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Feldmann", "Andreas Emil", ""], ["Marx", "Daniel", ""]]}, {"id": "1707.06814", "submitter": "Johan von Tangen Sivertsen M.Sc", "authors": "Tobias Christiani, Rasmus Pagh and Johan Sivertsen", "title": "Scalable and robust set similarity join", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set similarity join is a fundamental and well-studied database operator. It\nis usually studied in the exact setting where the goal is to compute all pairs\nof sets that exceed a given similarity threshold (measured e.g. as Jaccard\nsimilarity). But set similarity join is often used in settings where 100%\nrecall may not be important --- indeed, where the exact set similarity join is\nitself only an approximation of the desired result set.\n  We present a new randomized algorithm for set similarity join that can\nachieve any desired recall up to 100%, and show theoretically and empirically\nthat it significantly improves on existing methods. The present\nstate-of-the-art exact methods are based on prefix-filtering, the performance\nof which depends on the data set having many rare tokens. Our method is robust\nagainst the absence of such structure in the data. At 90% recall our algorithm\nis often more than an order of magnitude faster than state-of-the-art exact\nmethods, depending on how well a data set lends itself to prefix filtering. Our\nexperiments on benchmark data sets also show that the method is several times\nfaster than comparable approximate methods. Our algorithm makes use of recent\ntheoretical advances in high-dimensional sketching and indexing that we believe\nto be of wider relevance to the data engineering community.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 09:50:36 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 14:39:14 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 12:11:58 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Christiani", "Tobias", ""], ["Pagh", "Rasmus", ""], ["Sivertsen", "Johan", ""]]}, {"id": "1707.06844", "submitter": "Michael Bekos", "authors": "Patrizio Angelini, Michael A. Bekos", "title": "Hierarchical Partial Planarity", "comments": "Conference version appeared in WG2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider graphs whose edges are associated with a degree of\n{\\em importance}, which may depend on the type of connections they represent or\non how recently they appeared in the scene, in a streaming setting. The goal is\nto construct layouts of these graphs in which the readability of an edge is\nproportional to its importance, that is, more important edges have fewer\ncrossings. We formalize this problem and study the case in which there exist\nthree different degrees of importance. We give a polynomial-time testing\nalgorithm when the graph induced by the two most important sets of edges is\nbiconnected. We also discuss interesting relationships with other\nconstrained-planarity problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 11:17:27 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Angelini", "Patrizio", ""], ["Bekos", "Michael A.", ""]]}, {"id": "1707.06855", "submitter": "Stefan Walzer", "authors": "Stefan Walzer", "title": "Load Thresholds for Cuckoo Hashing with Overlapping Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dietzfelbinger and Weidling [DW07] proposed a natural variation of cuckoo\nhashing where each of $cn$ objects is assigned $k = 2$ intervals of size $\\ell$\nin a linear (or cyclic) hash table of size $n$ and both start points are chosen\nindependently and uniformly at random. Each object must be placed into a table\ncell within its intervals, but each cell can only hold one object. Experiments\nsuggested that this scheme outperforms the variant with blocks in which\nintervals are aligned at multiples of $\\ell$. In particular, the load threshold\nis higher, i.e. the load $c$ that can be achieved with high probability. For\ninstance, Lehman and Panigrahy [LP09] empirically observed the threshold for\n$\\ell = 2$ to be around $96.5\\%$ as compared to roughly $89.7\\%$ using blocks.\nThey managed to pin down the asymptotics of the thresholds for large $\\ell$,\nbut the precise values resisted rigorous analysis.\n  We establish a method to determine these load thresholds for all $\\ell \\geq\n2$, and, in fact, for general $k \\geq 2$. For instance, for $k = \\ell = 2$ we\nget $\\approx 96.4995\\%$. The key tool we employ is an insightful and general\ntheorem due to Leconte, Lelarge, and Massouli\\'e [LLM13], which adapts methods\nfrom statistical physics to the world of hypergraph orientability. In effect,\nthe orientability thresholds for our graph families are determined by belief\npropagation equations for certain graph limits. As a side note we provide\nexperimental evidence suggesting that placements can be constructed in linear\ntime with loads close to the threshold using an adapted version of an algorithm\nby Khosla [Kho13].\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 11:41:33 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 15:11:40 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 14:47:21 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Walzer", "Stefan", ""]]}, {"id": "1707.06867", "submitter": "Johan von Tangen Sivertsen M.Sc", "authors": "Johan Sivertsen", "title": "Fast Nearest Neighbor Preserving Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an analog to the Fast Johnson-Lindenstrauss Transform for Nearest\nNeighbor Preserving Embeddings in $\\ell_2$. These are sparse, randomized\nembeddings that preserve the (approximate) nearest neighbors. The\ndimensionality of the embedding space is bounded not by the size of the\nembedded set n, but by its doubling dimension {\\lambda}. For most large\nreal-world datasets this will mean a considerably lower-dimensional embedding\nspace than possible when preserving all distances. The resulting embeddings can\nbe used with existing approximate nearest neighbor data structures to yield\nspeed improvements.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 12:34:49 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Sivertsen", "Johan", ""]]}, {"id": "1707.07057", "submitter": "Vladyslav Sokol", "authors": "Vladyslav Sokol, Ante \\'Custi\\'c, Abraham P. Punnen, Binay\n  Bhattacharya", "title": "Bilinear Assignment Problem: Large Neighborhoods and Experimental\n  Analysis of Algorithms", "comments": "Corrected typos. Figures are now vector graphics (instead of raster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bilinear assignment problem (BAP) is a generalization of the well-known\nquadratic assignment problem (QAP). In this paper, we study the problem from\nthe computational analysis point of view. Several classes of neigborhood\nstructures are introduced for the problem along with some theoretical analysis.\nThese neighborhoods are then explored within a local search and a variable\nneighborhood search frameworks with multistart to generate robust heuristic\nalgorithms. Results of systematic experimental analysis have been presented\nwhich divulge the effectiveness of our algorithms. In addition, we present\nseveral very fast construction heuristics. Our experimental results disclosed\nsome interesting properties of the BAP model, different from those of\ncomparable models. This is the first thorough experimental analysis of\nalgorithms on BAP. We have also introduced benchmark test instances that can be\nused for future experiments on exact and heuristic algorithms for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 22:17:44 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 00:50:15 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Sokol", "Vladyslav", ""], ["\u0106usti\u0107", "Ante", ""], ["Punnen", "Abraham P.", ""], ["Bhattacharya", "Binay", ""]]}, {"id": "1707.07334", "submitter": "Pan Peng", "authors": "Morteza Monemizadeh, S. Muthukrishnan, Pan Peng, Christian Sohler", "title": "Testable Bounded Degree Graph Properties Are Random Order Streamable", "comments": "A preliminary version was presented at the 44th International\n  Colloquium on Automata, Languages, and Programming (ICALP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study which property testing and sublinear time algorithms can be\ntransformed into graph streaming algorithms for random order streams. Our main\nresult is that for bounded degree graphs, any property that is constant-query\ntestable in the adjacency list model can be tested with constant space in a\nsingle-pass in random order streams. Our result is obtained by estimating the\ndistribution of local neighborhoods of the vertices on a random order graph\nstream using constant space.\n  We then show that our approach can also be applied to constant time\napproximation algorithms for bounded degree graphs in the adjacency list model:\nAs an example, we obtain a constant-space single-pass random order streaming\nalgorithms for approximating the size of a maximum matching with additive error\n$\\epsilon n$ ($n$ is the number of nodes).\n  Our result establishes for the first time that a large class of sublinear\nalgorithms can be simulated in random order streams, while $\\Omega(n)$ space is\nneeded for many graph streaming problems for adversarial orders.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 19:35:37 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Monemizadeh", "Morteza", ""], ["Muthukrishnan", "S.", ""], ["Peng", "Pan", ""], ["Sohler", "Christian", ""]]}, {"id": "1707.07657", "submitter": "Ehsan Sadrfaridpour", "authors": "E. Sadrfaridpour, T. Razzaghi, I. Safro", "title": "Engineering fast multilevel support vector machines", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of solving nonlinear support vector machine\n(SVM) is prohibitive on large-scale data. In particular, this issue becomes\nvery sensitive when the data represents additional difficulties such as highly\nimbalanced class sizes. Typically, nonlinear kernels produce significantly\nhigher classification quality to linear kernels but introduce extra kernel and\nmodel parameters which requires computationally expensive fitting. This\nincreases the quality but also reduces the performance dramatically. We\nintroduce a generalized fast multilevel framework for regular and weighted SVM\nand discuss several versions of its algorithmic components that lead to a good\ntrade-off between quality and time. Our framework is implemented using PETSc\nwhich allows an easy integration with scientific computing tasks. The\nexperimental results demonstrate significant speed up compared to the\nstate-of-the-art nonlinear SVM libraries.\n  Reproducibility: our source code, documentation and parameters are available\nat https:// github.com/esadr/mlsvm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 17:32:37 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 00:41:30 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 02:37:58 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Sadrfaridpour", "E.", ""], ["Razzaghi", "T.", ""], ["Safro", "I.", ""]]}, {"id": "1707.07727", "submitter": "Jarno Alanko", "authors": "Jarno Alanko and Tuukka Norri", "title": "Greedy Shortest Common Superstring Approximation in Compact Space", "comments": "13 Pages, 3 figures, accepted to the 24th International Symposium on\n  String Processing and Information Retrieval (SPIRE 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of strings, the shortest common superstring problem is to find\nthe shortest possible string that contains all the input strings. The problem\nis NP-hard, but a lot of work has gone into designing approximation algorithms\nfor solving the problem. We present the first time and space efficient\nimplementation of the classic greedy heuristic which merges strings in\ndecreasing order of overlap length. Our implementation works in $O(n \\log\n\\sigma)$ time and bits of space, where $n$ is the total length of the input\nstrings in characters, and $\\sigma$ is the size of the alphabet. After index\nconstruction, a practical implementation of our algorithm uses roughly $5 n\n\\log \\sigma$ bits of space and reasonable time for a real dataset that consists\nof DNA fragments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 19:47:22 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:15:29 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Alanko", "Jarno", ""], ["Norri", "Tuukka", ""]]}, {"id": "1707.07899", "submitter": "Andrzej Jaszkiewicz", "authors": "Andrzej Jaszkiewicz", "title": "Many-Objective Pareto Local Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Pareto Local Search Algorithm for the many-objective\ncombinatorial optimization. Pareto Local Search proved to be a very effective\ntool in the case of the bi-objective combinatorial optimization and it was used\nin a number of the state-of-the-art algorithms for problems of this kind. On\nthe other hand, the standard Pareto Local Search algorithm becomes very\ninefficient for problems with more than two objectives. We build an effective\nMany-Objective Pareto Local Search algorithm using three new mechanisms: the\nefficient update of large Pareto archives with ND-Tree data structure, a new\nmechanism for the selection of the promising solutions for the neighborhood\nexploration, and a partial exploration of the neighborhoods. We apply the\nproposed algorithm to the instances of two different problems, i.e. the\ntraveling salesperson problem and the traveling salesperson problem with\nprofits with up to 5 objectives showing high effectiveness of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 10:29:04 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 14:00:25 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Jaszkiewicz", "Andrzej", ""]]}, {"id": "1707.08039", "submitter": "Shi Li", "authors": "Shi Li", "title": "Scheduling to Minimize Total Weighted Completion Time via Time-Indexed\n  Linear Programming Relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximation algorithms for scheduling problems with the objective\nof minimizing total weighted completion time, under identical and related\nmachine models with job precedence constraints. We give algorithms that improve\nupon many previous 15 to 20-year-old state-of-art results. A major theme in\nthese results is the use of time-indexed linear programming relaxations. These\nare natural relaxations for their respective problems, but surprisingly are not\nstudied in the literature.\n  We also consider the scheduling problem of minimizing total weighted\ncompletion time on unrelated machines. The recent breakthrough result of\n[Bansal-Srinivasan-Svensson, STOC 2016] gave a $(1.5-c)$-approximation for the\nproblem, based on some lift-and-project SDP relaxation. Our main result is that\na $(1.5 - c)$-approximation can also be achieved using a natural and\nconsiderably simpler time-indexed LP relaxation for the problem. We hope this\nrelaxation can provide new insights into the problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 15:26:08 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Li", "Shi", ""]]}, {"id": "1707.08092", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan, Mark Rudelson", "title": "Restricted Eigenvalue from Stable Rank with Applications to Sparse\n  Linear Regression", "comments": "27 pages, Updated paper with stronger results, Corrected Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional settings, where the data dimension ($d$) far exceeds the\nnumber of observations ($n$), are common in many statistical and machine\nlearning applications. Methods based on $\\ell_1$-relaxation, such as Lasso, are\nvery popular for sparse recovery in these settings. Restricted Eigenvalue (RE)\ncondition is among the weakest, and hence the most general, condition in\nliterature imposed on the Gram matrix that guarantees nice statistical\nproperties for the Lasso estimator. It is natural to ask: what families of\nmatrices satisfy the RE condition? Following a line of work in this area, we\nconstruct a new broad ensemble of dependent random design matrices that have an\nexplicit RE bound. Our construction starts with a fixed (deterministic) matrix\n$X \\in \\mathbb{R}^{n \\times d}$ satisfying a simple stable rank condition, and\nwe show that a matrix drawn from the distribution $X \\Phi^\\top \\Phi$, where\n$\\Phi \\in \\mathbb{R}^{m \\times d}$ is a subgaussian random matrix, with high\nprobability, satisfies the RE condition. This construction allows incorporating\na fixed matrix that has an easily {\\em verifiable} condition into the design\nprocess, and allows for generation of {\\em compressed} design matrices that\nhave a lower storage requirement than a standard design matrix. We give two\napplications of this construction to sparse linear regression problems,\nincluding one to a compressed sparse regression setting where the regression\nalgorithm only has access to a compressed representation of a fixed design\nmatrix $X$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 17:15:18 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 03:15:26 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 15:00:12 GMT"}, {"version": "v4", "created": "Sat, 17 Feb 2018 23:44:07 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Rudelson", "Mark", ""]]}, {"id": "1707.08186", "submitter": "Andrew Twigg", "authors": "Andrew Twigg", "title": "Persistent Cache-oblivious Streaming Indexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [SPAA2007], Bender et al. define a streaming B-tree (or index) as one that\nsupports updates in amortized $o(1)$ IOs, and present a structure achieving\namortized $O((\\log N)/B)$ IOs and queries in $O(\\log N)$ IOs. We extend their\nresult to the partially-persistent case. For a version $v$, let $N_v$ be the\nnumber of keys accessible at $v$ and $N$ be the total number of updates. We\ngive a data structure using space $O(N)$, supporting updates to a leaf version\n$v$ with $O((\\log N_{v})/B)$ amortized IOs and answering range queries\nreturning $Z$ elements with $O(\\log N_{v} + Z/B)$ IOs on average (where the\naverage is over all queries covering disjoint key ranges at a given version).\nThis is the first persistent `streaming' index we are aware of, i.e. that\nsupports updates in $o(1)$ IOs and supports efficient range queries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 19:43:06 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Twigg", "Andrew", ""]]}, {"id": "1707.08197", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui and Fabio Cunial", "title": "Fast Label Extraction in the CDAWG", "comments": "16 pages, 1 figure. In proceedings of the 24th International\n  Symposium on String Processing and Information Retrieval (SPIRE 2017). arXiv\n  admin note: text overlap with arXiv:1705.08640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compact directed acyclic word graph (CDAWG) of a string $T$ of length $n$\ntakes space proportional just to the number $e$ of right extensions of the\nmaximal repeats of $T$, and it is thus an appealing index for highly repetitive\ndatasets, like collections of genomes from similar species, in which $e$ grows\nsignificantly more slowly than $n$. We reduce from $O(m\\log{\\log{n}})$ to\n$O(m)$ the time needed to count the number of occurrences of a pattern of\nlength $m$, using an existing data structure that takes an amount of space\nproportional to the size of the CDAWG. This implies a reduction from\n$O(m\\log{\\log{n}}+\\mathtt{occ})$ to $O(m+\\mathtt{occ})$ in the time needed to\nlocate all the $\\mathtt{occ}$ occurrences of the pattern. We also reduce from\n$O(k\\log{\\log{n}})$ to $O(k)$ the time needed to read the $k$ characters of the\nlabel of an edge of the suffix tree of $T$, and we reduce from\n$O(m\\log{\\log{n}})$ to $O(m)$ the time needed to compute the matching\nstatistics between a query of length $m$ and $T$, using an existing\nrepresentation of the suffix tree based on the CDAWG. All such improvements\nderive from extracting the label of a vertex or of an arc of the CDAWG using a\nstraight-line program induced by the reversed CDAWG.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 20:16:50 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 05:12:24 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Cunial", "Fabio", ""]]}, {"id": "1707.08213", "submitter": "Lee Richardson", "authors": "Lee F. Richardson, William F. Eddy", "title": "The 2D Tree Sliding Window Discrete Fourier Transform", "comments": "15 pages, 4 figures, submitted to ACM TOMS", "journal-ref": "ACM Transactions on Mathematical Software, Vol. 45, No. 1, Article\n  12. Publication date: February 2019", "doi": "10.1145/3264426", "report-no": null, "categories": "cs.DS stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the 2D Sliding Window Discrete Fourier\nTransform (SWDFT). Our algorithm avoids repeating calculations in overlapping\nwindows by storing them in a tree data-structure based on the ideas of the\nCooley- Tukey Fast Fourier Transform (FFT). For an $N_0 \\times N_1$ array and\n$n_0 \\times n_1$ windows, our algorithm takes $O(N_0 N_1 n_0 n_1)$ operations.\nWe provide a C implementation of our algorithm for the Radix-2 case, compare\nours with existing algorithms, and show how our algorithm easily extends to\nhigher dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 20:48:46 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 18:27:27 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Richardson", "Lee F.", ""], ["Eddy", "William F.", ""]]}, {"id": "1707.08225", "submitter": "Henrique Stagni", "authors": "Carlos Hoppen, Yoshiharu Kohayakawa, Richard Lang, Hanno Lefmann,\n  Henrique Stagni", "title": "Estimating parameters associated with monotone properties", "comments": null, "journal-ref": "Combinator. Probab. Comp. 29 (2020) 616-632", "doi": "10.1017/S0963548320000048", "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been substantial interest in estimating the value of a graph\nparameter, i.e., of a real-valued function defined on the set of finite graphs,\nby querying a randomly sampled substructure whose size is independent of the\nsize of the input. Graph parameters that may be successfully estimated in this\nway are said to be testable or estimable, and the sample complexity\n$q_z=q_z(\\epsilon)$ of an estimable parameter $z$ is the size of a random\nsample of a graph $G$ required to ensure that the value of $z(G)$ may be\nestimated within an error of $\\epsilon$ with probability at least 2/3. In this\npaper, for any fixed monotone graph property\n$\\mathcal{P}=\\mbox{Forb}(\\mathcal{F})$, we study the sample complexity of\nestimating a bounded graph parameter $z_{\\mathcal{P}}$ that, for an input graph\n$G$, counts the number of spanning subgraphs of $G$ that satisfy $\\mathcal{P}$.\nTo improve upon previous upper bounds on the sample complexity, we show that\nthe vertex set of any graph that satisfies a monotone property $\\mathcal{P}$\nmay be partitioned equitably into a constant number of classes in such a way\nthat the cluster graph induced by the partition is not far from satisfying a\nnatural weighted graph generalization of $\\mathcal{P}$. Properties for which\nthis holds are said to be recoverable, and the study of recoverable properties\nmay be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 21:20:13 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Hoppen", "Carlos", ""], ["Kohayakawa", "Yoshiharu", ""], ["Lang", "Richard", ""], ["Lefmann", "Hanno", ""], ["Stagni", "Henrique", ""]]}, {"id": "1707.08238", "submitter": "Jieming Mao", "authors": "Xi Chen, Yuanzhi Li, Jieming Mao", "title": "A Nearly Instance Optimal Algorithm for Top-k Ranking under the\n  Multinomial Logit Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the active learning problem of top-$k$ ranking from multi-wise\ncomparisons under the popular multinomial logit model. Our goal is to identify\nthe top-$k$ items with high probability by adaptively querying sets for\ncomparisons and observing the noisy output of the most preferred item from each\ncomparison. To achieve this goal, we design a new active ranking algorithm\nwithout using any information about the underlying items' preference scores. We\nalso establish a matching lower bound on the sample complexity even when the\nset of preference scores is given to the algorithm. These two results together\nshow that the proposed algorithm is nearly instance optimal (similar to\ninstance optimal [FLN03], but up to polylog factors). Our work extends the\nexisting literature on rank aggregation in three directions. First, instead of\nstudying a static problem with fixed data, we investigate the top-$k$ ranking\nproblem in an active learning setting. Second, we show our algorithm is nearly\ninstance optimal, which is a much stronger theoretical guarantee. Finally, we\nextend the pairwise comparison to the multi-wise comparison, which has not been\nfully explored in ranking literature.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 22:03:21 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 14:44:22 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Chen", "Xi", ""], ["Li", "Yuanzhi", ""], ["Mao", "Jieming", ""]]}, {"id": "1707.08270", "submitter": "David Saulpic", "authors": "Amariah Becker, Philip N. Klein, David Saulpic", "title": "Polynomial-Time Approximation Schemes for k-Center and Bounded-Capacity\n  Vehicle Routing in Graphs with Bounded Highway Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of bounded highway dimension was developed to capture observed\nproperties of the metrics of road networks. We show that a graph with bounded\nhighway dimension, for any vertex, can be embedded into a a graph of bounded\ntreewidth in such a way that the distance between $u$ and $v$ is preserved up\nto an additive error of $\\epsilon$ times the distance from $u$ or $v$ to the\nselected vertex. We show that this theorem yields a PTAS for Bounded-Capacity\nVehicle Routing in graphs of bounded highway dimension. In this problem, the\ninput specifies a depot and a set of clients, each with a location and demand;\nthe output is a set of depot-to-depot tours, where each client is visited by\nsome tour and each tour covers at most $Q$ units of client demand. Our PTAS can\nbe extended to handle penalties for unvisited clients.\n  We extend this embedding result to handle a set $S$ of distinguished\nvertices. The treewidth depends on $|S|$, and the distance between $u$ and $v$\nis preserved up to an additive error of $\\epsilon$ times the distance from $u$\nand $v$ to $S$.\n  This embedding result implies a PTAS for Multiple Depot Bounded-Capacity\nVehicle Routing: the tours can go from one depot to another. The embedding\nresult also implies that, for fixed $k$, there is a PTAS for $k$-Center in\ngraphs of bounded highway dimension. In this problem, the goal is to minimize\n$d$ such that there exist $k$ vertices (the centers) such that every vertex is\nwithin distance $d$ of some center. Similarly, for fixed $k$, there is a PTAS\nfor $k$-Median in graphs of bounded highway dimension. In this problem, the\ngoal is to minimize the sum of distances to the $k$ centers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 01:43:56 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 22:12:33 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 18:17:41 GMT"}, {"version": "v4", "created": "Tue, 3 Oct 2017 17:45:27 GMT"}, {"version": "v5", "created": "Mon, 13 Nov 2017 16:58:38 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Becker", "Amariah", ""], ["Klein", "Philip N.", ""], ["Saulpic", "David", ""]]}, {"id": "1707.08272", "submitter": "Apurba Das", "authors": "Apurba Das, Srikanta Tirthapura", "title": "A Change-Sensitive Algorithm for Maintaining Maximal Bicliques in a\n  Dynamic Bipartite Graph", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maintenance of maximal bicliques from a dynamic bipartite\ngraph that changes over time due to the addition or deletion of edges. When the\nset of edges in a graph changes, we are interested in knowing the change in the\nset of maximal bicliques (the \"change\"), rather than in knowing the set of\nmaximal bicliques that remain unaffected. The challenge in an efficient\nalgorithm is to enumerate the change without explicitly enumerating the set of\nall maximal bicliques. In this work, we present (1) near-tight bounds on the\nmagnitude of change in the set of maximal bicliques of a graph, due to a change\nin the edge set (2) a \"change-sensitive\" algorithm for enumerating the change\nin the set of maximal bicliques, whose time complexity is proportional to the\nmagnitude of change that actually occurred in the set of maximal bicliques in\nthe graph. To our knowledge, these are the first algorithms for enumerating\nmaximal bicliques in a dynamic graph, with such provable performance\nguarantees. Our algorithms are easy to implement, and experimental results show\nthat their performance exceeds that of current baseline implementations by\norders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 02:01:22 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Das", "Apurba", ""], ["Tirthapura", "Srikanta", ""]]}, {"id": "1707.08300", "submitter": "Shinsaku Sakaue", "authors": "Shinsaku Sakaue, Masakazu Ishihata, Shin-ichi Minato", "title": "Practical Adversarial Combinatorial Bandit Algorithm via Compression of\n  Decision Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the adversarial combinatorial multi-armed bandit (CMAB) problem,\nwhose decision set can be exponentially large with respect to the number of\ngiven arms. To avoid dealing with such large decision sets directly, we propose\nan algorithm performed on a zero-suppressed binary decision diagram (ZDD),\nwhich is a compressed representation of the decision set. The proposed\nalgorithm achieves either $O(T^{2/3})$ regret with high probability or\n$O(\\sqrt{T})$ expected regret as the any-time guarantee, where $T$ is the\nnumber of past rounds. Typically, our algorithm works efficiently for CMAB\nproblems defined on networks. Experimental results show that our algorithm is\napplicable to various large adversarial CMAB instances including adaptive\nrouting problems on real-world networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 06:37:33 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Sakaue", "Shinsaku", ""], ["Ishihata", "Masakazu", ""], ["Minato", "Shin-ichi", ""]]}, {"id": "1707.08484", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Krzysztof Nowicki", "title": "MST in O(1) Rounds of the Congested Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed randomized algorithm finding Minimum Spanning Tree\n(MST) of a given graph in O(1) rounds, with high probability, in the Congested\nClique model. The input graph in the Congested Clique model is a graph of n\nnodes, where each node initially knows only its incident edges. The\ncommunication graph is a clique with limited edge bandwidth: each two nodes\n(not necessarily neighbours in the input graph) can exchange $O(\\log n)$ bits.\n  As in previous works, the key part of the MST algorithm is an efficient\nConnected Components (CC) algorithm. However, unlike the former approaches, we\ndo not aim at simulating the standard Boruvka algorithm, at least at initial\nstages of the CC algorithm. Instead, we develop a new technique which combines\nconnected components of sample sparse subgraphs of the input graph in order to\naccelerate the process of uncovering connected components of the original input\ngraph. More specifically, we develop a sparsification technique which reduces\nan initial CC problem in $O(1)$ rounds to its two restricted instances. The\nformer instance has a graph with maximal degree $O(\\log \\log n)$ as the input\n-- here our sample-combining technique helps. In the latter instance, a\npartition of the input graph into $O(n/\\log \\log n)$ connected components is\nknown. This gives an opportunity to apply previous algorithms to determine\nconnected components in $O(1)$ rounds.\n  Our result addresses the problem from and the $O(\\log \\log n)$ algorithm of\nLotker et al. [SPAA 2003; SICOMP 2005], improves over previous $O(\\log* n)$\nalgorithm of Ghaffari et al. [PODC 2016] and $O(\\log \\log \\log n)$ algorithm of\nHegeman et al. [PODC 2015] . It also determines $\\Theta(1)$ round complexity in\nthe congested clique for MST, as well as other graph problems, including\nbipartiteness, cut verification, s-t connectivity and cycle containment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:04:22 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 12:54:35 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 16:33:48 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Nowicki", "Krzysztof", ""]]}, {"id": "1707.08496", "submitter": "Keren Censor-Hillel", "authors": "Keren Censor-Hillel, Rina Levy and Hadas Shachnai", "title": "Fast Distributed Approximation for Max-Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a maximum cut is a fundamental task in many computational settings.\nSurprisingly, it has been insufficiently studied in the classic distributed\nsettings, where vertices communicate by synchronously sending messages to their\nneighbors according to the underlying graph, known as the $\\mathcal{LOCAL}$ or\n$\\mathcal{CONGEST}$ models. We amend this by obtaining almost optimal\nalgorithms for Max-Cut on a wide class of graphs in these models. In\nparticular, for any $\\epsilon > 0$, we develop randomized approximation\nalgorithms achieving a ratio of $(1-\\epsilon)$ to the optimum for Max-Cut on\nbipartite graphs in the $\\mathcal{CONGEST}$ model, and on general graphs in the\n$\\mathcal{LOCAL}$ model.\n  We further present efficient deterministic algorithms, including a\n$1/3$-approximation for Max-Dicut in our models, thus improving the best known\n(randomized) ratio of $1/4$. Our algorithms make non-trivial use of the greedy\napproach of Buchbinder et al. (SIAM Journal on Computing, 2015) for maximizing\nan unconstrained (non-monotone) submodular function, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:29:24 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Levy", "Rina", ""], ["Shachnai", "Hadas", ""]]}, {"id": "1707.08557", "submitter": "Derrek Yager", "authors": "Yu Wu, Gabriel Shindnes, Vaibhav Karve, Derrek Yager, Daniel B. Work,\n  Arnab Chakraborty, Richard B. Sowers", "title": "Congestion Barcodes: Exploring the Topology of Urban Congestion Using\n  Persistent Homology", "comments": "9 pages, 15 figures, Accepted to IEEE 20th International Conference\n  on Intelligent Transportation Systems 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DS math.AT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new method to quantify connectivity in transportation\nnetworks. Inspired by the field of topological data analysis, we propose a\nnovel approach to explore the robustness of road network connectivity in the\npresence of congestion on the roadway. The robustness of the pattern is\nsummarized in a congestion barcode, which can be constructed directly from\ntraffic datasets commonly used for navigation. As an initial demonstration, we\nillustrate the main technique on a publicly available traffic dataset in a\nneighborhood in New York City.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 00:12:43 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Wu", "Yu", ""], ["Shindnes", "Gabriel", ""], ["Karve", "Vaibhav", ""], ["Yager", "Derrek", ""], ["Work", "Daniel B.", ""], ["Chakraborty", "Arnab", ""], ["Sowers", "Richard B.", ""]]}, {"id": "1707.08684", "submitter": "Yixin Cao", "authors": "Yixin Cao", "title": "A Naive Algorithm for Feedback Vertex Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph on $n$ vertices and an integer $k$, the feedback vertex set\nproblem asks for the deletion of at most $k$ vertices to make the graph\nacyclic. We show that a greedy branching algorithm, which always branches on an\nundecided vertex with the largest degree, runs in single-exponential time,\ni.e., $O(c^k\\cdot n^2)$ for some constant $c$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 02:04:31 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 13:01:14 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Cao", "Yixin", ""]]}, {"id": "1707.08690", "submitter": "Yixin Cao", "authors": "Yixin Cao, Yuping Ke, Yota Otachi and Jie You", "title": "Vertex Deletion Problems on Chordal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Containing many classic optimization problems, the family of vertex deletion\nproblems has an important position in algorithm and complexity study. The\ncelebrated result of Lewis and Yannakakis gives a complete dichotomy of their\ncomplexity. It however has nothing to say about the case when the input graph\nis also special. This paper initiates a systematic study of vertex deletion\nproblems from one subclass of chordal graphs to another. We give\npolynomial-time algorithms or proofs of NP-completeness for most of the\nproblems. In particular, we show that the vertex deletion problem from chordal\ngraphs to interval graphs is NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 02:57:15 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 13:05:06 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Cao", "Yixin", ""], ["Ke", "Yuping", ""], ["Otachi", "Yota", ""], ["You", "Jie", ""]]}, {"id": "1707.08725", "submitter": "Cristian Frasinaru", "authors": "Cristian Frasinaru, Madalina Raschip", "title": "An Improved Subsumption Testing Algorithm for the Optimal-Size Sorting\n  Network Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new method for checking the subsumption relation for the\noptimal-size sorting network problem is described. The new approach is based on\ncreating a bipartite graph and modelling the subsumption test as the problem of\nenumerating all perfect matchings in this graph. Experiments showed significant\nimprovements over the previous approaches when considering the number of\nsubsumption checks and the time needed to find optimal-size sorting networks.\nWe were able to generate all the complete sets of filters for comparator\nnetworks with 9 channels, confirming that the 25-comparators sorting network is\noptimal. The running time was reduced more than 10 times, compared to the\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:05:21 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Frasinaru", "Cristian", ""], ["Raschip", "Madalina", ""]]}, {"id": "1707.08730", "submitter": "Ammar Daskin", "authors": "Ammar Daskin", "title": "A Quantum Approach to Subset-Sum and Similar Problems", "comments": "Missing references added, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the subset-sum problem by using a quantum heuristic\napproach similar to the verification circuit of quantum Arthur-Merlin games.\nUnder described certain assumptions, we show that the exact solution of the\nsubset sum problem my be obtained in polynomial time and the exponential\nspeed-up over the classical algorithms may be possible. We give a numerical\nexample and discuss the complexity of the approach and its further application\nto the knapsack problem.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:33:05 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 07:31:56 GMT"}, {"version": "v3", "created": "Sat, 16 Sep 2017 16:21:05 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 08:34:56 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Daskin", "Ammar", ""]]}, {"id": "1707.08769", "submitter": "Arnold Filtser", "authors": "Ittai Abraham, Shiri Chechik, Michael Elkin, Arnold Filtser, Ofer\n  Neiman", "title": "Ramsey Spanning Trees and their Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metric Ramsey problem asks for the largest subset $S$ of a metric space\nthat can be embedded into an ultrametric (more generally into a Hilbert space)\nwith a given distortion. Study of this problem was motivated as a non-linear\nversion of Dvoretzky theorem. Mendel and Naor 2007 devised the so called Ramsey\nPartitions to address this problem, and showed the algorithmic applications of\ntheir techniques to approximate distance oracles and ranking problems.\n  In this paper we study the natural extension of the metric Ramsey problem to\ngraphs, and introduce the notion of Ramsey Spanning Trees. We ask for the\nlargest subset $S\\subseteq V$ of a given graph $G=(V,E)$, such that there\nexists a spanning tree of $G$ that has small stretch for $S$. Applied\niteratively, this provides a small collection of spanning trees, such that each\nvertex has a tree providing low stretch paths to all other vertices. The union\nof these trees serves as a special type of spanner, a tree-padding spanner. We\nuse this spanner to devise the first compact stateless routing scheme with\n$O(1)$ routing decision time, and labels which are much shorter than in all\ncurrently existing schemes.\n  We first revisit the metric Ramsey problem, and provide a new deterministic\nconstruction. We prove that for every $k$, any $n$-point metric space has a\nsubset $S$ of size at least $n^{1-1/k}$ which embeds into an ultrametric with\ndistortion $8k$. This results improves the best previous result of Mendel and\nNaor that obtained distortion $128k$ and required randomization. In addition,\nit provides the state-of-the-art deterministic construction of a distance\noracle. Building on this result, we prove that for every $k$, any $n$-vertex\ngraph $G=(V,E)$ has a subset $S$ of size at least $n^{1-1/k}$, and a spanning\ntree of $G$, that has stretch $O(k \\log \\log n)$ between any point in $S$ and\nany point in $V$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 08:05:45 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Abraham", "Ittai", ""], ["Chechik", "Shiri", ""], ["Elkin", "Michael", ""], ["Filtser", "Arnold", ""], ["Neiman", "Ofer", ""]]}, {"id": "1707.08807", "submitter": "Pascal Su", "authors": "Fabian Kuhn, Konstantinos Panagiotou, Pascal Su", "title": "Nearest Common Ancestors: Universal Trees and Improved Labeling Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the nearest common ancestor (NCA) function in rooted trees. As\nthe main conceptual contribution, the paper introduces universal trees for the\nNCA function: For a given family of rooted trees, an NCA-universal tree $S$ is\na rooted tree such that any tree $T$ of the family can be embedded into $S$\nsuch that the embedding of the NCA in $T$ of two nodes of $T$ is equal to the\nNCA in $S$ of the embeddings of the two nodes.\n  As the main technical result we give explicit constructions of NCA-universal\ntrees of size $n^{2.318}$ for the family of rooted $n$-vertex trees and of size\n$n^{1.894}$ for the family of rooted binary $n$-vertex trees. A direct\nconsequence is the explicit construction of NCA-labeling schemes with labels of\nsize $2.318\\log_2 n$ and $1.894\\log_2 n$ for the two families of rooted trees.\nThis improves on the best known such labeling schemes established by Alstrup,\nHalvorsen and Larsen [SODA 2014].\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 10:05:33 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Kuhn", "Fabian", ""], ["Panagiotou", "Konstantinos", ""], ["Su", "Pascal", ""]]}, {"id": "1707.08861", "submitter": "Stefano Leucci", "authors": "Davide Bil\\`o, Feliciano Colella, Luciano Gual\\`a, Stefano Leucci,\n  Guido Proietti", "title": "Effective Edge-Fault-Tolerant Single-Source Spanners via Best (or Good)\n  Swap Edges", "comments": "15 pages, 4 figures, SIROCCO 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing \\emph{all best swap edges} (ABSE) of a spanning tree $T$ of a given\n$n$-vertex and $m$-edge undirected and weighted graph $G$ means to select, for\neach edge $e$ of $T$, a corresponding non-tree edge $f$, in such a way that the\ntree obtained by replacing $e$ with $f$ enjoys some optimality criterion (which\nis naturally defined according to some objective function originally addressed\nby $T$). Solving efficiently an ABSE problem is by now a classic algorithmic\nissue, since it conveys a very successful way of coping with a (transient)\n\\emph{edge failure} in tree-based communication networks: just replace the\nfailing edge with its respective swap edge, so as that the connectivity is\npromptly reestablished by minimizing the rerouting and set-up costs. In this\npaper, we solve the ABSE problem for the case in which $T$ is a\n\\emph{single-source shortest-path tree} of $G$, and our two selected swap\ncriteria aim to minimize either the \\emph{maximum} or the \\emph{average\nstretch} in the swap tree of all the paths emanating from the source. Having\nthese criteria in mind, the obtained structures can then be reviewed as\n\\emph{edge-fault-tolerant single-source spanners}. For them, we propose two\nefficient algorithms running in $O(m n +n^2 \\log n)$ and $O(m n \\log\n\\alpha(m,n))$ time, respectively, and we show that the guaranteed (either\nmaximum or average, respectively) stretch factor is equal to 3, and this is\ntight. Moreover, for the maximum stretch, we also propose an almost linear $O(m\n\\log \\alpha(m,n))$ time algorithm computing a set of \\emph{good} swap edges,\neach of which will guarantee a relative approximation factor on the maximum\nstretch of $3/2$ (tight) as opposed to that provided by the corresponding BSE.\nSurprisingly, no previous results were known for these two very natural swap\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 13:35:13 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Bil\u00f2", "Davide", ""], ["Colella", "Feliciano", ""], ["Gual\u00e0", "Luciano", ""], ["Leucci", "Stefano", ""], ["Proietti", "Guido", ""]]}, {"id": "1707.09225", "submitter": "Diego Ponce", "authors": "Diego Ponce, Justo Puerto, Federica Ricca, Andrea Scozzari", "title": "Mathematical Programming formulations for the efficient solution of the\n  $k$-sum approval voting problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of electing a committee among a set of\n$m$ candidates and on the basis of the preferences of a set of $n$ voters. We\nconsider the approval voting method in which each voter can approve as many\ncandidates as she/he likes by expressing a preference profile (boolean\n$m$-vector). In order to elect a committee, a voting rule must be established\nto `transform' the $n$ voters' profiles into a winning committee. The problem\nis widely studied in voting theory; for a variety of voting rules the problem\nwas shown to be computationally difficult and approximation algorithms and\nheuristic techniques were proposed in the literature. In this paper we follow\nan Ordered Weighted Averaging approach and study the $k$-sum approval voting\n(optimization) problem in the general case $1 \\leq k <n$. For this problem we\nprovide different mathematical programming formulations that allow us to solve\nit in an exact solution framework. We provide computational results showing\nthat our approach is efficient for medium-size test problems ($n$ up to 200,\n$m$ up to 60) since in all tested cases it was able to find the exact optimal\nsolution in very short computational times.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 13:34:23 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Ponce", "Diego", ""], ["Puerto", "Justo", ""], ["Ricca", "Federica", ""], ["Scozzari", "Andrea", ""]]}, {"id": "1707.09383", "submitter": "Matthew  Johnson", "authors": "Marthe Bonamy, Konrad K. Dabrowski, Carl Feghali, Matthew Johnson,\n  Daniel Paulusma", "title": "Independent Feedback Vertex Sets for Graphs of Bounded Diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Near-Bipartiteness problem is that of deciding whether or not the\nvertices of a graph can be partitioned into sets $A$ and $B$, where $A$ is an\nindependent set and $B$ induces a forest. The set $A$ in such a partition is\nsaid to be an independent feedback vertex set. Yang and Yuan proved that\nNear-Bipartiteness is polynomial-time solvable for graphs of diameter 2 and\nNP-complete for graphs of diameter 4. We show that Near-Bipartiteness is\nNP-complete for graphs of diameter 3, resolving their open problem. We also\ngeneralise their result for diameter 2 by proving that even the problem of\ncomputing a minimum independent feedback vertex is polynomial-time solvable for\ngraphs of diameter 2.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 19:26:46 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Bonamy", "Marthe", ""], ["Dabrowski", "Konrad K.", ""], ["Feghali", "Carl", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1707.09402", "submitter": "Matthew  Johnson", "authors": "Marthe Bonamy, Konrad K. Dabrowski, Carl Feghali, Matthew Johnson,\n  Daniel Paulusma", "title": "Independent Feedback Vertex Set for $P_5$-free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NP-complete problem Feedback Vertex Set is that of deciding whether or\nnot it is possible, for a given integer $k\\geq 0$, to delete at most $k$\nvertices from a given graph so that what remains is a forest. The variant in\nwhich the deleted vertices must form an independent set is called Independent\nFeedback Vertex Set and is also NP-complete. In fact, even deciding if an\nindependent feedback vertex set exists is NP-complete and this problem is\nclosely related to the $3$-Colouring problem, or equivalently, to the problem\nof deciding whether or not a graph has an independent odd cycle transversal,\nthat is, an independent set of vertices whose deletion makes the graph\nbipartite. We initiate a systematic study of the complexity of Independent\nFeedback Vertex Set for $H$-free graphs. We prove that it is NP-complete if $H$\ncontains a claw or cycle. Tamura, Ito and Zhou proved that it is\npolynomial-time solvable for $P_4$-free graphs. We show that it remains\npolynomial-time solvable for $P_5$-free graphs. We prove analogous results for\nthe Independent Odd Cycle Transversal problem, which asks whether or not a\ngraph has an independent odd cycle transversal of size at most $k$ for a given\ninteger $k\\geq 0$. Finally, in line with our underlying research aim, we\ncompare the complexity of Independent Feedback Vertex Set for $H$-free graphs\nwith the complexity of $3$-Colouring, Independent Odd Cycle Transversal and\nother related problems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 20:17:45 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Bonamy", "Marthe", ""], ["Dabrowski", "Konrad K.", ""], ["Feghali", "Carl", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1707.09545", "submitter": "Sushmita Gupta", "authors": "Sushmita Gupta, Sanjukta Roy, Saket Saurabh, and Meirav Zehavi", "title": "Balanced Stable Marriage: How Close is Close Enough?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Balanced Stable Marriage problem is a central optimization version of the\nclassic Stable Marriage problem. Here, the output cannot be an arbitrary stable\nmatching, but one that balances between the dissatisfaction of the two parties,\nmen and women. We study Balanced Stable Marriage from the viewpoint of\nParameterized Complexity. Our \"above guarantee parameterizations\" are arguably\nthe most natural parameterizations of the problem at hand. Indeed, our\nparameterizations precisely fit the scenario where there exists a stable\nmarriage that both parties would accept, that is, where the satisfaction of\neach party is \"close\" to the best it can hope for. Furthermore, our\nparameterizations accurately draw the line between tractability and\nintractability with respect to the target value.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 17:58:35 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Gupta", "Sushmita", ""], ["Roy", "Sanjukta", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1707.09757", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Jafari Siavoshani, Farzad Parvaresh, Ali Pourmiri, Seyed Pooya\n  Shariatpanahi", "title": "Coded Load Balancing in Cache Networks", "comments": "The paper is 12 pages and contains 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider load balancing problem in a cache network consisting of\nstorage-enabled servers forming a distributed content delivery scenario.\nPreviously proposed load balancing solutions cannot perfectly balance out\nrequests among servers, which is a critical issue in practical networks.\nTherefore, in this paper, we investigate a coded cache content placement where\ncoded chunks of original files are stored in servers based on the files\npopularity distribution. In our scheme, upon each request arrival at the\ndelivery phase, by dispatching enough coded chunks to the request origin from\nthe nearest servers, the requested file can be decoded.\n  Here, we show that if $n$ requests arrive randomly at $n$ servers, the\nproposed scheme results in the maximum load of $O(1)$ in the network. This\nresult is shown to be valid under various assumptions for the underlying\nnetwork topology. Our results should be compared to the maximum load of two\nbaseline schemes, namely, nearest replica and power of two choices strategies,\nwhich are $\\Theta(\\log n)$ and $\\Theta(\\log \\log n)$, respectively. This\nfinding shows that using coding, results in a considerable load balancing\nperformance improvement, without compromising communications cost performance.\nThis is confirmed by performing extensive simulation results, in non-asymptotic\nregimes as well.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 08:36:30 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 09:43:17 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Siavoshani", "Mahdi Jafari", ""], ["Parvaresh", "Farzad", ""], ["Pourmiri", "Ali", ""], ["Shariatpanahi", "Seyed Pooya", ""]]}, {"id": "1707.09817", "submitter": "Matthew  Johnson", "authors": "Marthe Bonamy, Konrad K. Dabrowski, Carl Feghali, Matthew Johnson,\n  Daniel Paulusma", "title": "Recognizing Graphs Close to Bipartite Graphs with an Application to\n  Colouring Reconfiguration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue research into a well-studied family of problems that ask whether\nthe vertices of a graph can be partitioned into sets $A$ and~$B$, where $A$ is\nan independent set and $B$ induces a graph from some specified graph class\n${\\cal G}$. We let ${\\cal G}$ be the class of $k$-degenerate graphs. This\nproblem is known to be polynomial-time solvable if $k=0$ (bipartite graphs) and\nNP-complete if $k=1$ (near-bipartite graphs) even for graphs of maximum degree\n$4$. Yang and Yuan [DM, 2006] showed that the $k=1$ case is polynomial-time\nsolvable for graphs of maximum degree $3$. This also follows from a result of\nCatlin and Lai [DM, 1995]. We consider graphs of maximum degree $k+2$ on $n$\nvertices. We show how to find $A$ and $B$ in $O(n)$ time for $k=1$, and in\n$O(n^2)$ time for $k\\geq 2$. Together, these results provide an algorithmic\nversion of a result of Catlin [JCTB, 1979] and also provide an algorithmic\nversion of a generalization of Brook's Theorem, which was proven in a more\ngeneral way by Borodin, Kostochka and Toft [DM, 2000] and Matamala [JGT, 2007].\nMoreover, the two results enable us to complete the complexity classification\nof an open problem of Feghali et al. [JGT, 2016]: finding a path in the vertex\ncolouring reconfiguration graph between two given $\\ell$-colourings of a graph\nof maximum degree $k$.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 12:32:54 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Bonamy", "Marthe", ""], ["Dabrowski", "Konrad K.", ""], ["Feghali", "Carl", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1707.09863", "submitter": "Andreas Bluhm", "authors": "Andreas Bluhm, Daniel Stilck Franca", "title": "Dimensionality reduction of SDPs through sketching", "comments": "15 pages. Significantly shortened and presentation streamlined", "journal-ref": "Linear Algebra and its Applications, 2019, 563, 461-475", "doi": "10.1016/j.laa.2018.11.012", "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to sketch semidefinite programs (SDPs) using positive maps in\norder to reduce their dimension. More precisely, we use\nJohnson\\hyp{}Lindenstrauss transforms to produce a smaller SDP whose solution\npreserves feasibility or approximates the value of the original problem with\nhigh probability. These techniques allow to improve both complexity and storage\nspace requirements. They apply to problems in which the Schatten 1-norm of the\nmatrices specifying the SDP and also of a solution to the problem is constant\nin the problem size. Furthermore, we provide some results which clarify the\nlimitations of positive, linear sketches in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:26:19 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 13:41:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Bluhm", "Andreas", ""], ["Franca", "Daniel Stilck", ""]]}, {"id": "1707.09904", "submitter": "Alfred Rossi", "authors": "Tamal K. Dey, Alfred Rossi, Anastasios Sidiropoulos", "title": "Temporal Hierarchical Clustering", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study hierarchical clusterings of metric spaces that change over time.\nThis is a natural geometric primitive for the analysis of dynamic data sets.\nSpecifically, we introduce and study the problem of finding a temporally\ncoherent sequence of hierarchical clusterings from a sequence of unlabeled\npoint sets. We encode the clustering objective by embedding each point set into\nan ultrametric space, which naturally induces a hierarchical clustering of the\nset of points. We enforce temporal coherence among the embeddings by finding\ncorrespondences between successive pairs of ultrametric spaces which exhibit\nsmall distortion in the Gromov-Hausdorff sense. We present both upper and lower\nbounds on the approximability of the resulting optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:58:44 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 19:51:04 GMT"}, {"version": "v3", "created": "Thu, 19 Oct 2017 11:13:39 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Dey", "Tamal K.", ""], ["Rossi", "Alfred", ""], ["Sidiropoulos", "Anastasios", ""]]}]