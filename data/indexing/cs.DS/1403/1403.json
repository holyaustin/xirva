[{"id": "1403.0099", "submitter": "Meirav Zehavi", "authors": "Hadas Shachnai, Meirav Zehavi", "title": "Parameterized Algorithms for Graph Partitioning Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a broad class of graph partitioning problems, where each problem is\nspecified by a graph $G=(V,E)$, and parameters $k$ and $p$. We seek a subset\n$U\\subseteq V$ of size $k$, such that $\\alpha_1m_1 + \\alpha_2m_2$ is at most\n(or at least) $p$, where $\\alpha_1,\\alpha_2\\in\\mathbb{R}$ are constants\ndefining the problem, and $m_1, m_2$ are the cardinalities of the edge sets\nhaving both endpoints, and exactly one endpoint, in $U$, respectively. This\nclass of fixed cardinality graph partitioning problems (FGPP) encompasses Max\n$(k,n-k)$-Cut, Min $k$-Vertex Cover, $k$-Densest Subgraph, and $k$-Sparsest\nSubgraph.\n  Our main result is an $O^*(4^{k+o(k)}\\Delta^k)$ algorithm for any problem in\nthis class, where $\\Delta \\geq 1$ is the maximum degree in the input graph.\nThis resolves an open question posed by Bonnet et al. [IPEC 2013]. We obtain\nfaster algorithms for certain subclasses of FGPPs, parameterized by $p$, or by\n$(k+p)$. In particular, we give an $O^*(4^{p+o(p)})$ time algorithm for Max\n$(k,n-k)$-Cut, thus improving significantly the best known $O^*(p^p)$ time\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 1 Mar 2014 15:45:12 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Shachnai", "Hadas", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1403.0178", "submitter": "Mathias B{\\ae}k Tejs Knudsen", "authors": "Mathias B{\\ae}k Tejs Knudsen", "title": "Additive Spanners: A Simple Construction", "comments": "To appear at proceedings of the 14th Scandinavian Symposium and\n  Workshop on Algorithm Theory (SWAT 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider additive spanners of unweighted undirected graphs. Let $G$ be a\ngraph and $H$ a subgraph of $G$. The most na\\\"ive way to construct an additive\n$k$-spanner of $G$ is the following: As long as $H$ is not an additive\n$k$-spanner repeat: Find a pair $(u,v) \\in H$ that violates the\nspanner-condition and a shortest path from $u$ to $v$ in $G$. Add the edges of\nthis path to $H$.\n  We show that, with a very simple initial graph $H$, this na\\\"ive method gives\nadditive $6$- and $2$-spanners of sizes matching the best known upper bounds.\nFor additive $2$-spanners we start with $H=\\emptyset$ and end with $O(n^{3/2})$\nedges in the spanner. For additive $6$-spanners we start with $H$ containing\n$\\lfloor n^{1/3} \\rfloor$ arbitrary edges incident to each node and end with a\nspanner of size $O(n^{4/3})$.\n", "versions": [{"version": "v1", "created": "Sun, 2 Mar 2014 09:33:30 GMT"}, {"version": "v2", "created": "Sun, 27 Apr 2014 15:31:52 GMT"}, {"version": "v3", "created": "Sun, 23 Nov 2014 18:03:31 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Knudsen", "Mathias B\u00e6k Tejs", ""]]}, {"id": "1403.0224", "submitter": "Rakesh Mohanty", "authors": "Mitali Sinha, Suchismita Pattanaik, Rakesh Mohanty and Prachi Tripathy", "title": "Experimental Study of A Novel Variant of Fiduccia Mattheyses(FM)\n  Partitioning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning is a well studied research problem in the area of VLSI physical\ndesign automation. In this problem, input is an integrated circuit and output\nis a set of almost equal disjoint blocks. The main objective of partitioning is\nto assign the components of circuit to blocks in order to minimize the numbers\nof inter-block connections. A partitioning algorithm using hypergraph was\nproposed by Fiduccia and Mattheyses with linear time complexity which has been\npopularly known as FM algorithm. Most of the hypergraph based partitioning\nalgorithms proposed in the literature are variants of FM algorithm. In this\npaper, we have proposed a novel variant of FM algorithm by using pair wise\nswapping technique. We have performed a comparative experimental study of FM\nalgorithm and our proposed algorithm using two dataset such as ISPD98 and\nISPD99. Experimental results show that performance of our proposed algorithm is\nbetter than the FM algorithm using the above dataset.\n", "versions": [{"version": "v1", "created": "Sun, 2 Mar 2014 15:34:48 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Sinha", "Mitali", ""], ["Pattanaik", "Suchismita", ""], ["Mohanty", "Rakesh", ""], ["Tripathy", "Prachi", ""]]}, {"id": "1403.0252", "submitter": "Daniel Larkin", "authors": "Daniel H. Larkin, Siddhartha Sen, Robert E. Tarjan", "title": "A Back-to-Basics Empirical Study of Priority Queues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory community has proposed several new heap variants in the recent\npast which have remained largely untested experimentally. We take the field\nback to the drawing board, with straightforward implementations of both classic\nand novel structures using only standard, well-known optimizations. We study\nthe behavior of each structure on a variety of inputs, including artificial\nworkloads, workloads generated by running algorithms on real map data, and\nworkloads from a discrete event simulator used in recent systems networking\nresearch. We provide observations about which characteristics are most\ncorrelated to performance. For example, we find that the L1 cache miss rate\nappears to be strongly correlated with wallclock time. We also provide\nobservations about how the input sequence affects the relative performance of\nthe different heap variants. For example, we show (both theoretically and in\npractice) that certain random insertion-deletion sequences are degenerate and\ncan lead to misleading results. Overall, our findings suggest that while the\nconventional wisdom holds in some cases, it is sorely mistaken in others.\n", "versions": [{"version": "v1", "created": "Sun, 2 Mar 2014 18:16:22 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Larkin", "Daniel H.", ""], ["Sen", "Siddhartha", ""], ["Tarjan", "Robert E.", ""]]}, {"id": "1403.0298", "submitter": "Juli\\'an Mestre", "authors": "Juli\\'an Mestre and Jos\\'e Verschae", "title": "A 4-approximation for scheduling on a single machine with general cost\n  function", "comments": "This paper has been withdrawn due to new merged paper\n  arXiv:1612.03339", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a single machine scheduling problem that seeks to minimize a\ngeneralized cost function: given a subset of jobs we must order them so as to\nminimize $\\sum f_j(C_j)$, where $C_j$ is the completion time of job $j$ and\n$f_j$ is a job-dependent cost function. This problem has received a\nconsiderably amount of attention lately, partly because it generalizes a large\nnumber of sequencing problems while still allowing constant approximation\nguarantees.\n  In a recent paper, Cheung and Shmoys provided a primal-dual algorithm for the\nproblem and claimed that is a 2-approximation. In this paper we show that their\nanalysis cannot yield an approximation guarantee better than $4$. We then cast\ntheir algorithm as a local ratio algorithm and show that in fact it has an\napproximation ratio of $4$. Additionally, we consider a more general problem\nwhere jobs has release dates and can be preempted. For this version we give a\n$4\\kappa$-approximation algorithm where $\\kappa$ is the number of distinct\nrelease dates.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 03:18:08 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 20:32:10 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Mestre", "Juli\u00e1n", ""], ["Verschae", "Jos\u00e9", ""]]}, {"id": "1403.0457", "submitter": "N. Jesper Larsson", "authors": "N. Jesper Larsson and Kasper Fuglsang and Kenneth Karlsson", "title": "Efficient Representation for Online Suffix Tree Construction", "comments": "Presented at SEA 2014, Copenhagen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suffix tree construction algorithms based on suffix links are popular because\nthey are simple to implement, can operate online in linear time, and because\nthe suffix links are often convenient for pattern matching. We present an\napproach using edge-oriented suffix links, which reduces the number of branch\nlookup operations (known to be a bottleneck in construction time) with some\nadditional techniques to reduce construction cost. We discuss various effects\nof our approach and compare it to previous techniques. An experimental\nevaluation shows that we are able to reduce construction time to around half\nthat of the original algorithm, and about two thirds that of previously known\nbranch-reduced construction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 15:01:23 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 14:19:27 GMT"}, {"version": "v3", "created": "Mon, 14 Jul 2014 15:48:36 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Larsson", "N. Jesper", ""], ["Fuglsang", "Kasper", ""], ["Karlsson", "Kenneth", ""]]}, {"id": "1403.0486", "submitter": "Grigory Yaroslavtsev", "authors": "Nikhil Devanur, Konstantin Makarychev, Debmalya Panigrahi, Grigory\n  Yaroslavtsev", "title": "Online Algorithms for Machine Minimization", "comments": "After the first version of the manuscript was posted online, it was\n  brought to our attention that Theorem 1.1 also follows from the results of\n  Bansal, Kimbrel and Pruhs, \"Speed Scaling to Minimize Energy and Temperature\"\n  (JACM'07), who consider energy-minimizing scheduling problems. This result\n  follows from Lemma 4.7 and Lemma 4.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the online version of the machine minimization\nproblem (introduced by Chuzhoy et al., FOCS 2004), where the goal is to\nschedule a set of jobs with release times, deadlines, and processing lengths on\na minimum number of identical machines. Since the online problem has strong\nlower bounds if all the job parameters are arbitrary, we focus on jobs with\nuniform length. Our main result is a complete resolution of the deterministic\ncomplexity of this problem by showing that a competitive ratio of $e$ is\nachievable and optimal, thereby improving upon existing lower and upper bounds\nof 2.09 and 5.2 respectively. We also give a constant-competitive online\nalgorithm for the case of uniform deadlines (but arbitrary job lengths); to the\nbest of our knowledge, no such algorithm was known previously. Finally, we\nconsider the complimentary problem of throughput maximization where the goal is\nto maximize the sum of weights of scheduled jobs on a fixed set of identical\nmachines (introduced by Bar-Noy et al. STOC 1999). We give a randomized online\nalgorithm for this problem with a competitive ratio of e/e-1; previous results\nachieved this bound only for the case of a single machine or in the limit of an\ninfinite number of machines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 16:59:18 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 04:52:59 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Devanur", "Nikhil", ""], ["Makarychev", "Konstantin", ""], ["Panigrahi", "Debmalya", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1403.0493", "submitter": "Joanna Tomasik", "authors": "Thomas Carli, St\\'ephane Henriot, Johanne Cohen, Joanna Tomasik", "title": "A packing problem approach to energy-aware load distribution in Clouds", "comments": "SUPELEC Technical Report, CEI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cloud Computing paradigm consists in providing customers with virtual\nservices of the quality which meets customers' requirements. A cloud service\noperator is interested in using his infrastructure in the most efficient way\nwhile serving customers. The efficiency of infrastructure exploitation may be\nexpressed, amongst others, by the electrical energy consumption of computing\ncenters.\n  We propose to model the energy consumption of private Clouds, which provides\nvirtual computation services, by a variant of the Bin Packing problem. This\nnovel generalization is obtained by introducing such constraints as: variable\nbin size, cost of packing and the possibility of splitting items.\n  We analyze the packing problem generalization from a theoretical point of\nview. We advance on-line and off-line approximation algorithms to solve our\nproblem to balance the load either on-the-fly or on the planning stage. In\naddition to the computation of the approximation factors of these two\nalgorithms, we evaluate experimentally their performance.\n  The quality of the results is encouraging. This conclusion makes a packing\napproach a serious candidate to model energy-aware load balancing in Cloud\nComputing.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 17:27:33 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Carli", "Thomas", ""], ["Henriot", "St\u00e9phane", ""], ["Cohen", "Johanne", ""], ["Tomasik", "Joanna", ""]]}, {"id": "1403.0734", "submitter": "Emanuele Guido Fusco", "authors": "Irene Finocchi, Marco Finocchi, Emanuele G. Fusco", "title": "Clique counting in MapReduce: theory and experiments", "comments": null, "journal-ref": "ACM Journal of Experimental Algorithmics 20: 1.7:1-1.7:20 (2015)", "doi": "10.1145/2794080", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of counting the number of $k$-cliques in large-scale\ngraphs, for any constant $k \\ge 3$. Clique counting is essential in a variety\nof applications, among which social network analysis. Due to its\ncomputationally intensive nature, we settle for parallel solutions in the\nMapReduce framework, which has become in the last few years a {\\em de facto}\nstandard for batch processing of massive data sets. We give both theoretical\nand experimental contributions.\n  On the theory side, we design the first exact scalable algorithm for counting\n(and listing) $k$-cliques. Our algorithm uses $O(m^{3/2})$ total space and\n$O(m^{k/2})$ work, where $m$ is the number of graph edges. This matches the\nbest-known bounds for triangle listing when $k=3$ and is work-optimal in the\nworst case for any $k$, while keeping the communication cost independent of\n$k$. We also design a sampling-based estimator that can dramatically reduce the\nrunning time and space requirements of the exact approach, while providing very\naccurate solutions with high probability.\n  We then assess the effectiveness of different clique counting approaches\nthrough an extensive experimental analysis over the Amazon EC2 platform,\nconsidering both our algorithms and their state-of-the-art competitors. The\nexperimental results clearly highlight the algorithm of choice in different\nscenarios and prove our exact approach to be the most effective when the number\nof $k$-cliques is large, gracefully scaling to non-trivial values of $k$ even\non clusters of small/medium size. Our approximation algorithm achieves\nextremely accurate estimates and large speedups, especially on the toughest\ninstances for the exact algorithms. As a side effect, our study also sheds\nlight on the number of $k$-cliques of several real-world graphs, mainly social\nnetworks, and on its growth rate as a function of $k$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 10:36:35 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 15:38:22 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Finocchi", "Irene", ""], ["Finocchi", "Marco", ""], ["Fusco", "Emanuele G.", ""]]}, {"id": "1403.0751", "submitter": "David Manlove", "authors": "Augustine Kwanashie, Robert W. Irving, David F. Manlove, Colin T.S.\n  Sng", "title": "Profile-based optimal matchings in the Student/Project Allocation\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Student / Project Allocation problem (SPA) we seek to assign students\nto individual or group projects offered by lecturers. Students provide a list\nof projects they find acceptable in order of preference. Each student can be\nassigned to at most one project and there are constraints on the maximum number\nof students that can be assigned to each project and lecturer. We seek\nmatchings of students to projects that are optimal with respect to profile,\nwhich is a vector whose rth component indicates how many students have their\nrth-choice project. We present an efficient algorithm for finding a greedy\nmaximum matching in the SPA context - this is a maximum matching whose profile\nis lexicographically maximum. We then show how to adapt this algorithm to find\na generous maximum matching - this is a matching whose reverse profile is\nlexicographically minimum. Our algorithms involve finding optimal flows in\nnetworks. We demonstrate how this approach can allow for additional\nconstraints, such as lecturer lower quotas, to be handled flexibly. Finally we\npresent results obtained from an empirical evaluation of the algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 11:54:32 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 13:21:36 GMT"}, {"version": "v3", "created": "Fri, 13 Jun 2014 14:25:22 GMT"}, {"version": "v4", "created": "Sun, 29 Jun 2014 14:29:07 GMT"}, {"version": "v5", "created": "Fri, 3 Jul 2015 15:22:29 GMT"}], "update_date": "2015-07-06", "authors_parsed": [["Kwanashie", "Augustine", ""], ["Irving", "Robert W.", ""], ["Manlove", "David F.", ""], ["Sng", "Colin T. S.", ""]]}, {"id": "1403.0789", "submitter": "Petr Golovach", "authors": "Petr A. Golovach, Dani\\\"el Paulusma, and Erik Jan van Leeuwen", "title": "Induced Disjoint Paths in Circular-Arc Graphs in Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Induced Disjoint Paths problem is to test whether a graph G with k\ndistinct pairs of vertices (s_i,t_i) contains paths P_1,...,P_k such that P_i\nconnects s_i and t_i for i=1,...,k, and P_i and P_j have neither common\nvertices nor adjacent vertices (except perhaps their ends) for 1<=i < j<=k. We\npresent a linear-time algorithm for Induced Disjoint Paths on circular-arc\ngraphs. For interval graphs, we exhibit a linear-time algorithm for the\ngeneralization of Induced Disjoint Paths where the pairs (s_i,t_i) are not\nnecessarily distinct.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 14:00:11 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Golovach", "Petr A.", ""], ["Paulusma", "Dani\u00ebl", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "1403.0800", "submitter": "N. Jesper Larsson", "authors": "N. Jesper Larsson", "title": "Most Recent Match Queries in On-Line Suffix Trees (with appendix)", "comments": "Result presented at CPM 2014, Moscow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A suffix tree is able to efficiently locate a pattern in an indexed string,\nbut not in general the most recent copy of the pattern in an online stream,\nwhich is desirable in some applications. We study the most general version of\nthe problem of locating a most recent match: supporting queries for arbitrary\npatterns, at each step of processing an online stream. We present augmentations\nto Ukkonen's suffix tree construction algorithm for optimal-time queries,\nmaintaining indexing time within a logarithmic factor in the size of the\nindexed string. We show that the algorithm is applicable to sliding-window\nindexing, and sketch a possible optimization for use in the special case of\nLempel-Ziv compression.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 14:32:23 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 10:09:58 GMT"}, {"version": "v3", "created": "Mon, 14 Jul 2014 15:35:25 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Larsson", "N. Jesper", ""]]}, {"id": "1403.1019", "submitter": "Zheng Shi", "authors": "Zheng Shi and Khee Meng Koh", "title": "Counting the Number of Minimum Roman Dominating Functions of a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two algorithms counting the number of minimum Roman dominating\nfunctions of a graph on n vertices in O(1.5673^n) time and polynomial space. We\nalso show that the time complexity can be reduced to O(1.5014^n) if exponential\nspace is used. Our result is obtained by transforming the Roman domination\nproblem into other combinatorial problems on graphs for which exact algorithms\nalready exist.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 06:54:25 GMT"}, {"version": "v2", "created": "Mon, 10 Mar 2014 09:37:19 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Shi", "Zheng", ""], ["Koh", "Khee Meng", ""]]}, {"id": "1403.1065", "submitter": "Patrick Hagge Cording", "authors": "Philip Bille, Patrick Hagge Cording, Inge Li G{\\o}rtz", "title": "Compressed Subsequence Matching and Packed Tree Coloring", "comments": "To appear at CPM '14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for subsequence matching in grammar compressed\nstrings. Given a grammar of size $n$ compressing a string of size $N$ and a\npattern string of size $m$ over an alphabet of size $\\sigma$, our algorithm\nuses $O(n+\\frac{n\\sigma}{w})$ space and $O(n+\\frac{n\\sigma}{w}+m\\log N\\log\nw\\cdot occ)$ or $O(n+\\frac{n\\sigma}{w}\\log w+m\\log N\\cdot occ)$ time. Here $w$\nis the word size and $occ$ is the number of occurrences of the pattern. Our\nalgorithm uses less space than previous algorithms and is also faster for\n$occ=o(\\frac{n}{\\log N})$ occurrences. The algorithm uses a new data structure\nthat allows us to efficiently find the next occurrence of a given character\nafter a given position in a compressed string. This data structure in turn is\nbased on a new data structure for the tree color problem, where the node colors\nare packed in bit strings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 10:16:27 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2014 09:37:56 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Bille", "Philip", ""], ["Cording", "Patrick Hagge", ""], ["G\u00f8rtz", "Inge Li", ""]]}, {"id": "1403.1081", "submitter": "O-joung Kwon", "authors": "Isolde Adler, Mamadou Moustapha Kant\\'e, O-joung Kwon", "title": "Linear rank-width of distance-hereditary graphs I. A polynomial-time\n  algorithm", "comments": "28 pages, 3 figures, 2 table. A preliminary version appeared in the\n  proceedings of WG'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear rank-width is a linearized variation of rank-width, and it is deeply\nrelated to matroid path-width. In this paper, we show that the linear\nrank-width of every $n$-vertex distance-hereditary graph, equivalently a graph\nof rank-width at most $1$, can be computed in time $\\mathcal{O}(n^2\\cdot \\log_2\nn)$, and a linear layout witnessing the linear rank-width can be computed with\nthe same time complexity. As a corollary, we show that the path-width of every\n$n$-element matroid of branch-width at most $2$ can be computed in time\n$\\mathcal{O}(n^2\\cdot \\log_2 n)$, provided that the matroid is given by an\nindependent set oracle.\n  To establish this result, we present a characterization of the linear\nrank-width of distance-hereditary graphs in terms of their canonical split\ndecompositions. This characterization is similar to the known characterization\nof the path-width of forests given by Ellis, Sudborough, and Turner [The vertex\nseparation and search number of a graph. Inf. Comput., 113(1):50--79, 1994].\nHowever, different from forests, it is non-trivial to relate substructures of\nthe canonical split decomposition of a graph with some substructures of the\ngiven graph. We introduce a notion of `limbs' of canonical split\ndecompositions, which correspond to certain vertex-minors of the original\ngraph, for the right characterization.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 11:27:38 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 13:03:21 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2015 13:16:44 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Adler", "Isolde", ""], ["Kant\u00e9", "Mamadou Moustapha", ""], ["Kwon", "O-joung", ""]]}, {"id": "1403.1178", "submitter": "Pawan  Tamta", "authors": "Pawan Tamta, B.P. Pande, H.S. Dhami", "title": "A Polynomial Time Solution to the Clique Problem", "comments": "There is an error while applying the algorithm to the large size\n  problems. This algorithm doesn't provide solution to all Clique problems es,\n  2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Clique Problem has a reduction to the Maximum Flow Network Interdiction\nProblem. We review the reduction to evolve a polynomial time algorithm for the\nClique Problem. A computer program in C language has been written to validate\nthe easiness of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 07:26:01 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 02:46:39 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Tamta", "Pawan", ""], ["Pande", "B. P.", ""], ["Dhami", "H. S.", ""]]}, {"id": "1403.1279", "submitter": "Hamid A. Toussi", "authors": "Hamid A. Toussi and Bahram Sadeghi Bigham", "title": "Design, Implementation and Evaluation of MTBDD based Fuzzy Sets and\n  Binary Fuzzy Relations", "comments": "A shorter version was published in Proceeding of International\n  Conference on Computer, Information Technology and Digital Media, Tehran,\n  Iran, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For fast and efficient analysis of large sets of fuzzy data, elimination of\nredundancies in the memory representation is needed. We used MTBDDs as the\nunderlying data-structure to represent fuzzy sets and binary fuzzy relations.\nThis leads to elimination of redundancies in the representation, less\ncomputations, and faster analyses. We have also extended a BDD package (BuDDy)\nto support MTBDDs in general and fuzzy sets and relations in particular.\nDifferent fuzzy operations such as max, min and max-min composition were\nimplemented based on our representation. Effectiveness of our representation is\nshown by applying it on fuzzy connectedness and image segmentation problem.\nCompared to a base implementation, the running time of our MTBDD based\nimplementation was faster (in our test cases) by a factor ranging from 2 to 27.\nAlso, when the MTBDD based data-structure was employed, the memory needed to\nrepresent the final results was improved by a factor ranging from 37.9 to\n265.5.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 21:48:58 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Toussi", "Hamid A.", ""], ["Bigham", "Bahram Sadeghi", ""]]}, {"id": "1403.1364", "submitter": "Hjalte Wedel Vildh{\\o}j", "authors": "Tatiana Starikovskaya and Hjalte Wedel Vildh{\\o}j", "title": "A Suffix Tree Or Not A Suffix Tree?", "comments": "Full version. An extended abstract has been accepted to IWOCA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the structure of suffix trees. Given an unlabeled tree\n$\\tau$ on $n$ nodes and suffix links of its internal nodes, we ask the question\n\"Is $\\tau$ a suffix tree?\", i.e., is there a string $S$ whose suffix tree has\nthe same topological structure as $\\tau$? We place no restrictions on $S$, in\nparticular we do not require that $S$ ends with a unique symbol. This\ncorresponds to considering the more general definition of implicit or extended\nsuffix trees. Such general suffix trees have many applications and are for\nexample needed to allow efficient updates when suffix trees are built online.\nWe prove that $\\tau$ is a suffix tree if and only if it is realized by a string\n$S$ of length $n-1$, and we give a linear-time algorithm for inferring $S$ when\nthe first letter on each edge is known. This generalizes the work of I et al.\n[Discrete Appl. Math. 163, 2014].\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 07:24:14 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 09:07:39 GMT"}, {"version": "v3", "created": "Mon, 1 Sep 2014 16:09:50 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Starikovskaya", "Tatiana", ""], ["Vildh\u00f8j", "Hjalte Wedel", ""]]}, {"id": "1403.1376", "submitter": "Juli\\'an Mestre", "authors": "Wiebke H\\\"ohn and Juli\\'an Mestre and Andreas Wiese", "title": "How Unsplittable-Flow-Covering helps Scheduling with Job-Dependent Cost\n  Functions", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizing many well-known and natural scheduling problems, scheduling with\njob-specific cost functions has gained a lot of attention recently. In this\nsetting, each job incurs a cost depending on its completion time, given by a\nprivate cost function, and one seeks to schedule the jobs to minimize the total\nsum of these costs. The framework captures many important scheduling objectives\nsuch as weighted flow time or weighted tardiness. Still, the general case as\nwell as the mentioned special cases are far from being very well understood\nyet, even for only one machine. Aiming for better general understanding of this\nproblem, in this paper we focus on the case of uniform job release dates on one\nmachine for which the state of the art is a 4-approximation algorithm. This is\ntrue even for a special case that is equivalent to the covering version of the\nwell-studied and prominent unsplittable flow on a path problem, which is\ninteresting in its own right. For that covering problem, we present a\nquasi-polynomial time $(1+\\epsilon)$-approximation algorithm that yields an\n$(e+\\epsilon)$-approximation for the above scheduling problem. Moreover, for\nthe latter we devise the best possible resource augmentation result regarding\nspeed: a polynomial time algorithm which computes a solution with \\emph{optimal\n}cost at $1+\\epsilon$ speedup. Finally, we present an elegant QPTAS for the\nspecial case where the cost functions of the jobs fall into at most $\\log n$\nmany classes. This algorithm allows the jobs even to have up to $\\log n$ many\ndistinct release dates.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 08:45:34 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["H\u00f6hn", "Wiebke", ""], ["Mestre", "Juli\u00e1n", ""], ["Wiese", "Andreas", ""]]}, {"id": "1403.1512", "submitter": "Gregory Gutin", "authors": "Gregory Gutin, Mark Jones and Bin Sheng", "title": "Parameterized Complexity of the $k$-Arc Chinese Postman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Mixed Chinese Postman Problem (MCPP), given an edge-weighted mixed\ngraph $G$ ($G$ may have both edges and arcs), our aim is to find a minimum\nweight closed walk traversing each edge and arc at least once. The MCPP\nparameterized by the number of edges was known to be fixed-parameter tractable\nusing a simple argument. Solving an open question of van Bevern et al., we\nprove that the MCPP parameterized by the number of arcs is also fixed-parameter\ntractable. Our proof is more involved and, in particular, uses a well-known\nresult of Marx, O'Sullivan and Razgon (2013) on the treewidth of torso graphs\nwith respect to small separators. We obtain a small cut analog of this result,\nand use it to construct a tree decomposition which, despite not having bounded\nwidth, has other properties allowing us to design a fixed-parameter algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 17:52:28 GMT"}, {"version": "v2", "created": "Thu, 27 Mar 2014 19:11:53 GMT"}, {"version": "v3", "created": "Mon, 4 Aug 2014 10:53:31 GMT"}, {"version": "v4", "created": "Mon, 12 Sep 2016 12:17:22 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Sheng", "Bin", ""]]}, {"id": "1403.1515", "submitter": "Yixin Cao", "authors": "Yixin Cao", "title": "Linear Recognition of Almost Interval Graphs", "comments": "Completely restructured, and results on unit interval graphs have\n  been dropped to make this version more focused", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mbox{interval} + k v$, $\\mbox{interval} + k e$, and $\\mbox{interval} -\nk e$ denote the classes of graphs that can be obtained from some interval graph\nby adding $k$ vertices, adding $k$ edges, and deleting $k$ edges, respectively.\nWhen $k$ is small, these graph classes are called almost interval graphs. They\nare well motivated from computational biology, where the data ought to be\nrepresented by an interval graph while we can only expect an almost interval\ngraph for the best. For any fixed $k$, we give linear-time algorithms for\nrecognizing all these classes, and in the case of membership, our algorithms\nprovide also a specific interval graph as evidence. When $k$ is part of the\ninput, these problems are also known as graph modification problems, all\nNP-complete. Our results imply that they are fixed-parameter tractable\nparameterized by $k$, thereby resolving the long-standing open problem on the\nparameterized complexity of recognizing $\\mbox{interval}+ k e$, first asked by\nBodlaender et al. [Bioinformatics, 11:49--57, 1995]. Moreover, our algorithms\nfor recognizing $\\mbox{interval}+ k v$ and $\\mbox{interval}- k e$ run in times\n$O(6^k \\cdot (n + m))$ and $O(8^k \\cdot (n + m))$, (where $n$ and $m$ stand for\nthe numbers of vertices and edges respectively in the input graph,)\nsignificantly improving the $O(k^{2k}\\cdot n^3m)$-time algorithm of Heggernes\net al. [STOC 2007] and the $O(10^k \\cdot n^9)$-time algorithm of Cao and Marx\n[SODA 2014] respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 18:06:28 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2014 14:25:35 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Cao", "Yixin", ""]]}, {"id": "1403.1556", "submitter": "Steffen Eger", "authors": "Steffen Eger", "title": "Corrections to the results derived in \"A Unified Approach to Algorithms\n  Generating Unrestricted and Restricted Integer Compositions and Integer\n  Partitions\"'; and a comparison of four restricted integer composition\n  generation algorithms", "comments": "This will remain an unpublished note. The journal wherein the\n  original article appeared (the one which is being criticized) no longer\n  exists (in its original form). Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, I discuss results on integer compositions/partitions given in\nthe paper \"A Unified Approach to Algorithms Generating Unrestricted and\nRestricted Integer Compositions and Integer Partitions\". I also experiment with\nfour different generation algorithms for restricted integer compositions and\nfind the algorithm designed in the named paper to be pretty slow,\ncomparatively.\n  Some of my comments may be subjective.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 08:36:35 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Eger", "Steffen", ""]]}, {"id": "1403.1706", "submitter": "Johannes K\\\"oster", "authors": "Johannes K\\\"oster, Sven Rahmann", "title": "Massively parallel read mapping on GPUs with PEANUT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PEANUT (ParallEl AligNment UTility), a highly parallel GPU-based\nread mapper with several distinguishing features, including a novel q-gram\nindex (called the q-group index) with small memory footprint built on-the-fly\nover the reads and the possibility to output both the best hits or all hits of\na read. Designing the algorithm particularly for the GPU architecture, we were\nable to reach maximum core occupancy for several key steps. Our benchmarks show\nthat PEANUT outperforms other state-of- the-art mappers in terms of speed and\nsensitivity. The software is available at http://peanut.readthedocs.org.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 10:10:07 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["K\u00f6ster", "Johannes", ""], ["Rahmann", "Sven", ""]]}, {"id": "1403.2009", "submitter": "Olawale Hassan", "authors": "Olawale Hassan (1), Iyad Kanj (1), Daniel Lokshtanov (2), and Ljubomir\n  Perkovi\\'c (1) ((1) School of Computing, DePaul University, (2) Department of\n  Informatics, University of Bergen, Bergen, Norway)", "title": "On the Ordered List Subgraph Embedding Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the (parameterized) Ordered List Subgraph Embedding problem (p-OLSE) we\nare given two graphs $G$ and $H$, each with a linear order defined on its\nvertices, a function $L$ that associates with every vertex in $G$ a list of\nvertices in $H$, and a parameter $k$. The question is to decide if we can embed\n(one-to-one) a subgraph $S$ of $G$ of $k$ vertices into $H$ such that: (1)\nevery vertex of $S$ is mapped to a vertex from its associated list, (2) the\nlinear orders inherited by $S$ and its image under the embedding are respected,\nand (3) if there is an edge between two vertices in $S$ then there is an edge\nbetween their images. If we require the subgraph $S$ to be embedded as an\ninduced subgraph, we obtain the Ordered List Induced Subgraph Embedding problem\n(p-OLISE). The p-OLSE and p-OLISE problems model various problems in\nBioinformatics related to structural comparison/alignment of proteins.\n  We investigate the complexity of p-OLSE and p-OLISE with respect to the\nfollowing structural parameters: the width $\\Delta_L$ of the function $L$ (size\nof the largest list), and the maximum degree $\\Delta_H$ of $H$ and $\\Delta_G$\nof $G$. In terms of the structural parameters under consideration, we draw a\ncomplete complexity landscape of p-OLSE and p-OLISE (and their optimization\nversions) with respect to the computational frameworks of classical complexity,\nparameterized complexity, and approximation.\n", "versions": [{"version": "v1", "created": "Sat, 8 Mar 2014 22:10:25 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Hassan", "Olawale", ""], ["Kanj", "Iyad", ""], ["Lokshtanov", "Daniel", ""], ["Perkovi\u0107", "Ljubomir", ""]]}, {"id": "1403.2041", "submitter": "Michael Lampis", "authors": "Michael Lampis, Kazuhisa Makino, Valia Mitsou and Yushi Uno", "title": "Parameterized Edge Hamiltonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of the classical Edge Hamiltonian Path\nproblem and give several fixed-parameter tractability results. First, we settle\nan open question of Demaine et al. by showing that Edge Hamiltonian Path is FPT\nparameterized by vertex cover, and that it also admits a cubic kernel. We then\nshow fixed-parameter tractability even for a generalization of the problem to\narbitrary hypergraphs, parameterized by the size of a (supplied) hitting set.\nWe also consider the problem parameterized by treewidth or clique-width.\nSurprisingly, we show that the problem is FPT for both of these standard\nparameters, in contrast to its vertex version, which is W-hard for\nclique-width. Our technique, which may be of independent interest, relies on a\nstructural characterization of clique-width in terms of treewidth and complete\nbipartite subgraphs due to Gurski and Wanke.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 09:53:39 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Lampis", "Michael", ""], ["Makino", "Kazuhisa", ""], ["Mitsou", "Valia", ""], ["Uno", "Yushi", ""]]}, {"id": "1403.2056", "submitter": "Timo Bingmann", "authors": "Timo Bingmann, Andreas Eberle, Peter Sanders", "title": "Engineering Parallel String Sorting", "comments": "46 pages, extension of \"Parallel String Sample Sort\" arXiv:1305.1157", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how string sorting algorithms can be parallelized on modern\nmulti-core shared memory machines. As a synthesis of the best sequential string\nsorting algorithms and successful parallel sorting algorithms for atomic\nobjects, we first propose string sample sort. The algorithm makes effective use\nof the memory hierarchy, uses additional word level parallelism, and largely\navoids branch mispredictions. Then we focus on NUMA architectures, and develop\nparallel multiway LCP-merge and -mergesort to reduce the number of random\nmemory accesses to remote nodes. Additionally, we parallelize variants of\nmultikey quicksort and radix sort that are also useful in certain situations.\nComprehensive experiments on five current multi-core platforms are then\nreported and discussed. The experiments show that our implementations scale\nvery well on real-world inputs and modern machines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 13:43:32 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Bingmann", "Timo", ""], ["Eberle", "Andreas", ""], ["Sanders", "Peter", ""]]}, {"id": "1403.2092", "submitter": "Vinicius Gusmao Pereira de Sa", "authors": "Vin\\'icius Gusm\\~ao Pereira de S\\'a, Celina Miraglia Herrera de\n  Figueiredo", "title": "Blind-friendly von Neumann's Heads or Tails", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The toss of a coin is usually regarded as the epitome of randomness, and has\nbeen used for ages as a means to resolve disputes in a simple, fair way.\nPerhaps as ancient as consulting objects such as coins and dice is the art of\nmaliciously biasing them in order to unbalance their outcomes. However, it is\npossible to employ a biased device to produce equiprobable results in a number\nof ways, the most famous of which is the method suggested by von Neumann back\nin 1951. This paper addresses how to extract uniformly distributed bits of\ninformation from a nonuniform source. We study some probabilities related to\nbiased dice and coins, culminating in an interesting variation of von Neumann's\nmechanism that can be employed in a more restricted setting where the actual\nresults of the coin tosses are not known to the contestants.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 19:03:19 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["de S\u00e1", "Vin\u00edcius Gusm\u00e3o Pereira", ""], ["de Figueiredo", "Celina Miraglia Herrera", ""]]}, {"id": "1403.2431", "submitter": "Gabriele Fici", "authors": "Gabriele Fici, Travis Gagie, Juha K\\\"arkk\\\"ainen, Dominik Kempa", "title": "A Subquadratic Algorithm for Minimum Palindromic Factorization", "comments": "Accepted for publication in Journal of Discrete Algorithms", "journal-ref": null, "doi": "10.1016/j.jda.2014.08.001", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an $\\mathcal{O}(n \\log n)$-time, $\\mathcal{O}(n)$-space algorithm for\nfactoring a string into the minimum number of palindromic substrings. That is,\ngiven a string $S [1..n]$, in $\\mathcal{O}(n \\log n)$ time our algorithm\nreturns the minimum number of palindromes $S_1,\\ldots, S_\\ell$ such that $S =\nS_1 \\cdots S_\\ell$. We also show that the time complexity is $\\mathcal{O}(n)$\non average and $\\Omega(n\\log n)$ in the worst case. The last result is based on\na characterization of the palindromic structure of Zimin words.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 22:18:40 GMT"}, {"version": "v2", "created": "Thu, 7 Aug 2014 09:52:23 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fici", "Gabriele", ""], ["Gagie", "Travis", ""], ["K\u00e4rkk\u00e4inen", "Juha", ""], ["Kempa", "Dominik", ""]]}, {"id": "1403.2439", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Hirakendu Das, Olgica Milenkovic, Alon Orlitsky and\n  Shengjun Pan", "title": "String Reconstruction from Substring Compositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by mass-spectrometry protein sequencing, we consider a\nsimply-stated problem of reconstructing a string from the multiset of its\nsubstring compositions. We show that all strings of length 7, one less than a\nprime, or one less than twice a prime, can be reconstructed uniquely up to\nreversal. For all other lengths we show that reconstruction is not always\npossible and provide sometimes-tight bounds on the largest number of strings\nwith given substring compositions. The lower bounds are derived by\ncombinatorial arguments and the upper bounds by algebraic considerations that\nprecisely characterize the set of strings with the same substring compositions\nin terms of the factorization of bivariate polynomials. The problem can be\nviewed as a combinatorial simplification of the turnpike problem, and its\nsolution may shed light on this long-standing problem as well. Using well known\nresults on transience of multi-dimensional random walks, we also provide a\nreconstruction algorithm that reconstructs random strings over alphabets of\nsize $\\ge4$ in optimal near-quadratic time.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 23:55:53 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Acharya", "Jayadev", ""], ["Das", "Hirakendu", ""], ["Milenkovic", "Olgica", ""], ["Orlitsky", "Alon", ""], ["Pan", "Shengjun", ""]]}, {"id": "1403.2777", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich", "title": "Zig-zag Sort: A Simple Deterministic Data-Oblivious Sorting Algorithm\n  Running in O(n log n) Time", "comments": "Appearing in ACM Symp. on Theory of Computing (STOC) 2014", "journal-ref": null, "doi": "10.1145/2591796.2591830", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and analyze Zig-zag Sort--a deterministic data-oblivious sorting\nalgorithm running in O(n log n) time that is arguably simpler than previously\nknown algorithms with similar properties, which are based on the AKS sorting\nnetwork. Because it is data-oblivious and deterministic, Zig-zag Sort can be\nimplemented as a simple O(n log n)-size sorting network, thereby providing a\nsolution to an open problem posed by Incerpi and Sedgewick in 1985. In\naddition, Zig-zag Sort is a variant of Shellsort, and is, in fact, the first\ndeterministic Shellsort variant running in O(n log n) time. The existence of\nsuch an algorithm was posed as an open problem by Plaxton et al. in 1992 and\nalso by Sedgewick in 1996. More relevant for today, however, is the fact that\nthe existence of a simple data-oblivious deterministic sorting algorithm\nrunning in O(n log n) time simplifies the inner-loop computation in several\nproposed oblivious-RAM simulation methods (which utilize AKS sorting networks),\nand this, in turn, implies simplified mechanisms for privacy-preserving data\noutsourcing in several cloud computing applications. We provide both\nconstructive and non-constructive implementations of Zig-zag Sort, based on the\nexistence of a circuit known as an epsilon-halver, such that the constant\nfactors in our constructive implementations are orders of magnitude smaller\nthan those for constructive variants of the AKS sorting network, which are also\nbased on the use of epsilon-halvers.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 23:07:41 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Goodrich", "Michael T.", ""]]}, {"id": "1403.3148", "submitter": "Kyle Kloster", "authors": "Kyle Kloster and David F. Gleich", "title": "Heat kernel based community detection", "comments": "10 pages, published in KDD2014 proceedings; Contains minor correction\n  to experiments from original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heat kernel is a particular type of graph diffusion that, like the\nmuch-used personalized PageRank diffusion, is useful in identifying a community\nnearby a starting seed node. We present the first deterministic, local\nalgorithm to compute this diffusion and use that algorithm to study the\ncommunities that it produces. Our algorithm is formally a relaxation method for\nsolving a linear system to estimate the matrix exponential in a degree-weighted\nnorm. We prove that this algorithm stays localized in a large graph and has a\nworst-case constant runtime that depends only on the parameters of the\ndiffusion, not the size of the graph. Our experiments on real-world networks\nindicate that the communities produced by this method have better conductance\nthan those produced by PageRank, although they take slightly longer to compute\non large graphs. On a real-world community identification task, the heat kernel\ncommunities perform better than those from the PageRank diffusion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2014 02:35:26 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 23:41:41 GMT"}, {"version": "v3", "created": "Mon, 19 Jan 2015 21:32:54 GMT"}, {"version": "v4", "created": "Tue, 15 Nov 2016 20:08:33 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Kloster", "Kyle", ""], ["Gleich", "David F.", ""]]}, {"id": "1403.3448", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi and Nesreen K. Ahmed", "title": "Coloring Large Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS math.CO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large social or information network, how can we partition the\nvertices into sets (i.e., colors) such that no two vertices linked by an edge\nare in the same set while minimizing the number of sets used. Despite the\nobvious practical importance of graph coloring, existing works have not\nsystematically investigated or designed methods for large complex networks. In\nthis work, we develop a unified framework for coloring large complex networks\nthat consists of two main coloring variants that effectively balances the\ntradeoff between accuracy and efficiency. Using this framework as a fundamental\nbasis, we propose coloring methods designed for the scale and structure of\ncomplex networks. In particular, the methods leverage triangles,\ntriangle-cores, and other egonet properties and their combinations. We\nsystematically compare the proposed methods across a wide range of networks\n(e.g., social, web, biological networks) and find a significant improvement\nover previous approaches in nearly all cases. Additionally, the solutions\nobtained are nearly optimal and sometimes provably optimal for certain classes\nof graphs (e.g., collaboration networks). We also propose a parallel algorithm\nfor the problem of coloring neighborhood subgraphs and make several key\nobservations. Overall, the coloring methods are shown to be (i) accurate with\nsolutions close to optimal, (ii) fast and scalable for large networks, and\n(iii) flexible for use in a variety of applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2014 22:10:24 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 16:00:44 GMT"}, {"version": "v3", "created": "Tue, 26 Aug 2014 18:42:03 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""]]}, {"id": "1403.3458", "submitter": "Haitao Wang", "authors": "Danny Z. Chen, Rajasekhar Inkulu, and Haitao Wang", "title": "Two-Point $L_1$ Shortest Path Queries in the Plane", "comments": "38 pages, 13 figures. A preliminary version appeared in SoCG 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{P}$ be a set of $h$ pairwise-disjoint polygonal obstacles with\na total of $n$ vertices in the plane. We consider the problem of building a\ndata structure that can quickly compute an $L_1$ shortest obstacle-avoiding\npath between any two query points $s$ and $t$. Previously, a data structure of\nsize $O(n^2\\log n)$ was constructed in $O(n^2\\log^2 n)$ time that answers each\ntwo-point query in $O(\\log^2 n+k)$ time, i.e., the shortest path length is\nreported in $O(\\log^2 n)$ time and an actual path is reported in additional\n$O(k)$ time, where $k$ is the number of edges of the output path. In this\npaper, we build a new data structure of size $O(n+h^2\\cdot \\log h \\cdot\n4^{\\sqrt{\\log h}})$ in $O(n+h^2\\cdot \\log^{2} h \\cdot 4^{\\sqrt{\\log h}})$ time\nthat answers each query in $O(\\log n+k)$ time. Note that $n+h^2\\cdot \\log^{2} h\n\\cdot 4^{\\sqrt{\\log h}}=O(n+h^{2+\\epsilon})$ for any constant $\\epsilon>0$.\nFurther, we extend our techniques to the weighted rectilinear version in which\nthe \"obstacles\" of $\\mathcal{P}$ are rectilinear regions with \"weights\" and\nallow $L_1$ paths to travel through them with weighted costs. Our algorithm\nanswers each query in $O(\\log n+k)$ time with a data structure of size\n$O(n^2\\cdot \\log n\\cdot 4^{\\sqrt{\\log n}})$ that is built in $O(n^2\\cdot\n\\log^{2} n\\cdot 4^{\\sqrt{\\log n}})$ time (note that $n^2\\cdot \\log^{2} n\\cdot\n4^{\\sqrt{\\log n}}= O(n^{2+\\epsilon})$ for any constant $\\epsilon>0$).\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2014 23:15:44 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Chen", "Danny Z.", ""], ["Inkulu", "Rajasekhar", ""], ["Wang", "Haitao", ""]]}, {"id": "1403.3551", "submitter": "Morten St\\\"ockel", "authors": "Rasmus Pagh, Morten St\\\"ockel", "title": "The Input/Output Complexity of Sparse Matrix Multiplication", "comments": "Submitted to ICALP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multiplying sparse matrices (over a semiring)\nwhere the number of non-zero entries is larger than main memory. In the\nclassical paper of Hong and Kung (STOC '81) it was shown that to compute a\nproduct of dense $U \\times U$ matrices, $\\Theta \\left(U^3 / (B \\sqrt{M})\n\\right)$ I/Os are necessary and sufficient in the I/O model with internal\nmemory size $M$ and memory block size $B$.\n  In this paper we generalize the upper and lower bounds of Hong and Kung to\nthe sparse case. Our bounds depend of the number $N =\n\\mathtt{nnz}(A)+\\mathtt{nnz}(C)$ of nonzero entries in $A$ and $C$, as well as\nthe number $Z = \\mathtt{nnz}(AC)$ of nonzero entries in $AC$.\n  We show that $AC$ can be computed using $\\tilde{O} \\left(\\tfrac{N}{B}\n\\min\\left(\\sqrt{\\tfrac{Z}{M}},\\tfrac{N}{M}\\right) \\right)$ I/Os, with high\nprobability. This is tight (up to polylogarithmic factors) when only semiring\noperations are allowed, even for dense rectangular matrices: We show a lower\nbound of $\\Omega \\left(\\tfrac{N}{B}\n\\min\\left(\\sqrt{\\tfrac{Z}{M}},\\tfrac{N}{M}\\right) \\right)$ I/Os.\n  While our lower bound uses fairly standard techniques, the upper bound makes\nuse of ``compressed matrix multiplication'' sketches, which is new in the\ncontext of I/O-efficient algorithms, and a new matrix product size estimation\ntechnique that avoids the ``no cancellation'' assumption.\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2014 12:18:26 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Pagh", "Rasmus", ""], ["St\u00f6ckel", "Morten", ""]]}, {"id": "1403.3841", "submitter": "Trent Rogers", "authors": "Jacob Hendricks, Matthew J. Patitz, and Trent A. Rogers", "title": "Doubles and Negatives are Positive (in Self-Assembly)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the abstract Tile Assembly Model (aTAM), the phenomenon of cooperation\noccurs when the attachment of a new tile to a growing assembly requires it to\nbind to more than one tile already in the assembly. Often referred to as\n``temperature-2'' systems, those which employ cooperation are known to be quite\npowerful (i.e. they are computationally universal and can build an enormous\nvariety of shapes and structures). Conversely, aTAM systems which do not\nenforce cooperative behavior, a.k.a. ``temperature-1'' systems, are conjectured\nto be relatively very weak, likely to be unable to perform complex computations\nor algorithmically direct the process of self-assembly. Nonetheless, a variety\nof models based on slight modifications to the aTAM have been developed in\nwhich temperature-1 systems are in fact capable of Turing universal computation\nthrough a restricted notion of cooperation. Despite that power, though, several\nof those models have previously been proven to be unable to perform or simulate\nthe stronger form of cooperation exhibited by temperature-2 aTAM systems.\n  In this paper, we first prove that another model in which temperature-1\nsystems are computationally universal, namely the restricted glue TAM (rgTAM)\nin which tiles are allowed to have edges which exhibit repulsive forces, is\nalso unable to simulate the strongly cooperative behavior of the temperature-2\naTAM. We then show that by combining the properties of two such models, the\nDupled Tile Assembly Model (DTAM) and the rgTAM into the DrgTAM, we derive a\nmodel which is actually more powerful at temperature-1 than the aTAM at\ntemperature-2. Specifically, the DrgTAM, at temperature-1, can simulate any\naTAM system of any temperature, and it also contains systems which cannot be\nsimulated by any system in the aTAM.\n", "versions": [{"version": "v1", "created": "Sat, 15 Mar 2014 18:41:23 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Hendricks", "Jacob", ""], ["Patitz", "Matthew J.", ""], ["Rogers", "Trent A.", ""]]}, {"id": "1403.3907", "submitter": "Chi-Kin Chau", "authors": "Chi-Kin Chau, Khaled Elbassioni, Majid Khonji", "title": "Truthful Mechanisms for Combinatorial AC Electric Power Allocation", "comments": "Appears in: Proceedings of the 13th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2014). With an updated\n  abstract and a correction in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional studies of combinatorial auctions often only consider linear\nconstraints (by which the demands for certain goods are limited by the\ncorresponding supplies). The rise of smart grid presents a new class of\nauctions, characterized by quadratic constraints. Yu and Chau [AAMAS 13']\nintroduced the complex-demand knapsack problem, in which the demands are\ncomplex-valued and the capacity of supplies is described by the magnitude of\ntotal complex-valued demand. This naturally captures the power constraints in\nAC electric systems. In this paper, we provide a more complete study and\ngeneralize the problem to the multi-minded version, beyond the previously known\n1/2-approximation algorithm for only a subclass of the problem. More precisely,\nwe give a truthful PTAS for the case phi in [0,pi/2-delta], and a truthful\nFPTAS, which fully optimizes the objective function but violates the capacity\nconstraint by at most (1+epsilon), for the case phi in (pi/2,pi-delta], where\nphi is the maximum angle between any two complex-valued demands and\nepsilon,delta>0 are arbitrarily small constants.\n", "versions": [{"version": "v1", "created": "Sun, 16 Mar 2014 11:36:20 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2014 13:14:33 GMT"}, {"version": "v3", "created": "Sun, 4 May 2014 17:42:51 GMT"}, {"version": "v4", "created": "Wed, 26 Nov 2014 10:18:37 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Chau", "Chi-Kin", ""], ["Elbassioni", "Khaled", ""], ["Khonji", "Majid", ""]]}, {"id": "1403.4445", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "A really simple approximation of smallest grammar", "comments": "Accepted for CPM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a really simple linear-time algorithm constructing a\ncontext-free grammar of size O(g log (N/g)) for the input string, where N is\nthe size of the input string and g the size of the optimal grammar generating\nthis string. The algorithm works for arbitrary size alphabets, but the running\ntime is linear assuming that the alphabet Sigma of the input string can be\nidentified with numbers from 1,ldots, N^c for some constant c. Algorithms with\nsuch an approximation guarantee and running time are known, however all of them\nwere non-trivial and their analyses were involved. The here presented algorithm\ncomputes the LZ77 factorisation and transforms it in phases to a grammar. In\neach phase it maintains an LZ77-like factorisation of the word with at most l\nfactors as well as additional O(l) letters, where l was the size of the\noriginal LZ77 factorisation. In one phase in a greedy way (by a left-to-right\nsweep and a help of the factorisation) we choose a set of pairs of consecutive\nletters to be replaced with new symbols, i.e. nonterminals of the constructed\ngrammar. We choose at least 2/3 of the letters in the word and there are O(l)\nmany different pairs among them. Hence there are O(log N) phases, each of them\nintroduces O(l) nonterminals to a grammar. A more precise analysis yields a\nbound O(l log(N/l)). As l \\leq g, this yields the desired bound O(g log(N/g)).\n", "versions": [{"version": "v1", "created": "Tue, 18 Mar 2014 13:27:46 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1403.4521", "submitter": "James Atwood", "authors": "James Atwood, Bruno Ribeiro, Don Towsley", "title": "Efficient Network Generation Under General Preferential Attachment", "comments": "James Atwood, Bruno Ribeiro, Don Towsley, Efficient Network\n  Generation Under General Preferential Attachment, SIMPLEX 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferential attachment (PA) models of network structure are widely used due\nto their explanatory power and conceptual simplicity. PA models are able to\naccount for the scale-free degree distributions observed in many real-world\nlarge networks through the remarkably simple mechanism of sequentially\nintroducing nodes that attach preferentially to high-degree nodes. The ability\nto efficiently generate instances from PA models is a key asset in\nunderstanding both the models themselves and the real networks that they\nrepresent. Surprisingly, little attention has been paid to the problem of\nefficient instance generation. In this paper, we show that the complexity of\ngenerating network instances from a PA model depends on the preference function\nof the model, provide efficient data structures that work under any preference\nfunction, and present empirical results from an implementation based on these\ndata structures. We demonstrate that, by indexing growing networks with a\nsimple augmented heap, we can implement a network generator which scales many\norders of magnitude beyond existing capabilities ($10^6$ -- $10^8$ nodes). We\nshow the utility of an efficient and general PA network generator by\ninvestigating the consequences of varying the preference functions of an\nexisting model. We also provide \"quicknet\", a freely-available open-source\nimplementation of the methods described in this work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Mar 2014 16:27:14 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 13:23:55 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Atwood", "James", ""], ["Ribeiro", "Bruno", ""], ["Towsley", "Don", ""]]}, {"id": "1403.4861", "submitter": "Philipp Kindermann", "authors": "Michael A. Bekos and Thomas C. van Dijk and Martin Fink and Philipp\n  Kindermann and Stephen Kobourov and Sergey Pupyrev and Joachim Spoerhase and\n  Alexander Wolff", "title": "Improved Approximation Algorithms for Box Contact Representations", "comments": null, "journal-ref": "Algorithmica 77(3): 902-920 (2017)", "doi": "10.1007/s00453-016-0121-3", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following geometric representation problem: Given a graph whose\nvertices correspond to axis-aligned rectangles with fixed dimensions, arrange\nthe rectangles without overlaps in the plane such that two rectangles touch if\nthe graph contains an edge between them. This problem is called \\textsc{Contact\nRepresentation of Word Networks} (\\textsc{Crown}) since it formalizes the\ngeometric problem behind drawing word clouds in which semantically related\nwords are close to each other. \\textsc{Crown} is known to be NP-hard, and there\nare approximation algorithms for certain graph classes for the optimization\nversion, \\textsc{Max-Crown}, in which realizing each desired adjacency yields a\ncertain profit. We present the first $O(1)$-approximation algorithm for the\ngeneral case, when the input is a complete weighted graph, and for the\nbipartite case. Since the subgraph of realized adjacencies is necessarily\nplanar, we also consider several planar graph classes (namely stars, trees,\nouterplanar, and planar graphs), improving upon the known results. For some\ngraph classes, we also describe improvements in the unweighted case, where each\nadjacency yields the same profit. Finally, we show that the problem is APX-hard\non bipartite graphs of bounded maximum degree.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 15:57:24 GMT"}, {"version": "v2", "created": "Wed, 19 Nov 2014 16:31:16 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Bekos", "Michael A.", ""], ["van Dijk", "Thomas C.", ""], ["Fink", "Martin", ""], ["Kindermann", "Philipp", ""], ["Kobourov", "Stephen", ""], ["Pupyrev", "Sergey", ""], ["Spoerhase", "Joachim", ""], ["Wolff", "Alexander", ""]]}, {"id": "1403.4991", "submitter": "Giorgio Lucarelli", "authors": "Evripidis Bampis, Alexander Kononov, Dimitrios Letsios, Giorgio\n  Lucarelli and Maxim Sviridenko", "title": "Energy Efficient Scheduling and Routing via Randomized Rounding", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unifying framework based on configuration linear programs and\nrandomized rounding, for different energy optimization problems in the dynamic\nspeed-scaling setting. We apply our framework to various scheduling and routing\nproblems in heterogeneous computing and networking environments. We first\nconsider the energy minimization problem of scheduling a set of jobs on a set\nof parallel speed scalable processors in a fully heterogeneous setting. For\nboth the preemptive-non-migratory and the preemptive-migratory variants, our\napproach allows us to obtain solutions of almost the same quality as for the\nhomogeneous environment. By exploiting the result for the\npreemptive-non-migratory variant, we are able to improve the best known\napproximation ratio for the single processor non-preemptive problem.\nFurthermore, we show that our approach allows to obtain a constant-factor\napproximation algorithm for the power-aware preemptive job shop scheduling\nproblem. Finally, we consider the min-power routing problem where we are given\na network modeled by an undirected graph and a set of uniform demands that have\nto be routed on integral routes from their sources to their destinations so\nthat the energy consumption is minimized. We improve the best known\napproximation ratio for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 21:52:55 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Bampis", "Evripidis", ""], ["Kononov", "Alexander", ""], ["Letsios", "Dimitrios", ""], ["Lucarelli", "Giorgio", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "1403.5111", "submitter": "Andreas Wotzlaw", "authors": "Andreas Wotzlaw", "title": "On Solving the Maximum $k$-club Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple undirected graph $G$, the maximum $k$-club problem is to find\na maximum-cardinality subset of nodes inducing a subgraph of diameter at most\n$k$ in $G$. This NP-hard generalization of clique, originally introduced to\nmodel low diameter clusters in social networks, is of interest in network-based\ndata mining and clustering applications. We give two MAX-SAT formulations of\nthe problem and show that two exact methods resulting from our encodings\noutperform significantly the state-of-the-art exact methods when evaluated both\non sparse and dense random graphs as well as on diverse real-life graphs from\nthe literature.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 12:28:43 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 07:37:16 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Wotzlaw", "Andreas", ""]]}, {"id": "1403.5171", "submitter": "Danupon Nanongkai", "authors": "Danupon Nanongkai", "title": "Distributed Approximation Algorithms for Weighted Shortest Paths", "comments": "Full version of STOC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed network is modeled by a graph having $n$ nodes (processors) and\ndiameter $D$. We study the time complexity of approximating {\\em weighted}\n(undirected) shortest paths on distributed networks with a $O(\\log n)$ {\\em\nbandwidth restriction} on edges (the standard synchronous \\congest model). The\nquestion whether approximation algorithms help speed up the shortest paths\n(more precisely distance computation) was raised since at least 2004 by Elkin\n(SIGACT News 2004). The unweighted case of this problem is well-understood\nwhile its weighted counterpart is fundamental problem in the area of\ndistributed approximation algorithms and remains widely open. We present new\nalgorithms for computing both single-source shortest paths (\\sssp) and\nall-pairs shortest paths (\\apsp) in the weighted case.\n  Our main result is an algorithm for \\sssp. Previous results are the classic\n$O(n)$-time Bellman-Ford algorithm and an $\\tilde O(n^{1/2+1/2k}+D)$-time\n$(8k\\lceil \\log (k+1) \\rceil -1)$-approximation algorithm, for any integer\n$k\\geq 1$, which follows from the result of Lenzen and Patt-Shamir (STOC 2013).\n(Note that Lenzen and Patt-Shamir in fact solve a harder problem, and we use\n$\\tilde O(\\cdot)$ to hide the $O(\\poly\\log n)$ term.) We present an $\\tilde\nO(n^{1/2}D^{1/4}+D)$-time $(1+o(1))$-approximation algorithm for \\sssp. This\nalgorithm is {\\em sublinear-time} as long as $D$ is sublinear, thus yielding a\nsublinear-time algorithm with almost optimal solution. When $D$ is small, our\nrunning time matches the lower bound of $\\tilde \\Omega(n^{1/2}+D)$ by Das Sarma\net al. (SICOMP 2012), which holds even when $D=\\Theta(\\log n)$, up to a\n$\\poly\\log n$ factor.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 15:30:46 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 05:35:21 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Nanongkai", "Danupon", ""]]}, {"id": "1403.5544", "submitter": "Ryan Lewis", "authors": "Ryan H. Lewis", "title": "Yet Another Graph Partitioning Problem is NP-Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a large number of graph separator problems have been proven to be\n\\textsc{NP-Hard}. Amazingly we have found that\n$\\alpha$-Subgraph-Balanced-Vertex-Separator, an important variant, has been\noverlooked. In this work ``Yet Another Graph Partitioning Problem is NP-Hard\"\nwe present the surprising result that\n$\\alpha$-Subgraph-Balanced-Vertex-Separator is $NP$-Hard. This is despite the\nfact that the constraints of our new problem are harder to satisfy than the\noriginal problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 19:03:10 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["Lewis", "Ryan H.", ""]]}, {"id": "1403.5606", "submitter": "Carlos Valencia", "authors": "Carlos E. Valencia and Marcos C. Vargas", "title": "Optimum matchings in weighted bipartite graphs", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an integer weighted bipartite graph $\\{G=(U\\sqcup V, E), w:E\\rightarrow\n\\mathbb{Z}\\}$ we consider the problems of finding all the edges that occur in\nsome minimum weight matching of maximum cardinality and enumerating all the\nminimum weight perfect matchings. Moreover, we construct a subgraph $G_{cs}$ of\n$G$ which depends on an $\\epsilon$-optimal solution of the dual linear program\nassociated to the assignment problem on $\\{G,w\\}$ that allows us to reduced\nthis problems to their unweighed variants on $G_{cs}$. For instance, when $G$\nhas a perfect matching and we have an $\\epsilon$-optimal solution of the dual\nlinear program associated to the assignment problem on $\\{G,w\\}$, we solve the\nproblem of finding all the edges that occur in some minimum weight perfect\nmatching in linear time on the number of edges. Therefore, starting from\nscratch we get an algorithm that solves this problem in time\n$O(\\sqrt{n}m\\log(nW))$, where $n=|U|\\geq |V|$, $m=|E|$, and $W={\\rm\nmax}\\{|w(e)|\\, :\\, e\\in E\\}$.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 03:16:26 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Valencia", "Carlos E.", ""], ["Vargas", "Marcos C.", ""]]}, {"id": "1403.5702", "submitter": "Dimitrios Thilikos", "authors": "Nathann Cohen, Daniel Gon\\c{c}alves, Eun Jung Kim, Christophe Paul,\n  Ignasi Sau, Dimitrios M. Thilikos, Mathias Weller", "title": "A Polynomial-time Algorithm for Outerplanar Diameter Improvement", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Outerplanar Diameter Improvement problem asks, given a graph $G$ and an\ninteger $D$, whether it is possible to add edges to $G$ in a way that the\nresulting graph is outerplanar and has diameter at most $D$. We provide a\ndynamic programming algorithm that solves this problem in polynomial time.\nOuterplanar Diameter Improvement demonstrates several structural analogues to\nthe celebrated and challenging Planar Diameter Improvement problem, where the\nresulting graph should, instead, be planar. The complexity status of this\nlatter problem is open.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 21:01:37 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 13:10:52 GMT"}, {"version": "v3", "created": "Fri, 23 May 2014 07:20:37 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Cohen", "Nathann", ""], ["Gon\u00e7alves", "Daniel", ""], ["Kim", "Eun Jung", ""], ["Paul", "Christophe", ""], ["Sau", "Ignasi", ""], ["Thilikos", "Dimitrios M.", ""], ["Weller", "Mathias", ""]]}, {"id": "1403.5804", "submitter": "Michael Kapralov", "authors": "Piotr Indyk and Michael Kapralov", "title": "Sample-Optimal Fourier Sampling in Any Constant Dimension -- Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for $\\ell_2/\\ell_2$ sparse recovery from Fourier\nmeasurements using $O(k\\log N)$ samples, matching the lower bound of\n\\cite{DIPW} for non-adaptive algorithms up to constant factors for any $k\\leq\nN^{1-\\delta}$. The algorithm runs in $\\tilde O(N)$ time. Our algorithm extends\nto higher dimensions, leading to sample complexity of $O_d(k\\log N)$, which is\noptimal up to constant factors for any $d=O(1)$. These are the first sample\noptimal algorithms for these problems.\n  A preliminary experimental evaluation indicates that our algorithm has\nempirical sampling complexity comparable to that of other recovery methods\nknown in the literature, while providing strong provable guarantees on the\nrecovery quality.\n", "versions": [{"version": "v1", "created": "Sun, 23 Mar 2014 21:39:20 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 21:59:47 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Indyk", "Piotr", ""], ["Kapralov", "Michael", ""]]}, {"id": "1403.5882", "submitter": "Bodo Manthey", "authors": "Maurits de Graaf and Bodo Manthey", "title": "Probabilistic Analysis of Power Assignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem for wireless ad hoc networks is the assignment of\nsuitable transmission powers to the wireless devices such that the resulting\ncommunication graph is connected. The goal is to minimize the total transmit\npower in order to maximize the life-time of the network. Our aim is a\nprobabilistic analysis of this power assignment problem. We prove complete\nconvergence for arbitrary combinations of the dimension d and the\ndistance-power gradient p. Furthermore, we prove that the expected\napproximation ratio of the simple spanning tree heuristic is strictly less than\nits worst-case ratio of 2.\n  Our main technical novelties are two-fold: First, we find a way to deal with\nthe unbounded degree that the communication network induced by the optimal\npower assignment can have. Minimum spanning trees and traveling salesman tours,\nfor which strong concentration results are known in Euclidean space, have\nbounded degree, which is heavily exploited in their analysis. Second, we apply\na recent generalization of Azuma-Hoeffding's inequality to prove complete\nconvergence for the case p>=d for both power assignments and minimum spanning\ntrees (MSTs). As far as we are aware, complete convergence for $p > d$ has not\nbeen proved yet for any Euclidean functional.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 08:50:59 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["de Graaf", "Maurits", ""], ["Manthey", "Bodo", ""]]}, {"id": "1403.5996", "submitter": "Matteo Dell'Amico Ph.D.", "authors": "Matteo Dell'Amico and Damiano Carra and Mario Pastorelli and Pietro\n  Michiardi", "title": "Revisiting Size-Based Scheduling with Estimated Job Sizes", "comments": "To be published in the proceedings of IEEE MASCOTS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study size-based schedulers, and focus on the impact of inaccurate job\nsize information on response time and fairness. Our intent is to revisit\nprevious results, which allude to performance degradation for even small errors\non job size estimates, thus limiting the applicability of size-based\nschedulers.\n  We show that scheduling performance is tightly connected to workload\ncharacteristics: in the absence of large skew in the job size distribution,\neven extremely imprecise estimates suffice to outperform size-oblivious\ndisciplines. Instead, when job sizes are heavily skewed, known size-based\ndisciplines suffer.\n  In this context, we show -- for the first time -- the dichotomy of\nover-estimation versus under-estimation. The former is, in general, less\nproblematic than the latter, as its effects are localized to individual jobs.\nInstead, under-estimation leads to severe problems that may affect a large\nnumber of jobs.\n  We present an approach to mitigate these problems: our technique requires no\ncomplex modifications to original scheduling policies and performs very well.\nTo support our claim, we proceed with a simulation-based evaluation that covers\nan unprecedented large parameter space, which takes into account a variety of\nsynthetic and real workloads.\n  As a consequence, we show that size-based scheduling is practical and\noutperforms alternatives in a wide array of use-cases, even in presence of\ninaccurate size information.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 15:23:57 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 12:36:59 GMT"}, {"version": "v3", "created": "Fri, 25 Jul 2014 16:47:31 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Dell'Amico", "Matteo", ""], ["Carra", "Damiano", ""], ["Pastorelli", "Mario", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1403.6135", "submitter": "Shuo Han", "authors": "Shuo Han, Ufuk Topcu, George J. Pappas", "title": "Differentially Private Convex Optimization with Piecewise Affine\n  Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a recently proposed notion of privacy that provides\nstrong privacy guarantees without any assumptions on the adversary. The paper\nstudies the problem of computing a differentially private solution to convex\noptimization problems whose objective function is piecewise affine. Such\nproblem is motivated by applications in which the affine functions that define\nthe objective function contain sensitive user information. We propose several\nprivacy preserving mechanisms and provide analysis on the trade-offs between\noptimality and the level of privacy for these mechanisms. Numerical experiments\nare also presented to evaluate their performance in practice.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 20:08:28 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Han", "Shuo", ""], ["Topcu", "Ufuk", ""], ["Pappas", "George J.", ""]]}, {"id": "1403.6188", "submitter": "Danupon Nanongkai", "authors": "Danupon Nanongkai", "title": "Brief Announcement: Almost-Tight Approximation Distributed Algorithm for\n  Minimum Cut", "comments": "To appear as a brief announcement at PODC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we present an improved algorithm for approximating the\nminimum cut on distributed (CONGEST) networks. Let $\\lambda$ be the minimum\ncut. Our algorithm can compute $\\lambda$ exactly in\n$\\tilde{O}((\\sqrt{n}+D)\\poly(\\lambda))$ time, where $n$ is the number of nodes\n(processors) in the network, $D$ is the network diameter, and $\\tilde{O}$ hides\n$\\poly\\log n$. By a standard reduction, we can convert this algorithm into a\n$(1+\\epsilon)$-approximation $\\tilde{O}((\\sqrt{n}+D)/\\poly(\\epsilon))$-time\nalgorithm. The latter result improves over the previous\n$(2+\\epsilon)$-approximation $\\tilde{O}((\\sqrt{n}+D)/\\poly(\\epsilon))$-time\nalgorithm of Ghaffari and Kuhn [DISC 2013]. Due to the lower bound of\n$\\tilde{\\Omega}(\\sqrt{n}+D)$ by Das Sarma et al. [SICOMP 2013], this running\ntime is {\\em tight} up to a $\\poly\\log n$ factor. Our algorithm is an extremely\nsimple combination of Thorup's tree packing theorem [Combinatorica 2007],\nKutten and Peleg's tree partitioning algorithm [J. Algorithms 1998], and\nKarger's dynamic programming [JACM 2000].\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 23:18:37 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 08:44:39 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Nanongkai", "Danupon", ""]]}, {"id": "1403.6207", "submitter": "Ravishankar Krishnaswamy", "authors": "Ravishankar Krishnaswamy, Viswanath Nagarajan, Kirk Pruhs, Cliff Stein", "title": "Cluster Before You Hallucinate: Approximating Node-Capacitated Network\n  Design and Energy Efficient Routing", "comments": "22 pages (full version of STOC 2014 paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider circuit routing with an objective of minimizing energy, in a\nnetwork of routers that are speed scalable and that may be shutdown when idle.\nWe consider both multicast routing and unicast routing. It is known that this\nenergy minimization problem can be reduced to a capacitated flow network design\nproblem, where vertices have a common capacity but arbitrary costs, and the\ngoal is to choose a minimum cost collection of vertices whose induced subgraph\nwill support the specified flow requirements. For the multicast (single-sink)\ncapacitated design problem we give a polynomial-time algorithm that is\nO(log^3n)-approximate with O(log^4 n) congestion. This translates back to a\nO(log ^(4{\\alpha}+3) n)-approximation for the multicast energy-minimization\nrouting problem, where {\\alpha} is the polynomial exponent in the dynamic power\nused by a router. For the unicast (multicommodity) capacitated design problem\nwe give a polynomial-time algorithm that is O(log^5 n)-approximate with\nO(log^12 n) congestion, which translates back to a O(log^(12{\\alpha}+5)\nn)-approximation for the unicast energy-minimization routing problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 01:38:59 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Krishnaswamy", "Ravishankar", ""], ["Nagarajan", "Viswanath", ""], ["Pruhs", "Kirk", ""], ["Stein", "Cliff", ""]]}, {"id": "1403.6331", "submitter": "P{\\aa}l Gr{\\o}n{\\aa}s Drange", "authors": "P{\\aa}l Gr{\\o}n{\\aa}s Drange, Markus Sortland Dregi, Pim van 't Hof", "title": "On the Computational Complexity of Vertex Integrity and Component Order\n  Connectivity", "comments": "A preliminary version of this paper already appeared in the\n  conference proceedings of ISAAC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weighted Vertex Integrity (wVI) problem takes as input an $n$-vertex\ngraph $G$, a weight function $w:V(G)\\to\\mathbb{N}$, and an integer $p$. The\ntask is to decide if there exists a set $X\\subseteq V(G)$ such that the weight\nof $X$ plus the weight of a heaviest component of $G-X$ is at most $p$. Among\nother results, we prove that:\n  (1) wVI is NP-complete on co-comparability graphs, even if each vertex has\nweight $1$;\n  (2) wVI can be solved in $O(p^{p+1}n)$ time;\n  (3) wVI admits a kernel with at most $p^3$ vertices.\n  Result (1) refutes a conjecture by Ray and Deogun and answers an open\nquestion by Ray et al. It also complements a result by Kratsch et al., stating\nthat the unweighted version of the problem can be solved in polynomial time on\nco-comparability graphs of bounded dimension, provided that an intersection\nmodel of the input graph is given as part of the input.\n  An instance of the Weighted Component Order Connectivity (wCOC) problem\nconsists of an $n$-vertex graph $G$, a weight function $w:V(G)\\to \\mathbb{N}$,\nand two integers $k$ and $l$, and the task is to decide if there exists a set\n$X\\subseteq V(G)$ such that the weight of $X$ is at most $k$ and the weight of\na heaviest component of $G-X$ is at most $l$. In some sense, the wCOC problem\ncan be seen as a refined version of the wVI problem. We prove, among other\nresults, that:\n  (4) wCOC can be solved in $O(\\min\\{k,l\\}\\cdot n^3)$ time on interval graphs,\nwhile the unweighted version can be solved in $O(n^2)$ time on this graph\nclass;\n  (5) wCOC is W[1]-hard on split graphs when parameterized by $k$ or by $l$;\n  (6) wCOC can be solved in $2^{O(k\\log l)} n$ time;\n  (7) wCOC admits a kernel with at most $kl(k+l)+k$ vertices.\n  We also show that result (6) is essentially tight by proving that wCOC cannot\nbe solved in $2^{o(k \\log l)}n^{O(1)}$ time, unless the ETH fails.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 13:11:09 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2014 11:32:17 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Drange", "P\u00e5l Gr\u00f8n\u00e5s", ""], ["Dregi", "Markus Sortland", ""], ["Hof", "Pim van 't", ""]]}, {"id": "1403.6347", "submitter": "Stefan Kratsch", "authors": "Matthew Johnson and Dieter Kratsch and Stefan Kratsch and Viresh Patel\n  and Dani\\\"el Paulusma", "title": "Finding Shortest Paths between Graph Colourings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-colouring reconfiguration problem asks whether, for a given graph\n$G$, two proper $k$-colourings $\\alpha$ and $\\beta$ of $G$, and a positive\ninteger $\\ell$, there exists a sequence of at most $\\ell+1$ proper\n$k$-colourings of $G$ which starts with $\\alpha$ and ends with $\\beta$ and\nwhere successive colourings in the sequence differ on exactly one vertex of\n$G$. We give a complete picture of the parameterized complexity of the\n$k$-colouring reconfiguration problem for each fixed $k$ when parameterized by\n$\\ell$. First we show that the $k$-colouring reconfiguration problem is\npolynomial-time solvable for $k=3$, settling an open problem of Cereceda, van\nden Heuvel and Johnson. Then, for all $k \\geq 4$, we show that the\n$k$-colouring reconfiguration problem, when parameterized by $\\ell$, is\nfixed-parameter tractable (addressing a question of Mouawad, Nishimura, Raman,\nSimjour and Suzuki) but that it has no polynomial kernel unless the polynomial\nhierarchy collapses.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 13:56:21 GMT"}, {"version": "v2", "created": "Mon, 31 Mar 2014 19:23:39 GMT"}, {"version": "v3", "created": "Tue, 1 Apr 2014 08:23:21 GMT"}, {"version": "v4", "created": "Wed, 29 Oct 2014 15:12:28 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Johnson", "Matthew", ""], ["Kratsch", "Dieter", ""], ["Kratsch", "Stefan", ""], ["Patel", "Viresh", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "1403.6600", "submitter": "Dirk Sudholt", "authors": "Dirk Sudholt", "title": "How Crossover Speeds Up Building-Block Assembly in Genetic Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We re-investigate a fundamental question: how effective is crossover in\nGenetic Algorithms in combining building blocks of good solutions? Although\nthis has been discussed controversially for decades, we are still lacking a\nrigorous and intuitive answer. We provide such answers for royal road functions\nand OneMax, where every bit is a building block. For the latter we show that\nusing crossover makes every ($\\mu$+$\\lambda$) Genetic Algorithm at least twice\nas fast as the fastest evolutionary algorithm using only standard bit mutation,\nup to small-order terms and for moderate $\\mu$ and $\\lambda$. Crossover is\nbeneficial because it effectively turns fitness-neutral mutations into\nimprovements by combining the right building blocks at a later stage. Compared\nto mutation-based evolutionary algorithms, this makes multi-bit mutations more\nuseful. Introducing crossover changes the optimal mutation rate on OneMax from\n$1/n$ to $(1+\\sqrt{5})/2 \\cdot 1/n \\approx 1.618/n$. This holds both for\nuniform crossover and $k$-point crossover. Experiments and statistical tests\nconfirm that our findings apply to a broad class of building-block functions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 09:28:56 GMT"}, {"version": "v2", "created": "Wed, 26 Nov 2014 11:46:21 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Sudholt", "Dirk", ""]]}, {"id": "1403.6602", "submitter": "Sebastian Wild", "authors": "Markus E. Nebel, Sebastian Wild", "title": "Pivot Sampling in Dual-Pivot Quicksort", "comments": "presented at AofA 2014 (http://www.aofa14.upmc.fr/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new dual-pivot Quicksort by Vladimir Yaroslavskiy - used in Oracle's Java\nruntime library since version 7 - features intriguing asymmetries in its\nbehavior. They were shown to cause a basic variant of this algorithm to use\nless comparisons than classic single-pivot Quicksort implementations. In this\npaper, we extend the analysis to the case where the two pivots are chosen as\nfixed order statistics of a random sample and give the precise leading term of\nthe average number of comparisons, swaps and executed Java Bytecode\ninstructions. It turns out that - unlike for classic Quicksort, where it is\noptimal to choose the pivot as median of the sample - the asymmetries in\nYaroslavskiy's algorithm render pivots with a systematic skew more efficient\nthan the symmetric choice. Moreover, the optimal skew heavily depends on the\nemployed cost measure; most strikingly, abstract costs like the number of swaps\nand comparisons yield a very different result than counting Java Bytecode\ninstructions, which can be assumed most closely related to actual running time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 09:37:30 GMT"}, {"version": "v2", "created": "Fri, 13 Jun 2014 08:44:20 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Nebel", "Markus E.", ""], ["Wild", "Sebastian", ""]]}, {"id": "1403.6758", "submitter": "Nicolas Schabanel", "authors": "David Eisenstat, Claire Mathieu and Nicolas Schabanel", "title": "Facility Location in Evolving Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamics of evolving social or infrastructure networks is a\nchallenge in applied areas such as epidemiology, viral marketing, or urban\nplanning. During the past decade, data has been collected on such networks but\nhas yet to be fully analyzed. We propose to use information on the dynamics of\nthe data to find stable partitions of the network into groups. For that\npurpose, we introduce a time-dependent, dynamic version of the facility\nlocation problem, that includes a switching cost when a client's assignment\nchanges from one facility to another. This might provide a better\nrepresentation of an evolving network, emphasizing the abrupt change of\nrelationships between subjects rather than the continuous evolution of the\nunderlying network. We show that in realistic examples this model yields indeed\nbetter fitting solutions than optimizing every snapshot independently. We\npresent an $O(\\log nT)$-approximation algorithm and a matching hardness result,\nwhere $n$ is the number of clients and $T$ the number of time steps. We also\ngive an other algorithms with approximation ratio $O(\\log nT)$ for the variant\nwhere one pays at each time step (leasing) for each open facility.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 17:17:44 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Eisenstat", "David", ""], ["Mathieu", "Claire", ""], ["Schabanel", "Nicolas", ""]]}, {"id": "1403.7058", "submitter": "Robert Krauthgamer", "authors": "Alexandr Andoni and Robert Krauthgamer and David P. Woodruff", "title": "The Sketching Complexity of Graph Cuts", "comments": "The current version differs slightly from an earlier one\n  (arXiv:1403.7058v1). First, the lower bound for the number of edges in\n  $(1+\\epsilon)$-cut sparsifiers is improved, and now our bound is tight.\n  Second, we retract our earlier claim that the sparsification algorithm can be\n  performed in two passes of streaming over the graph edges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sketching an input graph, so that given the sketch,\none can estimate the weight of any cut in the graph within factor $1+\\epsilon$.\nWe present lower and upper bounds on the size of a randomized sketch, focusing\non the dependence on the accuracy parameter $\\epsilon>0$.\n  First, we prove that for every $\\epsilon > 1/\\sqrt n$, every sketch that\nsucceeds (with constant probability) in estimating the weight of all cuts\n$(S,\\bar S)$ in an $n$-vertex graph (simultaneously), must be of size\n$\\Omega(n/\\epsilon^2)$ bits. In the special case where the sketch is itself a\nweighted graph (which may or may not be a subgraph) and the estimator is the\nsum of edge weights across the cut in the sketch, i.e., a cut sparsifier, we\nshow the sketch must have $\\Omega(n/\\epsilon^2)$ edges, which is optimal.\nDespite the long sequence of work on graph sparsification, no such lower bound\nwas known on the size of a cut sparsifier.\n  We then design a randomized sketch that, given $\\epsilon\\in(0,1)$ and an\nedge-weighted $n$-vertex graph, produces a sketch of size $\\tilde\nO(n/\\epsilon)$ bits, from which the weight of any cut $(S,\\bar S)$ can be\nreported, with high probability, within factor $1+\\epsilon$. The previous upper\nbound is $\\tilde O(n/\\epsilon^2)$ bits, which follows by storing a cut\nsparsifier (Bencz{\\'u}r and Karger, 1996). To obtain this improvement, we\ncritically use both that the sketch need only be correct on each fixed cut with\nhigh probability (rather than on all cuts), and that the estimation procedure\nof the data structure can be arbitrary (rather than a weighted subgraph). We\nalso show a lower bound of $\\Omega(n/\\epsilon)$ bits for the space requirement\nof any data structure achieving this guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 27 Mar 2014 14:42:11 GMT"}, {"version": "v2", "created": "Mon, 10 Nov 2014 19:54:35 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Andoni", "Alexandr", ""], ["Krauthgamer", "Robert", ""], ["Woodruff", "David P.", ""]]}, {"id": "1403.7343", "submitter": "Oded Lachish Dr", "authors": "Oded Lachish", "title": "O(log log rank) Competitive-Ratio for the Matroid Secretary Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\textit{Matroid Secretary Problem} (MSP), the elements of the ground\nset of a Matroid are revealed on-line one by one, each together with its value.\nAn algorithm for the MSP is \\textit{Matroid-Unknown} if, at every stage of its\nexecution: (i) it only knows the elements that have been revealed so far and\ntheir values, and (ii) it has access to an oracle for testing whether or not\nany subset of the elements that have been revealed so far is an independent\nset. An algorithm is \\textit{Known-Cardinality} if, in addition to (i) and\n(ii), it also initially knows the cardinality of the ground set of the Matroid.\nWe present here a Known-Cardinality and \\textit{Order-Oblivious} algorithm\nthat, with constant probability, selects an independent set of elements, whose\nvalue is at least the optimal value divided by $O(\\log{\\log{\\rho}})$, where\n$\\rho$ is the rank of the Matroid; that is, the algorithm has a\n\\textit{competitive-ratio} of $O(\\log{\\log{\\rho}})$. The best previous results\nfor a Known-Cardinality algorithm are a competitive-ratio of $O(\\log{\\rho})$,\nby Babaioff \\textit{et al.} (2007), and a competitive-ratio of\n$O(\\sqrt{\\log{\\rho}})$, by Chakraborty and Lachish (2012). In many non-trivial\ncases the algorithm we present has a competitive-ratio that is better than the\n$O(\\log{\\log{\\rho}})$. The cases in which it fails to do so are easily\ncharacterized. Understanding these cases may lead to improved algorithms for\nthe problem or, conversely, to non-trivial lower bounds.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 18:37:57 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 20:40:15 GMT"}, {"version": "v3", "created": "Sun, 24 Aug 2014 21:37:27 GMT"}, {"version": "v4", "created": "Tue, 2 Sep 2014 15:06:44 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Lachish", "Oded", ""]]}, {"id": "1403.7519", "submitter": "Christos Kalaitzis", "authors": "Christos Kalaitzis, Aleksander M\\c{a}dry, Alantha Newman, Luk\\'a\\v{s}\n  Pol\\'a\\v{c}ek and Ola Svensson", "title": "On the Configuration LP for Maximum Budgeted Allocation", "comments": "29 pages, 4 figures. To appear in the 17th Conference on Integer\n  Programming and Combinatorial Optimization (IPCO), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Maximum Budgeted Allocation problem, i.e., the problem of\nselling a set of $m$ indivisible goods to $n$ players, each with a separate\nbudget, such that we maximize the collected revenue. Since the natural\nassignment LP is known to have an integrality gap of $\\frac{3}{4}$, which\nmatches the best known approximation algorithms, our main focus is to improve\nour understanding of the stronger configuration LP relaxation. In this\ndirection, we prove that the integrality gap of the configuration LP is\nstrictly better than $\\frac{3}{4}$, and provide corresponding polynomial time\nroundings, in the following restrictions of the problem: (i) the Restricted\nBudgeted Allocation problem, in which all the players have the same budget and\nevery item has the same value for any player it can be sold to, and (ii) the\ngraph MBA problem, in which an item can be assigned to at most 2 players.\nFinally, we improve the best known upper bound on the integrality gap for the\ngeneral case from $\\frac{5}{6}$ to $2\\sqrt{2}-2\\approx 0.828$ and also prove\nhardness of approximation results for both cases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 19:59:11 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Kalaitzis", "Christos", ""], ["Mcadry", "Aleksander", ""], ["Newman", "Alantha", ""], ["Pol\u00e1\u010dek", "Luk\u00e1\u0161", ""], ["Svensson", "Ola", ""]]}, {"id": "1403.7579", "submitter": "EPTCS", "authors": "Benedikt L\\\"owe, Glynn Winskel", "title": "Proceedings 8th International Workshop on Developments in Computational\n  Models", "comments": null, "journal-ref": "EPTCS 143, 2014", "doi": "10.4204/EPTCS.143", "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the workshop series Developments in Computational Models (DCM) is\nto bring together researchers who are currently developing new computational\nmodels or new features for traditional computational models, in order to foster\ntheir interaction, to provide a forum for presenting new ideas and work in\nprogress, and to enable newcomers to learn about current activities in this\narea. The eighth workshop in the series, DCM 2012, was part of the celebrations\nof the Turing Centenary and was held as a satellite event of the Turing\ncentenary conference Computability in Europe 2012 (CiE 2012) in Cambridge. It\ntook place at Corpus Christi College in Cambridge on Sunday, 17 June 2013.\n  This electronic proceedings volume includes one of the keynote papers as well\nas revised versions of papers accepted for presentation by the programme\ncommittee.\n", "versions": [{"version": "v1", "created": "Sat, 29 Mar 2014 01:54:28 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["L\u00f6we", "Benedikt", ""], ["Winskel", "Glynn", ""]]}, {"id": "1403.7721", "submitter": "Rajsekar Manokaran", "authors": "Konstantin Makarychev and Rajsekar Manokaran and Maxim Sviridenko", "title": "Maximum Quadratic Assignment Problem: Reduction from Maximum Label Cover\n  and LP-based Approximation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for every positive $\\epsilon > 0$, unless NP $\\subset$ BPQP, it\nis impossible to approximate the maximum quadratic assignment problem within a\nfactor better than $2^{\\log^{1-\\epsilon} n}$ by a reduction from the maximum\nlabel cover problem. Our result also implies that Approximate Graph Isomorphism\nis not robust and is in fact, $1 - \\epsilon$ vs $\\epsilon$ hard assuming the\nUnique Games Conjecture.\n  Then, we present an $O(\\sqrt{n})$-approximation algorithm for the problem\nbased on rounding of the linear programming relaxation often used in the state\nof the art exact algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 09:13:49 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Manokaran", "Rajsekar", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "1403.7948", "submitter": "Marc Demange", "authors": "Ferhat Alkan, T\\\"urker B{\\i}y{\\i}ko\\u{g}lu, Marc Demange and Cesim\n  Erten", "title": "Structure of conflict graphs in constraint alignment problems and\n  algorithms", "comments": "22 pages, 6 figures", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 21 no.\n  4, Discrete Algorithms (September 11, 2019) dmtcs:5755", "doi": "10.23638/DMTCS-21-4-10", "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the constrained graph alignment problem which has applications in\nbiological network analysis. Given two input graphs $G_1=(V_1,E_1),\nG_2=(V_2,E_2)$, a pair of vertex mappings induces an {\\it edge conservation} if\nthe vertex pairs are adjacent in their respective graphs. %In general terms The\ngoal is to provide a one-to-one mapping between the vertices of the input\ngraphs in order to maximize edge conservation. However the allowed mappings are\nrestricted since each vertex from $V_1$ (resp. $V_2$) is allowed to be mapped\nto at most $m_1$ (resp. $m_2$) specified vertices in $V_2$ (resp. $V_1$). Most\nof results in this paper deal with the case $m_2=1$ which attracted most\nattention in the related literature. We formulate the problem as a maximum\nindependent set problem in a related {\\em conflict graph} and investigate\nstructural properties of this graph in terms of forbidden subgraphs. We are\ninterested, in particular, in excluding certain wheals, fans, cliques or claws\n(all terms are defined in the paper), which corresponds in excluding certain\ncycles, paths, cliques or independent sets in the neighborhood of each vertex.\nThen, we investigate algorithmic consequences of some of these properties,\nwhich illustrates the potential of this approach and raises new horizons for\nfurther works. In particular this approach allows us to reinterpret a known\npolynomial case in terms of conflict graph and to improve known approximation\nand fixed-parameter tractability results through efficiently solving the\nmaximum independent set problem in conflict graphs. Some of our new\napproximation results involve approximation ratios that are function of the\noptimal value, in particular its square root; this kind of results cannot be\nachieved for maximum independent set in general graphs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 11:18:32 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 17:23:39 GMT"}, {"version": "v3", "created": "Fri, 11 Aug 2017 03:55:36 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 13:10:50 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 05:33:12 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Alkan", "Ferhat", ""], ["B\u0131y\u0131ko\u011flu", "T\u00fcrker", ""], ["Demange", "Marc", ""], ["Erten", "Cesim", ""]]}, {"id": "1403.8144", "submitter": "Ping Li", "authors": "Ping Li, Michael Mitzenmacher, Anshumali Shrivastava", "title": "Coding for Random Projections and Approximate Near Neighbor Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical note compares two coding (quantization) schemes for random\nprojections in the context of sub-linear time approximate near neighbor search.\nThe first scheme is based on uniform quantization while the second scheme\nutilizes a uniform quantization plus a uniformly random offset (which has been\npopular in practice). The prior work compared the two schemes in the context of\nsimilarity estimation and training linear classifiers, with the conclusion that\nthe step of random offset is not necessary and may hurt the performance\n(depending on the similarity level). The task of near neighbor search is\nrelated to similarity estimation with importance distinctions and requires own\nstudy. In this paper, we demonstrate that in the context of near neighbor\nsearch, the step of random offset is not needed either and may hurt the\nperformance (sometimes significantly so, depending on the similarity and other\nparameters).\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 19:43:53 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Li", "Ping", ""], ["Mitzenmacher", "Michael", ""], ["Shrivastava", "Anshumali", ""]]}]