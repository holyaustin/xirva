[{"id": "2106.00001", "submitter": "Vikrant Singhal", "authors": "Vikrant Singhal, Thomas Steinke", "title": "Privately Learning Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private data analysis suffers a costly curse of dimensionality. However, the\ndata often has an underlying low-dimensional structure. For example, when\noptimizing via gradient descent, the gradients often lie in or near a\nlow-dimensional subspace. If that low-dimensional structure can be identified,\nthen we can avoid paying (in terms of privacy or accuracy) for the high ambient\ndimension.\n  We present differentially private algorithms that take input data sampled\nfrom a low-dimensional linear subspace (possibly with a small amount of error)\nand output that subspace (or an approximation to it). These algorithms can\nserve as a pre-processing step for other procedures.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:09:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Singhal", "Vikrant", ""], ["Steinke", "Thomas", ""]]}, {"id": "2106.00091", "submitter": "Kangning Wang", "authors": "Kamesh Munagala, Zeyu Shen and Kangning Wang", "title": "Optimal Algorithms for Multiwinner Elections and the Chamberlin-Courant\n  Rule", "comments": "Accepted by the Twenty-Second ACM Conference on Economics and\n  Computation (EC 2021)", "journal-ref": null, "doi": "10.1145/3465456.3467624", "report-no": null, "categories": "cs.GT cs.DS econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the algorithmic question of choosing a subset of candidates of a\ngiven size $k$ from a set of $m$ candidates, with knowledge of voters' ordinal\nrankings over all candidates. We consider the well-known and classic scoring\nrule for achieving diverse representation: the Chamberlin-Courant (CC) or\n$1$-Borda rule, where the score of a committee is the average over the voters,\nof the rank of the best candidate in the committee for that voter; and its\ngeneralization to the average of the top $s$ best candidates, called the\n$s$-Borda rule.\n  Our first result is an improved analysis of the natural and well-studied\ngreedy heuristic. We show that greedy achieves a $\\left(1 -\n\\frac{2}{k+1}\\right)$-approximation to the maximization (or satisfaction)\nversion of CC rule, and a $\\left(1 - \\frac{2s}{k+1}\\right)$-approximation to\nthe $s$-Borda score. Our result improves on the best known approximation\nalgorithm for this problem. We show that these bounds are almost tight.\n  For the dissatisfaction (or minimization) version of the problem, we show\nthat the score of $\\frac{m+1}{k+1}$ can be viewed as an optimal benchmark for\nthe CC rule, as it is essentially the best achievable score of any\npolynomial-time algorithm even when the optimal score is a polynomial factor\nsmaller (under standard computational complexity assumptions). We show that\nanother well-studied algorithm for this problem, called the Banzhaf rule,\nattains this benchmark.\n  We finally show that for the $s$-Borda rule, when the optimal value is small,\nthese algorithms can be improved by a factor of $\\tilde \\Omega(\\sqrt{s})$ via\nLP rounding. Our upper and lower bounds are a significant improvement over\nprevious results, and taken together, not only enable us to perform a finer\ncomparison of greedy algorithms for these problems, but also provide analytic\njustification for using such algorithms in practice.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 20:28:59 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Munagala", "Kamesh", ""], ["Shen", "Zeyu", ""], ["Wang", "Kangning", ""]]}, {"id": "2106.00124", "submitter": "Helen Xu", "authors": "Helen Xu, Sean Fraser, Charles E. Leiserson", "title": "Multidimensional Included and Excluded Sums", "comments": "18 pages, short version to appear in ACDA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents algorithms for the included-sums and excluded-sums\nproblems used by scientific computing applications such as the fast multipole\nmethod. These problems are defined in terms of a $d$-dimensional array of $N$\nelements and a binary associative operator~$\\oplus$ on the elements. The\nincluded-sum problem requires that the elements within overlapping boxes\ncornered at each element within the array be reduced using $\\oplus$. The\nexcluded-sum problem reduces the elements outside each box. The weak versions\nof these problems assume that the operator $\\oplus$ has an inverse $\\ominus$,\nwhereas the strong versions do not require this assumption. In addition to\nstudying existing algorithms to solve these problems, we introduce three new\nalgorithms.\n  The bidirectional box-sum (BDBS) algorithm solves the strong included-sums\nproblem in $\\Theta(d N)$ time, asymptotically beating the classical summed-area\ntable (SAT) algorithm, which runs in $\\Theta(2^d N)$ and which only solves the\nweak version of the problem. Empirically, the BDBS algorithm outperforms the\nSAT algorithm in higher dimensions by up to $17.1\\times$.\n  The \\defn{box-complement} algorithm can solve the strong excluded-sums\nproblem in $\\Theta(d N)$ time, asymptotically beating the state-of-the-art\ncorners algorithm by Demaine et al., which runs in $\\Omega(2^d N)$ time. In 3\ndimensions the box-complement algorithm empirically outperforms the corners\nalgorithm by about $1.4\\times$ given similar amounts of space.\n  The weak excluded-sums problem can be solved in $\\Theta(d N)$ time by the\nbidirectional box-sum complement (BDBSC) algorithm, which is a trivial\nextension of the BDBS algorithm. Given an operator inverse $\\ominus$, BDBSC can\nbeat box-complement by up to a factor of $4$.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 22:39:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Xu", "Helen", ""], ["Fraser", "Sean", ""], ["Leiserson", "Charles E.", ""]]}, {"id": "2106.00185", "submitter": "Tzu-Chi Yen", "authors": "Tzu-Chi Yen", "title": "Construction of Simplicial Complexes with Prescribed Degree-Size\n  Sequences", "comments": "6 pages, 4 figures. Code implementing our methods is available at\n  https://github.com/junipertcy/simplicial-test (Python, pip installable). Read\n  the Docs at https://docs.netscied.tw/simplicial-test/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS math.AT math.CO physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the realizability of simplicial complexes with a given pair of\ninteger sequences, representing the node degree distribution and facet size\ndistribution, respectively. While the $s$-uniform variant of the problem is\n$\\mathsf{NP}$-complete when $s \\geq 3$, we identify two populations of input\nsequences, most of which can be solved in polynomial time using a recursive\nalgorithm that we contribute. Combining with a sampler for the simplicial\nconfiguration model [Young $\\textit{et al.}$, Phys. Rev. E $\\textbf{96}$,\n032312 (2017)], we facilitate efficient sampling of simplicial ensembles from\narbitrary degree and size distributions. We find that, contrary to expectations\nbased on dyadic networks, increasing nodes' degrees reduces the number of loops\nin simplicial complexes. Our work unveils a fundamental constraint on the\ndegree-size sequences and sheds light on further analysis of higher-order\nphenomena based on local structures.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 02:21:44 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Yen", "Tzu-Chi", ""]]}, {"id": "2106.00232", "submitter": "Jiajian Liang", "authors": "Qian-Ping Gu, Jiajian Leo Liang", "title": "Multimodal Transportation with Ridesharing of Personal Vehicles", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current public transportation system is unable to keep up with the\ngrowing passenger demand as the population grows in urban areas. The slow or\nlack of improvements for public transportation pushes people to use private\ntransportation modes, such as carpooling and ridesharing. However, the\noccupancy rate of personal vehicles has been dropping in many cities. In this\npaper, we propose a centralized transit system that integrates public transit\nand ridesharing, which is capable of matching drivers and public transit riders\nsuch that the riders would result in shorter travel time. The optimization goal\nof the system is to assign as many riders to drivers as possible for\nridesharing. We describe an exact approach and approximation algorithms to\nachieve the optimization goal. We conduct an extensive computational study to\nshow the effectiveness of the transit system for different approximation\nalgorithms. Our experiments are based on the real-world traffic data in Chicago\nCity; the data sets include both public transit and ridesharing trip\ninformation. The experiment results show that our system is able to assign more\nthan 60% of riders to drivers, leading to a substantial increase in occupancy\nrate of personal vehicles and reducing riders' travel time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 05:14:09 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Gu", "Qian-Ping", ""], ["Liang", "Jiajian Leo", ""]]}, {"id": "2106.00274", "submitter": "Alex D\\'iaz Santos", "authors": "Alex D\\'iaz and Damian Steele", "title": "Analysis of classifiers robust to noisy labels", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore contemporary robust classification algorithms for overcoming\nclass-dependant labelling noise: Forward, Importance Re-weighting and\nT-revision. The classifiers are trained and evaluated on class-conditional\nrandom label noise data while the final test data is clean. We demonstrate\nmethods for estimating the transition matrix in order to obtain better\nclassifier performance when working with noisy data. We apply deep learning to\nthree data-sets and derive an end-to-end analysis with unknown noise on the\nCIFAR data-set from scratch. The effectiveness and robustness of the\nclassifiers are analysed, and we compare and contrast the results of each\nexperiment are using top-1 accuracy as our criterion.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:14:51 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["D\u00edaz", "Alex", ""], ["Steele", "Damian", ""]]}, {"id": "2106.00279", "submitter": "Quentin Stout", "authors": "Quentin F. Stout", "title": "$L_0$ Isotonic Regression With Secondary Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We provide algorithms for isotonic regression minimizing $L_0$ error (Hamming\ndistance). This is also known as monotonic relabeling, and is applicable when\nlabels have a linear ordering but not necessarily a metric. There may be\nexponentially many optimal relabelings, so we look at secondary criteria to\ndetermine which are best. For arbitrary ordinal labels the criterion is\nmaximizing the number of labels which are only changed to an adjacent label\n(and recursively apply this). For real-valued labels we minimize the $L_p$\nerror. For linearly ordered sets we also give algorithms which minimize the sum\nof the $L_p$ and weighted $L_0$ errors, a form of penalized (regularized)\nregression. We also examine $L_0$ isotonic regression on multidimensional\ncoordinate-wise orderings. Previous algorithms took $\\Theta(n^3)$ time, but we\nreduce this to $o(n^{3/2})$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:19:17 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Stout", "Quentin F.", ""]]}, {"id": "2106.00287", "submitter": "Michael Whitmeyer", "authors": "Vishnu Iyer, Avishay Tal, Michael Whitmeyer", "title": "Junta Distance Approximation with Sub-Exponential Queries", "comments": "To appear in CCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two\ndifferent results pertaining to the \\emph{tolerant testing} of juntas. Given\nblack-box access to a Boolean function $f:\\{\\pm1\\}^{n} \\to \\{\\pm1\\}$, we give a\n$poly(k, \\frac{1}{\\varepsilon})$ query algorithm that distinguishes between\nfunctions that are $\\gamma$-close to $k$-juntas and $(\\gamma+\\varepsilon)$-far\nfrom $k'$-juntas, where $k' = O(\\frac{k}{\\varepsilon^2})$.\n  In the non-relaxed setting, we extend our ideas to give a\n$2^{\\tilde{O}(\\sqrt{k/\\varepsilon})}$ (adaptive) query algorithm that\ndistinguishes between functions that are $\\gamma$-close to $k$-juntas and\n$(\\gamma+\\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this\nis the first subexponential-in-$k$ query algorithm for approximating the\ndistance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,\nLevi, and Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required\nexponentially many queries in $k$).\n  Our techniques are Fourier analytical and make use of the notion of\n\"normalized influences\" that was introduced by Talagrand [AoP, 1994].\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:39:26 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Iyer", "Vishnu", ""], ["Tal", "Avishay", ""], ["Whitmeyer", "Michael", ""]]}, {"id": "2106.00308", "submitter": "Jonathan Scarlett", "authors": "Eric Price and Jonathan Scarlett and Nelvin Tan", "title": "Fast Splitting Algorithms for Sparsity-Constrained and Noisy Group\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In group testing, the goal is to identify a subset of defective items within\na larger set of items based on tests whose outcomes indicate whether at least\none defective item is present. This problem is relevant in areas such as\nmedical testing, DNA sequencing, communication protocols, and many more. In\nthis paper, we study (i) a sparsity-constrained version of the problem, in\nwhich the testing procedure is subjected to one of the following two\nconstraints: items are finitely divisible and thus may participate in at most\n$\\gamma$ tests; or tests are size-constrained to pool no more than $\\rho$ items\nper test; and (ii) a noisy version of the problem, where each test outcome is\nindependently flipped with some constant probability. Under each of these\nsettings, considering the for-each recovery guarantee with asymptotically\nvanishing error probability, we introduce a fast splitting algorithm and\nestablish its near-optimality not only in terms of the number of tests, but\nalso in terms of the decoding time. While the most basic formulations of our\nalgorithms require $\\Omega(n)$ storage for each algorithm, we also provide\nlow-storage variants based on hashing, with similar recovery guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:30:53 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Price", "Eric", ""], ["Scarlett", "Jonathan", ""], ["Tan", "Nelvin", ""]]}, {"id": "2106.00323", "submitter": "Chundong Wang", "authors": "Chongnan Ye and Chundong Wang", "title": "Boosting the Search Performance of B+-tree for Non-volatile Memory with\n  Sentinels", "comments": "Accepted and Presented at MSC 2020 (@ESWeek 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The next-generation non-volatile memory (NVM) is striding into computer\nsystems as a new tier as it incorporates both DRAM's byte-addressability and\ndisk's persistency. Researchers and practitioners have considered building\npersistent memory by placing NVM on the memory bus for CPU to directly load and\nstore data. As a result, cache-friendly data structures have been developed for\nNVM. One of them is the prevalent B+-tree. State-of-the-art in-NVM B+-trees\nmainly focus on the optimization of write operations (insertion and deletion).\nHowever, search is of vital importance for B+-tree. Not only search-intensive\nworkloads benefit from an optimized search, but insertion and deletion also\nrely on a preceding search operation to proceed. In this paper, we attentively\nstudy a sorted B+-tree node that spans over contiguous cache lines. Such cache\nlines exhibit a monotonically increasing trend and searching a target key\nacross them can be accelerated by estimating a range the key falls into. To do\nso, we construct a probing Sentinel Array in which a sentinel stands for each\ncache line of B+-tree node. Checking the Sentinel Array avoids scanning\nunnecessary cache lines and hence significantly reduces cache misses for a\nsearch. A quantitative evaluation shows that using Sentinel Arrays boosts the\nsearch performance of state-of-the-art in-NVM B+-trees by up to 48.4% while the\ncost of maintaining of Sentinel Array is low.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:53:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ye", "Chongnan", ""], ["Wang", "Chundong", ""]]}, {"id": "2106.00374", "submitter": "Michal Dory", "authors": "Michal Dory, Merav Parter", "title": "Fault-Tolerant Labeling and Compact Routing Schemes", "comments": "PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents fault-tolerant (FT) labeling schemes for general graphs,\nas well as, improved FT routing schemes. For a given $n$-vertex graph $G$ and a\nbound $f$ on the number of faults, an $f$-FT connectivity labeling scheme is a\ndistributed data structure that assigns each of the graph edges and vertices a\nshort label, such that given the labels of the vertices $s$ and $t$, and at\nmost $f$ failing edges $F$, one can determine if $s$ and $t$ are connected in\n$G \\setminus F$. The primary complexity measure is the length of the individual\nlabels. Since their introduction by [Courcelle, Twigg, STACS '07], compact FT\nlabeling schemes have been devised only for a limited collection of graph\nfamilies. In this work, we fill in this gap by proposing two (independent) FT\nconnectivity labeling schemes for general graphs, with a nearly optimal label\nlength. This serves the basis for providing also FT approximate distance\nlabeling schemes, and ultimately also routing schemes. Our main results for an\n$n$-vertex graph and a fault bound $f$ are:\n  -- There is a randomized FT connectivity labeling scheme with a label length\nof $O(f+\\log n)$ bits, hence optimal for $f=O(\\log n)$. This scheme is based on\nthe notion of cycle space sampling [Pritchard, Thurimella, TALG '11].\n  -- There is a randomized FT connectivity labeling scheme with a label length\nof $O(\\log^3 n)$ bits (independent of the number of faults $f$). This scheme is\nbased on the notion of linear sketches of [Ahn et al., SODA '12].\n  -- For $k\\geq 1$, there is a randomized routing scheme that routes a message\nfrom $s$ to $t$ in the presence of a set $F$ of faulty edges, with stretch\n$O(|F|^2 k)$ and routing tables of size $\\tilde{O}(f^3 n^{1/k})$.\n  This significantly improves over the state-of-the-art bounds by [Chechik,\nICALP '11], providing the first scheme with sub-linear FT labeling and routing\nschemes for general graphs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:36:30 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Dory", "Michal", ""], ["Parter", "Merav", ""]]}, {"id": "2106.00463", "submitter": "Ziyue Huang", "authors": "Ziyue Huang, Yuting Liang, Ke Yi", "title": "Instance-optimal Mean Estimation Under Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean estimation under differential privacy is a fundamental problem, but\nworst-case optimal mechanisms do not offer meaningful utility guarantees in\npractice when the global sensitivity is very large. Instead, various heuristics\nhave been proposed to reduce the error on real-world data that do not resemble\nthe worst-case instance. This paper takes a principled approach, yielding a\nmechanism that is instance-optimal in a strong sense. In addition to its\ntheoretical optimality, the mechanism is also simple and practical, and adapts\nto a variety of data characteristics without the need of parameter tuning. It\neasily extends to the local and shuffle model as well.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:15:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Huang", "Ziyue", ""], ["Liang", "Yuting", ""], ["Yi", "Ke", ""]]}, {"id": "2106.00508", "submitter": "Alireza Farhadi", "authors": "Alireza Farhadi, MohammadTaghi Hajiaghayi and Elaine Shi", "title": "Differentially Private Densest Subgraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a graph, the densest subgraph problem asks for a set of vertices such\nthat the average degree among these vertices is maximized. Densest subgraph has\nnumerous applications in learning, e.g., community detection in social\nnetworks, link spam detection, correlation mining, bioinformatics, and so on.\nAlthough there are efficient algorithms that output either exact or approximate\nsolutions to the densest subgraph problem, existing algorithms may violate the\nprivacy of the individuals in the network, e.g., leaking the\nexistence/non-existence of edges.\n  In this paper, we study the densest subgraph problem in the framework of the\ndifferential privacy, and we derive the first upper and lower bounds for this\nproblem. We show that there exists a linear-time $\\epsilon$-differentially\nprivate algorithm that finds a $2$-approximation of the densest subgraph with\nan extra poly-logarithmic additive error. Our algorithm not only reports the\napproximate density of the densest subgraph, but also reports the vertices that\nform the dense subgraph.\n  Our upper bound almost matches the famous $2$-approximation by Charikar both\nin performance and in approximation ratio, but we additionally achieve\ndifferential privacy. In comparison with Charikar's algorithm, our algorithm\nhas an extra poly-logarithmic additive error. We partly justify the additive\nerror with a new lower bound, showing that for any differentially private\nalgorithm that provides a constant-factor approximation, a sub-logarithmic\nadditive error is inherent.\n  We also practically study our differentially private algorithm on real-world\ngraphs, and we show that in practice the algorithm finds a solution which is\nvery close to the optimal\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:11:18 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Farhadi", "Alireza", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Shi", "Elaine", ""]]}, {"id": "2106.00604", "submitter": "Robert Kleinberg", "authors": "Jon Kleinberg, Robert Kleinberg, and Sigal Oren", "title": "Optimal Stopping with Behaviorally Biased Agents: The Role of Loss\n  Aversion and Changing Reference Points", "comments": "To appear in the 2021 ACM Conference on Economics and Computation\n  (EC'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are often reluctant to sell a house, or shares of stock, below the\nprice at which they originally bought it. While this is generally not\nconsistent with rational utility maximization, it does reflect two strong\nempirical regularities that are central to the behavioral science of human\ndecision-making: a tendency to evaluate outcomes relative to a reference point\ndetermined by context (in this case the original purchase price), and the\nphenomenon of loss aversion in which people are particularly prone to avoid\noutcomes below the reference point. Here we explore the implications of\nreference points and loss aversion in optimal stopping problems, where people\nevaluate a sequence of options in one pass, either accepting the option and\nstopping the search or giving up on the option forever. The best option seen so\nfar sets a reference point that shifts as the search progresses, and a biased\ndecision-maker's utility incurs an additional penalty when they accept a later\noption that is below this reference point.\n  We formulate and study a behaviorally well-motivated version of the optimal\nstopping problem that incorporates these notions of reference dependence and\nloss aversion. We obtain tight bounds on the performance of a biased agent in\nthis model relative to the best option obtainable in retrospect (a type of\nprophet inequality for biased agents), as well as tight bounds on the ratio\nbetween the performance of a biased agent and the performance of a rational\none. We further establish basic monotonicity results, and show an exponential\ngap between the performance of a biased agent in a stopping problem with\nrespect to a worst-case versus a random order. As part of this, we establish\nfundamental differences between optimal stopping problems for rational versus\nbiased agents, and these differences inform our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 16:12:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Kleinberg", "Jon", ""], ["Kleinberg", "Robert", ""], ["Oren", "Sigal", ""]]}, {"id": "2106.00623", "submitter": "Arindam Khan", "authors": "Waldo Galvez, Arindam Khan, Mathieu Mari, Tobias Momke, Madhusudhan\n  Reddy, Andreas Wiese", "title": "A 3-Approximation Algorithm for Maximum Independent Set of Rectangles", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Maximum Independent Set of Rectangles (MISR) problem, where we\nare given a set of axis-parallel rectangles in the plane and the goal is to\nselect a subset of non-overlapping rectangles of maximum cardinality. In a\nrecent breakthrough, Mitchell [2021] obtained the first constant-factor\napproximation algorithm for MISR. His algorithm achieves an approximation ratio\nof 10 and it is based on a dynamic program that intuitively recursively\npartitions the input plane into special polygons called corner-clipped\nrectangles, without intersecting certain special horizontal line segments\ncalled fences.\n  In this paper, we present a 3-approximation algorithm for MISR which is based\non a similar recursive partitioning scheme. First, we use a partition into a\nmore general class of axis-parallel polygons with constant complexity each,\nwhich allows us to provide an arguably simpler analysis and at the same time\nalready improves the approximation ratio to 6. Then, using a more elaborate\ncharging scheme and a recursive partitioning into general axis-parallel\npolygons with constant complexity, we improve our approximation ratio to 3. In\nparticular, our partitioning uses more general fences that can be sequences of\nup to O(1) line segments each. This and our other new ideas may be useful for\nfuture work towards a PTAS for MISR.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 16:34:15 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 13:18:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Galvez", "Waldo", ""], ["Khan", "Arindam", ""], ["Mari", "Mathieu", ""], ["Momke", "Tobias", ""], ["Reddy", "Madhusudhan", ""], ["Wiese", "Andreas", ""]]}, {"id": "2106.00657", "submitter": "Madison Cooley", "authors": "Madison Cooley, Casey S. Greene, Davis Issac, Milton Pividori, and\n  Blair D. Sullivan", "title": "Parameterized algorithms for identifying gene co-expression modules via\n  weighted clique decomposition", "comments": "To be published in SIAM Conference on Applied and Computational\n  Discrete Algorithms 2021 (ACDA21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new combinatorial model for identifying regulatory modules in\ngene co-expression data using a decomposition into weighted cliques. To capture\ncomplex interaction effects, we generalize the previously-studied weighted edge\nclique partition problem. As a first step, we restrict ourselves to the\nnoise-free setting, and show that the problem is fixed parameter tractable when\nparameterized by the number of modules (cliques). We present two new algorithms\nfor finding these decompositions, using linear programming and integer\npartitioning to determine the clique weights. Further, we implement these\nalgorithms in Python and test them on a biologically-inspired synthetic corpus\ngenerated using real-world data from transcription factors and a latent\nvariable analysis of co-expression in varying cell types.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:44:55 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Cooley", "Madison", ""], ["Greene", "Casey S.", ""], ["Issac", "Davis", ""], ["Pividori", "Milton", ""], ["Sullivan", "Blair D.", ""]]}, {"id": "2106.00718", "submitter": "Binghui Peng", "authors": "Christos Papadimitriou and Binghui Peng", "title": "Public Goods Games in Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public goods games in undirected networks are generally known to have pure\nNash equilibria, which are easy to find. In contrast, we prove that, in\ndirected networks, a broad range of public goods games have intractable\nequilibrium problems: The existence of pure Nash equilibria is NP-hard to\ndecide, and mixed Nash equilibria are PPAD-hard to find. We define general\nutility public goods games, and prove a complexity dichotomy result for finding\npure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even\nin the divisible goods variant of the problem, where existence is easy to\nprove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of\nthe directed network is appropriately bounded, we prove that polynomial-time\nalgorithms are possible.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:25:06 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 14:17:13 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Papadimitriou", "Christos", ""], ["Peng", "Binghui", ""]]}, {"id": "2106.00730", "submitter": "Tavor Baharav", "authors": "Tavor Z. Baharav, Daniel L. Jiang, Kedarnath Kolluri, Sujay Sanghavi,\n  Inderjit S. Dhillon", "title": "Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMC) aims to learn a model that can tag\ndata points with a subset of relevant labels from an extremely large label set.\nReal world e-commerce applications like personalized recommendations and\nproduct advertising can be formulated as XMC problems, where the objective is\nto predict for a user a small subset of items from a catalog of several million\nproducts. For such applications, a common approach is to organize these labels\ninto a tree, enabling training and inference times that are logarithmic in the\nnumber of labels. While training a model once a label tree is available is well\nstudied, designing the structure of the tree is a difficult task that is not\nyet well understood, and can dramatically impact both model latency and\nstatistical performance. Existing approaches to tree construction fall at an\nextreme point, either optimizing exclusively for statistical performance, or\nfor latency. We propose an efficient information theory inspired algorithm to\nconstruct intermediary operating points that trade off between the benefits of\nboth. Our algorithm enables interpolation between these objectives, which was\nnot previously possible. We corroborate our theoretical analysis with numerical\nresults, showing that on the Wiki-500K benchmark dataset our method can reduce\na proxy for expected latency by up to 28% while maintaining the same accuracy\nas Parabel. On several datasets derived from e-commerce customer logs, our\nmodified label tree is able to improve this expected latency metric by up to\n20% while maintaining the same accuracy. Finally, we discuss challenges in\nrealizing these latency improvements in deployed models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 19:02:09 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Baharav", "Tavor Z.", ""], ["Jiang", "Daniel L.", ""], ["Kolluri", "Kedarnath", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "2106.00909", "submitter": "Nate Veldt", "authors": "Nate Veldt and Austin R. Benson and Jon Kleinberg", "title": "The Generalized Mean Densest Subgraph Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding dense subgraphs of a large graph is a standard problem in graph\nmining that has been studied extensively both for its theoretical richness and\nits many practical applications. In this paper we introduce a new family of\ndense subgraph objectives, parameterized by a single parameter $p$, based on\ncomputing generalized means of degree sequences of a subgraph. Our objective\ncaptures both the standard densest subgraph problem and the maximum $k$-core as\nspecial cases, and provides a way to interpolate between and extrapolate beyond\nthese two objectives when searching for other notions of dense subgraphs. In\nterms of algorithmic contributions, we first show that our objective can be\nminimized in polynomial time for all $p \\geq 1$ using repeated submodular\nminimization. A major contribution of our work is analyzing the performance of\ndifferent types of peeling algorithms for dense subgraphs both in theory and\npractice. We prove that the standard peeling algorithm can perform arbitrarily\npoorly on our generalized objective, but we then design a more sophisticated\npeeling method which for $p \\geq 1$ has an approximation guarantee that is\nalways at least $1/2$ and converges to 1 as $p \\rightarrow \\infty$. In\npractice, we show that this algorithm obtains extremely good approximations to\nthe optimal solution, scales to large graphs, and highlights a range of\ndifferent meaningful notions of density on graphs coming from numerous domains.\nFurthermore, it is typically able to approximate the densest subgraph problem\nbetter than the standard peeling algorithm, by better accounting for how the\nremoval of one node affects other nodes in its neighborhood.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:58:35 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 01:31:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Veldt", "Nate", ""], ["Benson", "Austin R.", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2106.01036", "submitter": "Shaked Matar", "authors": "Michael Elkin, Shaked Matar", "title": "Ultra-Sparse Near-Additive Emulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-additive (aka $(1+\\epsilon,\\beta)$-) emulators and spanners are a\nfundamental graph-algorithmic construct, with numerous applications for\ncomputing approximate shortest paths and related problems in distributed,\nstreaming and dynamic settings.\n  Known constructions of near-additive emulators enable one to trade between\ntheir sparsity (i.e., number of edges) and the additive stretch $\\beta$.\nSpecifically, for any pair of parameters $\\epsilon >0$, $ \\kappa=1,2,\\dots$,\none can have a $(1+\\epsilon,\\beta)$-emulator with $O(n^{1+1/\\kappa})$ edges,\nwith $\\beta = \\left(\\frac{\\log \\kappa}{\\epsilon}\\right)^{\\log \\kappa}$. At\ntheir sparsest, these emulators employ $c\\cdot n$ edges, for some constant\n$c\\geq 2$.\n  We tighten this bound, and show that in fact precisely $n^{1+1/\\kappa}$ edges\nsuffice.\n  In particular, our emulators can be \\emph{ultra-sparse}, i.e., we can have an\nemulator with $n+o(n)$ edges and $\\beta = \\left(\\frac{\\log {\\log n}}{\\epsilon\n}\\right)^{{\\log {\\log n}}(1+o(1))}$.\n  We also devise a distributed deterministic algorithm in the CONGEST model\nthat builds these emulators in low polynomial time (i.e., in $O(n^\\rho)$ time,\nfor an arbitrarily small constant parameter $\\rho >0$).\n  Finally, we also improve the state-of-the-art distributed deterministic\n\\congest-model construction of\n  $(1+\\epsilon,\\beta)$-spanners devised in the PODC'19 paper\n  [ElkinM19]. Specifically, the spanners of [ElkinM19] have $O(\\beta\\cdot\nn^{1+1/\\kappa})$ edges, i.e., at their sparsest they employ\n  $ O\\left(\\frac{\\log {\\log n}}{\\epsilon }\\right)^{{\\log {\\log n}}}\\cdot n$\nedges. In this paper, we devise an efficient distributed deterministic\nCONGEST-model algorithm that builds such spanners with $O(n^{1+1/\\kappa})$\nedges for $\\kappa = O\\left(\\frac{\\log n}{\\log ^{(3)}n}\\right)$. At their\nsparsest, these spanners employ only $O(n\\cdot {\\log {\\log n}})$ edges.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 09:10:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Elkin", "Michael", ""], ["Matar", "Shaked", ""]]}, {"id": "2106.01079", "submitter": "Chenyang Xu", "authors": "Thomas Lavastida, Benjamin Moseley, R. Ravi and Chenyang Xu", "title": "Using Predicted Weights for Ad Delivery", "comments": "15 pages, 10 figures. To appear in ACDA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of a proportional weights algorithm for online\ncapacitated bipartite matching modeling the delivery of impression ads. The\nalgorithm uses predictions on the advertiser nodes to match arriving impression\nnodes fractionally in proportion to the weights of its neighbors. This paper\ngives a thorough empirical study of the performance of the algorithm on a\ndata-set of ad impressions from Yahoo! and shows its superior performance\ncompared to natural baselines such as a greedy water-filling algorithm and the\nranking algorithm. The proportional weights algorithm has recently received\ninterest in the theoretical literature where it was shown to have strong\nguarantees beyond the worst-case model of algorithms augmented with\npredictions. We extend these results to the case where the advertisers'\ncapacities are no longer stationary over time. Additionally, we show the\nalgorithm has near optimal performance in the random-order arrival model when\nthe number of impressions and the optimal matching are sufficiently large.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:26:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lavastida", "Thomas", ""], ["Moseley", "Benjamin", ""], ["Ravi", "R.", ""], ["Xu", "Chenyang", ""]]}, {"id": "2106.01108", "submitter": "Fabien Dufoulon", "authors": "Fabien Dufoulon (Technion - Israel Institute of Technology), Shay\n  Kutten (Technion - Israel Institute of Technology) and William K. Moses Jr.\n  (University of Houston)", "title": "Efficient Deterministic Leader Election for Programmable Matter", "comments": "PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It was suggested that a programmable matter system (composed of multiple\ncomputationally weak mobile particles) should remain connected at all times\nsince otherwise, reconnection is difficult and may be impossible. At the same\ntime, it was not clear that allowing the system to disconnect carried a\nsignificant advantage in terms of time complexity. We demonstrate for a\nfundamental task, that of leader election, an algorithm where the system\ndisconnects and then reconnects automatically in a non-trivial way (particles\ncan move far away from their former neighbors and later reconnect to others).\nMoreover, the runtime of the temporarily disconnecting deterministic leader\nelection algorithm is linear in the diameter. Hence, the disconnecting --\nreconnecting algorithm is as fast as previous randomized algorithms. When\ncomparing to previous deterministic algorithms, we note that some of the\nprevious work assumed weaker schedulers. Still, the runtime of all the previous\ndeterministic algorithms that did not assume special shapes of the particle\nsystem (shapes with no holes) was at least quadratic in $n$, where $n$ is the\nnumber of particles in the system. (Moreover, the new algorithm is even faster\nin some parameters than the deterministic algorithms that did assume special\ninitial shapes.)\n  Since leader election is an important module in algorithms for various other\ntasks, the presented algorithm can be useful for speeding up other algorithms\nunder the assumption of a strong scheduler. This leaves open the question: \"can\na deterministic algorithm be as fast as the randomized ones also under weaker\nschedulers?\"\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:18:57 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dufoulon", "Fabien", "", "Technion - Israel Institute of Technology"], ["Kutten", "Shay", "", "Technion - Israel Institute of Technology"], ["Moses", "William K.", "Jr.", "University of Houston"]]}, {"id": "2106.01135", "submitter": "Noemie Perivier", "authors": "Abdellah Aznag, Vineet Goyal and Noemie Perivier", "title": "MNL-Bandit with Knapsacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a dynamic assortment selection problem where a seller has a fixed\ninventory of $N$ substitutable products and faces an unknown demand that\narrives sequentially over $T$ periods. In each period, the seller needs to\ndecide on the assortment of products (of cardinality at most $K$) to offer to\nthe customers. The customer's response follows an unknown multinomial logit\nmodel (MNL) with parameters $v$. The goal of the seller is to maximize the\ntotal expected revenue given the fixed initial inventory of $N$ products. We\ngive a policy that achieves a regret of $\\tilde O\\left(K \\sqrt{K N T}\\left(1 +\n\\frac{\\sqrt{v_{\\max}}}{q_{\\min}}\\text{OPT}\\right) \\right)$ under a mild\nassumption on the model parameters. In particular, our policy achieves a\nnear-optimal $\\tilde O(\\sqrt{T})$ regret in the large inventory setting.\n  Our policy builds upon the UCB-based approach for MNL-bandit without\ninventory constraints in [1] and addresses the inventory constraints through an\nexponentially sized LP for which we present a tractable approximation while\nkeeping the $\\tilde O(\\sqrt{T})$ regret bound.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:05:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Aznag", "Abdellah", ""], ["Goyal", "Vineet", ""], ["Perivier", "Noemie", ""]]}, {"id": "2106.01173", "submitter": "Yuto Nakashima", "authors": "Takumi Ideue, Takuya Mieno, Mitsuru Funakoshi, Yuto Nakashima,\n  Shunsuke Inenaga, Masayuki Takeda", "title": "On the approximation ratio of LZ-End to LZ77", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of Lempel-Ziv factorizations is a well-studied string structure. The\nLZ-End factorization is a member of the family that achieved faster extraction\nof any substrings (Kreft & Navarro, TCS 2013). One of the interests for LZ-End\nfactorizations is the possible difference between the size of LZ-End and LZ77\nfactorizations. They also showed families of strings where the approximation\nratio of the number of LZ-End phrases to the number of LZ77 phrases\nasymptotically approaches 2. However, the alphabet size of these strings is\nunbounded. In this paper, we analyze the LZ-End factorization of the\nperiod-doubling sequence. We also show that the approximation ratio for the\nperiod-doubling sequence asymptotically approaches 2 for the binary alphabet.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:11:12 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ideue", "Takumi", ""], ["Mieno", "Takuya", ""], ["Funakoshi", "Mitsuru", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Takeda", "Masayuki", ""]]}, {"id": "2106.01336", "submitter": "Huanyu Zhang", "authors": "Gautam Kamath, Xingtu Liu, Huanyu Zhang", "title": "Improved Rates for Differentially Private Stochastic Convex Optimization\n  with Heavy-Tailed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic convex optimization with heavy-tailed data under the\nconstraint of differential privacy. Most prior work on this problem is\nrestricted to the case where the loss function is Lipschitz. Instead, as\nintroduced by Wang, Xiao, Devadas, and Xu, we study general convex loss\nfunctions with the assumption that the distribution of gradients has bounded\n$k$-th moments. We provide improved upper bounds on the excess population risk\nunder approximate differential privacy of\n$\\tilde{O}\\left(\\sqrt{\\frac{d}{n}}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{k-1}{k}}\\right)$ and\n$\\tilde{O}\\left(\\frac{d}{n}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{2k-2}{k}}\\right)$ for convex and strongly convex loss\nfunctions, respectively. We also prove nearly-matching lower bounds under the\nconstraint of pure differential privacy, giving strong evidence that our bounds\nare tight.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:45:47 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 04:40:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kamath", "Gautam", ""], ["Liu", "Xingtu", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2106.01340", "submitter": "Tim Roughgarden", "authors": "Tim Roughgarden", "title": "Transaction Fee Mechanism Design", "comments": "Appears in the 22nd ACM Conference on Economics and Computation (EC\n  '21). This conference paper is derived from Sections 2, 4, 5, 6, and 8 of the\n  longer general-audience report published as arXiv:2012.00854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS cs.GT econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand for blockchains such as Bitcoin and Ethereum is far larger than\nsupply, necessitating a mechanism that selects a subset of transactions to\ninclude \"on-chain\" from the pool of all pending transactions. EIP-1559 is a\nproposal to make several tightly coupled changes to the Ethereum blockchain's\ntransaction fee mechanism, including the introduction of variable-size blocks\nand a burned base fee that rises and falls with demand. These changes are\nslated for deployment in Ethereum's \"London fork,\" scheduled for late\nsummer~2021, at which point it will be the biggest economic change made to a\nmajor blockchain to date.\n  The first goal of this paper is to formalize the problem of designing a\ntransaction fee mechanism, taking into account the many idiosyncrasies of the\nblockchain setting (ranging from off-chain collusion between miners and users\nto the ease of money-burning). The second goal is to situate the specific\nmechanism proposed in EIP-1559 in this framework and rigorously interrogate its\ngame-theoretic properties. The third goal is to suggest competing designs that\noffer alternative sets of trade-offs. The final goal is to highlight research\nopportunities for the EC community that could help shape the future of\nblockchain transaction fee mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:48:32 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Roughgarden", "Tim", ""]]}, {"id": "2106.01567", "submitter": "Jason Li", "authors": "Jason Li, Thatchaphol Saranurak", "title": "Deterministic Weighted Expander Decomposition in Almost-linear Time", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, we study the expander decomposition problem in a more general\nsetting where the input graph has positively weighted edges and nonnegative\ndemands on its vertices. We show how to extend the techniques of Chuzhoy et al.\n(FOCS 2020) to this wider setting, obtaining a deterministic algorithm for the\nproblem in almost-linear time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 03:24:36 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Li", "Jason", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "2106.01595", "submitter": "Shunsuke Inenaga", "authors": "Akio Nishimoto, Noriki Fujisato, Yuto Nakashima, Shunsuke Inenaga", "title": "Position Heaps for Cartesian-tree Matching on Strings and Tries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Cartesian-tree pattern matching is a recently introduced scheme of\npattern matching that detects fragments in a sequential data stream which have\na similar structure as a query pattern. Formally, Cartesian-tree pattern\nmatching seeks all substrings $S'$ of the text string $S$ such that the\nCartesian tree of $S'$ and that of a query pattern $P$ coincide. In this paper,\nwe present a new indexing structure for this problem called the Cartesian-tree\nPosition Heap (CPH). Let $n$ be the length of the input text string $S$, $m$\nthe length of a query pattern $P$, and $\\sigma$ the alphabet size. We show that\nthe CPH of $S$, denoted $\\mathsf{CPH}(S)$, supports pattern matching queries in\n$O(m (\\sigma + \\log (\\min\\{h, m\\})) + occ)$ time with $O(n)$ space, where $h$\nis the height of the CPH and $occ$ is the number of pattern occurrences. We\nshow how to build $\\mathsf{CPH}(S)$ in $O(n \\log \\sigma)$ time with $O(n)$\nworking space. Further, we extend the problem to the case where the text is a\nlabeled tree (i.e. a trie). Given a trie $T$ with $N$ nodes, we show that the\nCPH of $T$, denoted $\\mathsf{CPH}(T)$, supports pattern matching queries on the\ntrie in $O(m (\\sigma^2 + \\log (\\min\\{h, m\\})) + occ)$ time with $O(N \\sigma)$\nspace. We also show a construction algorithm for $\\mathsf{CPH}(T)$ running in\n$O(N \\sigma)$ time and $O(N \\sigma)$ working space.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 04:53:23 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Nishimoto", "Akio", ""], ["Fujisato", "Noriki", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""]]}, {"id": "2106.01763", "submitter": "Dmitry Kosolobov", "authors": "Golnaz Badkobeh, Panagiotis Charalampopoulos, Dmitry Kosolobov, and\n  Solon P. Pissis", "title": "Internal Shortest Absent Word Queries in Constant Time and Linear Space", "comments": "13 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a string $T$ of length $n$ over an alphabet $\\Sigma\\subset\n\\{1,2,\\ldots,n^{O(1)}\\}$ of size $\\sigma$, we are to preprocess $T$ so that\ngiven a range $[i,j]$, we can return a representation of a shortest string over\n$\\Sigma$ that is absent in the fragment $T[i]\\cdots T[j]$ of $T$. We present an\n$O(n)$-space data structure that answers such queries in constant time and can\nbe constructed in $O(n\\log_\\sigma n)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 11:32:50 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Badkobeh", "Golnaz", ""], ["Charalampopoulos", "Panagiotis", ""], ["Kosolobov", "Dmitry", ""], ["Pissis", "Solon P.", ""]]}, {"id": "2106.01880", "submitter": "Peter Davies", "authors": "Artur Czumaj, Peter Davies, Merav Parter", "title": "Component Stability in Low-Space Massively Parallel Computation", "comments": "45 pages, to appear at PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the power and limitations of component-stable algorithms in the\nlow-space model of Massively Parallel Computation (MPC). Recently Ghaffari,\nKuhn and Uitto (FOCS 2019) introduced the class of component-stable low-space\nMPC algorithms, which are, informally, defined as algorithms for which the\noutputs reported by the nodes in different connected components are required to\nbe independent. This very natural notion was introduced to capture most (if not\nall) of the known efficient MPC algorithms to date, and it was the first\ngeneral class of MPC algorithms for which one can show non-trivial conditional\nlower bounds. In this paper we enhance the framework of component-stable\nalgorithms and investigate its effect on the complexity of randomized and\ndeterministic low-space MPC. Our key contributions include:\n  1) We revise and formalize the lifting approach of Ghaffari, Kuhn and Uitto.\nThis requires a very delicate amendment of the notion of component stability,\nwhich allows us to fill in gaps in the earlier arguments.\n  2) We also extend the framework to obtain conditional lower bounds for\ndeterministic algorithms and fine-grained lower bounds that depend on the\nmaximum degree $\\Delta$.\n  3) We demonstrate a collection of natural graph problems for which\nnon-component-stable algorithms break the conditional lower bound obtained for\ncomponent-stable algorithms. This implies that, for both deterministic and\nrandomized algorithms, component-stable algorithms are conditionally weaker\nthan the non-component-stable ones.\n  Altogether our results imply that component-stability might limit the\ncomputational power of the low-space MPC model, at least in certain contexts,\npaving the way for improved upper bounds that escape the conditional lower\nbound setting of Ghaffari, Kuhn, and Uitto.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:25:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Czumaj", "Artur", ""], ["Davies", "Peter", ""], ["Parter", "Merav", ""]]}, {"id": "2106.01894", "submitter": "Merav Parter", "authors": "Shimon Kogan and Merav Parter", "title": "Low-Congestion Shortcuts in Constant Diameter Graphs", "comments": "To appear in PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low congestion shortcuts, introduced by Ghaffari and Haeupler (SODA 2016),\nprovide a unified framework for global optimization problems in the congest\nmodel of distributed computing. Roughly speaking, for a given graph $G$ and a\ncollection of vertex-disjoint connected subsets $S_1,\\ldots, S_\\ell \\subseteq\nV(G)$, $(c,d)$ low-congestion shortcuts augment each subgraph $G[S_i]$ with a\nsubgraph $H_i \\subseteq G$ such that: (i) each edge appears on at most $c$\nsubgraphs (congestion bound), and (ii) the diameter of each subgraph $G[S_i]\n\\cup H_i$ is bounded by $d$ (dilation bound). It is desirable to compute\nshortcuts of small congestion and dilation as these quantities capture the\nround complexity of many global optimization problems in the congest model. For\n$n$-vertex graphs with constant diameter $D=O(1)$, Elkin (STOC 2004) presented\nan (implicit) shortcuts lower bound with\n$c+d=\\widetilde{\\Omega}(n^{(D-2)/(2D-2)})$. A nearly matching upper bound,\nhowever, was only recently obtained for $D \\in \\{3,4\\}$ by Kitamura et al.\n(DISC 2019).\n  In this work, we resolve the long-standing complexity gap of shortcuts in\nconstant diameter graphs, originally posed by Lotker et al. (PODC 2001). We\npresent new shortcut constructions which match, up to poly-logarithmic terms,\nthe lower bounds of Das-Sarma et al. As a result, we provide improved and\nexistentially optimal algorithms for several network optimization tasks in\nconstant diameter graphs, including MST, $(1+\\epsilon)$-approximate minimum\ncuts and more.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:38:18 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:02:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kogan", "Shimon", ""], ["Parter", "Merav", ""]]}, {"id": "2106.02026", "submitter": "Xiao Mao", "authors": "Xiao Mao", "title": "Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance", "comments": "Minor update removing accidental attachment of figures from an\n  earlier draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (unweighted) tree edit distance problem for $n$ node trees asks to\ncompute a measure of dissimilarity between two rooted trees with node labels.\nThe current best algorithm from more than a decade ago runs in $O(n ^ 3)$ time\n[Demaine, Mozes, Rossman, and Weimann, ICALP 2007]. The same paper also showed\nthat $O(n ^ 3)$ is the best possible running time for any algorithm using the\nso-called decomposition strategy, which underlies almost all the known\nalgorithms for this problem. These algorithms would also work for the weighted\ntree edit distance problem, which cannot be solved in truly sub-cubic time\nunder the APSP conjecture [Bringmann, Gawrychowski, Mozes, and Weimann, SODA\n2018].\n  In this paper, we break the cubic barrier by showing an $O(n ^ {2.9546})$\ntime algorithm for the unweighted tree edit distance problem.\n  We consider an equivalent maximization problem and use a dynamic programming\nscheme involving matrices with many special properties. By using a\ndecomposition scheme as well as several combinatorial techniques, we reduce\ntree edit distance to the max-plus product of bounded-difference matrices,\nwhich can be solved in truly sub-cubic time [Bringmann, Grandoni, Saha, and\nVassilevska Williams, FOCS 2016].\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:50:33 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 09:49:21 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mao", "Xiao", ""]]}, {"id": "2106.02066", "submitter": "Vaclav Rozhon", "authors": "Sebastian Brandt, Yi-Jun Chang, Jan Greb\\'ik, Christoph Grunau,\n  V\\'aclav Rozho\\v{n}, Zolt\\'an Vidny\\'anszky", "title": "Local Problems on Trees from the Perspectives of Distributed Algorithms,\n  Finitary Factors, and Descriptive Combinatorics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC cs.DS math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study connections between distributed local algorithms, finitary factors\nof iid processes, and descriptive combinatorics in the context of regular\ntrees.\n  We extend the Borel determinacy technique of Marks coming from descriptive\ncombinatorics and adapt it to the area of distributed computing. Using this\ntechnique, we prove deterministic distributed $\\Omega(\\log n)$-round lower\nbounds for problems from a natural class of homomorphism problems.\nInterestingly, these lower bounds seem beyond the current reach of the powerful\nround elimination technique responsible for all substantial locality lower\nbounds of the last years. Our key technical ingredient is a novel ID graph\ntechnique that we expect to be of independent interest.\n  We prove that a local problem admits a Baire measurable coloring if and only\nif it admits a local algorithm with local complexity $O(\\log n)$, extending the\nclassification of Baire measurable colorings of Bernshteyn. A key ingredient of\nthe proof is a new and simple characterization of local problems that can be\nsolved in $O(\\log n)$ rounds. We complement this result by showing separations\nbetween complexity classes from distributed computing, finitary factors, and\ndescriptive combinatorics. Most notably, the class of problems that allow a\ndistributed algorithm with sublogarithmic randomized local complexity is\nincomparable with the class of problems with a Borel solution.\n  We hope that our treatment will help to view all three perspectives as part\nof a common theory of locality, in which we follow the insightful paper of\n[Bernshteyn -- arXiv 2004.04905].\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:15:07 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Brandt", "Sebastian", ""], ["Chang", "Yi-Jun", ""], ["Greb\u00edk", "Jan", ""], ["Grunau", "Christoph", ""], ["Rozho\u0148", "V\u00e1clav", ""], ["Vidny\u00e1nszky", "Zolt\u00e1n", ""]]}, {"id": "2106.02113", "submitter": "Martin Olsen", "authors": "Martin Olsen", "title": "Oblivious Stacking and MAX $k$-CUT for Circle Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stacking is an important process within logistics. Some notable examples of\nitems to be stacked are steel bars or steel plates in a steel yard or\ncontainers in a container terminal or on a ship. We say that two items are\nconflicting if their storage time intervals overlap in which case one of the\nitems needs to be rehandled if the items are stored at the same LIFO storage\nlocation. We consider the problem of stacking items using $k$ LIFO locations\nwith a minimum number of conflicts between items sharing a location. We present\nan extremely simple online stacking algorithm that is oblivious to the storage\ntime intervals and storage locations of all other items when it picks a storage\nlocation for an item. The risk of assigning the same storage location to two\nconflicting items is proved to be of the order $1/k^2$ under mild assumptions\non the distribution of the storage time intervals for the items. Intuitively,\nit seems natural to pick a storage location uniformly at random in the\noblivious setting implying a risk of $1/k$ so the risk for our algorithm is\nsurprisingly low. Our results can also be expressed within the context of the\nMAX $k$-CUT problem for circle graphs. The results indicate that circle graphs\non average have relatively big $k$-cuts compared to the total number of edges.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:12:02 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Olsen", "Martin", ""]]}, {"id": "2106.02114", "submitter": "Matthew Ferland", "authors": "Kyle Burke, Matthew Ferland, Shanghua Teng", "title": "Winning the War by (Strategically) Losing Battles: Settling the\n  Complexity of Grundy-Values in Undirected Geography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We settle two long-standing complexity-theoretical questions-open since 1981\nand 1993-in combinatorial game theory (CGT).\n  We prove that the Grundy value (a.k.a. nim-value, or nimber) of Undirected\nGeography is PSPACE-complete to compute. This exhibits a stark contrast with a\nresult from 1993 that Undirected Geography is polynomial-time solvable. By\ndistilling to a simple reduction, our proof further establishes a dichotomy\ntheorem, providing a \"phase transition to intractability\" in Grundy-value\ncomputation, sharply characterized by a maximum degree of four: The Grundy\nvalue of Undirected Geography over any degree-three graph is polynomial-time\ncomputable, but over degree-four graphs-even when planar and bipartite-is\nPSPACE-hard. Additionally, we show, for the first time, how to construct\nUndirected Geography instances with Grundy value $\\ast n$ and size polynomial\nin n.\n  We strengthen a result from 1981 showing that sums of tractable partisan\ngames are PSPACE-complete in two fundamental ways. First, since Undirected\nGeography is an impartial ruleset, we extend the hardness of sums to impartial\ngames, a strict subset of partisan. Second, the 1981 construction is not built\nfrom a natural ruleset, instead using a long sum of tailored short-depth game\npositions. We use the sum of two Undirected Geography positions to create our\nhard instances. Our result also has computational implications to\nSprague-Grundy Theory (1930s) which shows that the Grundy value of the\ndisjunctive sum of any two impartial games can be computed-in polynomial\ntime-from their Grundy values. In contrast, we prove that assuming PSPACE\n$\\neq$ P, there is no general polynomial-time method to summarize two\npolynomial-time solvable impartial games to efficiently solve their disjunctive\nsum.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:13:18 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Burke", "Kyle", ""], ["Ferland", "Matthew", ""], ["Teng", "Shanghua", ""]]}, {"id": "2106.02120", "submitter": "Jenny Kaufmann", "authors": "Mina Dalirrooyfard, Jenny Kaufmann", "title": "Approximation Algorithms for Min-Distance Problems in DAGs", "comments": "To appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The min-distance between two nodes $u, v$ is defined as the minimum of the\ndistance from $v$ to $u$ or from $u$ to $v$, and is a natural distance metric\nin DAGs. As with the standard distance problems, the Strong Exponential Time\nHypothesis [Impagliazzo-Paturi-Zane 2001, Calabro-Impagliazzo-Paturi 2009]\nleaves little hope for computing min-distance problems faster than computing\nAll Pairs Shortest Paths, which can be solved in $\\tilde{O}(mn)$ time. So it is\nnatural to resort to approximation algorithms in $\\tilde{O}(mn^{1-\\epsilon})$\ntime for some positive $\\epsilon$.\n  Abboud, Vassilevska W., and Wang [SODA 2016] first studied min-distance\nproblems achieving constant factor approximation algorithms on DAGs, obtaining\na $3$-approximation algorithm for min-radius on DAGs which works in\n$\\tilde{O}(m\\sqrt{n})$ time, and showing that any $(2-\\delta)$-approximation\nrequires $n^{2-o(1)}$ time for any $\\delta>0$, under the Hitting Set\nConjecture. We close the gap, obtaining a $2$-approximation algorithm which\nruns in $\\tilde{O}(m\\sqrt{n})$ time. As the lower bound of Abboud et al only\nworks for sparse DAGs, we further show that our algorithm is conditionally\ntight for dense DAGs using a reduction from Boolean matrix multiplication.\nMoreover, Abboud et al obtained a linear time $2$-approximation algorithm for\nmin-diameter along with a lower bound stating that any\n$(3/2-\\delta)$-approximation algorithm for sparse DAGs requires $n^{2-o(1)}$\ntime under SETH. We close this gap for dense DAGs by obtaining a\n$3/2$-approximation algorithm which works in $O(n^{2.350})$ time and showing\nthat the approximation factor is unlikely to be improved within $O(n^{\\omega -\no(1)})$ time under the high dimensional Orthogonal Vectors Conjecture, where\n$\\omega$ is the matrix multiplication exponent.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:32:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Kaufmann", "Jenny", ""]]}, {"id": "2106.02129", "submitter": "Brice Huang", "authors": "Guy Bresler, Brice Huang", "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree\n  Polynomials", "comments": "44 pages, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math-ph math.MP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Phi$ be a uniformly random $k$-SAT formula with $n$ variables and $m$\nclauses. We study the algorithmic task of finding a satisfying assignment of\n$\\Phi$. It is known that a satisfying assignment exists with high probability\nat clause density $m/n < 2^k \\log 2 - \\frac{1}{2} (\\log 2 + 1) + o_k(1)$, while\nthe best polynomial-time algorithm known, the Fix algorithm of Coja-Oghlan,\nfinds a satisfying assignment at the much lower clause density $(1 - o_k(1))\n2^k \\log k / k$. This prompts the question: is it possible to efficiently find\na satisfying assignment at higher clause densities?\n  To understand the algorithmic threshold of random $k$-SAT, we study low\ndegree polynomial algorithms, which are a powerful class of algorithms\nincluding Fix, Survey Propagation guided decimation (with bounded or mildly\ngrowing number of message passing rounds), and paradigms such as message\npassing and local graph algorithms. We show that low degree polynomial\nalgorithms can find a satisfying assignment at clause density $(1 - o_k(1)) 2^k\n\\log k / k$, matching Fix, and not at clause density $(1 + o_k(1)) \\kappa^* 2^k\n\\log k / k$, where $\\kappa^* \\approx 4.911$. This shows the first sharp (up to\nconstant factor) computational phase transition of random $k$-SAT for a class\nof algorithms. Our proof establishes and leverages a new many-way overlap gap\nproperty tailored to random $k$-SAT.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 21:01:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 02:36:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bresler", "Guy", ""], ["Huang", "Brice", ""]]}, {"id": "2106.02149", "submitter": "Kangning Wang", "authors": "Yuan Deng, Jieming Mao, Balasubramanian Sivan and Kangning Wang", "title": "Optimal Pricing Schemes for an Impatient Buyer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patient seller aims to sell a good to an impatient buyer (i.e., one who\ndiscounts utility over time). The buyer will remain in the market for a period\nof time $T$, and her private value is drawn from a publicly known distribution.\nWhat is the revenue-optimal pricing-curve (sequence of (price, time) pairs) for\nthe seller? Is randomization of help here? Is the revenue-optimal pricing-curve\ncomputable in polynomial time? We answer these questions in this paper. We give\nan efficient algorithm for computing the revenue-optimal pricing curve. We show\nthat pricing curves, that post a price at each point of time and let the buyer\npick her utility maximizing time to buy, are revenue-optimal among a much\nbroader class of sequential lottery mechanisms: namely, mechanisms that allow\nthe seller to post a menu of lotteries at each point of time cannot get any\nhigher revenue than pricing curves. We also show that the even broader class of\nmechanisms that allow the menu of lotteries to be adaptively set, can earn\nstrictly higher revenue than that of pricing curves, and the revenue gap can be\nas big as the support size of the buyer's value distribution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 21:53:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Deng", "Yuan", ""], ["Mao", "Jieming", ""], ["Sivan", "Balasubramanian", ""], ["Wang", "Kangning", ""]]}, {"id": "2106.02212", "submitter": "Soumyabrata Pal", "authors": "Wasim Huleihel, Arya Mazumdar, Soumyabrata Pal", "title": "Fuzzy Clustering with Similarity Queries", "comments": "47 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fuzzy or soft $k$-means objective is a popular generalization of the\nwell-known $k$-means problem, extending the clustering capability of the\n$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.\nIn this paper, we propose a semi-supervised active clustering framework, where\nthe learner is allowed to interact with an oracle (domain expert), asking for\nthe similarity between a certain set of chosen items. We study the query and\ncomputational complexities of clustering in this framework. We prove that\nhaving a few of such similarity queries enables one to get a polynomial-time\napproximation algorithm to an otherwise conjecturally NP-hard problem. In\nparticular, we provide probabilistic algorithms for fuzzy clustering in this\nsetting that asks $O(\\mathsf{poly}(k)\\log n)$ similarity queries and run with\npolynomial-time-complexity, where $n$ is the number of items. The fuzzy\n$k$-means objective is nonconvex, with $k$-means as a special case, and is\nequivalent to some other generic nonconvex problem such as non-negative matrix\nfactorization. The ubiquitous Lloyd-type algorithms (or,\nexpectation-maximization algorithm) can get stuck at a local minima. Our\nresults show that by making few similarity queries, the problem becomes easier\nto solve. Finally, we test our algorithms over real-world datasets, showing\ntheir effectiveness in real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:32:26 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Huleihel", "Wasim", ""], ["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2106.02233", "submitter": "Thatchaphol Saranurak", "authors": "Jason Li, Debmalya Panigrahi, Thatchaphol Saranurak", "title": "A Nearly Optimal All-Pairs Min-Cuts Algorithm in Simple Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give an $n^{2+o(1)}$-time algorithm for finding $s$-$t$ min-cuts for all\npairs of vertices $s$ and $t$ in a simple, undirected graph on $n$ vertices. We\ndo so by constructing a Gomory-Hu tree (or cut equivalent tree) in the same\nrunning time, thereby improving on the recent bound of $\\tilde{O}(n^{2.5})$ by\nAbboud et al. (FOCS 2021). Our running time is nearly optimal as a function of\n$n$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:17:50 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Jason", ""], ["Panigrahi", "Debmalya", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "2106.02350", "submitter": "Giulio Ermanno Pibiri", "authors": "Giulio Ermanno Pibiri and Roberto Trani", "title": "Parallel and External-Memory Construction of Minimal Perfect Hash\n  Functions with PTHash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A minimal perfect hash function $f$ for a set $S$ of $n$ keys is a bijective\nfunction of the form $f : S \\rightarrow \\{0,\\ldots,n-1\\}$. These functions are\nimportant for many practical applications in computing, such as search engines,\ncomputer networks, and databases. Several algorithms have been proposed to\nbuild minimal perfect hash functions that: scale well to large sets, retain\nfast evaluation time, and take very little space, e.g., 2 - 3 bits/key. PTHash\nis one such algorithm, achieving very fast evaluation in compressed space,\ntypically several times faster than other techniques. In this work, we propose\na new construction algorithm for PTHash enabling: (1) multi-threading, to\neither build functions more quickly or more space-efficiently, and (2)\nexternal-memory processing to scale to inputs much larger than the available\ninternal memory. Only few other algorithms in the literature share these\nfeatures, despite of their big practical impact. We conduct an extensive\nexperimental assessment on large real-world string collections and show that,\nwith respect to other techniques, PTHash is competitive in construction time\nand space consumption, but retains 2 - 6$\\times$ better lookup time.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:02:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Pibiri", "Giulio Ermanno", ""], ["Trani", "Roberto", ""]]}, {"id": "2106.02353", "submitter": "Jakab Tardos", "authors": "Michael Kapralov, Robert Krauthgamer, Jakab Tardos, Yuichi Yoshida", "title": "Spectral Hypergraph Sparsifiers of Nearly Linear Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph sparsification has been studied extensively over the past two decades,\nculminating in spectral sparsifiers of optimal size (up to constant factors).\nSpectral hypergraph sparsification is a natural analogue of this problem, for\nwhich optimal bounds on the sparsifier size are not known, mainly because the\nhypergraph Laplacian is non-linear, and thus lacks the linear-algebraic\nstructure and tools that have been so effective for graphs.\n  Our main contribution is the first algorithm for constructing\n$\\epsilon$-spectral sparsifiers for hypergraphs with $O^*(n)$ hyperedges, where\n$O^*$ suppresses $(\\epsilon^{-1} \\log n)^{O(1)}$ factors. This bound is\nindependent of the rank $r$ (maximum cardinality of a hyperedge), and is\nessentially best possible due to a recent bit complexity lower bound of\n$\\Omega(nr)$ for hypergraph sparsification.\n  This result is obtained by introducing two new tools. First, we give a new\nproof of spectral concentration bounds for sparsifiers of graphs; it avoids\nlinear-algebraic methods, replacing e.g.~the usual application of the matrix\nBernstein inequality and therefore applies to the (non-linear) hypergraph\nsetting. To achieve the result, we design a new sequence of\nhypergraph-dependent $\\epsilon$-nets on the unit sphere in $\\mathbb{R}^n$.\nSecond, we extend the weight assignment technique of Chen, Khanna and Nagda\n[FOCS'20] to the spectral sparsification setting. Surprisingly, the number of\nspanning trees after the weight assignment can serve as a potential function\nguiding the reweighting process in the spectral setting.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:06:35 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kapralov", "Michael", ""], ["Krauthgamer", "Robert", ""], ["Tardos", "Jakab", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2106.02397", "submitter": "Tillmann Miltzow", "authors": "Tillmann Miltzow and Reinier F. Schmiermann", "title": "On Classifying Continuous Constraint Satisfaction problems", "comments": "40 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.CL cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n  We restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n  We apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:23:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Miltzow", "Tillmann", ""], ["Schmiermann", "Reinier F.", ""]]}, {"id": "2106.02619", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative\n  Models for Real-World Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:33:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2106.02680", "submitter": "Allen Liu", "authors": "Allen Liu, Ankur Moitra", "title": "How to Decompose a Tensor with Group Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the orbit recovery problem, which is a natural\nabstraction for the problem of recovering a planted signal from noisy\nmeasurements under unknown group actions. Many important inverse problems in\nstatistics, engineering and the sciences fit into this framework. Prior work\nhas studied cases when the group is discrete and/or abelian. However\nfundamentally new techniques are needed in order to handle more complex group\nactions.\n  Our main result is a quasi-polynomial time algorithm to solve orbit recovery\nover $SO(3)$ - i.e. the cryo-electron tomography problem which asks to recover\nthe three-dimensional structure of a molecule from noisy measurements of\nrandomly rotated copies of it. We analyze a variant of the frequency marching\nheuristic in the framework of smoothed analysis. Our approach exploits the\nlayered structure of the invariant polynomials, and simultaneously yields a new\nclass of tensor decomposition algorithms that work in settings when the tensor\nis not low-rank but rather where the factors are algebraically related to each\nother by a group action.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:27:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2106.02685", "submitter": "Peilin Zhong", "authors": "Alessandro Epasto, Mohammad Mahdian, Vahab Mirrokni, Peilin Zhong", "title": "Massively Parallel and Dynamic Algorithms for Minimum Size Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the $r$-gather problem, a natural formulation of\nminimum-size clustering in metric spaces. The goal of $r$-gather is to\npartition $n$ points into clusters such that each cluster has size at least\n$r$, and the maximum radius of the clusters is minimized. This additional\nconstraint completely changes the algorithmic nature of the problem, and many\nclustering techniques fail. Also previous dynamic and parallel algorithms do\nnot achieve desirable complexity. We propose algorithms both in the Massively\nParallel Computation (MPC) model and in the dynamic setting. Our MPC algorithm\nhandles input points from the Euclidean space $\\mathbb{R}^d$. It computes an\n$O(1)$-approximate solution of $r$-gather in $O(\\log^{\\varepsilon} n)$ rounds\nusing total space $O(n^{1+\\gamma}\\cdot d)$ for arbitrarily small constants\n$\\varepsilon,\\gamma > 0$. In addition our algorithm is fully scalable, i.e.,\nthere is no lower bound on the memory per machine. Our dynamic algorithm\nmaintains an $O(1)$-approximate $r$-gather solution under insertions/deletions\nof points in a metric space with doubling dimension $d$. The update time is $r\n\\cdot 2^{O(d)}\\cdot \\log^{O(1)}\\Delta$ and the query time is $2^{O(d)}\\cdot\n\\log^{O(1)}\\Delta$, where $\\Delta$ is the ratio between the largest and the\nsmallest distance.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:49:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Epasto", "Alessandro", ""], ["Mahdian", "Mohammad", ""], ["Mirrokni", "Vahab", ""], ["Zhong", "Peilin", ""]]}, {"id": "2106.02703", "submitter": "Armen Allahverdyan", "authors": "Armen E. Allahverdyan and David Petrosyan", "title": "Dissipative search of an unstructured database", "comments": "4+2 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The search of an unstructured database amounts to finding one element having\na certain property out of $N$ elements. The classical search with an oracle\nchecking one element at a time requires on average $N/2$ steps. The Grover\nalgorithm for the quantum search, and its unitary Hamiltonian evolution\nanalogue, accomplish the search asymptotically optimally in $\\mathcal{O}\n(\\sqrt{N})$ time steps. We reformulate the search problem as a dissipative\nMarkov process acting on an $N$-level system weakly coupled to a thermal bath.\nAssuming that the energy levels of the system represent the database elements,\nwe show that, with a proper choice of the spectrum and physically admissible,\nlong-range transition rates between the energy levels, the system relaxes to\nthe ground state, corresponding to the sought element, in time $\\mathcal{O}\n(\\ln N)$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:28:19 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Allahverdyan", "Armen E.", ""], ["Petrosyan", "David", ""]]}, {"id": "2106.02755", "submitter": "Jason Altschuler", "authors": "Jason M. Altschuler and Pablo A. Parrilo", "title": "Kernel approximation on algebraic varieties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximation of kernels is a fundamental mathematical problem with\nwidespread algorithmic applications. Often the kernel is restricted to an\nalgebraic variety, e.g., in problems involving sparse or low-rank data. We show\nthat significantly better approximations are obtainable in this setting: the\nrank required to achieve a given error depends on the variety's dimension\nrather than the ambient dimension, which is typically much larger. This is true\nin both high-precision and high-dimensional regimes. Our results are presented\nfor smooth isotropic kernels, the predominant class of kernels used in\napplications. Our main technical insight is to approximate smooth kernels by\npolynomial kernels, and leverage two key properties of polynomial kernels that\nhold when they are restricted to a variety. First, their ranks decrease\nexponentially in the variety's co-dimension. Second, their maximum values are\ngoverned by their values over a small set of points. Together, our results\nprovide a general approach for exploiting (approximate) \"algebraic structure\"\nin datasets in order to efficiently solve large-scale data science problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 23:42:19 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Altschuler", "Jason M.", ""], ["Parrilo", "Pablo A.", ""]]}, {"id": "2106.02762", "submitter": "Noujan Pashanasangi", "authors": "Noujan Pashanasangi, C. Seshadhri", "title": "Faster and Generalized Temporal Triangle Counting, via Degeneracy\n  Ordering", "comments": "To be published in KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangle counting is a fundamental technique in network analysis, that has\nreceived much attention in various input models. The vast majority of triangle\ncounting algorithms are targeted to static graphs. Yet, many real-world graphs\nare directed and temporal, where edges come with timestamps. Temporal triangles\nyield much more information, since they account for both the graph topology and\nthe timestamps.\n  Temporal triangle counting has seen a few recent results, but there are\nvarying definitions of temporal triangles. In all cases, temporal triangle\npatterns enforce constraints on the time interval between edges (in the\ntriangle). We define a general notion $(\\delta_{1,3}, \\delta_{1,2},\n\\delta_{2,3})$-temporal triangles that allows for separate time constraints for\nall pairs of edges.\n  Our main result is a new algorithm, DOTTT (Degeneracy Oriented Temporal\nTriangle Totaler), that exactly counts all directed variants of $(\\delta_{1,3},\n\\delta_{1,2}, \\delta_{2,3})$-temporal triangles. Using the classic idea of\ndegeneracy ordering with careful combinatorial arguments, we can prove that\nDOTTT runs in $O(m\\kappa\\log m)$ time, where $m$ is the number of (temporal)\nedges and $\\kappa$ is the graph degeneracy (max core number). Up to log\nfactors, this matches the running time of the best static triangle counters.\nMoreover, this running time is better than existing.\n  DOTTT has excellent practical behavior and runs twice as fast as existing\nstate-of-the-art temporal triangle counters (and is also more general). For\nexample, DOTTT computes all types of temporal queries in Bitcoin temporal\nnetwork with half a billion edges in less than an hour on a commodity machine.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 00:25:06 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pashanasangi", "Noujan", ""], ["Seshadhri", "C.", ""]]}, {"id": "2106.02774", "submitter": "Allen Liu", "authors": "Jerry Li, Allen Liu, Ankur Moitra", "title": "Sparsification for Sums of Exponentials and its Algorithmic Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many works in signal processing and learning theory operate under the\nassumption that the underlying model is simple, e.g. that a signal is\napproximately $k$-Fourier-sparse or that a distribution can be approximated by\na mixture model that has at most $k$ components. However the problem of fitting\nthe parameters of such a model becomes more challenging when the\nfrequencies/components are too close together.\n  In this work we introduce new methods for sparsifying sums of exponentials\nand give various algorithmic applications. First we study Fourier-sparse\ninterpolation without a frequency gap, where Chen et al. gave an algorithm for\nfinding an $\\epsilon$-approximate solution which uses $k' = \\mbox{poly}(k, \\log\n1/\\epsilon)$ frequencies. Second, we study learning Gaussian mixture models in\none dimension without a separation condition. Kernel density estimators give an\n$\\epsilon$-approximation that uses $k' = O(k/\\epsilon^2)$ components. These\nmethods both output models that are much more complex than what we started out\nwith. We show how to post-process to reduce the number of\nfrequencies/components down to $k' = \\widetilde{O}(k)$, which is optimal up to\nlogarithmic factors. Moreover we give applications to model selection. In\nparticular, we give the first algorithms for approximately (and robustly)\ndetermining the number of components in a Gaussian mixture model that work\nwithout a separation condition.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 01:58:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Jerry", ""], ["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2106.02812", "submitter": "Ritajit Majumdar", "authors": "Ritajit Majumdar, Dhiraj Madan, Debasmita Bhoumik, Dhinakaran\n  Vinayagamurthy, Shesha Raghunathan, and Susmita Sur-Kolay", "title": "Optimizing Ansatz Design in QAOA for Max-cut", "comments": "13 pages; double column", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum Approximate Optimization Algorithm (QAOA) is studied primarily to\nfind approximate solutions to combinatorial optimization problems. For a graph\nwith $n$ vertices and $m$ edges, a depth $p$ QAOA for the Max-cut problem\nrequires $2\\cdot m \\cdot p$ CNOT gates. CNOT is one of the primary sources of\nerror in modern quantum computers. In this paper, we propose two hardware\nindependent methods to reduce the number of CNOT gates in the circuit. First,\nwe present a method based on Edge Coloring of the input graph that minimizes\nthe the number of cycles (termed as depth of the circuit), and reduces upto\n$\\lfloor \\frac{n}{2} \\rfloor$ CNOT gates. Next, we depict another method based\non Depth First Search (DFS) on the input graph that reduces $n-1$ CNOT gates,\nbut increases depth of the circuit moderately. We analytically derive the\ncondition for which the reduction in CNOT gates overshadows this increase in\ndepth, and the error probability of the circuit is still lowered. We show that\nall IBM Quantum Hardware satisfy this condition. We simulate these two methods\nfor graphs of various sparsity with the \\textit{ibmq\\_manhattan} noise model,\nand show that the DFS based method outperforms the edge coloring based method,\nwhich in turn, outperforms the traditional QAOA circuit in terms of reduction\nin the number of CNOT gates, and hence the probability of error of the circuit.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 06:43:48 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 09:58:15 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 13:27:08 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 11:59:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Majumdar", "Ritajit", ""], ["Madan", "Dhiraj", ""], ["Bhoumik", "Debasmita", ""], ["Vinayagamurthy", "Dhinakaran", ""], ["Raghunathan", "Shesha", ""], ["Sur-Kolay", "Susmita", ""]]}, {"id": "2106.02848", "submitter": "Sivakanth Gopi", "authors": "Sivakanth Gopi, Yin Tat Lee, Lukas Wutschitz", "title": "Numerical Composition of Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a fast algorithm to optimally compose privacy guarantees of\ndifferentially private (DP) algorithms to arbitrary accuracy. Our method is\nbased on the notion of privacy loss random variables to quantify the privacy\nloss of DP algorithms. The running time and memory needed for our algorithm to\napproximate the privacy curve of a DP algorithm composed with itself $k$ times\nis $\\tilde{O}(\\sqrt{k})$. This improves over the best prior method by Koskela\net al. (2020) which requires $\\tilde{\\Omega}(k^{1.5})$ running time. We\ndemonstrate the utility of our algorithm by accurately computing the privacy\nloss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm\nspeeds up the privacy computations by a few orders of magnitude compared to\nprior work, while maintaining similar accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 09:20:15 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 22:30:06 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Lee", "Yin Tat", ""], ["Wutschitz", "Lukas", ""]]}, {"id": "2106.02942", "submitter": "Soheil Behnezhad", "authors": "Soheil Behnezhad", "title": "Time-Optimal Sublinear Algorithms for Matching and Vertex Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a near-tight analysis of the average \"query complexity\" -- \\`a la\nNguyen and Onak [FOCS'08] -- of the randomized greedy maximal matching\nalgorithm, improving over the bound of Yoshida, Yamamoto and Ito [STOC'09]. For\nany $n$-vertex graph of average degree $\\bar{d}$, this leads to the following\nsublinear-time algorithms for estimating the size of maximum matching and\nminimum vertex cover, all of which are provably time-optimal up to logarithmic\nfactors:\n  $\\bullet$ A multiplicative $(2+\\epsilon)$-approximation in\n$\\widetilde{O}(n/\\epsilon^2)$ time using adjacency list queries. This (nearly)\nmatches an $\\Omega(n)$ time lower bound for any multiplicative approximation\nand is, notably, the first $O(1)$-approximation that runs in $o(n^{1.5})$ time.\n  $\\bullet$ A $(2, \\epsilon n)$-approximation in $\\widetilde{O}((\\bar{d} +\n1)/\\epsilon^2)$ time using adjacency list queries. This (nearly) matches an\n$\\Omega(\\bar{d}+1)$ lower bound of Parnas and Ron [TCS'07] which holds for any\n$(O(1), \\epsilon n)$-approximation, and improves over the bounds of [Yoshida et\nal. STOC'09; Onak et al. SODA'12] and [Kapralov et al. SODA'20]: The former two\ntake at least quadratic time in the degree which can be as large as\n$\\Omega(n^2)$ and the latter obtains a much larger approximation.\n  $\\bullet$ A $(2, \\epsilon n)$-approximation in $\\widetilde{O}(n/\\epsilon^3)$\ntime using adjacency matrix queries. This (nearly) matches an $\\Omega(n)$ time\nlower bound in this model and improves over the $\\widetilde{O}(n\\sqrt{n})$-time\n$(2, \\epsilon n)$-approximate algorithm of [Chen, Kannan, and Khanna ICALP'20].\nIt also turns out that any non-trivial multiplicative approximation in the\nadjacency matrix model requires $\\Omega(n^2)$ time, so the additive $\\epsilon\nn$ error is necessary too.\n  As immediate corollaries, we get improved sublinear time estimators for\n(variants of) TSP and an improved AMPC algorithm for maximal matching.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 18:41:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Behnezhad", "Soheil", ""]]}, {"id": "2106.02981", "submitter": "Ohad Trabelsi", "authors": "Amir Abboud, Robert Krauthgamer, Ohad Trabelsi", "title": "APMF < APSP? Gomory-Hu Tree for Unweighted Graphs in Almost-Quadratic\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an $n^{2+o(1)}$-time algorithm that constructs a cut-equivalent\n(Gomory-Hu) tree of a simple graph on $n$ nodes. This bound is almost-optimal\nin terms of $n$, and it improves on the recent $\\tilde{O}(n^{2.5})$ bound by\nthe authors (STOC 2021), which was the first to break the cubic barrier.\nConsequently, the All-Pairs Maximum-Flow (APMF) problem has time complexity\n$n^{2+o(1)}$, and for the first time in history, this problem can be solved\nfaster than All-Pairs Shortest Paths (APSP). We further observe that an\nalmost-linear time algorithm (in terms of the number of edges $m$) is not\npossible without first obtaining a subcubic algorithm for multigraphs.\n  Finally, we derandomize our algorithm, obtaining the first subcubic\ndeterministic algorithm for Gomory-Hu Tree in simple graphs, showing that\nrandomness is not necessary for beating the $n-1$ times max-flow bound from\n1961. The upper bound is $\\tilde{O}(n^{2\\frac{2}{3}})$ and it would improve to\n$n^{2+o(1)}$ if there is a deterministic single-pair maximum-flow algorithm\nthat is almost-linear. The key novelty is in using a ``dynamic pivot''\ntechnique instead of the randomized pivot selection that was central in recent\nworks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 22:32:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Abboud", "Amir", ""], ["Krauthgamer", "Robert", ""], ["Trabelsi", "Ohad", ""]]}, {"id": "2106.03058", "submitter": "Hanzhi Wang", "authors": "Hanzhi Wang, Mingguo He, Zhewei Wei, Sibo Wang, Ye Yuan, Xiaoyong Du\n  and Ji-Rong Wen", "title": "Approximate Graph Propagation", "comments": "ACM SIGKDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467243", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient computation of node proximity queries such as transition\nprobabilities, Personalized PageRank, and Katz are of fundamental importance in\nvarious graph mining and learning tasks. In particular, several recent works\nleverage fast node proximity computation to improve the scalability of Graph\nNeural Networks (GNN). However, prior studies on proximity computation and GNN\nfeature propagation are on a case-by-case basis, with each paper focusing on a\nparticular proximity measure.\n  In this paper, we propose Approximate Graph Propagation (AGP), a unified\nrandomized algorithm that computes various proximity queries and GNN feature\npropagation, including transition probabilities, Personalized PageRank, heat\nkernel PageRank, Katz, SGC, GDC, and APPNP. Our algorithm provides a\ntheoretical bounded error guarantee and runs in almost optimal time complexity.\nWe conduct an extensive experimental study to demonstrate AGP's effectiveness\nin two concrete applications: local clustering with heat kernel PageRank and\nnode classification with GNNs. Most notably, we present an empirical study on a\nbillion-edge graph Papers100M, the largest publicly available GNN dataset so\nfar. The results show that AGP can significantly improve various existing GNN\nmodels' scalability without sacrificing prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 08:11:36 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 06:07:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "Hanzhi", ""], ["He", "Mingguo", ""], ["Wei", "Zhewei", ""], ["Wang", "Sibo", ""], ["Yuan", "Ye", ""], ["Du", "Xiaoyong", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2106.03305", "submitter": "Tianyi Zhang", "authors": "Tianyi Zhang", "title": "Faster Cut-Equivalent Trees in Simple Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $G = (V, E)$ be an undirected connected simple graph on $n$ vertices. A\ncut-equivalent tree of $G$ is an edge-weighted tree on the same vertex set $V$,\nsuch that for any pair of vertices $s, t\\in V$, the minimum $(s, t)$-cut in the\ntree is also a minimum $(s, t)$-cut in $G$, and these two cuts have the same\ncut value. In a recent paper [Abboud, Krauthgamer and Trabelsi, 2021], the\nauthors propose the first subcubic time algorithm for constructing a\ncut-equivalent tree. More specifically, their algorithm has\n$\\widetilde{O}(n^{2.5})$ running time.\n  In this paper, we improve the running time to $\\widehat{O}(n^2)$ if\nalmost-linear time max-flow algorithms exist. Also, using the currently fastest\nmax-flow algorithm by [van den Brand \\etal, 2021], our algorithm runs in time\n$\\widetilde{O}(n^{17/8})$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 02:31:50 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Tianyi", ""]]}, {"id": "2106.03366", "submitter": "Zongchen Chen", "authors": "Zongchen Chen, Kuikui Liu, Eric Vigoda", "title": "Spectral Independence via Stability and Applications to Holant-Type\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formalizes connections between stability of polynomials and\nconvergence rates of Markov Chain Monte Carlo (MCMC) algorithms. We prove that\nif a (multivariate) partition function is nonzero in a region around a real\npoint $\\lambda$ then spectral independence holds at $\\lambda$. As a\nconsequence, for Holant-type problems (e.g., spin systems) on bounded-degree\ngraphs, we obtain optimal $O(n\\log n)$ mixing time bounds for the single-site\nupdate Markov chain known as the Glauber dynamics. Our result significantly\nimproves the running time guarantees obtained via the polynomial interpolation\nmethod of Barvinok (2017), refined by Patel and Regts (2017).\n  There are a variety of applications of our results. In this paper, we focus\non Holant-type (i.e., edge-coloring) problems, including weighted edge covers\nand weighted even subgraphs. For the weighted edge cover problem (and several\nnatural generalizations) we obtain an $O(n\\log{n})$ sampling algorithm on\nbounded-degree graphs. The even subgraphs problem corresponds to the\nhigh-temperature expansion of the ferromagnetic Ising model. We obtain an\n$O(n\\log{n})$ sampling algorithm for the ferromagnetic Ising model with a\nnonzero external field on bounded-degree graphs, which improves upon the\nclassical result of Jerrum and Sinclair (1993) for this class of graphs. We\nobtain further applications to antiferromagnetic two-spin models on line\ngraphs, weighted graph homomorphisms, tensor networks, and more.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 06:42:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Zongchen", ""], ["Liu", "Kuikui", ""], ["Vigoda", "Eric", ""]]}, {"id": "2106.03403", "submitter": "Zhijie Zhang", "authors": "Wei Chen, Xiaoming Sun, Jialin Zhang, Zhijie Zhang", "title": "Network Inference and Influence Maximization from Samples", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influence maximization is the task of selecting a small number of seed nodes\nin a social network to maximize the spread of the influence from these seeds,\nand it has been widely investigated in the past two decades. In the canonical\nsetting, the whole social network as well as its diffusion parameters is given\nas input. In this paper, we consider the more realistic sampling setting where\nthe network is unknown and we only have a set of passively observed cascades\nthat record the set of activated nodes at each diffusion step. We study the\ntask of influence maximization from these cascade samples (IMS), and present\nconstant approximation algorithms for this task under mild conditions on the\nseed set distribution. To achieve the optimization goal, we also provide a\nnovel solution to the network inference problem, that is, learning diffusion\nparameters and the network structure from the cascade data. Comparing with\nprior solutions, our network inference algorithm requires weaker assumptions\nand does not rely on maximum-likelihood estimation and convex programming. Our\nIMS algorithms enhance the learning-and-then-optimization approach by allowing\na constant approximation ratio even when the diffusion parameters are hard to\nlearn, and we do not need any assumption related to the network structure or\ndiffusion parameters.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 08:06:36 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Wei", ""], ["Sun", "Xiaoming", ""], ["Zhang", "Jialin", ""], ["Zhang", "Zhijie", ""]]}, {"id": "2106.03425", "submitter": "Dimitrios Thilikos", "authors": "Fedor V. Fomin and Petr A. Golovach and Giannos Stamoulis and\n  Dimitrios M. Thilikos", "title": "An Algorithmic Meta-Theorem for Graph Modification to Planarity and FOL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In general, a graph modification problem is defined by a graph modification\noperation $\\boxtimes$ and a target graph property ${\\cal P}$. Typically, the\nmodification operation $\\boxtimes$ may be vertex removal}, edge removal}, edge\ncontraction}, or edge addition and the question is, given a graph $G$ and an\ninteger $k$, whether it is possible to transform $G$ to a graph in ${\\cal P}$\nafter applying $k$ times the operation $\\boxtimes$ on $G$. This problem has\nbeen extensively studied for particilar instantiations of $\\boxtimes$ and\n${\\cal P}$. In this paper we consider the general property ${\\cal P}_{{\\phi}}$\nof being planar and, moreover, being a model of some First-Order Logic sentence\n${\\phi}$ (an FOL-sentence). We call the corresponding meta-problem Graph\n$\\boxtimes$-Modification to Planarity and ${\\phi}$ and prove the following\nalgorithmic meta-theorem: there exists a function $f:\\Bbb{N}^{2}\\to\\Bbb{N}$\nsuch that, for every $\\boxtimes$ and every FOL sentence ${\\phi}$, the Graph\n$\\boxtimes$-Modification to Planarity and ${\\phi}$ is solvable in\n$f(k,|{\\phi}|)\\cdot n^2$ time. The proof constitutes a hybrid of two different\nclassic techniques in graph algorithms. The first is the irrelevant vertex\ntechnique that is typically used in the context of Graph Minors and deals with\nproperties such as planarity or surface-embeddability (that are not\nFOL-expressible)\n  and the second is the use of Gaifman's Locality Theorem that is the\ntheoretical base for the meta-algorithmic study of FOL-expressible problems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 08:44:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Stamoulis", "Giannos", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2106.03457", "submitter": "Chenhao Wang", "authors": "Hau Chan, Aris Filos-Ratsikas, Bo Li, Minming Li, Chenhao Wang", "title": "Mechanism Design for Facility Location Problems: A Survey", "comments": "To appear in IJCAI 2021 (Survey Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of approximate mechanism design for facility location problems has\nbeen in the center of research at the intersection of artificial intelligence\nand economics for the last decades, largely due to its practical importance in\nvarious domains, such as social planning and clustering. At a high level, the\ngoal is to design mechanisms to select a set of locations on which to build a\nset of facilities, aiming to optimize some social objective and ensure\ndesirable properties based on the preferences of strategic agents, who might\nhave incentives to misreport their private information such as their locations.\nThis paper presents a comprehensive survey of the significant progress that has\nbeen made since the introduction of the problem, highlighting the different\nvariants and methodologies, as well as the most interesting directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 09:35:51 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 11:41:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chan", "Hau", ""], ["Filos-Ratsikas", "Aris", ""], ["Li", "Bo", ""], ["Li", "Minming", ""], ["Wang", "Chenhao", ""]]}, {"id": "2106.03462", "submitter": "Leonardo Pellegrina", "authors": "Leonardo Pellegrina, Fabio Vandin", "title": "SILVAN: Estimating Betweenness Centralities with Progressive Sampling\n  and Non-uniform Rademacher Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness centrality is a popular centrality measure with applications in\nseveral domains, and whose exact computation is impractical for modern-sized\nnetworks. We present SILVAN, a novel, efficient algorithm to compute, with high\nprobability, accurate estimates of the betweenness centrality of all nodes of a\ngraph and a high-quality approximation of the k most central nodes of a graph.\nSILVAN follows a progressive sampling approach, and builds on recently improved\nbounds on Monte-Carlo Empirical Rademacher Averages, a fundamental tool from\nstatistical learning theory. SILVAN relies on a novel estimation scheme that\nleads to non-uniform bounds on the deviation of the estimates from the true\nvalues of the between centrality of all the nodes, providing tight guarantees\non the quality of the approximation. Our extensive experimental evaluation\nshows that SILVAN extracts high-quality approximations while outperforming, in\nterms of number of samples and accuracy, the state-of-the-art approximation\nalgorithm with comparable quality guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 09:43:48 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pellegrina", "Leonardo", ""], ["Vandin", "Fabio", ""]]}, {"id": "2106.03476", "submitter": "Pan Peng", "authors": "Pan Peng, Daniel Lopatta, Yuichi Yoshida, Gramoz Goranci", "title": "Local Algorithms for Estimating Effective Resistance", "comments": "KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective resistance is an important metric that measures the similarity of\ntwo vertices in a graph. It has found applications in graph clustering,\nrecommendation systems and network reliability, among others. In spite of the\nimportance of the effective resistances, we still lack efficient algorithms to\nexactly compute or approximate them on massive graphs.\n  In this work, we design several \\emph{local algorithms} for estimating\neffective resistances, which are algorithms that only read a small portion of\nthe input while still having provable performance guarantees. To illustrate,\nour main algorithm approximates the effective resistance between any vertex\npair $s,t$ with an arbitrarily small additive error $\\varepsilon$ in time\n$O(\\mathrm{poly}(\\log n/\\varepsilon))$, whenever the underlying graph has\nbounded mixing time. We perform an extensive empirical study on several\nbenchmark datasets, validating the performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:08:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Peng", "Pan", ""], ["Lopatta", "Daniel", ""], ["Yoshida", "Yuichi", ""], ["Goranci", "Gramoz", ""]]}, {"id": "2106.03545", "submitter": "Meike Neuwohner", "authors": "Meike Neuwohner", "title": "An Improved Approximation Algorithm for the Maximum Weight Independent\n  Set Problem in d-Claw Free Graphs", "comments": "full version of the paper \"An Improved Approximation Algorithm for\n  the Maximum Weight Independent Set Problem in d-Claw Free Graphs\" published\n  in the proceedings of STACS 2021, 30 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we consider the task of computing an independent set of\nmaximum weight in a given $d$-claw free graph $G=(V,E)$ equipped with a\npositive weight function $w:V\\rightarrow\\mathbb{R}^+$. In doing so, $d\\geq 2$\nis considered a constant. The previously best known approximation algorithm for\nthis problem is the local improvement algorithm SquareImp proposed by Berman.\nIt achieves a performance ratio of $\\frac{d}{2}+\\epsilon$ in time\n$\\mathcal{O}(|V(G)|^{d+1}\\cdot(|V(G)|+|E(G)|)\\cdot (d-1)^2\\cdot\n\\left(\\frac{d}{2\\epsilon}+1\\right)^2)$ for any $\\epsilon>0$, which has remained\nunimproved for the last twenty years. By considering a broader class of local\nimprovements, we obtain an approximation ratio of\n$\\frac{d}{2}-\\frac{1}{63,700,992}+\\epsilon$ for any $\\epsilon>0$ at the cost of\nan additional factor of $\\mathcal{O}(|V(G)|^{(d-1)^2})$ in the running time. In\nparticular, our result implies a polynomial time $\\frac{d}{2}$-approximation\nalgorithm. Furthermore, the well-known reduction from the weighted $k$-Set\nPacking Problem to the Maximum Weight Independent Set Problem in $k+1$-claw\nfree graphs provides a\n$\\frac{k+1}{2}-\\frac{1}{63,700,992}+\\epsilon$-approximation algorithm for the\nweighted $k$-Set Packing Problem for any $\\epsilon>0$. This improves on the\npreviously best known approximation guarantee of $\\frac{k+1}{2}+\\epsilon$\noriginating from the result of Berman.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:15:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Neuwohner", "Meike", ""]]}, {"id": "2106.03555", "submitter": "Meike Neuwohner", "authors": "Meike Neuwohner", "title": "The Limits of Local Search for the Maximum Weight Independent Set\n  Problem in d-Claw Free Graphs", "comments": "50 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the Maximum Weight Independent Set Problem (MWIS) in $d$-claw\nfree graphs, i.e. the task of computing an independent set of maximum weight in\na given $d$-claw free graph $G=(V,E)$ equipped with a positive weight function\n$w:V\\rightarrow\\mathbb{R}_{>0}$. For $k\\geq 1$, the MWIS in $k+1$-claw free\ngraphs generalizes the weighted $k$-Set Packing Problem. Given that for $k\\geq\n3$, this problem does not permit a polynomial time $o(\\frac{k}{\\log\nk})$-approximation unless $P=NP$, most previous algorithms for both weighted\n$k$-Set Packing and the MWIS in $d$-claw free graphs rely on local search. For\nthe last twenty years, Berman's algorithm SquareImp, which yields a\n$\\frac{d}{2}+\\epsilon$-approximation for the MWIS in $d$-claw free graphs, has\nremained unchallenged for both problems. Recently, it was improved by\nNeuwohner, obtaining an approximation guarantee slightly below $\\frac{d}{2}$,\nand inevitably raising the question of how far one can get by using local\nsearch. In this paper, we finally answer this question asymptotically in the\nfollowing sense: By considering local improvements of logarithmic size, we\nobtain approximation ratios of $\\frac{d-1+\\epsilon_d}{2}$ for the MWIS in\n$d$-claw free graphs for $d\\geq 3$ in quasi-polynomial time, where $0\\leq\n\\epsilon_d\\leq 1$ and $\\lim_{d\\rightarrow\\infty}\\epsilon_d = 0$. By employing\nthe color coding technique, we can use the previous result to obtain a\npolynomial time $\\frac{k+\\epsilon_{k+1}}{2}$-approximation for weighted $k$-Set\nPacking. On the other hand, we provide examples showing that no local\nimprovement algorithm considering local improvements of size\n$\\mathcal{O}(\\log(|\\mathcal{S}|))$ with respect to some power $w^\\alpha$ of the\nweight function, where $\\alpha\\in\\mathbb{R}$ is chosen arbitrarily, but fixed,\ncan yield an approximation guarantee better than $\\frac{k}{2}$ for the weighted\n$k$-Set Packing Problem with $k\\geq 3$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:35:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Neuwohner", "Meike", ""]]}, {"id": "2106.03799", "submitter": "Ary Naim", "authors": "Aryan Naim, Joseph Bowkett, Sisir Karumanchi, Peyman Tavallali, Brett\n  Kennedy", "title": "Deterministic Iteratively Built KD-Tree with KNN Search for Exact\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial\nintelligence software with applications in robotics, and autonomous vehicles.\nThese wide-ranging applications utilize KNN either directly for simple\nclassification or combine KNN results as input to other algorithms such as\nLocally Weighted Learning (LWL). Similar to binary trees, kd-trees become\nunbalanced as new data is added in online applications which can lead to rapid\ndegradation in search performance unless the tree is rebuilt. Although\napproximate methods are suitable for graphics applications, which prioritize\nquery speed over query accuracy, they are unsuitable for certain applications\nin autonomous systems, aeronautics, and robotic manipulation where exact\nsolutions are desired. In this paper, we will attempt to assess the performance\nof non-recursive deterministic kd-tree functions and KNN functions. We will\nalso present a \"forest of interval kd-trees\" which reduces the number of tree\nrebuilds, without compromising the exactness of query results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:09:22 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Naim", "Aryan", ""], ["Bowkett", "Joseph", ""], ["Karumanchi", "Sisir", ""], ["Tavallali", "Peyman", ""], ["Kennedy", "Brett", ""]]}, {"id": "2106.03824", "submitter": "Quanquan C. Liu", "authors": "Quanquan C. Liu, Jessica Shi, Shangdi Yu, Laxman Dhulipala, Julian\n  Shun", "title": "Parallel Batch-Dynamic $k$-Core Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining a $k$-core decomposition quickly in a dynamic graph is an\nimportant problem in many applications, including social network analytics,\ngraph visualization, centrality measure computations, and community detection\nalgorithms. The main challenge for designing efficient $k$-core decomposition\nalgorithms is that a single change to the graph can cause the decomposition to\nchange significantly.\n  We present the first parallel batch-dynamic algorithm for maintaining an\napproximate $k$-core decomposition that is efficient in both theory and\npractice. Given an initial graph with $m$ edges, and a batch of $B$ updates,\nour algorithm maintains a $(2 + \\delta)$-approximation of the coreness values\nfor all vertices (for any constant $\\delta > 0$) in $O(B\\log^2 m)$ amortized\nwork and $O(\\log^2 m \\log\\log m)$ depth (parallel time) with high probability.\nOur algorithm also maintains a low out-degree orientation of the graph in the\nsame bounds. We implemented and experimentally evaluated our algorithm on a\n30-core machine with two-way hyper-threading on $11$ graphs of varying\ndensities and sizes. Compared to the state-of-the-art algorithms, our algorithm\nachieves up to a 114.52x speedup against the best multicore implementation and\nup to a 497.63x speedup against the best sequential algorithm, obtaining\nresults for graphs that are orders-of-magnitude larger than those used in\nprevious studies.\n  In addition, we present the first approximate static $k$-core algorithm with\nlinear work and polylogarithmic depth. We show that on a 30-core machine with\ntwo-way hyper-threading, our implementation achieves up to a 3.9x speedup in\nthe static case over the previous state-of-the-art parallel algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:45:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Quanquan C.", ""], ["Shi", "Jessica", ""], ["Yu", "Shangdi", ""], ["Dhulipala", "Laxman", ""], ["Shun", "Julian", ""]]}, {"id": "2106.03845", "submitter": "Dorna Abdolazimi", "authors": "Dorna Abdolazimi, Kuikui Liu, and Shayan Oveis Gharan", "title": "A Matrix Trickle-Down Theorem on Simplicial Complexes and Applications\n  to Sampling Colorings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the natural Glauber dynamics mixes rapidly and generates a\nrandom proper edge-coloring of a graph with maximum degree $\\Delta$ whenever\nthe number of colors is at least $q\\geq (\\frac{10}{3} + \\epsilon)\\Delta$, where\n$\\epsilon>0$ is arbitrary and the maximum degree satisfies $\\Delta \\geq C$ for\na constant $C = C(\\epsilon)$ depending only on $\\epsilon$. For edge-colorings,\nthis improves upon prior work \\cite{Vig99, CDMPP19} which show rapid mixing\nwhen $q\\geq (\\frac{11}{3}-\\epsilon_0 ) \\Delta$, where $\\epsilon_0 \\approx\n10^{-5}$ is a small fixed constant. At the heart of our proof, we establish a\nmatrix trickle-down theorem, generalizing Oppenheim's influential result, as a\nnew technique to prove that a high dimensional simplical complex is a local\nspectral expander.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:58:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Abdolazimi", "Dorna", ""], ["Liu", "Kuikui", ""], ["Gharan", "Shayan Oveis", ""]]}, {"id": "2106.03943", "submitter": "Ajay Kshemkalyani", "authors": "Ajay D. Kshemkalyani and Gokarna Sharma", "title": "Near-Optimal Dispersion on Arbitrary Anonymous Graphs", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected, anonymous, port-labeled graph of $n$ memory-less nodes,\n$m$ edges, and degree $\\Delta$, we consider the problem of dispersing $k\\leq n$\nrobots (or tokens) positioned initially arbitrarily on one or more nodes of the\ngraph to exactly $k$ different nodes of the graph, one on each node. The\nobjective is to simultaneously minimize time to achieve dispersion and memory\nrequirement at each robot. If all $k$ robots are positioned initially on a\nsingle node, depth first search (DFS) traversal solves this problem in\n$O(\\min\\{m,k\\Delta\\})$ time with $\\Theta(\\log(k+\\Delta))$ bits at each robot.\nHowever, if robots are positioned initially on multiple nodes, the best\npreviously known algorithm solves this problem in $O(\\min\\{m,k\\Delta\\}\\cdot\n\\log \\ell)$ time storing $\\Theta(\\log(k+\\Delta))$ bits at each robot, where\n$\\ell\\leq k/2$ is the number of multiplicity nodes in the initial\nconfiguration. In this paper, we present a novel multi-source DFS traversal\nalgorithm solving this problem in $O(\\min\\{m,k\\Delta\\})$ time with\n$\\Theta(\\log(k+\\Delta))$ bits at each robot, improving the time bound of the\nbest previously known algorithm by $O(\\log \\ell)$ and matching asymptotically\nthe single-source DFS traversal bounds. This is the first algorithm for\ndispersion that is optimal in both time and memory in arbitrary anonymous\ngraphs of constant degree, $\\Delta=O(1)$. Furthermore, the result holds in both\nsynchronous and asynchronous settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 20:08:48 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kshemkalyani", "Ajay D.", ""], ["Sharma", "Gokarna", ""]]}, {"id": "2106.03969", "submitter": "Enric Boix-Adser\\`a", "authors": "Enric Boix-Adsera, Guy Bresler, Frederic Koehler", "title": "Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models", "comments": "49 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a tree-structured Ising model from data,\nsuch that subsequent predictions computed using the model are accurate.\nConcretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small\nsets of variables $S$ are accurate. Since its introduction more than 50 years\nago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood\ntree, has been the benchmark algorithm for learning tree-structured graphical\nmodels. A bound on the sample complexity of the Chow-Liu algorithm with respect\nto the prediction-centric local total variation loss was shown in [BK19]. While\nthose results demonstrated that it is possible to learn a useful model even\nwhen recovering the true underlying graph is impossible, their bound depends on\nthe maximum strength of interactions and thus does not achieve the\ninformation-theoretic optimum. In this paper, we introduce a new algorithm that\ncarefully combines elements of the Chow-Liu algorithm with tree metric\nreconstruction methods to efficiently and optimally learn tree Ising models\nunder a prediction-centric loss. Our algorithm is robust to model\nmisspecification and adversarial corruptions. In contrast, we show that the\ncelebrated Chow-Liu algorithm can be arbitrarily suboptimal.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 21:09:29 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 13:18:46 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Boix-Adsera", "Enric", ""], ["Bresler", "Guy", ""], ["Koehler", "Frederic", ""]]}, {"id": "2106.04037", "submitter": "Deepan Muthirayan", "authors": "Deepan Muthirayan and Pramod P. Khargonekar", "title": "Online Algorithms for Network Robustness under Connectivity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present algorithms for designing networks that are robust\nto node failures with minimal or limited number of links. We present algorithms\nfor both the static network setting and the dynamic network setting; setting\nwhere new nodes can arrive in the future. For the static setting, we present\nalgorithms for constructing the optimal network in terms of the number of links\nused for a given node size and the number of nodes that can fail. We then\nconsider the dynamic setting where it is disruptive to remove any of the older\nlinks. For this setting, we present online algorithms for two cases: (i) when\nthe number of nodes that can fail remains constant and (ii) when only the\nproportion of the nodes that can fail remains constant. We show that the\nproposed algorithm for the first case saves nearly $3/4$th of the total\npossible links at any point of time. We then present algorithms for various\nlevels of the fraction of the nodes that can fail and characterize their link\nusage. We show that when $1/2$ the number of nodes can fail at any point of\ntime, the proposed algorithm saves nearly $1/2$ of the total possible links at\nany point of time. We show that when the number of nodes that can fail is\nlimited to the fraction $1/(2m)$ ($m \\in \\mathbb{N}$), the proposed algorithm\nsaves nearly as much as $(1-1/2m)$ of the total possible links at any point of\ntime. We also show that when the number of nodes that can fail at any point of\ntime is $1/2$ of the number of nodes plus $n$, $n \\in \\mathbb{N}$, the number\nof links saved by the proposed algorithm reduces only linearly in $n$. We\nconjecture that the saving ratio achieved by the algorithms we present is\noptimal for the dynamic setting.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 01:09:40 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Muthirayan", "Deepan", ""], ["Khargonekar", "Pramod P.", ""]]}, {"id": "2106.04105", "submitter": "Nima Anari", "authors": "Nima Anari, Vishesh Jain, Frederic Koehler, Huy Tuan Pham, Thuy-Duong\n  Vuong", "title": "Entropic Independence in High-Dimensional Expanders: Modified\n  Log-Sobolev Inequalities for Fractionally Log-Concave Polynomials and the\n  Ising Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion called entropic independence for distributions $\\mu$\ndefined on pure simplicial complexes, i.e., subsets of size $k$ of a ground set\nof elements. Informally, we call a background measure $\\mu$ entropically\nindependent if for any (possibly randomly chosen) set $S$, the relative entropy\nof an element of $S$ drawn uniformly at random carries at most $O(1/k)$\nfraction of the relative entropy of $S$, a constant multiple of its ``share of\nentropy.'' Entropic independence is the natural analog of spectral\nindependence, another recently established notion, if one replaces variance by\nentropy.\n  In our main result, we show that $\\mu$ is entropically independent exactly\nwhen a transformed version of the generating polynomial of $\\mu$ can be upper\nbounded by its linear tangent, a property implied by concavity of the said\ntransformation. We further show that this concavity is equivalent to spectral\nindependence under arbitrary external fields, an assumption that also goes by\nthe name of fractional log-concavity. Our result can be seen as a new tool to\nestablish entropy contraction from the much simpler variance contraction\ninequalities. A key differentiating feature of our result is that we make no\nassumptions on marginals of $\\mu$ or the degrees of the underlying graphical\nmodel when $\\mu$ is based on one. We leverage our results to derive tight\nmodified log-Sobolev inequalities for multi-step down-up walks on fractionally\nlog-concave distributions. As our main application, we establish the tight\nmixing time of $O(n\\log n)$ for Glauber dynamics on Ising models with\ninteraction matrix of operator norm smaller than $1$, improving upon the prior\nquadratic dependence on $n$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 05:07:24 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Anari", "Nima", ""], ["Jain", "Vishesh", ""], ["Koehler", "Frederic", ""], ["Pham", "Huy Tuan", ""], ["Vuong", "Thuy-Duong", ""]]}, {"id": "2106.04179", "submitter": "Slobodan Mitrovi\\'c", "authors": "Manuela Fischer, Slobodan Mitrovi\\'c, Jara Uitto", "title": "Deterministic $(1+\\varepsilon)$-Approximate Maximum Matching with\n  $\\mathsf{poly}(1/\\varepsilon)$ Passes in the Semi-Streaming Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic $(1+\\varepsilon)$-approximate maximum matching\nalgorithm in $\\mathsf{poly}(1/\\varepsilon)$ passes in the semi-streaming model,\nsolving the long-standing open problem of breaking the exponential barrier in\nthe dependence on $1/\\varepsilon$. Our algorithm exponentially improves on the\nwell-known randomized $(1/\\varepsilon)^{O(1/\\varepsilon)}$-pass algorithm from\nthe seminal work by McGregor [APPROX05], the recent deterministic algorithm by\nTirodkar with the same pass complexity [FSTTCS18], as well as the deterministic\n$\\log n \\cdot \\mathsf{poly}(1/\\varepsilon)$-pass algorithm by Ahn and Guha\n[ICALP11].\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:41:45 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 14:44:37 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 14:32:05 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fischer", "Manuela", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Uitto", "Jara", ""]]}, {"id": "2106.04191", "submitter": "Jari De Kroon", "authors": "Bart M.P. Jansen and Jari J.H. de Kroon", "title": "FPT Algorithms to Compute the Elimination Distance to Bipartite Graphs\n  and More", "comments": "14 pages, to appear at WG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a hereditary graph class $\\mathcal{H}$, the $\\mathcal{H}$-elimination\ndistance of a graph $G$ is the minimum number of rounds needed to reduce $G$ to\na member of $\\mathcal{H}$ by removing one vertex from each connected component\nin each round. The $\\mathcal{H}$-treewidth of a graph $G$ is the minimum, taken\nover all vertex sets $X$ for which each connected component of $G - X$ belongs\nto $\\mathcal{H}$, of the treewidth of the graph obtained from $G$ by replacing\nthe neighborhood of each component of $G-X$ by a clique and then removing $V(G)\n\\setminus X$. These parameterizations recently attracted interest because they\nare simultaneously smaller than the graph-complexity measures treedepth and\ntreewidth, respectively, and the vertex-deletion distance to $\\mathcal{H}$. For\nthe class $\\mathcal{H}$ of bipartite graphs, we present non-uniform\nfixed-parameter tractable algorithms for testing whether the\n$\\mathcal{H}$-elimination distance or $\\mathcal{H}$-treewidth of a graph is at\nmost $k$. Along the way, we also provide such algorithms for all graph classes\n$\\mathcal{H}$ defined by a finite set of forbidden induced subgraphs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:05:05 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["de Kroon", "Jari J. H.", ""]]}, {"id": "2106.04224", "submitter": "Zhiyi Huang", "authors": "Ruiquan Gao and Zhongtian He and Zhiyi Huang and Zipei Nie and Bijun\n  Yuan and Yan Zhong", "title": "Improved Online Correlated Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the online correlated selection (OCS) problem introduced\nby Fahrbach, Huang, Tao, and Zadimoghaddam (2020) to get the first\nedge-weighted online bipartite matching algorithm that breaks the $0.5$\nbarrier. Suppose that we receive a pair of elements in each round and select\none of them. Can we select with negative correlation to be more effective than\nindependent random selections? Our contributions are threefold. For semi-OCS,\nwhich considers the probability that an element remains unselected after\nappearing in $k$ rounds, we give an optimal algorithm that minimizes this\nprobability for all $k$. It leads to $0.536$-competitive unweighted and\nvertex-weighted online bipartite matching algorithms that randomize over only\ntwo options in each round, improving the previous 0.508-competitive ratio by\nFahrbach et al. (2020). Further, we give the first multi-way semi-OCS that\nallows an arbitrary number of elements with arbitrary masses in each round. As\nan application, it rounds the Balance algorithm in unweighted and\nvertex-weighted online bipartite matching to get a $0.593$-competitive ratio.\nThis is the first algorithm other than Ranking whose competitive ratio is\nbeyond the $0.5 + \\epsilon$ regime. Finally, we study OCS, which further\nconsiders the probability that an element is unselected in any subset of\nrounds. We prove that the optimal \"level of negative correlation\" is between\n$0.167$ and $0.25$, improving the previous bounds of $0.109$ and $1$ by\nFahrbach et al. (2020). Our OCS gives a $0.519$-competitive edge-weighted\nonline bipartite matching algorithm, improving the previous $0.508$-competitive\nratio by Fahrbach et al. (2020).\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:05:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Gao", "Ruiquan", ""], ["He", "Zhongtian", ""], ["Huang", "Zhiyi", ""], ["Nie", "Zipei", ""], ["Yuan", "Bijun", ""], ["Zhong", "Yan", ""]]}, {"id": "2106.04247", "submitter": "Pasin Manurangsi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Rasmus Pagh", "title": "Private Counting from Anonymous Messages: Near-Optimal Accuracy with\n  Vanishing Communication Overhead", "comments": "Originally appeared in ICML'20. This version contains a correction of\n  calculation errors in Theorem 13 of the ICML'20 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a formal notion for quantifying the privacy loss\nof algorithms. Algorithms in the central model of DP achieve high accuracy but\nmake the strongest trust assumptions whereas those in the local DP model make\nthe weakest trust assumptions but incur substantial accuracy loss. The shuffled\nDP model (Bittau et al., 2017; Erlingsson et al., 2019; Cheu et al., 2019) has\nrecently emerged as a feasible middle ground between the central and local\nmodels, providing stronger trust assumptions than the former while promising\nhigher accuracies than the latter. In this paper, we obtain practical\ncommunication-efficient algorithms in the shuffled DP model for two basic\naggregation primitives used in machine learning: 1) binary summation, and 2)\nhistograms over a moderate number of buckets. Our algorithms achieve accuracy\nthat is arbitrarily close to that of central DP algorithms with an expected\ncommunication per user essentially matching what is needed without any privacy\nconstraints! We demonstrate the practicality of our algorithms by\nexperimentally comparing their performance to several widely-used protocols\nsuch as Randomized Response (Warner, 1965) and RAPPOR (Erlingsson et al.,\n2014).\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:51:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""], ["Pagh", "Rasmus", ""]]}, {"id": "2106.04254", "submitter": "Cameron Musco", "authors": "Tung Mai and Anup B. Rao and Cameron Musco", "title": "Coresets for Classification -- Simplified and Strengthened", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give relative error coresets for training linear classifiers with a broad\nclass of loss functions, including the logistic loss and hinge loss. Our\nconstruction achieves $(1\\pm \\epsilon)$ relative error with $\\tilde O(d \\cdot\n\\mu_y(X)^2/\\epsilon^2)$ points, where $\\mu_y(X)$ is a natural complexity\nmeasure of the data matrix $X \\in \\mathbb{R}^{n \\times d}$ and label vector $y\n\\in \\{-1,1\\}^n$, introduced in by Munteanu et al. 2018. Our result is based on\nsubsampling data points with probabilities proportional to their $\\ell_1$\n$Lewis$ $weights$. It significantly improves on existing theoretical bounds and\nperforms well in practice, outperforming uniform subsampling along with other\nimportance sampling methods. Our sampling distribution does not depend on the\nlabels, so can be used for active learning. It also does not depend on the\nspecific loss function, so a single coreset can be used in multiple training\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:24:18 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 01:49:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Mai", "Tung", ""], ["Rao", "Anup B.", ""], ["Musco", "Cameron", ""]]}, {"id": "2106.04364", "submitter": "Ripon Patgiri", "authors": "Sabuzima Nayak and Ripon Patgiri", "title": "countBF: A General-purpose High Accuracy and Space Efficient Counting\n  Bloom Filter", "comments": "Submitted to IEEE Conference for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bloom Filter is a probabilistic data structure for the membership query, and\nit has been intensely experimented in various fields to reduce memory\nconsumption and enhance a system's performance. Bloom Filter is classified into\ntwo key categories: counting Bloom Filter (CBF), and non-counting Bloom Filter.\nCBF has a higher false positive probability than standard Bloom Filter (SBF),\ni.e., CBF uses a higher memory footprint than SBF. But CBF can address the\nissue of the false negative probability. Notably, SBF is also false negative\nfree, but it cannot support delete operations like CBF. To address these\nissues, we present a novel counting Bloom Filter based on SBF and 2D Bloom\nFilter, called countBF. countBF uses a modified murmur hash function to enhance\nits various requirements, which is experimentally evaluated. Our experimental\nresults show that countBF uses $1.96\\times$ and $7.85\\times$ less memory than\nSBF and CBF respectively, while preserving lower false positive probability and\nexecution time than both SBF and CBF. The overall accuracy of countBF is\n$99.999921$, and it proves the superiority of countBF over SBF and CBF. Also,\nwe compare with other state-of-the-art counting Bloom Filters.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:33:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nayak", "Sabuzima", ""], ["Patgiri", "Ripon", ""]]}, {"id": "2106.04365", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri", "title": "robustBF: A High Accuracy and Memory Efficient 2D Bloom Filter", "comments": "Submitted to IEEE conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bloom Filter is an important probabilistic data structure to reduce memory\nconsumption for membership filters. It is applied in diverse domains such as\nComputer Networking, Network Security and Privacy, IoT, Edge Computing, Cloud\nComputing, Big Data, and Biometrics. But Bloom Filter has an issue of the false\npositive probability. To address this issue, we propose a novel robust Bloom\nFilter, robustBF for short. robustBF is a 2D Bloom Filter, capable of filtering\nmillions of data with high accuracy without compromising the performance. Our\nproposed system is presented in two-fold. Firstly, we modify the murmur hash\nfunction, and test all modified hash functions for improvements and select the\nbest-modified hash function experimentally. Secondly, we embed the modified\nhash functions in 2D Bloom Filter. Our experimental results show that robustBF\nis better than standard Bloom Filter and counting Bloom Filter in every aspect.\nrobustBF exhibits nearly zero false positive probability with more than\n$10\\times$ and $44\\times$ lower memory consumption than standard Bloom filter\nand counting Bloom Filter, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:27:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Patgiri", "Ripon", ""]]}, {"id": "2106.04486", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Mohit Wadhwa, Philip S. Yu, Bryan Hooi", "title": "Sketch-Based Streaming Anomaly Detection in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges and subgraphs in an online manner, for the purpose of detecting\nunusual behavior, using constant time and memory? For example, in intrusion\ndetection, existing work seeks to detect either anomalous edges or anomalous\nsubgraphs, but not both. In this paper, we first extend the count-min sketch\ndata structure to a higher-order sketch. This higher-order sketch has the\nuseful property of preserving the dense subgraph structure (dense subgraphs in\nthe input turn into dense submatrices in the data structure). We then propose\nfour online algorithms that utilize this enhanced data structure, which (a)\ndetect both edge and graph anomalies; (b) process each edge and graph in\nconstant memory and constant update time per newly arriving edge, and; (c)\noutperform state-of-the-art baselines on four real-world datasets. Our method\nis the first streaming approach that incorporates dense subgraph search to\ndetect graph anomalies in constant memory and time.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:10:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Wadhwa", "Mohit", ""], ["Yu", "Philip S.", ""], ["Hooi", "Bryan", ""]]}, {"id": "2106.04629", "submitter": "Debasis Dwibedy", "authors": "Debasis Dwibedy, Rakesh Mohanty", "title": "New Competitive Semi-online Scheduling Algorithms for Small Number of\n  Identical Machines", "comments": "24 Pages, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design and analysis of constant competitive deterministic semi-online\nalgorithms for the multi-processor scheduling problem with small number of\nidentical machines have gained significant research interest in the last two\ndecades. In the semi-online scheduling problem for makespan minimization, we\nare given a sequence of independent jobs one by one in order and upon arrival,\neach job must be allocated to a machine with prior knowledge of some Extra\nPiece of Information (EPI) about the future jobs. Researchers have designed\nmultiple variants of semi-online scheduling algorithms with constant\ncompetitive ratios by considering one or more EPI. In this paper, we propose\nfour new variants of competitive deterministic semi-online algorithms for\nsmaller number of identical machines by considering two EPI such as Decr and\nSum. We obtain improved upper bound and lower bound results on the competitive\nratio for our proposed algorithms, which are comparable to the best known\nresults in the literature. In two identical machines setting with known Sum, we\nshow a tight bound of 1.33 on the competitive ratio by considering a sequence\nof equal size jobs. In the same setting we achieve a lower bound of 1.04 and an\nupper bound of 1.16 by considering Sum and a sequence of jobs arriving in order\nof decreasing sizes. For three identical machines setting with known Decr and\nSum, we show a lower bound of 1.11 on the competitive ratio. In this setting,\nwe obtain an upper bound of 1.5 for scheduling a sequence of equal size jobs\nand achieves an upper bound of 1.2 by considering a sequence of decreasing size\njobs. Further we develop an improved competitive algorithm with an upper bound\nof 1.11 on the competitive ratio.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:27:12 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dwibedy", "Debasis", ""], ["Mohanty", "Rakesh", ""]]}, {"id": "2106.04633", "submitter": "John Michael Goddard Kallaugher", "authors": "John Kallaugher", "title": "A Quantum Advantage for a Natural Streaming Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data streaming, in which a large dataset is received as a \"stream\" of\nupdates, is an important model in the study of space-bounded computation.\nStarting with the work of Le Gall [SPAA `06], it has been known that quantum\nstreaming algorithms can use asymptotically less space than their classical\ncounterparts for certain problems. However, so far, all known examples of\nquantum advantages in streaming are for problems that are either specially\nconstructed for that purpose, or require many streaming passes over the input.\n  We give a one-pass quantum streaming algorithm for one of the best studied\nproblems in classical graph streaming - the triangle counting problem.\nAlmost-tight parametrized upper and lower bounds are known for this problem in\nthe classical setting; our algorithm uses polynomially less space in certain\nregions of the parameter space, resolving a question posed by Jain and Nayak in\n2014 on achieving quantum advantages for natural streaming problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:34:22 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kallaugher", "John", ""]]}, {"id": "2106.04704", "submitter": "Yifeng Teng", "authors": "Shuchi Chawla, Rojin Rezvan, Yifeng Teng, Christos Tzamos", "title": "Pricing Ordered Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the revenue guarantees and approximability of item pricing. Recent\nwork shows that with $n$ heterogeneous items, item-pricing guarantees an\n$O(\\log n)$ approximation to the optimal revenue achievable by any (buy-many)\nmechanism, even when buyers have arbitrarily combinatorial valuations. However,\nfinding good item prices is challenging -- it is known that even under\nunit-demand valuations, it is NP-hard to find item prices that approximate the\nrevenue of the optimal item pricing better than $O(\\sqrt{n})$.\n  Our work provides a more fine-grained analysis of the revenue guarantees and\ncomputational complexity in terms of the number of item ``categories'' which\nmay be significantly fewer than $n$. We assume the items are partitioned in $k$\ncategories so that items within a category are totally-ordered and a buyer's\nvalue for a bundle depends only on the best item contained from every category.\n  We show that item-pricing guarantees an $O(\\log k)$ approximation to the\noptimal (buy-many) revenue and provide a PTAS for computing the optimal\nitem-pricing when $k$ is constant. We also provide a matching lower bound\nshowing that the problem is (strongly) NP-hard even when $k=1$. Our results\nnaturally extend to the case where items are only partially ordered, in which\ncase the revenue guarantees and computational complexity depend on the width of\nthe partial ordering, i.e. the largest set for which no two items are\ncomparable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:45:36 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chawla", "Shuchi", ""], ["Rezvan", "Rojin", ""], ["Teng", "Yifeng", ""], ["Tzamos", "Christos", ""]]}, {"id": "2106.04708", "submitter": "Duc P. Truong", "authors": "Duc P. Truong, Erik Skau, Derek Desantis, Boian Alexandrov", "title": "Boolean Matrix Factorization via Nonnegative Auxiliary Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel approach to Boolean matrix factorization (BMF) is presented. Instead\nof solving the BMF problem directly, this approach solves a nonnegative\noptimization problem with the constraint over an auxiliary matrix whose Boolean\nstructure is identical to the initial Boolean data. Then the solution of the\nnonnegative auxiliary optimization problem is thresholded to provide a solution\nfor the BMF problem. We provide the proofs for the equivalencies of the two\nsolution spaces under the existence of an exact solution. Moreover, the\nnonincreasing property of the algorithm is also proven. Experiments on\nsynthetic and real datasets are conducted to show the effectiveness and\ncomplexity of the algorithm compared to other current methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:55:49 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Truong", "Duc P.", ""], ["Skau", "Erik", ""], ["Desantis", "Derek", ""], ["Alexandrov", "Boian", ""]]}, {"id": "2106.04727", "submitter": "Shangdi Yu", "authors": "Shangdi Yu, Yiqiu Wang, Yan Gu, Laxman Dhulipala, Julian Shun", "title": "ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering\n  using Nearest-Neighbor Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the hierarchical clustering problem, where the goal is to\nproduce a dendrogram that represents clusters at varying scales of a data set.\nWe propose the ParChain framework for designing parallel hierarchical\nagglomerative clustering (HAC) algorithms, and using the framework we obtain\nnovel parallel algorithms for the complete linkage, average linkage, and Ward's\nlinkage criteria. Compared to most previous parallel HAC algorithms, which\nrequire quadratic memory, our new algorithms require only linear memory, and\nare scalable to large data sets. ParChain is based on our parallelization of\nthe nearest-neighbor chain algorithm, and enables multiple clusters to be\nmerged on every round. We introduce two key optimizations that are critical for\nefficiency: a range query optimization that reduces the number of distance\ncomputations required when finding nearest neighbors of clusters, and a caching\noptimization that stores a subset of previously computed distances, which are\nlikely to be reused.\n  Experimentally, we show that our highly-optimized implementations using 48\ncores with two-way hyper-threading achieve 5.8--110.1x speedup over\nstate-of-the-art parallel HAC algorithms and achieve 13.75--54.23x\nself-relative speedup. Compared to state-of-the-art algorithms, our algorithms\nrequire up to 237.3x less space. Our algorithms are able to scale to data set\nsizes with tens of millions of points, which existing algorithms are not able\nto handle.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:13:27 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Yu", "Shangdi", ""], ["Wang", "Yiqiu", ""], ["Gu", "Yan", ""], ["Dhulipala", "Laxman", ""], ["Shun", "Julian", ""]]}, {"id": "2106.04769", "submitter": "Siddharth Mitra", "authors": "Siddharth Mitra, Moran Feldman, Amin Karbasi", "title": "Submodular + Concave", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been well established that first order optimization methods can\nconverge to the maximal objective value of concave functions and provide\nconstant factor approximation guarantees for (non-convex/non-concave)\ncontinuous submodular functions. In this work, we initiate the study of the\nmaximization of functions of the form $F(x) = G(x) +C(x)$ over a solvable\nconvex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a\nsmooth concave function. This class of functions is a strict extension of both\nconcave and continuous DR-submodular functions for which no theoretical\nguarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,\ndepending on the nature of the objective function (i.e., if $G$ and $C$ are\nmonotone or not, and non-negative or not) and on the nature of the set $P$\n(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$\napproximation guarantees. We then use our algorithms to get a framework to\nsmoothly interpolate between choosing a diverse set of elements from a given\nground set (corresponding to the mode of a determinantal point process) and\nchoosing a clustered set of elements (corresponding to the maxima of a suitable\nconcave function). Additionally, we apply our algorithms to various functions\nin the above class (DR-submodular + concave) in both constrained and\nunconstrained settings, and show that our algorithms consistently outperform\nnatural baselines.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 01:59:55 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mitra", "Siddharth", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "2106.04819", "submitter": "Jonathan Schneider", "authors": "Sreenivas Gollapudi, Guru Guruganesh, Kostas Kollias, Pasin\n  Manurangsi, Renato Paes Leme, Jon Schneider", "title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the following variant of contextual linear bandits motivated by\nrouting applications in navigational engines and recommendation systems. We\nwish to learn a hidden $d$-dimensional value $w^*$. Every round, we are\npresented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible\nactions. If we choose (i.e. recommend to the user) action $x_t$, we obtain\nutility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best\naction $\\arg\\max_{x \\in \\mathcal{X}_t} \\langle x, w^* \\rangle$. We design\nalgorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d\n\\log d))$. To accomplish this, we design novel cutting-plane algorithms with\nlow \"regret\" -- the total distance between the true point $w^*$ and the\nhyperplanes the separation oracle returns. We also consider the variant where\nwe are allowed to provide a list of several recommendations. In this variant,\nwe give an algorithm with $O(d^2 \\log d)$ regret and list size\n$\\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker\nvariant of this problem where the learner only learns the identity of an action\nthat is better than the recommendation. Our results rely on new algorithmic\ntechniques in convex geometry (including a variant of Steiner's formula for the\ncentroid of a convex set) which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 05:39:05 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Gollapudi", "Sreenivas", ""], ["Guruganesh", "Guru", ""], ["Kollias", "Kostas", ""], ["Manurangsi", "Pasin", ""], ["Leme", "Renato Paes", ""], ["Schneider", "Jon", ""]]}, {"id": "2106.04856", "submitter": "Nithin Varma", "authors": "Ilan Newman and Nithin Varma", "title": "Strongly Sublinear Algorithms for Testing Pattern Freeness", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a permutation $\\pi:[k] \\to [k]$, a function $f:[n] \\to \\mathbb{R}$\ncontains a $\\pi$-appearance if there exists $1 \\leq i_1 < i_2 < \\dots < i_k\n\\leq n$ such that for all $s,t \\in [k]$, it holds that $f(i_s) < f(i_t)$ if and\nonly if $\\pi(s) < \\pi(t)$. The function is $\\pi$-free if it has no\n$\\pi$-appearances. In this paper, we investigate the problem of testing whether\nan input function $f$ is $\\pi$-free or whether at least $\\varepsilon n$ values\nin $f$ need to be changed in order to make it $\\pi$-free. This problem is a\ngeneralization of the well-studied monotonicity testing and was first studied\nby Newman, Rabinovich, Rajendraprasad and Sohler (Random Structures and\nAlgorithms 2019). We show that for all constants $k \\in \\mathbb{N}$,\n$\\varepsilon \\in (0,1)$, and permutation $\\pi:[k] \\to [k]$, there is a\none-sided error $\\varepsilon$-testing algorithm for $\\pi$-freeness of functions\n$f:[n] \\to \\mathbb{R}$ that makes $\\tilde{O}(n^{o(1)})$ queries. We improve\nsignificantly upon the previous best upper bound $O(n^{1 - 1/(k-1)})$ by\nBen-Eliezer and Canonne (SODA 2018). Our algorithm is adaptive, while the\nearlier best upper bound is known to be tight for nonadaptive algorithms.\nHence, our results also show that adaptivity helps in testing freeness of order\npatterns.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:31:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Newman", "Ilan", ""], ["Varma", "Nithin", ""]]}, {"id": "2106.04863", "submitter": "David Wajc", "authors": "Niv Buchbinder, Joseph (Seffi) Naor and David Wajc", "title": "A Randomness Threshold for Online Bipartite Matching, via Lossless\n  Online Rounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over three decades ago, Karp, Vazirani and Vazirani (STOC'90) introduced the\nonline bipartite matching problem. They observed that deterministic algorithms'\ncompetitive ratio for this problem is no greater than $1/2$, and proved that\nrandomized algorithms can do better. A natural question thus arises: \\emph{how\nrandom is random}? i.e., how much randomness is needed to outperform\ndeterministic algorithms? The \\textsc{ranking} algorithm of Karp et\nal.~requires $\\tilde{O}(n)$ random bits, which, ignoring polylog terms,\nremained unimproved. On the other hand, Pena and Borodin (TCS'19) established a\nlower bound of $(1-o(1))\\log\\log n$ random bits for any $1/2+\\Omega(1)$\ncompetitive ratio.\n  We close this doubly-exponential gap, proving that, surprisingly, the lower\nbound is tight. In fact, we prove a \\emph{sharp threshold} of $(1\\pm\no(1))\\log\\log n$ random bits for the randomness necessary and sufficient to\noutperform deterministic algorithms for this problem, as well as its\nvertex-weighted generalization. This implies the same threshold for the advice\ncomplexity (nondeterminism) of these problems.\n  Similar to recent breakthroughs in the online matching literature, for\nedge-weighted matching (Fahrbach et al.~FOCS'20) and adwords (Huang et\nal.~FOCS'20), our algorithms break the barrier of $1/2$ by randomizing matching\nchoices over two neighbors. Unlike these works, our approach does not rely on\nthe recently-introduced OCS machinery, nor the more established randomized\nprimal-dual method. Instead, our work revisits a highly-successful online\ndesign technique, which was nonetheless under-utilized in the area of online\nmatching, namely (lossless) online rounding of fractional algorithms. While\nthis technique is known to be hopeless for online matching in general, we show\nthat it is nonetheless applicable to carefully designed fractional algorithms\nwith additional (non-convex) constraints.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:40:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Buchbinder", "Niv", "", "Seffi"], ["Joseph", "", "", "Seffi"], ["Naor", "", ""], ["Wajc", "David", ""]]}, {"id": "2106.05123", "submitter": "Orson Peters", "authors": "Orson R. L. Peters", "title": "Pattern-defeating Quicksort", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A new solution for the Dutch national flag problem is proposed, requiring no\nthree-way comparisons, which gives quicksort a proper worst-case runtime of\n$O(nk)$ for inputs with $k$ distinct elements. This is used together with other\nknown and novel techniques to construct a hybrid sort that is never\nsignificantly slower than regular quicksort while speeding up drastically for\nmany input distributions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 15:00:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Peters", "Orson R. L.", ""]]}, {"id": "2106.05131", "submitter": "Yuchao Tao", "authors": "Yuchao Tao, Johes Bater, Ashwin Machanavajjhala", "title": "Prior-Aware Distribution Estimation for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joint distribution estimation of a dataset under differential privacy is a\nfundamental problem for many privacy-focused applications, such as query\nanswering, machine learning tasks and synthetic data generation. In this work,\nwe examine the joint distribution estimation problem given two data points: 1)\ndifferentially private answers of a workload computed over private data and 2)\na prior empirical distribution from a public dataset. Our goal is to find a new\ndistribution such that estimating the workload using this distribution is as\naccurate as the differentially private answer, and the relative entropy, or KL\ndivergence, of this distribution is minimized with respect to the prior\ndistribution. We propose an approach based on iterative optimization for\nsolving this problem. An application of our solution won second place in the\nNIST 2020 Differential Privacy Temporal Map Challenge, Sprint 2.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 15:15:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tao", "Yuchao", ""], ["Bater", "Johes", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "2106.05245", "submitter": "Peter Macgregor", "authors": "Peter Macgregor and He Sun", "title": "Local Algorithms for Finding Densely Connected Clusters", "comments": "This work is accepted at ICML'21 for a long presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Local graph clustering is an important algorithmic technique for analysing\nmassive graphs, and has been widely applied in many research fields of data\nscience. While the objective of most (local) graph clustering algorithms is to\nfind a vertex set of low conductance, there has been a sequence of recent\nstudies that highlight the importance of the inter-connection between clusters\nwhen analysing real-world datasets. Following this line of research, in this\nwork we study local algorithms for finding a pair of vertex sets defined with\nrespect to their inter-connection and their relationship with the rest of the\ngraph. The key to our analysis is a new reduction technique that relates the\nstructure of multiple sets to a single vertex set in the reduced graph. Among\nmany potential applications, we show that our algorithms successfully recover\ndensely connected clusters in the Interstate Disputes Dataset and the US\nMigration Dataset.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:40:45 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Macgregor", "Peter", ""], ["Sun", "He", ""]]}, {"id": "2106.05423", "submitter": "Leonidas Tsepenekas", "authors": "Darshan Chakrabarti, John P. Dickerson, Seyed A. Esmaeili, Aravind\n  Srinivasan, Leonidas Tsepenekas", "title": "A New Notion of Individually Fair Clustering: $\\alpha$-Equitable\n  $k$-Center", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised machine learning, and\nfair variants of it have recently received significant attention. In this work\nwe introduce a novel definition of fairness for clustering problems.\nSpecifically, in our model each point $j$ has a set of other points\n$\\mathcal{S}_j$ that it perceives as similar to itself, and it feels that it is\nfairly treated, if the quality of service it receives in the solution is\n$\\alpha$-close to that of the points in $\\mathcal{S}_j$. We begin our study by\nanswering questions regarding the structure of the problem, namely for what\nvalues of $\\alpha$ the problem is well-defined, and what the behavior of the\nPrice of Fairness (PoF) for it is. For the well-defined region of $\\alpha$, we\nprovide efficient and easily implementable approximation algorithms for the\n$k$-center objective, which in certain cases also enjoy bounded PoF guarantees.\nWe finally complement our analysis by an extensive suite of experiments that\nvalidates the effectiveness of our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 22:52:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chakrabarti", "Darshan", ""], ["Dickerson", "John P.", ""], ["Esmaeili", "Seyed A.", ""], ["Srinivasan", "Aravind", ""], ["Tsepenekas", "Leonidas", ""]]}, {"id": "2106.05424", "submitter": "Leonidas Tsepenekas", "authors": "Amy Babay, Michael Dinitz, Prathyush Sambaturu, Aravind Srinivasan,\n  Leonidas Tsepenekas, Anil Vullikanti", "title": "Fair Disaster Containment via Graph-Cut Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph cut problems form a fundamental problem type in combinatorial\noptimization, and are a central object of study in both theory and practice. In\naddition, the study of fairness in Algorithmic Design and Machine Learning has\nrecently received significant attention, with many different notions proposed\nand analyzed in a variety of contexts. In this paper we initiate the study of\nfairness for graph cut problems by giving the first fair definitions for them,\nand subsequently we demonstrate appropriate algorithmic techniques that yield a\nrigorous theoretical analysis. Specifically, we incorporate two different\ndefinitions of fairness, namely demographic and probabilistic individual\nfairness, in a particular cut problem modeling disaster containment scenarios.\nOur results include a variety of approximation algorithms with provable\ntheoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 22:52:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Babay", "Amy", ""], ["Dinitz", "Michael", ""], ["Sambaturu", "Prathyush", ""], ["Srinivasan", "Aravind", ""], ["Tsepenekas", "Leonidas", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2106.05480", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned\n  Distributions", "comments": "47 pages, 1 figure, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give lower bounds on the performance of two of the most popular sampling\nmethods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and\nmulti-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when\napplied to well-conditioned distributions. Our main result is a nearly-tight\nlower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from\nan exponentially warm start, matching a line of algorithmic results up to\nlogarithmic factors and answering an open question of Chewi et. al. We also\nshow that a polynomial dependence on dimension is necessary for the relaxation\ntime of HMC under any number of leapfrog steps, and bound the gains achievable\nby changing the step count. Our HMC analysis draws upon a novel connection\nbetween leapfrog integration and Chebyshev polynomials, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 03:47:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.05513", "submitter": "Jason Li", "authors": "Jason Li", "title": "Deterministic Mincut in Almost-Linear Time", "comments": "STOC 2021, 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a deterministic (global) mincut algorithm for weighted, undirected\ngraphs that runs in $m^{1+o(1)}$ time, answering an open question of Karger\nfrom the 1990s. To obtain our result, we de-randomize the construction of the\n\\emph{skeleton} graph in Karger's near-linear time mincut algorithm, which is\nits only randomized component. In particular, we partially de-randomize the\nwell-known Benczur-Karger graph sparsification technique by random sampling,\nwhich we accomplish by the method of pessimistic estimators. Our main technical\ncomponent is designing an efficient pessimistic estimator to capture the cuts\nof a graph, which involves harnessing the expander decomposition framework\nintroduced in recent work by Goranci et al. (SODA 2021). As a side-effect, we\nobtain a structural representation of all approximate mincuts in a graph, which\nmay have future applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:01:25 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Li", "Jason", ""]]}, {"id": "2106.05579", "submitter": "Guy Blanc", "authors": "Guy Blanc and Moses Charikar", "title": "Multiway Online Correlated Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a $0.5368$-competitive algorithm for edge-weighted online bipartite\nmatching. Prior to our work, the best competitive ratio was $0.5086$ due to\nFahrbach, Huang, Tao, and Zadimoghaddam (FOCS 2020). They achieved their\nbreakthrough result by developing a subroutine called \\emph{online correlated\nselection} (OCS) which takes as input a sequence of pairs and selects one item\nfrom each pair. Importantly, the selections the OCS makes are negatively\ncorrelated.\n  We achieve our result by defining \\emph{multiway} OCSes which receive\narbitrarily many elements at each step, rather than just two. In addition to\nbetter competitive ratios, our formulation allows for a simpler reduction from\nedge-weighted online bipartite matching to OCSes. While Fahrbach et al. used a\nfactor-revealing linear program to optimize the competitive ratio, our analysis\ndirectly connects the competitive ratio to the parameters of the multiway OCS.\nFinally, we show that the formulation of Farhbach et al. can achieve a\ncompetitive ratio of at most $0.5239$, confirming that multiway OCSes are\nstrictly more powerful.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:05:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Blanc", "Guy", ""], ["Charikar", "Moses", ""]]}, {"id": "2106.05610", "submitter": "Laxman Dhulipala", "authors": "Laxman Dhulipala, David Eisenstat, Jakub {\\L}\\k{a}cki, Vahab Mirrokni,\n  Jessica Shi", "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time", "comments": "This is the full version of the paper appearing in ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:29:05 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Dhulipala", "Laxman", ""], ["Eisenstat", "David", ""], ["\u0141\u0105cki", "Jakub", ""], ["Mirrokni", "Vahab", ""], ["Shi", "Jessica", ""]]}, {"id": "2106.05720", "submitter": "Maria Chiara Angelini", "authors": "Maria Chiara Angelini, Paolo Fachin, Simone de Feo", "title": "Mismatching as a tool to enhance algorithmic performances of Monte Carlo\n  methods for the planted clique model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.DS cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over-parametrization was a crucial ingredient for recent developments in\ninference and machine-learning fields. However a good theory explaining this\nsuccess is still lacking. In this paper we study a very simple case of\nmismatched over-parametrized algorithm applied to one of the most studied\ninference problem: the planted clique problem. We analyze a Monte Carlo (MC)\nalgorithm in the same class of the famous Jerrum algorithm. We show how this MC\nalgorithm is in general suboptimal for the recovery of the planted clique. We\nshow however how to enhance its performances by adding a (mismatched)\nparameter: the temperature; we numerically find that this over-parametrized\nversion of the algorithm can reach the supposed algorithmic threshold for the\nplanted clique problem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:07:17 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Angelini", "Maria Chiara", ""], ["Fachin", "Paolo", ""], ["de Feo", "Simone", ""]]}, {"id": "2106.05761", "submitter": "Diptapriyo Majumdar", "authors": "Jason Crampton, Eduard Eiben, Gregory Gutin, Daniel Karapetyan,\n  Diptapriyo Majumdar", "title": "Valued Authorization Policy Existence Problem: Theory and Experiments", "comments": "32 pages, 5 figures. Preliminary version appeared in SACMAT 2021\n  (https://doi.org/10.1145/3450569.3463571). Some of the theoretical results\n  (algorithms) have been improved. Computational experiments have been added to\n  this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that many problems of satisfiability and resiliency in\nworkflows may be viewed as special cases of the authorization policy existence\nproblem (APEP), which returns an authorization policy if one exists and 'No'\notherwise. However, in many practical settings it would be more useful to\nobtain a 'least bad' policy than just a 'No', where 'least bad' is\ncharacterized by some numerical value indicating the extent to which the policy\nviolates the base authorization relation and constraints. Accordingly, we\nintroduce the Valued APEP, which returns an authorization policy of minimum\nweight, where the (non-negative) weight is determined by the constraints\nviolated by the returned solution. We then establish a number of results\nconcerning the parameterized complexity of Valued APEP. We prove that the\nproblem is fixed-parameter tractable (FPT) if the set of constraints satisfies\ntwo restrictions, but is intractable if only one of these restrictions holds.\n(Most constraints known to be of practical use satisfy both restrictions.) We\nalso introduce a new type of resiliency for workflow satisfiability problem,\nshow how it can be addressed using Valued APEP and use this to build a set of\nbenchmark instances for Valued APEP. Following a set of computational\nexperiments with two mixed integer programming (MIP) formulations, we\ndemonstrate that the Valued APEP formulation based on the user profile concept\nhas FPT-like running time and usually significantly outperforms a naive\nformulation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:06:18 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 13:58:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Crampton", "Jason", ""], ["Eiben", "Eduard", ""], ["Gutin", "Gregory", ""], ["Karapetyan", "Daniel", ""], ["Majumdar", "Diptapriyo", ""]]}, {"id": "2106.05833", "submitter": "Luc Pronzato", "authors": "Amaya Nogales G\\'omez, Luc Pronzato, Maria-Jo\\~ao Rendas", "title": "Incremental space-filling design based on coverings and spacings:\n  improving upon low discrepancy sequences", "comments": "28 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper addresses the problem of defining families of ordered sequences\n$\\{x_i\\}_{i\\in N}$ of elements of a compact subset $X$ of $R^d$ whose prefixes\n$X_n=\\{x_i\\}_{i=1}^{n}$, for all orders $n$, have good space-filling properties\nas measured by the dispersion (covering radius) criterion. Our ultimate aim is\nthe definition of incremental algorithms that generate sequences $X_n$ with\nsmall optimality gap, i.e., with a small increase in the maximum distance\nbetween points of $X$ and the elements of $X_n$ with respect to the optimal\nsolution $X_n^\\star$. The paper is a first step in this direction, presenting\nincremental design algorithms with proven optimality bound for one-parameter\nfamilies of criteria based on coverings and spacings that both converge to\ndispersion for large values of their parameter. The examples presented show\nthat the covering-based method outperforms state-of-the-art competitors,\nincluding coffee-house, suggesting that it inherits from its guaranteed 50\\%\noptimality gap.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:30:40 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["G\u00f3mez", "Amaya Nogales", ""], ["Pronzato", "Luc", ""], ["Rendas", "Maria-Jo\u00e3o", ""]]}, {"id": "2106.05900", "submitter": "Kunal Marwaha", "authors": "Boaz Barak and Kunal Marwaha", "title": "Classical algorithms and quantum limitations for maximum cut on\n  high-girth graphs", "comments": "1+20 pages, 2 figures, code online at https://tiny.cc/QAOAvsALR", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the performance of local quantum algorithms such as the Quantum\nApproximate Optimization Algorithm (QAOA) for the maximum cut problem, and\ntheir relationship to that of classical algorithms.\n  (1) We prove that every (quantum or classical) one-local algorithm achieves\non $D$-regular graphs of girth $> 5$ a maximum cut of at most $1/2 +\nC/\\sqrt{D}$ for $C=1/\\sqrt{2} \\approx 0.7071$. This is the first such result\nshowing that one-local algorithms achieve a value bounded away from the true\noptimum for random graphs, which is $1/2 + P_*/\\sqrt{D} + o(1/\\sqrt{D})$ for\n$P_* \\approx 0.7632$. (2) We show that there is a classical $k$-local algorithm\nthat achieves a value of $1/2 + C/\\sqrt{D} - O(1/\\sqrt{k})$ for $D$-regular\ngraphs of girth $> 2k+1$, where $C = 2/\\pi \\approx 0.6366$. This is an\nalgorithmic version of the existential bound of Lyons and is related to the\nalgorithm of Aizenman, Lebowitz, and Ruelle (ALR) for the\nSherrington-Kirkpatrick model. This bound is better than that achieved by the\none-local and two-local versions of QAOA on high-girth graphs. (3) Through\ncomputational experiments, we give evidence that the ALR algorithm achieves\nbetter performance than constant-locality QAOA for random $D$-regular graphs,\nas well as other natural instances, including graphs that do have short cycles.\n  Our experimental work suggests that it could be possible to extend beyond our\ntheoretical constraints. This points at the tantalizing possibility that\n$O(1)$-local quantum maximum-cut algorithms might be *pointwise dominated* by\npolynomial-time classical algorithms, in the sense that there is a classical\nalgorithm outputting cuts of equal or better quality *on every possible\ninstance*. This is in contrast to the evidence that polynomial-time algorithms\ncannot simulate the probability distributions induced by local quantum\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:28:23 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Barak", "Boaz", ""], ["Marwaha", "Kunal", ""]]}, {"id": "2106.05939", "submitter": "Ran Yeheskel", "authors": "Roy Schwartz, Ran Yeheskel", "title": "Graph Balancing with Orientation Costs", "comments": null, "journal-ref": "ESA 2019: 82:1-82:15", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the classic Generalized Assignment Problem, we consider the\nGraph Balancing problem in the presence of orientation costs: given an\nundirected multi-graph G = (V,E) equipped with edge weights and orientation\ncosts on the edges, the goal is to find an orientation of the edges that\nminimizes both the maximum weight of edges oriented toward any vertex\n(makespan) and total orientation cost. We present a general framework for\nminimizing makespan in the presence of costs that allows us to: (1) achieve\nbicriteria approximations for the Graph Balancing problem that capture known\nprevious results (Shmoys-Tardos [Math. Progrm. 93], Ebenlendr-Krc\\'al- Sgall\n[Algorithmica 14], and Wang-Sitters [Inf. Process. Lett. 16]); and (2) achieve\nbicriteria approximations for extensions of the Graph Balancing problem that\nadmit hyperedges and unrelated weights. Our framework is based on a remarkably\nsimple rounding of a strengthened linear relaxation. We complement the above by\npresenting bicriteria lower bounds with respect to the linear programming\nrelaxations we use that show that a loss in the total orientation cost is\nrequired if one aims for an approximation better than 2 in the makespan.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:39:42 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Schwartz", "Roy", ""], ["Yeheskel", "Ran", ""]]}, {"id": "2106.05944", "submitter": "Crist\\'obal Guzm\\'an", "authors": "Santiago Armstrong, Crist\\'obal Guzm\\'an, Carlos A. Sing-Long", "title": "An Optimal Algorithm for Strict Circular Seriation", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of circular seriation, where we are given a matrix of\npairwise dissimilarities between $n$ objects, and the goal is to find a {\\em\ncircular order} of the objects in a manner that is consistent with their\ndissimilarity. This problem is a generalization of the classical {\\em linear\nseriation} problem where the goal is to find a {\\em linear order}, and for\nwhich optimal ${\\cal O}(n^2)$ algorithms are known. Our contributions can be\nsummarized as follows. First, we introduce {\\em circular Robinson matrices} as\nthe natural class of dissimilarity matrices for the circular seriation problem.\nSecond, for the case of {\\em strict circular Robinson dissimilarity matrices}\nwe provide an optimal ${\\cal O}(n^2)$ algorithm for the circular seriation\nproblem. Finally, we propose a statistical model to analyze the well-posedness\nof the circular seriation problem for large $n$. In particular, we establish\n${\\cal O}(\\log(n)/n)$ rates on the distance between any circular ordering found\nby solving the circular seriation problem to the underlying order of the model,\nin the Kendall-tau metric.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:42:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Armstrong", "Santiago", ""], ["Guzm\u00e1n", "Crist\u00f3bal", ""], ["Sing-Long", "Carlos A.", ""]]}, {"id": "2106.05947", "submitter": "Gwena\\\"el Joret", "authors": "Samuel Fiorini and Gwena\\\"el Joret and Stefan Weltge and Yelena\n  Yuditsky", "title": "Integer programs with bounded subdeterminants and two nonzeros per row", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a strongly polynomial-time algorithm for integer linear programs\ndefined by integer coefficient matrices whose subdeterminants are bounded by a\nconstant and that contain at most two nonzero entries in each row. The core of\nour approach is the first polynomial-time algorithm for the weighted stable set\nproblem on graphs that do not contain more than $k$ vertex-disjoint odd cycles,\nwhere $k$ is any constant. Previously, polynomial-time algorithms were only\nknown for $k=0$ (bipartite graphs) and for $k=1$.\n  We observe that integer linear programs defined by coefficient matrices with\nbounded subdeterminants and two nonzeros per column can be also solved in\nstrongly polynomial-time, using a reduction to $b$-matching.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:46:01 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Fiorini", "Samuel", ""], ["Joret", "Gwena\u00ebl", ""], ["Weltge", "Stefan", ""], ["Yuditsky", "Yelena", ""]]}, {"id": "2106.05964", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi", "title": "Fair Classification with Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fair classification in the presence of an omniscient adversary that,\ngiven an $\\eta$, is allowed to choose an arbitrary $\\eta$-fraction of the\ntraining samples and arbitrarily perturb their protected attributes. The\nmotivation comes from settings in which protected attributes can be incorrect\ndue to strategic misreporting, malicious actors, or errors in imputation; and\nprior approaches that make stochastic or independence assumptions on errors may\nnot satisfy their guarantees in this adversarial setting. Our main contribution\nis an optimization framework to learn fair classifiers in this adversarial\nsetting that comes with provable guarantees on accuracy and fairness. Our\nframework works with multiple and non-binary protected attributes, is designed\nfor the large class of linear-fractional fairness metrics, and can also handle\nperturbations besides protected attributes. We prove near-tightness of our\nframework's guarantees for natural hypothesis classes: no algorithm can have\nsignificantly better accuracy and any algorithm with better fairness must have\nlower accuracy. Empirically, we evaluate the classifiers produced by our\nframework for statistical rate on real-world and synthetic datasets for a\nfamily of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:56:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2106.06037", "submitter": "Tatiana Starikovskaya", "authors": "Tomasz Kociumaka, Ely Porat, Tatiana Starikovskaya", "title": "Small space and streaming pattern matching with k edits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we revisit the fundamental and well-studied problem of\napproximate pattern matching under edit distance. Given an integer $k$, a\npattern $P$ of length $m$, and a text $T$ of length $n \\ge m$, the task is to\nfind substrings of $T$ that are within edit distance $k$ from $P$. Our main\nresult is a streaming algorithm that solves the problem in $\\tilde{O}(k^5)$\nspace and $\\tilde{O}(k^8)$ amortised time per character of the text, providing\nanswers correct with high probability. (Hereafter, $\\tilde{O}(\\cdot)$ hides a\n$\\mathrm{poly}(\\log n)$ factor.) This answers a decade-old question: since the\ndiscovery of a $\\mathrm{poly}(k\\log n)$-space streaming algorithm for pattern\nmatching under Hamming distance by Porat and Porat [FOCS 2009], the existence\nof an analogous result for edit distance remained open. Up to this work, no\n$\\mathrm{poly}(k\\log n)$-space algorithm was known even in the simpler\nsemi-streaming model, where $T$ comes as a stream but $P$ is available for\nread-only access. In this model, we give a deterministic algorithm that\nachieves slightly better complexity.\n  In order to develop the fully streaming algorithm, we introduce a new edit\ndistance sketch parametrised by integers $n\\ge k$. For any string of length at\nmost $n$, the sketch is of size $\\tilde{O}(k^2)$ and it can be computed with an\n$\\tilde{O}(k^2)$-space streaming algorithm. Given the sketches of two strings,\nin $\\tilde{O}(k^3)$ time we can compute their edit distance or certify that it\nis larger than $k$. This result improves upon $\\tilde{O}(k^8)$-size sketches of\nBelazzougui and Zhu [FOCS 2016] and very recent $\\tilde{O}(k^3)$-size sketches\nof Jin, Nelson, and Wu [STACS 2021].\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:32:20 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kociumaka", "Tomasz", ""], ["Porat", "Ely", ""], ["Starikovskaya", "Tatiana", ""]]}, {"id": "2106.06249", "submitter": "Stefan Siemer", "authors": "Pawe{\\l} Gawrychowski, Florin Manea, Stefan Siemer", "title": "Matching Patterns with Variables under Hamming Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A pattern $\\alpha$ is a string of variables and terminal letters. We say that\n$\\alpha$ matches a word $w$, consisting only of terminal letters, if $w$ can be\nobtained by replacing the variables of $\\alpha$ by terminal words. The matching\nproblem, i.e., deciding whether a given pattern matches a given word, was\nheavily investigated: it is NP-complete in general, but can be solved\nefficiently for classes of patterns with restricted structure. In this paper,\nwe approach this problem in a generalized setting, by considering approximate\npattern matching under Hamming distance. More precisely, we are interested in\nwhat is the minimum Hamming distance between $w$ and any word $u$ obtained by\nreplacing the variables of $\\alpha$ by terminal words. Firstly, we address the\nclass of regular patterns (in which no variable occurs twice) and propose\nefficient algorithms for this problem, as well as matching conditional lower\nbounds. We show that the problem can still be solved efficiently if we allow\nrepeated variables, but restrict the way the different variables can be\ninterleaved according to a locality parameter. However, as soon as we allow a\nvariable to occur more than once and its occurrences can be interleaved\narbitrarily with those of other variables, even if none of them occurs more\nthan once, the problem becomes intractable.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 09:00:37 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Manea", "Florin", ""], ["Siemer", "Stefan", ""]]}, {"id": "2106.06308", "submitter": "Davin Choo", "authors": "Davin Choo, Tommaso d'Orsi", "title": "The Complexity of Sparse Tensor PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sparse tensor principal component analysis: given a\ntensor $\\pmb Y = \\pmb W + \\lambda x^{\\otimes p}$ with $\\pmb W \\in\n\\otimes^p\\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover\nthe $k$-sparse unit vector $x \\in \\mathbb{R}^n$. The model captures both sparse\nPCA (in its Wigner form) and tensor PCA.\n  For the highly sparse regime of $k \\leq \\sqrt{n}$, we present a family of\nalgorithms that smoothly interpolates between a simple polynomial-time\nalgorithm and the exponential-time exhaustive search algorithm. For any $1 \\leq\nt \\leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio\n$\\lambda \\geq \\tilde{\\mathcal{O}} (\\sqrt{t} \\cdot (k/t)^{p/2})$ in time\n$\\tilde{\\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for\nthe matrix settings (in both the polynomial-time and sub-exponential time\nregimes).\n  Our results naturally extend to the case of $r$ distinct $k$-sparse signals\nwith disjoint supports, with guarantees that are independent of the number of\nspikes. Even in the restricted case of sparse PCA, known algorithms only\nrecover the sparse vectors for $\\lambda \\geq \\tilde{\\mathcal{O}}(k \\cdot r)$\nwhile our algorithms require $\\lambda \\geq \\tilde{\\mathcal{O}}(k)$.\n  Finally, by analyzing the low-degree likelihood ratio, we complement these\nalgorithmic results with rigorous evidence illustrating the trade-offs between\nsignal-to-noise ratio and running time. This lower bound captures the known\nlower bounds for both sparse PCA and tensor PCA. In this general model, we\nobserve a more intricate three-way trade-off between the number of samples $n$,\nthe sparsity $k$, and the tensor power $p$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:57:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Choo", "Davin", ""], ["d'Orsi", "Tommaso", ""]]}, {"id": "2106.06453", "submitter": "Mark Simkin", "authors": "Nils Fleischhacker and Kasper Green Larsen and and Mark Simkin", "title": "Property-Preserving Hash Functions from Standard Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Property-preserving hash functions allow for compressing long inputs $x_0$\nand $x_1$ into short hashes $h(x_0)$ and $h(x_1)$ in a manner that allows for\ncomputing a predicate $P(x_0, x_1)$ given only the two hash values without\nhaving access to the original data. Such hash functions are said to be\nadversarially robust if an adversary that gets to pick $x_0$ and $x_1$ after\nthe hash function has been sampled, cannot find inputs for which the predicate\nevaluated on the hash values outputs the incorrect result.\n  In this work we construct robust property-preserving hash functions for the\nhamming-distance predicate which distinguishes inputs with a hamming distance\nat least some threshold $t$ from those with distance less than $t$. The\nsecurity of the construction is based on standard lattice hardness assumptions.\n  Our construction has several advantages over the best known previous\nconstruction by Fleischhacker and Simkin. Our construction relies on a single\nwell-studied hardness assumption from lattice cryptography whereas the previous\nwork relied on a newly introduced family of computational hardness assumptions.\nIn terms of computational effort, our construction only requires a small number\nof modular additions per input bit, whereas previously several exponentiations\nper bit as well as the interpolation and evaluation of high-degree polynomials\nover large fields were required. An additional benefit of our construction is\nthat the description of the hash function can be compressed to $\\lambda$ bits\nassuming a random oracle. Previous work has descriptions of length\n$\\mathcal{O}(\\ell \\lambda)$ bits for input bit-length $\\ell$, which has a\nsecret structure and thus cannot be compressed.\n  We prove a lower bound on the output size of any property-preserving hash\nfunction for the hamming distance predicate. The bound shows that the size of\nour hash value is not far from optimal.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:21:38 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Fleischhacker", "Nils", ""], ["Larsen", "Kasper Green", ""], ["Simkin", "and Mark", ""]]}, {"id": "2106.06525", "submitter": "Tal Ohayon", "authors": "Tal Ohayon", "title": "ExtendedHyperLogLog: Analysis of a new Cardinality Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of counting distinct elements in a stream. A stream is\nusually considered as a sequence of elements that come one at a time. An exact\nsolution to the problem requires memory space of the size of the stream. For\nmany applications this solution is infeasible due to very large streams. The\nsolution in that case, is to use a probabilistic data structure (also called\nsketch), from which we can estimate with high accuracy the cardinality of the\nstream. We present a new algorithm, ExtendedHyperLogLog (EHLL), which is based\non the state-of-the-art algorithm, HyperLogLog (HLL). In order to achieve the\nsame accuracy as HLL, EHLL uses 16% less memory. In recent years, a martingale\napproach has bean developed. In the martingale setting we receive better\naccuracy at the price of not being able to merge sketches. EHLL also works in\nthe martingale setting. Martingale EHLL achieves the same accuracy as\nMartingale HLL using 12% less memory.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:50:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 08:28:32 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Ohayon", "Tal", ""]]}, {"id": "2106.06601", "submitter": "Marko Kabi\\'c", "authors": "Marko Kabi\\'c, Simon Pintarelli, Anton Kozhevnikov and Joost\n  VandeVondele", "title": "COSTA: Communication-Optimal Shuffle and Transpose Algorithm with\n  Process Relabeling", "comments": "To be published in the proceedings of the 36th International\n  Conference on High Performance Computing, ISC High Performance 2021. The\n  implementation of the algorithm is available at:\n  https://github.com/eth-cscs/COSTA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication-avoiding algorithms for Linear Algebra have become increasingly\npopular, in particular for distributed memory architectures. In practice, these\nalgorithms assume that the data is already distributed in a specific way, thus\nmaking data reshuffling a key to use them. For performance reasons, a\nstraightforward all-to-all exchange must be avoided.\n  Here, we show that process relabeling (i.e. permuting processes in the final\nlayout) can be used to obtain communication optimality for data reshuffling,\nand that it can be efficiently found by solving a Linear Assignment Problem\n(Maximum Weight Bipartite Perfect Matching). Based on this, we have developed a\nCommunication-Optimal Shuffle and Transpose Algorithm (COSTA): this\nhighly-optimised algorithm implements $A=\\alpha\\cdot \\operatorname{op}(B) +\n\\beta \\cdot A,\\ \\operatorname{op} \\in \\{\\operatorname{transpose},\n\\operatorname{conjugate-transpose}, \\operatorname{identity}\\}$ on distributed\nsystems, where $A, B$ are matrices with potentially different (distributed)\nlayouts and $\\alpha, \\beta$ are scalars. COSTA can take advantage of the\ncommunication-optimal process relabeling even for heterogeneous network\ntopologies, where latency and bandwidth differ among nodes. The implementation\nnot only outperforms the best available ScaLAPACK redistribute and transpose\nroutines multiple times, but is also able to deal with more general matrix\nlayouts, in particular it is not limited to block-cyclic layouts. Finally, we\nuse COSTA to integrate a communication-optimal matrix multiplication algorithm\ninto the CP2K quantum chemistry simulation package. This way, we show that\nCOSTA can be used to unlock the full potential of recent Linear Algebra\nalgorithms in applications by facilitating interoperability between algorithms\nwith a wide range of data layouts, in addition to bringing significant\nredistribution speedups.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:31:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kabi\u0107", "Marko", ""], ["Pintarelli", "Simon", ""], ["Kozhevnikov", "Anton", ""], ["VandeVondele", "Joost", ""]]}, {"id": "2106.06755", "submitter": "Dishant Goyal", "authors": "Dishant Goyal and Ragesh Jaiswal", "title": "FPT Approximation for Socially Fair Clustering", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the socially fair $k$-median/$k$-means problem. We are\ngiven a set of points $P$ in a metric space $\\mathcal{X}$ with a distance\nfunction $d(.,.)$. There are $\\ell$ groups: $P_1,\\dotsc,P_{\\ell} \\subseteq P$.\nWe are also given a set $F$ of feasible centers in $\\mathcal{X}$. The goal of\nthe socially fair $k$-median problem is to find a set $C \\subseteq F$ of $k$\ncenters that minimizes the maximum average cost over all the groups. That is,\nfind $C$ that minimizes the objective function $\\Phi(C,P) \\equiv \\max_{j}\n\\sum_{x \\in P_j} d(C,x)/|P_j|$, where $d(C,x)$ is the distance of $x$ to the\nclosest center in $C$. The socially fair $k$-means problem is defined similarly\nby using squared distances, i.e., $d^{2}(.,.)$ instead of $d(.,.)$. In this\nwork, we design $(5+\\varepsilon)$ and $(33 + \\varepsilon)$ approximation\nalgorithms for the socially fair $k$-median and $k$-means problems,\nrespectively. For the parameters: $k$ and $\\ell$, the algorithms have an FPT\n(fixed parameter tractable) running time of $f(k,\\ell,\\varepsilon) \\cdot n$ for\n$f(k,\\ell,\\varepsilon) = 2^{{O}(k \\, \\ell/\\varepsilon)}$ and $n = |P \\cup F|$.\nWe also study a special case of the problem where the centers are allowed to be\nchosen from the point set $P$, i.e., $P \\subseteq F$. For this special case,\nour algorithms give better approximation guarantees of $(4+\\varepsilon)$ and\n$(18+\\varepsilon)$ for the socially fair $k$-median and $k$-means problems,\nrespectively. Furthermore, we convert these algorithms to constant pass\nlog-space streaming algorithms. Lastly, we show FPT hardness of approximation\nresults for the problem with a small gap between our upper and lower bounds.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 11:53:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Goyal", "Dishant", ""], ["Jaiswal", "Ragesh", ""]]}, {"id": "2106.06892", "submitter": "Nathaniel Grammel", "authors": "Brian Brubach, Nathaniel Grammel, Will Ma and Aravind Srinivasan", "title": "Improved Guarantees for Offline Stochastic Matching via new Ordered\n  Contention Resolution Schemes", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching is one of the most fundamental and broadly applicable problems\nacross many domains. In these diverse real-world applications, there is often a\ndegree of uncertainty in the input which has led to the study of stochastic\nmatching models. Here, each edge in the graph has a known, independent\nprobability of existing derived from some prediction. Algorithms must probe\nedges to determine existence and match them irrevocably if they exist. Further,\neach vertex may have a patience constraint denoting how many of its neighboring\nedges can be probed. We present new ordered contention resolution schemes\nyielding improved approximation guarantees for some of the foundational\nproblems studied in this area. For stochastic matching with patience\nconstraints in general graphs, we provide a 0.382-approximate algorithm,\nsignificantly improving over the previous best 0.31-approximation of Baveja et\nal. (2018). When the vertices do not have patience constraints, we describe a\n0.432-approximate random order probing algorithm with several corollaries such\nas an improved guarantee for the Prophet Secretary problem under Edge Arrivals.\nFinally, for the special case of bipartite graphs with unit patience\nconstraints on one of the partitions, we show a 0.632-approximate algorithm\nthat improves on the recent $1/3$-guarantee of Hikima et al. (2021).\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 01:26:22 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Brubach", "Brian", ""], ["Grammel", "Nathaniel", ""], ["Ma", "Will", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "2106.06950", "submitter": "Alberto Boffi", "authors": "Alberto Boffi", "title": "An efficient way to manage blocks of data with Wise Red-Black Trees", "comments": "Added references to order-statistic trees. Corrected some terms and\n  form. Results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes the most efficient way to manage operations on groups of\nconsecutive elements, or \"blocks\" of elements, within an ordered set. The goal\nis to improve existing solutions, by optimizing the average-case time\ncomplexity and getting rid of heavy multiplicative constants in the worst-case,\nwithout sacrificing space complexity. This is an high-impact operation in\npractical applications, and will be performed by introducing a new data\nstructure called Wise Red-Black Tree, an augmented version of the Red-Black\nTree.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 09:30:41 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 19:00:47 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Boffi", "Alberto", ""]]}, {"id": "2106.07017", "submitter": "Amihood Amir", "authors": "Amihood Amir and Itai Boneh and Eitan Kondratovsky", "title": "The k-mappability problem revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The $k$-mappability problem has two integers parameters $m$ and $k$. For\nevery subword of size $m$ in a text $S$, we wish to report the number of\nindices in $S$ in which the word occurs with at most $k$ mismatches.\n  The problem was lately tackled by Alzamel et al. For a text with constant\nalphabet $\\Sigma$ and $k \\in O(1)$, they present an algorithm with linear space\nand $O(n\\log^{k+1}n)$ time. For the case in which $k = 1$ and a constant size\nalphabet, a faster algorithm with linear space and $O(n\\log(n)\\log\\log(n))$\ntime was presented in a 2020 paper by Alzamel et al.\n  In this work, we enhance the techniques of Alzamel et al.'s 2020 paper to\nobtain an algorithm with linear space and $O(n \\log(n))$ time for $k = 1$. Our\nalgorithm removes the constraint of the alphabet being of constant size. We\nalso present linear algorithms for the case of $k=1$, $|\\Sigma|\\in O(1)$ and\n$m=\\Omega(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 14:58:53 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Amir", "Amihood", ""], ["Boneh", "Itai", ""], ["Kondratovsky", "Eitan", ""]]}, {"id": "2106.07046", "submitter": "Yujia Jin", "authors": "Yujia Jin, Aaron Sidford", "title": "Towards Tight Bounds on the Sample Complexity of Average-reward MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new upper and lower bounds for sample complexity of finding an\n$\\epsilon$-optimal policy of an infinite-horizon average-reward Markov decision\nprocess (MDP) given access to a generative model. When the mixing time of the\nprobability transition matrix of all policies is at most $t_\\mathrm{mix}$, we\nprovide an algorithm that solves the problem using\n$\\widetilde{O}(t_\\mathrm{mix} \\epsilon^{-3})$ (oblivious) samples per\nstate-action pair. Further, we provide a lower bound showing that a linear\ndependence on $t_\\mathrm{mix}$ is necessary in the worst case for any algorithm\nwhich computes oblivious samples. We obtain our results by establishing\nconnections between infinite-horizon average-reward MDPs and discounted MDPs of\npossible further utility.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:18:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2106.07059", "submitter": "Hongyang Sun", "authors": "Lucas Perotin, Hongyang Sun, Padma Raghavan", "title": "Multi-Resource List Scheduling of Moldable Parallel Jobs under\n  Precedence Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scheduling literature has traditionally focused on a single type of\nresource (e.g., computing nodes). However, scientific applications in modern\nHigh-Performance Computing (HPC) systems process large amounts of data, hence\nhave diverse requirements on different types of resources (e.g., cores, cache,\nmemory, I/O). All of these resources could potentially be exploited by the\nruntime scheduler to improve the application performance. In this paper, we\nstudy multi-resource scheduling to minimize the makespan of computational\nworkflows comprised of parallel jobs subject to precedence constraints. The\njobs are assumed to be moldable, allowing the scheduler to flexibly select a\nvariable set of resources before execution. We propose a multi-resource,\nlist-based scheduling algorithm, and prove that, on a system with $d$ types of\nschedulable resources, our algorithm achieves an approximation ratio of\n$1.619d+2.545\\sqrt{d}+1$ for any $d$, and a ratio of $d+O(\\sqrt[3]{d^2})$ for\nlarge $d$. We also present improved results for independent jobs and for jobs\nwith special precedence constraints (e.g., series-parallel graphs and trees).\nFinally, we prove a lower bound of $d$ on the approximation ratio of any list\nscheduling scheme with local priority considerations. To the best of our\nknowledge, these are the first approximation results for moldable workflows\nwith multiple resource requirements.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:56:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Perotin", "Lucas", ""], ["Sun", "Hongyang", ""], ["Raghavan", "Padma", ""]]}, {"id": "2106.07080", "submitter": "Shiwei Zeng", "authors": "Shiwei Zeng and Jie Shen", "title": "Semi-verified Learning from the Crowd with Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of {\\em crowdsourced PAC learning} of Boolean-valued\nfunctions through enriched queries, a problem that has attracted a surge of\nrecent research interests. In particular, we consider that the learner may\nquery the crowd to obtain a label of a given instance or a comparison tag of a\npair of instances. This is a challenging problem and only recently have\nbudget-efficient algorithms been established for the scenario where the\nmajority of the crowd are correct. In this work, we investigate the\nsignificantly more challenging case that the majority are incorrect which\nrenders learning impossible in general. We show that under the {semi-verified\nmodel} of Charikar~et~al.~(2017), where we have (limited) access to a trusted\noracle who always returns the correct annotation, it is possible to learn the\nunderlying function while the labeling cost is significantly mitigated by the\nenriched and more easily obtained queries.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:05:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zeng", "Shiwei", ""], ["Shen", "Jie", ""]]}, {"id": "2106.07116", "submitter": "Benwei Wu", "authors": "Kai Han, Shuang Cui, Tianshuai Zhu, Jing Tang, Benwei Wu, He Huang", "title": "The Power of Randomization: Efficient and Effective Algorithms for\n  Constrained Submodular Maximization", "comments": "Part of the contribution appears in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular optimization has numerous applications such as crowdsourcing and\nviral marketing. In this paper, we study the fundamental problem of\nnon-negative submodular function maximization subject to a $k$-system\nconstraint, which generalizes many other important constraints in submodular\noptimization such as cardinality constraint, matroid constraint, and\n$k$-extendible system constraint. The existing approaches for this problem\nachieve the best-known approximation ratio of $k+2\\sqrt{k+2}+3$ (for a general\nsubmodular function) based on deterministic algorithmic frameworks. We propose\nseveral randomized algorithms that improve upon the state-of-the-art algorithms\nin terms of approximation ratio and time complexity, both under the\nnon-adaptive setting and the adaptive setting. The empirical performance of our\nalgorithms is extensively evaluated in several applications related to data\nmining and social computing, and the experimental results demonstrate the\nsuperiorities of our algorithms in terms of both utility and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 00:14:36 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 02:39:54 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Han", "Kai", ""], ["Cui", "Shuang", ""], ["Zhu", "Tianshuai", ""], ["Tang", "Jing", ""], ["Wu", "Benwei", ""], ["Huang", "He", ""]]}, {"id": "2106.07152", "submitter": "Bandar Al-Dhalaan", "authors": "Bandar Al-Dhalaan", "title": "Fast Construction of 4-Additive Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-additive spanner of a graph is a subgraph that preserves the distance\nbetween any two nodes up to a total additive error of $+k$. Efficient\nalgorithms have been devised for constructing 2 [Aingworth et al. SIAM '99], 6\n[Baswana et al. ACM '10, Woodruff ICALP '13], and 8-additive spanners [Knudsen\n'17], but efficiency hasn't been studied for 4-additive spanner constructions.\nIn this paper we present a modification of Chechik's 4-additive spanner\nconstruction [Chechik SODA '13] that produces a 4-additive spanner on\n$\\widetilde{O}(n^{7/5})$ edges, with an improved runtime of\n$\\widetilde{O}(mn^{3/5})$ from $O(mn)$.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:14:47 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 23:52:46 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Al-Dhalaan", "Bandar", ""]]}, {"id": "2106.07153", "submitter": "Terrance Liu", "authors": "Terrance Liu, Giuseppe Vietri, Zhiwei Steven Wu", "title": "Iterative Methods for Private Synthetic Data: Unifying Framework and New\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study private synthetic data generation for query release, where the goal\nis to construct a sanitized version of a sensitive dataset, subject to\ndifferential privacy, that approximately preserves the answers to a large\ncollection of statistical queries. We first present an algorithmic framework\nthat unifies a long line of iterative algorithms in the literature. Under this\nframework, we propose two new methods. The first method, private entropy\nprojection (PEP), can be viewed as an advanced variant of MWEM that adaptively\nreuses past query measurements to boost accuracy. Our second method, generative\nnetworks with the exponential mechanism (GEM), circumvents computational\nbottlenecks in algorithms such as MWEM and PEP by optimizing over generative\nmodels parameterized by neural networks, which capture a rich family of\ndistributions while enabling fast gradient-based optimization. We demonstrate\nthat PEP and GEM empirically outperform existing algorithms. Furthermore, we\nshow that GEM nicely incorporates prior information from public data while\novercoming limitations of PMW^Pub, the existing state-of-the-art method that\nalso leverages public data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 04:19:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liu", "Terrance", ""], ["Vietri", "Giuseppe", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2106.07202", "submitter": "Caterina De Bacco", "authors": "Abdullahi Adinoyi Ibrahim, Alessandro Lonardi and Caterina De Bacco", "title": "Optimal transport in multilayer networks", "comments": "11 pages, 6 figures", "journal-ref": "Algorithms 2021, 14(7), 189", "doi": "10.3390/a14070189", "report-no": null, "categories": "physics.soc-ph cs.DS cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling traffic distribution and extracting optimal flows in multilayer\nnetworks is of utmost importance to design efficient multi-modal network\ninfrastructures. Recent results based on optimal transport theory provide\npowerful and computationally efficient methods to address this problem, but\nthey are mainly focused on modeling single-layer networks. Here we adapt these\nresults to study how optimal flows distribute on multilayer networks. We\npropose a model where optimal flows on different layers contribute differently\nto the total cost to be minimized. This is done by means of a parameter that\nvaries with layers, which allows to flexibly tune the sensitivity to traffic\ncongestion of the various layers. As an application, we consider transportation\nnetworks, where each layer is associated to a different transportation system\nand show how the traffic distribution varies as we tune this parameter across\nlayers. We show an example of this result on the real 2-layer network of the\ncity of Bordeaux with bus and tram, where we find that in certain regimes the\npresence of the tram network significantly unburdens the traffic on the road\nnetwork. Our model paves the way to further analysis of optimal flows and\nnavigability strategies in real multilayer networks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:33:09 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Ibrahim", "Abdullahi Adinoyi", ""], ["Lonardi", "Alessandro", ""], ["De Bacco", "Caterina", ""]]}, {"id": "2106.07239", "submitter": "Seyed Esmaeili", "authors": "Seyed A. Esmaeili, Brian Brubach, Aravind Srinivasan, John P.\n  Dickerson", "title": "Fair Clustering Under a Bounded Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental unsupervised learning problem where a dataset is\npartitioned into clusters that consist of nearby points in a metric space. A\nrecent variant, fair clustering, associates a color with each point\nrepresenting its group membership and requires that each color has\n(approximately) equal representation in each cluster to satisfy group fairness.\nIn this model, the cost of the clustering objective increases due to enforcing\nfairness in the algorithm. The relative increase in the cost, the ''price of\nfairness,'' can indeed be unbounded. Therefore, in this paper we propose to\ntreat an upper bound on the clustering objective as a constraint on the\nclustering problem, and to maximize equality of representation subject to it.\nWe consider two fairness objectives: the group utilitarian objective and the\ngroup egalitarian objective, as well as the group leximin objective which\ngeneralizes the group egalitarian objective. We derive fundamental lower bounds\non the approximation of the utilitarian and egalitarian objectives and\nintroduce algorithms with provable guarantees for them. For the leximin\nobjective we introduce an effective heuristic algorithm. We further derive\nimpossibility results for other natural fairness objectives. We conclude with\nexperimental results on real-world datasets that demonstrate the validity of\nour algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:47:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Esmaeili", "Seyed A.", ""], ["Brubach", "Brian", ""], ["Srinivasan", "Aravind", ""], ["Dickerson", "John P.", ""]]}, {"id": "2106.07300", "submitter": "Halvard Hummel", "authors": "Halvard Hummel, Magnus Lie Hetland", "title": "Guaranteeing Half-Maximin Shares Under Cardinality Constraints", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fair allocation of a set of indivisible items among\nagents with additive valuations, under cardinality constraints. In this setting\nthe items are partitioned into categories, each with its own limit on the\nnumber of items it may contribute to any bundle. One example of such a problem\nis allocating seats in a multitrack conference. We consider the fairness\nmeasure known as the maximin share (MMS) guarantee, and propose a novel\npolynomial-time algorithm for finding $1/2$-approximate MMS allocations. We\nextend the notions and algorithms related to ordered and reduced instances to\nwork with cardinality constraints, and combine these with a bag filling style\nprocedure. Our algorithm improves on that of Biswas and Barman (IJCAI-18), with\nits approximation ratio of $1/3$. We also present an optimizing algorithm,\nwhich for each instance, instead of fixing $\\alpha = 1/2$, uses bisection to\nfind the largest $\\alpha$ for which our algorithm obtains a valid\n$\\alpha$-approximate MMS allocation. Numerical tests show that our algorithm\nfinds strictly better approximations than the guarantee of $1/2$ for most\ninstances, in many cases surpassing $3/5$. The optimizing version of the\nalgorithm produces MMS allocations in a comparable number of instances to that\nof Biswas and Barman's algorithm, on average achieving a better approximation\nwhen MMS is not obtained.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:08:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hummel", "Halvard", ""], ["Hetland", "Magnus Lie", ""]]}, {"id": "2106.07319", "submitter": "Melanie Schmidt", "authors": "Melanie Schmidt and Julian Wargalla", "title": "Coresets for constrained k-median and k-means clustering in low\n  dimensional Euclidean space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study (Euclidean) $k$-median and $k$-means with constraints in the\nstreaming model.\n  There have been recent efforts to design unified algorithms to solve\nconstrained $k$-means problems without using knowledge of the specific\nconstraint at hand aside from mild assumptions like the polynomial\ncomputability of feasibility under the constraint (compute if a clustering\nsatisfies the constraint) or the presence of an efficient assignment oracle\n(given a set of centers, produce an optimal assignment of points to the centers\nwhich satisfies the constraint). These algorithms have a running time\nexponential in $k$, but can be applied to a wide range of constraints.\n  We demonstrate that a technique proposed in 2019 for solving a specific\nconstrained streaming $k$-means problem, namely fair $k$-means clustering,\nactually implies streaming algorithms for all these constraints. These work for\nlow dimensional Euclidean space. [Note that there are more algorithms for\nstreaming fair $k$-means today, in particular they exist for high dimensional\nspaces now as well.]\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:45:12 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Schmidt", "Melanie", ""], ["Wargalla", "Julian", ""]]}, {"id": "2106.07412", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Aneta Neumann, Frank Neumann", "title": "Exact Counting and Sampling of Optima for the Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing sets of high quality solutions has gained increasing interest in\nrecent years. In this paper, we investigate how to obtain sets of optimal\nsolutions for the classical knapsack problem. We present an algorithm to count\nexactly the number of optima to a zero-one knapsack problem instance. In\naddition, we show how to efficiently sample uniformly at random from the set of\nall global optima. In our experimental study, we investigate how the number of\noptima develops for classical random benchmark instances dependent on their\ngenerator parameters. We find that the number of global optima can increase\nexponentially for practically relevant classes of instances with correlated\nweights and profits which poses a justification for the considered exact\ncounting problem.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 13:24:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bossek", "Jakob", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2106.07534", "submitter": "Martino Trevisan Dr", "authors": "Nikhil Jha, Thomas Favale, Luca Vassio, Martino Trevisan, Marco Mellia", "title": "z-anonymity: Zero-Delay Anonymization for Data Streams", "comments": null, "journal-ref": "In 2020 IEEE International Conference on Big Data (Big Data), pp.\n  3996-4005. IEEE, 2020", "doi": "10.1109/BigData50022.2020.9378422", "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of big data and the birth of the data markets that sell\npersonal information, individuals' privacy is of utmost importance. The\nclassical response is anonymization, i.e., sanitizing the information that can\ndirectly or indirectly allow users' re-identification. The most popular\nsolution in the literature is the k-anonymity. However, it is hard to achieve\nk-anonymity on a continuous stream of data, as well as when the number of\ndimensions becomes high.In this paper, we propose a novel anonymization\nproperty called z-anonymity. Differently from k-anonymity, it can be achieved\nwith zero-delay on data streams and it is well suited for high dimensional\ndata. The idea at the base of z-anonymity is to release an attribute (an atomic\ninformation) about a user only if at least z - 1 other users have presented the\nsame attribute in a past time window. z-anonymity is weaker than k-anonymity\nsince it does not work on the combinations of attributes, but treats them\nindividually. In this paper, we present a probabilistic framework to map the\nz-anonymity into the k-anonymity property. Our results show that a proper\nchoice of the z-anonymity parameters allows the data curator to likely obtain a\nk-anonymized dataset, with a precisely measurable probability. We also evaluate\na real use case, in which we consider the website visits of a population of\nusers and show that z-anonymity can work in practice for obtaining the\nk-anonymity too.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:00:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Jha", "Nikhil", ""], ["Favale", "Thomas", ""], ["Vassio", "Luca", ""], ["Trevisan", "Martino", ""], ["Mellia", "Marco", ""]]}, {"id": "2106.07744", "submitter": "Mark Jerrum", "authors": "Mark Jerrum", "title": "Fundamentals of Partial Rejection Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Partial Rejection Sampling is an algorithmic approach to obtaining a perfect\nsample from a specified distribution. The objects to be sampled are assumed to\nbe represented by a number of random variables. In contrast to classical\nrejection sampling, in which all variables are resampled until a feasible\nsolution is found, partial rejection sampling aims at greater efficiency by\nresampling only a subset of variables that `go wrong'. Partial rejection\nsampling is closely related to Moser and Tardos' algorithmic version of the\nLov\\'asz Local Lemma, but with the additional requirement that a specified\noutput distribution should be met. This article provides a largely\nself-contained account of the basic form of the algorithm and its analysis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 20:30:49 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jerrum", "Mark", ""]]}, {"id": "2106.07752", "submitter": "Mark Braverman", "authors": "Mark Braverman", "title": "Optimization-friendly generic mechanisms without money", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to develop a generic framework for converting\nmodern optimization algorithms into mechanisms where inputs come from\nself-interested agents. We focus on aggregating preferences from $n$ players in\na context without money. Special cases of this setting include voting,\nallocation of items by lottery, and matching. Our key technical contribution is\na new meta-algorithm we call \\apex (Adaptive Pricing Equalizing Externalities).\nThe framework is sufficiently general to be combined with any optimization\nalgorithm that is based on local search. We outline an agenda for studying the\nalgorithm's properties and its applications. As a special case of applying the\nframework to the problem of one-sided assignment with lotteries, we obtain a\nstrengthening of the 1979 result by Hylland and Zeckhauser on allocation via a\ncompetitive equilibrium from equal incomes (CEEI). The [HZ79] result posits\nthat there is a (fractional) allocation and a set of item prices such that the\nallocation is a competitive equilibrium given prices. We further show that\nthere is always a reweighing of the players' utility values such that running\nunit-demand VCG with reweighed utilities leads to a HZ-equilibrium prices.\nInterestingly, not all HZ competitive equilibria come from VCG prices. As part\nof our proof, we re-prove the [HZ79] result using only Brouwer's fixed point\ntheorem (and not the more general Kakutani's theorem). This may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 20:42:23 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Braverman", "Mark", ""]]}, {"id": "2106.07815", "submitter": "Hao Wu", "authors": "Hao Wu, Anthony Wirth", "title": "Locally Differentially Private Frequency Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two new local differentially private algorithms for frequency\nestimation. One solves the fundamental frequency oracle problem; the other\nsolves the well-known heavy hitters identification problem. Consistent with\nprior art, these are randomized algorithms. As a function of failure\nprobability~$\\beta$, the former achieves optimal worst-case estimation error\nfor every~$\\beta$, while the latter is optimal when~$\\beta$ is at least inverse\npolynomial in~$n$, the number of users. In both algorithms, server running time\nis~$\\tilde{O}(n)$ while user running time is~$\\tilde{O}(1)$. Our\nfrequency-oracle algorithm achieves lower estimation error than the prior works\nof Bassily et al. (NeurIPS 2017). On the other hand, our heavy hitters\nidentification method is as easily implementable as as TreeHist (Bassily et\nal., 2017) and has superior worst-case error, by a factor of $\\Omega(\\sqrt{\\log\nn})$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:22:58 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wu", "Hao", ""], ["Wirth", "Anthony", ""]]}, {"id": "2106.07880", "submitter": "Insu Han", "authors": "Amir Zandieh, Insu Han, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo\n  Shin", "title": "Scaling Neural Tangent Kernels via Sketching and Random Features", "comments": "This is a merger of arXiv:2104.01351, arXiv:2104.00415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely-wide\nneural networks trained under least squares loss by gradient descent. Recent\nworks also report that NTK regression can outperform finitely-wide neural\nnetworks trained on small-scale datasets. However, the computational complexity\nof kernel methods has limited its use in large-scale learning tasks. To\naccelerate learning with NTK, we design a near input-sparsity time\napproximation algorithm for NTK, by sketching the polynomial expansions of\narc-cosine kernels: our sketch for the convolutional counterpart of NTK (CNTK)\ncan transform any image using a linear runtime in the number of pixels.\nFurthermore, we prove a spectral approximation guarantee for the NTK matrix, by\ncombining random features (based on leverage score sampling) of the arc-cosine\nkernels with a sketching algorithm. We benchmark our methods on various\nlarge-scale regression and classification tasks and show that a linear\nregressor trained on our CNTK features matches the accuracy of exact CNTK on\nCIFAR-10 dataset while achieving 150x speedup.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 04:44:52 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zandieh", "Amir", ""], ["Han", "Insu", ""], ["Avron", "Haim", ""], ["Shoham", "Neta", ""], ["Kim", "Chaewon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2106.08003", "submitter": "Michael Bekos", "authors": "Michael A. Bekos, Martin Gronemann, Chrysanthi N. Raftopoulou", "title": "On the Queue Number of Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A k-queue layout is a special type of a linear layout, in which the linear\norder avoids (k+1)-rainbows, i.e., k+1 independent edges that pairwise form a\nnested pair. The optimization goal is to determine the queue number of a graph,\ni.e., the minimum value of k for which a k-queue layout is feasible. Recently,\nDujmovi\\'c et al. [J. ACM, 67(4), 22:1-38, 2020] showed that the queue number\nof planar graphs is at most 49, thus settling in the positive a long-standing\nconjecture by Heath, Leighton and Rosenberg. To achieve this breakthrough\nresult, their approach involves three different techniques: (i) an algorithm to\nobtain straight-line drawings of outerplanar graphs, in which the y-distance of\nany two adjacent vertices is 1 or 2, (ii) an algorithm to obtain 5-queue\nlayouts of planar 3-trees, and (iii) a decomposition of a planar graph into\nso-called tripods. In this work, we push further each of these techniques to\nobtain the first non-trivial improvement on the upper bound from 49 to 42.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 09:35:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bekos", "Michael A.", ""], ["Gronemann", "Martin", ""], ["Raftopoulou", "Chrysanthi N.", ""]]}, {"id": "2106.08119", "submitter": "Alexander Barvinok", "authors": "Alexander Barvinok", "title": "When the positive semidefinite relaxation guarantees a solution to a\n  system of real quadratic equations", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS math.AG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By solving a positive semidefinite program, one can reduce a system of real\nquadratic equations to a system of the type $q_i(x)=\\alpha_i$, $i=1, \\ldots,\nm$, where $q_i: {\\Bbb R}^n \\longrightarrow {\\Bbb R}$ are quadratic forms and\n$\\alpha_i=\\operatorname{trace} q_i$. We prove a sufficient condition for the\nlatter system to have a solution $x \\in {\\Bbb R}^n$: assuming that the operator\nnorms of the $n \\times n$ matrices $Q_i$ of $q_i$ do not exceed 1, the smallest\neigenvalue the $m \\times m$ matrix with the $(i,j)$-th entry equal\n$\\operatorname{tr} (Q_i Q_j)$ is at least $\\gamma n^{2/3} m^2 \\ln n$ for an\nabsolute constant $\\gamma >0$. In particular, this happens when $n \\gg m^6$ and\nthe forms $q_i$ are sufficiently generic. We prove a similar sufficient\ncondition for a homogeneous system of quadratic equations to have a non-trivial\nsolution.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 13:28:37 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Barvinok", "Alexander", ""]]}, {"id": "2106.08195", "submitter": "Karl Bringmann", "authors": "Karl Bringmann, Vincent Cohen-Addad, and Debarati Das", "title": "A Linear-Time $n^{0.4}$-Approximation for Longest Common Subsequence", "comments": "full version of ICALP'21 paper, abstract shortened to fit Arxiv\n  requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic problem of computing the Longest Common Subsequence\n(LCS) of two strings of length $n$. While a simple quadratic algorithm has been\nknown for the problem for more than 40 years, no faster algorithm has been\nfound despite an extensive effort. The lack of progress on the problem has\nrecently been explained by Abboud, Backurs, and Vassilevska Williams [FOCS'15]\nand Bringmann and K\\\"unnemann [FOCS'15] who proved that there is no\nsubquadratic algorithm unless the Strong Exponential Time Hypothesis fails.\nThis has led the community to look for subquadratic approximation algorithms\nfor the problem.\n  Yet, unlike the edit distance problem for which a constant-factor\napproximation in almost-linear time is known, very little progress has been\nmade on LCS, making it a notoriously difficult problem also in the realm of\napproximation. For the general setting, only a naive\n$O(n^{\\varepsilon/2})$-approximation algorithm with running time\n$\\tilde{O}(n^{2-\\varepsilon})$ has been known, for any constant $0 <\n\\varepsilon \\le 1$. Recently, a breakthrough result by Hajiaghayi, Seddighin,\nSeddighin, and Sun [SODA'19] provided a linear-time algorithm that yields a\n$O(n^{0.497956})$-approximation in expectation; improving upon the naive\n$O(\\sqrt{n})$-approximation for the first time.\n  In this paper, we provide an algorithm that in time $O(n^{2-\\varepsilon})$\ncomputes an $\\tilde{O}(n^{2\\varepsilon/5})$-approximation with high\nprobability, for any $0 < \\varepsilon \\le 1$. Our result (1) gives an\n$\\tilde{O}(n^{0.4})$-approximation in linear time, improving upon the bound of\nHajiaghayi, Seddighin, Seddighin, and Sun, (2) provides an algorithm whose\napproximation scales with any subquadratic running time $O(n^{2-\\varepsilon})$,\nimproving upon the naive bound of $O(n^{\\varepsilon/2})$ for any $\\varepsilon$,\nand (3) instead of only in expectation, succeeds with high probability.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:49:52 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bringmann", "Karl", ""], ["Cohen-Addad", "Vincent", ""], ["Das", "Debarati", ""]]}, {"id": "2106.08393", "submitter": "Elchanan Mossel", "authors": "Ankur Moitra and Elchanan Mossel and Colin Sandon", "title": "Spoofing Generalization: When Can't You Trust Proprietary Models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study the computational complexity of determining whether a\nmachine learning model that perfectly fits the training data will generalizes\nto unseen data. In particular, we study the power of a malicious agent whose\ngoal is to construct a model g that fits its training data and nothing else,\nbut is indistinguishable from an accurate model f. We say that g strongly\nspoofs f if no polynomial-time algorithm can tell them apart. If instead we\nrestrict to algorithms that run in $n^c$ time for some fixed $c$, we say that g\nc-weakly spoofs f. Our main results are\n  1. Under cryptographic assumptions, strong spoofing is possible and 2. For\nany c> 0, c-weak spoofing is possible unconditionally\n  While the assumption of a malicious agent is an extreme scenario (hopefully\ncompanies training large models are not malicious), we believe that it sheds\nlight on the inherent difficulties of blindly trusting large proprietary models\nor data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 19:46:53 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Moitra", "Ankur", ""], ["Mossel", "Elchanan", ""], ["Sandon", "Colin", ""]]}, {"id": "2106.08396", "submitter": "Shyam Narayanan", "authors": "Talya Eden, Piotr Indyk, Shyam Narayanan, Ronitt Rubinfeld, Sandeep\n  Silwal, Tal Wagner", "title": "Learning-based Support Estimation in Sublinear Time", "comments": "17 pages. Published as a conference paper in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the number of distinct elements in a\nlarge data set (or, equivalently, the support size of the distribution induced\nby the data set) from a random sample of its elements. The problem occurs in\nmany applications, including biology, genomics, computer systems and\nlinguistics. A line of research spanning the last decade resulted in algorithms\nthat estimate the support up to $ \\pm \\varepsilon n$ from a sample of size\n$O(\\log^2(1/\\varepsilon) \\cdot n/\\log n)$, where $n$ is the data set size.\nUnfortunately, this bound is known to be tight, limiting further improvements\nto the complexity of this problem. In this paper we consider estimation\nalgorithms augmented with a machine-learning-based predictor that, given any\nelement, returns an estimation of its frequency. We show that if the predictor\nis correct up to a constant approximation factor, then the sample complexity\ncan be reduced significantly, to \\[ \\ \\log (1/\\varepsilon) \\cdot\nn^{1-\\Theta(1/\\log(1/\\varepsilon))}. \\] We evaluate the proposed algorithms on\na collection of data sets, using the neural-network based estimators from {Hsu\net al, ICLR'19} as predictors. Our experiments demonstrate substantial (up to\n3x) improvements in the estimation accuracy compared to the state of the art\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 19:53:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Eden", "Talya", ""], ["Indyk", "Piotr", ""], ["Narayanan", "Shyam", ""], ["Rubinfeld", "Ronitt", ""], ["Silwal", "Sandeep", ""], ["Wagner", "Tal", ""]]}, {"id": "2106.08448", "submitter": "Jakub Tarnawski", "authors": "Vincent Cohen-Addad, Silvio Lattanzi, Slobodan Mitrovi\\'c, Ashkan\n  Norouzi-Fard, Nikos Parotsidis, Jakub Tarnawski", "title": "Correlation Clustering in Constant Many Parallel Rounds", "comments": "ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Correlation clustering is a central topic in unsupervised learning, with many\napplications in ML and data mining. In correlation clustering, one receives as\ninput a signed graph and the goal is to partition it to minimize the number of\ndisagreements. In this work we propose a massively parallel computation (MPC)\nalgorithm for this problem that is considerably faster than prior work. In\nparticular, our algorithm uses machines with memory sublinear in the number of\nnodes in the graph and returns a constant approximation while running only for\na constant number of rounds. To the best of our knowledge, our algorithm is the\nfirst that can provably approximate a clustering problem on graphs using only a\nconstant number of MPC rounds in the sublinear memory regime. We complement our\nanalysis with an experimental analysis of our techniques.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:45:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Lattanzi", "Silvio", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Norouzi-Fard", "Ashkan", ""], ["Parotsidis", "Nikos", ""], ["Tarnawski", "Jakub", ""]]}, {"id": "2106.08537", "submitter": "Kevin Tian", "authors": "Ilias Diakonikolas, Daniel M. Kane, Daniel Kongsgaard, Jerry Li, Kevin\n  Tian", "title": "Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean\n  Estimation", "comments": "64 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of list-decodable mean estimation, where an adversary\ncan corrupt a majority of the dataset. Specifically, we are given a set $T$ of\n$n$ points in $\\mathbb{R}^d$ and a parameter $0< \\alpha <\\frac 1 2$ such that\nan $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a\nwell-behaved distribution $\\mathcal{D}$ and the remaining $(1-\\alpha)$-fraction\nof the points are arbitrary. The goal is to output a small list of vectors at\nleast one of which is close to the mean of $\\mathcal{D}$. As our main\ncontribution, we develop new algorithms for list-decodable mean estimation,\nachieving nearly-optimal statistical guarantees, with running time $n^{1 +\no(1)} d$. All prior algorithms for this problem had additional polynomial\nfactors in $\\frac 1 \\alpha$. As a corollary, we obtain the first almost-linear\ntime algorithms for clustering mixtures of $k$ separated well-behaved\ndistributions, nearly-matching the statistical guarantees of spectral methods.\nPrior clustering algorithms inherently relied on an application of $k$-PCA,\nthereby incurring runtimes of $\\Omega(n d k)$. This marks the first runtime\nimprovement for this basic statistical problem in nearly two decades.\n  The starting point of our approach is a novel and simpler near-linear time\nrobust mean estimation algorithm in the $\\alpha \\to 1$ regime, based on a\none-shot matrix multiplicative weights-inspired potential decrease. We\ncrucially leverage this new algorithmic framework in the context of the\niterative multi-filtering technique of Diakonikolas et. al. '18, '20, providing\na method to simultaneously cluster and downsample points using one-dimensional\nprojections -- thus, bypassing the $k$-PCA subroutines required by prior\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 03:34:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kongsgaard", "Daniel", ""], ["Li", "Jerry", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.08652", "submitter": "Francesco Bonchi", "authors": "David Garcia-Soriano and Francesco Bonchi", "title": "Maxmin-Fair Ranking: Individual Fairness under Group-Fairness\n  Constraints", "comments": "In proceedings of KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel problem of fairness in ranking aimed at minimizing the\namount of individual unfairness introduced when enforcing group-fairness\nconstraints. Our proposal is rooted in the distributional maxmin fairness\ntheory, which uses randomization to maximize the expected satisfaction of the\nworst-off individuals. We devise an exact polynomial-time algorithm to find\nmaxmin-fair distributions of general search problems (including, but not\nlimited to, ranking), and show that our algorithm can produce rankings which,\nwhile satisfying the given group-fairness constraints, ensure that the maximum\npossible value is brought to individuals.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 09:27:12 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:10:05 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Garcia-Soriano", "David", ""], ["Bonchi", "Francesco", ""]]}, {"id": "2106.08696", "submitter": "Lars Gottesb\\\"uren", "authors": "Sebastian Schlag, Tobias Heuer, Lars Gottesb\\\"uren, Yaroslav\n  Akhremtsev, Christian Schulz, Peter Sanders", "title": "High-Quality Hypergraph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the balanced hypergraph partitioning problem, which asks\nfor partitioning the vertices into $k$ disjoint blocks of bounded size while\nminimizing an objective function over the hyperedges. Here, we consider the\nmost commonly used connectivity metric. We describe our open source hypergraph\npartitioner KaHyPar which is based on the successful multi-level approach --\ndriving it to the extreme of one level for (almost) every vertex. Using\ncarefully designed data structures and dynamic update techniques, this approach\noffers a very good time-quality tradeoff. We present two preprocessing\ntechniques -- pin sparsification using locality sensitive hashing and community\ndetection based on the Louvain algorithm. The community structure is used to\nguide the coarsening process that incrementally contracts vertices.\nPortfolio-based partitioning of the contracted hypergraph already achieves good\ninitial solutions. While reversing the contractions, a combination of\nhighly-localized direct $k$-way local search and flow-based techniques that\ntake a more global view, refine the partition to achieve high quality.\nOptionally, a memetic algorithm evolves a pool of solution candidates to obtain\neven higher quality.\n  We evaluate KaHyPar on a large set of instances from a wide range of\napplication domains. With respect to quality, KaHyPar outperforms all\npreviously considered systems that can handle large hypergraphs such as hMETIS,\nPaToH, Mondriaan, or Zoltan. KaHyPar is also faster than most of these systems\nexcept for PaToH which represents a different speed-quality tradeoff. The\nresults even extend to the special case of graph partitioning, where\nspecialized systems such as KaHIP should have an advantage.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 11:01:16 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Schlag", "Sebastian", ""], ["Heuer", "Tobias", ""], ["Gottesb\u00fcren", "Lars", ""], ["Akhremtsev", "Yaroslav", ""], ["Schulz", "Christian", ""], ["Sanders", "Peter", ""]]}, {"id": "2106.09207", "submitter": "Dhruv Rohatgi", "authors": "Jonathan Kelner, Frederic Koehler, Raghu Meka, Dhruv Rohatgi", "title": "On the Power of Preconditioning in Sparse Linear Regression", "comments": "73 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression is a fundamental problem in high-dimensional\nstatistics, but strikingly little is known about how to efficiently solve it\nwithout restrictive conditions on the design matrix. We consider the\n(correlated) random design setting, where the covariates are independently\ndrawn from a multivariate Gaussian $N(0,\\Sigma)$ with $\\Sigma : n \\times n$,\nand seek estimators $\\hat{w}$ minimizing $(\\hat{w}-w^*)^T\\Sigma(\\hat{w}-w^*)$,\nwhere $w^*$ is the $k$-sparse ground truth. Information theoretically, one can\nachieve strong error bounds with $O(k \\log n)$ samples for arbitrary $\\Sigma$\nand $w^*$; however, no efficient algorithms are known to match these guarantees\neven with $o(n)$ samples, without further assumptions on $\\Sigma$ or $w^*$. As\nfar as hardness, computational lower bounds are only known with worst-case\ndesign matrices. Random-design instances are known which are hard for the\nLasso, but these instances can generally be solved by Lasso after a simple\nchange-of-basis (i.e. preconditioning).\n  In this work, we give upper and lower bounds clarifying the power of\npreconditioning in sparse linear regression. First, we show that the\npreconditioned Lasso can solve a large class of sparse linear regression\nproblems nearly optimally: it succeeds whenever the dependency structure of the\ncovariates, in the sense of the Markov property, has low treewidth -- even if\n$\\Sigma$ is highly ill-conditioned. Second, we construct (for the first time)\nrandom-design instances which are provably hard for an optimally preconditioned\nLasso. In fact, we complete our treewidth classification by proving that for\nany treewidth-$t$ graph, there exists a Gaussian Markov Random Field on this\ngraph such that the preconditioned Lasso, with any choice of preconditioner,\nrequires $\\Omega(t^{1/20})$ samples to recover $O(\\log n)$-sparse signals when\ncovariates are drawn from this model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 02:12:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kelner", "Jonathan", ""], ["Koehler", "Frederic", ""], ["Meka", "Raghu", ""], ["Rohatgi", "Dhruv", ""]]}, {"id": "2106.09350", "submitter": "Yuhao Wang", "authors": "Yuhao Wang, Arnab Bhattacharyya", "title": "Identifiability of AMP chain graph models", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study identifiability of Andersson-Madigan-Perlman (AMP) chain graph\nmodels, which are a common generalization of linear structural equation models\nand Gaussian graphical models. AMP models are described by DAGs on chain\ncomponents which themselves are undirected graphs.\n  For a known chain component decomposition, we show that the DAG on the chain\ncomponents is identifiable if the determinants of the residual covariance\nmatrices of the chain components are monotone non-decreasing in topological\norder. This condition extends the equal variance identifiability criterion for\nBayes nets, and it can be generalized from determinants to any super-additive\nfunction on positive semidefinite matrices. When the component decomposition is\nunknown, we describe conditions that allow recovery of the full structure using\na polynomial time algorithm based on submodular function minimization. We also\nconduct experiments comparing our algorithm's performance against existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:09:30 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Yuhao", ""], ["Bhattacharyya", "Arnab", ""]]}, {"id": "2106.09363", "submitter": "Johannes Bulin", "authors": "Johannes Bulin and Jan Hamaekers", "title": "Similarity of particle systems using an invariant root mean square\n  deviation measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether two particle systems are similar is a common problem in\nparticle simulations. When the comparison should be invariant under\npermutations, orthogonal transformations, and translations of the systems,\nspecial techniques are needed. We present an algorithm that can test particle\nsystems of finite size for similarity and, if they are similar, can find the\noptimal alignment between them. Our approach is based on an invariant version\nof the root mean square deviation (RMSD) measure and is capable of finding the\nglobally optimal solution in $O(n^3)$ operations where $n$ is the number of\nthree-dimensional particles.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:30:27 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bulin", "Johannes", ""], ["Hamaekers", "Jan", ""]]}, {"id": "2106.09481", "submitter": "Yair Carmon", "authors": "Hilal Asi, Yair Carmon, Arun Jambulapati, Yujia Jin and Aaron Sidford", "title": "Stochastic Bias-Reduced Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new primitive for stochastic optimization: a low-bias, low-cost\nestimator of the minimizer $x_\\star$ of any Lipschitz strongly-convex function.\nIn particular, we use a multilevel Monte-Carlo approach due to Blanchet and\nGlynn to turn any optimal stochastic gradient method into an estimator of\n$x_\\star$ with bias $\\delta$, variance $O(\\log(1/\\delta))$, and an expected\nsampling cost of $O(\\log(1/\\delta))$ stochastic gradient evaluations. As an\nimmediate consequence, we obtain cheap and nearly unbiased gradient estimators\nfor the Moreau-Yoshida envelope of any Lipschitz convex function, allowing us\nto perform dimension-free randomized smoothing.\n  We demonstrate the potential of our estimator through four applications.\nFirst, we develop a method for minimizing the maximum of $N$ functions,\nimproving on recent results and matching a lower bound up logarithmic factors.\nSecond and third, we recover state-of-the-art rates for projection-efficient\nand gradient-efficient optimization using simple algorithms with a transparent\nanalysis. Finally, we show that an improved version of our estimator would\nyield a nearly linear-time, optimal-utility, differentially-private non-smooth\nstochastic optimization method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:33:05 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Asi", "Hilal", ""], ["Carmon", "Yair", ""], ["Jambulapati", "Arun", ""], ["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2106.09663", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "A Short Note of PAGE: Optimal Convergence Rates for Nonconvex\n  Optimization", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we first recall the nonconvex problem setting and introduce the\noptimal PAGE algorithm (Li et al., ICML'21). Then we provide a simple and clean\nconvergence analysis of PAGE for achieving optimal convergence rates. Moreover,\nPAGE and its analysis can be easily adopted and generalized to other works. We\nhope that this note provides the insights and is helpful for future works.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:11:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "2106.09689", "submitter": "Ankit Pensia", "authors": "Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia, Thanasis Pittas,\n  Alistair Stewart", "title": "Statistical Query Lower Bounds for List-Decodable Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of list-decodable linear regression, where an adversary\ncan corrupt a majority of the examples. Specifically, we are given a set $T$ of\nlabeled examples $(x, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$ and a parameter\n$0< \\alpha <1/2$ such that an $\\alpha$-fraction of the points in $T$ are i.i.d.\nsamples from a linear regression model with Gaussian covariates, and the\nremaining $(1-\\alpha)$-fraction of the points are drawn from an arbitrary noise\ndistribution. The goal is to output a small list of hypothesis vectors such\nthat at least one of them is close to the target regression vector. Our main\nresult is a Statistical Query (SQ) lower bound of $d^{\\mathrm{poly}(1/\\alpha)}$\nfor this problem. Our SQ lower bound qualitatively matches the performance of\npreviously developed algorithms, providing evidence that current upper bounds\nfor this task are nearly best possible.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:45:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Pensia", "Ankit", ""], ["Pittas", "Thanasis", ""], ["Stewart", "Alistair", ""]]}, {"id": "2106.09805", "submitter": "Albert Cheu", "authors": "Albert Cheu and Matthew Joseph and Jieming Mao and Binghui Peng", "title": "Shuffle Private Stochastic Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In shuffle privacy, each user sends a collection of randomized messages to a\ntrusted shuffler, the shuffler randomly permutes these messages, and the\nresulting shuffled collection of messages must satisfy differential privacy.\nPrior work in this model has largely focused on protocols that use a single\nround of communication to compute algorithmic primitives like means,\nhistograms, and counts. In this work, we present interactive shuffle protocols\nfor stochastic convex optimization. Our optimization protocols rely on a new\nnoninteractive protocol for summing vectors of bounded $\\ell_2$ norm. By\ncombining this sum subroutine with techniques including mini-batch stochastic\ngradient descent, accelerated gradient descent, and Nesterov's smoothing\nmethod, we obtain loss guarantees for a variety of convex loss functions that\nsignificantly improve on those of the local model and sometimes match those of\nthe central model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:44:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Cheu", "Albert", ""], ["Joseph", "Matthew", ""], ["Mao", "Jieming", ""], ["Peng", "Binghui", ""]]}, {"id": "2106.09830", "submitter": "S\\'ilvia Casacuberta", "authors": "S\\'ilvia Casacuberta and Rasmus Kyng", "title": "Faster Sparse Matrix Inversion and Rank Computation in Finite Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the current best running time value to invert sparse matrices over\nfinite fields, lowering it to an expected $O\\big(n^{2.2131}\\big)$ time for the\ncurrent values of fast rectangular matrix multiplication. We achieve the same\nrunning time for the computation of the rank and nullspace of a sparse matrix\nover a finite field. This improvement relies on two key techniques. First, we\nadopt the decomposition of an arbitrary matrix into block Krylov and Hankel\nmatrices from Eberly et al. (ISSAC 2007). Second, we show how to recover the\nexplicit inverse of a block Hankel matrix using low displacement rank\ntechniques for structured matrices and fast rectangular matrix multiplication\nalgorithms. We generalize our inversion method to block structured matrices\nwith other displacement operators and strengthen the best known upper bounds\nfor explicit inversion of block Toeplitz-like and block Hankel-like matrices,\nas well as for explicit inversion of block Vandermonde-like matrices with\nstructured blocks. As a further application, we improve the complexity of\nseveral algorithms in topological data analysis and in finite group theory.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 22:01:46 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Casacuberta", "S\u00edlvia", ""], ["Kyng", "Rasmus", ""]]}, {"id": "2106.09917", "submitter": "Girija Limaye", "authors": "Girija Limaye", "title": "Envy-freeness and Relaxed Stability for Lower-Quotas: A Parameterized\n  Perspective", "comments": "19 pages, 2 figures. This submission essentially replaces the\n  following results from arXiv:1910.07159 - Theorem 4(I) MAXEFM result, Section\n  4.1 and 4.3 (Parameterized complexity). The consent of the remaining authors\n  of arXiv:1910.07159 is taken before making this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of assigning agents to resources in the two-sided\npreference model with upper and lower-quota requirements on resources. This\nsetting (known as the HRLQ setting) models real-world applications like\nassigning students to colleges or courses, resident doctors to hospitals and so\non. In presence of lower-quotas, an instance may not admit a stable matching\nthat fulfils the lower-quotas. Prem Krishnaa et al. [SAGT 2020] study two\nalternative notions of optimality for the HRLQ instances -- envy-freeness and\nrelaxed stability. They investigate the complexity of computing a maximum size\nenvy-free matching (MAXEFM) and a maximum size relaxed stable matching(MAXRSM)\nthat fulfils the lower-quotas. They show that both these optimization problems\nare NP-hard and not approximable within a constant factor unless P=NP.\n  In this work, we investigate the parameterized complexity of MAXEFM and\nMAXRSM. We consider natural parameters derived from the instance -- the number\nof lower-quota hospitals, deficiency of the instance, size of a maximum\nmatching, size of a stable matching, length of the preference list of a\nlower-quota hospital, to name a few. We show that MAXEFM problem is W[1]-hard\nfor several interesting parameters but admits a polynomial size kernel for a\ncombination of parameters. We show that MAXRSM problem does not admit an FPT\nalgorithm unless P=NP for two natural parameters but admits a polynomial size\nkernel for a combination of parameters in a special case. We also show that\nboth these problems admit FPT algorithms on a set of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:55:04 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Limaye", "Girija", ""]]}, {"id": "2106.09919", "submitter": "Adil Erzin I", "authors": "Adil Erzin, Georgii Melidi, Stepan Nazarenko, Roman Plotnikov", "title": "Approximation Algorithms for Two-Bar Charts Packing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the Two-Bar Charts Packing Problem (2-BCPP), it is required to pack the\nbar charts (BCs) consisting of two bars into the horizontal unit-height strip\nof minimal length. The bars may move vertically within the strip, but it is\nforbidden to change the order and separate the chart's bars. Recently, for this\nnew problem, which is a generalization of the Bin Packing Problem (BPP), Strip\nPacking Problem (SPP), and 2-Dimensional Vector Packing Problem (2-DVPP),\nseveral approximation algorithms with guaranteed estimates were proposed.\nHowever, after a preliminary analysis of the solutions constructed by\napproximation algorithms, we discerned that the guaranteed estimates are\ninaccurate. This fact inspired us to conduct a numerical experiment in which\nthe approximate solutions are compared to each other and with the optimal ones.\nTo construct the optimal solutions or lower bounds for optimum, we use the\nBoolean Linear Programming (BLP) formulation of 2-BCPP proposed earlier and\napply the CPLEX package. We also use a database of instances for BPP with known\noptimal solutions to construct the instances for the 2-BCPP with known minimal\npacking length. The results of the simulation make up the main content of this\npaper.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:58:11 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 04:33:33 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Erzin", "Adil", ""], ["Melidi", "Georgii", ""], ["Nazarenko", "Stepan", ""], ["Plotnikov", "Roman", ""]]}, {"id": "2106.10068", "submitter": "Christian Janos Lebeda", "authors": "Martin Aum\\\"uller, Christian Janos Lebeda, Rasmus Pagh", "title": "Differentially private sparse vectors with low error, optimal space, and\n  fast access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing a sparse histogram, or more generally a sparse vector, is a\nfundamental task in differential privacy. An ideal solution would use space\nclose to information-theoretical lower bounds, have an error distribution that\ndepends optimally on the desired privacy level, and allow fast random access to\nentries in the vector. However, existing approaches have only achieved two of\nthese three goals.\n  In this paper we introduce the Approximate Laplace Projection (ALP) mechanism\nfor approximating k-sparse vectors. This mechanism is shown to simultaneously\nhave information-theoretically optimal space (up to constant factors), fast\naccess to vector entries, and error of the same magnitude as the\nLaplace-mechanism applied to dense vectors. A key new technique is a unary\nrepresentation of small integers, which is shown to be robust against\n``randomized response'' noise. This representation is combined with hashing, in\nthe spirit of Bloom filters, to obtain a space-efficient, differentially\nprivate representation. Our theoretical performance bounds are complemented by\nsimulations which show that the constant factors on the main performance\nparameters are quite small, suggesting practicality of the technique.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:29:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Lebeda", "Christian Janos", ""], ["Pagh", "Rasmus", ""]]}, {"id": "2106.10201", "submitter": "David Doty", "authors": "David Doty, Mahsa Eftekhari, Leszek G\\k{a}sieniec, Eric Severson,\n  Grzegorz Stachowiak, Przemys{\\l}aw Uzna\\'nski", "title": "A time and space optimal stable population protocol solving exact\n  majority", "comments": "combined paper that replaces both arXiv:2012.15800 and\n  arXiv:2011.07392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study population protocols, a model of distributed computing appropriate\nfor modeling well-mixed chemical reaction networks and other physical systems\nwhere agents exchange information in pairwise interactions, but have no control\nover their schedule of interaction partners. The well-studied *majority*\nproblem is that of determining in an initial population of $n$ agents, each\nwith one of two opinions $A$ or $B$, whether there are more $A$, more $B$, or a\ntie. A *stable* protocol solves this problem with probability 1 by eventually\nentering a configuration in which all agents agree on a correct consensus\ndecision of $\\mathsf{A}$, $\\mathsf{B}$, or $\\mathsf{T}$, from which the\nconsensus cannot change. We describe a protocol that solves this problem using\n$O(\\log n)$ states ($\\log \\log n + O(1)$ bits of memory) and optimal expected\ntime $O(\\log n)$. The number of states $O(\\log n)$ is known to be optimal for\nthe class of polylogarithmic time stable protocols that are \"output dominant\"\nand \"monotone\". These are two natural constraints satisfied by our protocol,\nmaking it simultaneously time- and state-optimal for that class. We introduce a\nkey technique called a \"fixed resolution clock\" to achieve partial\nsynchronization.\n  Our protocol is *nonuniform*: the transition function has the value $\\left\n\\lceil {\\log n} \\right \\rceil$ encoded in it. We show that the protocol can be\nmodified to be uniform, while increasing the state complexity to $\\Theta(\\log n\n\\log \\log n)$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:21:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Doty", "David", ""], ["Eftekhari", "Mahsa", ""], ["G\u0105sieniec", "Leszek", ""], ["Severson", "Eric", ""], ["Stachowiak", "Grzegorz", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "2106.10321", "submitter": "David Wajc", "authors": "Mohammad Roghani, Amin Saberi and David Wajc", "title": "Beating the Folklore Algorithm for Dynamic Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The maximum matching problem in dynamic graphs subject to edge updates\n(insertions and deletions) has received much attention over the last few years;\na multitude of approximation/time tradeoffs were obtained, improving upon the\nfolklore algorithm, which maintains a maximal (and hence $2$-approximate)\nmatching in $O(n)$ worst-case update time in $n$-node graphs.\n  We present the first deterministic algorithm which outperforms the folklore\nalgorithm in terms of {\\em both} approximation ratio and worst-case update\ntime. Specifically, we give a $(2-\\Omega(1))$-approximate algorithm with\n$O(\\sqrt{n}\\sqrt[8]{m})=O(n^{3/4})$ worst-case update time in $n$-node,\n$m$-edge graphs. For sufficiently small constant $\\epsilon>0$, no deterministic\n$(2+\\epsilon)$-approximate algorithm with worst-case update time $O(n^{0.99})$\nwas known. Our second result is the first deterministic\n$(2+\\epsilon)$-approximate (weighted) matching algorithm with\n$O_\\epsilon(1)\\cdot O(\\sqrt[4]{m}) = O_\\epsilon(1)\\cdot O(\\sqrt{n})$ worst-case\nupdate time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:29:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Roghani", "Mohammad", ""], ["Saberi", "Amin", ""], ["Wajc", "David", ""]]}, {"id": "2106.10374", "submitter": "Pan Peng", "authors": "Pan Peng, Jiapeng Zhang", "title": "Towards a Query-Optimal and Time-Efficient Algorithm for Clustering with\n  a Faulty Oracle", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in crowdsourced entity resolution in database,\nsigned edge prediction in social networks and correlation clustering, Mazumdar\nand Saha [NIPS 2017] proposed an elegant theoretical model for studying\nclustering with a faulty oracle. In this model, given a set of $n$ items which\nbelong to $k$ unknown groups (or clusters), our goal is to recover the clusters\nby asking pairwise queries to an oracle. This oracle can answer the query that\n``do items $u$ and $v$ belong to the same cluster?''. However, the answer to\neach pairwise query errs with probability $\\varepsilon$, for some\n$\\varepsilon\\in(0,\\frac12)$. Mazumdar and Saha provided two algorithms under\nthis model: one algorithm is query-optimal while time-inefficient (i.e.,\nrunning in quasi-polynomial time), the other is time efficient (i.e., in\npolynomial time) while query-suboptimal. Larsen, Mitzenmacher and Tsourakakis\n[WWW 2020] then gave a new time-efficient algorithm for the special case of $2$\nclusters, which is query-optimal if the bias $\\delta:=1-2\\varepsilon$ of the\nmodel is large. It was left as an open question whether one can obtain a\nquery-optimal, time-efficient algorithm for the general case of $k$ clusters\nand other regimes of $\\delta$.\n  In this paper, we make progress on the above question and provide a\ntime-efficient algorithm with nearly-optimal query complexity (up to a factor\nof $O(\\log^2 n)$) for all constant $k$ and any $\\delta$ in the regime when\ninformation-theoretic recovery is possible. Our algorithm is built on a\nconnection to the stochastic block model.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:20:12 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Peng", "Pan", ""], ["Zhang", "Jiapeng", ""]]}, {"id": "2106.10386", "submitter": "Yu Chen", "authors": "Yu Chen, Sanjeev Khanna, Ansh Nagda", "title": "Sublinear Time Hypergraph Sparsification via Cut and Edge Sampling\n  Queries", "comments": "ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of sparsifying a graph or a hypergraph while approximately\npreserving its cut structure has been extensively studied and has many\napplications. In a seminal work, Bencz\\'ur and Karger (1996) showed that given\nany $n$-vertex undirected weighted graph $G$ and a parameter $\\varepsilon \\in\n(0,1)$, there is a near-linear time algorithm that outputs a weighted subgraph\n$G'$ of $G$ of size $\\tilde{O}(n/\\varepsilon^2)$ such that the weight of every\ncut in $G$ is preserved to within a $(1 \\pm \\varepsilon)$-factor in $G'$. The\ngraph $G'$ is referred to as a {\\em $(1 \\pm \\varepsilon)$-approximate cut\nsparsifier} of $G$. Subsequent recent work has obtained a similar result for\nthe more general problem of hypergraph cut sparsifiers. However, all known\nsparsification algorithms require $\\Omega(n + m)$ time where $n$ denotes the\nnumber of vertices and $m$ denotes the number of hyperedges in the hypergraph.\nSince $m$ can be exponentially large in $n$, a natural question is if it is\npossible to create a hypergraph cut sparsifier in time polynomial in $n$, {\\em\nindependent of the number of edges}. We resolve this question in the\naffirmative, giving the first sublinear time algorithm for this problem, given\nappropriate query access to the hypergraph.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 23:25:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Yu", ""], ["Khanna", "Sanjeev", ""], ["Nagda", "Ansh", ""]]}, {"id": "2106.10541", "submitter": "Marie-Pierre B\\'eal", "authors": "Marie-Pierre B\\'eal and Maxime Crochemore", "title": "Checking whether a word is Hamming-isometric in linear time", "comments": "A second algorithm for checking whether a word is Hamming-isometric\n  is added using the result given in reference [5]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A finite word $f$ is Hamming-isometric if for any two word $u$ and $v$ of\nsame length avoiding $f$, $u$ can be transformed into $v$ by changing one by\none all the letters on which $u$ differs from $v$, in such a way that all of\nthe new words obtained in this process also avoid~$f$. Words which are not\nHamming-isometric have been characterized as words having a border with two\nmismatches. We derive from this characterization a linear-time algorithm to\ncheck whether a word is Hamming-isometric. It is based on pattern matching\nalgorithms with $k$ mismatches. Lee-isometric words over a four-letter alphabet\nhave been characterized as words having a border with two Lee-errors. We derive\nfrom this characterization a linear-time algorithm to check whether a word over\nan alphabet of size four is Lee-isometric.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 17:41:30 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 09:36:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["B\u00e9al", "Marie-Pierre", ""], ["Crochemore", "Maxime", ""]]}, {"id": "2106.10659", "submitter": "Sajjad Ghobadi Babi", "authors": "Mansoor Davoodi, Esmaeil Delfaraz, Sajjad Ghobadi, and Mahtab Masoori", "title": "Hole Detection and Healing in Hybrid Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although monitoring and covering are fundamental goals of a wireless sensor\nnetwork (WSN), the accidental death of sensors or the running out of their\nenergy would result in holes in the WSN. Such holes have the potential to\ndisrupt the primary functions of WSNs. This paper investigates the hole\ndetection and healing problems in hybrid WSNs with non-identical sensor sensing\nranges. In particular, we aim to propose centralized algorithms for detecting\nholes in a given region and maximizing the area covered by a WSN in the\npresence of environmental obstacles. To precisely identify the boundary of the\nholes, we use an additively weighted Voronoi diagram and a polynomial-time\nalgorithm.Furthermore, since this problem is known to be computationally\ndifficult, we propose a centralized greedy 1/2-approximation algorithm to\nmaximize the area covered by sensors. Finally, we implement the algorithms and\nrun simulations to show that our approximation algorithm efficiently covers the\nholes by moving the mobile sensors.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 09:10:38 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Davoodi", "Mansoor", ""], ["Delfaraz", "Esmaeil", ""], ["Ghobadi", "Sajjad", ""], ["Masoori", "Mahtab", ""]]}, {"id": "2106.10971", "submitter": "David Naccache", "authors": "\\'Eric Brier and Megi Dervishi and R\\'emi G\\'eraud-Stewart and David\n  Naccache and Ofer Yifrach-Stav", "title": "Near-Optimal Pool Testing under Urgency Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of rare traits or diseases in a large population is challenging.\nPool testing allows covering larger swathes of population at a reduced cost,\nwhile simplifying logistics. However, testing precision decreases as it becomes\nunclear which member of a pool made the global test positive.\n  In this paper we discuss testing strategies that provably approach\nbest-possible strategy - optimal in the sense that no other strategy can give\nexact results with fewer tests. Our algorithms guarantee that they provide a\ncomplete and exact result for every individual, without exceeding $1/0.99$\ntimes the number of tests the optimal strategy would require.\n  This threshold is arbitrary: algorithms closer to the optimal bound can be\ndescribed, however their complexity increases, making them less practical.\n  Moreover, the way the algorithms process input samples leads to some\nindividuals' status to be known sooner, thus allowing to take urgency into\naccount when assigning individuals to tests.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 10:46:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Brier", "\u00c9ric", ""], ["Dervishi", "Megi", ""], ["G\u00e9raud-Stewart", "R\u00e9mi", ""], ["Naccache", "David", ""], ["Yifrach-Stav", "Ofer", ""]]}, {"id": "2106.11092", "submitter": "Jittat Fakcharoenphol", "authors": "Jittat Fakcharoenphol, Nonthaphat Wongwattanakij", "title": "A PTAS for $k$-hop MST on the Euclidean plane: Improving Dependency on\n  $k$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any $\\epsilon>0$, Laue and Matijevi\\'{c} [CCCG'07, IPL'08] give a PTAS\nfor finding a $(1+\\epsilon)$-approximate solution to the $k$-hop MST problem in\nthe Euclidean plane that runs in time $(n/\\epsilon)^{O(k/\\epsilon)}$. In this\npaper, we present an algorithm that runs in time $(n/\\epsilon)^{O(\\log k\n\\cdot(1/\\epsilon)^2\\cdot\\log^2(1/\\epsilon))}$. This gives an improvement on the\ndependency on $k$ on the exponent, while having a worse dependency on\n$\\epsilon$. As in Laue and Matijevi\\'{c}, we follow the framework introduced by\nArora for Euclidean TSP. Our key ingredients include exponential distance\nscaling and compression of dynamic programming state tables.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:20:23 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fakcharoenphol", "Jittat", ""], ["Wongwattanakij", "Nonthaphat", ""]]}, {"id": "2106.11191", "submitter": "Massimiliano Rossi", "authors": "Christina Boucher and Davide Cenzato and Zsuzsanna Lipt\\'ak and\n  Massimiliano Rossi and Marinella Sciortino", "title": "Computing the original eBWT faster, simpler, and with less memory", "comments": "20 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mantaci et al. [TCS 2007] defined the eBWT to extend the definition of the\nBWT to a collection of strings, however, since this introduction, it has been\nused more generally to describe any BWT of a collection of strings and the\nfundamental property of the original definition (i.e., the independence from\nthe input order) is frequently disregarded. In this paper, we propose a simple\nlinear-time algorithm for the construction of the original eBWT, which does not\nrequire the preprocessing of Bannai et al. [CPM 2021]. As a byproduct, we\nobtain the first linear-time algorithm for computing the BWT of a single string\nthat uses neither an end-of-string symbol nor Lyndon rotations. We combine our\nnew eBWT construction with a variation of prefix-free parsing to allow for\nscalable construction of the eBWT. We evaluate our algorithm (pfpebwt) on sets\nof human chromosomes 19, Salmonella, and SARS-CoV2 genomes, and demonstrate\nthat it is the fastest method for all collections, with a maximum speedup of\n7.6x on the second best method. The peak memory is at most 2x larger than the\nsecond best method. Comparing with methods that are also, as our algorithm,\nable to report suffix array samples, we obtain a 57.1x improvement in peak\nmemory. The source code is publicly available at\nhttps://github.com/davidecenzato/PFP-eBWT.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:29:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Boucher", "Christina", ""], ["Cenzato", "Davide", ""], ["Lipt\u00e1k", "Zsuzsanna", ""], ["Rossi", "Massimiliano", ""], ["Sciortino", "Marinella", ""]]}, {"id": "2106.11372", "submitter": "Sapna Grover", "authors": "Sapna Grover, Neelima Gupta and Rajni Dabas", "title": "First Approximation for Uniform Lower and Upper Bounded Facility\n  Location Problem avoiding violation in Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing emphasis on e-commerce marketplace platforms where we have a\ncentral platform mediating between the seller and the buyer, it becomes\nimportant to keep a check on the availability and profitability of the central\nstore. A store serving too less clients can be non-profitable and a store\ngetting too many orders can lead to bad service to the customers which can be\ndetrimental for the business. In this paper, we study the facility location\nproblem(FL) with upper and lower bounds on the number of clients an open\nfacility serves. Constant factor approximations are known for the restricted\nvariants of the problem with only the upper bounds or only the lower bounds.\nThe only work that deals with bounds on both the sides violates both the bounds\n[8]. In this paper, we present the first (constant factor) approximation for\nthe problem violating the upper bound by a factor of (5/2) without violating\nthe lower bounds when both the lower and the upper bounds are uniform. We first\ngive a tri-criteria (constant factor) approximation violating both the upper\nand the lower bounds and then get rid of violation in lower bounds by\ntransforming the problem instance to an instance of capacitated facility\nlocation problem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:12:01 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 09:21:52 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 17:22:39 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Grover", "Sapna", ""], ["Gupta", "Neelima", ""], ["Dabas", "Rajni", ""]]}, {"id": "2106.11426", "submitter": "Zichang Liu", "authors": "Zichang Liu, Benjamin Coleman, Anshumali Shrivastava", "title": "Efficient Inference via Universal LSH Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large machine learning models achieve unprecedented performance on various\ntasks and have evolved as the go-to technique. However, deploying these compute\nand memory hungry models on resource constraint environments poses new\nchallenges. In this work, we propose mathematically provable Representer\nSketch, a concise set of count arrays that can approximate the inference\nprocedure with simple hashing computations and aggregations. Representer Sketch\nbuilds upon the popular Representer Theorem from kernel literature, hence the\nname, providing a generic fundamental alternative to the problem of efficient\ninference that goes beyond the popular approach such as quantization, iterative\npruning and knowledge distillation. A neural network function is transformed to\nits weighted kernel density representation, which can be very efficiently\nestimated with our sketching algorithm. Empirically, we show that Representer\nSketch achieves up to 114x reduction in storage requirement and 59x reduction\nin computation complexity without any drop in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 22:06:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Liu", "Zichang", ""], ["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2106.11565", "submitter": "Benjamin Coleman", "authors": "Joshua Engels, Benjamin Coleman, Anshumali Shrivastava", "title": "Practical Near Neighbor Search via Group Testing", "comments": "For source code see https://github.com/JoshuaEng/FLINNG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the approximate near neighbor problem that\ncombines classical ideas from group testing with locality-sensitive hashing\n(LSH). We reduce the near neighbor search problem to a group testing problem by\ndesignating neighbors as \"positives,\" non-neighbors as \"negatives,\" and\napproximate membership queries as group tests. We instantiate this framework\nusing distance-sensitive Bloom Filters to Identify Near-Neighbor Groups\n(FLINNG). We prove that FLINNG has sub-linear query time and show that our\nalgorithm comes with a variety of practical advantages. For example, FLINNG can\nbe constructed in a single pass through the data, consists entirely of\nefficient integer operations, and does not require any distance computations.\nWe conduct large-scale experiments on high-dimensional search tasks such as\ngenome search, URL similarity search, and embedding search over the massive\nYFCC100M dataset. In our comparison with leading algorithms such as HNSW and\nFAISS, we find that FLINNG can provide up to a 10x query speedup with\nsubstantially smaller indexing time and memory.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 06:48:59 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Engels", "Joshua", ""], ["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2106.11675", "submitter": "Huib Donkers", "authors": "Huib Donkers and Bart M.P. Jansen", "title": "Preprocessing to Reduce the Search Space: Antler Structures for Feedback\n  Vertex Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to open up a new research direction aimed at\nunderstanding the power of preprocessing in speeding up algorithms that solve\nNP-hard problems exactly. We explore this direction for the classic Feedback\nVertex Set problem on undirected graphs, leading to a new type of graph\nstructure called antler decomposition, which identifies vertices that belong to\nan optimal solution. It is an analogue of the celebrated crown decomposition\nwhich has been used for Vertex Cover. We develop the graph structure theory\naround such decompositions and develop fixed-parameter tractable algorithms to\nfind them, parameterized by the number of vertices for which they witness\npresence in an optimal solution. This reduces the search space of\nfixed-parameter tractable algorithms parameterized by the solution size that\nsolve Feedback Vertex Set.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:17:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Donkers", "Huib", ""], ["Jansen", "Bart M. P.", ""]]}, {"id": "2106.11689", "submitter": "Celine Swennenhuis", "authors": "Isja Mannens, Jesper Nederlof, C\\'eline Swennenhuis and Krisztina\n  Szil\\'agyi", "title": "On the Parameterized Complexity of the Connected Flow and Many Visits\n  TSP Problem", "comments": "To be included in the proceedings of the 'International Workshop on\n  Graph-Theoretic Concepts in Computer Science' (WG2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of Min Cost Flow in which the flow needs to be connected.\nSpecifically, in the Connected Flow problem one is given a directed graph $G$,\nalong with a set of demand vertices $D \\subseteq V(G)$ with demands\n$\\mathsf{dem}: D \\rightarrow \\mathbb{N}$, and costs and capacities for each\nedge. The goal is to find a minimum cost flow that satisfies the demands,\nrespects the capacities and induces a (strongly) connected subgraph. This\ngeneralizes previously studied problems like the (Many Visits) TSP.\n  We study the parameterized complexity of Connected Flow parameterized by\n$|D|$, the treewidth $tw$ and by vertex cover size $k$ of $G$ and provide:\n  (i) $\\mathsf{NP}$-completeness already for the case $|D|=2$ with only unit\ndemands and capacities and no edge costs, and fixed-parameter tractability if\nthere are no capacities,\n  (ii) a fixed-parameter tractable $\\mathcal{O}^{\\star}(k^{\\mathcal{O}(k)})$\ntime algorithm for the general case, and a kernel of size polynomial in $k$ for\nthe special case of Many Visits TSP,\n  (iii) a $|V(G)|^{\\mathcal{O}(tw)}$ time algorithm and a matching\n$|V(G)|^{o(tw)}$ time conditional lower bound conditioned on the Exponential\nTime Hypothesis.\n  To achieve some of our results, we significantly extend an approach by\nKowalik et al.~[ESA'20].\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:44:49 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:20:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mannens", "Isja", ""], ["Nederlof", "Jesper", ""], ["Swennenhuis", "C\u00e9line", ""], ["Szil\u00e1gyi", "Krisztina", ""]]}, {"id": "2106.11696", "submitter": "Suhas Thejaswi", "authors": "Suhas Thejaswi and Bruno Ordozgoiti and Aristides Gionis", "title": "Diversity-aware $k$-median : Clustering with fair center representation", "comments": "To appear in ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel problem for diversity-aware clustering. We assume that\nthe potential cluster centers belong to a set of groups defined by protected\nattributes, such as ethnicity, gender, etc. We then ask to find a minimum-cost\nclustering of the data into $k$ clusters so that a specified minimum number of\ncluster centers are chosen from each group. We thus require that all groups are\nrepresented in the clustering solution as cluster centers, according to\nspecified requirements. More precisely, we are given a set of clients $C$, a\nset of facilities $\\pazocal{F}$, a collection $\\mathcal{F}=\\{F_1,\\dots,F_t\\}$\nof facility groups $F_i \\subseteq \\pazocal{F}$, budget $k$, and a set of\nlower-bound thresholds $R=\\{r_1,\\dots,r_t\\}$, one for each group in\n$\\mathcal{F}$. The \\emph{diversity-aware $k$-median problem} asks to find a set\n$S$ of $k$ facilities in $\\pazocal{F}$ such that $|S \\cap F_i| \\geq r_i$, that\nis, at least $r_i$ centers in $S$ are from group $F_i$, and the $k$-median cost\n$\\sum_{c \\in C} \\min_{s \\in S} d(c,s)$ is minimized. We show that in the\ngeneral case where the facility groups may overlap, the diversity-aware\n$k$-median problem is \\np-hard, fixed-parameter intractable, and inapproximable\nto any multiplicative factor. On the other hand, when the facility groups are\ndisjoint, approximation algorithms can be obtained by reduction to the\n\\emph{matroid median} and \\emph{red-blue median} problems. Experimentally, we\nevaluate our approximation methods for the tractable cases, and present a\nrelaxation-based heuristic for the theoretically intractable case, which can\nprovide high-quality and efficient solutions for real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:57:04 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Thejaswi", "Suhas", ""], ["Ordozgoiti", "Bruno", ""], ["Gionis", "Aristides", ""]]}, {"id": "2106.11744", "submitter": "Adam Karczmarz", "authors": "Adam Karczmarz", "title": "Fully Dynamic Algorithms for Minimum Weight Cycle and Related Problems", "comments": "Full version of an ICALP 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the directed minimum weight cycle problem in the fully dynamic\nsetting. To the best of our knowledge, so far no fully dynamic algorithms have\nbeen designed specifically for the minimum weight cycle problem in general\ndigraphs. One can achieve $\\tilde{O}(n^2)$ amortized update time by simply\ninvoking the fully dynamic APSP algorithm of Demetrescu and Italiano [J.\nACM'04]. This bound, however, yields no improvement over the trivial\nrecompute-from-scratch algorithm for sparse graphs.\n  Our first contribution is a very simple deterministic\n$(1+\\epsilon)$-approximate algorithm supporting vertex updates (i.e., changing\nall edges incident to a specified vertex) in conditionally near-optimal\n$\\tilde{O}(m\\log{(W)}/\\epsilon)$ amortized time for digraphs with real edge\nweights in $[1,W]$. Using known techniques, the algorithm can be implemented on\nplanar graphs and also gives some new sublinear fully dynamic algorithms\nmaintaining approximate cuts and flows in planar digraphs.\n  Additionally, we show a Monte Carlo randomized exact fully dynamic minimum\nweight cycle algorithm with $\\tilde{O}(mn^{2/3})$ worst-case update that works\nfor real edge weights. To this end, we generalize the exact fully dynamic APSP\ndata structure of Abraham et al. [SODA'17] to solve the ``multiple-pairs\nshortest paths problem'', where one is interested in computing distances for\nsome $k$ (instead of all $n^2$) fixed source-target pairs after each update. We\nshow that in such a scenario, $\\tilde{O}((m+k)n^{2/3})$ worst-case update time\nis possible.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 13:29:47 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Karczmarz", "Adam", ""]]}, {"id": "2106.11863", "submitter": "Yousef Saad", "authors": "Jie Chen, Yousef Saad and Zechen Zhang", "title": "Graph coarsening: From scientific computing to machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The general method of graph coarsening or graph reduction has been a\nremarkably useful and ubiquitous tool in scientific computing and it is now\njust starting to have a similar impact in machine learning. The goal of this\npaper is to take a broad look into coarsening techniques that have been\nsuccessfully deployed in scientific computing and see how similar principles\nare finding their way in more recent applications related to machine learning.\nIn scientific computing, coarsening plays a central role in algebraic multigrid\nmethods as well as the related class of multilevel incomplete LU\nfactorizations. In machine learning, graph coarsening goes under various names,\ne.g., graph downsampling or graph reduction. Its goal in most cases is to\nreplace some original graph by one which has fewer nodes, but whose structure\nand characteristics are similar to those of the original graph. As will be\nseen, a common strategy in these methods is to rely on spectral properties to\ndefine the coarse graph.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:31:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chen", "Jie", ""], ["Saad", "Yousef", ""], ["Zhang", "Zechen", ""]]}, {"id": "2106.11938", "submitter": "Kevin Tian", "authors": "Arun Jambulapati, Jerry Li, Tselil Schramm, Kevin Tian", "title": "Robust Regression Revisited: Acceleration and Improved Estimation Rates", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study fast algorithms for statistical regression problems under the strong\ncontamination model, where the goal is to approximately optimize a generalized\nlinear model (GLM) given adversarially corrupted samples. Prior works in this\nline of research were based on the robust gradient descent framework of Prasad\net. al., a first-order method using biased gradient queries, or the Sever\nframework of Diakonikolas et. al., an iterative outlier-removal method calling\na stationary point finder.\n  We present nearly-linear time algorithms for robust regression problems with\nimproved runtime or estimation guarantees compared to the state-of-the-art. For\nthe general case of smooth GLMs (e.g. logistic regression), we show that the\nrobust gradient descent framework of Prasad et. al. can be accelerated, and\nshow our algorithm extends to optimizing the Moreau envelopes of Lipschitz GLMs\n(e.g. support vector machines), answering several open questions in the\nliterature.\n  For the well-studied case of robust linear regression, we present an\nalternative approach obtaining improved estimation rates over prior\nnearly-linear time algorithms. Interestingly, our method starts with an\nidentifiability proof introduced in the context of the sum-of-squares algorithm\nof Bakshi and Prasad, which achieved optimal error rates while requiring large\npolynomial runtime and sample complexity. We reinterpret their proof within the\nSever framework and obtain a dramatically faster and more sample-efficient\nalgorithm under fewer distributional assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:21:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jambulapati", "Arun", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.12150", "submitter": "Maryam Negahbani", "authors": "Deeparnab Chakrabarty and Maryam Negahbani", "title": "Better Algorithms for Individually Fair $k$-Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study data clustering problems with $\\ell_p$-norm objectives (e.g.\n$k$-Median and $k$-Means) in the context of individual fairness. The dataset\nconsists of $n$ points, and we want to find $k$ centers such that (a) the\nobjective is minimized, while (b) respecting the individual fairness constraint\nthat every point $v$ has a center within a distance at most $r(v)$, where\n$r(v)$ is $v$'s distance to its $(n/k)$th nearest point. Jung, Kannan, and Lutz\n[FORC 2020] introduced this concept and designed a clustering algorithm with\nprovable (approximate) fairness and objective guarantees for the $\\ell_\\infty$\nor $k$-Center objective. Mahabadi and Vakilian [ICML 2020] revisited this\nproblem to give a local-search algorithm for all $\\ell_p$-norms. Empirically,\ntheir algorithms outperform Jung et. al.'s by a large margin in terms of cost\n(for $k$-Median and $k$-Means), but they incur a reasonable loss in fairness.\nIn this paper, our main contribution is to use Linear Programming (LP)\ntechniques to obtain better algorithms for this problem, both in theory and in\npractice. We prove that by modifying known LP rounding techniques, one gets a\nworst-case guarantee on the objective which is much better than in MV20, and\nempirically, this objective is extremely close to the optimal. Furthermore, our\ntheoretical fairness guarantees are comparable with MV20 in theory, and\nempirically, we obtain noticeably fairer solutions. Although solving the LP\n{\\em exactly} might be prohibitive, we demonstrate that in practice, a simple\nsparsification technique drastically improves the run-time of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 04:16:46 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Negahbani", "Maryam", ""]]}, {"id": "2106.12189", "submitter": "Anes Abdennebi", "authors": "Anes Abdennebi and Kamer Kaya", "title": "A Bloom Filter Survey: Variants for Different Domain Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is a plethora of data structures, algorithms, and frameworks dealing\nwith major data-stream problems like estimating the frequency of items,\nanswering set membership, association and multiplicity queries, and several\nother statistics that can be extracted from voluminous data streams. In this\nsurvey, we are focusing on exploring randomized data structures called Bloom\nFilters. This data structure answers whether an item exists or not in a data\nstream with a false positive probability fpp. In this survey, many variants of\nthe Bloom filter will be covered by showing the strengths of each structure and\nits drawbacks i.e. some Bloom filters deal with insertion and deletions and\nothers don't, some variants use the memory efficiently but increase the fpp\nwhere others pay the trade-off in the reversed way. Furthermore, in each Bloom\nfilter structure, the false positive probability will be highlighted alongside\nthe most important technical details showing the improvement it is presenting,\nwhile the main aim of this work is to provide an overall comparison between the\nvariants of the Bloom filter structure according to the application domain that\nit fits in.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:30:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Abdennebi", "Anes", ""], ["Kaya", "Kamer", ""]]}, {"id": "2106.12193", "submitter": "Jonathan Scarlett", "authors": "Bernard Teo and Jonathan Scarlett", "title": "Noisy Adaptive Group Testing via Noisy Binary Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group testing problem consists of determining a small set of defective\nitems from a larger set of items based on a number of possibly-noisy tests, and\nhas numerous practical applications. One of the defining features of group\ntesting is whether the tests are adaptive (i.e., a given test can be chosen\nbased on all previous outcomes) or non-adaptive (i.e., all tests must be chosen\nin advance). In this paper, building on the success of binary splitting\ntechniques in noiseless group testing (Hwang, 1972), we introduce noisy group\ntesting algorithms that apply noisy binary search as a subroutine. We provide\nthree variations of this approach with increasing complexity, culminating in an\nalgorithm that succeeds using a number of tests that matches the best known\npreviously (Scarlett, 2019), while overcoming fundamental practical limitations\nof the existing approach, and more precisely capturing the dependence of the\nnumber of tests on the error probability. We provide numerical experiments\ndemonstrating that adaptive group testing strategies based on noisy binary\nsearch can be highly effective in practice, using significantly fewer tests\ncompared to state-of-the-art non-adaptive strategies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:53:58 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Teo", "Bernard", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2106.12249", "submitter": "Irena Rusu Ph.D.", "authors": "Irena Rusu", "title": "Forced pairs in A-Stick graphs", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Stick graph G=(A\\cup B, E) is the intersection graph of a set A of\nhorizontal segments and a set B of vertical segments in the plane, whose left\nand respectively bottom endpoints lie on the same ground line with slope -1.\nThese endpoints are respectively called A-origins and B-origins. When a total\norder is provided for the A-origins, the resulting graphs are called A-Stick\ngraphs.\n  In this paper, we propose a characterization of the class of A-Stick graphs\nusing forced pairs, which are pairs of segments in B with the property that\nonly one left-to-right order of their origins is possible on the ground line.\nWe deduce a recognition algorithm for A-Stick graphs running in O(|A|+|B|+|E|)\ntime, thus improving the running time of O(|A|\\cdot |B|) of the best current\nalgorithm. We also introduce the problem of finding, for a Stick graph, a\nrepresentation using segments of minimum total length. The canonical order on\nthe A- and B-origins, output by our recognition algorithm, allows us to obtain\npartial results on this problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:09:28 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Rusu", "Irena", ""]]}, {"id": "2106.12270", "submitter": "Hans-Peter Lehmann", "authors": "Hans-Peter Lehmann, Lorenz H\\\"ubschle-Schneider, Peter Sanders", "title": "Weighted Random Sampling on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An alias table is a data structure that allows for efficiently drawing\nweighted random samples in constant time and can be constructed in linear time.\nThe PSA algorithm by H\\\"ubschle-Schneider and Sanders is able to construct\nalias tables in parallel on the CPU. In this report, we transfer the PSA\nalgorithm to the GPU. Our construction algorithm achieves a speedup of 17 on a\nconsumer GPU in comparison to the PSA method on a 16-core high-end desktop CPU.\nFor sampling, we achieve an up to 24 times higher throughput. Both operations\nalso require several times less energy than on the CPU. Adaptations helping to\nachieve this include changing memory access patterns to do coalesced access.\nWhere this is not possible, we first copy data to the faster shared memory\nusing coalesced access. We also enhance a generalization of binary search\nenabling to search for a range of items in parallel. Besides naive sampling, we\nalso give improved batched sampling algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:47:26 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lehmann", "Hans-Peter", ""], ["H\u00fcbschle-Schneider", "Lorenz", ""], ["Sanders", "Peter", ""]]}, {"id": "2106.12293", "submitter": "Stefano Leucci", "authors": "Davide Bil\\`o, Gianlorenzo D'Angelo, Luciano Gual\\`a, Stefano Leucci,\n  Guido Proietti, Mirko Rossi", "title": "Finding single-source shortest $p$-disjoint paths: fast computation and\n  sparse preservers", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a directed graph with $n$ vertices, $m$ edges, and non-negative\nedge costs. Given $G$, a fixed source vertex $s$, and a positive integer $p$,\nwe consider the problem of computing, for each vertex $t\\neq s$, $p$\nedge-disjoint paths of minimum total cost from $s$ to $t$ in $G$. Suurballe and\nTarjan~[Networks, 1984] solved the above problem for $p=2$ by designing a\n$O(m+n\\log n)$ time algorithm which also computes a sparse \\emph{single-source\n$2$-multipath preserver}, i.e., a subgraph containing $2$ edge-disjoint paths\nof minimum total cost from $s$ to every other vertex of $G$. The case $p \\geq\n3$ was left as an open problem.\n  We study the general problem ($p\\geq 2$) and prove that any graph admits a\nsparse single-source $p$-multipath preserver with $p(n-1)$ edges. This size is\noptimal since the in-degree of each non-root vertex $v$ must be at least $p$.\nMoreover, we design an algorithm that requires $O(pn^2 (p + \\log n))$ time to\ncompute both $p$ edge-disjoint paths of minimum total cost from the source to\nall other vertices and an optimal-size single-source $p$-multipath preserver.\nThe running time of our algorithm outperforms that of a natural approach that\nsolves $n-1$ single-pair instances using the well-known \\emph{successive\nshortest paths} algorithm by a factor of $\\Theta(\\frac{m}{np})$ and is\nasymptotically near optimal if $p=O(1)$ and $m=\\Theta(n^2)$. Our results extend\nnaturally to the case of $p$ vertex-disjoint paths.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 10:20:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bil\u00f2", "Davide", ""], ["D'Angelo", "Gianlorenzo", ""], ["Gual\u00e0", "Luciano", ""], ["Leucci", "Stefano", ""], ["Proietti", "Guido", ""], ["Rossi", "Mirko", ""]]}, {"id": "2106.12459", "submitter": "Jason Gaitonde", "authors": "Jason Gaitonde, Jon Kleinberg, and \\'Eva Tardos", "title": "Polarization in Geometric Opinion Dynamics", "comments": "22 pages, to appear at EC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In light of increasing recent attention to political polarization,\nunderstanding how polarization can arise poses an important theoretical\nquestion. While more classical models of opinion dynamics seem poorly equipped\nto study this phenomenon, a recent novel approach by H\\k{a}z{\\l}a, Jin, Mossel,\nand Ramnarayan (HJMR) proposes a simple geometric model of opinion evolution\nthat provably exhibits strong polarization in specialized cases. Moreover,\npolarization arises quite organically in their model: in each time step, each\nagent updates opinions according to their correlation/response with an issue\ndrawn at random. However, their techniques do not seem to extend beyond a set\nof special cases they identify, which benefit from fragile symmetry or\ncontractiveness assumptions, leaving open how general this phenomenon really\nis.\n  In this paper, we further the study of polarization in related geometric\nmodels. We show that the exact form of polarization in such models is quite\nnuanced: even when strong polarization does not hold, it is possible for weaker\nnotions of polarization to nonetheless attain. We provide a concrete example\nwhere weak polarization holds, but strong polarization provably fails. However,\nwe show that strong polarization provably holds in many variants of the HJMR\nmodel, which are also robust to a wider array of distributions of random issues\n-- this indicates that the form of polarization introduced by HJMR is more\nuniversal than suggested by their special cases. We also show that the weaker\nnotions connect more readily to the theory of Markov chains on general state\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:11:51 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Gaitonde", "Jason", ""], ["Kleinberg", "Jon", ""], ["Tardos", "\u00c9va", ""]]}, {"id": "2106.12710", "submitter": "Sidhanth Mohanty", "authors": "Jun-Ting Hsieh, Sidhanth Mohanty, Jeff Xu", "title": "Certifying solution geometry in random CSPs: counts, clusters and\n  balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active topic in the study of random constraint satisfaction problems\n(CSPs) is the geometry of the space of satisfying or almost satisfying\nassignments as the function of the density, for which a precise landscape of\npredictions has been made via statistical physics-based heuristics. In\nparallel, there has been a recent flurry of work on refuting random constraint\nsatisfaction problems, via nailing refutation thresholds for spectral and\nsemidefinite programming-based algorithms, and also on counting solutions to\nCSPs. Inspired by this, the starting point for our work is the following\nquestion: what does the solution space for a random CSP look like to an\nefficient algorithm?\n  In pursuit of this inquiry, we focus on the following problems about random\nBoolean CSPs at the densities where they are unsatisfiable but no refutation\nalgorithm is known.\n  1. Counts. For every Boolean CSP we give algorithms that with high\nprobability certify a subexponential upper bound on the number of solutions. We\nalso give algorithms to certify a bound on the number of large cuts in a\nGaussian-weighted graph, and the number of large independent sets in a random\n$d$-regular graph.\n  2. Clusters. For Boolean $3$CSPs we give algorithms that with high\nprobability certify an upper bound on the number of clusters of solutions.\n  3. Balance. We also give algorithms that with high probability certify that\nthere are no \"unbalanced\" solutions, i.e., solutions where the fraction of\n$+1$s deviates significantly from $50\\%$.\n  Finally, we also provide hardness evidence suggesting that our algorithms for\ncounting are optimal.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 01:15:35 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hsieh", "Jun-Ting", ""], ["Mohanty", "Sidhanth", ""], ["Xu", "Jeff", ""]]}, {"id": "2106.12725", "submitter": "Dominik Kempa", "authors": "Dominik Kempa, Tomasz Kociumaka", "title": "Breaking the $O(n)$-Barrier in the Construction of Compressed Suffix\n  Arrays", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The suffix array, describing the lexicographic order of suffixes of a given\ntext, is the central data structure in string algorithms. The suffix array of a\nlength-$n$ text uses $\\Theta(n \\log n)$ bits, which is prohibitive in many\napplications. To address this, Grossi and Vitter [STOC 2000] and,\nindependently, Ferragina and Manzini [FOCS 2000] introduced space-efficient\nversions of the suffix array, known as the compressed suffix array (CSA) and\nthe FM-index. For a length-$n$ text over an alphabet of size $\\sigma$, these\ndata structures use only $O(n \\log \\sigma)$ bits. Immediately after their\ndiscovery, they almost completely replaced plain suffix arrays in practical\napplications, and a race started to develop efficient construction procedures.\nYet, after more than 20 years, even for $\\sigma=2$, the fastest algorithm\nremains stuck at $O(n)$ time [Hon et al., FOCS 2003], which is slower by a\n$\\Theta(\\log n)$ factor than the lower bound of $\\Omega(n / \\log n)$ (following\nsimply from the necessity to read the entire input). We break this\nlong-standing barrier with a new data structure that takes $O(n \\log \\sigma)$\nbits, answers suffix array queries in $O(\\log^{\\epsilon} n)$ time, and can be\nconstructed in $O(n\\log \\sigma / \\sqrt{\\log n})$ time using $O(n\\log \\sigma)$\nbits of space. Our result is based on several new insights into the recently\ndeveloped notion of string synchronizing sets [STOC 2019]. In particular,\ncompared to their previous applications, we eliminate orthogonal range queries,\nreplacing them with new queries that we dub prefix rank and prefix selection\nqueries. As a further demonstration of our techniques, we present a new\npattern-matching index that simultaneously minimizes the construction time and\nthe query time among all known compact indexes (i.e., those using $O(n \\log\n\\sigma)$ bits).\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 02:14:13 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kempa", "Dominik", ""], ["Kociumaka", "Tomasz", ""]]}, {"id": "2106.12858", "submitter": "Michael Hartisch", "authors": "Michael Hartisch", "title": "Adaptive Relaxations for Multistage Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multistage robust optimization problems can be interpreted as two-person\nzero-sum games between two players. We exploit this game-like nature and\nutilize a game tree search in order to solve quantified integer programs\n(QIPs). In this algorithmic environment relaxations are repeatedly called to\nasses the quality of a branching variable and for the generation of bounds. A\nuseful relaxation, however, must be well balanced with regard to its quality\nand its computing time. We present two relaxations that incorporate scenarios\nfrom the uncertainty set, whereby the considered set of scenarios is\ncontinuously adapted according to the latest information gathered during the\nsearch process. Using selection, assignment, and runway scheduling problems as\na testbed, we show the impact of our findings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 09:44:19 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hartisch", "Michael", ""]]}, {"id": "2106.12959", "submitter": "Moshe Shechner", "authors": "Moshe Shechner", "title": "Differentially Private Algorithms for Clustering with Stability\n  Assumptions", "comments": "Thesis submitted in partial fulfillment of the requirements for the\n  M.Sc. degree in the Faculty of Natural Sciences. arXiv admin note: text\n  overlap with arXiv:1907.02513 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of differentially private clustering under\ninput-stability assumptions. Despite the ever-growing volume of works on\ndifferential privacy in general and differentially private clustering in\nparticular, only three works (Nissim et al. 2007, Wang et al. 2015, Huang et\nal. 2018) looked at the problem of privately clustering \"nice\" k-means\ninstances, all three relying on the sample-and-aggregate framework and all\nthree measuring utility in terms of Wasserstein distance between the true\ncluster centers and the centers returned by the private algorithm. In this work\nwe improve upon this line of works on multiple axes. We present a far simpler\nalgorithm for clustering stable inputs (not relying on the sample-and-aggregate\nframework), and analyze its utility in both the Wasserstein distance and the\nk-means cost. Moreover, our algorithm has straight-forward analogues for \"nice\"\nk-median instances and for the local-model of differential privacy.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:45:39 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Shechner", "Moshe", ""]]}, {"id": "2106.13078", "submitter": "Alexander Golovnev", "authors": "Chi-Ning Chou, Alexander Golovnev, Madhu Sudan, Ameya Velingker,\n  Santhoshini Velusamy", "title": "Linear Space Streaming Lower Bounds for Approximating CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the approximability of constraint satisfaction problems in the\nstreaming setting. For every constraint satisfaction problem (CSP) on $n$\nvariables taking values in $\\{0,\\ldots,q-1\\}$, we prove that improving over the\ntrivial approximability by a factor of $q$ requires $\\Omega(n)$ space even on\ninstances with $O(n)$ constraints. We also identify a broad subclass of\nproblems for which any improvement over the trivial approximability requires\n$\\Omega(n)$ space. The key technical core is an optimal,\n$q^{-(k-1)}$-inapproximability for the case where every constraint is given by\na system of $k-1$ linear equations $\\bmod\\; q$ over $k$ variables. Prior to our\nwork, no such hardness was known for an approximation factor less than $1/2$\nfor any CSP. Our work builds on and extends the work of Kapralov and Krachun\n(Proc. STOC 2019) who showed a linear lower bound on any non-trivial\napproximation of the max cut in graphs. This corresponds roughly to the case of\nMax $k$-LIN-$\\bmod\\; q$ with $k=q=2$. Each one of the extensions provides\nnon-trivial technical challenges that we overcome in this work.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:04:07 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Chou", "Chi-Ning", ""], ["Golovnev", "Alexander", ""], ["Sudan", "Madhu", ""], ["Velingker", "Ameya", ""], ["Velusamy", "Santhoshini", ""]]}, {"id": "2106.13210", "submitter": "Nikhil Vyas", "authors": "Mitali Bafna, Nikhil Vyas", "title": "Optimal Fine-grained Hardness of Approximation of Linear Equations", "comments": "To appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of solving linear systems is one of the most fundamental problems\nin computer science, where given a satisfiable linear system $(A,b)$, for $A\n\\in \\mathbb{R}^{n \\times n}$ and $b \\in \\mathbb{R}^n$, we wish to find a vector\n$x \\in \\mathbb{R}^n$ such that $Ax = b$. The current best algorithms for\nsolving dense linear systems reduce the problem to matrix multiplication, and\nrun in time $O(n^{\\omega})$. We consider the problem of finding\n$\\varepsilon$-approximate solutions to linear systems with respect to the\n$L_2$-norm, that is, given a satisfiable linear system $(A \\in \\mathbb{R}^{n\n\\times n}, b \\in \\mathbb{R}^n)$, find an $x \\in \\mathbb{R}^n$ such that $||Ax -\nb||_2 \\leq \\varepsilon||b||_2$. Our main result is a fine-grained reduction\nfrom computing the rank of a matrix to finding $\\varepsilon$-approximate\nsolutions to linear systems. In particular, if the best known $O(n^\\omega)$\ntime algorithm for computing the rank of $n \\times O(n)$ matrices is optimal\n(which we conjecture is true), then finding an $\\varepsilon$-approximate\nsolution to a dense linear system also requires $\\tilde{\\Omega}(n^{\\omega})$\ntime, even for $\\varepsilon$ as large as $(1 - 1/\\text{poly}(n))$. We also\nprove (under some modified conjectures for the rank-finding problem) optimal\nhardness of approximation for sparse linear systems, linear systems over\npositive semidefinite matrices, well-conditioned linear systems, and\napproximately solving linear systems with respect to the $L_p$-norm, for $p\n\\geq 1$. At the heart of our results is a novel reduction from the rank problem\nto a decision version of the approximate linear systems problem. This reduction\npreserves properties such as matrix sparsity and bit complexity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:43:57 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bafna", "Mitali", ""], ["Vyas", "Nikhil", ""]]}, {"id": "2106.13342", "submitter": "Antonia Kormpa", "authors": "Mahmoud Abo Khamis, George Chichirim, Antonia Kormpa, Dan Olteanu", "title": "The Complexity of Boolean Conjunctive Queries with Intersection Joins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection joins over interval data are relevant in spatial and temporal\ndata settings. A set of intervals join if their intersection is non-empty. In\ncase of point intervals, the intersection join becomes the standard equality\njoin.\n  We establish the complexity of Boolean conjunctive queries with intersection\njoins by a many-one equivalence to disjunctions of Boolean conjunctive queries\nwith equality joins. The complexity of any query with intersection joins is\nthat of the hardest query with equality joins in the disjunction exhibited by\nour equivalence. This is captured by a new width measure called the IJ-width.\n  We also introduce a new syntactic notion of acyclicity called iota-acyclicity\nto characterise the class of Boolean queries with intersection joins that admit\nlinear time computation modulo a poly-logarithmic factor in the data size.\nIota-acyclicity is for intersection joins what alpha-acyclicity is for equality\njoins. It strictly sits between gamma-acyclicity and Berge-acyclicity. The\nintersection join queries that are not iota-acyclic are at least as hard as the\nBoolean triangle query with equality joins, which is widely considered not\ncomputable in linear time.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 22:44:30 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Khamis", "Mahmoud Abo", ""], ["Chichirim", "George", ""], ["Kormpa", "Antonia", ""], ["Olteanu", "Dan", ""]]}, {"id": "2106.13349", "submitter": "Stefan Bamberger", "authors": "Stefan Bamberger, Felix Krahmer, Rachel Ward", "title": "Johnson-Lindenstrauss Embeddings with Kronecker Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the Johnson-Lindenstrauss property for matrices $\\Phi D_\\xi$ where\n$\\Phi$ has the restricted isometry property and $D_\\xi$ is a diagonal matrix\ncontaining the entries of a Kronecker product $\\xi = \\xi^{(1)} \\otimes \\dots\n\\otimes \\xi^{(d)}$ of $d$ independent Rademacher vectors. Such embeddings have\nbeen proposed in recent works for a number of applications concerning\ncompression of tensor structured data, including the oblivious sketching\nprocedure by Ahle et al. for approximate tensor computations. For preserving\nthe norms of $p$ points simultaneously, our result requires $\\Phi$ to have the\nrestricted isometry property for sparsity $C(d) (\\log p)^d$. In the case of\nsubsampled Hadamard matrices, this can improve the dependence of the embedding\ndimension on $p$ to $(\\log p)^d$ while the best previously known result\nrequired $(\\log p)^{d + 1}$. That is, for the case of $d=2$ at the core of the\noblivious sketching procedure by Ahle et al., the scaling improves from cubic\nto quadratic. We provide a counterexample to prove that the scaling established\nin our result is optimal under mild assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 23:12:07 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Bamberger", "Stefan", ""], ["Krahmer", "Felix", ""], ["Ward", "Rachel", ""]]}, {"id": "2106.13414", "submitter": "Gautam Kamath", "authors": "Cl\\'ement L. Canonne, Ayush Jain, Gautam Kamath, Jerry Li", "title": "The Price of Tolerance in Distribution Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of tolerant distribution testing. That is, given\nsamples from an unknown distribution $p$ over $\\{1, \\dots, n\\}$, is it\n$\\varepsilon_1$-close to or $\\varepsilon_2$-far from a reference distribution\n$q$ (in total variation distance)? Despite significant interest over the past\ndecade, this problem is well understood only in the extreme cases. In the\nnoiseless setting (i.e., $\\varepsilon_1 = 0$) the sample complexity is\n$\\Theta(\\sqrt{n})$, strongly sublinear in the domain size. At the other end of\nthe spectrum, when $\\varepsilon_1 = \\varepsilon_2/2$, the sample complexity\njumps to the barely sublinear $\\Theta(n/\\log n)$. However, very little is known\nabout the intermediate regime. We fully characterize the price of tolerance in\ndistribution testing as a function of $n$, $\\varepsilon_1$, $\\varepsilon_2$, up\nto a single $\\log n$ factor. Specifically, we show the sample complexity to be\n\\[\\tilde \\Theta\\left(\\frac{\\sqrt{n}}{\\varepsilon_2^{2}} + \\frac{n}{\\log n}\n\\cdot \\max\n\\left\\{\\frac{\\varepsilon_1}{\\varepsilon_2^2},\\left(\\frac{\\varepsilon_1}{\\varepsilon_2^2}\\right)^{\\!\\!2}\\right\\}\\right),\\]\nproviding a smooth tradeoff between the two previously known cases. We also\nprovide a similar characterization for the problem of tolerant equivalence\ntesting, where both $p$ and $q$ are unknown. Surprisingly, in both cases, the\nmain quantity dictating the sample complexity is the ratio\n$\\varepsilon_1/\\varepsilon_2^2$, and not the more intuitive\n$\\varepsilon_1/\\varepsilon_2$. Of particular technical interest is our lower\nbound framework, which involves novel approximation-theoretic tools required to\nhandle the asymmetry between $\\varepsilon_1$ and $\\varepsilon_2$, a challenge\nabsent from previous works.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 03:59:42 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Jain", "Ayush", ""], ["Kamath", "Gautam", ""], ["Li", "Jerry", ""]]}, {"id": "2106.13513", "submitter": "Roi Livni", "authors": "Noah Golowich and Roi Livni", "title": "Littlestone Classes are Privately Online Learnable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online classification under a privacy constraint.\nIn this setting a learner observes sequentially a stream of labelled examples\n$(x_t, y_t)$, for $1 \\leq t \\leq T$, and returns at each iteration $t$ a\nhypothesis $h_t$ which is used to predict the label of each new example $x_t$.\nThe learner's performance is measured by her regret against a known hypothesis\nclass $\\mathcal{H}$. We require that the algorithm satisfies the following\nprivacy constraint: the sequence $h_1, \\ldots, h_T$ of hypotheses output by the\nalgorithm needs to be an $(\\epsilon, \\delta)$-differentially private function\nof the whole input sequence $(x_1, y_1), \\ldots, (x_T, y_T)$. We provide the\nfirst non-trivial regret bound for the realizable setting. Specifically, we\nshow that if the class $\\mathcal{H}$ has constant Littlestone dimension then,\ngiven an oblivious sequence of labelled examples, there is a private learner\nthat makes in expectation at most $O(\\log T)$ mistakes -- comparable to the\noptimal mistake bound in the non-private case, up to a logarithmic factor.\nMoreover, for general values of the Littlestone dimension $d$, the same mistake\nbound holds but with a doubly-exponential in $d$ factor. A recent line of work\nhas demonstrated a strong connection between classes that are online learnable\nand those that are differentially-private learnable. Our results strengthen\nthis connection and show that an online learning algorithm can in fact be\ndirectly privatized (in the realizable setting). We also discuss an adaptive\nsetting and provide a sublinear regret bound of $O(\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 09:08:33 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Golowich", "Noah", ""], ["Livni", "Roi", ""]]}, {"id": "2106.13860", "submitter": "John Golden", "authors": "John Golden, Andreas B\\\"artschi, Daniel O'Malley, Stephan Eidenbenz", "title": "Threshold-Based Quantum Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study Th-QAOA (pronounced Threshold QAOA), a variation of the\nQuantum Alternating Operator Ansatz (QAOA) that replaces the standard phase\nseparator operator, which encodes the objective function, with a threshold\nfunction that returns a value $1$ for solutions with an objective value above\nthe threshold and a $0$ otherwise. We vary the threshold value to arrive at a\nquantum optimization algorithm. We focus on a combination with the Grover Mixer\noperator; the resulting GM-Th-QAOA can be viewed as a generalization of\nGrover's quantum search algorithm and its minimum/maximum finding cousin to\napproximate optimization.\n  Our main findings include: (i) we show semi-formally that the optimum\nparameter values of GM-Th-QAOA (angles and threshold value) can be found with\n$O(\\log(p) \\times \\log M)$ iterations of the classical outer loop, where $p$ is\nthe number of QAOA rounds and $M$ is an upper bound on the solution value\n(often the number of vertices or edges in an input graph), thus eliminating the\nnotorious outer-loop parameter finding issue of other QAOA algorithms; (ii)\nGM-Th-QAOA can be simulated classically with little effort up to 100 qubits\nthrough a set of tricks that cut down memory requirements; (iii) somewhat\nsurprisingly, GM-Th-QAOA outperforms its non-thresholded counterparts in terms\nof approximation ratios achieved. This third result holds across a range of\noptimization problems (MaxCut, Max k-VertexCover, Max k-DensestSubgraph,\nMaxBisection) and various experimental design parameters, such as different\ninput edge densities and constraint sizes.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 19:36:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Golden", "John", ""], ["B\u00e4rtschi", "Andreas", ""], ["O'Malley", "Daniel", ""], ["Eidenbenz", "Stephan", ""]]}, {"id": "2106.13951", "submitter": "Eklavya Sharma", "authors": "Arindam Khan, Eklavya Sharma, K. V. N. Sreenivas", "title": "Geometry Meets Vectors: Approximation Algorithms for Multidimensional\n  Packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalized multidimensional bin packing problem (GVBP) that\ngeneralizes both geometric packing and vector packing. Here, we are given $n$\nrectangular items where the $i^{\\textrm{th}}$ item has width $w(i)$, height\n$h(i)$, and $d$ nonnegative weights $v_1(i), v_2(i), \\ldots, v_{d}(i)$. Our\ngoal is to get an axis-parallel non-overlapping packing of the items into\nsquare bins so that for all $j \\in [d]$, the sum of the $j^{\\textrm{th}}$\nweight of items in each bin is at most 1. This is a natural problem arising in\nlogistics, resource allocation, and scheduling. Despite being well studied in\npractice, surprisingly, approximation algorithms for this problem have rarely\nbeen explored.\n  We first obtain two simple algorithms for GVBP having asymptotic\napproximation ratios $6(d+1)$ and $3(1 + \\ln(d+1) + \\varepsilon)$. We then\nextend the Round-and-Approx (R&A) framework [Bansal-Khan, SODA'14] to wider\nclasses of algorithms, and show how it can be adapted to GVBP. Using more\nsophisticated techniques, we obtain better approximation algorithms for GVBP,\nand we get further improvement by combining them with the R&A framework. This\ngives us an asymptotic approximation ratio of $2(1+\\ln((d+4)/2))+\\varepsilon$\nfor GVBP, which improves to $2.919+\\varepsilon$ for the special case of $d=1$.\nWe obtain further improvement when the items are allowed to be rotated. We also\npresent algorithms for a generalization of GVBP where the items are high\ndimensional cuboids.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:08:00 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khan", "Arindam", ""], ["Sharma", "Eklavya", ""], ["Sreenivas", "K. V. N.", ""]]}, {"id": "2106.14043", "submitter": "Mustafa Yal\\c{c}{\\i}ner", "authors": "Ali Vakilian, Mustafa Yal\\c{c}{\\i}ner", "title": "Improved Approximation Algorithms for Individually Fair Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the $k$-clustering problem with $\\ell_p$-norm cost, which\nincludes $k$-median, $k$-means and $k$-center cost functions, under an\nindividual notion of fairness proposed by Jung et al. [2020]: given a set of\npoints $P$ of size $n$, a set of $k$ centers induces a fair clustering if for\nevery point $v\\in P$, $v$ can find a center among its $n/k$ closest neighbors.\nRecently, Mahabadi and Vakilian [2020] showed how to get a\n$(p^{O(p)},7)$-bicriteria approximation for the problem of fair $k$-clustering\nwith $\\ell_p$-norm cost: every point finds a center within distance at most $7$\ntimes its distance to its $(n/k)$-th closest neighbor and the $\\ell_p$-norm\ncost of the solution is at most $p^{O(p)}$ times the cost of an optimal fair\nsolution. In this work, for any $\\varepsilon>0$, we present an improved $(16^p\n+\\varepsilon,3)$-bicriteria approximation for the fair $k$-clustering with\n$\\ell_p$-norm cost. To achieve our guarantees, we extend the framework of\n[Charikar et al., 2002, Swamy, 2016] and devise a $16^p$-approximation\nalgorithm for the facility location with $\\ell_p$-norm cost under matroid\nconstraint which might be of an independent interest. Besides, our approach\nsuggests a reduction from our individually fair clustering to a clustering with\na group fairness requirement proposed by Kleindessner et al. [2019], which is\nessentially the median matroid problem [Krishnaswamy et al., 2011].\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 15:22:52 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Vakilian", "Ali", ""], ["Yal\u00e7\u0131ner", "Mustafa", ""]]}, {"id": "2106.14116", "submitter": "William Maxwell", "authors": "William Maxwell, Amir Nayyeri", "title": "Generalized max-flows and min-cuts in simplicial complexes", "comments": "To appear at the European Symposium on Algorithms (ESA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.AT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider high dimensional variants of the maximum flow and minimum cut\nproblems in the setting of simplicial complexes and provide both algorithmic\nand hardness results. By viewing flows and cuts topologically in terms of the\nsimplicial (co)boundary operator we can state these problems as linear programs\nand show that they are dual to one another. Unlike graphs, complexes with\nintegral capacity constraints may have fractional max-flows. We show that\ncomputing a maximum integral flow is NP-hard. Moreover, we give a combinatorial\ndefinition of a simplicial cut that seems more natural in the context of\noptimization problems and show that computing such a cut is NP-hard. However,\nwe provide conditions on the simplicial complex for when the cut found by the\nlinear program is a combinatorial cut. For $d$-dimensional simplicial complexes\nembedded into $\\mathbb{R}^{d+1}$ we provide algorithms operating on the dual\ngraph: computing a maximum flow is dual to computing a shortest path and\ncomputing a minimum cut is dual to computing a minimum cost circulation.\nFinally, we investigate the Ford-Fulkerson algorithm on simplicial complexes,\nprove its correctness, and provide a heuristic which guarantees it to halt.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 00:21:10 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Maxwell", "William", ""], ["Nayyeri", "Amir", ""]]}, {"id": "2106.14169", "submitter": "Prafullkumar Tale Mr", "authors": "Fredrik Manne, Geevarghese Philip, Saket Saurabh and Prafullkumar Tale", "title": "$\\alpha$-approximate Reductions: a Novel Source of Heuristics for Better\n  Approximation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lokshtanov et al.~[STOC 2017] introduced \\emph{lossy kernelization} as a\nmathematical framework for quantifying the effectiveness of preprocessing\nalgorithms in preserving approximation ratios. \\emph{$\\alpha$-approximate\nreduction rules} are a central notion of this framework. We propose that\ncarefully crafted $\\alpha$-approximate reduction rules can yield improved\napproximation ratios in practice, while being easy to implement as well. This\nis distinctly different from the (theoretical) purpose for which Lokshtanov et\nal. designed $\\alpha$-approximate Reduction Rules. As evidence in support of\nthis proposal we present a new 2-approximate reduction rule for the\n\\textsc{Dominating Set} problem. This rule, when combined with an approximation\nalgorithm for \\textsc{Dominating Set}, yields significantly better\napproximation ratios on a variety of benchmark instances as compared to the\nlatter algorithm alone.\n  The central thesis of this work is that $\\alpha$-approximate reduction rules\ncan be used as a tool for designing approximation algorithms which perform\nbetter in practice. To the best of our knowledge, ours is the first exploration\nof the use of $\\alpha$-approximate reduction rules as a design technique for\npractical approximation algorithms. We believe that this technique could be\nuseful in coming up with improved approximation algorithms for other\noptimization problems as well.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 08:33:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Manne", "Fredrik", ""], ["Philip", "Geevarghese", ""], ["Saurabh", "Saket", ""], ["Tale", "Prafullkumar", ""]]}, {"id": "2106.14176", "submitter": "Eunjin Oh", "authors": "Kyungjin Cho and Eunjin Oh", "title": "Linear-Time Approximation Scheme for k-Means Clustering of Affine\n  Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a linear-time approximation scheme for $k$-means\nclustering of \\emph{incomplete} data points in $d$-dimensional Euclidean space.\nAn \\emph{incomplete} data point with $\\Delta>0$ unspecified entries is\nrepresented as an axis-parallel affine subspaces of dimension $\\Delta$. The\ndistance between two incomplete data points is defined as the Euclidean\ndistance between two closest points in the axis-parallel affine subspaces\ncorresponding to the data points. We present an algorithm for $k$-means\nclustering of axis-parallel affine subspaces of dimension $\\Delta$ that yields\nan $(1+\\epsilon)$-approximate solution in $O(nd)$ time. The constants hidden\nbehind $O(\\cdot)$ depend only on $\\Delta, \\epsilon$ and $k$. This improves the\n$O(n^2 d)$-time algorithm by Eiben et al.[SODA'21] by a factor of $n$.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 09:27:22 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Cho", "Kyungjin", ""], ["Oh", "Eunjin", ""]]}, {"id": "2106.14354", "submitter": "Tytus Pikies", "authors": "Tytus Pikies (1), Hanna Furma\\'nczyk (2) ((1) Dept. of Algorithims and\n  System Modelling, ETI Faculty, Gda\\'nsk University of Technology, 11/12\n  Gabriela Narutowicza Street, 80-233 Gda\\'nsk, Poland, (2) Institute of\n  Informatics, Faculty of Mathematics, Physics and Informatics, University of\n  Gda\\'nsk, 57 Wita Stwosza Street, 80-309 Gda\\'nsk, Poland)", "title": "Scheduling on uniform and unrelated machines with bipartite\n  incompatibility graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of scheduling of jobs on parallel machines under\nincompatibility relation is considered. In this model a binary relation between\njobs is given and no two jobs that are in the relation can be scheduled on the\nsame machine. In particular, we consider job scheduling under incompatibility\nrelation forming bipartite graphs, under makespan optimality criterion, on\nuniform and unrelated machines. We show that no algorithm can achieve a good\napproximation ratio for uniform machines, even for a case of unit time jobs,\nunder $P \\neq NP$. We also provide an approximation algorithm that achieves the\nbest possible approximation ratio, even for the case of jobs of arbitrary\nlengths $p_j$, under the same assumption. Precisely, we present an\n$O(n^{1/2-\\epsilon})$ inapproximability bound, for any $\\epsilon > 0$; and\n$\\sqrt{p_{sum}}$-approximation algorithm, respectively. To enrich the analysis,\nbipartite graphs generated randomly according to Gilbert's model\n$\\mathcal{G}_{n,n,p(n)}$ are considered. For a broad class of $p(n)$ functions\nwe show that there exists an algorithm producing a schedule with makespan\nalmost surely at most twice the optimum. Due to our knowledge, this is the\nfirst study of randomly generated graphs in the context of scheduling in the\nconsidered model.\n  For unrelated machines, an FPTAS for $R2|G = bipartite|C_{\\max}$ is provided.\nWe also show that there is no algorithm of approximation ratio\n$O(n^bp_{\\max}^{1-\\epsilon})$, even for $Rm|G = bipartite|C_{max}$ for $m \\ge\n3$ and any $\\epsilon > 0$, $b > 0$, unless $P = NP$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:43:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Pikies", "Tytus", ""], ["Furma\u0144czyk", "Hanna", ""]]}, {"id": "2106.14454", "submitter": "David Weckbecker", "authors": "Yann Disser and Max Klimm and David Weckbecker", "title": "Fractionally Subadditive Maximization under an Incremental Knapsack\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a fractionally subadditive function\nunder a knapsack constraint that grows over time. An incremental solution to\nthis problem is given by an order in which to include the elements of the\nground set, and the competitive ratio of an incremental solution is defined by\nthe worst ratio over all capacities relative to an optimum solution of the\ncorresponding capacity. We present an algorithm that finds an incremental\nsolution of competitive ratio at most $\\max\\{3.293\\sqrt{M},2M\\}$, under the\nassumption that the values of singleton sets are in the range $[1,M]$, and we\ngive a lower bound of $\\max\\{2.449,M\\}$ on the attainable competitive ratio. In\naddition, we establish that our framework captures potential-based flows\nbetween two vertices, and we give a tight bound of~$2$ for the incremental\nmaximization of classical flows with unit capacities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 08:14:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Disser", "Yann", ""], ["Klimm", "Max", ""], ["Weckbecker", "David", ""]]}, {"id": "2106.14601", "submitter": "Till Heller", "authors": "T. Heller and S.O. Krumke and K.-H. K\\\"ufer", "title": "The Reward-Penalty-Selection Problem", "comments": "24 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Set Cover Problem (SCP) and the Hitting Set Problem (HSP) are\nwell-studied optimization problems. In this paper we introduce the\nReward-Penalty-Selection Problem (RPSP) which can be understood as a\ncombination of the SCP and the HSP where the objectives of both problems are\ncontrary to each other. Applications of the RPSP can be found in the context of\ncombinatorial exchanges in order to solve the corresponding winner\ndetermination problem. We give complexity results for the minimization and the\nmaximization problem as well as for several variants with additional\nrestrictions. Further, we provide an algorithm that runs in polynomial time for\nthe special case of laminar sets and a dynamic programming approach for the\ncase where the instance can be represented by a tree or a graph with bounded\ntree-width. We further present a graph theoretical generalization of this\nproblem and results regarding its complexity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:12:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Heller", "T.", ""], ["Krumke", "S. O.", ""], ["K\u00fcfer", "K. -H.", ""]]}, {"id": "2106.14756", "submitter": "Wolfgang Ost", "authors": "Hendrik Fichtenberger, Monika Henzinger, Wolfgang Ost", "title": "Differentially Private Algorithms for Graphs Under Continual Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentially private algorithms protect individuals in data analysis\nscenarios by ensuring that there is only a weak correlation between the\nexistence of the user in the data and the result of the analysis. Dynamic graph\nalgorithms maintain the solution to a problem (e.g., a matching) on an evolving\ninput, i.e., a graph where nodes or edges are inserted or deleted over time.\nThey output the value of the solution after each update operation, i.e.,\ncontinuously. We study (event-level and user-level) differentially private\nalgorithms for graph problems under continual observation, i.e., differentially\nprivate dynamic graph algorithms. We present event-level private algorithms for\npartially dynamic counting-based problems such as triangle count that improve\nthe additive error by a polynomial factor (in the length $T$ of the update\nsequence) on the state of the art, resulting in the first algorithms with\nadditive error polylogarithmic in $T$.\n  We also give $\\varepsilon$-differentially private and partially dynamic\nalgorithms for minimum spanning tree, minimum cut, densest subgraph, and\nmaximum matching. The additive error of our improved MST algorithm is $O(W\n\\log^{3/2}T / \\varepsilon)$, where $W$ is the maximum weight of any edge,\nwhich, as we show, is tight up to a $(\\sqrt{\\log T} / \\varepsilon)$-factor. For\nthe other problems, we present a partially-dynamic algorithm with\nmultiplicative error $(1+\\beta)$ for any constant $\\beta > 0$ and additive\nerror $O(W \\log(nW) \\log(T) / (\\varepsilon \\beta) )$. Finally, we show that the\nadditive error for a broad class of dynamic graph algorithms with user-level\nprivacy must be linear in the value of the output solution's range.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:31:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Henzinger", "Monika", ""], ["Ost", "Wolfgang", ""]]}, {"id": "2106.14757", "submitter": "Stanislav \\v{Z}ivn\\'y", "authors": "Eden Pelleg and Stanislav \\v{Z}ivn\\'y", "title": "Additive Sparsification of CSPs", "comments": "Full version of an ESA'21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplicative cut sparsifiers, introduced by Bencz\\'ur and Karger [STOC'96],\nhave proved extremely influential and found various applications. Precise\ncharacterisations were established for sparsifiability of graphs with other\n2-variable predicates on Boolean domains by Filtser and Krauthgamer [SIDMA'17]\nand non-Boolean domains by Butti and \\v{Z}ivn\\'y [SIDMA'20].\n  Bansal, Svensson and Trevisan [FOCS'19] introduced a weaker notion of\nsparsification termed \"additive sparsification\", which does not require weights\non the edges of the graph. In particular, Bansal et al. designed algorithms for\nadditive sparsifiers for cuts in graphs and hypergraphs.\n  As our main result, we establish that all Boolean Constraint Satisfaction\nProblems (CSPs) admit an additive sparsifier; that is, for every Boolean\npredicate $P:\\{0,1\\}^k\\to\\{0,1\\}$ of a fixed arity $k$, we show that CSP($P$)\nadmits an additive sparsifier. Under our newly introduced notion of all-but-one\nsparsification for non-Boolean predicates, we show that CSP($P$) admits an\nadditive sparsifier for any predicate $P:D^k\\to\\{0,1\\}$ of a fixed arity $k$ on\nan arbitrary finite domain $D$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:32:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Pelleg", "Eden", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "2106.14805", "submitter": "Simon D. Fink", "authors": "Simon D. Fink, Matthias Pfretzschner, Ignaz Rutter", "title": "Experimental Comparison of PC-Trees and PQ-Trees", "comments": "to appear in Proceedings of ESA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PQ-trees and PC-trees are data structures that represent sets of linear and\ncircular orders, respectively, subject to constraints that specific subsets of\nelements have to be consecutive. While equivalent to each other, PC-trees are\nconceptually much simpler than PQ-trees; updating a PC-trees so that a set of\nelements becomes consecutive requires only a single operation, whereas PQ-trees\nuse an update procedure that is described in terms of nine transformation\ntemplates that have to be recursively matched and applied.\n  Despite these theoretical advantages, to date no practical PC-tree\nimplementation is available. This might be due to the original description by\nHsu and McConnell in some places only sketching the details of the\nimplementation. In this paper, we describe two alternative implementations of\nPC-trees. For the first one, we follow the approach by Hsu and McConnell,\nfilling in the necessary details and also proposing improvements on the\noriginal algorithm. For the second one, we use a different technique for\nefficiently representing the tree using a Union-Find data structure. In an\nextensive experimental evaluation we compare our implementations to a variety\nof other implementations of PQ-trees that are available on the web as part of\nacademic and other software libraries. Our results show that both PC-tree\nimplementations beat their closest fully correct competitor, the PQ-tree\nimplementation from the OGDF library, by a factor of 2 to 4, showing that\nPC-trees are not only conceptually simpler but also fast in practice. Moreover,\nwe find the Union-Find-based implementation, while having a slightly worse\nasymptotic runtime, to be twice as fast as the one based on the description by\nHsu and McConnell.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:28:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fink", "Simon D.", ""], ["Pfretzschner", "Matthias", ""], ["Rutter", "Ignaz", ""]]}, {"id": "2106.14840", "submitter": "Weihang Wang", "authors": "Karthekeyan Chandrasekaran, Weihang Wang", "title": "$\\ell_p$-norm Multiway Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study $\\ell_p$-norm-multiway-cut: the input here is an\nundirected graph with non-negative edge weights along with $k$ terminals and\nthe goal is to find a partition of the vertex set into $k$ parts each\ncontaining exactly one terminal so as to minimize the $\\ell_p$-norm of the cut\nvalues of the parts. This is a unified generalization of min-sum multiway cut\n(when $p=1$) and min-max multiway cut (when $p=\\infty$), both of which are\nwell-studied classic problems in the graph partitioning literature. We show\nthat $\\ell_p$-norm-multiway-cut is NP-hard for constant number of terminals and\nis NP-hard in planar graphs. On the algorithmic side, we design an $O(\\log^2\nn)$-approximation for all $p\\ge 1$. We also show an integrality gap of\n$\\Omega(k^{1-1/p})$ for a natural convex program and an\n$O(k^{1-1/p-\\epsilon})$-inapproximability for any constant $\\epsilon>0$\nassuming the small set expansion hypothesis.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:36:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Wang", "Weihang", ""]]}, {"id": "2106.14869", "submitter": "Daniel Neuen", "authors": "Daniel Neuen", "title": "Isomorphism Testing Parameterized by Genus and Beyond", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an isomorphism test for graphs of Euler genus $g$ running in time\n$2^{O(g^4 \\log g)}n^{O(1)}$. Our algorithm provides the first explicit upper\nbound on the dependence on $g$ for an fpt isomorphism test parameterized by the\nEuler genus of the input graphs. The only previous fpt algorithm runs in time\n$f(g)n$ for some function $f$ (Kawarabayashi 2015). Actually, our algorithm\neven works when the input graphs only exclude $K_{3,h}$ as a minor. For such\ngraphs, no fpt isomorphism test was known before.\n  The algorithm builds on an elegant combination of simple group-theoretic,\ncombinatorial, and graph-theoretic approaches. In particular, we introduce\n$(t,k)$-WL-bounded graphs which provide a powerful tool to combine\ngroup-theoretic techniques with the standard Weisfeiler-Leman algorithm. This\nconcept may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:40:53 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Neuen", "Daniel", ""]]}, {"id": "2106.14935", "submitter": "Katharina Klost", "authors": "Haim Kaplan, Alexander Kauer, Katharina Klost, Kristin Knorr, Wolfgang\n  Mulzer, Liam Roditty and Paul Seiferth", "title": "Dynamic Connectivity in Disk Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $S$ be a set of $n$ sites, each associated with a point in $\\mathbb{R}^2$\nand a radius $r_s$ and let $\\mathcal{D}(S)$ be the disk graph on $S$. We\nconsider the problem of designing data structures that maintain the\nconnectivity structure of $\\mathcal{D}(S)$ while allowing the insertion and\ndeletion of sites. For unit disk graphs we describe a data structure that has\n$O(\\log^2n)$ amortized update time and $O((\\log n)/(\\log\\log n))$ amortized\nquery time.\n  For disk graphs where the ratio $\\Psi$ between the largest and smallest\nradius is bounded, we consider the decremental and the incremental case\nseparately, in addition to the fully dynamic case. In the fully dynamic case we\nachieve amortized $O(\\Psi \\lambda_6(\\log n) \\log^{9}n)$ update time and $O(\\log\nn)$ query time, where $\\lambda_s(n)$ is the maximum length of a\nDavenport-Schinzel sequence of order $s$ on $n$ symbols. This improves the\nupdate time of the currently best known data structure by a factor of $\\Psi$ at\nthe cost of an additional $O(\\log \\log n)$ factor in the query time. In the\nincremental case we manage to achieve a logarithmic dependency on $\\Psi$ with a\ndata structure with $O(\\alpha(n))$ query and $O(\\log\\Psi \\lambda_6(\\log n)\n\\log^{9}n)$ update time.\n  For the decremental setting we first develop a new dynamic data structure\nthat allows us to maintain two sets $B$ and $P$ of disks, such than at a\ndeletion of a disk from $B$ we can efficiently report all disks in $P$ that no\nlonger intersect any disk of $B$. Having this data structure at hand, we get\ndecremental data structures with an amortized query time of $O((\\log n)/(\\log\n\\log n))$ supporting $m$ deletions in $O((n\\log^{5}n + m \\log^{9}n)\n\\lambda_6(\\log n) + n\\log\\Psi\\log^4n)$ overall time for bounded radius ratio\n$\\Psi$ and $O(( n\\log^{6} n + m \\log^{10}n) \\lambda_6(\\log n))$ for general\ndisk graphs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 18:32:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kaplan", "Haim", ""], ["Kauer", "Alexander", ""], ["Klost", "Katharina", ""], ["Knorr", "Kristin", ""], ["Mulzer", "Wolfgang", ""], ["Roditty", "Liam", ""], ["Seiferth", "Paul", ""]]}, {"id": "2106.14952", "submitter": "Samson Zhou", "authors": "Vladimir Braverman, Avinatan Hassidim, Yossi Matias, Mariano Schain,\n  Sandeep Silwal, Samson Zhou", "title": "Adversarial Robustness of Streaming Algorithms through Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce adversarially robust streaming algorithms for\ncentral machine learning and algorithmic tasks, such as regression and\nclustering, as well as their more general counterparts, subspace embedding,\nlow-rank approximation, and coreset construction. For regression and other\nnumerical linear algebra related tasks, we consider the row arrival streaming\nmodel. Our results are based on a simple, but powerful, observation that many\nimportance sampling-based algorithms give rise to adversarial robustness which\nis in contrast to sketching based algorithms, which are very prevalent in the\nstreaming literature but suffer from adversarial attacks. In addition, we show\nthat the well-known merge and reduce paradigm in streaming is adversarially\nrobust. Since the merge and reduce paradigm allows coreset constructions in the\nstreaming setting, we thus obtain robust algorithms for $k$-means, $k$-median,\n$k$-center, Bregman clustering, projective clustering, principal component\nanalysis (PCA) and non-negative matrix factorization. To the best of our\nknowledge, these are the first adversarially robust results for these problems\nyet require no new algorithmic implementations. Finally, we empirically confirm\nthe robustness of our algorithms on various adversarial attacks and demonstrate\nthat by contrast, some common existing algorithms are not robust.\n  (Abstract shortened to meet arXiv limits)\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 19:24:11 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Braverman", "Vladimir", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""], ["Schain", "Mariano", ""], ["Silwal", "Sandeep", ""], ["Zhou", "Samson", ""]]}, {"id": "2106.14969", "submitter": "Arnold Filtser", "authors": "Arnold Filtser", "title": "Hop-Constrained Metric Embeddings and their Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In network design problems, such as compact routing, the goal is to route\npackets between nodes using the (approximated) shortest paths. A desirable\nproperty of these routes is a small number of hops, which makes them more\nreliable, and reduces the transmission costs. Following the overwhelming\nsuccess of stochastic tree embeddings for algorithmic design, Haeupler,\nHershkowitz, and Zuzic (STOC'21) studied hop-constrained Ramsey-type metric\nembeddings into trees. Specifically, embedding $f:G(V,E)\\rightarrow T$ has\nRamsey hop-distortion $(t,M,\\beta,h)$ (here $t,\\beta,h\\ge1$ and $M\\subseteq V$)\nif $\\forall u,v\\in M$, $d_G^{(\\beta\\cdot h)}(u,v)\\le d_T(u,v)\\le t\\cdot\nd_G^{(h)}(u,v)$. $t$ is called the distortion, $\\beta$ is called the\nhop-stretch, and $d_G^{(h)}(u,v)$ denotes the minimum weight of a $u-v$ path\nwith at most $h$ hops. Haeupler {\\em et al.} constructed embedding where $M$\ncontains $1-\\epsilon$ fraction of the vertices and $\\beta=t=O(\\frac{\\log^2\nn}{\\epsilon})$. They used their embedding to obtain multiple bicriteria\napproximation algorithms for hop-constrained network design problems.\n  In this paper, we first improve the Ramsey-type embedding to obtain\nparameters $t=\\beta=\\frac{\\tilde{O}(\\log n)}{\\epsilon}$, and generalize it to\narbitrary distortion parameter $t$ (in the cost of reducing the size of $M$).\nThis embedding immediately implies polynomial improvements for all the\napproximation algorithms from Haeupler {\\em et al.}. Further, we construct\nhop-constrained clan embeddings (where each vertex has multiple copies), and\nuse them to construct bicriteria approximation algorithms for the group Steiner\ntree problem, matching the state of the art of the non constrained version.\nFinally, we use our embedding results to construct hop constrained distance\noracles, distance labeling, and most prominently, the first hop constrained\ncompact routing scheme with provable guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:23:26 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Filtser", "Arnold", ""]]}, {"id": "2106.14980", "submitter": "Christoph Glanzer", "authors": "Christoph Glanzer, Ingo Stallknecht, Robert Weismantel", "title": "Notes on $\\{a,b,c\\}$-Modular Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A \\in \\mathbb{Z}^{m \\times n}$ be an integral matrix and $a$, $b$, $c\n\\in \\mathbb{Z}$ satisfy $a \\geq b \\geq c \\geq 0$. The question is to recognize\nwhether $A$ is $\\{a,b,c\\}$-modular, i.e., whether the set of $n \\times n$\nsubdeterminants of $A$ in absolute value is $\\{a,b,c\\}$. We will succeed in\nsolving this problem in polynomial time unless $A$ possesses a duplicative\nrelation, that is, $A$ has nonzero $n \\times n$ subdeterminants $k_1$ and $k_2$\nsatisfying $2 \\cdot |k_1| = |k_2|$. This is an extension of the well-known\nrecognition algorithm for totally unimodular matrices. As a consequence of our\nanalysis, we present a polynomial time algorithm to solve integer programs in\nstandard form over $\\{a,b,c\\}$-modular constraint matrices for any constants\n$a$, $b$ and $c$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:53:28 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Glanzer", "Christoph", ""], ["Stallknecht", "Ingo", ""], ["Weismantel", "Robert", ""]]}, {"id": "2106.15034", "submitter": "Aditya Jayaprakash", "authors": "Aditya Jayaprakash and Mohammad R. Salavatipour", "title": "Approximation Schemes for Capacitated Vehicle Routing on Graphs of\n  Bounded Treewidth, Bounded Doubling, or Highway Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Approximation Schemes for Capacitated Vehicle\nRouting Problem (CVRP) on several classes of graphs. In CVRP, introduced by\nDantzig and Ramser (1959), we are given a graph $G=(V,E)$ with metric edges\ncosts, a depot $r\\in V$, and a vehicle of bounded capacity $Q$. The goal is to\nfind minimum cost collection of tours for the vehicle that returns to the\ndepot, each visiting at most $Q$ nodes, such that they cover all the nodes.\nThis generalizes classic TSP and has been studied extensively. In the more\ngeneral setting, each node $v$ has a demand $d_v$ and the total demand of each\ntour must be no more than $Q$. Either the demand of each node must be served by\none tour (unsplittable) or can be served by multiple tour (splittable). The\nbest known approximation algorithm for general graphs has ratio\n$\\alpha+2(1-\\epsilon)$ (for the unsplittable) and $\\alpha+1-\\epsilon$ (for the\nsplittable) for some fixed $\\epsilon>\\frac{1}{3000}$, where $\\alpha$ is the\nbest approximation for TSP. Even for the case of trees, the best approximation\nratio is $4/3$ by Becker (2018) and it has been an open question if there is an\napproximation scheme for this simple class of graphs. Das and Mathieu (2015)\npresented an approximation scheme with time $n^{\\log^{O(1/\\epsilon)}n}$ for\nEuclidean plane $\\mathbb{R}^2$. No other approximation scheme is known for any\nother class of metrics (without further restrictions on $Q$). In this paper, we\nmake significant progress on this classic problem by presenting\nQuasi-Polynomial Time Approximation Schemes (QPTAS) for graphs of bounded\ntreewidth, graphs of bounded highway dimensions, and graphs of bounded doubling\ndimensions. For comparison, our result implies an approximation scheme for\nEuclidean plane with run time $n^{O(\\log^{10}n/\\epsilon^{9})}$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 00:01:05 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Jayaprakash", "Aditya", ""], ["Salavatipour", "Mohammad R.", ""]]}, {"id": "2106.15234", "submitter": "Hadi Khodabandeh", "authors": "David Eppstein, Hadi Khodabandeh", "title": "Optimal Spanners for Unit Ball Graphs in Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolving an open question from 2006, we prove the existence of light-weight\nbounded-degree spanners for unit ball graphs in the metrics of bounded doubling\ndimension, and we design a simple $\\mathcal{O}(\\log^*n)$-round distributed\nalgorithm that given a unit ball graph $G$ with $n$ vertices and a positive\nconstant $\\epsilon < 1$ finds a $(1+\\epsilon)$-spanner with constant bounds on\nits maximum degree and its lightness using only 2-hop neighborhood information.\nThis immediately improves the algorithm of Damian, Pandit, and Pemmaraju which\nruns in $\\mathcal{O}(\\log^*n)$ rounds but has a $\\mathcal{O}(\\log \\Delta)$\nbound on its lightness, where $\\Delta$ is the ratio of the length of the\nlongest edge in $G$ to the length of the shortest edge. We further study the\nproblem in the two dimensional Euclidean plane and we provide a construction\nwith similar properties that has a constant average number of edge intersection\nper node. This is the first distributed low-intersection topology control\nalgorithm to the best of our knowledge. Our distributed algorithms rely on the\nmaximal independent set algorithm of Schneider and Wattenhofer that runs in\n$\\mathcal{O}(\\log^*n)$ rounds of communication. If a maximal independent set is\nknown beforehand, our algorithms run in constant number of rounds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:36:37 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Eppstein", "David", ""], ["Khodabandeh", "Hadi", ""]]}, {"id": "2106.15393", "submitter": "Daniel Schmidt genannt Waldschmidt", "authors": "Guillaume Sagnol and Daniel Schmidt genannt Waldschmidt", "title": "Restricted Adaptivity in Stochastic Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic scheduling problem of minimizing the expected\nmakespan on $m$ parallel identical machines. While the (adaptive) list\nscheduling policy achieves an approximation ratio of $2$, any (non-adaptive)\nfixed assignment policy has performance guarantee $\\Omega\\left(\\frac{\\log\nm}{\\log \\log m}\\right)$. Although the performance of the latter class of\npolicies are worse, there are applications in which non-adaptive policies are\ndesired. In this work, we introduce the two classes of $\\delta$-delay and\n$\\tau$-shift policies whose degree of adaptivity can be controlled by a\nparameter. We present a policy - belonging to both classes - which is an\n$\\mathcal{O}(\\log \\log m)$-approximation for reasonably bounded parameters. In\nother words, an exponential improvement on the performance of any fixed\nassignment policy can be achieved when allowing a small degree of adaptivity.\nMoreover, we provide a matching lower bound for any $\\delta$-delay and\n$\\tau$-shift policy when both parameters, respectively, are in the order of the\nexpected makespan of an optimal non-anticipatory policy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:27:42 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sagnol", "Guillaume", ""], ["Waldschmidt", "Daniel Schmidt genannt", ""]]}, {"id": "2106.15524", "submitter": "Kathrin Hanauer", "authors": "Kathrin Hanauer, Monika Henzinger, and Qi Cheng Hua", "title": "Fully Dynamic Four-Vertex Subgraph Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comprehensive study of algorithms for maintaining the\nnumber of all connected four-vertex subgraphs in a dynamic graph. Specifically,\nour algorithms maintain the number of any four-vertex subgraph, which is not a\nclique, in deterministic amortized update time $\\mathcal{O}(m^{1/2})$, resp.,\n$\\mathcal{O}(m^{2/3})$. Queries can be answered in constant time. For length-3\npaths, paws, 4-cycles, and diamonds these bounds match or are not far from\n(conditional) lower bounds: Based on the OMv conjecture we show that any\ndynamic algorithm that detects the existence of length-3 paths, 4-cycles,\ndiamonds, or 4-cliques takes amortized update time $\\Omega(m^{1/2-\\delta})$.\n  Additionally, for 4-cliques and all connected induced subgraphs, we show a\nlower bound of $\\Omega(m^{1-\\delta})$ for any small constant $\\delta > 0$ for\nthe amortized update time, assuming the static combinatorial 4-clique\nconjecture holds. This shows that the $\\mathcal{O}(m)$ algorithm by Eppstein et\nal. [9] for these subgraphs cannot be improved by a polynomial factor.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:52:23 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 10:43:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hanauer", "Kathrin", ""], ["Henzinger", "Monika", ""], ["Hua", "Qi Cheng", ""]]}, {"id": "2106.15549", "submitter": "Avah Banerjee", "authors": "Avah Banerjee, Guoli Ding, Maxwell Reeser", "title": "Distributed Matrix Tiling Using A Hypergraph Labeling Formulation", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partitioning large matrices is an important problem in distributed linear\nalgebra computing (used in ML among others). Briefly, our goal is to perform a\nsequence of matrix algebra operations in a distributed manner (whenever\npossible) on these large matrices. However, not all partitioning schemes work\nwell with different matrix algebra operations and their implementations\n(algorithms). This is a type of data tiling problem. In this work we consider a\ntheoretical model for a version of the matrix tiling problem in the setting of\nhypergraph labeling. We prove some hardness results and give a theoretical\ncharacterization of its complexity on random instances. Additionally we develop\na greedy algorithm and experimentally show its efficacy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:35:50 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Banerjee", "Avah", ""], ["Ding", "Guoli", ""], ["Reeser", "Maxwell", ""]]}, {"id": "2106.15566", "submitter": "Lunjia Hu", "authors": "Moses Charikar, Lunjia Hu", "title": "Near-Optimal Explainable $k$-Means for All Dimensions", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clustering algorithms are guided by certain cost functions such as the\nwidely-used $k$-means cost. These algorithms divide data points into clusters\nwith often complicated boundaries, creating difficulties in explaining the\nclustering decision. In a recent work, Dasgupta, Frost, Moshkovitz, and\nRashtchian (ICML'20) introduced explainable clustering, where the cluster\nboundaries are axis-parallel hyperplanes and the clustering is obtained by\napplying a decision tree to the data. The central question here is: how much\ndoes the explainability constraint increase the value of the cost function?\n  Given $d$-dimensional data points, we show an efficient algorithm that finds\nan explainable clustering whose $k$-means cost is at most $k^{1 -\n2/d}\\mathrm{poly}(d\\log k)$ times the minimum cost achievable by a clustering\nwithout the explainability constraint, assuming $k,d\\ge 2$. Combining this with\nan independent work by Makarychev and Shan (ICML'21), we get an improved bound\nof $k^{1 - 2/d}\\mathrm{polylog}(k)$, which we show is optimal for every choice\nof $k,d\\ge 2$ up to a poly-logarithmic factor in $k$. For $d = 2$ in\nparticular, we show an $O(\\log k\\log\\log k)$ bound, improving exponentially\nover the previous best bound of $\\widetilde O(k)$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:59:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Charikar", "Moses", ""], ["Hu", "Lunjia", ""]]}, {"id": "2106.15596", "submitter": "Hung Le", "authors": "Hung Le and Shay Solomon", "title": "Towards a Unified Theory of Light Spanners I: Fast (Yet Optimal)\n  Constructions", "comments": "55 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seminal works on light spanners over the years provide spanners with optimal\nor near-optimal lightness in various graph classes, such as in general graphs,\nEuclidean spanners, and minor-free graphs. Two shortcomings of all previous\nwork on light spanners are: (1) The techniques are ad hoc per graph class, and\nthus can't be applied broadly (e.g., some require large stretch and are thus\nsuitable to general graphs, while others are naturally suitable to stretch $1 +\n\\epsilon$). (2) The runtimes of these constructions are almost always\nsub-optimal, and usually far from optimal.\n  This work aims at initiating a unified theory of light spanners by presenting\na single framework that can be used to construct light spanners in a variety of\ngraph classes. This theory is developed in two papers. The current paper is the\nfirst of the two -- it lays the foundations of the theory of light spanners and\nthen applies it to design fast constructions with optimal lightness for several\ngraph classes. Our new constructions are significantly faster than the\nstate-of-the-art for every examined graph class; moreover, our runtimes are\nnear-linear and usually optimal.\n  Specifically, this paper includes the following results: (i) An $O(m\n\\alpha(m,n))$-time construction of $(2k-1)(1+\\epsilon)$-spanner with lightness\n$O(n^{1/k})$ for general graphs; (ii) An $O(n\\log n)$-time construction of\nEuclidean $(1+\\epsilon)$-spanners with lightness and degree both bounded by\nconstants in the basic algebraic computation tree (ACT) model. This\nconstruction resolves a major problem in the area of geometric spanners, which\nwas open for three decades; (iii) An $O(n\\log n)$-time construction of\n$(1+\\epsilon)$-spanners with constant lightness and degree, in the ACT model\nfor unit disk graphs; (iv) a linear-time algorithm for constructing\n$(1+\\epsilon)$-spanners with constant lightness for minor-free graphs.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:32:22 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 21:10:55 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Le", "Hung", ""], ["Solomon", "Shay", ""]]}, {"id": "2106.15662", "submitter": "Mingda Qiao", "authors": "Mingda Qiao, Gregory Valiant", "title": "Exponential Weights Algorithms for Selective Learning", "comments": "To appear in COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the selective learning problem introduced by Qiao and Valiant\n(2019), in which the learner observes $n$ labeled data points one at a time. At\na time of its choosing, the learner selects a window length $w$ and a model\n$\\hat\\ell$ from the model class $\\mathcal{L}$, and then labels the next $w$\ndata points using $\\hat\\ell$. The excess risk incurred by the learner is\ndefined as the difference between the average loss of $\\hat\\ell$ over those $w$\ndata points and the smallest possible average loss among all models in\n$\\mathcal{L}$ over those $w$ data points.\n  We give an improved algorithm, termed the hybrid exponential weights\nalgorithm, that achieves an expected excess risk of $O((\\log\\log|\\mathcal{L}| +\n\\log\\log n)/\\log n)$. This result gives a doubly exponential improvement in the\ndependence on $|\\mathcal{L}|$ over the best known bound of\n$O(\\sqrt{|\\mathcal{L}|/\\log n})$. We complement the positive result with an\nalmost matching lower bound, which suggests the worst-case optimality of the\nalgorithm.\n  We also study a more restrictive family of learning algorithms that are\nbounded-recall in the sense that when a prediction window of length $w$ is\nchosen, the learner's decision only depends on the most recent $w$ data points.\nWe analyze an exponential weights variant of the ERM algorithm in Qiao and\nValiant (2019). This new algorithm achieves an expected excess risk of\n$O(\\sqrt{\\log |\\mathcal{L}|/\\log n})$, which is shown to be nearly optimal\namong all bounded-recall learners. Our analysis builds on a generalized version\nof the selective mean prediction problem in Drucker (2013); Qiao and Valiant\n(2019), which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:14:01 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Qiao", "Mingda", ""], ["Valiant", "Gregory", ""]]}, {"id": "2106.15731", "submitter": "Martin Schirneck", "authors": "Davide Bil\\`o, Sarel Cohen, Tobias Friedrich and Martin Schirneck", "title": "Near-Optimal Deterministic Single-Source Distance Sensitivity Oracles", "comments": "Full version of a paper to appear at ESA 2021. Abstract shortened to\n  meet ArXiv requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a graph with a source vertex $s$, the Single Source Replacement Paths\n(SSRP) problem is to compute, for every vertex $t$ and edge $e$, the length\n$d(s,t,e)$ of a shortest path from $s$ to $t$ that avoids $e$. A Single-Source\nDistance Sensitivity Oracle (Single-Source DSO) is a data structure that\nanswers queries of the form $(t,e)$ by returning the distance $d(s,t,e)$. We\nshow how to deterministically compress the output of the SSRP problem on\n$n$-vertex, $m$-edge graphs with integer edge weights in the range $[1,M]$ into\na Single-Source DSO of size $O(M^{1/2}n^{3/2})$ with query time\n$\\widetilde{O}(1)$. The space requirement is optimal (up to the word size) and\nour techniques can also handle vertex failures.\n  Chechik and Cohen [SODA 2019] presented a combinatorial, randomized\n$\\widetilde{O}(m\\sqrt{n}+n^2)$ time SSRP algorithm for undirected and\nunweighted graphs. Grandoni and Vassilevska Williams [FOCS 2012, TALG 2020]\ngave an algebraic, randomized $\\widetilde{O}(Mn^\\omega)$ time SSRP algorithm\nfor graphs with integer edge weights in the range $[1,M]$, where $\\omega<2.373$\nis the matrix multiplication exponent. We derandomize both algorithms for\nundirected graphs in the same asymptotic running time and apply our compression\nto obtain deterministic Single-Source DSOs. The $\\widetilde{O}(m\\sqrt{n}+n^2)$\nand $\\widetilde{O}(Mn^\\omega)$ preprocessing times are polynomial improvements\nover previous $o(n^2)$-space oracles.\n  On sparse graphs with $m=O(n^{5/4-\\varepsilon}/M^{7/4})$ edges, for any\nconstant $\\varepsilon > 0$, we reduce the preprocessing to randomized\n$\\widetilde{O}(M^{7/8}m^{1/2}n^{11/8})=O(n^{2-\\varepsilon/2})$ time. This is\nthe first truly subquadratic time algorithm for building Single-Source DSOs on\nsparse graphs.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:37:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bil\u00f2", "Davide", ""], ["Cohen", "Sarel", ""], ["Friedrich", "Tobias", ""], ["Schirneck", "Martin", ""]]}, {"id": "2106.15740", "submitter": "Danylo Lykov", "authors": "Danylo Lykov, Yuri Alexeev", "title": "Importance of Diagonal Gates in Tensor Network Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present two techniques that tremendously increase the\nperformance of tensor-network based quantum circuit simulations. The techniques\nare implemented in the QTensor package and benchmarked using Quantum\nApproximate Optimization Algorithm (QAOA) circuits. The techniques allowed us\nto increase the depth and size of QAOA circuits that can be simulated. In\nparticular, we increased the QAOA depth from 2 to 5 and the size of a QAOA\ncircuit from 180 to 244 qubits. Moreover, we increased the speed of simulations\nby up to 10 million times. Our work provides important insights into how\nvarious techniques can dramatically speed up the simulations of circuits.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:55:11 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lykov", "Danylo", ""], ["Alexeev", "Yuri", ""]]}, {"id": "2106.15901", "submitter": "Ulrich Pferschy", "authors": "Gaia Nicosia, Andrea Pacifici, Ulrich Pferschy, Julia Resch, Giovanni\n  Righini", "title": "Optimally rescheduling jobs with a LIFO buffer", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers single-machine scheduling problems in which a given\nsolution, i.e. an ordered set of jobs, has to be improved as much as possible\nby re-sequencing the jobs. The need for rescheduling may arise in different\ncontexts, e.g. due to changes in the job data or because of the local objective\nin a stage of a supply chain \\red{that is} not aligned with the given sequence.\nA common production setting entails the movement of jobs (or parts) on a\nconveyor. This is reflected in our model by facilitating the re-sequencing of\njobs via a buffer of limited capacity accessible by a LIFO policy. We consider\nthe classical objective functions of total weighted completion time, maximum\nlateness and (weighted) number of late jobs and study their complexity. For\nthree of these problems we present strictly polynomial-time dynamic programming\nalgorithms, while for the case of minimizing the weighted number of late jobs\nNP-hardness is proven and a pseudo-polynomial algorithm is given.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:42:58 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Nicosia", "Gaia", ""], ["Pacifici", "Andrea", ""], ["Pferschy", "Ulrich", ""], ["Resch", "Julia", ""], ["Righini", "Giovanni", ""]]}, {"id": "2106.15992", "submitter": "Konrad Anand", "authors": "Konrad Anand and Mark Jerrum", "title": "Perfect Sampling in Infinite Spin Systems via Strong Spatial Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple algorithm that perfectly samples configurations from the\nunique Gibbs measure of a spin system on a potentially infinite graph $G$. The\nsampling algorithm assumes strong spatial mixing together with subexponential\ngrowth of $G$. It produces a finite window onto a perfect sample from the Gibbs\ndistribution. The run-time is linear in the size of the window.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:35:18 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Anand", "Konrad", ""], ["Jerrum", "Mark", ""]]}, {"id": "2106.16015", "submitter": "Hugo Jacob", "authors": "Hugo Jacob, Thomas Bellitto, Oscar Defrain, Marcin Pilipczuk", "title": "Close relatives (of Feedback Vertex Set), revisited", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At IPEC 2020, Bergougnoux, Bonnet, Brettell, and Kwon showed that a number of\nproblems related to the classic Feedback Vertex Set (FVS) problem do not admit\na $2^{o(k \\log k)} \\cdot n^{\\mathcal{O}(1)}$-time algorithm on graphs of\ntreewidth at most $k$, assuming the Exponential Time Hypothesis. This contrasts\nwith the $3^{k} \\cdot k^{\\mathcal{O}(1)} \\cdot n$-time algorithm for FVS using\nthe Cut&Count technique.\n  During their live talk at IPEC 2020, Bergougnoux et al.~posed a number of\nopen questions, which we answer in this work.\n  - Subset Even Cycle Transversal, Subset Odd Cycle Transversal, Subset\nFeedback Vertex Set can be solved in time $2^{\\mathcal{O}(k \\log k)} \\cdot n$\nin graphs of treewidth at most $k$. This matches a lower bound for Even Cycle\nTransversal of Bergougnoux et al.~and improves the polynomial factor in some of\ntheir upper bounds.\n  - Subset Feedback Vertex Set and Node Multiway Cut can be solved in time\n$2^{\\mathcal{O}(k \\log k)} \\cdot n$, if the input graph is given as a\nclique-width expression of size $n$ and width $k$.\n  - Odd Cycle Transversal can be solved in time $4^k \\cdot k^{\\mathcal{O}(1)}\n\\cdot n$ if the input graph is given as a clique-width expression of size $n$\nand width $k$. Furthermore, the existence of a constant $\\varepsilon > 0$ and\nan algorithm performing this task in time $(4-\\varepsilon)^k \\cdot\nn^{\\mathcal{O}(1)}$ would contradict the Strong Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 12:30:32 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jacob", "Hugo", ""], ["Bellitto", "Thomas", ""], ["Defrain", "Oscar", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "2106.16112", "submitter": "Shaofeng Jiang", "authors": "Vladimir Braverman and Shaofeng H.-C. Jiang and Robert Krauthgamer and\n  Xuan Wu", "title": "Coresets for Clustering with Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide the first coreset for clustering points in $\\mathbb{R}^d$ that\nhave multiple missing values (coordinates). Previous coreset constructions only\nallow one missing coordinate. The challenge in this setting is that objective\nfunctions, like $k$-Means, are evaluated only on the set of available\n(non-missing) coordinates, which varies across points. Recall that an\n$\\epsilon$-coreset of a large dataset is a small proxy, usually a reweighted\nsubset of points, that $(1+\\epsilon)$-approximates the clustering objective for\nevery possible center set.\n  Our coresets for $k$-Means and $k$-Median clustering have size\n$(jk)^{O(\\min(j,k))} (\\epsilon^{-1} d \\log n)^2$, where $n$ is the number of\ndata points, $d$ is the dimension and $j$ is the maximum number of missing\ncoordinates for each data point. We further design an algorithm to construct\nthese coresets in near-linear time, and consequently improve a recent\nquadratic-time PTAS for $k$-Means with missing values [Eiben et al., SODA 2021]\nto near-linear time.\n  We validate our coreset construction, which is based on importance sampling\nand is easy to implement, on various real data sets. Our coreset exhibits a\nflexible tradeoff between coreset size and accuracy, and generally outperforms\nthe uniform-sampling baseline. Furthermore, it significantly speeds up a\nLloyd's-style heuristic for $k$-Means with missing values.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:09:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Braverman", "Vladimir", ""], ["Jiang", "Shaofeng H. -C.", ""], ["Krauthgamer", "Robert", ""], ["Wu", "Xuan", ""]]}, {"id": "2106.16115", "submitter": "Rohan Ghuge", "authors": "Rohan Ghuge, Anupam Gupta, Viswanath Nagarajan", "title": "The Power of Adaptivity for Stochastic Submodular Cover", "comments": "In proceedings of ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the stochastic submodular cover problem, the goal is to select a subset of\nstochastic items of minimum expected cost to cover a submodular function.\nSolutions in this setting correspond to sequential decision processes that\nselect items one by one \"adaptively\" (depending on prior observations). While\nsuch adaptive solutions achieve the best objective, the inherently sequential\nnature makes them undesirable in many applications. We ask: how well can\nsolutions with only a few adaptive rounds approximate fully-adaptive solutions?\nWe give nearly tight answers for both independent and correlated settings,\nproving smooth tradeoffs between the number of adaptive rounds and the solution\nquality, relative to fully adaptive solutions. Experiments on synthetic and\nreal datasets show qualitative improvements in the solutions as we allow more\nrounds of adaptivity; in practice, solutions with a few rounds of adaptivity\nare nearly as good as fully adaptive solutions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:12:56 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ghuge", "Rohan", ""], ["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""]]}, {"id": "2106.16147", "submitter": "Adam Polak", "authors": "Buddhima Gamlath, Xinrui Jia, Adam Polak, Ola Svensson", "title": "Nearly-Tight and Oblivious Algorithms for Explainable Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of explainable clustering in the setting first\nformalized by Moshkovitz, Dasgupta, Rashtchian, and Frost (ICML 2020). A\n$k$-clustering is said to be explainable if it is given by a decision tree\nwhere each internal node splits data points with a threshold cut in a single\ndimension (feature), and each of the $k$ leaves corresponds to a cluster. We\ngive an algorithm that outputs an explainable clustering that loses at most a\nfactor of $O(\\log^2 k)$ compared to an optimal (not necessarily explainable)\nclustering for the $k$-medians objective, and a factor of $O(k \\log^2 k)$ for\nthe $k$-means objective. This improves over the previous best upper bounds of\n$O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\\Omega(\\log\nk)$ lower bound for $k$-medians and our new $\\Omega(k)$ lower bound for\n$k$-means. The algorithm is remarkably simple. In particular, given an initial\nnot necessarily explainable clustering in $\\mathbb{R}^d$, it is oblivious to\nthe data points and runs in time $O(dk \\log^2 k)$, independent of the number of\ndata points $n$. Our upper and lower bounds also generalize to objectives given\nby higher $\\ell_p$-norms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:49:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gamlath", "Buddhima", ""], ["Jia", "Xinrui", ""], ["Polak", "Adam", ""], ["Svensson", "Ola", ""]]}, {"id": "2106.16173", "submitter": "Andriy Miranskyy", "authors": "Mushahid Khan and Andriy Miranskyy", "title": "String Comparison on a Quantum Computer Using Hamming Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DS physics.bio-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hamming distance is ubiquitous in computing. Its computation gets\nexpensive when one needs to compare a string against many strings. Quantum\ncomputers (QCs) may speed up the comparison.\n  In this paper, we extend an existing algorithm for computing the Hamming\ndistance. The extension can compare strings with symbols drawn from an\narbitrary-long alphabet (which the original algorithm could not). We implement\nour extended algorithm using the QisKit framework to be executed by a\nprogrammer without the knowledge of a QC (the code is publicly available). We\nthen provide four pedagogical examples: two from the field of bioinformatics\nand two from the field of software engineering. We finish by discussing\nresource requirements and the time horizon of the QCs becoming practical for\nstring comparison.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:09:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Khan", "Mushahid", ""], ["Miranskyy", "Andriy", ""]]}, {"id": "2106.16180", "submitter": "Siddharth Gupta", "authors": "Siddharth Gupta, Guy Sa'ar, Meirav Zehavi", "title": "Grid Recognition: Classical and Parameterized Computational Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid graphs, and, more generally, $k\\times r$ grid graphs, form one of the\nmost basic classes of geometric graphs. Over the past few decades, a large body\nof works studied the (in)tractability of various computational problems on grid\ngraphs, which often yield substantially faster algorithms than general graphs.\nUnfortunately, the recognition of a grid graph is particularly hard -- it was\nshown to be NP-hard even on trees of pathwidth 3 already in 1987. Yet, in this\npaper, we provide several positive results in this regard in the framework of\nparameterized complexity (additionally, we present new and complementary\nhardness results). Specifically, our contribution is threefold. First, we show\nthat the problem is fixed-parameter tractable (FPT) parameterized by $k+\\mathsf\n{mcc}$ where $\\mathsf{mcc}$ is the maximum size of a connected component of\n$G$. This also implies that the problem is FPT parameterized by $\\mathtt{td}+k$\nwhere $\\mathtt{td}$ is the treedepth of $G$ (to be compared with the hardness\nfor pathwidth 2 where $k=3$). Further, we derive as a corollary that strip\npacking is FPT with respect to the height of the strip plus the maximum of the\ndimensions of the packed rectangles, which was previously only known to be in\nXP. Second, we present a new parameterization, denoted $a_G$, relating graph\ndistance to geometric distance, which may be of independent interest. We show\nthat the problem is para-NP-hard parameterized by $a_G$, but FPT parameterized\nby $a_G$ on trees, as well as FPT parameterized by $k+a_G$. Third, we show that\nthe recognition of $k\\times r$ grid graphs is NP-hard on graphs of pathwidth 2\nwhere $k=3$. Moreover, when $k$ and $r$ are unrestricted, we show that the\nproblem is NP-hard on trees of pathwidth 2, but trivially solvable in\npolynomial time on graphs of pathwidth 1.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:16:52 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gupta", "Siddharth", ""], ["Sa'ar", "Guy", ""], ["Zehavi", "Meirav", ""]]}]