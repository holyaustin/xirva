[{"id": "0707.0282", "submitter": "Igor Razgon", "authors": "Igor Razgon and Barry O'Sullivan", "title": "Directed Feedback Vertex Set is Fixed-Parameter Tractable", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": null, "abstract": "  We resolve positively a long standing open question regarding the\nfixed-parameter tractability of the parameterized Directed Feedback Vertex Set\nproblem. In particular, we propose an algorithm which solves this problem in\n$O(8^kk!*poly(n))$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 17:56:53 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Razgon", "Igor", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "0707.0421", "submitter": "Riccardo Dondi", "authors": "Paola Bonizzoni, Gianluca Della Vedova, Riccardo Dondi", "title": "The $k$-anonymity Problem is Hard", "comments": "21 pages, A short version of this paper has been accepted in FCT 2009\n  - 17th International Symposium on Fundamentals of Computation Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of publishing personal data without giving up privacy is becoming\nincreasingly important. An interesting formalization recently proposed is the\nk-anonymity. This approach requires that the rows in a table are clustered in\nsets of size at least k and that all the rows in a cluster become the same\ntuple, after the suppression of some records. The natural optimization problem,\nwhere the goal is to minimize the number of suppressed entries, is known to be\nNP-hard when the values are over a ternary alphabet, k = 3 and the rows length\nis unbounded. In this paper we give a lower bound on the approximation factor\nthat any polynomial-time algorithm can achive on two restrictions of the\nproblem,namely (i) when the records values are over a binary alphabet and k =\n3, and (ii) when the records have length at most 8 and k = 4, showing that\nthese restrictions of the problem are APX-hard.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 14:17:49 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2009 16:40:37 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Bonizzoni", "Paola", ""], ["Della Vedova", "Gianluca", ""], ["Dondi", "Riccardo", ""]]}, {"id": "0707.0546", "submitter": "Juli\\'an Mestre", "authors": "Juli\\'an Mestre", "title": "Weighted Popular Matchings", "comments": "14 pages, 3 figures. A preliminary version appeared in the\n  Proceedings of the 33rd International Colloquium on Automata, Languages and\n  Programming (ICALP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We study the problem of assigning jobs to applicants. Each applicant has a\nweight and provides a preference list ranking a subset of the jobs. A matching\nM is popular if there is no other matching M' such that the weight of the\napplicants who prefer M' over M exceeds the weight of those who prefer M over\nM'. This paper gives efficient algorithms to find a popular matching if one\nexists.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 06:55:43 GMT"}], "update_date": "2007-07-05", "authors_parsed": [["Mestre", "Juli\u00e1n", ""]]}, {"id": "0707.0644", "submitter": "Ali Akhavi", "authors": "Ali Akhavi (GREYC), C\\'eline Moreira (GREYC)", "title": "Another view of the Gaussian algorithm", "comments": null, "journal-ref": "Proceedings of Latin'04 (04/2004) 474--487", "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": null, "abstract": "  We introduce here a rewrite system in the group of unimodular matrices,\n\\emph{i.e.}, matrices with integer entries and with determinant equal to $\\pm\n1$. We use this rewrite system to precisely characterize the mechanism of the\nGaussian algorithm, that finds shortest vectors in a two--dimensional lattice\ngiven by any basis. Putting together the algorithmic of lattice reduction and\nthe rewrite system theory, we propose a new worst--case analysis of the\nGaussian algorithm. There is already an optimal worst--case bound for some\nvariant of the Gaussian algorithm due to Vall\\'ee \\cite {ValGaussRevisit}. She\nused essentially geometric considerations. Our analysis generalizes her result\nto the case of the usual Gaussian algorithm. An interesting point in our work\nis its possible (but not easy) generalization to the same problem in higher\ndimensions, in order to exhibit a tight upper-bound for the number of\niterations of LLL--like reduction algorithms in the worst case. Moreover, our\nmethod seems to work for analyzing other families of algorithms. As an\nillustration, the analysis of sorting algorithms are briefly developed in the\nlast section of the paper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 15:37:15 GMT"}], "update_date": "2007-07-05", "authors_parsed": [["Akhavi", "Ali", "", "GREYC"], ["Moreira", "C\u00e9line", "", "GREYC"]]}, {"id": "0707.0648", "submitter": "Viswanath Nagarajan", "authors": "Anupam Gupta, MohammadTaghi Hajiaghayi, Viswanath Nagarajan, R. Ravi", "title": "Dial a Ride from k-forest", "comments": "Preliminary version in Proc. European Symposium on Algorithms, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  The k-forest problem is a common generalization of both the k-MST and the\ndense-$k$-subgraph problems. Formally, given a metric space on $n$ vertices\n$V$, with $m$ demand pairs $\\subseteq V \\times V$ and a ``target'' $k\\le m$,\nthe goal is to find a minimum cost subgraph that connects at least $k$ demand\npairs. In this paper, we give an $O(\\min\\{\\sqrt{n},\\sqrt{k}\\})$-approximation\nalgorithm for $k$-forest, improving on the previous best ratio of\n$O(n^{2/3}\\log n)$ by Segev & Segev.\n  We then apply our algorithm for k-forest to obtain approximation algorithms\nfor several Dial-a-Ride problems. The basic Dial-a-Ride problem is the\nfollowing: given an $n$ point metric space with $m$ objects each with its own\nsource and destination, and a vehicle capable of carrying at most $k$ objects\nat any time, find the minimum length tour that uses this vehicle to move each\nobject from its source to destination. We prove that an $\\alpha$-approximation\nalgorithm for the $k$-forest problem implies an\n$O(\\alpha\\cdot\\log^2n)$-approximation algorithm for Dial-a-Ride. Using our\nresults for $k$-forest, we get an $O(\\min\\{\\sqrt{n},\\sqrt{k}\\}\\cdot\\log^2 n)$-\napproximation algorithm for Dial-a-Ride. The only previous result known for\nDial-a-Ride was an $O(\\sqrt{k}\\log n)$-approximation by Charikar &\nRaghavachari; our results give a different proof of a similar approximation\nguarantee--in fact, when the vehicle capacity $k$ is large, we give a slight\nimprovement on their results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 16:08:40 GMT"}], "update_date": "2007-07-05", "authors_parsed": [["Gupta", "Anupam", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Nagarajan", "Viswanath", ""], ["Ravi", "R.", ""]]}, {"id": "0707.1051", "submitter": "Mark Braverman", "authors": "Mark Braverman, Elchanan Mossel", "title": "Noisy Sorting Without Resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  In this paper we study noisy sorting without re-sampling. In this problem\nthere is an unknown order $a_{\\pi(1)} < ... < a_{\\pi(n)}$ where $\\pi$ is a\npermutation on $n$ elements. The input is the status of $n \\choose 2$ queries\nof the form $q(a_i,x_j)$, where $q(a_i,a_j) = +$ with probability at least\n$1/2+\\ga$ if $\\pi(i) > \\pi(j)$ for all pairs $i \\neq j$, where $\\ga > 0$ is a\nconstant and $q(a_i,a_j) = -q(a_j,a_i)$ for all $i$ and $j$. It is assumed that\nthe errors are independent. Given the status of the queries the goal is to find\nthe maximum likelihood order. In other words, the goal is find a permutation\n$\\sigma$ that minimizes the number of pairs $\\sigma(i) > \\sigma(j)$ where\n$q(\\sigma(i),\\sigma(j)) = -$. The problem so defined is the feedback arc set\nproblem on distributions of inputs, each of which is a tournament obtained as a\nnoisy perturbations of a linear order. Note that when $\\ga < 1/2$ and $n$ is\nlarge, it is impossible to recover the original order $\\pi$.\n  It is known that the weighted feedback are set problem on tournaments is\nNP-hard in general. Here we present an algorithm of running time\n$n^{O(\\gamma^{-4})}$ and sampling complexity $O_{\\gamma}(n \\log n)$ that with\nhigh probability solves the noisy sorting without re-sampling problem. We also\nshow that if $a_{\\sigma(1)},a_{\\sigma(2)},...,a_{\\sigma(n)}$ is an optimal\nsolution of the problem then it is ``close'' to the original order. More\nformally, with high probability it holds that $\\sum_i |\\sigma(i) - \\pi(i)| =\n\\Theta(n)$ and $\\max_i |\\sigma(i) - \\pi(i)| = \\Theta(\\log n)$.\n  Our results are of interest in applications to ranking, such as ranking in\nsports, or ranking of search items based on comparisons by experts.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2007 21:30:24 GMT"}], "update_date": "2007-07-10", "authors_parsed": [["Braverman", "Mark", ""], ["Mossel", "Elchanan", ""]]}, {"id": "0707.1095", "submitter": "Gregory Gutin", "authors": "Noga Alon, Fedor V. Fomin, Gregory Gutin, Michael Krivelevich, Saket\n  Saurabh", "title": "Better Algorithms and Bounds for Directed Maximum Leaf Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": null, "abstract": "  The {\\sc Directed Maximum Leaf Out-Branching} problem is to find an\nout-branching (i.e. a rooted oriented spanning tree) in a given digraph with\nthe maximum number of leaves. In this paper, we improve known parameterized\nalgorithms and combinatorial bounds on the number of leaves in out-branchings.\nWe show that\n  \\begin{itemize} \\item every strongly connected digraph $D$ of order $n$ with\nminimum in-degree at least 3 has an out-branching with at least $(n/4)^{1/3}-1$\nleaves; \\item if a strongly connected digraph $D$ does not contain an\nout-branching with $k$ leaves, then the pathwidth of its underlying graph is\n$O(k\\log k)$; \\item it can be decided in time $2^{O(k\\log^2 k)}\\cdot n^{O(1)}$\nwhether a strongly connected digraph on $n$ vertices has an out-branching with\nat least $k$ leaves. \\end{itemize}\n  All improvements use properties of extremal structures obtained after\napplying local search and of some out-branching decompositions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2007 15:52:29 GMT"}], "update_date": "2007-07-10", "authors_parsed": [["Alon", "Noga", ""], ["Fomin", "Fedor V.", ""], ["Gutin", "Gregory", ""], ["Krivelevich", "Michael", ""], ["Saurabh", "Saket", ""]]}, {"id": "0707.1532", "submitter": "Samantha Riesenfeld", "authors": "Constantinos Daskalakis (1), Richard M. Karp (1), Elchanan Mossel (1),\n  Samantha Riesenfeld (1), Elad Verbin (2) ((1) U.C. Berkeley, (2) Tel Aviv\n  University)", "title": "Sorting and Selection in Posets", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": null, "abstract": "  Classical problems of sorting and searching assume an underlying linear\nordering of the objects being compared. In this paper, we study a more general\nsetting, in which some pairs of objects are incomparable. This generalization\nis relevant in applications related to rankings in sports, college admissions,\nor conference submissions. It also has potential applications in biology, such\nas comparing the evolutionary fitness of different strains of bacteria, or\nunderstanding input-output relations among a set of metabolic reactions or the\ncausal influences among a set of interacting genes or proteins. Our results\nimprove and extend results from two decades ago of Faigle and Tur\\'{a}n.\n  A measure of complexity of a partially ordered set (poset) is its width. Our\nalgorithms obtain information about a poset by queries that compare two\nelements. We present an algorithm that sorts, i.e. completely identifies, a\nwidth w poset of size n and has query complexity O(wn + nlog(n)), which is\nwithin a constant factor of the information-theoretic lower bound. We also show\nthat a variant of Mergesort has query complexity O(wn(log(n/w))) and total\ncomplexity O((w^2)nlog(n/w)). Faigle and Tur\\'{a}n have shown that the sorting\nproblem has query complexity O(wn(log(n/w))) but did not address its total\ncomplexity.\n  For the related problem of determining the minimal elements of a poset, we\ngive efficient deterministic and randomized algorithms with O(wn) query and\ntotal complexity, along with matching lower bounds for the query complexity up\nto a factor of 2. We generalize these results to the k-selection problem of\ndetermining the elements of height at most k. We also derive upper bounds on\nthe total complexity of some other problems of a similar flavor.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2007 21:52:17 GMT"}], "update_date": "2007-07-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Karp", "Richard M.", ""], ["Mossel", "Elchanan", ""], ["Riesenfeld", "Samantha", ""], ["Verbin", "Elad", ""]]}, {"id": "0707.1714", "submitter": "Michael Mahoney", "authors": "Anirban Dasgupta, Petros Drineas, Boulos Harb, Ravi Kumar, and Michael\n  W. Mahoney", "title": "Sampling Algorithms and Coresets for Lp Regression", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  The Lp regression problem takes as input a matrix $A \\in \\Real^{n \\times d}$,\na vector $b \\in \\Real^n$, and a number $p \\in [1,\\infty)$, and it returns as\noutput a number ${\\cal Z}$ and a vector $x_{opt} \\in \\Real^d$ such that ${\\cal\nZ} = \\min_{x \\in \\Real^d} ||Ax -b||_p = ||Ax_{opt}-b||_p$. In this paper, we\nconstruct coresets and obtain an efficient two-stage sampling-based\napproximation algorithm for the very overconstrained ($n \\gg d$) version of\nthis classical problem, for all $p \\in [1, \\infty)$. The first stage of our\nalgorithm non-uniformly samples $\\hat{r}_1 = O(36^p d^{\\max\\{p/2+1, p\\}+1})$\nrows of $A$ and the corresponding elements of $b$, and then it solves the Lp\nregression problem on the sample; we prove this is an 8-approximation. The\nsecond stage of our algorithm uses the output of the first stage to resample\n$\\hat{r}_1/\\epsilon^2$ constraints, and then it solves the Lp regression\nproblem on the new sample; we prove this is a $(1+\\epsilon)$-approximation. Our\nalgorithm unifies, improves upon, and extends the existing algorithms for\nspecial cases of Lp regression, namely $p = 1,2$. In course of proving our\nresult, we develop two concepts--well-conditioned bases and subspace-preserving\nsampling--that are of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2007 22:04:18 GMT"}], "update_date": "2007-07-13", "authors_parsed": [["Dasgupta", "Anirban", ""], ["Drineas", "Petros", ""], ["Harb", "Boulos", ""], ["Kumar", "Ravi", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "0707.2160", "submitter": "Seth Pettie", "authors": "Seth Pettie", "title": "Splay Trees, Davenport-Schinzel Sequences, and the Deque Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": null, "abstract": "  We introduce a new technique to bound the asymptotic performance of splay\ntrees. The basic idea is to transcribe, in an indirect fashion, the rotations\nperformed by the splay tree as a Davenport-Schinzel sequence S, none of whose\nsubsequences are isomorphic to fixed forbidden subsequence. We direct this\ntechnique towards Tarjan's deque conjecture and prove that n deque operations\nrequire O(n alpha^*(n)) time, where alpha^*(n) is the minimum number of\napplications of the inverse-Ackermann function mapping n to a constant. We are\noptimistic that this approach could be directed towards other open conjectures\non splay trees such as the traversal and split conjectures.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2007 16:38:08 GMT"}], "update_date": "2007-07-17", "authors_parsed": [["Pettie", "Seth", ""]]}, {"id": "0707.2701", "submitter": "Gernot Schaller", "authors": "Gernot Schaller", "title": "A fixed point iteration for computing the matrix logarithm", "comments": "4 pages, 3 figures, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": null, "abstract": "  In various areas of applied numerics, the problem of calculating the\nlogarithm of a matrix A emerges. Since series expansions of the logarithm\nusually do not converge well for matrices far away from the identity, the\nstandard numerical method calculates successive square roots. In this article,\na new algorithm is presented that relies on the computation of successive\nmatrix exponentials. Convergence of the method is demonstrated for a large\nclass of initial matrices and favorable choices of the initial matrix are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2007 11:04:27 GMT"}], "update_date": "2007-07-19", "authors_parsed": [["Schaller", "Gernot", ""]]}, {"id": "0707.3407", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Faster subsequence recognition in compressed strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": null, "abstract": "  Computation on compressed strings is one of the key approaches to processing\nmassive data sets. We consider local subsequence recognition problems on\nstrings compressed by straight-line programs (SLP), which is closely related to\nLempel--Ziv compression. For an SLP-compressed text of length $\\bar m$, and an\nuncompressed pattern of length $n$, C{\\'e}gielski et al. gave an algorithm for\nlocal subsequence recognition running in time $O(\\bar mn^2 \\log n)$. We improve\nthe running time to $O(\\bar mn^{1.5})$. Our algorithm can also be used to\ncompute the longest common subsequence between a compressed text and an\nuncompressed pattern in time $O(\\bar mn^{1.5})$; the same problem with a\ncompressed pattern is known to be NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2007 16:26:24 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2007 14:16:07 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2008 21:54:54 GMT"}, {"version": "v4", "created": "Fri, 18 Jan 2008 10:20:48 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Tiskin", "Alexander", ""]]}, {"id": "0707.3409", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Faster exon assembly by sparse spliced alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CE q-bio.QM", "license": null, "abstract": "  Assembling a gene from candidate exons is an important problem in\ncomputational biology. Among the most successful approaches to this problem is\n\\emph{spliced alignment}, proposed by Gelfand et al., which scores different\ncandidate exon chains within a DNA sequence of length $m$ by comparing them to\na known related gene sequence of length n, $m = \\Theta(n)$. Gelfand et al.\\\ngave an algorithm for spliced alignment running in time O(n^3). Kent et al.\\\nconsidered sparse spliced alignment, where the number of candidate exons is\nO(n), and proposed an algorithm for this problem running in time O(n^{2.5}). We\nimprove on this result, by proposing an algorithm for sparse spliced alignment\nrunning in time O(n^{2.25}). Our approach is based on a new framework of\n\\emph{quasi-local string comparison}.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2007 16:35:54 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Tiskin", "Alexander", ""]]}, {"id": "0707.3619", "submitter": "Alexander Tiskin", "authors": "Alexander Tiskin", "title": "Semi-local string comparison: algorithmic techniques and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical measure of string comparison is given by the longest common\nsubsequence (LCS) problem on a pair of strings. We consider its generalisation,\ncalled the semi-local LCS problem, which arises naturally in many\nstring-related problems. The semi-local LCS problem asks for the LCS scores for\neach of the input strings against every substring of the other input string,\nand for every prefix of each input string against every suffix of the other\ninput string. Such a comparison pattern provides a much more detailed picture\nof string similarity than a single LCS score; it also arises naturally in many\nstring-related problems. In fact, the semi-local LCS problem turns out to be\nfundamental for string comparison, providing a powerful and flexible\nalternative to classical dynamic programming. It is especially useful when the\ninput to a string comparison problem may not be available all at once: for\nexample, comparison of dynamically changing strings; comparison of compressed\nstrings; parallel string comparison. The same approach can also be applied to\npermutation strings, providing efficient solutions for local versions of the\nlongest increasing subsequence (LIS) problem, and for the problem of computing\na maximum clique in a circle graph. Furthermore, the semi-local LCS problem\nturns out to have surprising connections in a few seemingly unrelated fields,\nsuch as computational geometry and algebra of semigroups. This work is devoted\nto exploring the structure of the semi-local LCS problem, its efficient\nsolutions, and its applications in string comparison and other related areas,\nincluding computational molecular biology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 19:12:23 GMT"}, {"version": "v10", "created": "Wed, 5 Aug 2009 16:07:43 GMT"}, {"version": "v11", "created": "Thu, 20 Aug 2009 22:16:33 GMT"}, {"version": "v12", "created": "Mon, 31 Aug 2009 13:08:55 GMT"}, {"version": "v13", "created": "Mon, 19 Oct 2009 14:48:06 GMT"}, {"version": "v14", "created": "Fri, 11 Dec 2009 20:34:12 GMT"}, {"version": "v15", "created": "Sat, 9 Jan 2010 16:22:30 GMT"}, {"version": "v16", "created": "Tue, 11 May 2010 11:43:57 GMT"}, {"version": "v17", "created": "Tue, 21 Feb 2012 22:50:39 GMT"}, {"version": "v18", "created": "Thu, 20 Sep 2012 12:52:02 GMT"}, {"version": "v19", "created": "Mon, 28 Jan 2013 02:37:21 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2007 13:29:39 GMT"}, {"version": "v20", "created": "Wed, 20 Nov 2013 20:54:28 GMT"}, {"version": "v21", "created": "Sat, 23 Nov 2013 23:30:05 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2007 14:09:50 GMT"}, {"version": "v4", "created": "Thu, 21 Aug 2008 15:17:48 GMT"}, {"version": "v5", "created": "Mon, 17 Nov 2008 22:31:37 GMT"}, {"version": "v6", "created": "Wed, 10 Dec 2008 19:46:02 GMT"}, {"version": "v7", "created": "Mon, 12 Jan 2009 17:49:28 GMT"}, {"version": "v8", "created": "Sun, 22 Mar 2009 16:36:29 GMT"}, {"version": "v9", "created": "Mon, 6 Jul 2009 15:59:42 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Tiskin", "Alexander", ""]]}, {"id": "0707.3622", "submitter": "Yaoyun Shi", "authors": "Igor Markov (University of Michigan) and Yaoyun Shi (University of\n  Michigan)", "title": "Constant-degree graph expansions that preserve the treewidth", "comments": "12 pages, 6 figures, the main result used by quant-ph/0511070", "journal-ref": "Algorithmica, Volume 59, Number 4, 461-470,2011", "doi": "10.1007/s00453-009-9312-5", "report-no": null, "categories": "cs.DM cs.DS math.CO quant-ph", "license": null, "abstract": "  Many hard algorithmic problems dealing with graphs, circuits, formulas and\nconstraints admit polynomial-time upper bounds if the underlying graph has\nsmall treewidth. The same problems often encourage reducing the maximal degree\nof vertices to simplify theoretical arguments or address practical concerns.\nSuch degree reduction can be performed through a sequence of splittings of\nvertices, resulting in an _expansion_ of the original graph. We observe that\nthe treewidth of a graph may increase dramatically if the splittings are not\nperformed carefully. In this context we address the following natural question:\nis it possible to reduce the maximum degree to a constant without substantially\nincreasing the treewidth?\n  Our work answers the above question affirmatively. We prove that any simple\nundirected graph G=(V, E) admits an expansion G'=(V', E') with the maximum\ndegree <= 3 and treewidth(G') <= treewidth(G)+1. Furthermore, such an expansion\nwill have no more than 2|E|+|V| vertices and 3|E| edges; it can be computed\nefficiently from a tree-decomposition of G. We also construct a family of\nexamples for which the increase by 1 in treewidth cannot be avoided.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 19:56:27 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Markov", "Igor", "", "University of Michigan"], ["Shi", "Yaoyun", "", "University of\n  Michigan"]]}, {"id": "0707.4448", "submitter": "Mohamed-Ali Belabbas", "authors": "Mohamed-Ali Belabbas and Patrick J. Wolfe", "title": "On sparse representations of linear operators and the approximation of\n  matrix products", "comments": "6 pages, 3 figures; presented at the 42nd Annual Conference on\n  Information Sciences and Systems (CISS 2008)", "journal-ref": null, "doi": "10.1109/CISS.2008.4558532", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thus far, sparse representations have been exploited largely in the context\nof robustly estimating functions in a noisy environment from a few\nmeasurements. In this context, the existence of a basis in which the signal\nclass under consideration is sparse is used to decrease the number of necessary\nmeasurements while controlling the approximation error. In this paper, we\ninstead focus on applications in numerical analysis, by way of sparse\nrepresentations of linear operators with the objective of minimizing the number\nof operations needed to perform basic operations (here, multiplication) on\nthese operators. We represent a linear operator by a sum of rank-one operators,\nand show how a sparse representation that guarantees a low approximation error\nfor the product can be obtained from analyzing an induced quadratic form. This\nconstruction in turn yields new algorithms for computing approximate matrix\nproducts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2007 17:20:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 12:04:44 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Belabbas", "Mohamed-Ali", ""], ["Wolfe", "Patrick J.", ""]]}]