[{"id": "1108.0047", "submitter": "Gianluca Della Vedova", "authors": "Stefano Beretta, Paola Bonizzoni, Gianluca Della Vedova and Raffaella\n  Rizzi", "title": "Reconstructing Isoform Graphs from RNA-Seq data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation sequencing (NGS) technologies allow new methodologies for\nalternative splicing (AS) analysis. Current computational methods for AS from\nNGS data are mainly focused on predicting splice site junctions or de novo\nassembly of full-length transcripts. These methods are computationally\nexpensive and produce a huge number of full-length transcripts or splice\njunctions, spanning the whole genome of organisms. Thus summarizing such data\ninto the different gene structures and AS events of the expressed genes is an\nhard task.\n  To face this issue in this paper we investigate the computational problem of\nreconstructing from NGS data, in absence of the genome, a gene structure for\neach gene that is represented by the isoform graph: we introduce such graph and\nwe show that it uniquely summarizes the gene transcripts. We define the\ncomputational problem of reconstructing the isoform graph and provide some\nconditions that must be met to allow such reconstruction.\n  Finally, we describe an efficient algorithmic approach to solve this problem,\nvalidating our approach with both a theoretical and an experimental analysis.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2011 07:10:58 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2012 14:15:24 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Beretta", "Stefano", ""], ["Bonizzoni", "Paola", ""], ["Della Vedova", "Gianluca", ""], ["Rizzi", "Raffaella", ""]]}, {"id": "1108.0129", "submitter": "Sebastian Roch", "authors": "Elchanan Mossel and Sebastien Roch", "title": "Identifiability and inference of non-parametric rates-across-sites\n  models on large-scale phylogenies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutation rate variation across loci is well known to cause difficulties,\nnotably identifiability issues, in the reconstruction of evolutionary trees\nfrom molecular sequences. Here we introduce a new approach for estimating\ngeneral rates-across-sites models. Our results imply, in particular, that large\nphylogenies are typically identifiable under rate variation. We also derive\nsequence-length requirements for high-probability reconstruction.\n  Our main contribution is a novel algorithm that clusters sites according to\ntheir mutation rate. Following this site clustering step, standard\nreconstruction techniques can be used to recover the phylogeny. Our results\nrely on a basic insight: that, for large trees, certain site statistics\nexperience concentration-of-measure phenomena.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jul 2011 03:55:03 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}, {"id": "1108.0286", "submitter": "Richard Brent", "authors": "Richard P. Brent and David Harvey", "title": "Fast computation of Bernoulli, Tangent and Secant numbers", "comments": "16 pages. To appear in Computational and Analytical Mathematics\n  (associated with the May 2011 workshop in honour of Jonathan Borwein's 60th\n  birthday). For further information, see\n  http://maths.anu.edu.au/~brent/pub/pub242.html", "journal-ref": "Springer Proceedings in Mathematics and Statistics, Vol. 50, 2013,\n  127-142", "doi": "10.1007/978-1-4614-7621-4_8", "report-no": null, "categories": "math.CO cs.DM cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computation of Bernoulli, Tangent (zag), and Secant (zig or\nEuler) numbers. In particular, we give asymptotically fast algorithms for\ncomputing the first n such numbers in O(n^2.(log n)^(2+o(1))) bit-operations.\nWe also give very short in-place algorithms for computing the first n Tangent\nor Secant numbers in O(n^2) integer operations. These algorithms are extremely\nsimple, and fast for moderate values of n. They are faster and use less space\nthan the algorithms of Atkinson (for Tangent and Secant numbers) and Akiyama\nand Tanigawa (for Bernoulli numbers).\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2011 11:37:42 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2011 09:58:32 GMT"}, {"version": "v3", "created": "Mon, 5 Sep 2011 10:43:36 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Brent", "Richard P.", ""], ["Harvey", "David", ""]]}, {"id": "1108.0295", "submitter": "Leslie Ann Goldberg", "authors": "Benjamin Doerr and Leslie Ann Goldberg", "title": "Adaptive Drift Analysis", "comments": "version 2 - fixed typos", "journal-ref": "Algorithmica, 2012", "doi": "10.1007/s00453-011-9585-3", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for any c>0, the (1+1) evolutionary algorithm using an\narbitrary mutation rate p_n = c/n finds the optimum of a linear objective\nfunction over bit strings of length n in expected time Theta(n log n).\nPreviously, this was only known for c at most 1. Since previous work also shows\nthat universal drift functions cannot exist for c larger than a certain\nconstant, we instead define drift functions which depend crucially on the\nrelevant objective functions (and also on c itself). Using these\ncarefully-constructed drift functions, we prove that the expected optimisation\ntime is Theta(n log n). By giving an alternative proof of the multiplicative\ndrift theorem, we also show that our optimisation-time bound holds with high\nprobability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2011 12:22:27 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2011 07:24:43 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Doerr", "Benjamin", ""], ["Goldberg", "Leslie Ann", ""]]}, {"id": "1108.0388", "submitter": "Fei Li", "authors": "Fei Li", "title": "A Comprehensive Study of an Online Packet Scheduling Algorithm", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the \\emph{bounded-delay model} for Qualify-of-Service buffer\nmanagement. Time is discrete. There is a buffer. Unit-length jobs (also called\n\\emph{packets}) arrive at the buffer over time. Each packet has an integer\nrelease time, an integer deadline, and a positive real value. A packet's\ncharacteristics are not known to an online algorithm until the packet actually\narrives. In each time step, at most one packet can be sent out of the buffer.\nThe objective is to maximize the total value of the packets sent by their\nrespective deadlines in an online manner. An online algorithm's performance is\nusually measured in terms of \\emph{competitive ratio}, when this online\nalgorithm is compared with a clairvoyant algorithm achieving the best total\nvalue. In this paper, we study a simple and intuitive online algorithm. We\nanalyze its performance in terms of competitive ratio for the general model and\na few important variants.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2011 18:49:37 GMT"}], "update_date": "2011-08-02", "authors_parsed": [["Li", "Fei", ""]]}, {"id": "1108.0408", "submitter": "Sergey Kardash Mr", "authors": "Sergey Kardash", "title": "Algorithmic complexity of pair cleaning method for k-satisfiability\n  problem. (draft version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-satisfiability problem is a well-known task in computational complexity\ntheory. In this paper approach for it's solving is introduced.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2011 22:15:31 GMT"}, {"version": "v2", "created": "Thu, 31 May 2012 08:15:47 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Kardash", "Sergey", ""]]}, {"id": "1108.0554", "submitter": "sharma V. Thankachan Mr", "authors": "Wing-Kai Hon, Rahul Shah and Sharma V. Thankachan", "title": "Towards an Optimal Space-and-Query-Time Index for Top-k Document\n  Retrieval", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\D = $$ \\{d_1,d_2,...d_D\\}$ be a given set of $D$ string documents of\ntotal length $n$, our task is to index $\\D$, such that the $k$ most relevant\ndocuments for an online query pattern $P$ of length $p$ can be retrieved\nefficiently. We propose an index of size $|CSA|+n\\log D(2+o(1))$ bits and\n$O(t_{s}(p)+k\\log\\log n+poly\\log\\log n)$ query time for the basic relevance\nmetric \\emph{term-frequency}, where $|CSA|$ is the size (in bits) of a\ncompressed full text index of $\\D$, with $O(t_s(p))$ time for searching a\npattern of length $p$ . We further reduce the space to $|CSA|+n\\log D(1+o(1))$\nbits, however the query time will be $O(t_s(p)+k(\\log \\sigma \\log\\log\nn)^{1+\\epsilon}+poly\\log\\log n)$, where $\\sigma$ is the alphabet size and\n$\\epsilon >0$ is any constant.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2011 12:00:02 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2012 23:04:11 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Hon", "Wing-Kai", ""], ["Shah", "Rahul", ""], ["Thankachan", "Sharma V.", ""]]}, {"id": "1108.0809", "submitter": "Peter Robinson", "authors": "John Augustine, Gopal Pandurangan, Peter Robinson, Eli Upfal", "title": "Distributed Agreement in Dynamic Peer-to-Peer Networks", "comments": "to appear at the Journal of Computer and System Sciences; preliminary\n  version appeared at SODA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need for robust and fast distributed computation in highly\ndynamic Peer-to-Peer (P2P) networks, we study algorithms for the fundamental\ndistributed agreement problem. P2P networks are highly dynamic networks that\nexperience heavy node {\\em churn}. Our goal is to design fast algorithms\n(running in a small number of rounds) that guarantee, despite high node churn\nrate, that almost all nodes reach a stable agreement. Our main contributions\nare randomized distributed algorithms that guarantee {\\em stable\nalmost-everywhere agreement} with high probability even under high adversarial\nchurn in a polylogarithmic number of rounds:\n  1. An $O(\\log^2 n)$-round ($n$ is the stable network size) randomized\nalgorithm that achieves almost-everywhere agreement with high probability under\nup to {\\em linear} churn {\\em per round} (i.e., $\\epsilon n$, for some small\nconstant $\\epsilon > 0$), assuming that the churn is controlled by an oblivious\nadversary (that has complete knowledge and control of what nodes join and leave\nand at what time and has unlimited computational power, but is oblivious to the\nrandom choices made by the algorithm). Our algorithm requires only\npolylogarithmic in $n$ bits to be processed and sent (per round) by each node.\n  2. An $O(\\log m\\log^3 n)$-round randomized algorithm that achieves\nalmost-everywhere agreement with high probability under up to $\\epsilon\n\\sqrt{n}$ churn per round (for some small $\\epsilon > 0$), where $m$ is the\nsize of the input value domain, that works even under an adaptive adversary\n(that also knows the past random choices made by the algorithm). This algorithm\nrequires up to polynomial in $n$ bits (and up to $O(\\log m)$ bits) to be\nprocessed and sent (per round) by each node.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2011 10:09:45 GMT"}, {"version": "v2", "created": "Wed, 10 Sep 2014 08:38:38 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Augustine", "John", ""], ["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""], ["Upfal", "Eli", ""]]}, {"id": "1108.0810", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and Marcin Pilipczuk and Micha{\\l} Pilipczuk and Jakub\n  Onufry Wojtaszczyk", "title": "Scheduling partially ordered jobs faster than 2^n", "comments": "full version of a paper accepted for ESA'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the SCHED problem we are given a set of n jobs, together with their\nprocessing times and precedence constraints. The task is to order the jobs so\nthat their total completion time is minimized. SCHED is a special case of the\nTraveling Repairman Problem with precedences. A natural dynamic programming\nalgorithm solves both these problems in 2^n n^O(1) time, and whether there\nexists an algorithms solving SCHED in O(c^n) time for some constant c < 2 was\nan open problem posted in 2004 by Woeginger. In this paper we answer this\nquestion positively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2011 10:12:03 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 11:59:56 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Cygan", "Marek", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Wojtaszczyk", "Jakub Onufry", ""]]}, {"id": "1108.0866", "submitter": "Marcin Peczarski", "authors": "Marcin Peczarski", "title": "Towards Optimal Sorting of 16 Elements", "comments": "10 pages, 7 figures, 2 tables. First submitted to IWOCA 2010, 21st\n  International Workshop on Combinatorial Algorithms. Submission was rejected", "journal-ref": "Acta Universitatis Sapientiae, Informatica, 4(2) (2012) 215-224", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problem in the theory of sorting is to find the\npessimistic number of comparisons sufficient to sort a given number of\nelements. Currently 16 is the lowest number of elements for which we do not\nknow the exact value. We know that 46 comparisons suffices and that 44 do not.\nThere is an open question if 45 comparisons are sufficient. We present an\nattempt to resolve that problem by performing an exhaustive computer search. We\nalso present an algorithm for counting linear extensions which substantially\nspeeds up computations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2011 15:24:49 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Peczarski", "Marcin", ""]]}, {"id": "1108.1055", "submitter": "Pradipta Mitra", "authors": "Magnus M. Halldorsson and Pradipta Mitra", "title": "Wireless Capacity With Arbitrary Gain Matrix", "comments": "8 pages, to appear in ALGOSENSORS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of wireless links, a fundamental problem is to find the largest\nsubset that can transmit simultaneously, within the SINR model of interference.\nSignificant progress on this problem has been made in recent years. In this\nnote, we study the problem in the setting where we are given a fixed set of\narbitrary powers each sender must use, and an arbitrary gain matrix defining\nhow signals fade. This variation of the problem appears immune to most\nalgorithmic approaches studied in the literature. Indeed it is very hard to\napproximate since it generalizes the max independent set problem. Here, we\npropose a simple semi-definite programming approach to the problem that yields\nconstant factor approximation, if the optimal solution is strictly larger than\nhalf of the input size.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2011 12:11:12 GMT"}], "update_date": "2012-03-15", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Mitra", "Pradipta", ""]]}, {"id": "1108.1060", "submitter": "Antonio Fern\\'andez Anta", "authors": "Jos\\'e Luis L\\'opez-Presa and Antonio Fern\\'andez Anta and Luis\n  N\\'u\\~nez Chiroque", "title": "Conauto-2.0: Fast Isomorphism Testing and Automorphism Group Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an algorithm, called conauto-2.0, that can\nefficiently compute a set of generators of the automorphism group of a graph,\nand test whether two graphs are isomorphic, finding an isomorphism if they are.\nThis algorithm uses the basic individualization/refinement technique, and is an\nimproved version of the algorithm conauto, which has been shown to be very fast\nfor random graphs and several families of hard graphs. In this paper, it is\nproved that, under some circumstances, it is not only possible to prune the\nsearch space (using already found generators of the automorphism group), but\nalso to infer new generators without the need of explicitly finding an\nautomorphism of the graph. This result is especially suited for graphs with\nregularly connected components, and can be applied in any isomorphism testing\nand canonical labeling algorithm (that use the individualization/refinement\ntechnique) to significantly improve its performance. Additionally, a dynamic\ntarget cell selection function is used to adapt to different graphs. The\nresulting algorithm preserves all the nice features of conauto, but reduces the\ntime for testing graphs with regularly connected components and other hard\ngraph families. We run extensive experiments, which show that the most popular\nalgorithms (namely, nauty, bliss, Traces, and saucy) are slower than\nconauto-2.0, among others, for the graph families based on components.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2011 12:16:27 GMT"}], "update_date": "2011-08-05", "authors_parsed": [["L\u00f3pez-Presa", "Jos\u00e9 Luis", ""], ["Anta", "Antonio Fern\u00e1ndez", ""], ["Chiroque", "Luis N\u00fa\u00f1ez", ""]]}, {"id": "1108.1130", "submitter": "Marcin Mucha", "authors": "Marcin Mucha", "title": "13/9-approximation for Graphic TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Travelling Salesman Problem is one the most fundamental and most studied\nproblems in approximation algorithms. For more than 30 years, the best\nalgorithm known for general metrics has been Christofides's algorithm with\napproximation factor of 3/2, even though the so-called Held-Karp LP relaxation\nof the problem is conjectured to have the integrality gap of only 4/3. Very\nrecently, significant progress has been made for the important special case of\ngraphic metrics, first by Oveis Gharan et al., and then by Momke and Svensson.\nIn this paper, we provide an improved analysis for the approach introduced by\nMomke and Svensson yielding a bound of 13/9 on the approximation factor, as\nwell as a bound of 19/12+epsilon for any epsilon>0 for a more general\nTravelling Salesman Path Problem in graphic metrics.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2011 16:23:48 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2011 16:16:46 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Mucha", "Marcin", ""]]}, {"id": "1108.1176", "submitter": "Rohit Khandekar", "authors": "MohammadTaghi Hajiaghayi and Rohit Khandekar and Guy Kortsarz and Zeev\n  Nutov", "title": "Combinatorial Algorithms for Capacitated Network Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2011 19:34:38 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hajiaghayi", "MohammadTaghi", ""], ["Khandekar", "Rohit", ""], ["Kortsarz", "Guy", ""], ["Nutov", "Zeev", ""]]}, {"id": "1108.1320", "submitter": "Rasmus Pagh", "authors": "Rasmus Pagh", "title": "Compressed Matrix Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problems of computing sample covariance matrices, and of\ntransforming a collection of vectors to a basis where they are sparse, we\npresent a simple algorithm that computes an approximation of the product of two\nn-by-n real matrices A and B. Let ||AB||_F denote the Frobenius norm of AB, and\nb be a parameter determining the time/accuracy trade-off. Given 2-wise\nindependent hash functions $_1,h_2: [n] -> [b], and s_1,s_2: [n] -> {-1,+1} the\nalgorithm works by first \"compressing\" the matrix product into the polynomial\np(x) = sum_{k=1}^n (sum_{i=1}^n A_{ik} s_1(i) x^{h_1(i)}) (sum_{j=1}^n B_{kj}\ns_2(j) x^{h_2(j)})\n  Using FFT for polynomial multiplication, we can compute c_0,...,c_{b-1} such\nthat sum_i c_i x^i = (p(x) mod x^b) + (p(x) div x^b) in time \\~O(n^2+ n b).\n  An unbiased estimator of (AB)_{ij} with variance at most ||AB||_F^2 / b can\nthen be computed as:\n  C_{ij} = s_1(i) s_2(j) c_{(h_1(i)+h_2(j)) mod b.\n  Our approach also leads to an algorithm for computing AB exactly, whp., in\ntime \\~O(N + nb) in the case where A and B have at most N nonzero entries, and\nAB has at most b nonzero entries.\n  Also, we use error-correcting codes in a novel way to recover significant\nentries of AB in near-linear time.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2011 12:29:06 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2011 18:02:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Pagh", "Rasmus", ""]]}, {"id": "1108.1351", "submitter": "Raied Salman Dr", "authors": "Raied Salman, Vojislav Kecman, Qi Li, Robert Strack and Erik Test", "title": "Fast k-means algorithm clustering", "comments": "16 pages, Wimo2011; International Journal of Computer Networks &\n  Communications (IJCNC) Vol.3, No.4, July 2011", "journal-ref": null, "doi": "10.5121/ijcnc.2011.3402", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-means has recently been recognized as one of the best algorithms for\nclustering unsupervised data. Since k-means depends mainly on distance\ncalculation between all data points and the centers, the time cost will be high\nwhen the size of the dataset is large (for example more than 500millions of\npoints). We propose a two stage algorithm to reduce the time cost of distance\ncalculation for huge datasets. The first stage is a fast distance calculation\nusing only a small portion of the data to produce the best possible location of\nthe centers. The second stage is a slow distance calculation in which the\ninitial centers used are taken from the first stage. The fast and slow stages\nrepresent the speed of the movement of the centers. In the slow stage, the\nwhole dataset can be used to get the exact location of the centers. The time\ncost of the distance calculation for the fast stage is very low due to the\nsmall size of the training data chosen. The time cost of the distance\ncalculation for the slow stage is also minimized due to small number of\niterations. Different initial locations of the clusters have been used during\nthe test of the proposed algorithms. For large datasets, experiments show that\nthe 2-stage clustering method achieves better speed-up (1-9 times).\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2011 15:37:23 GMT"}], "update_date": "2011-08-08", "authors_parsed": [["Salman", "Raied", ""], ["Kecman", "Vojislav", ""], ["Li", "Qi", ""], ["Strack", "Robert", ""], ["Test", "Erik", ""]]}, {"id": "1108.1439", "submitter": "Evgenios M. Kornaropoulos", "authors": "Evgenios M. Kornaropoulos, Ioannis G. Tollis", "title": "Weak Dominance Drawings and Linear Extension Diameter", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of Weak Dominance Drawing for general directed\nacyclic graphs and we show the connection with the linear extension diameter of\na partial order P. We present complexity results and bounds.\n", "versions": [{"version": "v1", "created": "Sat, 6 Aug 2011 01:50:59 GMT"}], "update_date": "2011-08-09", "authors_parsed": [["Kornaropoulos", "Evgenios M.", ""], ["Tollis", "Ioannis G.", ""]]}, {"id": "1108.1751", "submitter": "Joel Oren", "authors": "Siavosh Benabbas, Hyun Chul Lee, Joel Oren, Yuli Ye", "title": "Efficient Sum-Based Hierarchical Smoothing Under \\ell_1-Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new regression problem which we call the Sum-Based\nHierarchical Smoothing problem. Given a directed acyclic graph and a\nnon-negative value, called target value, for each vertex in the graph, we wish\nto find non-negative values for the vertices satisfying a certain constraint\nwhile minimizing the distance of these assigned values and the target values in\nthe lp-norm. The constraint is that the value assigned to each vertex should be\nno less than the sum of the values assigned to its children. We motivate this\nproblem with applications in information retrieval and web mining. While our\nproblem can be solved in polynomial time using linear programming, given the\ninput size in these applications such a solution might be too slow. We mainly\nstudy the \\ell_1-norm case restricting the underlying graphs to rooted trees.\nFor this case we provide an efficient algorithm, running in O(n^2) time. While\nthe algorithm is purely combinatorial, its proof of correctness is an elegant\nuse of linear programming duality. We believe that our approach may be\napplicable to similar problems, where comparable hierarchical constraints are\ninvolved, e.g. considering the average of the values assigned to the children\nof each vertex. While similar in flavor to other smoothing problems like\nIsotonic Regression (see for example [Angelov et al. SODA'06]), our problem is\narguably richer and theoretically more challenging.\n", "versions": [{"version": "v1", "created": "Mon, 8 Aug 2011 17:07:06 GMT"}], "update_date": "2011-08-09", "authors_parsed": [["Benabbas", "Siavosh", ""], ["Lee", "Hyun Chul", ""], ["Oren", "Joel", ""], ["Ye", "Yuli", ""]]}, {"id": "1108.1781", "submitter": "Eyal Lubetzky", "authors": "Tom Bohman, Alan Frieze, Eyal Lubetzky", "title": "Random greedy triangle-packing beyond the 7/4 barrier", "comments": "20 pages. Superceded by arXiv:1203.4223", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random greedy algorithm for constructing a large partial\nSteiner-Triple-System is defined as follows. Begin with a complete graph on $n$\nvertices and proceed to remove the edges of triangles one at a time, where each\ntriangle removed is chosen uniformly at random out of all remaining triangles.\nThis stochastic process terminates once it arrives at a triangle-free graph,\nand a longstanding open problem is to estimate the final number of edges, or\nequivalently the time it takes the process to conclude. The intuition that the\nedge distribution is roughly uniform at all times led to a folklore conjecture\nthat the final number of edges is $n^{3/2+o(1)}$ with high probability, whereas\nthe best known upper bound is $n^{7/4+o(1)}$. It is no coincidence that various\nmethods break precisely at the exponent 7/4 as it corresponds to the inherent\nbarrier where co-degrees become comparable to the variations in their values\nthat arose earlier in the process.\n  In this work we significantly improve upon the previous bounds by\nestablishing that w.h.p. the number of edges in the final graph is at most $\nn^{5/3+o(1)} $. Our approach relies on a system of martingales used to control\nkey graph parameters, where the crucial new idea is to harness the\nself-correcting nature of the process in order to control these parameters well\nbeyond the point where their early variation matches the order of their\nexpectation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Aug 2011 19:00:24 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 22:57:02 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Bohman", "Tom", ""], ["Frieze", "Alan", ""], ["Lubetzky", "Eyal", ""]]}, {"id": "1108.1926", "submitter": "Bernhard Haeupler", "authors": "Alejandro Cornejo, Bernhard Haeupler, Fabian Kuhn", "title": "Computing a Maximal Independent Set Using Beeps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a maximal independent set (MIS) in the\ndiscrete beeping model. At each time, a node in the network can either beep\n(i.e., emit a signal) or be silent. Silent nodes can only differentiate between\nno neighbor beeping, or at least one neighbor beeping. This basic communication\nmodel relies only on carrier-sensing. Furthermore, we assume nothing about the\nunderlying communication graph and allow nodes to wake up (and crash)\narbitrarily.\n  We show that if a polynomial upper bound on the size of the network n is\nknown, then with high probability every node becomes stable in O(\\log^3 n) time\nafter it is woken up. To contrast this, we establish a polynomial lower bound\nwhen no a priori upper bound on the network size is known. This holds even in\nthe much stronger model of local message broadcast with collision detection.\n  Finally, if we assume nodes have access to synchronized clocks or we consider\na somewhat restricted wake up, we can solve the MIS problem in O(\\log^2 n) time\nwithout requiring an upper bound on the size of the network, thereby achieving\nthe same bit complexity as Luby's MIS algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2011 13:42:00 GMT"}], "update_date": "2011-08-10", "authors_parsed": [["Cornejo", "Alejandro", ""], ["Haeupler", "Bernhard", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1108.1983", "submitter": "Rajeev Raman", "authors": "J. Ian Munro and Rajeev Raman and Venkatesh Raman and S. Srinivasa Rao", "title": "Succinct Representations of Permutations and Functions", "comments": "Preliminary versions of these results have appeared in the\n  Proceedings of ICALP 2003 and 2004. However, all results in this version are\n  improved over the earlier conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of succinctly representing an arbitrary\npermutation, \\pi, on {0,...,n-1} so that \\pi^k(i) can be computed quickly for\nany i and any (positive or negative) integer power k. A representation taking\n(1+\\epsilon) n lg n + O(1) bits suffices to compute arbitrary powers in\nconstant time, for any positive constant \\epsilon <= 1. A representation taking\nthe optimal \\ceil{\\lg n!} + o(n) bits can be used to compute arbitrary powers\nin O(lg n / lg lg n) time.\n  We then consider the more general problem of succinctly representing an\narbitrary function, f: [n] \\rightarrow [n] so that f^k(i) can be computed\nquickly for any i and any integer power k. We give a representation that takes\n(1+\\epsilon) n lg n + O(1) bits, for any positive constant \\epsilon <= 1, and\ncomputes arbitrary positive powers in constant time. It can also be used to\ncompute f^k(i), for any negative integer k, in optimal O(1+|f^k(i)|) time.\n  We place emphasis on the redundancy, or the space beyond the\ninformation-theoretic lower bound that the data structure uses in order to\nsupport operations efficiently. A number of lower bounds have recently been\nshown on the redundancy of data structures. These lower bounds confirm the\nspace-time optimality of some of our solutions. Furthermore, the redundancy of\none of our structures \"surpasses\" a recent lower bound by Golynski [Golynski,\nSODA 2009], thus demonstrating the limitations of this lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2011 17:01:12 GMT"}], "update_date": "2011-08-10", "authors_parsed": [["Munro", "J. Ian", ""], ["Raman", "Rajeev", ""], ["Raman", "Venkatesh", ""], ["Rao", "S. Srinivasa", ""]]}, {"id": "1108.2063", "submitter": "Muriel Dulieu", "authors": "Boris Aronov and Muriel Dulieu", "title": "How to Cover a Point Set with a V-Shape of Minimum Width", "comments": "In Proceedings of the 12th International Symposium on Algorithms and\n  Data Structures (WADS), p.61-72, August 2011, New York, NY, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A balanced V-shape is a polygonal region in the plane contained in the union\nof two crossing equal-width strips. It is delimited by two pairs of parallel\nrays that emanate from two points x, y, are contained in the strip boundaries,\nand are mirror-symmetric with respect to the line xy. The width of a balanced\nV-shape is the width of the strips. We first present an O(n^2 log n) time\nalgorithm to compute, given a set of n points P, a minimum-width balanced\nV-shape covering P. We then describe a PTAS for computing a\n(1+epsilon)-approximation of this V-shape in time O((n/epsilon)log\nn+(n/epsilon^(3/2))log^2(1/epsilon)). A much simpler constant-factor\napproximation algorithm is also described.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2011 22:29:31 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Aronov", "Boris", ""], ["Dulieu", "Muriel", ""]]}, {"id": "1108.2157", "submitter": "Rajeev Raman", "authors": "Alexander Golynski and Alessio Orlandi and Rajeev Raman and S.\n  Srinivasa Rao", "title": "Optimal Indexes for Sparse Bit Vectors", "comments": "Some of these results were published in preliminary form in the\n  proceedings of SWAT 2008. There are new upper bounds not in the SWAT version,\n  however", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of supporting Rank() and Select() operations on a bit\nvector of length m with n 1 bits. The problem is considered in the succinct\nindex model, where the bit vector is stored in \"read-only\" memory and an\nadditional data structure, called the index, is created during pre-processing\nto help answer the above queries. We give asymptotically optimal\ndensity-sensitive trade-offs, involving both m and n, that relate the size of\nthe index to the number of accesses to the bit vector (and processing time)\nneeded to answer the above queries. The results are particularly interesting\nfor the case where n = o(m).\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2011 11:36:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Golynski", "Alexander", ""], ["Orlandi", "Alessio", ""], ["Raman", "Rajeev", ""], ["Rao", "S. Srinivasa", ""]]}, {"id": "1108.2191", "submitter": "Robert Bredereck", "authors": "Robert Bredereck", "title": "Graph and Election Problems Parameterized by Feedback Set Numbers", "comments": "A full-featured version can be found at http://robert.bredereck.info,\n  where you can also find the complete abstract. (ArXiv allows only 1920\n  characters.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the parameterized complexity of three related graph\nmodification problems. Given a directed graph, a distinguished vertex, and a\npositive integer k, Minimum Indegree Deletion asks for a vertex subset of size\nat most k whose removal makes the distinguished vertex the only vertex with\nminimum indegree. Minimum Degree Deletion is analogously defined, but deals\nwith undirected graphs. Bounded Degree Deletion is also defined on undirected\ngraphs, but has a positive integer d instead of a distinguished vertex as part\nof the input. It asks for a vertex subset of size at most k whose removal\nresults in a graph in which every vertex has degree at most d. The first two\nproblems have applications in computational social choice whereas the third\nproblem is used in computational biology. We investigate the parameterized\ncomplexity with respect to the parameters \"treewidth\", \"size of a feedback\nvertex set\" and \"size of a feedback edge set\" respectively \"size of a feedback\narc set\". Each of these parameters measures the \"degree of acyclicity\" in\ndifferent ways.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2011 14:33:05 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Bredereck", "Robert", ""]]}, {"id": "1108.2290", "submitter": "James Lee", "authors": "James R. Lee and Arnaud de Mesmay and Mohammad Moharrami", "title": "Dimension reduction for finite trees in L_1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every n-point tree metric admits a (1+eps)-embedding into a\nC(eps) log n-dimensional L_1 space, for every eps > 0, where C(eps) =\nO((1/eps)^4 log(1/eps)). This matches the natural volume lower bound up to a\nfactor depending only on eps. Previously, it was unknown whether even complete\nbinary trees on n nodes could be embedded in O(log n) dimensions with O(1)\ndistortion. For complete d-ary trees, our construction achieves C(eps) =\nO(1/eps^2).\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2011 21:23:12 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2011 01:51:17 GMT"}, {"version": "v3", "created": "Tue, 6 Sep 2011 18:07:33 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Lee", "James R.", ""], ["de Mesmay", "Arnaud", ""], ["Moharrami", "Mohammad", ""]]}, {"id": "1108.2464", "submitter": "Assaf Naor", "authors": "Subhash Khot and Assaf Naor", "title": "Grothendieck-type inequalities in combinatorial optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey connections of the Grothendieck inequality and its variants to\ncombinatorial optimization and computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2011 17:05:51 GMT"}], "update_date": "2011-08-12", "authors_parsed": [["Khot", "Subhash", ""], ["Naor", "Assaf", ""]]}, {"id": "1108.2498", "submitter": "Vadim Zharnitsky", "authors": "Yuliy Baryshnikov and Vadim Zharnitsky", "title": "Search on the Brink of Chaos", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": "10.1088/0951-7715/25/11/3023", "report-no": null, "categories": "math.CA cs.DS math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical linear search problem is studied from the view point of\nHamiltonian dynamics. For the specific, yet representative case of\nexponentially distributed position of the hidden object, we show that the\noptimal plan follows an unstable separatrix which is present in the associated\nHamiltonian system.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2011 19:36:47 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2011 22:34:33 GMT"}, {"version": "v3", "created": "Fri, 25 May 2012 19:16:12 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Baryshnikov", "Yuliy", ""], ["Zharnitsky", "Vadim", ""]]}, {"id": "1108.2664", "submitter": "Christopher Whidden", "authors": "Chris Whidden, Robert G. Beiko, and Norbert Zeh", "title": "Fixed-Parameter and Approximation Algorithms for Maximum Agreement\n  Forests", "comments": "36 pages, 9 figures. Removed the Approximation and TBR sections and\n  simplified the Hybridization section. To appear in SIAM Journal on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new and improved fixed-parameter algorithms for computing maximum\nagreement forests (MAFs) of pairs of rooted binary phylogenetic trees. The size\nof such a forest for two trees corresponds to their subtree prune-and-regraft\ndistance and, if the agreement forest is acyclic, to their hybridization\nnumber. These distance measures are essential tools for understanding\nreticulate evolution. Our algorithm for computing maximum acyclic agreement\nforests is the first depth-bounded search algorithm for this problem. Our\nalgorithms substantially outperform the best previous algorithms for these\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2011 17:20:39 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 14:53:59 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Whidden", "Chris", ""], ["Beiko", "Robert G.", ""], ["Zeh", "Norbert", ""]]}, {"id": "1108.3048", "submitter": "Michael Kallitsis", "authors": "Michael Kallitsis, Stilian Stoev, George Michailidis", "title": "Fast Approximation Algorithms for Near-optimal Large-scale Network\n  Monitoring", "comments": "Paper withdrawn since the official journal paper is now available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimal traffic prediction and monitoring in\nlarge-scale networks. Our goal is to determine which subset of K links to\nmonitor in order to \"best\" predict the traffic on the remaining links in the\nnetwork. We consider several optimality criteria. This can be formulated as a\ncombinatorial optimization problem, belonging to the family of subset selection\nproblems. Similar NP-hard problems arise in statistics, machine learning and\nsignal processing. Some include subset selection for regression, variable\nselection, and sparse approximation. Exact solutions are computationally\nprohibitive. We present both new heuristics as well as new efficient algorithms\nimplementing the classical greedy heuristic - commonly used to tackle such\ncombinatorial problems. Our approach exploits connections to principal\ncomponent analysis (PCA), and yields new types of performance lower bounds\nwhich do not require submodularity of the objective functions. We show that an\nensemble method applied to our new randomized heuristic algorithm, often\noutperforms the classical greedy heuristic in practice. We evaluate our\nalgorithms under several large-scale networks, including real life networks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2011 18:27:11 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 20:11:38 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Kallitsis", "Michael", ""], ["Stoev", "Stilian", ""], ["Michailidis", "George", ""]]}, {"id": "1108.3092", "submitter": "Tamara Mchedlidze David", "authors": "Michael Kaufmann, Tamara Mchedlidze, Antonios Symvonis", "title": "Upward Point Set Embeddability for Convex Point Sets is in $P$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a polynomial dynamic programming algorithm that\ntests whether a $n$-vertex directed tree $T$ has an upward planar embedding\ninto a convex point-set $S$ of size $n$. Further, we extend our approach to the\nclass of outerplanar digraphs. This nontrivial and surprising result implies\nthat any given digraph can be efficiently tested for an upward planar embedding\ninto a given convex point set.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2011 20:35:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kaufmann", "Michael", ""], ["Mchedlidze", "Tamara", ""], ["Symvonis", "Antonios", ""]]}, {"id": "1108.3112", "submitter": "Elchanan Mossel", "authors": "Elchanan Mossel, Sebastien Roch", "title": "Phylogenetic mixtures: Concentration of measure in the large-tree limit", "comments": "Published in at http://dx.doi.org/10.1214/11-AAP837 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 6, 2429-2459", "doi": "10.1214/11-AAP837", "report-no": "IMS-AAP-AAP837", "categories": "math.PR cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction of phylogenies from DNA or protein sequences is a major\ntask of computational evolutionary biology. Common phenomena, notably\nvariations in mutation rates across genomes and incongruences between gene\nlineage histories, often make it necessary to model molecular data as\noriginating from a mixture of phylogenies. Such mixed models play an\nincreasingly important role in practice. Using concentration of measure\ntechniques, we show that mixtures of large trees are typically identifiable. We\nalso derive sequence-length requirements for high-probability reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2011 22:45:35 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 07:47:31 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Mossel", "Elchanan", ""], ["Roch", "Sebastien", ""]]}, {"id": "1108.3383", "submitter": "Tyson Williams", "authors": "Jin-Yi Cai, Michael Kowalczyk, and Tyson Williams", "title": "Gadgets and Anti-Gadgets Leading to a Complexity Dichotomy", "comments": "26 pages, 14 figures, To appear at ITCS 2012, New version changes:\n  minor copy edits, workaround for arXiv bug that made subscript references too\n  large", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an idea called anti-gadgets in complexity reductions. These\ncombinatorial gadgets have the effect of erasing the presence of some other\ngraph fragment, as if we had managed to include a negative copy of a graph\ngadget. We use this idea to prove a complexity dichotomy theorem for the\npartition function $Z(G)$ on 3-regular directed graphs $G$, where each edge is\ngiven a complex-valued binary function $f: \\{0,1\\}^2 \\rightarrow \\mathbb{C}$.\nWe show that \\[Z(G) = \\sum_{\\sigma: V(G) \\to \\{0,1\\}} \\prod_{(u,v) \\in E(G)}\nf(\\sigma(u), \\sigma(v)),\\] is either computable in polynomial time or #P-hard,\ndepending explicitly on $f$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2011 02:17:51 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2011 23:45:36 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Kowalczyk", "Michael", ""], ["Williams", "Tyson", ""]]}, {"id": "1108.3413", "submitter": "Qin Zhang", "authors": "Zengfeng Huang and Ke Yi and Qin Zhang", "title": "Randomized Algorithms for Tracking Distributed Count, Frequencies, and\n  Ranks", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that randomization can lead to significant improvements for a few\nfundamental problems in distributed tracking. Our basis is the {\\em\ncount-tracking} problem, where there are $k$ players, each holding a counter\n$n_i$ that gets incremented over time, and the goal is to track an\n$\\eps$-approximation of their sum $n=\\sum_i n_i$ continuously at all times,\nusing minimum communication. While the deterministic communication complexity\nof the problem is $\\Theta(k/\\eps \\cdot \\log N)$, where $N$ is the final value\nof $n$ when the tracking finishes, we show that with randomization, the\ncommunication cost can be reduced to $\\Theta(\\sqrt{k}/\\eps \\cdot \\log N)$. Our\nalgorithm is simple and uses only O(1) space at each player, while the lower\nbound holds even assuming each player has infinite computing power. Then, we\nextend our techniques to two related distributed tracking problems: {\\em\nfrequency-tracking} and {\\em rank-tracking}, and obtain similar improvements\nover previous deterministic algorithms. Both problems are of central importance\nin large data monitoring and analysis, and have been extensively studied in the\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2011 07:31:27 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2011 10:39:34 GMT"}], "update_date": "2011-12-05", "authors_parsed": [["Huang", "Zengfeng", ""], ["Yi", "Ke", ""], ["Zhang", "Qin", ""]]}, {"id": "1108.3516", "submitter": "Panteleimon Rodis", "authors": "Panteleimon Rodis", "title": "Model for networks of spatial objects and simulation of geographical\n  phenomena propagation", "comments": "19 pages, 4 figures; theoretical substantiation corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of this paper is the presentation of a new network model designed\nfor networks consisting of spatial objects. This model allows the development\nof more advance representations of systems of networked objects and the study\nof geographical phenomena propagated through networks. The capabilities of the\nmodel in simulation of geographical phenomena propagation are also studied and\nrelevant algorithms are presented. As examples of use, modeling of water supply\nnetwork and the simulation of traffic flow in road networks are presented.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2011 16:13:53 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2011 22:23:20 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2012 23:02:09 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Rodis", "Panteleimon", ""]]}, {"id": "1108.3556", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Charles H. Cannon, Zhanshan Sam Ma, Douglas W. Yu, Mihai\n  Pop", "title": "SparseAssembler2: Sparse k-mer Graph for Memory Efficient Genome\n  Assembly", "comments": "Corresponding authors: Zhanshan (Sam) Ma, ma@vandals.uidaho.edu;\n  Mihai Pop, mpop@umiacs.umd.edu || Availability: Programs in both Windows and\n  Linux are available at: https://sites.google.com/site/sparseassembler/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formal version of our work has been published in BMC Bioinformatics and\ncan be found here: http://www.biomedcentral.com/1471-2105/13/S6/S1 Motivation:\nTo tackle the problem of huge memory usage associated with de Bruijn\ngraph-based algorithms, upon which some of the most widely used de novo genome\nassemblers have been built, we released SparseAssembler1. SparseAssembler1 can\nsave as much as 90% memory consumption in comparison with the state-of-art\nassemblers, but it requires rounds of denoising to accurately assemble genomes.\nIn this paper, we introduce a new general model for genome assembly that uses\nonly sparse k-mers. The new model replaces the idea of the de Bruijn graph from\nthe beginning, and achieves similar memory efficiency and much better\nrobustness compared with our previous SparseAssembler1. Results: We demonstrate\nthat the decomposition of reads of all overlapping k-mers, which is used in\nexisting de Bruijn graph genome assemblers, is overly cautious. We introduce a\nsparse k-mer graph structure for saving sparse k-mers, which greatly reduces\nmemory space requirements necessary for de novo genome assembly. In contrast\nwith the de Bruijn graph approach, we devise a simple but powerful strategy,\ni.e., finding links between the k-mers in the genome and traversing following\nthe links, which can be done by saving only a few k-mers. To implement the\nstrategy, we need to only select some k-mers that may not even be overlapping\nones, and build the links between these k-mers indicated by the reads. We can\ntraverse through this sparse k-mer graph to build the contigs, and ultimately\ncomplete the genome assembly. Since the new sparse k-mers graph shares almost\nall advantages of de Bruijn graph, we are able to adapt a Dijkstra-like\nbreadth-first search algorithm to circumvent sequencing errors and resolve\npolymorphisms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2011 19:24:45 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2013 19:12:17 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Ye", "Chengxi", ""], ["Cannon", "Charles H.", ""], ["Ma", "Zhanshan Sam", ""], ["Yu", "Douglas W.", ""], ["Pop", "Mihai", ""]]}, {"id": "1108.3636", "submitter": "EPTCS", "authors": "Mathieu Roux (LMNO and GREYC, CNRS and University of Caen, France),\n  Brigitte Vall\\'ee (GREYC, CNRS and University of Caen, France)", "title": "Information theory: Sources, Dirichlet series, and realistic analyses of\n  data structures", "comments": "In Proceedings WORDS 2011, arXiv:1108.3412", "journal-ref": "EPTCS 63, 2011, pp. 199-214", "doi": "10.4204/EPTCS.63.26", "report-no": null, "categories": "cs.IT cs.DM cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the text algorithms build data structures on words, mainly trees, as\ndigital trees (tries) or binary search trees (bst). The mechanism which\nproduces symbols of the words (one symbol at each unit time) is called a\nsource, in information theory contexts. The probabilistic behaviour of the\ntrees built on words emitted by the same source depends on two factors: the\nalgorithmic properties of the tree, together with the information-theoretic\nproperties of the source. Very often, these two factors are considered in a too\nsimplified way: from the algorithmic point of view, the cost of the Bst is only\nmeasured in terms of the number of comparisons between words --from the\ninformation theoretic point of view, only simple sources (memoryless sources or\nMarkov chains) are studied.\n  We wish to perform here a realistic analysis, and we choose to deal together\nwith a general source and a realistic cost for data structures: we take into\naccount comparisons between symbols, and we consider a general model of source,\nrelated to a dynamical system, which is called a dynamical source. Our methods\nare close to analytic combinatorics, and our main object of interest is the\ngenerating function of the source Lambda(s), which is here of Dirichlet type.\nSuch an object transforms probabilistic properties of the source into analytic\nproperties. The tameness of the source, which is defined through analytic\nproperties of Lambda(s), appears to be central in the analysis, and is\nprecisely studied for the class of dynamical sources. We focus here on\narithmetical conditions, of diophantine type, which are sufficient to imply\ntameness on a domain with hyperbolic shape.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2011 03:54:43 GMT"}], "update_date": "2011-08-19", "authors_parsed": [["Roux", "Mathieu", "", "LMNO and GREYC, CNRS and University of Caen, France"], ["Vall\u00e9e", "Brigitte", "", "GREYC, CNRS and University of Caen, France"]]}, {"id": "1108.3655", "submitter": "Charl Ras", "authors": "M. Brazil, C.J. Ras, D.A. Thomas", "title": "The bottleneck 2-connected $k$-Steiner network problem for $k\\leq 2$", "comments": null, "journal-ref": "Discrete Applied Mathematics 160 (2012) 1028-1038", "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric bottleneck Steiner network problem on a set of vertices $X$\nembedded in a normed plane requires one to construct a graph $G$ spanning $X$\nand a variable set of $k\\geq 0$ additional points, such that the length of the\nlongest edge is minimised. If no other constraints are placed on $G$ then a\nsolution always exists which is a tree. In this paper we consider the Euclidean\nbottleneck Steiner network problem for $k\\leq 2$, where $G$ is constrained to\nbe 2-connected. By taking advantage of relative neighbourhood graphs, Voronoi\ndiagrams, and the tree structure of block cut-vertex decompositions of graphs,\nwe produce exact algorithms of complexity $O(n^2)$ and $O(n^2\\log n)$ for the\ncases $k=1$ and $k=2$ respectively. Our algorithms can also be extended to\nother norms such as the $L_p$ planes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2011 06:15:35 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Brazil", "M.", ""], ["Ras", "C. J.", ""], ["Thomas", "D. A.", ""]]}, {"id": "1108.3683", "submitter": "Philip Bille", "authors": "Philip Bille and Inge Li Goertz", "title": "Substring Range Reporting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit various string indexing problems with range reporting features,\nnamely, position-restricted substring searching, indexing substrings with gaps,\nand indexing substrings with intervals. We obtain the following main results.\n{itemize} We give efficient reductions for each of the above problems to a new\nproblem, which we call \\emph{substring range reporting}. Hence, we unify the\nprevious work by showing that we may restrict our attention to a single problem\nrather than studying each of the above problems individually. We show how to\nsolve substring range reporting with optimal query time and little space.\nCombined with our reductions this leads to significantly improved time-space\ntrade-offs for the above problems. In particular, for each problem we obtain\nthe first solutions with optimal time query and $O(n\\log^{O(1)} n)$ space,\nwhere $n$ is the length of the indexed string. We show that our techniques for\nsubstring range reporting generalize to \\emph{substring range counting} and\n\\emph{substring range emptiness} variants. We also obtain non-trivial\ntime-space trade-offs for these problems. {itemize} Our bounds for substring\nrange reporting are based on a novel combination of suffix trees and range\nreporting data structures. The reductions are simple and general and may apply\nto other combinations of string indexing with range reporting.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2011 08:31:11 GMT"}], "update_date": "2011-08-19", "authors_parsed": [["Bille", "Philip", ""], ["Goertz", "Inge Li", ""]]}, {"id": "1108.4034", "submitter": "Thang Dinh", "authors": "Thang N. Dinh and My T. Thai", "title": "Finding Community Structure with Performance Guarantees in Complex\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many networks including social networks, computer networks, and biological\nnetworks are found to divide naturally into communities of densely connected\nindividuals. Finding community structure is one of fundamental problems in\nnetwork science. Since Newman's suggestion of using \\emph{modularity} as a\nmeasure to qualify the goodness of community structures, many efficient methods\nto maximize modularity have been proposed but without a guarantee of\noptimality. In this paper, we propose two polynomial-time algorithms to the\nmodularity maximization problem with theoretical performance guarantees. The\nfirst algorithm comes with a \\emph{priori guarantee} that the modularity of\nfound community structure is within a constant factor of the optimal modularity\nwhen the network has the power-law degree distribution. Despite being mainly of\ntheoretical interest, to our best knowledge, this is the first approximation\nalgorithm for finding community structure in networks. In our second algorithm,\nwe propose a \\emph{sparse metric}, a substantially faster linear programming\nmethod for maximizing modularity and apply a rounding technique based on this\nsparse metric with a \\emph{posteriori approximation guarantee}. Our experiments\nshow that the rounding algorithm returns the optimal solutions in most cases\nand are very scalable, that is, it can run on a network of a few thousand nodes\nwhereas the LP solution in the literature only ran on a network of at most 235\nnodes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2011 19:59:18 GMT"}], "update_date": "2011-08-22", "authors_parsed": [["Dinh", "Thang N.", ""], ["Thai", "My T.", ""]]}, {"id": "1108.4142", "submitter": "Aleksandrs Slivkins", "authors": "Moshe Babaioff, Shaddin Dughmi, Robert Kleinberg and Aleksandrs\n  Slivkins", "title": "Dynamic Pricing with Limited Supply", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of dynamic pricing with limited supply. A seller has\n$k$ identical items for sale and is facing $n$ potential buyers (\"agents\") that\nare arriving sequentially. Each agent is interested in buying one item. Each\nagent's value for an item is an IID sample from some fixed distribution with\nsupport $[0,1]$. The seller offers a take-it-or-leave-it price to each arriving\nagent (possibly different for different agents), and aims to maximize his\nexpected revenue.\n  We focus on \"prior-independent\" mechanisms -- ones that do not use any\ninformation about the distribution. They are desirable because knowing the\ndistribution is unrealistic in many practical scenarios. We study how the\nrevenue of such mechanisms compares to the revenue of the optimal offline\nmechanism that knows the distribution (\"offline benchmark\").\n  We present a prior-independent dynamic pricing mechanism whose revenue is at\nmost $O((k \\log n)^{2/3})$ less than the offline benchmark, for every\ndistribution that is regular. In fact, this guarantee holds without *any*\nassumptions if the benchmark is relaxed to fixed-price mechanisms. Further, we\nprove a matching lower bound. The performance guarantee for the same mechanism\ncan be improved to $O(\\sqrt{k} \\log n)$, with a distribution-dependent\nconstant, if $k/n$ is sufficiently small. We show that, in the worst case over\nall demand distributions, this is essentially the best rate that can be\nobtained with a distribution-specific constant.\n  On a technical level, we exploit the connection to multi-armed bandits (MAB).\nWhile dynamic pricing with unlimited supply can easily be seen as an MAB\nproblem, the intuition behind MAB approaches breaks when applied to the setting\nwith limited supply. Our high-level conceptual contribution is that even the\nlimited supply setting can be fruitfully treated as a bandit problem.\n", "versions": [{"version": "v1", "created": "Sat, 20 Aug 2011 20:28:09 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 18:42:22 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 20:08:07 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Babaioff", "Moshe", ""], ["Dughmi", "Shaddin", ""], ["Kleinberg", "Robert", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "1108.4217", "submitter": "Yoshinobu Kawahara", "authors": "Yoshinobu Kawahara and Takashi Washio", "title": "Prismatic Algorithm for Discrete D.C. Programming Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the first exact algorithm for minimizing the\ndifference of two submodular functions (D.S.), i.e., the discrete version of\nthe D.C. programming problem. The developed algorithm is a\nbranch-and-bound-based algorithm which responds to the structure of this\nproblem through the relationship between submodularity and convexity. The D.S.\nprogramming problem covers a broad range of applications in machine learning\nbecause this generalizes the optimization of a wide class of set functions. We\nempirically investigate the performance of our algorithm, and illustrate the\ndifference between exact and approximate solutions respectively obtained by the\nproposed and existing algorithms in feature selection and discriminative\nstructure learning.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2011 22:09:21 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["Kawahara", "Yoshinobu", ""], ["Washio", "Takashi", ""]]}, {"id": "1108.4358", "submitter": "Gunnar W. Klau", "authors": "Mohammed El-Kebir and Jaap Heringa and Gunnar W. Klau", "title": "Lagrangian Relaxation Applied to Sparse Global Network Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data on molecular interactions is increasing at a tremendous pace, while the\ndevelopment of solid methods for analyzing this network data is lagging behind.\nThis holds in particular for the field of comparative network analysis, where\none wants to identify commonalities between biological networks. Since\nbiological functionality primarily operates at the network level, there is a\nclear need for topology-aware comparison methods.\n  In this paper we present a method for global network alignment that is fast\nand robust, and can flexibly deal with various scoring schemes taking both\nnode-to-node correspondences as well as network topologies into account. It is\nbased on an integer linear programming formulation, generalizing the\nwell-studied quadratic assignment problem. We obtain strong upper and lower\nbounds for the problem by improving a Lagrangian relaxation approach and\nintroduce the software tool natalie 2.0, a publicly available implementation of\nour method. In an extensive computational study on protein interaction networks\nfor six different species, we find that our new method outperforms alternative\nstate-of-the-art methods with respect to quality and running time.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2011 15:52:10 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["El-Kebir", "Mohammed", ""], ["Heringa", "Jaap", ""], ["Klau", "Gunnar W.", ""]]}, {"id": "1108.4408", "submitter": "Gonzalo Navarro", "authors": "J\\'er\\'emy Barbay and Gonzalo Navarro", "title": "On Compressing Permutations and Adaptive Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous compact representations of permutations have focused on adding a\nsmall index on top of the plain data $<\\pi(1), \\pi(2),...\\pi(n)>$, in order to\nefficiently support the application of the inverse or the iterated permutation.\n  In this paper we initiate the study of techniques that exploit the\ncompressibility of the data itself, while retaining efficient computation of\n$\\pi(i)$ and its inverse.\n  In particular, we focus on exploiting {\\em runs}, which are subsets\n(contiguous or not) of the domain where the permutation is monotonic.\n  Several variants of those types of runs arise in real applications such as\ninverted indexes and suffix arrays.\n  Furthermore, our improved results on compressed data structures for\npermutations also yield better adaptive sorting algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2011 19:59:03 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1108.4501", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin, Mark Jones, Venkatesh Raman, and Saket\n  Saurabh", "title": "Parameterized Complexity of MaxSat Above Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In MaxSat, we are given a CNF formula $F$ with $n$ variables and $m$ clauses\nand asked to find a truth assignment satisfying the maximum number of clauses.\nLet $r_1,..., r_m$ be the number of literals in the clauses of $F$. Then\n$asat(F)=\\sum_{i=1}^m (1-2^{-r_i})$ is the expected number of clauses satisfied\nby a random truth assignment (the truth values to the variables are distributed\nuniformly and independently). It is well-known that, in polynomial time, one\ncan find a truth assignment satisfying at least $asat(F)$ clauses. In the\nparameterized problem MaxSat-AA, we are to decide whether there is a truth\nassignment satisfying at least $asat(F)+k$ clauses, where $k$ is the parameter.\nWe prove that MaxSat-AA is para-NP-complete and, thus, MaxSat-AA is not\nfixed-parameter tractable unless P$=$NP. This is in sharp contrast to\nMaxLin2-AA which was recently proved to be fixed-parameter tractable by\nCrowston et al. (arXiv:1104.1135v3). In fact, we consider a more refined\nversion of {\\sc MaxSat-AA}, {\\sc Max-$r(n)$-Sat-AA}, where $r_j\\le r(n)$ for\neach $j$. Alon {\\em et al.} (SODA 2010) proved that if $r=r(n)$ is a constant,\nthen {\\sc Max-$r$-Sat-AA} is fixed-parameter tractable. We prove that {\\sc\nMax-$r(n)$-Sat-AA} is para-NP-complete for $r(n)=\\lceil \\log n\\rceil.$ We also\nprove that assuming the exponential time hypothesis, {\\sc Max-$r(n)$-Sat-AA} is\nnot in XP already for any $r(n)\\ge \\log \\log n +\\phi(n)$, where $\\phi(n)$ is\nany unbounded strictly increasing function. This lower bound on $r(n)$ cannot\nbe decreased much further as we prove that {\\sc Max-$r(n)$-Sat-AA} is (i) in XP\nfor any $r(n)\\le \\log \\log n - \\log \\log \\log n$ and (ii) fixed-parameter\ntractable for any $r(n)\\le \\log \\log n - \\log \\log \\log n - \\phi(n)$, where\n$\\phi(n)$ is any unbounded strictly increasing function. The proof uses some\nresults on {\\sc MaxLin2-AA}.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2011 05:54:32 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2011 09:58:16 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Raman", "Venkatesh", ""], ["Saurabh", "Saket", ""]]}, {"id": "1108.4606", "submitter": "Mong-Jen Kao", "authors": "Mong-Jen Kao and D.T. Lee", "title": "Capacitated Domination: Constant Factor Approximation for Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the capacitated domination problem, which models a\nservice-requirement assigning scenario and which is also a generalization of\nthe dominating set problem. In this problem, we are given a graph with three\nparameters defined on the vertex set, which are cost, capacity, and demand. The\nobjective of this problem is to compute a demand assignment of least cost, such\nthat the demand of each vertex is fully-assigned to some of its closed\nneighbours without exceeding the amount of capacity they provide.\n  In this paper, we provide the first constant factor approximation for this\nproblem on planar graphs, based on a new perspective on the hierarchical\nstructure of outer-planar graphs. We believe that this new perspective and\ntechnique can be applied to other capacitated covering problems to help tackle\nvertices of large degrees.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2011 14:10:15 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Kao", "Mong-Jen", ""], ["Lee", "D. T.", ""]]}, {"id": "1108.4642", "submitter": "Steven Kelk", "authors": "Steven Kelk", "title": "A note on efficient computation of hybridization number via softwired\n  clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a new fixed parameter tractable algorithm to compute the\nhybridization number r of two rooted binary phylogenetic trees on taxon set X\nin time (6r)^r.poly(n), where n=|X|. The novelty of this approach is that it\navoids the use of Maximum Acyclic Agreement Forests (MAAFs) and instead\nexploits the equivalence of the problem with a related problem from the\nsoftwired clusters literature. This offers an alternative perspective on the\nunderlying combinatorial structure of the hybridization number problem.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2011 15:54:02 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Kelk", "Steven", ""]]}, {"id": "1108.4675", "submitter": "Lowell Trott", "authors": "David Eppstein, Michael T. Goodrich, Maarten L\\\"offler, Darren Strash,\n  Lowell Trott", "title": "Category-Based Routing in Social Networks: Membership Dimension and the\n  Small-World Phenomenon (Short)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic experiment by Milgram shows that individuals can route messages\nalong short paths in social networks, given only simple categorical information\nabout recipients (such as \"he is a prominent lawyer in Boston\" or \"she is a\nFreshman sociology major at Harvard\"). That is, these networks have very short\npaths between pairs of nodes (the so-called small-world phenomenon); moreover,\nparticipants are able to route messages along these paths even though each\nperson is only aware of a small part of the network topology. Some sociologists\nconjecture that participants in such scenarios use a greedy routing strategy in\nwhich they forward messages to acquaintances that have more categories in\ncommon with the recipient than they do, and similar strategies have recently\nbeen proposed for routing messages in dynamic ad-hoc networks of mobile\ndevices. In this paper, we introduce a network property called membership\ndimension, which characterizes the cognitive load required to maintain\nrelationships between participants and categories in a social network. We show\nthat any connected network has a system of categories that will support greedy\nrouting, but that these categories can be made to have small membership\ndimension if and only if the underlying network exhibits the small-world\nphenomenon.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2011 19:22:25 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""], ["L\u00f6ffler", "Maarten", ""], ["Strash", "Darren", ""], ["Trott", "Lowell", ""]]}, {"id": "1108.4803", "submitter": "Gregory Gutin", "authors": "G. Gutin and A. Yeo", "title": "Constraint Satisfaction Problems Parameterized Above or Below Tight\n  Bounds: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider constraint satisfaction problems parameterized above or below\ntight bounds. One example is MaxSat parameterized above $m/2$: given a CNF\nformula $F$ with $m$ clauses, decide whether there is a truth assignment that\nsatisfies at least $m/2+k$ clauses, where $k$ is the parameter. Among other\nproblems we deal with are MaxLin2-AA (given a system of linear equations over\n$\\mathbb{F}_2$ in which each equation has a positive integral weight, decide\nwhether there is an assignment to the variables that satisfies equations of\ntotal weight at least $W/2+k$, where $W$ is the total weight of all equations),\nMax-$r$-Lin2-AA (the same as MaxLin2-AA, but each equation has at most $r$\nvariables, where $r$ is a constant) and Max-$r$-Sat-AA (given a CNF formula $F$\nwith $m$ clauses in which each clause has at most $r$ literals, decide whether\nthere is a truth assignment satisfying at least $\\sum_{i=1}^m(1-2^{r_i})+k$\nclauses, where $k$ is the parameter, $r_i$ is the number of literals in Clause\n$i$, and $r$ is a constant). We also consider Max-$r$-CSP-AA, a natural\ngeneralization of both Max-$r$-Lin2-AA and Max-$r$-Sat-AA, order (or,\npermutation) constraint satisfaction problems of arities 2 and 3 parameterized\nabove the average value and some other problems related to MaxSat. We discuss\nresults, both polynomial kernels and parameterized algorithms, obtained for the\nproblems mainly in the last few years as well as some open questions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2011 10:52:20 GMT"}], "update_date": "2011-08-25", "authors_parsed": [["Gutin", "G.", ""], ["Yeo", "A.", ""]]}, {"id": "1108.4983", "submitter": "Justin Ward", "authors": "Justin Ward", "title": "A $(k + 3)/2$-approximation algorithm for monotone submodular\n  maximization over a $k$-exchange system", "comments": null, "journal-ref": "29th Symp. on Theoretical Aspects of Comp. Sci. (STACS 2012) 42-53", "doi": "10.4230/LIPIcs.STACS.2012.42", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a monotone submodular function in a\n$k$-exchange system. These systems, introduced by Feldman et al., generalize\nthe matroid k-parity problem in a wide class of matroids and capture many other\ncombinatorial optimization problems. Feldman et al. show that a simple\nnon-oblivious local search algorithm attains a $(k + 1)/2$ approximation ratio\nfor the problem of linear maximization in a $k$-exchange system. Here, we\nextend this approach to the case of monotone submodular objective functions. We\ngive a deterministic, non-oblivious local search algorithm that attains an\napproximation ratio of $(k + 3)/2$ for the problem of maximizing a monotone\nsubmodular function in a $k$-exchange system.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2011 01:28:59 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2011 00:06:52 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Ward", "Justin", ""]]}, {"id": "1108.5095", "submitter": "Marcin Kik", "authors": "Marcin Kik", "title": "RBO Protocol: Broadcasting Huge Databases for Tiny Receivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.DM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a protocol (called RBO) for broadcasting long streams of\nsingle-packet messages over radio channel for tiny, battery powered, receivers.\nThe messages are labeled by the keys from some linearly ordered set. The sender\nrepeatedly broadcasts a sequence of many (possibly millions) of messages, while\neach receiver is interested in reception of a message with a specified key\nwithin this sequence. The transmission is arranged so that the receiver can\nwake up in arbitrary moment and find the nearest transmission of its searched\nmessage. Even if it does not know the position of the message in the sequence,\nit needs only to receive a small number of (the headers of) other messages to\nlocate it properly. Thus it can save energy by keeping the radio switched off\nmost of the time. We show that bit-reversal permutation has \"recursive\nbisection properties\" and, as a consequence, RBO can be implemented very\nefficiently with only constant number of $\\log_2 n$-bit variables, where $n$ is\nthe total number of messages in the sequence. The total number of the required\nreceptions is at most $2\\log_2 n +2$ in the model with perfect synchronization.\nThe basic procedure of RBO (computation of the time slot for the next required\nreception) requires only $O(\\log^3 n)$ bit-wise operations. We propose\nimplementation mechanisms for realistic model (with imperfect synchronization),\nfor operating systems (such as e.g. TinyOS).\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2011 14:05:30 GMT"}], "update_date": "2011-08-26", "authors_parsed": [["Kik", "Marcin", ""]]}, {"id": "1108.5361", "submitter": "Joseph A. Simons", "authors": "David Eppstein and Joseph A. Simons", "title": "Confluent Hasse diagrams", "comments": "20 pages, 13 figures", "journal-ref": "J. Graph Algorithms & Applications 17(7): 689-710, 2013", "doi": "10.7155/jgaa.00312", "report-no": null, "categories": "cs.CG cs.DS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a transitively reduced digraph has a confluent upward drawing if\nand only if its reachability relation has order dimension at most two. In this\ncase, we construct a confluent upward drawing with $O(n^2)$ features, in an\n$O(n) \\times O(n)$ grid in $O(n^2)$ time. For the digraphs representing\nseries-parallel partial orders we show how to construct a drawing with $O(n)$\nfeatures in an $O(n) \\times O(n)$ grid in $O(n)$ time from a series-parallel\ndecomposition of the partial order. Our drawings are optimal in the number of\nconfluent junctions they use.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2011 18:07:50 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2013 23:14:28 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Eppstein", "David", ""], ["Simons", "Joseph A.", ""]]}, {"id": "1108.5405", "submitter": "Jose Antonio Martin H.", "authors": "H. Jose Antonio Martin", "title": "Solving Hard Computational Problems Efficiently: Asymptotic Parametric\n  Complexity 3-Coloring Algorithm", "comments": "Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical problems in almost all scientific and technological\ndisciplines have been classified as computationally hard (NP-hard or even\nNP-complete). In life sciences, combinatorial optimization problems frequently\narise in molecular biology, e.g., genome sequencing; global alignment of\nmultiple genomes; identifying siblings or discovery of dysregulated pathways.In\nalmost all of these problems, there is the need for proving a hypothesis about\ncertain property of an object that can be present only when it adopts some\nparticular admissible structure (an NP-certificate) or be absent (no admissible\nstructure), however, none of the standard approaches can discard the hypothesis\nwhen no solution can be found, since none can provide a proof that there is no\nadmissible structure. This article presents an algorithm that introduces a\nnovel type of solution method to \"efficiently\" solve the graph 3-coloring\nproblem; an NP-complete problem. The proposed method provides certificates\n(proofs) in both cases: present or absent, so it is possible to accept or\nreject the hypothesis on the basis of a rigorous proof. It provides exact\nsolutions and is polynomial-time (i.e., efficient) however parametric. The only\nrequirement is sufficient computational power, which is controlled by the\nparameter $\\alpha\\in\\mathbb{N}$. Nevertheless, here it is proved that the\nprobability of requiring a value of $\\alpha>k$ to obtain a solution for a\nrandom graph decreases exponentially: $P(\\alpha>k) \\leq 2^{-(k+1)}$, making\ntractable almost all problem instances. Thorough experimental analyses were\nperformed. The algorithm was tested on random graphs, planar graphs and\n4-regular planar graphs. The obtained experimental results are in accordance\nwith the theoretical expected results.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2011 23:44:09 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 22:50:57 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2011 15:43:41 GMT"}, {"version": "v4", "created": "Mon, 24 Oct 2011 17:48:37 GMT"}, {"version": "v5", "created": "Wed, 2 Nov 2011 23:08:34 GMT"}, {"version": "v6", "created": "Sat, 22 Sep 2012 15:51:07 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Martin", "H. Jose Antonio", ""]]}, {"id": "1108.5422", "submitter": "M. Sohel Rahman", "authors": "Tanaeem M. Moosa, Sumaiya Nazeen, M. Sohel Rahman and Rezwana Reaz", "title": "Linear Time Inference of Strings from Cover Arrays using a Binary\n  Alphabet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covers being one of the most popular form of regularities in strings, have\ndrawn much attention over time. In this paper, we focus on the problem of\nlinear time inference of strings from cover arrays using the least sized\nalphabet possible. We present an algorithm that can reconstruct a string $x$\nover a two-letter alphabet whenever a valid cover array $C$ is given as an\ninput. This algorithm uses several interesting combinatorial properties of\ncover arrays and an interesting relation between border array and cover array\nto achieve this. Our algorithm runs in linear time.\n", "versions": [{"version": "v1", "created": "Sat, 27 Aug 2011 05:15:16 GMT"}], "update_date": "2011-08-30", "authors_parsed": [["Moosa", "Tanaeem M.", ""], ["Nazeen", "Sumaiya", ""], ["Rahman", "M. Sohel", ""], ["Reaz", "Rezwana", ""]]}, {"id": "1108.5457", "submitter": "Daniel Kral", "authors": "Tomas Gavenciak and Daniel Kral and Sang-il Oum", "title": "Deciding first order logic properties of matroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frick and Grohe [J. ACM 48 (2006), 1184-1206] introduced a notion of graph\nclasses with locally bounded tree-width and established that every first order\nlogic property can be decided in almost linear time in such a graph class.\nHere, we introduce an analogous notion for matroids (locally bounded\nbranch-width) and show the existence of a fixed parameter algorithm for first\norder logic properties in classes of regular matroids with locally bounded\nbranch-width. To obtain this result, we show that the problem of deciding the\nexistence of a circuit of length at most k containing two given elements is\nfixed parameter tractable for regular matroids.\n", "versions": [{"version": "v1", "created": "Sat, 27 Aug 2011 15:02:37 GMT"}], "update_date": "2011-08-30", "authors_parsed": [["Gavenciak", "Tomas", ""], ["Kral", "Daniel", ""], ["Oum", "Sang-il", ""]]}, {"id": "1108.5471", "submitter": "Li Yan", "authors": "Li Yan and Marek Chrobak", "title": "New Results on the Fault-Tolerant Facility Placement Problem", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the Fault-Tolerant Facility Placement problem (FTFP) which\ngeneralizes the uncapacitated facility location problem (UFL). In FTFP, we are\ngiven a set F of sites at which facilities can be built, and a set C of clients\nwith some demands that need to be satisfied by different facilities. A client\n$j$ has demand $r_j$. Building one facility at a site $i$ incurs a cost $f_i$,\nand connecting one unit of demand from client $j$ to a facility at site\n$i\\in\\fac$ costs $d_{ij}$. $d_{ij}$'s are assumed to form a metric. A feasible\nsolution specifies the number of facilities to be built at each site and the\nway to connect demands from clients to facilities, with the restriction that\ndemands from the same client must go to different facilities. Facilities at the\nsame site are considered different. The goal is to find a solution with minimum\ntotal cost. We gave a 1.7245-approximation algorithm to the FTFP problem. Our\ntechnique is via a reduction to the Fault-Tolerant Facility Location problem,\nin which each client has demand $r_j$ but each site can have at most one\nfacility built.\n", "versions": [{"version": "v1", "created": "Sat, 27 Aug 2011 19:31:25 GMT"}], "update_date": "2011-08-30", "authors_parsed": [["Yan", "Li", ""], ["Chrobak", "Marek", ""]]}, {"id": "1108.5525", "submitter": "Yogish Sabharwal", "authors": "Manoj Gupta, Yogish Sabharwal and Sandeep Sen", "title": "The update complexity of selection and related problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for computing with input data specified by intervals,\nrepresenting uncertainty in the values of the input parameters. To compute a\nsolution, the algorithm can query the input parameters that yield more refined\nestimates in form of sub-intervals and the objective is to minimize the number\nof queries. The previous approaches address the scenario where every query\nreturns an exact value. Our framework is more general as it can deal with a\nwider variety of inputs and query responses and we establish interesting\nrelationships between them that have not been investigated previously. Although\nsome of the approaches of the previous restricted models can be adapted to the\nmore general model, we require more sophisticated techniques for the analysis\nand we also obtain improved algorithms for the previous model.\n  We address selection problems in the generalized model and show that there\nexist 2-update competitive algorithms that do not depend on the lengths or\ndistribution of the sub-intervals and hold against the worst case adversary. We\nalso obtain similar bounds on the competitive ratio for the MST problem in\ngraphs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2011 12:40:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gupta", "Manoj", ""], ["Sabharwal", "Yogish", ""], ["Sen", "Sandeep", ""]]}, {"id": "1108.5669", "submitter": "Maria Florina Balcan", "authors": "Maria Florina Balcan, Florin Constantin, Satoru Iwata, Lei Wang", "title": "Learning Valuation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the approximate learnability of valuations commonly\nused throughout economics and game theory for the quantitative encoding of\nagent preferences. We provide upper and lower bounds regarding the learnability\nof important subclasses of valuation functions that express\nno-complementarities. Our main results concern their approximate learnability\nin the distributional learning (PAC-style) setting. We provide nearly tight\nlower and upper bounds of $\\tilde{\\Theta}(n^{1/2})$ on the approximation factor\nfor learning XOS and subadditive valuations, both widely studied superclasses\nof submodular valuations. Interestingly, we show that the\n$\\tilde{\\Omega}(n^{1/2})$ lower bound can be circumvented for XOS functions of\npolynomial complexity; we provide an algorithm for learning the class of XOS\nvaluations with a representation of polynomial size achieving an $O(n^{\\eps})$\napproximation factor in time $O(n^{1/\\eps})$ for any $\\eps > 0$. This\nhighlights the importance of considering the complexity of the target function\nfor polynomial time learning. We also provide new learning results for\ninteresting subclasses of submodular functions.\n  Our upper bounds for distributional learning leverage novel structural\nresults for all these valuation classes. We show that many of these results\nprovide new learnability results in the Goemans et al. model (SODA 2009) of\napproximate learning everywhere via value queries.\n  We also introduce a new model that is more realistic in economic settings, in\nwhich the learner can set prices and observe purchase decisions at these prices\nrather than observing the valuation function directly. In this model, most of\nour upper bounds continue to hold despite the fact that the learner receives\nless information (both for learning in the distributional setting and with\nvalue queries), while our lower bounds naturally extend.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2011 17:48:28 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2011 18:07:58 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Balcan", "Maria Florina", ""], ["Constantin", "Florin", ""], ["Iwata", "Satoru", ""], ["Wang", "Lei", ""]]}, {"id": "1108.5781", "submitter": "Sebastian Roch", "authors": "Sebastien Roch", "title": "Phase Transition in Distance-Based Phylogeny Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new distance-based phylogeny reconstruction technique which\nprovably achieves, at sufficiently short branch lengths, a logarithmic\nsequence-length requirement---improving significantly over previous polynomial\nbounds for distance-based methods and matching existing results for general\nmethods. The technique is based on an averaging procedure that implicitly\nreconstructs ancestral sequences.\n  In the same token, we extend previous results on phase transitions in\nphylogeny reconstruction to general time-reversible models. More precisely, we\nshow that in the so-called Kesten-Stigum zone (roughly, a region of the\nparameter space where ancestral sequences are well approximated by \"linear\ncombinations\" of the observed sequences) sequences of length $O(\\log n)$\nsuffice for reconstruction when branch lengths are discretized. Here $n$ is the\nnumber of extant species.\n  Our results challenge, to some extent, the conventional wisdom that estimates\nof evolutionary distances alone carry significantly less information about\nphylogenies than full sequence datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2011 23:59:24 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Roch", "Sebastien", ""]]}, {"id": "1108.5893", "submitter": "Amitabh Trehan", "authors": "Atish Das Sarma and Amitabh Trehan", "title": "Edge-preserving self-healing: keeping network backbones densely\n  connected", "comments": "Submitted to IEEE InfoComm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healing algorithms play a crucial part in distributed P2P networks where\nfailures occur continuously and frequently. Several self-healing algorithms\nhave been suggested recently [IPDPS'08, PODC'08, PODC'09, PODC'11] in a line of\nwork that has yielded gradual improvements in the properties ensured on the\ngraph. This work motivates a strong general phenomenon of edge-preserving\nhealing that aims at obtaining self-healing algorithms with the constraint that\nall original edges in the graph (not deleted by the adversary), be retained in\nevery intermediate graph.\n  The previous algorithms, in their nascent form, are not explicitly edge\npreserving. In this paper, we show they can be suitably modified (We introduce\nXheal+, an edge-preserving version of Xheal[PODC'11]). Towards this end, we\npresent a general self-healing model that unifies the previous models. The main\ncontribution of this paper is not in the technical complexity, rather in the\nsimplicity with which the edge-preserving property can be ensured and the\nmessage that this is a crucial property with several benefits. In particular,\nwe highlight this by showing that, almost as an immediate corollary, subgraph\ndensities are preserved or increased. Maintaining density is a notion motivated\nby the fact that in certain distributed networks, certain nodes may require and\ninitially have a larger number of inter-connections. It is vital that a healing\nalgorithm, even amidst failures, respect these requirements. Our suggested\nmodifications yield such subgraph density preservation as a by product. In\naddition, edge preservation helps maintain any subgraph induced property that\nis monotonic. Also, algorithms that are edge-preserving require minimal\nalteration of edges which can be an expensive cost in healing - something that\nhas not been modeled in any of the past work.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2011 09:51:39 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Sarma", "Atish Das", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1108.5904", "submitter": "Shailesh Vaya", "authors": "Shailesh Vaya", "title": "Information Dissemination in Unknown Radio networks with Large Labels", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of deterministic broadcasting and gossiping in\ncompletely unknown ad-hoc radio networks. We assume that nothing is known to\nthe nodes about the topology or even the size of the network, $n$, except that\n$n > 1$. Protocols for vanilla model, when $n$ is known, may be run for\nincreasingly larger estimates $2^i$ on the size of the network, but one cannot\ndetermine when such a protocol should terminate. Thus, to carry this design\nparadigm, successful completion or in-completion of the process should be\ndetected, and this knowledge circulated in the network. We consider the problem\nof deterministic Acknowledged Broadcasting and Gossiping when nodes can take\npolynomially large labels.\n  For the above setting, we present the following results for strongly\nconnected networks: (a) A deterministic protocol for acknowledged broadcasting\nwhich takes $NRG(n,n^c)$ rounds, where $NRG(n,n^c)$ is the round complexity of\ndeterministic gossiping for vanilla model. (b) A deterministic protocol for\nacknowledged gossiping, which takes $O(n^2 \\lg n)$ rounds when collision\ndetection mechanism is available. The structure of the transmissions of nodes\nin the network, to enable them to infer collisions, and discover existence of\nunknown in-neighborhood as a result, is abstracted as a family of integral sets\ncalled Selecting-Colliding family. We prove the existence of\nSelecting-Colliding families using the probabilistic method and employ them to\ndesign protocol for acknowledged gossiping when no collision detection\nmechanism is available.\n  Finally, we present a deterministic protocol for acknowledged broadcasting\nfor bidirectional networks, with a round complexity of $O(n \\lg n)$ rounds.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2011 10:16:16 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Vaya", "Shailesh", ""]]}, {"id": "1108.6022", "submitter": "Shay Solomon", "authors": "Shay Solomon and Michael Elkin", "title": "Balancing Degree, Diameter and Weight in Euclidean Spanners", "comments": "27 pages, 7 figures; a preliminary version of this paper appeared in\n  ESA'10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we devise a novel \\emph{unified} construction of Euclidean\nspanners that trades between the maximum degree, diameter and weight\ngracefully. For a positive integer k, our construction provides a\n(1+eps)-spanner with maximum degree O(k), diameter O(log_k n + alpha(k)),\nweight O(k \\cdot log_k n \\cdot log n) \\cdot w(MST(S)), and O(n) edges. Note\nthat for k= n^{1/alpha(n)} this gives rise to diameter O(alpha(n)), weight\nO(n^{1/alpha(n)} \\cdot log n \\cdot alpha(n)) \\cdot w(MST(S)) and maximum degree\nO(n^{1/alpha(n)}), which improves upon a classical result of Arya et al.\n\\cite{ADMSS95}; in the corresponding result from \\cite{ADMSS95} the spanner has\nthe same number of edges and diameter, but its weight and degree may be\narbitrarily large. Also, for k = O(1) this gives rise to maximum degree O(1),\ndiameter O(log n) and weight O(log^2 n) \\cdot w(MST(S)), which reproves another\nclassical result of Arya et al. \\cite{ADMSS95}. Our bound of O(log_k n +\nalpha(k)) on the diameter is optimal under the constraints that the maximum\ndegree is O(k) and the number of edges is O(n). Our bound on the weight is\noptimal up to a factor of log n. Our construction also provides a similar\ntradeoff in the complementary range of parameters, i.e., when the weight should\nbe smaller than log^2 n, but the diameter is allowed to grow beyond log n.\n  For random point sets in the d-dimensional unit cube, we \"shave\" a factor of\nlog n from the weight bound. Specifically, in this case our construction\nachieves maximum degree O(k), diameter O(log_k n + alpha(k)) and weight that is\nwith high probability O(k \\cdot log_k n) \\cdot w(MST(S)).\n  Finally, en route to these results we devise optimal constructions of\n1-spanners for general tree metrics, which are of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2011 17:49:19 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Solomon", "Shay", ""], ["Elkin", "Michael", ""]]}, {"id": "1108.6123", "submitter": "Aleksandar Nikolov", "authors": "Jean Bolot, Nadia Fawaz, S. Muthukrishnan, Aleksandar Nikolov, Nina\n  Taft", "title": "Private Decayed Sum Estimation under Continual Observation", "comments": null, "journal-ref": null, "doi": "10.1145/2448496.2448530", "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In monitoring applications, recent data is more important than distant data.\nHow does this affect privacy of data analysis? We study a general class of data\nanalyses - computing predicate sums - with privacy. Formally, we study the\nproblem of estimating predicate sums {\\em privately}, for sliding windows (and\nother well-known decay models of data, i.e. exponential and polynomial decay).\nWe extend the recently proposed continual privacy model of Dwork et al.\n  We present algorithms for decayed sum which are $\\eps$-differentially\nprivate, and are accurate. For window and exponential decay sums, our\nalgorithms are accurate up to additive $1/\\eps$ and polylog terms in the range\nof the computed function; for polynomial decay sums which are technically more\nchallenging because partial solutions do not compose easily, our algorithms\nincur additional relative error. Further, we show lower bounds, tight within\npolylog factors and tight with respect to the dependence on the probability of\nerror.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 03:56:50 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2012 01:06:44 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Bolot", "Jean", ""], ["Fawaz", "Nadia", ""], ["Muthukrishnan", "S.", ""], ["Nikolov", "Aleksandar", ""], ["Taft", "Nina", ""]]}, {"id": "1108.6160", "submitter": "Alfredo Braunstein", "authors": "Fabrizio Altarelli and Alfredo Braunstein and Abolfazl Ramezanpour and\n  Riccardo Zecchina", "title": "Stochastic optimization by message passing", "comments": "31 pages, 8 figures", "journal-ref": "J. Stat. Mech. (2011) P11009", "doi": "10.1088/1742-5468/2011/11/P11009", "report-no": null, "categories": "cond-mat.stat-mech cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most optimization problems in applied sciences realistically involve\nuncertainty in the parameters defining the cost function, of which only\nstatistical information is known beforehand. In a recent work we introduced a\nmessage passing algorithm based on the cavity method of statistical physics to\nsolve the two-stage matching problem with independently distributed stochastic\nparameters. In this paper we provide an in-depth explanation of the general\nmethod and caveats, show the details of the derivation and resulting algorithm\nfor the matching problem and apply it to a stochastic version of the\nindependent set problem, which is a computationally hard and relevant problem\nin communication networks. We compare the results with some greedy algorithms\nand briefly discuss the extension to more complicated stochastic multi-stage\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 08:49:21 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Altarelli", "Fabrizio", ""], ["Braunstein", "Alfredo", ""], ["Ramezanpour", "Abolfazl", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1108.6304", "submitter": "Eraldo Marinho", "authors": "Eraldo Pereira Marinho and Carmen Maria Andreazza", "title": "Anisotropic k-Nearest Neighbor Search Using Covariance Quadtree", "comments": "Work presented at the Minisymposia of Computational Geometry in the\n  joint events IX Argentinian Congress on Computational Mechanics, XXXI\n  Iberian-Latin-American Congress on Computational Methods in Engineering, II\n  South American Congress on Computational Mechanics, held in Buenos Aires in\n  15-18 November 2010; Mec\\'anica Computacional (Computational Mechanics) Vol.\n  XXIX, 2010, ISSN 1666-6070", "journal-ref": "2010, Mec\\'anica Computacional, Volume XXIX. Number 60.\n  Computational Geometry (A), pp 6045-6064", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a variant of the hyper-quadtree that divides a multidimensional\nspace according to the hyperplanes associated to the principal components of\nthe data in each hyperquadrant. Each of the $2^\\lambda$ hyper-quadrants is a\ndata partition in a $\\lambda$-dimension subspace, whose intrinsic\ndimensionality $\\lambda\\leq d$ is reduced from the root dimensionality $d$ by\nthe principal components analysis, which discards the irrelevant eigenvalues of\nthe local covariance matrix. In the present method a component is irrelevant if\nits length is smaller than, or comparable to, the local inter-data spacing.\nThus, the covariance hyper-quadtree is fully adaptive to the local\ndimensionality. The proposed data-structure is used to compute the anisotropic\nK nearest neighbors (kNN), supported by the Mahalanobis metric. As an\napplication, we used the present k nearest neighbors method to perform density\nestimation over a noisy data distribution. Such estimation method can be\nfurther incorporated to the smoothed particle hydrodynamics, allowing computer\nsimulations of anisotropic fluid flows.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 17:57:27 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Marinho", "Eraldo Pereira", ""], ["Andreazza", "Carmen Maria", ""]]}]