[{"id": "0803.0248", "submitter": "Emmanuelle Lebhar", "authors": "Augustin Chaintreau, Pierre Fraigniaud, Emmanuelle Lebhar", "title": "Networks become navigable as nodes move and forget", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamical process for network evolution, aiming at explaining\nthe emergence of the small world phenomenon, i.e., the statistical observation\nthat any pair of individuals are linked by a short chain of acquaintances\ncomputable by a simple decentralized routing algorithm, known as greedy\nrouting. Previously proposed dynamical processes enabled to demonstrate\nexperimentally (by simulations) that the small world phenomenon can emerge from\nlocal dynamics. However, the analysis of greedy routing using the probability\ndistributions arising from these dynamics is quite complex because of mutual\ndependencies. In contrast, our process enables complete formal analysis. It is\nbased on the combination of two simple processes: a random walk process, and an\nharmonic forgetting process. Both processes reflect natural behaviors of the\nindividuals, viewed as nodes in the network of inter-individual acquaintances.\nWe prove that, in k-dimensional lattices, the combination of these two\nprocesses generates long-range links mutually independently distributed as a\nk-harmonic distribution. We analyze the performances of greedy routing at the\nstationary regime of our process, and prove that the expected number of steps\nfor routing from any source to any target in any multidimensional lattice is a\npolylogarithmic function of the distance between the two nodes in the lattice.\nUp to our knowledge, these results are the first formal proof that navigability\nin small worlds can emerge from a dynamical process for network evolution. Our\ndynamical process can find practical applications to the design of spatial\ngossip and resource location protocols.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 14:44:08 GMT"}], "update_date": "2008-03-04", "authors_parsed": [["Chaintreau", "Augustin", ""], ["Fraigniaud", "Pierre", ""], ["Lebhar", "Emmanuelle", ""]]}, {"id": "0803.0473", "submitter": "Edith Cohen", "authors": "Edith Cohen, Nick Duffield, Haim Kaplan, Carsten Lund, and Mikkel\n  Thorup", "title": "Stream sampling for variance-optimal estimation of subset sums", "comments": "31 pages. An extended abstract appeared in the proceedings of the\n  20th ACM-SIAM Symposium on Discrete Algorithms (SODA 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a high volume stream of weighted items, we want to maintain a generic\nsample of a certain limited size $k$ that we can later use to estimate the\ntotal weight of arbitrary subsets. This is the classic context of on-line\nreservoir sampling, thinking of the generic sample as a reservoir. We present\nan efficient reservoir sampling scheme, $\\varoptk$, that dominates all previous\nschemes in terms of estimation quality.\n  $\\varoptk$ provides {\\em variance optimal unbiased estimation of subset\nsums}. More precisely, if we have seen $n$ items of the stream, then for {\\em\nany} subset size $m$, our scheme based on $k$ samples minimizes the average\nvariance over all subsets of size $m$. In fact, the optimality is against any\noff-line scheme with $k$ samples tailored for the concrete set of items seen.\nIn addition to optimal average variance, our scheme provides tighter worst-case\nbounds on the variance of {\\em particular} subsets than previously possible. It\nis efficient, handling each new item of the stream in $O(\\log k)$ time.\nFinally, it is particularly well suited for combination of samples from\ndifferent streams in a distributed setting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2008 15:12:24 GMT"}, {"version": "v2", "created": "Mon, 15 Nov 2010 16:43:54 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Cohen", "Edith", ""], ["Duffield", "Nick", ""], ["Kaplan", "Haim", ""], ["Lund", "Carsten", ""], ["Thorup", "Mikkel", ""]]}, {"id": "0803.0476", "submitter": "Renaud Lambiotte", "authors": "Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte and Etienne\n  Lefebvre", "title": "Fast unfolding of communities in large networks", "comments": "6 pages, 5 figures, 1 table; new version with new figures in order to\n  clarify our method, where we look more carefully at the role played by the\n  ordering of the nodes and where we compare our method with that of Wakita and\n  Tsurumi", "journal-ref": "J. Stat. Mech. (2008) P10008", "doi": "10.1088/1742-5468/2008/10/P10008", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple method to extract the community structure of large\nnetworks. Our method is a heuristic method that is based on modularity\noptimization. It is shown to outperform all other known community detection\nmethod in terms of computation time. Moreover, the quality of the communities\ndetected is very good, as measured by the so-called modularity. This is shown\nfirst by identifying language communities in a Belgian mobile phone network of\n2.6 million customers and by analyzing a web graph of 118 million nodes and\nmore than one billion links. The accuracy of our algorithm is also verified on\nad-hoc modular networks. .\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2008 15:29:44 GMT"}, {"version": "v2", "created": "Fri, 25 Jul 2008 09:52:42 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Blondel", "Vincent D.", ""], ["Guillaume", "Jean-Loup", ""], ["Lambiotte", "Renaud", ""], ["Lefebvre", "Etienne", ""]]}, {"id": "0803.0701", "submitter": "Gregory Gutin", "authors": "N Alon, F.V. Fomin, G. Gutin, M. Krivelevich and S. Saurabh", "title": "Spanning directed trees with many leaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\sc Directed Maximum Leaf Out-Branching} problem is to find an\nout-branching (i.e. a rooted oriented spanning tree) in a given digraph with\nthe maximum number of leaves. In this paper, we obtain two combinatorial\nresults on the number of leaves in out-branchings. We show that\n  - every strongly connected $n$-vertex digraph $D$ with minimum in-degree at\nleast 3 has an out-branching with at least $(n/4)^{1/3}-1$ leaves;\n  - if a strongly connected digraph $D$ does not contain an out-branching with\n$k$ leaves, then the pathwidth of its underlying graph UG($D$) is $O(k\\log k)$.\nMoreover, if the digraph is acyclic, the pathwidth is at most $4k$.\n  The last result implies that it can be decided in time $2^{O(k\\log^2 k)}\\cdot\nn^{O(1)}$ whether a strongly connected digraph on $n$ vertices has an\nout-branching with at least $k$ leaves. On acyclic digraphs the running time of\nour algorithm is $2^{O(k\\log k)}\\cdot n^{O(1)}$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2008 16:38:34 GMT"}], "update_date": "2008-03-06", "authors_parsed": [["Alon", "N", ""], ["Fomin", "F. V.", ""], ["Gutin", "G.", ""], ["Krivelevich", "M.", ""], ["Saurabh", "S.", ""]]}, {"id": "0803.0726", "submitter": "Marie-Pierre B\\'eal", "authors": "Marie-Pierre B\\'eal, Dominique Perrin", "title": "A quadratic algorithm for road coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Road Coloring Theorem states that every aperiodic directed graph with\nconstant out-degree has a synchronized coloring. This theorem had been\nconjectured during many years as the Road Coloring Problem before being settled\nby A. Trahtman. Trahtman's proof leads to an algorithm that finds a\nsynchronized labeling with a cubic worst-case time complexity. We show a\nvariant of his construction with a worst-case complexity which is quadratic in\ntime and linear in space. We also extend the Road Coloring Theorem to the\nperiodic case.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2008 20:35:54 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2008 21:33:23 GMT"}, {"version": "v3", "created": "Mon, 7 Apr 2008 15:12:00 GMT"}, {"version": "v4", "created": "Tue, 15 Apr 2008 16:32:12 GMT"}, {"version": "v5", "created": "Wed, 14 May 2008 14:54:09 GMT"}, {"version": "v6", "created": "Fri, 11 Jul 2008 14:21:07 GMT"}, {"version": "v7", "created": "Wed, 7 Oct 2009 16:00:57 GMT"}, {"version": "v8", "created": "Mon, 23 Apr 2012 16:17:48 GMT"}, {"version": "v9", "created": "Thu, 30 May 2013 16:16:40 GMT"}], "update_date": "2013-05-31", "authors_parsed": [["B\u00e9al", "Marie-Pierre", ""], ["Perrin", "Dominique", ""]]}, {"id": "0803.0731", "submitter": "Ning Chen", "authors": "Ning Chen and Zhiyuan Yan", "title": "Complexity Analysis of Reed-Solomon Decoding over GF(2^m) Without Using\n  Syndromes", "comments": "11 pages, submitted to EURASIP Journal on Wireless Communications and\n  Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the majority of the applications of Reed-Solomon (RS) codes, hard\ndecision decoding is based on syndromes. Recently, there has been renewed\ninterest in decoding RS codes without using syndromes. In this paper, we\ninvestigate the complexity of syndromeless decoding for RS codes, and compare\nit to that of syndrome-based decoding. Aiming to provide guidelines to\npractical applications, our complexity analysis differs in several aspects from\nexisting asymptotic complexity analysis, which is typically based on\nmultiplicative fast Fourier transform (FFT) techniques and is usually in big O\nnotation. First, we focus on RS codes over characteristic-2 fields, over which\nsome multiplicative FFT techniques are not applicable. Secondly, due to\nmoderate block lengths of RS codes in practice, our analysis is complete since\nall terms in the complexities are accounted for. Finally, in addition to fast\nimplementation using additive FFT techniques, we also consider direct\nimplementation, which is still relevant for RS codes with moderate lengths.\nComparing the complexities of both syndromeless and syndrome-based decoding\nalgorithms based on direct and fast implementations, we show that syndromeless\ndecoding algorithms have higher complexities than syndrome-based ones for high\nrate RS codes regardless of the implementation. Both errors-only and\nerrors-and-erasures decoding are considered in this paper. We also derive\ntighter bounds on the complexities of fast polynomial multiplications based on\nCantor's approach and the fast extended Euclidean algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2008 18:54:35 GMT"}, {"version": "v2", "created": "Wed, 7 May 2008 21:05:41 GMT"}], "update_date": "2008-05-08", "authors_parsed": [["Chen", "Ning", ""], ["Yan", "Zhiyuan", ""]]}, {"id": "0803.0792", "submitter": "Siddhartha Sen", "authors": "Bernhard Haeupler, Siddhartha Sen, and Robert E. Tarjan", "title": "Incremental Topological Ordering and Strong Component Maintenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an on-line algorithm for maintaining a topological order of a\ndirected acyclic graph as arcs are added, and detecting a cycle when one is\ncreated. Our algorithm takes O(m^{1/2}) amortized time per arc, where m is the\ntotal number of arcs. For sparse graphs, this bound improves the best previous\nbound by a logarithmic factor and is tight to within a constant factor for a\nnatural class of algorithms that includes all the existing ones. Our main\ninsight is that the bidirectional search method of previous algorithms does not\nrequire an ordered search, but can be more general. This allows us to avoid the\nuse of heaps (priority queues) entirely. Instead, the deterministic version of\nour algorithm uses (approximate) median-finding. The randomized version of our\nalgorithm avoids this complication, making it very simple. We extend our\ntopological ordering algorithm to give the first detailed algorithm for\nmaintaining the strong components of a directed graph, and a topological order\nof these components, as arcs are added. This extension also has an amortized\ntime bound of O(m^{1/2}) per arc.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 05:11:18 GMT"}], "update_date": "2008-03-07", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Sen", "Siddhartha", ""], ["Tarjan", "Robert E.", ""]]}, {"id": "0803.0845", "submitter": "Evain Laurent", "authors": "Laurent Evain", "title": "Knapsack cryptosystems built on NP-hard instance", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct three public key knapsack cryptosystems. Standard knapsack\ncryptosystems hide easy instances of the knapsack problem and have been broken.\nThe systems considered in the article face this problem: They hide a random\n(possibly hard) instance of the knapsack problem. We provide both complexity\nresults (size of the key, time needed to encypher/decypher...) and experimental\nresults. Security results are given for the second cryptosystem (the fastest\none and the one with the shortest key). Probabilistic polynomial reductions\nshow that finding the private key is as difficult as factorizing a product of\ntwo primes. We also consider heuristic attacks. First, the density of the\ncryptosystem can be chosen arbitrarily close to one, discarding low density\nattacks. Finally, we consider explicit heuristic attacks based on the LLL\nalgorithm and we prove that with respect to these attacks, the public key is as\nsecure as a random key.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 12:20:35 GMT"}], "update_date": "2008-03-17", "authors_parsed": [["Evain", "Laurent", ""]]}, {"id": "0803.0929", "submitter": "Daniel A. Spielman", "authors": "Daniel A. Spielman, Nikhil Srivastava", "title": "Graph Sparsification by Effective Resistances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a nearly-linear time algorithm that produces high-quality\nsparsifiers of weighted graphs. Given as input a weighted graph $G=(V,E,w)$ and\na parameter $\\epsilon>0$, we produce a weighted subgraph\n$H=(V,\\tilde{E},\\tilde{w})$ of $G$ such that $|\\tilde{E}|=O(n\\log\nn/\\epsilon^2)$ and for all vectors $x\\in\\R^V$ $(1-\\epsilon)\\sum_{uv\\in\nE}(x(u)-x(v))^2w_{uv}\\le \\sum_{uv\\in\\tilde{E}}(x(u)-x(v))^2\\tilde{w}_{uv} \\le\n(1+\\epsilon)\\sum_{uv\\in E}(x(u)-x(v))^2w_{uv}. (*)$\n  This improves upon the sparsifiers constructed by Spielman and Teng, which\nhad $O(n\\log^c n)$ edges for some large constant $c$, and upon those of\nBencz\\'ur and Karger, which only satisfied (*) for $x\\in\\{0,1\\}^V$.\n  A key ingredient in our algorithm is a subroutine of independent interest: a\nnearly-linear time algorithm that builds a data structure from which we can\nquery the approximate effective resistance between any two vertices in a graph\nin $O(\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 18:03:06 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2008 23:10:59 GMT"}, {"version": "v3", "created": "Fri, 14 Mar 2008 19:49:32 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2009 07:22:03 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Spielman", "Daniel A.", ""], ["Srivastava", "Nikhil", ""]]}, {"id": "0803.0954", "submitter": "Michael Hahsler", "authors": "Michael Hahsler, Christian Buchta, and Kurt Hornik", "title": "Selective association rule generation", "comments": null, "journal-ref": "Computational Statistics, 2007. Online First, Published: 25 July\n  2007", "doi": "10.1007/s00180-007-0062-z", "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining association rules is a popular and well researched method for\ndiscovering interesting relations between variables in large databases. A\npractical problem is that at medium to low support values often a large number\nof frequent itemsets and an even larger number of association rules are found\nin a database. A widely used approach is to gradually increase minimum support\nand minimum confidence or to filter the found rules using increasingly strict\nconstraints on additional measures of interestingness until the set of rules\nfound is reduced to a manageable size. In this paper we describe a different\napproach which is based on the idea to first define a set of ``interesting''\nitemsets (e.g., by a mixture of mining and expert knowledge) and then, in a\nsecond step to selectively generate rules for only these itemsets. The main\nadvantage of this approach over increasing thresholds or filtering rules is\nthat the number of rules found is significantly reduced while at the same time\nit is not necessary to increase the support and confidence thresholds which\nmight lead to missing important information in the database.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 19:43:35 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Hahsler", "Michael", ""], ["Buchta", "Christian", ""], ["Hornik", "Kurt", ""]]}, {"id": "0803.0988", "submitter": "Samuel Daitch", "authors": "Samuel I. Daitch, Daniel A. Spielman", "title": "Faster Approximate Lossy Generalized Flow via Interior Point Algorithms", "comments": "v2: bug fixes and some expanded proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present faster approximation algorithms for generalized network flow\nproblems. A generalized flow is one in which the flow out of an edge differs\nfrom the flow into the edge by a constant factor. We limit ourselves to the\nlossy case, when these factors are at most 1.\n  Our algorithm uses a standard interior-point algorithm to solve a linear\nprogram formulation of the network flow problem. The system of linear equations\nthat arises at each step of the interior-point algorithm takes the form of a\nsymmetric M-matrix. We present an algorithm for solving such systems in nearly\nlinear time. The algorithm relies on the Spielman-Teng nearly linear time\nalgorithm for solving linear systems in diagonally-dominant matrices.\n  For a graph with m edges, our algorithm obtains an additive epsilon\napproximation of the maximum generalized flow and minimum cost generalized flow\nin time tildeO(m^(3/2) * log(1/epsilon)). In many parameter ranges, this\nimproves over previous algorithms by a factor of approximately m^(1/2). We also\nobtain a similar improvement for exactly solving the standard min-cost flow\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 21:57:53 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2008 19:02:38 GMT"}], "update_date": "2008-04-07", "authors_parsed": [["Daitch", "Samuel I.", ""], ["Spielman", "Daniel A.", ""]]}, {"id": "0803.1245", "submitter": "George Bell", "authors": "George I. Bell", "title": "The shortest game of Chinese Checkers and related problems", "comments": "22 pages, 10 figures; published version", "journal-ref": "INTEGERS: Electronic Journal of Combinatorial Number Theory 9\n  (2009) #G01", "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1979, David Fabian found a complete game of two-person Chinese Checkers in\n30 moves (15 by each player) [Martin Gardner, Penrose Tiles to Trapdoor\nCiphers, MAA, 1997]. This solution requires that the two players cooperate to\ngenerate a win as quickly as possible for one of them. We show, using\ncomputational search techniques, that no shorter game is possible. We also\nconsider a solitaire version of Chinese Checkers where one player attempts to\nmove her pieces across the board in as few moves as possible. In 1971, Octave\nLevenspiel found a solution in 27 moves [Ibid.]; we demonstrate that no shorter\nsolution exists. To show optimality, we employ a variant of A* search, as well\nas bidirectional search.\n", "versions": [{"version": "v1", "created": "Sat, 8 Mar 2008 14:38:31 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2009 18:41:21 GMT"}], "update_date": "2009-01-13", "authors_parsed": [["Bell", "George I.", ""]]}, {"id": "0803.1321", "submitter": "Yngve Villanger", "authors": "Fedor V. Fomin and Yngve Villanger", "title": "Treewidth computation and extremal combinatorics", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given graph G and integers b,f >= 0, let S be a subset of vertices of G\nof size b+1 such that the subgraph of G induced by S is connected and S can be\nseparated from other vertices of G by removing f vertices. We prove that every\ngraph on n vertices contains at most n\\binom{b+f}{b} such vertex subsets. This\nresult from extremal combinatorics appears to be very useful in the design of\nseveral enumeration and exact algorithms. In particular, we use it to provide\nalgorithms that for a given n-vertex graph G - compute the treewidth of G in\ntime O(1.7549^n) by making use of exponential space and in time O(2.6151^n) and\npolynomial space; - decide in time O(({\\frac{2n+k+1}{3})^{k+1}\\cdot kn^6}) if\nthe treewidth of G is at most k; - list all minimal separators of G in time\nO(1.6181^n) and all potential maximal cliques of G in time O(1.7549^n). This\nsignificantly improves previous algorithms for these problems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2008 20:54:58 GMT"}, {"version": "v2", "created": "Mon, 5 May 2008 09:34:16 GMT"}], "update_date": "2008-05-05", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Villanger", "Yngve", ""]]}, {"id": "0803.2174", "submitter": "Mirela Damian", "authors": "Mirela Damian, Saurav Pandit and Sriram Pemmaraju", "title": "Local Approximation Schemes for Topology Control", "comments": "11 pages, 6 figures", "journal-ref": "Proceedings of the 25th ACM Symposium on Principles of Distributed\n  Computing, pages 208-218, July 2006", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributed algorithm on wireless ad-hoc networks that\nruns in polylogarithmic number of rounds in the size of the network and\nconstructs a linear size, lightweight, (1+\\epsilon)-spanner for any given\n\\epsilon > 0. A wireless network is modeled by a d-dimensional \\alpha-quasi\nunit ball graph (\\alpha-UBG), which is a higher dimensional generalization of\nthe standard unit disk graph (UDG) model. The d-dimensional \\alpha-UBG model\ngoes beyond the unrealistic ``flat world'' assumption of UDGs and also takes\ninto account transmission errors, fading signal strength, and physical\nobstructions. The main result in the paper is this: for any fixed \\epsilon > 0,\n0 < \\alpha \\le 1, and d \\ge 2, there is a distributed algorithm running in\nO(\\log n \\log^* n) communication rounds on an n-node, d-dimensional \\alpha-UBG\nG that computes a (1+\\epsilon)-spanner G' of G with maximum degree \\Delta(G') =\nO(1) and total weight w(G') = O(w(MST(G)). This result is motivated by the\ntopology control problem in wireless ad-hoc networks and improves on existing\ntopology control algorithms along several dimensions. The technical\ncontributions of the paper include a new, sequential, greedy algorithm with\nrelaxed edge ordering and lazy updating, and clustering techniques for\nfiltering out unnecessary edges.\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2008 14:37:12 GMT"}], "update_date": "2008-03-17", "authors_parsed": [["Damian", "Mirela", ""], ["Pandit", "Saurav", ""], ["Pemmaraju", "Sriram", ""]]}, {"id": "0803.2615", "submitter": "Olivier Laval", "authors": "Olivier Laval (LIPN), Sophie Toulouse (LIPN), Anass Nagih (LITA)", "title": "Rapport de recherche sur le probl\\`eme du plus court chemin contraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an overview of the performance and the theoretical\ncomplexity of approximate and exact methods for various versions of the\nshortest path problem. The proposed study aims to improve the resolution of a\nmore general covering problem within a column generation scheme in which the\nshortest path problem is the sub-problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Mar 2008 12:37:36 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Laval", "Olivier", "", "LIPN"], ["Toulouse", "Sophie", "", "LIPN"], ["Nagih", "Anass", "", "LITA"]]}, {"id": "0803.2842", "submitter": "Shai  Gutner", "authors": "Noga Alon, Yossi Azar, Shai Gutner", "title": "Admission Control to Minimize Rejections and Online Set Cover with\n  Repetitions", "comments": null, "journal-ref": "Proc. of 17th SPAA (2005), 238-244", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the admission control problem in general networks. Communication\nrequests arrive over time, and the online algorithm accepts or rejects each\nrequest while maintaining the capacity limitations of the network. The\nadmission control problem has been usually analyzed as a benefit problem, where\nthe goal is to devise an online algorithm that accepts the maximum number of\nrequests possible. The problem with this objective function is that even\nalgorithms with optimal competitive ratios may reject almost all of the\nrequests, when it would have been possible to reject only a few. This could be\ninappropriate for settings in which rejections are intended to be rare events.\n  In this paper, we consider preemptive online algorithms whose goal is to\nminimize the number of rejected requests. Each request arrives together with\nthe path it should be routed on. We show an $O(\\log^2 (mc))$-competitive\nrandomized algorithm for the weighted case, where $m$ is the number of edges in\nthe graph and $c$ is the maximum edge capacity. For the unweighted case, we\ngive an $O(\\log m \\log c)$-competitive randomized algorithm. This settles an\nopen question of Blum, Kalai and Kleinberg raised in \\cite{BlKaKl01}. We note\nthat allowing preemption and handling requests with given paths are essential\nfor avoiding trivial lower bounds.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2008 16:53:42 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Alon", "Noga", ""], ["Azar", "Yossi", ""], ["Gutner", "Shai", ""]]}, {"id": "0803.3531", "submitter": "Daniel Raible", "authors": "Daniel Raible and Henning Fernau", "title": "A New Upper Bound for Max-2-Sat: A Graph-Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In {\\sc MaxSat}, we ask for an assignment which satisfies the maximum number\nof clauses for a boolean formula in CNF. We present an algorithm yielding a run\ntime upper bound of $O^*(2^{\\frac{1}{6.2158}})$ for {\\sc Max-2-Sat} (each\nclause contains at most 2 literals), where $K$ is the number of clauses. The\nrun time has been achieved by using heuristic priorities on the choice of the\nvariable on which we branch. The implementation of these heuristic priorities\nis rather simple, though they have a significant effect on the run time. The\nanalysis is done using a tailored non-standard measure.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2008 11:32:22 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2008 08:36:18 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Raible", "Daniel", ""], ["Fernau", "Henning", ""]]}, {"id": "0803.3632", "submitter": "Mikhail Nesterenko", "authors": "Mikhail Nesterenko, Adnan Vora", "title": "Void Traversal for Guaranteed Delivery in Geometric Routing", "comments": null, "journal-ref": "The 2nd IEEE International Conference on Mobile Ad-hoc and Sensor\n  Systems (MASS 2005), Washington, DC, November, 2005", "doi": "10.1109/MAHSS.2005.1542862", "report-no": null, "categories": "cs.OS cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric routing algorithms like GFG (GPSR) are lightweight, scalable\nalgorithms that can be used to route in resource-constrained ad hoc wireless\nnetworks. However, such algorithms run on planar graphs only. To efficiently\nconstruct a planar graph, they require a unit-disk graph. To make the topology\nunit-disk, the maximum link length in the network has to be selected\nconservatively. In practical setting this leads to the designs where the node\ndensity is rather high. Moreover, the network diameter of a planar subgraph is\ngreater than the original graph, which leads to longer routes. To remedy this\nproblem, we propose a void traversal algorithm that works on arbitrary\ngeometric graphs. We describe how to use this algorithm for geometric routing\nwith guaranteed delivery and compare its performance with GFG.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2008 20:52:17 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Nesterenko", "Mikhail", ""], ["Vora", "Adnan", ""]]}, {"id": "0803.3657", "submitter": "Yeow Meng Chee", "authors": "Yeow Meng Chee and San Ling", "title": "Improved Lower Bounds for Constant GC-Content DNA Codes", "comments": "4 pages", "journal-ref": "IEEE Transactions on Information Theory, vol. 54, no. 1, pp.\n  391-394, 2008", "doi": "10.1109/TIT.2007.911167", "report-no": null, "categories": "cs.IT cs.DS math.CO math.IT q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of large libraries of oligonucleotides having constant GC-content\nand satisfying Hamming distance constraints between oligonucleotides and their\nWatson-Crick complements is important in reducing hybridization errors in DNA\ncomputing, DNA microarray technologies, and molecular bar coding. Various\ntechniques have been studied for the construction of such oligonucleotide\nlibraries, ranging from algorithmic constructions via stochastic local search\nto theoretical constructions via coding theory. We introduce a new stochastic\nlocal search method which yields improvements up to more than one third of the\nbenchmark lower bounds of Gaborit and King (2005) for n-mer oligonucleotide\nlibraries when n <= 14. We also found several optimal libraries by computing\nmaximum cliques on certain graphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2008 02:26:36 GMT"}], "update_date": "2008-03-27", "authors_parsed": [["Chee", "Yeow Meng", ""], ["Ling", "San", ""]]}, {"id": "0803.3693", "submitter": "Rasmus Pagh", "authors": "Martin Dietzfelbinger and Rasmus Pagh", "title": "Succinct Data Structures for Retrieval and Approximate Membership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The retrieval problem is the problem of associating data with keys in a set.\nFormally, the data structure must store a function f: U ->{0,1}^r that has\nspecified values on the elements of a given set S, a subset of U, |S|=n, but\nmay have any value on elements outside S. Minimal perfect hashing makes it\npossible to avoid storing the set S, but this induces a space overhead of\nTheta(n) bits in addition to the nr bits needed for function values. In this\npaper we show how to eliminate this overhead. Moreover, we show that for any k\nquery time O(k) can be achieved using space that is within a factor 1+e^{-k} of\noptimal, asymptotically for large n. If we allow logarithmic evaluation time,\nthe additive overhead can be reduced to O(log log n) bits whp. The time to\nconstruct the data structure is O(n), expected. A main technical ingredient is\nto utilize existing tight bounds on the probability of almost square random\nmatrices with rows of low weight to have full row rank. In addition to direct\nconstructions, we point out a close connection between retrieval structures and\nhash tables where keys are stored in an array and some kind of probing scheme\nis used. Further, we propose a general reduction that transfers the results on\nretrieval into analogous results on approximate membership, a problem\ntraditionally addressed using Bloom filters. Again, we show how to eliminate\nthe space overhead present in previously known methods, and get arbitrarily\nclose to the lower bound. The evaluation procedures of our data structures are\nextremely simple (similar to a Bloom filter). For the results stated above we\nassume free access to fully random hash functions. However, we show how to\njustify this assumption using extra space o(n) to simulate full randomness on a\nRAM.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2008 10:53:49 GMT"}], "update_date": "2008-03-27", "authors_parsed": [["Dietzfelbinger", "Martin", ""], ["Pagh", "Rasmus", ""]]}, {"id": "0803.3746", "submitter": "Leonid Litinskii", "authors": "Leonid B. Litinskii", "title": "Cluster Approach to the Domains Formation", "comments": "11 pages, 5 figures, PDF-file", "journal-ref": "Optical Memory & Neural Networks (Information Optics), 2007,\n  v.16(3) pp.144-153", "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a rule, a quadratic functional depending on a great number of binary\nvariables has a lot of local minima. One of approaches allowing one to find in\naveraged deeper local minima is aggregation of binary variables into larger\nblocks/domains. To minimize the functional one has to change the states of\naggregated variables (domains). In the present publication we discuss methods\nof domains formation. It is shown that the best results are obtained when\ndomains are formed by variables that are strongly connected with each other.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2008 15:14:33 GMT"}], "update_date": "2008-03-27", "authors_parsed": [["Litinskii", "Leonid B.", ""]]}, {"id": "0803.4260", "submitter": "Xin Han", "authors": "Xin Han, Kazuo Iwama, Guochuan Zhang", "title": "On Two Dimensional Orthogonal Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the following knapsack problem: Given a list of\nsquares with profits, we are requested to pack a sublist of them into a\nrectangular bin (not a unit square bin) to make profits in the bin as large as\npossible. We first observe there is a Polynomial Time Approximation Scheme\n(PTAS) for the problem of packing weighted squares into rectangular bins with\nlarge resources, then apply the PTAS to the problem of packing squares with\nprofits into a rectangular bin and get a $\\frac65+\\epsilon$ approximation\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 Mar 2008 11:15:11 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Han", "Xin", ""], ["Iwama", "Kazuo", ""], ["Zhang", "Guochuan", ""]]}, {"id": "0803.4355", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "Grammar-Based Random Walkers in Semantic Networks", "comments": "First draft of manuscript originally written in November 2006", "journal-ref": "Rodriguez, M.A., \"Grammar-Based Random Walkers in Semantic\n  Networks\", Knowledge-Based Systems, volume 21, issue 7, pages 727-739, ISSN:\n  0950-7051, Elsevier, October 2008", "doi": "10.1016/j.knosys.2008.03.030", "report-no": "LA-UR-06-7791", "categories": "cs.AI cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Semantic networks qualify the meaning of an edge relating any two vertices.\nDetermining which vertices are most \"central\" in a semantic network is\ndifficult because one relationship type may be deemed subjectively more\nimportant than another. For this reason, research into semantic network metrics\nhas focused primarily on context-based rankings (i.e. user prescribed\ncontexts). Moreover, many of the current semantic network metrics rank semantic\nassociations (i.e. directed paths between two vertices) and not the vertices\nthemselves. This article presents a framework for calculating semantically\nmeaningful primary eigenvector-based metrics such as eigenvector centrality and\nPageRank in semantic networks using a modified version of the random walker\nmodel of Markov chain analysis. Random walkers, in the context of this article,\nare constrained by a grammar, where the grammar is a user defined data\nstructure that determines the meaning of the final vertex ranking. The ideas in\nthis article are presented within the context of the Resource Description\nFramework (RDF) of the Semantic Web initiative.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2008 00:13:26 GMT"}, {"version": "v2", "created": "Wed, 10 Sep 2008 23:58:07 GMT"}], "update_date": "2008-09-11", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}]