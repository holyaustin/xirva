[{"id": "1708.00002", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Gautam Kamath, John Wright", "title": "Which Distribution Distances are Sublinearly Testable?", "comments": "To appear in SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given samples from an unknown distribution $p$ and a description of a\ndistribution $q$, are $p$ and $q$ close or far? This question of \"identity\ntesting\" has received significant attention in the case of testing whether $p$\nand $q$ are equal or far in total variation distance. However, in recent work,\nthe following questions have been been critical to solving problems at the\nfrontiers of distribution testing:\n  -Alternative Distances: Can we test whether $p$ and $q$ are far in other\ndistances, say Hellinger?\n  -Tolerance: Can we test when $p$ and $q$ are close, rather than equal? And if\nso, close in which distances?\n  Motivated by these questions, we characterize the complexity of distribution\ntesting under a variety of distances, including total variation, $\\ell_2$,\nHellinger, Kullback-Leibler, and $\\chi^2$. For each pair of distances $d_1$ and\n$d_2$, we study the complexity of testing if $p$ and $q$ are close in $d_1$\nversus far in $d_2$, with a focus on identifying which problems allow strongly\nsublinear testers (i.e., those with complexity $O(n^{1 - \\gamma})$ for some\n$\\gamma > 0$ where $n$ is the size of the support of the distributions $p$ and\n$q$). We provide matching upper and lower bounds for each case. We also study\nthese questions in the case where we only have samples from $q$ (equivalence\ntesting), showing qualitative differences from identity testing in terms of\nwhen tolerance can be achieved. Our algorithms fall into the classical paradigm\nof $\\chi^2$-statistics, but require crucial changes to handle the challenges\nintroduced by each distance we consider. Finally, we survey other recent\nresults in an attempt to serve as a reference for the complexity of various\ndistribution testing problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 18:00:00 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 02:44:14 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""], ["Wright", "John", ""]]}, {"id": "1708.00121", "submitter": "Vanessa Teague", "authors": "Michelle Blom, Peter J. Stuckey and Vanessa Teague", "title": "Computing the Margin of Victory in Preferential Parliamentary Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use automated computation of election margins to assess the\nnumber of votes that would need to change in order to alter a parliamentary\noutcome for single-member preferential electorates. In the context of\nincreasing automation of Australian electoral processes, and accusations of\ndeliberate interference in elections in Europe and the USA, this work forms the\nbasis of a rigorous statistical audit of the parliamentary election outcome.\nOur example is the New South Wales Legislative Council election of 2015, but\nthe same process could be used for any similar parliament for which data was\navailable, such as the Australian House of Representatives given the proposed\nautomatic scanning of ballots.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 01:15:06 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Blom", "Michelle", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""]]}, {"id": "1708.00143", "submitter": "Hamidreza Jahanjou", "authors": "Hamidreza Jahanjou, Erez Kantor, and Rajmohan Rajaraman", "title": "Improved Algorithms for Scheduling Unsplittable Flows on Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate offline and online algorithms for rufpp, the\nproblem of minimizing the number of rounds required to schedule a set of\nunsplittable flows of non-uniform sizes on a given path with non-uniform edge\ncapacities. rufpp is NP-hard and constant-factor approximation algorithms are\nknown under the no bottleneck assumption (NBA), which stipulates that maximum\nsize of a flow is at most the minimum edge capacity. We study rufpp without the\nNBA, and present improved online and offline algorithms. We first study offline\nrufpp for a restricted class of instances called $\\alpha$-small, where the size\nof each flow is at most $\\alpha$ times the capacity of its bottleneck edge, and\npresent an $O(\\log(1/(1-\\alpha)))$-approximation algorithm. Our main result is\nan online $O(\\log\\log c_{\\max})$-competitive algorithm for rufpp for general\ninstances, where $c_{\\max}$ is the largest edge capacities, improving upon the\nprevious best bound of $O(\\log c_{\\max})$ due to Epstein et al. Our result\nleads to an offline $O(\\min(\\log n, \\log m, \\log\\log c_{\\max}))$-approximation\nalgorithm and an online $O(\\min(\\log m, \\log\\log c_{\\max}))$-competitive\nalgorithm for rufpp, where $n$ is the number of flows and $m$ is the number of\nedges.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:57:43 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Jahanjou", "Hamidreza", ""], ["Kantor", "Erez", ""], ["Rajaraman", "Rajmohan", ""]]}, {"id": "1708.00149", "submitter": "Ehsan Emamjomeh-Zadeh", "authors": "Ehsan Emamjomeh-Zadeh and David Kempe", "title": "Adaptive Hierarchical Clustering Using Ordinal Queries", "comments": "In SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of clustering (for example, ontologies or clusterings of\nanimal or plant species), hierarchical clusterings are more descriptive than a\nflat clustering. A hierarchical clustering over $n$ elements is represented by\na rooted binary tree with $n$ leaves, each corresponding to one element. The\nsubtrees rooted at interior nodes capture the clusters. In this paper, we study\nactive learning of a hierarchical clustering using only ordinal queries. An\nordinal query consists of a set of three elements, and the response to a query\nreveals the two elements (among the three elements in the query) which are\n\"closer\" to each other than to the third one. We say that elements $x$ and $x'$\nare closer to each other than $x\"$ if there exists a cluster containing $x$ and\n$x'$, but not $x\"$.\n  When all the query responses are correct, there is a deterministic algorithm\nthat learns the underlying hierarchical clustering using at most $n \\log_2 n$\nadaptive ordinal queries. We generalize this algorithm to be robust in a model\nin which each query response is correct independently with probability $p >\n\\frac{1}{2}$, and adversarially incorrect with probability $1 - p$. We show\nthat in the presence of noise, our algorithm outputs the correct hierarchical\nclustering with probability at least $1 - \\delta$, using $O(n \\log n + n\n\\log(1/\\delta))$ adaptive ordinal queries. For our results, adaptivity is\ncrucial: we prove that even in the absence of noise, every non-adaptive\nalgorithm requires $\\Omega(n^3)$ ordinal queries in the worst case.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 03:34:10 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 17:01:46 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 07:24:24 GMT"}, {"version": "v4", "created": "Tue, 17 Apr 2018 01:34:09 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Emamjomeh-Zadeh", "Ehsan", ""], ["Kempe", "David", ""]]}, {"id": "1708.00240", "submitter": "Mohammad Reza Hooshmandasl", "authors": "M. Rajaati, P. Sharifani, A. Shakiba, M. R. Hooshmandasl, M. J.\n  Dinneen", "title": "An Efficient Algorithm for Mixed Domination on Generalized\n  Series-Parallel Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixed dominating set $S$ of a graph $G=(V,E)$ is a subset $ S \\subseteq V\n\\cup E$ such that each element $v\\in (V \\cup E) \\setminus S$ is adjacent or\nincident to at least one element in $S$. The mixed domination number\n$\\gamma_m(G)$ of a graph $G$ is the minimum cardinality among all mixed\ndominating sets in $G$. The problem of finding $\\gamma_{m}(G)$ is know to be\nNP-complete. In this paper, we present an explicit polynomial-time algorithm to\nconstruct a mixed dominating set of size $\\gamma_{m}(G)$ by a parse tree when\n$G$ is a generalized series-parallel graph.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 10:49:30 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Rajaati", "M.", ""], ["Sharifani", "P.", ""], ["Shakiba", "A.", ""], ["Hooshmandasl", "M. R.", ""], ["Dinneen", "M. J.", ""]]}, {"id": "1708.00276", "submitter": "Gregory Schwartzman", "authors": "Reuven Bar-Yehuda, Keren Censor-Hillel, Mohsen Ghaffari, Gregory\n  Schwartzman", "title": "Distributed Approximation of Maximum Independent Set and Maximum\n  Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple distributed $\\Delta$-approximation algorithm for maximum\nweight independent set (MaxIS) in the $\\mathsf{CONGEST}$ model which completes\nin $O(\\texttt{MIS}(G)\\cdot \\log W)$ rounds, where $\\Delta$ is the maximum\ndegree, $\\texttt{MIS}(G)$ is the number of rounds needed to compute a maximal\nindependent set (MIS) on $G$, and $W$ is the maximum weight of a node. %Whether\nour algorithm is randomized or deterministic depends on the \\texttt{MIS}\nalgorithm used as a black-box.\n  Plugging in the best known algorithm for MIS gives a randomized solution in\n$O(\\log n \\log W)$ rounds, where $n$ is the number of nodes.\n  We also present a deterministic $O(\\Delta +\\log^* n)$-round algorithm based\non coloring.\n  We then show how to use our MaxIS approximation algorithms to compute a\n$2$-approximation for maximum weight matching without incurring any additional\nround penalty in the $\\mathsf{CONGEST}$ model. We use a known reduction for\nsimulating algorithms on the line graph while incurring congestion, but we show\nour algorithm is part of a broad family of \\emph{local aggregation algorithms}\nfor which we describe a mechanism that allows the simulation to run in the\n$\\mathsf{CONGEST}$ model without an additional overhead.\n  Next, we show that for maximum weight matching, relaxing the approximation\nfactor to ($2+\\varepsilon$) allows us to devise a distributed algorithm\nrequiring $O(\\frac{\\log \\Delta}{\\log\\log\\Delta})$ rounds for any constant\n$\\varepsilon>0$. For the unweighted case, we can even obtain a\n$(1+\\varepsilon)$-approximation in this number of rounds. These algorithms are\nthe first to achieve the provably optimal round complexity with respect to\ndependency on $\\Delta$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 12:19:50 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Bar-Yehuda", "Reuven", ""], ["Censor-Hillel", "Keren", ""], ["Ghaffari", "Mohsen", ""], ["Schwartzman", "Gregory", ""]]}, {"id": "1708.00331", "submitter": "Junhua Wu", "authors": "Junhua Wu, Markus Wagner, Sergey Polyakovskiy and Frank Neumann", "title": "Exact Approaches for the Travelling Thief Problem", "comments": "13 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many evolutionary and constructive heuristic approaches have been introduced\nin order to solve the Traveling Thief Problem (TTP). However, the accuracy of\nsuch approaches is unknown due to their inability to find global optima. In\nthis paper, we propose three exact algorithms and a hybrid approach to the TTP.\nWe compare these with state-of-the-art approaches to gather a comprehensive\noverview on the accuracy of heuristic methods for solving small TTP instances.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 13:56:27 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Wu", "Junhua", ""], ["Wagner", "Markus", ""], ["Polyakovskiy", "Sergey", ""], ["Neumann", "Frank", ""]]}, {"id": "1708.00354", "submitter": "Scott Haag", "authors": "Scott Haag, Ali Shokoufandeh", "title": "A Watershed Delineation Algorithm for 2D Flow Direction Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm and associated data model for creating\na watershed boundary using a 2D Flow Direction Grid. Flow Direction Grids\n(FDGs) are common abstractions for hydrodynamic models and are utilized for\ndelineating physical systems (e.g. watersheds, fluvial, and non-fluvial flow\npaths). The proposed algorithm and associated data model provides geometric\nspeed increases in watershed boundary retrieval while keeping storage\nconstraints linear in comparison to existing techniques. The algorithm called\nHaag Shokoufandehs' March (HSM) relies on an existing data structure, the\nmodified nested set model, originally described by Celko and applied to\nhydrodynamic models by Haag and Shokoufandeh in 2017. The proposed algorithm\ncreates watershed boundaries by marching around the edges of its' corresponding\nregion, never entering the internal area. In contrast to existing algorithms\nthat scales in proportional to the area of the underlying region, the\ncomplexity of the HSM algorithm is proportional to the boundary length. Results\nfor a group of tested watersheds (n = 14,718) in the approximately 36,000 km^2\nDelaware River Watershed show a reduction of between 0 and 99% in computational\ncomplexity using a 30 m DEM vs. existing techniques. Larger watersheds have a\nconsistent reduction in the number of (read) operation complexity, with the\nlargest watershed resulting in approximately 35 million reads using traditional\ntechniques compared to approximately 45 thousand using the HSM algorithm,\nrespectively. Modelled estimates of the complexity for the approximately 6.1\nmillion km^2 Amazon River basin show a reduction from 6.7 billion to 1.4\nmillion reads.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 14:25:38 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Haag", "Scott", ""], ["Shokoufandeh", "Ali", ""]]}, {"id": "1708.00510", "submitter": "Shai Vardi", "authors": "Shai Vardi", "title": "A note on the size of query trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider query trees of graphs with degree bounded by a constant, $d$. We\ngive simple proofs that the size of a query tree is constant in expectation and\n$2^{O(d)}\\log{n}$ w.h.p.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 20:58:12 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Vardi", "Shai", ""]]}, {"id": "1708.00582", "submitter": "Kenjiro Takazawa", "authors": "Kenjiro Takazawa", "title": "Excluded $t$-factors in Bipartite Graphs: Unified Framework for\n  Nonbipartite Matchings, Restricted 2-matchings, and Matroids", "comments": "23 pages, 7 figures, A preliminary version of this paper appears in\n  Proceedings of the 19th IPCO (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for optimal $t$-matchings excluding the prescribed\n$t$-factors in bipartite graphs. The proposed framework is a generalization of\nthe nonbipartite matching problem and includes several problems, such as the\ntriangle-free $2$-matching, square-free $2$-matching, even factor, and\narborescence problems. In this paper, we demonstrate a unified understanding of\nthese problems by commonly extending previous important results. We solve our\nproblem under a reasonable assumption, which is sufficiently broad to include\nthe specific problems listed above. We first present a min-max theorem and a\ncombinatorial algorithm for the unweighted version. We then provide a linear\nprogramming formulation with dual integrality and a primal-dual algorithm for\nthe weighted version. A key ingredient of the proposed algorithm is a technique\nto shrink forbidden structures, which corresponds to the techniques of\nshrinking odd cycles, triangles, squares, and directed cycles in Edmonds'\nblossom algorithm, a triangle-free $2$-matching algorithm, a square-free\n$2$-matching algorithm, and an arborescence algorithm, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 02:42:43 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Takazawa", "Kenjiro", ""]]}, {"id": "1708.00622", "submitter": "Prafullkumar Tale Mr", "authors": "Akanksha Agrawal, Saket Saurabh and Prafullkumar Tale", "title": "On the Parameterized Complexity of Contraction to Generalization of\n  Trees", "comments": "Full version of paper appeared in IPEC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a family of graphs $\\cal F$, the $\\mathcal{F}$-Contraction problem takes\nas an input a graph $G$ and an integer $k$, and the goal is to decide if there\nexists $S \\subseteq E(G)$ of size at most $k$ such that $G/S$ belongs to $\\cal\nF$. Here, $G/S$ is the graph obtained from $G$ by contracting all the edges in\n$S$. Heggernes et al.~[Algorithmica (2014)] were the first to study edge\ncontraction problems in the realm of Parameterized Complexity. They studied\n$\\cal F$-Contraction when $\\cal F$ is a simple family of graphs such as trees\nand paths. In this paper, we study the $\\mathcal{F}$-Contraction problem, where\n$\\cal F$ generalizes the family of trees. In particular, we define this\ngeneralization in a \"parameterized way\". Let $\\mathbb{T}_\\ell$ be the family of\ngraphs such that each graph in $\\mathbb{T}_\\ell$ can be made into a tree by\ndeleting at most $\\ell$ edges. Thus, the problem we study is\n$\\mathbb{T}_\\ell$-Contraction. We design an FPT algorithm for\n$\\mathbb{T}_\\ell$-Contraction running in time\n$\\mathcal{O}((2\\sqrt(\\ell))^{\\mathcal{O}(k + \\ell)} \\cdot n^{\\mathcal{O}(1)})$.\nFurthermore, we show that the problem does not admit a polynomial kernel when\nparameterized by $k$. Inspired by the negative result for the kernelization, we\ndesign a lossy kernel for $\\mathbb{T}_\\ell$-Contraction of size $\n\\mathcal{O}([k(k + 2\\ell)] ^{(\\lceil {\\frac{\\alpha}{\\alpha-1}\\rceil + 1)}})$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 07:44:40 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Saurabh", "Saket", ""], ["Tale", "Prafullkumar", ""]]}, {"id": "1708.00774", "submitter": "Anton Eremeev", "authors": "Pavel Borisovsky, Anton Eremeev, Sergei Hrushev, Vadim Teplyakov,\n  Mikhail Vorozhtsov", "title": "Approximate solution of length-bounded maximum multicommodity flow with\n  unit edge-lengths", "comments": "17-th Baikal International Triannual School-Seminar \"Methods of\n  Optimization and Their Applications\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An improved fully polynomial-time approximation scheme and a greedy heuristic\nfor the fractional length-bounded maximum multicommodity flow problem with unit\nedge-lengths are proposed. Computational experiments are carried out on\nbenchmark graphs and on graphs that model software defined satellite networks\nto compare the proposed algorithms and an exact linear programming solver. The\nresults of experiments demonstrate a trade-off between the computing time and\nthe precision of algorithms under consideration.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 14:42:36 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Borisovsky", "Pavel", ""], ["Eremeev", "Anton", ""], ["Hrushev", "Sergei", ""], ["Teplyakov", "Vadim", ""], ["Vorozhtsov", "Mikhail", ""]]}, {"id": "1708.00854", "submitter": "Alex Zhai", "authors": "Yuval Peres and Alex Zhai", "title": "Average-case reconstruction for the deletion channel: subpolynomially\n  many traces suffice", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deletion channel takes as input a bit string $\\mathbf{x} \\in \\{0,1\\}^n$,\nand deletes each bit independently with probability $q$, yielding a shorter\nstring. The trace reconstruction problem is to recover an unknown string\n$\\mathbf{x}$ from many independent outputs (called \"traces\") of the deletion\nchannel applied to $\\mathbf{x}$. We show that if $\\mathbf{x}$ is drawn\nuniformly at random and $q < 1/2$, then $e^{O(\\log^{1/2} n)}$ traces suffice to\nreconstruct $\\mathbf{x}$ with high probability. The previous best bound,\nestablished in 2008 by Holenstein-Mitzenmacher-Panigrahy-Wieder, uses\n$n^{O(1)}$ traces and only applies for $q$ less than a smaller threshold (it\nseems that $q < 0.07$ is needed). Our algorithm combines several ideas: 1) an\nalignment scheme for \"greedily\" fitting the output of the deletion channel as a\nsubsequence of the input; 2) a version of the idea of \"anchoring\" used by\nHolenstein-Mitzenmacher-Panigrahy-Wieder; and 3) complex analysis techniques\nfrom recent work of Nazarov-Peres and De-O'Donnell-Servedio.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:46:06 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Peres", "Yuval", ""], ["Zhai", "Alex", ""]]}, {"id": "1708.00964", "submitter": "Adnan Mohammed", "authors": "Adnan Saher Mohammed, \\c{S}ahin Emrah Amrahov, Fatih V. \\c{C}elebi", "title": "Efficient hybrid search algorithm on ordered datasets", "comments": "13 pages full-length article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in the rate of data is much higher than the increase in the\nspeed of computers, which results in a heavy emphasis on search algorithms in\nresearch literature. Searching an item in ordered list is an efficient\noperation in data processing. Binary and interpolation search algorithms\ncommonly are used for searching ordered dataset in many applications. In this\npaper, we present a hybrid algorithm to search ordered datasets based on the\nidea of interpolation and binary search. The proposed algorithm called Hybrid\nSearch (HS), which is designed to work efficiently on unknown distributed\nordered datasets, experimental results showed that our proposed algorithm has\nbetter performance when compared with other algorithms that use a similar\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 01:13:40 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Mohammed", "Adnan Saher", ""], ["Amrahov", "\u015eahin Emrah", ""], ["\u00c7elebi", "Fatih V.", ""]]}, {"id": "1708.00977", "submitter": "Muaz Niazi", "authors": "Bisma S. Khan, Muaz A. Niazi", "title": "Network Community Detection: A Review and Visual Survey", "comments": "39 pages, 17 figures, 24 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.DL cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community structure is an important area of research. It has received a\nconsiderable attention from the scientific community. Despite its importance,\none of the key problems in locating information about community detection is\nthe diverse spread of related articles across various disciplines. To the best\nof our knowledge, there is no current comprehensive review of recent literature\nwhich uses a scientometric analysis using complex networks analysis covering\nall relevant articles from the Web of Science (WoS). Here we present a visual\nsurvey of key literature using CiteSpace. The idea is to identify emerging\ntrends besides using network techniques to examine the evolution of the domain.\nTowards that end, we identify the most influential, central, as well as active\nnodes using scientometric analyses. We examine authors, key articles, cited\nreferences, core subject categories, key journals, institutions, as well as\ncountries. The exploration of the scientometric literature of the domain\nreveals that Yong Wang is a pivot node with the highest centrality.\nAdditionally, we have observed that Mark Newman is the most highly cited author\nin the network. We have also identified that the journal, \"Reviews of Modern\nPhysics\" has the strongest citation burst. In terms of cited documents, an\narticle by Andrea Lancichinetti has the highest centrality score. We have also\ndiscovered that the origin of the key publications in this domain is from the\nUnited States. Whereas Scotland has the strongest and longest citation burst.\nAdditionally, we have found that the categories of \"Computer Science\" and\n\"Engineering\" lead other categories based on frequency and centrality\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 02:57:35 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Khan", "Bisma S.", ""], ["Niazi", "Muaz A.", ""]]}, {"id": "1708.01011", "submitter": "Parter Merav", "authors": "Ofer Grossman and Merav Parter", "title": "Improved Deterministic Distributed Construction of Spanners", "comments": "To appear in DISC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph spanners are fundamental graph structures with a wide range of\napplications in distributed networks. We consider a standard synchronous\nmessage passing model where in each round $O(\\log n)$ bits can be transmitted\nover every edge (the CONGEST model).\n  The state of the art of deterministic distributed spanner constructions\nsuffers from large messages. The only exception is the work of Derbel et al.\n'10, which computes an optimal-sized $(2k-1)$-spanner but uses $O(n^{1-1/k})$\nrounds.\n  In this paper, we significantly improve this bound. We present a\ndeterministic distributed algorithm that given an unweighted $n$-vertex graph\n$G = (V, E)$ and a parameter $k > 2$, constructs a $(2k-1)$-spanner with $O(k\n\\cdot n^{1+1/k})$ edges within $O(2^{k} \\cdot n^{1/2 - 1/k})$ rounds for every\neven $k$. For odd $k$, the number of rounds is $O(2^{k} \\cdot n^{1/2 -\n1/(2k)})$. For the weighted case, we provide the first deterministic\nconstruction of a $3$-spanner with $O(n^{3/2})$ edges that uses $O(\\log\nn)$-size messages and $\\widetilde{O}(1)$ rounds. If the nodes have IDs in $[1,\n\\Theta(n)]$, then the algorithm works in only $2$ rounds!\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 06:00:18 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 21:15:33 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Grossman", "Ofer", ""], ["Parter", "Merav", ""]]}, {"id": "1708.01079", "submitter": "Shashwat Garg", "authors": "Nikhil Bansal, Daniel Dadush, Shashwat Garg, Shachar Lovett", "title": "The Gram-Schmidt Walk: A Cure for the Banaszczyk Blues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important result in discrepancy due to Banaszczyk states that for any set\nof $n$ vectors in $\\mathbb{R}^m$ of $\\ell_2$ norm at most $1$ and any convex\nbody $K$ in $\\mathbb{R}^m$ of Gaussian measure at least half, there exists a\n$\\pm 1$ combination of these vectors which lies in $5K$. This result implies\nthe best known bounds for several problems in discrepancy. Banaszczyk's proof\nof this result is non-constructive and a major open problem has been to give an\nefficient algorithm to find such a $\\pm 1$ combination of the vectors.\n  In this paper, we resolve this question and give an efficient randomized\nalgorithm to find a $\\pm 1$ combination of the vectors which lies in $cK$ for\n$c>0$ an absolute constant. This leads to new efficient algorithms for several\nproblems in discrepancy theory.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 09:49:42 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Bansal", "Nikhil", ""], ["Dadush", "Daniel", ""], ["Garg", "Shashwat", ""], ["Lovett", "Shachar", ""]]}, {"id": "1708.01130", "submitter": "Thierry Lecroq", "authors": "Jacqueline W. Daykin and Richard Groult and Yannick Guesnet and\n  Thierry Lecroq and Arnaud Lefebvre and Martine L\\'eonard and Laurent Mouchard\n  and \\'Elise Prieur-Gaston and Bruce Watson", "title": "Efficient pattern matching in degenerate strings with the\n  Burrows-Wheeler transform", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A degenerate or indeterminate string on an alphabet $\\Sigma$ is a sequence of\nnon-empty subsets of $\\Sigma$. Given a degenerate string $t$ of length $n$, we\npresent a new method based on the Burrows--Wheeler transform for searching for\na degenerate pattern of length $m$ in $t$ running in $O(mn)$ time on a constant\nsize alphabet $\\Sigma$. Furthermore, it is a hybrid pattern-matching technique\nthat works on both regular and degenerate strings. A degenerate string is said\nto be conservative if its number of non-solid letters is upper-bounded by a\nfixed positive constant $q$; in this case we show that the search complexity\ntime is $O(qm^2)$. Experimental results show that our method performs well in\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 13:30:41 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Daykin", "Jacqueline W.", ""], ["Groult", "Richard", ""], ["Guesnet", "Yannick", ""], ["Lecroq", "Thierry", ""], ["Lefebvre", "Arnaud", ""], ["L\u00e9onard", "Martine", ""], ["Mouchard", "Laurent", ""], ["Prieur-Gaston", "\u00c9lise", ""], ["Watson", "Bruce", ""]]}, {"id": "1708.01212", "submitter": "Sergey Dovgal", "authors": "Maciej Bendkowski, Olivier Bodini, Sergey Dovgal", "title": "Polynomial tuning of multiparametric combinatorial samplers", "comments": "Extended abstract, accepted to ANALCO2018. 20 pages, 6 figures,\n  colours. Implementation and examples are available at [1]\n  https://github.com/maciej-bendkowski/boltzmann-brain [2]\n  https://github.com/maciej-bendkowski/multiparametric-combinatorial-samplers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann samplers and the recursive method are prominent algorithmic\nframeworks for the approximate-size and exact-size random generation of large\ncombinatorial structures, such as maps, tilings, RNA sequences or various\ntree-like structures. In their multiparametric variants, these samplers allow\nto control the profile of expected values corresponding to multiple\ncombinatorial parameters. One can control, for instance, the number of leaves,\nprofile of node degrees in trees or the number of certain subpatterns in\nstrings. However, such a flexible control requires an additional non-trivial\ntuning procedure. In this paper, we propose an efficient polynomial-time, with\nrespect to the number of tuned parameters, tuning algorithm based on convex\noptimisation techniques. Finally, we illustrate the efficiency of our approach\nusing several applications of rational, algebraic and P\\'olya structures\nincluding polyomino tilings with prescribed tile frequencies, planar trees with\na given specific node degree distribution, and weighted partitions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 16:59:37 GMT"}, {"version": "v2", "created": "Sun, 29 Oct 2017 05:58:30 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Bendkowski", "Maciej", ""], ["Bodini", "Olivier", ""], ["Dovgal", "Sergey", ""]]}, {"id": "1708.01249", "submitter": "Panos P. Markopoulos", "authors": "Nicholas Tsagkarakis, Panos P. Markopoulos, Dimitris A. Pados", "title": "L1-norm Principal-Component Analysis of Complex Data", "comments": "This draft is a preprint. In case you identify a typographical error,\n  please contact the corresponding author", "journal-ref": null, "doi": "10.1109/TSP.2018.2821641", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L1-norm Principal-Component Analysis (L1-PCA) of real-valued data has\nattracted significant research interest over the past decade. However, L1-PCA\nof complex-valued data remains to date unexplored despite the many possible\napplications (e.g., in communication systems). In this work, we establish\ntheoretical and algorithmic foundations of L1-PCA of complex-valued data\nmatrices. Specifically, we first show that, in contrast to the real-valued case\nfor which an optimal polynomial-cost algorithm was recently reported by\nMarkopoulos et al., complex L1-PCA is formally NP-hard in the number of data\npoints. Then, casting complex L1-PCA as a unimodular optimization problem, we\npresent the first two suboptimal algorithms in the literature for its solution.\nOur experimental studies illustrate the sturdy resistance of complex L1-PCA\nagainst faulty measurements/outliers in the processed data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 17:54:21 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Tsagkarakis", "Nicholas", ""], ["Markopoulos", "Panos P.", ""], ["Pados", "Dimitris A.", ""]]}, {"id": "1708.01335", "submitter": "Chaitanya Swamy", "authors": "Zachary Friggstad and Chaitanya Swamy", "title": "Compact, Provably-Good LPs for Orienteering and Regret-Bounded Vehicle\n  Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop polynomial-size LP-relaxations for {\\em orienteering} and the {\\em\nregret-bounded vehicle routing problem} (\\rvrp) and devise suitable LP-rounding\nalgorithms that lead to various new insights and approximation results for\nthese problems. In orienteering, the goal is to find a maximum-reward\n$r$-rooted path, possibly ending at a specified node, of length at most some\ngiven budget $B$. In \\rvrp, the goal is to find the minimum number of\n$r$-rooted paths of {\\em regret} at most a given bound $R$ that cover all\nnodes, where the regret of an $r$-$v$ path is its length $-$ $c_{rv}$.\n  For {\\em rooted orienteering}, we introduce a natural bidirected\nLP-relaxation and obtain a simple $3$-approximation algorithm via LP-rounding.\nThis is the {\\em first LP-based} guarantee for this problem. We also show that\n{\\em point-to-point} (\\ptp) {\\em orienteering} can be reduced to a\nregret-version of rooted orienteering at the expense of a factor-2 loss in\napproximation. For \\rvrp, we propose two compact LPs that lead to significant\nimprovements, in both approximation ratio and running time, over the approach\nin~\\cite{FriggstadS14}. One of these is a natural modification of the LP for\nrooted orienteering; the other is an unconventional formulation that is\nmotivated by certain structural properties of an \\rvrp-solution, which leads to\na $15$-approximation algorithm for \\rvrp.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 00:06:38 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Friggstad", "Zachary", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1708.01386", "submitter": "Shay Mozes", "authors": "Pawe{\\l} Gawrychowski, Shay Mozes, Oren Weimann, and Christian\n  Wulff-Nilsen", "title": "Better Tradeoffs for Exact Distance Oracles in Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $O(n^{1.5})$-space distance oracle for directed planar graphs\nthat answers distance queries in $O(\\log n)$ time. Our oracle both\nsignificantly simplifies and significantly improves the recent oracle of\nCohen-Addad, Dahlgaard and Wulff-Nilsen [FOCS 2017], which uses\n$O(n^{5/3})$-space and answers queries in $O(\\log n)$ time. We achieve this by\ndesigning an elegant and efficient point location data structure for Voronoi\ndiagrams on planar graphs.\n  We further show a smooth tradeoff between space and query-time. For any $S\\in\n[n,n^2]$, we show an oracle of size $S$ that answers queries in $\\tilde\nO(\\max\\{1,n^{1.5}/S\\})$ time. This new tradeoff is currently the best (up to\npolylogarithmic factors) for the entire range of $S$ and improves by polynomial\nfactors over all the previously known tradeoffs for the range $S \\in\n[n,n^{5/3}]$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 05:58:10 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Mozes", "Shay", ""], ["Weimann", "Oren", ""], ["Wulff-Nilsen", "Christian", ""]]}, {"id": "1708.01402", "submitter": "Yuhang Zhang", "authors": "Yuhang Zhang, Tania Churchill and Kee Siong Ng", "title": "Exploiting Redundancy, Recurrence and Parallelism: How to Link Millions\n  of Addresses with Ten Lines of Code in Ten Minutes", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient record linkage is an open challenge of particular\nrelevance to Australian Government Agencies, who recognise that so-called\nwicked social problems are best tackled by forming partnerships founded on\nlarge-scale data fusion. Names and addresses are the most common attributes on\nwhich data from different government agencies can be linked. In this paper, we\nfocus on the problem of address linking. Linkage is particularly problematic\nwhen the data has significant quality issues. The most common approach for\ndealing with quality issues is to standardise raw data prior to linking. If a\nmistake is made in standardisation, however, it is usually impossible to\nrecover from it to perform linkage correctly. This paper proposes a novel\nalgorithm for address linking that is particularly practical for linking large\ndisparate sets of addresses, being highly scalable, robust to data quality\nissues and simple to implement. It obviates the need for labour intensive and\nproblematic address standardisation. We demonstrate the efficacy of the\nalgorithm by matching two large address datasets from two government agencies\nwith good accuracy and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 07:26:20 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 02:59:29 GMT"}, {"version": "v3", "created": "Tue, 19 Dec 2017 00:07:44 GMT"}, {"version": "v4", "created": "Wed, 31 Jan 2018 05:57:54 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Zhang", "Yuhang", ""], ["Churchill", "Tania", ""], ["Ng", "Kee Siong", ""]]}, {"id": "1708.01625", "submitter": "Florian Neukart", "authors": "Florian Neukart, Gabriele Compostella, Christian Seidel, David von\n  Dollen, Sheir Yarkoni, Bob Parney", "title": "Traffic flow optimization using a quantum annealer", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum annealing algorithms belong to the class of meta-heuristic tools,\napplicable for solving binary optimization problems. Hardware implementations\nof quantum annealing, such as the quantum processing units (QPUs) produced by\nD-Wave Systems, have been subject to multiple analyses in research, with the\naim of characterizing the technology's usefulness for optimization and sampling\ntasks. In this paper, we present a real-world application that uses quantum\ntechnologies. Specifically, we show how to map certain parts of the real-world\ntraffic flow optimization problem to be suitable for quantum annealing. We show\nthat time-critical optimization tasks, such as continuous redistribution of\nposition data for cars in dense road networks, are suitable candidates for\nquantum applications. Due to the limited size and connectivity of\ncurrent-generation D-Wave QPUs, we use a hybrid quantum and classical approach\nto solve the traffic flow problem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 18:09:33 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 20:52:38 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Neukart", "Florian", ""], ["Compostella", "Gabriele", ""], ["Seidel", "Christian", ""], ["von Dollen", "David", ""], ["Yarkoni", "Sheir", ""], ["Parney", "Bob", ""]]}, {"id": "1708.01632", "submitter": "Nikhil Srivastava", "authors": "Aaron Schild, Satish Rao, Nikhil Srivastava", "title": "Localization of Electrical Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that in any graph, the average length of a flow path in an electrical\nflow between the endpoints of a random edge is $O(\\log^2 n)$. This is a\nconsequence of a more general result which shows that the spectral norm of the\nentrywise absolute value of the transfer impedance matrix of a graph is\n$O(\\log^2 n)$. This result implies a simple oblivious routing scheme based on\nelectrical flows in the case of transitive graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 18:26:03 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Schild", "Aaron", ""], ["Rao", "Satish", ""], ["Srivastava", "Nikhil", ""]]}, {"id": "1708.01657", "submitter": "Denis Pankratov", "authors": "Allan Borodin, Denis Pankratov, Amirali Salehi-Abari", "title": "A Simple PTAS for the Dual Bin Packing Problem and Advice Complexity of\n  Its Online Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Renault (2016) studied the dual bin packing problem in the\nper-request advice model of online algorithms. He showed that given\n$O(1/\\epsilon)$ advice bits for each input item allows approximating the dual\nbin packing problem online to within a factor of $1+\\epsilon$. Renault asked\nabout the advice complexity of dual bin packing in the tape-advice model of\nonline algorithms. We make progress on this question. Let $s$ be the maximum\nbit size of an input item weight. We present a conceptually simple online\nalgorithm that with total advice $O\\left(\\frac{s + \\log n}{\\epsilon^2}\\right)$\napproximates the dual bin packing to within a $1+\\epsilon$ factor. To this end,\nwe describe and analyze a simple offline PTAS for the dual bin packing problem.\nAlthough a PTAS for a more general problem was known prior to our work\n(Kellerer 1999, Chekuri and Khanna 2006), our PTAS is arguably simpler to state\nand analyze. As a result, we could easily adapt our PTAS to obtain the\nadvice-complexity result.\n  We also consider whether the dependence on $s$ is necessary in our algorithm.\nWe show that if $s$ is unrestricted then for small enough $\\epsilon > 0$\nobtaining a $1+\\epsilon$ approximation to the dual bin packing requires\n$\\Omega_\\epsilon(n)$ bits of advice. To establish this lower bound we analyze\nan online reduction that preserves the advice complexity and approximation\nratio from the binary separation problem due to Boyar et al. (2016). We define\ntwo natural advice complexity classes that capture the distinction similar to\nthe Turing machine world distinction between pseudo polynomial time algorithms\nand polynomial time algorithms. Our results on the dual bin packing problem\nimply the separation of the two classes in the advice complexity world.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 20:25:46 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Borodin", "Allan", ""], ["Pankratov", "Denis", ""], ["Salehi-Abari", "Amirali", ""]]}, {"id": "1708.01696", "submitter": "Rodrigo de Lamare", "authors": "Andr\\'e Flores and Rodrigo C. de Lamare", "title": "Study of Sparsity-Aware Set-Membership Adaptive Algorithms with\n  Adjustable Penalties", "comments": "4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose sparsity-aware data-selective adaptive filtering\nalgorithms with adjustable penalties. Prior work incorporates a penalty\nfunction into the cost function used in the optimization that originates the\nalgorithms to improve their performance by exploiting sparsity. However, the\nstrength of the penalty function is controlled by a scalar that is often a\nfixed parameter. In contrast to prior work, we develop a framework to derive\nalgorithms that automatically adjust the penalty function parameter and the\nstep size to achieve a better performance. Simulations for a system\nidentification application show that the proposed algorithms outperform in\nconvergence speed existing sparsity-aware algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 01:41:00 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Flores", "Andr\u00e9", ""], ["de Lamare", "Rodrigo C.", ""]]}, {"id": "1708.02105", "submitter": "Wei Hu", "authors": "Zeyuan Allen-Zhu, Elad Hazan, Wei Hu, Yuanzhi Li", "title": "Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls", "comments": "In NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rank-$k$ variant of the classical Frank-Wolfe algorithm to solve\nconvex optimization over a trace-norm ball. Our algorithm replaces the top\nsingular-vector computation ($1$-SVD) in Frank-Wolfe with a top-$k$\nsingular-vector computation ($k$-SVD), which can be done by repeatedly applying\n$1$-SVD $k$ times. Alternatively, our algorithm can be viewed as a rank-$k$\nrestricted version of projected gradient descent. We show that our algorithm\nhas a linear convergence rate when the objective function is smooth and\nstrongly convex, and the optimal solution has rank at most $k$. This improves\nthe convergence rate and the total time complexity of the Frank-Wolfe method\nand its variants.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 13:07:20 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 23:33:37 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 02:16:15 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Hazan", "Elad", ""], ["Hu", "Wei", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1708.02142", "submitter": "Yoav Kolumbus", "authors": "Yoav Kolumbus and Sorin Solomon", "title": "Phase Transition in the Maximal Influence Problem: When Do We Need\n  Optimization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cond-mat.stat-mech cs.DS physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable efforts were made in recent years in devising optimization\nalgorithms for influence maximization in networks. Here we ask: \"When do we\nneed optimization?\" We use results from statistical mechanics and direct\nsimulations on ER networks, small-world networks, power-law networks and a\ndataset of real-world networks to characterize the parameter-space region where\noptimization is required. We show that in both synthetic and real-world\nnetworks this optimization region is due to a well known physical phase\ntransition of the network, and that it vanishes as a power-law with the network\nsize. We then show that also from a utility-maximization perspective (when\nconsidering the costs of the optimization process), for large networks standard\noptimization is profitable only in a vanishing parameter region near the phase\ntransition. Finally, we introduce a novel constant-time optimization approach,\nand demonstrate it through a simple algorithm that manages to give similar\nresults to standard optimization methods in terms of the influenced-set size,\nwhile improving the results in terms of the net utility.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 14:50:22 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 13:46:14 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kolumbus", "Yoav", ""], ["Solomon", "Sorin", ""]]}, {"id": "1708.02222", "submitter": "Rohit Gurjar", "authors": "Rohit Gurjar, Thomas Thierauf, Nisheeth K. Vishnoi", "title": "Isolating a Vertex via Lattices: Polytopes with Totally Unimodular Faces", "comments": "Changes mainly in the introduction and abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a geometric approach towards derandomizing the Isolation Lemma by\nMulmuley, Vazirani, and Vazirani. In particular, our approach produces a\nquasi-polynomial family of weights, where each weight is an integer and\nquasi-polynomially bounded, that can isolate a vertex in any 0/1 polytope for\nwhich each face lies in an affine space defined by a totally unimodular matrix.\nThis includes the polytopes given by totally unimodular constraints and\ngeneralizes the recent derandomization of the Isolation Lemma for bipartite\nperfect matching and matroid intersection. We prove our result by associating a\nlattice to each face of the polytope and showing that if there is a totally\nunimodular kernel matrix for this lattice, then the number of vectors of length\nwithin 3/2 of the shortest vector in it is polynomially bounded. The proof of\nthis latter geometric fact is combinatorial and follows from a polynomial bound\non the number of circuits of size within 3/2 of the shortest circuit in a\nregular matroid. This is the technical core of the paper and relies on a\nvariant of Seymour's decomposition theorem for regular matroids. It generalizes\nan influential result by Karger on the number of minimum cuts in a graph to\nregular matroids.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 17:40:12 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 20:11:17 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 15:47:55 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Gurjar", "Rohit", ""], ["Thierauf", "Thomas", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1708.02266", "submitter": "Matthew Fahrbach", "authors": "Megan Bernstein, Matthew Fahrbach, Dana Randall", "title": "Analyzing Boltzmann Samplers for Bose-Einstein Condensates with\n  Dirichlet Generating Functions", "comments": "20 pages, 1 figure", "journal-ref": "Proceedings of the Fifteenth Workshop on Analytic Algorithmics and\n  Combinatorics (ANALCO 2018) 107-117", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann sampling is commonly used to uniformly sample objects of a\nparticular size from large combinatorial sets. For this technique to be\neffective, one needs to prove that (1) the sampling procedure is efficient and\n(2) objects of the desired size are generated with sufficiently high\nprobability. We use this approach to give a provably efficient sampling\nalgorithm for a class of weighted integer partitions related to Bose-Einstein\ncondensation from statistical physics. Our sampling algorithm is a\nprobabilistic interpretation of the ordinary generating function for these\nobjects, derived from the symbolic method of analytic combinatorics. Using the\nKhintchine-Meinardus probabilistic method to bound the rejection rate of our\nBoltzmann sampler through singularity analysis of Dirichlet generating\nfunctions, we offer an alternative approach to analyze Boltzmann samplers for\nobjects with multiplicative structure.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 18:57:35 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 19:45:49 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Bernstein", "Megan", ""], ["Fahrbach", "Matthew", ""], ["Randall", "Dana", ""]]}, {"id": "1708.02323", "submitter": "Sahand Mozaffari", "authors": "Karthekeyan Chandrasekaran and Matthias Mnich and Sahand Mozaffari", "title": "Odd Multiway Cut in Directed Acyclic Graphs", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the odd multiway node (edge) cut problem where the input is a\ngraph with a specified collection of terminal nodes and the goal is to find a\nsmallest subset of nonterminal nodes (edges) to delete so that the terminal\nnodes do not have an odd length path between them. In an earlier work,\nLokshtanov and Ramanujan showed that both odd multiway node cut and odd\nmultiway edge cut are fixed-parameter tractable (FPT) when parameterized by the\nsize of the solution in undirected graphs. In this work, we focus on directed\nacyclic graphs (DAGs) and design a fixed-parameter algorithm. Our main\ncontribution is a broadening of the shadow-removal framework to address parity\nproblems in DAGs. We complement our FPT results with tight approximability as\nwell as polyhedral results for 2 terminals in DAGs. Additionally, we show\ninapproximability results for odd multiway edge cut in undirected graphs even\nfor 2 terminals.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 22:21:24 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 17:17:30 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Mnich", "Matthias", ""], ["Mozaffari", "Sahand", ""]]}, {"id": "1708.02581", "submitter": "Damian Straszak", "authors": "Damian Straszak and Nisheeth K. Vishnoi", "title": "Belief Propagation, Bethe Approximation and Polynomials", "comments": "Invited to Allerton 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor graphs are important models for succinctly representing probability\ndistributions in machine learning, coding theory, and statistical physics.\nSeveral computational problems, such as computing marginals and partition\nfunctions, arise naturally when working with factor graphs. Belief propagation\nis a widely deployed iterative method for solving these problems. However,\ndespite its significant empirical success, not much is known about the\ncorrectness and efficiency of belief propagation.\n  Bethe approximation is an optimization-based framework for approximating\npartition functions. While it is known that the stationary points of the Bethe\napproximation coincide with the fixed points of belief propagation, in general,\nthe relation between the Bethe approximation and the partition function is not\nwell understood. It has been observed that for a few classes of factor graphs,\nthe Bethe approximation always gives a lower bound to the partition function,\nwhich distinguishes them from the general case, where neither a lower bound,\nnor an upper bound holds universally. This has been rigorously proved for\npermanents and for attractive graphical models.\n  Here we consider bipartite normal factor graphs and show that if the local\nconstraints satisfy a certain analytic property, the Bethe approximation is a\nlower bound to the partition function. We arrive at this result by viewing\nfactor graphs through the lens of polynomials. In this process, we reformulate\nthe Bethe approximation as a polynomial optimization problem. Our sufficient\ncondition for the lower bound property to hold is inspired by recent\ndevelopments in the theory of real stable polynomials. We believe that this way\nof viewing factor graphs and its connection to real stability might lead to a\nbetter understanding of belief propagation and factor graphs in general.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 17:56:15 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Straszak", "Damian", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1708.02638", "submitter": "Milad Makkie", "authors": "Milad Makkie, Xiang Li, Binbin Lin, Jieping Ye, Mojtaba Sedigh Fazli,\n  Tianming Liu, Shannon Quinn", "title": "Distributed rank-1 dictionary learning: Towards fast and scalable\n  solutions for fMRI big data analytics", "comments": "One of the authors name, Mojtaba Sedigh Fazli, has been mistakenly\n  missed from this paper presented at the IEEE Big Data confrence. In result we\n  are submitting this verison to correct the authors' names", "journal-ref": null, "doi": "10.1109/BigData.2016.7841000", "report-no": null, "categories": "cs.DS cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of functional brain imaging for research and diagnosis has benefitted\ngreatly from the recent advancements in neuroimaging technologies, as well as\nthe explosive growth in size and availability of fMRI data. While it has been\nshown in literature that using multiple and large scale fMRI datasets can\nimprove reproducibility and lead to new discoveries, the computational and\ninformatics systems supporting the analysis and visualization of such fMRI big\ndata are extremely limited and largely under-discussed. We propose to address\nthese shortcomings in this work, based on previous success in using dictionary\nlearning method for functional network decomposition studies on fMRI data. We\npresented a distributed dictionary learning framework based on rank-1 matrix\ndecomposition with sparseness constraint (D-r1DL framework). The framework was\nimplemented using the Spark distributed computing engine and deployed on three\ndifferent processing units: an in-house server, in-house high performance\nclusters, and the Amazon Elastic Compute Cloud (EC2) service. The whole\nanalysis pipeline was integrated with our neuroinformatics system for data\nmanagement, user input/output, and real-time visualization. Performance and\naccuracy of D-r1DL on both individual and group-wise fMRI Human Connectome\nProject (HCP) dataset shows that the proposed framework is highly scalable. The\nresulting group-wise functional network decompositions are highly accurate, and\nthe fast processing time confirm this claim. In addition, D-r1DL can provide\nreal-time user feedback and results visualization which are vital for\nlarge-scale data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:11:35 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Makkie", "Milad", ""], ["Li", "Xiang", ""], ["Lin", "Binbin", ""], ["Ye", "Jieping", ""], ["Fazli", "Mojtaba Sedigh", ""], ["Liu", "Tianming", ""], ["Quinn", "Shannon", ""]]}, {"id": "1708.02677", "submitter": "Shai Vardi", "authors": "Shai Vardi", "title": "Randomly coloring graphs of bounded treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling a proper $k$-coloring of a graph of\nmaximal degree $\\Delta$ uniformly at random. We describe a new Markov chain for\nsampling colorings, and show that it mixes rapidly on graphs of bounded\ntreewidth if $k\\geq(1+\\epsilon)\\Delta$, for any $\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 23:38:51 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Vardi", "Shai", ""]]}, {"id": "1708.02728", "submitter": "John Peebles", "authors": "Ilias Diakonikolas, Themis Gouleakis, John Peebles, Eric Price", "title": "Optimal Identity Testing with High Probability", "comments": null, "journal-ref": "ICALP 2018", "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing identity against a given distribution with a\nfocus on the high confidence regime. More precisely, given samples from an\nunknown distribution $p$ over $n$ elements, an explicitly given distribution\n$q$, and parameters $0< \\epsilon, \\delta < 1$, we wish to distinguish, {\\em\nwith probability at least $1-\\delta$}, whether the distributions are identical\nversus $\\varepsilon$-far in total variation distance. Most prior work focused\non the case that $\\delta = \\Omega(1)$, for which the sample complexity of\nidentity testing is known to be $\\Theta(\\sqrt{n}/\\epsilon^2)$. Given such an\nalgorithm, one can achieve arbitrarily small values of $\\delta$ via black-box\namplification, which multiplies the required number of samples by\n$\\Theta(\\log(1/\\delta))$.\n  We show that black-box amplification is suboptimal for any $\\delta = o(1)$,\nand give a new identity tester that achieves the optimal sample complexity. Our\nnew upper and lower bounds show that the optimal sample complexity of identity\ntesting is \\[\n  \\Theta\\left( \\frac{1}{\\epsilon^2}\\left(\\sqrt{n \\log(1/\\delta)} +\n\\log(1/\\delta) \\right)\\right) \\] for any $n, \\varepsilon$, and $\\delta$. For\nthe special case of uniformity testing, where the given distribution is the\nuniform distribution $U_n$ over the domain, our new tester is surprisingly\nsimple: to test whether $p = U_n$ versus $d_{\\mathrm TV}(p, U_n) \\geq\n\\varepsilon$, we simply threshold $d_{\\mathrm TV}(\\widehat{p}, U_n)$, where\n$\\widehat{p}$ is the empirical probability distribution. The fact that this\nsimple \"plug-in\" estimator is sample-optimal is surprising, even in the\nconstant $\\delta$ case. Indeed, it was believed that such a tester would not\nattain sublinear sample complexity even for constant values of $\\varepsilon$\nand $\\delta$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 06:17:30 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 23:23:35 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "1708.02758", "submitter": "Zuzana Majdisova", "authors": "Vaclav Skala, Zuzana Majdisova", "title": "Fast Algorithm for Finding Maximum Distance with Space Subdivision in E2", "comments": null, "journal-ref": "ICIG 2015 Proceedings Part II, China, pp.261-274, Springer, 2015", "doi": "10.1007/978-3-319-21963-9_24", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an exact maximum distance of two points in the given set is a\nfundamental computational problem which is solved in many applications. This\npaper presents a fast, simple to implement and robust algorithm for finding\nthis maximum distance of two points in E2. This algorithm is based on a polar\nsubdivision followed by division of remaining points into uniform grid. The\nmain idea of the algorithm is to eliminate as many input points as possible\nbefore finding the maximum distance. The proposed algorithm gives the\nsignificant speed up compared to the standard algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 08:51:15 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Skala", "Vaclav", ""], ["Majdisova", "Zuzana", ""]]}, {"id": "1708.02769", "submitter": "Zuzana Majdisova", "authors": "Vaclav Skala, Zuzana Majdisova, Michal Smolik", "title": "Space Subdivision to Speed-up Convex Hull Construction in E3", "comments": null, "journal-ref": "Advances in Engineering Software, Vol.91, pp.12-22, ISSN\n  0965-9978, Elsevier, January 2016", "doi": "10.1016/j.advengsoft.2015.09.002", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex hulls are fundamental geometric tools used in a number of algorithms.\nThis paper presents a fast, simple to implement and robust Smart Convex Hull\n(S-CH) algorithm for computing the convex hull of a set of points in E3. This\nalgorithm is based on \"spherical\" space subdivision. The main idea of the S-CH\nalgorithm is to eliminate as many input points as possible before the convex\nhull construction. The experimental results show that only a very small number\nof points are used for the final convex hull calculation. Experiments made also\nproved that the proposed S-CH algorithm achieves a better time complexity in\ncomparison with other algorithms in E3.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 09:23:48 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Skala", "Vaclav", ""], ["Majdisova", "Zuzana", ""], ["Smolik", "Michal", ""]]}, {"id": "1708.02772", "submitter": "Nils Kriege", "authors": "Nils Kriege, Florian Kurpicz, Petra Mutzel", "title": "On Maximum Common Subgraph Problems in Series-Parallel Graphs", "comments": "accepted for publication in the European Journal of Combinatorics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of the maximum common connected subgraph problem in partial\n$k$-trees is still not fully understood. Polynomial-time solutions are known\nfor degree-bounded outerplanar graphs, a subclass of the partial $2$-trees. On\nthe other hand, the problem is known to be ${\\bf NP}$-hard in vertex-labeled\npartial $11$-trees of bounded degree. We consider series-parallel graphs, i.e.,\npartial $2$-trees. We show that the problem remains ${\\bf NP}$-hard in\nbiconnected series-parallel graphs with all but one vertex of degree $3$ or\nless. A positive complexity result is presented for a related problem of high\npractical relevance which asks for a maximum common connected subgraph that\npreserves blocks and bridges of the input graphs. We present a polynomial time\nalgorithm for this problem in series-parallel graphs, which utilizes a\ncombination of BC- and SP-tree data structures to decompose both graphs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 09:45:22 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kriege", "Nils", ""], ["Kurpicz", "Florian", ""], ["Mutzel", "Petra", ""]]}, {"id": "1708.02966", "submitter": "Meena Jagadeesan", "authors": "Meena Jagadeesan", "title": "Simple Analysis of Sparse, Sign-Consistent JL", "comments": "Appeared at RANDOM 2019; this is the full version with some\n  additional appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allen-Zhu, Gelashvili, Micali, and Shavit construct a sparse, sign-consistent\nJohnson-Lindenstrauss distribution, and prove that this distribution yields an\nessentially optimal dimension for the correct choice of sparsity. However,\ntheir analysis of the upper bound on the dimension and sparsity requires a\ncomplicated combinatorial graph-based argument similar to Kane and Nelson's\nanalysis of sparse JL. We present a simple, combinatorics-free analysis of\nsparse, sign-consistent JL that yields the same dimension and sparsity upper\nbounds as the original analysis. Our analysis also yields dimension/sparsity\ntradeoffs, which were not previously known.\n  As with previous proofs in this area, our analysis is based on applying\nMarkov's inequality to the pth moment of an error term that can be expressed as\na quadratic form of Rademacher variables. Interestingly, we show that, unlike\nin previous work in the area, the traditionally used Hanson-Wright bound is not\nstrong enough to yield our desired result. Indeed, although the Hanson-Wright\nbound is known to be optimal for gaussian degree-2 chaos, it was already shown\nto be suboptimal for Rademachers. Surprisingly, we are able to show a simple\nmoment bound for quadratic forms of Rademachers that is sufficiently tight to\nachieve our desired result, which given the ubiquity of moment and tail bounds\nin theoretical computer science, is likely to be of broader interest.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 18:32:42 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 02:57:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Jagadeesan", "Meena", ""]]}, {"id": "1708.03081", "submitter": "Kshitij Gajjar", "authors": "Kshitij Gajjar and Jaikumar Radhakrishnan", "title": "Distance-preserving Subgraphs of Interval Graphs", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding small distance-preserving subgraphs of\nundirected, unweighted interval graphs with $k$ terminal vertices.\n  To start with, we show that finding an optimal distance-preserving subgraph\nis $\\mathsf{NP}$-hard for general graphs. Then, we show that every interval\ngraph admits a subgraph with $O(k)$ branching vertices that approximates\npairwise terminal distances up to an additive term of $+1$. We also present an\ninterval graph $G_{\\mathrm{int}}$ for which the $+1$ approximation is necessary\nto obtain the $O(k)$ upper bound on the number of branching vertices. In\nparticular, any distance-preserving subgraph of $G_{\\mathrm{int}}$ has\n$\\Omega(k\\log k)$ branching vertices. Furthermore, we prove that every interval\ngraph admits a distance-preserving subgraph with $O(k\\log k)$ branching\nvertices, implying that the $\\Omega(k\\log k)$ lower bound for interval graphs\nis tight. To conclude, we show that there exists an interval graph such that\nevery optimal distance-preserving subgraph of it has $O(k)$ branching vertices\nand $\\Omega(k\\log k)$ branching edges, thereby providing a separation between\nbranching vertices and branching edges.\n  The $O(k)$ bound for distance-approximating subgraphs follows from a na\\\"ive\nanalysis of shortest paths in interval graphs. $G_{\\mathrm{int}}$ is\nconstructed using bit-reversal permutation matrices. The $O(k\\log k)$ bound for\ndistance-preserving subgraphs uses a divide-and-conquer approach. Finally, the\nseparation between branching vertices and branching edges employs Hansel's\nlemma for graph covering.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 05:53:02 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 13:36:41 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Gajjar", "Kshitij", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "1708.03228", "submitter": "Leah Epstein", "authors": "J\\'anos Balogh, J\\'ozsef B\\'ek\\'esi, Gy\\\"orgy D\\'osa, Leah Epstein,\n  Asaf Levin", "title": "Lower bounds for several online variants of bin packing", "comments": "WAOA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several previously studied online variants of bin packing and\nprove new and improved lower bounds on the asymptotic competitive ratios for\nthem. For that, we use a method of fully adaptive constructions. In particular,\nwe improve the lower bound for the asymptotic competitive ratio of online\nsquare packing significantly, raising it from roughly 1.68 to above 1.75.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 14:13:45 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Balogh", "J\u00e1nos", ""], ["B\u00e9k\u00e9si", "J\u00f3zsef", ""], ["D\u00f3sa", "Gy\u00f6rgy", ""], ["Epstein", "Leah", ""], ["Levin", "Asaf", ""]]}, {"id": "1708.03252", "submitter": "Maciej Drwal", "authors": "Maciej Drwal", "title": "Robust scheduling to minimize the weighted number of late jobs with\n  interval due-date uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of single machine scheduling problems with the\nobjective to minimize the weighted number of late jobs, under the assumption\nthat completion due-dates are not known precisely at the time when\ndecision-maker must provide a schedule. It is assumed that only the intervals\nto which the due-dates belong are known. The concept of maximum regret is used\nto define robust solution. A polynomial time algorithm is given for the case\nwhen weights of jobs are all equal. A mixed-integer linear programming\nformulation is provided for the general case, and computational experiments are\nreported.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 21:34:45 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Drwal", "Maciej", ""]]}, {"id": "1708.03257", "submitter": "Sushrut Karmalkar", "authors": "Daniel Kane, Sushrut Karmalkar, Eric Price", "title": "Robust polynomial regression up to the information theoretic limit", "comments": "19 Pages. To appear in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust polynomial regression, where one receives\nsamples $(x_i, y_i)$ that are usually within $\\sigma$ of a polynomial $y =\np(x)$, but have a $\\rho$ chance of being arbitrary adversarial outliers.\nPreviously, it was known how to efficiently estimate $p$ only when $\\rho <\n\\frac{1}{\\log d}$. We give an algorithm that works for the entire feasible\nrange of $\\rho < 1/2$, while simultaneously improving other parameters of the\nproblem. We complement our algorithm, which gives a factor 2 approximation,\nwith impossibility results that show, for example, that a $1.09$ approximation\nis impossible even with infinitely many samples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:31:02 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Kane", "Daniel", ""], ["Karmalkar", "Sushrut", ""], ["Price", "Eric", ""]]}, {"id": "1708.03314", "submitter": "Alexander Bauer", "authors": "Alexander Bauer, Shinichi Nakajima, Nico G\\\"ornitz, Klaus-Robert\n  M\\\"uller", "title": "Partial Optimality of Dual Decomposition for MAP Inference in Pairwise\n  MRFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov random fields (MRFs) are a powerful tool for modelling statistical\ndependencies for a set of random variables using a graphical representation. An\nimportant computational problem related to MRFs, called maximum a posteriori\n(MAP) inference, is finding a joint variable assignment with the maximal\nprobability. It is well known that the two popular optimisation techniques for\nthis task, linear programming (LP) relaxation and dual decomposition (DD), have\na strong connection both providing an optimal solution to the MAP problem when\na corresponding LP relaxation is tight. However, less is known about their\nrelationship in the opposite and more realistic case. In this paper, we explain\nhow the fully integral assignments obtained via DD partially agree with the\noptimal fractional assignments via LP relaxation when the latter is not tight.\nIn particular, for binary pairwise MRFs the corresponding result suggests that\nboth methods share the partial optimality property of their solutions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 06:32:20 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Bauer", "Alexander", ""], ["Nakajima", "Shinichi", ""], ["G\u00f6rnitz", "Nico", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1708.03429", "submitter": "Samson Zhou", "authors": "Venkata Gandikota, Elena Grigorescu, Sidharth Jaggi, Samson Zhou", "title": "Nearly Optimal Sparse Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group testing is the process of pooling arbitrary subsets from a set of $n$\nitems so as to identify, with a minimal number of tests, a \"small\" subset of\n$d$ defective items. In \"classical\" non-adaptive group testing, it is known\nthat when $d$ is substantially smaller than $n$, $\\Theta(d\\log(n))$ tests are\nboth information-theoretically necessary and sufficient to guarantee recovery\nwith high probability. Group testing schemes in the literature meeting this\nbound require most items to be tested $\\Omega(\\log(n))$ times, and most tests\nto incorporate $\\Omega(n/d)$ items.\n  Motivated by physical considerations, we study group testing models in which\nthe testing procedure is constrained to be \"sparse\". Specifically, we consider\n(separately) scenarios in which (a) items are finitely divisible and hence may\nparticipate in at most $\\gamma \\in o(\\log(n))$ tests; or (b) tests are\nsize-constrained to pool no more than $\\rho \\in o(n/d)$items per test. For both\nscenarios we provide information-theoretic lower bounds on the number of tests\nrequired to guarantee high probability recovery. In both scenarios we provide\nboth randomized constructions (under both $\\epsilon$-error and zero-error\nreconstruction guarantees) and explicit constructions of designs with\ncomputationally efficient reconstruction algorithms that require a number of\ntests that are optimal up to constant or small polynomial factors in some\nregimes of $n, d, \\gamma,$ and $\\rho$. The randomized design/reconstruction\nalgorithm in the $\\rho$-sized test scenario is universal -- independent of the\nvalue of $d$, as long as $\\rho \\in o(n/d)$. We also investigate the effect of\nunreliability/noise in test outcomes. For the full abstract, please see the\nfull text PDF.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 04:47:09 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 00:14:43 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Gandikota", "Venkata", ""], ["Grigorescu", "Elena", ""], ["Jaggi", "Sidharth", ""], ["Zhou", "Samson", ""]]}, {"id": "1708.03439", "submitter": "Ali Narimani", "authors": "Ali Narimani, Seyed Saeed Changiz Rezaei, Arman Zaribafiyan", "title": "Combinatorial Optimization by Decomposition on Hybrid CPU--non-CPU\n  Solver Architectures", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of new special-purpose hardware such as FPGA or ASIC-based\nannealers and quantum processors has shown potential in solving certain\nfamilies of complex combinatorial optimization problems more efficiently than\nconventional CPUs. We show that to address an industrial optimization problem,\na hybrid architecture of CPUs and non-CPU devices is inevitable. In this paper,\nwe propose problem decomposition as an effective method for designing a hybrid\nCPU--non-CPU optimization solver. We introduce the required algorithmic\nelements for making problem decomposition a viable approach in meeting the\nreal-world constraints such as communication time and the potential higher cost\nof using non-CPU hardware. We then turn to the well-known maximum clique\nproblem, and propose a new method of decomposition for this problem. Our method\nenables us to solve the maximum clique problem on very large graphs using\nnon-CPU hardware that is considerably smaller than the size of the graph. As an\nexample, we show that the maximum clique problem on the com-Amazon graph, with\n334,863 vertices and 925,872 edges, can be solved with a single call to a\ndevice that can embed a fully connected graph of size at least 21 nodes, such\nas the D-Wave 2000Q. We also show that our proposed problem decomposition\napproach can improve the runtime of two of the best-known classical algorithms\nfor large, sparse graphs, namely PMC and BBMCSP, by orders of magnitude. In the\nlight of our study, we believe that new non-CPU hardware that is small in size\ncould become competitive with CPUs if it could be either mass produced and\nhighly parallelized, or able to provide high-quality solutions to specific,\nsmall-sized problems significantly faster than CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 05:42:14 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 01:04:28 GMT"}, {"version": "v3", "created": "Sat, 16 Sep 2017 01:36:54 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Narimani", "Ali", ""], ["Rezaei", "Seyed Saeed Changiz", ""], ["Zaribafiyan", "Arman", ""]]}, {"id": "1708.03495", "submitter": "Youming Qiao", "authors": "G\\'abor Ivanyos, Youming Qiao", "title": "Algorithms based on *-algebras, and their applications to isomorphism of\n  polynomials with one secret, group isomorphism, and polynomial identity\n  testing", "comments": "41 pages; improved presentation; accepted to SICOMP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two basic algorithmic problems concerning tuples of\n(skew-)symmetric matrices. The first problem asks to decide, given two tuples\nof (skew-)symmetric matrices $(B_1, \\dots, B_m)$ and $(C_1, \\dots, C_m)$,\nwhether there exists an invertible matrix $A$ such that for every $i\\in\\{1,\n\\dots, m\\}$, $A^tB_iA=C_i$. We show that this problem can be solved in\nrandomized polynomial time over finite fields of odd size, the real field, and\nthe complex field. The second problem asks to decide, given a tuple of square\nmatrices $(B_1, \\dots, B_m)$, whether there exist invertible matrices $A$ and\n$D$, such that for every $i\\in\\{1, \\dots, m\\}$, $AB_iD$ is (skew-)symmetric. We\nshow that this problem can be solved in deterministic polynomial time over\nfields of characteristic not $2$. For both problems we exploit the structure of\nthe underlying $*$-algebras, and utilize results and methods from the module\nisomorphism problem.\n  Applications of our results range from multivariate cryptography, group\nisomorphism, to polynomial identity testing. Specifically, these results imply\nefficient algorithms for the following problems. (1) Test isomorphism of\nquadratic forms with one secret over a finite field of odd size. This problem\nbelongs to a family of problems that serves as the security basis of certain\nauthentication schemes proposed by Patarin (Eurocrypto 1996). (2) Test\nisomorphism of $p$-groups of class 2 and exponent $p$ ($p$ odd) with order\n$p^k$ in time polynomial in the group order, when the commutator subgroup is of\norder $p^{O(\\sqrt{k})}$. (3) Deterministically reveal two families of\nsingularity witnesses caused by the skew-symmetric structure, which represents\na natural next step for the polynomial identity testing problem following the\ndirection set up by the recent resolution of the non-commutative rank problem\n(Garg et al., FOCS 2016; Ivanyos et al., ITCS 2017).\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 10:03:03 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 10:28:06 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 22:53:07 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Ivanyos", "G\u00e1bor", ""], ["Qiao", "Youming", ""]]}, {"id": "1708.03496", "submitter": "Shuliang Xu", "authors": "Junhong Wang, Shuliang Xu, Bingqian Duan, Caifeng Liu, Jiye Liang", "title": "An Ensemble Classification Algorithm Based on Information Entropy for\n  Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data stream mining problem has caused widely concerns in the area of machine\nlearning and data mining. In some recent studies, ensemble classification has\nbeen widely used in concept drift detection, however, most of them regard\nclassification accuracy as a criterion for judging whether concept drift\nhappening or not. Information entropy is an important and effective method for\nmeasuring uncertainty. Based on the information entropy theory, a new algorithm\nusing information entropy to evaluate a classification result is developed. It\nuses ensemble classification techniques, and the weight of each classifier is\ndecided through the entropy of the result produced by an ensemble classifiers\nsystem. When the concept in data streams changing, the classifiers' weight\nbelow a threshold value will be abandoned to adapt to a new concept in one\ntime. In the experimental analysis section, six databases and four proposed\nalgorithms are executed. The results show that the proposed method can not only\nhandle concept drift effectively, but also have a better classification\naccuracy and time performance than the contrastive algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 10:04:47 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Wang", "Junhong", ""], ["Xu", "Shuliang", ""], ["Duan", "Bingqian", ""], ["Liu", "Caifeng", ""], ["Liang", "Jiye", ""]]}, {"id": "1708.03515", "submitter": "Jesper Nederlof", "authors": "Nikhil Bansal, Parinya Chalermsook, Bundit Laekhanukit, Danupon\n  Nanongkai, Jesper Nederlof", "title": "New Tools and Connections for Exponential-time Approximation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop new tools and connections for exponential time\napproximation. In this setting, we are given a problem instance and a parameter\n$\\alpha>1$, and the goal is to design an $\\alpha$-approximation algorithm with\nthe fastest possible running time. We show the following results:\n  - An $r$-approximation for maximum independent set in $O^*(\\exp(\\tilde O(n/r\n\\log^2 r+r\\log^2r)))$ time,\n  - An $r$-approximation for chromatic number in $O^*(\\exp(\\tilde{O}(n/r \\log\nr+r\\log^2r)))$ time,\n  - A $(2-1/r)$-approximation for minimum vertex cover in\n$O^*(\\exp(n/r^{\\Omega(r)}))$ time, and\n  - A $(k-1/r)$-approximation for minimum $k$-hypergraph vertex cover in\n$O^*(\\exp(n/(kr)^{\\Omega(kr)}))$ time.\n  (Throughout, $\\tilde O$ and $O^*$ omit $\\mathrm{polyloglog}(r)$ and factors\npolynomial in the input size, respectively.) The best known time bounds for all\nproblems were $O^*(2^{n/r})$ [Bourgeois et al. 2009, 2011 & Cygan et al. 2008].\nFor maximum independent set and chromatic number, these bounds were\ncomplemented by $\\exp(n^{1-o(1)}/r^{1+o(1)})$ lower bounds (under the\nExponential Time Hypothesis (ETH)) [Chalermsook et al., 2013 & Laekhanukit,\n2014 (Ph.D. Thesis)]. Our results show that the naturally-looking\n$O^*(2^{n/r})$ bounds are not tight for all these problems. The key to these\nalgorithmic results is a sparsification procedure, allowing the use of better\napproximation algorithms for bounded degree graphs. For obtaining the first two\nresults, we introduce a new randomized branching rule.\n  Finally, we show a connection between PCP parameters and exponential-time\napproximation algorithms. This connection together with our independent set\nalgorithm refute the possibility to overly reduce the size of Chan's PCP [Chan,\n2016]. It also implies that a (significant) improvement over our result will\nrefute the gap-ETH conjecture [Dinur 2016 & Manurangsi and Raghavendra, 2016].\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 12:16:47 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Bansal", "Nikhil", ""], ["Chalermsook", "Parinya", ""], ["Laekhanukit", "Bundit", ""], ["Nanongkai", "Danupon", ""], ["Nederlof", "Jesper", ""]]}, {"id": "1708.03684", "submitter": "Giacomo Nannicini", "authors": "Giacomo Nannicini", "title": "An Introduction to Quantum Computing, Without the Physics", "comments": "v5 simplifies a proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a gentle but rigorous introduction to quantum computing\nintended for discrete mathematicians. Starting from a small set of assumptions\non the behavior of quantum computing devices, we analyze their main\ncharacteristics, stressing the differences with classical computers, and\nfinally describe two well-known algorithms (Simon's algorithm and Grover's\nalgorithm) using the formalism developed in previous sections. This paper does\nnot touch on the physics of the devices, and therefore does not require any\nnotion of quantum mechanics. Numerical examples on an implementation of\nGrover's algorithm using open-source software are provided.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 19:52:47 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 03:20:00 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 14:51:08 GMT"}, {"version": "v4", "created": "Mon, 19 Nov 2018 16:08:57 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 13:15:49 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Nannicini", "Giacomo", ""]]}, {"id": "1708.03708", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Adam Klivans", "title": "Eigenvalue Decay Implies Polynomial-Time Learnability for Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning function classes computed by neural\nnetworks with various activations (e.g. ReLU or Sigmoid), a task believed to be\ncomputationally intractable in the worst-case. A major open problem is to\nunderstand the minimal assumptions under which these classes admit provably\nefficient algorithms. In this work we show that a natural distributional\nassumption corresponding to {\\em eigenvalue decay} of the Gram matrix yields\npolynomial-time algorithms in the non-realizable setting for expressive classes\nof networks (e.g. feed-forward networks of ReLUs). We make no assumptions on\nthe structure of the network or the labels. Given sufficiently-strong\npolynomial eigenvalue decay, we obtain {\\em fully}-polynomial time algorithms\nin {\\em all} the relevant parameters with respect to square-loss. Milder decay\nassumptions also lead to improved algorithms. This is the first purely\ndistributional assumption that leads to polynomial-time algorithms for networks\nof ReLUs, even with one hidden layer. Further, unlike prior distributional\nassumptions (e.g., the marginal distribution is Gaussian), eigenvalue decay has\nbeen observed in practice on common data sets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 21:26:05 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Goel", "Surbhi", ""], ["Klivans", "Adam", ""]]}, {"id": "1708.03812", "submitter": "Bryce Sandlund", "authors": "Richard Peng, Bryce Sandlund, Daniel D. Sleator", "title": "Optimal Offline Dynamic $2,3$-Edge/Vertex Connectivity", "comments": "Revised version of a WADS '13 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give offline algorithms for processing a sequence of $2$ and $3$ edge and\nvertex connectivity queries in a fully-dynamic undirected graph. While the\ncurrent best fully-dynamic online data structures for $3$-edge and $3$-vertex\nconnectivity require $O(n^{2/3})$ and $O(n)$ time per update, respectively, our\nper-operation cost is only $O(\\log n)$, optimal due to the dynamic connectivity\nlower bound of Patrascu and Demaine. Our approach utilizes a divide and conquer\nscheme that transforms a graph into smaller equivalents that preserve\nconnectivity information. This construction of equivalents is closely-related\nto the development of vertex sparsifiers, and shares important connections to\nseveral upcoming results in dynamic graph data structures, outside of just the\noffline model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 19:20:23 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 01:01:38 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Peng", "Richard", ""], ["Sandlund", "Bryce", ""], ["Sleator", "Daniel D.", ""]]}, {"id": "1708.03835", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Wilko Schwarting", "title": "Training Support Vector Machines using Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel coreset construction algorithm for solving classification\ntasks using Support Vector Machines (SVMs) in a computationally efficient\nmanner. A coreset is a weighted subset of the original data points that\nprovably approximates the original set. We show that coresets of size\npolylogarithmic in $n$ and polynomial in $d$ exist for a set of $n$ input\npoints with $d$ features and present an $(\\epsilon,\\delta)$-FPRAS for\nconstructing coresets for scalable SVM training. Our method leverages the\ninsight that data points are often redundant and uses an importance sampling\nscheme based on the sensitivity of each data point to construct coresets\nefficiently. We evaluate the performance of our algorithm in accelerating SVM\ntraining against real-world data sets and compare our algorithm to\nstate-of-the-art coreset approaches. Our empirical results show that our\napproach outperforms a state-of-the-art coreset approach and uniform sampling\nin enabling computational speedups while achieving low approximation error.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 01:02:07 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 04:01:46 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Schwarting", "Wilko", ""]]}, {"id": "1708.03853", "submitter": "Vinod Reddy", "authors": "Neeldhara Misra and I. Vinod Reddy", "title": "The Parameterized Complexity of Happy Colorings", "comments": "16 pages, appears in IWOCA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider a graph $G = (V,E)$ and a coloring $c$ of vertices with colors from\n$[\\ell]$. A vertex $v$ is said to be happy with respect to $c$ if $c(v) = c(u)$\nfor all neighbors $u$ of $v$. Further, an edge $(u,v)$ is happy if $c(u) =\nc(v)$. Given a partial coloring $c$ of $V$, the Maximum Happy Vertex (Edge)\nproblem asks for a total coloring of $V$ extending $c$ to all vertices of $V$\nthat maximises the number of happy vertices (edges). Both problems are known to\nbe NP-hard in general even when $\\ell = 3$, and is polynomially solvable when\n$\\ell = 2$. In [IWOCA 2016] it was shown that both problems are polynomially\nsolvable on trees, and for arbitrary $k$, it was shown that MHE is \\NPH{} on\nplanar graphs and is \\FPT{} parameterized by the number of precolored vertices\nand branchwidth.\n  We continue the study of this problem from a parameterized prespective. Our\nfocus is on both structural and standard parameterizations. To begin with, we\nestablish that the problems are \\FPT{} when parameterized by the treewidth and\nthe number of colors used in the precoloring, which is a potential improvement\nover the total number of precolored vertices. Further, we show that both the\nvertex and edge variants of the problem is \\FPT{} when parameterized by vertex\ncover and distance-to-clique parameters. We also show that the problem of\nmaximizing the number of happy edges is \\FPT{} when parameterized by the\nstandard parameter, the number of happy edges. We show that the maximum happy\nvertex (edge) problem is \\NPH{} on split graphs and bipartite graphs and\npolynomially solvable on cographs.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 04:52:27 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Misra", "Neeldhara", ""], ["Reddy", "I. Vinod", ""]]}, {"id": "1708.03903", "submitter": "Danupon Nanongkai", "authors": "Chien-Chung Huang, Danupon Nanongkai, Thatchaphol Saranurak", "title": "Distributed Exact Weighted All-Pairs Shortest Paths in $\\tilde\n  O(n^{5/4})$ Rounds", "comments": "Minor corrections in Section 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computing {\\em all-pairs shortest paths} (APSP) on distributed\nnetworks (the CONGEST model). The goal is for every node in the (weighted)\nnetwork to know the distance from every other node using communication. The\nproblem admits $(1+o(1))$-approximation $\\tilde O(n)$-time algorithms\n~\\cite{LenzenP-podc15,Nanongkai-STOC14}, which are matched with $\\tilde\n\\Omega(n)$-time lower\nbounds~\\cite{Nanongkai-STOC14,LenzenP_stoc13,FrischknechtHW12}\\footnote{$\\tilde\n\\Theta$, $\\tilde O$ and $\\tilde \\Omega$ hide polylogarithmic factors. Note that\nthe lower bounds also hold even in the unweighted case and in the weighted case\nwith polynomial approximation ratios.}. No $\\omega(n)$ lower bound or $o(m)$\nupper bound were known for exact computation.\n  In this paper, we present an $\\tilde O(n^{5/4})$-time randomized (Las Vegas)\nalgorithm for exact weighted APSP; this provides the first improvement over the\nnaive $O(m)$-time algorithm when the network is not so sparse. Our result also\nholds for the case where edge weights are {\\em asymmetric} (a.k.a. the directed\ncase where communication is bidirectional). Our techniques also yield an\n$\\tilde O(n^{3/4}k^{1/2}+n)$-time algorithm for the {\\em $k$-source shortest\npaths} problem where we want every node to know distances from $k$ sources;\nthis improves Elkin's recent bound~\\cite{Elkin-STOC17} when $k=\\tilde\n\\omega(n^{1/4})$.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 13:27:47 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 09:50:24 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Huang", "Chien-Chung", ""], ["Nanongkai", "Danupon", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "1708.03962", "submitter": "Thatchaphol Saranurak", "authors": "Danupon Nanongkai, Thatchaphol Saranurak and Christian Wulff-Nilsen", "title": "Dynamic Minimum Spanning Forest with Subpolynomial Worst-case Update\n  Time", "comments": "Open problems added. To appear at FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Las Vegas algorithm for dynamically maintaining a minimum\nspanning forest of an $n$-node graph undergoing edge insertions and deletions.\nOur algorithm guarantees an $O(n^{o(1)})$ worst-case update time with high\nprobability. This significantly improves the two recent Las Vegas algorithms by\nWulff-Nilsen [STOC'17] with update time $O(n^{0.5-\\epsilon})$ for some constant\n$\\epsilon>0$ and, independently, by Nanongkai and Saranurak [STOC'17] with\nupdate time $O(n^{0.494})$ (the latter works only for maintaining a spanning\nforest).\n  Our result is obtained by identifying the common framework that both two\nprevious algorithms rely on, and then improve and combine the ideas from both\nworks. There are two main algorithmic components of the framework that are\nnewly improved and critical for obtaining our result. First, we improve the\nupdate time from $O(n^{0.5-\\epsilon})$ in Wulff-Nilsen [STOC'17] to\n$O(n^{o(1)})$ for decrementally removing all low-conductance cuts in an\nexpander undergoing edge deletions. Second, by revisiting the \"contraction\ntechnique\" by Henzinger and King [1997] and Holm et al. [STOC'98], we show a\nnew approach for maintaining a minimum spanning forest in connected graphs with\nvery few (at most $(1+o(1))n$) edges. This significantly improves the previous\napproach in [Wulff-Nilsen STOC'17] and [Nanongkai and Saranurak STOC'17] which\nis based on Frederickson's 2-dimensional topology tree and illustrates a new\napplication to this old technique.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 19:59:20 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 14:48:09 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Nanongkai", "Danupon", ""], ["Saranurak", "Thatchaphol", ""], ["Wulff-Nilsen", "Christian", ""]]}, {"id": "1708.04073", "submitter": "Arnold Filtser", "authors": "Ittai Abraham, Arnold Filtser, Anupam Gupta, Ofer Neiman", "title": "Metric Embedding via Shortest Path Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of embedding shortest-path metrics of weighted graphs\ninto $\\ell_p$ spaces. We introduce a new embedding technique based on low-depth\ndecompositions of a graph via shortest paths. The notion of Shortest Path\nDecomposition depth is inductively defined: A (weighed) path graph has shortest\npath decomposition (SPD) depth $1$. General graph has an SPD of depth $k$ if it\ncontains a shortest path whose deletion leads to a graph, each of whose\ncomponents has SPD depth at most $k-1$. In this paper we give an\n$O(k^{\\min\\{\\frac{1}{p},\\frac{1}{2}\\}})$-distortion embedding for graphs of SPD\ndepth at most $k$. This result is asymptotically tight for any fixed $p>1$,\nwhile for $p=1$ it is tight up to second order terms.\n  As a corollary of this result, we show that graphs having pathwidth $k$ embed\ninto $\\ell_p$ with distortion $O(k^{\\min\\{\\frac{1}{p},\\frac{1}{2}\\}})$. For\n$p=1$, this improves over the best previous bound of Lee and Sidiropoulos that\nwas exponential in $k$; moreover, for other values of $p$ it gives the first\nembeddings whose distortion is independent of the graph size $n$. Furthermore,\nwe use the fact that planar graphs have SPD depth $O(\\log n)$ to give a new\nproof that any planar graph embeds into $\\ell_1$ with distortion $O(\\sqrt{\\log\nn})$. Our approach also gives new results for graphs with bounded treewidth,\nand for graphs excluding a fixed minor.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 10:59:30 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:21:15 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Abraham", "Ittai", ""], ["Filtser", "Arnold", ""], ["Gupta", "Anupam", ""], ["Neiman", "Ofer", ""]]}, {"id": "1708.04109", "submitter": "Kitty Meeks", "authors": "Kitty Meeks and Baharak Rastegari", "title": "Solving Hard Stable Matching Problems Involving Groups of Similar Agents", "comments": "Results on SMTI appear in proceedings of WINE 2018; Section 6\n  contains work in progress", "journal-ref": null, "doi": "10.1007/978-3-030-04612-5_21", "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.MA math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important stable matching problems are known to be NP-hard, even when\nstrong restrictions are placed on the input. In this paper we seek to identify\nstructural properties of instances of stable matching problems which will allow\nus to design efficient algorithms using elementary techniques. We focus on the\nsetting in which all agents involved in some matching problem can be\npartitioned into k different types, where the type of an agent determines his\nor her preferences, and agents have preferences over types (which may be\nrefined by more detailed preferences within a single type). This situation\nwould arise in practice if agents form preferences solely based on some small\ncollection of agents' attributes. We also consider a generalisation in which\neach agent may consider some small collection of other agents to be\nexceptional, and rank these in a way that is not consistent with their types;\nthis could happen in practice if agents have prior contact with a small number\nof candidates. We show that (for the case without exceptions), several\nwell-studied NP-hard stable matching problems including Max SMTI (that of\nfinding the maximum cardinality stable matching in an instance of stable\nmarriage with ties and incomplete lists) belong to the parameterised complexity\nclass FPT when parameterised by the number of different types of agents needed\nto describe the instance. For Max SMTI this tractability result can be extended\nto the setting in which each agent promotes at most one `exceptional' candidate\nto the top of his/her list (when preferences within types are not refined), but\nthe problem remains NP-hard if preference lists can contain two or more\nexceptions and the exceptional candidates can be placed anywhere in the\npreference lists, even if the number of types is bounded by a constant.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 13:15:19 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 14:56:55 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Meeks", "Kitty", ""], ["Rastegari", "Baharak", ""]]}, {"id": "1708.04127", "submitter": "Abdolmajid Yolmeh", "authors": "Abdolmajid Yolmeh, Najmeh Salehi", "title": "A branch, price and remember algorithm for the U shaped assembly line\n  balancing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a branch, price and remember algorithm to solve the\nU shaped assembly line balancing problem. Our proposed algorithm uses a column\ngeneration approach to obtain tight lower bounds for this problem. It also\nstores generated columns in memory to enhance the speed of column generation\napproach. We also develop a modification of Hoffman algorithm to obtain high\nquality upper bounds. Our computational results show that our proposed\nalgorithm is able to optimally solve 255 of Scholl's well-known 269 benchmark\nproblems. Previous best known exact algorithm, ULINO, is able to solve 233 of\nthe 269 benchmark problems. We also examined our algorithm on a new data set\nand the results show that our algorithm is able to solve 96.48 percent of all\navailable benchmark problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 14:08:46 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 01:07:54 GMT"}, {"version": "v3", "created": "Sat, 2 Sep 2017 21:03:18 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Yolmeh", "Abdolmajid", ""], ["Salehi", "Najmeh", ""]]}, {"id": "1708.04215", "submitter": "L\\'aszl\\'o V\\'egh", "authors": "Ola Svensson, Jakub Tarnawski, L\\'aszl\\'o A. V\\'egh", "title": "A Constant-Factor Approximation Algorithm for the Asymmetric Traveling\n  Salesman Problem", "comments": "This is an extended version of the paper also incorporating the\n  results of the paper arxiv:1502.02051", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a constant-factor approximation algorithm for the asymmetric\ntraveling salesman problem (ATSP). Our approximation guarantee is analyzed with\nrespect to the standard LP relaxation, and thus our result confirms the\nconjectured constant integrality gap of that relaxation.\n  The main idea of our approach is a reduction to Subtour Partition Cover, an\neasier problem obtained by significantly relaxing the general connectivity\nrequirements into local connectivity conditions. We first show that any\nalgorithm for Subtour Partition Cover can be turned into an algorithm for ATSP\nwhile only losing a small constant factor in the performance guarantee. Next,\nwe present a reduction from general ATSP instances to structured instances, on\nwhich we then solve Subtour Partition Cover, yielding our constant-factor\napproximation algorithm for ATSP.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 17:21:05 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 14:55:12 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 10:20:12 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 20:57:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Svensson", "Ola", ""], ["Tarnawski", "Jakub", ""], ["V\u00e9gh", "L\u00e1szl\u00f3 A.", ""]]}, {"id": "1708.04290", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang, Qizheng He, Wenzheng Li, Seth Pettie, Jara Uitto", "title": "The Complexity of Distributed Edge Coloring with Small Palettes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of distributed edge coloring depends heavily on the palette\nsize as a function of the maximum degree $\\Delta$. In this paper we explore the\ncomplexity of edge coloring in the LOCAL model in different palette size\nregimes.\n  1. We simplify the \\emph{round elimination} technique of Brandt et al. and\nprove that $(2\\Delta-2)$-edge coloring requires $\\Omega(\\log_\\Delta \\log n)$\ntime w.h.p. and $\\Omega(\\log_\\Delta n)$ time deterministically, even on trees.\nThe simplified technique is based on two ideas: the notion of an irregular\nrunning time and some general observations that transform weak lower bounds\ninto stronger ones.\n  2. We give a randomized edge coloring algorithm that can use palette sizes as\nsmall as $\\Delta + \\tilde{O}(\\sqrt{\\Delta})$, which is a natural barrier for\nrandomized approaches. The running time of the algorithm is at most\n$O(\\log\\Delta \\cdot T_{LLL})$, where $T_{LLL}$ is the complexity of a\npermissive version of the constructive Lovasz local lemma.\n  3. We develop a new distributed Lovasz local lemma algorithm for\ntree-structured dependency graphs, which leads to a $(1+\\epsilon)\\Delta$-edge\ncoloring algorithm for trees running in $O(\\log\\log n)$ time. This algorithm\narises from two new results: a deterministic $O(\\log n)$-time LLL algorithm for\ntree-structured instances, and a randomized $O(\\log\\log n)$-time graph\nshattering method for breaking the dependency graph into independent $O(\\log\nn)$-size LLL instances.\n  4. A natural approach to computing $(\\Delta+1)$-edge colorings (Vizing's\ntheorem) is to extend partial colorings by iteratively re-coloring parts of the\ngraph. We prove that this approach may be viable, but in the worst case\nrequires recoloring subgraphs of diameter $\\Omega(\\Delta\\log n)$. This stands\nin contrast to distributed algorithms for Brooks' theorem, which exploit the\nexistence of $O(\\log_\\Delta n)$-length augmenting paths.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 19:47:53 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 03:34:02 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Chang", "Yi-Jun", ""], ["He", "Qizheng", ""], ["Li", "Wenzheng", ""], ["Pettie", "Seth", ""], ["Uitto", "Jara", ""]]}, {"id": "1708.04341", "submitter": "Wayne Hayes", "authors": "Adib Hassan, Po-Chien Chung, Wayne B. Hayes", "title": "Graphettes: Constant-time determination of graphlet and orbit identity\n  including (possibly disconnected) graphlets up to size 8", "comments": "13 pages, 4 figures, 2 tables. Accepted to PLOS ONE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphlets are small connected induced subgraphs of a larger graph $G$.\nGraphlets are now commonly used to quantify local and global topology of\nnetworks in the field. Methods exist to exhaustively enumerate all graphlets\n(and their orbits) in large networks as efficiently as possible using orbit\ncounting equations. However, the number of graphlets in $G$ is exponential in\nboth the number of nodes and edges in $G$. Enumerating them all is already\nunacceptably expensive on existing large networks, and the problem will only\nget worse as networks continue to grow in size and density. Here we introduce\nan efficient method designed to aid statistical sampling of graphlets up to\nsize $k=8$ from a large network. We define graphettes as the generalization of\ngraphlets allowing for disconnected graphlets. Given a particular (undirected)\ngraphette $g$, we introduce the idea of the canonical graphette $\\mathcal K(g)$\nas a representative member of the isomorphism group $Iso(g)$ of $g$. We compute\nthe mapping $\\mathcal K$, in the form of a lookup table, from all\n$2^{k(k-1)/2}$ undirected graphettes $g$ of size $k\\le 8$ to their canonical\nrepresentatives $\\mathcal K(g)$, as well as the permutation that transforms $g$\nto $\\mathcal K(g)$. We also compute all automorphism orbits for each canonical\ngraphette. Thus, given any $k\\le 8$ nodes in a graph $G$, we can in constant\ntime infer which graphette it is, as well as which orbit each of the $k$ nodes\nbelongs to. Sampling a large number $N$ of such $k$-sets of nodes provides an\napproximation of both the distribution of graphlets and orbits across $G$, and\nthe orbit degree vector at each node.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 22:06:44 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Hassan", "Adib", ""], ["Chung", "Po-Chien", ""], ["Hayes", "Wayne B.", ""]]}, {"id": "1708.04369", "submitter": "Shashwat Garg", "authors": "Shashwat Garg", "title": "Quasi-PTAS for Scheduling with Precedences using LP Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in scheduling is to schedule $n$ unit size jobs with\nprecedence constraints on $m$ identical machines so as to minimize the\nmakespan. For $m=3$, it is not even known if the problem is NP-hard and this is\none of the last open problems from the book of Garey and Johnson.\n  We show that for fixed $m$ and $\\epsilon$, $(\\log n)^{O(1)}$ rounds of\nSherali-Adams hierarchy applied to a natural LP of the problem provides a\n$(1+\\epsilon)$-approximation algorithm running in quasi-polynomial time. This\nimproves over the recent result of Levey and Rothvoss, who used $r=(\\log\nn)^{O(\\log \\log n)}$ rounds of Sherali-Adams in order to get a\n$(1+\\epsilon)$-approximation algorithm with a running time of $n^{O(r)}$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 00:52:30 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Garg", "Shashwat", ""]]}, {"id": "1708.04381", "submitter": "Samson Zhou", "authors": "Funda Erg\\\"un, Elena Grigorescu, Erfan Sadeqi Azer, Samson Zhou", "title": "Streaming Periodicity with Mismatches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding all $k$-periods of a length-$n$ string $S$,\npresented as a data stream. $S$ is said to have $k$-period $p$ if its prefix of\nlength $n-p$ differs from its suffix of length $n-p$ in at most $k$ locations.\n  We give a one-pass streaming algorithm that computes the $k$-periods of a\nstring $S$ using $\\text{poly}(k, \\log n)$ bits of space, for $k$-periods of\nlength at most $\\frac{n}{2}$. We also present a two-pass streaming algorithm\nthat computes $k$-periods of $S$ using $\\text{poly}(k, \\log n)$ bits of space,\nregardless of period length. We complement these results with comparable lower\nbounds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 02:12:48 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Erg\u00fcn", "Funda", ""], ["Grigorescu", "Elena", ""], ["Azer", "Erfan Sadeqi", ""], ["Zhou", "Samson", ""]]}, {"id": "1708.04501", "submitter": "Youming Qiao", "authors": "Yinan Li, Youming Qiao", "title": "Linear algebraic analogues of the graph isomorphism problem and the\n  Erd\\H{o}s-R\\'enyi model", "comments": "32 pages, 2 figures. The implication to group enumeration corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical difficult isomorphism testing problem is to test isomorphism of\np-groups of class 2 and exponent p in time polynomial in the group order. It is\nknown that this problem can be reduced to solving the alternating matrix space\nisometry problem over a finite field in time polynomial in the underlying\nvector space size. We propose a venue of attack for the latter problem by\nviewing it as a linear algebraic analogue of the graph isomorphism problem.\nThis viewpoint leads us to explore the possibility of transferring techniques\nfor graph isomorphism to this long-believed bottleneck case of group\nisomorphism.\n  In 1970's, Babai, Erd\\H{o}s, and Selkow presented the first average-case\nefficient graph isomorphism testing algorithm (SIAM J Computing, 1980).\nInspired by that algorithm, we devise an average-case efficient algorithm for\nthe alternating matrix space isometry problem over a key range of parameters,\nin a random model of alternating matrix spaces in vein of the Erd\\H{o}s-R\\'enyi\nmodel of random graphs. For this, we develop a linear algebraic analogue of the\nclassical individualisation technique, a technique belonging to a set of\ncombinatorial techniques that has been critical for the progress on the\nworst-case time complexity for graph isomorphism, but was missing in the group\nisomorphism context. As a consequence of the main algorithm, we establish a\nweaker linear algebraic analogue of Erd\\H{o}s and R\\'enyi's classical result\nthat most graphs have the trivial automorphism group. We finally show that\nLuks' dynamic programming technique for graph isomorphism (STOC 1999) can be\nadapted to slightly improve the worst-case time complexity of the alternating\nmatrix space isometry problem in a certain range of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 14:04:20 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 12:48:59 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Li", "Yinan", ""], ["Qiao", "Youming", ""]]}, {"id": "1708.04536", "submitter": "Lars Jaffke", "authors": "Lars Jaffke, O-joung Kwon, Jan Arne Telle", "title": "Polynomial-time algorithms for the Longest Induced Path and Induced\n  Disjoint Paths problems on graphs of bounded mim-width", "comments": "20 pages, 4 figures; accepted at IPEC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time algorithms on graphs of bounded maximum\ninduced matching width (mim-width) for problems that are not locally checkable.\nIn particular, we give $n^{\\mathcal{O}(w)}$-time algorithms on graphs of\nmim-width at most $w$, when given a decomposition, for the following problems:\nLongest Induced Path, Induced Disjoint Paths and $H$-Induced Topological Minor\nfor fixed $H$. Our results imply that the following graph classes have\npolynomial-time algorithms for these three problems: Interval and Bi-Interval\ngraphs, Circular Arc, Permutation and Circular Permutation graphs, Convex\ngraphs, $k$-Trapezoid, Circular $k$-Trapezoid, $k$-Polygon, Dilworth-$k$ and\nCo-$k$-Degenerate graphs for fixed $k$.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 15:05:10 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 15:40:34 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Jaffke", "Lars", ""], ["Kwon", "O-joung", ""], ["Telle", "Jan Arne", ""]]}, {"id": "1708.04544", "submitter": "Michael Kapralov", "authors": "Michael Kapralov", "title": "Sample Efficient Estimation and Recovery in Sparse FFT via Isolation on\n  Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of computing the Fourier Transform of a signal whose spectrum is\ndominated by a small number $k$ of frequencies quickly and using a small number\nof samples of the signal in time domain (the Sparse FFT problem) has received\nsignificant attention recently. It is known how to approximately compute the\n$k$-sparse Fourier transform in $\\approx k\\log^2 n$ time [Hassanieh et\nal'STOC'12], or using the optimal number $O(k\\log n)$ of samples [Indyk et\nal'FOCS'14] in time domain, or come within $(\\log\\log n)^{O(1)}$ factors of\nboth these bounds simultaneously, but no algorithm achieving the optimal\n$O(k\\log n)$ bound in sublinear time is known.\n  In this paper we propose a new technique for analysing noisy hashing schemes\nthat arise in Sparse FFT, which we refer to as isolation on average. We apply\nthis technique to two problems in Sparse FFT: estimating the values of a list\nof frequencies using few samples and computing Sparse FFT itself, achieving\nsample-optimal results in $k\\log^{O(1)} n$ time for both. We feel that our\napproach will likely be of interest in designing Fourier sampling schemes for\nmore general settings (e.g. model based Sparse FFT).\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 15:11:18 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 15:55:10 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Kapralov", "Michael", ""]]}, {"id": "1708.04597", "submitter": "Juling Zhang", "authors": "Juling Zhang, Guowu Yang, William N. N. Hung, and Yan Zhang", "title": "An Efficient NPN Boolean Matching Algorithm Based on Structural\n  Signature and Shannon Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient pairwise Boolean matching algorithm to solve the problem of\nmatching single-output specified Boolean functions under input negation and/or\ninput permutation and/or output negation (NPN) is proposed in this paper. We\npresent the Structural Signature (SS) vector, which is composed of a 1st\nsignature value, two symmetry marks, and a group mark. As a necessary condition\nfor NPN Boolean matching, the structural signature is more effective than is\nthe traditional signature. Two Boolean functions, f and g, may be equivalent\nwhen they have the same SS vector. The symmetry mark can distinguish symmetric\nvariables and asymmetric variables and search multiple variable mappings in a\nsingle variable-mapping search operation, which reduces the search space\nsignificantly. Updating the SS vector using Shannon decomposition provides\nbenefits in distinguishing unidentified variables, and the group mark and the\nphase collision check discover incorrect variable mappings quickly, which also\nspeeds up the NPN Boolean matching process. Using the algorithm proposed in\nthis paper, we tested both equivalent and non-equivalent matching peeds on the\nMCNC benchmark circuit sets and the random circuit sets. In the experiment, our\nalgorithm is two times faster than competitors when testing equivalent circuits\nand averages at least one hundred times faster when testing non-equivalent\ncircuits. The experimental results show that our approach is highly effective\nin solving the NPN Boolean matching problem.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 05:30:48 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 06:06:16 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zhang", "Juling", ""], ["Yang", "Guowu", ""], ["Hung", "William N. N.", ""], ["Zhang", "Yan", ""]]}, {"id": "1708.04696", "submitter": "Cl\\'ement Canonne", "authors": "Tu\\u{g}kan Batu and Cl\\'ement L. Canonne", "title": "Generalized Uniformity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we revisit the problem of uniformity testing of discrete\nprobability distributions. A fundamental problem in distribution testing,\ntesting uniformity over a known domain has been addressed over a significant\nline of works, and is by now fully understood.\n  The complexity of deciding whether an unknown distribution is uniform over\nits unknown (and arbitrary) support, however, is much less clear. Yet, this\ntask arises as soon as no prior knowledge on the domain is available, or\nwhenever the samples originate from an unknown and unstructured universe. In\nthis work, we introduce and study this generalized uniformity testing question,\nand establish nearly tight upper and lower bound showing that -- quite\nsurprisingly -- its sample complexity significantly differs from the\nknown-domain case. Moreover, our algorithm is intrinsically adaptive, in\ncontrast to the overwhelming majority of known distribution testing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 21:32:04 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Batu", "Tu\u011fkan", ""], ["Canonne", "Cl\u00e9ment L.", ""]]}, {"id": "1708.04723", "submitter": "Anastasios Sidiropoulos", "authors": "Ken-ichi Kawarabayashi, Anastasios Sidiropoulos", "title": "Polylogarithmic approximation for minimum planarization (almost)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the minimum planarization problem, given some $n$-vertex graph, the goal\nis to find a set of vertices of minimum cardinality whose removal leaves a\nplanar graph. This is a fundamental problem in topological graph theory. We\npresent a $\\log^{O(1)} n$-approximation algorithm for this problem on general\ngraphs with running time $n^{O(\\log n/\\log\\log n)}$. We also obtain a\n$O(n^\\varepsilon)$-approximation with running time $n^{O(1/\\varepsilon)}$ for\nany arbitrarily small constant $\\varepsilon > 0$. Prior to our work, no\nnon-trivial algorithm was known for this problem on general graphs, and the\nbest known result even on graphs of bounded degree was a\n$n^{\\Omega(1)}$-approximation [Chekuri and Sidiropoulos 2013].\n  As an immediate corollary, we also obtain improved approximation algorithms\nfor the crossing number problem on graphs of bounded degree. Specifically, we\nobtain $O(n^{1/2+\\varepsilon})$-approximation and $n^{1/2} \\log^{O(1)}\nn$-approximation algorithms in time $n^{O(1/\\varepsilon)}$ and $n^{O(\\log\nn/\\log\\log n)}$ respectively. The previously best-known result was a\npolynomial-time $n^{9/10}\\log^{O(1)} n$-approximation algorithm [Chuzhoy 2011].\n  Our algorithm introduces several new tools including an efficient grid-minor\nconstruction for apex graphs, and a new method for computing irrelevant\nvertices. Analogues of these tools were previously available only for exact\nalgorithms. Our work gives efficient implementations of these ideas in the\nsetting of approximation algorithms, which could be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 23:54:36 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Kawarabayashi", "Ken-ichi", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1708.04862", "submitter": "Orgad Keller", "authors": "Orgad Keller, Avinatan Hassidim and Noam Hazon", "title": "New Approximations for Coalitional Manipulation in General Scoring Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of coalitional manipulation---where $k$ manipulators try\nto manipulate an election on $m$ candidates---under general scoring rules, with\na focus on the Borda protocol. We do so both in the weighted and unweighted\nsettings. We focus on minimizing the maximum score obtainable by a\nnon-preferred candidate.\n  In the strongest, most general setting, we provide an algorithm for any\nscoring rule as described by a vector\n$\\vec{\\alpha}=(\\alpha_1,\\ldots,\\alpha_m)$: for some $\\beta=O(\\sqrt{m\\log m})$,\nit obtains an additive approximation equal to $W\\cdot \\max_i \\lvert\n\\alpha_{i+\\beta}-\\alpha_i \\rvert$, where $W$ is the sum of voter weights.\n  For Borda, both the weighted and unweighted variants are known to be\n$NP$-hard. For the unweighted case, our simpler algorithm provides a\nrandomized, additive $O(k \\sqrt{m \\log m} )$ approximation; in other words, if\nthere exists a strategy enabling the preferred candidate to win by an $\\Omega(k\n\\sqrt{m \\log m} )$ margin, our method, with high probability, will find a\nstrategy enabling her to win (albeit with a possibly smaller margin). It thus\nprovides a somewhat stronger guarantee compared to the previous methods, which\nimplicitly implied a strategy that provides an $\\Omega(m)$-additive\napproximation to the maximum score of a non-preferred candidate.\n  For the weighted case, our generalized algorithm provides an $O(W \\sqrt{m\n\\log m} )$-additive approximation, where $W$ is the sum of voter weights. This\nis a clear advantage over previous methods: some of them do not generalize to\nthe weighted case, while others---which approximate the number of\nmanipulators---pose restrictions on the weights of extra manipulators added.\n  Our methods are based on carefully rounding an exponentially-large\nconfiguration linear program that is solved by using the ellipsoid method with\nan efficient separation oracle.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 12:47:19 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Keller", "Orgad", ""], ["Hassidim", "Avinatan", ""], ["Hazon", "Noam", ""]]}, {"id": "1708.04903", "submitter": "Thang Nguyen Kim", "authors": "Nguyen Kim Thang", "title": "Online Primal-Dual Algorithms with Configuration Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear, especially convex, objective functions have been extensively\nstudied in recent years in which approaches relies crucially on the convexity\nproperty of cost functions. In this paper, we present primal-dual approaches\nbased on configuration linear programs to design competitive online algorithms\nfor problems with arbitrarily-grown objective. This approach is particularly\nappropriate for non-linear (non-convex) objectives in online setting.\n  We first present a simple greedy algorithm for a general cost-minimization\nproblem. The competitive ratio of the algorithm is characterized by the mean of\na notion, called smoothness, which is inspired by a similar concept in the\ncontext of algorithmic game theory. The algorithm gives optimal (up to a\nconstant factor) competitive ratios while applying to different contexts such\nas network routing, vector scheduling, energy-efficient scheduling and\nnon-convex facility location.\n  Next, we consider the online $0-1$ covering problems with non-convex\nobjective. Building upon the resilient ideas from the primal-dual framework\nwith configuration LPs, we derive a competitive algorithm for these problems.\nOur result generalizes the online primal-dual algorithm developed recently by\nAzar et al. for convex objectives with monotone gradients to non-convex\nobjectives. The competitive ratio is now characterized by a new concept, called\nlocal smoothness --- a notion inspired by the smoothness. Our algorithm yields\ntight competitive ratio for the objectives such as the sum of $\\ell_{k}$-norms\nand gives competitive solutions for online problems of submodular minimization\nand some natural non-convex minimization under covering constraints.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 14:13:06 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Thang", "Nguyen Kim", ""]]}, {"id": "1708.04908", "submitter": "Alan Frieze", "authors": "Colin Cooper, Alan Frieze, Samantha Petti", "title": "The covertime of a biased random walk on $G_{n,p}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the covertime of a biased random walk on the random graph\n$G_{n,p}$. The walk is biased towards visiting vertices of low degree and this\nmakes the covertime less than in the unbiased case\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 14:30:55 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Cooper", "Colin", ""], ["Frieze", "Alan", ""], ["Petti", "Samantha", ""]]}, {"id": "1708.04945", "submitter": "Alan Frieze", "authors": "Alan Frieze and Samantha Petti", "title": "Balanced Allocation Through Random Walk", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the allocation problem in which $m \\leq (1-\\epsilon) dn $ items\nare to be allocated to $n$ bins with capacity $d$. The items\n$x_1,x_2,\\ldots,x_m$ arrive sequentially and when item $x_i$ arrives it is\ngiven two possible bin locations $p_i=h_1(x_i),q_i=h_2(x_i)$ via hash functions\n$h_1,h_2$. We consider a random walk procedure for inserting items and show\nthat the expected time insertion time is constant provided $\\epsilon =\n\\Omega\\left(\\sqrt{ \\frac{ \\log d}{d}} \\right).$\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 15:40:30 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 20:19:11 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Frieze", "Alan", ""], ["Petti", "Samantha", ""]]}, {"id": "1708.04974", "submitter": "Jeremy Alm", "authors": "Jeremy F. Alm, Andrew Ylvisaker", "title": "A fast coset-translation algorithm for computing the cycle structure of\n  Comer relation algebras over $\\mathbb{Z}/p\\mathbb{Z}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper relation algebras can be constructed using $\\mathbb{Z}/p\\mathbb{Z}$ as\na base set using a method due to Comer. The cycle structure of such an algebra\nmust, in general, be determined \\emph{a posteriori}, normally with the aid of a\ncomputer. In this paper, we give an improved algorithm for checking the cycle\nstructure that reduces the time complexity from $\\mathcal{O}(p^2)$ to\n$\\mathcal{O}(p)$.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 20:22:58 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 23:34:05 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Alm", "Jeremy F.", ""], ["Ylvisaker", "Andrew", ""]]}, {"id": "1708.05076", "submitter": "Cetin Savkli", "authors": "Cetin Savkli, Ryan Carr, Matthew Chapman, Brant Chee, David Minch", "title": "SOCRATES: A System For Scalable Graph Analytics", "comments": "5 pages", "journal-ref": null, "doi": "10.1109/HPEC.2014.7040993", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed semantic graph processing system that provides locality\ncontrol, indexing, graph query, and parallel processing capabilities is\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 20:45:10 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Savkli", "Cetin", ""], ["Carr", "Ryan", ""], ["Chapman", "Matthew", ""], ["Chee", "Brant", ""], ["Minch", "David", ""]]}, {"id": "1708.05102", "submitter": "Imed Kacem Prof.", "authors": "Imed Kacem, Hans Kellerer", "title": "Approximation Schemes for Minimizing the Maximum Lateness on a Single\n  Machine with Release Times under Non-Availability or Deadline Constraints", "comments": "The extended version has been submitted to an international journal.\n  It has been received by Springer on 12 April 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider four single-machine scheduling problems with\nrelease times, with the aim of minimizing the maximum lateness. In the first\nproblem we have a common deadline for all the jobs. The second problem looks\nfor the Pareto frontier with respect to the two objective functions maximum\nlateness and makespan. The third problem is associated with a non-availability\nconstraint. In the fourth one, the non-availibility interval is related to the\noperator who is organizing the execution of jobs on the machine (no job can\nstart, and neither can complete during the operator non-availability period).\nFor each of the four problems, we establish the existence of a polynomial time\napproximation scheme (PTAS).\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 22:47:08 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Kacem", "Imed", ""], ["Kellerer", "Hans", ""]]}, {"id": "1708.05159", "submitter": "Hoa Vu", "authors": "Branislav Kveton, S. Muthukrishnan, Hoa T. Vu, Yikun Xian", "title": "Finding Subcube Heavy Hitters in Analytics Data Streams", "comments": "To appear in WWW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data streams typically have items of large number of dimensions. We study the\nfundamental heavy-hitters problem in this setting. Formally, the data stream\nconsists of $d$-dimensional items $x_1,\\ldots,x_m \\in [n]^d$. A $k$-dimensional\nsubcube $T$ is a subset of distinct coordinates $\\{ T_1,\\cdots,T_k \\} \\subseteq\n[d]$. A subcube heavy hitter query ${\\rm Query}(T,v)$, $v \\in [n]^k$, outputs\nYES if $f_T(v) \\geq \\gamma$ and NO if $f_T(v) < \\gamma/4$, where $f_T$ is the\nratio of number of stream items whose coordinates $T$ have joint values $v$.\nThe all subcube heavy hitters query ${\\rm AllQuery}(T)$ outputs all joint\nvalues $v$ that return YES to ${\\rm Query}(T,v)$. The one dimensional version\nof this problem where $d=1$ was heavily studied in data stream theory,\ndatabases, networking and signal processing. The subcube heavy hitters problem\nis applicable in all these cases.\n  We present a simple reservoir sampling based one-pass streaming algorithm to\nsolve the subcube heavy hitters problem in $\\tilde{O}(kd/\\gamma)$ space. This\nis optimal up to poly-logarithmic factors given the established lower bound. In\nthe worst case, this is $\\Theta(d^2/\\gamma)$ which is prohibitive for large\n$d$, and our goal is to circumvent this quadratic bottleneck.\n  Our main contribution is a model-based approach to the subcube heavy hitters\nproblem. In particular, we assume that the dimensions are related to each other\nvia the Naive Bayes model, with or without a latent dimension. Under this\nassumption, we present a new two-pass, $\\tilde{O}(d/\\gamma)$-space algorithm\nfor our problem, and a fast algorithm for answering ${\\rm AllQuery}(T)$ in\n$O(k/\\gamma^2)$ time. Our work develops the direction of model-based data\nstream analysis, with much that remains to be explored.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 07:37:51 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 19:28:40 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Kveton", "Branislav", ""], ["Muthukrishnan", "S.", ""], ["Vu", "Hoa T.", ""], ["Xian", "Yikun", ""]]}, {"id": "1708.05214", "submitter": "Jin-Kao Hao", "authors": "Yangming Zhou, Jin-Kao Hao, B\\'eatrice Duval", "title": "When data mining meets optimization: A case study on the quadratic\n  assignment problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hybrid approach called frequent pattern based search\nthat combines data mining and optimization. The proposed method uses a data\nmining procedure to mine frequent patterns from a set of high-quality solutions\ncollected from previous search, and the mined frequent patterns are then\nemployed to build starting solutions that are improved by an optimization\nprocedure. After presenting the general approach and its composing ingredients,\nwe illustrate its application to solve the well-known and challenging quadratic\nassignment problem. Computational results on the 21 hardest benchmark instances\nshow that the proposed approach competes favorably with state-of-the-art\nalgorithms both in terms of solution quality and computing time.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 11:56:20 GMT"}, {"version": "v2", "created": "Sat, 7 Oct 2017 12:36:09 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Zhou", "Yangming", ""], ["Hao", "Jin-Kao", ""], ["Duval", "B\u00e9atrice", ""]]}, {"id": "1708.05223", "submitter": "Raphael Clifford", "authors": "Rapha\\\"el Clifford, Tomasz Kociumaka, Ely Porat", "title": "The streaming $k$-mismatch problem", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the streaming complexity of a fundamental task in approximate\npattern matching: the $k$-mismatch problem. It asks to compute Hamming\ndistances between a pattern of length $n$ and all length-$n$ substrings of a\ntext for which the Hamming distance does not exceed a given threshold $k$. In\nour problem formulation, we report not only the Hamming distance but also, on\ndemand, the full \\emph{mismatch information}, that is the list of mismatched\npairs of symbols and their indices. The twin challenges of streaming pattern\nmatching derive from the need both to achieve small working space and also to\nguarantee that every arriving input symbol is processed quickly.\n  We present a streaming algorithm for the $k$-mismatch problem which uses\n$O(k\\log{n}\\log\\frac{n}{k})$ bits of space and spends \\ourcomplexity time on\neach symbol of the input stream, which consists of the pattern followed by the\ntext. The running time almost matches the classic offline solution and the\nspace usage is within a logarithmic factor of optimal.\n  Our new algorithm therefore effectively resolves and also extends an open\nproblem first posed in FOCS'09. En route to this solution, we also give a\ndeterministic $O( k (\\log \\frac{n}{k} + \\log |\\Sigma|) )$-bit encoding of all\nthe alignments with Hamming distance at most $k$ of a length-$n$ pattern within\na text of length $O(n)$. This secondary result provides an optimal solution to\na natural communication complexity problem which may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 12:13:53 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 12:18:28 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Clifford", "Rapha\u00ebl", ""], ["Kociumaka", "Tomasz", ""], ["Porat", "Ely", ""]]}, {"id": "1708.05510", "submitter": "Theja Tulabandhula", "authors": "Deeksha Sinha and Theja Tulabandhula", "title": "Optimizing Revenue over Data-driven Assortments", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of large-scale assortment optimization under the\nmultinomial logit choice model without any assumptions on the structure of the\nfeasible assortments. Scalable real-time assortment optimization has become\nessential in e-commerce operations due to the need for personalization and the\navailability of a large variety of items. While this can be done when there are\nsimplistic assortment choices to be made, not imposing any constraints on the\ncollection of feasible assortments gives more flexibility to incorporate\ninsights of store-managers and historically well-performing assortments. We\ndesign fast and flexible algorithms based on variations of binary search that\nfind the revenue of the (approximately) optimal assortment. We speed up the\ncomparisons steps using novel vector space embeddings, based on advances in the\ninformation retrieval literature. For an arbitrary collection of assortments,\nour algorithms can find a solution in time that is sub-linear in the number of\nassortments and for the simpler case of cardinality constraints - linear in the\nnumber of items (existing methods are quadratic or worse). Empirical\nvalidations using the Billion Prices dataset and several retail transaction\ndatasets show that our algorithms are competitive even when the number of items\nis $\\sim 10^5$ ($100$x larger instances than previously studied).\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 05:05:49 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 04:44:44 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Sinha", "Deeksha", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1708.05520", "submitter": "Steffen Rechner", "authors": "Steffen Rechner", "title": "An Optimal Realization Algorithm for Bipartite Graphs with Degrees in\n  Prescribed Intervals", "comments": "Submitted to the Journal of Discrete Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing a bipartite graph whose degrees lie\nin prescribed intervals. Necessary and sufficient conditions for the existence\nof such graphs are well-known. However, existing realization algorithms suffer\nfrom large running times. In this paper, we present a realization algorithm\nthat constructs an appropriate bipartite graph G=(U,V,E) in O(|U| + |V| + |E|)\ntime, which is asymptotically optimal. In addition, we show that our algorithm\nproduces edge-minimal bipartite graphs and that it can easily be modified to\nconstruct edge-maximal graphs.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 06:58:37 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Rechner", "Steffen", ""]]}, {"id": "1708.05611", "submitter": "Debmalya Panigrahi", "authors": "Yossi Azar, Arun Ganesh, Rong Ge, Debmalya Panigrahi", "title": "Online Service with Delay", "comments": "30 pages, 11 figures, Appeared in 49th ACM Symposium on Theory of\n  Computing (STOC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the online service with delay problem. In this\nproblem, there are $n$ points in a metric space that issue service requests\nover time, and a server that serves these requests. The goal is to minimize the\nsum of distance traveled by the server and the total delay in serving the\nrequests. This problem models the fundamental tradeoff between batching\nrequests to improve locality and reducing delay to improve response time, that\nhas many applications in operations management, operating systems, logistics,\nsupply chain management, and scheduling.\n  Our main result is to show a poly-logarithmic competitive ratio for the\nonline service with delay problem. This result is obtained by an algorithm that\nwe call the preemptive service algorithm. The salient feature of this algorithm\nis a process called preemptive service, which uses a novel combination of\n(recursive) time forwarding and spatial exploration on a metric space. We hope\nthis technique will be useful for related problems such as reordering buffer\nmanagement, online TSP, vehicle routing, etc. We also generalize our results to\n$k > 1$ servers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:45:14 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Azar", "Yossi", ""], ["Ganesh", "Arun", ""], ["Ge", "Rong", ""], ["Panigrahi", "Debmalya", ""]]}, {"id": "1708.05622", "submitter": "Florent Urrutia", "authors": "Fran\\c{c}ois Le Gall, Florent Urrutia", "title": "Improved Rectangular Matrix Multiplication using Powers of the\n  Coppersmith-Winograd Tensor", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, successive improvements of the asymptotic complexity\nof square matrix multiplication have been obtained by developing novel methods\nto analyze the powers of the Coppersmith-Winograd tensor, a basic construction\nintroduced thirty years ago. In this paper we show how to generalize this\napproach to make progress on the complexity of rectangular matrix\nmultiplication as well, by developing a framework to analyze powers of tensors\nin an asymmetric way. By applying this methodology to the fourth power of the\nCoppersmith-Winograd tensor, we succeed in improving the complexity of\nrectangular matrix multiplication. Let $\\alpha$ denote the maximum value such\nthat the product of an $n\\times n^\\alpha$ matrix by an $n^\\alpha\\times n$\nmatrix can be computed with $O(n^{2+\\epsilon})$ arithmetic operations for any\n$\\epsilon>0$. By analyzing the fourth power of the Coppersmith-Winograd tensor\nusing our methods, we obtain the new lower bound $\\alpha>0.31389$, which\nimproves the previous lower bound $\\alpha>0.30298$ obtained five years ago by\nLe Gall (FOCS'12) from the analysis of the second power of the\nCoppersmith-Winograd tensor. More generally, we give faster algorithms\ncomputing the product of an $n\\times n^k$ matrix by an $n^k\\times n$ matrix for\nany value $k\\neq 1$. (In the case $k=1$, we recover the bounds recently\nobtained for square matrix multiplication). These improvements immediately lead\nto improvements in the complexity of a multitude of fundamental problems for\nwhich the bottleneck is rectangular matrix multiplication, such as computing\nthe all-pair shortest paths in directed graphs with bounded weights.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 14:13:01 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 12:51:42 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Urrutia", "Florent", ""]]}, {"id": "1708.05903", "submitter": "Cedric Bentz", "authors": "C\\'edric Bentz", "title": "An FPT algorithm for planar multicuts with sources and sinks on the\n  outer face", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a list of k source-sink pairs in an edge-weighted graph G, the minimum\nmulticut problem consists in selecting a set of edges of minimum total weight\nin G, such that removing these edges leaves no path from each source to its\ncorresponding sink. To the best of our knowledge, no non-trivial FPT result for\nspecial cases of this problem, which is APX-hard in general graphs for any\nfixed k>2, is known with respect to k only. When the graph G is planar, this\nproblem is known to be polynomial-time solvable if k=O(1), but cannot be FPT\nwith respect to k under the Exponential Time Hypothesis.\n  In this paper, we show that, if G is planar and in addition all sources and\nsinks lie on the outer face, then this problem does admit an FPT algorithm when\nparameterized by k (although it remains APX-hard when k is part of the input,\neven in stars). To do this, we provide a new characterization of optimal\nsolutions in this case, and then use it to design a \"divide-and-conquer\"\napproach: namely, some edges that are part of any such solution actually define\nan optimal solution for a polynomial-time solvable multiterminal variant of the\nproblem on some of the sources and sinks (which can be identified thanks to a\nreduced enumeration phase). Removing these edges from the graph cuts it into\nseveral smaller instances, which can then be solved recursively.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 21:30:52 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Bentz", "C\u00e9dric", ""]]}, {"id": "1708.05959", "submitter": "Huan Li", "authors": "Huan Li and Zhongzhi Zhang", "title": "Kirchhoff Index As a Measure of Edge Centrality in Weighted Networks:\n  Nearly Linear Time Algorithms", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611975031.153", "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous work of centralities focuses on metrics of vertex importance\nand methods for identifying powerful vertices, while related work for edges is\nmuch lesser, especially for weighted networks, due to the computational\nchallenge. In this paper, we propose to use the well-known Kirchhoff index as\nthe measure of edge centrality in weighted networks, called $\\theta$-Kirchhoff\nedge centrality. The Kirchhoff index of a network is defined as the sum of\neffective resistances over all vertex pairs. The centrality of an edge $e$ is\nreflected in the increase of Kirchhoff index of the network when the edge $e$\nis partially deactivated, characterized by a parameter $\\theta$. We define two\nequivalent measures for $\\theta$-Kirchhoff edge centrality. Both are global\nmetrics and have a better discriminating power than commonly used measures,\nbased on local or partial structural information of networks, e.g. edge\nbetweenness and spanning edge centrality.\n  Despite the strong advantages of Kirchhoff index as a centrality measure and\nits wide applications, computing the exact value of Kirchhoff edge centrality\nfor each edge in a graph is computationally demanding. To solve this problem,\nfor each of the $\\theta$-Kirchhoff edge centrality metrics, we present an\nefficient algorithm to compute its $\\epsilon$-approximation for all the $m$\nedges in nearly linear time in $m$. The proposed $\\theta$-Kirchhoff edge\ncentrality is the first global metric of edge importance that can be provably\napproximated in nearly-linear time. Moreover, according to the\n$\\theta$-Kirchhoff edge centrality, we present a $\\theta$-Kirchhoff vertex\ncentrality measure, as well as a fast algorithm that can compute\n$\\epsilon$-approximate Kirchhoff vertex centrality for all the $n$ vertices in\nnearly linear time in $m$.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 12:48:03 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 14:00:47 GMT"}, {"version": "v3", "created": "Sun, 14 Jan 2018 18:38:56 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Li", "Huan", ""], ["Zhang", "Zhongzhi", ""]]}, {"id": "1708.06002", "submitter": "Costin B\\u{a}descu", "authors": "Costin B\\u{a}descu, Ryan O'Donnell, John Wright", "title": "Quantum state certification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantum state certification, where one is given\n$n$ copies of an unknown $d$-dimensional quantum mixed state $\\rho$, and one\nwants to test whether $\\rho$ is equal to some known mixed state $\\sigma$ or\nelse is $\\epsilon$-far from $\\sigma$. The goal is to use notably fewer copies\nthan the $\\Omega(d^2)$ needed for full tomography on $\\rho$ (i.e., density\nestimation). We give two robust state certification algorithms: one with\nrespect to fidelity using $n = O(d/\\epsilon)$ copies, and one with respect to\ntrace distance using $n = O(d/\\epsilon^2)$ copies. The latter algorithm also\napplies when $\\sigma$ is unknown as well. These copy complexities are optimal\nup to constant factors.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 18:41:41 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 03:08:28 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 19:07:01 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["B\u0103descu", "Costin", ""], ["O'Donnell", "Ryan", ""], ["Wright", "John", ""]]}, {"id": "1708.06048", "submitter": "Shuguang Li", "authors": "Shuguang Li", "title": "Efficient algorithms for scheduling equal-length jobs with processing\n  set restrictions on uniform parallel batch machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling jobs with equal lengths on uniform\nparallel batch machines with non-identical capacities where each job can only\nbe processed on a specified subset of machines called its processing set. For\nthe case of equal release times, we give efficient exact algorithms for various\nobjective functions. For the case of unequal release times, we give efficient\nexact algorithms for minimizing makespan.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 01:40:27 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Li", "Shuguang", ""]]}, {"id": "1708.06127", "submitter": "Alexander Noe", "authors": "Monika Henzinger, Alexander Noe, Christian Schulz, Darren Strash", "title": "Practical Minimum Cut Algorithms", "comments": null, "journal-ref": "J. Exp. Algorithmics 23: 1.8:1-1.8:22 (2018)", "doi": "10.1145/3274662", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum cut problem for an undirected edge-weighted graph asks us to\ndivide its set of nodes into two blocks while minimizing the weight sum of the\ncut edges. Here, we introduce a linear-time algorithm to compute near-minimum\ncuts. Our algorithm is based on cluster contraction using label propagation and\nPadberg and Rinaldi's contraction heuristics [SIAM Review, 1991]. We give both\nsequential and shared-memory parallel implementations of our algorithm.\nExtensive experiments on both real-world and generated instances show that our\nalgorithm finds the optimal cut on nearly all instances significantly faster\nthan other state-of-the-art algorithms while our error rate is lower than that\nof other heuristic algorithms. In addition, our parallel algorithm shows good\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 09:34:13 GMT"}, {"version": "v2", "created": "Sun, 27 Aug 2017 08:25:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Henzinger", "Monika", ""], ["Noe", "Alexander", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""]]}, {"id": "1708.06151", "submitter": "Christian Schulz", "authors": "Demian Hespe, Christian Schulz, Darren Strash", "title": "Scalable Kernelization for Maximum Independent Sets", "comments": "Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most efficient algorithms for finding maximum independent sets in both\ntheory and practice use reduction rules to obtain a much smaller problem\ninstance called a kernel. The kernel can then be solved quickly using exact or\nheuristic algorithms---or by repeatedly kernelizing recursively in the\nbranch-and-reduce paradigm. It is of critical importance for these algorithms\nthat kernelization is fast and returns a small kernel. Current algorithms are\neither slow but produce a small kernel, or fast and give a large kernel. We\nattempt to accomplish both of these goals simultaneously, by giving an\nefficient parallel kernelization algorithm based on graph partitioning and\nparallel bipartite maximum matching. We combine our parallelization techniques\nwith two techniques to accelerate kernelization further: dependency checking\nthat prunes reductions that cannot be applied, and reduction tracking that\nallows us to stop kernelization when reductions become less fruitful. Our\nalgorithm produces kernels that are orders of magnitude smaller than the\nfastest kernelization methods, while having a similar execution time.\nFurthermore, our algorithm is able to compute kernels with size comparable to\nthe smallest known kernels, but up to two orders of magnitude faster than\npreviously possible. Finally, we show that our kernelization algorithm can be\nused to accelerate existing state-of-the-art heuristic algorithms, allowing us\nto find larger independent sets faster on large real-world networks and\nsynthetic instances.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 11:14:42 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 08:16:16 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hespe", "Demian", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""]]}, {"id": "1708.06183", "submitter": "Sebastien Tixeuil", "authors": "Adam Heriban (NPA), Xavier D\\'efago (TITECH), S\\'ebastien Tixeuil\n  (NPA, IUF, LINCS)", "title": "Optimally Gathering Two Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that ensures in finite time the gathering of two\nrobots in the non-rigid ASYNC model. To circumvent established impossibility\nresults, we assume robots are equipped with 2-colors lights and are able to\nmeasure distances between one another. Aside from its light, a robot has no\nmemory of its past actions, and its protocol is deterministic. Since, in the\nsame model, gathering is impossible when lights have a single color, our\nsolution is optimal with respect to the number of used colors.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 12:29:25 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Heriban", "Adam", "", "NPA"], ["D\u00e9fago", "Xavier", "", "TITECH"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1708.06275", "submitter": "Christiana Lymouri", "authors": "Mohsen Ghaffari, Christiana Lymouri", "title": "Simple and Near-Optimal Distributed Coloring for Sparse Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph coloring is one of the central problems in distributed graph\nalgorithms. Much of the research on this topic has focused on coloring with\n$\\Delta+1$ colors, where $\\Delta$ denotes the maximum degree. Using $\\Delta+1$\ncolors may be unsatisfactory in sparse graphs, where not all nodes have such a\nhigh degree; it would be more desirable to use a number of colors that improves\nwith sparsity. A standard measure that captures sparsity is arboricity, which\nis the smallest number of forests into which the edges of the graph can be\npartitioned.\n  We present simple randomized distributed algorithms that, with high\nprobability, color any $n$-node $\\alpha$-arboricity graph:\n  - using $(2+\\varepsilon)\\cdot \\alpha$ colors, for constant $\\varepsilon>0$,\nin $O(\\log n)$ rounds, if $\\alpha=\\tilde{\\Omega}(\\log n)$, or\n  - using $O(\\alpha \\log \\alpha )$ colors, in $O(\\log n)$ rounds, or\n  - using $O(\\alpha)$ colors, in $O(\\log n \\cdot \\min\\{\\log\\log n,\\; \\log\n\\alpha\\})$ rounds.\n  These algorithms are nearly-optimal, as it is known by results of Linial\n[FOCS'87] and Barenboim and Elkin [PODC'08] that coloring with $\\Theta(\\alpha)$\ncolors, or even poly$(\\alpha)$ colors, requires $\\Omega(\\log_{\\alpha} n)$\nrounds. The previously best-known $O(\\log n)$-time result was a deterministic\nalgorithm due to Barenboim and Elkin [PODC'08], which uses $\\Theta(\\alpha ^2)$\ncolors. Barenboim and Elkin stated improving this number of colors as an open\nproblem in their Distributed Graph Coloring Book.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 15:07:36 GMT"}, {"version": "v2", "created": "Wed, 23 Aug 2017 08:28:47 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Lymouri", "Christiana", ""]]}, {"id": "1708.06395", "submitter": "Piotr Wygocki", "authors": "Piotr Sankowski and Piotr Wygocki", "title": "Approximate nearest neighbors search without false negatives for $l_2$\n  for $c>\\sqrt{\\log\\log{n}}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report progress on answering the open problem presented by\nPagh~[14], who considered the nearest neighbor search without false negatives\nfor the Hamming distance. We show new data structures for solving the\n$c$-approximate nearest neighbors problem without false negatives for Euclidean\nhigh dimensional space $\\mathcal{R}^d$. These data structures work for any $c =\n\\omega(\\sqrt{\\log{\\log{n}}})$, where $n$ is the number of points in the input\nset, with poly-logarithmic query time and polynomial preprocessing time. This\nimproves over the known algorithms, which require $c$ to be $\\Omega(\\sqrt{d})$.\n  This improvement is obtained by applying a sequence of reductions, which are\ninteresting on their own. First, we reduce the problem to $d$ instances of\ndimension logarithmic in $n$. Next, these instances are reduced to a number of\n$c$-approximate nearest neighbor search instances in $\\big(\\mathbb{R}^k\\big)^L$\nspace equipped with metric $m(x,y) = \\max_{1 \\le i \\le L}(\\lVert x_i -\ny_i\\rVert_2)$.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 19:59:53 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 11:27:08 GMT"}, {"version": "v3", "created": "Wed, 13 Sep 2017 11:35:32 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Sankowski", "Piotr", ""], ["Wygocki", "Piotr", ""]]}, {"id": "1708.06499", "submitter": "Thang Nguyen Kim", "authors": "Nguyen Kim Thang", "title": "Game Efficiency through Linear Programming Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of a game is typically quantified by the price of anarchy\n(PoA), defined as the worst ratio of the objective function value of an\nequilibrium --- solution of the game --- and that of an optimal outcome. Given\nthe tremendous impact of tools from mathematical programming in the design of\nalgorithms and the similarity of the price of anarchy and different measures\nsuch as the approximation and competitive ratios, it is intriguing to develop a\nduality-based method to characterize the efficiency of games.\n  In the paper, we present an approach based on linear programming duality to\nstudy the efficiency of games. We show that the approach provides a general\nrecipe to analyze the efficiency of games and also to derive concepts leading\nto improvements. The approach is particularly appropriate to bound the PoA.\nSpecifically, in our approach the dual programs naturally lead to competitive\nPoA bounds that are (almost) optimal for several classes of games. The approach\nindeed captures the smoothness framework and also some current non-smooth\ntechniques/concepts. We show the applicability to the wide variety of games and\nenvironments, from congestion games to Bayesian welfare, from full-information\nsettings to incomplete-information ones.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 05:24:21 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Thang", "Nguyen Kim", ""]]}, {"id": "1708.06783", "submitter": "Sam Cole", "authors": "Sam Cole", "title": "Recovering Nonuniform Planted Partitions via Iterated Projection", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the planted partition problem, the $n$ vertices of a random graph are\npartitioned into $k$ \"clusters,\" and edges between vertices in the same cluster\nand different clusters are included with constant probability $p$ and $q$,\nrespectively (where $0 \\le q < p \\le 1$). We give an efficient spectral\nalgorithm that recovers the clusters with high probability, provided that the\nsizes of any two clusters are either very close or separated by $\\geq\n\\Omega(\\sqrt n)$. We also discuss a generalization of planted partition in\nwhich the algorithm's input is not a random graph, but a random real symmetric\nmatrix with independent above-diagonal entries.\n  Our algorithm is an adaptation of a previous algorithm for the uniform case,\ni.e., when all clusters are size $n / k \\geq \\Omega(\\sqrt n)$. The original\nalgorithm recovers the clusters one by one via iterated projection: it\nconstructs the orthogonal projection operator onto the dominant $k$-dimensional\neigenspace of the random graph's adjacency matrix, uses it to recover one of\nthe clusters, then deletes it and recurses on the remaining vertices. We show\nherein that a similar algorithm works in the nonuniform case.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 18:47:39 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Cole", "Sam", ""]]}, {"id": "1708.06839", "submitter": "Kevin Lang", "authors": "Kevin J Lang", "title": "Back to the Future: an Even More Nearly Optimal Cardinality Estimation\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new cardinality estimation algorithm that is extremely\nspace-efficient. It applies one of three novel estimators to the compressed\nstate of the Flajolet-Martin-85 coupon collection process. In an\napples-to-apples empirical comparison against compressed HyperLogLog sketches,\nthe new algorithm simultaneously wins on all three dimensions of the\ntime/space/accuracy tradeoff. Our prototype uses the zstd compression library,\nand produces sketches that are smaller than the entropy of HLL, so no possible\nimplementation of compressed HLL can match its space efficiency. The paper's\ntechnical contributions include analyses and simulations of the three new\nestimators, accurate values for the entropies of FM85 and HLL, and a\nnon-trivial method for estimating a double asymptotic limit via simulation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 22:11:43 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Lang", "Kevin J", ""]]}, {"id": "1708.06866", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Vijay Gadepally, Michael Hurley, Michael Jones,\n  Edward Kao, Sanjeev Mohindra, Paul Monticciolo, Albert Reuther, Steven Smith,\n  William Song, Diane Staheli, Jeremy Kepner", "title": "Static Graph Challenge: Subgraph Isomorphism", "comments": null, "journal-ref": null, "doi": "10.1109/HPEC.2017.8091039", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of graph analytic systems has created a need for ways to measure and\ncompare the capabilities of these systems. Graph analytics present unique\nscalability difficulties. The machine learning, high performance computing, and\nvisual analytics communities have wrestled with these difficulties for decades\nand developed methodologies for creating challenges to move these communities\nforward. The proposed Subgraph Isomorphism Graph Challenge draws upon prior\nchallenges from machine learning, high performance computing, and visual\nanalytics to create a graph challenge that is reflective of many real-world\ngraph analytics processing systems. The Subgraph Isomorphism Graph Challenge is\na holistic specification with multiple integrated kernels that can be run\ntogether or independently. Each kernel is well defined mathematically and can\nbe implemented in any programming environment. Subgraph isomorphism is amenable\nto both vertex-centric implementations and array-based implementations (e.g.,\nusing the GraphBLAS.org standard). The computations are simple enough that\nperformance predictions can be made based on simple computing hardware models.\nThe surrounding kernels provide the context for each kernel that allows\nrigorous definition of both the input and the output for each kernel.\nFurthermore, since the proposed graph challenge is scalable in both problem\nsize and hardware, it can be used to measure and quantitatively compare a wide\nrange of present day and future systems. Serial implementations in C++, Python,\nPython with Pandas, Matlab, Octave, and Julia have been implemented and their\nsingle threaded performance have been measured. Specifications, data, and\nsoftware are publicly available at GraphChallenge.org.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 01:51:08 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Samsi", "Siddharth", ""], ["Gadepally", "Vijay", ""], ["Hurley", "Michael", ""], ["Jones", "Michael", ""], ["Kao", "Edward", ""], ["Mohindra", "Sanjeev", ""], ["Monticciolo", "Paul", ""], ["Reuther", "Albert", ""], ["Smith", "Steven", ""], ["Song", "William", ""], ["Staheli", "Diane", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1708.07081", "submitter": "Samer Abdallah", "authors": "Samer Abdallah", "title": "More declarative tabling in Prolog using multi-prompt delimited control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several Prolog implementations include a facility for tabling, an alternative\nresolution strategy which uses memoisation to avoid redundant duplication of\ncomputations. Until relatively recently, tabling has required either low-level\nsupport in the underlying Prolog engine, or extensive program transormation (de\nGuzman et al., 2008). An alternative approach is to augment Prolog with low\nlevel support for continuation capturing control operators, particularly\ndelimited continuations, which have been investigated in the field of\nfunctional programming and found to be capable of supporting a wide variety of\ncomputational effects within an otherwise declarative language.\n  This technical report describes an implementation of tabling in SWI Prolog\nbased on delimited control operators for Prolog recently introduced by\nSchrijvers et al. (2013). In comparison with a previous implementation of\ntabling for SWI Prolog using delimited control (Desouter et al., 2015), this\napproach, based on the functional memoising parser combinators of Johnson\n(1995), stays closer to the declarative core of Prolog, requires less code, and\nis able to deliver solutions from systems of tabled predicates incrementally\n(as opposed to finding all solutions before delivering any to the rest of the\nprogram).\n  A collection of benchmarks shows that a small number of carefully targeted\noptimisations yields performance within a factor of about 2 of the optimised\nversion of Desouter et al.'s system currently included in SWI Prolog.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 16:26:15 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 08:22:39 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Abdallah", "Samer", ""]]}, {"id": "1708.07111", "submitter": "Dmitry Lande", "authors": "A.M. Hraivoronska, D.V. Lande", "title": "Elements of nonlinear analysis of information streams", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review considers methods of nonlinear dynamics to apply for analysis of\ntime series corresponding to information streams on the Internet. In the main,\nthese methods are based on correlation, fractal, multifractal, wavelet, and\nFourier analysis. The article is dedicated to a detailed description of these\napproaches and interconnections among them. The methods and corresponding\nalgorithms presented can be used for detecting key points in the dynamic of\ninformation processes; identifying periodicity, anomaly, self-similarity, and\ncorrelations; forecasting various information processes. The methods discussed\ncan form the basis for detecting information attacks, campaigns, operations,\nand wars.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 17:22:01 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Hraivoronska", "A. M.", ""], ["Lande", "D. V.", ""]]}, {"id": "1708.07242", "submitter": "Philip Graff", "authors": "Cetin Savkli, Jeffrey Lin, Philip Graff, Matthew Kinsey", "title": "GALILEO: A Generalized Low-Entropy Mixture Model", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": "Proceedings of the International Conference on Data Mining (DMIN\n  17). The Steering Committee of The World Congress in Computer Science,\n  Computer Engineering and Applied Computing (WorldComp). 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method of generating mixture models for data with\ncategorical attributes. The keys to this approach are an entropy-based density\nmetric in categorical space and annealing of high-entropy/low-density\ncomponents from an initial state with many components. Pruning of low-density\ncomponents using the entropy-based density allows GALILEO to consistently find\nhigh-quality clusters and the same optimal number of clusters. GALILEO has\nshown promising results on a range of test datasets commonly used for\ncategorical clustering benchmarks. We demonstrate that the scaling of GALILEO\nis linear in the number of records in the dataset, making this method suitable\nfor very large categorical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 01:27:34 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Savkli", "Cetin", ""], ["Lin", "Jeffrey", ""], ["Graff", "Philip", ""], ["Kinsey", "Matthew", ""]]}, {"id": "1708.07271", "submitter": "Travis Gagie", "authors": "Alexandre P. Francisco, Travis Gagie, Susana Ladra and Gonzalo Navarro", "title": "Exploiting Computation-Friendly Graph Compression Methods", "comments": "This research has received funding from the European Union's Horizon\n  2020 research and innovation programme under the Marie Sklodowska-Curie\n  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Accepted to 2018 Data\n  Compression Conference (DCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the product of the (binary) adjacency matrix of a large graph with\na real-valued vector is an important operation that lies at the heart of\nvarious graph analysis tasks, such as computing PageRank. In this paper we show\nthat some well-known Web and social graph compression formats are\ncomputation-friendly, in the sense that they allow boosting the computation. In\nparticular, we show that the format of Boldi and Vigna allows computing the\nproduct in time proportional to the compressed graph size. Our experimental\nresults show speedups of at least 2 on graphs that were compressed at least 5\ntimes with respect to the original. We show that other successful graph\ncompression formats enjoy this property as well.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 03:47:52 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 11:01:46 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 23:36:00 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Francisco", "Alexandre P.", ""], ["Gagie", "Travis", ""], ["Ladra", "Susana", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1708.07381", "submitter": "Vincent Cohen-Addad", "authors": "Vincent Cohen-Addad", "title": "A Fast Approximation Scheme for Low-Dimensional $k$-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the popular $k$-means problem in $d$-dimensional Euclidean space.\nRecently Friggstad, Rezapour, Salavatipour [FOCS'16] and Cohen-Addad, Klein,\nMathieu [FOCS'16] showed that the standard local search algorithm yields a\n$(1+\\epsilon)$-approximation in time $(n \\cdot k)^{1/\\epsilon^{O(d)}}$, giving\nthe first polynomial-time approximation scheme for the problem in\nlow-dimensional Euclidean space. While local search achieves optimal\napproximation guarantees, it is not competitive with the state-of-the-art\nheuristics such as the famous $k$-means++ and $D^2$-sampling algorithms.\n  In this paper, we aim at bridging the gap between theory and practice by\ngiving a $(1+\\epsilon)$-approximation algorithm for low-dimensional $k$-means\nrunning in time $n \\cdot k \\cdot (\\log n)^{(d\\epsilon^{-1})^{O(d)}}$, and so\nmatching the running time of the $k$-means++ and $D^2$-sampling heuristics up\nto polylogarithmic factors. We speed-up the local search approach by making a\nnon-standard use of randomized dissections that allows to find the best local\nmove efficiently using a quite simple dynamic program. We hope that our\ntechniques could help design better local search heuristics for geometric\nproblems. We note that the doubly exponential dependency on $d$ is necessary as\n$k$-means is APX-hard in dimension $d = \\omega(\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 13:00:38 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 10:50:34 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Cohen-Addad", "Vincent", ""]]}, {"id": "1708.07389", "submitter": "Jacob Holm", "authors": "Anders Aamand, Niklas Hjuler, Jacob Holm, Eva Rotenberg", "title": "One-Way Trail Orientations", "comments": "Earlier version submitted to SODA'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph, does there exist an orientation of the edges such that the\nresulting directed graph is strongly connected?\n  Robbins' theorem [Robbins, Am. Math. Monthly, 1939] states that such an\norientation exists if and only if the graph is $2$-edge connected. A natural\nextension of this problem is the following: Suppose that the edges of the graph\nis partitioned into trails. Can we orient the trails such that the resulting\ndirected graph is strongly connected?\n  We show that $2$-edge connectivity is again a sufficient condition and we\nprovide a linear time algorithm for finding such an orientation, which is both\noptimal and the first polynomial time algorithm for deciding this problem.\n  The generalised Robbins' theorem [Boesch, Am. Math. Monthly, 1980] for mixed\nmultigraphs states that the undirected edges of a mixed multigraph can be\noriented making the resulting directed graph strongly connected exactly when\nthe mixed graph is connected and the underlying graph is bridgeless. We show\nthat as long as all cuts have at least $2$ undirected edges or directed edges\nboth ways, then there exists an orientation making the resulting directed graph\nstrongly connected. This provides the first polynomial time algorithm for this\nproblem and a very simple polynomial time algorithm to the previous problem.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 13:18:54 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Aamand", "Anders", ""], ["Hjuler", "Niklas", ""], ["Holm", "Jacob", ""], ["Rotenberg", "Eva", ""]]}, {"id": "1708.07428", "submitter": "Boris Klemz", "authors": "Boris Klemz, G\\\"unter Rote", "title": "Ordered Level Planarity, Geodesic Planarity and Bi-Monotonicity", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": "ACM Transactions on Algorithms 15 (2019), Article 53, 53:1-53:25", "doi": "10.1145/3359587", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the problem Ordered Level Planarity which asks for a\nplanar drawing of a graph such that vertices are placed at prescribed positions\nin the plane and such that every edge is realized as a y-monotone curve. This\ncan be interpreted as a variant of Level Planarity in which the vertices on\neach level appear in a prescribed total order. We establish a complexity\ndichotomy with respect to both the maximum degree and the level-width, that is,\nthe maximum number of vertices that share a level. Our study of Ordered Level\nPlanarity is motivated by connections to several other graph drawing problems.\n  Geodesic Planarity asks for a planar drawing of a graph such that vertices\nare placed at prescribed positions in the plane and such that every edge is\nrealized as a polygonal path composed of line segments with two adjacent\ndirections from a given set $S$ of directions symmetric with respect to the\norigin. Our results on Ordered Level Planarity imply $NP$-hardness for any $S$\nwith $|S|\\ge 4$ even if the given graph is a matching. Katz, Krug, Rutter and\nWolff claimed that for matchings Manhattan Geodesic Planarity, the case where\n$S$ contains precisely the horizontal and vertical directions, can be solved in\npolynomial time [GD'09]. Our results imply that this is incorrect unless\n$P=NP$. Our reduction extends to settle the complexity of the Bi-Monotonicity\nproblem, which was proposed by Fulek, Pelsmajer, Schaefer and\n\\v{S}tefankovi\\v{c}.\n  Ordered Level Planarity turns out to be a special case of T-Level Planarity,\nClustered Level Planarity and Constrained Level Planarity. Thus, our results\nstrengthen previous hardness results. In particular, our reduction to Clustered\nLevel Planarity generates instances with only two non-trivial clusters. This\nanswers a question posed by Angelini, Da Lozzo, Di Battista, Frati and Roselli.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 14:06:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Klemz", "Boris", ""], ["Rote", "G\u00fcnter", ""]]}, {"id": "1708.07481", "submitter": "Andrew Knyazev", "authors": "David Zhuzhunashvili and Andrew Knyazev", "title": "Preconditioned Spectral Clustering for Stochastic Block Partition\n  Streaming Graph Challenge", "comments": "6 pages. To appear in Proceedings of the 2017 IEEE High Performance\n  Extreme Computing Conference. Student Innovation Award Streaming Graph\n  Challenge: Stochastic Block Partition, see\n  http://graphchallenge.mit.edu/champions", "journal-ref": "2017 IEEE High Performance Extreme Computing Conference (HPEC),\n  Waltham, MA, USA, 2017, pp. 1-6", "doi": "10.1109/HPEC.2017.8091045", "report-no": null, "categories": "cs.MS cs.DC cs.DS stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) is\ndemonstrated to efficiently solve eigenvalue problems for graph Laplacians that\nappear in spectral clustering. For static graph partitioning, 10-20 iterations\nof LOBPCG without preconditioning result in ~10x error reduction, enough to\nachieve 100% correctness for all Challenge datasets with known truth\npartitions, e.g., for graphs with 5K/.1M (50K/1M) Vertices/Edges in 2 (7)\nseconds, compared to over 5,000 (30,000) seconds needed by the baseline Python\ncode. Our Python code 100% correctly determines 98 (160) clusters from the\nChallenge static graphs with 0.5M (2M) vertices in 270 (1,700) seconds using\n10GB (50GB) of memory. Our single-precision MATLAB code calculates the same\nclusters at half time and memory. For streaming graph partitioning, LOBPCG is\ninitiated with approximate eigenvectors of the graph Laplacian already computed\nfor the previous graph, in many cases reducing 2-3 times the number of required\nLOBPCG iterations, compared to the static case. Our spectral clustering is\ngeneric, i.e. assuming nothing specific of the block model or streaming, used\nto generate the graphs for the Challenge, in contrast to the base code.\nNevertheless, in 10-stage streaming comparison with the base code for the 5K\ngraph, the quality of our clusters is similar or better starting at stage 4 (7)\nfor emerging edging (snowballing) streaming, while the computations are over\n100-1000 faster.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 14:09:05 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Zhuzhunashvili", "David", ""], ["Knyazev", "Andrew", ""]]}, {"id": "1708.07586", "submitter": "Tobias Christiani", "authors": "Tobias Christiani", "title": "Fast Locality-Sensitive Hashing Frameworks for Approximate Near Neighbor\n  Search", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Indyk-Motwani Locality-Sensitive Hashing (LSH) framework (STOC 1998) is a\ngeneral technique for constructing a data structure to answer approximate near\nneighbor queries by using a distribution $\\mathcal{H}$ over locality-sensitive\nhash functions that partition space. For a collection of $n$ points, after\npreprocessing, the query time is dominated by $O(n^{\\rho} \\log n)$ evaluations\nof hash functions from $\\mathcal{H}$ and $O(n^{\\rho})$ hash table lookups and\ndistance computations where $\\rho \\in (0,1)$ is determined by the\nlocality-sensitivity properties of $\\mathcal{H}$. It follows from a recent\nresult by Dahlgaard et al. (FOCS 2017) that the number of locality-sensitive\nhash functions can be reduced to $O(\\log^2 n)$, leaving the query time to be\ndominated by $O(n^{\\rho})$ distance computations and $O(n^{\\rho} \\log n)$\nadditional word-RAM operations. We state this result as a general framework and\nprovide a simpler analysis showing that the number of lookups and distance\ncomputations closely match the Indyk-Motwani framework, making it a viable\nreplacement in practice. Using ideas from another locality-sensitive hashing\nframework by Andoni and Indyk (SODA 2006) we are able to reduce the number of\nadditional word-RAM operations to $O(n^\\rho)$.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 00:47:38 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 17:26:34 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Christiani", "Tobias", ""]]}, {"id": "1708.07591", "submitter": "Ohad Trabelsi", "authors": "Robert Krauthgamer and Ohad Trabelsi", "title": "Conditional Lower Bound for Subgraph Isomorphism with a Tree Pattern", "comments": "A merged work containing the results in this paper is available at\n  arXiv:1711.08041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kTree problem is a special case of Subgraph Isomorphism where the pattern\ngraph is a tree, that is, the input is an $n$-node graph $G$ and a $k$-node\ntree $T$, and the goal is to determine whether $G$ has a subgraph isomorphic to\n$T$. We provide evidence that this problem cannot be computed significantly\nfaster than $2^{k} \\textsf{poly}(n)$, which matches the fastest algorithm known\nfor this problem by Koutis and Williams [ICALP 2009 and TALG 2016].\nSpecifically, we show that if kTree can be solved in time $(2-\\varepsilon)^k\n\\textsf{poly}(n)$ for some constant $\\varepsilon>0$, then Set Cover with $n'$\nelements and $m'$ sets can be solved in time $(2-\\delta)^{n'}\n\\textsf{poly}(m')$ for a constant $\\delta(\\varepsilon) > 0$, which would refute\nthe Set Cover Conjecture by Cygan et al. [CCC 2012 and TALG 2016].\n  Our techniques yield a new algorithm for the p-Partial Cover problem, a\nparameterized version of Set Cover that requires covering at least $p$ elements\n(rather than all elements). Its running time is $(2+\\varepsilon)^p\n(m')^{O(1/\\varepsilon)}$ for any fixed $\\varepsilon>0$, which improves the\nprevious $2.597^p \\textsf{poly}(m')$-time algorithm by Zehavi [ESA 2015]. Our\nrunning time is nearly optimal, as a $(2-\\varepsilon')^p\n\\textsf{poly}(m')$-time algorithm would refute the Set Cover Conjecture.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 01:09:01 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 16:54:32 GMT"}, {"version": "v3", "created": "Tue, 19 Dec 2017 22:36:27 GMT"}, {"version": "v4", "created": "Mon, 9 Apr 2018 13:09:38 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Krauthgamer", "Robert", ""], ["Trabelsi", "Ohad", ""]]}, {"id": "1708.07786", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Alexei Vernitski", "title": "Efficient Adaptive Implementation of the Serial Schedule Generation\n  Scheme using Preprocessing and Bloom Filters", "comments": "To appear in proceedings of the 11th Learning and Intelligent\n  Optimization Conference (LION)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of scheduling metaheuristics use indirect representation of\nsolutions as a way to efficiently explore the search space. Thus, a crucial\npart of such metaheuristics is a \"schedule generation scheme\" -- procedure\ntranslating the indirect solution representation into a schedule. Schedule\ngeneration scheme is used every time a new candidate solution needs to be\nevaluated. Being relatively slow, it eats up most of the running time of the\nmetaheuristic and, thus, its speed plays significant role in performance of the\nmetaheuristic. Despite its importance, little attention has been paid in the\nliterature to efficient implementation of schedule generation schemes. We give\ndetailed description of serial schedule generation scheme, including new\nimprovements, and propose a new approach for speeding it up, by using Bloom\nfilters. The results are further strengthened by automated control of\nparameters. Finally, we employ online algorithm selection to dynamically choose\nwhich of the two implementations to use. This hybrid approach significantly\noutperforms conventional implementation on a wide range of instances.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 15:46:57 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Vernitski", "Alexei", ""]]}, {"id": "1708.07788", "submitter": "Christopher Musco", "authors": "Cameron Musco, Christopher Musco, Aaron Sidford", "title": "Stability of the Lanczos Method for Matrix Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous Lanczos method can approximate $f(A)x$ for any symmetric $n\n\\times n$ matrix $A$, vector $x$, and function $f$. In exact arithmetic, the\nmethod's error after $k$ iterations is bounded by the error of the best\ndegree-$k$ polynomial uniformly approximating $f(x)$ on the range\n$[\\lambda_{min}(A), \\lambda_{max}(A)]$. However, despite decades of work, it\nhas been unclear if this powerful guarantee holds in finite precision.\n  We resolve this problem, proving that when $\\max_{x \\in [\\lambda_{min},\n\\lambda_{max}]}|f(x)| \\le C$, Lanczos essentially matches the exact arithmetic\nguarantee if computations use roughly $\\log(nC\\|A\\|)$ bits of precision. Our\nproof extends work of Druskin and Knizhnerman [DK91], leveraging the stability\nof the classic Chebyshev recurrence to bound the stability of any polynomial\napproximating $f(x)$.\n  We also study the special case of $f(A) = A^{-1}$, where stronger guarantees\nhold. In exact arithmetic Lanczos performs as well as the best polynomial\napproximating $1/x$ at each of $A$'s eigenvalues, rather than on the full\neigenvalue range. In seminal work, Greenbaum gives an approach to extending\nthis bound to finite precision: she proves that finite precision Lanczos and\nthe related CG method match any polynomial approximating $1/x$ in a tiny range\naround each eigenvalue [Gre89].\n  For $A^{-1}$, this bound appears stronger than ours. However, we exhibit\nmatrices with condition number $\\kappa$ where exact arithmetic Lanczos\nconverges in $polylog(\\kappa)$ iterations, but Greenbaum's bound predicts\n$\\Omega(\\kappa^{1/5})$ iterations. It thus cannot offer significant improvement\nover the $O(\\kappa^{1/2})$ bound achievable via our result. Our analysis raises\nthe question of if convergence in less than $poly(\\kappa)$ iterations can be\nexpected in finite precision, even for matrices with clustered, skewed, or\notherwise favorable eigenvalue distributions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 15:53:17 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Sidford", "Aaron", ""]]}, {"id": "1708.07821", "submitter": "Saurabh Sawlani", "authors": "David Durfee, Kevin A. Lai, Saurabh Sawlani", "title": "$\\ell_1$ Regression using Lewis Weights Preconditioning and Stochastic\n  Gradient Descent", "comments": "31 pages, COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present preconditioned stochastic gradient descent (SGD) algorithms for\nthe $\\ell_1$ minimization problem $\\min_{x}\\|A x - b\\|_1$ in the overdetermined\ncase, where there are far more constraints than variables. Specifically, we\nhave $A \\in \\mathbb{R}^{n \\times d}$ for $n \\gg d$. Commonly known as the Least\nAbsolute Deviations problem, $\\ell_1$ regression can be used to solve many\nimportant combinatorial problems, such as minimum cut and shortest path.\nSGD-based algorithms are appealing for their simplicity and practical\nefficiency. Our primary insight is that careful preprocessing can yield\npreconditioned matrices $\\tilde{A}$ with strong properties (besides good\ncondition number and low-dimension) that allow for faster convergence of\ngradient descent. In particular, we precondition using Lewis weights to obtain\nan isotropic matrix with fewer rows and strong upper bounds on all row norms.\nWe leverage these conditions to find a good initialization, which we use along\nwith recent smoothing reductions and accelerated stochastic gradient descent\nalgorithms to achieve $\\epsilon$ relative error in $\\tilde{O}(nnz(A) + d^{2.5}\n\\epsilon^{-2})$ time with high probability, where $nnz(A)$ is the number of\nnon-zeros in $A$. This improves over the previous best result using gradient\ndescent for $\\ell_1$ regression. We also match the best known running times for\ninterior point methods in several settings.\n  Finally, we also show that if our original matrix $A$ is approximately\nisotropic and the row norms are approximately equal, we can give an algorithm\nthat avoids using fast matrix multiplication and obtains a running time of\n$\\tilde{O}(nnz(A) + s d^{1.5}\\epsilon^{-2} + d^2\\epsilon^{-2})$, where $s$ is\nthe maximum number of non-zeros in a row of $A$. In this setting, we beat the\nbest interior point methods for certain parameter regimes.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 17:44:37 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 21:35:10 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 20:08:04 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Durfee", "David", ""], ["Lai", "Kevin A.", ""], ["Sawlani", "Saurabh", ""]]}, {"id": "1708.07829", "submitter": "Sergio Garc\\'ia Prado", "authors": "Sergio Garc\\'ia Prado", "title": "Algorithms for Big Data: Graphs and PageRank", "comments": "in Spanish, 143 pages, final degree project (bachelor's thesis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work consists of a study of a set of techniques and strategies related\nwith algorithm's design, whose purpose is the resolution of problems on massive\ndata sets, in an efficient way. This field is known as Algorithms for Big Data.\nIn particular, this work has studied the Streaming Algorithms, which represents\nthe basis of the data structures of sublinear order $o(n)$ in space, known as\nSketches. In addition, it has deepened in the study of problems applied to\nGraphs on the Semi-Streaming model. Next, the PageRank algorithm was analyzed\nas a concrete case study. Finally, the development of a library for the\nresolution of graph problems, implemented on the top of the intensive\nmathematical computation platform known as TensorFlow has been started.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 12:51:07 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Prado", "Sergio Garc\u00eda", ""]]}, {"id": "1708.07883", "submitter": "Edward Kao", "authors": "Edward Kao, Vijay Gadepally, Michael Hurley, Michael Jones, Jeremy\n  Kepner, Sanjeev Mohindra, Paul Monticciolo, Albert Reuther, Siddharth Samsi,\n  William Song, Diane Staheli, Steven Smith", "title": "Streaming Graph Challenge: Stochastic Block Partition", "comments": "To be published in 2017 IEEE High Performance Extreme Computing\n  Conference (HPEC)", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091040", "report-no": null, "categories": "cs.DC cs.DS cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important objective for analyzing real-world graphs is to achieve scalable\nperformance on large, streaming graphs. A challenging and relevant example is\nthe graph partition problem. As a combinatorial problem, graph partition is\nNP-hard, but existing relaxation methods provide reasonable approximate\nsolutions that can be scaled for large graphs. Competitive benchmarks and\nchallenges have proven to be an effective means to advance state-of-the-art\nperformance and foster community collaboration. This paper describes a graph\npartition challenge with a baseline partition algorithm of sub-quadratic\ncomplexity. The algorithm employs rigorous Bayesian inferential methods based\non a statistical model that captures characteristics of the real-world graphs.\nThis strong foundation enables the algorithm to address limitations of\nwell-known graph partition approaches such as modularity maximization. This\npaper describes various aspects of the challenge including: (1) the data sets\nand streaming graph generator, (2) the baseline partition algorithm with\npseudocode, (3) an argument for the correctness of parallelizing the Bayesian\ninference, (4) different parallel computation strategies such as node-based\nparallelism and matrix-based parallelism, (5) evaluation metrics for partition\ncorrectness and computational requirements, (6) preliminary timing of a\nPython-based demonstration code and the open source C++ code, and (7)\nconsiderations for partitioning the graph in streaming fashion. Data sets and\nsource code for the algorithm as well as metrics, with detailed documentation\nare available at GraphChallenge.org.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 21:10:06 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kao", "Edward", ""], ["Gadepally", "Vijay", ""], ["Hurley", "Michael", ""], ["Jones", "Michael", ""], ["Kepner", "Jeremy", ""], ["Mohindra", "Sanjeev", ""], ["Monticciolo", "Paul", ""], ["Reuther", "Albert", ""], ["Samsi", "Siddharth", ""], ["Song", "William", ""], ["Staheli", "Diane", ""], ["Smith", "Steven", ""]]}, {"id": "1708.07906", "submitter": "Shanghua Teng", "authors": "Shang-Hua Teng", "title": "Network Essence: PageRank Completion and Centrality-Conforming Markov\n  Chains", "comments": "In \"A Journey Through Discrete Mathematics, A Tribute to Ji\\v{r}\\'i\n  Matou\\v{s}ek\", Editors Martin Loebl, Jaroslav Ne\\v{s}et\\v{r}il and Robin\n  Thomas, Springer International Publishing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CG cs.DS math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ji\\v{r}\\'i Matou\\v{s}ek (1963-2015) had many breakthrough contributions in\nmathematics and algorithm design. His milestone results are not only profound\nbut also elegant. By going beyond the original objects --- such as Euclidean\nspaces or linear programs --- Jirka found the essence of the challenging\nmathematical/algorithmic problems as well as beautiful solutions that were\nnatural to him, but were surprising discoveries to the field.\n  In this short exploration article, I will first share with readers my initial\nencounter with Jirka and discuss one of his fundamental geometric results from\nthe early 1990s. In the age of social and information networks, I will then\nturn the discussion from geometric structures to network structures, attempting\nto take a humble step towards the holy grail of network science, that is to\nunderstand the network essence that underlies the observed\nsparse-and-multifaceted network data. I will discuss a simple result which\nsummarizes some basic algebraic properties of personalized PageRank matrices.\nUnlike the traditional transitive closure of binary relations, the personalized\nPageRank matrices take \"accumulated Markovian closure\" of network data. Some of\nthese algebraic properties are known in various contexts. But I hope featuring\nthem together in a broader context will help to illustrate the desirable\nproperties of this Markovian completion of networks, and motivate systematic\ndevelopments of a network theory for understanding vast and ubiquitous\nmultifaceted network data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 22:35:23 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Teng", "Shang-Hua", ""]]}, {"id": "1708.07932", "submitter": "Kui Zhao", "authors": "Xuejian Zhao, Kui Zhao, Feng Ha", "title": "An Algorithm of Parking Planning for Smart Parking System", "comments": "Proceeding of the 11th World Congress on Intelligent Control and\n  Automation (WCICA)", "journal-ref": null, "doi": "10.1109/WCICA.2014.7053556", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are so many vehicles in the world and the number of vehicles is\nincreasing rapidly. To alleviate the parking problems caused by that, the smart\nparking system has been developed. The parking planning is one of the most\nimportant parts of it. An effective parking planning strategy makes the better\nuse of parking resources possible. In this paper, we present a feasible method\nto do parking planning. We transform the parking planning problem into a kind\nof linear assignment problem. We take vehicles as jobs and parking spaces as\nagents. We take distances between vehicles and parking spaces as costs for\nagents doing jobs. Then we design an algorithm for this particular assignment\nproblem and solve the parking planning problem. The method proposed can give\ntimely and efficient guide information to vehicles for a real time smart\nparking system. Finally, we show the effectiveness of the method with\nexperiments over some data, which can simulate the situation of doing parking\nplanning in the real world.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 05:26:39 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Zhao", "Xuejian", ""], ["Zhao", "Kui", ""], ["Ha", "Feng", ""]]}, {"id": "1708.07973", "submitter": "Bin Fu", "authors": "Bin Fu, Fengjuan Zhu, John Abraham", "title": "A Model for Donation Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a model for donation verification. A randomized\nalgorithm is developed to check if the money claimed being received by the\ncollector is $(1-\\epsilon)$-approximation to the total amount money contributed\nby the donors. We also derive some negative results that show it is impossible\nto verify the donations under some circumstances.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 13:58:08 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Fu", "Bin", ""], ["Zhu", "Fengjuan", ""], ["Abraham", "John", ""]]}, {"id": "1708.08083", "submitter": "Christian Ikenmeyer", "authors": "Christian Ikenmeyer and Vladimir Lysikov", "title": "Strassen's 2x2 matrix multiplication algorithm: A conceptual perspective", "comments": "6 pages", "journal-ref": "Annali dell'Universit\\`a di Ferrara. Sezione VII: Science\n  matematiche. 65(2), pp. 241-248. (2019)", "doi": "10.1007/s11565-019-00318-1", "report-no": null, "categories": "cs.DS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this paper is pedagogical.\n  Despite its importance, all proofs of the correctness of Strassen's famous\n1969 algorithm to multiply two 2x2 matrices with only seven multiplications\ninvolve some basis-dependent calculations such as explicitly multiplying\nspecific 2x2 matrices, expanding expressions to cancel terms with opposing\nsigns, or expanding tensors over the standard basis. This makes the proof\nnontrivial to memorize and many presentations of the proof avoid showing all\nthe details and leave a significant amount of verifications to the reader.\n  In this note we give a short, self-contained, basis-independent proof of the\nexistence of Strassen's algorithm that avoids these types of calculations. We\nachieve this by focusing on symmetries and algebraic properties.\n  Our proof can be seen as a coordinate-free version of the construction of\nClausen from 1988, combined with recent work on the geometry of Strassen's\nalgorithm by Chiantini, Ikenmeyer, Landsberg, and Ottaviani from 2016.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 13:27:32 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 10:59:50 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Ikenmeyer", "Christian", ""], ["Lysikov", "Vladimir", ""]]}, {"id": "1708.08377", "submitter": "Shunichi Matsubara", "authors": "Shunichi Matsubara", "title": "Two-Dimensional Indirect Binary Search for the Positive One-in-Three\n  Satisfiability Problem", "comments": "This version added a subsection for describing the idea of the\n  algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an algorithm for the positive one-in-three\nsatisfiability problem (Pos1in3SAT). The proposed algorithm can efficiently\ndecide the existence of a satisfying assignment in all assignments for a given\nformula by using a 2-dimensional binary search method without constructing an\nexponential number of assignments.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 15:34:04 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 11:50:50 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Matsubara", "Shunichi", ""]]}, {"id": "1708.08436", "submitter": "Bei Wang", "authors": "Braxton Osting, Sourabh Palande, Bei Wang", "title": "Spectral Sparsification of Simplicial Complexes for Clustering and Label\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of the use of graphs to describe pairwise interactions,\nsimplicial complexes can be used to model higher-order interactions between\nthree or more objects in complex systems. There has been a recent surge in\nactivity for the development of data analysis methods applicable to simplicial\ncomplexes, including techniques based on computational topology, higher-order\nrandom processes, generalized Cheeger inequalities, isoperimetric inequalities,\nand spectral methods. In particular, spectral learning methods (e.g. label\npropagation and clustering) that directly operate on simplicial complexes\nrepresent a new direction for analyzing such complex datasets.\n  To apply spectral learning methods to massive datasets modeled as simplicial\ncomplexes, we develop a method for sparsifying simplicial complexes that\npreserves the spectrum of the associated Laplacian matrices. We show that the\ntheory of Spielman and Srivastava for the sparsification of graphs extends to\nsimplicial complexes via the up Laplacian. In particular, we introduce a\ngeneralized effective resistance for simplices, provide an algorithm for\nsparsifying simplicial complexes at a fixed dimension, and give a specific\nversion of the generalized Cheeger inequality for weighted simplicial\ncomplexes. Finally, we introduce higher-order generalizations of spectral\nclustering and label propagation for simplicial complexes and demonstrate via\nexperiments the utility of the proposed spectral sparsification method for\nthese applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 17:46:48 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 03:02:13 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 05:06:42 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Osting", "Braxton", ""], ["Palande", "Sourabh", ""], ["Wang", "Bei", ""]]}, {"id": "1708.08647", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski, Dariusz R. Kowalski, Michal Rozanski and Grzegorz\n  Stachowiak", "title": "Deterministic Digital Clustering of Wireless Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deterministic distributed communication in wireless ad hoc\nnetworks of identical weak devices under the SINR model without predefined\ninfrastructure. Most algorithmic results in this model rely on various\nadditional features or capabilities, e.g., randomization, access to geographic\ncoordinates, power control, carrier sensing with various precision of\nmeasurements, and/or interference cancellation. We study a pure scenario, when\nno such properties are available. As a general tool, we develop a deterministic\ndistributed clustering algorithm. Our solution relies on a new type of\ncombinatorial structures (selectors), which might be of independent interest.\nUsing the clustering, we develop a deterministic distributed local broadcast\nalgorithm accomplishing this task in $O(\\Delta \\log^*N \\log N)$ rounds, where\n$\\Delta$ is the density of the network. To the best of our knowledge, this is\nthe first solution in pure scenario which is only polylog$(n)$ away from the\nuniversal lower bound $\\Omega(\\Delta)$, valid also for scenarios with\nrandomization and other features. Therefore, none of these features\nsubstantially helps in performing the local broadcast task. Using clustering,\nwe also build a deterministic global broadcast algorithm that terminates within\n$O(D(\\Delta + \\log^* N) \\log N)$ rounds, where $D$ is the diameter of the\nnetwork. This result is complemented by a lower bound $\\Omega(D\n\\Delta^{1-1/\\alpha})$, where $\\alpha > 2$ is the path-loss parameter of the\nenvironment. This lower bound shows that randomization or knowledge of own\nlocation substantially help (by a factor polynomial in $\\Delta$) in the global\nbroadcast. Therefore, unlike in the case of local broadcast, some additional\nmodel features may help in global broadcast.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 09:09:37 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 08:10:07 GMT"}, {"version": "v3", "created": "Wed, 10 Jan 2018 09:47:44 GMT"}, {"version": "v4", "created": "Fri, 12 Jan 2018 13:54:45 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Kowalski", "Dariusz R.", ""], ["Rozanski", "Michal", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "1708.08694", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu", "title": "Natasha 2: Faster Non-Convex Optimization Than SGD", "comments": "V2 and V3 polished writing; V4 was a deep revision and simplified\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a stochastic algorithm to train any smooth neural network to\n$\\varepsilon$-approximate local minima, using $O(\\varepsilon^{-3.25})$\nbackpropagations. The best result was essentially $O(\\varepsilon^{-4})$ by SGD.\n  More broadly, it finds $\\varepsilon$-approximate local minima of any smooth\nnonconvex function in rate $O(\\varepsilon^{-3.25})$, with only oracle access to\nstochastic gradients.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 10:56:28 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 11:23:34 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 09:40:29 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2018 10:25:50 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""]]}, {"id": "1708.08739", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani and Albert Bifet and Talel Abdessalem", "title": "Efficient Exact and Approximate Algorithms for Computing Betweenness\n  Centrality in Directed Graphs", "comments": "arXiv admin note: text overlap with arXiv:1704.07351", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are an important tool to model data in different domains, including\nsocial networks, bioinformatics and the world wide web. Most of the networks\nformed in these domains are directed graphs, where all the edges have a\ndirection and they are not symmetric. Betweenness centrality is an important\nindex widely used to analyze networks. In this paper, first given a directed\nnetwork $G$ and a vertex $r \\in V(G)$, we propose a new exact algorithm to\ncompute betweenness score of $r$. Our algorithm pre-computes a set\n$\\mathcal{RV}(r)$, which is used to prune a huge amount of computations that do\nnot contribute in the betweenness score of $r$. Time complexity of our exact\nalgorithm depends on $|\\mathcal{RV}(r)|$ and it is respectively\n$\\Theta(|\\mathcal{RV}(r)|\\cdot|E(G)|)$ and\n$\\Theta(|\\mathcal{RV}(r)|\\cdot|E(G)|+|\\mathcal{RV}(r)|\\cdot|V(G)|\\log |V(G)|)$\nfor unweighted graphs and weighted graphs with positive weights.\n$|\\mathcal{RV}(r)|$ is bounded from above by $|V(G)|-1$ and in most cases, it\nis a small constant. Then, for the cases where $\\mathcal{RV}(r)$ is large, we\npresent a simple randomized algorithm that samples from $\\mathcal{RV}(r)$ and\nperforms computations for only the sampled elements. We show that this\nalgorithm provides an $(\\epsilon,\\delta)$-approximation of the betweenness\nscore of $r$. Finally, we perform extensive experiments over several real-world\ndatasets from different domains for several randomly chosen vertices as well as\nfor the vertices with the highest betweenness scores. Our experiments reveal\nthat in most cases, our algorithm significantly outperforms the most efficient\nexisting randomized algorithms, in terms of both running time and accuracy. Our\nexperiments also show that our proposed algorithm computes betweenness scores\nof all vertices in the sets of sizes 5, 10 and 15, much faster and more\naccurate than the most efficient existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 16:13:51 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""], ["Bifet", "Albert", ""], ["Abdessalem", "Talel", ""]]}, {"id": "1708.08778", "submitter": "Marcel Radermacher", "authors": "Tamara Mchedlidze, Marcel Radermacher, Ignaz Rutter", "title": "Aligned Drawings of Planar Graphs", "comments": "Preliminary work appeared in the Proceedings of the 25th\n  International Symposium on Graph Drawing and Network Visualization (GD 2017)", "journal-ref": "J. Graph Algorithms & Applications 22 (3): 401-429 (2018)", "doi": "10.7155/jgaa.00475", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a graph that is topologically embedded in the plane and let\n$\\mathcal{A}$ be an arrangement of pseudolines intersecting the drawing of $G$.\nAn aligned drawing of $G$ and $\\mathcal{A}$ is a planar polyline drawing\n$\\Gamma$ of $G$ with an arrangement $A$ of lines so that $\\Gamma$ and $A$ are\nhomeomorphic to $G$ and $\\mathcal{A}$. We show that if $\\mathcal{A}$ is\nstretchable and every edge $e$ either entirely lies on a pseudoline or it has\nat most one intersection with $\\mathcal{A}$, then $G$ and $\\mathcal{A}$ have a\nstraight-line aligned drawing. In order to prove this result, we strengthen a\nresult of Da Lozzo et al., and prove that a planar graph $G$ and a single\npseudoline $\\mathcal{L}$ have an aligned drawing with a prescribed convex\ndrawing of the outer face. We also study the less restrictive version of the\nalignment problem with respect to one line, where only a set of vertices is\ngiven and we need to determine whether they can be collinear. We show that the\nproblem is NP-complete but fixed-parameter tractable.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 14:31:15 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 14:41:59 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 13:01:09 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 14:59:16 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Mchedlidze", "Tamara", ""], ["Radermacher", "Marcel", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1708.08781", "submitter": "Yuichi Yoshida", "authors": "Yuichi Yoshida", "title": "Cheeger Inequalities for Submodular Transformations", "comments": "SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cheeger inequality for undirected graphs, which relates the conductance\nof an undirected graph and the second smallest eigenvalue of its normalized\nLaplacian, is a cornerstone of spectral graph theory. The Cheeger inequality\nhas been extended to directed graphs and hypergraphs using normalized\nLaplacians for those, that are no longer linear but piecewise linear\ntransformations.\n  In this paper, we introduce the notion of a submodular transformation\n$F:\\{0,1\\}^n \\to \\mathbb{R}^m$, which applies $m$ submodular functions to the\n$n$-dimensional input vector, and then introduce the notions of its Laplacian\nand normalized Laplacian. With these notions, we unify and generalize the\nexisting Cheeger inequalities by showing a Cheeger inequality for submodular\ntransformations, which relates the conductance of a submodular transformation\nand the smallest non-trivial eigenvalue of its normalized Laplacian. This\nresult recovers the Cheeger inequalities for undirected graphs, directed\ngraphs, and hypergraphs, and derives novel Cheeger inequalities for mutual\ninformation and directed information.\n  Computing the smallest non-trivial eigenvalue of a normalized Laplacian of a\nsubmodular transformation is NP-hard under the small set expansion hypothesis.\nIn this paper, we present a polynomial-time $O(\\log n)$-approximation algorithm\nfor the symmetric case, which is tight, and a polynomial-time $O(\\log^2n+\\log n\n\\cdot \\log m)$-approximation algorithm for the general case.\n  We expect the algebra concerned with submodular transformations, or\n\\emph{submodular algebra}, to be useful in the future not only for generalizing\nspectral graph theory but also for analyzing other problems that involve\npiecewise linear transformations, e.g., deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 14:35:05 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 21:33:22 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 12:45:08 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Yoshida", "Yuichi", ""]]}, {"id": "1708.08906", "submitter": "Carla Lintzmayer", "authors": "Carla Negri Lintzmayer, Fl\\'avio Keidi Miyazawa, Eduardo Candido\n  Xavier", "title": "Online Circle and Sphere Packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the Online Bin Packing Problem in three variants:\nCircles in Squares, Circles in Isosceles Right Triangles, and Spheres in Cubes.\nThe two first ones receive an online sequence of circles (items) of different\nradii while the third one receive an online sequence of spheres (items) of\ndifferent radii, and they want to pack the items into the minimum number of\nunit squares, isosceles right triangles of leg length one, and unit cubes,\nrespectively. For Online Circle Packing in Squares, we improve the previous\nbest-known competitive ratio for the bounded space version, when at most a\nconstant number of bins can be open at any given time, from 2.439 to 2.3536.\nFor Online Circle Packing in Isosceles Right Triangles and Online Sphere\nPacking in Cubes we show bounded space algorithms of asymptotic competitive\nratios 2.5490 and 3.5316, respectively, as well as lower bounds of 2.1193 and\n2.7707 on the competitive ratio of any online bounded space algorithm for these\ntwo problems. We also considered the online unbounded space variant of these\nthree problems which admits a small reorganization of the items inside the bin\nafter their packing, and we present algorithms of competitive ratios 2.3105,\n2.5094, and 3.5146 for Circles in Squares, Circles in Isosceles Right\nTriangles, and Spheres in Cubes, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 17:48:51 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Lintzmayer", "Carla Negri", ""], ["Miyazawa", "Fl\u00e1vio Keidi", ""], ["Xavier", "Eduardo Candido", ""]]}, {"id": "1708.08932", "submitter": "Zhi-Cheng Yang", "authors": "Zhi-Cheng Yang, Stefanos Kourtis, Claudio Chamon, Eduardo R. Mucciolo,\n  and Andrei E. Ruckenstein", "title": "Tensor network method for reversible classical computation", "comments": "Updated version with more careful discussions on the distribution of\n  bond dimensions over random instances, as well as distinguishing between\n  average versus typical behavior. 13.5 pages, 13 figures", "journal-ref": "Phys. Rev. E 97, 033303 (2018)", "doi": "10.1103/PhysRevE.97.033303", "report-no": null, "categories": "cond-mat.stat-mech cs.DS physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a tensor network technique that can solve universal reversible\nclassical computational problems, formulated as vertex models on a square\nlattice [Nat. Commun. 8, 15303 (2017)]. By encoding the truth table of each\nvertex constraint in a tensor, the total number of solutions compatible with\npartial inputs/outputs at the boundary can be represented as the full\ncontraction of a tensor network. We introduce an iterative\ncompression-decimation (ICD) scheme that performs this contraction efficiently.\nThe ICD algorithm first propagates local constraints to longer ranges via\nrepeated contraction-decomposition sweeps over all lattice bonds, thus\nachieving compression on a given length scale. It then decimates the lattice\nvia coarse-graining tensor contractions. Repeated iterations of these two steps\ngradually collapse the tensor network and ultimately yield the exact tensor\ntrace for large systems, without the need for manual control of tensor\ndimensions. Our protocol allows us to obtain the exact number of solutions for\ncomputations where a naive enumeration would take astronomically long times.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 18:00:02 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 15:25:24 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Yang", "Zhi-Cheng", ""], ["Kourtis", "Stefanos", ""], ["Chamon", "Claudio", ""], ["Mucciolo", "Eduardo R.", ""], ["Ruckenstein", "Andrei E.", ""]]}, {"id": "1708.09046", "submitter": "Benjamin Moseley", "authors": "Sungjin Im, Benjamin Moseley, Kirk Pruhs and Clifford Stein", "title": "An O(log log m)-competitive Algorithm for Online Machine Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the online machine minimization problem, a basic real\ntime scheduling problem. The setting for this problem consists of n jobs that\narrive over time, where each job has a deadline by which it must be completed.\nThe goal is to design an online scheduler that feasibly schedules the jobs on a\nnearly minimal number of machines. An algorithm is c-machine optimal if the\nalgorithm will feasibly schedule a collection of jobs on cm machines if there\nexists a feasible schedule on m machines. For over two decades the best known\nresult was a O(log P)-machine optimal algorithm, where P is the ratio of the\nmaximum to minimum job size. In a recent breakthrough, a O(log m)-machine\noptimal algorithm was given. In this paper, we exponentially improve on this\nrecent result by giving a O(log log m)-machine optimal algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:57:22 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 22:41:50 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Im", "Sungjin", ""], ["Moseley", "Benjamin", ""], ["Pruhs", "Kirk", ""], ["Stein", "Clifford", ""]]}, {"id": "1708.09059", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich", "title": "Answering Spatial Multiple-Set Intersection Queries Using 2-3 Cuckoo\n  Hash-Filters", "comments": "Full version of paper from 2017 ACM SIGSPATIAL International\n  Conference on Advances in Geographic Information Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to answer spatial multiple-set intersection queries in O(n(log\nw)/w + kt) expected time, where n is the total size of the t sets involved in\nthe query, w is the number of bits in a memory word, k is the output size, and\nc is any fixed constant. This improves the asymptotic performance over previous\nsolutions and is based on an interesting data structure, known as 2-3 cuckoo\nhash-filters. Our results apply in the word-RAM model (or practical RAM model),\nwhich allows for constant-time bit-parallel operations, such as bitwise AND,\nOR, NOT, and MSB (most-significant 1-bit), as exist in modern CPUs and GPUs.\nOur solutions apply to any multiple-set intersection queries in spatial data\nsets that can be reduced to one-dimensional range queries, such as spatial join\nqueries for one-dimensional points or sets of points stored along space-filling\ncurves, which are used in GIS applications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 23:42:28 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Goodrich", "Michael T.", ""]]}, {"id": "1708.09080", "submitter": "Andr\\'e van Renssen", "authors": "Luis Barba, Jean Cardinal, Matias Korman, Stefan Langerman, Andr\\'e\n  van Renssen, Marcel Roeloffzen, Sander Verdonschot", "title": "Dynamic Graph Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the number of vertex recolorings that an algorithm\nneeds to perform in order to maintain a proper coloring of a graph under\ninsertion and deletion of vertices and edges. We present two algorithms that\nachieve different trade-offs between the number of recolorings and the number\nof colors used. For any $d>0$, the first algorithm maintains a proper\n$O(\\mathcal{C} d N^{1/d})$-coloring while recoloring at most $O(d)$ vertices\nper update, where $\\mathcal{C}$ and $N$ are the maximum chromatic number and\nmaximum number of vertices, respectively. The second algorithm reverses the\ntrade-off, maintaining an $O(\\mathcal{C} d)$-coloring with $O(d N^{1/d})$\nrecolorings per update. The two converge when $d = \\log N$, maintaining an\n$O(\\mathcal{C} \\log N)$-coloring with $O(\\log N)$ recolorings per update. We\nalso present a lower bound, showing that any algorithm that maintains a\n$c$-coloring of a $2$-colorable graph on $N$ vertices must recolor at least\n$\\Omega(N^\\frac{2}{c(c-1)})$ vertices per update, for any constant $c \\geq 2$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 01:50:36 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 00:58:54 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Barba", "Luis", ""], ["Cardinal", "Jean", ""], ["Korman", "Matias", ""], ["Langerman", "Stefan", ""], ["van Renssen", "Andr\u00e9", ""], ["Roeloffzen", "Marcel", ""], ["Verdonschot", "Sander", ""]]}, {"id": "1708.09107", "submitter": "Giordano Da Lozzo", "authors": "Steven Chaplick, Markus Chimani, Sabine Cornelsen, Giordano Da Lozzo,\n  Martin N\\\"ollenburg, Maurizio Patrignani, Ioannis G. Tollis, and Alexander\n  Wolff", "title": "Planar L-Drawings of Directed Graphs", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study planar drawings of directed graphs in the L-drawing standard. We\nprovide necessary conditions for the existence of these drawings and show that\ntesting for the existence of a planar L-drawing is an NP-complete problem.\nMotivated by this result, we focus on upward-planar L-drawings. We show that\ndirected st-graphs admitting an upward- (resp. upward-rightward-) planar\nL-drawing are exactly those admitting a bitonic (resp. monotonically\nincreasing) st-ordering. We give a linear-time algorithm that computes a\nbitonic (resp. monotonically increasing) st-ordering of a planar st-graph or\nreports that there exists none.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 04:28:29 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 20:08:42 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Chaplick", "Steven", ""], ["Chimani", "Markus", ""], ["Cornelsen", "Sabine", ""], ["Da Lozzo", "Giordano", ""], ["N\u00f6llenburg", "Martin", ""], ["Patrignani", "Maurizio", ""], ["Tollis", "Ioannis G.", ""], ["Wolff", "Alexander", ""]]}, {"id": "1708.09197", "submitter": "Henry F\\\"orster", "authors": "Michael A. Bekos, Henry F\\\"orster, Michael Kaufmann", "title": "On Smooth Orthogonal and Octilinear Drawings: Relations, Complexity and\n  Kandinsky Drawings", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two variants of the well-known orthogonal drawing model: (i) the\nsmooth orthogonal, and (ii) the octilinear. Both models form an extension of\nthe orthogonal, by supporting one additional type of edge segments (circular\narcs and diagonal segments, respectively).\n  For planar graphs of max-degree 4, we analyze relationships between the graph\nclasses that can be drawn bendless in the two models and we also prove\nNP-hardness for a restricted version of the bendless drawing problem for both\nmodels. For planar graphs of higher degree, we present an algorithm that\nproduces bi-monotone smooth orthogonal drawings with at most two segments per\nedge, which also guarantees a linear number of edges with exactly one segment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 09:43:12 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Bekos", "Michael A.", ""], ["F\u00f6rster", "Henry", ""], ["Kaufmann", "Michael", ""]]}, {"id": "1708.09221", "submitter": "Jonathan Klawitter", "authors": "Jonathan Klawitter, Tamara Mchedlidze, Martin N\\\"ollenburg", "title": "Experimental Evaluation of Book Drawing Algorithms", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-page book drawing of a graph $G=(V,E)$ consists of a linear ordering of\nits vertices along a spine and an assignment of each edge to one of the $k$\npages, which are half-planes bounded by the spine. In a book drawing, two edges\ncross if and only if they are assigned to the same page and their vertices\nalternate along the spine. Crossing minimization in a $k$-page book drawing is\nNP-hard, yet book drawings have multiple applications in visualization and\nbeyond. Therefore several heuristic book drawing algorithms exist, but there is\nno broader comparative study on their relative performance. In this paper, we\npropose a comprehensive benchmark set of challenging graph classes for book\ndrawing algorithms and provide an extensive experimental study of the\nperformance of existing book drawing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 11:35:20 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Klawitter", "Jonathan", ""], ["Mchedlidze", "Tamara", ""], ["N\u00f6llenburg", "Martin", ""]]}, {"id": "1708.09233", "submitter": "Patrizio Angelini", "authors": "Patrizio Angelini, Steven Chaplick, Felice De Luca, Jiri Fiala,\n  Jaroslav Hancl Jr., Niklas Heinsohn, Michael Kaufmann, Stephen Kobourov, Jan\n  Kratochvil, and Pavel Valtr", "title": "On Vertex- and Empty-Ply Proximity Drawings", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of the vertex-ply of straight-line drawings, as a\nrelaxation of the recently introduced ply number. Consider the disks centered\nat each vertex with radius equal to half the length of the longest edge\nincident to the vertex. The vertex-ply of a drawing is determined by the vertex\ncovered by the maximum number of disks. The main motivation for considering\nthis relaxation is to relate the concept of ply to proximity drawings. In fact,\nif we interpret the set of disks as proximity regions, a drawing with\nvertex-ply number 1 can be seen as a weak proximity drawing, which we call\nempty-ply drawing. We show non-trivial relationships between the ply number and\nthe vertex-ply number. Then, we focus on empty-ply drawings, proving some\nproperties and studying what classes of graphs admit such drawings. Finally, we\nprove a lower bound on the ply and the vertex-ply of planar drawings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 12:24:25 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 08:55:02 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Angelini", "Patrizio", ""], ["Chaplick", "Steven", ""], ["De Luca", "Felice", ""], ["Fiala", "Jiri", ""], ["Hancl", "Jaroslav", "Jr."], ["Heinsohn", "Niklas", ""], ["Kaufmann", "Michael", ""], ["Kobourov", "Stephen", ""], ["Kratochvil", "Jan", ""], ["Valtr", "Pavel", ""]]}, {"id": "1708.09238", "submitter": "Felice De Luca", "authors": "Michael Bekos, Felice De Luca, Walter Didimo, Tamara Mchedlidze,\n  Martin N\\\"ollenburg, Antonios Symvonis and Ioannis Tollis", "title": "Planar Drawings of Fixed-Mobile Bigraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fixed-mobile bigraph G is a bipartite graph such that the vertices of one\npartition set are given with fixed positions in the plane and the mobile\nvertices of the other part, together with the edges, must be added to the\ndrawing. We assume that G is planar and study the problem of finding, for a\ngiven k >= 0, a planar poly-line drawing of G with at most k bends per edge. In\nthe most general case, we show NP-hardness. For k=0 and under additional\nconstraints on the positions of the fixed or mobile vertices, we either prove\nthat the problem is polynomial-time solvable or prove that it belongs to NP.\nFinally, we present a polynomial-time testing algorithm for a certain type of\n\"layered\" 1-bend drawings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 12:37:09 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Bekos", "Michael", ""], ["De Luca", "Felice", ""], ["Didimo", "Walter", ""], ["Mchedlidze", "Tamara", ""], ["N\u00f6llenburg", "Martin", ""], ["Symvonis", "Antonios", ""], ["Tollis", "Ioannis", ""]]}, {"id": "1708.09250", "submitter": "Niklas Heinsohn", "authors": "Niklas Heinsohn, Michael Kaufmann", "title": "An Interactive Tool to Explore and Improve the Ply Number of Drawings", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a straight-line drawing $\\Gamma$ of a graph $G=(V,E)$, for every vertex\n$v$ the ply disk $D_v$ is defined as a disk centered at $v$ where the radius of\nthe disk is half the length of the longest edge incident to $v$. The ply number\nof a given drawing is defined as the maximum number of overlapping disks at\nsome point in $\\mathbb{R}^2$. Here we present a tool to explore and evaluate\nthe ply number for graphs with instant visual feedback for the user. We\nevaluate our methods in comparison to an existing ply computation by De Luca et\nal. [WALCOM'17]. We are able to reduce the computation time from seconds to\nmilliseconds for given drawings and thereby contribute to further research on\nthe ply topic by providing an efficient tool to examine graphs extensively by\nuser interaction as well as some automatic features to reduce the ply number.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 13:13:24 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Heinsohn", "Niklas", ""], ["Kaufmann", "Michael", ""]]}, {"id": "1708.09253", "submitter": "Dominik Velan", "authors": "Tom\\'a\\v{s} Br\\'azdil, Krishnendu Chatterjee, Anton\\'in Ku\\v{c}era,\n  Petr Novotn\\'y, Dominik Velan", "title": "Efficient Algorithms for Checking Fast Termination in VASS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS cs.FL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Vector Addition Systems with States (VASS) consists of a finite state space\nequipped with d counters, where in each transition every counter is\nincremented, decremented, or left unchanged. VASS provide a fundamental model\nfor analysis of concurrent processes, parametrized systems, and they are also\nused as abstract models for programs for bounds analysis. While termination is\nthe basic liveness property that asks the qualitative question of whether a\ngiven model always terminates or not, the more general quantitative question\nasks for bounds on the number of steps to termination. In the realm of\nquantitative bounds a fundamental problem is to obtain asymptotic bounds on\ntermination time. Large asymptotic bounds such as exponential or higher already\nsuggest that either there is some error in modeling, or the model is not useful\nin practice. Hence we focus on polynomial asymptotic bounds for VASS. While\nsome well-known approaches (e.g., lexicographic ranking functions) are neither\nsound nor complete with respect to polynomial bounds, other approaches only\npresent sound methods for upper bounds. In this work our main contributions are\nas follows: First, for linear asymptotic bounds we present a sound and complete\nmethod for VASS, and moreover, our algorithm runs in polynomial time. Second,\nwe classify VASS according the normals of the vectors of the cycles. We show\nthat singularities in the normal are the key reason for asymptotic bounds such\nas exponential and non-elementary for VASS. In absence of singularities, we\nshow that the asymptotic complexity bound is always polynomial and of the form\n${\\Theta}(n^k)$, for some k $\\leq$ d. We present an algorithm, with time\ncomplexity polynomial in the size of the VASS and exponential in dimension d,\nto compute the optimal k.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 12:29:41 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Novotn\u00fd", "Petr", ""], ["Velan", "Dominik", ""]]}, {"id": "1708.09281", "submitter": "Alessandra Tappini", "authors": "Emilio Di Giacomo, Giuseppe Liotta, Maurizio Patrignani, Ignaz Rutter\n  and Alessandra Tappini", "title": "NodeTrix Planarity Testing with Small Clusters", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the NodeTrix planarity testing problem for flat clustered graphs\nwhen the maximum size of each cluster is bounded by a constant $k$. We consider\nboth the case when the sides of the matrices to which the edges are incident\nare fixed and the case when they can be chosen arbitrarily. We show that\nNodeTrix planarity testing with fixed sides can be solved in\n$O(k^{3k+\\frac{3}{2}} \\cdot n)$ time for every flat clustered graph that can be\nreduced to a partial 2-tree by collapsing its clusters into single vertices. In\nthe general case, NodeTrix planarity testing with fixed sides can be solved in\n$O(n)$ time for $k = 2$, but it is NP-complete for any $k > 2$. NodeTrix\nplanarity testing remains NP-complete also in the free sides model when $k >\n4$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 14:03:27 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 12:39:22 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 20:37:54 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Di Giacomo", "Emilio", ""], ["Liotta", "Giuseppe", ""], ["Patrignani", "Maurizio", ""], ["Rutter", "Ignaz", ""], ["Tappini", "Alessandra", ""]]}, {"id": "1708.09325", "submitter": "Saeed Mehrabi", "authors": "Saeed Mehrabi", "title": "Approximating Weighted Duo-Preservation in Comparative Genomics", "comments": "Appeared in proceedings of the 23rd International Computing and\n  Combinatorics Conference (COCOON 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by comparative genomics, Chen et al. [9] introduced the Maximum\nDuo-preservation String Mapping (MDSM) problem in which we are given two\nstrings $s_1$ and $s_2$ from the same alphabet and the goal is to find a\nmapping $\\pi$ between them so as to maximize the number of duos preserved. A\nduo is any two consecutive characters in a string and it is preserved in the\nmapping if its two consecutive characters in $s_1$ are mapped to same two\nconsecutive characters in $s_2$. The MDSM problem is known to be NP-hard and\nthere are approximation algorithms for this problem [3, 5, 13], but all of them\nconsider only the \"unweighted\" version of the problem in the sense that a duo\nfrom $s_1$ is preserved by mapping to any same duo in $s_2$ regardless of their\npositions in the respective strings. However, it is well-desired in comparative\ngenomics to find mappings that consider preserving duos that are \"closer\" to\neach other under some distance measure [19]. In this paper, we introduce a\ngeneralized version of the problem, called the Maximum-Weight Duo-preservation\nString Mapping (MWDSM) problem that captures both duos-preservation and\nduos-distance measures in the sense that mapping a duo from $s_1$ to each\npreserved duo in $s_2$ has a weight, indicating the \"closeness\" of the two\nduos. The objective of the MWDSM problem is to find a mapping so as to maximize\nthe total weight of preserved duos. In this paper, we give a polynomial-time\n6-approximation algorithm for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 15:25:16 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Mehrabi", "Saeed", ""]]}, {"id": "1708.09398", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow and Cristopher Moore", "title": "Designing Strassen's algorithm", "comments": "This is a simplified, generalized, and self-contained version of\n  Section 5 of arXiv:1612.01527v2 [cs.CC]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1969, Strassen shocked the world by showing that two n x n matrices could\nbe multiplied in time asymptotically less than $O(n^3)$. While the recursive\nconstruction in his algorithm is very clear, the key gain was made by showing\nthat 2 x 2 matrix multiplication could be performed with only 7 multiplications\ninstead of 8. The latter construction was arrived at by a process of\nelimination and appears to come out of thin air. Here, we give the simplest and\nmost transparent proof of Strassen's algorithm that we are aware of, using only\na simple unitary 2-design and a few easy lines of calculation. Moreover, using\nbasic facts from the representation theory of finite groups, we use 2-designs\ncoming from group orbits to generalize our construction to all n (although the\nresulting algorithms aren't optimal for n at least 3).\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 18:00:06 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Moore", "Cristopher", ""]]}, {"id": "1708.09455", "submitter": "Dawood Hasanzadeh", "authors": "Dawood Hasanzadeh and Sama Goliaei", "title": "An algorithm to simulate alternating Turing machine in signal machine", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometrical Computation as a new model of computation is the counterpart of\nCellular Automata that has Turing computing ability. In this paper we provide\nan algorithm to simulate Alternating Turing Machine in the context of Signal\nMachine using techniques adopted from the features of Signal Machine to set up\nand manage the copies/branches of Alternating Turing Machine. We show that our\nalgorithm can simulate Alternating Turing Machine in Signal Machine as same\nfunctionality as classic family of Turing Machines. Time complexity of the\nalgorithm is linear as ordinary simulated Turing Machines. Depending on the\ncomputation tree space complexity is exponential order of d, where d is the\ndepth of the computation tree.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 20:23:29 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Hasanzadeh", "Dawood", ""], ["Goliaei", "Sama", ""]]}, {"id": "1708.09653", "submitter": "Antonios Symvonis", "authors": "Anargyros Oikonomou, Antonios Symvonis", "title": "Simple Compact Monotone Tree Drawings", "comments": "A preliminary version of this paper which included the one-quadrant\n  algorithm for monotone tree drawings was presented in the 25th International\n  Symposium on Graph Drawing and Network Visualization, GD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A monotone drawing of a graph G is a straight-line drawing of G such that\nevery pair of vertices is connected by a path that is monotone with respect to\nsome direction.\n  Trees, as a special class of graphs, have been the focus of several papers\nand, recently, He and He~\\cite{mt:4} showed how to produce a monotone drawing\nof an arbitrary $n$-vertex tree that is contained in a $12n \\times 12n$ grid.\n  All monotone tree drawing algorithms that have appeared in the literature\nconsider rooted ordered trees and they draw them so that (i) the root of the\ntree is drawn at the origin of the drawing, (ii) the drawing is confined in the\nfirst quadrant, and (iii) the ordering/embedding of the tree is respected. In\nthis paper, we provide a simple algorithm that has the exact same\ncharacteristics and, given an $n$-vertex rooted tree $T$, it outputs a monotone\ndrawing of $T$ that fits on a $n \\times n$ grid.\n  For unrooted ordered trees, we present an algorithms that produces monotone\ndrawings that respect the ordering and fit in an $(n+1) \\times (\\frac{n}{2}\n+1)$ grid, while, for unrooted non-ordered trees we produce monotone drawings\nof good aspect ratio which fit on a grid of size at most $\\left\\lfloor\n\\frac{3}{4} \\left(n+2\\right)\\right\\rfloor \\times \\left\\lfloor \\frac{3}{4}\n\\left(n+2\\right)\\right\\rfloor$.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 10:23:36 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 21:31:07 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2018 21:44:44 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Oikonomou", "Anargyros", ""], ["Symvonis", "Antonios", ""]]}, {"id": "1708.09691", "submitter": "Maurizio Patrignani", "authors": "Tiziana Calamoneri and Valentino Di Donato and Diego Mariottini and\n  Maurizio Patrignani", "title": "Visualizing Co-Phylogenetic Reconciliations", "comments": "This paper appears in the Proceedings of the 25th International\n  Symposium on Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hybrid metaphor for the visualization of the reconciliations\nof co-phylogenetic trees, that are mappings among the nodes of two trees. The\ntypical application is the visualization of the co-evolution of hosts and\nparasites in biology. Our strategy combines a space-filling and a node-link\napproach. Differently from traditional methods, it guarantees an unambiguous\nand `downward' representation whenever the reconciliation is time-consistent\n(i.e., meaningful). We address the problem of the minimization of the number of\ncrossings in the representation, by giving a characterization of planar\ninstances and by establishing the complexity of the problem. Finally, we\npropose heuristics for computing representations with few crossings.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 12:58:02 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Calamoneri", "Tiziana", ""], ["Di Donato", "Valentino", ""], ["Mariottini", "Diego", ""], ["Patrignani", "Maurizio", ""]]}, {"id": "1708.09708", "submitter": "Harald Oberhauser", "authors": "Terry Lyons, Harald Oberhauser", "title": "Sketching the order of events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce features for massive data streams. These stream features can be\nthought of as \"ordered moments\" and generalize stream sketches from \"moments of\norder one\" to \"ordered moments of arbitrary order\". In analogy to classic\nmoments, they have theoretical guarantees such as universality that are\nimportant for learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 13:51:03 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Lyons", "Terry", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1708.09827", "submitter": "Klaus-Tycho Foerster", "authors": "Saeed Akhoondian Amiri, Klaus-Tycho Foerster, Stefan Schmid", "title": "Walking Through Waypoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of a fundamental combinatorial problem: Given a\ncapacitated graph $G=(V,E)$, find a shortest walk (\"route\") from a source $s\\in\nV$ to a destination $t\\in V$ that includes all vertices specified by a set\n$\\mathscr{W}\\subseteq V$: the \\emph{waypoints}. This waypoint routing problem\nfinds immediate applications in the context of modern networked distributed\nsystems. Our main contribution is an exact polynomial-time algorithm for graphs\nof bounded treewidth. We also show that if the number of waypoints is\nlogarithmically bounded, exact polynomial-time algorithms exist even for\ngeneral graphs. Our two algorithms provide an almost complete characterization\nof what can be solved exactly in polynomial-time: we show that more general\nproblems (e.g., on grid graphs of maximum degree 3, with slightly more\nwaypoints) are computationally intractable.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 17:28:39 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 14:33:41 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["Foerster", "Klaus-Tycho", ""], ["Schmid", "Stefan", ""]]}, {"id": "1708.09842", "submitter": "Darren Strash", "authors": "Nodari Sitchinava and Darren Strash", "title": "Reconstructing Generalized Staircase Polygons with Uniform Step Length", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visibility graph reconstruction, which asks us to construct a polygon that\nhas a given visibility graph, is a fundamental problem with unknown complexity\n(although visibility graph recognition is known to be in PSPACE). We show that\ntwo classes of uniform step length polygons can be reconstructed efficiently by\nfinding and removing rectangles formed between consecutive convex boundary\nvertices called tabs. In particular, we give an $O(n^2m)$-time reconstruction\nalgorithm for orthogonally convex polygons, where $n$ and $m$ are the number of\nvertices and edges in the visibility graph, respectively. We further show that\nreconstructing a monotone chain of staircases (a histogram) is fixed-parameter\ntractable, when parameterized on the number of tabs, and polynomially solvable\nin time $O(n^2m)$ under reasonable alignment restrictions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 17:47:05 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 15:55:22 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Sitchinava", "Nodari", ""], ["Strash", "Darren", ""]]}]