[{"id": "0810.0052", "submitter": "Martin Ziegler", "authors": "Matthias Fischer, Matthias Hilbig, Claudius J\\\"ahn, Friedhelm Meyer\n  auf der Heide and Martin Ziegler", "title": "Planar Visibility Counting", "comments": "added Section 4: Implementation and Empirical Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a fixed virtual scene (=collection of simplices) S and given observer\nposition p, how many elements of S are weakly visible (i.e. not fully occluded\nby others) from p? The present work explores the trade-off between query time\nand preprocessing space for these quantities in 2D: exactly, in the approximate\ndeterministic, and in the probabilistic sense. We deduce the EXISTENCE of an\nO(m^2/n^2) space data structure for S that, given p and time O(log n), allows\nto approximate the ratio of occluded segments up to arbitrary constant absolute\nerror; here m denotes the size of the Visibility Graph--which may be quadratic,\nbut typically is just linear in the size n of the scene S. On the other hand,\nwe present a data structure CONSTRUCTIBLE in O(n*log(n)+m^2*polylog(n)/k)\npreprocessing time and space with similar approximation properties and query\ntime O(k*polylog n), where k<n is an arbitrary parameter. We describe an\nimplementation of this approach and demonstrate the practical benefit of the\nparameter k to trade memory for query time in an empirical evaluation on three\nclasses of benchmark scenes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2008 01:53:52 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2008 02:43:08 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2009 09:51:22 GMT"}], "update_date": "2009-02-05", "authors_parsed": [["Fischer", "Matthias", ""], ["Hilbig", "Matthias", ""], ["J\u00e4hn", "Claudius", ""], ["der Heide", "Friedhelm Meyer auf", ""], ["Ziegler", "Martin", ""]]}, {"id": "0810.0075", "submitter": "Alvaro Salas Humberto", "authors": "Alvaro Salas (Universidad de Caldas, Universidad Nacional de Colombia,\n  sede Manizales)", "title": "Acerca del Algoritmo de Dijkstra", "comments": "In spanish, the paper contains illustrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove the correctness of Dijkstra's algorithm. We also\ndiscuss it and at the end we show an application.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2008 04:55:11 GMT"}], "update_date": "2008-10-02", "authors_parsed": [["Salas", "Alvaro", "", "Universidad de Caldas, Universidad Nacional de Colombia,\n  sede Manizales"]]}, {"id": "0810.0264", "submitter": "David Musser", "authors": "David R. Musser, Gor V. Nishanov", "title": "A Fast Generic Sequence Matching Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A string matching -- and more generally, sequence matching -- algorithm is\npresented that has a linear worst-case computing time bound, a low worst-case\nbound on the number of comparisons (2n), and sublinear average-case behavior\nthat is better than that of the fastest versions of the Boyer-Moore algorithm.\nThe algorithm retains its efficiency advantages in a wide variety of sequence\nmatching problems of practical interest, including traditional string matching;\nlarge-alphabet problems (as in Unicode strings); and small-alphabet,\nlong-pattern problems (as in DNA searches). Since it is expressed as a generic\nalgorithm for searching in sequences over an arbitrary type T, it is well\nsuited for use in generic software libraries such as the C++ Standard Template\nLibrary. The algorithm was obtained by adding to the Knuth-Morris-Pratt\nalgorithm one of the pattern-shifting techniques from the Boyer-Moore\nalgorithm, with provision for use of hashing in this technique. In situations\nin which a hash function or random access to the sequences is not available,\nthe algorithm falls back to an optimized version of the Knuth-Morris-Pratt\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2008 19:54:51 GMT"}], "update_date": "2008-10-02", "authors_parsed": [["Musser", "David R.", ""], ["Nishanov", "Gor V.", ""]]}, {"id": "0810.0558", "submitter": "Ashish Goel", "authors": "Ashish Goel, Sanjeev Khanna, Brad Null", "title": "The Ratio Index for Budgeted Learning, with Applications", "comments": "This paper has a substantial bug that we are trying to fix. Many\n  thanks to Joe Halpern for pointing this bug out. Please do not cite in the\n  meantime. Please let us know if you would like to understand and/or try to\n  fix the bug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the budgeted learning problem, we are allowed to experiment on a set of\nalternatives (given a fixed experimentation budget) with the goal of picking a\nsingle alternative with the largest possible expected payoff. Approximation\nalgorithms for this problem were developed by Guha and Munagala by rounding a\nlinear program that couples the various alternatives together. In this paper we\npresent an index for this problem, which we call the ratio index, which also\nguarantees a constant factor approximation. Index-based policies have the\nadvantage that a single number (i.e. the index) can be computed for each\nalternative irrespective of all other alternatives, and the alternative with\nthe highest index is experimented upon. This is analogous to the famous Gittins\nindex for the discounted multi-armed bandit problem.\n  The ratio index has several interesting structural properties. First, we show\nthat it can be computed in strongly polynomial time. Second, we show that with\nthe appropriate discount factor, the Gittins index and our ratio index are\nconstant factor approximations of each other, and hence the Gittins index also\ngives a constant factor approximation to the budgeted learning problem.\nFinally, we show that the ratio index can be used to create an index-based\npolicy that achieves an O(1)-approximation for the finite horizon version of\nthe multi-armed bandit problem. Moreover, the policy does not require any\nknowledge of the horizon (whereas we compare its performance against an optimal\nstrategy that is aware of the horizon). This yields the following surprising\nresult: there is an index-based policy that achieves an O(1)-approximation for\nthe multi-armed bandit problem, oblivious to the underlying discount factor.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2008 01:37:45 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2016 18:47:16 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Goel", "Ashish", ""], ["Khanna", "Sanjeev", ""], ["Null", "Brad", ""]]}, {"id": "0810.0674", "submitter": "Shuchi Chawla", "authors": "Siddharth Barman and Shuchi Chawla", "title": "Packing multiway cuts in capacitated graphs", "comments": "The conference version of this paper is to appear at SODA 2009. This\n  is the full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following \"multiway cut packing\" problem in undirected\ngraphs: we are given a graph G=(V,E) and k commodities, each corresponding to a\nset of terminals located at different vertices in the graph; our goal is to\nproduce a collection of cuts {E_1,...,E_k} such that E_i is a multiway cut for\ncommodity i and the maximum load on any edge is minimized. The load on an edge\nis defined to be the number of cuts in the solution crossing the edge. In the\ncapacitated version of the problem the goal is to minimize the maximum relative\nload on any edge--the ratio of the edge's load to its capacity. Multiway cut\npacking arises in the context of graph labeling problems where we are given a\npartial labeling of a set of items and a neighborhood structure over them, and,\ninformally, the goal is to complete the labeling in the most consistent way.\nThis problem was introduced by Rabani, Schulman, and Swamy (SODA'08), who\ndeveloped an O(log n/log log n) approximation for it in general graphs, as well\nas an improved O(log^2 k) approximation in trees. Here n is the number of nodes\nin the graph. We present the first constant factor approximation for this\nproblem in arbitrary undirected graphs. Our approach is based on the\nobservation that every instance of the problem admits a near-optimal laminar\nsolution (that is, one in which no pair of cuts cross each other).\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2008 16:13:00 GMT"}], "update_date": "2008-10-06", "authors_parsed": [["Barman", "Siddharth", ""], ["Chawla", "Shuchi", ""]]}, {"id": "0810.0906", "submitter": "Hirotaka Ono", "authors": "Toru Hasunuma, Toshimasa Ishii, Hirotaka Ono, Yushi Uno", "title": "A linear time algorithm for L(2,1)-labeling of trees", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An L(2,1)-labeling of a graph $G$ is an assignment $f$ from the vertex set\n$V(G)$ to the set of nonnegative integers such that $|f(x)-f(y)|\\ge 2$ if $x$\nand $y$ are adjacent and $|f(x)-f(y)|\\ge 1$ if $x$ and $y$ are at distance 2,\nfor all $x$ and $y$ in $V(G)$. A $k$-L(2,1)-labeling is an assignment\n$f:V(G)\\to\\{0,..., k\\}$, and the L(2,1)-labeling problem asks the minimum $k$,\nwhich we denote by $\\lambda(G)$, among all possible assignments. It is known\nthat this problem is NP-hard even for graphs of treewidth 2, and tree is one of\na very few classes for which the problem is polynomially solvable. The running\ntime of the best known algorithm for trees had been $\\mO(\\Delta^{4.5} n)$ for\nmore than a decade, however, an $\\mO(n^{1.75})$-time algorithm has been\nproposed recently, which substantially improved the previous one, where\n$\\Delta$ is the maximum degree of $T$ and $n=|V(T)|$. In this paper, we finally\nestablish a linear time algorithm for L(2,1)-labeling of trees.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2008 08:21:17 GMT"}, {"version": "v2", "created": "Wed, 24 Nov 2010 07:06:08 GMT"}], "update_date": "2010-11-25", "authors_parsed": [["Hasunuma", "Toru", ""], ["Ishii", "Toshimasa", ""], ["Ono", "Hirotaka", ""], ["Uno", "Yushi", ""]]}, {"id": "0810.1355", "submitter": "Michael Mahoney", "authors": "Jure Leskovec, Kevin J. Lang, Anirban Dasgupta, and Michael W. Mahoney", "title": "Community Structure in Large Networks: Natural Cluster Sizes and the\n  Absence of Large Well-Defined Clusters", "comments": "66 pages, a much expanded version of our WWW 2008 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of work has been devoted to defining and identifying clusters or\ncommunities in social and information networks. We explore from a novel\nperspective several questions related to identifying meaningful communities in\nlarge social and information networks, and we come to several striking\nconclusions. We employ approximation algorithms for the graph partitioning\nproblem to characterize as a function of size the statistical and structural\nproperties of partitions of graphs that could plausibly be interpreted as\ncommunities. In particular, we define the network community profile plot, which\ncharacterizes the \"best\" possible community--according to the conductance\nmeasure--over a wide range of size scales. We study over 100 large real-world\nsocial and information networks. Our results suggest a significantly more\nrefined picture of community structure in large networks than has been\nappreciated previously. In particular, we observe tight communities that are\nbarely connected to the rest of the network at very small size scales; and\ncommunities of larger size scales gradually \"blend into\" the expander-like core\nof the network and thus become less \"community-like.\" This behavior is not\nexplained, even at a qualitative level, by any of the commonly-used network\ngeneration models. Moreover, it is exactly the opposite of what one would\nexpect based on intuition from expander graphs, low-dimensional or\nmanifold-like graphs, and from small social networks that have served as\ntestbeds of community detection algorithms. We have found that a generative\ngraph model, in which new edges are added via an iterative \"forest fire\"\nburning process, is able to produce graphs exhibiting a network community\nprofile plot similar to what we observe in our network datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2008 05:42:43 GMT"}], "update_date": "2008-10-13", "authors_parsed": [["Leskovec", "Jure", ""], ["Lang", "Kevin J.", ""], ["Dasgupta", "Anirban", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "0810.1499", "submitter": "Lenka Zdeborova", "authors": "Lenka Zdeborov\\'a and Marc M\\'ezard", "title": "Constraint satisfaction problems with isolated solutions are hard", "comments": "19 pages, 12 figures", "journal-ref": "J. Stat. Mech. (2008) P12004", "doi": "10.1088/1742-5468/2008/12/P12004", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the phase diagram and the algorithmic hardness of the random\n`locked' constraint satisfaction problems, and compare them to the commonly\nstudied 'non-locked' problems like satisfiability of boolean formulas or graph\ncoloring. The special property of the locked problems is that clusters of\nsolutions are isolated points. This simplifies significantly the determination\nof the phase diagram, which makes the locked problems particularly appealing\nfrom the mathematical point of view. On the other hand we show empirically that\nthe clustered phase of these problems is extremely hard from the algorithmic\npoint of view: the best known algorithms all fail to find solutions. Our\nresults suggest that the easy/hard transition (for currently known algorithms)\nin the locked problems coincides with the clustering transition. These should\nthus be regarded as new benchmarks of really hard constraint satisfaction\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2008 18:28:28 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2008 07:53:25 GMT"}], "update_date": "2008-12-09", "authors_parsed": [["Zdeborov\u00e1", "Lenka", ""], ["M\u00e9zard", "Marc", ""]]}, {"id": "0810.1639", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate", "title": "Identifying almost sorted permutations from TCP buffer dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associate to each sequence $A$ of integers (intending to represent packet\nIDs) a sequence of positive integers of the same length ${\\mathcal M}(A)$. The\n$i$'th entry of ${\\mathcal M}(A)$ is the size (at time $i$) of the smallest\nbuffer needed to hold out-of-order packets, where space is accounted for\nunreceived packets as well. Call two sequences $A$, $B$ {\\em equivalent}\n(written $A\\equiv_{FB} B$) if ${\\mathcal M}(A)={\\mathcal M}(B)$.\n  We prove the following result: any two permutations $A,B$ of the same length\nwith $SUS(A)$, $SUS(B)\\leq 3$ (where SUS is the {\\em shuffled-up-sequences}\nreordering measure), and such that $A\\equiv_{FB} B$ are identical.\n  The result (which is no longer valid if we replace the upper bound 3 by 4)\nwas motivated by RESTORED, a receiver-oriented model of network traffic we have\npreviously introduced.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2008 12:27:32 GMT"}], "update_date": "2008-11-04", "authors_parsed": [["Istrate", "Gabriel", ""]]}, {"id": "0810.1756", "submitter": "Milan Bradonjic", "authors": "Milan Bradonjic, Eddie Kohler, Rafail Ostrovsky", "title": "Near-Optimal Radio Use For Wireless Network Synchronization", "comments": "23 pages", "journal-ref": null, "doi": "10.1016/j.tcs.2011.09.026", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of communication where wireless devices can either\nswitch their radios off to save energy, or switch their radios on and engage in\ncommunication. We distill a clean theoretical formulation of this problem of\nminimizing radio use and present near-optimal solutions. Our base model ignores\nissues of communication interference, although we also extend the model to\nhandle this requirement. We assume that nodes intend to communicate\nperiodically, or according to some time-based schedule. Clearly, perfectly\nsynchronized devices could switch their radios on for exactly the minimum\nperiods required by their joint schedules. The main challenge in the deployment\nof wireless networks is to synchronize the devices' schedules, given that their\ninitial schedules may be offset relative to one another (even if their clocks\nrun at the same speed). We significantly improve previous results, and show\noptimal use of the radio for two processors and near-optimal use of the radio\nfor synchronization of an arbitrary number of processors. In particular, for\ntwo processors we prove deterministically matching $\\Theta(\\sqrt{n})$ upper and\nlower bounds on the number of times the radio has to be on, where $n$ is the\ndiscretized uncertainty period of the clock shift between the two processors.\n(In contrast, all previous results for two processors are randomized.) For\n$m=n^\\beta$ processors (for any $\\beta < 1$) we prove $\\Omega(n^{(1-\\beta)/2})$\nis the lower bound on the number of times the radio has to be switched on (per\nprocessor), and show a nearly matching (in terms of the radio use)\n$\\~{O}(n^{(1-\\beta)/2})$ randomized upper bound per processor, with failure\nprobability exponentially close to 0. For $\\beta \\geq 1$ our algorithm runs\nwith at most $poly-log(n)$ radio invocations per processor. Our bounds also\nhold in a radio-broadcast model where interference must be taken into account.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2008 20:41:23 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2012 22:44:09 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Bradonjic", "Milan", ""], ["Kohler", "Eddie", ""], ["Ostrovsky", "Rafail", ""]]}, {"id": "0810.1823", "submitter": "Christophe Paul", "authors": "Emeric Gioan and Christophe Paul", "title": "Split decomposition and graph-labelled trees: characterizations and\n  fully-dynamic algorithms for totally decomposable graphs", "comments": "extended abstract appeared in ISAAC 2007: Dynamic distance hereditary\n  graphs using split decompositon. In International Symposium on Algorithms and\n  Computation - ISAAC. Number 4835 in Lecture Notes, pages 41-51, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the split decomposition of graphs and give new\ncombinatorial and algorithmic results for the class of totally decomposable\ngraphs, also known as the distance hereditary graphs, and for two non-trivial\nsubclasses, namely the cographs and the 3-leaf power graphs. Precisely, we give\nstrutural and incremental characterizations, leading to optimal fully-dynamic\nrecognition algorithms for vertex and edge modifications, for each of these\nclasses. These results rely on a new framework to represent the split\ndecomposition, namely the graph-labelled trees, which also captures the modular\ndecomposition of graphs and thereby unify these two decompositions techniques.\nThe point of the paper is to use bijections between these graph classes and\ntrees whose nodes are labelled by cliques and stars. Doing so, we are also able\nto derive an intersection model for distance hereditary graphs, which answers\nan open problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2008 07:49:30 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2011 12:53:57 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Gioan", "Emeric", ""], ["Paul", "Christophe", ""]]}, {"id": "0810.1851", "submitter": "Marek Karpinski", "authors": "Piotr Berman, Marek Karpinski, Alex Zelikovsky", "title": "1.25 Approximation Algorithm for the Steiner Tree Problem with Distances\n  One and Two", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a 1.25 approximation algorithm for the Steiner Tree Problem with\ndistances one and two, improving on the best known bound for that problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2008 11:25:09 GMT"}], "update_date": "2008-10-13", "authors_parsed": [["Berman", "Piotr", ""], ["Karpinski", "Marek", ""], ["Zelikovsky", "Alex", ""]]}, {"id": "0810.2150", "submitter": "Christine Task", "authors": "Christine Task, Arun Chauhan", "title": "A Model for Communication in Clusters of Multi-core Machines", "comments": "This paper has been withdrawn by the author because it was basically\n  a short-hand write-up of an incompletely formed idea from her Masters, and\n  she'd like to start using her ArXiv account for her formal PhD research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common paradigm for scientific computing is distributed message-passing\nsystems, and a common approach to these systems is to implement them across\nclusters of high-performance workstations. As multi-core architectures become\nincreasingly mainstream, these clusters are very likely to include multi-core\nmachines. However, the theoretical models which are currently used to develop\ncommunication algorithms across these systems do not take into account the\nunique properties of processes running on shared-memory architectures,\nincluding shared external network connections and communication via shared\nmemory locations. Because of this, existing algorithms are far from optimal for\nmodern clusters. Additionally, recent attempts to adapt these algorithms to\nmulticore systems have proceeded without the introduction of a more accurate\nformal model and have generally neglected to capitalize on the full power these\nsystems offer. We propose a new model which simply and effectively captures the\nstrengths of multi-core machines in collective communications patterns and\nsuggest how it could be used to properly optimize these patterns.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2008 04:04:42 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2012 19:16:37 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Task", "Christine", ""], ["Chauhan", "Arun", ""]]}, {"id": "0810.2390", "submitter": "Simone Faro", "authors": "Simone Faro and Thierry Lecroq", "title": "Efficient Pattern Matching on Binary Strings", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary string matching problem consists in finding all the occurrences of\na pattern in a text where both strings are built on a binary alphabet. This is\nan interesting problem in computer science, since binary data are omnipresent\nin telecom and computer network applications. Moreover the problem finds\napplications also in the field of image processing and in pattern matching on\ncompressed texts. Recently it has been shown that adaptations of classical\nexact string matching algorithms are not very efficient on binary data. In this\npaper we present two efficient algorithms for the problem adapted to completely\navoid any reference to bits allowing to process pattern and text byte by byte.\nExperimental results show that the new algorithms outperform existing solutions\nin most cases.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2008 08:44:27 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2008 12:15:24 GMT"}], "update_date": "2008-10-15", "authors_parsed": [["Faro", "Simone", ""], ["Lecroq", "Thierry", ""]]}, {"id": "0810.3058", "submitter": "Dimitrios Tsolis Dr", "authors": "Dimitrios K. Tsolis, Spyros Sioutas and Theodore S. Papatheodorou", "title": "Watermarking Digital Images Based on a Content Based Image Retrieval\n  Technique", "comments": "18 pages, 4 figures, 4 tables, submitted to Multimedia Tools and\n  Applications Journal, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The current work is focusing on the implementation of a robust watermarking\nalgorithm for digital images, which is based on an innovative spread spectrum\nanalysis algorithm for watermark embedding and on a content-based image\nretrieval technique for watermark detection. The highly robust watermark\nalgorithms are applying \"detectable watermarks\" for which a detection mechanism\nchecks if the watermark exists or no (a Boolean decision) based on a\nwatermarking key. The problem is that the detection of a watermark in a digital\nimage library containing thousands of images means that the watermark detection\nalgorithm is necessary to apply all the keys to the digital images. This\napplication is non-efficient for very large image databases. On the other hand\n\"readable\" watermarks may prove weaker but easier to detect as only the\ndetection mechanism is required. The proposed watermarking algorithm combine's\nthe advantages of both \"detectable\" and \"readable\" watermarks. The result is a\nfast and robust watermarking algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2008 04:22:01 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Tsolis", "Dimitrios K.", ""], ["Sioutas", "Spyros", ""], ["Papatheodorou", "Theodore S.", ""]]}, {"id": "0810.3203", "submitter": "David Harvey", "authors": "David Harvey", "title": "A cache-friendly truncated FFT", "comments": "14 pages, 11 figures, uses algorithm2e package", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a cache-friendly version of van der Hoeven's truncated FFT and\ninverse truncated FFT, focusing on the case of `large' coefficients, such as\nthose arising in the Schonhage--Strassen algorithm for multiplication in Z[x].\nWe describe two implementations and examine their performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2008 17:36:27 GMT"}], "update_date": "2008-10-20", "authors_parsed": [["Harvey", "David", ""]]}, {"id": "0810.3227", "submitter": "Oliver Kennedy", "authors": "Oliver Kennedy, Christoph Koch, Al Demers", "title": "Dynamic Approaches to In-Network Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration between small-scale wireless devices hinges on their ability to\ninfer properties shared across multiple nearby nodes. Wireless-enabled mobile\ndevices in particular create a highly dynamic environment not conducive to\ndistributed reasoning about such global properties. This paper addresses a\nspecific instance of this problem: distributed aggregation. We present\nextensions to existing unstructured aggregation protocols that enable\nestimation of count, sum, and average aggregates in highly dynamic\nenvironments. With the modified protocols, devices with only limited\nconnectivity can maintain estimates of the aggregate, despite\n\\textit{unexpected} peer departures and arrivals. Our analysis of these\naggregate maintenance extensions demonstrates their effectiveness in\nunstructured environments despite high levels of node mobility.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2008 19:48:38 GMT"}], "update_date": "2008-10-20", "authors_parsed": [["Kennedy", "Oliver", ""], ["Koch", "Christoph", ""], ["Demers", "Al", ""]]}, {"id": "0810.3438", "submitter": "Amit Bhosle", "authors": "Amit M Bhosle and Teofilo F Gonzalez", "title": "Efficient Algorithms and Routing Protocols for Handling Transient Single\n  Node Failures", "comments": "6 pages, 2 columns, 3 figures. To appear in: Proceedings of the 20th\n  IASTED International Conference on Parallel and Distributed Computing and\n  Systems (Nov 16-18, 2008, Orlando, FL, USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single node failures represent more than 85% of all node failures in the\ntoday's large communication networks such as the Internet. Also, these node\nfailures are usually transient. Consequently, having the routing paths globally\nrecomputed does not pay off since the failed nodes recover fairly quickly, and\nthe recomputed routing paths need to be discarded. Instead, we develop\nalgorithms and protocols for dealing with such transient single node failures\nby suppressing the failure (instead of advertising it across the network), and\nrouting messages to the destination via alternate paths that do not use the\nfailed node. We compare our solution to that of Ref. [11] wherein the authors\nhave presented a \"Failure Insensitive Routing\" protocol as a proactive recovery\nscheme for handling transient node failures. We show that our algorithms are\nfaster by an order of magnitude while our paths are equally good. We show via\nsimulation results that our paths are usually within 15% of the optimal for\nrandomly generated graph with 100-1000 nodes.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2008 22:57:53 GMT"}], "update_date": "2008-10-21", "authors_parsed": [["Bhosle", "Amit M", ""], ["Gonzalez", "Teofilo F", ""]]}, {"id": "0810.4002", "submitter": "Laetitia Omer", "authors": "Julien Allali (LaBRI), Marie-France Sagot (ENS Lyon / Insa Lyon /\n  INRIA Grenoble Rh\\^one-Alpes)", "title": "A new distance for high level RNA secondary structure comparison", "comments": null, "journal-ref": "IEEE/ACM Transactions on Computational Biology and Bioinformatics\n  2 (2005) 3--14", "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm for comparing two RNA secondary structures coded in\nthe form of trees that introduces two new operations, called node fusion and\nedge fusion, besides the tree edit operations of deletion, insertion, and\nrelabeling classically used in the literature. This allows us to address some\nserious limitations of the more traditional tree edit operations when the trees\nrepresent RNAs and what is searched for is a common structural core of two\nRNAs. Although the algorithm complexity has an exponential term, this term\ndepends only on the number of successive fusions that may be applied to a same\nnode, not on the total number of fusions. The algorithm remains therefore\nefficient in practice and is used for illustrative purposes on ribosomal as\nwell as on other types of RNAs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 08:24:53 GMT"}], "update_date": "2008-10-23", "authors_parsed": [["Allali", "Julien", "", "LaBRI"], ["Sagot", "Marie-France", "", "ENS Lyon / Insa Lyon /\n  INRIA Grenoble Rh\u00f4ne-Alpes"]]}, {"id": "0810.4061", "submitter": "Satu Elisa Schaeffer", "authors": "Pekka Orponen, Satu Elisa Schaeffer, Vanesa Avalos Gayt\\'an", "title": "Locally computable approximations for spectral clustering and absorption\n  times of random walks", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of determining a natural local neighbourhood or\n\"cluster\" associated to a given seed vertex in an undirected graph. We\nformulate the task in terms of absorption times of random walks from other\nvertices to the vertex of interest, and observe that these times are well\napproximated by the components of the principal eigenvector of the\ncorresponding fundamental matrix of the graph's adjacency matrix. We further\npresent a locally computable gradient-descent method to estimate this\nDirichlet-Fiedler vector, based on minimising the respective Rayleigh quotient.\nExperimental evaluation shows that the approximations behave well and yield\nwell-defined local clusters.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 17:48:12 GMT"}], "update_date": "2008-10-23", "authors_parsed": [["Orponen", "Pekka", ""], ["Schaeffer", "Satu Elisa", ""], ["Gayt\u00e1n", "Vanesa Avalos", ""]]}, {"id": "0810.4423", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica", "title": "Efficient Algorithmic Techniques for Several Multidimensional Geometric\n  Data Management and Analysis Problems", "comments": "The algorithmic techniques presented in this paper were later used by\n  the author in developing solutions for algorithmic tasks in several contests\n  in which the author participated (see the attached zip archive for some\n  examples of task statements and solutions). Knowledge Management - Projects,\n  Systems and Technologies, Bucharest : Romania (2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I present several novel, efficient, algorithmic techniques for\nsolving some multidimensional geometric data management and analysis problems.\nThe techniques are based on several data structures from computational geometry\n(e.g. segment tree and range tree) and on the well-known sweep-line method.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2008 09:44:03 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2013 20:58:46 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Andreica", "Mugurel Ionut", ""]]}, {"id": "0810.4796", "submitter": "Daniel Raible", "authors": "Henning Fernau, Fedor V. Fomin, Daniel Lokshtanov, Daniel Raible,\n  Saket Saurabh, Yngve Villanger", "title": "Kernel(s) for Problems With no Kernel: On Out-Trees With Many Leaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\sc $k$-Leaf Out-Branching} problem is to find an out-branching (i.e. a\nrooted oriented spanning tree) with at least $k$ leaves in a given digraph. The\nproblem has recently received much attention from the viewpoint of\nparameterized algorithms {alonLNCS4596,AlonFGKS07fsttcs,BoDo2,KnLaRo}. In this\npaper we step aside and take a kernelization based approach to the {\\sc\n$k$-Leaf-Out-Branching} problem. We give the first polynomial kernel for {\\sc\nRooted $k$-Leaf-Out-Branching}, a variant of {\\sc $k$-Leaf-Out-Branching} where\nthe root of the tree searched for is also a part of the input. Our kernel has\ncubic size and is obtained using extremal combinatorics.\n  For the {\\sc $k$-Leaf-Out-Branching} problem we show that no polynomial\nkernel is possible unless polynomial hierarchy collapses to third level\n%$PH=\\Sigma_p^3$ by applying a recent breakthrough result by Bodlaender et al.\n{BDFH08} in a non-trivial fashion. However our positive results for {\\sc Rooted\n$k$-Leaf-Out-Branching} immediately imply that the seemingly intractable the\n{\\sc $k$-Leaf-Out-Branching} problem admits a data reduction to $n$ independent\n$O(k^3)$ kernels. These two results, tractability and intractability side by\nside, are the first separating {\\it many-to-one kernelization} from {\\it Turing\nkernelization}. This answers affirmatively an open problem regarding \"cheat\nkernelization\" raised in {IWPECOPEN08}.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2008 11:53:47 GMT"}, {"version": "v2", "created": "Thu, 6 Nov 2008 09:17:43 GMT"}], "update_date": "2008-11-06", "authors_parsed": [["Fernau", "Henning", ""], ["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Raible", "Daniel", ""], ["Saurabh", "Saket", ""], ["Villanger", "Yngve", ""]]}, {"id": "0810.4812", "submitter": "Robin Moser", "authors": "Robin A. Moser", "title": "A constructive proof of the Lovasz Local Lemma", "comments": "11 pages; minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lovasz Local Lemma [EL75] is a powerful tool to prove the existence of\ncombinatorial objects meeting a prescribed collection of criteria. The\ntechnique can directly be applied to the satisfiability problem, yielding that\na k-CNF formula in which each clause has common variables with at most 2^(k-2)\nother clauses is always satisfiable. All hitherto known proofs of the Local\nLemma are non-constructive and do thus not provide a recipe as to how a\nsatisfying assignment to such a formula can be efficiently found. In his\nbreakthrough paper [Bec91], Beck demonstrated that if the neighbourhood of each\nclause be restricted to O(2^(k/48)), a polynomial time algorithm for the search\nproblem exists. Alon simplified and randomized his procedure and improved the\nbound to O(2^(k/8)) [Alo91]. Srinivasan presented in [Sri08] a variant that\nachieves a bound of essentially O(2^(k/4)). In [Mos08], we improved this to\nO(2^(k/2)). In the present paper, we give a randomized algorithm that finds a\nsatisfying assignment to every k-CNF formula in which each clause has a\nneighbourhood of at most the asymptotic optimum of 2^(k-5)-1 other clauses and\nthat runs in expected time polynomial in the size of the formula, irrespective\nof k. If k is considered a constant, we can also give a deterministic variant.\nIn contrast to all previous approaches, our analysis does not anymore invoke\nthe standard non-constructive versions of the Local Lemma and can therefore be\nconsidered an alternative, constructive proof of it.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2008 14:02:48 GMT"}, {"version": "v2", "created": "Wed, 29 Oct 2008 14:35:58 GMT"}], "update_date": "2008-10-29", "authors_parsed": [["Moser", "Robin A.", ""]]}, {"id": "0810.4934", "submitter": "Lukasz Kowalik", "authors": "Marek Cygan, Lukasz Kowalik, Marcin Pilipczuk and Mateusz Wykurz", "title": "Exponential-Time Approximation of Hard Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimization problems that are neither approximable in polynomial\ntime (at least with a constant factor) nor fixed parameter tractable, under\nwidely believed complexity assumptions. Specifically, we focus on Maximum\nIndependent Set, Vertex Coloring, Set Cover, and Bandwidth.\n  In recent years, many researchers design exact exponential-time algorithms\nfor these and other hard problems. The goal is getting the time complexity\nstill of order $O(c^n)$, but with the constant $c$ as small as possible. In\nthis work we extend this line of research and we investigate whether the\nconstant $c$ can be made even smaller when one allows constant factor\napproximation. In fact, we describe a kind of approximation schemes --\ntrade-offs between approximation factor and the time complexity.\n  We study two natural approaches. The first approach consists of designing a\nbacktracking algorithm with a small search tree. We present one result of that\nkind: a $(4r-1)$-approximation of Bandwidth in time $O^*(2^{n/r})$, for any\npositive integer $r$.\n  The second approach uses general transformations from exponential-time exact\nalgorithms to approximations that are faster but still exponential-time. For\nexample, we show that for any reduction rate $r$, one can transform any\n$O^*(c^n)$-time algorithm for Set Cover into a $(1+\\ln r)$-approximation\nalgorithm running in time $O^*(c^{n/r})$. We believe that results of that kind\nextend the applicability of exact algorithms for NP-hard problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2008 20:18:00 GMT"}], "update_date": "2008-10-29", "authors_parsed": [["Cygan", "Marek", ""], ["Kowalik", "Lukasz", ""], ["Pilipczuk", "Marcin", ""], ["Wykurz", "Mateusz", ""]]}, {"id": "0810.4946", "submitter": "Gregory Gutin", "authors": "Jean Daligault, Gregory Gutin, Eun Jung Kim, Anders Yeo", "title": "FPT Algorithms and Kernels for the Directed $k$-Leaf Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subgraph $T$ of a digraph $D$ is an {\\em out-branching} if $T$ is an\noriented spanning tree with only one vertex of in-degree zero (called the {\\em\nroot}). The vertices of $T$ of out-degree zero are {\\em leaves}. In the {\\sc\nDirected $k$-Leaf} Problem, we are given a digraph $D$ and an integral\nparameter $k$, and we are to decide whether $D$ has an out-branching with at\nleast $k$ leaves. Recently, Kneis et al. (2008) obtained an algorithm for the\nproblem of running time $4^{k}\\cdot n^{O(1)}$. We describe a new algorithm for\nthe problem of running time $3.72^{k}\\cdot n^{O(1)}$. In {\\sc Rooted Directed\n$k$-Leaf} Problem, apart from $D$ and $k$, we are given a vertex $r$ of $D$ and\nwe are to decide whether $D$ has an out-branching rooted at $r$ with at least\n$k$ leaves. Very recently, Fernau et al. (2008) found an $O(k^3)$-size kernel\nfor {\\sc Rooted Directed $k$-Leaf}. In this paper, we obtain an $O(k)$ kernel\nfor {\\sc Rooted Directed $k$-Leaf} restricted to acyclic digraphs.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2008 21:44:42 GMT"}, {"version": "v2", "created": "Fri, 31 Oct 2008 17:41:51 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2009 07:52:06 GMT"}], "update_date": "2009-08-18", "authors_parsed": [["Daligault", "Jean", ""], ["Gutin", "Gregory", ""], ["Kim", "Eun Jung", ""], ["Yeo", "Anders", ""]]}, {"id": "0810.5064", "submitter": "Travis Gagie", "authors": "Travis Gagie", "title": "A New Algorithm for Building Alphabetic Minimax Trees", "comments": "in preparation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to build an alphabetic minimax tree for a sequence (W = w_1,\n>..., w_n) of real weights in (O (n d \\log \\log n)) time, where $d$ is the\nnumber of distinct integers (\\lceil w_i \\rceil). We apply this algorithm to\nbuilding an alphabetic prefix code given a sample.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2008 15:59:55 GMT"}], "update_date": "2008-10-29", "authors_parsed": [["Gagie", "Travis", ""]]}, {"id": "0810.5263", "submitter": "Andrew Twigg", "authors": "Rahul Sami, Andy Twigg", "title": "Lower bounds for distributed markov chain problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the worst-case communication complexity of distributed algorithms\ncomputing a path problem based on stationary distributions of random walks in a\nnetwork $G$ with the caveat that $G$ is also the communication network. The\nproblem is a natural generalization of shortest path lengths to expected path\nlengths, and represents a model used in many practical applications such as\npagerank and eigentrust as well as other problems involving Markov chains\ndefined by networks.\n  For the problem of computing a single stationary probability, we prove an\n$\\Omega(n^2 \\log n)$ bits lower bound; the trivial centralized algorithm costs\n$O(n^3)$ bits and no known algorithm beats this. We also prove lower bounds for\nthe related problems of approximately computing the stationary probabilities,\ncomputing only the ranking of the nodes, and computing the node with maximal\nrank. As a corollary, we obtain lower bounds for labelling schemes for the\nhitting time between two nodes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2008 12:52:59 GMT"}], "update_date": "2008-10-30", "authors_parsed": [["Sami", "Rahul", ""], ["Twigg", "Andy", ""]]}, {"id": "0810.5428", "submitter": "Amitabha Bagchi", "authors": "Amitabha Bagchi, Garima Lahoti", "title": "Relating Web pages to enable information-gathering tasks", "comments": "In Proceedings of ACM Hypertext 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that relationships between Web pages are functions of the user's\nintent. We identify a class of Web tasks - information-gathering - that can be\nfacilitated by a search engine that provides links to pages which are related\nto the page the user is currently viewing. We define three kinds of intentional\nrelationships that correspond to whether the user is a) seeking sources of\ninformation, b) reading pages which provide information, or c) surfing through\npages as part of an extended information-gathering process. We show that these\nthree relationships can be productively mined using a combination of textual\nand link information and provide three scoring mechanisms that correspond to\nthem: {\\em SeekRel}, {\\em FactRel} and {\\em SurfRel}. These scoring mechanisms\nincorporate both textual and link information. We build a set of capacitated\nsubnetworks - each corresponding to a particular keyword - that mirror the\ninterconnection structure of the World Wide Web. The scores are computed by\ncomputing flows on these subnetworks. The capacities of the links are derived\nfrom the {\\em hub} and {\\em authority} values of the nodes they connect,\nfollowing the work of Kleinberg (1998) on assigning authority to pages in\nhyperlinked environments. We evaluated our scoring mechanism by running\nexperiments on four data sets taken from the Web. We present user evaluations\nof the relevance of the top results returned by our scoring mechanisms and\ncompare those to the top results returned by Google's Similar Pages feature,\nand the {\\em Companion} algorithm proposed by Dean and Henzinger (1999).\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 07:17:49 GMT"}, {"version": "v2", "created": "Wed, 19 May 2010 11:43:29 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Bagchi", "Amitabha", ""], ["Lahoti", "Garima", ""]]}, {"id": "0810.5477", "submitter": "Andrew Twigg", "authors": "Andrew Twigg", "title": "Worst-case time decremental connectivity and k-edge witness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple algorithm for decremental graph connectivity that handles\nedge deletions in worst-case time $O(k \\log n)$ and connectivity queries in\n$O(\\log k)$, where $k$ is the number of edges deleted so far, and uses\nworst-case space $O(m^2)$. We use this to give an algorithm for $k$-edge\nwitness (``does the removal of a given set of $k$ edges disconnect two vertices\n$u,v$?'') with worst-case time $O(k^2 \\log n)$ and space $O(k^2 n^2)$. For $k =\no(\\sqrt{n})$ these improve the worst-case $O(\\sqrt{n})$ bound for deletion due\nto Eppstein et al. We also give a decremental connectivity algorithm using\n$O(n^2 \\log n / \\log \\log n)$ space, whose time complexity depends on the\ntoughness and independence number of the input graph. Finally, we show how to\nconstruct a distributed data structure for \\kvw by giving a labeling scheme.\nThis is the first data structure for \\kvw that can efficiently distributed\nwithout just giving each vertex a copy of the whole structure. Its complexity\ndepends on being able to construct a linear layout with good properties.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 12:15:33 GMT"}], "update_date": "2008-10-31", "authors_parsed": [["Twigg", "Andrew", ""]]}, {"id": "0810.5573", "submitter": "David Correa Martins Jr", "authors": "Marcelo Ris, Junior Barrera, David C. Martins Jr", "title": "A branch-and-bound feature selection algorithm for U-shaped cost\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents the formulation of a combinatorial optimization problem\nwith the following characteristics: i.the search space is the power set of a\nfinite set structured as a Boolean lattice; ii.the cost function forms a\nU-shaped curve when applied to any lattice chain. This formulation applies for\nfeature selection in the context of pattern recognition. The known approaches\nfor this problem are branch-and-bound algorithms and heuristics, that explore\npartially the search space. Branch-and-bound algorithms are equivalent to the\nfull search, while heuristics are not. This paper presents a branch-and-bound\nalgorithm that differs from the others known by exploring the lattice structure\nand the U-shaped chain curves of the search space. The main contribution of\nthis paper is the architecture of this algorithm that is based on the\nrepresentation and exploration of the search space by new lattice properties\nproven here. Several experiments, with well known public data, indicate the\nsuperiority of the proposed method to SFFS, which is a popular heuristic that\ngives good results in very short computational time. In all experiments, the\nproposed method got better or equal results in similar or even smaller\ncomputational time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 20:24:28 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Ris", "Marcelo", ""], ["Barrera", "Junior", ""], ["Martins", "David C.", "Jr"]]}, {"id": "0810.5578", "submitter": "Shubha Nabar", "authors": "Tomas Feder, Shubha U. Nabar, Evimaria Terzi", "title": "Anonymizing Graphs", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recently discovered privacy attacks on social networks, we study\nthe problem of anonymizing the underlying graph of interactions in a social\nnetwork. We call a graph (k,l)-anonymous if for every node in the graph there\nexist at least k other nodes that share at least l of its neighbors. We\nconsider two combinatorial problems arising from this notion of anonymity in\ngraphs. More specifically, given an input graph we ask for the minimum number\nof edges to be added so that the graph becomes (k,l)-anonymous. We define two\nvariants of this minimization problem and study their properties. We show that\nfor certain values of k and l the problems are polynomial-time solvable, while\nfor others they become NP-hard. Approximation algorithms for the latter cases\nare also given.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 21:12:25 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Feder", "Tomas", ""], ["Nabar", "Shubha U.", ""], ["Terzi", "Evimaria", ""]]}, {"id": "0810.5582", "submitter": "Shubha Nabar", "authors": "Rajeev Motwani, Shubha U. Nabar", "title": "Anonymizing Unstructured Data", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of anonymizing datasets in which each\nindividual is associated with a set of items that constitute private\ninformation about the individual. Illustrative datasets include market-basket\ndatasets and search engine query logs. We formalize the notion of k-anonymity\nfor set-valued data as a variant of the k-anonymity model for traditional\nrelational datasets. We define an optimization problem that arises from this\ndefinition of anonymity and provide O(klogk) and O(1)-approximation algorithms\nfor the same. We demonstrate applicability of our algorithms to the America\nOnline query log dataset.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2008 19:25:02 GMT"}, {"version": "v2", "created": "Mon, 3 Nov 2008 23:33:20 GMT"}], "update_date": "2008-11-04", "authors_parsed": [["Motwani", "Rajeev", ""], ["Nabar", "Shubha U.", ""]]}, {"id": "0810.5685", "submitter": "Daniel Roche", "authors": "Mark Giesbrecht and Daniel S. Roche", "title": "Interpolation of Shifted-Lacunary Polynomials", "comments": "22 pages, to appear in Computational Complexity", "journal-ref": "Computational Complexity, Vol. 19, No 3., pp. 333-354, 2010", "doi": "10.1007/s00037-010-0294-0", "report-no": null, "categories": "cs.SC cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a \"black box\" function to evaluate an unknown rational polynomial f in\nQ[x] at points modulo a prime p, we exhibit algorithms to compute the\nrepresentation of the polynomial in the sparsest shifted power basis. That is,\nwe determine the sparsity t, the shift s (a rational), the exponents 0 <= e1 <\ne2 < ... < et, and the coefficients c1,...,ct in Q\\{0} such that f(x) =\nc1(x-s)^e1+c2(x-s)^e2+...+ct(x-s)^et. The computed sparsity t is absolutely\nminimal over any shifted power basis. The novelty of our algorithm is that the\ncomplexity is polynomial in the (sparse) representation size, and in particular\nis logarithmic in deg(f). Our method combines previous celebrated results on\nsparse interpolation and computing sparsest shifts, and provides a way to\nhandle polynomials with extremely high degree which are, in some sense, sparse\nin information.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2008 13:35:08 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2008 00:39:28 GMT"}, {"version": "v3", "created": "Mon, 10 Nov 2008 18:33:23 GMT"}, {"version": "v4", "created": "Thu, 11 Dec 2008 04:05:14 GMT"}, {"version": "v5", "created": "Fri, 4 Dec 2009 06:10:58 GMT"}, {"version": "v6", "created": "Mon, 23 Aug 2010 16:20:07 GMT"}], "update_date": "2010-12-06", "authors_parsed": [["Giesbrecht", "Mark", ""], ["Roche", "Daniel S.", ""]]}]