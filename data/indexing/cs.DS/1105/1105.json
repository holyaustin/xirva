[{"id": "1105.0007", "submitter": "Marvin Weinstein", "authors": "Marvin Weinstein, Assa Auerbach, V. Ravi Chandra", "title": "Reducing Memory Cost of Exact Diagonalization using Singular Value\n  Decomposition", "comments": "7 pages, 8 figures", "journal-ref": "Phys. Rev. E 84, 056701 (2011)", "doi": "10.1103/PhysRevE.84.056701", "report-no": null, "categories": "cond-mat.str-el cond-mat.stat-mech cs.DS hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modified Lanczos algorithm to diagonalize lattice Hamiltonians\nwith dramatically reduced memory requirements, {\\em without restricting to\nvariational ansatzes}. The lattice of size $N$ is partitioned into two\nsubclusters. At each iteration the Lanczos vector is projected into two sets of\n$n_{{\\rm svd}}$ smaller subcluster vectors using singular value decomposition.\nFor low entanglement entropy $S_{ee}$, (satisfied by short range Hamiltonians),\nthe truncation error is expected to vanish as $\\exp(-n_{{\\rm\nsvd}}^{1/S_{ee}})$. Convergence is tested for the Heisenberg model on Kagom\\'e\nclusters of 24, 30 and 36 sites, with no lattice symmetries exploited, using\nless than 15GB of dynamical memory. Generalization of the Lanczos-SVD algorithm\nto multiple partitioning is discussed, and comparisons to other techniques are\ngiven.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 20:00:09 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2011 12:10:42 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Weinstein", "Marvin", ""], ["Auerbach", "Assa", ""], ["Chandra", "V. Ravi", ""]]}, {"id": "1105.0187", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Sasmita Tripathy", "title": "An Improved Move-To-Front(IMTF) Off-line Algorithm for the List\n  Accessing Problem", "comments": "6 pages, 4 Figures", "journal-ref": "International Journal of Advanced Computing and\n  Communications(IJACC), January, 2011, Vol. 3, No. 1, pp-19-24", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the List Accessing Problem, Move-To-Front(MTF) algorithm has been proved\nto be the best performing online list accessing algorithm till date in the\nliterature[10]. In this paper, we have made a comprehensive analysis of MTF\nalgorithm and developed an Improved-MTF (IMTF) offline algorithm. We have\ngenerated two new types of data set and devise a new method of experimental\nanalysis for our proposed algorithm. Our experimental analysis shows that IMTF\nis performing better than MTF algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2011 17:17:17 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Tripathy", "Sasmita", ""]]}, {"id": "1105.0232", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Online Assignment Algorithms for Dynamic Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the problem of assigning weights to edges incrementally\nin a dynamic complete bipartite graph consisting of producer and consumer\nnodes. The objective is to minimize the overall cost while satisfying certain\nconstraints. The cost and constraints are functions of attributes of the edges,\nnodes and online service requests. Novelty of this work is that it models\nreal-time distributed resource allocation using an approach to solve this\ntheoretical problem. This paper studies variants of this assignment problem\nwhere the edges, producers and consumers can disappear and reappear or their\nattributes can change over time. Primal-Dual algorithms are used for solving\nthese problems and their competitive ratios are evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 02:09:05 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1105.0233", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Derandomization of Online Assignment Algorithms for Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes different online algorithms for the problem of assigning\nweights to edges in a fully-connected bipartite graph that minimizes the\noverall cost while satisfying constraints. Edges in this graph may disappear\nand reappear over time. Performance of these algorithms is measured using\nsimulations. This paper also attempts to derandomize the randomized online\nalgorithm for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 02:13:24 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1105.0464", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis", "title": "Improved Low-rank Matrix Decompositions via the Subsampled Randomized\n  Hadamard Transform", "comments": "This paper has been withdrawn; an updated study is available by\n  Boutsidis and Gittens: http://arxiv.org/abs/1204.0062", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We comment on two randomized algorithms for constructing low-rank matrix\ndecompositions. Both algorithms employ the Subsampled Randomized Hadamard\nTransform [14]. The first algorithm appeared recently in [9]; here, we provide\na novel analysis that significantly improves the approximation bound obtained\nin [9]. A preliminary version of the second algorithm appeared in [7]; here, we\npresent a mild modification of this algorithm that achieves the same\napproximation bound but significantly improves the corresponding running time.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 01:39:02 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2012 19:33:59 GMT"}, {"version": "v3", "created": "Tue, 3 Apr 2012 05:32:02 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Boutsidis", "Christos", ""]]}, {"id": "1105.0477", "submitter": "Bingkai Lin", "authors": "Bingkai Lin and Yijia Chen", "title": "The parameterized complexity of k-edge induced subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that finding a $k$-edge induced subgraph is fixed-parameter\ntractable, thereby answering an open problem of Leizhen Cai. Our algorithm is\nbased on several combinatorial observations, Gauss' famous \\emph{Eureka}\ntheorem [Andrews, 86], and a generalization of the well-known fpt-algorithm for\nthe model-checking problem for first-order logic on graphs with locally bounded\ntree-width due to Frick and Grohe [Frick and Grohe, 01]. On the other hand, we\nshow that two natural counting versions of the problem are hard. Hence, the\n$k$-edge induced subgraph problem is one of the rare known examples in\nparameterized complexity that are easy for decision while hard for counting.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 05:25:14 GMT"}, {"version": "v2", "created": "Tue, 10 May 2011 05:56:49 GMT"}, {"version": "v3", "created": "Tue, 1 May 2012 01:33:14 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Lin", "Bingkai", ""], ["Chen", "Yijia", ""]]}, {"id": "1105.0479", "submitter": "Shailesh Vaya", "authors": "Shailesh Vaya", "title": "Faster Gossiping in Bidirectional Radio Networks with Large Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unknown ad-hoc radio networks, when the underlying network is\nbidirectional and nodes can have polynomially large labels. For this model, we\npresent a deterministic protocol for gossiping which takes $O(n \\lg^2 n \\lg \\lg\nn)$ rounds. This improves upon the previous best result for deterministic\ngossiping for this model by [Gasienec, Potapov, Pagourtizis, Deterministic\nGossiping in Radio Networks with Large labels, ESA (2002)], who present a\nprotocol of round complexity $O(n \\lg^3 n \\lg \\lg n)$ for this problem. This\nresolves open problem posed in [Gasienec, Efficient gossiping in radio\nnetworks, SIROCCO (2009)], who cite bridging gap between lower and upper bounds\nfor this problem as an important objective. We emphasize that a salient feature\nof our protocol is its simplicity, especially with respect to the previous best\nknown protocol for this problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 06:06:15 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Vaya", "Shailesh", ""]]}, {"id": "1105.0608", "submitter": "Bang Ye Wu", "authors": "Bang Ye Wu", "title": "A simpler and more efficient algorithm for the next-to-shortest path\n  problem", "comments": "Partial result appeared in COCOA2010", "journal-ref": null, "doi": "10.1007/s00453-011-9601-7", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph $G=(V,E)$ with positive edge lengths and two\nvertices $s$ and $t$, the next-to-shortest path problem is to find an $st$-path\nwhich length is minimum amongst all $st$-paths strictly longer than the\nshortest path length. In this paper we show that the problem can be solved in\nlinear time if the distances from $s$ and $t$ to all other vertices are given.\nParticularly our new algorithm runs in $O(|V|\\log |V|+|E|)$ time for general\ngraphs, which improves the previous result of $O(|V|^2)$ time for sparse\ngraphs, and takes only linear time for unweighted graphs, planar graphs, and\ngraphs with positive integer edge lengths.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 15:27:00 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Wu", "Bang Ye", ""]]}, {"id": "1105.0624", "submitter": "Jost Neigenfind", "authors": "Jost Neigenfind and Sergio Grimbs and Zoran Nikoloski", "title": "Biochemical network decomposition reveals absolute concentration\n  robustness", "comments": "46 pages, 13 figures, 2 tables, 93 equations This paper has been\n  withdrawn by the author due to complete rework", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.DS math.AC math.CA math.CO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of biochemical systems has become one of the central questions in\nSystems Biology, although it is notoriously difficult to formally capture its\nmultifaceted nature. Maintenance of normal system function depends not only on\nthe stoichiometry of the underlying interrelated components, but also on a\nmultitude of kinetic parameters. For given parameter values, recent findings\nhave aimed at characterizing the property of the system components to exhibit\nsame concentrations in the resulting steady states, termed absolute\nconcentration robustness (ACR). However, the existing method for determining\nsystem components exhibiting ACR is applicable only to one class of mass-action\nnetworks for which this property can be confirmed, but not discarded. Here we\ndesign a new method which relies on biochemical network decompositions into\nsubnetworks, called elementary flux modes, to identify ACR in a broader class\nof mass-action networks by using only the given stoichiometry. This approach\nreduces the problem of determining ACR to that of solving parameterized systems\nof linear equations, rendering it amenable to networks of larger sizes. Our\nunified framework will be helpful in analyzing this biologically important type\nof robustness as well as detection of novel systemic properties independent of\nthe kinetic parameters for more complex biochemical networks.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 16:22:25 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 09:37:59 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Neigenfind", "Jost", ""], ["Grimbs", "Sergio", ""], ["Nikoloski", "Zoran", ""]]}, {"id": "1105.0697", "submitter": "Manuel Gomez Rodriguez", "authors": "Manuel Gomez Rodriguez, David Balduzzi, Bernhard Sch\\\"olkopf", "title": "Uncovering the Temporal Dynamics of Diffusion Networks", "comments": "To appear in the 28th International Conference on Machine Learning\n  (ICML), 2011. Website: http://www.stanford.edu/~manuelgr/netrate/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time plays an essential role in the diffusion of information, influence and\ndisease over networks. In many cases we only observe when a node copies\ninformation, makes a decision or becomes infected -- but the connectivity,\ntransmission rates between nodes and transmission sources are unknown.\nInferring the underlying dynamics is of outstanding interest since it enables\nforecasting, influencing and retarding infections, broadly construed. To this\nend, we model diffusion processes as discrete networks of continuous temporal\nprocesses occurring at different rates. Given cascade data -- observed\ninfection times of nodes -- we infer the edges of the global diffusion network\nand estimate the transmission rates of each edge that best explain the observed\ndata. The optimization problem is convex. The model naturally (without\nheuristics) imposes sparse solutions and requires no parameter tuning. The\nproblem decouples into a collection of independent smaller problems, thus\nscaling easily to networks on the order of hundreds of thousands of nodes.\nExperiments on real and synthetic data show that our algorithm both recovers\nthe edges of diffusion networks and accurately estimates their transmission\nrates from cascade data.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 21:49:54 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Rodriguez", "Manuel Gomez", ""], ["Balduzzi", "David", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1105.0709", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis", "title": "Topics in Matrix Sampling Algorithms", "comments": "PhD Thesis, 150 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three fundamental problems of Linear Algebra, lying in the heart of\nvarious Machine Learning applications, namely: 1)\"Low-rank Column-based Matrix\nApproximation\". We are given a matrix A and a target rank k. The goal is to\nselect a subset of columns of A and, by using only these columns, compute a\nrank k approximation to A that is as good as the rank k approximation that\nwould have been obtained by using all the columns; 2) \"Coreset Construction in\nLeast-Squares Regression\". We are given a matrix A and a vector b. Consider the\n(over-constrained) least-squares problem of minimizing ||Ax-b||, over all\nvectors x in D. The domain D represents the constraints on the solution and can\nbe arbitrary. The goal is to select a subset of the rows of A and b and, by\nusing only these rows, find a solution vector that is as good as the solution\nvector that would have been obtained by using all the rows; 3) \"Feature\nSelection in K-means Clustering\". We are given a set of points described with\nrespect to a large number of features. The goal is to select a subset of the\nfeatures and, by using only this subset, obtain a k-partition of the points\nthat is as good as the partition that would have been obtained by using all the\nfeatures. We present novel algorithms for all three problems mentioned above.\nOur results can be viewed as follow-up research to a line of work known as\n\"Matrix Sampling Algorithms\". [Frieze, Kanna, Vempala, 1998] presented the\nfirst such algorithm for the Low-rank Matrix Approximation problem. Since then,\nsuch algorithms have been developed for several other problems, e.g. Graph\nSparsification and Linear Equation Solving. Our contributions to this line of\nresearch are: (i) improved algorithms for Low-rank Matrix Approximation and\nRegression (ii) algorithms for a new problem domain (K-means Clustering).\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 00:19:49 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Boutsidis", "Christos", ""]]}, {"id": "1105.0791", "submitter": "Sandor P. Fekete", "authors": "Erin Wolf Chambers, S\\'andor P. Fekete, Hella-Franziska Hoffmann,\n  Dimitri Marinakis, Joseph S.B. Mitchell, Venkatesh Srinivasan, Ulrike Stege,\n  Sue Whitesides", "title": "Connecting a Set of Circles with Minimum Sum of Radii", "comments": "21 pages, 15 figures, full version of extended abstract that appeared\n  in Proceedings of the 12th Algorithms and Data Structures Symposium (WADS\n  2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of assigning radii to a given set of points in the\nplane, such that the resulting set of circles is connected, and the sum of\nradii is minimized. We show that the problem is polynomially solvable if a\nconnectivity tree is given. If the connectivity tree is unknown, the problem is\nNP-hard if there are upper bounds on the radii and open otherwise. We give\napproximation guarantees for a variety of polynomial-time algorithms, describe\nupper and lower bounds (which are matching in some of the cases), provide\npolynomial-time approximation schemes, and conclude with experimental results\nand open problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 11:13:46 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2016 18:31:20 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Chambers", "Erin Wolf", ""], ["Fekete", "S\u00e1ndor P.", ""], ["Hoffmann", "Hella-Franziska", ""], ["Marinakis", "Dimitri", ""], ["Mitchell", "Joseph S. B.", ""], ["Srinivasan", "Venkatesh", ""], ["Stege", "Ulrike", ""], ["Whitesides", "Sue", ""]]}, {"id": "1105.1071", "submitter": "Yunlei Zhao", "authors": "Andrew C. Yao, Yunlei Zhao", "title": "A New Family of Practical Non-Malleable Diffie-Hellman Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptography algorithm standards play a key role both to the practice of\ninformation security and to cryptography theory research. Among them, the MQV\nand HMQV protocols ((H)MQV, in short) are a family of (implicitly\nauthenticated) Diffie-Hellman key-exchange (DHKE) protocols that are widely\nstandardized and deployed. In this work, from some new perspectives and\napproaches and under some new design rationales and insights, we develop a new\nfamily of practical implicitly authenticated DHKE protocols, which enjoy\nnotable performance among security, privacy, efficiency and easy deployment. We\nmake detailed comparisons between our new DHKE protocols and (H)MQV, showing\nthat the newly developed protocols outperform HMQV in most aspects. Along the\nway, guided by our new design rationales, we also identify a new vulnerability\n(H)MQV, which brings some new perspectives (e.g., computational fairness) to\nthe literature.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 13:39:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 06:46:35 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2011 14:38:10 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2011 03:33:45 GMT"}, {"version": "v5", "created": "Mon, 19 Dec 2011 02:14:48 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Yao", "Andrew C.", ""], ["Zhao", "Yunlei", ""]]}, {"id": "1105.1109", "submitter": "Thu-Hien To", "authors": "Michel Habib and Thu-Hien To", "title": "On a conjecture of compatibility of multi-states characters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perfect phylogeny consisting of determining the compatibility of a set of\ncharacters is known to be NP-complete. We propose in this article a conjecture\non the necessary and sufficient conditions of compatibility: Given a set\n$\\mathcal{C}$ of $r$-states full characters, there exists a function $f(r)$\nsuch that $\\mathcal{C}$ is compatible iff every set of $f(r)$ characters of\n$\\mathcal{C}$ is compatible. Some previous work showed that $f(2)=2$, $f(3)=3$\nand $f(r) \\ge r-1$. Gusfield et al. 09 conjectured that $f(r) = r$ for any $r\n\\ge 2$. In this paper, we present an example showing that $f(4) \\ge 5$ and then\na closure operation for chordal sandwich graphs. The later problem is a common\napproach of perfect phylogeny. This operation can be the first step to simplify\nthe problem before solving some particular cases $f(4), f(5), ... $, and\ndetermining the function $f(r)$.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 15:58:02 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Habib", "Michel", ""], ["To", "Thu-Hien", ""]]}, {"id": "1105.1178", "submitter": "Daniel Tarlow", "authors": "Daniel Tarlow, Inmar E. Givoni, Richard S. Zemel, Brendan J. Frey", "title": "Interpreting Graph Cuts as a Max-Product Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum a posteriori (MAP) configuration of binary variable models with\nsubmodular graph-structured energy functions can be found efficiently and\nexactly by graph cuts. Max-product belief propagation (MP) has been shown to be\nsuboptimal on this class of energy functions by a canonical counterexample\nwhere MP converges to a suboptimal fixed point (Kulesza & Pereira, 2008).\n  In this work, we show that under a particular scheduling and damping scheme,\nMP is equivalent to graph cuts, and thus optimal. We explain the apparent\ncontradiction by showing that with proper scheduling and damping, MP always\nconverges to an optimal fixed point. Thus, the canonical counterexample only\nshows the suboptimality of MP with a particular suboptimal choice of schedule\nand damping. With proper choices, MP is optimal.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 21:24:37 GMT"}], "update_date": "2012-02-19", "authors_parsed": [["Tarlow", "Daniel", ""], ["Givoni", "Inmar E.", ""], ["Zemel", "Richard S.", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1105.1261", "submitter": "Robin Scheibler", "authors": "Robin Scheibler, Paul Hurley, Amina Chebira", "title": "Pruned Continuous Haar Transform of 2D Polygonal Patterns with\n  Application to VLSI Layouts", "comments": "4 pages, 5 figures, 1 algorithm", "journal-ref": "R. Scheibler, P. Hurley, and A. Chebira, \"Pruned Continuous Haar\n  Transform of 2D Polygonal Patterns with Application to VLSI Layouts,\" Proc.\n  of the 2010 IRAST Int. Cong. on Comp. App. and Computational Sci. (CACS\n  2010), pp. 984--987, 2010", "doi": null, "report-no": null, "categories": "cs.CE cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm for the efficient computation of the continuous\nHaar transform of 2D patterns that can be described by polygons. These patterns\nare ubiquitous in VLSI processes where they are used to describe design and\nmask layouts. There, speed is of paramount importance due to the magnitude of\nthe problems to be solved and hence very fast algorithms are needed. We show\nthat by techniques borrowed from computational geometry we are not only able to\ncompute the continuous Haar transform directly, but also to do it quickly. This\nis achieved by massively pruning the transform tree and thus dramatically\ndecreasing the computational load when the number of vertices is small, as is\nthe case for VLSI layouts. We call this new algorithm the pruned continuous\nHaar transform. We implement this algorithm and show that for patterns found in\nVLSI layouts the proposed algorithm was in the worst case as fast as its\ndiscrete counterpart and up to 12 times faster.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 10:46:32 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Scheibler", "Robin", ""], ["Hurley", "Paul", ""], ["Chebira", "Amina", ""]]}, {"id": "1105.1325", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Elena Grigorescu, Prasad Raghavendra, Asaf\n  Shapira", "title": "Testing Odd-Cycle-Freeness in Boolean Functions", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Call a function f : F_2^n -> {0,1} odd-cycle-free if there are no x_1, ...,\nx_k in F_2^n with k an odd integer such that f(x_1) = ... = f(x_k) = 1 and x_1\n+ ... + x_k = 0. We show that one can distinguish odd-cycle-free functions from\nthose eps-far from being odd-cycle-free by making poly(1/eps) queries to an\nevaluation oracle. To obtain this result, we use connections between basic\nFourier analysis and spectral graph theory to show that one can reduce testing\nodd-cycle-freeness of Boolean functions to testing bipartiteness of dense\ngraphs. Our work forms part of a recent sequence of works that shows\nconnections between testability of properties of Boolean functions and of graph\nproperties. We also prove that there is a canonical tester for\nodd-cycle-freeness making poly(1/eps) queries, meaning that the testing\nalgorithm operates by picking a random linear subspace of dimension O(log\n1/eps) and then checking if the restriction of the function to the subspace is\nodd-cycle-free or not. The test is analyzed by studying the effect of random\nsubspace restriction on the Fourier coefficients of a function. Our work\nimplies that testing odd-cycle-freeness using a canonical tester instead of an\narbitrary tester incurs no more than a polynomial blowup in the query\ncomplexity. The question of whether a canonical tester with polynomial blowup\nexists for all linear-invariant properties remains an open problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 16:48:34 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Grigorescu", "Elena", ""], ["Raghavendra", "Prasad", ""], ["Shapira", "Asaf", ""]]}, {"id": "1105.1370", "submitter": "Massimo Callisto De Donato", "authors": "Massimo Callisto De Donato (1) and Maria Rita Di Berardini (1) ((1)\n  Scuola di Scienze e Tecnologie, Sezione Informatica. Universit\\`a di\n  Camerino)", "title": "A Framework for the Evaluation of Worst-Case System Efficiency", "comments": "5 Pages. In ICTCS 2010: 12th Italian Conference on Theoretical\n  Computer Science, University of Camerino, Camerino, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present FASE (Fast Asynchronous Systems Evaluation), a tool\nfor evaluating worst-case efficiency of asynchronous systems. This tool\nimplements some well-established results in the setting of a timed CCS-like\nprocess algebra: PAFAS (a Process Algebra for Faster Asynchronous Systems).\nMoreover, we discuss some new solutions that are useful to improve the\napplicability of FASE to concrete meaningful examples. We finally use fase to\nevaluate the efficiency of three different implementations of a bounded buffer\nand compare our results with previous ones obtained when the same\nimplementations have been contrasted according to an efficiency preorder.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 10:56:23 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["De Donato", "Massimo Callisto", ""], ["Di Berardini", "Maria Rita", ""]]}, {"id": "1105.1569", "submitter": "Bala Chandran", "authors": "Bala G. Chandran and Dorit S. Hochbaum", "title": "Practical and theoretical improvements for bipartite matching using the\n  pseudoflow algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the pseudoflow algorithm for maximum flow is particularly\nefficient for the bipartite matching problem both in theory and in practice. We\ndevelop several implementations of the pseudoflow algorithm for bipartite\nmatching, and compare them over a wide set of benchmark instances to\nstate-of-the-art implementations of push-relabel and augmenting path algorithms\nthat are specifically designed to solve these problems. The experiments show\nthat the pseudoflow variants are in most cases faster than the other\nalgorithms.\n  We also show that one particular implementation---the matching pseudoflow\nalgorithm---is theoretically efficient. For a graph with $n$ nodes, $m$ arcs,\n$n_1$ the size of the smaller set in the bipartition, and the maximum matching\nvalue $\\kappa \\leq n_1$, the algorithm's complexity given input in the form of\nadjacency lists is $O(\\min{n_1\\kappa,m} + \\sqrt{\\kappa}\\min{\\kappa^2,m})$.\nSimilar algorithmic ideas are shown to work for an adaptation of Hopcroft and\nKarp's bipartite matching algorithm with the same complexity. Using boolean\noperations on words of size $\\lambda$, the complexity of the pseudoflow\nalgorithm is further improved to $O(\\min{n_1\\kappa, \\frac{n_1n_2}{\\lambda}, m}\n+ \\kappa^2 + \\frac{\\kappa^{2.5}}{\\lambda})$. This run time is faster than for\nprevious algorithms such as Cheriyan and Mehlhorn's algorithm of complexity\n$O(\\frac{n^{2.5}}{\\lambda})$.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 02:03:40 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Chandran", "Bala G.", ""], ["Hochbaum", "Dorit S.", ""]]}, {"id": "1105.1622", "submitter": "Gianluca De Marco", "authors": "Gianluca De Marco and Evangelos Kranakis and Gabor Wiener", "title": "Computing Majority with Triple Queries", "comments": "22 pages, 1 figure, conference version to appear in proceedings of\n  the 17th Annual International Computing and Combinatorics Conference (COCOON\n  2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a bin containing $n$ balls colored with two colors. In a $k$-query,\n$k$ balls are selected by a questioner and the oracle's reply is related\n(depending on the computation model being considered) to the distribution of\ncolors of the balls in this $k$-tuple; however, the oracle never reveals the\ncolors of the individual balls. Following a number of queries the questioner is\nsaid to determine the majority color if it can output a ball of the majority\ncolor if it exists, and can prove that there is no majority if it does not\nexist. We investigate two computation models (depending on the type of replies\nbeing allowed). We give algorithms to compute the minimum number of 3-queries\nwhich are needed so that the questioner can determine the majority color and\nprovide tight and almost tight upper and lower bounds on the number of queries\nneeded in each case.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 10:26:01 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["De Marco", "Gianluca", ""], ["Kranakis", "Evangelos", ""], ["Wiener", "Gabor", ""]]}, {"id": "1105.1842", "submitter": "Francois Le Gall", "authors": "Francois Le Gall and Yuichi Yoshida", "title": "Property Testing for Cyclic Groups and Beyond", "comments": "15 pages, full version of a paper to appear in the proceedings of\n  COCOON'11. v2: Ref. [14] added and a few modifications to Appendix A done", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of testing if an input (Gamma,*), where Gamma\nis a finite set of unknown size and * is a binary operation over Gamma given as\nan oracle, is close to a specified class of groups. Friedl et al. [Efficient\ntesting of groups, STOC'05] have constructed an efficient tester using\npoly(log|Gamma|) queries for the class of abelian groups. We focus in this\npaper on subclasses of abelian groups, and show that these problems are much\nharder: Omega(|Gamma|^{1/6}) queries are necessary to test if the input is\nclose to a cyclic group, and Omega(|Gamma|^c) queries for some constant c are\nnecessary to test more generally if the input is close to an abelian group\ngenerated by k elements, for any fixed integer k>0. We also show that knowledge\nof the size of the ground set Gamma helps only for k=1, in which case we\nconstruct an efficient tester using poly(log|Gamma|) queries; for any other\nvalue k>1 the query complexity remains Omega(|Gamma|^c). All our upper and\nlower bounds hold for both the edit distance and the Hamming distance. These\nare, to the best of our knowledge, the first nontrivial lower bounds for such\ngroup-theoretic problems in the property testing model and, in particular, they\nimply the first exponential separations between the classical and quantum query\ncomplexities of testing closeness to classes of groups.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 01:56:06 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2011 06:55:42 GMT"}], "update_date": "2011-08-05", "authors_parsed": [["Gall", "Francois Le", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1105.2003", "submitter": "Justin Thaler", "authors": "Graham Cormode, Michael Mitzenmacher, Justin Thaler", "title": "Practical Verified Computation with Streaming Interactive Proofs", "comments": "39 pages, 12 figures, 2 tables. Accepted to ITCS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 17:34:25 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 18:17:03 GMT"}, {"version": "v3", "created": "Fri, 12 Aug 2011 15:20:31 GMT"}, {"version": "v4", "created": "Fri, 25 Nov 2011 22:14:11 GMT"}, {"version": "v5", "created": "Mon, 13 Feb 2012 02:36:57 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cormode", "Graham", ""], ["Mitzenmacher", "Michael", ""], ["Thaler", "Justin", ""]]}, {"id": "1105.2040", "submitter": "Chandra Chekuri", "authors": "Chandra Chekuri and Alina Ene", "title": "Submodular Cost Allocation Problem and Applications", "comments": "Extended abstract to appear in Proceedings of ICALP, July 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Minimum Submodular-Cost Allocation problem (MSCA). In this\nproblem we are given a finite ground set $V$ and $k$ non-negative submodular\nset functions $f_1 ,..., f_k$ on $V$. The objective is to partition $V$ into\n$k$ (possibly empty) sets $A_1 ,..., A_k$ such that the sum $\\sum_{i=1}^k\nf_i(A_i)$ is minimized. Several well-studied problems such as the non-metric\nfacility location problem, multiway-cut in graphs and hypergraphs, and uniform\nmetric labeling and its generalizations can be shown to be special cases of\nMSCA. In this paper we consider a convex-programming relaxation obtained via\nthe Lov\\'asz-extension for submodular functions. This allows us to understand\nseveral previous relaxations and rounding procedures in a unified fashion and\nalso develop new formulations and approximation algorithms for several\nproblems. In particular, we give a $(1.5 - 1/k)$-approximation for the\nhypergraph multiway partition problem. We also give a $\\min\\{2(1-1/k),\nH_{\\Delta}\\}$-approximation for the hypergraph multiway cut problem when\n$\\Delta$ is the maximum hyperedge size. Both problems generalize the multiway\ncut problem in graphs and the hypergraph cut problem is approximation\nequivalent to the node-weighted multiway cut problem in graphs.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 20:04:24 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Chekuri", "Chandra", ""], ["Ene", "Alina", ""]]}, {"id": "1105.2048", "submitter": "Chandra Chekuri", "authors": "Chandra Chekuri and Alina Ene", "title": "Approximation Algorithms for Submodular Multiway Partition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for the Submodular Multiway Partition problem (SubMP). An\ninstance of SubMP consists of a finite ground set $V$, a subset of $k$ elements\n$S = \\{s_1,s_2,...,s_k\\}$ called terminals, and a non-negative submodular set\nfunction $f:2^V\\rightarrow \\mathbb{R}_+$ on $V$ provided as a value oracle. The\ngoal is to partition $V$ into $k$ sets $A_1,...,A_k$ such that for $1 \\le i \\le\nk$, $s_i \\in A_i$ and $\\sum_{i=1}^k f(A_i)$ is minimized. SubMP generalizes\nsome well-known problems such as the Multiway Cut problem in graphs and\nhypergraphs, and the Node-weighed Multiway Cut problem in graphs. SubMP for\narbitrarysubmodular functions (instead of just symmetric functions) was\nconsidered by Zhao, Nagamochi and Ibaraki \\cite{ZhaoNI05}. Previous algorithms\nwere based on greedy splitting and divide and conquer strategies. In very\nrecent work \\cite{ChekuriE11} we proposed a convex-programming relaxation for\nSubMP based on the Lov\\'asz-extension of a submodular function and showed its\napplicability for some special cases. In this paper we obtain the following\nresults for arbitrary submodular functions via this relaxation. (i) A\n2-approximation for SubMP. This improves the $(k-1)$-approximation from\n\\cite{ZhaoNI05} and (ii) A $(1.5-1/k)$-approximation for SubMP when $f$ is\nsymmetric. This improves the $2(1-1/k)$-approximation from\n\\cite{Queyranne99,ZhaoNI05}.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 20:22:08 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Chekuri", "Chandra", ""], ["Ene", "Alina", ""]]}, {"id": "1105.2228", "submitter": "Shay Mozes", "authors": "Glencora Borradaile, Philip N. Klein, Shay Mozes, Yahav Nussbaum,\n  Christian Wulff-Nilsen", "title": "Multiple-Source Multiple-Sink Maximum Flow in Directed Planar Graphs in\n  Near-Linear Time", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an O(n log^3 n) algorithm that, given an n-node directed planar graph\nwith arc capacities, a set of source nodes, and a set of sink nodes, finds a\nmaximum flow from the sources to the sinks. Previously, the fastest algorithms\nknown for this problem were those for general graphs.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 15:56:42 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Borradaile", "Glencora", ""], ["Klein", "Philip N.", ""], ["Mozes", "Shay", ""], ["Nussbaum", "Yahav", ""], ["Wulff-Nilsen", "Christian", ""]]}, {"id": "1105.2391", "submitter": "Hyung-Chan An", "authors": "Hyung-Chan An and David B. Shmoys", "title": "LP-Based Approximation Algorithms for Traveling Salesman Path Problems", "comments": "This paper has been merged into 1110.4604", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been merged into 1110.4604.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 07:30:50 GMT"}, {"version": "v2", "created": "Fri, 20 May 2011 00:36:55 GMT"}, {"version": "v3", "created": "Mon, 20 Jun 2011 19:40:18 GMT"}, {"version": "v4", "created": "Fri, 28 Oct 2011 02:30:33 GMT"}], "update_date": "2011-10-31", "authors_parsed": [["An", "Hyung-Chan", ""], ["Shmoys", "David B.", ""]]}, {"id": "1105.2397", "submitter": "Siddhartha Sen", "authors": "Bernhard Haeupler, Telikepalli Kavitha, Rogers Mathew, Siddhartha Sen,\n  Robert Endre Tarjan", "title": "Incremental Cycle Detection, Topological Ordering, and Strong Component\n  Maintenance", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two on-line algorithms for maintaining a topological order of a\ndirected $n$-vertex acyclic graph as arcs are added, and detecting a cycle when\none is created. Our first algorithm handles $m$ arc additions in $O(m^{3/2})$\ntime. For sparse graphs ($m/n = O(1)$), this bound improves the best previous\nbound by a logarithmic factor, and is tight to within a constant factor among\nalgorithms satisfying a natural {\\em locality} property. Our second algorithm\nhandles an arbitrary sequence of arc additions in $O(n^{5/2})$ time. For\nsufficiently dense graphs, this bound improves the best previous bound by a\npolynomial factor. Our bound may be far from tight: we show that the algorithm\ncan take $\\Omega(n^2 2^{\\sqrt{2\\lg n}})$ time by relating its performance to a\ngeneralization of the $k$-levels problem of combinatorial geometry. A\ncompletely different algorithm running in $\\Theta(n^2 \\log n)$ time was given\nrecently by Bender, Fineman, and Gilbert. We extend both of our algorithms to\nthe maintenance of strong components, without affecting the asymptotic time\nbounds.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 07:57:28 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Kavitha", "Telikepalli", ""], ["Mathew", "Rogers", ""], ["Sen", "Siddhartha", ""], ["Tarjan", "Robert Endre", ""]]}, {"id": "1105.2434", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt, Evangelos Markakis", "title": "Diffusion in Social Networks with Competing Products", "comments": "13 pages. Appeared in Proc. 4th International Symposium on\n  Algorithmic Game Theory, (SAGT 2011), Lecture Notes in Computer Science 6982,\n  Springer, pp. 212-223", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new threshold model of social networks, in which the nodes\ninfluenced by their neighbours can adopt one out of several alternatives. We\ncharacterize the graphs for which adoption of a product by the whole network is\npossible (respectively necessary) and the ones for which a unique outcome is\nguaranteed. These characterizations directly yield polynomial time algorithms\nthat allow us to determine whether a given social network satisfies one of the\nabove properties.\n  We also study algorithmic questions for networks without unique outcomes. We\nshow that the problem of computing the minimum possible spread of a product is\nNP-hard to approximate with an approximation ratio better than $\\Omega(n)$, in\ncontrast to the maximum spread, which is efficiently computable. We then move\non to questions regarding the behavior of a node with respect to adopting some\n(resp. a given) product. We show that the problem of determining whether a\ngiven node has to adopt some (resp. a given) product in all final networks is\nco-NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 11:44:58 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 07:14:54 GMT"}, {"version": "v3", "created": "Thu, 26 Apr 2012 15:04:25 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Apt", "Krzysztof R.", ""], ["Markakis", "Evangelos", ""]]}, {"id": "1105.2525", "submitter": "Dirk Oliver Theis", "authors": "Kathrin Ballerstein and Dirk Oliver Theis", "title": "An algorithm for random signed 3-SAT with Intervals", "comments": "30 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In signed k-SAT problems, one fixes a set M and a set $\\mathcal S$ of subsets\nof M, and is given a formula consisting of a disjunction of m clauses, each of\nwhich is a conjunction of k literals. Each literal is of the form \"$x \\in S$\",\nwhere $S \\in \\mathcal S$, and x is one of n variables.\n  For Interval-SAT (iSAT), M is an ordered set and $\\mathcal S$ the set of\nintervals in M.\n  We propose an algorithm for 3-iSAT, and analyze it on uniformly random\nformulas. The algorithm follows the Unit Clause paradigm, enhanced by a (very\nlimited) backtracking option. Using Wormald's ODE method, we prove that, if\n$m/n \\le 2.3$, with high probability, our algorithm succeeds in finding an\nassignment of values to the variables satisfying the formula.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 16:34:59 GMT"}, {"version": "v2", "created": "Sun, 15 May 2011 15:16:44 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2013 19:49:41 GMT"}], "update_date": "2013-08-15", "authors_parsed": [["Ballerstein", "Kathrin", ""], ["Theis", "Dirk Oliver", ""]]}, {"id": "1105.2686", "submitter": "Heiko R\\\"oglin", "authors": "Tobias Brunsch, Heiko R\\\"oglin, Cyriel Rutten, Tjark Vredeveld", "title": "Smoothed Performance Guarantees for Local Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study popular local search and greedy algorithms for scheduling. The\nperformance guarantee of these algorithms is well understood, but the\nworst-case lower bounds seem somewhat contrived and it is questionable if they\narise in practical applications. To find out how robust these bounds are, we\nstudy the algorithms in the framework of smoothed analysis, in which instances\nare subject to some degree of random noise.\n  While the lower bounds for all scheduling variants with restricted machines\nare rather robust, we find out that the bounds are fragile for unrestricted\nmachines. In particular, we show that the smoothed performance guarantee of the\njump and the lex-jump algorithm are (in contrast to the worst case) independent\nof the number of machines. They are Theta(phi) and Theta(log(phi)),\nrespectively, where 1/phi is a parameter measuring the magnitude of the\nperturbation. The latter immediately implies that also the smoothed price of\nanarchy is Theta(log(phi)) for routing games on parallel links. Additionally we\nshow that for unrestricted machines also the greedy list scheduling algorithm\nhas an approximation guarantee of Theta(log(phi)).\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 11:04:11 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 15:15:13 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Brunsch", "Tobias", ""], ["R\u00f6glin", "Heiko", ""], ["Rutten", "Cyriel", ""], ["Vredeveld", "Tjark", ""]]}, {"id": "1105.2704", "submitter": "Gwena\\\"el Joret", "authors": "Gwena\\\"el Joret, Christophe Paul, Ignasi Sau, Saket Saurabh, and\n  St\\'ephan Thomass\\'e", "title": "Hitting and Harvesting Pumpkins", "comments": "v2: several minor changes", "journal-ref": "SIAM Journal on Discrete Mathematics, 103/1:1363--1390, 2014", "doi": "10.1137/120883736", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"c-pumpkin\" is the graph with two vertices linked by c>0 parallel edges.\nA c-pumpkin-model in a graph G is a pair A,B of disjoint subsets of vertices of\nG, each inducing a connected subgraph of G, such that there are at least c\nedges in G between A and B. We focus on covering and packing c-pumpkin-models\nin a given graph: On the one hand, we provide an FPT algorithm running in time\n2^O(k) n^O(1) deciding, for any fixed c>0, whether all c-pumpkin-models can be\ncovered by at most k vertices. This generalizes known single-exponential FPT\nalgorithms for Vertex Cover and Feedback Vertex Set, which correspond to the\ncases c=1,2 respectively. On the other hand, we present a O(log\nn)-approximation algorithm for both the problems of covering all\nc-pumpkin-models with a smallest number of vertices, and packing a maximum\nnumber of vertex-disjoint c-pumpkin-models.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 12:21:17 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2013 06:48:36 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Joret", "Gwena\u00ebl", ""], ["Paul", "Christophe", ""], ["Sau", "Ignasi", ""], ["Saurabh", "Saket", ""], ["Thomass\u00e9", "St\u00e9phan", ""]]}, {"id": "1105.2769", "submitter": "Dongryeol Lee", "authors": "Dongryeol Lee, Arkadas Ozakin, and Alexander G. Gray", "title": "Multibody Multipole Methods", "comments": "To appear in Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2012.06.027", "report-no": null, "categories": "physics.comp-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A three-body potential function can account for interactions among triples of\nparticles which are uncaptured by pairwise interaction functions such as\nCoulombic or Lennard-Jones potentials. Likewise, a multibody potential of order\n$n$ can account for interactions among $n$-tuples of particles uncaptured by\ninteraction functions of lower orders. To date, the computation of multibody\npotential functions for a large number of particles has not been possible due\nto its $O(N^n)$ scaling cost. In this paper we describe a fast tree-code for\nefficiently approximating multibody potentials that can be factorized as\nproducts of functions of pairwise distances. For the first time, we show how to\nderive a Barnes-Hut type algorithm for handling interactions among more than\ntwo particles. Our algorithm uses two approximation schemes: 1) a deterministic\nseries expansion-based method; 2) a Monte Carlo-based approximation based on\nthe central limit theorem. Our approach guarantees a user-specified bound on\nthe absolute or relative error in the computed potential with an asymptotic\nprobability guarantee. We provide speedup results on a three-body dispersion\npotential, the Axilrod-Teller potential.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 16:31:21 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 00:35:41 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2012 16:20:47 GMT"}, {"version": "v4", "created": "Wed, 25 Jan 2012 15:30:13 GMT"}, {"version": "v5", "created": "Mon, 11 Jun 2012 15:53:05 GMT"}, {"version": "v6", "created": "Tue, 26 Jun 2012 13:38:14 GMT"}, {"version": "v7", "created": "Sat, 30 Jun 2012 15:00:44 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Lee", "Dongryeol", ""], ["Ozakin", "Arkadas", ""], ["Gray", "Alexander G.", ""]]}, {"id": "1105.2942", "submitter": "Thore Husfeldt", "authors": "Thore Husfeldt", "title": "Invitation to Algorithmic Uses of Inclusion-Exclusion", "comments": "Invited talk at ICALP 2011, 18 pages, 10 figures. To appear in\n  Proceedings of the 38th International Colloquium on Automata, Languages and\n  Programming (ICALP 2011), Z\\\"urich, Switzerland, July 4-8, 2011, Part II,\n  Springer LNCS 6756, 2011, pages 42-59", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I give an introduction to algorithmic uses of the principle of\ninclusion-exclusion. The presentation is intended to be be concrete and\naccessible, at the expense of generality and comprehensiveness.\n", "versions": [{"version": "v1", "created": "Sun, 15 May 2011 12:22:43 GMT"}, {"version": "v2", "created": "Tue, 17 May 2011 12:11:27 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Husfeldt", "Thore", ""]]}, {"id": "1105.3234", "submitter": "Louis Theran", "authors": "Matthew Berardi, Brent Heeringa, Justin Malestein, and Louis Theran", "title": "Rigid components in fixed-lattice and cone frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 21:59:49 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Berardi", "Matthew", ""], ["Heeringa", "Brent", ""], ["Malestein", "Justin", ""], ["Theran", "Louis", ""]]}, {"id": "1105.3748", "submitter": "Ravishankar Krishnaswamy", "authors": "Anupam Gupta, Ravishankar Krishnaswamy, Kirk Pruhs", "title": "Scalably Scheduling Power-Heterogeneous Processors", "comments": "A preliminary version appeared in ICALP 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a natural online algorithm for scheduling jobs on a\nheterogeneous multiprocessor, with arbitrary power functions, is scalable for\nthe objective function of weighted flow plus energy.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 20:51:32 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Gupta", "Anupam", ""], ["Krishnaswamy", "Ravishankar", ""], ["Pruhs", "Kirk", ""]]}, {"id": "1105.3770", "submitter": "Benny Sudakov", "authors": "Yuval Peres, Dimitry Sotnikov, Benny Sudakov, Uri Zwick", "title": "All-Pairs Shortest Paths in $O(n^2)$ time with high probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an all-pairs shortest path algorithm whose running time on a\ncomplete directed graph on $n$ vertices whose edge weights are chosen\nindependently and uniformly at random from $[0,1]$ is $O(n^2)$, in expectation\nand with high probability. This resolves a long standing open problem. The\nalgorithm is a variant of the dynamic all-pairs shortest paths algorithm of\nDemetrescu and Italiano. The analysis relies on a proof that the number of\n\\emph{locally shortest paths} in such randomly weighted graphs is $O(n^2)$, in\nexpectation and with high probability. We also present a dynamic version of the\nalgorithm that recomputes all shortest paths after a random edge update in\n$O(\\log^{2}n)$ expected time.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 00:42:48 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Peres", "Yuval", ""], ["Sotnikov", "Dimitry", ""], ["Sudakov", "Benny", ""], ["Zwick", "Uri", ""]]}, {"id": "1105.3829", "submitter": "Alexander Alekseychuk Dr.-Ing.", "authors": "Alexander Alekseychuk", "title": "Hierarchical Recursive Running Median", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, the histogram-based running median filter of Perreault and H\\'ebert\nis considered the fastest for 8-bit images, being roughly O(1) in average case.\nWe present here another approximately constant time algorithm which further\nimproves the aforementioned one and exhibits lower associated constant, being\nat the time of writing the lowest theoretical complexity algorithm for\ncalculation of 2D and higher dimensional median filters. The algorithm scales\nnaturally to higher precision (e.g. 16-bit) integer data without any\nmodifications. Its adaptive version offers additional speed-up for images\nshowing compact modes in gray-value distribution. The experimental comparison\nto the previous constant-time algorithm defines the application domain of this\nnew development, besides theoretical interest, as high bit depth data and/or\nhardware without SIMD extensions. The C/C++ implementation of the algorithm is\navailable under GPL for research purposes.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 09:50:31 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 12:58:15 GMT"}, {"version": "v3", "created": "Mon, 16 Jan 2012 22:27:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Alekseychuk", "Alexander", ""]]}, {"id": "1105.4204", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury, Daniel Sage, and Michael Unser", "title": "Fast O(1) bilateral filtering using trigonometric range kernels", "comments": "Accepted in IEEE Transactions on Image Processing. Also see addendum:\n  https://sites.google.com/site/kunalspage/home/Addendum.pdf", "journal-ref": "IEEE Transactions on Image Processing, vol. 20(12), pp. 3376 -\n  3382, 2011", "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that spatial averaging can be realized (in space or\nfrequency domain) using algorithms whose complexity does not depend on the size\nor shape of the filter. These fast algorithms are generally referred to as\nconstant-time or O(1) algorithms in the image processing literature. Along with\nthe spatial filter, the edge-preserving bilateral filter [Tomasi1998] involves\nan additional range kernel. This is used to restrict the averaging to those\nneighborhood pixels whose intensity are similar or close to that of the pixel\nof interest. The range kernel operates by acting on the pixel intensities. This\nmakes the averaging process non-linear and computationally intensive,\nespecially when the spatial filter is large. In this paper, we show how the\nO(1) averaging algorithms can be leveraged for realizing the bilateral filter\nin constant-time, by using trigonometric range kernels. This is done by\ngeneralizing the idea in [Porikli2008] of using polynomial range kernels. The\nclass of trigonometric kernels turns out to be sufficiently rich, allowing for\nthe approximation of the standard Gaussian bilateral filter. The attractive\nfeature of our approach is that, for a fixed number of terms, the quality of\napproximation achieved using trigonometric kernels is much superior to that\nobtained in [Porikli2008] using polynomials.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 01:44:38 GMT"}, {"version": "v2", "created": "Thu, 26 May 2011 01:50:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2011 17:33:32 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Sage", "Daniel", ""], ["Unser", "Michael", ""]]}, {"id": "1105.4250", "submitter": "Zeev Nutov", "authors": "Zeev Nutov", "title": "Approximating subset $k$-connectivity problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subset $T \\subseteq V$ of terminals is $k$-connected to a root $s$ in a\ndirected/undirected graph $J$ if $J$ has $k$ internally-disjoint $vs$-paths for\nevery $v \\in T$; $T$ is $k$-connected in $J$ if $T$ is $k$-connected to every\n$s \\in T$. We consider the {\\sf Subset $k$-Connectivity Augmentation} problem:\ngiven a graph $G=(V,E)$ with edge/node-costs, node subset $T \\subseteq V$, and\na subgraph $J=(V,E_J)$ of $G$ such that $T$ is $k$-connected in $J$, find a\nminimum-cost augmenting edge-set $F \\subseteq E \\setminus E_J$ such that $T$ is\n$(k+1)$-connected in $J \\cup F$. The problem admits trivial ratio $O(|T|^2)$.\nWe consider the case $|T|>k$ and prove that for directed/undirected graphs and\nedge/node-costs, a $\\rho$-approximation for {\\sf Rooted Subset $k$-Connectivity\nAugmentation} implies the following ratios for {\\sf Subset $k$-Connectivity\nAugmentation}: (i) $b(\\rho+k) + {(\\frac{3|T|}{|T|-k})}^2\nH(\\frac{3|T|}{|T|-k})$; (ii) $\\rho \\cdot O(\\frac{|T|}{|T|-k} \\log k)$, where\nb=1 for undirected graphs and b=2 for directed graphs, and $H(k)$ is the $k$th\nharmonic number. The best known values of $\\rho$ on undirected graphs are\n$\\min\\{|T|,O(k)\\}$ for edge-costs and $\\min\\{|T|,O(k \\log |T|)\\}$ for\nnode-costs; for directed graphs $\\rho=|T|$ for both versions. Our results imply\nthat unless $k=|T|-o(|T|)$, {\\sf Subset $k$-Connectivity Augmentation} admits\nthe same ratios as the best known ones for the rooted version. This improves\nthe ratios in \\cite{N-focs,L}.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 11:55:36 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Nutov", "Zeev", ""]]}, {"id": "1105.4372", "submitter": "Madhur Tulsiani", "authors": "Madhur Tulsiani and Julia Wolf", "title": "Quadratic Goldreich-Levin Theorems", "comments": null, "journal-ref": null, "doi": "10.1137/12086827X", "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition theorems in classical Fourier analysis enable us to express a\nbounded function in terms of few linear phases with large Fourier coefficients\nplus a part that is pseudorandom with respect to linear phases. The\nGoldreich-Levin algorithm can be viewed as an algorithmic analogue of such a\ndecomposition as it gives a way to efficiently find the linear phases\nassociated with large Fourier coefficients.\n  In the study of \"quadratic Fourier analysis\", higher-degree analogues of such\ndecompositions have been developed in which the pseudorandomness property is\nstronger but the structured part correspondingly weaker. For example, it has\npreviously been shown that it is possible to express a bounded function as a\nsum of a few quadratic phases plus a part that is small in the $U^3$ norm,\ndefined by Gowers for the purpose of counting arithmetic progressions of length\n4. We give a polynomial time algorithm for computing such a decomposition.\n  A key part of the algorithm is a local self-correction procedure for\nReed-Muller codes of order 2 (over $\\F_2^n$) for a function at distance\n$1/2-\\epsilon$ from a codeword. Given a function $f:\\F_2^n \\to \\{-1,1\\}$ at\nfractional Hamming distance $1/2-\\epsilon$ from a quadratic phase (which is a\ncodeword of Reed-Muller code of order 2), we give an algorithm that runs in\ntime polynomial in $n$ and finds a codeword at distance at most $1/2-\\eta$ for\n$\\eta = \\eta(\\epsilon)$. This is an algorithmic analogue of Samorodnitsky's\nresult, which gave a tester for the above problem. To our knowledge, it\nrepresents the first instance of a correction procedure for any class of codes,\nbeyond the list-decoding radius.\n  In the process, we give algorithmic versions of results from additive\ncombinatorics used in Samorodnitsky's proof and a refined version of the\ninverse theorem for the Gowers $U^3$ norm over $\\F_2^n$.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2011 21:13:32 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Tulsiani", "Madhur", ""], ["Wolf", "Julia", ""]]}, {"id": "1105.4490", "submitter": "Bas Fagginger Auer", "authors": "B. O. Fagginger Auer and R. H. Bisseling", "title": "A Geometric Approach to Matrix Ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recursive way to partition hypergraphs which creates and\nexploits hypergraph geometry and is suitable for many-core parallel\narchitectures. Such partitionings are then used to bring sparse matrices in a\nrecursive Bordered Block Diagonal form (for processor-oblivious parallel LU\ndecomposition) or recursive Separated Block Diagonal form (for cache-oblivious\nsparse matrix-vector multiplication). We show that the quality of the obtained\npartitionings and orderings is competitive by comparing obtained fill-in for LU\ndecomposition with SuperLU (with better results for 8 of the 28 test matrices)\nand comparing cut sizes for sparse matrix-vector multiplication with Mondriaan\n(with better results for 4 of the 12 test matrices). The main advantage of the\nnew method is its speed: it is on average 21.6 times faster than Mondriaan.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 13:14:30 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Auer", "B. O. Fagginger", ""], ["Bisseling", "R. H.", ""]]}, {"id": "1105.4593", "submitter": "Rico Zenklusen", "authors": "Chandra Chekuri, Jan Vondr\\'ak, Rico Zenklusen", "title": "Submodular Function Maximization via the Multilinear Relaxation and\n  Contention Resolution Schemes", "comments": "Revision of previous version; extended abstract appeared at STOC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a non-negative submodular set function\n$f:2^N \\rightarrow \\mathbb{R}_+$ over a ground set $N$ subject to a variety of\npacking type constraints including (multiple) matroid constraints, knapsack\nconstraints, and their intersections. In this paper we develop a general\nframework that allows us to derive a number of new results, in particular when\n$f$ may be a non-monotone function. Our algorithms are based on (approximately)\nmaximizing the multilinear extension $F$ of $f$ over a polytope $P$ that\nrepresents the constraints, and then effectively rounding the fractional\nsolution. Although this approach has been used quite successfully, it has been\nlimited in some important ways. We overcome these limitations as follows.\n  First, we give constant factor approximation algorithms to maximize $F$ over\na down-closed polytope $P$ described by an efficient separation oracle.\nPreviously this was known only for monotone functions. For non-monotone\nfunctions, a constant factor was known only when the polytope was either the\nintersection of a fixed number of knapsack constraints or a matroid polytope.\nSecond, we show that contention resolution schemes are an effective way to\nround a fractional solution, even when $f$ is non-monotone. In particular,\ncontention resolution schemes for different polytopes can be combined to handle\nthe intersection of different constraints. Via LP duality we show that a\ncontention resolution scheme for a constraint is related to the correlation gap\nof weighted rank functions of the constraint. This leads to an optimal\ncontention resolution scheme for the matroid polytope.\n  Our results provide a broadly applicable framework for maximizing linear and\nsubmodular functions subject to independence constraints. We give several\nillustrative examples. Contention resolution schemes may find other\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 19:38:56 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2011 01:11:19 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2012 16:23:23 GMT"}, {"version": "v4", "created": "Tue, 22 Jul 2014 20:20:13 GMT"}, {"version": "v5", "created": "Wed, 13 Aug 2014 12:38:18 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Chekuri", "Chandra", ""], ["Vondr\u00e1k", "Jan", ""], ["Zenklusen", "Rico", ""]]}, {"id": "1105.4924", "submitter": "Guangliang Chen", "authors": "William K. Allard, Guangliang Chen, and Mauro Maggioni", "title": "Multiscale Geometric Methods for Data Sets II: Geometric\n  Multi-Resolution Analysis", "comments": "Re-formatted using AMS style", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sets are often modeled as point clouds in $R^D$, for $D$ large. It is\noften assumed that the data has some interesting low-dimensional structure, for\nexample that of a $d$-dimensional manifold $M$, with $d$ much smaller than $D$.\nWhen $M$ is simply a linear subspace, one may exploit this assumption for\nencoding efficiently the data by projecting onto a dictionary of $d$ vectors in\n$R^D$ (for example found by SVD), at a cost $(n+D)d$ for $n$ data points. When\n$M$ is nonlinear, there are no \"explicit\" constructions of dictionaries that\nachieve a similar efficiency: typically one uses either random dictionaries, or\ndictionaries obtained by black-box optimization. In this paper we construct\ndata-dependent multi-scale dictionaries that aim at efficient encoding and\nmanipulating of the data. Their construction is fast, and so are the algorithms\nthat map data points to dictionary coefficients and vice versa. In addition,\ndata points are guaranteed to have a sparse representation in terms of the\ndictionary. We think of dictionaries as the analogue of wavelets, but for\napproximating point clouds rather than functions.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 03:13:39 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 18:41:30 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2011 03:33:33 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Allard", "William K.", ""], ["Chen", "Guangliang", ""], ["Maggioni", "Mauro", ""]]}, {"id": "1105.4953", "submitter": "Sylvain Corlay", "authors": "Sylvain Corlay (LPMA)", "title": "A fast nearest neighbor search algorithm based on vector quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a new fast nearest neighbor search algorithm,\nbased on vector quantization. Like many other branch and bound search\nalgorithms [1,10], a preprocessing recursively partitions the data set into\ndisjointed subsets until the number of points in each part is small enough. In\ndoing so, a search-tree data structure is built. This preliminary recursive\ndata-set partition is based on the vector quantization of the empirical\ndistribution of the initial data-set. Unlike previously cited methods, this\nkind of partitions does not a priori allow to eliminate several brother nodes\nin the search tree with a single test. To overcome this difficulty, we propose\nan algorithm to reduce the number of tested brother nodes to a minimal list\nthat we call \"friend Voronoi cells\". The complete description of the method\nrequires a deeper insight into the properties of Delaunay triangulations and\nVoronoi diagrams\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 07:48:30 GMT"}], "update_date": "2011-05-26", "authors_parsed": [["Corlay", "Sylvain", "", "LPMA"]]}, {"id": "1105.5177", "submitter": "David Felber", "authors": "David Felber and Adam Meyerson", "title": "Scheduling under Precedence, Communication, and Energy Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling a set of $n$ tasks on $m$ processors\nunder precedence, communication, and global system energy constraints to\nminimize makespan. We extend existing scheduling models to account for energy\nusage and give convex programming algorithms that yield essentially the same\nresults as existing algorithms that do not consider energy, while adhering to a\nstrict energy bound.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 00:27:07 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["Felber", "David", ""], ["Meyerson", "Adam", ""]]}, {"id": "1105.5718", "submitter": "Vojt\\v{e}ch P\\v{r}ehnal Mgr.", "authors": "Vojtech Prehnal", "title": "Relational Schema Protocol (RSP)", "comments": "IETF Internet-Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document specifies the Relational Schema Protocol (RSP). RSP enables\nloosely coupled applications to share and exchange relational data. It defines\nfixed message format for an arbitrary relational schema so that the changes in\nthe data schema do not affect the message format. This prevents the interacting\napplications from having to be reimplemented during the data schema evolvement.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 14:28:30 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Prehnal", "Vojtech", ""]]}, {"id": "1105.5915", "submitter": "Bang Ye Wu", "authors": "Bang Ye Wu", "title": "Algorithms for the minimum non-separating path and the balanced\n  connected bipartition problems on grid graphs (With erratum)", "comments": "With erratum", "journal-ref": "Journal of Combinatorial Optimization, 26 (2013): 592--607", "doi": "10.1007/s10878-012-9481-z", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For given a pair of nodes in a graph, the minimum non-separating path problem\nlooks for a minimum weight path between the two nodes such that the remaining\ngraph after removing the path is still connected. The balanced connected\nbipartition (BCP$_2$) problem looks for a way to bipartition a graph into two\nconnected subgraphs with their weights as equal as possible. In this paper we\npresent an algorithm in time $O(N\\log N)$ for finding a minimum weight\nnon-separating path between two given nodes in a grid graph of $N$ nodes with\npositive weight. This result leads to a 5/4-approximation algorithm for the\nBCP$_2$ problem on grid graphs, which is the currently best ratio achieved in\npolynomial time. We also developed an exact algorithm for the BCP$_2$ problem\non grid graphs. Based on the exact algorithm and a rounding technique, we show\nan approximation scheme, which is a fully polynomial time approximation scheme\nfor fixed number of rows.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 09:33:36 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2014 06:07:52 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Wu", "Bang Ye", ""]]}, {"id": "1105.5933", "submitter": "Kasper Green Larsen", "authors": "Kasper Green Larsen", "title": "The Cell Probe Complexity of Dynamic Range Counting", "comments": "This is an updated version of the paper which has been submitted to\n  Journal of the ACM by invitation. The new version contains a new section\n  which introduces an artificial problem for which it is significantly easier\n  to apply the new lower bound technique", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a new technique for proving lower bounds on the\nupdate time and query time of dynamic data structures in the cell probe model.\nWith this technique, we prove the highest lower bound to date for any explicit\nproblem, namely a lower bound of $t_q=\\Omega((\\lg n/\\lg(wt_u))^2)$. Here $n$ is\nthe number of update operations, $w$ the cell size, $t_q$ the query time and\n$t_u$ the update time. In the most natural setting of cell size $w=\\Theta(\\lg\nn)$, this gives a lower bound of $t_q=\\Omega((\\lg n/\\lg \\lg n)^2)$ for any\npolylogarithmic update time. This bound is almost a quadratic improvement over\nthe highest previous lower bound of $\\Omega(\\lg n)$, due to P\\v{a}tra\\c{s}cu\nand Demaine [SICOMP'06].\n  We prove the lower bound for the fundamental problem of weighted orthogonal\nrange counting. In this problem, we are to support insertions of\ntwo-dimensional points, each assigned a $\\Theta(\\lg n)$-bit integer weight. A\nquery to this problem is specified by a point $q=(x,y)$, and the goal is to\nreport the sum of the weights assigned to the points dominated by $q$, where a\npoint $(x',y')$ is dominated by $q$ if $x' \\leq x$ and $y' \\leq y$. In addition\nto being the highest cell probe lower bound to date, the lower bound is also\ntight for data structures with update time $t_u = \\Omega(\\lg^{2+\\eps}n)$, where\n$\\eps>0$ is an arbitrarily small constant.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 10:25:03 GMT"}, {"version": "v2", "created": "Sat, 11 Feb 2012 19:32:46 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2012 08:39:17 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Larsen", "Kasper Green", ""]]}, {"id": "1105.5979", "submitter": "Utz-Uwe Haus", "authors": "Elke Eisenschmidt and Utz-Uwe Haus", "title": "A Polynomial Time Approximation Algorithm for the Two-Commodity\n  Splittable Flow Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of the unsplittable maximum two-commodity flow\nproblem on undirected graphs where each commodity $i\\in{1,2}$ can be split into\na bounded number $k_i$ of equally-sized chunks that can be routed on different\npaths. We show that in contrast to the single-commodity case this problem is\nNP-hard, and hard to approximate to within a factor of $\\alpha>1/2$. We present\na polynomial time 1/2-approximation algorithm for the case of uniform chunk\nsize over both commodities and show that for even $k_i$ and a mild cut\ncondition it can be modified to yield an exact method. The uniform case can be\nused to derive a 1/4-approximation for the maximum concurrent\n$(k_1,k_2)$-splittable flow without chunk size restrictions for fixed demand\nratios.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 13:07:12 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2011 11:58:53 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Eisenschmidt", "Elke", ""], ["Haus", "Utz-Uwe", ""]]}, {"id": "1105.6138", "submitter": "Mark Iwen", "authors": "J. Bailey and M. A. Iwen and C. V. Spencer", "title": "On the Design of Deterministic Matrices for Fast Recovery of Fourier\n  Compressible Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general class of compressed sensing matrices which are then\ndemonstrated to have associated sublinear-time sparse approximation algorithms.\nWe then develop methods for constructing specialized matrices from this class\nwhich are sparse when multiplied with a discrete Fourier transform matrix.\nUltimately, these considerations improve previous sampling requirements for\ndeterministic sparse Fourier transform methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 23:44:14 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Bailey", "J.", ""], ["Iwen", "M. A.", ""], ["Spencer", "C. V.", ""]]}, {"id": "1105.6151", "submitter": "Miguel Mosteiro", "authors": "Martin Farach-Colton, Antonio Fernandez Anta, Alessia Milani, Miguel\n  A. Mosteiro, and Shmuel Zaks", "title": "Opportunistic Information Dissemination in Mobile Ad-hoc Networks:\n  adaptiveness vs. obliviousness and randomization vs. determinism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of information dissemination in Mobile Ad-hoc\nNetworks (MANET) is studied. The problem is to disseminate a piece of\ninformation, initially held by a distinguished source node, to all nodes in a\nset defined by some predicate. We use a model of MANETs that is well suited for\ndynamic networks and opportunistic communication. In this model nodes are\nplaced in a plane, in which they can move with bounded speed, and communication\nbetween nodes occurs over a collision-prone single channel. In this setup\ninformed and uninformed nodes can be disconnected for some time (bounded by a\nparameter alpha), but eventually some uninformed node must become neighbor of\nan informed node and remain so for some time (bounded by a parameter beta). In\naddition, nodes can start at different times, and they can crash and recover.\nUnder the above framework, we show negative and positive results for different\ntypes of randomized protocols, and we put those results in perspective with\nrespect to previous deterministic results.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 02:44:06 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Farach-Colton", "Martin", ""], ["Anta", "Antonio Fernandez", ""], ["Milani", "Alessia", ""], ["Mosteiro", "Miguel A.", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1105.6331", "submitter": "Anton Stolbunov", "authors": "Steven Galbraith and Anton Stolbunov", "title": "Improved Algorithm for the Isogeny Problem for Ordinary Elliptic Curves", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A low storage algorithm for constructing isogenies between ordinary elliptic\ncurves was proposed by Galbraith, Hess and Smart (GHS). We give an improvement\nof this algorithm by modifying the pseudorandom walk so that lower-degree\nisogenies are used more frequently. This is motivated by the fact that high\ndegree isogenies are slower to compute than low degree ones. We analyse the\nrunning time of the parallel collision search algorithm when the partitioning\nis uneven. We also give experimental results. We conclude that our algorithm is\naround 14 times faster than the GHS algorithm when constructing horizontal\nisogenies between random isogenous elliptic curves over a 160-bit prime field.\n  The results apply to generic adding walks and the more general group action\ninverse problem; a speed-up is obtained whenever the cost of computing edges in\nthe graph varies significantly.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 16:13:36 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Galbraith", "Steven", ""], ["Stolbunov", "Anton", ""]]}]