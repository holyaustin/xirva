[{"id": "0908.0060", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica", "title": "Algorithmic Decision Optimization Techniques for Multiple Types of\n  Agents with Contrasting Interests", "comments": null, "journal-ref": "Metalurgia International, vol. 14, special issue no. 11, pp.\n  162-170, 2009. (ISSN: 1582-2214)", "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I present several algorithmic techniques for improving the\ndecision process of multiple types of agents behaving in environments where\ntheir interests are in conflict. The interactions between the agents are\nmodelled by using several types of two-player games, where the agents have\nidentical roles and compete for the same resources, or where they have\ndifferent roles, like in query-response games. The described situations have\napplications in modelling behavior in many types of environments, like\ndistributed systems, learning environments, resource negotiation environments,\nand many others. The mentioned models are applicable in a wide range of\ndomains, like computer science or the industrial (e.g. metallurgical), economic\nor financial sector.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2009 10:06:49 GMT"}], "update_date": "2009-08-04", "authors_parsed": [["Andreica", "Mugurel Ionut", ""]]}, {"id": "0908.0239", "submitter": "Manfred Kufleitner", "authors": "Manfred Kufleitner", "title": "On Bijective Variants of the Burrows-Wheeler Transform", "comments": "15 pages, presented at the Prague Stringology Conference 2009 (PSC\n  2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sort transform (ST) is a modification of the Burrows-Wheeler transform\n(BWT). Both transformations map an arbitrary word of length n to a pair\nconsisting of a word of length n and an index between 1 and n. The BWT sorts\nall rotation conjugates of the input word, whereas the ST of order k only uses\nthe first k letters for sorting all such conjugates. If two conjugates start\nwith the same prefix of length k, then the indices of the rotations are used\nfor tie-breaking. Both transforms output the sequence of the last letters of\nthe sorted list and the index of the input within the sorted list. In this\npaper, we discuss a bijective variant of the BWT (due to Scott), proving its\ncorrectness and relations to other results due to Gessel and Reutenauer (1993)\nand Crochemore, Desarmenien, and Perrin (2005). Further, we present a novel\nbijective variant of the ST.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2009 13:10:48 GMT"}], "update_date": "2009-08-04", "authors_parsed": [["Kufleitner", "Manfred", ""]]}, {"id": "0908.0350", "submitter": "Siddharth Barman", "authors": "Siddharth Barman, Shuchi Chawla", "title": "Region growing for multi-route cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a number of multi-route cut problems: given a graph G=(V,E) and\nconnectivity thresholds k_(u,v) on pairs of nodes, the goal is to find a\nminimum cost set of edges or vertices the removal of which reduces the\nconnectivity between every pair (u,v) to strictly below its given threshold.\nThese problems arise in the context of reliability in communication networks;\nThey are natural generalizations of traditional minimum cut problems where the\nthresholds are either 1 (we want to completely separate the pair) or infinity\n(we don't care about the connectivity for the pair). We provide the first\nnon-trivial approximations to a number of variants of the problem including for\nboth node-disjoint and edge-disjoint connectivity thresholds. A main\ncontribution of our work is an extension of the region growing technique for\napproximating minimum multicuts to the multi-route setting. When the\nconnectivity thresholds are either 2 or infinity (the \"2-route cut\" case), we\nobtain polylogarithmic approximations while satisfying the thresholds exactly.\nFor arbitrary connectivity thresholds this approach leads to bicriteria\napproximations where we approximately satisfy the thresholds and approximately\nminimize the cost. We present a number of different algorithms achieving\ndifferent cost-connectivity tradeoffs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2009 21:21:06 GMT"}], "update_date": "2009-08-05", "authors_parsed": [["Barman", "Siddharth", ""], ["Chawla", "Shuchi", ""]]}, {"id": "0908.0375", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran, Navin Goyal, Bernhard Haeupler", "title": "Deterministic Algorithms for the Lovasz Local Lemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lovasz Local Lemma (LLL) is a powerful result in probability theory that\nstates that the probability that none of a set of bad events happens is nonzero\nif the probability of each event is small compared to the number of events that\ndepend on it. It is often used in combination with the probabilistic method for\nnon-constructive existence proofs. A prominent application is to k-CNF\nformulas, where LLL implies that, if every clause in the formula shares\nvariables with at most d <= 2^k/e other clauses then such a formula has a\nsatisfying assignment. Recently, a randomized algorithm to efficiently\nconstruct a satisfying assignment was given by Moser. Subsequently Moser and\nTardos gave a randomized algorithm to construct the structures guaranteed by\nthe LLL in a very general algorithmic framework. We address the main problem\nleft open by Moser and Tardos of derandomizing these algorithms efficiently.\nSpecifically, for a k-CNF formula with m clauses and d <= 2^{k/(1+\\eps)}/e for\nany \\eps\\in (0,1), we give an algorithm that finds a satisfying assignment in\ntime \\tilde{O}(m^{2(1+1/\\eps)}). This improves upon the deterministic\nalgorithms of Moser and of Moser-Tardos with running time m^{\\Omega(k^2)} which\nis superpolynomial for k=\\omega(1) and upon other previous algorithms which\nwork only for d\\leq 2^{k/16}/4. Our algorithm works efficiently for a general\nversion of LLL under the algorithmic framework of Moser and Tardos, and is also\nparallelizable, i.e., has polylogarithmic running time using polynomially many\nprocessors.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 02:13:54 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 23:11:39 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Goyal", "Navin", ""], ["Haeupler", "Bernhard", ""]]}, {"id": "0908.0411", "submitter": "Gerhard Mayer", "authors": "Gerhard Mayer", "title": "Data management in systems biology I - Overview and bibliography", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large systems biology projects can encompass several workgroups often located\nin different countries. An overview about existing data standards in systems\nbiology and the management, storage, exchange and integration of the generated\ndata in large distributed research projects is given, the pros and cons of the\ndifferent approaches are illustrated from a practical point of view, the\nexisting software - open source as well as commercial - and the relevant\nliterature is extensively overview, so that the reader should be enabled to\ndecide which data management approach is the best suited for his special needs.\nAn emphasis is laid on the use of workflow systems and of TAB-based formats.\nThe data in this format can be viewed and edited easily using spreadsheet\nprograms which are familiar to the working experimental biologists. The use of\nworkflows for the standardized access to data in either own or publicly\navailable databanks and the standardization of operation procedures is\npresented. The use of ontologies and semantic web technologies for data\nmanagement will be discussed in a further paper.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 08:53:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2009 08:35:53 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2009 09:09:32 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Mayer", "Gerhard", ""]]}, {"id": "0908.0554", "submitter": "Aran Nayebi", "authors": "Aran Nayebi", "title": "On integers as the sum of a prime and a $k$-th power", "comments": "This paper has been withdrawn by the author due to several errors in\n  the manuscript, a prominent problem being that it has been known at least\n  since Tarski that in real numbers there exists a deterministic Turing machine\n  which determines if a variety is empty or nonempty", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{R}_k(n)$ be the number of representations of an integer $n$ as\nthe sum of a prime and a $k$-th power. Define E_k(X) := |\\{n \\le X, n \\in I_k,\nn\\text{not a sum of a prime and a $k$-th power}\\}|.\n  Hardy and Littlewood conjectured that for $k = 2$ and $k=3$, E_k(X) \\ll_{k}\n1. In this note we present an alternative approach grounded in the theory of\nDiophantine equations towards a proof of the conjecture for all $k \\ge 2$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2009 18:33:44 GMT"}, {"version": "v10", "created": "Wed, 7 Oct 2009 00:58:30 GMT"}, {"version": "v11", "created": "Mon, 12 Oct 2009 16:29:17 GMT"}, {"version": "v12", "created": "Wed, 14 Oct 2009 02:36:10 GMT"}, {"version": "v13", "created": "Thu, 15 Oct 2009 06:13:11 GMT"}, {"version": "v14", "created": "Wed, 21 Oct 2009 22:50:16 GMT"}, {"version": "v15", "created": "Mon, 26 Oct 2009 03:40:59 GMT"}, {"version": "v16", "created": "Sun, 6 Dec 2009 04:05:36 GMT"}, {"version": "v17", "created": "Mon, 14 Dec 2009 04:17:58 GMT"}, {"version": "v18", "created": "Mon, 4 Jan 2010 05:07:56 GMT"}, {"version": "v19", "created": "Mon, 5 Apr 2010 17:29:32 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2009 17:07:56 GMT"}, {"version": "v20", "created": "Sun, 5 Sep 2010 01:03:35 GMT"}, {"version": "v21", "created": "Mon, 7 Mar 2011 19:01:06 GMT"}, {"version": "v22", "created": "Wed, 9 Mar 2011 17:52:11 GMT"}, {"version": "v23", "created": "Sun, 10 Apr 2011 05:35:39 GMT"}, {"version": "v24", "created": "Sun, 24 Apr 2011 17:02:04 GMT"}, {"version": "v25", "created": "Mon, 13 Jun 2011 23:33:32 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2009 16:33:24 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2009 00:55:02 GMT"}, {"version": "v5", "created": "Wed, 12 Aug 2009 15:11:41 GMT"}, {"version": "v6", "created": "Fri, 14 Aug 2009 14:51:45 GMT"}, {"version": "v7", "created": "Sun, 23 Aug 2009 17:11:32 GMT"}, {"version": "v8", "created": "Mon, 5 Oct 2009 07:45:51 GMT"}, {"version": "v9", "created": "Tue, 6 Oct 2009 05:25:27 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Nayebi", "Aran", ""]]}, {"id": "0908.0772", "submitter": "Daniel Golovin", "authors": "Daniel Golovin, Andreas Krause, and Matthew Streeter", "title": "Online Learning of Assignments that Maximize Submodular Functions", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "0908.0772", "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which ads should we display in sponsored search in order to maximize our\nrevenue? How should we dynamically rank information sources to maximize value\nof information? These applications exhibit strong diminishing returns:\nSelection of redundant ads and information sources decreases their marginal\nutility. We show that these and other problems can be formalized as repeatedly\nselecting an assignment of items to positions to maximize a sequence of\nmonotone submodular functions that arrive one by one. We present an efficient\nalgorithm for this general problem and analyze it in the no-regret model. Our\nalgorithm possesses strong theoretical guarantees, such as a performance ratio\nthat converges to the optimal constant of 1-1/e. We empirically evaluate our\nalgorithm on two real-world online optimization problems on the web: ad\nallocation with submodular utilities, and dynamically ranking blogs to detect\ninformation cascades.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2009 23:56:22 GMT"}], "update_date": "2009-08-07", "authors_parsed": [["Golovin", "Daniel", ""], ["Krause", "Andreas", ""], ["Streeter", "Matthew", ""]]}, {"id": "0908.0968", "submitter": "Yuval Emek", "authors": "Yuval Emek, Amos Korman, and Yuval Shavitt", "title": "Approximating the Statistics of various Properties in Randomly Weighted\n  Graphs", "comments": "22 pages (excluding the title page)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the setting of \\emph{randomly weighted graphs}, namely, graphs whose\nedge weights are chosen independently according to probability distributions\nwith finite support over the non-negative reals. Under this setting, properties\nof weighted graphs typically become random variables and we are interested in\ncomputing their statistical features. Unfortunately, this turns out to be\ncomputationally hard for some properties albeit the problem of computing them\nin the traditional setting of algorithmic graph theory is tractable. For\nexample, there are well known efficient algorithms that compute the\n\\emph{diameter} of a given weighted graph, yet, computing the \\emph{expected}\ndiameter of a given randomly weighted graph is \\SharpP{}-hard even if the edge\nweights are identically distributed. In this paper, we define a family of\nproperties of weighted graphs and show that for each property in this family,\nthe problem of computing the \\emph{$k^{\\text{th}}$ moment} (and in particular,\nthe expected value) of the corresponding random variable in a given randomly\nweighted graph $G$ admits a \\emph{fully polynomial time randomized\napproximation scheme (FPRAS)} for every fixed $k$. This family includes\nfundamental properties of weighted graphs such as the diameter of $G$, the\n\\emph{radius} of $G$ (with respect to any designated vertex) and the weight of\na \\emph{minimum spanning tree} of $G$.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2009 05:53:45 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2009 15:16:47 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2009 17:29:32 GMT"}, {"version": "v4", "created": "Sun, 28 Mar 2010 18:23:28 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Emek", "Yuval", ""], ["Korman", "Amos", ""], ["Shavitt", "Yuval", ""]]}, {"id": "0908.1181", "submitter": "Vijay  Vazirani", "authors": "Vijay V. Vazirani", "title": "2-Player Nash and Nonsymmetric Bargaining Games: Algorithms and\n  Structural Properties", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-16170-4_28", "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution to a Nash or a nonsymmetric bargaining game is obtained by\nmaximizing a concave function over a convex set, i.e., it is the solution to a\nconvex program. We show that each 2-player game whose convex program has linear\nconstraints, admits a rational solution and such a solution can be found in\npolynomial time using only an LP solver. If in addition, the game is succinct,\ni.e., the coefficients in its convex program are ``small'', then its solution\ncan be found in strongly polynomial time. We also give a non-succinct linear\ngame whose solution can be found in strongly polynomial time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2009 01:52:35 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2009 05:04:35 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2009 21:35:32 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Vazirani", "Vijay V.", ""]]}, {"id": "0908.1379", "submitter": "Jonah Sherman", "authors": "Jonah Sherman", "title": "Breaking the Multicommodity Flow Barrier for sqrt(log(n))-Approximations\n  to Sparsest Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper ties the line of work on algorithms that find an\nO(sqrt(log(n)))-approximation to the sparsest cut together with the line of\nwork on algorithms that run in sub-quadratic time by using only\nsingle-commodity flows. We present an algorithm that simultaneously achieves\nboth goals, finding an O(sqrt(log(n)/eps))-approximation using O(n^eps log^O(1)\nn) max-flows. The core of the algorithm is a stronger, algorithmic version of\nArora et al.'s structure theorem, where we show that matching-chaining argument\nat the heart of their proof can be viewed as an algorithm that finds good\naugmenting paths in certain geometric multicommodity flow networks. By using\nthat specialized algorithm in place of a black-box solver, we are able to solve\nthose instances much more efficiently. We also show the cut-matching game\nframework can not achieve an approximation any better than Omega(log(n)/log\nlog(n)) without re-routing flow.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2009 19:57:32 GMT"}], "update_date": "2009-08-11", "authors_parsed": [["Sherman", "Jonah", ""]]}, {"id": "0908.1448", "submitter": "Aleksander M{\\ka}dry", "authors": "Jonathan A. Kelner, Aleksander Madry", "title": "Faster generation of random spanning trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we set forth a new algorithm for generating approximately\nuniformly random spanning trees in undirected graphs. We show how to sample\nfrom a distribution that is within a multiplicative $(1+\\delta)$ of uniform in\nexpected time $\\TO(m\\sqrt{n}\\log 1/\\delta)$. This improves the sparse graph\ncase of the best previously known worst-case bound of $O(\\min \\{mn,\nn^{2.376}\\})$, which has stood for twenty years.\n  To achieve this goal, we exploit the connection between random walks on\ngraphs and electrical networks, and we use this to introduce a new approach to\nthe problem that integrates discrete random walk-based techniques with\ncontinuous linear algebraic methods. We believe that our use of electrical\nnetworks and sparse linear system solvers in conjunction with random walks and\ncombinatorial partitioning techniques is a useful paradigm that will find\nfurther applications in algorithmic graph theory.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2009 05:14:39 GMT"}], "update_date": "2009-08-12", "authors_parsed": [["Kelner", "Jonathan A.", ""], ["Madry", "Aleksander", ""]]}, {"id": "0908.1528", "submitter": "Robert Geisberger", "authors": "Robert Geisberger", "title": "Contraction of Timetable Networks with Realistic Transfers", "comments": "15 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We successfully contract timetable networks with realistic transfer times.\nContraction gradually removes nodes from the graph and adds shortcuts to\npreserve shortest paths. This reduces query times to 1 ms with preprocessing\ntimes around 6 minutes on all tested instances. We achieve this by an improved\ncontraction algorithm and by using a station graph model. Every node in our\ngraph has a one-to-one correspondence to a station and every edge has an\nassigned collection of connections. Our graph model does not need parallel\nedges. The query algorithm does not compute a single earliest arrival time at a\nstation but a set of arriving connections that allow best transfer\nopportunities.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2009 16:03:46 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2009 14:26:01 GMT"}], "update_date": "2009-08-12", "authors_parsed": [["Geisberger", "Robert", ""]]}, {"id": "0908.2056", "submitter": "Sebastian Roch", "authors": "Yuval Peres and Sebastien Roch", "title": "Reconstruction on Trees: Exponential Moment Bounds for Linear Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a Markov chain $(\\xi_v)_{v \\in V} \\in [k]^V$ on the infinite $b$-ary\ntree $T = (V,E)$ with irreducible edge transition matrix $M$, where $b \\geq 2$,\n$k \\geq 2$ and $[k] = \\{1,...,k\\}$. We denote by $L_n$ the level-$n$ vertices\nof $T$. Assume $M$ has a real second-largest (in absolute value) eigenvalue\n$\\lambda$ with corresponding real eigenvector $\\nu \\neq 0$. Letting $\\sigma_v =\n\\nu_{\\xi_v}$, we consider the following root-state estimator, which was\nintroduced by Mossel and Peres (2003) in the context of the \"recontruction\nproblem\" on trees: \\begin{equation*} S_n = (b\\lambda)^{-n} \\sum_{x\\in L_n}\n\\sigma_x. \\end{equation*} As noted by Mossel and Peres, when $b\\lambda^2 > 1$\n(the so-called Kesten-Stigum reconstruction phase) the quantity $S_n$ has\nuniformly bounded variance. Here, we give bounds on the moment-generating\nfunctions of $S_n$ and $S_n^2$ when $b\\lambda^2 > 1$. Our results have\nimplications for the inference of evolutionary trees.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2009 13:05:32 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Peres", "Yuval", ""], ["Roch", "Sebastien", ""]]}, {"id": "0908.2061", "submitter": "Sebastian Roch", "authors": "Sebastien Roch", "title": "Sequence-Length Requirement of Distance-Based Phylogeny Reconstruction:\n  Breaking the Polynomial Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new distance-based phylogeny reconstruction technique which\nprovably achieves, at sufficiently short branch lengths, a polylogarithmic\nsequence-length requirement -- improving significantly over previous polynomial\nbounds for distance-based methods. The technique is based on an averaging\nprocedure that implicitly reconstructs ancestral sequences.\n  In the same token, we extend previous results on phase transitions in\nphylogeny reconstruction to general time-reversible models. More precisely, we\nshow that in the so-called Kesten-Stigum zone (roughly, a region of the\nparameter space where ancestral sequences are well approximated by ``linear\ncombinations'' of the observed sequences) sequences of length $\\poly(\\log n)$\nsuffice for reconstruction when branch lengths are discretized. Here $n$ is the\nnumber of extant species.\n  Our results challenge, to some extent, the conventional wisdom that estimates\nof evolutionary distances alone carry significantly less information about\nphylogenies than full sequence datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2009 13:20:44 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Roch", "Sebastien", ""]]}, {"id": "0908.2256", "submitter": "Viswanath Nagarajan", "authors": "Nikhil Bansal, Nitish Korula, Viswanath Nagarajan and Aravind\n  Srinivasan", "title": "On k-Column Sparse Packing Programs", "comments": "19 pages, v3: additional details", "journal-ref": null, "doi": "10.1007/978-3-642-13036-6_28", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the class of packing integer programs (PIPs) that are column\nsparse, i.e. there is a specified upper bound k on the number of constraints\nthat each variable appears in. We give an (ek+o(k))-approximation algorithm for\nk-column sparse PIPs, improving on recent results of $k^2\\cdot 2^k$ and\n$O(k^2)$. We also show that the integrality gap of our linear programming\nrelaxation is at least 2k-1; it is known that k-column sparse PIPs are\n$\\Omega(k/ \\log k)$-hard to approximate. We also extend our result (at the loss\nof a small constant factor) to the more general case of maximizing a submodular\nobjective over k-column sparse packing constraints.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2009 17:55:03 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2009 02:27:09 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2010 15:29:51 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bansal", "Nikhil", ""], ["Korula", "Nitish", ""], ["Nagarajan", "Viswanath", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "0908.2644", "submitter": "Marvin Weinstein", "authors": "Marvin Weinstein, David Horn", "title": "Dynamic quantum clustering: a method for visual exploration of\n  structures in data", "comments": "15 pages, 9 figures", "journal-ref": "Phys.Rev.E80:066117,2009", "doi": "10.1103/PhysRevE.80.066117", "report-no": "SLAC-PUB-13759", "categories": "physics.data-an cs.DS hep-ex physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A given set of data-points in some feature space may be associated with a\nSchrodinger equation whose potential is determined by the data. This is known\nto lead to good clustering solutions. Here we extend this approach into a\nfull-fledged dynamical scheme using a time-dependent Schrodinger equation.\nMoreover, we approximate this Hamiltonian formalism by a truncated calculation\nwithin a set of Gaussian wave functions (coherent states) centered around the\noriginal points. This allows for analytic evaluation of the time evolution of\nall such states, opening up the possibility of exploration of relationships\namong data-points through observation of varying dynamical-distances among\npoints and convergence of points into clusters. This formalism may be further\nsupplemented by preprocessing, such as dimensional reduction through singular\nvalue decomposition or feature filtering.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2009 21:40:03 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Weinstein", "Marvin", ""], ["Horn", "David", ""]]}, {"id": "0908.2834", "submitter": "Benjamin Birnbaum", "authors": "Yossi Azar, Benjamin Birnbaum, Anna R. Karlin, C. Thach Nguyen", "title": "On Revenue Maximization in Second-Price Ad Auctions", "comments": "Full version of ESA 2009 paper, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent papers addressing the algorithmic problem of allocating\nadvertisement space for keywords in sponsored search auctions assume that\npricing is done via a first-price auction, which does not realistically model\nthe Generalized Second Price (GSP) auction used in practice. Towards the goal\nof more realistically modeling these auctions, we introduce the Second-Price Ad\nAuctions problem, in which bidders' payments are determined by the GSP\nmechanism. We show that the complexity of the Second-Price Ad Auctions problem\nis quite different than that of the more studied First-Price Ad Auctions\nproblem. First, unlike the first-price variant, for which small constant-factor\napproximations are known, it is NP-hard to approximate the Second-Price Ad\nAuctions problem to any non-trivial factor. Second, this discrepancy extends\neven to the 0-1 special case that we call the Second-Price Matching problem\n(2PM). In particular, offline 2PM is APX-hard, and for online 2PM there is no\ndeterministic algorithm achieving a non-trivial competitive ratio and no\nrandomized algorithm achieving a competitive ratio better than 2. This stands\nin contrast to the results for the analogous special case in the first-price\nmodel, the standard bipartite matching problem, which is solvable in polynomial\ntime and which has deterministic and randomized online algorithms achieving\nbetter competitive ratios. On the positive side, we provide a 2-approximation\nfor offline 2PM and a 5.083-competitive randomized algorithm for online 2PM.\nThe latter result makes use of a new generalization of a classic result on the\nperformance of the \"Ranking\" algorithm for online bipartite matching.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2009 23:46:02 GMT"}], "update_date": "2009-08-21", "authors_parsed": [["Azar", "Yossi", ""], ["Birnbaum", "Benjamin", ""], ["Karlin", "Anna R.", ""], ["Nguyen", "C. Thach", ""]]}, {"id": "0908.3089", "submitter": "Maxim Kolosovskiy", "authors": "Maxim A. Kolosovskiy (Altai State Technical University, Russia)", "title": "Data structure for representing a graph: combination of linked list and\n  hash table", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we discuss a data structure, which combines advantages of two\ndifferent ways for representing graphs: adjacency matrix and collection of\nadjacency lists. This data structure can fast add and search edges (advantages\nof adjacency matrix), use linear amount of memory, let to obtain adjacency list\nfor certain vertex (advantages of collection of adjacency lists). Basic\nknowledge of linked lists and hash tables is required to understand this\narticle. The article contains examples of implementation on Java.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2009 10:12:31 GMT"}], "update_date": "2009-08-24", "authors_parsed": [["Kolosovskiy", "Maxim A.", "", "Altai State Technical University, Russia"]]}, {"id": "0908.3222", "submitter": "Tetsuya Hattori", "authors": "Kumiko Hattori, Tetsuya Hattori", "title": "Hydrodynamic limit of move-to-front rules and search cost probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a hydrodynamic limit approach to move-to-front rules, namely, a\nscaling limit as the number of items tends to infinity, of the joint\ndistribution of jump rate and position of items. As an application of the limit\nformula, we present asymptotic formulas on search cost probability\ndistributions, applicable for general jump rate distributions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2009 01:32:55 GMT"}], "update_date": "2009-08-26", "authors_parsed": [["Hattori", "Kumiko", ""], ["Hattori", "Tetsuya", ""]]}, {"id": "0908.3233", "submitter": "Yavuz Oruc A.", "authors": "A. Yavuz Oruc and Abdullah Atmaca", "title": "Asymptotically Optimal Assignments In Ordinal Evaluations of Proposals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ordinal evaluations of proposals in peer review systems, a set of\nproposals is assigned to a fixed set of referees so as to maximize the number\nof pairwise comparisons of proposals under certain referee capacity and\nproposal subject constraints. In this paper, the following two related problems\nare considered: (1) Assuming that each referee has a capacity to review k out\nof n proposals, 2 < k < n, determine the minimum number of referees needed to\nensure that each pair of proposals is reviewed by at least one referee, (2)\nFind an assignment that meets the lower bound determined in (1). It is easy to\nsee that one referee is both necessary and sufficient when k = n, and n(n-1)/2\nreferees are both necessary and sufficient when k = 2. We show that 6 referees\nare both necessary and sufficient when k = n/2. We further show that 11\nreferees are necessary and 12 are sufficient when k = n/3, and 18 referees are\nnecessary and 20 referees are sufficient when k = n/4. A more general lower\nbound of n(n-1)/k(k-1) referees is also given for any k, 2 < k < n, and an\nassignment asymptotically matching this lower bound within a factor of 2 is\npresented. These results are not only theoretically interesting but they also\nprovide practical methods for efficient assignments of proposals to referees.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2009 07:08:30 GMT"}], "update_date": "2009-08-25", "authors_parsed": [["Oruc", "A. Yavuz", ""], ["Atmaca", "Abdullah", ""]]}, {"id": "0908.3455", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Ion Pargaru, Florin Ionescu, Cristina Teodora\n  Andreica", "title": "Algorithmic Aspects of Several Data Transfer Service Optimization\n  Problems", "comments": "Proceedings of the International Symposium on Sustainable Development\n  in Conditions of Economic Instability, Satu Mare, 26-27 June, 2009", "journal-ref": "\"Quality - Access to Success\" Journal, vol. 10, special issue no.\n  101, pp. 30-32, 2009. (ISSN: 1582-2559)", "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimized data transfer services are highly demanded nowadays, due to the\nlarge amounts of data which are frequently being produced and accessed. In this\npaper we consider several data transfer service optimization problems (optimal\nserver location in path networks, optimal packet sequencing and minimum\nmakespan packet scheduling), for which we provide novel algorithmic solutions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 15:56:58 GMT"}], "update_date": "2009-08-25", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Pargaru", "Ion", ""], ["Ionescu", "Florin", ""], ["Andreica", "Cristina Teodora", ""]]}, {"id": "0908.3459", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Mihai Aristotel Ungureanu, Romulus Andreica,\n  Angela Andreica", "title": "An Algorithmic Perspective on Some Network Design, Construction and\n  Analysis Problems", "comments": "Proceedings of the International Symposium on Sustainable Development\n  in Conditions of Economic Instability, Satu Mare, 26-27 June, 2009", "journal-ref": "\"Quality - Access to Success\" Journal, vol. 10, special issue no.\n  101, pp. 20-22, 2009. (ISSN: 1582-2559)", "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient network design, construction and analysis are important topics,\nconsidering the highly dynamic environment in which data communication occurs\nnowadays. In this paper we address several problems concerning these topics\nfrom an algorithmic point of view.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 16:05:50 GMT"}], "update_date": "2009-08-25", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Ungureanu", "Mihai Aristotel", ""], ["Andreica", "Romulus", ""], ["Andreica", "Angela", ""]]}, {"id": "0908.3505", "submitter": "Christoph Durr", "authors": "Philippe Baptiste, Marek Chrobak, Christoph Durr", "title": "Polynomial Time Algorithms for Minimum Energy Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of power management policies is to reduce the amount of energy\nconsumed by computer systems while maintaining satisfactory level of\nperformance. One common method for saving energy is to simply suspend the\nsystem during the idle times. No energy is consumed in the suspend mode.\nHowever, the process of waking up the system itself requires a certain fixed\namount of energy, and thus suspending the system is beneficial only if the idle\ntime is long enough to compensate for this additional energy expenditure. In\nthe specific problem studied in the paper, we have a set of jobs with release\ntimes and deadlines that need to be executed on a single processor. Preemptions\nare allowed. The processor requires energy L to be woken up and, when it is on,\nit uses one unit of energy per one unit of time. It has been an open problem\nwhether a schedule minimizing the overall energy consumption can be computed in\npolynomial time. We solve this problem in positive, by providing an O(n^5)-time\nalgorithm. In addition we provide an O(n^4)-time algorithm for computing the\nminimum energy schedule when all jobs have unit length.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 21:44:45 GMT"}, {"version": "v2", "created": "Fri, 3 Sep 2010 12:28:21 GMT"}], "update_date": "2010-09-06", "authors_parsed": [["Baptiste", "Philippe", ""], ["Chrobak", "Marek", ""], ["Durr", "Christoph", ""]]}, {"id": "0908.3545", "submitter": "Pat Morin", "authors": "Vida Dujmovic, Joachim Gudmundsson, Pat Morin, Thomas Wolle", "title": "Notes on large angle crossing graphs", "comments": null, "journal-ref": "Chicago Journal of Theoretical Computer Science, Article 2011-4", "doi": "10.4086/cjtcs.2011.004", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph G is an a-angle crossing (aAC) graph if every pair of crossing edges\nin G intersect at an angle of at least a. The concept of right angle crossing\n(RAC) graphs (a=Pi/2) was recently introduced by Didimo et. al. It was shown\nthat any RAC graph with n vertices has at most 4n-10 edges and that there are\ninfinitely many values of n for which there exists a RAC graph with n vertices\nand 4n-10 edges. In this paper, we give upper and lower bounds for the number\nof edges in aAC graphs for all 0 < a < Pi/2.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2009 06:21:41 GMT"}, {"version": "v2", "created": "Mon, 29 Nov 2010 15:05:40 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Dujmovic", "Vida", ""], ["Gudmundsson", "Joachim", ""], ["Morin", "Pat", ""], ["Wolle", "Thomas", ""]]}, {"id": "0908.3574", "submitter": "Christian Esteve Rothenberg", "authors": "Christian Esteve Rothenberg, Carlos A. Macapuna, Fabio L. Verdi,\n  Mauricio F. Magalhaes, Alexander Wiesmaier", "title": "In-packet Bloom filters: Design and networking applications", "comments": "15 pages, 11 figures, preprint submitted to Elsevier COMNET Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bloom filter (BF) is a well-known space-efficient data structure that\nanswers set membership queries with some probability of false positives. In an\nattempt to solve many of the limitations of current inter-networking\narchitectures, some recent proposals rely on including small BFs in packet\nheaders for routing, security, accountability or other purposes that move\napplication states into the packets themselves. In this paper, we consider the\ndesign of such in-packet Bloom filters (iBF). Our main contributions are\nexploring the design space and the evaluation of a series of extensions (1) to\nincrease the practicality and performance of iBFs, (2) to enable\nfalse-negative-free element deletion, and (3) to provide security enhancements.\nIn addition to the theoretical estimates, extensive simulations of the multiple\ndesign parameters and implementation alternatives validate the usefulness of\nthe extensions, providing for enhanced and novel iBF networking applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2009 09:10:51 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2010 00:35:00 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Rothenberg", "Christian Esteve", ""], ["Macapuna", "Carlos A.", ""], ["Verdi", "Fabio L.", ""], ["Magalhaes", "Mauricio F.", ""], ["Wiesmaier", "Alexander", ""]]}, {"id": "0908.3652", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Eliana-Dina Tirsa, Cristina Teodora Andreica,\n  Romulus Andreica, Mihai Aristotel Ungureanu", "title": "Optimal Geometric Partitions, Covers and K-Centers", "comments": "Extended version of the conference paper", "journal-ref": "Proc. of the 9th WSEAS Intl. Conf. on Mathematics and Computers in\n  Business and Economics (MCBE), pp. 173-178, Bucharest, Romania, 24-26 June,\n  2008. (ISBN: 978-960-6766-76-3 / ISSN: 1790-5109)", "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present some new, practical, geometric optimization\ntechniques for computing polygon partitions, 1D and 2D point, interval, square\nand rectangle covers, as well as 1D and 2D interval and rectangle K-centers.\nAll the techniques we present have immediate applications to several cost\noptimization and facility location problems which are quite common in practice.\nThe main technique employed is dynamic programming, but we also make use of\nefficient data structures and fast greedy algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2009 17:47:50 GMT"}], "update_date": "2009-08-26", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tirsa", "Eliana-Dina", ""], ["Andreica", "Cristina Teodora", ""], ["Andreica", "Romulus", ""], ["Ungureanu", "Mihai Aristotel", ""]]}, {"id": "0908.3740", "submitter": "Ian Post", "authors": "Ashish Goel and Ian Post", "title": "An Oblivious O(1)-Approximation for Single Source Buy-at-Bulk", "comments": "22 pages, 1 figure To appear in the proceedings of the 50th annual\n  IEEE Symposium on Foundations of Computer Science (FOCS 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the single-source (or single-sink) buy-at-bulk problem with an\nunknown concave cost function. We want to route a set of demands along a graph\nto or from a designated root node, and the cost of routing x units of flow\nalong an edge is proportional to some concave, non-decreasing function f such\nthat f(0) = 0. We present a polynomial time algorithm that finds a distribution\nover trees such that the expected cost of a tree for any f is within an\nO(1)-factor of the optimum cost for that f. The previous best simultaneous\napproximation for this problem, even ignoring computation time, was O(log |D|),\nwhere D is the multi-set of demand nodes.\n  We design a simple algorithmic framework using the ellipsoid method that\nfinds an O(1)-approximation if one exists, and then construct a separation\noracle using a novel adaptation of the Guha, Meyerson, and Munagala algorithm\nfor the single-sink buy-at-bulk problem that proves an O(1) approximation is\npossible for all f. The number of trees in the support of the distribution\nconstructed by our algorithm is at most 1+log |D|.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2009 07:20:01 GMT"}], "update_date": "2009-08-27", "authors_parsed": [["Goel", "Ashish", ""], ["Post", "Ian", ""]]}, {"id": "0908.4116", "submitter": "Nikos Triandopoulos", "authors": "Michael T. Goodrich, Roberto Tamassia, Nikos Triandopoulos", "title": "Efficient Authenticated Data Structures for Graph Connectivity and\n  Geometric Search Problems", "comments": "Full version of related paper appearing in CT-RSA 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticated data structures provide cryptographic proofs that their answers\nare as accurate as the author intended, even if the data structure is being\ncontrolled by a remote untrusted host. We present efficient techniques for\nauthenticating data structures that represent graphs and collections of\ngeometric objects. We introduce the path hash accumulator, a new primitive\nbased on cryptographic hashing for efficiently authenticating various\nproperties of structured data represented as paths, including any decomposable\nquery over sequences of elements. We show how to employ our primitive to\nauthenticate queries about properties of paths in graphs and search queries on\nmulti-catalogs. This allows the design of new, efficient authenticated data\nstructures for fundamental problems on networks, such as path and connectivity\nqueries over graphs, and complex queries on two-dimensional geometric objects,\nsuch as intersection and containment queries.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2009 00:18:06 GMT"}], "update_date": "2009-08-31", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Tamassia", "Roberto", ""], ["Triandopoulos", "Nikos", ""]]}, {"id": "0908.4309", "submitter": "Li Yan", "authors": "Francis Chin, Marek Chrobak, Li Yan", "title": "Algorithms for Placing Monitors in a Flow Network", "comments": "13 pages, 5 figures. Preliminary version appeared in AAIM 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Flow Edge-Monitor Problem, we are given an undirected graph G=(V,E),\nan integer k > 0 and some unknown circulation \\psi on G. We want to find a set\nof k edges in G, so that if we place k monitors on those edges to measure the\nflow along them, the total number of edges for which the flow can be uniquely\ndetermined is maximized. In this paper, we first show that the Flow\nEdge-Monitor Problem is NP-hard, and then we give two approximation algorithms:\na 3-approximation algorithm with running time O((m+n)^2) and a 2-approximation\nalgorithm with running time O((m+n)^3), where n = |V| and m=|E|.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2009 01:45:44 GMT"}], "update_date": "2009-09-01", "authors_parsed": [["Chin", "Francis", ""], ["Chrobak", "Marek", ""], ["Yan", "Li", ""]]}, {"id": "0908.4499", "submitter": "Yann Strozecki", "authors": "Yann Strozecki", "title": "Monadic second-order model-checking on decomposable matroids", "comments": "32 pages, journal paper. Revision: the last part has been removed and\n  the writing improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of branch-width, which generalizes the one known for graphs, can be\ndefined for matroids. We first give a proof of the polynomial time\nmodel-checking of monadic second-order formulas on representable matroids of\nbounded branch-width, by reduction to monadic second-order formulas on trees.\nThis proof is much simpler than the one previously known. We also provide a\nlink between our logical approach and a grammar that allows to build matroids\nof bounded branch-width. Finally, we introduce a new class of non-necessarily\nrepresentable matroids, described by a grammar and on which monadic\nsecond-order formulas can be checked in linear time.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2009 11:00:44 GMT"}, {"version": "v2", "created": "Sat, 29 Jan 2011 23:43:14 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Strozecki", "Yann", ""]]}]