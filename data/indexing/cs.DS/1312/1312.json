[{"id": "1312.0042", "submitter": "Bojian Xu", "authors": "Bojian Xu", "title": "Boosting the Basic Counting on Distributed Streams", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic basic counting problem in the distributed streaming\nmodel that was studied by Gibbons and Tirthapura (GT). In the solution for\nmaintaining an $(\\epsilon,\\delta)$-estimate, as what GT's method does, we make\nthe following new contributions: (1) For a bit stream of size $n$, where each\nbit has a probability at least $\\gamma$ to be 1, we exponentially reduced the\naverage total processing time from GT's $\\Theta(n \\log(1/\\delta))$ to\n$O((1/(\\gamma\\epsilon^2))(\\log^2 n) \\log(1/\\delta))$, thus providing the first\nsublinear-time streaming algorithm for this problem. (2) In addition to an\noverall much faster processing speed, our method provides a new tradeoff that a\nlower accuracy demand (a larger value for $\\epsilon$) promises a faster\nprocessing speed, whereas GT's processing speed is $\\Theta(n \\log(1/\\delta))$\nin any case and for any $\\epsilon$. (3) The worst-case total time cost of our\nmethod matches GT's $\\Theta(n\\log(1/\\delta))$, which is necessary but rarely\noccurs in our method. (4) The space usage overhead in our method is a lower\norder term compared with GT's space usage and occurs only $O(\\log n)$ times\nduring the stream processing and is too negligible to be detected by the\noperating system in practice. We further validate these solid theoretical\nresults with experiments on both real-world and synthetic data, showing that\nour method is faster than GT's by a factor of several to several thousands\ndepending on the stream size and accuracy demands, without any detectable space\nusage overhead. Our method is based on a faster sampling technique that we\ndesign for boosting GT's method and we believe this technique can be of other\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 23:56:52 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Xu", "Bojian", ""]]}, {"id": "1312.0186", "submitter": "Krasimir Yordzhev", "authors": "Krasimir Yordzhev", "title": "On an Algorithm for Obtaining All Binary Matrices of Special Class\n  Related to V. E. Tarakanov's Formula", "comments": null, "journal-ref": "Journal of Mathematical Sciences and Applications, 2013, Vol. 1,\n  No. 2, 36-38", "doi": "10.12691/jmsa-1-2-5", "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for obtaining all n\\times n binary matrices having exactly 2\nunits in every row and every column is described in the paper. After analysing\nthe work of the algorithm a formula for calculating the number of these\nmatrices has been obtained. This formula is known and has been obtained using\nother methods, which by their nature are purely analytical and not\nconstructive. Thus a new, constructive proof of this known formula has been\nobtained.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2013 07:45:42 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Yordzhev", "Krasimir", ""]]}, {"id": "1312.0192", "submitter": "Krasimir Yordzhev", "authors": "Krasimir Yordzhev", "title": "Random Permutations, Random Sudoku Matrices and Randomized Algorithms", "comments": null, "journal-ref": "International J. of Math. Sci. & Engg. Appls. (IJMSEA), ISSN\n  0973-9424, Vol. 6 No. VI (November, 2012), pp. 291-302", "doi": null, "report-no": null, "categories": "math.CO cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some randomized algorithms, used to obtain a random $n^2 \\times n^2$ Sudoku\nmatrix, where $n$ is a natural number, is reviewed in this study. Below is\ndescribed the set $\\Pi_n$ of all $(2n) \\times n$ matrices, consisting of\nelements of the set $\\mathbb{Z}_n =\\{ 1,2,\\ldots ,n\\}$, such that every row is\na permutation. It is proved that such matrices would be particularly useful in\ndeveloping efficient algorithms in generating Sudoku matrices. An algorithm to\nobtain random $\\Pi_n$ matrices is presented in this paper. The algorithms are\nevaluated according to two criteria - probability evaluation, and time\nevaluation. This type of criteria is interesting from both theoretical and\npractical point of view because they are particularly useful in the analysis of\ncomputer programs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2013 08:45:20 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Yordzhev", "Krasimir", ""]]}, {"id": "1312.0194", "submitter": "Krasimir Yordzhev", "authors": "Krasimir Yordzhev", "title": "Some Combinatorial Problems on Binary Matrices in Programming Courses", "comments": null, "journal-ref": "Informational Technologies in Education, 2012, 12, 39-43", "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study proves the existence of an algorithm to receive all elements of a\nclass of binary matrices without obtaining redundant elements, e. g. without\nobtaining binary matrices that do not belong to the class. This makes it\npossible to avoid checking whether each of the objects received possesses the\nnecessary properties. This significantly improves the efficiency of the\nalgorithm in terms of the criterion of time. Certain useful educational effects\nrelated to the analysis of such problems in programming classes are also\npointed out.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2013 09:05:14 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Yordzhev", "Krasimir", ""]]}, {"id": "1312.0497", "submitter": "Frank Hellweg", "authors": "Frank Hellweg and Christian Sohler", "title": "Property-Testing in Sparse Directed Graphs: 3-Star-Freeness and\n  Connectivity", "comments": "Results partly published at ESA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study property testing in directed graphs in the bounded degree model,\nwhere we assume that an algorithm may only query the outgoing edges of a\nvertex, a model proposed by Bender and Ron in 2002. As our first main result,\nwe we present a property testing algorithm for strong connectivity in this\nmodel, having a query complexity of $\\mathcal{O}(n^{1-\\epsilon/(3+\\alpha)})$\nfor arbitrary $\\alpha>0$; it is based on a reduction to estimating the vertex\nindegree distribution. For subgraph-freeness we give a property testing\nalgorithm with a query complexity of $\\mathcal{O}(n^{1-1/k})$, where $k$ is the\nnumber of connected componentes in the queried subgraph which have no incoming\nedge. We furthermore take a look at the problem of testing whether a weakly\nconnected graph contains vertices with a degree of least $3$, which can be\nviewed as testing for freeness of all orientations of $3$-stars; as our second\nmain result, we show that this property can be tested with a query complexity\nof $\\mathcal{O}(\\sqrt{n})$ instead of, what would be expected,\n$\\Omega(n^{2/3})$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 16:17:22 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Hellweg", "Frank", ""], ["Sohler", "Christian", ""]]}, {"id": "1312.0526", "submitter": "Giuseppe Ottaviano", "authors": "Djamal Belazzougui, Paolo Boldi, Giuseppe Ottaviano, Rossano\n  Venturini, Sebastiano Vigna", "title": "Cache-Oblivious Peeling of Random Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of a peeling order in a randomly generated hypergraph is the\nmost time-consuming step in a number of constructions, such as perfect hashing\nschemes, random $r$-SAT solvers, error-correcting codes, and approximate set\nencodings. While there exists a straightforward linear time algorithm, its poor\nI/O performance makes it impractical for hypergraphs whose size exceeds the\navailable internal memory.\n  We show how to reduce the computation of a peeling order to a small number of\nsequential scans and sorts, and analyze its I/O complexity in the\ncache-oblivious model. The resulting algorithm requires $O(\\mathrm{sort}(n))$\nI/Os and $O(n \\log n)$ time to peel a random hypergraph with $n$ edges.\n  We experimentally evaluate the performance of our implementation of this\nalgorithm in a real-world scenario by using the construction of minimal perfect\nhash functions (MPHF) as our test case: our algorithm builds a MPHF of $7.6$\nbillion keys in less than $21$ hours on a single machine. The resulting data\nstructure is both more space-efficient and faster than that obtained with the\ncurrent state-of-the-art MPHF construction for large-scale key sets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 17:37:51 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Boldi", "Paolo", ""], ["Ottaviano", "Giuseppe", ""], ["Venturini", "Rossano", ""], ["Vigna", "Sebastiano", ""]]}, {"id": "1312.0722", "submitter": "Yannis Moysoglou", "authors": "Stavros G. Kolliopoulos and Yannis Moysoglou", "title": "Sherali-Adams gaps, flow-cover inequalities and generalized\n  configurations for capacity-constrained Facility Location", "comments": "arXiv admin note: substantial text overlap with arXiv:1305.5998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric facility location is a well-studied problem for which linear\nprogramming methods have been used with great success in deriving approximation\nalgorithms. The capacity-constrained generalizations, such as capacitated\nfacility location (CFL) and lower-bounded facility location (LBFL), have proved\nnotorious as far as LP-based approximation is concerned: while there are\nlocal-search-based constant-factor approximations, there is no known linear\nrelaxation with constant integrality gap. According to Williamson and Shmoys\ndevising a relaxation-based approximation for \\cfl\\ is among the top 10 open\nproblems in approximation algorithms.\n  This paper advances significantly the state-of-the-art on the effectiveness\nof linear programming for capacity-constrained facility location through a host\nof impossibility results for both CFL and LBFL. We show that the relaxations\nobtained from the natural LP at $\\Omega(n)$ levels of the Sherali-Adams\nhierarchy have an unbounded gap, partially answering an open question of\n\\cite{LiS13, AnBS13}. Here, $n$ denotes the number of facilities in the\ninstance. Building on the ideas for this result, we prove that the standard CFL\nrelaxation enriched with the generalized flow-cover valid inequalities\n\\cite{AardalPW95} has also an unbounded gap. This disproves a long-standing\nconjecture of \\cite{LeviSS12}. We finally introduce the family of proper\nrelaxations which generalizes to its logical extreme the classic star\nrelaxation and captures general configuration-style LPs. We characterize the\nbehavior of proper relaxations for CFL and LBFL through a sharp threshold\nphenomenon.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 07:46:57 GMT"}, {"version": "v2", "created": "Sat, 14 Jun 2014 07:05:56 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Kolliopoulos", "Stavros G.", ""], ["Moysoglou", "Yannis", ""]]}, {"id": "1312.0723", "submitter": "Francesco Silvestri", "authors": "Rasmus Pagh and Francesco Silvestri", "title": "The Input/Output Complexity of Triangle Enumeration", "comments": "Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART Symposium on\n  Principles of Database Systems, PODS 2014", "journal-ref": null, "doi": "10.1145/2594538.2594552", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the well-known problem of enumerating all triangles of an\nundirected graph. Our focus is on determining the input/output (I/O) complexity\nof this problem. Let $E$ be the number of edges, $M<E$ the size of internal\nmemory, and $B$ the block size. The best results obtained previously are\nsort$(E^{3/2})$ I/Os (Dementiev, PhD thesis 2006) and $O(E^2/(MB))$ I/Os (Hu et\nal., SIGMOD 2013), where sort$(n)$ denotes the number of I/Os for sorting $n$\nitems. We improve the I/O complexity to $O(E^{3/2}/(\\sqrt{M} B))$ expected\nI/Os, which improves the previous bounds by a factor\n$\\min(\\sqrt{E/M},\\sqrt{M})$. Our algorithm is cache-oblivious and also I/O\noptimal: We show that any algorithm enumerating $t$ distinct triangles must\nalways use $\\Omega(t/(\\sqrt{M} B))$ I/Os, and there are graphs for which\n$t=\\Omega(E^{3/2})$. Finally, we give a deterministic cache-aware algorithm\nusing $O(E^{3/2}/(\\sqrt{M} B))$ I/Os assuming $M\\geq E^\\varepsilon$ for a\nconstant $\\varepsilon > 0$. Our results are based on a new color coding\ntechnique, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 07:54:00 GMT"}, {"version": "v2", "created": "Sat, 22 Mar 2014 22:32:42 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Pagh", "Rasmus", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1312.0925", "submitter": "Moritz Hardt", "authors": "Moritz Hardt", "title": "Understanding Alternating Minimization for Matrix Completion", "comments": "Slightly improved main theorem and a correction: The tail bound\n  stated in Lemma A.5 of the previous version is incorrect. See manuscript for\n  fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Minimization is a widely used and empirically successful\nheuristic for matrix completion and related low-rank optimization problems.\nTheoretical guarantees for Alternating Minimization have been hard to come by\nand are still poorly understood. This is in part because the heuristic is\niterative and non-convex in nature. We give a new algorithm based on\nAlternating Minimization that provably recovers an unknown low-rank matrix from\na random subsample of its entries under a standard incoherence assumption. Our\nresults reduce the sample size requirements of the Alternating Minimization\napproach by at least a quartic factor in the rank and the condition number of\nthe unknown matrix. These improvements apply even if the matrix is only close\nto low-rank in the Frobenius norm. Our algorithm runs in nearly linear time in\nthe dimension of the matrix and, in a broad range of parameters, gives the\nstrongest sample bounds among all subquadratic time algorithms that we are\naware of.\n  Underlying our work is a new robust convergence analysis of the well-known\nPower Method for computing the dominant singular vectors of a matrix. This\nviewpoint leads to a conceptually simple understanding of Alternating\nMinimization. In addition, we contribute a new technique for controlling the\ncoherence of intermediate solutions arising in iterative algorithms based on a\nsmoothed analysis of the QR factorization. These techniques may be of interest\nbeyond their application here.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 20:37:28 GMT"}, {"version": "v2", "created": "Wed, 9 Apr 2014 21:28:27 GMT"}, {"version": "v3", "created": "Wed, 14 May 2014 19:54:58 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Hardt", "Moritz", ""]]}, {"id": "1312.1054", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Gautam Kamath", "title": "Faster and Sample Near-Optimal Algorithms for Proper Learning Mixtures\n  of Gaussians", "comments": "31 pages, to appear in COLT 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an algorithm for properly learning mixtures of two\nsingle-dimensional Gaussians without any separability assumptions. Given\n$\\tilde{O}(1/\\varepsilon^2)$ samples from an unknown mixture, our algorithm\noutputs a mixture that is $\\varepsilon$-close in total variation distance, in\ntime $\\tilde{O}(1/\\varepsilon^5)$. Our sample complexity is optimal up to\nlogarithmic factors, and significantly improves upon both Kalai et al., whose\nalgorithm has a prohibitive dependence on $1/\\varepsilon$, and Feldman et al.,\nwhose algorithm requires bounds on the mixture parameters and depends\npseudo-polynomially in these parameters.\n  One of our main contributions is an improved and generalized algorithm for\nselecting a good candidate distribution from among competing hypotheses.\nNamely, given a collection of $N$ hypotheses containing at least one candidate\nthat is $\\varepsilon$-close to an unknown distribution, our algorithm outputs a\ncandidate which is $O(\\varepsilon)$-close to the distribution. The algorithm\nrequires ${O}(\\log{N}/\\varepsilon^2)$ samples from the unknown distribution and\n${O}(N \\log N/\\varepsilon^2)$ time, which improves previous such results (such\nas the Scheff\\'e estimator) from a quadratic dependence of the running time on\n$N$ to quasilinear. Given the wide use of such results for the purpose of\nhypothesis selection, our improved algorithm implies immediate improvements to\nany such use.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 08:31:58 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2014 16:35:23 GMT"}, {"version": "v3", "created": "Mon, 19 May 2014 13:26:05 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""]]}, {"id": "1312.1273", "submitter": "Jun He", "authors": "Boris Mitavskiy and Jun He", "title": "Design and Analysis of an Estimation of Distribution Approximation\n  Algorithm for Single Machine Scheduling in Uncertain Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current work we introduce a novel estimation of distribution algorithm\nto tackle a hard combinatorial optimization problem, namely the single-machine\nscheduling problem, with uncertain delivery times. The majority of the existing\nresearch coping with optimization problems in uncertain environment aims at\nfinding a single sufficiently robust solution so that random noise and\nunpredictable circumstances would have the least possible detrimental effect on\nthe quality of the solution. The measures of robustness are usually based on\nvarious kinds of empirically designed averaging techniques. In contrast to the\nprevious work, our algorithm aims at finding a collection of robust schedules\nthat allow for a more informative decision making. The notion of robustness is\nmeasured quantitatively in terms of the classical mathematical notion of a norm\non a vector space. We provide a theoretical insight into the relationship\nbetween the properties of the probability distribution over the uncertain\ndelivery times and the robustness quality of the schedules produced by the\nalgorithm after a polynomial runtime in terms of approximation ratios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 10:40:35 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Mitavskiy", "Boris", ""], ["He", "Jun", ""]]}, {"id": "1312.1277", "submitter": "Aleksandrs Slivkins", "authors": "Robert Kleinberg, Aleksandrs Slivkins and Eli Upfal", "title": "Bandits and Experts in Metric Spaces", "comments": "This manuscript is a merged and definitive version of (R. Kleinberg,\n  Slivkins, Upfal: STOC 2008) and (R. Kleinberg, Slivkins: SODA 2010), with a\n  significantly revised presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-armed bandit problem, an online algorithm chooses from a set of\nstrategies in a sequence of trials so as to maximize the total payoff of the\nchosen strategies. While the performance of bandit algorithms with a small\nfinite strategy set is quite well understood, bandit problems with large\nstrategy sets are still a topic of very active investigation, motivated by\npractical applications such as online auctions and web advertisement. The goal\nof such research is to identify broad and natural classes of strategy sets and\npayoff functions which enable the design of efficient solutions.\n  In this work we study a very general setting for the multi-armed bandit\nproblem in which the strategies form a metric space, and the payoff function\nsatisfies a Lipschitz condition with respect to the metric. We refer to this\nproblem as the \"Lipschitz MAB problem\". We present a solution for the\nmulti-armed bandit problem in this setting. That is, for every metric space we\ndefine an isometry invariant which bounds from below the performance of\nLipschitz MAB algorithms for this metric space, and we present an algorithm\nwhich comes arbitrarily close to meeting this bound. Furthermore, our technique\ngives even better results for benign payoff functions. We also address the\nfull-feedback (\"best expert\") version of the problem, where after every round\nthe payoffs from all arms are revealed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 18:48:00 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 14:26:27 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 22:17:00 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 14:49:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kleinberg", "Robert", ""], ["Slivkins", "Aleksandrs", ""], ["Upfal", "Eli", ""]]}, {"id": "1312.1382", "submitter": "Tsvi Kopelowitz", "authors": "Tsvi Kopelowitz, Robert Krauthgamer, Ely Porat, Shay Solomon", "title": "Orienting Fully Dynamic Graphs with Worst-Case Time Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In edge orientations, the goal is usually to orient (direct) the edges of an\nundirected $n$-vertex graph $G$ such that all out-degrees are bounded. When the\ngraph $G$ is fully dynamic, i.e., admits edge insertions and deletions, we wish\nto maintain such an orientation while keeping a tab on the update time. Low\nout-degree orientations turned out to be a surprisingly useful tool, with\nseveral algorithmic applications involving static or dynamic graphs.\n  Brodal and Fagerberg (1999) initiated the study of the edge orientation\nproblem in terms of the graph's arboricity, which is very natural in this\ncontext. They provided a solution with constant out-degree and \\emph{amortized}\nlogarithmic update time for all graphs with constant arboricity, which include\nall planar and excluded-minor graphs. However, it remained an open question\n(first proposed by Brodal and Fagerberg, later by others) to obtain similar\nbounds with worst-case update time.\n  We resolve this 15 year old question in the affirmative, by providing a\nsimple algorithm with worst-case bounds that nearly match the previous\namortized bounds. Our algorithm is based on a new approach of a combinatorial\ninvariant, and achieves a logarithmic out-degree with logarithmic worst-case\nupdate times. This result has applications in various dynamic graph problems\nsuch as maintaining a maximal matching, where we obtain $O(\\log n)$ worst-case\nupdate time compared to the $O(\\frac{\\log n}{\\log\\log n})$ amortized update\ntime of Neiman and Solomon (2013).\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 23:28:27 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Kopelowitz", "Tsvi", ""], ["Krauthgamer", "Robert", ""], ["Porat", "Ely", ""], ["Solomon", "Shay", ""]]}, {"id": "1312.1526", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Amiri, Ali Golshani, Stephan Kreutzer, Sebastian Siebertz", "title": "Vertex Disjoint Path in Upward Planar Graphs", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-vertex disjoint paths problem is one of the most studied problems in\nalgorithmic graph theory. In 1994, Schrijver proved that the problem can be\nsolved in polynomial time for every fixed $k$ when restricted to the class of\nplanar digraphs and it was a long standing open question whether it is\nfixed-parameter tractable (with respect to parameter $k$) on this restricted\nclass. Only recently, \\cite{CMPP}.\\ achieved a major breakthrough and answered\nthe question positively. Despite the importance of this result (and the\nbrilliance of their proof), it is of rather theoretical importance. Their proof\ntechnique is both technically extremely involved and also has at least double\nexponential parameter dependence. Thus, it seems unrealistic that the algorithm\ncould actually be implemented. In this paper, therefore, we study a smaller\nclass of planar digraphs, the class of upward planar digraphs, a well studied\nclass of planar graphs which can be drawn in a plane such that all edges are\ndrawn upwards. We show that on the class of upward planar digraphs the problem\n(i) remains NP-complete and (ii) the problem is fixed-parameter tractable.\nWhile membership in FPT follows immediately from \\cite{CMPP}'s general result,\nour algorithm has only single exponential parameter dependency compared to the\ndouble exponential parameter dependence for general planar digraphs.\nFurthermore, our algorithm can easily be implemented, in contrast to the\nalgorithm in \\cite{CMPP}.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 12:47:28 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Amiri", "Saeed", ""], ["Golshani", "Ali", ""], ["Kreutzer", "Stephan", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1312.1558", "submitter": "Tarek Hamrouni", "authors": "Tarek Hamrouni and Sadok Ben Yahia and Engelbert Mephu Nguifo", "title": "Efficient construction of the lattice of frequent closed patterns and\n  simultaneous extraction of generic bases of rules", "comments": "50 pages, in French", "journal-ref": "Mathematics and Social Sciences, Volume 49, Number 195, 2011(3),\n  pages 5-54", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, the amount of collected data, in various computer\nscience applications, has grown considerably. These large volumes of data need\nto be analyzed in order to extract useful hidden knowledge. This work focuses\non association rule extraction. This technique is one of the most popular in\ndata mining. Nevertheless, the number of extracted association rules is often\nvery high, and many of them are redundant. In this paper, we propose a new\nalgorithm, called PRINCE. Its main feature is the construction of a partially\nordered structure for extracting subsets of association rules, called generic\nbases. Without loss of information these subsets form representation of the\nwhole association rule set. To reduce the cost of such a construction, the\npartially ordered structure is built thanks to the minimal generators\nassociated to frequent closed patterns. The closed ones are simultaneously\nderived with generic bases thanks to a simple bottom-up traversal of the\nobtained structure. The experimentations we carried out in benchmark and \"worst\ncase\" contexts showed the efficiency of the proposed algorithm, compared to\nalgorithms like CLOSE, A-CLOSE and TITANIC.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 14:23:16 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 11:51:11 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Hamrouni", "Tarek", ""], ["Yahia", "Sadok Ben", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "1312.1672", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Stefan Szeider", "title": "The Parameterized Complexity of Reasoning Problems Beyond NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's propositional satisfiability (SAT) solvers are extremely powerful and\ncan be used as an efficient back-end for solving NP-complete problems. However,\nmany fundamental problems in knowledge representation and reasoning are located\nat the second level of the Polynomial Hierarchy or even higher, and hence\npolynomial-time transformations to SAT are not possible, unless the hierarchy\ncollapses. Recent research shows that in certain cases one can break through\nthese complexity barriers by fixed-parameter tractable (fpt) reductions which\nexploit structural aspects of problem instances in terms of problem parameters.\nIn this paper we develop a general theoretical framework that supports the\nclassification of parameterized problems on whether they admit such an\nfpt-reduction to SAT or not. This framework is based on several new\nparameterized complexity classes. As a running example, we use the framework to\nclassify the complexity of the consistency problem for disjunctive answer set\nprogramming, with respect to various natural parameters. We underpin the\nrobustness of our theory by providing a characterization of the new complexity\nclasses in terms of weighted QBF satisfiability, alternating Turing machines,\nand first-order model checking. In addition, we provide a compendium of\nparameterized problems that are complete for the new complexity classes,\nincluding problems related to Knowledge Representation and Reasoning, Logic,\nand Combinatorics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 20:20:06 GMT"}, {"version": "v2", "created": "Wed, 9 Jul 2014 13:01:25 GMT"}, {"version": "v3", "created": "Fri, 31 Oct 2014 16:33:04 GMT"}, {"version": "v4", "created": "Fri, 1 Jul 2016 17:37:52 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["de Haan", "Ronald", ""], ["Szeider", "Stefan", ""]]}, {"id": "1312.1755", "submitter": "David J. Rosenbaum", "authors": "David J. Rosenbaum and Fabian Wagner", "title": "Beating the Generator-Enumeration Bound for $p$-Group Isomorphism", "comments": "15 pages. This is an updated and improved version of the results for\n  p-groups in arXiv:1205.0642 and TR11-052 in ECCC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the group isomorphism problem: given two finite groups G and H\nspecified by their multiplication tables, decide if G cong H. For several\ndecades, the n^(log_p n + O(1)) generator-enumeration bound (where p is the\nsmallest prime dividing the order of the group) has been the best worst-case\nresult for general groups. In this work, we show the first improvement over the\ngenerator-enumeration bound for p-groups, which are believed to be the hard\ncase of the group isomorphism problem. We start by giving a Turing reduction\nfrom group isomorphism to n^((1 / 2) log_p n + O(1)) instances of p-group\ncomposition-series isomorphism. By showing a Karp reduction from p-group\ncomposition-series isomorphism to testing isomorphism of graphs of degree at\nmost p + O(1) and applying algorithms for testing isomorphism of graphs of\nbounded degree, we obtain an n^(O(p)) time algorithm for p-group\ncomposition-series isomorphism. Combining these two results yields an algorithm\nfor p-group isomorphism that takes at most n^((1 / 2) log_p n + O(p)) time.\nThis algorithm is faster than generator-enumeration when p is small and slower\nwhen p is large. Choosing the faster algorithm based on p and n yields an upper\nbound of n^((1 / 2 + o(1)) log n) for p-group isomorphism.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 02:36:07 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Rosenbaum", "David J.", ""], ["Wagner", "Fabian", ""]]}, {"id": "1312.1763", "submitter": "Bernhard Haeupler", "authors": "Mohsen Ghaffari, Bernhard Haeupler", "title": "Optimal Error Rates for Interactive Coding II: Efficiency and List\n  Decoding", "comments": "preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study coding schemes for error correction in interactive communications.\nSuch interactive coding schemes simulate any $n$-round interactive protocol\nusing $N$ rounds over an adversarial channel that corrupts up to $\\rho N$\ntransmissions. Important performance measures for a coding scheme are its\nmaximum tolerable error rate $\\rho$, communication complexity $N$, and\ncomputational complexity.\n  We give the first coding scheme for the standard setting which performs\noptimally in all three measures: Our randomized non-adaptive coding scheme has\na near-linear computational complexity and tolerates any error rate $\\delta <\n1/4$ with a linear $N = \\Theta(n)$ communication complexity. This improves over\nprior results which each performed well in two of these measures.\n  We also give results for other settings of interest, namely, the first\ncomputationally and communication efficient schemes that tolerate $\\rho <\n\\frac{2}{7}$ adaptively, $\\rho < \\frac{1}{3}$ if only one party is required to\ndecode, and $\\rho < \\frac{1}{2}$ if list decoding is allowed. These are the\noptimal tolerable error rates for the respective settings. These coding schemes\nalso have near linear computational and communication complexity.\n  These results are obtained via two techniques: We give a general black-box\nreduction which reduces unique decoding, in various settings, to list decoding.\nWe also show how to boost the computational and communication efficiency of any\nlist decoder to become near linear.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 04:18:55 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 01:29:21 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""]]}, {"id": "1312.1764", "submitter": "Bernhard Haeupler", "authors": "Mohsen Ghaffari, Bernhard Haeupler, Madhu Sudan", "title": "Optimal Error Rates for Interactive Coding I: Adaptivity and Other\n  Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of interactive communication in the presence of\nadversarial errors and present tight bounds on the tolerable error-rates in a\nnumber of different settings.\n  Most significantly, we explore adaptive interactive communication where the\ncommunicating parties decide who should speak next based on the history of the\ninteraction. Braverman and Rao [STOC'11] show that non-adaptively one can code\nfor any constant error rate below 1/4 but not more. They asked whether this\nbound could be improved using adaptivity. We answer this open question in the\naffirmative (with a slightly different collection of resources): Our adaptive\ncoding scheme tolerates any error rate below 2/7 and we show that tolerating a\nhigher error rate is impossible. We also show that in the setting of Franklin\net al. [CRYPTO'13], where parties share randomness not known to the adversary,\nadaptivity increases the tolerable error rate from 1/2 to 2/3. For\nlist-decodable interactive communications, where each party outputs a constant\nsize list of possible outcomes, the tight tolerable error rate is 1/2.\n  Our negative results hold even if the communication and computation are\nunbounded, whereas for our positive results communication and computation are\npolynomially bounded. Most prior work considered coding schemes with linear\namount of communication, while allowing unbounded computations. We argue that\nstudying tolerable error rates in this relaxed context helps to identify a\nsetting's intrinsic optimal error rate. We set forward a strong working\nhypothesis which stipulates that for any setting the maximum tolerable error\nrate is independent of many computational and communication complexity\nmeasures. We believe this hypothesis to be a powerful guideline for the design\nof simple, natural, and efficient coding schemes and for understanding the\n(im)possibilities of coding for interactive communications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 04:23:26 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""], ["Sudan", "Madhu", ""]]}, {"id": "1312.1819", "submitter": "Yannis Moysoglou", "authors": "Stavros G. Kolliopoulos and Yannis Moysoglou", "title": "Exponential lower bounds on the size of approximate formulations in the\n  natural encoding for Capacitated Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metric capacitated facility location is a well-studied problem for which,\nwhile constant factor approximations are known, no efficient relaxation with\nconstant integrality gap is known. The question whether there is such a\nrelaxation is among the most important open problems of approximation\nalgorithms \\cite{ShmoysWbook}.\n  In this paper we show that, if one is restricted to linear programs that use\nthe natural encoding for facility location, at least an exponential number of\nconstraints is needed to achieve a constant gap. Our proof does not assume any\nspecial property of the relaxation such as locality or symmetry.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 10:06:20 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Kolliopoulos", "Stavros G.", ""], ["Moysoglou", "Yannis", ""]]}, {"id": "1312.1831", "submitter": "Chaitanya Swamy", "authors": "Deeparnab Chakrabarty and Chaitanya Swamy", "title": "Welfare Maximization and Truthfulness in Mechanism Design with Ordinal\n  Preferences", "comments": "Some typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study mechanism design problems in the {\\em ordinal setting} wherein the\npreferences of agents are described by orderings over outcomes, as opposed to\nspecific numerical values associated with them. This setting is relevant when\nagents can compare outcomes, but aren't able to evaluate precise utilities for\nthem. Such a situation arises in diverse contexts including voting and matching\nmarkets.\n  Our paper addresses two issues that arise in ordinal mechanism design. To\ndesign social welfare maximizing mechanisms, one needs to be able to\nquantitatively measure the welfare of an outcome which is not clear in the\nordinal setting. Second, since the impossibility results of Gibbard and\nSatterthwaite~\\cite{Gibbard73,Satterthwaite75} force one to move to randomized\nmechanisms, one needs a more nuanced notion of truthfulness.\n  We propose {\\em rank approximation} as a metric for measuring the quality of\nan outcome, which allows us to evaluate mechanisms based on worst-case\nperformance, and {\\em lex-truthfulness} as a notion of truthfulness for\nrandomized ordinal mechanisms. Lex-truthfulness is stronger than notions\nstudied in the literature, and yet flexible enough to admit a rich class of\nmechanisms {\\em circumventing classical impossibility results}. We demonstrate\nthe usefulness of the above notions by devising lex-truthful mechanisms\nachieving good rank-approximation factors, both in the general ordinal setting,\nas well as structured settings such as {\\em (one-sided) matching markets}, and\nits generalizations, {\\em matroid} and {\\em scheduling} markets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 11:38:02 GMT"}, {"version": "v2", "created": "Sat, 8 Mar 2014 01:33:37 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1312.1961", "submitter": "Christian  Lavault", "authors": "Marc Bui (CHART), Franck Butelle (LIPN), Christian Lavault (LIPN)", "title": "A Distributed Algorithm for Constructing a Minimum Diameter Spanning\n  Tree", "comments": "Comments: 11 pages LaTeX, 2 figures; International Journal with\n  referees article; New version (full paper design): results added in Section\n  2.2 and 2.2; typos removed", "journal-ref": "Journal of Parallel and Distributed Computing 64, 5 (2004) 571-577", "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm, which solves the problem of distributively\nfinding a minimum diameter spanning tree of any (non-negatively) real-weighted\ngraph $G = (V,E,\\omega)$. As an intermediate step, we use a new, fast,\nlinear-time all-pairs shortest paths distributed algorithm to find an absolute\ncenter of $G$. The resulting distributed algorithm is asynchronous, it works\nfor named asynchronous arbitrary networks and achieves $\\mathcal{O}(|V|)$ time\ncomplexity and $\\mathcal{O}\\left(|V|\\,|E|\\right)$\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 19:04:02 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 08:09:33 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Bui", "Marc", "", "CHART"], ["Butelle", "Franck", "", "LIPN"], ["Lavault", "Christian", "", "LIPN"]]}, {"id": "1312.1986", "submitter": "Christina Lee", "authors": "Christina E. Lee, Asuman Ozdaglar, Devavrat Shah", "title": "Approximating the Stationary Probability of a Single State in a Markov\n  chain", "comments": "A short version appeared in NIPS Conference Dec 2013", "journal-ref": null, "doi": null, "report-no": "MIT LIDS Report 2914", "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel iterative Monte Carlo method for\napproximating the stationary probability of a single state of a positive\nrecurrent Markov chain. We utilize the characterization that the stationary\nprobability of a state $i$ is inversely proportional to the expected return\ntime of a random walk beginning at $i$. Our method obtains an\n$\\epsilon$-multiplicative close estimate with probability greater than $1 -\n\\alpha$ using at most $\\tilde{O}\\left(t_{\\text{mix}} \\ln(1/\\alpha) / \\pi_i\n\\epsilon^2 \\right)$ simulated random walk steps on the Markov chain across all\niterations, where $t_{\\text{mix}}$ is the standard mixing time and $\\pi_i$ is\nthe stationary probability. In addition, the estimate at each iteration is\nguaranteed to be an upper bound with high probability, and is decreasing in\nexpectation with the iteration count, allowing us to monitor the progress of\nthe algorithm and design effective termination criteria. We propose a\ntermination criteria which guarantees a $\\epsilon (1 + 4 \\ln(2)\nt_{\\text{mix}})$ multiplicative error performance for states with stationary\nprobability larger than $\\Delta$, while providing an additive error for states\nwith stationary probability less than $\\Delta \\in (0,1)$. The algorithm along\nwith this termination criteria uses at most\n$\\tilde{O}\\left(\\frac{\\ln(1/\\alpha)}{\\epsilon^2}\n\\min\\left(\\frac{t_{\\text{mix}}}{\\pi_i}, \\frac{1}{\\epsilon\n\\Delta}\\right)\\right)$ simulated random walk steps, which is bounded by a\nconstant with respect to the Markov Chain. We provide a tight analysis of our\nalgorithm based on a locally weighted variant of the mixing time. Our results\nnaturally extend for countably infinite state space Markov chains via Lyapunov\nfunction analysis.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 20:04:40 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 19:21:39 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Lee", "Christina E.", ""], ["Ozdaglar", "Asuman", ""], ["Shah", "Devavrat", ""]]}, {"id": "1312.2018", "submitter": "Mikkel Thorup", "authors": "Lars Arge and Mikkel Thorup", "title": "RAM-Efficient External Memory Sorting", "comments": "To appear in Proceedings of ISAAC 2013, getting the Best Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years a large number of problems have been considered in external\nmemory models of computation, where the complexity measure is the number of\nblocks of data that are moved between slow external memory and fast internal\nmemory (also called I/Os). In practice, however, internal memory time often\ndominates the total running time once I/O-efficiency has been obtained. In this\npaper we study algorithms for fundamental problems that are simultaneously\nI/O-efficient and internal memory efficient in the RAM model of computation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 21:26:44 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2013 17:43:13 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Arge", "Lars", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1312.2141", "submitter": "Jenish Mehta", "authors": "Jenish C. Mehta", "title": "Dynamic Complexity of Planar 3-connected Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Complexity (as introduced by Patnaik and Immerman) tries to express\nhow hard it is to update the solution to a problem when the input is changed\nslightly. It considers the changes required to some stored data structure\n(possibly a massive database) as small quantities of data (or a tuple) are\ninserted or deleted from the database (or a structure over some vocabulary).\nThe main difference from previous notions of dynamic complexity is that instead\nof treating the update quantitatively by finding the the time/space trade-offs,\nit tries to consider the update qualitatively, by finding the complexity class\nin which the update can be expressed (or made). In this setting, DynFO, or\nDynamic First-Order, is one of the smallest and the most natural complexity\nclass (since SQL queries can be expressed in First-Order Logic), and contains\nthose problems whose solutions (or the stored data structure from which the\nsolution can be found) can be updated in First-Order Logic when the data\nstructure undergoes small changes.\n  Etessami considered the problem of isomorphism in the dynamic setting, and\nshowed that Tree Isomorphism can be decided in DynFO. In this work, we show\nthat isomorphism of Planar 3-connected graphs can be decided in DynFO+ (which\nis DynFO with some polynomial precomputation). We maintain a canonical\ndescription of 3-connected Planar graphs by maintaining a database which is\naccessed and modified by First-Order queries when edges are added to or deleted\nfrom the graph. We specifically exploit the ideas of Breadth-First Search and\nCanonical Breadth-First Search to prove the results. We also introduce a novel\nmethod for canonizing a 3-connected planar graph in First-Order Logic from\nCanonical Breadth-First Search Trees.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 20:49:44 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Mehta", "Jenish C.", ""]]}, {"id": "1312.2173", "submitter": "Norman Huang", "authors": "Norman Huang and Allan Borodin", "title": "Bounds on Double-Sided Myopic Algorithms for Unconstrained Non-monotone\n  Submodular Maximization", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unconstrained submodular maximization captures many NP-hard combinatorial\noptimization problems, including Max-Cut, Max-Di-Cut, and variants of facility\nlocation problems. Recently, Buchbinder et al. presented a surprisingly simple\nlinear time randomized greedy-like online algorithm that achieves a constant\napproximation ratio of 1/2, matching optimally the hardness result of Feige et\nal.. Motivated by the algorithm of Buchbinder et al., we introduce a precise\nalgorithmic model called double-sided myopic algorithms. We show that while the\nalgorithm of Buchbinder et al. can be realized as a randomized online\ndouble-sided myopic algorithm, no such deterministic algorithm, even with\nadaptive ordering, can achieve the same approximation ratio. With respect to\nthe Max-Di-Cut problem, we relate the Buchbinder et al. algorithm and our\nmyopic framework to the online algorithm and inapproximation of Bar-Noy and\nLampis.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 03:54:33 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 06:23:21 GMT"}, {"version": "v3", "created": "Thu, 24 Apr 2014 18:14:14 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Huang", "Norman", ""], ["Borodin", "Allan", ""]]}, {"id": "1312.2194", "submitter": "Natan Rubin", "authors": "Natan Rubin", "title": "On Kinetic Delaunay Triangulations: A Near Quadratic Bound for Unit\n  Speed Motions", "comments": "138 pages+ Appendix of 7 pages. A preliminary version has appeared in\n  Proceedings of the 54th Annual Symposium on Foundations of Computer Science\n  (FOCS 2013). The paper extends the result of http://arxiv.org/abs/1304.3671\n  to more general motions. The presentation is self-contained with main ideas\n  delivered in Sections 1--4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a collection of $n$ points in the plane, each moving along some\nstraight line at unit speed. We obtain an almost tight upper bound of\n$O(n^{2+\\epsilon})$, for any $\\epsilon>0$, on the maximum number of discrete\nchanges that the Delaunay triangulation $\\mathbb{DT}(P)$ of $P$ experiences\nduring this motion. Our analysis is cast in a purely topological setting, where\nwe only assume that (i) any four points can be co-circular at most three times,\nand (ii) no triple of points can be collinear more than twice; these\nassumptions hold for unit speed motions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 11:49:19 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Rubin", "Natan", ""]]}, {"id": "1312.2217", "submitter": "Szymon Grabowski", "authors": "Szymon Grabowski", "title": "New tabulation and sparse dynamic programming based techniques for\n  sequence similarity problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculating the length of a longest common subsequence (LCS) of two strings\n$A$ and $B$ of length $n$ and $m$ is a classic research topic, with many\nworst-case oriented results known. We present two algorithms for LCS length\ncalculation with respectively $O(mn \\log\\log n / \\log^2 n)$ and $O(mn / \\log^2\nn + r)$ time complexity, the latter working for $r = o(mn / (\\log n \\log\\log\nn))$, where $r$ is the number of matches in the dynamic programming matrix. We\nalso describe conditions for a given problem sufficient to apply our\ntechniques, with several concrete examples presented, namely the edit distance,\nLCTS and MerLCS problems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 14:09:17 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 16:37:34 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Grabowski", "Szymon", ""]]}, {"id": "1312.2381", "submitter": "Jakub Radoszewski", "authors": "Maxime Crochemore, Costas S. Iliopoulos, Tomasz Kociumaka, Marcin\n  Kubica, Alessio Langiu, Jakub Radoszewski, Wojciech Rytter, Bartosz Szreder,\n  Tomasz Wale\\'n", "title": "A Note on the Longest Common Compatible Prefix Problem for Partial Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a partial word $w$ the longest common compatible prefix of two positions\n$i,j$, denoted $lccp(i,j)$, is the largest $k$ such that $w[i,i+k-1]\\uparrow\nw[j,j+k-1]$, where $\\uparrow$ is the compatibility relation of partial words\n(it is not an equivalence relation). The LCCP problem is to preprocess a\npartial word in such a way that any query $lccp(i,j)$ about this word can be\nanswered in $O(1)$ time. It is a natural generalization of the longest common\nprefix (LCP) problem for regular words, for which an $O(n)$ preprocessing time\nand $O(1)$ query time solution exists.\n  Recently an efficient algorithm for this problem has been given by F.\nBlanchet-Sadri and J. Lazarow (LATA 2013). The preprocessing time was\n$O(nh+n)$, where $h$ is the number of \"holes\" in $w$. The algorithm was\ndesigned for partial words over a constant alphabet and was quite involved.\n  We present a simple solution to this problem with slightly better runtime\nthat works for any linearly-sortable alphabet. Our preprocessing is in time\n$O(n\\mu+n)$, where $\\mu$ is the number of blocks of holes in $w$. Our algorithm\nuses ideas from alignment algorithms and dynamic programming.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 11:10:11 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Crochemore", "Maxime", ""], ["Iliopoulos", "Costas S.", ""], ["Kociumaka", "Tomasz", ""], ["Kubica", "Marcin", ""], ["Langiu", "Alessio", ""], ["Radoszewski", "Jakub", ""], ["Rytter", "Wojciech", ""], ["Szreder", "Bartosz", ""], ["Wale\u0144", "Tomasz", ""]]}, {"id": "1312.2502", "submitter": "Tobias M\\\"omke", "authors": "Matthias Mnich and Tobias M\\\"omke", "title": "Improved integrality gap upper bounds for TSP with distances one and two", "comments": "36 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structure of solutions to linear programming formulations for\nthe traveling salesperson problem (TSP).\n  We perform a detailed analysis of the support of the subtour elimination\nlinear programming relaxation, which leads to algorithms that find 2-matchings\nwith few components in polynomial time. The number of components directly leads\nto integrality gap upper bounds for the TSP with distances one and two, for\nboth undirected and directed graphs.\n  Our main results concern the subtour elimination relaxation with one\nadditional cutting plane inequality:\n  - For undirected instances we obtain an integrality gap upper bound of 5/4\nwithout any further restrictions, of 7/6 if the optimal LP solution is\nhalf-integral.\n  - For instances of order n where the fractional LP value has a cost of n, we\nobtain a tight integrality gap upper bound of 10/9 if there is an optimal\nsolution with subcubic support graph. The latter property that the graph is\nsubcubic is implied if the solution is a basic solution in the fractional\n2-matching polytope.\n  - For directed instances we obtain an integrality gap upper bound of 3/2, and\nof 4/3 if given an optimal 1/2-integral solution. In the case of undirected\ngraphs, we can avoid to add the cutting plane inequality if we accept slightly\nincreased values. For the tight result, the cutting plane is not required.\n  Additionally, we show that relying on the structure of the support is not an\nartefact of our algorithm, but is necessary under standard complexity-theoretic\nassumptions: we show that finding improved solutions via local search is\nW[1]-hard for k-edge change neighborhoods even for the TSP with distances one\nand two, which strengthens a result of D\\'aniel Marx.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 16:30:44 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 14:29:08 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Mnich", "Matthias", ""], ["M\u00f6mke", "Tobias", ""]]}, {"id": "1312.2738", "submitter": "Bojian Xu", "authors": "Atalay Mert \\.Ileri and M. O\\u{g}uzhan K\\\"ulekci and Bojian Xu", "title": "Shortest Unique Substring Query Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of finding shortest unique substring (SUS) proposed\nrecently by [6]. We propose an optimal $O(n)$ time and space algorithm that can\nfind an SUS for every location of a string of size $n$. Our algorithm\nsignificantly improves the $O(n^2)$ time complexity needed by [6]. We also\nsupport finding all the SUSes covering every location, whereas the solution in\n[6] can find only one SUS for every location. Further, our solution is simpler\nand easier to implement and can also be more space efficient in practice, since\nwe only use the inverse suffix array and longest common prefix array of the\nstring, while the algorithm in [6] uses the suffix tree of the string and other\nauxiliary data structures. Our theoretical results are validated by an\nempirical study that shows our algorithm is much faster and more space-saving\nthan the one in [6].\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 10:06:13 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 01:37:52 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2014 23:10:22 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["\u0130leri", "Atalay Mert", ""], ["K\u00fclekci", "M. O\u011fuzhan", ""], ["Xu", "Bojian", ""]]}, {"id": "1312.2889", "submitter": "Ignasi Sau", "authors": "Julien Baste and Ignasi Sau", "title": "The role of planarity in connectivity problems parameterized by\n  treewidth", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some years it was believed that for \"connectivity\" problems such as\nHamiltonian Cycle, algorithms running in time 2^{O(tw)}n^{O(1)} -called\nsingle-exponential- existed only on planar and other sparse graph classes,\nwhere tw stands for the treewidth of the n-vertex input graph. This was\nrecently disproved by Cygan et al. [FOCS 2011], Bodlaender et al. [ICALP 2013],\nand Fomin et al. [SODA 2014], who provided single-exponential algorithms on\ngeneral graphs for essentially all connectivity problems that were known to be\nsolvable in single-exponential time on sparse graphs. In this article we\nfurther investigate the role of planarity in connectivity problems\nparameterized by treewidth, and convey that several problems can indeed be\ndistinguished according to their behavior on planar graphs. Known results from\nthe literature imply that there exist problems, like Cycle Packing, that cannot\nbe solved in time 2^{o(tw logtw)}n^{O(1)} on general graphs but that can be\nsolved in time 2^{O(tw)}n^{O(1)} when restricted to planar graphs. Our main\ncontribution is to show that there exist problems that can be solved in time\n2^{O(tw logtw)}n^{O(1)} on general graphs but that cannot be solved in time\n2^{o(tw logtw)}n^{O(1)} even when restricted to planar graphs. Furthermore, we\nprove that Planar Cycle Packing and Planar Disjoint Paths cannot be solved in\ntime 2^{o(tw)}n^{O(1)}. The mentioned negative results hold unless the ETH\nfails. We feel that our results constitute a first step in a subject that can\nbe further exploited.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 17:27:12 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Baste", "Julien", ""], ["Sau", "Ignasi", ""]]}, {"id": "1312.3024", "submitter": "Ali Sinop", "authors": "Venkatesan Guruswami and Ali Kemal Sinop", "title": "Rounding Lasserre SDPs using column selection and spectrum-based\n  approximation schemes for graph partitioning and Quadratic IPs", "comments": "This manuscript is a merged and definitive version of (Guruswami,\n  Sinop: FOCS 2011) and (Guruswami, Sinop: SODA 2013), with a significantly\n  revised presentation. arXiv admin note: substantial text overlap with\n  arXiv:1104.4746", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation scheme for minimizing certain Quadratic Integer\nProgramming problems with positive semidefinite objective functions and global\nlinear constraints. This framework includes well known graph problems such as\nMinimum graph bisection, Edge expansion, Sparsest Cut, and Small Set expansion,\nas well as the Unique Games problem. These problems are notorious for the\nexistence of huge gaps between the known algorithmic results and NP-hardness\nresults. Our algorithm is based on rounding semidefinite programs from the\nLasserre hierarchy, and the analysis uses bounds for low-rank approximations of\na matrix in Frobenius norm using columns of the matrix.\n  For all the above graph problems, we give an algorithm running in time\n$n^{O(r/\\epsilon^2)}$ with approximation ratio\n$\\frac{1+\\epsilon}{\\min\\{1,\\lambda_r\\}}$, where $\\lambda_r$ is the $r$'th\nsmallest eigenvalue of the normalized graph Laplacian $\\mathcal{L}$. In the\ncase of graph bisection and small set expansion, the number of vertices in the\ncut is within lower-order terms of the stipulated bound. Our results imply\n$(1+O(\\epsilon))$ factor approximation in time $n^{O(r^\\ast/\\epsilon^2)}$ where\nis the number of eigenvalues of $\\mathcal{L}$ smaller than $1-\\epsilon$ (for\nvariants of sparsest cut, $\\lambda_{r^\\ast} \\ge \\mathrm{OPT}/\\epsilon$ also\nsuffices, and as $\\mathrm{OPT}$ is usually $o(1)$ on interesting instances of\nthese problems, this requirement on $r^\\ast$ is typically weaker). For Unique\nGames, we give a factor $(1+\\frac{2+\\epsilon}{\\lambda_r})$ approximation for\nminimizing the number of unsatisfied constraints in $n^{O(r/\\epsilon)}$ time,\nimproving upon an earlier bound for solving Unique Games on expanders. We also\ngive an algorithm for independent sets in graphs that performs well when the\nLaplacian does not have too many eigenvalues bigger than $1+o(1)$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 02:58:22 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1312.3134", "submitter": "Michael Lunglmayr", "authors": "Michael Lunglmayr, Christoph Unterrieder, Mario Huemer", "title": "Approximate Least Squares", "comments": "Preprint of the paper submitted to IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP) 2014", "journal-ref": null, "doi": "10.1109/ICASSP.2014.6854489", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel iterative algorithm for approximating the linear least\nsquares solution with low complexity. After a motivation of the algorithm we\ndiscuss the algorithm's properties including its complexity, and we present\ntheoretical results as well as simulation based performance results. We\ndescribe the analysis of its convergence behavior and show that in the noise\nfree case the algorithm converges to the least squares solution.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 12:14:08 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Lunglmayr", "Michael", ""], ["Unterrieder", "Christoph", ""], ["Huemer", "Mario", ""]]}, {"id": "1312.3158", "submitter": "James Murphy", "authors": "James Murphy", "title": "Benders, Nested Benders and Stochastic Programming: An Intuitive\n  Introduction", "comments": "57 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": "CUED/F-INFENG/TR.675", "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to explain the Nested Benders algorithm for the solution of\nlarge-scale stochastic programming problems in a way that is intelligible to\nsomeone coming to it for the first time. In doing so it gives an explanation of\nBenders decomposition and of its application to two-stage stochastic\nprogramming problems (also known in this context as the L-shaped method), then\nextends this to multi-stage problems as the Nested Benders algorithm. The\narticle is aimed at readers with some knowledge of linear and possibly\nstochastic programming but aims to develop most concepts from simple principles\nin an understandable way. The focus is on intuitive understanding rather than\nrigorous proofs.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 13:38:43 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Murphy", "James", ""]]}, {"id": "1312.3188", "submitter": "Victor Alvarez", "authors": "Victor Alvarez, Karl Bringmann, Saurabh Ray", "title": "A Simple Sweep Line Algorithm for Counting Triangulations and\n  Pseudo-triangulations", "comments": "38 pages, 48 figures. Submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P\\subset\\mathbb{R}^{2}$ be a set of $n$ points. In this paper we show\ntwo new algorithms, one to compute the number of triangulations of $P$, and one\nto compute the number of pseudo-triangulations of $P$. We show that our\nalgorithms run in time $O^{*}(t(P))$ and $O^{*}(pt(P))$ respectively, where\n$t(P)$ and $pt(P)$ are the largest number of triangulation paths (T-paths) and\npseudo-triangulations paths (PT-paths), respectively, that the algorithms\nencounter during their execution. Moreover, we show that $t(P) = O^{*}(9^{n})$,\nwhich is the first non-trivial bound on $t(P)$ to be known.\n  While there already are algorithms that count triangulations in\n$O^{*}\\left(2^n\\right)$, and $O^{*}\\left(3.1414^{n}\\right)$, there are sets of\npoints where the number of T-paths is $O(2^{n})$. In such cases the algorithm\nherein presented could potentially be faster. Furthermore, it is not clear\nwhether the already-known algorithms can be modified to count\npseudo-triangulations so that their running times remain $O^{*}(c^n)$, for some\nsmall constant $c\\in\\mathbb{R}$. Therefore, for counting pseudo-triangulations\n(and possibly other similar structures) our approach seems better.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 14:34:12 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Alvarez", "Victor", ""], ["Bringmann", "Karl", ""], ["Ray", "Saurabh", ""]]}, {"id": "1312.3288", "submitter": "Fabio Protti", "authors": "Rian G. S. Pinheiro, Ivan C. Martins, F\\'abio Protti, Luiz S. Ochi,\n  Luidi G. Simonetti, Anand Subramanian", "title": "On Solving Manufacturing Cell Formation via Bicluster Editing", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the Bicluster Graph Editing Problem (BGEP) and how it\ncan be applied to solve the Manufacturing Cell Formation Problem (MCFP). We\ndevelop an exact method for the BGEP that consists of a Branch-and-Cut approach\ncombined with a special separation algorithm based on dynamic programming. We\nalso describe a new preprocessing procedure for the BGEP derived from\ntheoretical results on vertex distances in the input graph. Computational\nexperiments performed on randomly generated instances with various levels of\ndifficulty show that our separation algorithm accelerates the convergence\nspeed, and our preprocessing procedure is effective for low density instances.\nOther contribution of this work is to reveal the similarities between the BGEP\nand the MCFP. We show that the BGEP and the MCFP have the same solution space.\nThis fact leads to the proposal of two new exact approaches for the MCFP based\non mathematical formulations for the BGEP. Both approaches use the grouping\nefficacy measure as the objective function. Up to the authors' knowledge, these\nare the first exact methods that employ such a measure to optimally solve\ninstances of the MCFP. The first approach consists of iteratively running\nseveral calls to a parameterized version of the BGEP, and the second is a\nlinearization of a new fractional-linear model for the MCFP. Computational\nexperiments performed on instances of the MCFP found in the literature show\nthat our exact methods for the MCFP are able to prove several previously\nunknown optima.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 19:26:34 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Pinheiro", "Rian G. S.", ""], ["Martins", "Ivan C.", ""], ["Protti", "F\u00e1bio", ""], ["Ochi", "Luiz S.", ""], ["Simonetti", "Luidi G.", ""], ["Subramanian", "Anand", ""]]}, {"id": "1312.3303", "submitter": "Christian Lavault", "authors": "Franck Butelle (LIPN), Christian Lavault (LIPN), Marc Bui (CHART)", "title": "A Uniform Self-Stabilizing Minimum Diameter Spanning Tree Algorithm", "comments": "14 pages; International conf\\'erence; Uniform self-stabilizing\n  variant of the problem, 9th International Workshop on Distributed Algorithms\n  (WDAG'95), Mont-Saint-Michel : France (1995)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a uniform self-stabilizing algorithm, which solves the problem of\ndistributively finding a minimum diameter spanning tree of an arbitrary\npositively real-weighted graph. Our algorithm consists in two stages of\nstabilizing protocols. The first stage is a uniform randomized stabilizing {\\em\nunique naming} protocol, and the second stage is a stabilizing {\\em MDST}\nprotocol, designed as a {\\em fair composition} of Merlin--Segall's stabilizing\nprotocol and a distributed deterministic stabilizing protocol solving the\n(MDST) problem. The resulting randomized distributed algorithm presented herein\nis a composition of the two stages; it stabilizes in $O(n\\Delta+{\\cal D}^2 + n\n\\log\\log n)$ expected time, and uses $O(n^2\\log n + n \\log W)$ memory bits\n(where $n$ is the order of the graph, $\\Delta$ is the maximum degree of the\nnetwork, $\\cal D$ is the diameter in terms of hops, and $W$ is the largest edge\nweight). To our knowledge, our protocol is the very first distributed algorithm\nfor the (MDST) problem. Moreover, it is fault-tolerant and works for any\nanonymous arbitrary network.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 20:13:48 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Butelle", "Franck", "", "LIPN"], ["Lavault", "Christian", "", "LIPN"], ["Bui", "Marc", "", "CHART"]]}, {"id": "1312.3345", "submitter": "Peruvemba Sundaram Ravi", "authors": "Peruvemba Sundaram Ravi, Levent Tuncel, Michael Huang", "title": "Worst-Case Performance Analysis of Some Approximation Algorithms for\n  Minimizing Makespan and Flow-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1976, Coffman and Sethi conjectured that a natural extension of LPT list\nscheduling to the bicriteria scheduling problem of minimizing makespan over\nflowtime optimal schedules, called LD algorithm, has a simple worst-case\nperformance bound: (5m-2)/(4m-1), where m is the number of machines. We study\nstructure of potential minimal counterexamples to this conjecture and prove\nthat the conjecture holds for the cases (i) n > 5m, (ii) m = 2, (iii) m = 3,\nand (iv) m greater than or equal to 4, n less than or equal to 3m, where n is\nthe number of jobs. We further conclude that to verify the conjecture, it\nsuffices to analyze the following case: for every m greater than or equal to 4,\nn is either equal to 4m or 5m.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 21:07:58 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Ravi", "Peruvemba Sundaram", ""], ["Tuncel", "Levent", ""], ["Huang", "Michael", ""]]}, {"id": "1312.3422", "submitter": "Travis Gagie", "authors": "Travis Gagie, Giovanni Manzini and Daniel Valenzuela", "title": "Compressed Spaced Suffix Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spaced seeds are important tools for similarity search in bioinformatics, and\nusing several seeds together often significantly improves their performance.\nWith existing approaches, however, for each seed we keep a separate linear-size\ndata structure, either a hash table or a spaced suffix array (SSA). In this\npaper we show how to compress SSAs relative to normal suffix arrays (SAs) and\nstill support fast random access to them. We first prove a theoretical upper\nbound on the space needed to store an SSA when we already have the SA. We then\npresent experiments indicating that our approach works even better in practice.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2013 09:15:47 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 22:31:53 GMT"}, {"version": "v3", "created": "Sun, 9 Mar 2014 10:40:30 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Gagie", "Travis", ""], ["Manzini", "Giovanni", ""], ["Valenzuela", "Daniel", ""]]}, {"id": "1312.3552", "submitter": "Nitesh Jha", "authors": "Rupam Acharyya, Sourav Chakraborty, Nitesh Jha", "title": "Counting Popular Matchings in House Allocation Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of counting the number of popular matchings in a given\ninstance. A popular matching instance consists of agents A and houses H, where\neach agent ranks a subset of houses according to their preferences. A matching\nis an assignment of agents to houses. A matching M is more popular than\nmatching M' if the number of agents that prefer M to M' is more than the number\nof people that prefer M' to M. A matching M is called popular if there exists\nno matching more popular than M. McDermid and Irving gave a poly-time algorithm\nfor counting the number of popular matchings when the preference lists are\nstrictly ordered.\n  We first consider the case of ties in preference lists. Nasre proved that the\nproblem of counting the number of popular matching is #P-hard when there are\nties. We give an FPRAS for this problem.\n  We then consider the popular matching problem where preference lists are\nstrictly ordered but each house has a capacity associated with it. We give a\nswitching graph characterization of popular matchings in this case. Such\ncharacterizations were studied earlier for the case of strictly ordered\npreference lists (McDermid and Irving) and for preference lists with ties\n(Nasre). We use our characterization to prove that counting popular matchings\nin capacitated case is #P-hard.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2013 17:21:20 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Acharyya", "Rupam", ""], ["Chakraborty", "Sourav", ""], ["Jha", "Nitesh", ""]]}, {"id": "1312.3779", "submitter": "Ashwin Pananjady", "authors": "Sounaka Mishra, Ashwin Pananjady, N Safina Devi", "title": "On the Complexity of Making a Distinguished Vertex Minimum or Maximum\n  Degree by Vertex Deletion", "comments": "16 pages, 4 figures, submitted to Elsevier's Journal of Discrete\n  Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the approximability of two node deletion\nproblems. Given a vertex weighted graph $G=(V,E)$ and a specified, or\n\"distinguished\" vertex $p \\in V$, MDD(min) is the problem of finding a minimum\nweight vertex set $S \\subseteq V\\setminus \\{p\\}$ such that $p$ becomes the\nminimum degree vertex in $G[V \\setminus S]$; and MDD(max) is the problem of\nfinding a minimum weight vertex set $S \\subseteq V\\setminus \\{p\\}$ such that\n$p$ becomes the maximum degree vertex in $G[V \\setminus S]$. These are known\n$NP$-complete problems and have been studied from the parameterized complexity\npoint of view in previous work. Here, we prove that for any $\\epsilon > 0$,\nboth the problems cannot be approximated within a factor $(1 - \\epsilon)\\log\nn$, unless $NP \\subseteq DTIME(n^{\\log\\log n})$. We also show that for any\n$\\epsilon > 0$, MDD(min) cannot be approximated within a factor $(1\n-\\epsilon)\\log n$ on bipartite graphs, unless $NP \\subseteq DTIME(n^{\\log\\log\nn})$, and that for any $\\epsilon > 0$, MDD(max) cannot be approximated within a\nfactor $(1/2 - \\epsilon)\\log n$ on bipartite graphs, unless $NP \\subseteq\nDTIME(n^{\\log\\log n})$. We give an $O(\\log n)$ factor approximation algorithm\nfor MDD(max) on general graphs, provided the degree of $p$ is $O(\\log n)$. We\nthen show that if the degree of $p$ is $n-O(\\log n)$, a similar result holds\nfor MDD(min). We prove that MDD(max) is $APX$-complete on 3-regular unweighted\ngraphs and provide an approximation algorithm with ratio $1.583$ when $G$ is a\n3-regular unweighted graph. In addition, we show that MDD(min) can be solved in\npolynomial time when $G$ is a regular graph of constant degree.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 11:42:19 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2013 18:34:11 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2014 12:58:44 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Mishra", "Sounaka", ""], ["Pananjady", "Ashwin", ""], ["Devi", "N Safina", ""]]}, {"id": "1312.3836", "submitter": "Filipe Brand\\~ao M.Sc", "authors": "Filipe Brand\\~ao, Jo\\~ao Pedro Pedroso", "title": "Multiple-choice Vector Bin Packing: Arc-flow Formulation with Graph\n  Compression", "comments": "arXiv admin note: text overlap with arXiv:1310.6887 by other authors", "journal-ref": null, "doi": null, "report-no": "DCC-2013-13", "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vector bin packing problem (VBP) is a generalization of bin packing with\nmultiple constraints. In this problem we are required to pack items,\nrepresented by p-dimensional vectors, into as few bins as possible. The\nmultiple-choice vector bin packing (MVBP) is a variant of the VBP in which bins\nhave several types and items have several incarnations. We present an exact\nmethod, based on an arc-flow formulation with graph compression, for solving\nMVBP by simply representing all the patterns in a very compact graph. As a\nproof of concept we report computational results on a variable-sized bin\npacking data set.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 15:14:44 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Brand\u00e3o", "Filipe", ""], ["Pedroso", "Jo\u00e3o Pedro", ""]]}, {"id": "1312.3905", "submitter": "Ruben Becker", "authors": "Ruben Becker and Andreas Karrenbauer", "title": "A Combinatorial $\\tilde{O}(m^{3/2})$-time Algorithm for the Min-Cost\n  Flow Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a combinatorial method for the min-cost flow problem and prove\nthat its expected running time is bounded by $\\tilde O(m^{3/2})$. This matches\nthe best known bounds, which previously have only been achieved by numerical\nalgorithms or for special cases. Our contribution contains three parts that\nmight be interesting in their own right: (1) We provide a construction of an\nequivalent auxiliary network and interior primal and dual points with potential\n$P_0=\\tilde{O}(\\sqrt{m})$ in linear time. (2) We present a combinatorial\npotential reduction algorithm that transforms initial solutions of potential\n$P_0$ to ones with duality gap below $1$ in $\\tilde O(P_0\\cdot\n\\mbox{CEF}(n,m,\\epsilon))$ time, where $\\epsilon^{-1}=O(m^2)$ and\n$\\mbox{CEF}(n,m,\\epsilon)$ denotes the running time of any combinatorial\nalgorithm that computes an $\\epsilon$-approximate electrical flow. (3) We show\nthat solutions with duality gap less than $1$ suffice to compute optimal\nintegral potentials in $O(m+n\\log n)$ time with our novel crossover procedure.\nAll in all, using a variant of a state-of-the-art $\\epsilon$-electrical flow\nsolver, we obtain an algorithm for the min-cost flow problem running in $\\tilde\nO(m^{3/2})$.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 19:01:48 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 10:23:27 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Becker", "Ruben", ""], ["Karrenbauer", "Andreas", ""]]}, {"id": "1312.4116", "submitter": "Niraj Kumar", "authors": "Niraj Kumar, Debabrata Goswami", "title": "Quantum Algorithm to Solve a Maze: Converting the Maze Problem into a\n  Search Problem", "comments": "5 pages, 5 figures,Appeared in Asian Quantum Information\n  Science(AQIS'13) Conference, Chennai, India, August 2013.\n  http://www.imsc.res.in/ aqis13/submissions/", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a different methodology towards approaching a Maze problem. We\nconvert the problem into a Quantum Search Problem (QSP), and its solutions are\nsought for using the iterative Grover's Search Algorithm. Though the category\nof mazes we are looking at are of the NP complete class, we have redirected\nsuch a NP complete problem into a QSP. Our solution deals with two dimensional\nperfect mazes with no closed loops. We encode all possible individual paths\nfrom the starting point of the maze into a quantum register. A quantum fitness\noperator applied on the register encodes each individual with its fitness\nvalue. We propose an oracle design which marks all the individuals above a\ncertain fitness value and use the Grover search algorithm to find one of the\nmarked states. Iterating over this method, we approach towards the optimum\nsolution.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 06:57:43 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Kumar", "Niraj", ""], ["Goswami", "Debabrata", ""]]}, {"id": "1312.4182", "submitter": "Ran Gelles", "authors": "Shweta Agrawal, Ran Gelles, Amit Sahai", "title": "Adaptive Protocols for Interactive Communication", "comments": "Content is similar to previous version yet with an improved\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much adversarial noise can protocols for interactive communication\ntolerate? This question was examined by Braverman and Rao (IEEE Trans. Inf.\nTheory, 2014) for the case of \"robust\" protocols, where each party sends\nmessages only in fixed and predetermined rounds. We consider a new class of\nnon-robust protocols for Interactive Communication, which we call adaptive\nprotocols. Such protocols adapt structurally to the noise induced by the\nchannel in the sense that both the order of speaking, and the length of the\nprotocol may vary depending on observed noise.\n  We define models that capture adaptive protocols and study upper and lower\nbounds on the permissible noise rate in these models. When the length of the\nprotocol may adaptively change according to the noise, we demonstrate a\nprotocol that tolerates noise rates up to $1/3$. When the order of speaking may\nadaptively change as well, we demonstrate a protocol that tolerates noise rates\nup to $2/3$. Hence, adaptivity circumvents an impossibility result of $1/4$ on\nthe fraction of tolerable noise (Braverman and Rao, 2014).\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 19:20:45 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2014 06:28:09 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2015 18:17:02 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Agrawal", "Shweta", ""], ["Gelles", "Ran", ""], ["Sahai", "Amit", ""]]}, {"id": "1312.4203", "submitter": "Georgios Zois", "authors": "Dimitrios Fotakis, Ioannis Milis, Emmanouil Zampetakis, Georgios Zois", "title": "Scheduling MapReduce Jobs and Data Shuffle on Unrelated Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose constant approximation algorithms for generalizations of the\nFlexible Flow Shop (FFS) problem which form a realistic model for\nnon-preemptive scheduling in MapReduce systems. Our results concern the\nminimization of the total weighted completion time of a set of MapReduce jobs\non unrelated processors and improve substantially on the model proposed by\nMoseley et al. (SPAA 2011) in two directions. First, we consider each job\nconsisting of multiple Map and Reduce tasks, as this is the key idea behind\nMapReduce computations, and we propose a constant approximation algorithm.\nThen, we introduce into our model the crucial cost of data shuffle phase, i.e.,\nthe cost for the transmission of intermediate data from Map to Reduce tasks. In\nfact, we model this phase by an additional set of Shuffle tasks for each job\nand we manage to keep the same approximation ratio when they are scheduled on\nthe same processors with the corresponding Reduce tasks and to provide also a\nconstant ratio when they are scheduled on different processors. This is the\nmost general setting of the FFS problem (with a special third stage) for which\na constant approximation ratio is known.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 23:10:27 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2014 20:00:24 GMT"}, {"version": "v3", "created": "Tue, 24 Jun 2014 14:45:53 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Fotakis", "Dimitrios", ""], ["Milis", "Ioannis", ""], ["Zampetakis", "Emmanouil", ""], ["Zois", "Georgios", ""]]}, {"id": "1312.4345", "submitter": "Yuri Frota", "authors": "Rosa Figueiredo, Yuri Frota", "title": "An improved Branch-and-cut code for the maximum balanced subgraph of a\n  signed graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum Balanced Subgraph Problem (MBSP) is the problem of finding a\nsubgraph of a signed graph that is balanced and maximizes the cardinality of\nits vertex set. We are interested in the exact solution of the problem: an\nimproved version of a branch-and-cut algorithm is proposed. Extensive\ncomputational experiments are carried out on a set of instances from three\napplications previously discussed in the literature as well as on a set of\nrandom instances.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 13:10:06 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Figueiredo", "Rosa", ""], ["Frota", "Yuri", ""]]}, {"id": "1312.4413", "submitter": "Esben Halvorsen", "authors": "Stephen Alstrup, Esben Bistrup Halvorsen, Kasper Green Larsen", "title": "Near-optimal labeling schemes for nearest common ancestors", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611973402.72", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider NCA labeling schemes: given a rooted tree $T$, label the nodes of\n$T$ with binary strings such that, given the labels of any two nodes, one can\ndetermine, by looking only at the labels, the label of their nearest common\nancestor.\n  For trees with $n$ nodes we present upper and lower bounds establishing that\nlabels of size $(2\\pm \\epsilon)\\log n$, $\\epsilon<1$ are both sufficient and\nnecessary. (All logarithms in this paper are in base 2.)\n  Alstrup, Bille, and Rauhe (SIDMA'05) showed that ancestor and NCA labeling\nschemes have labels of size $\\log n +\\Omega(\\log \\log n)$. Our lower bound\nincreases this to $\\log n + \\Omega(\\log n)$ for NCA labeling schemes. Since\nFraigniaud and Korman (STOC'10) established that labels in ancestor labeling\nschemes have size $\\log n +\\Theta(\\log \\log n)$, our new lower bound separates\nancestor and NCA labeling schemes. Our upper bound improves the $10 \\log n$\nupper bound by Alstrup, Gavoille, Kaplan and Rauhe (TOCS'04), and our\ntheoretical result even outperforms some recent experimental studies by Fischer\n(ESA'09) where variants of the same NCA labeling scheme are shown to all have\nlabels of size approximately $8 \\log n$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 15:55:03 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Alstrup", "Stephen", ""], ["Halvorsen", "Esben Bistrup", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "1312.4490", "submitter": "Gunnar W. Klau", "authors": "Kasper Dinkla, Mohammed El-Kebir, Cristina-Iulia Bucur, Marco\n  Siderius, Martine J. Smit, Michel A. Westenberg and Gunnar W. Klau", "title": "eXamine: a Cytoscape app for exploring annotated modules in networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Biological networks have growing importance for the\ninterpretation of high-throughput \"omics\" data. Statistical and combinatorial\nmethods allow to obtain mechanistic insights through the extraction of smaller\nsubnetwork modules. Further enrichment analyses provide set-based annotations\nof these modules.\n  Results. We present eXamine, a set-oriented visual analysis approach for\nannotated modules that displays set membership as contours on top of a\nnode-link layout. Our approach extends upon Self Organizing Maps to\nsimultaneously lay out nodes, links, and set contours.\n  Conclusions. We implemented eXamine as a freely available Cytoscape app.\nUsing eXamine we study a module that is activated by the virally-encoded\nG-protein coupled receptor US28 and formulate a novel hypothesis about its\nfunctioning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 19:58:54 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Dinkla", "Kasper", ""], ["El-Kebir", "Mohammed", ""], ["Bucur", "Cristina-Iulia", ""], ["Siderius", "Marco", ""], ["Smit", "Martine J.", ""], ["Westenberg", "Michel A.", ""], ["Klau", "Gunnar W.", ""]]}, {"id": "1312.4508", "submitter": "Christian Lavault", "authors": "Gabriel Paillard (LIPN), Christian Lavault (LIPN), Felipe Franca\n  (PESC)", "title": "A distributed prime sieving algorithm based on Scheduling by Multiple\n  Edge Reversal", "comments": "11 pages. Special issue : Selected papers from the ISPDC'05\n  Conference (4th International Symposium on Parallel and Distributed\n  Computing); 4th International Symposium on Parallel and Distributed\n  Computing, Lille : France (2005)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new distributed approach for generating all prime\nnumbers in a given interval of integers. From Eratosthenes, who elaborated the\nfirst prime sieve (more than 2000 years ago), to the current generation of\nparallel computers, which have permitted to reach larger bounds on the interval\nor to obtain previous results in a shorter time, prime numbers generation still\nrepresents an attractive domain of research and plays a central role in\ncryptography. We propose a fully distributed algorithm for finding all primes\nin the interval $[2\\ldots, n]$, based on the \\emph{wheel sieve} and the SMER\n(\\emph{Scheduling by Multiple Edge Reversal}) multigraph dynamics. Given a\nmultigraph $\\mathcal{M}$ of arbitrary topology, having $N$ nodes, a SMER-driven\nsystem is defined by the number of directed edges (arcs) between any two nodes\nof $\\mathcal{M}$, and by the global period length of all \"arc reversals\" in\n$\\mathcal{M}$. The new prime number generation method inherits the distributed\nand parallel nature of SMER and requires at most $n + \\lfloor \\sqrt{n}\\rfloor$\ntime steps. The message complexity achieves at most $n\\Delta_N + \\lfloor\n\\sqrt{n}\\rfloor \\Delta_N$, where $1\\le \\Delta_N\\le N - 1$ is the maximal\nmultidegree of $\\mathcal{M}$, and the maximal amount of memory space required\nper process is $\\mathcal{O}(n)$ bits.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 20:30:57 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Paillard", "Gabriel", "", "LIPN"], ["Lavault", "Christian", "", "LIPN"], ["Franca", "Felipe", "", "PESC"]]}, {"id": "1312.4628", "submitter": "Victor Alvarez", "authors": "Victor Alvarez, Karl Bringmann, Radu Curticapean, Saurabh Ray", "title": "Counting Triangulations and other Crossing-free Structures via Onion\n  Layers", "comments": "33 pages, 10 figures, 9 tables. A preliminary version appeared at\n  SoCG 2012. This version contains experimental results comparing algorithms\n  for counting triangulations. This paper has been submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ points in the plane. A crossing-free structure on $P$\nis a plane graph with vertex set $P$. Examples of crossing-free structures\ninclude triangulations of $P$, spanning cycles of $P$, also known as\npolygonalizations of $P$, among others. In this paper we develop a general\ntechnique for computing the number of crossing-free structures of an input set\n$P$. We apply the technique to obtain algorithms for computing the number of\ntriangulations, matchings, and spanning cycles of $P$. The running time of our\nalgorithms is upper bounded by $n^{O(k)}$, where $k$ is the number of onion\nlayers of $P$. In particular, for $k = O(1)$ our algorithms run in polynomial\ntime. In addition, we show that our algorithm for counting triangulations is\nnever slower than $O^{*}(3.1414^{n})$, even when $k = \\Theta(n)$. Given that\nthere are several well-studied configurations of points with at least\n$\\Omega(3.464^{n})$ triangulations, and some even with $\\Omega(8^{n})$\ntriangulations, our algorithm asymptotically outperforms any enumeration\nalgorithm for such instances. In fact, it is widely believed that any set of\n$n$ points must have at least $\\Omega(3.464^{n})$ triangulations. If this is\ntrue, then our algorithm is strictly sub-linear in the number of triangulations\ncounted. We also show that our techniques are general enough to solve the\n\"Restricted-Triangulation-Counting-Problem\", which we prove to be $W[2]$-hard\nin the parameter $k$. This implies a \"no free lunch\" result: In order to be\nfixed-parameter tractable, our general algorithm must rely on additional\nproperties that are specific to the considered class of structures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 03:41:41 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Alvarez", "Victor", ""], ["Bringmann", "Karl", ""], ["Curticapean", "Radu", ""], ["Ray", "Saurabh", ""]]}, {"id": "1312.4666", "submitter": "Vladimir Kostyukov", "authors": "Vladimir Kostyukov", "title": "A Functional Approach to Standard Binary Heaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  This paper describes a new and purely functional implementation technique of\nbinary heaps. A binary heap is a tree-based data structure that implements\npriority queue operations (insert, remove, minimum/maximum) and guarantees at\nworst logarithmic running time for them. Approaches and ideas described in this\npaper present a simple and asymptotically optimal implementation of immutable\nbinary heap.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 07:06:57 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Kostyukov", "Vladimir", ""]]}, {"id": "1312.4678", "submitter": "Djamal Belazzougui", "authors": "Ibrahim Chegrane and Djamal Belazzougui", "title": "Simple, compact and robust approximate string dictionary", "comments": "Accepted to a journal (19 pages, 2 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with practical implementations of approximate string\ndictionaries that allow edit errors. In this problem, we have as input a\ndictionary $D$ of $d$ strings of total length $n$ over an alphabet of size\n$\\sigma$. Given a bound $k$ and a pattern $x$ of length $m$, a query has to\nreturn all the strings of the dictionary which are at edit distance at most $k$\nfrom $x$, where the edit distance between two strings $x$ and $y$ is defined as\nthe minimum-cost sequence of edit operations that transform $x$ into $y$. The\ncost of a sequence of operations is defined as the sum of the costs of the\noperations involved in the sequence. In this paper, we assume that each of\nthese operations has unit cost and consider only three operations: deletion of\none character, insertion of one character and substitution of a character by\nanother. We present a practical implementation of the data structure we\nrecently proposed and which works only for one error. We extend the scheme to\n$2\\leq k<m$. Our implementation has many desirable properties: it has a very\nfast and space-efficient building algorithm. The dictionary data structure is\ncompact and has fast and robust query time. Finally our data structure is\nsimple to implement as it only uses basic techniques from the literature,\nmainly hashing (linear probing and hash signatures) and succinct data\nstructures (bitvectors supporting rank queries).\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 07:54:49 GMT"}, {"version": "v2", "created": "Sat, 23 Aug 2014 01:50:57 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Chegrane", "Ibrahim", ""], ["Belazzougui", "Djamal", ""]]}, {"id": "1312.4802", "submitter": "Niraj Singh", "authors": "Niraj Kumar Singh, Soubhik Chakraborty, and Dheeresh Kumar Mallick", "title": "A Statistical Peek into Average Case Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper gives a statistical adventure towards exploring the average\ncase complexity behavior of computer algorithms. Rather than following the\ntraditional count based analytical (pen and paper) approach, we instead talk in\nterms of the weight based analysis that permits mixing of distinct operations\ninto a conceptual bound called the statistical bound and its empirical\nestimate, the so called \"empirical O\". Based on careful analysis of the results\nobtained, we have introduced two new conjectures in the domain of algorithmic\nanalysis. The analytical way of average case analysis falls flat when it comes\nto a data model for which the expectation does not exist (e.g. Cauchy\ndistribution for continuous input data and certain discrete distribution inputs\nas those studied in the paper). The empirical side of our approach, with a\nthrust in computer experiments and applied statistics in its paradigm, lends a\nhelping hand by complimenting and supplementing its theoretical counterpart.\nComputer science is or at least has aspects of an experimental science as well,\nand hence hopefully, our statistical findings will be equally recognized among\ntheoretical scientists as well.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 14:36:36 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Singh", "Niraj Kumar", ""], ["Chakraborty", "Soubhik", ""], ["Mallick", "Dheeresh Kumar", ""]]}, {"id": "1312.4863", "submitter": "Ariel Gabizon", "authors": "Hasan Abasi and Nader H. Bshouty and Ariel Gabizon and Elad Haramaty", "title": "On $r$-Simple $k$-Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $r$-simple $k$-path is a {path} in the graph of length $k$ that passes\nthrough each vertex at most $r$ times. The $r$-SIMPLE $k$-PATH problem, given a\ngraph $G$ as input, asks whether there exists an $r$-simple $k$-path in $G$. We\nfirst show that this problem is NP-Complete. We then show that there is a graph\n$G$ that contains an $r$-simple $k$-path and no simple path of length greater\nthan $4\\log k/\\log r$. So this, in a sense, motivates this problem especially\nwhen one's goal is to find a short path that visits many vertices in the graph\nwhile bounding the number of visits at each vertex.\n  We then give a randomized algorithm that runs in time $$\\mathrm{poly}(n)\\cdot\n2^{O( k\\cdot \\log r/r)}$$ that solves the $r$-SIMPLE $k$-PATH on a graph with\n$n$ vertices with one-sided error. We also show that a randomized algorithm\nwith running time $\\mathrm{poly}(n)\\cdot 2^{(c/2)k/ r}$ with $c<1$ gives a\nrandomized algorithm with running time $\\poly(n)\\cdot 2^{cn}$ for the\nHamiltonian path problem in a directed graph - an outstanding open problem. So\nin a sense our algorithm is optimal up to an $O(\\log r)$ factor.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 17:08:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 15:51:18 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Abasi", "Hasan", ""], ["Bshouty", "Nader H.", ""], ["Gabizon", "Ariel", ""], ["Haramaty", "Elad", ""]]}, {"id": "1312.5105", "submitter": "David Garcia Soriano", "authors": "Francesco Bonchi, David Garc\\'ia-Soriano, Konstantin Kutzkov", "title": "Local correlation clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation clustering is perhaps the most natural formulation of clustering.\nGiven $n$ objects and a pairwise similarity measure, the goal is to cluster the\nobjects so that, to the best possible extent, similar objects are put in the\nsame cluster and dissimilar objects are put in different clusters. Despite its\ntheoretical appeal, the practical relevance of correlation clustering still\nremains largely unexplored, mainly due to the fact that correlation clustering\nrequires the $\\Theta(n^2)$ pairwise similarities as input.\n  In this paper we initiate the investigation into \\emph{local} algorithms for\ncorrelation clustering. In \\emph{local correlation clustering} we are given the\nidentifier of a single object and we want to return the cluster to which it\nbelongs in some globally consistent near-optimal clustering, using a small\nnumber of similarity queries. Local algorithms for correlation clustering open\nthe door to \\emph{sublinear-time} algorithms, which are particularly useful\nwhen the similarity between items is costly to compute, as it is often the case\nin many practical application domains. They also imply $(i)$ distributed and\nstreaming clustering algorithms, $(ii)$ constant-time estimators and testers\nfor cluster edit distance, and $(iii)$ property-preserving parallel\nreconstruction algorithms for clusterability.\n  Specifically, we devise a local clustering algorithm attaining a $(3,\n\\varepsilon)$-approximation in time $O(1/\\varepsilon^2)$ independently of the\ndataset size. An explicit approximate clustering for all objects can be\nproduced in time $O(n/\\varepsilon)$ (which is provably optimal). We also\nprovide a fully additive $(1,\\varepsilon)$-approximation with local query\ncomplexity $poly(1/\\varepsilon)$ and time complexity $2^{poly(1/\\varepsilon)}$.\nThe latter yields the fastest polynomial-time approximation scheme for\ncorrelation clustering known to date.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 12:04:10 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Bonchi", "Francesco", ""], ["Garc\u00eda-Soriano", "David", ""], ["Kutzkov", "Konstantin", ""]]}, {"id": "1312.5180", "submitter": "Pim van 't Hof", "authors": "Manu Basavaraju, Pinar Heggernes, Pim van 't Hof, Reza Saei, Yngve\n  Villanger", "title": "Maximal induced matchings in triangle-free graphs", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An induced matching in a graph is a set of edges whose endpoints induce a\n$1$-regular subgraph. It is known that any $n$-vertex graph has at most\n$10^{n/5} \\approx 1.5849^n$ maximal induced matchings, and this bound is best\npossible. We prove that any $n$-vertex triangle-free graph has at most $3^{n/3}\n\\approx 1.4423^n$ maximal induced matchings, and this bound is attained by any\ndisjoint union of copies of the complete bipartite graph $K_{3,3}$. Our result\nimplies that all maximal induced matchings in an $n$-vertex triangle-free graph\ncan be listed in time $O(1.4423^n)$, yielding the fastest known algorithm for\nfinding a maximum induced matching in a triangle-free graph.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 15:36:40 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Basavaraju", "Manu", ""], ["Heggernes", "Pinar", ""], ["Hof", "Pim van 't", ""], ["Saei", "Reza", ""], ["Villanger", "Yngve", ""]]}, {"id": "1312.5408", "submitter": "Paul Tupper", "authors": "David Bryant and Paul F. Tupper", "title": "Diversities and the Geometry of Hypergraphs", "comments": "19 pages, no figures. This version: further small corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The embedding of finite metrics in $\\ell_1$ has become a fundamental tool for\nboth combinatorial optimization and large-scale data analysis. One important\napplication is to network flow problems in which there is close relation\nbetween max-flow min-cut theorems and the minimal distortion embeddings of\nmetrics into $\\ell_1$. Here we show that this theory can be generalized\nconsiderably to encompass Steiner tree packing problems in both graphs and\nhypergraphs. Instead of the theory of $\\ell_1$ metrics and minimal distortion\nembeddings, the parallel is the theory of diversities recently introduced by\nBryant and Tupper, and the corresponding theory of $\\ell_1$ diversities and\nembeddings which we develop here.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 05:08:10 GMT"}, {"version": "v2", "created": "Thu, 27 Mar 2014 17:14:34 GMT"}, {"version": "v3", "created": "Fri, 18 Apr 2014 02:16:34 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Bryant", "David", ""], ["Tupper", "Paul F.", ""]]}, {"id": "1312.5479", "submitter": "Jonathan Masci", "authors": "Jonathan Masci and Alex M. Bronstein and Michael M. Bronstein and\n  Pablo Sprechmann and Guillermo Sapiro", "title": "Sparse similarity-preserving hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a lot of attention has been devoted to efficient nearest\nneighbor search by means of similarity-preserving hashing. One of the plights\nof existing hashing techniques is the intrinsic trade-off between performance\nand computational complexity: while longer hash codes allow for lower false\npositive rates, it is very difficult to increase the embedding dimensionality\nwithout incurring in very high false negatives rates or prohibiting\ncomputational costs. In this paper, we propose a way to overcome this\nlimitation by enforcing the hash codes to be sparse. Sparse high-dimensional\ncodes enjoy from the low false positive rates typical of long hashes, while\nkeeping the false negative rates similar to those of a shorter dense hashing\nscheme with equal number of degrees of freedom. We use a tailored feed-forward\nneural network for the hashing function. Extensive experimental evaluation\ninvolving visual and multi-modal data shows the benefits of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 11:04:40 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 10:05:07 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2014 20:37:10 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Masci", "Jonathan", ""], ["Bronstein", "Alex M.", ""], ["Bronstein", "Michael M.", ""], ["Sprechmann", "Pablo", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1312.5520", "submitter": "Tamara Mchedlidze David", "authors": "William Evans and Michael Kaufmann and William Lenhart and Giuseppe\n  Liotta and Tamara Mchedlidze and Stephen Wismath", "title": "Bar 1-Visibility Graphs and their relation to other Nearly Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is called a strong (resp. weak) bar 1-visibility graph if its\nvertices can be represented as horizontal segments (bars) in the plane so that\nits edges are all (resp. a subset of) the pairs of vertices whose bars have a\n$\\epsilon$-thick vertical line connecting them that intersects at most one\nother bar.\n  We explore the relation among weak (resp. strong) bar 1-visibility graphs and\nother nearly planar graph classes. In particular, we study their relation to\n1-planar graphs, which have a drawing with at most one crossing per edge;\nquasi-planar graphs, which have a drawing with no three mutually crossing\nedges; the squares of planar 1-flow networks, which are upward digraphs with\nin- or out-degree at most one. Our main results are that 1-planar graphs and\nthe (undirected) squares of planar 1-flow networks are weak bar 1-visibility\ngraphs and that these are quasi-planar graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 12:52:02 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Evans", "William", ""], ["Kaufmann", "Michael", ""], ["Lenhart", "William", ""], ["Liotta", "Giuseppe", ""], ["Mchedlidze", "Tamara", ""], ["Wismath", "Stephen", ""]]}, {"id": "1312.5667", "submitter": "Xin-She Yang", "authors": "Xin-She Yang, Suash Deb, M. Loomes, M. Karamanoglu", "title": "A Framework for Self-Tuning Optimization Algorithm", "comments": "12 pages", "journal-ref": "Neural Computing and Applications, Vol. 23, No. 7-8, pp. 2051-2057\n  (2013)", "doi": "10.1007/s00521-013-1498-4", "report-no": null, "categories": "math.OC cs.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of any algorithm will largely depend on the setting of its\nalgorithm-dependent parameters. The optimal setting should allow the algorithm\nto achieve the best performance for solving a range of optimization problems.\nHowever, such parameter-tuning itself is a tough optimization problem. In this\npaper, we present a framework for self-tuning algorithms so that an algorithm\nto be tuned can be used to tune the algorithm itself. Using the firefly\nalgorithm as an example, we show that this framework works well. It is also\nfound that different parameters may have different sensitivities, and thus\nrequire different degrees of tuning. Parameters with high sensitivities require\nfine-tuning to achieve optimality.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 17:55:33 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Yang", "Xin-She", ""], ["Deb", "Suash", ""], ["Loomes", "M.", ""], ["Karamanoglu", "M.", ""]]}, {"id": "1312.5972", "submitter": "Yu Hin Au", "authors": "Yu Hin Au and Levent Tun\\c{c}el", "title": "A Comprehensive Analysis of Polyhedral Lift-and-Project Methods", "comments": null, "journal-ref": "SIAM Journal on Discrete Mathematics 30(1) (2016), 411-451", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider lift-and-project methods for combinatorial optimization problems\nand focus mostly on those lift-and-project methods which generate polyhedral\nrelaxations of the convex hull of integer solutions. We introduce many new\nvariants of Sherali--Adams and Bienstock--Zuckerberg operators. These new\noperators fill the spectrum of polyhedral lift-and-project operators in a way\nwhich makes all of them more transparent, easier to relate to each other, and\neasier to analyze. We provide new techniques to analyze the worst-case\nperformances as well as relative strengths of these operators in a unified way.\nIn particular, using the new techniques and a result of Mathieu and Sinclair\nfrom 2009, we prove that the polyhedral Bienstock--Zuckerberg operator requires\nat least $\\sqrt{2n}- \\frac{3}{2}$ iterations to compute the matching polytope\nof the $(2n+1)$-clique. We further prove that the operator requires\napproximately $\\frac{n}{2}$ iterations to reach the stable set polytope of the\n$n$-clique, if we start with the fractional stable set polytope. Lastly, we\nshow that some of the worst-case instances for the positive semidefinite\nLov\\'asz--Schrijver lift-and-project operator are also bad instances for the\nstrongest variants of the Sherali--Adams operator with positive semidefinite\nstrengthenings, and discuss some consequences for integrality gaps of convex\nrelaxations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 14:55:01 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2015 14:27:02 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 12:23:44 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Au", "Yu Hin", ""], ["Tun\u00e7el", "Levent", ""]]}, {"id": "1312.6039", "submitter": "Dekel Tsur", "authors": "Dekel Tsur", "title": "Succinct representation of labeled trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a representation for labeled ordered trees that supports labeled\nqueries such as finding the i-th ancestor of a node with a given label. Our\nrepresentation is succinct, namely the redundancy is small-o of the optimal\nspace for storing the tree. This improves the representation of He et al. which\nis succinct unless the entropy of the labels is small.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 16:56:28 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Tsur", "Dekel", ""]]}, {"id": "1312.6155", "submitter": "Stefan Ratschan", "authors": "Milan Hlad\\'ik, Stefan Ratschan", "title": "Efficient Solution of a Class of Quantified Constraints with Quantifier\n  Prefix Exists-Forall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various applications the search for certificates for certain properties\n(e.g., stability of dynamical systems, program termination) can be formulated\nas a quantified constraint solving problem with quantifier prefix\nexists-forall. In this paper, we present an algorithm for solving a certain\nclass of such problems based on interval techniques in combination with\nconservative linear programming approximation. In comparison with previous\nwork, the method is more general - allowing general Boolean structure in the\ninput constraint, and more efficient - using splitting heuristics that learn\nfrom the success of previous linear programming approximations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 21:41:18 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 15:02:33 GMT"}, {"version": "v3", "created": "Tue, 24 Jun 2014 20:07:13 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Hlad\u00edk", "Milan", ""], ["Ratschan", "Stefan", ""]]}, {"id": "1312.6214", "submitter": "Elad Hazan", "authors": "Elad Hazan and Zohar Karnin and Raghu Mehka", "title": "Volumetric Spanners: an Efficient Exploration Basis for Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous machine learning problems require an exploration basis - a mechanism\nto explore the action space. We define a novel geometric notion of exploration\nbasis with low variance, called volumetric spanners, and give efficient\nalgorithms to construct such a basis.\n  We show how efficient volumetric spanners give rise to the first efficient\nand optimal regret algorithm for bandit linear optimization over general convex\nsets. Previously such results were known only for specific convex sets, or\nunder special conditions such as the existence of an efficient self-concordant\nbarrier for the underlying set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 06:51:50 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2014 12:16:59 GMT"}, {"version": "v3", "created": "Sun, 25 May 2014 11:57:08 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Hazan", "Elad", ""], ["Karnin", "Zohar", ""], ["Mehka", "Raghu", ""]]}, {"id": "1312.6260", "submitter": "Mingyu Xiao", "authors": "Mingyu Xiao and Hiroshi Nagamochi", "title": "Exact Algorithms for Maximum Independent Set", "comments": null, "journal-ref": "Information and Computation 255(1) (2017):126-146", "doi": "10.1016/j.ic.2017.06.001", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the maximum independent set problem (MIS) on an $n$-vertex graph\ncan be solved in $1.1996^nn^{O(1)}$ time and polynomial space, which even is\nfaster than Robson's $1.2109^{n}n^{O(1)}$-time exponential-space algorithm\npublished in 1986. We also obtain improved algorithms for MIS in graphs with\nmaximum degree 6 and 7, which run in time of $1.1893^nn^{O(1)}$ and\n$1.1970^nn^{O(1)}$, respectively. Our algorithms are obtained by using fast\nalgorithms for MIS in low-degree graphs in a hierarchical way and making a\ncareful analyses on the structure of bounded-degree graphs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 15:08:22 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Xiao", "Mingyu", ""], ["Nagamochi", "Hiroshi", ""]]}, {"id": "1312.6447", "submitter": "Thomas Kalinowski", "authors": "Thomas Kalinowski, Dmytro Matsypura, Martin W.P. Savelsbergh", "title": "Incremental Network Design with Maximum Flows", "comments": "26 pages", "journal-ref": "European Journal of Operational Research 242 (2015), pp. 51-62", "doi": "10.1016/j.ejor.2014.10.003", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an incremental network design problem, where in each time period of\nthe planning horizon an arc can be added to the network and a maximum flow\nproblem is solved, and where the objective is to maximize the cumulative flow\nover the entire planning horizon. After presenting two mixed integer\nprogramming (MIP) formulations for this NP-complete problem, we describe\nseveral heuristics and prove performance bounds for some special cases. In a\nseries of computational experiments, we compare the performance of the MIP\nformulations as well as the heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 00:26:00 GMT"}, {"version": "v2", "created": "Sat, 21 Jun 2014 00:06:09 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Kalinowski", "Thomas", ""], ["Matsypura", "Dmytro", ""], ["Savelsbergh", "Martin W. P.", ""]]}, {"id": "1312.6492", "submitter": "Pawan  Tamta", "authors": "Pawan Tamta, Bhagwati Prasad Pande, H.S.Dhami", "title": "Cardinality Maximum Flow Network Interdiction Problem Vs. The Clique\n  Problem", "comments": "10 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality Maximum Flow Network Interdiction Problem (CMFNIP) is known to be\nstrongly NP-hard problem in the literature. A particular case of CMFNIP has\nbeen shown to have reduction from clique problem. In the present work,an effort\nis being made to solve this particular case of CMFNIP in polynomial time.\nDirect implication of this solution is that the clique problem gets solved in\npolynomial time. 3-CNF Satisfiability and Vertex Cover problems, having\nreductions to and from the Clique Problem respectively, are also being solved\nin polynomial time by same algorithm. The obvious conclusion of the work is P =\nNP.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 09:32:35 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Tamta", "Pawan", ""], ["Pande", "Bhagwati Prasad", ""], ["Dhami", "H. S.", ""]]}, {"id": "1312.6493", "submitter": "Monaldo Mastrolilli", "authors": "Monaldo Mastrolilli", "title": "The Lasserre Hierarchy in Almost Diagonal Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasserre hierarchy is a systematic procedure for constructing a sequence\nof increasingly tight relaxations that capture the convex formulations used in\nthe best available approximation algorithms for a wide variety of optimization\nproblems. Despite the increasing interest, there are very few techniques for\nanalyzing Lasserre integrality gaps. Satisfying the positive semi-definite\nrequirement is one of the major hurdles to constructing Lasserre gap examples.\n  We present a novel characterization of the Lasserre hierarchy based on moment\nmatrices that differ from diagonal ones by matrices of rank one (almost\ndiagonal form). We provide a modular recipe to obtain positive semi-definite\nfeasibility conditions by iteratively diagonalizing rank one matrices.\n  Using this, we prove strong lower bounds on integrality gaps of Lasserre\nhierarchy for two basic capacitated covering problems. For the min-knapsack\nproblem, we show that the integrality gap remains arbitrarily large even at\nlevel $n-1$ of Lasserre hierarchy. For the min-sum of tardy jobs scheduling\nproblem, we show that the integrality gap is unbounded at level\n$\\Omega(\\sqrt{n})$ (even when the objective function is integrated as a\nconstraint). These bounds are interesting on their own, since both problems\nadmit FPTAS.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 09:34:33 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 21:47:00 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2014 18:14:22 GMT"}, {"version": "v4", "created": "Wed, 2 Apr 2014 16:57:35 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Mastrolilli", "Monaldo", ""]]}, {"id": "1312.6550", "submitter": "Krzysztof Fleszar", "authors": "Jaros{\\l}aw Byrka, Krzysztof Fleszar, Bartosz Rybicki, Joachim\n  Spoerhase", "title": "Bi-Factor Approximation Algorithms for Hard Capacitated $k$-Median\n  Problems", "comments": "Inaccuracies from the previous version have been addressed. Extended\n  argument was the basis for a chapter of the PhD thesis of Krzysztof Fleszar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-Facility Location problem is a generalization of the classical\nproblems $k$-Median and Facility Location. The goal is to select a subset of at\nmost $k$ facilities that minimizes the total cost of opened facilities and\nestablished connections between clients and opened facilities. We consider the\nhard-capacitated version of the problem, where a single facility may only serve\na limited number of clients and creating multiple copies of a facility is not\nallowed. We construct approximation algorithms slightly violating the\ncapacities based on rounding a fractional solution to the standard LP.\n  It is well known that the standard LP (even in the case of uniform capacities\nand opening costs) has unbounded integrality gap if we only allow violating\ncapacities by a factor smaller than $2$, or if we only allow violating the\nnumber of facilities by a factor smaller than $2$. In this paper, we present\nthe first constant-factor approximation algorithms for the hard-capacitated\nvariants of the problem. For uniform capacities, we obtain a\n$(2+\\varepsilon)$-capacity violating algorithm with approximation ratio\n$O(1/\\varepsilon^2)$; our result has not yet been improved. Then, for\nnon-uniform capacities, we consider the case of $k$-Median, which is equivalent\nto $k$-Facility Location with uniform opening cost of the facilities. Here, we\nobtain a $(3+\\varepsilon)$-capacity violating algorithm with approximation\nratio $O(1/\\varepsilon)$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 14:03:29 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2014 07:46:57 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 03:58:22 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Byrka", "Jaros\u0142aw", ""], ["Fleszar", "Krzysztof", ""], ["Rybicki", "Bartosz", ""], ["Spoerhase", "Joachim", ""]]}, {"id": "1312.6585", "submitter": "Dimitrios Thilikos", "authors": "Valentin Garnero, Christophe Paul, Ignasi Sau, Dimitrios M. Thilikos", "title": "Explicit linear kernels via dynamic programming", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several algorithmic meta-theorems on kernelization have appeared in the last\nyears, starting with the result of Bodlaender et al. [FOCS 2009] on graphs of\nbounded genus, then generalized by Fomin et al. [SODA 2010] to graphs excluding\na fixed minor, and by Kim et al. [ICALP 2013] to graphs excluding a fixed\ntopological minor. Typically, these results guarantee the existence of linear\nor polynomial kernels on sparse graph classes for problems satisfying some\ngeneric conditions but, mainly due to their generality, it is not clear how to\nderive from them constructive kernels with explicit constants. In this paper we\nmake a step toward a fully constructive meta-kernelization theory on sparse\ngraphs. Our approach is based on a more explicit protrusion replacement\nmachinery that, instead of expressibility in CMSO logic, uses dynamic\nprogramming, which allows us to find an explicit upper bound on the size of the\nderived kernels. We demonstrate the usefulness of our techniques by providing\nthe first explicit linear kernels for $r$-Dominating Set and $r$-Scattered Set\non apex-minor-free graphs, and for Planar-\\mathcal{F}-Deletion on graphs\nexcluding a fixed (topological) minor in the case where all the graphs in\n\\mathcal{F} are connected.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 15:54:24 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 16:10:31 GMT"}, {"version": "v3", "created": "Wed, 7 May 2014 15:28:52 GMT"}, {"version": "v4", "created": "Thu, 20 Nov 2014 13:03:31 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Garnero", "Valentin", ""], ["Paul", "Christophe", ""], ["Sau", "Ignasi", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "1312.6652", "submitter": "Boaz Barak", "authors": "Boaz Barak, Jonathan Kelner, David Steurer", "title": "Rounding Sum-of-Squares Relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach to rounding semidefinite programming\nrelaxations obtained by the Sum-of-Squares method (Lasserre hierarchy). Our\napproach is based on using the connection between these relaxations and the\nSum-of-Squares proof system to transform a *combining algorithm* -- an\nalgorithm that maps a distribution over solutions into a (possibly weaker)\nsolution -- into a *rounding algorithm* that maps a solution of the relaxation\nto a solution of the original problem.\n  Using this approach, we obtain algorithms that yield improved results for\nnatural variants of three well-known problems:\n  1) We give a quasipolynomial-time algorithm that approximates the maximum of\na low degree multivariate polynomial with non-negative coefficients over the\nEuclidean unit sphere. Beyond being of interest in its own right, this is\nrelated to an open question in quantum information theory, and our techniques\nhave already led to improved results in this area (Brand\\~{a}o and Harrow, STOC\n'13).\n  2) We give a polynomial-time algorithm that, given a d dimensional subspace\nof R^n that (almost) contains the characteristic function of a set of size n/k,\nfinds a vector $v$ in the subspace satisfying $|v|_4^4 > c(k/d^{1/3}) |v|_2^2$,\nwhere $|v|_p = (E_i v_i^p)^{1/p}$. Aside from being a natural relaxation, this\nis also motivated by a connection to the Small Set Expansion problem shown by\nBarak et al. (STOC 2012) and our results yield a certain improvement for that\nproblem.\n  3) We use this notion of L_4 vs. L_2 sparsity to obtain a polynomial-time\nalgorithm with substantially improved guarantees for recovering a planted\n$\\mu$-sparse vector v in a random d-dimensional subspace of R^n. If v has mu n\nnonzero coordinates, we can recover it with high probability whenever $\\mu <\nO(\\min(1,n/d^2))$, improving for $d < n^{2/3}$ prior methods which\nintrinsically required $\\mu < O(1/\\sqrt(d))$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 19:30:46 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Barak", "Boaz", ""], ["Kelner", "Jonathan", ""], ["Steurer", "David", ""]]}, {"id": "1312.6677", "submitter": "Yin Tat Lee", "authors": "Yin Tat Lee and Aaron Sidford", "title": "Path Finding I :Solving Linear Programs with \\~O(sqrt(rank)) Linear\n  System Solves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new algorithm for solving linear programs that\nrequires only $\\tilde{O}(\\sqrt{rank(A)}L)$ iterations to solve a linear program\nwith $m$ constraints, $n$ variables, and constraint matrix $A$, and bit\ncomplexity $L$. Each iteration of our method consists of solving $\\tilde{O}(1)$\nlinear systems and additional nearly linear time computation.\n  Our method improves upon the previous best iteration bound by factor of\n$\\tilde{\\Omega}((m/rank(A))^{1/4})$ for methods with polynomial time computable\niterations and by $\\tilde{\\Omega}((m/rank(A))^{1/2})$ for methods which solve\nat most $\\tilde{O}(1)$ linear systems in each iteration. Our method is\nparallelizable and amenable to linear algebraic techniques for accelerating the\nlinear system solver. As such, up to polylogarithmic factors we either match or\nimprove upon the best previous running times in both depth and work for\ndifferent ratios of $m$ and $rank(A)$.\n  Moreover, our method matches up to polylogarithmic factors a theoretical\nlimit established by Nesterov and Nemirovski in 1994 regarding the use of a\n\"universal barrier\" for interior point methods, thereby resolving a\nlong-standing open question regarding the running time of polynomial time\ninterior point methods for linear programming.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:54:43 GMT"}, {"version": "v2", "created": "Wed, 7 May 2014 19:02:03 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2015 19:51:27 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Lee", "Yin Tat", ""], ["Sidford", "Aaron", ""]]}, {"id": "1312.6680", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "Faster all-pairs shortest paths via circuit complexity", "comments": "24 pages. Updated version now has slightly faster running time. To\n  appear in ACM Symposium on Theory of Computing (STOC), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new randomized method for computing the min-plus product\n(a.k.a., tropical product) of two $n \\times n$ matrices, yielding a faster\nalgorithm for solving the all-pairs shortest path problem (APSP) in dense\n$n$-node directed graphs with arbitrary edge weights. On the real RAM, where\nadditions and comparisons of reals are unit cost (but all other operations have\ntypical logarithmic cost), the algorithm runs in time\n\\[\\frac{n^3}{2^{\\Omega(\\log n)^{1/2}}}\\] and is correct with high probability.\nOn the word RAM, the algorithm runs in $n^3/2^{\\Omega(\\log n)^{1/2}} +\nn^{2+o(1)}\\log M$ time for edge weights in $([0,M] \\cap {\\mathbb\nZ})\\cup\\{\\infty\\}$. Prior algorithms used either $n^3/(\\log^c n)$ time for\nvarious $c \\leq 2$, or $O(M^{\\alpha}n^{\\beta})$ time for various $\\alpha > 0$\nand $\\beta > 2$.\n  The new algorithm applies a tool from circuit complexity, namely the\nRazborov-Smolensky polynomials for approximately representing ${\\sf AC}^0[p]$\ncircuits, to efficiently reduce a matrix product over the $(\\min,+)$ algebra to\na relatively small number of rectangular matrix products over ${\\mathbb F}_2$,\neach of which are computable using a particularly efficient method due to\nCoppersmith. We also give a deterministic version of the algorithm running in\n$n^3/2^{\\log^{\\delta} n}$ time for some $\\delta > 0$, which utilizes the\nYao-Beigel-Tarui translation of ${\\sf AC}^0[m]$ circuits into \"nice\" depth-two\ncircuits.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:59:43 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 01:13:37 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1312.6700", "submitter": "Turlough Neary", "authors": "Turlough Neary", "title": "Undecidability in binary tag systems and the Post correspondence problem\n  for four pairs of words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Cocke and Minsky proved 2-tag systems universal, they have been\nextensively used to prove the universality of numerous computational models.\nUnfortunately, all known algorithms give universal 2-tag systems that have a\nlarge number of symbols. In this work, tag systems with only 2 symbols (the\nminimum possible) are proved universal via an intricate construction showing\nthat they simulate cyclic tag systems. Our simulation algorithm has a\npolynomial time overhead, and thus shows that binary tag systems simulate\nTuring machines in polynomial time.\n  We immediately find applications of our result. We reduce the halting problem\nfor binary tag systems to the Post correspondence problem for 4 pairs of words.\nThis improves on 7 pairs, the previous bound for undecidability in this\nproblem. Following our result, only the case for 3 pairs of words remains open,\nas the problem is known to be decidable for 2 pairs. As a further application,\nwe find that the matrix mortality problem is undecidable for sets with five\n$3\\times 3$ matrices and for sets with two $15\\times 15$ matrices. The previous\nbounds for the undecidability in this problem was seven $3\\times 3$ matrices\nand two $ 21\\times 21$ matrices.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 19:59:13 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Neary", "Turlough", ""]]}, {"id": "1312.6713", "submitter": "Aaron Sidford", "authors": "Yin Tat Lee and Aaron Sidford", "title": "Path Finding II : An \\~O(m sqrt(n)) Algorithm for the Minimum Cost Flow\n  Problem", "comments": "arXiv admin note: text overlap with arXiv:1312.6677", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an $\\tilde{O}(m\\sqrt{n}\\log^{O(1)}U)$ time algorithm\nfor solving the maximum flow problem on directed graphs with $m$ edges, $n$\nvertices, and capacity ratio $U$. This improves upon the previous fastest\nrunning time of\n$O(m\\min\\left(n^{2/3},m^{1/2}\\right)\\log\\left(n^{2}/m\\right)\\log U)$ achieved\nover 15 years ago by Goldberg and Rao. In the special case of solving dense\ndirected unit capacity graphs our algorithm improves upon the previous fastest\nrunning times of of $O(\\min\\{m^{3/2},mn^{^{2/3}}\\})$ achieved by Even and\nTarjan and Karzanov over 35 years ago and of $\\tilde{O}(m^{10/7})$ achieved\nrecently by M\\k{a}dry.\n  We achieve these results through the development and application of a new\ngeneral interior point method that we believe is of independent interest. The\nnumber of iterations required by this algorithm is better than that predicted\nby analyzing the best self-concordant barrier of the feasible region. By\napplying this method to the linear programming formulations of maximum flow,\nminimum cost flow, and lossy generalized minimum cost flow and applying\nanalysis by Daitch and Spielman we achieve running time of\n$\\tilde{O}(m\\sqrt{n}\\log^{O(1)}(U/\\epsilon))$ for these problems as well.\nFurthermore, our algorithm is parallelizable and using a recent nearly linear\ntime work polylogarithmic depth Laplacian system solver of Spielman and Peng we\nachieve a $\\tilde{O}(\\sqrt{n}\\log^{O(1)}(U/\\epsilon))$ depth algorithm and\n$\\tilde{O}(m\\sqrt{n}\\log^{O(1)}(U/\\epsilon))$ work algorithm for solving these\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 22:16:49 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 20:21:17 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Lee", "Yin Tat", ""], ["Sidford", "Aaron", ""]]}, {"id": "1312.6724", "submitter": "Konstantin Voevodski", "authors": "Pranjal Awasthi and Maria-Florina Balcan and Konstantin Voevodski", "title": "Local algorithms for interactive clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of interactive clustering algorithms for data sets\nsatisfying natural stability assumptions. Our algorithms start with any initial\nclustering and only make local changes in each step; both are desirable\nfeatures in many applications. We show that in this constrained setting one can\nstill design provably efficient algorithms that produce accurate clusterings.\nWe also show that our algorithms perform well on real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 00:16:37 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 05:12:20 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2015 23:45:54 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Balcan", "Maria-Florina", ""], ["Voevodski", "Konstantin", ""]]}, {"id": "1312.6820", "submitter": "Ahmed Farahat", "authors": "Ahmed K. Farahat, Ali Ghodsi, Mohamed S. Kamel", "title": "A Fast Greedy Algorithm for Generalized Column Subset Selection", "comments": "NIPS'13 Workshop on Greedy Algorithms, Frank-Wolfe and Friends", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a generalized column subset selection problem which is\nconcerned with the selection of a few columns from a source matrix A that best\napproximate the span of a target matrix B. The paper then proposes a fast\ngreedy algorithm for solving this problem and draws connections to different\nproblems that can be efficiently solved using the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 14:19:43 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Farahat", "Ahmed K.", ""], ["Ghodsi", "Ali", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1312.6838", "submitter": "Ahmed Farahat", "authors": "Ahmed K. Farahat, Ahmed Elgohary, Ali Ghodsi, Mohamed S. Kamel", "title": "Greedy Column Subset Selection for Large-scale Data Sets", "comments": "Under consideration for publication in Knowledge and Information\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's information systems, the availability of massive amounts of data\nnecessitates the development of fast and accurate algorithms to summarize these\ndata and represent them in a succinct format. One crucial problem in big data\nanalytics is the selection of representative instances from large and\nmassively-distributed data, which is formally known as the Column Subset\nSelection (CSS) problem. The solution to this problem enables data analysts to\nunderstand the insights of the data and explore its hidden structure. The\nselected instances can also be used for data preprocessing tasks such as\nlearning a low-dimensional embedding of the data points or computing a low-rank\napproximation of the corresponding matrix. This paper presents a fast and\naccurate greedy algorithm for large-scale column subset selection. The\nalgorithm minimizes an objective function which measures the reconstruction\nerror of the data matrix based on the subset of selected columns. The paper\nfirst presents a centralized greedy algorithm for column subset selection which\ndepends on a novel recursive formula for calculating the reconstruction error\nof the data matrix. The paper then presents a MapReduce algorithm which selects\na few representative columns from a matrix whose columns are massively\ndistributed across several commodity machines. The algorithm first learns a\nconcise representation of all columns using random projection, and it then\nsolves a generalized column subset selection problem at each machine in which a\nsubset of columns are selected from the sub-matrix on that machine such that\nthe reconstruction error of the concise representation is minimized. The paper\ndemonstrates the effectiveness and efficiency of the proposed algorithm through\nan empirical evaluation on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 15:10:23 GMT"}], "update_date": "2013-12-27", "authors_parsed": [["Farahat", "Ahmed K.", ""], ["Elgohary", "Ahmed", ""], ["Ghodsi", "Ali", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1312.7014", "submitter": "Ren\\'e van Bevern", "authors": "Ren\\'e van Bevern, Andreas Emil Feldmann, Manuel Sorge, Ond\\v{r}ej\n  Such\\'y", "title": "On the Parameterized Complexity of Computing Balanced Partitions in\n  Graphs", "comments": "This version of the article is to appear in Theory of Computing\n  Systems", "journal-ref": "Theory of Computing Systems 57(1):1-35, 2015", "doi": "10.1007/s00224-014-9557-5", "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A balanced partition is a clustering of a graph into a given number of\nequal-sized parts. For instance, the Bisection problem asks to remove at most k\nedges in order to partition the vertices into two equal-sized parts. We prove\nthat Bisection is FPT for the distance to constant cliquewidth if we are given\nthe deletion set. This implies FPT algorithms for some well-studied parameters\nsuch as cluster vertex deletion number and feedback vertex set. However, we\nshow that Bisection does not admit polynomial-size kernels for these\nparameters.\n  For the Vertex Bisection problem, vertices need to be removed in order to\nobtain two equal-sized parts. We show that this problem is FPT for the number\nof removed vertices k if the solution cuts the graph into a constant number c\nof connected components. The latter condition is unavoidable, since we also\nprove that Vertex Bisection is W[1]-hard w.r.t. (k,c).\n  Our algorithms for finding bisections can easily be adapted to finding\npartitions into d equal-sized parts, which entails additional running time\nfactors of n^{O(d)}. We show that a substantial speed-up is unlikely since the\ncorresponding task is W[1]-hard w.r.t. d, even on forests of maximum degree\ntwo. We can, however, show that it is FPT for the vertex cover number.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2013 20:10:09 GMT"}, {"version": "v2", "created": "Fri, 16 May 2014 08:48:20 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["van Bevern", "Ren\u00e9", ""], ["Feldmann", "Andreas Emil", ""], ["Sorge", "Manuel", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "1312.7042", "submitter": "S Kapoor", "authors": "Sanjiv Kapoor and Hemanshu Kaul", "title": "Approximating Quadratic 0-1 Programming via SOCP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating Quadratic O-1 Integer Programs with\nbounded number of constraints and non-negative constraint matrix entries, which\nwe term as PIQP.\n  We describe and analyze a randomized algorithm based on a program with\nhyperbolic constraints (a Second-Order Cone Programming -SOCP- formulation)\nthat achieves an approximation ratio of $O(a_{max} \\frac{n}{\\beta(n)})$, where\n$a_{max}$ is the maximum size of an entry in the constraint matrix and\n$\\beta(n) \\leq \\min_i{W_i} $, where $W_i$ are the constant terms that define\nthe constraint inequalities. We note that by appropriately choosing $\\beta(n)$\nthe randomized algorithm, when combined with other algorithms that achieve good\napproximations for smaller values of $ W_i$, allows better algorithms for the\ncomplete range of $W_i$. This, together with a greedy algorithm, provides a\n$O^*(a_{max} n^{1/2} )$ factor approximation, where $O^*$ hides logarithmic\nterms. Our solution is achieved by a randomization of the optimal solution to\nthe relaxed version of the hyperbolic program. We show that this solution\nprovides the approximation bounds using concentration bounds provided by\nChernoff-Hoeffding and Kim-Vu.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 02:31:45 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Kapoor", "Sanjiv", ""], ["Kaul", "Hemanshu", ""]]}, {"id": "1312.7062", "submitter": "EPTCS", "authors": "Anton Wijs (Eindhoven University of Technology), Dragan\n  Bo\\v{s}na\\v{c}ki (Eindhoven University of Technology), Stefan Edelkamp\n  (University of Bremen)", "title": "Proceedings 2nd Workshop on GRAPH Inspection and Traversal Engineering", "comments": null, "journal-ref": "EPTCS 138, 2013", "doi": "10.4204/EPTCS.138", "report-no": null, "categories": "cs.DS cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the proceedings of the Second Workshop on GRAPH Inspection and\nTraversal Engineering (GRAPHITE 2013), which took place on March 24, 2013 in\nRome, Italy, as a satellite event of the 16th European Joint Conferences on\nTheory and Practice of Software (ETAPS 2013).\n  The topic of the GRAPHITE workshop is graph analysis in all its forms in\ncomputer science. Graphs are used to represent data in many application areas,\nand they are subjected to various computational algorithms in order to acquire\nthe desired information. These graph algorithms tend to have common\ncharacteristics, such as duplicate detection to guarantee their termination,\nindependent of their application domain. Over the past few years, it has been\nshown that the scalability of such algorithms can be dramatically improved by\nusing, e.g., external memory, by exploiting parallel architectures, such as\nclusters, multi-core CPUs, and graphics processing units, and by using\nheuristics to guide the search. Novel techniques to further scale graph search\nalgorithms, and new applications of graph search are within the scope of this\nworkshop.\n  Another topic of interest of the event is more related to the structural\nproperties of graphs: which kind of graph characteristics are relevant for a\nparticular application area, and how can these be measured? Finally, any novel\nway of using graphs for a particular application area is on topic.\n  The goal of this event is to gather scientists from different communities,\nsuch as model checking, artificial intelligence planning, game playing, and\nalgorithm engineering, who do research on graph search algorithms, such that\nawareness of each others' work is increased.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 07:26:41 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Wijs", "Anton", "", "Eindhoven University of Technology"], ["Bo\u0161na\u010dki", "Dragan", "", "Eindhoven University of Technology"], ["Edelkamp", "Stefan", "", "University of Bremen"]]}, {"id": "1312.7217", "submitter": "Venkatesan Chakaravarthy", "authors": "Archita Agarwal and Venkatesan T. Chakaravarthy and Anamitra R.\n  Choudhury and Sambuddha Roy and Yogish Sabharwal", "title": "Distributed and Parallel Algorithms for Set Cover Problems with Small\n  Neighborhood Covers", "comments": "Full version of FSTTCS'13 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a class of set cover problems that satisfy a special\nproperty which we call the {\\em small neighborhood cover} property. This class\nencompasses several well-studied problems including vertex cover, interval\ncover, bag interval cover and tree cover. We design unified distributed and\nparallel algorithms that can handle any set cover problem falling under the\nabove framework and yield constant factor approximations. These algorithms run\nin polylogarithmic communication rounds in the distributed setting and are in\nNC, in the parallel setting.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 09:03:42 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Agarwal", "Archita", ""], ["Chakaravarthy", "Venkatesan T.", ""], ["Choudhury", "Anamitra R.", ""], ["Roy", "Sambuddha", ""], ["Sabharwal", "Yogish", ""]]}, {"id": "1312.7243", "submitter": "Gautam K. Das", "authors": "Ramesh K. Jallu, Prajwal R. Prasad and Gautam K. Das", "title": "Minimum Dominating Set for a Point Set in $\\IR^2$", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the problem of computing minimum dominating set\nfor a given set $S$ of $n$ points in $\\IR^2$. Here the objective is to find a\nminimum cardinality subset $S'$ of $S$ such that the union of the unit radius\ndisks centered at the points in $S'$ covers all the points in $S$. We first\npropose a simple 4-factor and 3-factor approximation algorithms in $O(n^6 \\log\nn)$ and $O(n^{11} \\log n)$ time respectively improving time complexities by a\nfactor of $O(n^2)$ and $O(n^4)$ respectively over the best known result\navailable in the literature [M. De, G.K. Das, P. Carmi and S.C. Nandy, {\\it\nApproximation algorithms for a variant of discrete piercing set problem for\nunit disk}, Int. J. of Comp. Geom. and Appl., to appear]. Finally, we propose a\nvery important shifting lemma, which is of independent interest and using this\nlemma we propose a $\\frac{5}{2}$-factor approximation algorithm and a PTAS for\nthe minimum dominating set problem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 11:09:37 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2014 13:29:55 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Jallu", "Ramesh K.", ""], ["Prasad", "Prajwal R.", ""], ["Das", "Gautam K.", ""]]}, {"id": "1312.7296", "submitter": "Anupam Gupta", "authors": "Anupam Gupta and Amit Kumar", "title": "Online Steiner Tree with Deletions", "comments": "An extended abstract appears in the SODA 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online Steiner tree problem, the input is a set of vertices that\nappear one-by-one, and we have to maintain a Steiner tree on the current set of\nvertices. The cost of the tree is the total length of edges in the tree, and we\nwant this cost to be close to the cost of the optimal Steiner tree at all\npoints in time. If we are allowed to only add edges, a tight bound of\n$\\Theta(\\log n)$ on the competitiveness is known. Recently it was shown that if\nwe can add one new edge and make one edge swap upon every vertex arrival, we\ncan maintain a constant-competitive tree online.\n  But what if the set of vertices sees both additions and deletions? Again, we\nwould like to obtain a low-cost Steiner tree with as few edge changes as\npossible. The original paper of Imase and Waxman had also considered this\nmodel, and it gave a greedy algorithm that maintained a constant-competitive\ntree online, and made at most $O(n^{3/2})$ edge changes for the first $n$\nrequests. In this paper give the following two results.\n  Our first result is an online algorithm that maintains a Steiner tree only\nunder deletions: we start off with a set of vertices, and at each time one of\nthe vertices is removed from this set: our Steiner tree no longer has to span\nthis vertex. We give an algorithm that changes only a constant number of edges\nupon each request, and maintains a constant-competitive tree at all times. Our\nalgorithm uses the primal-dual framework and a global charging argument to\ncarefully make these constant number of changes.\n  We then study the natural greedy algorithm proposed by Imase and Waxman that\nmaintains a constant-competitive Steiner tree in the fully-dynamic model (where\neach request either adds or deletes a vertex). Our second result shows that\nthis algorithm makes only a constant number of changes per request in an\namortized sense.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 16:47:27 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Gupta", "Anupam", ""], ["Kumar", "Amit", ""]]}, {"id": "1312.7306", "submitter": "Bhaskar DasGupta", "authors": "Satabdi Aditya, Bhaskar DasGupta, Marek Karpinski", "title": "Algorithmic Perspectives of Network Transitive Reduction Problems and\n  their Applications to Synthesis and Analysis of Biological Networks", "comments": null, "journal-ref": "Biology, 3 (1), 1-21, 2014", "doi": "10.3390/biology3010001", "report-no": null, "categories": "cs.CC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey paper, we will present a number of core algorithmic questions\nconcerning several transitive reduction problems on network that have\napplications in network synthesis and analysis involving cellular processes.\nOur starting point will be the so-called minimum equivalent digraph problem, a\nclassic computational problem in combinatorial algorithms. We will subsequently\nconsider a few non-trivial extensions or generalizations of this problem\nmotivated by applications in systems biology. We will then discuss the\napplications of these algorithmic methodologies in the context of three major\nbiological research questions: synthesizing and simplifying signal transduction\nnetworks, analyzing disease networks, and measuring redundancy of biological\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 18:09:40 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Aditya", "Satabdi", ""], ["DasGupta", "Bhaskar", ""], ["Karpinski", "Marek", ""]]}, {"id": "1312.7468", "submitter": "Nikhil Balaji", "authors": "Nikhil Balaji, Samir Datta", "title": "Tree-width and Logspace: Determinants and Counting Euler Tours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent result of [EJT10] showing that MSO properties are\nLogspace computable on graphs of bounded tree-width, we consider the complexity\nof computing the determinant of the adjacency matrix of a bounded tree-width\ngraph and prove that it is L-complete. It is important to notice that the\ndeterminant is neither an MSO-property nor counts the number of solutions of an\nMSO-predicate. We extend this technique to count the number of spanning\narborescences and directed Euler tours in bounded tree-width digraphs, and\nfurther to counting the number of spanning trees and the number of Euler tours\nin undirected graphs, all in L. Notice that undirected Euler tours are not\nknown to be MSO-expressible and the corresponding counting problem is in fact\n#P-hard for general graphs. Counting undirected Euler tours in bounded\ntree-width graphs was not known to be polynomial time computable till very\nrecently Chebolu et al [CCM13] gave a polynomial time algorithm for this\nproblem (concurrently and independently of this work). Finally, we also show\nsome linear algebraic extensions of the determinant algorithm to show how to\ncompute the charcteristic polynomial and trace of the powers of a bounded\ntree-width graph in L.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2013 19:59:01 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2013 02:57:24 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Balaji", "Nikhil", ""], ["Datta", "Samir", ""]]}, {"id": "1312.7499", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis, Malik Magdon-Ismail", "title": "A note on sparse least-squares regression", "comments": "Information Processing Letters, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute a \\emph{sparse} solution to the classical least-squares problem\n$\\min_x||A x -b||,$ where $A$ is an arbitrary matrix. We describe a novel\nalgorithm for this sparse least-squares problem. The algorithm operates as\nfollows: first, it selects columns from $A$, and then solves a least-squares\nproblem only with the selected columns. The column selection algorithm that we\nuse is known to perform well for the well studied column subset selection\nproblem. The contribution of this article is to show that it gives favorable\nresults for sparse least-squares as well. Specifically, we prove that the\nsolution vector obtained by our algorithm is close to the solution vector\nobtained via what is known as the \"SVD-truncated regularization approach\".\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2013 04:48:13 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Boutsidis", "Christos", ""], ["Magdon-Ismail", "Malik", ""]]}]