[{"id": "1502.00089", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Ralf Klasing, Yessin M. Neggaz, Joseph G. Peters", "title": "Efficiently Testing T-Interval Connectivity in Dynamic Graphs", "comments": "Long version of a CIAC 2015 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many types of dynamic networks are made up of durable entities whose links\nevolve over time. When considered from a {\\em global} and {\\em discrete}\nstandpoint, these networks are often modelled as evolving graphs, i.e. a\nsequence of graphs ${\\cal G}=(G_1,G_2,...,G_{\\delta})$ such that $G_i=(V,E_i)$\nrepresents the network topology at time step $i$. Such a sequence is said to be\n$T$-interval connected if for any $t\\in [1, \\delta-T+1]$ all graphs in\n$\\{G_t,G_{t+1},...,G_{t+T-1}\\}$ share a common connected spanning subgraph. In\nthis paper, we consider the problem of deciding whether a given sequence ${\\cal\nG}$ is $T$-interval connected for a given $T$. We also consider the related\nproblem of finding the largest $T$ for which a given ${\\cal G}$ is $T$-interval\nconnected. We assume that the changes between two consecutive graphs are\narbitrary, and that two operations, {\\em binary intersection} and {\\em\nconnectivity testing}, are available to solve the problems. We show that\n$\\Omega(\\delta)$ such operations are required to solve both problems, and we\npresent optimal $O(\\delta)$ online algorithms for both problems. We extend our\nonline algorithms to a dynamic setting in which connectivity is based on the\nrecent evolution of the network.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 10:26:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2015 14:29:57 GMT"}, {"version": "v3", "created": "Fri, 17 Mar 2017 17:07:07 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Klasing", "Ralf", ""], ["Neggaz", "Yessin M.", ""], ["Peters", "Joseph G.", ""]]}, {"id": "1502.00182", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani, George Atia", "title": "High Dimensional Low Rank plus Sparse Matrix Decomposition", "comments": "IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2017.2649482", "report-no": null, "categories": "cs.NA cs.DS cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of low rank plus sparse matrix\ndecomposition for big data. Conventional algorithms for matrix decomposition\nuse the entire data to extract the low-rank and sparse components, and are\nbased on optimization problems with complexity that scales with the dimension\nof the data, which limits their scalability. Furthermore, existing randomized\napproaches mostly rely on uniform random sampling, which is quite inefficient\nfor many real world data matrices that exhibit additional structures (e.g.\nclustering). In this paper, a scalable subspace-pursuit approach that\ntransforms the decomposition problem to a subspace learning problem is\nproposed. The decomposition is carried out using a small data sketch formed\nfrom sampled columns/rows. Even when the data is sampled uniformly at random,\nit is shown that the sufficient number of sampled columns/rows is roughly\nO(r\\mu), where \\mu is the coherency parameter and r the rank of the low rank\ncomponent. In addition, adaptive sampling algorithms are proposed to address\nthe problem of column/row sampling from structured data. We provide an analysis\nof the proposed method with adaptive sampling and show that adaptive sampling\nmakes the required number of sampled columns/rows invariant to the distribution\nof the data. The proposed approach is amenable to online implementation and an\nonline scheme is proposed.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 00:57:57 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2016 03:56:48 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 06:41:34 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1502.00413", "submitter": "Asaf Shapira", "authors": "Reut Levi, Guy Moshkovitz, Dana Ron, Ronitt Rubinfeld and Asaf Shapira", "title": "Constructing Near Spanning Trees with Few Local Inspections", "comments": "References fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing a spanning tree of a graph is one of the most basic tasks in\ngraph theory. Motivated by several recent studies of local graph algorithms, we\nconsider the following variant of this problem. Let G be a connected\nbounded-degree graph. Given an edge $e$ in $G$ we would like to decide whether\n$e$ belongs to a connected subgraph $G'$ consisting of $(1+\\epsilon)n$ edges\n(for a prespecified constant $\\epsilon >0$), where the decision for different\nedges should be consistent with the same subgraph $G'$. Can this task be\nperformed by inspecting only a {\\em constant} number of edges in $G$? Our main\nresults are:\n  (1) We show that if every $t$-vertex subgraph of $G$ has expansion $1/(\\log\nt)^{1+o(1)}$ then one can (deterministically) construct a sparse spanning\nsubgraph $G'$ of $G$ using few inspections. To this end we analyze a \"local\"\nversion of a famous minimum-weight spanning tree algorithm.\n  (2) We show that the above expansion requirement is sharp even when allowing\nrandomization. To this end we construct a family of $3$-regular graphs of high\ngirth, in which every $t$-vertex subgraph has expansion $1/(\\log t)^{1-o(1)}$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 09:20:39 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 09:06:04 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Levi", "Reut", ""], ["Moshkovitz", "Guy", ""], ["Ron", "Dana", ""], ["Rubinfeld", "Ronitt", ""], ["Shapira", "Asaf", ""]]}, {"id": "1502.00447", "submitter": "David Tian", "authors": "Wenhong Tian, Chaojie Huang, Xinyang Wang, Qin Xiong", "title": "Obtaining Quality-Proved Near Optimal Results for Traveling Salesman\n  Problem", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": "Technical Report 20150129", "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The traveling salesman problem (TSP) is one of the most challenging NP-hard\nproblems. It has widely applications in various disciplines such as physics,\nbiology, computer science and so forth. The best known approximation algorithm\nfor Symmetric TSP (STSP) whose cost matrix satisfies the triangle inequality\n(called $\\triangle$STSP) is Christofides algorithm which was proposed in 1976\nand is a $\\frac{3}{2}$-approximation. Since then no proved improvement is made\nand improving upon this bound is a fundamental open question in combinatorial\noptimization.\n  In this paper, for the first time, we propose Truncated Generalized Beta\ndistribution (TGB) for the probability distribution of optimal tour lengths in\na TSP. We then introduce an iterative TGB approach to obtain quality-proved\nnear optimal approximation, i.e.,\n(1+$\\frac{1}{2}(\\frac{\\alpha+1}{\\alpha+2})^{K-1}$)-approximation where $K$ is\nthe number of iterations in TGB and $\\alpha (>>1)$ is the shape parameters of\nTGB. The result can approach the true optimum as $K$ increases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 12:07:37 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 02:51:07 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Tian", "Wenhong", ""], ["Huang", "Chaojie", ""], ["Wang", "Xinyang", ""], ["Xiong", "Qin", ""]]}, {"id": "1502.00716", "submitter": "Hung Le", "authors": "Glencora Borradaile and Hung Le", "title": "Optimal dynamic program for r-domination problems over tree\n  decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent progress in showing that the exponential dependence on\ntreewidth in dynamic programming algorithms for solving NP-hard problems are\noptimal under the Strong Exponential Time Hypothesis (SETH). We extend this\nwork to $r$-domination problems. In $r$-dominating set, one wished to find a\nminimum subset $S$ of vertices such that every vertex of $G$ is within $r$ hops\nof some vertex in $S$. In connected $r$-dominating set, one additionally\nrequires that the set induces a connected subgraph of $G$. We give a\n$O((2r+1)^{\\mathrm{tw}} n)$ time algorithm for $r$-dominating set and a\n$O((2r+2)^{\\mathrm{tw}} n^{O(1)})$ time algorithm for connected $r$-dominating\nset in $n$-vertex graphs of treewidth $\\mathrm{tw}$. We show that the running\ntime dependence on $r$ and $\\mathrm{tw}$ is the best possible under SETH. This\nadds to earlier observations that a \"+1\" in the denominator is required for\nconnectivity constraints.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 02:59:51 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Borradaile", "Glencora", ""], ["Le", "Hung", ""]]}, {"id": "1502.00859", "submitter": "Piotr Micek", "authors": "Piotr Micek and Veit Wiechert", "title": "An on-line competitive algorithm for coloring bipartite graphs without\n  long induced paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of an on-line competitive algorithm for coloring bipartite\ngraphs remains a tantalizing open problem. So far there are only partial\npositive results for bipartite graphs with certain small forbidden graphs as\ninduced subgraphs. We propose a new on-line competitive coloring algorithm for\n$P_9$-free bipartite graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 13:32:08 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Micek", "Piotr", ""], ["Wiechert", "Veit", ""]]}, {"id": "1502.00911", "submitter": "\\'Eric Colin de Verdi\\`ere", "authors": "\\'Eric Colin de Verdi\\`ere", "title": "Multicuts in Planar and Bounded-Genus Graphs with Bounded Number of\n  Terminals", "comments": "removed erroneous refinement of main theorem; minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected, edge-weighted graph G together with pairs of vertices,\ncalled pairs of terminals, the minimum multicut problem asks for a\nminimum-weight set of edges such that, after deleting these edges, the two\nterminals of each pair belong to different connected components of the graph.\nRelying on topological techniques, we provide a polynomial-time algorithm for\nthis problem in the case where G is embedded on a fixed surface of genus g\n(e.g., when G is planar) and has a fixed number t of terminals. The running\ntime is a polynomial of degree O(sqrt{g^2+gt}) in the input size.\n  In the planar case, our result corrects an error in an extended abstract by\nBentz [Int. Workshop on Parameterized and Exact Computation, 109-119, 2012].\nThe minimum multicut problem is also a generalization of the multiway cut\nproblem, a.k.a. multiterminal cut problem; even for this special case, no\ndedicated algorithm was known for graphs embedded on surfaces.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 16:23:50 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2016 07:31:34 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 11:20:47 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["de Verdi\u00e8re", "\u00c9ric Colin", ""]]}, {"id": "1502.00993", "submitter": "Tiphaine Viard", "authors": "Tiphaine Viard (LIP6), Matthieu Latapy (LIP6), Cl\\'emence Magnien\n  (LIP6)", "title": "Computing maximal cliques in link streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A link stream is a collection of triplets $(t, u, v)$ indicating that an\ninteraction occurred between u and v at time t. We generalize the classical\nnotion of cliques in graphs to such link streams: for a given $\\Delta$, a\n$\\Delta$-clique is a set of nodes and a time interval such that all pairs of\nnodes in this set interact at least once during each sub-interval of duration\n$\\Delta$. We propose an algorithm to enumerate all maximal (in terms of nodes\nor time interval) cliques of a link stream, and illustrate its practical\nrelevance on a real-world contact trace.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 20:19:26 GMT"}, {"version": "v2", "created": "Thu, 5 Feb 2015 10:14:16 GMT"}, {"version": "v3", "created": "Mon, 9 Feb 2015 15:25:19 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2015 11:49:15 GMT"}, {"version": "v5", "created": "Mon, 10 Aug 2015 14:26:24 GMT"}, {"version": "v6", "created": "Wed, 30 Sep 2015 14:30:43 GMT"}, {"version": "v7", "created": "Mon, 4 Jul 2016 15:46:34 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Viard", "Tiphaine", "", "LIP6"], ["Latapy", "Matthieu", "", "LIP6"], ["Magnien", "Cl\u00e9mence", "", "LIP6"]]}, {"id": "1502.01063", "submitter": "Marvin K\\\"unnemann", "authors": "Karl Bringmann and Marvin K\\\"unnemann", "title": "Quadratic Conditional Lower Bounds for String Problems and Dynamic Time\n  Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic similarity measures of strings are longest common subsequence and\nLevenshtein distance (i.e., the classic edit distance). A classic similarity\nmeasure of curves is dynamic time warping. These measures can be computed by\nsimple $O(n^2)$ dynamic programming algorithms, and despite much effort no\nalgorithms with significantly better running time are known.\n  We prove that, even restricted to binary strings or one-dimensional curves,\nrespectively, these measures do not have strongly subquadratic time algorithms,\ni.e., no algorithms with running time $O(n^{2-\\varepsilon})$ for any\n$\\varepsilon > 0$, unless the Strong Exponential Time Hypothesis fails. We\ngeneralize the result to edit distance for arbitrary fixed costs of the four\noperations (deletion in one of the two strings, matching, substitution), by\nidentifying trivial cases that can be solved in constant time, and proving\nquadratic-time hardness on binary strings for all other cost choices. This\nimproves and generalizes the known hardness result for Levenshtein distance\n[Backurs, Indyk STOC'15] by the restriction to binary strings and the\ngeneralization to arbitrary costs, and adds important problems to a recent line\nof research showing conditional lower bounds for a growing number of quadratic\ntime problems.\n  As our main technical contribution, we introduce a framework for proving\nquadratic-time hardness of similarity measures. To apply the framework it\nsuffices to construct a single gadget, which encapsulates all the expressive\npower necessary to emulate a reduction from satisfiability.\n  Finally, we prove quadratic-time hardness for longest palindromic subsequence\nand longest tandem subsequence via reductions from longest common subsequence,\nshowing that conditional lower bounds based on the Strong Exponential Time\nHypothesis also apply to string problems that are not necessarily similarity\nmeasures.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 23:27:26 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 21:30:10 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Bringmann", "Karl", ""], ["K\u00fcnnemann", "Marvin", ""]]}, {"id": "1502.01220", "submitter": "Tarek Lahlou", "authors": "Tarek A. Lahlou and Alan V. Oppenheim", "title": "Unveiling The Tree: A Convex Framework for Sparse Problems", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP.2015.7178687", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general framework for generating greedy algorithms for\nsolving convex constraint satisfaction problems for sparse solutions by mapping\nthe satisfaction problem into one of graph traversal on a rooted tree of\nunknown topology. For every pre-walk of the tree an initial set of generally\ndense feasible solutions is processed in such a way that the sparsity of each\nsolution increases with each generation unveiled. The specific computation\nperformed at any particular child node is shown to correspond to an embedding\nof a polytope into the polytope received from that nodes parent. Several issues\nrelated to pre-walk order selection, computational complexity and tractability,\nand the use of heuristic and/or side information is discussed. An example of a\nsingle-path, depth-first algorithm on a tree with randomized vertex reduction\nand a run-time path selection algorithm is presented in the context of sparse\nlowpass filter design.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 14:54:37 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Lahlou", "Tarek A.", ""], ["Oppenheim", "Alan V.", ""]]}, {"id": "1502.01403", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan", "title": "Distributed Estimation of Generalized Matrix Rank: Efficient Algorithms\n  and Lower Bounds", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following generalized matrix rank estimation problem: given an\n$n \\times n$ matrix and a constant $c \\geq 0$, estimate the number of\neigenvalues that are greater than $c$. In the distributed setting, the matrix\nof interest is the sum of $m$ matrices held by separate machines. We show that\nany deterministic algorithm solving this problem must communicate $\\Omega(n^2)$\nbits, which is order-equivalent to transmitting the whole matrix. In contrast,\nwe propose a randomized algorithm that communicates only $\\widetilde O(n)$\nbits. The upper bound is matched by an $\\Omega(n)$ lower bound on the\nrandomized communication complexity. We demonstrate the practical effectiveness\nof the proposed algorithm with some numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 00:53:01 GMT"}, {"version": "v2", "created": "Fri, 6 Feb 2015 18:51:23 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Zhang", "Yuchen", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1502.01435", "submitter": "Quentin Stout", "authors": "Quentin F. Stout", "title": "Optimal component labeling algorithms for mesh-connected computers and\n  VLSI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph $G$ of $n$ weighted edges, stored one edge per\nprocessor in a square mesh of $n$ processors, we show how to determine the\nconnected components and a minimal spanning forest in $\\Theta(\\sqrt{n})$ time.\nMore generally, we show how to solve these problems in $\\Theta(n^{1/d})$ time\nwhen the mesh is a $d$-dimensional cube, where the implied constants depend\nupon $d$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 05:11:47 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Stout", "Quentin F.", ""]]}, {"id": "1502.01461", "submitter": "Ivan Bliznets", "authors": "Ivan Bliznets, Fedor V. Fomin, Petr A. Golovach, Nikolay Karpov,\n  Alexander S. Kulikov, Saket Saurabh", "title": "Parameterized Complexity of Superstring Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Shortest Superstring problem we are given a set of strings $S=\\{s_1,\n\\ldots, s_n\\}$ and integer $\\ell$ and the question is to decide whether there\nis a superstring $s$ of length at most $\\ell$ containing all strings of $S$ as\nsubstrings. We obtain several parameterized algorithms and complexity results\nfor this problem.\n  In particular, we give an algorithm which in time $2^{O(k)}\n\\operatorname{poly}(n)$ finds a superstring of length at most $\\ell$ containing\nat least $k$ strings of $S$. We complement this by the lower bound showing that\nsuch a parameterization does not admit a polynomial kernel up to some\ncomplexity assumption. We also obtain several results about \"below guaranteed\nvalues\" parameterization of the problem. We show that parameterization by\ncompression admits a polynomial kernel while parameterization \"below matching\"\nis hard.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 08:52:44 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Bliznets", "Ivan", ""], ["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Karpov", "Nikolay", ""], ["Kulikov", "Alexander S.", ""], ["Saurabh", "Saket", ""]]}, {"id": "1502.01566", "submitter": "Helio M. de Oliveira", "authors": "H.M. de Oliveira, R.M. Campello de Souza and R.C. de Oliveira", "title": "A Matrix Laurent Series-based Fast Fourier Transform for Blocklengths\n  N=4 (mod 8)", "comments": "6 pages, 2 figures, 2 tables. Conference: XXVII Simposio Brasileiro\n  de Telecomunicacoes - SBrT'09, 2009, Blumenau, SC, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General guidelines for a new fast computation of blocklength 8m+4 DFTs are\npresented, which is based on a Laurent series involving matrices. Results of\nnon-trivial real multiplicative complexity are presented for blocklengths N=64,\nachieving lower multiplication counts than previously published FFTs. A\ndetailed description for the cases m=1 and m=2 is presented.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 14:25:33 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["de Oliveira", "H. M.", ""], ["de Souza", "R. M. Campello", ""], ["de Oliveira", "R. C.", ""]]}, {"id": "1502.01687", "submitter": "Christian Schulz", "authors": "Sebastian Lamm and Peter Sanders and Christian Schulz", "title": "Graph Partitioning for Independent Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing maximum independent sets in graphs is an important problem in\ncomputer science. In this paper, we develop an evolutionary algorithm to tackle\nthe problem. The core innovations of the algorithm are very natural combine\noperations based on graph partitioning and local search algorithms. More\nprecisely, we employ a state-of-the-art graph partitioner to derive operations\nthat enable us to quickly exchange whole blocks of given independent sets. To\nenhance newly computed offsprings we combine our operators with a local search\nalgorithm. Our experimental evaluation indicates that we are able to outperform\nstate-of-the-art algorithms on a variety of instances.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 19:35:24 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Lamm", "Sebastian", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1502.01802", "submitter": "Ning Kang", "authors": "T-H. Hubert Chan and Zhiyi Huang and Ning Kang", "title": "Online Convex Covering and Packing Problems", "comments": "Fixed an error in Theorem 3.2 together with its proof, and changed\n  Corollary 3.1 accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online convex covering problem and online convex packing\nproblem. The (offline) convex covering problem is modeled by the following\nconvex program: $\\min_{x \\in R_+^n} f(x) \\ \\text{s.t}\\ A x \\ge 1$, where $f :\nR_+^n \\mapsto R_+$ is a monotone and convex cost function, and $A$ is an $m\n\\times n$ matrix with non-negative entries. Each row of the constraint matrix\n$A$ corresponds to a covering constraint. In the online problem, each row of\n$A$ comes online and the algorithm must maintain a feasible assignment $x$ and\nmay only increase $x$ over time. The (offline) convex packing problem is\nmodeled by the following convex program: $\\max_{y\\in R_+^m} \\sum_{j = 1}^m y_j\n- g(A^T y)$, where $g : R_+^n \\mapsto R_+$ is a monotone and convex cost\nfunction. It is the Fenchel dual program of convex covering when $g$ is the\nconvex conjugate of $f$. In the online problem, each variable $y_j$ arrives\nonline and the algorithm must decide the value of $y_j$ on its arrival.\n  We propose simple online algorithms for both problems using the online primal\ndual technique, and obtain nearly optimal competitive ratios for both problems\nfor the important special case of polynomial cost functions. For any convex\npolynomial cost functions with non-negative coefficients and maximum degree\n$\\tau$, we introduce an $O(\\tau \\log n)^\\tau$-competitive online convex\ncovering algorithm, and an $O(\\tau)$-competitive online convex packing\nalgorithm, matching the known $\\Omega(\\tau \\log n)^\\tau$ and $\\Omega(\\tau)$\nlower bounds respectively.\n  There is a large family of online resource allocation problems that can be\nmodeled under this online convex covering and packing framework, including\nonline covering and packing problems (with linear objectives), online mixed\ncovering and packing, and online combinatorial auction. Our framework allows us\nto study these problems using a unified approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 05:33:10 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 14:56:01 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2015 07:22:46 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Chan", "T-H. Hubert", ""], ["Huang", "Zhiyi", ""], ["Kang", "Ning", ""]]}, {"id": "1502.01837", "submitter": "Scott Lilienthal", "authors": "Scott Lilienthal", "title": "Bipartite Synthesis Method applied to the Subset Sum Problem\n  demonstrates capability as decision and optimization tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a deterministic algorithm for solving an instance of\nthe Subset Sum Problem based on a new method entitled the Bipartite Synthesis\nMethod. The algorithm is described and shown to have worst-case limiting\nperformance over similar to the best deterministic algorithms achieving run\ntime complexity on the order of O(2^0.5n). This algorithm is representative of\na more expansive capability that might convey significant advantages over\nexisting deterministic or probabilistic methods, and it is amenable to blending\nwith existing methods. The method introduced can be applied to a variety of\ndecision and optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 09:59:48 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Lilienthal", "Scott", ""]]}, {"id": "1502.01861", "submitter": "Sebastian Deorowicz", "authors": "Tomasz Kowalski, Szymon Grabowski, Sebastian Deorowicz", "title": "Indexing arbitrary-length $k$-mers in sequencing reads", "comments": null, "journal-ref": "PLOS One, Article no. 0133198 (2015)", "doi": "10.1371/journal.pone.0133198", "report-no": null, "categories": "cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lightweight data structure for indexing and querying collections\nof NGS reads data in main memory. The data structure supports the interface\nproposed in the pioneering work by Philippe et al. for counting and locating\n$k$-mers in sequencing reads. Our solution, PgSA (pseudogenome suffix array),\nbased on finding overlapping reads, is competitive to the existing algorithms\nin the space use, query times, or both. The main applications of our index\ninclude variant calling, error correction and analysis of reads from RNA-seq\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 11:36:30 GMT"}, {"version": "v2", "created": "Mon, 9 Feb 2015 16:28:34 GMT"}, {"version": "v3", "created": "Fri, 13 Feb 2015 13:43:24 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Kowalski", "Tomasz", ""], ["Grabowski", "Szymon", ""], ["Deorowicz", "Sebastian", ""]]}, {"id": "1502.01951", "submitter": "Lu\\'is Tarrayava", "authors": "Lu\\'is Tarrataca and Andreas Wichert", "title": "Tree Search and Quantum Computation", "comments": null, "journal-ref": "Quantum Information Processing, 2011, 10:4, 475-500", "doi": "10.1007/s11128-010-0212-z", "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional tree search algorithms supply a blueprint for modeling problem\nsolving behaviour. A diverse spectrum of problems can be formulated in terms of\ntree search. Quantum computation, in particular Grover's algorithm, has aroused\na great deal of interest since it allows for a quadratic speedup to be obtained\nin search procedures. In this work we consider the impact of incorporating\nclassical search concepts alongside Grover's algorithm into a hybrid quantum\nsearch system. Some of the crucial points examined include: (1) the\nreverberations of contemplating the use of non-constant branching factors; (2)\ndetermining the consequences of incorporating an heuristic perspective into a\nquantum tree search model.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 16:55:10 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Tarrataca", "Lu\u00eds", ""], ["Wichert", "Andreas", ""]]}, {"id": "1502.01959", "submitter": "Lu\\'is Tarrataca", "authors": "Lu\\'is Tarrataca and Andreas Wichert", "title": "Can Quantum Entanglement Detection Schemes Improve Search?", "comments": null, "journal-ref": "Quantum Information Processing, 2012, 11:1, 55-66", "doi": "10.1007/s11128-011-0231-4", "report-no": null, "categories": "cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computation, in particular Grover's algorithm, has aroused a great\ndeal of interest since it allows for a quadratic speedup to be obtained in\nsearch procedures. Classical search procedures for an $N$ element database\nrequire at most $O(N)$ time complexity. Grover's algorithm is able to find a\nsolution with high probability in $O(\\sqrt{N})$ time through an amplitude\namplification scheme. In this work we draw elements from both classical and\nquantum computation to develop an alternative search proposal based on quantum\nentanglement detection schemes. In 2002, Horodecki and Ekert proposed an\nefficient method for direct detection of quantum entanglement. Our proposition\nto quantum search combines quantum entanglement detection alongside\nentanglement inducing operators. Grover's quantum search relies on measuring a\nquantum superposition after having applied a unitary evolution. We deviate from\nthe standard method by focusing on fine-tuning a unitary operator in order to\ninfer the solution with certainty. Our proposal sacrifices space for speed and\ndepends on the mathematical properties of linear positive maps $\\Lambda$ which\nhave not been operationally characterized. Whether such a $\\Lambda$ can be\neasily determined remains an open question.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 17:04:50 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Tarrataca", "Lu\u00eds", ""], ["Wichert", "Andreas", ""]]}, {"id": "1502.02051", "submitter": "Ola Svensson", "authors": "Ola Svensson", "title": "Approximating ATSP by Relaxing Connectivity", "comments": "25 pages, 2 figures, fixed some typos in previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard LP relaxation of the asymmetric traveling salesman problem has\nbeen conjectured to have a constant integrality gap in the metric case. We\nprove this conjecture when restricted to shortest path metrics of node-weighted\ndigraphs. Our arguments are constructive and give a constant factor\napproximation algorithm for these metrics. We remark that the considered case\nis more general than the directed analog of the special case of the symmetric\ntraveling salesman problem for which there were recent improvements on\nChristofides' algorithm.\n  The main idea of our approach is to first consider an easier problem obtained\nby significantly relaxing the general connectivity requirements into local\nconnectivity conditions. For this relaxed problem, it is quite easy to give an\nalgorithm with a guarantee of 3 on node-weighted shortest path metrics. More\nsurprisingly, we then show that any algorithm (irrespective of the metric) for\nthe relaxed problem can be turned into an algorithm for the asymmetric\ntraveling salesman problem by only losing a small constant factor in the\nperformance guarantee. This leaves open the intriguing task of designing a\n\"good\" algorithm for the relaxed problem on general metrics.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 21:22:39 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2015 12:58:37 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Svensson", "Ola", ""]]}, {"id": "1502.02135", "submitter": "Diptarka Chakraborty", "authors": "Diptarka Chakraborty and Raghunath Tewari", "title": "Simultaneous Time-Space Upper Bounds for Certain Problems in Planar\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that given a weighted, directed planar graph $G$, and\nany $\\epsilon >0$, there exists a polynomial time and\n$O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm that computes the shortest path\nbetween two fixed vertices in $G$.\n  We also consider the {\\RB} problem, which states that given a graph $G$ whose\nedges are colored either red or blue and two fixed vertices $s$ and $t$ in $G$,\nis there a path from $s$ to $t$ in $G$ that alternates between red and blue\nedges. The {\\RB} problem in planar DAGs is {\\NL}-complete. We exhibit a\npolynomial time and $O(n^{\\frac{1}{2}+\\epsilon})$ space algorithm (for any\n$\\epsilon >0$) for the {\\RB} problem in planar DAG.\n  In the last part of this paper, we consider the problem of deciding and\nconstructing the perfect matching present in a planar bipartite graph and also\na similar problem which is to find a Hall-obstacle in a planar bipartite graph.\nWe show the time-space bound of these two problems are same as the bound of\nshortest path problem in a directed planar graph.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 12:54:48 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1502.02155", "submitter": "Rad Niazadeh", "authors": "Thomas Kesselheim, Robert Kleinberg, Rad Niazadeh", "title": "Secretary Problems with Non-Uniform Arrival Order", "comments": "To appear in Proceedings of the 47th Annual ACM Symposium on Theory\n  of Computing (STOC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many online problems, it is known that the uniform arrival order enables\nthe design of algorithms with much better performance guarantees than under\nworst-case. The quintessential example is the secretary problem. If the\nsequence of elements is presented in uniformly random order there is an\nalgorithm that picks the maximum value with probability 1/e, whereas no\nnon-trivial performance guarantee is possible if the elements arrive in\nworst-case order. This work initiates an investigation into relaxations of the\nrandom-ordering hypothesis in online algorithms, by focusing on the secretary\nproblems. We present two sets of properties of distributions over permutations\nas sufficient conditions, called the block-independence property and\nuniform-induced-ordering property. We show these two are asymptotically\nequivalent by borrowing some techniques from the approximation theory.\nMoreover, we show they both imply the existence of secretary algorithms with\nconstant probability of correct selection, approaching the optimal constant 1/e\nin the limit. We substantiate our idea by providing several constructions of\ndistributions that satisfy block-independence. We also show that {\\Theta}(log\nlog n) is the minimum entropy of any permutation distribution that permits\nconstant probability of correct selection in the secretary problem with n\nelements. While our block-independence condition is sufficient for constant\nprobability of correct selection, it is not necessary; however, we present\ncomplexity-theoretic evidence that no simple necessary and sufficient criterion\nexists. Finally, we explore the extent to which the performance guarantees of\nother algorithms are preserved when one relaxes the uniform random ordering\nassumption, obtaining a positive result for Kleinberg's multiple-choice\nsecretary algorithm and a negative result for the weighted bipartite matching\nalgorithm of Korula and Pal.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 16:04:14 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Kesselheim", "Thomas", ""], ["Kleinberg", "Robert", ""], ["Niazadeh", "Rad", ""]]}, {"id": "1502.02168", "submitter": "Renato J Cintra", "authors": "H. M. de Oliveira, R. J. Cintra, R. M. Campello de Souza", "title": "Multilayer Hadamard Decomposition of Discrete Hartley Transforms", "comments": "Fixed several typos. 7 pages, 5 figures, XVIII Simp\\'osio Brasileiro\n  de Telecomunica\\c{c}\\~oes, 2000, Gramado, RS, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete transforms such as the discrete Fourier transform (DFT) or the\ndiscrete Hartley transform (DHT) furnish an indispensable tool in signal\nprocessing. The successful application of transform techniques relies on the\nexistence of the so-called fast transforms. In this paper some fast algorithms\nare derived which meet the lower bound on the multiplicative complexity of the\nDFT/DHT. The approach is based on a decomposition of the DHT into layers of\nWalsh-Hadamard transforms. In particular, fast algorithms for short block\nlengths such as $N \\in \\{4, 8, 12, 24\\}$ are presented.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 17:44:57 GMT"}, {"version": "v2", "created": "Thu, 12 Feb 2015 14:08:14 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2015 13:52:49 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""], ["de Souza", "R. M. Campello", ""]]}, {"id": "1502.02178", "submitter": "Shahar Dobzinski", "authors": "Shahar Dobzinski and Ami Mor", "title": "On the Greedy Algorithm for Combinatorial Auctions with a Random Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we study the greedy algorithm for combinatorial auctions with\nsubmodular bidders. It is well known that this algorithm provides an\napproximation ratio of $2$ for every order of the items. We show that if the\nvaluations are vertex cover functions and the order is random then the expected\napproximation ratio imrpoves to $\\frac 7 4$.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 19:36:15 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Dobzinski", "Shahar", ""], ["Mor", "Ami", ""]]}, {"id": "1502.02242", "submitter": "Jelle Hellings", "authors": "Jelle Hellings", "title": "Querying for Paths in Graphs using Context-Free Path Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigational queries for graph-structured data, such as the regular path\nqueries and the context-free path queries, are usually evaluated to a relation\nof node-pairs $(m, n)$ such that there is a path from $m$ to $n$ satisfying the\nconditions of the query. Although this relational query semantics has practical\nvalue, we believe that the relational query semantics can only provide limited\ninsight in the structure of the graph data. To address the limits of the\nrelational query semantics, we introduce the all-path query semantics and the\nsingle-path query semantics. Under these path-based query semantics, a query is\nevaluated to all paths satisfying the conditions of the query, or,\nrespectively, to a single such path.\n  While focusing on context-free path queries, we provide a formal framework\nfor evaluating queries on graphs using both path-based query semantics. For the\nall-path query semantics, we show that the result of a query can be represented\nby a finite context-free grammar annotated with node-information relevant for\nderiving each path in the query result. For the single-path query semantics, we\npropose to search for a path of minimum length. We reduce the problem of\nfinding such a path of minimum length to finding a string of minimum length in\na context-free language, and for deriving such a string we propose a novel\nalgorithm.\n  Our initial results show that the path-based query semantics have added\npractical value and that query evaluation for both path-based query semantics\nis feasible, even when query results grow very large. For the single-path query\nsemantics, determining strict worst-case upper bounds on the size of the query\nresult remains the focus of future work.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 12:11:33 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2016 14:43:13 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Hellings", "Jelle", ""]]}, {"id": "1502.02328", "submitter": "Jonathan Graehl", "authors": "Jonathan Graehl", "title": "Context-free Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Algorithms on grammars/transducers with context-free derivations: hypergraph\nreachability, shortest path, and inside-outside pruning of 'relatively useless'\narcs that are unused by any near-shortest paths.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 01:45:17 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Graehl", "Jonathan", ""]]}, {"id": "1502.02422", "submitter": "Koji M. Kobayashi", "authors": "Jun Kawahara and Koji M. Kobayashi", "title": "An improved lower bound for one-dimensional online unit clustering", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online unit clustering problem was proposed by Chan and Zarrabi-Zadeh\n(WAOA2007 and Theory of Computing Systems 45(3), 2009), which is defined as\nfollows: \"Points\" are given online in the $d$-dimensional Euclidean space one\nby one. An algorithm creates a \"cluster,\" which is a $d$-dimensional rectangle.\nThe initial length of each edge of a cluster is 0. An algorithm can extend an\nedge until it reaches unit length independently of other dimensions. The task\nof an algorithm is to cover a new given point either by creating a new cluster\nand assigning it to the point, or by extending edges of an existing cluster\ncreated in past times. The goal is to minimize the total number of created\nclusters. Chan and Zarrabi-Zadeh proposed some method to obtain a competitive\nalgorithm for the $d$-dimensional case using an algorithm for the\none-dimensional case, and thus the one-dimensional case has been extensively\nstudied including some variants of the unit clustering problem. In this paper,\nwe show a lower bound of $13/8 = 1.625$ on the competitive ratio of any\ndeterministic online algorithm for the one-dimensional unit clustering,\nimproving the previous lower bound $8/5 (=1.6)$ presented by Epstein and van\nStee (WAOA2007 and ACM Transactions on Algorithms 7(1), 2010). Note that Ehmsen\nand Larsen (SWAT2010 and Theoretical Computer Science, 500, 2013) showed the\ncurrent best upper bound of $5/3$, and conjectured that the exact competitive\nratio in the one-dimensional case may be $13/8$.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 10:34:48 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Kawahara", "Jun", ""], ["Kobayashi", "Koji M.", ""]]}, {"id": "1502.02426", "submitter": "Fabian Fuchs", "authors": "Fabian Fuchs, Roman Prutkin", "title": "Simple Distributed Delta + 1 Coloring in the SINR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless ad hoc or sensor networks, distributed node coloring is a\nfundamental problem closely related to establishing efficient communication\nthrough TDMA schedules. For networks with maximum degree Delta, a Delta + 1\ncoloring is the ultimate goal in the distributed setting as this is always\npossible. In this work we propose Delta + 1 coloring algorithms for the\nsynchronous and asynchronous setting. All algorithms have a runtime of O(Delta\nlog n) time slots. This improves on the previous algorithms for the SINR model\neither in terms of the number of required colors or the runtime and matches the\nruntime of local broadcasting in the SINR model (which can be seen as a lower\nbound).\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 10:43:01 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Fuchs", "Fabian", ""], ["Prutkin", "Roman", ""]]}, {"id": "1502.02427", "submitter": "Gianluca De Marco", "authors": "Gianluca De Marco, Mauro Leoncini, Manuela Montangero", "title": "A Distributed Message-Optimal Assignment on Rings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set of items and a set of $m$ colors, where each item is\nassociated to one color. Consider also $n$ computational agents connected by a\nring. Each agent holds a subset of the items and items of the same color can be\nheld by different agents. We analyze the problem of distributively assigning\ncolors to agents in such a way that (a) each color is assigned to one agent\nonly and (b) the number of different colors assigned to each agent is minimum.\nSince any color assignment requires the items be distributed according to it\n(e.g. all items of the same color are to be held by only one agent), we define\nthe cost of a color assignment as the amount of items that need to be moved,\ngiven an initial allocation. We first show that any distributed algorithm for\nthis problem requires a message complexity of $\\Omega(n\\cdot m)$ and then we\nexhibit an optimal message complexity algorithm for synchronous rings that in\npolynomial time determines a color assignment with cost at most three times the\noptimal. We also discuss solutions for the asynchronous setting. Finally, we\nshow how to get a better cost solution at the expenses of either the message or\nthe time complexity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 10:43:37 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 11:12:05 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["De Marco", "Gianluca", ""], ["Leoncini", "Mauro", ""], ["Montangero", "Manuela", ""]]}, {"id": "1502.02472", "submitter": "Srimanta Bhattacharya", "authors": "Srimanta Bhattacharya", "title": "Derandomized Construction of Combinatorial Batch Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial Batch Codes (CBCs), replication-based variant of Batch Codes\nintroduced by Ishai et al. in STOC 2004, abstracts the following data\ndistribution problem: $n$ data items are to be replicated among $m$ servers in\nsuch a way that any $k$ of the $n$ data items can be retrieved by reading at\nmost one item from each server with the total amount of storage over $m$\nservers restricted to $N$. Given parameters $m, c,$ and $k$, where $c$ and $k$\nare constants, one of the challenging problems is to construct $c$-uniform CBCs\n(CBCs where each data item is replicated among exactly $c$ servers) which\nmaximizes the value of $n$. In this work, we present explicit construction of\n$c$-uniform CBCs with $\\Omega(m^{c-1+{1 \\over k}})$ data items. The\nconstruction has the property that the servers are almost regular, i.e., number\nof data items stored in each server is in the range $[{nc \\over\nm}-\\sqrt{{n\\over 2}\\ln (4m)}, {nc \\over m}+\\sqrt{{n \\over 2}\\ln (4m)}]$. The\nconstruction is obtained through better analysis and derandomization of the\nrandomized construction presented by Ishai et al. Analysis reveals almost\nregularity of the servers, an aspect that so far has not been addressed in the\nliterature. The derandomization leads to explicit construction for a wide range\nof values of $c$ (for given $m$ and $k$) where no other explicit construction\nwith similar parameters, i.e., with $n = \\Omega(m^{c-1+{1 \\over k}})$, is\nknown. Finally, we discuss possibility of parallel derandomization of the\nconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 13:09:59 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Bhattacharya", "Srimanta", ""]]}, {"id": "1502.02481", "submitter": "Shahbaz Khan", "authors": "Surender Baswana, Shreejit Ray Chaudhury, Keerti Choudhary and Shahbaz\n  Khan", "title": "Dynamic DFS Tree in Undirected Graphs: breaking the $O(m)$ barrier", "comments": "27 pages, SODA 2016", "journal-ref": null, "doi": "10.1137/1.9781611974331.ch52", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth first search (DFS) tree is a fundamental data structure for solving\nvarious problems in graphs. It is well known that it takes $O(m+n)$ time to\nbuild a DFS tree for a given undirected graph $G=(V,E)$ on $n$ vertices and $m$\nedges. We address the problem of maintaining a DFS tree when the graph is\nundergoing {\\em updates} (insertion and deletion of vertices or edges). We\npresent the following results for this problem.\n  (a) Fault tolerant DFS tree: There exists a data structure of size ${O}(m\n~polylog~ n)$ such that given any set ${\\cal F}$ of failed vertices or edges, a\nDFS tree of the graph $G\\setminus {\\cal F}$ can be reported in ${O}(n|{\\cal F}|\n~polylog~ n)$ time.\n  (b) Fully dynamic DFS tree: There exists a fully dynamic algorithm for\nmaintaining a DFS tree that takes worst case ${O}(\\sqrt{mn} ~polylog~ n)$ time\nper update for any arbitrary online sequence of updates.\n  (c) Incremental DFS tree: Given any arbitrary online sequence of edge\ninsertions, we can maintain a DFS tree in ${O}(n ~polylog~ n)$ worst case time\nper edge insertion.\n  These are the first $o(m)$ worst case time results for maintaining a DFS tree\nin a dynamic environment. Moreover, our fully dynamic algorithm provides, in a\nseamless manner, the first deterministic algorithm with $O(1)$ query time and\n$o(m)$ worst case update time for the dynamic subgraph connectivity,\nbiconnectivity, and 2-edge connectivity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 13:36:20 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 10:11:02 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2015 17:34:08 GMT"}, {"version": "v4", "created": "Wed, 7 Feb 2018 15:42:54 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Baswana", "Surender", ""], ["Chaudhury", "Shreejit Ray", ""], ["Choudhary", "Keerti", ""], ["Khan", "Shahbaz", ""]]}, {"id": "1502.02557", "submitter": "Martin Derka", "authors": "Martin Derka, Alejandro L\\'opez-Ortiz, Daniela Maftuleac", "title": "List Colouring Big Graphs On-Line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of graph list colouring in the\non-line setting. We provide several results on paintability of graphs in the\nmodel introduced by Schauz [13] and Zhu [20]. We prove that the on-line version\nof Ohba's conjecture is true in the class of planar graphs. We also consider\nseveral alternate on-line list colouring models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 16:49:15 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Derka", "Martin", ""], ["L\u00f3pez-Ortiz", "Alejandro", ""], ["Maftuleac", "Daniela", ""]]}, {"id": "1502.02800", "submitter": "Svyatoslav Covanov", "authors": "Svyatoslav Covanov (CARAMBA), Emmanuel Thom\\'e (CARAMBA)", "title": "Fast integer multiplication using generalized Fermat primes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For almost 35 years, Sch{\\\"o}nhage-Strassen's algorithm has been the fastest\nalgorithm known for multiplying integers, with a time complexity O(n $\\times$\nlog n $\\times$ log log n) for multiplying n-bit inputs. In 2007, F{\\\"u}rer\nproved that there exists K > 1 and an algorithm performing this operation in\nO(n $\\times$ log n $\\times$ K log n). Recent work by Harvey, van der Hoeven,\nand Lecerf showed that this complexity estimate can be improved in order to get\nK = 8, and conjecturally K = 4. Using an alternative algorithm, which relies on\narithmetic modulo generalized Fermat primes, we obtain conjecturally the same\nresult K = 4 via a careful complexity analysis in the deterministic multitape\nTuring model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 07:15:16 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 15:12:17 GMT"}, {"version": "v3", "created": "Tue, 29 Aug 2017 08:59:14 GMT"}, {"version": "v4", "created": "Tue, 17 Apr 2018 11:13:59 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Covanov", "Svyatoslav", "", "CARAMBA"], ["Thom\u00e9", "Emmanuel", "", "CARAMBA"]]}, {"id": "1502.02899", "submitter": "Filipe Brand\\~ao M.Sc", "authors": "Filipe Brand\\~ao, Jo\\~ao Pedro Pedroso", "title": "Cutting Stock with Binary Patterns: Arc-flow Formulation with Graph\n  Compression", "comments": "arXiv admin note: text overlap with arXiv:1310.6887", "journal-ref": null, "doi": null, "report-no": "DCC-2013-09", "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cutting stock problem with binary patterns (0-1 CSP) is a variant of CSP\nthat usually appears as a relaxation of 2D and 3D packing problems. We present\nan exact method, based on an arc-flow formulation with side constraints, for\nsolving 0-1 CSP by simply representing all the patterns in a very compact\ngraph.\n  Gilmore-Gomory's column generation approach is usually used to compute strong\nlower bounds for 0-1 CSP. We report a computational comparison between the\narc-flow approach and the Gilmore-Gomory's approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 13:30:23 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Brand\u00e3o", "Filipe", ""], ["Pedroso", "Jo\u00e3o Pedro", ""]]}, {"id": "1502.03032", "submitter": "Jiyan Yang", "authors": "Jiyan Yang, Xiangrui Meng, Michael W. Mahoney", "title": "Implementing Randomized Matrix Algorithms in Parallel and Distributed\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of large-scale data, distributed systems built on top of clusters\nof commodity hardware provide cheap and reliable storage and scalable\nprocessing of massive data. Here, we review recent work on developing and\nimplementing randomized matrix algorithms in large-scale parallel and\ndistributed environments. Randomized algorithms for matrix problems have\nreceived a great deal of attention in recent years, thus far typically either\nin theory or in machine learning applications or with implementations on a\nsingle machine. Our main focus is on the underlying theory and practical\nimplementation of random projection and random sampling algorithms for very\nlarge very overdetermined (i.e., overconstrained) $\\ell_1$ and $\\ell_2$\nregression problems. Randomization can be used in one of two related ways:\neither to construct sub-sampled problems that can be solved, exactly or\napproximately, with traditional numerical methods; or to construct\npreconditioned versions of the original full problem that are easier to solve\nwith traditional iterative algorithms. Theoretical results demonstrate that in\nnear input-sparsity time and with only a few passes through the data one can\nobtain very strong relative-error approximate solutions, with high probability.\nEmpirical results highlight the importance of various trade-offs (e.g., between\nthe time to construct an embedding and the conditioning quality of the\nembedding, between the relative importance of computation versus communication,\netc.) and demonstrate that $\\ell_1$ and $\\ell_2$ regression problems can be\nsolved to low, medium, or high precision in existing distributed systems on up\nto terabyte-sized data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 18:38:44 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 07:15:33 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Yang", "Jiyan", ""], ["Meng", "Xiangrui", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1502.03201", "submitter": "Yann Ponty", "authors": "Jozef Hale\\v{s}, J\\'an Ma\\v{n}uch (UBC-Computer Science), Yann Ponty\n  (LIX, AMIB), Ladislav Stacho", "title": "Combinatorial RNA Design: Designability and Structure-Approximating\n  Algorithm", "comments": "CPM - 26th Annual Symposium on Combinatorial Pattern Matching, Jun\n  2015, Ischia Island, Italy. LNCS, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the Combinatorial RNA Design problem, a minimal\ninstance of the RNA design problem which aims at finding a sequence that admits\na given target as its unique base pair maximizing structure. We provide\ncomplete characterizations for the structures that can be designed using\nrestricted alphabets. Under a classic four-letter alphabet, we provide a\ncomplete characterization of designable structures without unpaired bases. When\nunpaired bases are allowed, we provide partial characterizations for classes of\ndesignable/undesignable structures, and show that the class of designable\nstructures is closed under the stutter operation. Membership of a given\nstructure to any of the classes can be tested in linear time and, for positive\ninstances, a solution can be found in linear time. Finally, we consider a\nstructure-approximating version of the problem that allows to extend bands\n(helices) and, assuming that the input structure avoids two motifs, we provide\na linear-time algorithm that produces a designable structure with at most twice\nmore base pairs than the input structure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 06:47:23 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 08:34:03 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Hale\u0161", "Jozef", "", "UBC-Computer Science"], ["Ma\u0148uch", "J\u00e1n", "", "UBC-Computer Science"], ["Ponty", "Yann", "", "LIX, AMIB"], ["Stacho", "Ladislav", ""]]}, {"id": "1502.03288", "submitter": "Nicola Prezza", "authors": "Nicola Prezza", "title": "A Compressed-Gap Data-Aware Measure", "comments": "11 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of efficiently representing a set $S$\nof $n$ items out of a universe $U=\\{0,...,u-1\\}$ while supporting a number of\noperations on it. Let $G=g_1...g_n$ be the gap stream associated with $S$,\n$gap$ its bit-size when encoded with \\emph{gap-encoding}, and $H_0(G)$ its\nempirical zero-order entropy. We prove that (1) $nH_0(G)\\in o(gap)$ if $G$ is\nhighly compressible, and (2) $nH_0(G) \\leq n\\log(u/n) + n \\leq uH_0(S)$. Let\n$d$ be the number of \\emph{distinct} gap lengths between elements in $S$. We\nfirstly propose a new space-efficient zero-order compressed representation of\n$S$ taking $n(H_0(G)+1)+\\mathcal O(d\\log u)$ bits of space. Then, we describe a\nfully-indexable dictionary that supports \\emph{rank} and \\emph{select} queries\nin $\\mathcal O(\\log(u/n)+\\log\\log u)$ time while requiring asymptotically the\nsame space as the proposed compressed representation of $S$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 12:53:53 GMT"}, {"version": "v2", "created": "Thu, 14 May 2015 12:56:29 GMT"}], "update_date": "2015-05-15", "authors_parsed": [["Prezza", "Nicola", ""]]}, {"id": "1502.03316", "submitter": "Ali Sinop", "authors": "Pranjal Awasthi, Moses Charikar, Ravishankar Krishnaswamy, Ali Kemal\n  Sinop", "title": "The Hardness of Approximation of Euclidean k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-means problem is a classical problem that has been\nextensively studied in the theoretical computer science, machine learning and\nthe computational geometry communities. In this problem, we are given a set of\n$n$ points in Euclidean space $R^d$, and the goal is to choose $k$ centers in\n$R^d$ so that the sum of squared distances of each point to its nearest center\nis minimized. The best approximation algorithms for this problem include a\npolynomial time constant factor approximation for general $k$ and a\n$(1+\\epsilon)$-approximation which runs in time $poly(n) 2^{O(k/\\epsilon)}$. At\nthe other extreme, the only known computational complexity result for this\nproblem is NP-hardness [ADHP'09]. The main difficulty in obtaining hardness\nresults stems from the Euclidean nature of the problem, and the fact that any\npoint in $R^d$ can be a potential center. This gap in understanding left open\nthe intriguing possibility that the problem might admit a PTAS for all $k,d$.\n  In this paper we provide the first hardness of approximation for the\nEuclidean $k$-means problem. Concretely, we show that there exists a constant\n$\\epsilon > 0$ such that it is NP-hard to approximate the $k$-means objective\nto within a factor of $(1+\\epsilon)$. We show this via an efficient reduction\nfrom the vertex cover problem on triangle-free graphs: given a triangle-free\ngraph, the goal is to choose the fewest number of vertices which are incident\non all the edges. Additionally, we give a proof that the current best hardness\nresults for vertex cover can be carried over to triangle-free graphs. To show\nthis we transform $G$, a known hard vertex cover instance, by taking a graph\nproduct with a suitably chosen graph $H$, and showing that the size of the\n(normalized) maximum independent set is almost exactly preserved in the product\ngraph using a spectral analysis, which might be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 14:38:45 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Charikar", "Moses", ""], ["Krishnaswamy", "Ravishankar", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1502.03320", "submitter": "Shay Kutten", "authors": "Valerie King, Shay Kutten, Mikkel Thorup", "title": "Construction and impromptu repair of an MST in a distributed network\n  with o(m) communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the CONGEST model, a communications network is an undirected graph whose\n$n$ nodes are processors and whose $m$ edges are the communications links\nbetween processors. At any given time step, a message of size $O(\\log n)$ may\nbe sent by each node to each of its neighbors. We show for the synchronous\nmodel: If all nodes start in the same round, and each node knows its ID and the\nID's of its neighbors, or in the case of MST, the distinct weights of its\nincident edges and knows $n$, then there are Monte Carlo algorithms which\nsucceed w.h.p. to determine a minimum spanning forest (MST) and a spanning\nforest (ST) using $O(n \\log^2 n/\\log\\log n)$ messages for MST and $O(n \\log n\n)$ messages for ST, resp. These results contradict the \"folk theorem\" noted in\nAwerbuch, et.al., JACM 1990 that the distributed construction of a broadcast\ntree requires $\\Omega(m)$ messages. This lower bound has been shown there and\nin other papers for some CONGEST models; our protocol demonstrates the limits\nof these models.\n  A dynamic distributed network is one which undergoes online edge insertions\nor deletions. We also show how to repair an MST or ST in a dynamic network with\nasynchronous communication. An edge deletion can be processed in $O(n\\log n\n/\\log \\log n)$ expected messages in the MST, and $O(n)$ expected messages for\nthe ST problem, while an edge insertion uses $O(n)$ messages in the worst case.\nWe call this \"impromptu\" updating as we assume that between processing of edge\nupdates there is no preprocessing or storage of additional information.\nPrevious algorithms for this problem that use an amortized $o(m)$ messages per\nupdate require substantial preprocessing and additional local storage between\nupdates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 14:43:28 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["King", "Valerie", ""], ["Kutten", "Shay", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1502.03372", "submitter": "Jelena Marasevic", "authors": "Jelena Marasevic, Cliff Stein, and Gil Zussman", "title": "A Fast Distributed Stateless Algorithm for $\\alpha$-Fair Packing\n  Problems", "comments": "Added structural results for asymptotic cases of \\alpha-fairness\n  (\\alpha approaching 0, 1, or infinity), improved presentation, and revised\n  throughout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, fair resource allocation problems have received\nconsiderable attention in a variety of application areas. However, little\nprogress has been made in the design of distributed algorithms with convergence\nguarantees for general and commonly used $\\alpha$-fair allocations. In this\npaper, we study weighted $\\alpha$-fair packing problems, that is, the problems\nof maximizing the objective functions (i) $\\sum_j w_j\nx_j^{1-\\alpha}/(1-\\alpha)$ when $\\alpha > 0$, $\\alpha \\neq 1$ and (ii) $\\sum_j\nw_j \\ln x_j$ when $\\alpha = 1$, over linear constraints $Ax \\leq b$, $x\\geq 0$,\nwhere $w_j$ are positive weights and $A$ and $b$ are non-negative. We consider\nthe distributed computation model that was used for packing linear programs and\nnetwork utility maximization problems. Under this model, we provide a\ndistributed algorithm for general $\\alpha$ that converges to an\n$\\varepsilon-$approximate solution in time (number of distributed iterations)\nthat has an inverse polynomial dependence on the approximation parameter\n$\\varepsilon$ and poly-logarithmic dependence on the problem size. This is the\nfirst distributed algorithm for weighted $\\alpha-$fair packing with\npoly-logarithmic convergence in the input size. The algorithm uses simple local\nupdate rules and is stateless (namely, it allows asynchronous updates, is\nself-stabilizing, and allows incremental and local adjustments). We also obtain\na number of structural results that characterize $\\alpha-$fair allocations as\nthe value of $\\alpha$ is varied. These results deepen our understanding of\nfairness guarantees in $\\alpha-$fair packing allocations, and also provide\ninsight into the behavior of $\\alpha-$fair allocations in the asymptotic cases\n$\\alpha\\rightarrow 0$, $\\alpha \\rightarrow 1$, and $\\alpha \\rightarrow \\infty$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 16:58:16 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2015 16:49:27 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2016 00:02:04 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Marasevic", "Jelena", ""], ["Stein", "Cliff", ""], ["Zussman", "Gil", ""]]}, {"id": "1502.03379", "submitter": "Anthony Labarre", "authors": "Philippe Gambette and Andreas D. M. Gunawan and Anthony Labarre and\n  St\\'ephane Vialette and Louxin Zhang", "title": "Locating a Tree in a Phylogenetic Network in Quadratic Time", "comments": "Accepted to RECOMB 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in the study of phylogenetic networks is to determine\nwhether or not a given phylogenetic network contains a given phylogenetic tree.\nWe develop a quadratic-time algorithm for this problem for binary nearly-stable\nphylogenetic networks. We also show that the number of reticulations in a\nreticulation visible or nearly stable phylogenetic network is bounded from\nabove by a function linear in the number of taxa.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 17:07:06 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Gambette", "Philippe", ""], ["Gunawan", "Andreas D. M.", ""], ["Labarre", "Anthony", ""], ["Vialette", "St\u00e9phane", ""], ["Zhang", "Louxin", ""]]}, {"id": "1502.03496", "submitter": "Yu Cheng", "authors": "Dehua Cheng, Yu Cheng, Yan Liu, Richard Peng, Shang-Hua Teng", "title": "Spectral Sparsification of Random-Walk Matrix Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fundamental algorithmic question in spectral graph theory:\nCompute a spectral sparsifier of random-walk matrix-polynomial\n$$L_\\alpha(G)=D-\\sum_{r=1}^d\\alpha_rD(D^{-1}A)^r$$ where $A$ is the adjacency\nmatrix of a weighted, undirected graph, $D$ is the diagonal matrix of weighted\ndegrees, and $\\alpha=(\\alpha_1...\\alpha_d)$ are nonnegative coefficients with\n$\\sum_{r=1}^d\\alpha_r=1$. Recall that $D^{-1}A$ is the transition matrix of\nrandom walks on the graph. The sparsification of $L_\\alpha(G)$ appears to be\nalgorithmically challenging as the matrix power $(D^{-1}A)^r$ is defined by all\npaths of length $r$, whose precise calculation would be prohibitively\nexpensive.\n  In this paper, we develop the first nearly linear time algorithm for this\nsparsification problem: For any $G$ with $n$ vertices and $m$ edges, $d$\ncoefficients $\\alpha$, and $\\epsilon > 0$, our algorithm runs in time\n$O(d^2m\\log^2n/\\epsilon^{2})$ to construct a Laplacian matrix\n$\\tilde{L}=D-\\tilde{A}$ with $O(n\\log n/\\epsilon^{2})$ non-zeros such that\n$\\tilde{L}\\approx_{\\epsilon}L_\\alpha(G)$.\n  Matrix polynomials arise in mathematical analysis of matrix functions as well\nas numerical solutions of matrix equations. Our work is particularly motivated\nby the algorithmic problems for speeding up the classic Newton's method in\napplications such as computing the inverse square-root of the precision matrix\nof a Gaussian random field, as well as computing the $q$th-root transition (for\n$q\\geq1$) in a time-reversible Markov model. The key algorithmic step for both\napplications is the construction of a spectral sparsifier of a constant degree\nrandom-walk matrix-polynomials introduced by Newton's method. Our algorithm can\nalso be used to build efficient data structures for effective resistances for\nmulti-step time-reversible Markov models, and we anticipate that it could be\nuseful for other tasks in network analysis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 00:25:32 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Cheng", "Dehua", ""], ["Cheng", "Yu", ""], ["Liu", "Yan", ""], ["Peng", "Richard", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "1502.03690", "submitter": "Michael Kerber", "authors": "Sergio Cabello and Michael Kerber", "title": "Semi-dynamic connectivity in the plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a path planning problem we consider the following procedure.\nAssume that we have two points $s$ and $t$ in the plane and take\n$\\mathcal{K}=\\emptyset$. At each step we add to $\\mathcal{K}$ a compact convex\nset that does not contain $s$ nor $t$. The procedure terminates when the sets\nin $\\mathcal{K}$ separate $s$ and $t$. We show how to add one set to\n$\\mathcal{K}$ in $O(1+k\\alpha(n))$ amortized time plus the time needed to find\nall sets of $\\mathcal{K}$ intersecting the newly added set, where $n$ is the\ncardinality of $\\mathcal{K}$, $k$ is the number of sets in $\\mathcal{K}$\nintersecting the newly added set, and $\\alpha(\\cdot)$ is the inverse of the\nAckermann function.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 15:03:56 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Cabello", "Sergio", ""], ["Kerber", "Michael", ""]]}, {"id": "1502.03715", "submitter": "Jens Vygen", "authors": "Jens Vygen", "title": "Reassembling trees for the traveling salesman", "comments": "minor revision, final version, to appear in SIAM Journal of Discrete\n  Mathematics, please use color printer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent approximation algorithms for different variants of the traveling\nsalesman problem (asymmetric TSP, graph TSP, s-t-path TSP) exploit the\nwell-known fact that a solution of the natural linear programming relaxation\ncan be written as convex combination of spanning trees. The main argument then\nis that randomly sampling a tree from such a distribution and then completing\nthe tree to a tour at minimum cost yields a better approximation guarantee than\nsimply taking a minimum cost spanning tree (as in Christofides' algorithm). We\nargue that an additional step can help: reassembling the spanning trees before\nsampling. Exchanging two edges in a pair of spanning trees can improve their\nproperties under certain conditions. We demonstrate the usefulness for the\nmetric s-t-path TSP by devising a deterministic polynomial-time algorithm that\nimproves on Seb\\H{o}'s previously best approximation ratio of 8/5.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 16:14:47 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 17:36:45 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Vygen", "Jens", ""]]}, {"id": "1502.03845", "submitter": "Alessandro Provetti", "authors": "Biagio Bonasera, Emilio Ferrara, Giacomo Fiumara, Francesco Pagano,\n  Alessandro Provetti", "title": "Adaptive Search over Sorted Sets", "comments": "9 pages", "journal-ref": "Journal of Discrete Algorithms, Volume 30, 2015, pp. 128--133", "doi": "10.1016/j.jda.2014.12.007", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classical algorithms for searching over sorted sets to\nintroduce an algorithm refinement, called Adaptive Search, that combines the\ngood features of Interpolation search and those of Binary search. W.r.t.\nInterpolation search, only a constant number of extra comparisons is\nintroduced. Yet, under diverse input data distributions our algorithm shows\ncosts comparable to that of Interpolation search, i.e., O(log log n) while the\nworst-case cost is always in O(log n), as with Binary search. On benchmarks\ndrawn from large datasets, both synthetic and real-life, Adaptive search scores\nbetter times and lesser memory accesses even than Santoro and Sidney's\nInterpolation-Binary search.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 22:12:54 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Bonasera", "Biagio", ""], ["Ferrara", "Emilio", ""], ["Fiumara", "Giacomo", ""], ["Pagano", "Francesco", ""], ["Provetti", "Alessandro", ""]]}, {"id": "1502.03942", "submitter": "Lorenz H\\\"ubschle-Schneider", "authors": "Lorenz H\\\"ubschle-Schneider and Peter Sanders and Ingo M\\\"uller", "title": "Communication Efficient Algorithms for Top-k Selection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present scalable parallel algorithms with sublinear per-processor\ncommunication volume and low latency for several fundamental problems related\nto finding the most relevant elements in a set, for various notions of\nrelevance: We begin with the classical selection problem with unsorted input.\nWe present generalizations with locally sorted inputs, dynamic content\n(bulk-parallel priority queues), and multiple criteria. Then we move on to\nfinding frequent objects and top-k sum aggregation. Since it is unavoidable\nthat the output of these algorithms might be unevenly distributed over the\nprocessors, we also explain how to redistribute this data with minimal\ncommunication.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 11:01:29 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 15:28:27 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["H\u00fcbschle-Schneider", "Lorenz", ""], ["Sanders", "Peter", ""], ["M\u00fcller", "Ingo", ""]]}, {"id": "1502.03946", "submitter": "Giorgio Lucarelli", "authors": "Spyros Angelopoulos, Giorgio Lucarelli and Nguyen Kim Thang", "title": "Primal-dual and dual-fitting analysis of online scheduling algorithms\n  for generalized flow-time problems", "comments": "30 pages", "journal-ref": "Algorithmica 81, 3391-3421 (2019)", "doi": "10.1007/s00453-019-00583-8", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online scheduling problems on a single processor that can be viewed\nas extensions of the well-studied problem of minimizing total weighted flow\ntime. In particular, we provide a framework of analysis that is derived by\nduality properties, does not rely on potential functions and is applicable to a\nvariety of scheduling problems. A key ingredient in our approach is bypassing\nthe need for \"black-box\" rounding of fractional solutions, which yields\nimproved competitive ratios.\n  We begin with an interpretation of Highest-Density-First (HDF) as a\nprimal-dual algorithm, and a corresponding proof that HDF is optimal for total\nfractional weighted flow time (and thus scalable for the integral objective).\nBuilding upon the salient ideas of the proof, we show how to apply and extend\nthis analysis to the more general problem of minimizing $\\sum_j w_j g(F_j)$,\nwhere $w_j$ is the job weight, $F_j$ is the flow time and $g$ is a\nnon-decreasing cost function. Among other results, we present improved\ncompetitive ratios for the setting in which $g$ is a concave function, and the\nsetting of same-density jobs but general cost functions. We further apply our\nframework of analysis to online weighted completion time with general cost\nfunctions as well as scheduling under polyhedral constraints.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 11:31:19 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 06:32:40 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 07:14:45 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Angelopoulos", "Spyros", ""], ["Lucarelli", "Giorgio", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "1502.03965", "submitter": "Bart M. P. Jansen", "authors": "Archontia C. Giannopoulou and Bart M. P. Jansen and Daniel Lokshtanov\n  and Saket Saurabh", "title": "Uniform Kernelization Complexity of Hitting Forbidden Minors", "comments": "34 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-Minor-Free Deletion problem asks, for a fixed set F and an input\nconsisting of a graph G and integer k, whether k vertices can be removed from G\nsuch that the resulting graph does not contain any member of F as a minor. This\npaper analyzes to what extent provably effective and efficient preprocessing is\npossible for F-Minor-Free Deletion. Fomin et al. (FOCS 2012) showed that the\nspecial case Planar F-Deletion (when F contains at least one planar graph) has\na kernel of size f(F) * k^{g(F)} for some functions f and g. The degree g of\nthe polynomial grows very quickly; it is not even known to be computable. Fomin\net al. left open whether Planar F-Deletion has kernels whose size is uniformly\npolynomial, i.e., of the form f(F) * k^c for some universal constant c that\ndoes not depend on F. Our results in this paper are twofold. (1) We prove that\nsome Planar F-Deletion problems do not have uniformly polynomial kernels\n(unless NP is in coNP/poly). In particular, we prove that Treewidth-Eta\nDeletion does not have a kernel with O(k^{eta/4} - eps) vertices for any eps >\n0, unless NP is in coNP/poly. In fact, we even prove the kernelization lower\nbound for the larger parameter vertex cover number. This resolves an open\nproblem of Cygan et al. (IPEC 2011). It is a natural question whether further\nrestrictions on F lead to uniformly polynomial kernels. However, we prove that\neven when F contains a path, the degree of the polynomial must, in general,\ndepend on the set F. (2) A canonical F-Minor-Free Deletion problem when F\ncontains a path is Treedepth-eta Deletion: can k vertices be removed to obtain\na graph of treedepth at most eta? We prove that Treedepth-eta Deletion admits\nuniformly polynomial kernels with O(k^6) vertices for every fixed eta. In order\nto develop the kernelization we prove several new results about the structure\nof optimal treedepth-decompositions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 12:48:31 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Jansen", "Bart M. P.", ""], ["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""]]}, {"id": "1502.03971", "submitter": "Noy Rotbart", "authors": "Casper Petersen, Noy Rotbart, Jakob Grue Simonsen and Christian\n  Wulff-Nilsen", "title": "Near-optimal adjacency labeling scheme for power-law graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adjacency labeling scheme is a method that assigns labels to the vertices\nof a graph such that adjacency between vertices can be inferred directly from\nthe assigned label, without using a centralized data structure. We devise\nadjacency labeling schemes for the family of power-law graphs. This family that\nhas been used to model many types of networks, e.g. the Internet AS-level\ngraph. Furthermore, we prove an almost matching lower bound for this family. We\nalso provide an asymptotically near- optimal labeling scheme for sparse graphs.\nFinally, we validate the efficiency of our labeling scheme by an experimental\nevaluation using both synthetic data and real-world networks of up to hundreds\nof thousands of vertices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 13:02:08 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Petersen", "Casper", ""], ["Rotbart", "Noy", ""], ["Simonsen", "Jakob Grue", ""], ["Wulff-Nilsen", "Christian", ""]]}, {"id": "1502.03985", "submitter": "Elmar Langetepe", "authors": "Rolf Klein, David Kriesel, Elmar Langetepe", "title": "A local strategy for cleaning expanding cellular domains by simple\n  robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a strategy SEP for finite state machines tasked with cleaning a\ncellular environment in which a contamination spreads. Initially, the\ncontaminated area is of height $h$ and width $w$. It may be bounded by four\nmonotonic chains, and contain rectangular holes. The robot does not know the\ninitial contamination, sensing only the eight cells in its neighborhood. It\nmoves from cell to cell, $d$ times faster than the contamination spreads, and\nis able to clean its current cell. A speed of $d<\\sqrt{2}(h+w)$ is in general\nnot sufficient to contain the contamination. Our strategy SEP succeeds if $d\n\\geq 3(h+w)$ holds. It ensures that the contaminated cells stay connected.\nGreedy strategies violating this principle need speed at least $d \\geq 4(h+w)$;\nall bounds are up to small additive constants.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 13:45:35 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Klein", "Rolf", ""], ["Kriesel", "David", ""], ["Langetepe", "Elmar", ""]]}, {"id": "1502.03989", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin, Petr A. Golovach, Nikolay Karpov, and Alexander S.\n  Kulikov", "title": "Parameterized Complexity of Secluded Connectivity Problems", "comments": "Minor corrections are done", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Secluded Path problem models a situation where a sensitive information\nhas to be transmitted between a pair of nodes along a path in a network. The\nmeasure of the quality of a selected path is its exposure, which is the total\nweight of vertices in its closed neighborhood. In order to minimize the risk of\nintercepting the information, we are interested in selecting a secluded path,\ni.e. a path with a small exposure. Similarly, the Secluded Steiner Tree problem\nis to find a tree in a graph connecting a given set of terminals such that the\nexposure of the tree is minimized. The problems were introduced by Chechik et\nal. in [ESA 2013]. Among other results, Chechik et al. have shown that Secluded\nPath is fixed-parameter tractable (FPT) on unweighted graphs being\nparameterized by the maximum vertex degree of the graph and that Secluded\nSteiner Tree is FPT parameterized by the treewidth of the graph. In this work,\nwe obtain the following results about parameterized complexity of secluded\nconnectivity problems.\n  We give FPT-algorithms deciding if a graph G with a given cost function\ncontains a secluded path and a secluded Steiner tree of exposure at most k with\nthe cost at most C.\n  We initiate the study of \"above guarantee\" parameterizations for secluded\nproblems, where the lower bound is given by the size of a Steiner tree.\n  We investigate Secluded Steiner Tree from kernelization perspective and\nprovide several lower and upper bounds when parameters are the treewidth, the\nsize of a vertex cover, maximum vertex degree and the solution size. Finally,\nwe refine the algorithmic result of Chechik et al. by improving the exponential\ndependence from the treewidth of the input graph.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 13:53:48 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 11:49:11 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Karpov", "Nikolay", ""], ["Kulikov", "Alexander S.", ""]]}, {"id": "1502.04022", "submitter": "Reut Levi", "authors": "Reut Levi, Ronitt Rubinfeld, Anak Yodpinyanee", "title": "Local Computation Algorithms for Graphs of Non-Constant Degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the model of \\emph{local computation algorithms} (LCAs), we aim to compute\nthe queried part of the output by examining only a small (sublinear) portion of\nthe input. Many recently developed LCAs on graph problems achieve time and\nspace complexities with very low dependence on $n$, the number of vertices.\nNonetheless, these complexities are generally at least exponential in $d$, the\nupper bound on the degree of the input graph. Instead, we consider the case\nwhere parameter $d$ can be moderately dependent on $n$, and aim for\ncomplexities with subexponential dependence on $d$, while maintaining\npolylogarithmic dependence on $n$. We present: a randomized LCA for computing\nmaximal independent sets whose time and space complexities are quasi-polynomial\nin $d$ and polylogarithmic in $n$; for constant $\\epsilon > 0$, a randomized\nLCA that provides a $(1-\\epsilon)$-approximation to maximum matching whose time\nand space complexities are polynomial in $d$ and polylogarithmic in $n$.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 15:15:20 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Levi", "Reut", ""], ["Rubinfeld", "Ronitt", ""], ["Yodpinyanee", "Anak", ""]]}, {"id": "1502.04048", "submitter": "Sebastian Wild", "authors": "Raphael Reitzig and Sebastian Wild", "title": "Efficient Algorithms for Envy-Free Stick Division With Fewest Cuts", "comments": "v3 adds more context about the problem", "journal-ref": "Reitzig, R. & Wild, S. Algorithmica (2017).\n  https://doi.org/10.1007/s00453-017-0392-3", "doi": "10.1007/s00453-017-0392-3", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of n sticks of various (not necessarily different) lengths, what\nis the largest length so that we can cut k equally long pieces of this length\nfrom the given set of sticks? We analyze the structure of this problem and show\nthat it essentially reduces to a single call of a selection algorithm; we thus\nobtain an optimal linear-time algorithm.\n  This algorithm also solves the related envy-free stick-division problem,\nwhich Segal-Halevi, Hassidim, and Aumann (AAMAS, 2015) recently used as their\ncentral primitive operation for the first discrete and bounded envy-free cake\ncutting protocol with a proportionality guarantee when pieces can be put to\nwaste.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 16:22:18 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2015 13:33:57 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 17:22:24 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Reitzig", "Raphael", ""], ["Wild", "Sebastian", ""]]}, {"id": "1502.04220", "submitter": "Can Lu", "authors": "Can Lu, Jeffrey Xu Yu, Rong-Hua Li, Hao Wei", "title": "Exploring Hierarchies in Online Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social hierarchy (i.e., pyramid structure of societies) is a fundamental\nconcept in sociology and social network analysis. The importance of social\nhierarchy in a social network is that the topological structure of the social\nhierarchy is essential in both shaping the nature of social interactions\nbetween individuals and unfolding the structure of the social networks. The\nsocial hierarchy found in a social network can be utilized to improve the\naccuracy of link prediction, provide better query results, rank web pages, and\nstudy information flow and spread in complex networks. In this paper, we model\na social network as a directed graph G, and consider the social hierarchy as\nDAG (directed acyclic graph) of G, denoted as GD. By DAG, all the vertices in G\ncan be partitioned into different levels, the vertices at the same level\nrepresent a disjoint group in the social hierarchy, and all the edges in DAG\nfollow one direction. The main issue we study in this paper is how to find DAG\nGD in G. The approach we take is to find GD by removing all possible cycles\nfrom G such that G = U(G) + GD where U(G) is a maximum Eulerian subgraph which\ncontains all possible cycles. We give the reasons for doing so, investigate the\nproperties of GD found, and discuss the applications. In addition, we develop a\nnovel two-phase algorithm, called Greedy-&-Refine, which greedily computes an\nEulerian subgraph and then refines this greedy solution to find the maximum\nEulerian subgraph. We give a bound between the greedy solution and the optimal.\nThe quality of our greedy approach is high. We conduct comprehensive\nexperimental studies over 14 real-world datasets. The results show that our\nalgorithms are at least two orders of magnitude faster than the baseline\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 16:02:00 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Lu", "Can", ""], ["Yu", "Jeffrey Xu", ""], ["Li", "Rong-Hua", ""], ["Wei", "Hao", ""]]}, {"id": "1502.04265", "submitter": "Jan-Philipp Kappmeier", "authors": "Jan-Philipp W. Kappmeier and Daniel R. Schmidt and Melanie Schmidt", "title": "Solving $k$-means on High-dimensional Big Data", "comments": "23 pages, 9 figures, published at the 14th International Symposium on\n  Experimental Algorithms - SEA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been major efforts to develop data stream\nalgorithms that process inputs in one pass over the data with little memory\nrequirement. For the $k$-means problem, this has led to the development of\nseveral $(1+\\varepsilon)$-approximations (under the assumption that $k$ is a\nconstant), but also to the design of algorithms that are extremely fast in\npractice and compute solutions of high accuracy. However, when not only the\nlength of the stream is high but also the dimensionality of the input points,\nthen current methods reach their limits.\n  We propose two algorithms, piecy and piecy-mr that are based on the recently\ndeveloped data stream algorithm BICO that can process high dimensional data in\none pass and output a solution of high quality. While piecy is suited for high\ndimensional data with a medium number of points, piecy-mr is meant for high\ndimensional data that comes in a very long stream. We provide an extensive\nexperimental study to evaluate piecy and piecy-mr that shows the strength of\nthe new algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 01:03:47 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 23:26:46 GMT"}, {"version": "v3", "created": "Thu, 28 May 2015 23:29:56 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Kappmeier", "Jan-Philipp W.", ""], ["Schmidt", "Daniel R.", ""], ["Schmidt", "Melanie", ""]]}, {"id": "1502.04301", "submitter": "Shmuel Onn", "authors": "Volker Kaibel, Shmuel Onn, Pauline Sarrabezolles", "title": "The Unimodular Intersection Problem", "comments": null, "journal-ref": "Operations Research Letters, 43:592-594, 2015", "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that finding minimally intersecting $n$ paths from $s$ to $t$ in a\ndirected graph or $n$ perfect matchings in a bipartite graph can be done in\npolynomial time. This holds more generally for unimodular set systems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 11:30:02 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2015 10:40:03 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2015 08:38:19 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Kaibel", "Volker", ""], ["Onn", "Shmuel", ""], ["Sarrabezolles", "Pauline", ""]]}, {"id": "1502.04354", "submitter": "Palash Dey", "authors": "Arnab Bhattacharyya and Palash Dey", "title": "Sample Complexity for Winner Prediction in Elections", "comments": "Accepted in AAMAS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the winner of an election is a favorite problem both for news\nmedia pundits and computational social choice theorists. Since it is often\ninfeasible to elicit the preferences of all the voters in a typical prediction\nscenario, a common algorithm used for winner prediction is to run the election\non a small sample of randomly chosen votes and output the winner as the\nprediction. We analyze the performance of this algorithm for many common voting\nrules.\n  More formally, we introduce the $(\\epsilon, \\delta)$-winner determination\nproblem, where given an election on $n$ voters and $m$ candidates in which the\nmargin of victory is at least $\\epsilon n$ votes, the goal is to determine the\nwinner with probability at least $1-\\delta$. The margin of victory of an\nelection is the smallest number of votes that need to be modified in order to\nchange the election winner. We show interesting lower and upper bounds on the\nnumber of samples needed to solve the $(\\epsilon, \\delta)$-winner determination\nproblem for many common voting rules, including scoring rules, approval,\nmaximin, Copeland, Bucklin, plurality with runoff, and single transferable\nvote. Moreover, the lower and upper bounds match for many common voting rules\nin a wide range of practically appealing scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 19:54:47 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 16:26:35 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 06:06:19 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Dey", "Palash", ""]]}, {"id": "1502.04514", "submitter": "Sanjeev Saxena", "authors": "Neethi K.S. and Sanjeev Saxena", "title": "Maximal Independent Sets in Generalised Caterpillar Graphs", "comments": null, "journal-ref": "J. Comb. Optim. 33(1): 326-332 (2017)", "doi": "10.1007/s10878-015-9960-0", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A caterpillar graph is a tree which on removal of all its pendant vertices\nleaves a chordless path. The chordless path is called the backbone of the\ngraph. The edges from the backbone to the pendant vertices are called the hairs\nof the caterpillar graph. Ortiz and Villanueva (C.Ortiz and M.Villanueva,\nDiscrete Applied Mathematics, 160(3): 259-266, 2012) describe an algorithm,\nlinear in the size of the output, for finding a family of maximal independent\nsets in a caterpillar graph.\n  In this paper, we propose an algorithm, again linear in the output size, for\na generalised caterpillar graph, where at each vertex of the backbone, there\ncan be any number of hairs of length one and at most one hair of length two.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 12:41:07 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["S.", "Neethi K.", ""], ["Saxena", "Sanjeev", ""]]}, {"id": "1502.04551", "submitter": "Micha{\\l}  Karpi\\'nski", "authors": "Micha{\\l} Karpi\\'nski, Marek Piotr\\'ow", "title": "Smaller Selection Networks for Cardinality Constraints Encoding", "comments": "Extended version of the paper sent to CP2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection comparator networks have been studied for many years. Recently,\nthey have been successfully applied to encode cardinality constraints for\nSAT-solvers. To decrease the size of generated formula there is a need for\nconstructions of selection networks that can be efficiently generated and\nproduce networks of small sizes for the practical range of their two\nparameters: n - the number of inputs (boolean variables) and k - the number of\nselected items (a cardinality bound). In this paper we give and analyze a new\nconstruction of smaller selection networks that are based on the pairwise\nselection networks introduced by Codish and Zanon-Ivry. We prove also that\nstandard encodings of cardinality constraints with selection networks preserve\narc-consistency.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 14:29:01 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Karpi\u0144ski", "Micha\u0142", ""], ["Piotr\u00f3w", "Marek", ""]]}, {"id": "1502.04588", "submitter": "Andreas Emil Feldmann", "authors": "Andreas Emil Feldmann, Wai Shing Fung, Jochen K\\\"onemann, Ian Post", "title": "A $(1 + {\\varepsilon})$-Embedding of Low Highway Dimension Graphs into\n  Bounded Treewidth Graphs", "comments": "A preliminary version of this paper appeared in the proceedings of\n  the 42nd International Colloquium on Automata, Languages, and Programming\n  (ICALP), 2015", "journal-ref": "SIAM J. Comput. 47(4): 1667-1704 (2018)", "doi": "10.1137/16M1067196", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs with bounded highway dimension were introduced by Abraham et al. [SODA\n2010] as a model of transportation networks. We show that any such graph can be\nembedded into a distribution over bounded treewidth graphs with arbitrarily\nsmall distortion. More concretely, given a weighted graph G = (V, E) of\nconstant highway dimension, we show how to randomly compute a weighted graph H\n= (V, E') that distorts shortest path distances of G by at most a 1 +\n${\\varepsilon}$ factor in expectation, and whose treewidth is polylogarithmic\nin the aspect ratio of G. Our probabilistic embedding implies quasi-polynomial\ntime approximation schemes for a number of optimization problems that naturally\narise in transportation networks, including Travelling Salesman, Steiner Tree,\nand Facility Location.\n  To construct our embedding for low highway dimension graphs we extend\nTalwar's [STOC 2004] embedding of low doubling dimension metrics into bounded\ntreewidth graphs, which generalizes known results for Euclidean metrics. We add\nseveral non-trivial ingredients to Talwar's techniques, and in particular\nthoroughly analyse the structure of low highway dimension graphs. Thus we\ndemonstrate that the geometric toolkit used for Euclidean metrics extends\nbeyond the class of low doubling metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 16:00:09 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2015 14:34:05 GMT"}, {"version": "v3", "created": "Tue, 22 Mar 2016 12:50:31 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 14:46:44 GMT"}, {"version": "v5", "created": "Tue, 8 Aug 2017 13:06:55 GMT"}, {"version": "v6", "created": "Wed, 19 Jun 2019 17:13:17 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Feldmann", "Andreas Emil", ""], ["Fung", "Wai Shing", ""], ["K\u00f6nemann", "Jochen", ""], ["Post", "Ian", ""]]}, {"id": "1502.04600", "submitter": "Dariusz Dereniowski", "authors": "Bo Chen, Ed Coffman, Dariusz Dereniowski, Wieslaw Kubiak", "title": "Structural Properties of an Open Problem in Preemptive Scheduling", "comments": null, "journal-ref": "Journal of Scheduling 19 (2016) 701-728", "doi": "10.1007/s10951-015-0446-9", "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural properties of optimal preemptive schedules have been studied in a\nnumber of recent papers with a primary focus on two structural parameters: the\nminimum number of preemptions necessary, and a tight lower bound on `shifts',\ni.e., the sizes of intervals bounded by the times created by preemptions, job\nstarts, or completions. So far only rough bounds for these parameters have been\nderived for specific problems. This paper sharpens the bounds on these\nstructural parameters for a well-known open problem in the theory of preemptive\nscheduling: Instances consist of in-trees of $n$ unit-execution-time jobs with\nrelease dates, and the objective is to minimize the total completion time on\ntwo processors. This is among the current, tantalizing `threshold' problems of\nscheduling theory: Our literature survey reveals that any significant\ngeneralization leads to an NP-hard problem, but that any significant\nsimplification leads to tractable problem.\n  For the above problem, we show that the number of preemptions necessary for\noptimality need not exceed $2n-1$; that the number must be of order\n$\\Omega(\\log n)$ for some instances; and that the minimum shift need not be\nless than $2^{-2n+1}$. These bounds are obtained by combinatorial analysis of\noptimal schedules rather than by the analysis of polytope corners for\nlinear-program formulations, an approach to be found in earlier papers. The\nbounds immediately follow from a fundamental structural property called\n`normality', by which minimal shifts of a job are exponentially decreasing\nfunctions. In particular, the first interval between a preempted job's start\nand its preemption is a multiple of 1/2, the second such interval is a multiple\nof 1/4, and in general, the $i$-th preemption occurs at a multiple of $2^{-i}$.\nWe expect the new structural properties to play a prominent role in finally\nsettling a vexing, still-open question of complexity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 16:22:38 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Chen", "Bo", ""], ["Coffman", "Ed", ""], ["Dereniowski", "Dariusz", ""], ["Kubiak", "Wieslaw", ""]]}, {"id": "1502.04625", "submitter": "Markus Lohrey", "authors": "Markus Lohrey, Sebastian Maneth and Fabian Peternek", "title": "Compressed Tree Canonization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Straight-line (linear) context-free tree (SLT) grammars have been used to\ncompactly represent ordered trees. It is well known that equivalence of SLT\ngrammars is decidable in polynomial time. Here we extend this result and show\nthat isomorphism of unordered trees given as SLT grammars is decidable in\npolynomial time. The proof constructs a compressed version of the canonical\nform of the tree represented by the input SLT grammar. The result is\ngeneralized to unrooted trees by \"re-rooting\" the compressed trees in\npolynomial time. We further show that bisimulation equivalence of unrooted\nunordered trees represented by SLT grammars is decidable in polynomial time.\nFor non-linear SLT grammars which can have double-exponential compression\nratios, we prove that unordered isomorphism is PSPACE-hard and in EXPTIME. The\nsame complexity bounds are shown for bisimulation equivalence.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 16:57:17 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Lohrey", "Markus", ""], ["Maneth", "Sebastian", ""], ["Peternek", "Fabian", ""]]}, {"id": "1502.04748", "submitter": "Martin Marinov Mr", "authors": "Martin Marinov and David Gregg", "title": "The Takeoff Towards Optimal Sorting Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete set of filters $F_n$ for the optimal-depth $n$-input sorting\nnetwork problem is such that if there exists an $n$-input sorting network of\ndepth $d$ then there exists one of the form $C \\oplus C'$ for some $C \\in F_n$.\nPrevious work on the topic presents a method for finding complete set of\nfilters $R_{n, 1}$ and $R_{n, 2}$ that consists only of networks of depths one\nand two respectively, whose outputs are minimal and representative up to\npermutation and reflection. Our main contribution is a practical approach for\nfinding a complete set of filters $R_{n, 3}$ containing only networks of depth\nthree whose outputs are minimal and representative up to permutation and\nreflection. In previous work, we have developed a highly efficient algorithm\nfor finding extremal sets ( i.e. outputs of comparator networks; itemsets; ) up\nto permutation. In this paper we present a modification to this algorithm that\nidentifies the representative itemsets up to permutation and reflection. Hence,\nthe presented practical approach is the successful combination of known theory\nand practice that we apply to the domain of sorting networks. For $n < 17$, we\nempirically compute the complete set of filters $R_{n, 2}$, $R_{n, 3}$, $R_{n,\n2} \\upharpoonright w $ and $R_{n, 3}^w$ of the representative minimal up to\npermutation and reflection $n$-input networks, where all but $R_{n, 2}$ are\nnovel to this work.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 23:13:32 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 17:17:18 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Marinov", "Martin", ""], ["Gregg", "David", ""]]}, {"id": "1502.04803", "submitter": "Amer Mouawad", "authors": "Daniel Lokshtanov, Amer E. Mouawad, Fahad Panolan, M.S. Ramanujan,\n  Saket Saurabh", "title": "Reconfiguration on sparse graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vertex-subset graph problem Q defines which subsets of the vertices of an\ninput graph are feasible solutions. A reconfiguration variant of a\nvertex-subset problem asks, given two feasible solutions S and T of size k,\nwhether it is possible to transform S into T by a sequence of vertex additions\nand deletions such that each intermediate set is also a feasible solution of\nsize bounded by k. We study reconfiguration variants of two classical\nvertex-subset problems, namely Independent Set and Dominating Set. We denote\nthe former by ISR and the latter by DSR. Both ISR and DSR are PSPACE-complete\non graphs of bounded bandwidth and W[1]-hard parameterized by k on general\ngraphs. We show that ISR is fixed-parameter tractable parameterized by k when\nthe input graph is of bounded degeneracy or nowhere-dense. As a corollary, we\nanswer positively an open question concerning the parameterized complexity of\nthe problem on graphs of bounded treewidth. Moreover, our techniques generalize\nrecent results showing that ISR is fixed-parameter tractable on planar graphs\nand graphs of bounded degree. For DSR, we show the problem fixed-parameter\ntractable parameterized by k when the input graph does not contain large\nbicliques, a class of graphs which includes graphs of bounded degeneracy and\nnowhere-dense graphs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 05:38:16 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Mouawad", "Amer E.", ""], ["Panolan", "Fahad", ""], ["Ramanujan", "M. S.", ""], ["Saurabh", "Saket", ""]]}, {"id": "1502.04885", "submitter": "Guillaume Pitel", "authors": "Guillaume Pitel and Geoffroy Fouquier", "title": "Count-Min-Log sketch: Approximately counting with approximate counters", "comments": "7 pages, 3 figures. Some preliminary notes can be found on\n  http://blog.guillaume-pitel.fr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count-Min Sketch is a widely adopted algorithm for approximate event counting\nin large scale processing. However, the original version of the\nCount-Min-Sketch (CMS) suffers of some deficiences, especially if one is\ninterested by the low-frequency items, such as in text-mining related tasks.\nSeveral variants of CMS have been proposed to compensate for the high relative\nerror for low-frequency events, but the proposed solutions tend to correct the\nerrors instead of preventing them. In this paper, we propose the Count-Min-Log\nsketch, which uses logarithm-based, approximate counters instead of linear\ncounters to improve the average relative error of CMS at constant memory\nfootprint.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 13:17:17 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Pitel", "Guillaume", ""], ["Fouquier", "Geoffroy", ""]]}, {"id": "1502.04963", "submitter": "Joel Rybicki", "authors": "Joel Rybicki, Jukka Suomela", "title": "Exact bounds for distributed graph colouring", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove exact bounds on the time complexity of distributed graph colouring.\nIf we are given a directed path that is properly coloured with $n$ colours, by\nprior work it is known that we can find a proper 3-colouring in $\\frac{1}{2}\n\\log^*(n) \\pm O(1)$ communication rounds. We close the gap between upper and\nlower bounds: we show that for infinitely many $n$ the time complexity is\nprecisely $\\frac{1}{2} \\log^* n$ communication rounds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 17:23:35 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 17:40:24 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""]]}, {"id": "1502.05023", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Sujay Sanghavi", "title": "A New Sampling Technique for Tensors", "comments": "29 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose new techniques to sample arbitrary third-order\ntensors, with an objective of speeding up tensor algorithms that have recently\ngained popularity in machine learning. Our main contribution is a new way to\nselect, in a biased random way, only $O(n^{1.5}/\\epsilon^2)$ of the possible\n$n^3$ elements while still achieving each of the three goals: \\\\ {\\em (a)\ntensor sparsification}: for a tensor that has to be formed from arbitrary\nsamples, compute very few elements to get a good spectral approximation, and\nfor arbitrary orthogonal tensors {\\em (b) tensor completion:} recover an\nexactly low-rank tensor from a small number of samples via alternating least\nsquares, or {\\em (c) tensor factorization:} approximating factors of a low-rank\ntensor corrupted by noise. \\\\ Our sampling can be used along with existing\ntensor-based algorithms to speed them up, removing the computational bottleneck\nin these methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 20:23:13 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 21:05:53 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1502.05204", "submitter": "Moshe Lewenstein", "authors": "Timothy M. Chan and Moshe Lewenstein", "title": "Clustered Integer 3SUM via Additive Combinatorics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a collection of new results on problems related to 3SUM,\nincluding:\n  1. The first truly subquadratic algorithm for\n  $\\ \\ \\ \\ \\ $ 1a. computing the (min,+) convolution for monotone increasing\nsequences with integer values bounded by $O(n)$,\n  $\\ \\ \\ \\ \\ $1b. solving 3SUM for monotone sets in 2D with integer coordinates\nbounded by $O(n)$, and\n  $\\ \\ \\ \\ \\ $1c. preprocessing a binary string for histogram indexing (also\ncalled jumbled indexing).\n  The running time is:\n$O(n^{(9+\\sqrt{177})/12}\\,\\textrm{polylog}\\,n)=O(n^{1.859})$ with\nrandomization, or $O(n^{1.864})$ deterministically. This greatly improves the\nprevious $n^2/2^{\\Omega(\\sqrt{\\log n})}$ time bound obtained from Williams'\nrecent result on all-pairs shortest paths [STOC'14], and answers an open\nquestion raised by several researchers studying the histogram indexing problem.\n  2. The first algorithm for histogram indexing for any constant alphabet size\nthat achieves truly subquadratic preprocessing time and truly sublinear query\ntime.\n  3. A truly subquadratic algorithm for integer 3SUM in the case when the given\nset can be partitioned into $n^{1-\\delta}$ clusters each covered by an interval\nof length $n$, for any constant $\\delta>0$.\n  4. An algorithm to preprocess any set of $n$ integers so that subsequently\n3SUM on any given subset can be solved in $O(n^{13/7}\\,\\textrm{polylog}\\,n)$\ntime.\n  All these results are obtained by a surprising new technique, based on the\nBalog--Szemer\\'edi--Gowers Theorem from additive combinatorics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 12:49:06 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Chan", "Timothy M.", ""], ["Lewenstein", "Moshe", ""]]}, {"id": "1502.05222", "submitter": "Spyros Kontogiannis", "authors": "Spyros Kontogiannis, Dorothea Wagner, Christos Zaroliagis", "title": "Hierarchical Time-Dependent Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study networks obeying \\emph{time-dependent} min-cost path metrics, and\npresent novel oracles for them which \\emph{provably} achieve two unique\nfeatures: % (i) \\emph{subquadratic} preprocessing time and space,\n\\emph{independent} of the metric's amount of disconcavity; % (ii)\n\\emph{sublinear} query time, in either the network size or the actual\nDijkstra-Rank of the query at hand.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 13:34:22 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 08:19:13 GMT"}, {"version": "v3", "created": "Wed, 22 Jun 2016 15:15:23 GMT"}, {"version": "v4", "created": "Fri, 1 Jul 2016 09:27:44 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Kontogiannis", "Spyros", ""], ["Wagner", "Dorothea", ""], ["Zaroliagis", "Christos", ""]]}, {"id": "1502.05279", "submitter": "Tigran Tonoyan", "authors": "Magnus M. Halldorsson and Tigran Tonoyan", "title": "The Price of Local Power Control in Wireless Scheduling", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling wireless links in the physical model,\nwhere we seek an assignment of power levels and a partition of the given set of\nlinks into the minimum number of subsets satisfying the\nsignal-to-interference-and-noise-ratio (SINR) constraints. Specifically, we are\ninterested in the efficiency of local power assignment schemes, or oblivious\npower schemes, in approximating wireless scheduling. Oblivious power schemes\nare motivated by networking scenarios when power levels must be decided in\nadvance, and not as part of the scheduling computation.\n  We first show that the known algorithms fail to obtain sub-logarithmic\nbounds; that is, their approximation ratio are $\\tilde\\Omega(\\log\n\\max(\\Delta,n))$, where $n$ is the number of links, $\\Delta$ is the ratio of\nthe maximum and minimum link lengths, and $\\tilde\\Omega$ hides\ndoubly-logarithmic factors. We then present the first\n$O(\\log{\\log\\Delta})$-approximation algorithm, which is known to be best\npossible (in terms of $\\Delta$) for oblivious power schemes. We achieve this by\nrepresenting interference by a conflict graph, which allows the application of\ngraph-theoretic results for a variety of related problems, including the\nweighted capacity problem. We explore further the contours of approximability,\nand find the choice of power assignment matters; that not all metric spaces are\nequal; and that the presence of weak links makes the problem harder. Combined,\nour result resolve the price of oblivious power for wireless scheduling, or the\nvalue of allowing unfettered power control.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 15:46:33 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Tonoyan", "Tigran", ""]]}, {"id": "1502.05292", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Luigi Laura", "title": "Dynamic subtrees queries revisited: the Depth First Tour Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the dynamic tree problem the goal is the maintenance of an arbitrary\nn-vertex forest, where the trees are subject to joining and splitting by,\nrespectively, adding and removing edges. Depending on the application,\ninformation can be associated to nodes or edges (or both), and queries might\nrequire to combine values in path or (sub)trees.\n  In this paper we present a novel data structure, called the Depth First Tour\nTree, based on a linearization of a DFS visit of the tree. Despite the\nsimplicity of the approach, similar to the ET-Trees (based on a Euler Tour),\nour data structure is able to answer queries related to both paths and\n(sub)trees. In particular, focusing on subtree computations, we show how to\ncustomize the data structure in order to answer queries for three distinct\napplications: impact of the removal of an articulation point from a graph,\nbetweenness centrality and closeness centrality of a dynamic tree.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 16:32:59 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2015 14:15:43 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2015 13:11:16 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Farina", "Gabriele", ""], ["Laura", "Luigi", ""]]}, {"id": "1502.05334", "submitter": "David Eppstein", "authors": "David Eppstein", "title": "Simple Recognition of Halin Graphs and Their Generalizations", "comments": "16 pages, 5 figures", "journal-ref": "J. Graph Algorithms & Applications 20 (2): 323-346, 2016", "doi": "10.7155/jgaa.00395", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and implement two local reduction rules that can be used to\nrecognize Halin graphs in linear time, avoiding the complicated planarity\ntesting step of previous linear time Halin graph recognition algorithms. The\nsame two rules can be used as the basis for linear-time algorithms for other\nalgorithmic problems on Halin graphs, including decomposing these graphs into a\ntree and a cycle, finding a Hamiltonian cycle, or constructing a planar\nembedding. These reduction rules can also be used to recognize a broader class\nof polyhedral graphs. These graphs, which we call the D3-reducible graphs, are\nthe dual graphs of the polyhedra formed by gluing pyramids together on their\ntriangular faces; their treewidth is bounded, and they necessarily have\nLombardi drawings.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 18:36:01 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 23:50:47 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Eppstein", "David", ""]]}, {"id": "1502.05375", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Ameet Gadekar, Ninad Rajgopal", "title": "On learning k-parities with and without noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first consider the problem of learning $k$-parities in the on-line\nmistake-bound model: given a hidden vector $x \\in \\{0,1\\}^n$ with $|x|=k$ and a\nsequence of \"questions\" $a_1, a_2, ...\\in \\{0,1\\}^n$, where the algorithm must\nreply to each question with $< a_i, x> \\pmod 2$, what is the best tradeoff\nbetween the number of mistakes made by the algorithm and its time complexity?\nWe improve the previous best result of Buhrman et al. by an $\\exp(k)$ factor in\nthe time complexity.\n  Second, we consider the problem of learning $k$-parities in the presence of\nclassification noise of rate $\\eta \\in (0,1/2)$. A polynomial time algorithm\nfor this problem (when $\\eta > 0$ and $k = \\omega(1)$) is a longstanding\nchallenge in learning theory. Grigorescu et al. showed an algorithm running in\ntime ${n \\choose k/2}^{1 + 4\\eta^2 +o(1)}$. Note that this algorithm inherently\nrequires time ${n \\choose k/2}$ even when the noise rate $\\eta$ is polynomially\nsmall. We observe that for sufficiently small noise rate, it is possible to\nbreak the $n \\choose k/2$ barrier. In particular, if for some function $f(n) =\n\\omega(1)$ and $\\alpha \\in [1/2, 1)$, $k = n/f(n)$ and $\\eta = o(f(n)^{-\n\\alpha}/\\log n)$, then there is an algorithm for the problem with running time\n$poly(n)\\cdot {n \\choose k}^{1-\\alpha} \\cdot e^{-k/4.01}$.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 20:36:19 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gadekar", "Ameet", ""], ["Rajgopal", "Ninad", ""]]}, {"id": "1502.05447", "submitter": "Alexander Golovnev", "authors": "Fedor V. Fomin, Alexander Golovnev, Alexander S. Kulikov, and Ivan\n  Mihajlin", "title": "Lower Bounds for the Graph Homomorphism Problem", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph homomorphism problem (HOM) asks whether the vertices of a given\n$n$-vertex graph $G$ can be mapped to the vertices of a given $h$-vertex graph\n$H$ such that each edge of $G$ is mapped to an edge of $H$. The problem\ngeneralizes the graph coloring problem and at the same time can be viewed as a\nspecial case of the $2$-CSP problem. In this paper, we prove several lower\nbound for HOM under the Exponential Time Hypothesis (ETH) assumption. The main\nresult is a lower bound $2^{\\Omega\\left( \\frac{n \\log h}{\\log \\log h}\\right)}$.\nThis rules out the existence of a single-exponential algorithm and shows that\nthe trivial upper bound $2^{{\\mathcal O}(n\\log{h})}$ is almost asymptotically\ntight.\n  We also investigate what properties of graphs $G$ and $H$ make it difficult\nto solve HOM$(G,H)$. An easy observation is that an ${\\mathcal O}(h^n)$ upper\nbound can be improved to ${\\mathcal O}(h^{\\operatorname{vc}(G)})$ where\n$\\operatorname{vc}(G)$ is the minimum size of a vertex cover of $G$. The second\nlower bound $h^{\\Omega(\\operatorname{vc}(G))}$ shows that the upper bound is\nasymptotically tight. As to the properties of the \"right-hand side\" graph $H$,\nit is known that HOM$(G,H)$ can be solved in time $(f(\\Delta(H)))^n$ and\n$(f(\\operatorname{tw}(H)))^n$ where $\\Delta(H)$ is the maximum degree of $H$\nand $\\operatorname{tw}(H)$ is the treewidth of $H$. This gives\nsingle-exponential algorithms for graphs of bounded maximum degree or bounded\ntreewidth. Since the chromatic number $\\chi(H)$ does not exceed\n$\\operatorname{tw}(H)$ and $\\Delta(H)+1$, it is natural to ask whether similar\nupper bounds with respect to $\\chi(H)$ can be obtained. We provide a negative\nanswer to this question by establishing a lower bound $(f(\\chi(H)))^n$ for any\nfunction $f$. We also observe that similar lower bounds can be obtained for\nlocally injective homomorphisms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 00:12:26 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovnev", "Alexander", ""], ["Kulikov", "Alexander S.", ""], ["Mihajlin", "Ivan", ""]]}, {"id": "1502.05511", "submitter": "Vedran Dunjko", "authors": "Vedran Dunjko and Hans J. Briegel", "title": "Quantum mixing of Markov chains for special distributions", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preparation of the stationary distribution of irreducible,\ntime-reversible Markov chains is a fundamental building block in many heuristic\napproaches to algorithmically hard problems. It has been conjectured that\nquantum analogs of classical mixing processes may offer a generic quadratic\nspeed-up in realizing such stationary distributions. Such a speed-up would also\nimply a speed-up of a broad family of heuristic algorithms.\n  However, a true quadratic speed up has thus far only been demonstrated for\nspecial classes of Markov chains. These results often presuppose a regular\nstructure of the underlying graph of the Markov chain, and also a regularity in\nthe transition probabilities.\n  In this work, we demonstrate a true quadratic speed-up for a class of Markov\nchains where the restriction is only on the form of the stationary\ndistribution, rather than directly on the Markov chain structure itself. In\nparticular, we show efficient mixing can be achieved when it is beforehand\nknown that the distribution is monotonically decreasing relative to a known\norder on the state space. Following this, we show that our approach extends to\na wider class of distributions, where only a fraction of the shape of the\ndistribution is known to be monotonic. Our approach is built on the\nSzegedy-type quantization of transition operators.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 09:39:10 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Dunjko", "Vedran", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1502.05543", "submitter": "Arnold Filtser", "authors": "Michael Elkin, Arnold Filtser, Ofer Neiman", "title": "Prioritized Metric Structures and Embedding", "comments": "To appear at STOC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric data structures (distance oracles, distance labeling schemes, routing\nschemes) and low-distortion embeddings provide a powerful algorithmic\nmethodology, which has been successfully applied for approximation algorithms\n\\cite{llr}, online algorithms \\cite{BBMN11}, distributed algorithms\n\\cite{KKMPT12} and for computing sparsifiers \\cite{ST04}. However, this\nmethodology appears to have a limitation: the worst-case performance inherently\ndepends on the cardinality of the metric, and one could not specify in advance\nwhich vertices/points should enjoy a better service (i.e., stretch/distortion,\nlabel size/dimension) than that given by the worst-case guarantee.\n  In this paper we alleviate this limitation by devising a suit of {\\em\nprioritized} metric data structures and embeddings. We show that given a\npriority ranking $(x_1,x_2,\\ldots,x_n)$ of the graph vertices (respectively,\nmetric points) one can devise a metric data structure (respectively, embedding)\nin which the stretch (resp., distortion) incurred by any pair containing a\nvertex $x_j$ will depend on the rank $j$ of the vertex. We also show that other\nimportant parameters, such as the label size and (in some sense) the dimension,\nmay depend only on $j$. In some of our metric data structures (resp.,\nembeddings) we achieve both prioritized stretch (resp., distortion) and label\nsize (resp., dimension) {\\em simultaneously}. The worst-case performance of our\nmetric data structures and embeddings is typically asymptotically no worse than\nof their non-prioritized counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 12:15:58 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2015 16:47:48 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Elkin", "Michael", ""], ["Filtser", "Arnold", ""], ["Neiman", "Ofer", ""]]}, {"id": "1502.05545", "submitter": "Dominik Pajak", "authors": "Artur Menc, Dominik Paj\\k{a}k, Przemys{\\l}aw Uzna\\'nski", "title": "Time and space optimality of rotor-router graph exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exploration of an anonymous, port-labeled,\nundirected graph with $n$ nodes and $m$ edges and diameter $D$, by a single\nmobile agent. Initially the agent does not know the graph topology nor any of\nthe global parameters. Moreover, the agent does not know the incoming port when\nentering to a vertex. Each vertex is endowed with memory that can be read and\nmodified by the agent upon its visit to that node. However the agent has no\noperational memory i.e., it cannot carry any state while traversing an edge. In\nsuch a model at least $\\log_2 d$ bits are needed at each vertex of degree $d$\nfor the agent to be able to traverse each graph edge. This number of bits is\nalways sufficient to explore any graph in time $O(mD)$ using algorithm\nRotor-Router. We show that even if the available node memory is unlimited then\ntime $\\Omega(n^3)$ is sometimes required for any algorithm. This shows that\nRotor-Router is asymptotically optimal in the worst-case graphs. Secondly we\nshow that for the case of the path the Rotor-Router attains exactly optimal\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 12:19:48 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 08:26:26 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2015 18:49:39 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Menc", "Artur", ""], ["Paj\u0105k", "Dominik", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1502.05599", "submitter": "Gennaro Cordasco PhD", "authors": "Ferdinando Cicalese, Gennaro Cordasco, Luisa Gargano, Martin Milanic,\n  Joseph Peters, and Ugo Vaccaro", "title": "Spread of Influence in Weighted Networks under Time and Budget\n  Constraints", "comments": "This paper will appear in the special issue of Theoretical Computer\n  Science devoted to selected papers presented at Fun 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a network represented by a weighted directed graph G, we consider the\nproblem of finding a bounded cost set of nodes S such that the influence\nspreading from S in G, within a given time bound, is as large as possible. The\ndynamic that governs the spread of influence is the following: initially only\nelements in S are influenced; subsequently at each round, the set of influenced\nelements is augmented by all nodes in the network that have a sufficiently\nlarge number of already influenced neighbors. We prove that the problem is\nNP-hard, even in simple networks like complete graphs and trees. We also derive\na series of positive results. We present exact pseudo-polynomial time\nalgorithms for general trees, that become polynomial time in case the trees are\nunweighted. This last result improves on previously published results. We also\ndesign polynomial time algorithms for general weighted paths and cycles, and\nfor unweighted complete graphs.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 09:19:11 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 13:58:02 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Cicalese", "Ferdinando", ""], ["Cordasco", "Gennaro", ""], ["Gargano", "Luisa", ""], ["Milanic", "Martin", ""], ["Peters", "Joseph", ""], ["Vaccaro", "Ugo", ""]]}, {"id": "1502.05675", "submitter": "Malik Magdon-Ismail", "authors": "Malik Magdon-Ismail", "title": "NP-Hardness and Inapproximability of Sparse PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a reduction from {\\sc clique} to establish that sparse PCA is\nNP-hard. The reduction has a gap which we use to exclude an FPTAS for sparse\nPCA (unless P=NP). Under weaker complexity assumptions, we also exclude\npolynomial constant-factor approximation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 19:30:46 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 13:00:17 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Magdon-Ismail", "Malik", ""]]}, {"id": "1502.05729", "submitter": "Morten St\\\"ockel", "authors": "Mathias B{\\ae}k Tejs Knudsen, Morten St\\\"ockel", "title": "Quicksort, Largest Bucket, and Min-Wise Hashing with Limited\n  Independence", "comments": "Submitted to ICALP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized algorithms and data structures are often analyzed under the\nassumption of access to a perfect source of randomness. The most fundamental\nmetric used to measure how \"random\" a hash function or a random number\ngenerator is, is its independence: a sequence of random variables is said to be\n$k$-independent if every variable is uniform and every size $k$ subset is\nindependent. In this paper we consider three classic algorithms under limited\nindependence. We provide new bounds for randomized quicksort, min-wise hashing\nand largest bucket size under limited independence. Our results can be\nsummarized as follows.\n  -Randomized quicksort. When pivot elements are computed using a\n$5$-independent hash function, Karloff and Raghavan, J.ACM'93 showed $O ( n\n\\log n)$ expected worst-case running time for a special version of quicksort.\nWe improve upon this, showing that the same running time is achieved with only\n$4$-independence.\n  -Min-wise hashing. For a set $A$, consider the probability of a particular\nelement being mapped to the smallest hash value. It is known that\n$5$-independence implies the optimal probability $O (1 /n)$. Broder et al.,\nSTOC'98 showed that $2$-independence implies it is $O(1 / \\sqrt{|A|})$. We show\na matching lower bound as well as new tight bounds for $3$- and $4$-independent\nhash functions.\n  -Largest bucket. We consider the case where $n$ balls are distributed to $n$\nbuckets using a $k$-independent hash function and analyze the largest bucket\nsize. Alon et. al, STOC'97 showed that there exists a $2$-independent hash\nfunction implying a bucket of size $\\Omega ( n^{1/2})$. We generalize the\nbound, providing a $k$-independent family of functions that imply size $\\Omega\n( n^{1/k})$.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 21:20:56 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Knudsen", "Mathias B\u00e6k Tejs", ""], ["St\u00f6ckel", "Morten", ""]]}, {"id": "1502.05746", "submitter": "Eric Price", "authors": "Xinyang Yi, Constantine Caramanis and Eric Price", "title": "Binary Embedding: Fundamental Limits and Fast Algorithm", "comments": "Note: the previous version of this paper also included a claimed fast\n  upper bound for certain parameter regimes. The proof of this had an error, as\n  pointed out in Dirksen and Stollenwerk (2018); the same paper also presents a\n  correct algorithm for the setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary embedding is a nonlinear dimension reduction methodology where high\ndimensional data are embedded into the Hamming cube while preserving the\nstructure of the original space. Specifically, for an arbitrary $N$ distinct\npoints in $\\mathbb{S}^{p-1}$, our goal is to encode each point using\n$m$-dimensional binary strings such that we can reconstruct their geodesic\ndistance up to $\\delta$ uniform distortion. Existing binary embedding\nalgorithms either lack theoretical guarantees or suffer from running time\n$O\\big(mp\\big)$. We make three contributions: (1) we establish a lower bound\nthat shows any binary embedding oblivious to the set of points requires $m =\n\\Omega(\\frac{1}{\\delta^2}\\log{N})$ bits and a similar lower bound for\nnon-oblivious embeddings into Hamming distance; (2) [DELETED, see comment]; (3)\nwe also provide an analytic result about embedding a general set of points $K\n\\subseteq \\mathbb{S}^{p-1}$ with even infinite size. Our theoretical findings\nare supported through experiments on both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 23:15:02 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 04:40:32 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Yi", "Xinyang", ""], ["Caramanis", "Constantine", ""], ["Price", "Eric", ""]]}, {"id": "1502.05828", "submitter": "Michael Lampis", "authors": "\\'Edouard Bonnet, Michael Lampis, Vangelis Th. Paschos", "title": "Time-Approximation Trade-offs for Inapproximable Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on problems which do not admit a constant-factor\napproximation in polynomial time and explore how quickly their approximability\nimproves as the allowed running time is gradually increased from polynomial to\n(sub-)exponential.\n  We tackle a number of problems: For Min Independent Dominating Set, Max\nInduced Path, Forest and Tree, for any $r(n)$, a simple, known scheme gives an\napproximation ratio of $r$ in time roughly $r^{n/r}$. We show that, for most\nvalues of $r$, if this running time could be significantly improved the ETH\nwould fail. For Max Minimal Vertex Cover we give a non-trivial\n$\\sqrt{r}$-approximation in time $2^{n/r}$. We match this with a similarly\ntight result. We also give a $\\log r$-approximation for Min ATSP in time\n$2^{n/r}$ and an $r$-approximation for Max Grundy Coloring in time $r^{n/r}$.\n  Furthermore, we show that Min Set Cover exhibits a curious behavior in this\nsuper-polynomial setting: for any $\\delta > 0$ it admits an\n$m^\\delta$-approximation, where $m$ is the number of sets, in just\nquasi-polynomial time. We observe that if such ratios could be achieved in\npolynomial time, the ETH or the Projection Games Conjecture would fail.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 11:07:52 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Lampis", "Michael", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1502.05910", "submitter": "Jannis Bulian", "authors": "Jannis Bulian and Anuj Dawar", "title": "Fixed-parameter Tractable Distances to Sparse Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for various classes C of sparse graphs, and several measures of\ndistance to such classes (such as edit distance and elimination distance), the\nproblem of determining the distance of a given graph G to C is fixed-parameter\ntractable. The results are based on two general techniques. The first of these,\nbuilding on recent work of Grohe et al. establishes that any class of graphs\nthat is slicewise nowhere dense and slicewise first-order definable is FPT. The\nsecond shows that determining the elimination distance of a graph G to a\nminor-closed class C is FPT.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:44:17 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Bulian", "Jannis", ""], ["Dawar", "Anuj", ""]]}, {"id": "1502.05937", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui, Fabio Cunial, Travis Gagie, Nicola Prezza and\n  Mathieu Raffinot", "title": "Composite repetition-aware data structures", "comments": "(the name of the third co-author was inadvertently omitted from\n  previous version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In highly repetitive strings, like collections of genomes from the same\nspecies, distinct measures of repetition all grow sublinearly in the length of\nthe text, and indexes targeted to such strings typically depend only on one of\nthese measures. We describe two data structures whose size depends on multiple\nmeasures of repetition at once, and that provide competitive tradeoffs between\nthe time for counting and reporting all the exact occurrences of a pattern, and\nthe space taken by the structure. The key component of our constructions is the\nrun-length encoded BWT (RLBWT), which takes space proportional to the number of\nBWT runs: rather than augmenting RLBWT with suffix array samples, we combine it\nwith data structures from LZ77 indexes, which take space proportional to the\nnumber of LZ77 factors, and with the compact directed acyclic word graph\n(CDAWG), which takes space proportional to the number of extensions of maximal\nrepeats. The combination of CDAWG and RLBWT enables also a new representation\nof the suffix tree, whose size depends again on the number of extensions of\nmaximal repeats, and that is powerful enough to support matching statistics and\nconstant-space traversal.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 17:00:26 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2015 10:18:46 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Cunial", "Fabio", ""], ["Gagie", "Travis", ""], ["Prezza", "Nicola", ""], ["Raffinot", "Mathieu", ""]]}, {"id": "1502.05983", "submitter": "Martin Marinov Mr", "authors": "Martin Marinov and David Gregg", "title": "Sorting Networks: The Final Countdown", "comments": "arXiv admin note: substantial text overlap with arXiv:1502.04748", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the knowledge on the problem of empirically searching\nfor sorting networks of minimal depth. We present new search space pruning\ntechniques for the last four levels of a candidate sorting network by\nconsidering only the output set representation of a network. We present an\nalgorithm for checking whether an $n$-input sorting network of depth $d$ exists\nby considering the minimal up to permutation and reflection itemsets at each\nlevel and using the pruning at the last four levels. We experimentally\nevaluated this algorithm to find the optimal depth sorting networks for all $n\n\\leq 12$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 20:12:30 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Marinov", "Martin", ""], ["Gregg", "David", ""]]}, {"id": "1502.06062", "submitter": "Tadao Takaoka", "authors": "Tadao Takaoka", "title": "Multi-level Loop-less Algorithm for Multi-set Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that generates multiset permutations in O(1) time for\neach permutation, that is, by a loop-less algorithm with O(n) extra memory\nrequirement. There already exist several such algorithms that generate multiset\npermutations in various orders. For multiset permutations, we combine two\nloop-less algorithms that are designed in the same principle of tree traversal.\nOur order of generation is different from any existing order, and the algorithm\nis simpler and faster than the previous ones. We also apply the new algorithm\nto parking functions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 03:28:26 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Takaoka", "Tadao", ""]]}, {"id": "1502.06079", "submitter": "Ali D. Mehrabi", "authors": "Mark de Berg, Joachim Gudmundsson, and Ali D. Mehrabi", "title": "Finding Pairwise Intersections Inside a Query Range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following problem: preprocess a set O of objects into a data\nstructure that allows us to efficiently report all pairs of objects from O that\nintersect inside an axis-aligned query range Q. We present data structures of\nsize $O(n({\\rm polylog} n))$ and with query time $O((k+1)({\\rm polylog} n))$\ntime, where k is the number of reported pairs, for two classes of objects in\nthe plane: axis-aligned rectangles and objects with small union complexity. For\nthe 3-dimensional case where the objects and the query range are axis-aligned\nboxes in R^3, we present a data structures of size $O(n\\sqrt{n}({\\rm polylog}\nn))$ and query time $O((\\sqrt{n}+k)({\\rm polylog} n))$. When the objects and\nquery are fat, we obtain $O((k+1)({\\rm polylog} n))$ query time using $O(n({\\rm\npolylog} n))$ storage.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 07:27:49 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["de Berg", "Mark", ""], ["Gudmundsson", "Joachim", ""], ["Mehrabi", "Ali D.", ""]]}, {"id": "1502.06168", "submitter": "Farhad Shahrokhi", "authors": "Farhad Shahrokhi", "title": "A new upper bound for the clique cover number with applications", "comments": null, "journal-ref": "Congressus Numerantium 205 (2010), 105-111", "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\alpha(G)$ and $\\beta(G)$, denote the size of a largest independent set\nand the clique cover number of an undirected graph $G$. Let $H$ be an interval\ngraph with $V(G)=V(H)$ and $E(G)\\subseteq E(H)$, and let $\\phi(G,H)$ denote the\nmaximum of ${\\beta(G[W])\\over \\alpha(G[W])}$ overall induced subgraphs $G[W]$\nof $G$ that are cliques in $H$. The main result of this paper is to prove that\nfor any graph $G$ $${\\beta(G)}\\le 2 \\alpha(H)\\phi(G,H)(\\log \\alpha(H)+1),$$\nwhere, $\\alpha(H)$ is the size of a largest independent set in $H$. We further\nprovide a generalization that significantly unifies or improves some past\nalgorithmic and structural results concerning the clique cover number for some\nwell known intersection graphs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 02:42:44 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Shahrokhi", "Farhad", ""]]}, {"id": "1502.06208", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb and Aryeh Kontorovich", "title": "Nearly optimal classification for semimetrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the rigorous study of classification in semimetric spaces, which\nare point sets with a distance function that is non-negative and symmetric, but\nneed not satisfy the triangle inequality. For metric spaces, the doubling\ndimension essentially characterizes both the runtime and sample complexity of\nclassification algorithms --- yet we show that this is not the case for\nsemimetrics. Instead, we define the {\\em density dimension} and discover that\nit plays a central role in the statistical and algorithmic feasibility of\nlearning in semimetric spaces. We present nearly optimal sample compression\nalgorithms and use these to obtain generalization guarantees, including fast\nrates. The latter hold for general sample compression schemes and may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 10:42:52 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1502.06250", "submitter": "Aleksandr Cariow", "authors": "Aleksandr Cariow, Galina Cariowa, Jaroslaw Knapinski", "title": "Derivation of a low multiplicative complexity algorithm for multiplying\n  hyperbolic octonions", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm to multiply two hyperbolic octonions. The\ndirect multiplication of two hyperbolic octonions requires 64 real\nmultiplications and 56 real additions. More effective solutions still do not\nexist. We show how to compute a product of the hyperbolic octonions with 26\nreal multiplications and 92 real additions. During synthesis of the discussed\nalgorithm we use the fact that product of two hyperbolic octonions may be\nrepresented as a matrix - vector product. The matrix multiplicand that\nparticipates in the product calculating has unique structural properties that\nallow performing its advantageous factorization. Namely this factorization\nleads to significant reducing of the computational complexity of hyperbolic\noctonions multiplication.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 17:17:44 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Cariow", "Aleksandr", ""], ["Cariowa", "Galina", ""], ["Knapinski", "Jaroslaw", ""]]}, {"id": "1502.06370", "submitter": "Djamal Belazzougui", "authors": "Djamal Belazzougui and Fabio Cunial", "title": "A framework for space-efficient string kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String kernels are typically used to compare genome-scale sequences whose\nlength makes alignment impractical, yet their computation is based on data\nstructures that are either space-inefficient, or incur large slowdowns. We show\nthat a number of exact string kernels, like the $k$-mer kernel, the substrings\nkernels, a number of length-weighted kernels, the minimal absent words kernel,\nand kernels with Markovian corrections, can all be computed in $O(nd)$ time and\nin $o(n)$ bits of space in addition to the input, using just a\n$\\mathtt{rangeDistinct}$ data structure on the Burrows-Wheeler transform of the\ninput strings, which takes $O(d)$ time per element in its output. The same\nbounds hold for a number of measures of compositional complexity based on\nmultiple value of $k$, like the $k$-mer profile and the $k$-th order empirical\nentropy, and for calibrating the value of $k$ using the data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 10:18:16 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Belazzougui", "Djamal", ""], ["Cunial", "Fabio", ""]]}, {"id": "1502.06528", "submitter": "Edo Liberty", "authors": "Christos Boutsidis, Edo Liberty, Maxim Sviridenko", "title": "Greedy Minimization of Weakly Supermodular Set Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines weak-$\\alpha$-supermodularity for set functions. Many\noptimization objectives in machine learning and data mining seek to minimize\nsuch functions under cardinality constrains. We prove that such problems\nbenefit from a greedy extension phase. Explicitly, let $S^*$ be the optimal set\nof cardinality $k$ that minimizes $f$ and let $S_0$ be an initial solution such\nthat $f(S_0)/f(S^*) \\le \\rho$. Then, a greedy extension $S \\supset S_0$ of size\n$|S| \\le |S_0| + \\lceil \\alpha k \\ln(\\rho/\\varepsilon) \\rceil$ yields\n$f(S)/f(S^*) \\le 1+\\varepsilon$. As example usages of this framework we give\nnew bicriteria results for $k$-means, sparse regression, and columns subset\nselection.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 17:48:35 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Boutsidis", "Christos", ""], ["Liberty", "Edo", ""], ["Sviridenko", "Maxim", ""]]}, {"id": "1502.06631", "submitter": "Igor Shparlinski", "authors": "Gabor Ivanyos, Marek Karpinski, Miklos Santha, Nitin Saxena and Igor\n  Shparlinski", "title": "Polynomial Interpolation and Identity Testing from High Powers over\n  Finite Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering (that is, interpolating) and identity\ntesting of a \"hidden\" monic polynomial $f$, given an oracle access to $f(x)^e$\nfor $x\\in{\\mathbb F_q}$ (extension fields access is not permitted). The naive\ninterpolation algorithm needs $O(e\\, \\mathrm{deg}\\, f)$ queries and thus\nrequires $e\\, \\mathrm{deg}\\, f<q$. We design algorithms that are asymptotically\nbetter in certain cases; requiring only $e^{o(1)}$ queries to the oracle. In\nthe randomized (and quantum) setting, we give a substantially better\ninterpolation algorithm, that requires only $O(\\mathrm{deg}\\, f \\log q)$\nqueries. Such results have been known before only for the special case of a\nlinear $f$, called the hidden shifted power problem.\n  We use techniques from algebra, such as effective versions of Hilbert's\nNullstellensatz, and analytic number theory, such as results on the\ndistribution of rational functions in subgroups and character sum estimates.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 21:12:46 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Ivanyos", "Gabor", ""], ["Karpinski", "Marek", ""], ["Santha", "Miklos", ""], ["Saxena", "Nitin", ""], ["Shparlinski", "Igor", ""]]}, {"id": "1502.06764", "submitter": "Ching-Lueh Chang", "authors": "Ching-Lueh Chang", "title": "A deterministic sublinear-time nonadaptive algorithm for metric\n  $1$-median selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a deterministic $O(hn^{1+1/h})$-time $(2h)$-approximation nonadaptive\nalgorithm for $1$-median selection in $n$-point metric spaces, where\n$h\\in\\mathbb{Z}^+\\setminus\\{1\\}$ is arbitrary. Our proof generalizes that of\nChang.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 11:18:58 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Chang", "Ching-Lueh", ""]]}, {"id": "1502.06820", "submitter": "Song Yang", "authors": "Song Yang, Stojan Trajanovski, Fernando A. Kuipers", "title": "Optimization Problems in Correlated Networks", "comments": "11 pages, 10 figures, accepted for publication in Computational\n  Social Networks, Springer", "journal-ref": "Computational Social Networks 2016, 3:1", "doi": "10.1186/s40649-016-0026-y", "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the shortest path and the min-cut problems are key in achieving high\nperformance and robust communication networks. Those problems have often beeny\nstudied in deterministic and independent networks both in their original\nformulations as well as in several constrained variants. However, in real-world\nnetworks, link weights (e.g., delay, bandwidth, failure probability) are often\ncorrelated due to spatial or temporal reasons, and these correlated link\nweights together behave in a different manner and are not always additive.\n  In this paper, we first propose two correlated link-weight models, namely (i)\nthe deterministic correlated model and (ii) the (log-concave) stochastic\ncorrelated model. Subsequently, we study the shortest path problem and the\nmin-cut problem under these two correlated models. We prove that these two\nproblems are NP-hard under the deterministic correlated model, and even cannot\nbe approximated to arbitrary degree in polynomial time. However, these two\nproblems are polynomial-time solvable under the (constrained) nodal\ndeterministic correlated model, and can be solved by convex optimization under\nthe (log-concave) stochastic correlated model.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 14:23:32 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2016 19:54:06 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Yang", "Song", ""], ["Trajanovski", "Stojan", ""], ["Kuipers", "Fernando A.", ""]]}, {"id": "1502.06967", "submitter": "Christopher Chubb", "authors": "Christopher T. Chubb and Steven T. Flammia", "title": "Computing the Degenerate Ground Space of Gapped Spin Chains in\n  Polynomial Time", "comments": "33 pages", "journal-ref": "Chicago Journal of Theoretical Computer Science 2016, 9 (2016)", "doi": "10.4086/cjtcs.2016.009", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a gapped Hamiltonian of a spin chain, we give a polynomial-time\nalgorithm for finding the degenerate ground space projector. The output is an\northonormal set of matrix product states that approximate the true ground space\nprojector up to an inverse polynomial error in any Schatten norm, with a\nruntime exponential in the degeneracy. Our algorithm is an extension of the\nrecent algorithm of Landau, Vazirani, and Vidick for the nondegenerate case,\nand it includes the recent improvements due to Huang. The main new idea is to\nincorporate the local distinguishability of ground states on the half-chain to\nensure that the algorithm returns a complete set of global ground states.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 21:00:13 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 05:23:08 GMT"}, {"version": "v3", "created": "Wed, 11 May 2016 16:11:26 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Chubb", "Christopher T.", ""], ["Flammia", "Steven T.", ""]]}, {"id": "1502.07027", "submitter": "David Felber", "authors": "David Felber and Rafail Ostrovsky", "title": "Variability in data streams", "comments": "submitted to ICALP 2015 (here, fullpage formatting)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of tracking with small relative error an integer\nfunction $f(n)$ defined by a distributed update stream $f'(n)$. Existing\nstreaming algorithms with worst-case guarantees for this problem assume $f(n)$\nto be monotone; there are very large lower bounds on the space requirements for\nsummarizing a distributed non-monotonic stream, often linear in the size $n$ of\nthe stream.\n  Input streams that give rise to large space requirements are highly variable,\nmaking relatively large jumps from one timestep to the next. However, streams\noften vary slowly in practice. What has heretofore been lacking is a framework\nfor non-monotonic streams that admits algorithms whose worst-case performance\nis as good as existing algorithms for monotone streams and degrades gracefully\nfor non-monotonic streams as those streams vary more quickly.\n  In this paper we propose such a framework. We introduce a new stream\nparameter, the \"variability\" $v$, deriving its definition in a way that shows\nit to be a natural parameter to consider for non-monotonic streams. It is also\na useful parameter. From a theoretical perspective, we can adapt existing\nalgorithms for monotone streams to work for non-monotonic streams, with only\nminor modifications, in such a way that they reduce to the monotone case when\nthe stream happens to be monotone, and in such a way that we can refine the\nworst-case communication bounds from $\\Theta(n)$ to $\\tilde{O}(v)$. From a\npractical perspective, we demonstrate that $v$ can be small in practice by\nproving that $v$ is $O(\\log f(n))$ for monotone streams and $o(n)$ for streams\nthat are \"nearly\" monotone or that are generated by random walks. We expect $v$\nto be $o(n)$ for many other interesting input classes as well.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 01:40:48 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Felber", "David", ""], ["Ostrovsky", "Rafail", ""]]}, {"id": "1502.07045", "submitter": "Andrew Francis", "authors": "Andrew R. Francis and Mike Steel", "title": "Which phylogenetic networks are merely trees with additional arcs?", "comments": "The final version of this article will appear in Systematic Biology.\n  20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary phylogenetic network may or may not be obtainable from a tree by the\naddition of directed edges (arcs) between tree arcs. Here, we establish a\nprecise and easily tested criterion (based on `2-SAT') that efficiently\ndetermines whether or not any given network can be realized in this way.\nMoreover, the proof provides a polynomial-time algorithm for finding one or\nmore trees (when they exist) on which the network can be based. A number of\ninteresting consequences are presented as corollaries; these lead to some\nfurther relevant questions and observations, which we outline in the\nconclusion.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 03:58:35 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2015 08:42:21 GMT"}, {"version": "v3", "created": "Thu, 21 May 2015 20:19:00 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Francis", "Andrew R.", ""], ["Steel", "Mike", ""]]}, {"id": "1502.07085", "submitter": "Asghar Asgharian Sardroud", "authors": "Asghar Asgharian Sardroud and Alireza Bagheri", "title": "An approximation algorithm for the longest cycle problem in solid grid\n  graphs", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although, the Hamiltonicity of solid grid graphs are polynomial-time\ndecidable, the complexity of the longest cycle problem in these graphs is still\nopen. In this paper, by presenting a linear-time constant-factor approximation\nalgorithm, we show that the longest cycle problem in solid grid graphs is in\nAPX. More precisely, our algorithm finds a cycle of length at least\n$\\frac{2n}{3}+1$ in 2-connected $n$-node solid grid graphs.\n  Keywords: Longest cycle, Hamiltonian cycle, Approximation algorithm, Solid\ngrid graph.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 08:54:58 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Sardroud", "Asghar Asgharian", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1502.07118", "submitter": "Andreas Holzer", "authors": "Andreas Haas, Thomas A. Henzinger, Andreas Holzer, Christoph M.\n  Kirsch, Michael Lippautz, Hannes Payer, Ali Sezgin, Ana Sokolova, Helmut\n  Veith", "title": "Local Linearizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantics of concurrent data structures is usually given by a sequential\nspecification and a consistency condition. Linearizability is the most popular\nconsistency condition due to its simplicity and general applicability.\nNevertheless, for applications that do not require all guarantees offered by\nlinearizability, recent research has focused on improving performance and\nscalability of concurrent data structures by relaxing their semantics.\n  In this paper, we present local linearizability, a relaxed consistency\ncondition that is applicable to container-type concurrent data structures like\npools, queues, and stacks. While linearizability requires that the effect of\neach operation is observed by all threads at the same time, local\nlinearizability only requires that for each thread T, the effects of its local\ninsertion operations and the effects of those removal operations that remove\nvalues inserted by T are observed by all threads at the same time. We\ninvestigate theoretical and practical properties of local linearizability and\nits relationship to many existing consistency conditions. We present a generic\nimplementation method for locally linearizable data structures that uses\nexisting linearizable data structures as building blocks. Our implementations\nshow performance and scalability improvements over the original building blocks\nand outperform the fastest existing container-type implementations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 10:40:13 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 07:40:31 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2015 05:24:41 GMT"}, {"version": "v4", "created": "Fri, 24 Jun 2016 15:39:28 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Haas", "Andreas", ""], ["Henzinger", "Thomas A.", ""], ["Holzer", "Andreas", ""], ["Kirsch", "Christoph M.", ""], ["Lippautz", "Michael", ""], ["Payer", "Hannes", ""], ["Sezgin", "Ali", ""], ["Sokolova", "Ana", ""], ["Veith", "Helmut", ""]]}, {"id": "1502.07167", "submitter": "George Ovchinnikov", "authors": "I.V. Oseledets, G.V. Ovchinnikov, A. M. Katrutsa", "title": "Linear complexity SimRank computation based on the iterative diagonal\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deterministic linear time complexity IDE-SimRank method\nto approximately compute SimRank with proved error bound. SimRank is a\nwell-known similarity measure between graph vertices which relies on graph\ntopology only and is built on intuition that \"two objects are similar if they\nare related to similar objects\". The fixed point equation for direct SimRank\ncomputation is the discrete Lyapunov equation with specific diagonal matrix in\nthe right hand side. The proposed method is based on estimation of this\ndiagonal matrix with GMRES and use this estimation to compute singe-source and\nsingle pairs queries. These computations are executed with the part of series\nconverging to the discrete Lyapunov equation solution.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 14:08:13 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Oseledets", "I. V.", ""], ["Ovchinnikov", "G. V.", ""], ["Katrutsa", "A. M.", ""]]}, {"id": "1502.07206", "submitter": "Paolo Giulio Franciosa", "authors": "Giorgio Ausiello and Paolo G. Franciosa and Giuseppe F. Italiano and\n  Andrea Ribichini", "title": "Incremental DFS Trees on Arbitrary Directed Graphs", "comments": "The paper has been withdrawn by the authors due to a flaw in the\n  complexity analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for maintaining a DFS tree of an arbitrary\ndirected graph under any sequence of edge insertions. Our algorithm requires a\ntotal of $O(m\\cdot n)$ time in the worst case to process a sequence of edge\ninsertions, where $n$ is the number of vertices in the graph and $m$ is the\ntotal number of edges in the final graph. We also prove lower bounds for\nvariations of this problem.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 15:39:34 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2015 12:33:09 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Ausiello", "Giorgio", ""], ["Franciosa", "Paolo G.", ""], ["Italiano", "Giuseppe F.", ""], ["Ribichini", "Andrea", ""]]}, {"id": "1502.07288", "submitter": "Ananda Theertha Suresh", "authors": "Mehryar Mohri, Michael Riley, Ananda Theertha Suresh", "title": "Automata and Graph Compression", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.FL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical framework for the compression of automata, which are\nwidely used in speech processing and other natural language processing tasks.\nThe framework extends to graph compression. Similar to stationary ergodic\nprocesses, we formulate a probabilistic process of graph and automata\ngeneration that captures real world phenomena and provide a universal\ncompression scheme LZA for this probabilistic model. Further, we show that LZA\nsignificantly outperforms other compression techniques such as gzip and the\nUNIX compress command for several synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 18:30:36 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Mohri", "Mehryar", ""], ["Riley", "Michael", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1502.07406", "submitter": "Yuichi Yoshida", "authors": "Satoru Iwata, Shin-ichi Tanigawa, Yuichi Yoshida", "title": "Improved Approximation Algorithms for k-Submodular Function Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a polynomial-time $1/2$-approximation algorithm for\nmaximizing nonnegative $k$-submodular functions. This improves upon the\nprevious $\\max\\{1/3, 1/(1+a)\\}$-approximation by Ward and\n\\v{Z}ivn\\'y~(SODA'14), where $a=\\max\\{1, \\sqrt{(k-1)/4}\\}$. We also show that\nfor monotone $k$-submodular functions there is a polynomial-time\n$k/(2k-1)$-approximation algorithm while for any $\\varepsilon>0$ a\n$((k+1)/2k+\\varepsilon)$-approximation algorithm for maximizing monotone\n$k$-submodular functions would require exponentially many queries. In\nparticular, our hardness result implies that our algorithms are asymptotically\ntight.\n  We also extend the approach to provide constant factor approximation\nalgorithms for maximizing skew-bisubmodular functions, which were recently\nintroduced as generalizations of bisubmodular functions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 00:09:23 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Iwata", "Satoru", ""], ["Tanigawa", "Shin-ichi", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1502.07467", "submitter": "Thomas Zeume", "authors": "Samir Datta, Raghav Kulkarni, Anish Mukherjee, Thomas Schwentick,\n  Thomas Zeume", "title": "Reachability is in DynFO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patnaik and Immerman introduced the dynamic complexity class DynFO of\ndatabase queries that can be maintained by first-order dynamic programs with\nthe help of auxiliary relations under insertions and deletions of edges\n(Patnaik and Immerman 1997). This article confirms their conjecture that the\nReachability query is in DynFO.\n  As a byproduct it is shown that the rank of a matrix with small values can be\nmaintained in DynFO(+,x). It is further shown that the (size of the) maximum\nmatching of a graph can be maintained in non-uniform DynFO, another extension\nof DynFO, with non-uniform initialisation of the auxiliary relations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:30:57 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 17:54:46 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 07:28:08 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Datta", "Samir", ""], ["Kulkarni", "Raghav", ""], ["Mukherjee", "Anish", ""], ["Schwentick", "Thomas", ""], ["Zeume", "Thomas", ""]]}, {"id": "1502.07576", "submitter": "Hamida Seba", "authors": "Hamida Seba and Sofiane Lagraa and Elsen Ronando", "title": "Comparison Issues in Large Graphs: State of the Art and Future\n  Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph comparison is fundamentally important for many applications such as the\nanalysis of social networks and biological data and has been a significant\nresearch area in the pattern recognition and pattern analysis domains.\nNowadays, the graphs are large, they may have billions of nodes and edges.\nComparison issues in such huge graphs are a challenging research problem.\n  In this paper, we survey the research advances of comparison problems in\nlarge graphs. We review graph comparison and pattern matching approaches that\nfocus on large graphs. We categorize the existing approaches into three\nclasses: partition-based approaches, search space based approaches and summary\nbased approaches. All the existing algorithms in these approaches are described\nin detail and analyzed according to multiple metrics such as time complexity,\ntype of graphs or comparison concept. Finally, we identify directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 14:45:42 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Seba", "Hamida", ""], ["Lagraa", "Sofiane", ""], ["Ronando", "Elsen", ""]]}, {"id": "1502.07659", "submitter": "Ignasi Sau", "authors": "Luis Pedro Montejano and Ignasi Sau", "title": "On the complexity of computing the $k$-restricted edge-connectivity of a\n  graph", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{$k$-restricted edge-connectivity} of a graph $G$, denoted by\n$\\lambda_k(G)$, is defined as the minimum size of an edge set whose removal\nleaves exactly two connected components each containing at least $k$ vertices.\nThis graph invariant, which can be seen as a generalization of a minimum\nedge-cut, has been extensively studied from a combinatorial point of view.\nHowever, very little is known about the complexity of computing $\\lambda_k(G)$.\nVery recently, in the parameterized complexity community the notion of\n\\emph{good edge separation} of a graph has been defined, which happens to be\nessentially the same as the $k$-restricted edge-connectivity. Motivated by the\nrelevance of this invariant from both combinatorial and algorithmic points of\nview, in this article we initiate a systematic study of its computational\ncomplexity, with special emphasis on its parameterized complexity for several\nchoices of the parameters. We provide a number of NP-hardness and W[1]-hardness\nresults, as well as FPT-algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 18:10:43 GMT"}, {"version": "v2", "created": "Sat, 17 Sep 2016 21:18:18 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Montejano", "Luis Pedro", ""], ["Sau", "Ignasi", ""]]}, {"id": "1502.07663", "submitter": "Oren Weimann", "authors": "Pawel Gawrychowski, Shay Mozes, Oren Weimann", "title": "Submatrix Maximum Queries in Monge Matrices are Equivalent to\n  Predecessor Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimal data structure for submatrix maximum queries in n x n\nMonge matrices. Our result is a two-way reduction showing that the problem is\nequivalent to the classical predecessor problem in a universe of polynomial\nsize. This gives a data structure of O(n) space that answers submatrix maximum\nqueries in O(loglogn) time. It also gives a matching lower bound, showing that\nO(loglogn) query-time is optimal for any data structure of size O(n\npolylog(n)). Our result concludes a line of improvements that started in\nSODA'12 with O(log^2 n) query-time and continued in ICALP'14 with O(log n)\nquery-time. Finally, we show that partial Monge matrices can be handled in the\nsame bounds as full Monge matrices. In both previous results, partial Monge\nmatrices incurred additional inverse-Ackerman factors.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 18:22:03 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2015 13:48:47 GMT"}, {"version": "v3", "created": "Mon, 25 Dec 2017 12:07:00 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gawrychowski", "Pawel", ""], ["Mozes", "Shay", ""], ["Weimann", "Oren", ""]]}, {"id": "1502.07725", "submitter": "Meirav Zehavi", "authors": "Meirav Zehavi", "title": "The $k$-Leaf Spanning Tree Problem Admits a Klam Value of 39", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph $G$ and a parameter $k$, the $k$-Leaf Spanning Tree\n($k$-LST) problem asks if $G$ contains a spanning tree with at least $k$\nleaves. This problem has been extensively studied over the past three decades.\nIn 2000, Fellows et al. [FSTTCS'00] explicitly asked whether it admits a klam\nvalue of 50. A steady progress towards an affirmative answer continued until 5\nyears ago, when an algorithm of klam value 37 was discovered. In this paper, we\npresent an $O^*(3.188^k)$-time parameterized algorithm for $k$-LST, which shows\nthat the problem admits a klam value of 39. Our algorithm is based on an\ninteresting application of the well-known bounded search trees technique, where\nthe correctness of rules crucially depends on the history of previously applied\nrules in a non-standard manner.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 20:41:16 GMT"}, {"version": "v2", "created": "Mon, 11 May 2015 13:26:10 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Zehavi", "Meirav", ""]]}, {"id": "1502.07870", "submitter": "Ali Alatabbi", "authors": "Ali Alatabbi, M. Sohel Rahman, W. F. Smyth", "title": "Inferring an Indeterminate String from a Prefix Graph", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": "10.1016/j.jda.2014.12.006", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An \\itbf{indeterminate string} (or, more simply, just a \\itbf{string}) $\\s{x}\n= \\s{x}[1..n]$ on an alphabet $\\Sigma$ is a sequence of nonempty subsets of\n$\\Sigma$. We say that $\\s{x}[i_1]$ and $\\s{x}[i_2]$ \\itbf{match} (written\n$\\s{x}[i_1] \\match \\s{x}[i_2]$) if and only if $\\s{x}[i_1] \\cap \\s{x}[i_2] \\ne\n\\emptyset$. A \\itbf{feasible array} is an array $\\s{y} = \\s{y}[1..n]$ of\nintegers such that $\\s{y}[1] = n$ and for every $i \\in 2..n$, $\\s{y}[i] \\in\n0..n\\- i\\+ 1$. A \\itbf{prefix table} of a string $\\s{x}$ is an array $\\s{\\pi} =\n\\s{\\pi}[1..n]$ of integers such that, for every $i \\in 1..n$, $\\s{\\pi}[i] = j$\nif and only if $\\s{x}[i..i\\+ j\\- 1]$ is the longest substring at position $i$\nof \\s{x} that matches a prefix of \\s{x}. It is known from \\cite{CRSW13} that\nevery feasible array is a prefix table of some indetermintate string. A\n\\itbf{prefix graph} $\\mathcal{P} = \\mathcal{P}_{\\s{y}}$ is a labelled simple\ngraph whose structure is determined by a feasible array \\s{y}. In this paper we\nshow, given a feasible array \\s{y}, how to use $\\mathcal{P}_{\\s{y}}$ to\nconstruct a lexicographically least indeterminate string on a minimum alphabet\nwhose prefix table $\\s{\\pi} = \\s{y}$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 11:59:01 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Alatabbi", "Ali", ""], ["Rahman", "M. Sohel", ""], ["Smyth", "W. F.", ""]]}, {"id": "1502.07888", "submitter": "Henning Meyerhenke", "authors": "Daniel Hoske, Dimitar Lukarski, Henning Meyerhenke, Michael Wegner", "title": "Is Nearly-linear the same in Theory and Practice? A Case Study with a\n  Combinatorial Laplacian Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear system solving is one of the main workhorses in applied mathematics.\nRecently, theoretical computer scientists have contributed sophisticated\nalgorithms for solving linear systems with symmetric diagonally dominant\nmatrices (a class to which Laplacian matrices belong) in provably nearly-linear\ntime. While these algorithms are highly interesting from a theoretical\nperspective, there are no published results how they perform in practice.\n  With this paper we address this gap. We provide the first implementation of\nthe combinatorial solver by [Kelner et al., STOC 2013], which is particularly\nappealing for implementation due to its conceptual simplicity. The algorithm\nexploits that a Laplacian matrix corresponds to a graph; solving Laplacian\nlinear systems amounts to finding an electrical flow in this graph with the\nhelp of cycles induced by a spanning tree with the low-stretch property.\n  The results of our comprehensive experimental study are ambivalent. They\nconfirm a nearly-linear running time, but for reasonable inputs the constant\nfactors make the solver much slower than methods with higher asymptotic\ncomplexity. One other aspect predicted by theory is confirmed by our findings,\nthough: Spanning trees with lower stretch indeed reduce the solver's running\ntime. Yet, simple spanning tree algorithms perform in practice better than\nthose with a guaranteed low stretch.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 13:23:27 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Hoske", "Daniel", ""], ["Lukarski", "Dimitar", ""], ["Meyerhenke", "Henning", ""], ["Wegner", "Michael", ""]]}, {"id": "1502.07930", "submitter": "Vangelis Paschos", "authors": "Vangelis Th. Paschos", "title": "Combinatorial approximation of maximum $k$-vertex cover in bipartite\n  graphs within ratio~0.7", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a \\textit{purely combinatorial algorithm} for \\mkvc{} in bipartite\ngraphs, achieving approximation ratio~0.7. The only combinatorial algorithms\ncurrently known until now for this problem are the natural greedy algorithm,\nthat achieves ratio 0.632, and an easy~$2/3$-approximation algorithm presented\nin \\cite{DBLP:journals/corr/BonnetEPS14}.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 15:19:46 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2015 11:13:29 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Paschos", "Vangelis Th.", ""]]}]