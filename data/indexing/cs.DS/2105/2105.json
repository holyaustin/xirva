[{"id": "2105.00057", "submitter": "Christian Kehl", "authors": "Christian Kehl and Erik van Sebille and Angus Gibson", "title": "Speeding up Python-based Lagrangian Fluid-Flow Particle Simulations via\n  Dynamic Collection Data Structures", "comments": "submitted for review in SIAM Journal on Scientific Computing on\n  2021-01-25", "journal-ref": null, "doi": null, "report-no": "M139395", "categories": "physics.comp-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Array-like collection data structures are widely established in Python's\nscientific computing-ecosystem for high-performance computations. The structure\nmaps well to regular, gridded lattice structures that are common to\ncomputational problems in physics and geosciences. High performance is,\nhowever, only guaranteed for static computations with a fixed computational\ndomain. We show that for dynamic computations within an actively changing\ncomputational domain, the array-like collections provided by NumPy and its\nderivatives are a bottleneck for large computations. In response, we describe\nthe integration of naturally-dynamic collection data structures (e.g.\ndouble-linked lists) into NumPy simulations and \\textit{ctypes}-based\nC-bindings. Our benchmarks verify and quantify the performance increase\nattributed to the change of the collection data structure. Our application\nscenario, a Lagrangian (oceanic) fluid-flow particle simulation within the\n\\textit{Parcels} framework, demonstrates the speed-up yield in a realistic\nsetting and demonstrates the novel capabilities that are facilitated by\noptimised collection data structures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 19:43:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kehl", "Christian", ""], ["van Sebille", "Erik", ""], ["Gibson", "Angus", ""]]}, {"id": "2105.00110", "submitter": "Paul Burkhardt", "authors": "Paul Burkhardt", "title": "Triangle Centrality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangle centrality is introduced for finding important vertices in a graph\nbased on the concentration of triangles surrounding each vertex. An important\nvertex in triangle centrality is at the center of many triangles, and therefore\nit may be in many triangles or none at all.\n  We give optimal algorithms that compute triangle centrality in $O(m^{3/2})$\ntime and $O(m+n)$ space. Using fast matrix multiplication it takes\n$n^{\\omega+o(1)}$ time where $\\omega$ is the matrix product exponent.\n  On a Concurrent Read Exclusive Write (CREW) Parallel Random Access Memory\n(PRAM) machine, we give a near work-optimal algorithm that takes $O(\\log n)$\ntime using $O(m\\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes\nfour rounds using $O(m\\sqrt{m})$ communication bits, and is therefore optimal.\n  We also give a deterministic algorithm to find the triangle neighborhood and\ntriangle count of each vertex in $O(m\\sqrt{m})$ time and $O(m+n)$ space. It can\nbe also easily be computed in $O(m\\bar\\delta(G))$ expected time, where\n$\\bar\\delta(G)$ is the average graph degeneracy and is related to the\narboricity. We leave it as an open problem to deterministically compute\ntriangle neighbors in $O(m\\bar\\delta(G))$ time and $O(m+n)$ space.\n  Our empirical results demonstrate that triangle centrality uniquely\nidentified central vertices thirty-percent of the time in comparison to five\nother well-known centrality measures, while being asymptotically faster to\ncompute on sparse graphs than all but the most trivial of these other measures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 22:29:10 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Burkhardt", "Paul", ""]]}, {"id": "2105.00111", "submitter": "Sai Sandeep", "authors": "Sami Davies, Janardhan Kulkarni, Thomas Rothvoss, Sai Sandeep, Jakub\n  Tarnawski, Yihao Zhang", "title": "On the Hardness of Scheduling With Non-Uniform Communication Delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the scheduling with non-uniform communication delay problem, the input is\na set of jobs with precedence constraints. Associated with every precedence\nconstraint between a pair of jobs is a communication delay, the time duration\nthe scheduler has to wait between the two jobs if they are scheduled on\ndifferent machines. The objective is to assign the jobs to machines to minimize\nthe makespan of the schedule. Despite being a fundamental problem in theory and\na consequential problem in practice, the approximability of scheduling problems\nwith communication delays is not very well understood. One of the top ten open\nproblems in scheduling theory, in the influential list by Schuurman and\nWoeginger and its latest update by Bansal, asks if the problem admits a\nconstant factor approximation algorithm. In this paper, we answer the question\nin negative by proving that there is a logarithmic hardness for the problem\nunder the standard complexity theory assumption that NP-complete problems do\nnot admit quasi-polynomial time algorithms.\n  Our hardness result is obtained using a surprisingly simple reduction from a\nproblem that we call Unique Machine Precedence constraints Scheduling (UMPS).\nWe believe that this problem is of central importance in understanding the\nhardness of many scheduling problems and conjecture that it is very hard to\napproximate. Among other things, our conjecture implies a logarithmic hardness\nof related machine scheduling with precedences, a long-standing open problem in\nscheduling theory and approximation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 22:29:53 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Davies", "Sami", ""], ["Kulkarni", "Janardhan", ""], ["Rothvoss", "Thomas", ""], ["Sandeep", "Sai", ""], ["Tarnawski", "Jakub", ""], ["Zhang", "Yihao", ""]]}, {"id": "2105.00254", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Anders Yeo", "title": "Perfect Forests in Graphs and Their Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $G$ be a graph on $n$ vertices. For $i\\in \\{0,1\\}$ and a connected graph\n$G$, a spanning forest $F$ of $G$ is called an $i$-perfect forest if every tree\nin $F$ is an induced subgraph of $G$ and exactly $i$ vertices of $F$ have even\ndegree (including zero). A $i$-perfect forest of $G$ is proper if it has no\nvertices of degree zero. Scott (2001) showed that every connected graph with\neven number of vertices contains a (proper) 0-perfect forest. We prove that one\ncan find a 0-perfect forest with minimum number of edges in polynomial time,\nbut it is NP-hard to obtain a 0-perfect forest with maximum number of edges.\nMoreover, we show that to decide whether $G$ has a 0-perfect forest with at\nleast $|V(G)|/2+k$ edges, where $k$ is the parameter, is W[1]-hard. We also\nprove that for a prescribed edge $e$ of $G,$ it is NP-hard to obtain a\n0-perfect forest containing $e,$ but one can decide if there existsa 0-perfect\nforest not containing $e$ in polynomial time. It is easy to see that every\ngraph with odd number of vertices has a 1-perfect forest. It is not the case\nfor proper 1-perfect forests. We give a characterization of when a connected\ngraph has a proper 1-perfect forest.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 14:06:36 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:53:05 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gutin", "Gregory", ""], ["Yeo", "Anders", ""]]}, {"id": "2105.00299", "submitter": "Jesse Racicot", "authors": "Hovhannes Harutyunyan, Denis Pankratov, Jesse Racicot", "title": "Online Domination: The Value of Getting to Know All your Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the dominating set problem in an online setting. An algorithm is\nrequired to guarantee competitiveness against an adversary that reveals the\ninput graph one node at a time. When a node is revealed, the algorithm learns\nabout the entire neighborhood of the node (including those nodes that have not\nyet been revealed). Furthermore, the adversary is required to keep the revealed\nportion of the graph connected at all times. We present an algorithm that\nachieves 2-competitiveness on trees and prove that this competitive ratio\ncannot be improved by any other algorithm. We also present algorithms that\nachieve 2.5-competitiveness on cactus graphs, $(t-1)$-competitiveness on\n$K_{1,t}$-free graphs, and $\\Theta(\\sqrt{\\Delta})$ for maximum degree $\\Delta$\ngraphs. We show that all of those competitive ratios are tight. Then, we study\nseveral more general classes of graphs, such as threshold, bipartite planar,\nand series-parallel graphs, and show that they do not admit competitive\nalgorithms (that is, when competitive ratio is independent of the input size).\nPreviously, the dominating set problem was considered in a slightly different\ninput model, where a vertex is revealed alongside its restricted neighborhood:\nthose neighbors that are among already revealed vertices. Thus, conceptually,\nour results quantify the value of knowing the entire neighborhood at the time a\nvertex is revealed as compared to the restricted neighborhood. For instance, it\nwas known in the restricted neighborhood model that 3-competitiveness is\noptimal for trees, whereas knowing the neighbors allows us to improve it to\n2-competitiveness.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 16:41:43 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Harutyunyan", "Hovhannes", ""], ["Pankratov", "Denis", ""], ["Racicot", "Jesse", ""]]}, {"id": "2105.00419", "submitter": "Scott Freitas", "authors": "Scott Freitas, Diyi Yang, Srijan Kumar, Hanghang Tong, Duen Horng Chau", "title": "Graph Vulnerability and Robustness: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of network robustness is a critical tool in the characterization\nand sense making of complex interconnected systems such as infrastructure,\ncommunication and social networks. While significant research has been\nconducted in all of these areas, gaps in the surveying literature still exist.\nAnswers to key questions are currently scattered across multiple scientific\nfields and numerous papers. In this survey, we distill key findings across\nnumerous domains and provide researchers crucial access to important\ninformation by--(1) summarizing and comparing recent and classical graph\nrobustness measures; (2) exploring which robustness measures are most\napplicable to different categories of networks (e.g., social, infrastructure;\n(3) reviewing common network attack strategies, and summarizing which attacks\nare most effective across different network topologies; and (4) extensive\ndiscussion on selecting defense techniques to mitigate attacks across a variety\nof networks. This survey guides researchers and practitioners in navigating the\nexpansive field of network robustness, while summarizing answers to key\nquestions. We conclude by highlighting current research directions and open\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 08:38:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Freitas", "Scott", ""], ["Yang", "Diyi", ""], ["Kumar", "Srijan", ""], ["Tong", "Hanghang", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2105.00524", "submitter": "James Stewart", "authors": "Andreas Galanis, Leslie Ann Goldberg, James Stewart", "title": "Fast mixing via polymers for random graphs with unbounded degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polymer model framework is a classical tool from statistical mechanics\nthat has recently been used to obtain approximation algorithms for spin systems\non classes of bounded-degree graphs; examples include the ferromagnetic Potts\nmodel on expanders and on the grid. One of the key ingredients in the analysis\nof polymer models is controlling the growth rate of the number of polymers,\nwhich has been typically achieved so far by invoking the bounded-degree\nassumption. Nevertheless, this assumption is often restrictive and obstructs\nthe applicability of the method to more general graphs. For example, sparse\nrandom graphs typically have bounded average degree and good expansion\nproperties, but they include vertices with unbounded degree, and therefore are\nexcluded from the current polymer-model framework.\n  We develop a less restrictive framework for polymer models that relaxes the\nstandard bounded-degree assumption, by reworking the relevant polymer models\nfrom the edge perspective. The edge perspective allows us to bound the growth\nrate of the number of polymers in terms of the total degree of polymers, which\nin turn can be related more easily to the expansion properties of the\nunderlying graph. To apply our methods, we consider random graphs with\nunbounded degrees from a fixed degree sequence (with minimum degree at least 3)\nand obtain approximation algorithms for the ferromagnetic Potts model, which is\na standard benchmark for polymer models. Our techniques also extend to more\ngeneral spin systems.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 18:09:27 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 19:46:36 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Stewart", "James", ""]]}, {"id": "2105.00639", "submitter": "Arnab Bhattacharyya", "authors": "A. Pavan and N.V. Vinodchandran and Arnab Bhattacharyya and Kuldeep S.\n  Meel", "title": "Model Counting meets F0 Estimation", "comments": "Appears in PODS '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constraint satisfaction problems (CSP's) and data stream models are two\npowerful abstractions to capture a wide variety of problems arising in\ndifferent domains of computer science. Developments in the two communities have\nmostly occurred independently and with little interaction between them. In this\nwork, we seek to investigate whether bridging the seeming communication gap\nbetween the two communities may pave the way to richer fundamental insights. To\nthis end, we focus on two foundational problems: model counting for CSP's and\ncomputation of zeroth frequency moments ($F_0$) for data streams.\n  Our investigations lead us to observe striking similarity in the core\ntechniques employed in the algorithmic frameworks that have evolved separately\nfor model counting and $F_0$ computation. We design a recipe for translation of\nalgorithms developed for $F_0$ estimation to that of model counting, resulting\nin new algorithms for model counting. We then observe that algorithms in the\ncontext of distributed streaming can be transformed to distributed algorithms\nfor model counting. We next turn our attention to viewing streaming from the\nlens of counting and show that framing $F_0$ estimation as a special case of\n#DNF counting allows us to obtain a general recipe for a rich class of\nstreaming problems, which had been subjected to case-specific analysis in prior\nworks. In particular, our view yields a state-of-the art algorithm for\nmultidimensional range efficient $F_0$ estimation with a simpler analysis.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:14:14 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Pavan", "A.", ""], ["Vinodchandran", "N. V.", ""], ["Bhattacharyya", "Arnab", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2105.00656", "submitter": "Shankar Sastry", "authors": "Shankar P Sastry", "title": "A 3D Advancing-Front Delaunay Mesh Refinement Algorithm", "comments": "28 pages, 13 figures; submitted to Computational Geometry: Theory and\n  Application", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  I present a 3D advancing-front mesh refinement algorithm that generates a\nconstrained Delaunay mesh for any piecewise linear complex (PLC) and extend\nthis algorithm to produce truly Delaunay meshes for any PLC. First, as in my\nrecently published 2D algorithm, I split the input line segments such that the\nlength of the subsegments is asymptotically proportional to the local feature\nsize (LFS). For each facet, I refine the mesh such that the edge lengths and\nthe radius of the circumcircle of every triangular element are asymptotically\nproportional to the LFS. Finally, I refine the volume mesh to produce a\nconstrained Delaunay mesh whose tetrahedral elements are well graded and have a\nradius-edge ratio less than some $\\omega^* > 2/\\sqrt{3}$ (except ``near'' small\ninput angles). I extend this algorithm to generate truly Delaunay meshes by\nensuring that every triangular element on a facet satisfies Gabriel's\ncondition, i.e., its diametral sphere is empty. On an ``apex'' vertex where\nmultiple facets intersect, Gabriel's condition is satisfied by a modified\nsplit-on-a-sphere (SOS) technique. On a line where multiple facets intersect,\nGabriel's condition is satisfied by mirroring meshes near the line of\nintersection. The SOS technique ensures that the triangles on a facet near the\napex vertex have angles that are proportional to the angular feature size\n(AFS), a term I define in the paper. All tetrahedra (except ``near'' small\ninput angles) are well graded and have a radius-edge ratio less than $\\omega^*\n> \\sqrt{2}$ for a truly Delaunay mesh. The upper bounds for the radius-edge\nratio are an improvement by a factor of $\\sqrt{2}$ over current\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 07:13:46 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sastry", "Shankar P", ""]]}, {"id": "2105.00759", "submitter": "Yonatan Nakar", "authors": "Yonatan Nakar and Dana Ron", "title": "Testing Dynamic Environments: Back to Basics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We continue the line of work initiated by Goldreich and Ron (Journal of the\nACM, 2017) on testing dynamic environments and propose to pursue a systematic\nstudy of the complexity of testing basic dynamic environments and local rules.\nAs a first step, in this work we focus on dynamic environments that correspond\nto elementary cellular automata that evolve according to threshold rules.\n  Our main result is the identification of a set of conditions on local rules,\nand a meta-algorithm that tests evolution according to local rules that satisfy\nthe conditions. The meta-algorithm has query complexity poly$ (1/\\epsilon) $,\nis non-adaptive and has one-sided error. We show that all the threshold rules\nsatisfy the set of conditions, and therefore are poly$ (1/\\epsilon) $-testable.\nWe believe that this is a rich area of research and suggest a variety of open\nproblems and natural research directions that may extend and expand our\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:27:03 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 15:35:05 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nakar", "Yonatan", ""], ["Ron", "Dana", ""]]}, {"id": "2105.00857", "submitter": "Dimitrios Thilikos", "authors": "Eun Jung Kim and Euiwoong Lee and Dimitrios M. Thilikos", "title": "A Constant-factor Approximation for Weighted Bond Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The {\\sc Weighted} $\\mathcal{F}$-\\textsc{Vertex Deletion} for a class ${\\cal\nF}$ of graphs asks, weighted graph $G$, for a minimum weight vertex set $S$\nsuch that $G-S\\in{\\cal F}.$ The case when ${\\cal F}$ is minor-closed and\nexcludes some graph as a minor has received particular attention but a\nconstant-factor approximation remained elusive for \\textsc{Weighted}\n$\\mathcal{F}$-{\\sc Vertex Deletion}. Only three cases of minor-closed ${\\cal\nF}$ are known to admit constant-factor approximations, namely \\textsc{Vertex\nCover}, \\textsc{Feedback Vertex Set} and \\textsc{Diamond Hitting Set}. We study\nthe problem for the class ${\\cal F}$ of $\\theta_c$-minor-free graphs, under the\nequivalent setting of the \\textsc{Weighted $c$-Bond Cover} problem, and present\na constant-factor approximation algorithm using the primal-dual method. For\nthis, we leverage a structure theorem implicit in [Joret et al., SIDMA'14]\nwhich states the following: any graph $G$ containing a $\\theta_c$-minor-model\neither contains a large two-terminal {\\sl protrusion}, or contains a\nconstant-size $\\theta_c$-minor-model, or a collection of pairwise disjoint {\\sl\nconstant-sized} connected sets that can be contracted simultaneously to yield a\ndense graph. In the first case, we tame the graph by replacing the protrusion\nwith a special-purpose weighted gadget. For the second and third case, we\nprovide a weighting scheme which guarantees a local approximation ratio.\nBesides making an important step in the quest of (dis)proving a constant-factor\napproximation for \\textsc{Weighted} $\\mathcal{F}$-\\textsc{Vertex Deletion}, our\nresult may be useful as a template for algorithms for other minor-closed\nfamilies.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:42:53 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kim", "Eun Jung", ""], ["Lee", "Euiwoong", ""], ["Thilikos", "Dimitrios M.", ""]]}, {"id": "2105.00882", "submitter": "Yaron Fairstein", "authors": "Yaron Fairstein, Ariel Kulik, Joseph (Seffi) Naor, Danny Raz", "title": "General Knapsack Problems in a Dynamic Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is dynamic and changes over time, thus any optimization problems\nused to model real life problems must address this dynamic nature. Otherwise,\nignoring the dynamicity of the problem will result in locally optimal solutions\non the one hand, but inadequate on the other hand. The multistage model was\nintroduced with this goal in mind. In the multistage model we are given a\nseries of instance of an optimization problem, and a solution is provided for\neach instance. The strive for continuous and similar solutions over time are\nquantified and integrated into the objective function. In this paper we\nconsider the Generalized Multistage $d$-Knapsack problem, a generalization of\nthe multistage variants of the Multiple Knapsack problem as well as the\n$d$-Dimensional Knapsack problem. We present a PTAS for Generalized Multistage\n$d$-Knapsack.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 14:08:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fairstein", "Yaron", "", "Seffi"], ["Kulik", "Ariel", "", "Seffi"], ["Joseph", "", "", "Seffi"], ["Naor", "", ""], ["Raz", "Danny", ""]]}, {"id": "2105.01138", "submitter": "Tigran Tonoyan", "authors": "Keren Censor-Hillel and Noa Marelly and Roy Schwartz and Tigran\n  Tonoyan", "title": "Fault Tolerant Max-Cut", "comments": "29 pages, 4 figures, conference: ICALP '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we initiate the study of fault tolerant Max Cut, where given an\nedge-weighted undirected graph $G=(V,E)$, the goal is to find a cut $S\\subseteq\nV$ that maximizes the total weight of edges that cross $S$ even after an\nadversary removes $k$ vertices from $G$. We consider two types of adversaries:\nan adaptive adversary that sees the outcome of the random coin tosses used by\nthe algorithm, and an oblivious adversary that does not. For any constant\nnumber of failures $k$ we present an approximation of $(0.878-\\epsilon)$\nagainst an adaptive adversary and of $\\alpha_{GW}\\approx 0.8786$ against an\noblivious adversary (here $\\alpha_{GW}$ is the approximation achieved by the\nrandom hyperplane algorithm of [Goemans-Williamson J. ACM `95]). Additionally,\nwe present a hardness of approximation of $\\alpha_{GW}$ against both types of\nadversaries, rendering our results (virtually) tight.\n  The non-linear nature of the fault tolerant objective makes the design and\nanalysis of algorithms harder when compared to the classic Max Cut. Hence, we\nemploy approaches ranging from multi-objective optimization to LP duality and\nthe ellipsoid algorithm to obtain our results.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 19:35:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Marelly", "Noa", ""], ["Schwartz", "Roy", ""], ["Tonoyan", "Tigran", ""]]}, {"id": "2105.01149", "submitter": "Akhil Jalan", "authors": "Akhil Jalan, Dana Moshkovitz", "title": "Near-Optimal Cayley Expanders for Abelian Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We give an efficient deterministic algorithm that outputs an expanding\ngenerating set for any finite abelian group. The size of the generating set is\nclose to the randomized construction of Alon and Roichman (1994), improving\nupon various deterministic constructions in both the dependence on the\ndimension and the spectral gap. By obtaining optimal dependence on the\ndimension we resolve a conjecture of Azar, Motwani, and Naor (1998) in the\naffirmative. Our technique is an extension of the bias amplification technique\nof Ta-Shma (2017), who used random walks on expanders to obtain expanding\ngenerating sets over the additive group of n-bit strings. As a consequence, we\nobtain (i) randomness-efficient constructions of almost k-wise independent\nvariables, (ii) a faster deterministic algorithm for the Remote Point Problem,\n(iii) randomness-efficient low-degree tests, and (iv) randomness-efficient\nverification of matrix multiplication.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 20:07:03 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jalan", "Akhil", ""], ["Moshkovitz", "Dana", ""]]}, {"id": "2105.01193", "submitter": "Mehdi Soleimanifar", "authors": "Anurag Anshu, David Gosset, Karen J. Morenz Korol, Mehdi Soleimanifar", "title": "Improved approximation algorithms for bounded-degree local Hamiltonians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of approximating the ground state energy of two-local\nquantum Hamiltonians on bounded-degree graphs. Most existing algorithms\noptimize the energy over the set of product states. Here we describe a family\nof shallow quantum circuits that can be used to improve the approximation ratio\nachieved by a given product state. The algorithm takes as input an $n$-qubit\nproduct state $|v\\rangle$ with mean energy $e_0=\\langle v|H|v\\rangle$ and\nvariance $\\mathrm{Var}=\\langle v|(H-e_0)^2|v\\rangle$, and outputs a state with\nan energy that is lower than $e_0$ by an amount proportional to\n$\\mathrm{Var}^2/n$. In a typical case, we have $\\mathrm{Var}=\\Omega(n)$ and the\nenergy improvement is proportional to the number of edges in the graph. When\napplied to an initial random product state, we recover and generalize the\nperformance guarantees of known algorithms for bounded-occurrence classical\nconstraint satisfaction problems. We extend our results to $k$-local\nHamiltonians and entangled initial states.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:23:47 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Anshu", "Anurag", ""], ["Gosset", "David", ""], ["Korol", "Karen J. Morenz", ""], ["Soleimanifar", "Mehdi", ""]]}, {"id": "2105.01201", "submitter": "Vishesh Jain", "authors": "Vishesh Jain, Huy Tuan Pham, Thuy Duong Vuong", "title": "Spectral independence, coupling with the stationary distribution, and\n  the spectral gap of the Glauber dynamics", "comments": "18 pages; comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new lower bound on the spectral gap of the Glauber dynamics for\nthe Gibbs distribution of a spectrally independent $q$-spin system on a graph\n$G = (V,E)$ with maximum degree $\\Delta$. Notably, for several interesting\nexamples, our bound covers the entire regime of $\\Delta$ excluded by arguments\nbased on coupling with the stationary distribution. As concrete applications,\nby combining our new lower bound with known spectral independence computations\nand known coupling arguments:\n  (1) We show that for a triangle-free graph $G = (V,E)$ with maximum degree\n$\\Delta \\geq 3$, the Glauber dynamics for the uniform distribution on proper\n$k$-colorings with $k \\geq (1.763\\dots + \\delta)\\Delta$ colors has spectral gap\n$\\tilde{\\Omega}_{\\delta}(|V|^{-1})$. Previously, such a result was known either\nif the girth of $G$ is at least $5$ [Dyer et.~al, FOCS 2004], or under\nrestrictions on $\\Delta$ [Chen et.~al, STOC 2021; Hayes-Vigoda, FOCS 2003].\n  (2) We show that for a regular graph $G = (V,E)$ with degree $\\Delta \\geq 3$\nand girth at least $6$, and for any $\\varepsilon, \\delta > 0$, the partition\nfunction of the hardcore model with fugacity $\\lambda \\leq\n(1-\\delta)\\lambda_{c}(\\Delta)$ may be approximated within a\n$(1+\\varepsilon)$-multiplicative factor in time\n$\\tilde{O}_{\\delta}(n^{2}\\varepsilon^{-2})$. Previously, such a result was\nknown if the girth is at least $7$ [Efthymiou et.~al, SICOMP 2019].\n  (3) We show for the binomial random graph $G(n,d/n)$ with $d = O(1)$, with\nhigh probability, an approximately uniformly random matching may be sampled in\ntime $O_{d}(n^{2+o(1)})$. This improves the corresponding running time of\n$\\tilde{O}_{d}(n^{3})$ due to [Jerrum-Sinclair, SICOMP 1989; Jerrum, 2003].\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:39:36 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jain", "Vishesh", ""], ["Pham", "Huy Tuan", ""], ["Vuong", "Thuy Duong", ""]]}, {"id": "2105.01265", "submitter": "Adrian Dumitrescu", "authors": "Adrian Dumitrescu", "title": "Finding Triangles or Independent Sets", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (I) We revisit the algorithmic problem of finding all triangles in a graph\n  $G=(V,E)$ with $n$ vertices and $m$ edges. According to a result of Chiba and\nNishizeki (1985), this task can be achieved by a combinatorial algorithm\nrunning in $O(m^{3/2})$ time. We derive this worst-case bound from first\nprinciples and with a simple proof. We then provide a combinatorial algorithm\nfor finding all triangles in a graph and show that is amenable to the same\nrunning time analysis. We also show that the running time of such an algorithm\ncannot be improved in the worst-case and for the entire range of parameters $m$\nand $n$. Our arguments are extended to the problem of finding all small\ncomplete subgraphs of a given fixed size.\n  (II) Given a graph $G=(V,E)$ with $n$ vertices and $m$ edges, we present a\nrandomized algorithm that computes a $(1 \\pm \\varepsilon)$-approximation of the\nnumber of triangles in $G$ and finds a witness with high probability in\n$O\\left( n^{\\omega(1-\\delta)} \\right)$ or $O \\left( \\left( m n^{-2\\delta}\n\\right)^{\\frac{2\\omega}{\\omega+1}} \\right)$ expected time, provided $G$ has a\nsuitable superlinear number of edges and triangles (where $\\omega < 2.376$ is\nthe exponent of matrix multiplication, and $\\varepsilon \\leq 0.5$, $\\delta \\leq\n0.25$ are positive constants). This limits the range of a conjecture of\nP\\v{a}tra\\c{s}cu (2010) regarding the triangle detection problem.\n  (III) We present an algorithm which given a graph $G=(V,E)$ performs one of\nthe following tasks in $O(m+n)$ (i.e., linear) time: (i) compute a\n$\\Omega(1/\\sqrt{n})$-approximation of a maximum independent set in $G$ (a\nwell-known NP-hard problem), or (ii) find a triangle in $G$. The run-time is\nfaster than that for any previous method for each of these tasks. A series of\ntrade-off results is also available.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:11:37 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Dumitrescu", "Adrian", ""]]}, {"id": "2105.01413", "submitter": "Lars Jaffke", "authors": "Lars Jaffke, O-joung Kwon, Jan Arne Telle", "title": "Classes of intersection digraphs with good algorithmic properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intersection digraph is a digraph where every vertex $v$ is represented by\nan ordered pair $(S_v, T_v)$ of sets such that there is an edge from $v$ to $w$\nif and only if $S_v$ and $T_w$ intersect. An intersection digraph is reflexive\nif $S_v\\cap T_v\\neq \\emptyset$ for every vertex $v$. Compared to well-known\nundirected intersection graphs like interval graphs and permutation graphs, not\nmany algorithmic applications on intersection digraphs have been developed.\nMotivated by the successful story on algorithmic applications of intersection\ngraphs using a graph width parameter called mim-width, we introduce its\ndirected analogue called `bi-mim-width' and prove that various classes of\nreflexive intersection digraphs have bounded bi-mim-width. In particular, we\nshow that as a natural extension of $H$-graphs, reflexive $H$-digraphs have\nlinear bi-mim-width at most $12|E(H)|$, which extends a bound on the linear\nmim-width of $H$-graphs [On the Tractability of Optimization Problems on\n$H$-Graphs. Algorithmica 2020]. For applications, we introduce a novel\nframework of directed versions of locally checkable problems, that streamlines\nthe definitions and the study of many problems in the literature and\nfacilitates their common algorithmic treatment. We obtain unified\npolynomial-time algorithms for these problems on digraphs of bounded\nbi-mim-width, when a branch decomposition is given. Locally checkable problems\ninclude Kernel, Dominating Set, and Directed $H$-Homomorphism.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:59:39 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jaffke", "Lars", ""], ["Kwon", "O-joung", ""], ["Telle", "Jan Arne", ""]]}, {"id": "2105.01465", "submitter": "Karol W\\k{e}grzycki", "authors": "Jesper Nederlof, Micha{\\l} Pilipczuk, C\\'eline M. F. Swennenhuis,\n  Karol W\\k{e}grzycki", "title": "Isolation schemes for problems on decomposable graphs", "comments": "54 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isolation Lemma of Mulmuley, Vazirani and Vazirani [Combinatorica'87]\nprovides a self-reduction scheme that allows one to assume that a given\ninstance of a problem has a unique solution, provided a solution exists at all.\nSince its introduction, much effort has been dedicated towards derandomization\nof the Isolation Lemma for specific classes of problems. So far, the focus was\nmainly on problems solvable in polynomial time.\n  In this paper, we study a setting that is more typical for\n$\\mathsf{NP}$-complete problems, and obtain partial derandomizations in the\nform of significantly decreasing the number of required random bits. In\nparticular, motivated by the advances in parameterized algorithms, we focus on\nproblems on decomposable graphs. For example, for the problem of detecting a\nHamiltonian cycle, we build upon the rank-based approach from [Bodlaender et\nal., Inf. Comput.'15] and design isolation schemes that use\n  - $O(t\\log n + \\log^2{n})$ random bits on graphs of treewidth at most $t$;\n  - $O(\\sqrt{n})$ random bits on planar or $H$-minor free graphs; and\n  - $O(n)$-random bits on general graphs.\n  In all these schemes, the weights are bounded exponentially in the number of\nrandom bits used. As a corollary, for every fixed $H$ we obtain an algorithm\nfor detecting a Hamiltonian cycle in an $H$-minor-free graph that runs in\ndeterministic time $2^{O(\\sqrt{n})}$ and uses polynomial space; this is the\nfirst algorithm to achieve such complexity guarantees. For problems of more\nlocal nature, such as finding an independent set of maximum size, we obtain\nisolation schemes on graphs of treedepth at most $d$ that use $O(d)$ random\nbits and assign polynomially-bounded weights.\n  We also complement our findings with several unconditional and conditional\nlower bounds, which show that many of the results cannot be significantly\nimproved.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:46:51 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nederlof", "Jesper", ""], ["Pilipczuk", "Micha\u0142", ""], ["Swennenhuis", "C\u00e9line M. F.", ""], ["W\u0119grzycki", "Karol", ""]]}, {"id": "2105.01485", "submitter": "Ruslan Sharipov", "authors": "Ruslan Sharipov", "title": "Hadamard matrices in $\\{0,1\\}$ presentation and an algorithm for\n  generating them", "comments": "AmSTeX, 12 pages, amsppt style", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadamard matrices are square $n\\times n$ matrices whose entries are ones and\nminus ones and whose rows are orthogonal to each other with respect to the\nstandard scalar product in $\\Bbb R^n$. Each Hadamard matrix can be transformed\nto a matrix whose entries are zeros and ones. This presentation of Hadamard\nmatrices is investigated in the paper and based on it an algorithm for\ngenerating them is designed.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 13:23:13 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Sharipov", "Ruslan", ""]]}, {"id": "2105.01582", "submitter": "Ignasi Sau", "authors": "St\\'ephane Bessy, Florian H\\\"orsch, Ana Karolinna Maia, Dieter\n  Rautenbach, Ignasi Sau", "title": "FPT algorithms for packing $k$-safe spanning rooted sub(di)graphs", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three problems introduced by Bang-Jensen and Yeo [Theor. Comput.\nSci. 2015] and by Bang-Jensen, Havet, and Yeo [Discret. Appl. Math. 2016] about\nfinding disjoint \"balanced\" spanning rooted substructures in graphs and\ndigraphs, which generalize classic packing problems. Namely, given a positive\ninteger $k$, a digraph $D=(V,A)$, and a root $r \\in V$, we consider the problem\nof finding two arc-disjoint $k$-safe spanning $r$-arborescences and the problem\nof finding two arc-disjoint $(r,k)$-flow branchings. We show that both these\nproblems are FPT with parameter $k$, improving on existing XP algorithms. The\nlatter of these results answers a question of Bang-Jensen, Havet, and Yeo\n[Discret. Appl. Math. 2016]. Further, given an integer $k$, a graph $G=(V,E)$,\nand $r \\in V$, we consider the problem of finding two arc-disjoint $(r,k)$-safe\nspanning trees. We show that this problem is also FPT with parameter $k$, again\nimproving on a previous XP algorithm. Our main technical contribution is to\nprove that the existence of such spanning substructures is equivalent to the\nexistence of substructures with size and maximum (out-)degree both bounded by a\n(linear or quadratic) function of $k$, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 15:47:44 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bessy", "St\u00e9phane", ""], ["H\u00f6rsch", "Florian", ""], ["Maia", "Ana Karolinna", ""], ["Rautenbach", "Dieter", ""], ["Sau", "Ignasi", ""]]}, {"id": "2105.01615", "submitter": "Sayan Bhattacharya", "authors": "Sayan Bhattacharya and Peter Kiss", "title": "Deterministic Rounding of Dynamic Fractional Matchings", "comments": "An extended abstract of this paper will appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a framework for deterministically rounding a dynamic fractional\nmatching. Applying our framework in a black-box manner on top of existing\nfractional matching algorithms, we derive the following new results: (1) The\nfirst deterministic algorithm for maintaining a $(2-\\delta)$-approximate\nmaximum matching in a fully dynamic bipartite graph, in arbitrarily small\npolynomial update time. (2) The first deterministic algorithm for maintaining a\n$(1+\\delta)$-approximate maximum matching in a decremental bipartite graph, in\npolylogarithmic update time. (3) The first deterministic algorithm for\nmaintaining a $(2+\\delta)$-approximate maximum matching in a fully dynamic\ngeneral graph, in small polylogarithmic (specifically, $O(\\log^4 n)$) update\ntime. These results are respectively obtained by applying our framework on top\nof the fractional matching algorithms of Bhattacharya et al. [STOC'16],\nBernstein et al. [FOCS'20], and Bhattacharya and Kulkarni [SODA'19].\n  Prior to our work, there were two known general-purpose rounding schemes for\ndynamic fractional matchings. Both these schemes, by Arar et al. [ICALP'18] and\nWajc [STOC'20], were randomized.\n  Our rounding scheme works by maintaining a good {\\em matching-sparsifier}\nwith bounded arboricity, and then applying the algorithm of Peleg and Solomon\n[SODA'16] to maintain a near-optimal matching in this low arboricity graph. To\nthe best of our knowledge, this is the first dynamic matching algorithm that\nworks on general graphs by using an algorithm for low-arboricity graphs as a\nblack-box subroutine. This feature of our rounding scheme might be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:47:01 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bhattacharya", "Sayan", ""], ["Kiss", "Peter", ""]]}, {"id": "2105.01699", "submitter": "Wojciech Nadara", "authors": "Wojciech Nadara, Mateusz Radecki, Marcin Smulewicz, Marek\n  Soko{\\l}owski", "title": "Determining 4-edge-connected components in linear time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the first linear time deterministic algorithm\ncomputing the 4-edge-connected components of an undirected graph. First, we\nshow an algorithm listing all 3-edge-cuts in a given 3-edge-connected graph,\nand then we use the output of this algorithm in order to determine the\n4-edge-connected components of the graph.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 18:38:34 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Nadara", "Wojciech", ""], ["Radecki", "Mateusz", ""], ["Smulewicz", "Marcin", ""], ["Soko\u0142owski", "Marek", ""]]}, {"id": "2105.01738", "submitter": "Daniele Dell'Erba", "authors": "Massimo Benerecetti (1), Daniele Dell'Erba (2), Fabio Mogavero (1),\n  Sven Schewe (2), Dominik Wojtczak (2) ((1) Universit\\`a di Napoli Federico\n  II, (2) University of Liverpool)", "title": "Priority Promotion with Parysian Flair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm that combines the advantages of priority promotion -\nthe leading approach to solving large parity games in practice - with the\nquasi-polynomial time guarantees offered by Parys' algorithm. Hybridising these\nalgorithms sounds both natural and difficult, as they both generalise the\nclassic recursive algorithm in different ways that appear to be irreconcilable:\nwhile the promotion transcends the call structure, the guarantees change on\neach level. We show that an interface that respects both is not only effective,\nbut also efficient.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:29:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Benerecetti", "Massimo", ""], ["Dell'Erba", "Daniele", ""], ["Mogavero", "Fabio", ""], ["Schewe", "Sven", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "2105.01778", "submitter": "Yair Carmon", "authors": "Yair Carmon, Arun Jambulapati, Yujia Jin, Aaron Sidford", "title": "Thinking Inside the Ball: Near-Optimal Minimization of the Maximal Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the complexity of minimizing $\\max_{i\\in[N]} f_i(x)$ for\nconvex, Lipschitz functions $f_1,\\ldots, f_N$. For non-smooth functions,\nexisting methods require $O(N\\epsilon^{-2})$ queries to a first-order oracle to\ncompute an $\\epsilon$-suboptimal point and $\\tilde{O}(N\\epsilon^{-1})$ queries\nif the $f_i$ are $O(1/\\epsilon)$-smooth. We develop methods with improved\ncomplexity bounds of $\\tilde{O}(N\\epsilon^{-2/3} + \\epsilon^{-8/3})$ in the\nnon-smooth case and $\\tilde{O}(N\\epsilon^{-2/3} + \\sqrt{N}\\epsilon^{-1})$ in\nthe $O(1/\\epsilon)$-smooth case. Our methods consist of a recently proposed\nball optimization oracle acceleration algorithm (which we refine) and a careful\nimplementation of said oracle for the softmax function. We also prove an oracle\ncomplexity lower bound scaling as $\\Omega(N\\epsilon^{-2/3})$, showing that our\ndependence on $N$ is optimal up to polylogarithmic factors.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 21:49:15 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Carmon", "Yair", ""], ["Jambulapati", "Arun", ""], ["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2105.01780", "submitter": "Abhiruk Lahiri", "authors": "Zden\\v{e}k Dvo\\v{r}\\'ak, Abhiruk Lahiri", "title": "Approximation schemes for bounded distance problems on fractionally\n  treewidth-fragile graphs", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give polynomial-time approximation schemes for monotone maximization\nproblems expressible in terms of distances (up to a fixed upper bound) and\nefficiently solvable in graphs of bounded treewidth. These schemes apply in all\nfractionally treewidth-fragile graph classes, a property that is true for many\nnatural graph classes with sublinear separators. We also provide\nquasipolynomial-time approximation schemes for these problems in all classes\nwith sublinear separators.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:12:10 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dvo\u0159\u00e1k", "Zden\u011bk", ""], ["Lahiri", "Abhiruk", ""]]}, {"id": "2105.01782", "submitter": "Noah Singer", "authors": "Noah Singer and Madhu Sudan and Santhoshini Velusamy", "title": "Streaming approximation resistance of every ordering CSP", "comments": "23 pages, 1 figure. Replaces earlier version with $o(\\sqrt{n})$ lower\n  bound, using new bounds from arXiv:2106.13078. To appear in APPROX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordering constraint satisfaction problem (OCSP) is given by a positive\ninteger $k$ and a constraint predicate $\\Pi$ mapping permutations on\n$\\{1,\\ldots,k\\}$ to $\\{0,1\\}$. Given an instance of OCSP$(\\Pi)$ on $n$\nvariables and $m$ constraints, the goal is to find an ordering of the $n$\nvariables that maximizes the number of constraints that are satisfied, where a\nconstraint specifies a sequence of $k$ distinct variables and the constraint is\nsatisfied by an ordering on the $n$ variables if the ordering induced on the\n$k$ variables in the constraint satisfies $\\Pi$. OCSPs capture natural problems\nincluding \"Maximum acyclic subgraph (MAS)\" and \"Betweenness\".\n  In this work we consider the task of approximating the maximum number of\nsatisfiable constraints in the (single-pass) streaming setting, where an\ninstance is presented as a stream of constraints. We show that for every $\\Pi$,\nOCSP$(\\Pi)$ is approximation-resistant to $o(n)$-space streaming algorithms.\nThis space bound is tight up to polylogarithmic factors. In the case of MAS our\nresult shows that for every $\\epsilon>0$, MAS is not\n$1/2+\\epsilon$-approximable in $o(n)$ space. The previous best\ninapproximability result only ruled out a $3/4$-approximation in $o(\\sqrt n)$\nspace.\n  Our results build on recent works of Chou, Golovnev, Sudan, Velingker, and\nVelusamy who show tight, linear-space inapproximability results for a broad\nclass of (non-ordering) constraint satisfaction problems over arbitrary\n(finite) alphabets. We design a family of appropriate CSPs (one for every $q$)\nfrom any given OCSP, and apply their work to this family of CSPs. We show that\nthe hard instances from this earlier work have a particular \"small-set\nexpansion\" property. By exploiting this combinatorial property, in combination\nwith the hardness results of the resulting families of CSPs, we give optimal\ninapproximability results for all OCSPs.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:18:04 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:37:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Singer", "Noah", ""], ["Sudan", "Madhu", ""], ["Velusamy", "Santhoshini", ""]]}, {"id": "2105.01784", "submitter": "Zongchen Chen", "authors": "Zongchen Chen, Andreas Galanis, Daniel \\v{S}tefankovi\\v{c}, Eric\n  Vigoda", "title": "Sampling Colorings and Independent Sets of Random Regular Bipartite\n  Graphs in the Non-Uniqueness Region", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For spin systems, such as the $q$-colorings and independent-set models,\napproximating the partition function in the so-called non-uniqueness region,\nwhere the model exhibits long-range correlations, is typically computationally\nhard for bounded-degree graphs. We present new algorithmic results for\napproximating the partition function and sampling from the Gibbs distribution\nfor spin systems in the non-uniqueness region on random regular bipartite\ngraphs. We give an $\\mathsf{FPRAS}$ for counting $q$-colorings for even\n$q=O\\big(\\tfrac{\\Delta}{\\log{\\Delta}}\\big)$ on almost every $\\Delta$-regular\nbipartite graph. This is within a factor $O(\\log{\\Delta})$ of the sampling\nalgorithm for general graphs in the uniqueness region and improves\nsignificantly upon the previous best bound of\n$q=O\\big(\\tfrac{\\sqrt{\\Delta}}{(\\log\\Delta)^2}\\big)$ by Jenssen, Keevash, and\nPerkins (SODA'19). Analogously, for the hard-core model on independent sets\nweighted by $\\lambda>0$, we present an $\\mathsf{FPRAS}$ for estimating the\npartition function when $\\lambda=\\Omega\\big(\\tfrac{\\log{\\Delta}}{\\Delta}\\big)$,\nwhich improves upon previous results by an $\\Omega(\\log \\Delta)$ factor. Our\nresults for the colorings and hard-core models follow from a general result\nthat applies to arbitrary spin systems. Our main contribution is to show how to\nelevate probabilistic/analytic bounds on the marginal probabilities for the\ntypical structure of phases on random bipartite regular graphs into efficient\nalgorithms, using the polymer method. We further show evidence that our result\nfor colorings is within a constant factor of best possible using current\npolymer-method approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:33:02 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Chen", "Zongchen", ""], ["Galanis", "Andreas", ""], ["\u0160tefankovi\u010d", "Daniel", ""], ["Vigoda", "Eric", ""]]}, {"id": "2105.01785", "submitter": "John Michael Goddard Kallaugher", "authors": "Rajesh Jayaram, John Kallaugher", "title": "An Optimal Algorithm for Triangle Counting in the Stream", "comments": "Title changed and some minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for approximating the number of triangles in a\ngraph $G$ whose edges arrive as an arbitrary order stream. If $m$ is the number\nof edges in $G$, $T$ the number of triangles, $\\Delta_E$ the maximum number of\ntriangles which share a single edge, and $\\Delta_V$ the maximum number of\ntriangles which share a single vertex, then our algorithm requires space: \\[\n\\widetilde{O}\\left(\\frac{m}{T}\\cdot \\left(\\Delta_E +\n\\sqrt{\\Delta_V}\\right)\\right) \\] Taken with the $\\Omega\\left(\\frac{m\n\\Delta_E}{T}\\right)$ lower bound of Braverman, Ostrovsky, and Vilenchik (ICALP\n2013), and the $\\Omega\\left( \\frac{m \\sqrt{\\Delta_V}}{T}\\right)$ lower bound of\nKallaugher and Price (SODA 2017), our algorithm is optimal up to log factors,\nresolving the complexity of a classic problem in graph streaming.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:39:38 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 21:58:25 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jayaram", "Rajesh", ""], ["Kallaugher", "John", ""]]}, {"id": "2105.01818", "submitter": "Stavros Sintos", "authors": "Pankaj K. Agarwal, Xiao Hu, Stavros Sintos, Jun Yang", "title": "Dynamic Enumeration of Similarity Joins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers enumerating answers to similarity-join queries under\ndynamic updates: Given two sets of $n$ points $A,B$ in $\\mathbb{R}^d$, a metric\n$\\phi(\\cdot)$, and a distance threshold $r > 0$, report all pairs of points\n$(a, b) \\in A \\times B$ with $\\phi(a,b) \\le r$. Our goal is to store $A,B$ into\na dynamic data structure that, whenever asked, can enumerate all result pairs\nwith worst-case delay guarantee, i.e., the time between enumerating two\nconsecutive pairs is bounded. Furthermore, the data structure can be\nefficiently updated when a point is inserted into or deleted from $A$ or $B$.\n  We propose several efficient data structures for answering similarity-join\nqueries in low dimension. For exact enumeration of similarity join, we present\nnear-linear-size data structures for $\\ell_1, \\ell_\\infty$ metrics with\n$\\log^{O(1)} n$ update time and delay. We show that such a data structure is\nnot feasible for the $\\ell_2$ metric for $d \\ge 4$. For approximate enumeration\nof similarity join, where the distance threshold is a soft constraint, we\nobtain a unified linear-size data structure for $\\ell_p$ metric, with\n$\\log^{O(1)} n$ delay and update time. In high dimensions, we present an\nefficient data structure with worst-case delay-guarantee using locality\nsensitive hashing (LSH).\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 01:18:27 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Hu", "Xiao", ""], ["Sintos", "Stavros", ""], ["Yang", "Jun", ""]]}, {"id": "2105.01833", "submitter": "Peter Robinson", "authors": "Christian Konrad, Sriram V. Pemmaraju, Talal Riaz, Peter Robinson", "title": "The Complexity of Symmetry Breaking in Massive Graphs", "comments": "A preliminary version of this paper appeared in DISC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to understand the complexity of symmetry breaking\nproblems, specifically maximal independent set (MIS) and the closely related\n$\\beta$-ruling set problem, in two computational models suited for large-scale\ngraph processing, namely the $k$-machine model and the graph streaming model.\nWe present a number of results. For MIS in the $k$-machine model, we improve\nthe $\\tilde{O}(m/k^2 + \\Delta/k)$-round upper bound of Klauck et al. (SODA\n2015) by presenting an $\\tilde{O}(m/k^2)$-round algorithm. We also present an\n$\\tilde{\\Omega}(n/k^2)$ round lower bound for MIS, the first lower bound for a\nsymmetry breaking problem in the $k$-machine model. For $\\beta$-ruling sets, we\nuse hierarchical sampling to obtain more efficient algorithms in the\n$k$-machine model and also in the graph streaming model. More specifically, we\nobtain a $k$-machine algorithm that runs in $\\tilde{O}(\\beta\nn\\Delta^{1/\\beta}/k^2)$ rounds and, by using a similar hierarchical sampling\ntechnique, we obtain one-pass algorithms for both insertion-only and\ninsertion-deletion streams that use $O(\\beta \\cdot n^{1+1/2^{\\beta-1}})$ space.\nThe latter result establishes a clear separation between MIS, which is known to\nrequire $\\Omega(n^2)$ space (Cormode et al., ICALP 2019), and $\\beta$-ruling\nsets, even for $\\beta = 2$. Finally, we present an even faster 2-ruling set\nalgorithm in the $k$-machine model, one that runs in\n$\\tilde{O}(n/k^{2-\\epsilon} + k^{1-\\epsilon})$ rounds for any $\\epsilon$, $0\n\\le \\epsilon \\le 1$.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 02:09:44 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Konrad", "Christian", ""], ["Pemmaraju", "Sriram V.", ""], ["Riaz", "Talal", ""], ["Robinson", "Peter", ""]]}, {"id": "2105.01856", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne and Karl Wimmer", "title": "Identity testing under label mismatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing whether the observed data conforms to a purported model (probability\ndistribution) is a basic and fundamental statistical task, and one that is by\nnow well understood. However, the standard formulation, identity testing, fails\nto capture many settings of interest; in this work, we focus on one such\nnatural setting, identity testing under promise of permutation. In this\nsetting, the unknown distribution is assumed to be equal to the purported one,\nup to a relabeling (permutation) of the model: however, due to a systematic\nerror in the reporting of the data, this relabeling may not be the identity.\nThe goal is then to test identity under this assumption: equivalently, whether\nthis systematic labeling error led to a data distribution statistically far\nfrom the reference model.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 03:57:12 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Wimmer", "Karl", ""]]}, {"id": "2105.01864", "submitter": "Tianqi Yang", "authors": "Tianqi Yang", "title": "Tree Path Minimum Query Oracle via Boruvka Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tree path minimum query problem is a fundamental problem while processing\ntrees, and is used widely in minimum spanning tree verification and randomized\nminimum spanning tree algorithms. In this paper, we study the possibility of\nbuilding an oracle in advance, which is able to answer the queries efficiently.\nWe present an algorithm based on Boruvka trees. Our algorithm is the first to\nachieve a near-optimal bound on query time, while matching the currently\noptimal trade-off between construction time and the number of comparisons\nrequired at query. Particularly, in order to answer each query within $2k$\ncomparisons, our algorithm requires $O(n \\log \\lambda_k(n))$ time and space to\nconstruct the oracle, and the oracle can answer queries in $O(k + \\log\n\\lambda_k(n))$ time. Here $\\lambda_k(n)$ is the inverse of the Ackermann\nfunction along the $k$-th column. This algorithm not only is simpler than the\nprevious ones, but also gives a completely different method of solving this\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 04:38:17 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yang", "Tianqi", ""]]}, {"id": "2105.02022", "submitter": "Daniel Seemaier", "authors": "Lars Gottesb\\\"uren, Tobias Heuer, Peter Sanders, Christian Schulz,\n  Daniel Seemaier", "title": "Deep Multilevel Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partitioning a graph into blocks of \"roughly equal\" weight while cutting only\nfew edges is a fundamental problem in computer science with a wide range of\napplications. In particular, the problem is a building block in applications\nthat require parallel processing. While the amount of available cores in\nparallel architectures has significantly increased in recent years,\nstate-of-the-art graph partitioning algorithms do not work well if the input\nneeds to be partitioned into a large number of blocks. Often currently\navailable algorithms compute highly imbalanced solutions, solutions of low\nquality, or have excessive running time for this case. This is because most\nhigh-quality general-purpose graph partitioners are multilevel algorithms which\nperform graph coarsening to build a hierarchy of graphs, initial partitioning\nto compute an initial solution, and local improvement to improve the solution\nthroughout the hierarchy. However, for large number of blocks, the smallest\ngraph in the hierarchy that is used for initial partitioning still has to be\nlarge.\n  In this work, we substantially mitigate these problems by introducing deep\nmultilevel graph partitioning and a shared-memory implementation thereof. Our\nscheme continues the multilevel approach deep into initial partitioning --\nintegrating it into a framework where recursive bipartitioning and direct k-way\npartitioning are combined such that they can operate with high performance and\nquality. Our approach is stronger, more flexible, arguably more elegant, and\nreduces bottlenecks for parallelization compared to other multilevel\napproaches. For example, for large number of blocks our algorithm is on average\nan order of magnitude faster than competing algorithms while computing balanced\npartitions with comparable solution quality. For small number of blocks, our\nalgorithms are the fastest among competing systems with comparable quality.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 12:43:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Gottesb\u00fcren", "Lars", ""], ["Heuer", "Tobias", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""], ["Seemaier", "Daniel", ""]]}, {"id": "2105.02052", "submitter": "Alexander Eckl", "authors": "Susanne Albers, Alexander Eckl", "title": "Scheduling with Testing on Multiple Identical Parallel Machines", "comments": "27 pages, 15 pages main text including references, 12 pages appendix,\n  Conference: Algorithms and Data Structures Symposium (WADS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling with testing is a recent online problem within the framework of\nexplorable uncertainty motivated by environments where some preliminary action\ncan influence the duration of a task. Jobs have an unknown processing time that\ncan be explored by running a test. Alternatively, jobs can be executed for the\nduration of a given upper limit. We consider this problem within the setting of\nmultiple identical parallel machines and present competitive deterministic\nalgorithms and lower bounds for the objective of minimizing the makespan of the\nschedule. In the non-preemptive setting, we present the SBS algorithm whose\ncompetitive ratio approaches $3.1016$ if the number of machines becomes large.\nWe compare this result with a simple greedy strategy and a lower bound which\napproaches $2$. In the case of uniform testing times, we can improve the SBS\nalgorithm to be $3$-competitive. For the preemptive case we provide a\n$2$-competitive algorithm and a tight lower bound which approaches the same\nvalue.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:44:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Albers", "Susanne", ""], ["Eckl", "Alexander", ""]]}, {"id": "2105.02084", "submitter": "Shay Solomon", "authors": "Shay Solomon", "title": "Local Algorithms for Bounded Degree Sparsifiers in Sparse Graphs", "comments": "Appeared in ITCS'18. A new subsection on subsequent work added in the\n  introduction; abstract truncated to fit arXiv limits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graph sparsification, the goal has almost always been of {global} nature:\ncompress a graph into a smaller subgraph ({sparsifier}) that maintains certain\nfeatures of the original graph. Algorithms can then run on the sparsifier,\nwhich in many cases leads to improvements in the overall runtime and memory.\nThis paper studies sparsifiers that have bounded (maximum) degree, and are thus\n{locally} sparse, aiming to improve local measures of runtime and memory. To\nimprove those local measures, it is important to be able to compute such\nsparsifiers {locally}.\n  We initiate the study of local algorithms for bounded degree sparsifiers in\nunweighted sparse graphs, focusing on the problems of vertex cover, matching,\nand independent set. Let $\\epsilon > 0$ be a slack parameter and $\\alpha \\ge 1$\nbe a density parameter. We devise local algorithms for computing: (1) A\n$(1+\\epsilon)$-vertex cover sparsifier of degree $O(\\alpha / \\epsilon)$, for\nany graph of {arboricity} $\\alpha$. (2) A $(1+\\epsilon)$-maximum matching\nsparsifier and also a $(1+\\epsilon)$-maximal matching sparsifier of degree\n$O(\\alpha / \\epsilon)$, for any graph of arboricity $\\alpha$. (3) A\n$(1+\\epsilon)$-independent set sparsifier of degree $O(\\alpha^2 / \\epsilon)$,\nfor any graph of average degree $\\alpha$.\n  Our algorithms require only a single communication round in the standard\nmessage passing models of distributed computing, and moreover, they can be\nsimulated locally in a trivial way. As an immediate application we can extend\nresults from distributed computing and local computation algorithms that apply\nto graphs of degree bounded by $d$ to graphs of arboricity $O(d / \\epsilon)$ or\naverage degree $O(d^2 / \\epsilon)$, at the expense of increasing the\napproximation guarantee by a factor of $(1+\\epsilon)$. In particular, we can\nextend the plethora of recent local computation algorithms [...]\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 14:32:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Solomon", "Shay", ""]]}, {"id": "2105.02110", "submitter": "Vicky Choi", "authors": "Vicky Choi", "title": "Essentiality of the Non-stoquastic Hamiltonians and Driver Graph Design\n  in Quantum Optimization Annealing", "comments": "31 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinct features of quantum mechanics is that the probability\namplitude can have both positive and negative signs, which has no classical\ncounterpart as the classical probability must be positive. Consequently, one\npossible way to achieve quantum speedup is to explicitly harness this feature.\nUnlike a stoquastic Hamiltonian whose ground state has only positive amplitudes\n(with respect to the computational basis), a non-stoquastic Hamiltonian can be\neventually stoquastic or properly non-stoquastic when its ground state has both\npositive and negative amplitudes. In this paper, we describe that, for some\nhard instances which are characterized by the presence of an anti-crossing (AC)\nin a stoquastic quantum annealing (QA) algorithm, how to design an appropriate\nXX-driver graph (without knowing the prior problem structure) with an\nappropriate XX-coupler strength such that the resulting non-stoquastic QA\nalgorithm is proper-non-stoquastic with two bridged anti-crossings (a\ndouble-AC) where the spectral gap between the first and second level is large\nenough such that the system can be operated diabatically in polynomial time.\nThe speedup is exponential in the original AC-distance, which can be\nsub-exponential or exponential in the system size, over the stoquastic QA\nalgorithm, and possibly the same order of speedup over the state-of-the-art\nclassical algorithms in optimization. This work is developed based on the novel\ncharacterizations of a modified and generalized parametrization definition of\nan anti-crossing in the context of quantum optimization annealing introduced in\n[4].\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 15:21:34 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Choi", "Vicky", ""]]}, {"id": "2105.02363", "submitter": "Arun Ganesh", "authors": "Arun Ganesh, Bruce M. Maggs, Debmalya Panigrahi", "title": "Universal Algorithms for Clustering Problems", "comments": "Appeared in ICALP 2021, Track A. Fixed mismatch between paper title\n  and arXiv title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents universal algorithms for clustering problems, including\nthe widely studied $k$-median, $k$-means, and $k$-center objectives. The input\nis a metric space containing all potential client locations. The algorithm must\nselect $k$ cluster centers such that they are a good solution for any subset of\nclients that actually realize. Specifically, we aim for low regret, defined as\nthe maximum over all subsets of the difference between the cost of the\nalgorithm's solution and that of an optimal solution. A universal algorithm's\nsolution $SOL$ for a clustering problem is said to be an $(\\alpha,\n\\beta)$-approximation if for all subsets of clients $C'$, it satisfies $SOL(C')\n\\leq \\alpha \\cdot OPT(C') + \\beta \\cdot MR$, where $OPT(C')$ is the cost of the\noptimal solution for clients $C'$ and $MR$ is the minimum regret achievable by\nany solution.\n  Our main results are universal algorithms for the standard clustering\nobjectives of $k$-median, $k$-means, and $k$-center that achieve $(O(1),\nO(1))$-approximations. These results are obtained via a novel framework for\nuniversal algorithms using linear programming (LP) relaxations. These results\ngeneralize to other $\\ell_p$-objectives and the setting where some subset of\nthe clients are fixed. We also give hardness results showing that $(\\alpha,\n\\beta)$-approximation is NP-hard if $\\alpha$ or $\\beta$ is at most a certain\nconstant, even for the widely studied special case of Euclidean metric spaces.\nThis shows that in some sense, $(O(1), O(1))$-approximation is the strongest\ntype of guarantee obtainable for universal clustering.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 22:52:42 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 21:30:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ganesh", "Arun", ""], ["Maggs", "Bruce M.", ""], ["Panigrahi", "Debmalya", ""]]}, {"id": "2105.02428", "submitter": "Ce Jin", "authors": "Shyan Akmal and Ce Jin", "title": "Faster Algorithms for Bounded Tree Edit Distance", "comments": "To appear in ICALP 2021. Updated funding information and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree edit distance is a well-studied measure of dissimilarity between rooted\ntrees with node labels. It can be computed in $O(n^3)$ time [Demaine, Mozes,\nRossman, and Weimann, ICALP 2007], and fine-grained hardness results suggest\nthat the weighted version of this problem cannot be solved in truly subcubic\ntime unless the APSP conjecture is false [Bringmann, Gawrychowski, Mozes, and\nWeimann, SODA 2018].\n  We consider the unweighted version of tree edit distance, where every\ninsertion, deletion, or relabeling operation has unit cost. Given a parameter\n$k$ as an upper bound on the distance, the previous fastest algorithm for this\nproblem runs in $O(nk^3)$ time [Touzet, CPM 2005], which improves upon the\ncubic-time algorithm for $k\\ll n^{2/3}$. In this paper, we give a faster\nalgorithm taking $O(nk^2 \\log n)$ time, improving both of the previous results\nfor almost the full range of $\\log n \\ll k\\ll n/\\sqrt{\\log n}$.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:54:27 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:40:12 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Akmal", "Shyan", ""], ["Jin", "Ce", ""]]}, {"id": "2105.02736", "submitter": "Daniel Paulusma", "authors": "Giacomo Paesani and Dani\\\"el Paulusma and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Feedback Vertex Set and Even Cycle Transversal for H-Free Graphs:\n  Finding Large Block Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new complexity results for Feedback Vertex Set and Even Cycle\nTransversal on $H$-free graphs, that is, graphs that do not contain some fixed\ngraph $H$ as an induced subgraph. In particular, we prove that both problems\nare polynomial-time solvable for $sP_3$-free graphs for every integer $s\\geq\n1$. Our results show that both problems exhibit the same behaviour on $H$-free\ngraphs (subject to some open cases). This is in part explained by a new general\nalgorithm we design for finding in a graph $G$ a largest induced subgraph whose\nblocks belong to some finite class ${\\cal C}$ of graphs. We also compare our\nresults with the state-of-the-art results for the Odd Cycle Transversal\nproblem, which is known to behave differently on $H$-free graphs.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:56:38 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Paesani", "Giacomo", ""], ["Paulusma", "Dani\u00ebl", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2105.02761", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Charles Blundell", "title": "Neural Algorithmic Reasoning", "comments": "Accepted as an Opinion paper in Patterns. 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms have been fundamental to recent global technological advances and,\nin particular, they have been the cornerstone of technical advances in one\nfield rapidly being applied to another. We argue that algorithms possess\nfundamentally different qualities to deep learning methods, and this strongly\nsuggests that, were deep learning methods better able to mimic algorithms,\ngeneralisation of the sort seen with algorithms would become possible with deep\nlearning -- something far out of the reach of current machine learning methods.\nFurthermore, by representing elements in a continuous space of learnt\nalgorithms, neural networks are able to adapt known algorithms more closely to\nreal-world problems, potentially finding more efficient and pragmatic solutions\nthan those proposed by human computer scientists.\n  Here we present neural algorithmic reasoning -- the art of building neural\nnetworks that are able to execute algorithmic computation -- and provide our\nopinion on its transformative potential for running classical algorithms on\ninputs previously considered inaccessible to them.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:33:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Blundell", "Charles", ""]]}, {"id": "2105.02806", "submitter": "Adam Polak", "authors": "Yuzhou Gu, Adam Polak, Virginia Vassilevska Williams, Yinzhan Xu", "title": "Faster Monotone Min-Plus Product, Range Mode, and Single Source\n  Replacement Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most basic graph problems, All-Pairs Shortest Paths (APSP) is\nknown to be solvable in $n^{3-o(1)}$ time, and it is widely open whether it has\nan $O(n^{3-\\epsilon})$ time algorithm for $\\epsilon > 0$. To better understand\nAPSP, one often strives to obtain subcubic time algorithms for structured\ninstances of APSP and problems equivalent to it, such as the Min-Plus matrix\nproduct.\n  A natural structured version of Min-Plus product is Monotone Min-Plus product\nwhich has been studied in the context of the Batch Range Mode [SODA'20] and\nDynamic Range Mode [ICALP'20] problems. This paper improves the known\nalgorithms for Monotone Min-Plus Product and for Batch and Dynamic Range Mode,\nand establishes a connection between Monotone Min-Plus Product and the Single\nSource Replacement Paths (SSRP) problem on an $n$-vertex graph with potentially\nnegative edge weights in $\\{-M, \\ldots, M\\}$.\n  SSRP with positive integer edge weights bounded by $M$ can be solved in\n$\\tilde{O}(Mn^\\omega)$ time, whereas the prior fastest algorithm for graphs\nwith possibly negative weights [FOCS'12] runs in $O(M^{0.7519} n^{2.5286})$\ntime, the current best running time for directed APSP with small integer\nweights. Using Monotone Min-Plus Product, we obtain an improved $O(M^{0.8043}\nn^{2.4957})$ time SSRP algorithm, showing that SSRP with constant negative\ninteger weights is likely easier than directed unweighted APSP, a problem that\nis believed to require $n^{2.5-o(1)}$ time.\n  Complementing our algorithm for SSRP, we give a reduction from the\nBounded-Difference Min-Plus Product problem studied by Bringmann et al.\n[FOCS'16] to negative weight SSRP. This reduction shows that it might be\ndifficult to obtain an $\\tilde{O}(M n^{\\omega})$ time algorithm for SSRP with\nnegative weight edges, thus separating the problem from SSRP with only positive\nweight edges.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 16:54:43 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Gu", "Yuzhou", ""], ["Polak", "Adam", ""], ["Williams", "Virginia Vassilevska", ""], ["Xu", "Yinzhan", ""]]}, {"id": "2105.02827", "submitter": "Eklavya Sharma", "authors": "Arindam Khan, Eklavya Sharma", "title": "Tight Approximation Algorithms for Geometric Bin Packing with Skewed\n  Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Two-dimensional Bin Packing (2BP) problem, we are given a set of\nrectangles of height and width at most one and our goal is to find an\naxis-aligned nonoverlapping packing of these rectangles into the minimum number\nof unit square bins. The problem admits no APTAS and the current best\napproximation ratio is $1.406$ by Bansal and Khan [SODA'14]. A well-studied\nvariant of the problem is Guillotine Two-dimensional Bin Packing (G2BP), where\nall rectangles must be packed in such a way that every rectangle in the packing\ncan be obtained by recursively applying a sequence of end-to-end axis-parallel\ncuts, also called guillotine cuts. Bansal, Lodi, and Sviridenko [FOCS'05]\nobtained an APTAS for this problem. Let $\\lambda$ be the smallest constant such\nthat for every set $I$ of items, the number of bins in the optimal solution to\nG2BP for $I$ is upper bounded by $\\lambda\\operatorname{opt}(I) + c$, where\n$\\operatorname{opt}(I)$ is the number of bins in the optimal solution to 2BP\nfor $I$ and $c$ is a constant. It is known that $4/3 \\le \\lambda \\le 1.692$.\nBansal and Khan [SODA'14] conjectured that $\\lambda = 4/3$. The conjecture, if\ntrue, will imply a $(4/3+\\varepsilon)$-approximation algorithm for 2BP.\nAccording to convention, for a given constant $\\delta>0$, a rectangle is large\nif both its height and width are at least $\\delta$, and otherwise it is called\nskewed. We make progress towards the conjecture by showing $\\lambda = 4/3$ for\nskewed instance, i.e., when all input rectangles are skewed. Even for this\ncase, the previous best upper bound on $\\lambda$ was roughly 1.692. We also\ngive an APTAS for 2BP for skewed instance, though general 2BP does not admit an\nAPTAS.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:16:11 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Khan", "Arindam", ""], ["Sharma", "Eklavya", ""]]}, {"id": "2105.02856", "submitter": "Krzysztof Maziarz", "authors": "Krzysztof Maziarz, Tom Ellis, Alan Lawrence, Andrew Fitzgibbon, Simon\n  Peyton Jones", "title": "Hashing Modulo Alpha-Equivalence", "comments": "Accepted for publication at the 42nd ACM SIGPLAN International\n  Conference on Programming Language Design and Implementation (PLDI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications one wants to identify identical subtrees of a program\nsyntax tree. This identification should ideally be robust to alpha-renaming of\nthe program, but no existing technique has been shown to achieve this with good\nefficiency (better than $\\mathcal{O}(n^2)$ in expression size). We present a\nnew, asymptotically efficient way to hash modulo alpha-equivalence. A key\ninsight of our method is to use a weak (commutative) hash combiner at exactly\none point in the construction, which admits an algorithm with $\\mathcal{O}(n\n(\\log n)^2)$ time complexity. We prove that the use of the commutative combiner\nnevertheless yields a strong hash with low collision probability. Numerical\nbenchmarks attest to the asymptotic behaviour of the method.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:44:30 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Maziarz", "Krzysztof", ""], ["Ellis", "Tom", ""], ["Lawrence", "Alan", ""], ["Fitzgibbon", "Andrew", ""], ["Jones", "Simon Peyton", ""]]}, {"id": "2105.02910", "submitter": "Evangelos Kosinas", "authors": "Loukas Georgiadis, Giuseppe F. Italiano, Evangelos Kosinas", "title": "Computing the $4$-Edge-Connected Components of a Graph in Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first linear-time algorithm that computes the\n$4$-edge-connected components of an undirected graph. Hence, we also obtain the\nfirst linear-time algorithm for testing $4$-edge connectivity. Our results are\nbased on a linear-time algorithm that computes the $3$-edge cuts of a\n$3$-edge-connected graph $G$, and a linear-time procedure that, given the\ncollection of all $3$-edge cuts, partitions the vertices of $G$ into the\n$4$-edge-connected components.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:33:01 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Georgiadis", "Loukas", ""], ["Italiano", "Giuseppe F.", ""], ["Kosinas", "Evangelos", ""]]}, {"id": "2105.03028", "submitter": "Shyan Akmal", "authors": "Shyan Akmal and Virginia Vassilevska Williams", "title": "Improved Approximation for Longest Common Subsequence over Small\n  Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the approximability of the Longest Common Subsequence\n(LCS) problem. The fastest algorithm for solving the LCS problem exactly runs\nin essentially quadratic time in the length of the input, and it is known that\nunder the Strong Exponential Time Hypothesis the quadratic running time cannot\nbe beaten. There are no such limitations for the approximate computation of the\nLCS however, except in some limited scenarios. There is also a scarcity of\napproximation algorithms. When the two given strings are over an alphabet of\nsize $k$, returning the subsequence formed by the most frequent symbol\noccurring in both strings achieves a $1/k$ approximation for the LCS. It is an\nopen problem whether a better than $1/k$ approximation can be achieved in truly\nsubquadratic time ($O(n^{2-\\delta})$ time for constant $\\delta>0$).\n  A recent result [Rubinstein and Song SODA'2020] showed that a $1/2+\\epsilon$\napproximation for the LCS over a binary alphabet is possible in truly\nsubquadratic time, provided the input strings have the same length. In this\npaper we show that if a $1/2+\\epsilon$ approximation (for $\\epsilon>0$) is\nachievable for binary LCS in truly subquadratic time when the input strings can\nbe unequal, then for every constant $k$, there is a truly subquadratic time\nalgorithm that achieves a $1/k+\\delta$ approximation for $k$-ary alphabet LCS\nfor some $\\delta>0$. Thus the binary case is the hardest. We also show that for\nevery constant $k$, if one is given two strings of \\emph{equal} length over a\n$k$-ary alphabet, one can obtain a $1/k+\\epsilon$ approximation for some\nconstant $\\epsilon>0$ in truly subquadratic time, thus extending the Rubinstein\nand Song result to all alphabets of constant size.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 01:44:13 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Akmal", "Shyan", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2105.03093", "submitter": "Yu Yokoi Dr.", "authors": "Hiromichi Goko, Kazuhisa Makino, Shuichi Miyazaki, Yu Yokoi", "title": "Maximally Satisfying Lower Quotas in the Hospitals/Residents Problem\n  with Ties", "comments": "44 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a serious issue that hospitals in rural areas suffer from\nshortage of residents, we study the Hospitals/Residents model in which\nhospitals are associated with lower quotas and the goal is to satisfy them as\nmuch as possible. When preference lists are strict, the number of residents\nassigned to each hospital is the same in any stable matching due to the famous\nrural hospitals theorem, so there is no room for algorithmic interventions.\nHowever, when ties are introduced in preference lists, this is not the case\nsince the number of residents may vary over stable matchings. The main focus of\nthis paper is to investigate how much we can utilize this flexibility to aid\nrural hospitals, in the presence of ties. We first show that the exact\noptimization is NP-hard and incompatible with strategy-proofness for residents.\nWe then propose a linear-time strategy-proof algorithm whose approximation\nratio is substantially better than a naive algorithm that breaks ties\narbitrarily and applies the Gale-Shapley algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 07:46:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Goko", "Hiromichi", ""], ["Makino", "Kazuhisa", ""], ["Miyazaki", "Shuichi", ""], ["Yokoi", "Yu", ""]]}, {"id": "2105.03106", "submitter": "Solon Pissis", "authors": "Panagiotis Charalampopoulos and Tomasz Kociumaka and Solon P. Pissis\n  and Jakub Radoszewski", "title": "Faster Algorithms for Longest Common Substring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the classic longest common substring (LCS) problem, we are given two\nstrings $S$ and $T$, each of length at most $n$, over an alphabet of size\n$\\sigma$, and we are asked to find a longest string occurring as a fragment of\nboth $S$ and $T$. Weiner, in his seminal paper that introduced the suffix tree,\npresented an $\\mathcal{O}(n \\log \\sigma)$-time algorithm for this problem [SWAT\n1973]. For polynomially-bounded integer alphabets, the linear-time construction\nof suffix trees by Farach yielded an $\\mathcal{O}(n)$-time algorithm for the\nLCS problem [FOCS 1997]. However, for small alphabets, this is not necessarily\noptimal for the LCS problem in the word RAM model of computation, in which the\nstrings can be stored in $\\mathcal{O}(n \\log \\sigma/\\log n )$ space and read in\n$\\mathcal{O}(n \\log \\sigma/\\log n )$ time. We show that, in this model, we can\ncompute an LCS in time $\\mathcal{O}(n \\log \\sigma / \\sqrt{\\log n})$, which is\nsublinear in $n$ if $\\sigma=2^{o(\\sqrt{\\log n})}$ (in particular, if\n$\\sigma=\\mathcal{O}(1)$), using optimal space $\\mathcal{O}(n \\log \\sigma/\\log\nn)$.\n  We then lift our ideas to the problem of computing a $k$-mismatch LCS, which\nhas received considerable attention in recent years. In this problem, the aim\nis to compute a longest substring of $S$ that occurs in $T$ with at most $k$\nmismatches. Thankachan et al.~showed how to compute a $k$-mismatch LCS in\n$\\mathcal{O}(n \\log^k n)$ time for $k=\\mathcal{O}(1)$ [J. Comput. Biol. 2016].\nWe show an $\\mathcal{O}(n \\log^{k-1/2} n)$-time algorithm, for any constant\n$k>0$ and irrespective of the alphabet size, using $\\mathcal{O}(n)$ space as\nthe previous approaches. We thus notably break through the well-known $n \\log^k\nn$ barrier, which stems from a recursive heavy-path decomposition technique\nthat was first introduced in the seminal paper of Cole et al. [STOC 2004] for\nstring indexing with $k$ errors.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 08:19:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Charalampopoulos", "Panagiotis", ""], ["Kociumaka", "Tomasz", ""], ["Pissis", "Solon P.", ""], ["Radoszewski", "Jakub", ""]]}, {"id": "2105.03594", "submitter": "Li-Yang Tan", "authors": "Guy Blanc and Jane Lange and Li-Yang Tan", "title": "Learning stochastic decision trees", "comments": "To appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quasipolynomial-time algorithm for learning stochastic decision\ntrees that is optimally resilient to adversarial noise. Given an\n$\\eta$-corrupted set of uniform random samples labeled by a size-$s$ stochastic\ndecision tree, our algorithm runs in time\n$n^{O(\\log(s/\\varepsilon)/\\varepsilon^2)}$ and returns a hypothesis with error\nwithin an additive $2\\eta + \\varepsilon$ of the Bayes optimal. An additive\n$2\\eta$ is the information-theoretic minimum.\n  Previously no non-trivial algorithm with a guarantee of $O(\\eta) +\n\\varepsilon$ was known, even for weaker noise models. Our algorithm is\nfurthermore proper, returning a hypothesis that is itself a decision tree;\npreviously no such algorithm was known even in the noiseless setting.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:54:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2105.03753", "submitter": "Sayan Bandyapadhyay", "authors": "Sayan Bandyapadhyay, Fedor V. Fomin, Petr A. Golovach, Kirill Simonov", "title": "Parameterized Complexity of Feature Selection for Categorical Data\n  Clustering", "comments": "25 pages, full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop new algorithmic methods with provable guarantees for feature\nselection in regard to categorical data clustering. While feature selection is\none of the most common approaches to reduce dimensionality in practice, most of\nthe known feature selection methods are heuristics. We study the following\nmathematical model. We assume that there are some inadvertent (or undesirable)\nfeatures of the input data that unnecessarily increase the cost of clustering.\nConsequently, we want to select a subset of the original features from the data\nsuch that there is a small-cost clustering on the selected features. More\nprecisely, for given integers $\\ell$ (the number of irrelevant features) and\n$k$ (the number of clusters), budget $B$, and a set of $n$ categorical data\npoints (represented by $m$-dimensional vectors whose elements belong to a\nfinite set of values $\\Sigma$), we want to select $m-\\ell$ relevant features\nsuch that the cost of any optimal $k$-clustering on these features does not\nexceed $B$. Here the cost of a cluster is the sum of Hamming distances\n($\\ell_0$-distances) between the selected features of the elements of the\ncluster and its center. The clustering cost is the total sum of the costs of\nthe clusters. We use the framework of parameterized complexity to identify how\nthe complexity of the problem depends on parameters $k$, $B$, and $|\\Sigma|$.\nOur main result is an algorithm that solves the Feature Selection problem in\ntime $f(k,B,|\\Sigma|)\\cdot m^{g(k,|\\Sigma|)}\\cdot n^2$ for some functions $f$\nand $g$. In other words, the problem is fixed-parameter tractable parameterized\nby $B$ when $|\\Sigma|$ and $k$ are constants. Our algorithm is based on a\nsolution to a more general problem, Constrained Clustering with Outliers. We\nalso complement our algorithmic findings with complexity lower bounds.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 18:04:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bandyapadhyay", "Sayan", ""], ["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Simonov", "Kirill", ""]]}, {"id": "2105.03773", "submitter": "Samson Zhou", "authors": "David P. Woodruff and Samson Zhou", "title": "Separations for Estimating Large Frequency Moments on Data Streams", "comments": "ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the classical problem of moment estimation of an underlying vector\nwhose $n$ coordinates are implicitly defined through a series of updates in a\ndata stream. We show that if the updates to the vector arrive in the\nrandom-order insertion-only model, then there exist space efficient algorithms\nwith improved dependencies on the approximation parameter $\\varepsilon$. In\nparticular, for any real $p > 2$, we first obtain an algorithm for $F_p$ moment\nestimation using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^{4/p}}\\cdot\nn^{1-2/p}\\right)$ bits of memory. Our techniques also give algorithms for $F_p$\nmoment estimation with $p>2$ on arbitrary order insertion-only and turnstile\nstreams, using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^{4/p}}\\cdot\nn^{1-2/p}\\right)$ bits of space and two passes, which is the first optimal\nmulti-pass $F_p$ estimation algorithm up to $\\log n$ factors. Finally, we give\nan improved lower bound of $\\Omega\\left(\\frac{1}{\\varepsilon^2}\\cdot\nn^{1-2/p}\\right)$ for one-pass insertion-only streams. Our results separate the\ncomplexity of this problem both between random and non-random orders, as well\nas one-pass and multi-pass streams.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 20:39:30 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 03:32:41 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 20:17:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Woodruff", "David P.", ""], ["Zhou", "Samson", ""]]}, {"id": "2105.03782", "submitter": "Dmitry Kosolobov", "authors": "Dmitry Kosolobov and Nikita Sivukhin", "title": "Construction of Sparse Suffix Trees and LCE Indexes in Optimal Time and\n  Space", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notions of synchronizing and partitioning sets are recently introduced\nvariants of locally consistent parsings with great potential in\nproblem-solving. In this paper we propose a deterministic algorithm that\nconstructs for a given readonly string of length $n$ over the alphabet\n$\\{0,1,\\ldots,n^{\\mathcal{O}(1)}\\}$ a variant of $\\tau$-partitioning set with\nsize $\\mathcal{O}(b)$ and $\\tau = \\frac{n}{b}$ using $\\mathcal{O}(b)$ space and\n$\\mathcal{O}(\\frac{1}{\\epsilon}n)$ time provided $b \\ge n^\\epsilon$, for\n$\\epsilon > 0$. As a corollary, for $b \\ge n^\\epsilon$ and constant $\\epsilon >\n0$, we obtain linear construction algorithms with $\\mathcal{O}(b)$ space on top\nof the string for two major small-space indexes: a sparse suffix tree, which is\na compacted trie built on $b$ chosen suffixes of the string, and a longest\ncommon extension (LCE) index, which occupies $\\mathcal{O}(b)$ space and allows\nus to compute the longest common prefix for any pair of substrings in\n$\\mathcal{O}(n/b)$ time. For both, the $\\mathcal{O}(b)$ construction storage is\nasymptotically optimal since the tree itself takes $\\mathcal{O}(b)$ space and\nany LCE index with $\\mathcal{O}(n/b)$ query time must occupy at least\n$\\mathcal{O}(b)$ space by a known trade-off (at least for $b \\ge \\Omega(n /\n\\log n)$). In case of arbitrary $b \\ge \\Omega(\\log^2 n)$, we present\nconstruction algorithms for the partitioning set, sparse suffix tree, and LCE\nindex with $\\mathcal{O}(n\\log_b n)$ running time and $\\mathcal{O}(b)$ space,\nthus also improving the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 21:24:55 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 20:49:29 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kosolobov", "Dmitry", ""], ["Sivukhin", "Nikita", ""]]}, {"id": "2105.03968", "submitter": "Vasileios Nakos", "authors": "Karl Bringmann, Vasileios Nakos", "title": "Fast $n$-fold Boolean Convolution via Additive Combinatorics", "comments": "ICALP 2021, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of computing the Boolean convolution (with\nwraparound) of $n$~vectors of dimension $m$, or, equivalently, the problem of\ncomputing the sumset $A_1+A_2+\\ldots+A_n$ for $A_1,\\ldots,A_n \\subseteq\n\\mathbb{Z}_m$. Boolean convolution formalizes the frequent task of combining\ntwo subproblems, where the whole problem has a solution of size $k$ if for some\n$i$ the first subproblem has a solution of size~$i$ and the second subproblem\nhas a solution of size $k-i$. Our problem formalizes a natural generalization,\nnamely combining solutions of $n$ subproblems subject to a modular constraint.\nThis simultaneously generalises Modular Subset Sum and Boolean Convolution\n(Sumset Computation). Although nearly optimal algorithms are known for special\ncases of this problem, not even tiny improvements are known for the general\ncase.\n  We almost resolve the computational complexity of this problem, shaving\nessentially a factor of $n$ from the running time of previous algorithms.\nSpecifically, we present a \\emph{deterministic} algorithm running in\n\\emph{almost} linear time with respect to the input plus output size $k$. We\nalso present a \\emph{Las Vegas} algorithm running in \\emph{nearly} linear\nexpected time with respect to the input plus output size $k$. Previously, no\ndeterministic or randomized $o(nk)$ algorithm was known.\n  At the heart of our approach lies a careful usage of Kneser's theorem from\nAdditive Combinatorics, and a new deterministic almost linear output-sensitive\nalgorithm for non-negative sparse convolution. In total, our work builds a\nsolid toolbox that could be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 16:51:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bringmann", "Karl", ""], ["Nakos", "Vasileios", ""]]}, {"id": "2105.04023", "submitter": "Gokhan Gokturk", "authors": "Gokhan Gokturk and Kamer Kaya", "title": "Fast and Error-Adaptive Influence Maximization based on Count-Distinct\n  Sketches", "comments": "12 pages. Sent to IEEE Transactions on Knowledge and Data Engineering\n  as a regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influence maximization (IM) is the problem of finding a seed vertex set that\nmaximizes the expected number of vertices influenced under a given diffusion\nmodel. Due to the NP-Hardness of finding an optimal seed set, approximation\nalgorithms are frequently used for IM. In this work, we describe a fast,\nerror-adaptive approach that leverages Count-Distinct sketches and hash-based\nfused sampling. To estimate the number of influenced vertices throughout a\ndiffusion, we use per-vertex Flajolet-Martin sketches where each sketch\ncorresponds to a sampled subgraph. To efficiently simulate the diffusions, the\nreach-set cardinalities of a single vertex are stored in memory in a\nconsecutive fashion. This allows the proposed algorithm to estimate the number\nof influenced vertices in a single step for simulations at once. For a faster\nIM kernel, we rebuild the sketches in parallel only after observing estimation\nerrors above a given threshold. Our experimental results show that the proposed\nalgorithm yields high-quality seed sets while being up to 119x faster than a\nstate-of-the-art approximation algorithm. In addition, it is up to 62x faster\nthan a sketch-based approach while producing seed sets with 3%-12% better\ninfluence scores\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 21:15:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gokturk", "Gokhan", ""], ["Kaya", "Kamer", ""]]}, {"id": "2105.04035", "submitter": "Adam Polak", "authors": "Adam Polak, Lars Rohwedder, Karol W\\k{e}grzycki", "title": "Knapsack and Subset Sum with Small Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knapsack and Subset Sum are fundamental NP-hard problems in combinatorial\noptimization. Recently there has been a growing interest in understanding the\nbest possible pseudopolynomial running times for these problems with respect to\nvarious parameters.\n  In this paper we focus on the maximum item size $s$ and the maximum item\nvalue $v$. We give algorithms that run in time $O(n + s^3)$ and $O(n + v^3)$\nfor the Knapsack problem, and in time $\\tilde{O}(n + s^{5/3})$ for the Subset\nSum problem.\n  Our algorithms work for the more general problem variants with\nmultiplicities, where each input item comes with a (binary encoded)\nmultiplicity, which succinctly describes how many times the item appears in the\ninstance. In these variants $n$ denotes the (possibly much smaller) number of\ndistinct items.\n  Our results follow from combining and optimizing several diverse lines of\nresearch, notably proximity arguments for integer programming due to Eisenbrand\nand Weismantel (TALG 2019), fast structured $(\\min,+)$-convolution by Kellerer\nand Pferschy (J. Comb. Optim. 2004), and additive combinatorics methods\noriginating from Galil and Margalit (SICOMP 1991).\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 22:03:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Polak", "Adam", ""], ["Rohwedder", "Lars", ""], ["W\u0119grzycki", "Karol", ""]]}, {"id": "2105.04146", "submitter": "Kazuhiro Kurita", "authors": "Yasuaki Kobayashi, Kazuhiro Kurita, Kunihiro Wasa", "title": "Polynomial-Delay Enumeration of Large Maximal Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enumerating matchings is a classical problem in the field of enumeration\nalgorithms. There are polynomial-delay enumeration algorithms for several\nsettings, such as enumerating perfect matchings, maximal matchings, and\n(weighted) matchings in specific orders. In this paper, we present\npolynomial-delay enumeration algorithms for maximal matchings with cardinality\nat least given threshold $t$. Our algorithm enumerates all such matchings in\n$O(nm)$ delay with exponential space, where $n$ and $m$ are the number of\nvertices and edges of an input graph, respectively. We also present a\npolynomial-delay and polynomial-space enumeration algorithm for this problem.\nAs a variant of this algorithm, we give an algorithm that enumerates all\nmaximal matchings in non-decreasing order of its cardinality and runs in\n$O(nm)$ delay.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 06:58:01 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 23:06:41 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kobayashi", "Yasuaki", ""], ["Kurita", "Kazuhiro", ""], ["Wasa", "Kunihiro", ""]]}, {"id": "2105.04228", "submitter": "Manuel S\\'aenz", "authors": "Matthieu Jonckheere, Manuel S\\'aenz", "title": "Exact asymptotic characterisation of running time for approximate\n  gradient descent on random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the time complexity for the search of local minima in\nrandom graphs whose vertices have i.i.d. cost values. We show that, for\nErd\\\"os-R\\'enyi graphs with connection probability given by $\\lambda/n^\\alpha$\n(with $\\lambda > 0$ and $0 < \\alpha < 1$), a family of local algorithms that\napproximate a gradient descent find local minima faster than the full gradient\ndescent. Furthermore, we find a probabilistic representation for the running\ntime of these algorithms leading to asymptotic estimates of the mean running\ntimes.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 09:41:30 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Jonckheere", "Matthieu", ""], ["S\u00e1enz", "Manuel", ""]]}, {"id": "2105.04588", "submitter": "Daniel Paulusma", "authors": "Christoph Brause and Petr Golovach and Barnaby Martin and Dani\\\"el\n  Paulusma and Siani Smith", "title": "Partitioning H-Free Graphs of Bounded Diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural way of increasing our understanding of NP-complete graph problems\nis to restrict the input to a special graph class. Classes of $H$-free graphs,\nthat is, graphs that do not contain some graph $H$ as an induced subgraph, have\nproven to be an ideal testbed for such a complexity study. However, if the\nforbidden graph $H$ contains a cycle or claw, then these problems often stay\nNP-complete. A recent complexity study on the $k$-Colouring problem shows that\nwe may still obtain tractable results if we also bound the diameter of the\n$H$-free input graph. We continue this line of research by initiating a\ncomplexity study on the impact of bounding the diameter for a variety of\nclassical vertex partitioning problems restricted to $H$-free graphs. We prove\nthat bounding the diameter does not help for Independent Set, but leads to new\ntractable cases for problems closely related to 3-Colouring. That is, we show\nthat Near-Bipartiteness, Independent Feedback Vertex Set, Independent Odd Cycle\nTransversal, Acyclic 3-Colouring and Star 3-Colouring are all polynomial-time\nsolvable for chair-free graphs of bounded diameter. To obtain these results we\nexploit a new structural property of 3-colourable chair-free graphs.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:02:48 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Brause", "Christoph", ""], ["Golovach", "Petr", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Dani\u00ebl", ""], ["Smith", "Siani", ""]]}, {"id": "2105.04660", "submitter": "Ashwin Jacob", "authors": "Ashwin Jacob, Jari J. H. de Kroon, Diptapriyo Majumdar, Venkatesh\n  Raman", "title": "Parameterized Complexity of Deletion to Scattered Graph Classes", "comments": "An extended abstract of the paper appeared in IPEC 2020. This version\n  has a new co-author Jari J. H. de Kroon and an extension of our main result\n  for the case when forbidden subgraphs of each class can be infinite, under\n  certain other conditions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-modification problems, where we add/delete a small number of\nvertices/edges to make the given graph to belong to a simpler graph class, is a\nwell-studied optimization problem in all algorithmic paradigms including\nclassical, approximation and parameterized complexity. Specifically,\ngraph-deletion problems, where one needs to delete at most $k$ vertices to\nplace it in a given non-trivial hereditary (closed under induced subgraphs)\ngraph class, captures several well-studied problems including {\\sc Vertex\nCover}, {\\sc Feedback Vertex Set}, {\\sc Odd Cycle Transveral}, {\\sc Cluster\nVertex Deletion}, and {\\sc Perfect Deletion}. Investigation into these problems\nin parameterized complexity has given rise to powerful tools and techniques.\nWhile a precise characterization of the graph classes for which the problem is\n{\\it fixed-parameter tractable} (FPT) is elusive, it has long been known that\nif the graph class is characterized by a {\\it finite} set of forbidden graphs,\nthen the problem is FPT.\n  In this paper, we initiate a study of a natural variation of the problem of\ndeletion to {\\it scattered graph classes} where we need to delete at most $k$\nvertices so that in the resulting graph, each connected component belongs to\none of a constant number of graph classes. A simple hitting set based approach\nis no longer feasible even if each of the graph classes is characterized by\nfinite forbidden sets.\n  As our main result, we show that this problem is fixed-parameter tractable\n(FPT) when the deletion problem corresponding to each of the finite classes is\nknown to be FPT and the properties that a graph belongs to each of the classes\nis expressible in CMSO logic.\n  When each graph class has a finite forbidden set, we give a faster FPT\nalgorithm using the well-known techniques of iterative compression and\nimportant separators.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:37:45 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Jacob", "Ashwin", ""], ["de Kroon", "Jari J. H.", ""], ["Majumdar", "Diptapriyo", ""], ["Raman", "Venkatesh", ""]]}, {"id": "2105.04700", "submitter": "Alexandre Nolin", "authors": "Magn\\'us M. Halld\\'orsson, Alexandre Nolin, Tigran Tonoyan", "title": "Ultrafast Distributed Coloring of High Degree Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new randomized distributed algorithm for the $\\Delta+1$-list\ncoloring problem. The algorithm and its analysis dramatically simplify the\nprevious best result known of Chang, Li, and Pettie [SICOMP 2020]. This allows\nfor numerous refinements, and in particular, we can color all $n$-node graphs\nof maximum degree $\\Delta \\ge \\log^{2+\\Omega(1)} n$ in $O(\\log^* n)$ rounds.\nThe algorithm works in the CONGEST model, i.e., it uses only $O(\\log n)$ bits\nper message for communication. On low-degree graphs, the algorithm shatters the\ngraph into components of size $\\operatorname{poly}(\\log n)$ in $O(\\log^*\n\\Delta)$ rounds, showing that the randomized complexity of $\\Delta+1$-list\ncoloring in CONGEST depends inherently on the deterministic complexity of\nrelated coloring problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 22:49:48 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Halld\u00f3rsson", "Magn\u00fas M.", ""], ["Nolin", "Alexandre", ""], ["Tonoyan", "Tigran", ""]]}, {"id": "2105.04702", "submitter": "David Doty", "authors": "David Doty and Eric Severson", "title": "ppsim: A software package for efficiently simulating and visualizing\n  population protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ppsim, a software package for efficiently simulating population\nprotocols, a widely-studied subclass of chemical reaction networks (CRNs) in\nwhich all reactions have two reactants and two products. Each step in the\ndynamics involves picking a uniform random pair from a population of $n$\nmolecules to collide and have a (potentially null) reaction. In a recent\nbreakthrough, Berenbrink, Hammer, Kaaser, Meyer, Penschuck, and Tran [ESA 2020]\ndiscovered a population protocol simulation algorithm quadratically faster than\nthe naive algorithm, simulating $\\Theta(\\sqrt{n})$ reactions in *constant* time\n(independently of $n$, though the time scales with the number of species),\nwhile preserving the *exact* stochastic dynamics.\n  ppsim implements this algorithm, with a tightly optimized Cython\nimplementation that can exactly simulate hundreds of billions of reactions in\nseconds. It dynamically switches to the CRN Gillespie algorithm for efficiency\ngains when the number of applicable reactions in a configuration becomes small.\nAs a Python library, ppsim also includes many useful tools for data\nvisualization in Jupyter notebooks, allowing robust visualization of time\ndynamics such as histogram plots at time snapshots and averaging repeated\ntrials.\n  Finally, we give a framework that takes any CRN with only bimolecular (2\nreactant, 2 product) or unimolecular (1 reactant, 1 product) reactions, with\narbitrary rate constants, and compiles it into a continuous-time population\nprotocol. This lets ppsim exactly sample from the chemical master equation\n(unlike approximate heuristics such as tau-leaping or LNA), while achieving\nasymptotic gains in running time. In linked Jupyter notebooks, we demonstrate\nthe efficacy of the tool on some protocols of interest in molecular\nprogramming, including the approximate majority CRN and CRN models of DNA\nstrand displacement reactions.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:05:28 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 23:10:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Doty", "David", ""], ["Severson", "Eric", ""]]}, {"id": "2105.04712", "submitter": "Aleksandar Nikolov", "authors": "Deepanshu Kush, Aleksandar Nikolov, Haohua Tang", "title": "Near Neighbor Search via Efficient Average Distortion Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent series of papers by Andoni, Naor, Nikolov, Razenshteyn, and\nWaingarten (STOC 2018, FOCS 2018) has given approximate near neighbour search\n(NNS) data structures for a wide class of distance metrics, including all\nnorms. In particular, these data structures achieve approximation on the order\nof $p$ for $\\ell_p^d$ norms with space complexity nearly linear in the dataset\nsize $n$ and polynomial in the dimension $d$, and query time sub-linear in $n$\nand polynomial in $d$. The main shortcoming is the exponential in $d$\npre-processing time required for their construction.\n  In this paper, we describe a more direct framework for constructing NNS data\nstructures for general norms. More specifically, we show via an algorithmic\nreduction that an efficient NNS data structure for a given metric is implied by\nan efficient average distortion embedding of it into $\\ell_1$ or into Euclidean\nspace. In particular, the resulting data structures require only polynomial\npre-processing time, as long as the embedding can be computed in polynomial\ntime. As a concrete instantiation of this framework, we give an NNS data\nstructure for $\\ell_p$ with efficient pre-processing that matches the\napproximation factor, space and query complexity of the aforementioned data\nstructure of Andoni et al. On the way, we resolve a question of Naor (Analysis\nand Geometry in Metric Spaces, 2014) and provide an explicit, efficiently\ncomputable embedding of $\\ell_p$, for $p \\ge 2$, into $\\ell_2$ with (quadratic)\naverage distortion on the order of $p$. We expect our approach to pave the way\nfor constructing efficient NNS data structures for all norms.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:49:35 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kush", "Deepanshu", ""], ["Nikolov", "Aleksandar", ""], ["Tang", "Haohua", ""]]}, {"id": "2105.04735", "submitter": "Susumu Hashimoto", "authors": "Susumu Hashimoto and Shinji Mizuno", "title": "A 3-approximation list scheduling algorithm for a single-machine\n  scheduling problem with a non-renewable resource and total weighted\n  completion time criterion", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a single-machine scheduling problem with a non-renewable\nresource (NR-SSP) and total weighted completion time criterion. The\nnon-renewable resource is consumed when the machine starts processing a job. We\nconsider the case where each job's weight in the objective function is\nproportional to its resource consumption amount. The problem is known to be\nNP-hard in this case. We propose a 3-approximation list scheduling algorithm\nfor this problem. Besides, we show that the approximation ratio 3 is tight for\nthe algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 01:11:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Hashimoto", "Susumu", ""], ["Mizuno", "Shinji", ""]]}, {"id": "2105.04802", "submitter": "Tatsuya Akutsu", "authors": "Tatsuya Akutsu, Tomoya Mori, Naotoshi Nakamura, Satoshi Kozawa, Yuhei\n  Ueno, Thomas N. Sato", "title": "Tree Edit Distance with Variables. Measuring the Similarity between\n  Mathematical Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we propose tree edit distance with variables, which is an\nextension of the tree edit distance to handle trees with variables and has a\npotential application to measuring the similarity between mathematical\nformulas, especially, those appearing in mathematical models of biological\nsystems. We analyze the computational complexities of several variants of this\nnew model. In particular, we show that the problem is NP-complete for ordered\ntrees. We also show for unordered trees that the problem of deciding whether or\nnot the distance is 0 is graph isomorphism complete but can be solved in\npolynomial time if the maximum outdegree of input trees is bounded by a\nconstant. This distance model is then extended for measuring the\ndifference/similarity between two systems of differential equations, for which\nresults of preliminary computational experiments using biological models are\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 06:29:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Akutsu", "Tatsuya", ""], ["Mori", "Tomoya", ""], ["Nakamura", "Naotoshi", ""], ["Kozawa", "Satoshi", ""], ["Ueno", "Yuhei", ""], ["Sato", "Thomas N.", ""]]}, {"id": "2105.04809", "submitter": "Reut Levi", "authors": "Reut Levi", "title": "Testing Triangle Freeness in the General Model in Graphs with Arboricity\n  $O(\\sqrt{n})$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing triangle freeness in the general graph model.\nThis problem was first studied in the general graph model by Alon et al. (SIAM\nJ. Discret. Math. 2008) who provided both lower bounds and upper bounds that\ndepend on the number of vertices and the average degree of the graph. Their\nbounds are tight only when $d_{\\rm max} = O(d)$ and $\\bar{d} \\leq \\sqrt{n}$ or\nwhen $\\bar{d} = \\Theta(1)$, where $d_{\\rm max}$ denotes the maximum degree and\n$\\bar{d}$ denotes the average degree of the graph. In this paper we provide\nbounds that depend on the arboricity of the graph and the average degree. As in\nAlon et al., the parameters of our tester is the number of vertices, $n$, the\nnumber of edges, $m$, and the proximity parameter $\\epsilon$ (the arboricity of\nthe graph is not a parameter of the algorithm). The query complexity of our\ntester is $\\tilde{O}(\\Gamma/\\bar{d} + \\Gamma)\\cdot poly(1/\\epsilon)$ on\nexpectation, where $\\Gamma$ denotes the arboricity of the input graph (we use\n$\\tilde{O}(\\cdot)$ to suppress $O(\\log \\log n)$ factors). We show that for\ngraphs with arboricity $O(\\sqrt{n})$ this upper bound is tight in the following\nsense. For any $\\Gamma \\in [s]$ where $s= \\Theta(\\sqrt{n})$ there exists a\nfamily of graphs with arboricity $\\Gamma$ and average degree $\\bar{d}$ such\nthat $\\Omega(\\Gamma/\\bar{d} + \\Gamma)$ queries are required for testing\ntriangle freeness on this family of graphs. Moreover, this lower bound holds\nfor any such $\\Gamma$ and for a large range of feasible average degrees.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 06:47:22 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Levi", "Reut", ""]]}, {"id": "2105.04847", "submitter": "Reut Levi", "authors": "Rubi Arviv and Reut Levi", "title": "Improved LCAs for constructing spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of constructing spanners in a local\nmanner, specifically in the Local Computation Model proposed by Rubinfeld et\nal. (ICS 2011).\n  We provide an LCA for constructing $(2r-1)$-spanners with\n$\\widetilde{O}(n^{1+1/r})$ edges and probe complexity of\n$\\widetilde{O}(n^{1-1/r})$ $r \\in \\{2,3\\}$, where $n$ denotes the number of\nvertices in the input graph. Up to polylogarithmic factors, in both cases the\nstretch factor is optimal (for the respective number of edges). In addition,\nour probe complexity for $r=2$, i.e., for constructing $3$-spanner is optimal\nup to polylogarithmic factors. Our result improves over the probe complexity of\nParter et al. (ITCS 2019) that is $\\widetilde{O}(n^{1-1/2r})$ for $r \\in\n\\{2,3\\}$.\n  For general $k\\geq 1$, we provide an LCA for constructing $O(k^2)$-spanners\nwith $\\tilde{O}(n^{1+1/k})$ edges on expectation whose probe complexity is\n$O(n^{2/3}\\Delta^2)$. This improves over the probe complexity of Parter et al.\nthat is $O(n^{2/3}\\Delta^4)$.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:06:59 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Arviv", "Rubi", ""], ["Levi", "Reut", ""]]}, {"id": "2105.04856", "submitter": "Leon Kellerhals", "authors": "Leon Kellerhals, Malte Renken and Philipp Zschoche", "title": "Parameterized Algorithms for Diverse Multistage Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is rarely static -- many problems need not only be solved once but\nrepeatedly, under changing conditions. This setting is addressed by the\n\"multistage\" view on computational problems. We study the \"diverse multistage\"\nvariant, where consecutive solutions of large variety are preferable to similar\nones, e.g. for reasons of fairness or wear minimization. While some aspects of\nthis model have been tackled before, we introduce a framework allowing us to\nprove that a number of diverse multistage problems are fixed-parameter\ntractable by diversity, namely Perfect Matching, s-t Path, Matroid Independent\nSet, and Plurality Voting. This is achieved by first solving special, colored\nvariants of these problems, which might also be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:15:14 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kellerhals", "Leon", ""], ["Renken", "Malte", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2105.04965", "submitter": "Travis Gagie", "authors": "Travis Gagie and Sebastian Wild", "title": "Succinct Euler-Tour Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how a collection of Euler-tour trees for a forest on $n$ vertices can\nbe stored in $2 n + o (n)$ bits such that simple queries take constant time,\nmore complex queries take logarithmic time and updates take polylogarithmic\namortized time.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:01:51 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 17:58:17 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gagie", "Travis", ""], ["Wild", "Sebastian", ""]]}, {"id": "2105.04993", "submitter": "Dominique Lavenier", "authors": "Dominique Lavenier", "title": "Constrained Consensus Sequence Algorithm for DNA Archiving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper describes an algorithm to compute a consensus sequence from a set\nof DNA sequences of approximatively identical length generated by 3rd\nsequencing generation technologies. Its purpose targets DNA storage and is\nguided by specific features that cannot be exhibited from biological data such\nas the exact length of the consensus sequences, the precise location of known\npatterns, the kmer composition, etc.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:53:25 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lavenier", "Dominique", ""]]}, {"id": "2105.05062", "submitter": "Karl Bringmann", "authors": "Karl Bringmann and Jasper Slusallek", "title": "Current Algorithms for Detecting Subgraphs of Bounded Treewidth are\n  Probably Optimal", "comments": "Full version of ICALP 2021 paper, 55 pages, abstract shortened to fit\n  ArXiv requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Subgraph Isomorphism problem is of considerable importance in computer\nscience. We examine the problem when the pattern graph H is of bounded\ntreewidth, as occurs in a variety of applications. This problem has a\nwell-known algorithm via color-coding that runs in time $O(n^{tw(H)+1})$ [Alon,\nYuster, Zwick'95], where $n$ is the number of vertices of the host graph $G$.\nWhile there are pattern graphs known for which Subgraph Isomorphism can be\nsolved in an improved running time of $O(n^{tw(H)+1-\\varepsilon})$ or even\nfaster (e.g. for $k$-cliques), it is not known whether such improvements are\npossible for all patterns. The only known lower bound rules out time\n$n^{o(tw(H) / \\log(tw(H)))}$ for any class of patterns of unbounded treewidth\nassuming the Exponential Time Hypothesis [Marx'07].\n  In this paper, we demonstrate the existence of maximally hard pattern graphs\n$H$ that require time $n^{tw(H)+1-o(1)}$. Specifically, under the Strong\nExponential Time Hypothesis (SETH), a standard assumption from fine-grained\ncomplexity theory, we prove the following asymptotic statement for large\ntreewidth $t$: For any $\\varepsilon > 0$ there exists $t \\ge 3$ and a pattern\ngraph $H$ of treewidth $t$ such that Subgraph Isomorphism on pattern $H$ has no\nalgorithm running in time $O(n^{t+1-\\varepsilon})$.\n  Under the more recent 3-uniform Hyperclique hypothesis, we even obtain tight\nlower bounds for each specific treewidth $t \\ge 3$: For any $t \\ge 3$ there\nexists a pattern graph $H$ of treewidth $t$ such that for any $\\varepsilon>0$\nSubgraph Isomorphism on pattern $H$ has no algorithm running in time\n$O(n^{t+1-\\varepsilon})$.\n  In addition to these main results, we explore (1) colored and uncolored\nproblem variants (and why they are equivalent for most cases), (2) Subgraph\nIsomorphism for $tw < 3$, (3) Subgraph Isomorphism parameterized by pathwidth,\nand (4) a weighted problem variant.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 14:12:43 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bringmann", "Karl", ""], ["Slusallek", "Jasper", ""]]}, {"id": "2105.05130", "submitter": "Li Wang", "authors": "Li Wang", "title": "Towards a Model for LSH", "comments": "arXiv admin note: text overlap with arXiv:2103.01888", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As data volumes continue to grow, clustering and outlier detection algorithms\nare becoming increasingly time-consuming. Classical index structures for\nneighbor search are no longer sustainable due to the \"curse of dimensionality\".\nInstead, approximated index structures offer a good opportunity to\nsignificantly accelerate the neighbor search for clustering and outlier\ndetection and to have the lowest possible error rate in the results of the\nalgorithms. Locality-sensitive hashing is one of those. We indicate directions\nto model the properties of LSH.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 15:39:55 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Wang", "Li", ""]]}, {"id": "2105.05383", "submitter": "Jingwei Chen", "authors": "Jingwei Chen, Yong Feng, Yang Liu and Wenyuan Wu", "title": "On the probability of generating a primitive matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a $k\\times n$ integer primitive matrix $A$ (i.e., a matrix can be\nextended to an $n\\times n$ unimodular matrix over the integers) with size of\nentries bounded by $\\lambda$, we study the probability that the $m\\times n$\nmatrix extended from $A$ by choosing other $m-k$ vectors uniformly at random\nfrom $\\{0, 1, \\ldots, \\lambda-1\\}$ is still primitive. We present a complete\nand rigorous proof that the probability is at least a constant for the case of\n$m\\le n-4$. Previously, only the limit case for $\\lambda\\rightarrow\\infty$ with\n$k=0$ was analysed in Maze et al. (2011), known as the natural density. As an\napplication, we prove that there exists a fast Las Vegas algorithm that\ncompletes a $k\\times n$ primitive matrix $A$ to an $n\\times n$ unimodular\nmatrix within expected $\\tilde{O}(n^{\\omega}\\log \\|A\\|)$ bit operations, where\n$\\tilde{O}$ is big-$O$ but without log factors, $\\omega$ is the exponent on the\narithmetic operations of matrix multiplication and $\\|A\\|$ is the maximal\nabsolute value of entries of $A$.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 01:03:20 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Chen", "Jingwei", ""], ["Feng", "Yong", ""], ["Liu", "Yang", ""], ["Wu", "Wenyuan", ""]]}, {"id": "2105.05495", "submitter": "Meenakshi D'Souza", "authors": "Aritra Bhowmick, Meenakshi D'Souza, G. Srinivasa Raghavan", "title": "LipBaB: Computing exact Lipschitz constant of ReLU networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Lipschitz constant of neural networks plays an important role in several\ncontexts of deep learning ranging from robustness certification and\nregularization to stability analysis of systems with neural network\ncontrollers. Obtaining tight bounds of the Lipschitz constant is therefore\nimportant. We introduce LipBaB, a branch and bound framework to compute\ncertified bounds of the local Lipschitz constant of deep neural networks with\nReLU activation functions up to any desired precision. We achieve this by\nbounding the norm of the Jacobians, corresponding to different activation\npatterns of the network caused within the input domain. Our algorithm can\nprovide provably exact computation of the Lipschitz constant for any p-norm.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:06:11 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 06:25:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bhowmick", "Aritra", ""], ["D'Souza", "Meenakshi", ""], ["Raghavan", "G. Srinivasa", ""]]}, {"id": "2105.05503", "submitter": "Oshan Mudannayake", "authors": "Oshan Mudannayake, Nalin Ranasinghe", "title": "kMatrix: A Space Efficient Streaming Graph Summarization Technique", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The amount of collected information on data repositories has vastly increased\nwith the advent of the internet. It has become increasingly complex to deal\nwith these massive data streams due to their sheer volume and the throughput of\nincoming data. Many of these data streams are mapped into graphs, which helps\ndiscover some of their properties. However, due to the difficulty in processing\nmassive streaming graphs, they are summarized such that their properties can be\napproximately evaluated using the summaries. gSketch, TCM, and gMatrix are some\nof the major streaming graph summarization techniques. Our primary contribution\nis devising kMatrix, which is much more memory efficient than existing\nstreaming graph summarization techniques. We achieved this by partitioning the\nallocated memory using a sample of the original graph stream. Through the\nexperiments, we show that kMatrix can achieve a significantly less error for\nthe queries using the same space as that of TCM and gMatrix.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:26:49 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mudannayake", "Oshan", ""], ["Ranasinghe", "Nalin", ""]]}, {"id": "2105.05555", "submitter": "Honghao Lin", "authors": "Yu Cheng and Honghao Lin", "title": "Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Bayesian networks where an\n$\\epsilon$-fraction of the samples are adversarially corrupted. We focus on the\nfully-observable case where the underlying graph structure is known. In this\nwork, we present the first nearly-linear time algorithm for this problem with a\ndimension-independent error guarantee. Previous robust algorithms with\ncomparable error guarantees are slower by at least a factor of $(d/\\epsilon)$,\nwhere $d$ is the number of variables in the Bayesian network and $\\epsilon$ is\nthe fraction of corrupted samples.\n  Our algorithm and analysis are considerably simpler than those in previous\nwork. We achieve this by establishing a direct connection between robust\nlearning of Bayesian networks and robust mean estimation. As a subroutine in\nour algorithm, we develop a robust mean estimation algorithm whose runtime is\nnearly-linear in the number of nonzeros in the input samples, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:11:32 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Cheng", "Yu", ""], ["Lin", "Honghao", ""]]}, {"id": "2105.05574", "submitter": "Yannic Maus", "authors": "Alkida Balliu, Keren Censor-Hillel, Yannic Maus, Dennis Olivetti,\n  Jukka Suomela", "title": "Locally Checkable Labelings with Small Messages", "comments": "fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rich line of work has been addressing the computational complexity of\nlocally checkable labelings (LCLs), illustrating the landscape of possible\ncomplexities. In this paper, we study the landscape of LCL complexities under\nbandwidth restrictions. Our main results are twofold. First, we show that on\ntrees, the CONGEST complexity of an LCL problem is asymptotically equal to its\ncomplexity in the LOCAL model. An analog statement for general (non-LCL)\nproblems is known to be false. Second, we show that for general graphs this\nequivalence does not hold, by providing an LCL problem for which we show that\nit can be solved in $O(\\log n)$ rounds in the LOCAL model, but requires\n$\\tilde{\\Omega}(n^{1/2})$ rounds in the CONGEST model.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:50:43 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 09:47:30 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Balliu", "Alkida", ""], ["Censor-Hillel", "Keren", ""], ["Maus", "Yannic", ""], ["Olivetti", "Dennis", ""], ["Suomela", "Jukka", ""]]}, {"id": "2105.05575", "submitter": "Yannic Maus", "authors": "Yannic Maus", "title": "Distributed Graph Coloring Made Easy", "comments": "SPAA 2021 v2: removed typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a deterministic CONGEST algorithm to compute an\n$O(k\\Delta)$-vertex coloring in $O(\\Delta/k)+\\log^* n$ rounds, where $\\Delta$\nis the maximum degree of the network graph and $1\\leq k\\leq O(\\Delta)$ can be\nfreely chosen. The algorithm is extremely simple: Each node locally computes a\nsequence of colors and then it \"tries colors\" from the sequence in batches of\nsize $k$. Our algorithm subsumes many important results in the history of\ndistributed graph coloring as special cases, including Linial's color reduction\n[Linial, FOCS'87], the celebrated locally iterative algorithm from [Barenboim,\nElkin, Goldenberg, PODC'18], and various algorithms to compute defective and\narbdefective colorings. Our algorithm can smoothly scale between these and also\nsimplifies the state of the art $(\\Delta+1)$-coloring algorithm. At the cost of\nlosing the full algorithm's simplicity we also provide a $O(k\\Delta)$-coloring\nalgorithm in $O(\\sqrt{\\Delta/k})+\\log^* n$ rounds. We also provide improved\ndeterministic algorithms for ruling sets, and, additionally, we provide a tight\ncharacterization for one-round color reduction algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:50:56 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 09:18:09 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Maus", "Yannic", ""]]}, {"id": "2105.05626", "submitter": "Yuri Gurevich", "authors": "Yuri Gurevich", "title": "Reversify any sequential algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reversify an arbitrary sequential algorithm $A$, we gently instrument $A$\nwith bookkeeping machinery. The result is a step-for-step reversible algorithm\nthat mimics $A$ step-for-step and stops exactly when $A$ does.\n  Without loss of generality, we presume that algorithm $A$ is presented as an\nabstract state machine that is behaviorally identical to $A$. The existence of\nsuch representation has been proven theoretically, and the practicality of such\nrepresentation has been amply demonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 12:48:24 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 22:27:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gurevich", "Yuri", ""]]}, {"id": "2105.05637", "submitter": "Ivo Sbalzarini", "authors": "Johannes Bamme, Ivo F. Sbalzarini", "title": "A Mathematical Definition of Particle Methods", "comments": "35 pages, 38 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We provide a formal definition for a class of algorithms known as \"particle\nmethods\". Particle methods are used in scientific computing. They include\npopular simulation methods, such as Discrete Element Methods (DEM), Molecular\nDynamics (MD), Particle Strength Exchange (PSE), and Smoothed Particle\nHydrodynamics (SPH), but also particle-based image processing methods,\npoint-based computer graphics, and computational optimization algorithms using\npoint samples. All of these rest on a common concept, which we here formally\ndefine. The presented definition of particle methods makes it possible to\ndistinguish what formally constitutes a particle method, and what not. It also\nenables us to define different sub-classes of particle methods that differ with\nrespect to their computational complexity and power. Our definition is purely\nformal, independent of any application. After stating the definition, we\ntherefore illustrate how several well-known particle methods can be formalized\nin our framework, and we show how the formal definition can be used to\nformulate novel particle methods for non-canonical problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 13:09:31 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bamme", "Johannes", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "2105.05673", "submitter": "Joakim Blikstad", "authors": "Joakim Blikstad", "title": "Breaking O(nr) for Matroid Intersection", "comments": "17 pages; also at ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present algorithms that break the $\\tilde O(nr)$-independence-query bound\nfor the Matroid Intersection problem for the full range of $r$; where $n$ is\nthe size of the ground set and $r\\leq n$ is the size of the largest common\nindependent set. The $\\tilde O(nr)$ bound was due to the efficient\nimplementations [CLSSW FOCS'19; Nguyen 2019] of the classic algorithm of\nCunningham [SICOMP'86]. It was recently broken for large $r$\n($r=\\omega(\\sqrt{n})$), first by the $\\tilde O(n^{1.5}/\\epsilon^{1.5})$-query\n$(1-\\epsilon)$-approximation algorithm of CLSSW [FOCS'19], and subsequently by\nthe $\\tilde O(n^{6/5}r^{3/5})$-query exact algorithm of BvdBMN [STOC'21]. No\nalgorithm, even an approximation one, was known to break the $\\tilde O(nr)$\nbound for the full range of $r$. We present an $\\tilde\nO(n\\sqrt{r}/\\epsilon)$-query $(1-\\epsilon)$-approximation algorithm and an\n$\\tilde O(nr^{3/4})$-query exact algorithm. Our algorithms improve the $\\tilde\nO(nr)$ bound and also the bounds by CLSSW and BvdBMN for the full range of $r$.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 14:13:13 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Blikstad", "Joakim", ""]]}, {"id": "2105.05685", "submitter": "Florian Ingels", "authors": "Florian Ingels, Romain Aza\\\"is", "title": "Isomorphic unordered labeled trees up to substitution ciphering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given two messages - as linear sequences of letters, it is immediate to\ndetermine whether one can be transformed into the other by simple substitution\ncipher of the letters. On the other hand, if the letters are carried as labels\non nodes of topologically isomorphic unordered trees, determining if a\nsubstitution exists is referred to as marked tree isomorphism problem in the\nliterature and has been show to be as hard as graph isomorphism. While the\nleft-to-right direction provides the cipher of letters in the case of linear\nmessages, if the messages are carried by unordered trees, the cipher is given\nby a tree isomorphism. The number of isomorphisms between two trees is roughly\nexponential in the size of the trees, which makes the problem of finding a\ncipher difficult by exhaustive search. This paper presents a method that aims\nto break the combinatorics of the isomorphisms search space. We show that in a\nlinear time (in the size of the trees), we reduce the cardinality of this space\nby an exponential factor on average.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 14:23:37 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Ingels", "Florian", ""], ["Aza\u00efs", "Romain", ""]]}, {"id": "2105.05698", "submitter": "Kevin Thompson", "authors": "Ojas Parekh and Kevin Thompson", "title": "Application of the Level-$2$ Quantum Lasserre Hierarchy in Quantum\n  Approximation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND Number: SAND2021-5796 O", "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasserre Hierarchy is a set of semidefinite programs which yield\nincreasingly tight bounds on optimal solutions to many NP-hard optimization\nproblems. The hierarchy is parameterized by levels, with a higher level\ncorresponding to a more accurate relaxation. High level programs have proven to\nbe invaluable components of approximation algorithms for many NP-hard\noptimization problems. There is a natural analogous quantum hierarchy, which is\nalso parameterized by level and provides a relaxation of many (QMA-hard)\nquantum problems of interest. In contrast to the classical case, however, there\nis only one approximation algorithm which makes use of higher levels of the\nhierarchy. Here we provide the first ever use of the level-$2$ hierarchy in an\napproximation algorithm for a particular QMA-complete problem, so-called\nQuantum Max Cut. We obtain modest improvements on state-of-the-art\napproximation factors for this problem, as well as demonstrate that the\nlevel-$2$ hierarchy satisfies many physically-motivated constraints that the\nlevel-$1$ does not satisfy. Indeed, this observation is at the heart of our\nanalysis and indicates that higher levels of the quantum Lasserre Hierarchy may\nbe very useful tools in the design of approximation algorithms for QMA-complete\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 14:33:27 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Parekh", "Ojas", ""], ["Thompson", "Kevin", ""]]}, {"id": "2105.05725", "submitter": "Manuel Sorge", "authors": "Jiehua Chen, Adrian Chmurovic, Fabian Jogl, and Manuel Sorge", "title": "On (Coalitional) Exchange-Stable Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study (coalitional) exchange stability, which Alcalde [Economic Design,\n1995] introduced as an alternative solution concept for matching markets\ninvolving property rights, such as assigning persons to two-bed rooms. Here, a\nmatching of a given Stable Marriage or Stable Roommates instance is called\ncoalitional exchange-stable if it does not admit any exchange-blocking\ncoalition, that is, a subset S of agents in which everyone prefers the partner\nof some other agent in S. The matching is exchange-stable if it does not admit\nany exchange-blocking pair, that is, an exchange-blocking coalition of size\ntwo.\n  We investigate the computational and parameterized complexity of the\nCoalitional Exchange-Stable Marriage (resp. Coalitional Exchange Roommates)\nproblem, which is to decide whether a Stable Marriage (resp. Stable Roommates)\ninstance admits a coalitional exchange-stable matching. Our findings resolve an\nopen question and confirm the conjecture of Cechl\\'arov\\'a and Manlove\n[Discrete Applied Mathematics, 2005] that Coalitional Exchange-Stable Marriage\nis NP-hard even for complete preferences without ties. We also study\nbounded-length preference lists and a local-search variant of deciding whether\na given matching can reach an exchange-stable one after at most k swaps, where\na swap is defined as exchanging the partners of the two agents in an\nexchange-blocking pair.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:17:35 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:12:37 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "Jiehua", ""], ["Chmurovic", "Adrian", ""], ["Jogl", "Fabian", ""], ["Sorge", "Manuel", ""]]}, {"id": "2105.05761", "submitter": "Alexandr Andoni", "authors": "Alexandr Andoni, David Cheikhi", "title": "From Average Embeddings To Nearest Neighbor Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, we show that one can use average embeddings, introduced\nrecently in [Naor'20, arXiv:1905.01280], to obtain efficient algorithms for\napproximate nearest neighbor search. In particular, a metric $X$ embeds into\n$\\ell_2$ on average, with distortion $D$, if, for any distribution $\\mu$ on\n$X$, the embedding is $D$ Lipschitz and the (square of) distance does not\ndecrease on average (wrt $\\mu$). In particular existence of such an embedding\n(assuming it is efficient) implies a $O(D^3)$ approximate nearest neighbor\nsearch under $X$. This can be seen as a strengthening of the classic\n(bi-Lipschitz) embedding approach to nearest neighbor search, and is another\napplication of data-dependent hashing paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:28:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Andoni", "Alexandr", ""], ["Cheikhi", "David", ""]]}, {"id": "2105.05782", "submitter": "Sainyam Galhotra", "authors": "Raghavendra Addanki, Sainyam Galhotra, Barna Saha", "title": "How to Design Robust Algorithms using Noisy Comparison Oracle", "comments": "PVLDB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metric based comparison operations such as finding maximum, nearest and\nfarthest neighbor are fundamental to studying various clustering techniques\nsuch as $k$-center clustering and agglomerative hierarchical clustering. These\ntechniques crucially rely on accurate estimation of pairwise distance between\nrecords. However, computing exact features of the records, and their pairwise\ndistances is often challenging, and sometimes not possible. We circumvent this\nchallenge by leveraging weak supervision in the form of a comparison oracle\nthat compares the relative distance between the queried points such as `Is\npoint u closer to v or w closer to x?'.\n  However, it is possible that some queries are easier to answer than others\nusing a comparison oracle. We capture this by introducing two different noise\nmodels called adversarial and probabilistic noise. In this paper, we study\nvarious problems that include finding maximum, nearest/farthest neighbor search\nunder these noise models. Building upon the techniques we develop for these\ncomparison operations, we give robust algorithms for k-center clustering and\nagglomerative hierarchical clustering. We prove that our algorithms achieve\ngood approximation guarantees with a high probability and analyze their query\ncomplexity. We evaluate the effectiveness and efficiency of our techniques\nempirically on various real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:58:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Addanki", "Raghavendra", ""], ["Galhotra", "Sainyam", ""], ["Saha", "Barna", ""]]}, {"id": "2105.05784", "submitter": "Christian Rieck", "authors": "Jakob Keller, Christian Rieck, Christian Scheffer, Arne Schmidt", "title": "Particle-Based Assembly Using Precise Global Control", "comments": "20 pages, 12 figures, full version of an extended abstract accepted\n  for publication in the proceedings of the 17th Algorithms and Data Structures\n  Symposium (WADS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In micro- and nano-scale systems, particles can be moved by using an external\nforce like gravity or a magnetic field. In the presence of adhesive particles\nthat can attach to each other, the challenge is to decide whether a shape is\nconstructible. Previous work provides a class of shapes for which\nconstructibility can be decided efficiently, when particles move maximally into\nthe same direction on actuation.\n  In this paper, we consider a stronger model. On actuation, each particle\nmoves one unit step into the given direction. We prove that deciding\nconstructibility is NP-hard for three-dimensional shapes, and that a maximum\nconstructible shape can be approximated. The same approximation algorithm\napplies for 2D. We further present linear-time algorithms to decide whether a\ntree-shape in 2D or 3D is constructible. If scaling is allowed, we show that\nthe $c$-scaled copy of every non-degenerate polyomino is constructible, for\nevery $c \\geq 2$.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:00:12 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Keller", "Jakob", ""], ["Rieck", "Christian", ""], ["Scheffer", "Christian", ""], ["Schmidt", "Arne", ""]]}, {"id": "2105.05911", "submitter": "Christopher Morris", "authors": "Christopher Morris, Matthias Fey, Nils M. Kriege", "title": "The Power of the Weisfeiler-Leman Algorithm for Machine Learning with\n  Graphs", "comments": "Accepted at IJCAI 2021 (survey track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, algorithms and neural architectures based on the\nWeisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism\nproblem, emerged as a powerful tool for (supervised) machine learning with\ngraphs and relational data. Here, we give a comprehensive overview of the\nalgorithm's use in a machine learning setting. We discuss the theoretical\nbackground, show how to use it for supervised graph- and node classification,\ndiscuss recent extensions, and its connection to neural architectures.\nMoreover, we give an overview of current applications and future directions to\nstimulate research.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 19:05:18 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 05:04:15 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Morris", "Christopher", ""], ["Fey", "Matthias", ""], ["Kriege", "Nils M.", ""]]}, {"id": "2105.05923", "submitter": "Leah Epstein", "authors": "Leah Epstein", "title": "Open-end bin packing: new and old analysis approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a recently introduced concept, called the price of clustering, for\nvariants of bin packing called open-end bin packing problems (OEBP). Input\nitems have sizes, and they also belong to a certain number of types. The new\nconcept deals with the comparison of optimal solutions for the cases where\nitems of distinct types can and cannot be packed together, respectively. The\nproblem is related to greedy bin packing algorithms and to batched bin packing,\nand we discuss some of those concepts as well. We analyze max-OEBP, where a\npacked bin is valid if by excluding its largest item, the total size of items\nis below 1. For this variant, we study the case of general item sizes, and the\nparametric case with bounded item sizes, which shows the effect of small items.\nFinally, we briefly discuss min-OEBP, where a bin is valid if the total size of\nits items excluding the smallest item is below 1, which is known to be an\nentirely different problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 19:32:47 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Epstein", "Leah", ""]]}, {"id": "2105.05984", "submitter": "Nick Fischer", "authors": "Karl Bringmann, Nick Fischer, Vasileios Nakos", "title": "Sparse Nonnegative Convolution Is Equivalent to Dense Nonnegative\n  Convolution", "comments": "44 pages, appears in STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing the convolution $A\\star B$ of two length-$n$ vectors $A,B$ is an\nubiquitous computational primitive. Applications range from string problems to\nKnapsack-type problems, and from 3SUM to All-Pairs Shortest Paths. These\napplications often come in the form of nonnegative convolution, where the\nentries of $A,B$ are nonnegative integers. The classical algorithm to compute\n$A\\star B$ uses the Fast Fourier Transform and runs in time $O(n\\log n)$.\n  However, often $A$ and $B$ satisfy sparsity conditions, and hence one could\nhope for significant improvements. The ideal goal is an $O(k\\log k)$-time\nalgorithm, where $k$ is the number of non-zero elements in the output, i.e.,\nthe size of the support of $A\\star B$. This problem is referred to as sparse\nnonnegative convolution, and has received considerable attention in the\nliterature; the fastest algorithms to date run in time $O(k\\log^2 n)$.\n  The main result of this paper is the first $O(k\\log k)$-time algorithm for\nsparse nonnegative convolution. Our algorithm is randomized and assumes that\nthe length $n$ and the largest entry of $A$ and $B$ are subexponential in $k$.\nSurprisingly, we can phrase our algorithm as a reduction from the sparse case\nto the dense case of nonnegative convolution, showing that, under some mild\nassumptions, sparse nonnegative convolution is equivalent to dense nonnegative\nconvolution for constant-error randomized algorithms. Specifically, if $D(n)$\nis the time to convolve two nonnegative length-$n$ vectors with success\nprobability $2/3$, and $S(k)$ is the time to convolve two nonnegative vectors\nwith output size $k$ with success probability $2/3$, then\n$S(k)=O(D(k)+k(\\log\\log k)^2)$.\n  Our approach uses a variety of new techniques in combination with some old\nmachinery from linear sketching and structured linear algebra, as well as new\ninsights on linear hashing, the most classical hash function.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 21:58:37 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 11:59:01 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bringmann", "Karl", ""], ["Fischer", "Nick", ""], ["Nakos", "Vasileios", ""]]}, {"id": "2105.06131", "submitter": "Mingyu Xiao", "authors": "Junqiang Peng and Mingyu Xiao", "title": "A Fast Algorithm for SAT in Terms of Formula Length", "comments": "Accepted by SAT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that the general CNF satisfiability problem can be\nsolved in $O^*(1.0646^L)$ time, where $L$ is the length of the input\nCNF-formula (i.e., the total number of literals in the formula), which improves\nthe current bound $O^*(1.0652^L)$ given by Chen and Liu 12 years ago. Our\nalgorithm is a standard branch-and-search algorithm analyzed by using the\nmeasure-and-conquer method. We avoid the bottleneck in Chen and Liu's algorithm\nby simplifying the branching operation for 4-degree variables and carefully\nanalyzing the branching operation for 5-degree variables. To simplify\ncase-analyses, we also introduce a general framework for analysis, which may be\nable to be used in other problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 08:15:56 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Peng", "Junqiang", ""], ["Xiao", "Mingyu", ""]]}, {"id": "2105.06145", "submitter": "Xiaojun Dong", "authors": "Xiaojun Dong, Yan Gu, Yihan Sun, Yunming Zhang", "title": "Efficient Stepping Algorithms and Implementations for Parallel Shortest\n  Paths", "comments": null, "journal-ref": null, "doi": "10.1145/3350755.3400227", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the single-source shortest-path (SSSP) problem with\npositive edge weights, which is a notoriously hard problem in the parallel\ncontext. In practice, the $\\Delta$-stepping algorithm proposed by Meyer and\nSanders has been widely adopted. However, $\\Delta$-stepping has no known\nworst-case bounds for general graphs. The performance of $\\Delta$-stepping also\nhighly relies on the parameter $\\Delta$. There have also been lots of\nalgorithms with theoretical bounds, such as Radius-stepping, but they either\nhave no implementations available or are much slower than $\\Delta$-stepping in\npractice.\n  We propose a stepping algorithm framework that generalizes existing\nalgorithms such as $\\Delta$-stepping and Radius-stepping. The framework allows\nfor similar analysis and implementations of all stepping algorithms. We also\npropose a new ADT, lazy-batched priority queue (LaB-PQ), that abstracts the\nsemantics of the priority queue needed by the stepping algorithms. We provide\ntwo data structures for LaB-PQ, focusing on theoretical and practical\nefficiency, respectively. Based on the new framework and LaB-PQ, we show two\nnew stepping algorithms, $\\rho$-stepping and $\\Delta^*$-stepping, that are\nsimple, with non-trivial worst-case bounds, and fast in practice.\n  The stepping algorithm framework also provides almost identical\nimplementations for three algorithms: Bellman-Ford, $\\Delta^*$-stepping, and\n$\\rho$-stepping. We compare our code with four state-of-the-art\nimplementations. On five social and web graphs, $\\rho$-stepping is 1.3--2.5x\nfaster than all the existing implementations. On two road graphs, our\n$\\Delta^*$-stepping is at least 14\\% faster than existing implementations,\nwhile $\\rho$-stepping is also competitive. The almost identical implementations\nfor stepping algorithms also allow for in-depth analyses and comparisons among\nthe stepping algorithms in practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 08:50:39 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 22:52:59 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Dong", "Xiaojun", ""], ["Gu", "Yan", ""], ["Sun", "Yihan", ""], ["Zhang", "Yunming", ""]]}, {"id": "2105.06166", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Rapha\\\"el Clifford, Pawe{\\l} Gawrychowski, Tomasz Kociumaka, Daniel P.\n  Martin, Przemys{\\l}aw Uzna\\'nski", "title": "The Dynamic k-Mismatch Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text-to-pattern Hamming distances problem asks to compute the Hamming\ndistances between a given pattern of length $m$ and all length-$m$ substrings\nof a given text of length $n\\ge m$. We focus on the $k$-mismatch version of the\nproblem, where a distance needs to be returned only if it does not exceed a\nthreshold $k$. We assume $n\\le 2m$ (in general, one can partition the text into\noverlapping blocks). In this work, we show data structures for the dynamic\nversion of this problem supporting two operations: An update performs a\nsingle-letter substitution in the pattern or the text, and a query, given an\nindex $i$, returns the Hamming distance between the pattern and the text\nsubstring starting at position $i$, or reports that it exceeds $k$.\n  First, we show a data structure with $\\tilde{O}(1)$ update and $\\tilde{O}(k)$\nquery time. Then we show that $\\tilde{O}(k)$ update and $\\tilde{O}(1)$ query\ntime is also possible. These two provide an optimal trade-off for the dynamic\n$k$-mismatch problem with $k \\le \\sqrt{n}$: we prove that, conditioned on the\nstrong 3SUM conjecture, one cannot simultaneously achieve $k^{1-\\Omega(1)}$\ntime for all operations.\n  For $k\\ge \\sqrt{n}$, we give another lower bound, conditioned on the Online\nMatrix-Vector conjecture, that excludes algorithms taking $n^{1/2-\\Omega(1)}$\ntime per operation. This is tight for constant-sized alphabets: Clifford et al.\n(STACS 2018) achieved $\\tilde{O}(\\sqrt{n})$ time per operation in that case,\nbut with $\\tilde{O}(n^{3/4})$ time per operation for large alphabets. We\nimprove and extend this result with an algorithm that, given $1\\le x\\le k$,\nachieves update time $\\tilde{O}(\\frac{n}{k} +\\sqrt{\\frac{nk}{x}})$ and query\ntime $\\tilde{O}(x)$. In particular, for $k\\ge \\sqrt{n}$, an appropriate choice\nof $x$ yields $\\tilde{O}(\\sqrt[3]{nk})$ time per operation, which is\n$\\tilde{O}(n^{2/3})$ when no threshold $k$ is provided.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 09:51:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Clifford", "Rapha\u00ebl", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Kociumaka", "Tomasz", ""], ["Martin", "Daniel P.", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "2105.06287", "submitter": "Xueyan Tang", "authors": "Mozhengfu Liu, Xueyan Tang", "title": "Analysis of Busy-Time Scheduling on Heterogeneous Machines", "comments": "Extended version of a paper that will appear in ACM SPAA '21\n  conference", "journal-ref": null, "doi": "10.1145/3409964.3461795", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a generalized busy-time scheduling model on heterogeneous\nmachines. The input to the model includes a set of jobs and a set of machine\ntypes. Each job has a size and a time interval during which it should be\nprocessed. Each job is to be placed on a machine for execution. Different types\nof machines have distinct capacities and cost rates. The total size of the jobs\nrunning on a machine must always be kept within the machine's capacity, giving\nrise to placement restrictions for jobs of various sizes among the machine\ntypes. Each machine used is charged according to the time duration in which it\nis busy, i.e., it is processing jobs. The objective is to schedule the jobs\nonto machines to minimize the total cost of all the machines used. We develop\nan $O(1)$-approximation algorithm in the offline setting and an\n$O(\\mu)$-competitive algorithm in the online setting (where $\\mu$ is the\nmax/min job length ratio), both of which are asymptotically optimal.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:34:22 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liu", "Mozhengfu", ""], ["Tang", "Xueyan", ""]]}, {"id": "2105.06322", "submitter": "Maurice Herlihy", "authors": "Yingjie Xue and Maurice Herlihy", "title": "Hedging Against Sore Loser Attacks in Cross-Chain Transactions", "comments": "To apper in PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A *sore loser attack* in cross-blockchain commerce rises when one party\ndecides to halt participation partway through, leaving other parties' assets\nlocked up for a long duration. Although vulnerability to sore loser attacks\ncannot be entirely eliminated, it can be reduced to an arbitrarily low level.\nThis paper proposes new distributed protocols for hedging a range of\ncross-chain transactions in a synchronous communication model, such as\ntwo-party swaps, $n$-party swaps, brokered transactions, and auctions.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:22:04 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 17:21:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Xue", "Yingjie", ""], ["Herlihy", "Maurice", ""]]}, {"id": "2105.06349", "submitter": "Daniel Paulusma", "authors": "Walter Kern and Barnaby Martin and Dani\\\"el Paulusma and Siani Smith\n  and Erik Jan van Leeuwen", "title": "Disjoint Paths and Connected Subgraphs for H-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Disjoint Paths problem is to decide if a graph contains k\npairwise disjoint paths, each connecting a different terminal pair from a set\nof k distinct pairs. We determine, with an exception of two cases, the\ncomplexity of the Disjoint Paths problem for $H$-free graphs. If $k$ is fixed,\nwe obtain the $k$-Disjoint Paths problem, which is known to be polynomial-time\nsolvable on the class of all graphs for every $k \\geq 1$. The latter does no\nlonger hold if we need to connect vertices from terminal sets instead of\nterminal pairs. We completely classify the complexity of $k$-Disjoint Connected\nSubgraphs for $H$-free graphs, and give the same almost-complete classification\nfor Disjoint Connected Subgraphs for $H$-free graphs as for Disjoint Paths.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:06:50 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Kern", "Walter", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Dani\u00ebl", ""], ["Smith", "Siani", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "2105.06357", "submitter": "Kai Gao", "authors": "Kai Gao, Si Wei Feng, Jingjin Yu", "title": "On Minimizing the Number of Running Buffers for Tabletop Rearrangement", "comments": "To appear in Robotics: Science and Systems(RSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For tabletop rearrangement problems with overhand grasps, storage space\noutside the tabletop workspace, or buffers, can temporarily hold objects which\ngreatly facilitates the resolution of a given rearrangement task. This brings\nforth the natural question of how many running buffers are required so that\ncertain classes of tabletop rearrangement problems are feasible. In this work,\nwe examine the problem for both the labeled (where each object has a specific\ngoal pose) and the unlabeled (where goal poses of objects are interchangeable)\nsettings. On the structural side, we observe that finding the minimum number of\nrunning buffers (MRB) can be carried out on a dependency graph abstracted from\na problem instance, and show that computing MRB on dependency graphs is\nNP-hard. We then prove that under both labeled and unlabeled settings, even for\nuniform cylindrical objects, the number of required running buffers may grow\nunbounded as the number of objects to be rearranged increases; we further show\nthat the bound for the unlabeled case is tight. On the algorithmic side, we\ndevelop highly effective algorithms for finding MRB for both labeled and\nunlabeled tabletop rearrangement problems, scalable to over a hundred objects\nunder very high object density. Employing these algorithms, empirical\nevaluations show that random labeled and unlabeled instances, which more\nclosely mimics real-world setups, have much smaller MRBs.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:31:11 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Gao", "Kai", ""], ["Feng", "Si Wei", ""], ["Yu", "Jingjin", ""]]}, {"id": "2105.06399", "submitter": "Ali Jazayeri", "authors": "Ali Jazayeri and Christopher C. Yang", "title": "Frequent Pattern Mining in Continuous-time Temporal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CV cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are used as highly expressive tools in different disciplines. In\nrecent years, the analysis and mining of temporal networks have attracted\nsubstantial attention. Frequent pattern mining is considered an essential task\nin the network science literature. In addition to the numerous applications,\nthe investigation of frequent pattern mining in networks directly impacts other\nanalytical approaches, such as clustering, quasi-clique and clique mining, and\nlink prediction. In nearly all the algorithms proposed for frequent pattern\nmining in temporal networks, the networks are represented as sequences of\nstatic networks. Then, the inter- or intra-network patterns are mined. This\ntype of representation imposes a computation-expressiveness trade-off to the\nmining problem. In this paper, we propose a novel representation that can\npreserve the temporal aspects of the network losslessly. Then, we introduce the\nconcept of constrained interval graphs (CIGs). Next, we develop a series of\nalgorithms for mining the complete set of frequent temporal patterns in a\ntemporal network data set. We also consider four different definitions of\nisomorphism to allow noise tolerance in temporal data collection. Implementing\nthe algorithm for three real-world data sets proves the practicality of the\nproposed algorithm and its capability to discover unknown patterns in various\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 02:47:24 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Jazayeri", "Ali", ""], ["Yang", "Christopher C.", ""]]}, {"id": "2105.06595", "submitter": "Tyler Chen", "authors": "Tyler Chen, Thomas Trogdon, Shashanka Ubaru", "title": "Analysis of stochastic Lanczos quadrature for spectrum approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cumulative empirical spectral measure (CESM) $\\Phi[\\mathbf{A}] :\n\\mathbb{R} \\to [0,1]$ of a $n\\times n$ symmetric matrix $\\mathbf{A}$ is defined\nas the fraction of eigenvalues of $\\mathbf{A}$ less than a given threshold,\ni.e., $\\Phi[\\mathbf{A}](x) := \\sum_{i=1}^{n} \\frac{1}{n}\n{\\large\\unicode{x1D7D9}}[ \\lambda_i[\\mathbf{A}]\\leq x]$. Spectral sums\n$\\operatorname{tr}(f[\\mathbf{A}])$ can be computed as the Riemann--Stieltjes\nintegral of $f$ against $\\Phi[\\mathbf{A}]$, so the task of estimating CESM\narises frequently in a number of applications, including machine learning. We\npresent an error analysis for stochastic Lanczos quadrature (SLQ). We show that\nSLQ obtains an approximation to the CESM within a Wasserstein distance of $t \\:\n| \\lambda_{\\text{max}}[\\mathbf{A}] - \\lambda_{\\text{min}}[\\mathbf{A}] |$ with\nprobability at least $1-\\eta$, by applying the Lanczos algorithm for $\\lceil 12\nt^{-1} + \\frac{1}{2} \\rceil$ iterations to $\\lceil 4 ( n+2 )^{-1}t^{-2}\n\\ln(2n\\eta^{-1}) \\rceil$ vectors sampled independently and uniformly from the\nunit sphere. We additionally provide (matrix-dependent) a posteriori error\nbounds for the Wasserstein and Kolmogorov--Smirnov distances between the output\nof this algorithm and the true CESM. The quality of our bounds is demonstrated\nusing numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 23:46:49 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 03:12:49 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chen", "Tyler", ""], ["Trogdon", "Thomas", ""], ["Ubaru", "Shashanka", ""]]}, {"id": "2105.06676", "submitter": "Rathish Das", "authors": "Zafar Ahmad, Rezaul Chowdhury, Rathish Das, Pramod Ganapathi, Aaron\n  Gregory, Yimin Zhu", "title": "Fast Stencil Computations using Fast Fourier Transforms", "comments": "This paper will appear in the proceedings of SPAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil computations are widely used to simulate the change of state of\nphysical systems across a multidimensional grid over multiple timesteps. The\nstate-of-the-art techniques in this area fall into three groups: cache-aware\ntiled looping algorithms, cache-oblivious divide-and-conquer trapezoidal\nalgorithms, and Krylov subspace methods.\n  In this paper, we present two efficient parallel algorithms for performing\nlinear stencil computations. Current direct solvers in this domain are\ncomputationally inefficient, and Krylov methods require manual labor and\nmathematical training. We solve these problems for linear stencils by using DFT\npreconditioning on a Krylov method to achieve a direct solver which is both\nfast and general. Indeed, while all currently available algorithms for solving\ngeneral linear stencils perform $\\Theta(NT)$ work, where $N$ is the size of the\nspatial grid and $T$ is the number of timesteps, our algorithms perform $o(NT)$\nwork.\n  To the best of our knowledge, we give the first algorithms that use fast\nFourier transforms to compute final grid data by evolving the initial data for\nmany timesteps at once. Our algorithms handle both periodic and aperiodic\nboundary conditions, and achieve polynomially better performance bounds (i.e.,\ncomputational complexity and parallel runtime) than all other existing\nsolutions.\n  Initial experimental results show that implementations of our algorithms that\nevolve grids of roughly $10^7$ cells for around $10^5$ timesteps run orders of\nmagnitude faster than state-of-the-art implementations for periodic stencil\nproblems, and 1.3$\\times$ to 8.5$\\times$ faster for aperiodic stencil problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 07:24:36 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ahmad", "Zafar", ""], ["Chowdhury", "Rezaul", ""], ["Das", "Rathish", ""], ["Ganapathi", "Pramod", ""], ["Gregory", "Aaron", ""], ["Zhu", "Yimin", ""]]}, {"id": "2105.06889", "submitter": "Shay Solomon", "authors": "Sepehr Assadi and Shay Solomon", "title": "Fully Dynamic Set Cover via Hypergraph Maximal Matching: An Optimal\n  Approximation Through a Local Approach", "comments": "Abstract truncated to fit arXiv limits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the (fully) dynamic set cover problem, we have a collection of $m$ sets\nfrom a universe of size $n$ that undergo element insertions and deletions; the\ngoal is to maintain an approximate set cover of the universe after each update.\nWe give an $O(f^2)$ update time algorithm for this problem that achieves an\n$f$-approximation, where $f$ is the maximum number of sets that an element\nbelongs to; under the unique games conjecture, this approximation is best\npossible for any fixed $f$. This is the first algorithm for dynamic set cover\nwith approximation ratio that {exactly} matches $f$ (as opposed to {almost} $f$\nin prior work), as well as the first one with runtime \\emph{independent of\n$n,m$} (for any approximation factor of $o(f^3)$).\n  Prior to our work, the state-of-the-art algorithms for this problem were\n$O(f^2)$ update time algorithms of Gupta et al. [STOC'17] and Bhattacharya et\nal. [IPCO'17] with $O(f^3)$ approximation, and the recent algorithm of\nBhattacharya et al. [FOCS'19] with $O(f \\cdot \\log{n}/\\epsilon^2)$ update time\nand $(1+\\epsilon) \\cdot f$ approximation, improving the $O(f^2 \\cdot\n\\log{n}/\\epsilon^5)$ bound of Abboud et al. [STOC'19].\n  The key technical ingredient of our work is an algorithm for maintaining a\n{maximal} matching in a dynamic hypergraph of rank $r$, where each hyperedge\nhas at most $r$ vertices, which undergoes hyperedge insertions and deletions in\n$O(r^2)$ amortized update time; our algorithm is randomized, and the bound on\nthe update time holds in expectation and with high probability. This result\ngeneralizes the maximal matching algorithm of Solomon [FOCS'16] with constant\nupdate time in ordinary graphs to hypergraphs, and is of independent merit; the\nprevious state-of-the-art algorithms for set cover do not translate to\n(integral) matchings for hypergraphs, let alone a maximal one. Our quantitative\nresult for the set cover problem is [...]\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:21:02 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Assadi", "Sepehr", ""], ["Solomon", "Shay", ""]]}, {"id": "2105.06932", "submitter": "Rudy Raymond", "authors": "Stefan Hillmich and Charles Hadfield and Rudy Raymond and Antonio\n  Mezzacapo and Robert Wille", "title": "Decision Diagrams for Quantum Measurements with Shallow Circuits", "comments": "Omitting labels of vertices in the figures due to the differences of\n  outputs by pdflatex from LuaLaTeX. No changes in contents. 19 pages and 7\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of estimating quantum observables on a collection of\nqubits, given as a linear combination of Pauli operators, with shallow quantum\ncircuits consisting of single-qubit rotations. We introduce estimators based on\nrandomised measurements, which use decision diagrams to sample from probability\ndistributions on measurement bases. This approach generalises previously known\nuniform and locally-biased randomised estimators. The decision diagrams are\nconstructed given target quantum operators and can be optimised considering\ndifferent strategies. We show numerically that the estimators introduced here\ncan produce more precise estimates on some quantum chemistry Hamiltonians,\ncompared to previously known randomised protocols and Pauli grouping methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:23:08 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 01:17:09 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hillmich", "Stefan", ""], ["Hadfield", "Charles", ""], ["Raymond", "Rudy", ""], ["Mezzacapo", "Antonio", ""], ["Wille", "Robert", ""]]}, {"id": "2105.06944", "submitter": "David Wajc", "authors": "Amin Saberi and David Wajc", "title": "The Greedy Algorithm is \\emph{not} Optimal for On-Line Edge Coloring", "comments": "In ICALP21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly three decades ago, Bar-Noy, Motwani and Naor showed that no online\nedge-coloring algorithm can edge color a graph optimally. Indeed, their work,\ntitled \"the greedy algorithm is optimal for on-line edge coloring\", shows that\nthe competitive ratio of $2$ of the na\\\"ive greedy algorithm is best possible\nonline. However, their lower bound required bounded-degree graphs, of maximum\ndegree $\\Delta = O(\\log n)$, which prompted them to conjecture that better\nbounds are possible for higher-degree graphs. While progress has been made\ntowards resolving this conjecture for restricted inputs and arrivals or for\nrandom arrival orders, an answer for fully general \\emph{adversarial} arrivals\nremained elusive.\n  We resolve this thirty-year-old conjecture in the affirmative, presenting a\n$(1.9+o(1))$-competitive online edge coloring algorithm for general graphs of\ndegree $\\Delta = \\omega(\\log n)$ under vertex arrivals. At the core of our\nresults, and of possible independent interest, is a new online algorithm which\nrounds a fractional bipartite matching $x$ online under vertex arrivals,\nguaranteeing that each edge $e$ is matched with probability $(1/2+c)\\cdot x_e$,\nfor a constant $c>0.027$.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:36:42 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Saberi", "Amin", ""], ["Wajc", "David", ""]]}, {"id": "2105.07006", "submitter": "Leon Kellerhals", "authors": "Aleksander Figiel, Leon Kellerhals, Rolf Niedermeier, Matthias Rost,\n  Stefan Schmid and Philipp Zschoche", "title": "Optimal Virtual Network Embeddings for Tree Topologies", "comments": "An extended abstract of this work appears in the Proceedings of the\n  33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of distributed and data-centric applications often critically\ndepends on the interconnecting network. Applications are hence modeled as\nvirtual networks, also accounting for resource demands on links. At the heart\nof provisioning such virtual networks lies the NP-hard Virtual Network\nEmbedding Problem (VNEP): how to jointly map the virtual nodes and links onto a\nphysical substrate network at minimum cost while obeying capacities.\n  This paper studies the VNEP in the light of parameterized complexity. We\nfocus on tree topology substrates, a case often encountered in practice and for\nwhich the VNEP remains NP-hard. We provide the first fixed-parameter algorithm\nfor the VNEP with running time $O(3^r (s+r^2))$ for requests and substrates of\n$r$ and $s$ nodes, respectively. In a computational study our algorithm yields\nrunning time improvements in excess of 200x compared to state-of-the-art\ninteger programming approaches. This makes it comparable in speed to the\nwell-established ViNE heuristic while providing optimal solutions. We\ncomplement our algorithmic study with hardness results for the VNEP and related\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:00:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Figiel", "Aleksander", ""], ["Kellerhals", "Leon", ""], ["Niedermeier", "Rolf", ""], ["Rost", "Matthias", ""], ["Schmid", "Stefan", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2105.07073", "submitter": "Ioannis Xezonakis", "authors": "Ioannis S. Xezonakis, Svoronos Leivadaros", "title": "N-ary Huffman Encoding Using High-Degree Trees -- A Performance\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we implement an n-ary Huffman Encoding and Decoding application\nusing different degrees of tree structures. Our goal is to compare the\nperformance of the algorithm in terms of compression ratio, decompression speed\nand weighted path length when using higher degree trees, compared to the 2-ary\nHuffman Code. The Huffman tree degrees that we compare are 2-ary, 3-ary, 4-ary,\n5-ary, 6-ary, 7-ary, 8-ary and 16-mal. We also present the impact that branch\nprediction has on the performance of the n-ary Huffman Decoding.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 21:24:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Xezonakis", "Ioannis S.", ""], ["Leivadaros", "Svoronos", ""]]}, {"id": "2105.07219", "submitter": "Arindam Khan", "authors": "Max A. Deppert, Klaus Jansen, Arindam Khan, Malin Rau, Malte Tutas", "title": "Peak Demand Minimization via Sliced Strip Packing", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study Nonpreemptive Peak Demand Minimization (NPDM) problem, where we are\ngiven a set of jobs, specified by their processing times and energy\nrequirements. The goal is to schedule all jobs within a fixed time period such\nthat the peak load (the maximum total energy requirement at any time) is\nminimized. This problem has recently received significant attention due to its\nrelevance in smart-grids. Theoretically, the problem is related to the\nclassical strip packing problem (SP). In SP, a given set of axis-aligned\nrectangles must be packed into a fixed-width strip, such that the height of the\nstrip is minimized. NPDM can be modeled as strip packing with slicing and\nstacking constraint: each rectangle may be cut vertically into multiple slices\nand the slices may be packed into the strip as individual pieces. The stacking\nconstraint forbids solutions where two slices of the same rectangle are\nintersected by the same vertical line. Nonpreemption enforces the slices to be\nplaced in contiguous horizontal locations (but may be placed at different\nvertical locations).\n  We obtain a $(5/3+\\epsilon)$-approximation algorithm for the problem. We also\nprovide an asymptotic efficient polynomial-time approximation scheme (AEPTAS)\nwhich generates a schedule for almost all jobs with energy consumption\n$(1+\\epsilon)OPT$. The remaining jobs fit into a thin container of height $1$.\nThe previous best for NPDM was 2.7 approximation based on FFDH [Ranjan et al.\n2015]. One of our key ideas is providing several new lower bounds on the\noptimal solution of a geometric packing, which could be useful in other related\nproblems. These lower bounds help us to obtain approximative solutions based on\nSteinberg's algorithm in many cases. In addition, we show how to split\nschedules generated by the AEPTAS into few segments and to rearrange the\ncorresponding jobs to insert the thin container mentioned above.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 13:13:05 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Deppert", "Max A.", ""], ["Jansen", "Klaus", ""], ["Khan", "Arindam", ""], ["Rau", "Malin", ""], ["Tutas", "Malte", ""]]}, {"id": "2105.07329", "submitter": "Yash Kanoria", "authors": "Yash Kanoria", "title": "Dynamic Matching under Spatial Frictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS econ.TH math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider demand and supply which arise i.i.d. uniformly in the unit\nhypercube [0,1]^d in d dimensions, and need to be matched with each other while\nminimizing the expected average distance between matched pairs (the \"cost\"). We\ncharacterize the scaling behavior of the achievable cost in three models as a\nfunction of the dimension d: (i) Static matching of N demand units with N+M\nsupply units. (ii) A semi-dynamic model where N+M supply units are present\nbeforehand and N demand units arrive sequentially and must be matched\nimmediately. (iii) A fully dynamic model where there are always m supply units\npresent in the system, one supply and one demand unit arrive in each period,\nand the demand must be matched immediately. We show that one can achieve nearly\nthe same cost under the semi-dynamic model as under the static model, despite\nuncertainty about the future, and that, under these two models, d=1 is the only\ncase where cost far exceeds distance to the nearest neighbor (which is\n\\Theta(1/N^{1/d})) and where adding excess supply M substantially reduces cost\n(by smoothing stochastic fluctuations at larger spatial length scales). In the\nfully dynamic model, we show that, remarkably, for all d we can achieve a cost\nonly slightly more than the optimistic distance to the nearest neighbor\n\\Theta(1/m^{1/d}). Thus, excess supply m reduces cost in the fully dynamic\nmodel for all $d$ by reducing the distance to the nearest neighbor. This is a\nfundamentally different phenomenon than that seen in the other two models,\nwhere excess supply reduces cost while leaving the distance to the nearest\nneighbor unchanged, only for d=1. Our achievability results are based on\nanalysis of a certain \"Hierarchical Greedy\" algorithm which separately handles\nstochastic fluctuations at different length scales.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 01:49:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kanoria", "Yash", ""]]}, {"id": "2105.07511", "submitter": "Carlos E. Budde", "authors": "Carlos E. Budde, Mari\\\"elle Stoelinga", "title": "Efficient Algorithms for Quantitative Attack Tree Analysis", "comments": "Public version of CSF'21 paper, including an appendix with all proofs\n  of lemmas and theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Numerous analysis methods for quantitative attack tree analysis have been\nproposed. These algorithms compute relevant security metrics, i.e. performance\nindicators that quantify how good the security of a system is, such as the most\nlikely attack, the cheapest, or the most damaging one. This paper classifies\nattack trees in two dimensions: proper trees vs. directed acyclic graphs (i.e.\nwith shared subtrees); and static vs. dynamic gates. For each class, we propose\nnovel algorithms that work over a generic attribute domain, encompassing a\nlarge number of concrete security metrics defined on the attack tree semantics.\nWe also analyse the computational complexity of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 20:52:20 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 10:28:04 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Budde", "Carlos E.", ""], ["Stoelinga", "Mari\u00eblle", ""]]}, {"id": "2105.07518", "submitter": "Shunhua Jiang", "authors": "Yi-Jun Chang, Ran Duan, Shunhua Jiang", "title": "Near-Optimal Time-Energy Trade-Offs for Deterministic Leader Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the energy complexity of the leader election problem in the\nsingle-hop radio network model, where each device has a unique identifier in\n$\\{1, 2, \\ldots, N\\}$. Energy is a scarce resource for small battery-powered\ndevices. For such devices, most of the energy is often spent on communication,\nnot on computation. To approximate the actual energy cost, the energy\ncomplexity of an algorithm is defined as the maximum over all devices of the\nnumber of time slots where the device transmits or listens. Much progress has\nbeen made in understanding the energy complexity of leader election in radio\nnetworks, but very little is known about the trade-off between time and energy.\n  $\\textbf{Time-energy trade-off:}$ For any $k \\geq \\log \\log N$, we show that\na leader among at most $n$ devices can be elected deterministically in\n$O(n^{1+\\epsilon}) + O(k \\cdot N^{1/k})$ time and $O(k)$ energy if each device\ncan simultaneously transmit and listen, where $\\epsilon > 0$ is any small\nconstant. This improves upon the previous $O(N)$-time $O(\\log \\log N)$-energy\nalgorithm by Chang et al. [STOC 2017]. We provide lower bounds to show that the\ntime-energy trade-off of our algorithm is near-optimal.\n  $\\textbf{Dense instances:}$ For the dense instances where the number of\ndevices is $n = \\Theta(N)$, we design a deterministic leader election algorithm\nusing only $O(1)$ energy. This improves upon the $O(\\log^* N)$-energy algorithm\nby Jurdzi\\'{n}ski et al. [PODC 2002] and the $O(\\alpha(N))$-energy algorithm by\nChang et al. [STOC 2017]. More specifically, we show that the optimal\ndeterministic energy complexity of leader election is\n$\\Theta\\left(\\max\\left\\{1, \\log \\frac{N}{n}\\right\\}\\right)$ if the devices\ncannot simultaneously transmit and listen, and it is $\\Theta\\left(\\max\\left\\{1,\n\\log \\log \\frac{N}{n}\\right\\}\\right)$ if they can.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:34:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Duan", "Ran", ""], ["Jiang", "Shunhua", ""]]}, {"id": "2105.07560", "submitter": "Varsha Lohani", "authors": "Varsha Lohani, Anjali Sharma, and Yatindra Nath Singh", "title": "Dynamic Routing and Spectrum Assignment based on the Availability of\n  Consecutive Sub-channels in Flexi-grid Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using Optical Orthogonal Frequency Multiplexing (O-OFDM), variable bandwidth\nchannels can be created in Elastic Optical Networks (EON). This allows the use\nof spectrum more efficiently by allocating integral multiple of basic bandwidth\nslots to the lightpath requests. Consequently, such networks are also called\nflexible grid optical networks. It also adds a constraint of keeping all the\nallocated slots together when deciding the routes for the requests. This\nconstraint called the contiguity constraint makes the routing and spectrum\nalgorithms more challenging. In any network, the lightpath requests will arrive\nand depart dynamically and will invariably lead to spectrum fragmentation, and\nhence network will have a reduction in maximum possible utilization due to\nincreased blocking probability. In this paper, we have presented an improvised\nRSA algorithm that leads to lesser fragmentation. It is evident from the\nresults that the presented RSA algorithm uses adaptive parameters to reduce the\nblocking probability and fragmentation compared to other algorithms reported in\nthe recent past.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 01:15:14 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lohani", "Varsha", ""], ["Sharma", "Anjali", ""], ["Singh", "Yatindra Nath", ""]]}, {"id": "2105.07608", "submitter": "Aimin Hou", "authors": "Aimin Hou", "title": "Hamiltonian Cycle Problem is in P", "comments": "29 pages, 6 figures, FOCS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present the first deterministic polynomial time algorithm\nfor determining the existence of a Hamiltonian cycle and finding a Hamiltonian\ncycle in general graphs. Our algorithm can also resolve the Hamiltonian path\nproblem in the traceable graphs. The space complexity of our algorithm is\nO(n^4). The time complexity are theoretically O(n^5*d^2) on average and\nO(n^6*d^2) in the worst case respectively, where d is the maximum degree of\nvertex. With parallel computing, the space complexity can be improved to O(n^3)\nand the time complexity to O(n^3*d^2) on average and O(n^4*d^2) in the worst\ncase. We construct the corresponding path hologram transformed from the\noriginal graph and compute the path set, which is a collection of segment sets\nconsisting of all the vertices located on the same segment layer among all the\nlongest basic paths, of every vertex with dynamic programming. The path\nhologram is a multi-segment graph with the vertex <u, k> where u is a vertex\nand k is the segment layer of u in the path hologram. To ensure each path\nstored in the path set is legal and each segment set of the path set contains\nonly valid vertices, the key strategy of our method is the \"consecutive\"\ndeleting-replenishing operations recursively on the left/right action field of\na vertex, respectively. The greatest contribution of our method is the path set\nin which all the legal paths can be stored in O(n^2) space for a complete graph\nof order n. In fact, our algorithm can be directly applied to the original\ngraph. Besides, our algorithm can deal with the finite general graphs including\nundirected, directed, and mixed. As a result, the well-known problem HCP in NPC\ncan be now resolved practically in deterministic polynomial time for general\ngraphs in the worst case.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:26:40 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 08:26:41 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hou", "Aimin", ""]]}, {"id": "2105.07612", "submitter": "Xiaoyu Fan", "authors": "Xiaoyu Fan, Guosai Wang, Kun Chen, Xu He, Wei Xu", "title": "PPCA: Privacy-preserving Principal Component Analysis Using Secure\n  Multiparty Computation(MPC)", "comments": "11 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy-preserving data mining has become an important topic. People have\nbuilt several multi-party-computation (MPC)-based frameworks to provide\ntheoretically guaranteed privacy, the poor performance of real-world algorithms\nhave always been a challenge. Using Principal Component Analysis (PCA) as an\nexample, we show that by considering the unique performance characters of the\nMPC platform, we can design highly effective algorithm-level optimizations,\nsuch as replacing expensive operators and batching up. We achieve about\n200$\\times$ performance boost over existing privacy-preserving PCA algorithms\nwith the same level of privacy guarantee. Also, using real-world datasets, we\nshow that by combining multi-party data, we can achieve better training\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 05:05:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Fan", "Xiaoyu", ""], ["Wang", "Guosai", ""], ["Chen", "Kun", ""], ["He", "Xu", ""], ["Xu", "Wei", ""]]}, {"id": "2105.07791", "submitter": "Boris Bonev", "authors": "Boris Bonev and Jan S. Hesthaven", "title": "A hierarchical preconditioner for wave problems in quasilinear\n  complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper introduces a novel, hierarchical preconditioner based on nested\ndissection and hierarchical matrix compression. The preconditioner is intended\nfor continuous and discontinuous Galerkin formulations of elliptic problems. We\nexploit the property that Schur complements arising in such problems can be\nwell approximated by hierarchical matrices. An approximate factorization can be\ncomputed matrix-free and in a (quasi-)linear number of operations. The nested\ndissection is specifically designed to aid the factorization process using\nhierarchical matrices. We demonstrate the viability of the preconditioner on a\nrange of 2D problems, including the Helmholtz equation and the elastic wave\nequation. Throughout all tests, including wave phenomena with high wavenumbers,\nthe generalized minimal residual method (GMRES) with the proposed\npreconditioner converges in a very low number of iterations. We demonstrate\nthat this is due to the hierarchical nature of our approach which makes the\nhigh wavenumber limit manageable.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:02:01 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bonev", "Boris", ""], ["Hesthaven", "Jan S.", ""]]}, {"id": "2105.07968", "submitter": "David Rhodes", "authors": "David L. Rhodes, Breanna N. Johnson", "title": "A New Vertex Connectivity Metric", "comments": "9 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new metric for quantifying pairwise vertex connectivity in graphs is\ndefined and an implementation presented. While general in nature, it features a\ncombination of input features well-suited for social networks, including\napplicability to directed or undirected graphs, weighted edges, and computes\nusing the impact from all-paths between the vertices. Moreover, the $O(V+E)$\nmethod is applicable to large graphs. Comparisons with other techniques are\nincluded.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:48:22 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 13:36:42 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Rhodes", "David L.", ""], ["Johnson", "Breanna N.", ""]]}, {"id": "2105.08005", "submitter": "Ainesh Bakshi", "authors": "Ainesh Bakshi, Chiranjib Bhattacharyya, Ravi Kannan, David P. Woodruff\n  and Samson Zhou", "title": "Learning a Latent Simplex in Input-Sparsity Time", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of learning a latent $k$-vertex simplex\n$K\\subset\\mathbb{R}^d$, given access to $A\\in\\mathbb{R}^{d\\times n}$, which can\nbe viewed as a data matrix with $n$ points that are obtained by randomly\nperturbing latent points in the simplex $K$ (potentially beyond $K$). A large\nclass of latent variable models, such as adversarial clustering, mixed\nmembership stochastic block models, and topic models can be cast as learning a\nlatent simplex. Bhattacharyya and Kannan (SODA, 2020) give an algorithm for\nlearning such a latent simplex in time roughly $O(k\\cdot\\textrm{nnz}(A))$,\nwhere $\\textrm{nnz}(A)$ is the number of non-zeros in $A$. We show that the\ndependence on $k$ in the running time is unnecessary given a natural assumption\nabout the mass of the top $k$ singular values of $A$, which holds in many of\nthese applications. Further, we show this assumption is necessary, as otherwise\nan algorithm for learning a latent simplex would imply an algorithmic\nbreakthrough for spectral low rank approximation.\n  At a high level, Bhattacharyya and Kannan provide an adaptive algorithm that\nmakes $k$ matrix-vector product queries to $A$ and each query is a function of\nall queries preceding it. Since each matrix-vector product requires\n$\\textrm{nnz}(A)$ time, their overall running time appears unavoidable.\nInstead, we obtain a low-rank approximation to $A$ in input-sparsity time and\nshow that the column space thus obtained has small $\\sin\\Theta$ (angular)\ndistance to the right top-$k$ singular space of $A$. Our algorithm then selects\n$k$ points in the low-rank subspace with the largest inner product with $k$\ncarefully chosen random vectors. By working in the low-rank subspace, we avoid\nreading the entire matrix in each iteration and thus circumvent the\n$\\Theta(k\\cdot\\textrm{nnz}(A))$ running time.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:40:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Bhattacharyya", "Chiranjib", ""], ["Kannan", "Ravi", ""], ["Woodruff", "David P.", ""], ["Zhou", "Samson", ""]]}, {"id": "2105.08098", "submitter": "Nikita Koval", "authors": "Alexander Fedorov, Nikita Koval, Dan Alistarh", "title": "A Scalable Concurrent Algorithm for Dynamic Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic Connectivity is a fundamental algorithmic graph problem, motivated by\na wide range of applications to social and communication networks and used as a\nbuilding block in various other algorithms, such as the bi-connectivity and the\ndynamic minimal spanning tree problems. In brief, we wish to maintain the\nconnected components of the graph under dynamic edge insertions and deletions.\nIn the sequential case, the problem has been well-studied from both theoretical\nand practical perspectives. However, much less is known about efficient\nconcurrent solutions to this problem. This is the gap we address in this paper.\n  We start from one of the classic data structures used to solve this problem,\nthe Euler Tour Tree. Our first contribution is a non-blocking single-writer\nimplementation of it. We leverage this data structure to obtain the first truly\nconcurrent generalization of dynamic connectivity, which preserves the time\ncomplexity of its sequential counterpart, but is also scalable in practice. To\nachieve this, we rely on three main techniques. The first is to ensure that\nconnectivity queries, which usually dominate real-world workloads, are\nnon-blocking. The second non-trivial technique expands the above idea by making\nall queries that do not change the connectivity structure non-blocking. The\nthird ingredient is applying fine-grained locking for updating the connected\ncomponents, which allows operations on disjoint components to occur in\nparallel.\n  We evaluate the resulting algorithm on various workloads, executing on both\nreal and synthetic graphs. The results show the efficiency of each of the\nproposed optimizations; the most efficient variant improves the performance of\na coarse-grained based implementation on realistic scenarios up to 6x on\naverage and up to 30x when connectivity queries dominate.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 18:11:49 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fedorov", "Alexander", ""], ["Koval", "Nikita", ""], ["Alistarh", "Dan", ""]]}, {"id": "2105.08116", "submitter": "Xie Xie", "authors": "Xie Xie", "title": "A Neat Linked Queue with the Rear Sentinel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a very simple queue implementation with the singly linked list.\nWith the help of the rear sentinel instead of the traditional header node, we\navoid additional check steps in the pop operation. The essence of this\nrepresentation is the half-opened pointer interval, which can guarantee the\nuniform treatment even in the empty queue case. We also present the variants of\nlinked queue, circularly linked queue and lazy circularly linked queue, which\ncan also be used to implement stack and improve the time performance in some\nspecial cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 19:00:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Xie", "Xie", ""]]}, {"id": "2105.08215", "submitter": "Prantar Ghosh", "authors": "Amit Chakrabarti, Prantar Ghosh, Andrew McGregor, Sofya Vorotnikova", "title": "Vertex Ordering Problems in Directed Graph Streams", "comments": "Appeared in SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider directed graph algorithms in a streaming setting, focusing on\nproblems concerning orderings of the vertices. This includes such fundamental\nproblems as topological sorting and acyclicity testing. We also study the\nrelated problems of finding a minimum feedback arc set (edges whose removal\nyields an acyclic graph), and finding a sink vertex. We are interested in both\nadversarially-ordered and randomly-ordered streams. For arbitrary input graphs\nwith edges ordered adversarially, we show that most of these problems have high\nspace complexity, precluding sublinear-space solutions. Some lower bounds also\napply when the stream is randomly ordered: e.g., in our most technical result\nwe show that testing acyclicity in the $p$-pass random-order model requires\nroughly $n^{1+1/p}$ space. For other problems, random ordering can make a\ndramatic difference: e.g., it is possible to find a sink in an acyclic\ntournament in the one-pass random-order model using polylog$(n)$ space whereas\nunder adversarial ordering roughly $n^{1/p}$ space is necessary and sufficient\ngiven $\\Theta(p)$ passes. We also design sublinear algorithms for the feedback\narc set problem in tournament graphs; for random graphs; and for randomly\nordered streams. In some cases, we give lower bounds establishing that our\nalgorithms are essentially space-optimal. Together, our results complement the\nmuch maturer body of work on algorithms for undirected graph streams.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 00:55:57 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Ghosh", "Prantar", ""], ["McGregor", "Andrew", ""], ["Vorotnikova", "Sofya", ""]]}, {"id": "2105.08285", "submitter": "Zhaozhuo Xu", "authors": "Anshumali Shrivastava, Zhao Song, Zhaozhuo Xu", "title": "Sublinear Least-Squares Value Iteration via Locality Sensitive Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the first provable Least-Squares Value Iteration (LSVI) algorithms\nthat have runtime complexity sublinear in the number of actions. We formulate\nthe value function estimation procedure in value iteration as an approximate\nmaximum inner product search problem and propose a locality sensitive hashing\n(LSH) [Indyk and Motwani STOC'98, Andoni and Razenshteyn STOC'15, Andoni,\nLaarhoven, Razenshteyn and Waingarten SODA'17] type data structure to solve\nthis problem with sublinear time complexity. Moreover, we build the connections\nbetween the theory of approximate maximum inner product search and the regret\nanalysis of reinforcement learning. We prove that, with our choice of\napproximation factor, our Sublinear LSVI algorithms maintain the same regret as\nthe original LSVI algorithms while reducing the runtime complexity to sublinear\nin the number of actions. To the best of our knowledge, this is the first work\nthat combines LSH with reinforcement learning resulting in provable\nimprovements. We hope that our novel way of combining data-structures and\niterative algorithm will open the door for further study into cost reduction in\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:23:53 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 16:45:58 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Shrivastava", "Anshumali", ""], ["Song", "Zhao", ""], ["Xu", "Zhaozhuo", ""]]}, {"id": "2105.08292", "submitter": "Linda Cai", "authors": "Linda Cai and Raghuvansh R. Saxena", "title": "99% Revenue with Constant Enhanced Competition", "comments": "Accepted to Economic and Computing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The enhanced competition paradigm is an attempt at bridging the gap between\nsimple and optimal auctions. In this line of work, given an auction setting\nwith $m$ items and $n$ bidders, the goal is to find the smallest $n' \\geq n$\nsuch that selling the items to $n'$ bidders through a simple auction generates\n(almost) the same revenue as the optimal auction.\n  Recently, Feldman, Friedler, and Rubinstein [EC, 2018] showed that an\narbitrarily large constant fraction of the optimal revenue from selling $m$\nitems to a single bidder can be obtained via simple auctions with a constant\nnumber of bidders. However, their techniques break down even for two bidders,\nand can only show a bound of $n' = n \\cdot O(\\log \\frac{m}{n})$.\n  Our main result is that $n' = O(n)$ bidders suffice for all values of $m$ and\n$n$. That is, we show that, for all $m$ and $n$, an arbitrarily large constant\nfraction of the optimal revenue from selling $m$ items to $n$ bidders can be\nobtained via simple auctions with $O(n)$ bidders. Moreover, when the items are\nregular, we can achieve the same result through auctions that are\nprior-independent, {\\em i.e.}, they do not depend on the distribution from\nwhich the bidders' valuations are sampled.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:53:56 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cai", "Linda", ""], ["Saxena", "Raghuvansh R.", ""]]}, {"id": "2105.08309", "submitter": "Leila Taghavi", "authors": "Salman Beigi, Leila Taghavi, Artin Tajdini", "title": "Time and Query Optimal Quantum Algorithms Based on Decision Trees", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has recently been shown that starting with a classical query algorithm\n(decision tree) and a guessing algorithm that tries to predict the query\nanswers, we can design a quantum algorithm with query complexity $O(\\sqrt{GT})$\nwhere $T$ is the query complexity of the classical algorithm (depth of the\ndecision tree) and $G$ is the maximum number of wrong answers by the guessing\nalgorithm [arXiv:1410.0932, arXiv:1905.13095]. In this paper we show that,\ngiven some constraints on the classical algorithms, this quantum algorithm can\nbe implemented in time $\\tilde O(\\sqrt{GT})$. Our algorithm is based on\nnon-binary span programs and their efficient implementation. We conclude that\nvarious graph theoretic problems including bipartiteness, cycle detection and\ntopological sort can be solved in time $O(n^{3/2}\\log n)$ and with $O(n^{3/2})$\nquantum queries. Moreover, finding a maximal matching can be solved with\n$O(n^{3/2})$ quantum queries in time $O(n^{3/2}\\log n)$, and maximum bipartite\nmatching can be solved in time $O(n^2\\log n)$.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:51:11 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Beigi", "Salman", ""], ["Taghavi", "Leila", ""], ["Tajdini", "Artin", ""]]}, {"id": "2105.08335", "submitter": "Philipp Zschoche", "authors": "Nina Klobas, George B. Mertzios, Hendrik Molter, Rolf Niedermeier, and\n  Philipp Zschoche", "title": "Interference-free Walks in Time: Temporally Disjoint Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of finding temporally disjoint\npaths or walks in temporal graphs. There, the edge set changes over discrete\ntime steps and a temporal path (resp. walk) uses edges that appear at\nmonotonically increasing time steps. Two paths (or walks) are temporally\ndisjoint if they never use the same vertex at the same time; otherwise, they\ninterfere. This reflects applications in robotics, traffic routing, or finding\nsafe pathways in dynamically changing networks. On the one extreme, we show\nthat on general graphs the problem is computationally hard. The \"walk version\"\nis W[1]-hard when parameterized by the number of routes. However, it is\npolynomial-time solvable for any constant number of walks. The \"path version\"\nremains NP-hard even if we want to find only two temporally disjoint paths. On\nthe other extreme, restricting the input temporal graph to have a path as\nunderlying graph, quite counterintuitively, we find NP-hardness in general but\nalso identify natural tractable cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 07:59:07 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 20:29:27 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Klobas", "Nina", ""], ["Mertzios", "George B.", ""], ["Molter", "Hendrik", ""], ["Niedermeier", "Rolf", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2105.08339", "submitter": "Ran Ben Basat", "authors": "Shay Vargaftik, Ran Ben Basat, Amit Portnoy, Gal Mendelson, Yaniv\n  Ben-Itzhak, Michael Mitzenmacher", "title": "DRIVE: One-bit Distributed Mean Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem where $n$ clients transmit $d$-dimensional\nreal-valued vectors using $d(1+o(1))$ bits each, in a manner that allows the\nreceiver to approximately reconstruct their mean. Such compression problems\nnaturally arise in distributed and federated learning. We provide novel\nmathematical results and derive computationally efficient algorithms that are\nmore accurate than previous compression techniques. We evaluate our methods on\na collection of distributed and federated learning tasks, using a variety of\ndatasets, and show a consistent improvement over the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 08:03:39 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 16:10:02 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 17:12:21 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vargaftik", "Shay", ""], ["Basat", "Ran Ben", ""], ["Portnoy", "Amit", ""], ["Mendelson", "Gal", ""], ["Ben-Itzhak", "Yaniv", ""], ["Mitzenmacher", "Michael", ""]]}, {"id": "2105.08378", "submitter": "Dorothee Henke", "authors": "Christoph Buchheim, Dorothee Henke, Felix Hommelsheim", "title": "On the Complexity of Robust Bilevel Optimization With Uncertain\n  Follower's Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We investigate the complexity of bilevel combinatorial optimization with\nuncertainty in the follower's objective, in a robust optimization approach. We\nshow that the robust counterpart of the bilevel problem under interval\nuncertainty can be $\\Sigma^{\\text P}_2$-hard, even when the certain bilevel\nproblem is NP-equivalent and the follower's problem is tractable. On the\ncontrary, in the discrete uncertainty case, the robust bilevel problem is at\nmost one level harder than the follower's problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 09:07:41 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:27:15 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Buchheim", "Christoph", ""], ["Henke", "Dorothee", ""], ["Hommelsheim", "Felix", ""]]}, {"id": "2105.08490", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler, Noleen K\\\"ohler and Pan Peng", "title": "GSF-locality is not sufficient for proximity-oblivious testing", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Property Testing, proximity-oblivious testers (POTs) form a class of\nparticularly simple testing algorithms, where a basic test is performed a\nnumber of times that may depend on the proximity parameter, but the basic test\nitself is independent of the proximity parameter. In their seminal work,\nGoldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties that\nallow constant-query proximity-oblivious testing in the bounded-degree model\nare precisely the properties that can be expressed as a generalised subgraph\nfreeness (GSF) property that satisfies the non-propagation condition. It is\nleft open whether the non-propagation condition is necessary. Indeed, calling\nproperties expressible as a generalised subgraph freeness property GSF-local\nproperties, they ask whether all GSF-local properties are non-propagating. We\ngive a negative answer by exhibiting a property of graphs that is GSF-local and\npropagating. Hence in particular, our property does not admit a POT, despite\nbeing GSF-local. We prove our result by exploiting a recent work of the authors\nwhich constructed a first-order (FO) property that is not testable [SODA 2021],\nand a new connection between FO properties and GSF-local properties via\nneighbourhood profiles.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 13:08:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Adler", "Isolde", ""], ["K\u00f6hler", "Noleen", ""], ["Peng", "Pan", ""]]}, {"id": "2105.08549", "submitter": "Anthony Perez", "authors": "Ma\\\"el Dumas, Anthony Perez, Ioan Todinca", "title": "A cubic vertex-kernel for Trivially Perfect Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the Trivially Perfect Editing problem, where one is given an\nundirected graph $G = (V,E)$ and a parameter $k \\in \\mathbb{N}$ and seeks to\nedit (add or delete) at most $k$ edges from $G$ to obtain a trivially perfect\ngraph. The related Trivially Perfect Completion and Trivially Perfect Deletion\nproblems are obtained by only allowing edge additions or edge deletions,\nrespectively. Trivially perfect graphs are both chordal and cographs, and have\napplications related to the tree-depth width parameter and to social network\nanalysis. All variants of the problem are known to be NP-Complete and to admit\nso-called polynomial kernels. More precisely, the existence of an $O(k^3)$\nvertex-kernel for Trivially Perfect Completion was announced by Guo (ISAAC\n2007) but without a stand-alone proof. More recently, Drange and Pilipczuk\n(Algorithmica 2018) provided $O(k^7)$ vertex-kernels for these problems and\nleft open the existence of cubic vertex-kernels. In this work, we answer\npositively to this question for all three variants of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 14:35:12 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Dumas", "Ma\u00ebl", ""], ["Perez", "Anthony", ""], ["Todinca", "Ioan", ""]]}, {"id": "2105.08577", "submitter": "Waldo G\\'alvez", "authors": "Waldo G\\'alvez, Fabrizio Grandoni, Afrouz Jabal Ameli and Kamyar\n  Khodamoradi", "title": "Approximation Algorithms for Demand Strip Packing", "comments": "Submitted to The 24th International Conference on Approximation\n  Algorithms for Combinatorial Optimization Problems (APPROX 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Demand Strip Packing problem (DSP), we are given a time interval and a\ncollection of tasks, each characterized by a processing time and a demand for a\ngiven resource (such as electricity, computational power, etc.). A feasible\nsolution consists of a schedule of the tasks within the mentioned time\ninterval. Our goal is to minimize the peak resource consumption, i.e. the\nmaximum total demand of tasks executed at any point in time.\n  It is known that DSP is NP-hard to approximate below a factor 3/2, and\nstandard techniques for related problems imply a (polynomial-time)\n2-approximation. Our main result is a (5/3+eps)-approximation algorithm for any\nconstant eps>0. We also achieve best-possible approximation factors for some\nrelevant special cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:03:46 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:16:34 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["G\u00e1lvez", "Waldo", ""], ["Grandoni", "Fabrizio", ""], ["Ameli", "Afrouz Jabal", ""], ["Khodamoradi", "Kamyar", ""]]}, {"id": "2105.08675", "submitter": "Christoph Hertrich", "authors": "Vincent Froese, Christoph Hertrich, Rolf Niedermeier", "title": "The Computational Complexity of ReLU Network Training Parameterized by\n  Data Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the computational complexity of training simple neural networks\nwith rectified linear units (ReLUs) has recently been a subject of intensive\nresearch. Closing gaps and complementing results from the literature, we\npresent several results on the parameterized complexity of training two-layer\nReLU networks with respect to various loss functions. After a brief discussion\nof other parameters, we focus on analyzing the influence of the dimension $d$\nof the training data on the computational complexity. We provide running time\nlower bounds in terms of W[1]-hardness for parameter $d$ and prove that known\nbrute-force strategies are essentially optimal (assuming the Exponential Time\nHypothesis). In comparison with previous work, our results hold for a broad(er)\nrange of loss functions, including $\\ell^p$-loss for all $p\\in[0,\\infty]$. In\nparticular, we extend a known polynomial-time algorithm for constant $d$ and\nconvex loss functions to a more general class of loss functions, matching our\nrunning time lower bounds also in these cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:05:26 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:32:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Froese", "Vincent", ""], ["Hertrich", "Christoph", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2105.08706", "submitter": "Gal Sela", "authors": "Gal Sela, Erez Petrank", "title": "Durable Queues: The Second Amendment", "comments": "Code: https://github.com/galysela/DurableQueues", "journal-ref": "Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms\n  and Architectures (SPAA '21), July 6-8, 2021, Virtual Event, USA. ACM, New\n  York, NY, USA, 385-397", "doi": "10.1145/3409964.3461791", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider durable data structures for non-volatile main memory, such as the\nnew Intel Optane memory architecture. Substantial recent work has concentrated\non making concurrent data structures durable with low overhead, by adding a\nminimal number of blocking persist operations (i.e., flushes and fences). In\nthis work we show that focusing on minimizing the number of persist\ninstructions is important, but not enough. We show that access to flushed\ncontent is of high cost due to cache invalidation in current architectures.\nGiven this finding, we present a design of the queue data structure that\nproperly takes care of minimizing blocking persist operations as well as\nminimizing access to flushed content. The proposed design outperforms\nstate-of-the-art durable queues.\n  We start by providing a durable version of the Michael Scott queue (MSQ). We\namend MSQ by adding a minimal number of persist instructions, fewer than in\navailable durable queues, and meeting the theoretical lower bound on the number\nof blocking persist operations. We then proceed with a second amendment to this\ndesign, that eliminates accesses to flushed data. Evaluation shows that the\nsecond amendment yields substantial performance improvement, outperforming the\nstate of the art and demonstrating the importance of reduced accesses to\nflushed content. The presented queues are durably linearizable and lock-free.\nFinally, we discuss the theoretical optimal number of accesses to flushed\ncontent.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:45:37 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:42:37 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sela", "Gal", ""], ["Petrank", "Erez", ""]]}, {"id": "2105.08763", "submitter": "Leah Epstein", "authors": "Leah Epstein and Loay Mualem", "title": "Online bin packing of squares and cubes", "comments": "WADS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the d-dimensional online bin packing problem, d-dimensional cubes of\npositive sizes no larger than 1 are presented one by one to be assigned to\npositions in d-dimensional unit cube bins. In this work, we provide improved\nupper bounds on the asymptotic competitive ratio for square and cube bin\npacking problems, where our bounds do not exceed 2.0885 and 2.5735 for square\nand cube packing, respectively. To achieve these results, we adapt and improve\na previously designed harmonic-type algorithm, and apply a different method for\ndefining weight functions. We detect deficiencies in the state-of-the-art\nresults by providing counter-examples to the current best algorithms and the\nanalysis, where the claimed bounds were 2.1187 for square packing and 2.6161\nfor cube packing.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:23:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Epstein", "Leah", ""], ["Mualem", "Loay", ""]]}, {"id": "2105.08917", "submitter": "Shreyas Pai", "authors": "Shreyas Pai and Gopal Pandurangan and Sriram V. Pemmaraju and Peter\n  Robinson", "title": "Can We Break Symmetry with o(m) Communication?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the communication cost (or message complexity) of fundamental\ndistributed symmetry breaking problems, namely, coloring and MIS. While\nsignificant progress has been made in understanding and improving the running\ntime of such problems, much less is known about the message complexity of these\nproblems. In fact, all known algorithms need at least $\\Omega(m)$ communication\nfor these problems, where $m$ is the number of edges in the graph. We address\nthe following question in this paper: can we solve problems such as coloring\nand MIS using sublinear, i.e., $o(m)$ communication, and if so under what\nconditions? [See full abstract in pdf]\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 04:34:32 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Pai", "Shreyas", ""], ["Pandurangan", "Gopal", ""], ["Pemmaraju", "Sriram V.", ""], ["Robinson", "Peter", ""]]}, {"id": "2105.08967", "submitter": "Rahul Vaze", "authors": "Rahul Vaze, Jayakrishnan Nair", "title": "Speed Scaling On Parallel Servers with MapReduce Type Precedence\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A multiple server setting is considered, where each server has tunable speed,\nand increasing the speed incurs an energy cost. Jobs arrive to a single queue,\nand each job has two types of sub-tasks, map and reduce, and a {\\bf precedence}\nconstraint among them: any reduce task of a job can only be processed once all\nthe map tasks of the job have been completed. In addition to the scheduling\nproblem, i.e., which task to execute on which server, with tunable speed, an\nadditional decision variable is the choice of speed for each server, so as to\nminimize a linear combination of the sum of the flow times of jobs/tasks and\nthe total energy cost. The precedence constraints present new challenges for\nthe speed scaling problem with multiple servers, namely that the number of\ntasks that can be executed at any time may be small but the total number of\noutstanding tasks might be quite large. We present simple speed scaling\nalgorithms that are shown to have competitive ratios, that depend on the power\ncost function, and/or the ratio of the size of the largest task and the\nshortest reduce task, but not on the number of jobs, or the number of servers.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:37:47 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Vaze", "Rahul", ""], ["Nair", "Jayakrishnan", ""]]}, {"id": "2105.08974", "submitter": "Ruslan Sharipov", "authors": "Ruslan Sharipov", "title": "Pseudo-Hadamard matrices of the first generation and an algorithm for\n  producing them", "comments": "AmSTeX, 9 pages, amsppt style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadamard matrices in $\\{0,1\\}$ presentation are square $m\\times m$ matrices\nwhose entries are zeros and ones and whose rows considered as vectors in $\\Bbb\nR^m$ produce the Gram matrix of a special form with respect to the standard\nscalar product in $\\Bbb R^m$. The concept of Hadamard matrices is extended in\nthe present paper. As a result pseudo-Hadamard matrices of the first generation\nare defined and investigated. An algorithm for generating these pseudo-Hadamard\nmatrices is designed and is used for testing some conjectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 08:12:55 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sharipov", "Ruslan", ""]]}, {"id": "2105.08980", "submitter": "Philipp Schepper", "authors": "D\\'aniel Marx, Govind S. Sankar, Philipp Schepper", "title": "Degrees and Gaps: Tight Complexity Results of General Factor Problems\n  Parameterized by Treewidth and Cutwidth", "comments": "Full version of the paper accepted for ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For the General Factor problem we are given an undirected graph $G$ and for\neach vertex $v\\in V(G)$ a finite set $B_v$ of non-negative integers. The task\nis to decide if there is a subset $S\\subseteq E(G)$ such that $deg_S(v)\\in B_v$\nfor all vertices $v$ of $G$. The maxgap of a finite integer set $B$ is the\nlargest $d\\ge 0$ such that there is an $a\\ge 0$ with $[a,a+d+1]\\cap\nB=\\{a,a+d+1\\}$. Cornu\\'ejols (1988) showed that if the maxgap of all sets $B_v$\nis at most 1, then the decision version of General Factor is poly-time\nsolvable. Dudycz and Paluch (2018) extended this result for the minimization\nand maximization versions. Using convolution techniques from van Rooij (2020),\nwe improve upon the previous algorithm by Arulselvan et al. (2018) and present\nan algorithm counting the number of solutions of a certain size in time\n$O^*((M+1)^k)$, given a tree decomposition of width $k$, where $M=\\max_v \\max\nB_v$.\n  We prove that this algorithm is essentially optimal for all cases that are\nnot polynomial time solvable for the decision, minimization or maximization\nversions. We prove that such improvements are not possible even for $B$-Factor,\nwhich is General Factor on graphs where all sets $B_v$ agree with the fixed set\n$B$. We show that for every fixed $B$ where the problem is NP-hard, our new\nalgorithm cannot be significantly improved: assuming the Strong Exponential\nTime Hypothesis (SETH), no algorithm can solve $B$-Factor in time $O^*((\\max\nB+1-\\epsilon)^k)$ for any $\\epsilon>0$. We extend this bound to the counting\nversion of $B$-Factor for arbitrary, non-trivial sets $B$, assuming #SETH.\n  We also investigate the parameterization of the problem by cutwidth. Unlike\nfor treewidth, a larger set $B$ does not make the problem harder: Given a\nlinear layout of width $k$ we give a $O^*(2^k)$ algorithm for any $B$ and\nprovide a matching lower bound that this is optimal for the NP-hard cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 08:26:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Sankar", "Govind S.", ""], ["Schepper", "Philipp", ""]]}, {"id": "2105.09217", "submitter": "Gautam K. Das", "authors": "Pawan K. Mishra and Gautam K. Das", "title": "Approximation Algorithms For The Euclidean Dispersion Problems", "comments": "17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we consider the Euclidean dispersion problems. Let\n$P=\\{p_{1}, p_{2}, \\ldots, p_{n}\\}$ be a set of $n$ points in $\\mathbb{R}^2$.\nFor each point $p \\in P$ and $S \\subseteq P$, we define $cost_{\\gamma}(p,S)$ as\nthe sum of Euclidean distance from $p$ to the nearest $\\gamma $ point in $S\n\\setminus \\{p\\}$. We define $cost_{\\gamma}(S)=\\min_{p \\in\nS}\\{cost_{\\gamma}(p,S)\\}$ for $S \\subseteq P$. In the $\\gamma$-dispersion\nproblem, a set $P$ of $n$ points in $\\mathbb{R}^2$ and a positive integer $k\n\\in [\\gamma+1,n]$ are given. The objective is to find a subset $S\\subseteq P$\nof size $k$ such that $cost_{\\gamma}(S)$ is maximized. We consider both\n$2$-dispersion and $1$-dispersion problem in $\\mathbb{R}^2$. Along with these,\nwe also consider $2$-dispersion problem when points are placed on a line. In\nthis paper, we propose a simple polynomial time $(2\\sqrt 3 + \\epsilon )$-factor\napproximation algorithm for the $2$-dispersion problem, for any $\\epsilon > 0$,\nwhich is an improvement over the best known approximation factor $4\\sqrt3$\n[Amano, K. and Nakano, S. I., An approximation algorithm for the $2$-dispersion\nproblem, IEICE Transactions on Information and Systems, Vol. 103(3), pp.\n506-508, 2020]. Next, we develop a common framework for designing an\napproximation algorithm for the Euclidean dispersion problem. With this common\nframework, we improve the approximation factor to $2\\sqrt 3$ for the\n$2$-dispersion problem in $\\mathbb{R}^2$. Using the same framework, we propose\na polynomial time algorithm, which returns an optimal solution for the\n$2$-dispersion problem when points are placed on a line. Moreover, to show the\neffectiveness of the framework, we also propose a $2$-factor approximation\nalgorithm for the $1$-dispersion problem in $\\mathbb{R}^2$.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 15:56:30 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mishra", "Pawan K.", ""], ["Das", "Gautam K.", ""]]}, {"id": "2105.09313", "submitter": "Gautam K. Das", "authors": "Pawan K. Mishra and Gautam K. Das", "title": "Approximation Algorithms For The Dispersion Problems in a Metric Space", "comments": "9. arXiv admin note: text overlap with arXiv:2105.09217", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we consider the $c$-dispersion problem in a metric space\n$(X,d)$. Let $P=\\{p_{1}, p_{2}, \\ldots, p_{n}\\}$ be a set of $n$ points in a\nmetric space $(X,d)$. For each point $p \\in P$ and $S \\subseteq P$, we define\n$cost_{c}(p,S)$ as the sum of distances from $p$ to the nearest $c $ points in\n$S \\setminus \\{p\\}$, where $c\\geq 1$ is a fixed integer. We define\n$cost_{c}(S)=\\min_{p \\in S}\\{cost_{c}(p,S)\\}$ for $S \\subseteq P$. In the\n$c$-dispersion problem, a set $P$ of $n$ points in a metric space $(X,d)$ and a\npositive integer $k \\in [c+1,n]$ are given. The objective is to find a subset\n$S\\subseteq P$ of size $k$ such that $cost_{c}(S)$ is maximized. We propose a\nsimple polynomial time greedy algorithm that produces a $2c$-factor\napproximation result for the $c$-dispersion problem in a metric space. The best\nknown result for the $c$-dispersion problem in the Euclidean metric space\n$(X,d)$ is $2c^2$, where $P \\subseteq \\mathbb{R}^2$ and the distance function\nis Euclidean distance [ Amano, K. and Nakano, S. I., Away from Rivals, CCCG,\npp.68-71, 2018 ]. We also prove that the $c$-dispersion problem in a metric\nspace is $W[1]$-hard.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:01:21 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 13:42:45 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mishra", "Pawan K.", ""], ["Das", "Gautam K.", ""]]}, {"id": "2105.09413", "submitter": "Mateus de Oliveira Oliveira", "authors": "Emmanuel Arrighi, Henning Fernau, Daniel Lokshtanov, Mateus de\n  Oliveira Oliveira, Petra Wolf", "title": "Diversity in Kemeny Rank Aggregation: A Parameterized Approach", "comments": "Accepted to the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its most traditional setting, the main concern of optimization theory is\nthe search for optimal solutions for instances of a given computational\nproblem. A recent trend of research in artificial intelligence, called solution\ndiversity, has focused on the development of notions of optimality that may be\nmore appropriate in settings where subjectivity is essential. The idea is that\ninstead of aiming at the development of algorithms that output a single optimal\nsolution, the goal is to investigate algorithms that output a small set of\nsufficiently good solutions that are sufficiently diverse from one another. In\nthis way, the user has the opportunity to choose the solution that is most\nappropriate to the context at hand. It also displays the richness of the\nsolution space.\n  When combined with techniques from parameterized complexity theory, the\nparadigm of diversity of solutions offers a powerful algorithmic framework to\naddress problems of practical relevance. In this work, we investigate the\nimpact of this combination in the field of Kemeny Rank Aggregation, a\nwell-studied class of problems lying in the intersection of order theory and\nsocial choice theory and also in the field of order theory itself. In\nparticular, we show that the Kemeny Rank Aggregation problem is fixed-parameter\ntractable with respect to natural parameters providing natural formalizations\nof the notions of diversity and of the notion of a sufficiently good solution.\nOur main results work both when considering the traditional setting of\naggregation over linearly ordered votes, and in the more general setting where\nvotes are partially ordered.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 21:50:03 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Arrighi", "Emmanuel", ""], ["Fernau", "Henning", ""], ["Lokshtanov", "Daniel", ""], ["Oliveira", "Mateus de Oliveira", ""], ["Wolf", "Petra", ""]]}, {"id": "2105.09439", "submitter": "P\\'eter Madarasi", "authors": "P\\'eter Madarasi", "title": "The Simultaneous Assignment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the \\emph{Simultaneous Assignment Problem}. Here, we\nare given an assignment problem on some of the subgraphs of a given graph, and\nwe are looking for a heaviest assignment which is feasible when restricted to\nany of the assignment problems. More precisely, we are given a graph with a\nweight- and a capacity function on its edges and a set of its subgraphs\n$H_1,\\dots,H_k$ along with a degree upper bound function for each of them. In\naddition, we are also given a laminar system on the node set with an upper\nbound on the degree-sum of the nodes in each set in the system. We want to\nassign each edge a non-negative integer below its capacity such that the total\nweight is maximized, the degrees in each subgraph are below the degree upper\nbound associated with the subgraph, and the degree-sum bound is respected in\neach set of the laminar system.\n  The problem is shown to be APX-hard in the unweighted case even if the graph\nis a forest and $k=2$. This also implies that the Distance matching problem is\nAPX-hard in the weighted case and that the Cyclic distance matching problem is\nAPX-hard in the unweighted case. We identify multiple special cases when the\nproblem can be solved in strongly polynomial time. One of these cases, the\nso-called locally laminar case, is a common generalization of the Hierarchical\nb-matching problem and the Laminar matchoid problem, and it implies that both\nof these problems can be solved efficiently in the weighted, capacitated case\n-- improving upon the most general polynomial-time algorithms for these\nproblems. The problem can be constant approximated when $k$ is a constant, and\nwe show that the approximation factor matches the integrality gap of a\nstrengthened LP-relaxation for small $k$. We give improved approximation\nalgorithms for special cases, for example, when the degree bounds are uniform\nor the graph is sparse.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 00:36:21 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Madarasi", "P\u00e9ter", ""]]}, {"id": "2105.09508", "submitter": "Wentao Cai", "authors": "Wentao Cai, Haosen Wen, Vladimir Maksimovski, Mingzhe Du, Rafaello\n  Sanna, Shreif Abdallah, Michael L. Scott", "title": "Fast Nonblocking Persistence for Concurrent Data Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a fully lock-free variant of the recent Montage system for\npersistent data structures. Our variant, nbMontage, adds persistence to almost\nany nonblocking concurrent structure without introducing significant overhead\nor blocking of any kind. Like its predecessor, nbMontage is buffered durably\nlinearizable: it guarantees that the state recovered in the wake of a crash\nwill represent a consistent prefix of pre-crash execution. Unlike its\npredecessor, nbMontage ensures wait-free progress of the persistence frontier,\nthereby bounding the number of recent updates that may be lost on a crash, and\nallowing a thread to force an update of the frontier (i.e., to perform a sync\noperation) without the risk of blocking. As an extra benefit, the helping\nmechanism employed by our wait-free sync significantly reduces its latency.\n  Performance results for nonblocking queues, skip lists, trees, and hash\ntables rival custom data structures in the literature -- dramatically faster\nthan achieved with prior general-purpose systems, and generally within 50% of\nequivalent non-persistent structures placed in DRAM.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 04:24:58 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cai", "Wentao", ""], ["Wen", "Haosen", ""], ["Maksimovski", "Vladimir", ""], ["Du", "Mingzhe", ""], ["Sanna", "Rafaello", ""], ["Abdallah", "Shreif", ""], ["Scott", "Michael L.", ""]]}, {"id": "2105.09522", "submitter": "Prajakta Nimbhorkar", "authors": "Govind S. Sankar, Anand Louis, Meghana Nasre, Prajakta Nimbhorkar", "title": "Matchings with Group Fairness Constraints: Online and Offline Algorithms", "comments": "16 pages, to appear in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of assigning items to platforms in the presence of\ngroup fairness constraints. In the input, each item belongs to certain\ncategories, called classes in this paper. Each platform specifies the group\nfairness constraints through an upper bound on the number of items it can serve\nfrom each class. Additionally, each platform also has an upper bound on the\ntotal number of items it can serve. The goal is to assign items to platforms so\nas to maximize the number of items assigned while satisfying the upper bounds\nof each class. In some cases, there is a revenue associated with matching an\nitem to a platform, then the goal is to maximize the revenue generated.\n  This problem models several important real-world problems like ad-auctions,\nscheduling, resource allocations, school choice etc.We also show an interesting\nconnection to computing a generalized maximum independent set on hypergraphs\nand ranking items under group fairness constraints.\n  We show that if the classes are arbitrary, then the problem is NP-hard and\nhas a strong inapproximability. We consider the problem in both online and\noffline settings under natural restrictions on the classes. Under these\nrestrictions, the problem continues to remain NP-hard but admits approximation\nalgorithms with small approximation factors. We also implement some of the\nalgorithms. Our experiments show that the algorithms work well in practice both\nin terms of efficiency and the number of items that get assigned to some\nplatform.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 05:30:15 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Sankar", "Govind S.", ""], ["Louis", "Anand", ""], ["Nasre", "Meghana", ""], ["Nimbhorkar", "Prajakta", ""]]}, {"id": "2105.09566", "submitter": "Gabriel Bathie", "authors": "Gabriel Bathie (ENS Lyon), Nicolas Bousquet (LIRIS, Universit\\'e Lyon\n  1), Th\\'eo Pierron (LIRIS, Universit\\'e Lyon 1)", "title": "(Sub)linear kernels for edge modification problems towards structured\n  graph classes", "comments": "18 pages, submitted to ESA'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a (parameterized) graph edge modification problem, we are given a graph\n$G$, an integer $k$ and a (usually well-structured) class of graphs\n$\\mathcal{G}$, and ask whether it is possible to transform $G$ into a graph $G'\n\\in \\mathcal{G}$ by adding and/or removing at most $k$ edges. Parameterized\ngraph edge modification problems received considerable attention in the last\ndecades.\n  In this paper we focus on finding small kernels for edge modification\nproblems. One of the most studied problems is the \\textsc{Cluster Editing}\nproblem, in which the goal is to partition the vertex set into a disjoint union\nof cliques. Even if a $2k$ kernel exists for \\textsc{Cluster Editing}, this\nkernel does not reduce the size of the instance in most cases. Therefore, we\nexplore the question of whether linear kernels are a theoretical limit in edge\nmodification problems, in particular when the target graphs are very structured\n(such as a partition into cliques for instance). We prove, as far as we know,\nthe first sublinear kernel for an edge modification problem. Namely, we show\nthat \\textsc{Clique + Independent Set Deletion}, which is a restriction of\n\\textsc{Cluster Deletion}, admits a kernel of size $O(k/\\log k)$.\n  We also obtain small kernels for several other edge modification problems. We\nprove that \\textsc{Split Addition} (and the equivalent \\textsc{Split Deletion})\nadmits a linear kernel, improving the existing quadratic kernel of Ghosh et al.\n\\cite{ghosh2015faster}. We also prove that \\textsc{Trivially Perfect Addition}\nadmits a quadratic kernel (improving the cubic kernel of Guo\n\\cite{guo2007problem}), and finally prove that its triangle-free version\n(\\textsc{Starforest Deletion}) admits a linear kernel, which is optimal under\nETH.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:39:24 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Bathie", "Gabriel", "", "ENS Lyon"], ["Bousquet", "Nicolas", "", "LIRIS, Universit\u00e9 Lyon\n  1"], ["Pierron", "Th\u00e9o", "", "LIRIS, Universit\u00e9 Lyon 1"]]}, {"id": "2105.09602", "submitter": "Changyong Hu", "authors": "Changyong Hu, Vijay K. Garg", "title": "Characterization of Super-stable Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An instance of the super-stable matching problem with incomplete lists and\nties is an undirected bipartite graph $G = (A \\cup B, E)$, with an adjacency\nlist being a linearly ordered list of ties. Ties are subsets of vertices\nequally good for a given vertex. An edge $(x,y) \\in E \\backslash M$ is a\nblocking edge for a matching $M$ if by getting matched to each other neither of\nthe vertices $x$ and $y$ would become worse off. Thus, there is no disadvantage\nif the two vertices would like to match up. A matching $M$ is super-stable if\nthere is no blocking edge with respect to $M$. It has previously been shown\nthat super-stable matchings form a distributive lattice and the number of\nsuper-stable matchings can be exponential in the number of vertices. We give\ntwo compact representations of size $O(m)$ that can be used to construct all\nsuper-stable matchings, where $m$ denotes the number of edges in the graph. The\nconstruction of the second representation takes $O(mn)$ time, where $n$ denotes\nthe number of vertices in the graph, and gives an explicit rotation poset\nsimilar to the rotation poset in the classical stable marriage problem. We also\ngive a polyhedral characterisation of the set of all super-stable matchings and\nprove that the super-stable matching polytope is integral, thus solving an open\nproblem stated in the book by Gusfield and Irving .\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:56:54 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hu", "Changyong", ""], ["Garg", "Vijay K.", ""]]}, {"id": "2105.09675", "submitter": "Niels Gr\\\"uttemeier", "authors": "Niels Gr\\\"uttemeier, Christian Komusiewicz, Nils Morawietz", "title": "On the Parameterized Complexity of Polytree Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A Bayesian network is a directed acyclic graph that represents statistical\ndependencies between variables of a joint probability distribution. A\nfundamental task in data science is to learn a Bayesian network from observed\ndata. \\textsc{Polytree Learning} is the problem of learning an optimal Bayesian\nnetwork that fulfills the additional property that its underlying undirected\ngraph is a forest. In this work, we revisit the complexity of \\textsc{Polytree\nLearning}. We show that \\textsc{Polytree Learning} can be solved in $3^n \\cdot\n|I|^{\\mathcal{O}(1)}$ time where $n$ is the number of variables and $|I|$ is\nthe total instance size. Moreover, we consider the influence of the number of\nvariables $d$ that might receive a nonempty parent set in the final DAG on the\ncomplexity of \\textsc{Polytree Learning}. We show that \\textsc{Polytree\nLearning} has no $f(d)\\cdot |I|^{\\mathcal{O}(1)}$-time algorithm, unlike\nBayesian network learning which can be solved in $2^d \\cdot\n|I|^{\\mathcal{O}(1)}$ time. We show that, in contrast, if $d$ and the maximum\nparent set size are bounded, then we can obtain efficient algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:29:12 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Gr\u00fcttemeier", "Niels", ""], ["Komusiewicz", "Christian", ""], ["Morawietz", "Nils", ""]]}, {"id": "2105.09838", "submitter": "Tasuku Soma", "authors": "Tasuku Soma and Yuichi Yoshida", "title": "Online Risk-Averse Submodular Maximization", "comments": "Full version of our paper in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial-time online algorithm for maximizing the conditional\nvalue at risk (CVaR) of a monotone stochastic submodular function. Given $T$\ni.i.d. samples from an underlying distribution arriving online, our algorithm\nproduces a sequence of solutions that converges to a ($1-1/e$)-approximate\nsolution with a convergence rate of $O(T^{-1/4})$ for monotone continuous\nDR-submodular functions. Compared with previous offline algorithms, which\nrequire $\\Omega(T)$ space, our online algorithm only requires $O(\\sqrt{T})$\nspace. We extend our online algorithm to portfolio optimization for monotone\nsubmodular set functions under a matroid constraint. Experiments conducted on\nreal-world datasets demonstrate that our algorithm can rapidly achieve CVaRs\nthat are comparable to those obtained by existing offline algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:37:57 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Soma", "Tasuku", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2105.10043", "submitter": "Nathan Klein", "authors": "Anna Karlin, Nathan Klein, Shayan Oveis Gharan", "title": "A (Slightly) Improved Bound on the Integrality Gap of the Subtour LP for\n  TSP", "comments": "arXiv admin note: text overlap with arXiv:2007.01409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for some $\\epsilon > 10^{-36}$ and any metric TSP instance, the\nmax entropy algorithm returns a solution of expected cost at most\n$\\frac{3}{2}-\\epsilon$ times the cost of the optimal solution to the subtour\nelimination LP. This implies that the integrality gap of the subtour LP is at\nmost $\\frac{3}{2}-\\epsilon$.\n  This analysis also shows that there is a randomized $\\frac{3}{2}-\\epsilon$\napproximation for the 2-edge-connected multi-subgraph problem, improving upon\nChristofides' algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:43:18 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Karlin", "Anna", ""], ["Klein", "Nathan", ""], ["Gharan", "Shayan Oveis", ""]]}, {"id": "2105.10094", "submitter": "Anshul Gupta", "authors": "Anshul Gupta and Toyotaro Suzumura", "title": "Finding All Bounded-Length Simple Cycles in a Directed Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A new efficient algorithm is presented for finding all simple cycles that\nsatisfy a length constraint in a directed graph. When the number of vertices is\nnon-trivial, most cycle-finding problems are of practical interest for sparse\ngraphs only. We show that for a class of sparse graphs in which the vertex\ndegrees are almost uniform, our algorithm can find all cycles of length less\nthan or equal to $k$ in $O((c+n)(k-1)d^k)$ steps, where $n$ is the number of\nvertices, $c$ is the total number of cycles discovered, $d$ is the average\ndegree of the graph's vertices, and $k > 1$. While our analysis for the running\ntime addresses only a class of sparse graphs, we provide empirical and\nexperimental evidence of the efficiency of the algorithm for general sparse\ngraphs. This algorithm is a significant improvement over the only other\ndeterministic algorithm for this problem known to us; it also lends itself to\nmassive parallelism. Experimental results of a serial implementation on some\nlarge real-world graphs are presented.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 02:15:50 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 17:41:09 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Gupta", "Anshul", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "2105.10184", "submitter": "Du\\v{s}an Knop", "authors": "Du\\v{s}an Knop, \\v{S}imon Schierreich, Ond\\v{r}ej Such\\'y", "title": "Balancing the Spread of Two Opinions in Sparse Social Networks", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the famous Target Set Selection problem, we propose a new\ndiscrete model for simultaneously spreading several opinions within a social\nnetwork and perform an initial study of its complexity. Here, we are given a\nsocial network, a seed-set of agents for each opinion, and two thresholds for\neach agent. The first threshold represents the willingness of an agent to adopt\nan opinion if the agent has no opinion at all, while the second threshold\nstates for willingness to acquire second opinion. The goal is to add as few\nagents as possible to the initial seed-sets such that, once the process started\nwith these seed-sets stabilizes, each agent has either both opinions or none.\n  We show that the problem is NP-hard. Further, we investigate the complexity\nfrom the parameterized point-of-view. The problem is W[1]-hard with respect to\nthe solution size. The problem remains W[1]-hard even for the combination of\nparameters the solution size and treewidth of the network even if all\nthresholds are at most 3, or the activation process stabilizes within 4 rounds.\nOn the other hand, the problem is FPT when parameterized by the number of\nrounds, maximum threshold, and treewidth. This algorithm applies also for\ncombined parameter treedepth and maximum threshold. Finally, we show that the\nproblem is FPT when parameterized by vertex cover number of the input network\nalone. Our results also imply that the original Target Set Selection problem is\nFPT when parameterized by 3-PVC.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 07:52:24 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Knop", "Du\u0161an", ""], ["Schierreich", "\u0160imon", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "2105.10225", "submitter": "Daniel Schmidt", "authors": "David K\\\"onen and Daniel R. Schmidt and Christiane Spisla", "title": "Finding all minimum cost flows and a faster algorithm for the K best\n  flow problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of determining all optimal integer solutions\nof a linear integer network flow problem, which we call the all optimal integer\nflow (AOF) problem. We derive an O(F (m + n) + mn + M ) time algorithm to\ndetermine all F many optimal integer flows in a directed network with n nodes\nand m arcs, where M is the best time needed to find one minimum cost flow. We\nremark that stopping Hamacher's well-known method for the determination of the\nK best integer flows at the first sub-optimal flow results in an algorithm with\na running time of O(F m(n log n + m) + M ) for solving the AOF problem. Our\nimprovement is essentially made possible by replacing the shortest path\nsub-problem with a more efficient way to determine a so called proper zero cost\ncycle using a modified depth-first search technique. As a byproduct, our\nanalysis yields an enhanced algorithm to determine the K best integer flows\nthat runs in O(Kn3 + M ). Besides, we give lower and upper bounds for the\nnumber of all optimal integer and feasible integer solutions. Our bounds are\nbased on the fact that any optimal solution can be obtained by an initial\noptimal tree solution plus a conical combination of incidence vectors of all\ninduced cycles with bounded coefficients.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:23:55 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["K\u00f6nen", "David", ""], ["Schmidt", "Daniel R.", ""], ["Spisla", "Christiane", ""]]}, {"id": "2105.10327", "submitter": "Dana Shapira", "authors": "Aharon Fruchtman, Yoav Gross, Shmuel T. Klein, Dana Shapira", "title": "Weighted Burrows-Wheeler Compression", "comments": "14 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A weight based dynamic compression method has recently been proposed, which\nis especially suitable for the encoding of files with locally skewed\ndistributions. Its main idea is to assign larger weights to closer to be\nencoded symbols by means of an increasing weight function, rather than\nconsidering each position in the text evenly. A well known transformation that\ntends to convert input files into files with a more skewed distribution is the\nBurrows-Wheeler Transform. This paper employs the weighted approach on\nBurrows-Wheeler transformed files and provides empirical evidence of the\nefficiency of this combination.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 12:59:19 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Fruchtman", "Aharon", ""], ["Gross", "Yoav", ""], ["Klein", "Shmuel T.", ""], ["Shapira", "Dana", ""]]}, {"id": "2105.10434", "submitter": "Barak Steindl", "authors": "Barak Steindl and Meirav Zehavi", "title": "Verification of Multi-Layered Assignment Problems", "comments": "arXiv admin note: text overlap with arXiv:2004.00655", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of assignment problems is a fundamental and well-studied class in\nthe intersection of Social Choice, Computational Economics and Discrete\nAllocation. In a general assignment problem, a group of agents expresses\npreferences over a set of items, and the task is to allocate items to agents in\nan \"optimal\" way. A verification variant of this problem includes an allocation\nas part of the input, and the question becomes whether this allocation is\n\"optimal\". In this paper, we generalize the verification variant to the setting\nwhere each agent is equipped with multiple incomplete preference lists: Each\nlist (called a layer) is a ranking of items in a possibly different way\naccording to a different criterion.\n  In particular, we introduce three multi-layer verification problems, each\ncorresponds to an optimality notion that weakens the notion of global\noptimality (that is, pareto optimality in multiple layers) in a different way.\nInformally, the first notion requires that, for each group of agents whose size\nis exactly some input parameter k, the agents in the group will not be able to\ntrade their assigned items among themselves and benefit in at least alpha\nlayers; the second notion is similar, but it concerns all groups of size at\nmost k rather than exactly k; the third notion strengthens these notions by\nrequiring that groups of k agents will not be part of possibly larger groups\nthat benefit in at least alpha layers. We study the three problems from the\nperspective of parameterized complexity under several natural parameterizations\nsuch as the number of layers, the number of agents, the number of items, the\nnumber of allocated items, the maximum length of a preference list, and more.\nWe present an almost comprehensive picture of the parameterized complexity of\nthe problems with respect to these parameters.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:12:31 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 17:56:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Steindl", "Barak", ""], ["Zehavi", "Meirav", ""]]}, {"id": "2105.10595", "submitter": "Adam Ga\\'nczorz", "authors": "Adam Ga\\'nczorz (1), Tomasz Jurdzi\\'nski (1), Mateusz Lewko (1),\n  Andrzej Pelc (2) ((1) Institute of Computer Science, University of\n  Wroc{\\l}aw, (2) D\\'epartement d'informatique, Universit\\'e du Qu\\'ebec en\n  Outaouais)", "title": "Deterministic Size Discovery and Topology Recognition in Radio Networks\n  with Short Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the fundamental problems of size discovery and topology\nrecognition in radio networks modeled by simple undirected connected graphs.\nSize discovery calls for all nodes to output the number of nodes in the graph,\ncalled its size, and in the task of topology recognition each node has to learn\nthe topology of the graph and its position in it. In radio networks, nodes\ncommunicate in synchronous rounds and start in the same round. In each round a\nnode can either transmit the same message to all its neighbors, or stay silent\nand listen. At the receiving end, a node $v$ hears a message from a neighbor\n$w$ in a given round, if $v$ listens in this round, and if $w$ is its only\nneighbor that transmits in this round. If more than one neighbor of a node $v$\ntransmits in a given round, there is a collision at $v$. We do not assume\ncollision detection: in case of a collision, node $v$ does not hear anything.\nThe time of a deterministic algorithm for each of the above problems is the\nworst-case number of rounds it takes to solve it.\n  Our goal is to construct short labeling schemes for size discovery and\ntopology recognition in arbitrary radio networks, and to design efficient\ndeterministic algorithms using these schemes. For size discovery, we construct\na labeling scheme of length $O(\\log\\log\\Delta)$ and we design an algorithm for\nthis problem using this scheme and working in time $O(\\log^2 n)$, where $n$ is\nthe size of the graph. We also show that time complexity $O(\\log^2 n)$ is\noptimal for the problem of size discovery, whenever the labeling scheme is of\noptimal length. For topology recognition, we construct a labeling scheme of\nlength $O(\\log\\Delta)$, and we design an algorithm for this problem using this\nscheme working in time $O\\left(D\\Delta+\\min(\\Delta^2,n)\\right)$. We also show\nthat the length of our labeling scheme is asymptotically optimal.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 22:37:50 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ga\u0144czorz", "Adam", ""], ["Jurdzi\u0144ski", "Tomasz", ""], ["Lewko", "Mateusz", ""], ["Pelc", "Andrzej", ""]]}, {"id": "2105.10622", "submitter": "Samuel McCauley", "authors": "Tsvi Kopelowitz, Samuel McCauley, Ely Porat", "title": "Support Optimality and Adaptive Cuckoo Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Filters (such as Bloom Filters) are data structures that speed up network\nrouting and measurement operations by storing a compressed representation of a\nset. Filters are space efficient, but can make bounded one-sided errors: with\ntunable probability epsilon, they may report that a query element is stored in\nthe filter when it is not. This is called a false positive. Recent research has\nfocused on designing methods for dynamically adapting filters to false\npositives, reducing the number of false positives when some elements are\nqueried repeatedly.\n  Ideally, an adaptive filter would incur a false positive with bounded\nprobability epsilon for each new query element, and would incur o(epsilon)\ntotal false positives over all repeated queries to that element. We call such a\nfilter support optimal.\n  In this paper we design a new Adaptive Cuckoo Filter and show that it is\nsupport optimal (up to additive logarithmic terms) over any n queries when\nstoring a set of size n. Our filter is simple: fixing previous false positives\nrequires a simple cuckoo operation, and the filter does not need to store any\nadditional metadata. This data structure is the first practical data structure\nthat is support optimal, and the first filter that does not require additional\nspace to fix false positives.\n  We complement these bounds with experiments showing that our data structure\nis effective at fixing false positives on network traces, outperforming\nprevious Adaptive Cuckoo Filters.\n  Finally, we investigate adversarial adaptivity, a stronger notion of\nadaptivity in which an adaptive adversary repeatedly queries the filter, using\nthe result of previous queries to drive the false positive rate as high as\npossible. We prove a lower bound showing that a broad family of filters,\nincluding all known Adaptive Cuckoo Filters, can be forced by such an adversary\nto incur a large number of false positives.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 02:33:34 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kopelowitz", "Tsvi", ""], ["McCauley", "Samuel", ""], ["Porat", "Ely", ""]]}, {"id": "2105.10625", "submitter": "Orestis Papadigenopoulos", "authors": "Alexia Atsidakou, Orestis Papadigenopoulos, Soumya Basu, Constantine\n  Caramanis, Sanjay Shakkottai", "title": "Combinatorial Blocking Bandits with Stochastic Delays", "comments": "International Conference on Machine Learning, ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has considered natural variations of the multi-armed bandit\nproblem, where the reward distribution of each arm is a special function of the\ntime passed since its last pulling. In this direction, a simple (yet widely\napplicable) model is that of blocking bandits, where an arm becomes unavailable\nfor a deterministic number of rounds after each play. In this work, we extend\nthe above model in two directions: (i) We consider the general combinatorial\nsetting where more than one arms can be played at each round, subject to\nfeasibility constraints. (ii) We allow the blocking time of each arm to be\nstochastic. We first study the computational/unconditional hardness of the\nabove setting and identify the necessary conditions for the problem to become\ntractable (even in an approximate sense). Based on these conditions, we provide\na tight analysis of the approximation guarantee of a natural greedy heuristic\nthat always plays the maximum expected reward feasible subset among the\navailable (non-blocked) arms. When the arms' expected rewards are unknown, we\nadapt the above heuristic into a bandit algorithm, based on UCB, for which we\nprovide sublinear (approximate) regret guarantees, matching the theoretical\nlower bounds in the limiting case of absence of delays.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 02:46:04 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Atsidakou", "Alexia", ""], ["Papadigenopoulos", "Orestis", ""], ["Basu", "Soumya", ""], ["Caramanis", "Constantine", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2105.10689", "submitter": "G\\\"ozde Filiz", "authors": "G\\\"ozde Filiz, M. O\\u{g}uzhan K\\\"ulekci", "title": "An Algorithm for Reordering Buffer Management Problem and Experimental\n  Evaluations on Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the reordering buffer management problem, a sequence of requests must be\nexecuted by a service station, where a cost occurs for each pair of consecutive\nrequests with different attributes. A reordering buffer management algorithm\naims to permute the input sequence using the buffer to minimize the total cost.\nReordering buffers has many potential applications in computer sciences and\neconomics. In this article, we proved the minimum buffer length for the optimal\nsolution to the reordering buffer management problem in the offline setting.\nWith the assumption that color selection is always made when the buffer is\nfull, selecting the most frequent color from the buffer given the smallest\nbuffer size $k$ that satisfies either $o_1 < 2 \\cdot \\lceil \\frac{k}{\\sigma}\n\\rceil$ OR $o_2 < \\lceil \\frac{k}{\\sigma} \\rceil$ guarantees the optimal\nsolution, where $o_1$ and $o_2$ represent respectively the frequency of the\nmost and the second most frequent colors in the input sequence $\\mathcal{X}$,\nand $\\sigma$ is the number of distinct colors appearing in $\\mathcal{X}$. We\nproposed a new algorithm for the online setting of the problem that uses the\nresults of the proof made on the minimum buffer length required for the optimal\nsolution. Moreover, we presented the results of the first experimental setup\nthat uses input sequences following discrete distributions to evaluate the\nperformance of algorithms. Out of 432 cases, the new algorithm showed the best\nperformance in 409 cases that is approximately $95\\%$ of all cases.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 11:02:18 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Filiz", "G\u00f6zde", ""], ["K\u00fclekci", "M. O\u011fuzhan", ""]]}, {"id": "2105.10742", "submitter": "Ajinkya Ramdas Gaikwad", "authors": "Ajinkya Gaikwad, Soumen Maity, Shuvam Kant Tripathi", "title": "Parameterized Complexity of Locally Minimal Defensive Alliances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Defensive Alliance problem has been studied extensively during the last\ntwenty years. A set $S$ of vertices of a graph is a defensive alliance if, for\neach element of $S$, the majority of its neighbours is in $S$. We consider the\nnotion of local minimality in this paper. We are interested in locally minimal\ndefensive alliance of maximum size. This problem is known to be NP-hard but its\nparameterized complexity remains open until now. We enhance our understanding\nof the problem from the viewpoint of parameterized complexity. The main results\nof the paper are the following: (1) when the input graph happens to be a tree,\nConnected Locally Minimal Strong Defensive Alliance} can be solved in\npolynomial time, (2) the Locally Minimal Defensive Alliance problem is\nNP-complete, even when restricted to planar graphs, (3) a color coding\nalgorithm for Exact Connected Locally Minimal Defensive Alliance, (4) the\nLocally Minimal Defensive Alliance problem is fixed parameter tractable (FPT)\nwhen parametrized by neighbourhood diversity, (5) the Exact Connected Locally\nMinimal Defensive Alliance problem parameterized by treewidth is W[1]-hard and\nthus not FPT (unless FPT=W[1]), (6) Locally Minimal Defensive Alliance can be\nsolved in polynomial time for graphs of bounded treewidth.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 14:59:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Gaikwad", "Ajinkya", ""], ["Maity", "Soumen", ""], ["Tripathi", "Shuvam Kant", ""]]}, {"id": "2105.11004", "submitter": "Aleksandros Sobczyk", "authors": "Aleksandros Sobczyk (1) and Efstratios Gallopoulos (2) ((1) IBM\n  Research Europe, Zurich, Switzerland (2) Computer Engineering and Informatics\n  Department, University of Patras, Greece)", "title": "Estimating leverage scores via rank revealing methods and randomization", "comments": "To appear in SIAM Journal on Matrix Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study algorithms for estimating the statistical leverage scores of\nrectangular dense or sparse matrices of arbitrary rank. Our approach is based\non combining rank revealing methods with compositions of dense and sparse\nrandomized dimensionality reduction transforms. We first develop a set of fast\nnovel algorithms for rank estimation, column subset selection and least squares\npreconditioning. We then describe the design and implementation of leverage\nscore estimators based on these primitives. These estimators are also effective\nfor rank deficient input, which is frequently the case in data analytics\napplications. We provide detailed complexity analyses for all algorithms as\nwell as meaningful approximation bounds and comparisons with the\nstate-of-the-art. We conduct extensive numerical experiments to evaluate our\nalgorithms and to illustrate their properties and performance using synthetic\nand real world data sets.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 19:21:55 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sobczyk", "Aleksandros", ""], ["Gallopoulos", "Efstratios", ""]]}, {"id": "2105.11052", "submitter": "Dominik Kempa", "authors": "Dominik Kempa, Ben Langmead", "title": "Fast and Space-Efficient Construction of AVL Grammars from the LZ77\n  Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar compression is, next to Lempel-Ziv (LZ77) and run-length\nBurrows-Wheeler transform (RLBWT), one of the most flexible approaches to\nrepresenting and processing highly compressible strings. The main idea is to\nrepresent a text as a context-free grammar whose language is precisely the\ninput string. This is called a straight-line grammar (SLG). An AVL grammar,\nproposed by Rytter [Theor. Comput. Sci., 2003] is a type of SLG that\nadditionally satisfies the AVL-property: the heights of parse-trees for\nchildren of every nonterminal differ by at most one. In contrast to other SLG\nconstructions, AVL grammars can be constructed from the LZ77 parsing in\ncompressed time: $\\mathcal{O}(z \\log n)$ where $z$ is the size of the LZ77\nparsing and $n$ is the length of the input text. Despite these advantages, AVL\ngrammars are thought to be too large to be practical.\n  We present a new technique for rapidly constructing a small AVL grammar from\nan LZ77 or LZ77-like parse. Our algorithm produces grammars that are always at\nleast five times smaller than those produced by the original algorithm, and\nnever more than double the size of grammars produced by the practical Re-Pair\ncompressor [Larsson and Moffat, Proc. IEEE, 2000]. Our algorithm also achieves\nlow peak RAM usage. By combining this algorithm with recent advances in\napproximating the LZ77 parsing, we show that our method has the potential to\nconstruct a run-length BWT from an LZ77 parse in about one third of the time\nand peak RAM required by other approaches. Overall, we show that AVL grammars\nare surprisingly practical, opening the door to much faster construction of key\ncompressed data structures.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 00:27:53 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kempa", "Dominik", ""], ["Langmead", "Ben", ""]]}, {"id": "2105.11250", "submitter": "Subhashis Majumder", "authors": "Biswajit Sanyal, Subhashis Majumder, Priya Ranjan Sinha Mahapatra", "title": "Efficient Reporting of Top-k Subset Sums", "comments": "21 pages, 7 figures, 2 tables, 2 algorithms, 3 functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer science, the \"Subset Sum problem\" is a very well known\nNP-complete problem. In this article, we consider its top-k variation - the\n\"Top-k Subset Sums problem\" that has wide application in recommendation\nsystems, where instead of k best objects they require k best subsets of objects\nwith lowest (or highest) overall scores. Given any input set R of n real\nnumbers, and a positive integer k, our target is to generate the k best subsets\n(top-k Subset Sums) of R, whose sum of elements is minimized. The direct\nsolution for this problem is prohibitively expensive since it requires\nenumerating all the possible subsets, which is exponential to the value of n.\nIn this article, our method is based on constructing a metadata structure G for\nn. Each node of G stores a bit vector of size n from which a subset of R can be\nretrieved. We finally show that we do not need to explicitly construct G as a\nwhole, rather to answer a query, we traverse only the required portion of G on\ndemand that obviously helps to bypass the high space requirement of the\npre-processing step.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:01:18 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sanyal", "Biswajit", ""], ["Majumder", "Subhashis", ""], ["Mahapatra", "Priya Ranjan Sinha", ""]]}, {"id": "2105.11338", "submitter": "Akshay Kamath", "authors": "Akshay Kamath, Eric Price, David P. Woodruff", "title": "A Simple Proof of a New Set Disjointness with Applications to Data\n  Streams", "comments": "CCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multiplayer promise set disjointness is one of the most widely used\nproblems from communication complexity in applications. In this problem there\nare $k$ players with subsets $S^1, \\ldots, S^k$, each drawn from $\\{1, 2,\n\\ldots, n\\}$, and we are promised that either the sets are (1) pairwise\ndisjoint, or (2) there is a unique element $j$ occurring in all the sets, which\nare otherwise pairwise disjoint. The total communication of solving this\nproblem with constant probability in the blackboard model is $\\Omega(n/k)$.\n  We observe for most applications, it instead suffices to look at what we call\nthe ``mostly'' set disjointness problem, which changes case (2) to say there is\na unique element $j$ occurring in at least half of the sets, and the sets are\notherwise disjoint. This change gives us a much simpler proof of an\n$\\Omega(n/k)$ randomized total communication lower bound, avoiding Hellinger\ndistance and Poincare inequalities. Using this we show several new results for\ndata streams:\n  \\begin{itemize} \\item for $\\ell_2$-Heavy Hitters, any $O(1)$-pass streaming\nalgorithm in the insertion-only model for detecting if an $\\eps$-$\\ell_2$-heavy\nhitter exists requires $\\min(\\frac{1}{\\eps^2}\\log \\frac{\\eps^2n}{\\delta},\n\\frac{1}{\\eps}n^{1/2})$ bits of memory, which is optimal up to a $\\log n$\nfactor. For deterministic algorithms and constant $\\eps$, this gives an\n$\\Omega(n^{1/2})$ lower bound, improving the prior $\\Omega(\\log n)$ lower\nbound. We also obtain lower bounds for Zipfian distributions. \\item for\n$\\ell_p$-Estimation, $p > 2$, we show an $O(1)$-pass $\\Omega(n^{1-2/p}\n\\log(1/\\delta))$ bit lower bound for outputting an $O(1)$-approximation with\nprobability $1-\\delta$, in the insertion-only model. This is optimal, and the\nbest previous lower bound was $\\Omega(n^{1-2/p} + \\log(1/\\delta))$.\n\\end{itemize}\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:15:46 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kamath", "Akshay", ""], ["Price", "Eric", ""], ["Woodruff", "David P.", ""]]}, {"id": "2105.11693", "submitter": "Takuya Mieno", "authors": "Mitsuru Funakoshi and Takuya Mieno", "title": "Minimal unique palindromic substrings after single-character\n  substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A palindrome is a string that reads the same forward and backward. A\npalindromic substring $w$ of a string $T$ is called a minimal unique\npalindromic substring (MUPS) of $T$ if $w$ occurs only once in $T$ and any\nproper palindromic substring of $w$ occurs at least twice in $T$. MUPSs are\nutilized for answering the shortest unique palindromic substring problem, which\nis motivated by molecular biology [Inoue et al., 2018]. Given a string $T$ of\nlength $n$, all MUPSs of $T$ can be computed in $O(n)$ time. In this paper, we\nstudy the problem of updating the set of MUPSs when a character in the input\nstring $T$ is substituted by another character. We first analyze the number $d$\nof changes of MUPSs when a character is substituted, and show that $d$ is in\n$O(\\log n)$. Further, we present an algorithm that uses $O(n)$ time and space\nfor preprocessing, and updates the set of MUPSs in $O(\\log\\sigma + (\\log\\log\nn)^2 + d)$ time where $\\sigma$ is the alphabet size. We also propose a variant\nof the algorithm, which runs in optimal $O(d)$ time when the alphabet size is\nconstant.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 06:22:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Funakoshi", "Mitsuru", ""], ["Mieno", "Takuya", ""]]}, {"id": "2105.11713", "submitter": "Ran Gelles", "authors": "Pierre Fraigniaud and Ran Gelles and Zvi Lotker", "title": "The Topology of Randomized Symmetry-Breaking Distributed Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Studying distributed computing through the lens of algebraic topology has\nbeen the source of many significant breakthroughs during the last two decades,\nespecially in the design of lower bounds or impossibility results for\ndeterministic algorithms. This paper aims at studying randomized synchronous\ndistributed computing through the lens of algebraic topology. We do so by\nstudying the wide class of (input-free) symmetry-breaking tasks, e.g., leader\nelection, in synchronous fault-free anonymous systems. We show that it is\npossible to redefine solvability of a task \"locally\", i.e., for each simplex of\nthe protocol complex individually, without requiring any global consistency.\nHowever, this approach has a drawback: it eliminates the topological aspect of\nthe computation, since a single facet has a trivial topological structure. To\novercome this issue, we introduce a \"projection\" $\\pi$ of both protocol and\noutput complexes, where every simplex $\\sigma$ is mapped to a complex\n$\\pi(\\sigma)$; the later has a rich structure that replaces the structure we\nlost by considering one single facet at a time.\n  To show the significance and applicability of our topological approach, we\nderive necessary and sufficient conditions for solving leader election in\nsynchronous fault-free anonymous shared-memory and message-passing models. In\nboth models, we consider scenarios in which there might be correlations between\nthe random values provided to the nodes. In particular, different parties might\nhave access to the same randomness source so their randomness is not\nindependent but equal. Interestingly, we find that solvability of leader\nelection relates to the number of parties that possess correlated randomness,\neither directly or via their greatest common divisor, depending on the specific\ncommunication model.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:38:36 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Gelles", "Ran", ""], ["Lotker", "Zvi", ""]]}, {"id": "2105.11788", "submitter": "Jan Martens", "authors": "Jan Martens, Jan Friso Groote, Lars van den Haak, Pieter Hijma and\n  Anton Wijs", "title": "A linear parallel algorithm to compute bisimulation and relational\n  coarsest partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most efficient way to calculate strong bisimilarity is by calculation the\nrelational coarsest partition on a transition system. We provide the first\nlinear time algorithm to calculate strong bisimulation using parallel random\naccess machines (PRAMs). More precisely, with $n$ states, $m$ transitions and\n$|\\mathit{Act}|\\leq m$ action labels, we provide an algorithm on $max(n,m)$\nprocessors that calculates strong bisimulation in time $O(n+|\\mathit{Act}|)$\nand space $O(n+m)$. The best-known PRAM algorithm has time complexity $O(n\\log\nn)$ on a smaller number of processors making it less suitable for massive\nparallel devices such as GPUs. An implementation on a GPU shows that the linear\ntime-bound is achievable on contemporary hardware.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 09:32:50 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Martens", "Jan", ""], ["Groote", "Jan Friso", ""], ["Haak", "Lars van den", ""], ["Hijma", "Pieter", ""], ["Wijs", "Anton", ""]]}, {"id": "2105.11888", "submitter": "Saman Ahmadi", "authors": "Saman Ahmadi, Guido Tack, Daniel Harabor, Philip Kilby", "title": "Bi-objective Search with Bi-directional A*", "comments": "16 pages, 4 figures, in Proceedings of The European Symposium on\n  Algorithms 2021 (ESA21), Changes: including the backward search of BOBA*", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bi-objective search is a well-known algorithmic problem, concerned with\nfinding a set of optimal solutions in a two-dimensional domain. This problem\nhas a wide variety of applications such as planning in transport systems or\noptimal control in energy systems. Recently, bi-objective A*-based search\n(BOA*) has shown state-of-the-art performance in large networks. This paper\ndevelops a bi-directional and parallel variant of BOA*, enriched with several\nspeed-up heuristics. Our experimental results on 1,000 benchmark cases show\nthat our bi-directional A* algorithm for bi-objective search (BOBA*) can\noptimally solve all of the benchmark cases within the time limit, outperforming\nthe state of the art BOA*, bi-objective Dijkstra and bi-directional\nbi-objective Dijkstra by an average runtime improvement of a factor of five\nover all of the benchmark instances.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:46:25 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 04:32:30 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ahmadi", "Saman", ""], ["Tack", "Guido", ""], ["Harabor", "Daniel", ""], ["Kilby", "Philip", ""]]}, {"id": "2105.11919", "submitter": "Ivo Fagundes David De Oliveira", "authors": "I. F. D. Oliveira and R. H. C. Takahashi", "title": "Minmax-optimal list searching with $O(\\log_2\\log_2 n)$ average cost", "comments": "under consideration by the Journal of Computer and System Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We find a searching method on ordered lists that surprisingly outperforms\nbinary searching with respect to average query complexity while retaining\nminmax optimality. The method is shown to require $O(\\log_2\\log_2 n)$ queries\non average while never exceeding $\\lceil \\log_2 n \\rceil$ queries in the worst\ncase, i.e. the minmax bound of binary searching. Our average results assume a\nuniform distribution hypothesis similar to those of prevous authors under which\nthe expected query complexity of interpolation search of $O(\\log_2\\log_2 n)$ is\nknown to be optimal. Hence our method turns out to be optimal with respect to\nboth minmax and average performance. We further provide robustness guarantees\nand perform several numerical experiments with both artificial and real data.\nOur results suggest that time savings range roughly from a constant factor of\n10\\% to 50\\% to a logarithmic factor spanning orders of magnitude when\ndifferent metrics are considered.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 13:22:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Oliveira", "I. F. D.", ""], ["Takahashi", "R. H. C.", ""]]}, {"id": "2105.11992", "submitter": "Richard Santiago", "authors": "Danish Kashaev, Richard Santiago", "title": "A Simple Optimal Contention Resolution Scheme for Uniform Matroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach to solve a combinatorial optimization problem is to first\nsolve a continous relaxation and then round the fractional solution. For the\nlatter, the framework of contention resolution schemes (or CR schemes)\nintroduced by Chekuri, Vondrak, and Zenklusen, has become a general and\nsuccessful tool. A CR scheme takes a fractional point $x$ in a relaxation\npolytope, rounds each coordinate $x_i$ independently to get a possibly\nnon-feasible set, and then drops some elements in order to satisfy the\nindependence constraints. Intuitively, a CR scheme is $c$-balanced if every\nelement $i$ is selected with probability at least $c \\cdot x_i$.\n  It is known that general matroids admit a $(1-1/e)$-balanced CR scheme, and\nthat this is (asymptotically) optimal. This is in particular true for the\nspecial case of uniform matroids of rank one. In this work, we provide a simple\nand explicit monotone CR scheme with a balancedness factor of $1 -\ne^{-k}k^k/k!$ for uniform matroids of rank $k$ (which matches the balancedness\nof $1-1/e$ for $k=1$), and show that this is optimal. While this bound can be\nobtained by combining previously known results, these require defining an\nexponential-sized linear program and using random sampling and the ellipsoid\nalgorithm. Our procedure, on the other hand, has the advantage of being simple\nand explicit. Moreover, this scheme generalizes into an optimal CR scheme for\npartition matroids.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:55:37 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:29:22 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 13:33:32 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kashaev", "Danish", ""], ["Santiago", "Richard", ""]]}, {"id": "2105.12003", "submitter": "Hendrik Molter", "authors": "Nicolas Maack and Hendrik Molter and Rolf Niedermeier and Malte Renken", "title": "On Finding Separators in Temporal Split and Permutation Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Removing all connections between two vertices s and z in a graph by removing\na minimum number of vertices is a fundamental problem in algorithmic graph\ntheory. This (s,z)-separation problem is well-known to be polynomial solvable\nand serves as an important primitive in many applications related to network\nconnectivity. We study the NP-hard temporal (s,z)-separation problem on\ntemporal graphs, which are graphs with fixed vertex sets but edge sets that\nchange over discrete time steps. We tackle this problem by restricting the\nlayers (i.e., graphs characterized by edges that are present at a certain point\nin time) to specific graph classes. We restrict the layers of the temporal\ngraphs to be either all split graphs or all permutation graphs (both being\nperfect graph classes) and provide both intractability and tractability\nresults. In particular, we show that in general the problem remains NP-hard\nboth on temporal split and temporal permutation graphs, but we also spot\npromising islands of fixed-parameter tractability particularly based on\nparameterizations that measure the amount of \"change over time\".\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:12:32 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Maack", "Nicolas", ""], ["Molter", "Hendrik", ""], ["Niedermeier", "Rolf", ""], ["Renken", "Malte", ""]]}, {"id": "2105.12086", "submitter": "Kangning Wang", "authors": "Kangning Wang", "title": "An $\\Omega(\\log n)$ Lower Bound for Online Matching on the Line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For online matching with the line metric, we present a lower bound of\n$\\Omega(\\log n)$ on the approximation ratio of any online (possibly randomized)\nalgorithm. This beats the previous best lower bound of $\\Omega(\\sqrt{\\log n})$\nand matches the known upper bound of $O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:10:45 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Wang", "Kangning", ""]]}, {"id": "2105.12093", "submitter": "Svein H{\\o}gemo", "authors": "Svein H{\\o}gemo, Benjamin Bergougnoux, Ulrik Brandes, Christophe Paul\n  and Jan Arne Telle", "title": "On Dasgupta's hierarchical clustering objective and its relation to\n  other graph parameters", "comments": "Full version, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The minimum height of vertex and edge partition trees are well-studied graph\nparameters known as, for instance, vertex and edge ranking number. While they\nare NP-hard to determine in general, linear-time algorithms exist for trees.\nMotivated by a correspondence with Dasgupta's objective for hierarchical\nclustering we consider the total rather than maximum depth of vertices as an\nalternative objective for minimization. For vertex partition trees this leads\nto a new parameter with a natural interpretation as a measure of robustness\nagainst vertex removal.\n  As tools for the study of this family of parameters we show that they have\nsimilar recursive expressions and prove a binary tree rotation lemma. The new\nparameter is related to trivially perfect graph completion and therefore\nintractable like the other three are known to be. We give polynomial-time\nalgorithms for both total-depth variants on caterpillars and on trees with a\nbounded number of leaf neighbors. For general trees, we obtain a\n2-approximation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:21:21 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["H\u00f8gemo", "Svein", ""], ["Bergougnoux", "Benjamin", ""], ["Brandes", "Ulrik", ""], ["Paul", "Christophe", ""], ["Telle", "Jan Arne", ""]]}, {"id": "2105.12125", "submitter": "James Mitchell", "authors": "James D. Mitchell and Maria Tsalakou", "title": "An explicit algorithm for normal forms in small overlap monoids", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If $\\mathcal{P} = \\left\\langle A \\, | \\,R \\right\\rangle$ is a monoid\npresentation, then the relation words in $\\mathcal{P}$ are just the set of\nwords on the left or right hand side of any pair in $R$. A word $w\\in A ^*$ is\nsaid to be a piece of $\\mathcal{P}$ if $w$ is a factor of at least two distinct\nrelation words, or $w$ occurs more than once as a factor of a single relation\nword (possibly overlapping). A finitely presented monoid is a small overlap\nmonoid if no relation word can be written as a product of fewer than $4$\npieces. In this paper, we present a quadratic time algorithm for computing\nnormal forms of words in small overlap monoids where the coefficients are\nsufficiently small to allow for practical computation. Additionally, we show\nthat the uniform word problem for small overlap monoids can be solved in linear\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 13:40:14 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Mitchell", "James D.", ""], ["Tsalakou", "Maria", ""]]}, {"id": "2105.12150", "submitter": "Pierre Berg\\'e", "authors": "Pierre Berg\\'e, Michel Habib", "title": "Diameter, radius and all eccentricities in linear time for\n  constant-dimension median graphs", "comments": "22 pages, an extended abstract of this paper will appear in the\n  proceedings of LAGOS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Median graphs form the class of graphs which is the most studied in metric\ngraph theory. Recently, B\\'en\\'eteau et al. [2019] designed a linear-time\nalgorithm computing both the $\\Theta$-classes and the median set of median\ngraphs. A natural question emerges: is there a linear-time algorithm computing\nthe diameter and the radius for median graphs?\n  We answer positively to this question for median graphs $G$ with constant\ndimension $d$, i.e. the dimension of the largest induced hypercube of $G$. We\npropose a combinatorial algorithm computing all eccentricities of median graphs\nwith running time $O(2^{O(d\\log d)}n)$. As a consequence, this provides us with\na linear-time algorithm determining both the diameter and the radius of median\ngraphs with $d = O(1)$, such as cube-free median graphs. As the hypercube of\ndimension 4 is not planar, it shows also that all eccentricities of planar\nmedian graphs can be computed in $O(n)$.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 18:02:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berg\u00e9", "Pierre", ""], ["Habib", "Michel", ""]]}, {"id": "2105.12208", "submitter": "Yu Qin", "authors": "Yu Qin, Brittany Terese Fasy, Carola Wenk, and Brian Summa", "title": "A Domain-Oblivious Approach for Learning Concise Representations of\n  Filtered Topological Spaces", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams have been widely used to quantify the underlying\nfeatures of filtered topological spaces in data visualization. In many\napplications, computing distances between diagrams is essential; however,\ncomputing these distances has been challenging due to the computational cost.\nIn this paper, we propose a persistence diagram hashing framework that learns a\nbinary code representation of persistence diagrams, which allows for fast\ncomputation of distances. This framework is built upon a generative adversarial\nnetwork (GAN) with a diagram distance loss function to steer the learning\nprocess. Instead of attempting to transform diagrams into vectorized\nrepresentations, we hash diagrams into binary codes, which have natural\nadvantages in large-scale tasks. The training of this model is domain-oblivious\nin that it can be computed purely from synthetic, randomly created diagrams. As\na consequence, our proposed method is directly applicable to various datasets\nwithout the need of retraining the model. These binary codes, when compared\nusing fast Hamming distance, better maintain topological similarity properties\nbetween datasets than other vectorized representations. To evaluate this\nmethod, we apply our framework to the problem of diagram clustering and we\ncompare the quality and performance of our approach to the state-of-the-art. In\naddition, we show the scalability of our approach on a dataset with 10k\npersistence diagrams, which is not possible with current techniques. Moreover,\nour experimental results demonstrate that our method is significantly faster\nwith less memory usage, while retaining comparable or better quality\ncomparisons.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 20:44:28 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Qin", "Yu", ""], ["Fasy", "Brittany Terese", ""], ["Wenk", "Carola", ""], ["Summa", "Brian", ""]]}, {"id": "2105.12407", "submitter": "Benjamin Bergougnoux", "authors": "Benjamin Bergougnoux, Svein H{\\o}gemo, Jan Arne Telle and Martin\n  Vatshelle", "title": "On Alternative Models for Leaf Powers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental problem in computational biology is the construction of\nphylogenetic trees, also called evolutionary trees, for a set of organisms. A\ngraph-theoretic approach takes as input a similarity graph $G$ on the set of\norganisms, with adjacency denoting evolutionary closeness, and asks for a tree\n$T$ whose leaves are the set of organisms, with two vertices adjacent in $G$ if\nand only if the distance between them in the tree is less than some specified\ndistance bound. If this exists $G$ is called a leaf power. Over 20 years ago,\n[Nishimura et al., J. Algorithms, 2002] posed the question if leaf powers could\nbe recognized in polynomial time. In this paper we explore this still\nunanswered question from the perspective of two alternative models of leaf\npowers that have been rather overlooked. These models do not rely on a variable\ndistance bound and are therefore more apt for generalization.\n  Our first result concerns leaf powers with a linear structure and uses a\nmodel where the edges of the tree $T$ are weighted by rationals between 0 and\n1, and the distance bound is fixed to 1. We show that the graphs having such a\nmodel with $T$ a caterpillar are exactly the co-threshold tolerance graphs and\ncan therefore be recognized in $O(n^2)$ time by an algorithm of [Golovach et\nal., Discret. Appl. Math., 2017].\n  Our second result concerns leaf powers with a star structure and concerns the\ngeometric NeS model used by [Brandst\\\"adt et al., Discret. Math., 2010]. We\nshow that the graphs having a NeS model where the main embedding tree is a star\ncan be recognized in polynomial time. These results pave the way for an attack\non the main question, to settle the issue if leaf powers can be recognized in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:02:09 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bergougnoux", "Benjamin", ""], ["H\u00f8gemo", "Svein", ""], ["Telle", "Jan Arne", ""], ["Vatshelle", "Martin", ""]]}, {"id": "2105.12490", "submitter": "Prajnanaswaroopa S", "authors": "S. Prajnanaswaroopa, J. Geetha and K. Somasundaram", "title": "Total, Equitable Total and Neighborhood sum distinguishing Total\n  Colorings of Some Classes of Circulant Graphs", "comments": "13 Pages, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we have obtained the total chromatic as well as equitable and\nneighborhood sum distinguishing total chromatic numbers of some classes of the\ncirculant graphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:50:21 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 09:48:22 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Prajnanaswaroopa", "S.", ""], ["Geetha", "J.", ""], ["Somasundaram", "K.", ""]]}, {"id": "2105.12514", "submitter": "Johannes Hartmann", "authors": "Johannes Hartmann", "title": "Finding optimal strategies in sequential games with the novel selection\n  monad", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently discovered monad, Tx = Selection (x -> r) -> r, provides an\nelegant way to finnd optimal strategies in sequential games. During this\nthesis, a library was developed which provides a set of useful functions using\nthe selection monad to compute optimal games and AIs for sequential games. In\norder to explore the selection monads ability to support these AI\nimplementations, three example case studies were developed using Haskell: The\ntwo-player game Connect Four, a Sudoku solver and a simplified version of\nChess. These case studies show how to elegantly implement a game AI.\nFurthermore, a performance analysis of these case studies was done, identifying\nthe major points where performance can be increased.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 12:33:32 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hartmann", "Johannes", ""]]}, {"id": "2105.12623", "submitter": "Mauricio Resende", "authors": "Yuanyuan Dong, Andrew V. Goldberg, Alexander Noe, Nikos Parotsidis,\n  Mauricio G. C. Resende, and Quico Spaen", "title": "New instances for maximum weight independent set from a vehicle routing\n  application", "comments": "5 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of new instances of the maximum weight independent set\nproblem. These instances are derived from a real-world vehicle routing problem\nand are challenging to solve in part because of their large size. We present\ninstances with up to 881 thousand nodes and 383 million edges.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:23:25 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 19:36:29 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Dong", "Yuanyuan", ""], ["Goldberg", "Andrew V.", ""], ["Noe", "Alexander", ""], ["Parotsidis", "Nikos", ""], ["Resende", "Mauricio G. C.", ""], ["Spaen", "Quico", ""]]}, {"id": "2105.12758", "submitter": "Mark Wilde", "authors": "Margarite L. LaBorde and Mark M. Wilde", "title": "Testing symmetry on quantum computers", "comments": "v1: 24 pages, preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry is a unifying concept in physics. In quantum information and beyond,\nit is known that quantum states possessing symmetry are not useful for certain\ninformation-processing tasks. For example, states that commute with a\nHamiltonian realizing a time evolution are not useful for timekeeping during\nthat evolution, and bipartite states that are highly extendible are not\nstrongly entangled and thus not useful for basic tasks like teleportation.\nMotivated by this perspective, this paper details several quantum algorithms\nthat test the symmetry of quantum states and channels. For the case of testing\nBose symmetry of a state, we show that there is a simple and efficient quantum\nalgorithm, while the tests for other kinds of symmetry rely on the aid of a\nquantum prover. We prove that the acceptance probability of each algorithm is\nequal to the maximum symmetric fidelity of the state being tested, thus giving\na firm operational meaning to these latter resource quantifiers. Special cases\nof the algorithms test for incoherence or separability of quantum states. We\nevaluate the performance of these algorithms by using the variational approach\nto quantum algorithms, replacing the quantum prover with a variational circuit.\nWe also show that the maximum symmetric fidelities can be calculated by\nsemi-definite programs, which is useful for benchmarking the performance of the\nquantum algorithms for sufficiently small examples. Finally, we establish\nvarious generalizations of the resource theory of asymmetry, with the upshot\nbeing that the acceptance probabilities of the algorithms are resource\nmonotones and thus well motivated from the resource-theoretic perspective.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:01:54 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["LaBorde", "Margarite L.", ""], ["Wilde", "Mark M.", ""]]}, {"id": "2105.12881", "submitter": "Andrea Sportiello", "authors": "Andrea Sportiello", "title": "Boltzmann sampling of irreducible context-free structures in linear time", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We continue our program of improving the complexity of so-called Boltzmann\nsampling algorithms, for the exact sampling of combinatorial structures, and\nreach average linear-time complexity, i.e. optimality up to a multiplicative\nconstant. Here we solve this problem for irreducible context-free structures, a\nbroad family of structures to which the celebrated Drmota--Lalley--Woods\nTheorem applies. Our algorithm is a rejection algorithm. The main idea is to\nsingle out some degrees of freedom, i.e. write $p(x)=p_1(y) p_2(x|y)$, which\nallows to introduce a rejection factor at the level of the $y$ object, that is\nalmost surely of order $1$.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 23:59:57 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sportiello", "Andrea", ""]]}, {"id": "2105.12982", "submitter": "Pieter Kleer", "authors": "Pieter Kleer", "title": "Sampling from the Gibbs Distribution in Congestion Games", "comments": "Accepted at the 22nd ACM Conference on Economics and Computation (EC\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logit dynamics is a form of randomized game dynamics where players have a\nbias towards strategic deviations that give a higher improvement in cost. It is\nused extensively in practice. In congestion (or potential) games, the dynamics\nconverges to the so-called Gibbs distribution over the set of all strategy\nprofiles, when interpreted as a Markov chain. In general, logit dynamics might\nconverge slowly to the Gibbs distribution, but beyond that, not much is known\nabout their algorithmic aspects, nor that of the Gibbs distribution. In this\nwork, we are interested in the following two questions for congestion games: i)\nIs there an efficient algorithm for sampling from the Gibbs distribution? ii)\nIf yes, do there also exist natural randomized dynamics that converges quickly\nto the Gibbs distribution?\n  We first study these questions in extension parallel congestion games, a\nwell-studied special case of symmetric network congestion games. As our main\nresult, we show that there is a simple variation on the logit dynamics (in\nwhich we in addition are allowed to randomly interchange the strategies of two\nplayers) that converges quickly to the Gibbs distribution in such games. This\nanswers both questions above affirmatively. We also address the first question\nfor the class of so-called capacitated $k$-uniform congestion games.\n  To prove our results, we rely on the recent breakthrough work of Anari, Liu,\nOveis-Gharan and Vinzant (2019) concerning the approximate sampling of the base\nof a matroid according to strongly log-concave probability distribution.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:00:14 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Kleer", "Pieter", ""]]}, {"id": "2105.13055", "submitter": "Hendrik Molter", "authors": "Maciej Rymar and Hendrik Molter and Andr\\'e Nichterlein and Rolf\n  Niedermeier", "title": "Towards Classifying the Polynomial-Time Solvability of Temporal\n  Betweenness Centrality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In static graphs, the betweenness centrality of a graph vertex measures how\nmany times this vertex is part of a shortest path between any two graph\nvertices. Betweenness centrality is efficiently computable and it is a\nfundamental tool in network science. Continuing and extending previous work, we\nstudy the efficient computability of betweenness centrality in temporal graphs\n(graphs with fixed vertex set but time-varying arc sets). Unlike in the static\ncase, there are numerous natural notions of being a \"shortest\" temporal path\n(walk). Depending on which notion is used, it was already observed that the\nproblem is #P-hard in some cases while polynomial-time solvable in others. In\nthis conceptual work, we contribute towards classifying what a \"shortest path\n(walk) concept\" has to fulfill in order to gain polynomial-time computability\nof temporal betweenness centrality.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 10:50:41 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Rymar", "Maciej", ""], ["Molter", "Hendrik", ""], ["Nichterlein", "Andr\u00e9", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2105.13078", "submitter": "Rui Yao", "authors": "Rui Yao, Shlomo Bekhor", "title": "A Dynamic Tree Algorithm for Peer-to-Peer Ride-sharing Matching", "comments": "Accepted for publication on Networks and Spatial Economics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-demand peer-to-peer ride-sharing services provide flexible mobility\noptions, and are expected to alleviate congestion by sharing empty car seats.\nAn efficient matching algorithm is essential to the success of a ride-sharing\nsystem. The matching problem is related to the well-known dial-a-ride problem,\nwhich also tries to find the optimal pickup and delivery sequence for a given\nset of passengers. In this paper, we propose an efficient dynamic tree\nalgorithm to solve the on-demand peer-to-peer ride-sharing matching problem.\nThe dynamic tree algorithm benefits from given ride-sharing driver schedules,\nand provides satisfactory runtime performances. In addition, an efficient\npre-processing procedure to select candidate passenger requests is proposed,\nwhich further improves the algorithm performance. Numerical experiments\nconducted in a small network show that the dynamic tree algorithm reaches the\nsame objective function values of the exact algorithm, but with shorter\nruntimes. Furthermore, the proposed method is applied to a larger size problem.\nResults show that the spatial distribution of ride-sharing participants\ninfluences the algorithm performance. Sensitivity analysis confirms that the\nmost critical ride-sharing matching constraints are the excess travel times.\nThe network analysis suggests that small vehicle capacities do not guarantee\noverall vehicle-kilometer travel savings.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:53:02 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yao", "Rui", ""], ["Bekhor", "Shlomo", ""]]}, {"id": "2105.13172", "submitter": "Ami Paz", "authors": "Monika Henzinger, Ami Paz, Stefan Schmid", "title": "On the Complexity of Weight-Dynamic Network Algorithms", "comments": "To appear in IFIP Networking 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While operating communication networks adaptively may improve utilization and\nperformance, frequent adjustments also introduce an algorithmic challenge: the\nre-optimization of traffic engineering solutions is time-consuming and may\nlimit the granularity at which a network can be adjusted. This paper is\nmotivated by question whether the reactivity of a network can be improved by\nre-optimizing solutions dynamically rather than from scratch, especially if\ninputs such as link weights do not change significantly. This paper explores to\nwhat extent dynamic algorithms can be used to speed up fundamental tasks in\nnetwork operations. We specifically investigate optimizations related to\ntraffic engineering (namely shortest paths and maximum flow computations), but\nalso consider spanning tree and matching applications. While prior work on\ndynamic graph algorithms focuses on link insertions and deletions, we are\ninterested in the practical problem of link weight changes. We revisit existing\nupper bounds in the weight-dynamic model, and present several novel lower\nbounds on the amortized runtime for recomputing solutions. In general, we find\nthat the potential performance gains depend on the application, and there are\nalso strict limitations on what can be achieved, even if link weights change\nonly slightly.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 14:29:27 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Henzinger", "Monika", ""], ["Paz", "Ami", ""], ["Schmid", "Stefan", ""]]}, {"id": "2105.13202", "submitter": "Leon Sering", "authors": "Leon Sering and Laura Vargas Koch and Theresa Ziemke", "title": "Convergence of a Packet Routing Model to Flows Over Time", "comments": null, "journal-ref": null, "doi": "10.1145/3465456.3467626", "report-no": null, "categories": "cs.GT cs.DS math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The mathematical approaches for modeling dynamic traffic can roughly be\ndivided into two categories: discrete packet routing models and continuous flow\nover time models. Despite very vital research activities on models in both\ncategories, the connection between these approaches was poorly understood so\nfar. In this work we build this connection by specifying a (competitive) packet\nrouting model, which is discrete in terms of flow and time, and by proving its\nconvergence to the intensively studied model of flows over time with\ndeterministic queuing. More precisely, we prove that the limit of the\nconvergence process, when decreasing the packet size and time step length in\nthe packet routing model, constitutes a flow over time with multiple\ncommodities. In addition, we show that the convergence result implies the\nexistence of approximate equilibria in the competitive version of the packet\nrouting model. This is of significant interest as exact pure Nash equilibria,\nsimilar to almost all other competitive models, cannot be guaranteed in the\nmulti-commodity setting. Moreover, the introduced packet routing model with\ndeterministic queuing is very application-oriented as it is based on the\nnetwork loading module of the agent-based transport simulation MATSim. As the\npresent work is the first mathematical formalization of this simulation, it\nprovides a theoretical foundation and an environment for provable mathematical\nstatements for MATSim.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 14:50:01 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sering", "Leon", ""], ["Koch", "Laura Vargas", ""], ["Ziemke", "Theresa", ""]]}, {"id": "2105.13287", "submitter": "Dung Nguyen", "authors": "Dung Nguyen and Anil Vullikanti", "title": "Differentially Private Densest Subgraph Detection", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Densest subgraph detection is a fundamental graph mining problem, with a\nlarge number of applications. There has been a lot of work on efficient\nalgorithms for finding the densest subgraph in massive networks. However, in\nmany domains, the network is private, and returning a densest subgraph can\nreveal information about the network. Differential privacy is a powerful\nframework to handle such settings. We study the densest subgraph problem in the\nedge privacy model, in which the edges of the graph are private. We present the\nfirst sequential and parallel differentially private algorithms for this\nproblem. We show that our algorithms have an additive approximation guarantee.\nWe evaluate our algorithms on a large number of real-world networks, and\nobserve a good privacy-accuracy tradeoff when the network has high density.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:36:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 17:33:02 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nguyen", "Dung", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2105.13595", "submitter": "Cristian Urbina", "authors": "Gonzalo Navarro (1 and 2) and Cristian Urbina (1 and 2) ((1)\n  University of Chile, (2) CeBiB)", "title": "On Stricter Reachable Repetitiveness Measures*", "comments": "Funded in part by Basal Funds FB0001, Fondecyt Grant 1-200038, and a\n  Conicyt Doctoral Scholarship, ANID, Chile", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size $b$ of the smallest bidirectional macro scheme, which is arguably\nthe most general copy-paste scheme to generate a given sequence, is considered\nto be the strictest reachable measure of repetitiveness. It is strictly\nlower-bounded by measures like $\\gamma$ and $\\delta$, which are known or\nbelieved to be unreachable and to capture the entropy of repetitiveness. In\nthis paper we study another sequence generation mechanism, namely compositions\nof a morphism. We show that these form another plausible mechanism to\ncharacterize repetitive sequences and define NU-systems, which combine such a\nmechanism with macro schemes. We show that the size $\\nu \\leq b$ of the\nsmallest NU-system is reachable and can be $o(\\delta)$ for some string\nfamilies, thereby implying that the limit of compressibility of repetitive\nsequences can be even smaller than previously thought. We also derive several\nother results characterizing $\\nu$.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 05:24:53 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Navarro", "Gonzalo", "", "1 and 2"], ["Urbina", "Cristian", "", "1 and 2"]]}, {"id": "2105.13655", "submitter": "Dabeen Lee", "authors": "Dabeen Lee, Milan Vojnovic", "title": "Learning to Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a learning and scheduling algorithm to minimize the\nexpected cumulative holding cost incurred by jobs, where statistical parameters\ndefining their individual holding costs are unknown a priori. In each time\nslot, the server can process a job while receiving the realized random holding\ncosts of the jobs remaining in the system. Our algorithm is a learning-based\nvariant of the $c\\mu$ rule for scheduling: it starts with a preemption period\nof fixed length which serves as a learning phase, and after accumulating enough\ndata about individual jobs, it switches to nonpreemptive scheduling mode. The\nalgorithm is designed to handle instances with large or small gaps in jobs'\nparameters and achieves near-optimal performance guarantees. The performance of\nour algorithm is captured by its regret, where the benchmark is the minimum\npossible cost attained when the statistical parameters of jobs are fully known.\nWe prove upper bounds on the regret of our algorithm, and we derive a regret\nlower bound that is almost matching the proposed upper bounds. Our numerical\nresults demonstrate the effectiveness of our algorithm and show that our\ntheoretical regret analysis is nearly tight.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:04:06 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lee", "Dabeen", ""], ["Vojnovic", "Milan", ""]]}, {"id": "2105.13729", "submitter": "Rohit Vaish", "authors": "Telikepalli Kavitha and Rohit Vaish", "title": "Matchings and Copeland's Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Given a graph $G = (V,E)$ where every vertex has weak preferences over its\nneighbors, we consider the problem of computing an optimal matching as per\nagent preferences. The classical notion of optimality in this setting is\nstability. However stable matchings, and more generally, popular matchings need\nnot exist when $G$ is non-bipartite. Unlike popular matchings, Copeland winners\nalways exist in any voting instance -- we study the complexity of computing a\nmatching that is a Copeland winner and show there is no polynomial-time\nalgorithm for this problem unless $\\mathsf{P} = \\mathsf{NP}$.\n  We introduce a relaxation of both popular matchings and Copeland winners\ncalled semi-Copeland winners. These are matchings with Copeland score at least\n$\\mu/2$, where $\\mu$ is the total number of matchings in $G$; the maximum\npossible Copeland score is $(\\mu-1/2)$. We show a fully polynomial-time\nrandomized approximation scheme to compute a matching with Copeland score at\nleast $\\mu/2\\cdot(1-\\varepsilon)$ for any $\\varepsilon > 0$.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 10:50:47 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kavitha", "Telikepalli", ""], ["Vaish", "Rohit", ""]]}, {"id": "2105.13744", "submitter": "Dominik K\\\"oppl", "authors": "Tooru Akagi and Dominik K\\\"oppl and Yuto Nakashima and Shunsuke\n  Inenaga and Hideo Bannai and Masayuki Takeda", "title": "Grammar Index By Induced Suffix Sorting", "comments": "Our implementation is available at\n  https://github.com/TooruAkagi/GCIS_Index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern matching is the most central task for text indices. Most recent\nindices leverage compression techniques to make pattern matching feasible for\nmassive but highly-compressible datasets. Within this kind of indices, we\npropose a new compressed text index built upon a grammar compression based on\ninduced suffix sorting [Nunes et al., DCC'18]. We show that this grammar\nexhibits a locality sensitive parsing property, which allows us to specify,\ngiven a pattern $P$, certain substrings of $P$, called cores, that are\nsimilarly parsed in the text grammar whenever these occurrences are extensible\nto occurrences of $P$. Supported by the cores, given a pattern of length $m$,\nwe can locate all its $occ$ occurrences in a text $T$ of length $n$ within $O(m\n\\lg |\\mathcal{S}| + occ_C \\lg|\\mathcal{S}| \\lg n + occ)$ time, where\n$\\mathcal{S}$ is the set of all characters and non-terminals, $occ$ is the\nnumber of occurrences, and $occ_C$ is the number of occurrences of a chosen\ncore $C$ of $P$ in the right hand side of all production rules of the grammar\nof $T$. Our grammar index requires $O(g)$ words of space and can be built in\n$O(n)$ time using $O(g)$ working space, where $g$ is the sum of the right hand\nsides of all production rules. We underline the strength of our grammar index\nwith an exhaustive practical evaluation that gives evidence that our proposed\nsolution excels at locating long patterns in highly-repetitive texts.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 11:15:05 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Akagi", "Tooru", ""], ["K\u00f6ppl", "Dominik", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""]]}, {"id": "2105.13980", "submitter": "Rustam Latypov", "authors": "Rustam Latypov and Jara Uitto", "title": "Deterministic 3-Coloring of Trees in the Sublinear MPC model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deterministic $O(\\log^2 \\log n)$ time sublinear Massively Parallel\nComputation (MPC) algorithms for 3-coloring, maximal independent set and\nmaximal matching in trees with $n$ nodes. In accordance with the sublinear MPC\nregime, our algorithms run on machines that have memory as little as\n$O(n^\\delta)$ for any arbitrary constant $0<\\delta<1$. Furthermore, our\nalgorithms use only $O(n)$ global memory. Our main result is the 3-coloring\nalgorithm, which contrasts the probabilistic 4-coloring algorithm of Ghaffari,\nGrunau and Jin [DISC'20]. The maximal independent set and maximal matching\nalgorithms follow in $O(1)$ time after obtaining the coloring. The key\ningredient of our 3-coloring algorithm is an $O(\\log^2 \\log n)$ time MPC\nimplementation of a variant of the rake-and-compress tree decomposition used by\nChang and Pettie [FOCS'17], which is closely related to the $H$-partition by\nBarenboim and Elkin [PODC'08]. When restricting to trees of constant maximum\ndegree, we bring the runtime down to $O(\\log \\log n)$.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 17:03:28 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Latypov", "Rustam", ""], ["Uitto", "Jara", ""]]}, {"id": "2105.14119", "submitter": "Adam Kalai", "authors": "Adam Tauman Kalai, Varun Kanade", "title": "Towards optimally abstaining from prediction", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common challenge across all areas of machine learning is that training data\nis not distributed like test data, due to natural shifts, \"blind spots,\" or\nadversarial examples. We consider a model where one may abstain from\npredicting, at a fixed cost. In particular, our transductive abstention\nalgorithm takes labeled training examples and unlabeled test examples as input,\nand provides predictions with optimal prediction loss guarantees. The loss\nbounds match standard generalization bounds when test examples are i.i.d. from\nthe training distribution, but add an additional term that is the cost of\nabstaining times the statistical distance between the train and test\ndistribution (or the fraction of adversarial examples). For linear regression,\nwe give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization\nalgorithms. For binary classification, we show how to efficiently implement it\nusing a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the\nclass of interest. Our work builds on a recent abstention algorithm of\nGoldwasser, Kalais, and Montasser (2020) for transductive binary\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:44:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kalai", "Adam Tauman", ""], ["Kanade", "Varun", ""]]}, {"id": "2105.14260", "submitter": "Houshuang Chen", "authors": "Houshuang Chen (1), Zengfeng Huang (2), Shuai Li (1) and Chihao Zhang\n  (1) ((1) Shanghai Jiao Tong University, (2) Fudan University)", "title": "Understanding Bandits with Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bandit problem with graph feedback, proposed in [Mannor and Shamir,\nNeurIPS 2011], is modeled by a directed graph $G=(V,E)$ where $V$ is the\ncollection of bandit arms, and once an arm is triggered, all its incident arms\nare observed. A fundamental question is how the structure of the graph affects\nthe min-max regret. We propose the notions of the fractional weak domination\nnumber $\\delta^*$ and the $k$-packing independence number capturing upper bound\nand lower bound for the regret respectively. We show that the two notions are\ninherently connected via aligning them with the linear program of the weakly\ndominating set and its dual -- the fractional vertex packing set respectively.\nBased on this connection, we utilize the strong duality theorem to prove a\ngeneral regret upper bound $O\\left(\\left( \\delta^*\\log\n|V|\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$ and a lower bound\n$\\Omega\\left(\\left(\\delta^*/\\alpha\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$\nwhere $\\alpha$ is the integrality gap of the dual linear program. Therefore,\nour bounds are tight up to a $\\left(\\log |V|\\right)^{\\frac{1}{3}}$ factor on\ngraphs with bounded integrality gap for the vertex packing problem including\ntrees and graphs with bounded degree. Moreover, we show that for several\nspecial families of graphs, we can get rid of the $\\left(\\log\n|V|\\right)^{\\frac{1}{3}}$ factor and establish optimal regret.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 09:35:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Houshuang", "", "Shanghai Jiao Tong University"], ["Huang", "Zengfeng", "", "Fudan University"], ["Li", "Shuai", "", "Shanghai Jiao Tong University"], ["Zhang", "Chihao", "", "Shanghai Jiao Tong University"]]}, {"id": "2105.14423", "submitter": "Ryoma Sato", "authors": "Ryoma Sato", "title": "Enumerating Fair Packages for Group Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In package recommendations, a set of items is regarded as a unified package\ntowards a single common goal, whereas conventional recommender systems treat\nitems independently. For example, for music playlist recommendations, each\npackage (i.e., playlist) should be consistent with respect to the genres. In\ngroup recommendations, items are recommended to a group of users, whereas\nconventional recommender systems recommend items to an individual user.\nDifferent from the conventional settings, it is difficult to measure the\nutility of group recommendations because it involves more than one user. In\nparticular, fairness is crucial in group recommendations. Even if some members\nin a group are substantially satisfied with a recommendation, it is undesirable\nif other members are ignored to increase the total utility. Various methods for\nevaluating and applying the fairness of group recommendations have been\nproposed in the literature. However, all these methods maximize the score and\noutput only a single package. This is in contrast to conventional recommender\nsystems, which output several (e.g., top-$K$) candidates. This can be\nproblematic because a group can be dissatisfied with the recommended package\nowing to some unobserved reasons, even if the score is high. In particular,\neach fairness measure is not absolute, and users may call for different\nfairness criteria than the one adopted in the recommender system in operation.\nTo address this issue, we propose a method to enumerate fair packages so that a\ngroup can select their favorite packages from the list. Our proposed method can\nenumerate fair packages efficiently, and users can search their favorite\npackages by various filtering queries. We confirm that our algorithm scales to\nlarge datasets and can balance several aspects of the utility of the packages.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:06:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sato", "Ryoma", ""]]}, {"id": "2105.14527", "submitter": "Denis Roio", "authors": "Denis Roio, Alberto Ibrisevic, Andrea D'Intino", "title": "Reflow: Zero Knowledge Multi Party Signatures with Application to\n  Distributed Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reflow is a novel signature scheme supporting unlinkable signatures by\nmultiple parties authenticated by means of zero-knowledge credentials. Reflow\nintegrates with blockchains and graph databases to ensure confidentiality and\nauthenticity of signatures made by disposable identities that can be verified\neven when credential issuing authorities are offline. We implement and evaluate\nReflow smart contracts for Zenroom and present an application to produce\nauthenticated material passports for resource-event-agent accounting systems\nbased on graph data structures. Reflow uses short and computationally efficient\nauthentication credentials and can easily scale signatures to include thousands\nof participants.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 13:07:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Roio", "Denis", ""], ["Ibrisevic", "Alberto", ""], ["D'Intino", "Andrea", ""]]}, {"id": "2105.14629", "submitter": "Li Chen", "authors": "Li Chen, Richard Peng, and Di Wang", "title": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion is a fundamental graph procedure and has been a basic building\nblock in a wide range of theoretical and empirical applications such as graph\npartitioning and semi-supervised learning on graphs. In this paper, we study\ncomputationally efficient diffusion primitives beyond random walk.\n  We design an $\\widetilde{O}(m)$-time randomized algorithm for the\n$\\ell_2$-norm flow diffusion problem, a recently proposed diffusion model based\non network flow with demonstrated graph clustering related applications both in\ntheory and in practice. Examples include finding locally-biased low conductance\ncuts. Using a known connection between the optimal dual solution of the flow\ndiffusion problem and the local cut structure, our algorithm gives an\nalternative approach for finding such cuts in nearly linear time.\n  From a technical point of view, our algorithm contributes a novel way of\ndealing with inequality constraints in graph optimization problems. It adapts\nthe high-level algorithmic framework of nearly linear time Laplacian system\nsolvers, but requires several new tools: vertex elimination under constraints,\na new family of graph ultra-sparsifiers, and accelerated proximal gradient\nmethods with inexact proximal mapping computation.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 21:27:58 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 21:02:24 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Chen", "Li", ""], ["Peng", "Richard", ""], ["Wang", "Di", ""]]}, {"id": "2105.14695", "submitter": "Koji Nuida", "authors": "Takuto Odagawa and Koji Nuida", "title": "Halt Properties and Complexity Evaluations for Optimal DeepLLL Algorithm\n  Families", "comments": "20 pages; (v2) Abstract slightly revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepLLL algorithm (Schnorr, 1994) is a famous variant of LLL lattice basis\nreduction algorithm, and PotLLL algorithm (Fontein et al., 2014) and $S^2$LLL\nalgorithm (Yasuda and Yamaguchi, 2019) are recent polynomial-time variants of\nDeepLLL algorithm developed from cryptographic applications. However, the known\npolynomial bounds for computational complexity are shown only for parameter\n$\\delta < 1$; for \"optimal\" parameter $\\delta = 1$ which ensures the best\noutput quality, no polynomial bounds are known, and except for LLL algorithm,\nit is even not formally proved that the algorithm always halts within finitely\nmany steps. In this paper, we prove that these four algorithms always halt also\nwith optimal parameter $\\delta = 1$, and furthermore give explicit upper bounds\nfor the numbers of loops executed during the algorithms. Unlike the known bound\n(Akhavi, 2003) applicable to LLL algorithm only, our upper bounds are deduced\nin a unified way for all of the four algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 04:26:46 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 03:54:11 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Odagawa", "Takuto", ""], ["Nuida", "Koji", ""]]}, {"id": "2105.14961", "submitter": "Vin\\'icius L. de Lima", "authors": "Vin\\'icius L. de Lima and Manuel Iori and Fl\\'avio K. Miyazawa", "title": "Exact solution of network flow models with strong relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the solution of Mixed Integer Linear Programming (MILP) models\nwith strong relaxations that are derived from Dantzig-Wolfe decompositions and\nallow a pseudo-polynomial pricing algorithm. We exploit their network-flow\ncharacterization and provide a framework based on column generation,\nreduced-cost variable-fixing, and a highly asymmetric branching scheme that\nallows us to take advantage of the potential of the current MILP solvers. We\napply our framework to a variety of cutting and packing problems from the\nliterature. The efficiency of the framework is proved by extensive\ncomputational experiments, in which a significant number of open instances\ncould be solved to proven optimality for the first time.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 13:46:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["de Lima", "Vin\u00edcius L.", ""], ["Iori", "Manuel", ""], ["Miyazawa", "Fl\u00e1vio K.", ""]]}, {"id": "2105.15005", "submitter": "Weiming Feng", "authors": "Xiaoyu Chen, Weiming Feng, Yitong Yin, Xinyuan Zhang", "title": "Rapid mixing of Glauber dynamics via spectral independence for all\n  degrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an optimal $\\Omega(n^{-1})$ lower bound on the spectral gap of\nGlauber dynamics for anti-ferromagnetic two-spin systems with $n$ vertices in\nthe tree uniqueness regime. This spectral gap holds for all, including\nunbounded, maximum degree $\\Delta$. Consequently, we have the following mixing\ntime bounds for the models satisfying the uniqueness condition with a slack\n$\\delta\\in(0,1)$:\n  $\\bullet$ $C(\\delta) n^2\\log n$ mixing time for the hardcore model with\nfugacity $\\lambda\\le (1-\\delta)\\lambda_c(\\Delta)= (1-\\delta)\\frac{(\\Delta -\n1)^{\\Delta - 1}}{(\\Delta - 2)^\\Delta}$;\n  $\\bullet$ $C(\\delta) n^2$ mixing time for the Ising model with edge activity\n$\\beta\\in\\left[\\frac{\\Delta-2+\\delta}{\\Delta-\\delta},\\frac{\\Delta-\\delta}{\\Delta-2+\\delta}\\right]$;\n  where the maximum degree $\\Delta$ may depend on the number of vertices $n$,\nand $C(\\delta)$ depends only on $\\delta$.\n  Our proof is built upon the recently developed connections between the\nGlauber dynamics for spin systems and the high-dimensional expander walks. In\nparticular, we prove a stronger notion of spectral independence, called the\ncomplete spectral independence, and use a novel Markov chain called the field\ndynamics to connect this stronger spectral independence to the rapid mixing of\nGlauber dynamics for all degrees.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:40:34 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Feng", "Weiming", ""], ["Yin", "Yitong", ""], ["Zhang", "Xinyuan", ""]]}, {"id": "2105.15007", "submitter": "Anamay Chaturvedi", "authors": "Anamay Chaturvedi, Matthew Jones, Huy L. Nguyen", "title": "Locally Private $k$-Means Clustering with Constant Multiplicative\n  Approximation and Near-Optimal Additive Error", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a data set of size $n$ in $d'$-dimensional Euclidean space, the\n$k$-means problem asks for a set of $k$ points (called centers) so that the sum\nof the $\\ell_2^2$-distances between points of a given data set of size $n$ and\nthe set of $k$ centers is minimized. Recent work on this problem in the locally\nprivate setting achieves constant multiplicative approximation with additive\nerror $\\tilde{O} (n^{1/2 + a} \\cdot k \\cdot \\max \\{\\sqrt{d}, \\sqrt{k} \\})$ and\nproves a lower bound of $\\Omega(\\sqrt{n})$ on the additive error for any\nsolution with a constant number of rounds. In this work we bridge the gap\nbetween the exponents of $n$ in the upper and lower bounds on the additive\nerror with two new algorithms. Given any $\\alpha>0$, our first algorithm\nachieves a multiplicative approximation guarantee which is at most a\n$(1+\\alpha)$ factor greater than that of any non-private $k$-means clustering\nalgorithm with $k^{\\tilde{O}(1/\\alpha^2)} \\sqrt{d' n} \\mbox{poly}\\log n$\nadditive error. Given any $c>\\sqrt{2}$, our second algorithm achieves $O(k^{1 +\n\\tilde{O}(1/(2c^2-1))} \\sqrt{d' n} \\mbox{poly} \\log n)$ additive error with\nconstant multiplicative approximation. Both algorithms go beyond the\n$\\Omega(n^{1/2 + a})$ factor that occurs in the additive error for arbitrarily\nsmall parameters $a$ in previous work, and the second algorithm in particular\nshows for the first time that it is possible to solve the locally private\n$k$-means problem in a constant number of rounds with constant factor\nmultiplicative approximation and polynomial dependence on $k$ in the additive\nerror arbitrarily close to linear.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:41:40 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Jones", "Matthew", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "2105.15030", "submitter": "Chandresh Maurya", "authors": "Chandresh Kumar Maurya, Seemandhar Jain, Vishal Thakre", "title": "Digital Contact Tracing for Covid 19", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID19 pandemic created a worldwide emergency as it is estimated that\nsuch a large number of infections are due to human-to-human transmission of the\nCOVID19. As a necessity, there is a need to track users who came in contact\nwith users having travel history, asymptomatic and not yet symptomatic, but\nthey can be in the future. To solve this problem, the present work proposes a\nsolution for contact tracing based on assisted GPS and cloud computing\ntechnologies. An application is developed to collect each user's assisted GPS\ncoordinates once all the users install this application. This application\nperiodically sends assisted GPS data to the cloud. To determine which devices\nare within the permissible limit of 5m, we perform clustering over assisted GPS\ncoordinates and track the clusters for about t mins to allow the measure of\nspread. We assume that it takes around 3 or 5 mins to get the virus from an\ninfected object. For clustering, the proposed M way like tree data structure\nstores the assisted GPS coordinates in degree, minute, and second format. Thus,\nevery user is mapped to a leaf node of the tree. We split the \"seconds\" part of\nthe assisted GPS location into m equal parts, which amount to d meter in\nlatitude(longitude). Hence, two users who are within d meter range will map to\nthe same leaf node. Thus, by mapping assisted GPS locations every t mins, we\ncan find out how many users came in contact with a particular user for at least\nt mins. Our work's salient feature is that it runs in linear time O(n) for n\nusers in the static case, i.e., when users are not moving. We also propose a\nvariant of our solution to handle the dynamic case, that is, when users are\nmoving. Besides, the proposed solution offers potential hotspot detection and\nsafe-route recommendation as an additional feature, and proof of concept is\npresented through experiments on simulated data of 10M users.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 07:03:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Maurya", "Chandresh Kumar", ""], ["Jain", "Seemandhar", ""], ["Thakre", "Vishal", ""]]}, {"id": "2105.15032", "submitter": "Alexander Braun", "authors": "Alexander Braun and Thomas Kesselheim", "title": "Truthful Mechanisms for Two-Sided Markets via Prophet Inequalities", "comments": "An extended abstract will appear at EC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design novel mechanisms for welfare-maximization in two-sided markets.\nThat is, there are buyers willing to purchase items and sellers holding items\ninitially, both acting rationally and strategically in order to maximize\nutility. Our mechanisms are designed based on a powerful correspondence between\ntwo-sided markets and prophet inequalities. They satisfy individual\nrationality, dominant-strategy incentive compatibility, budget-balance\nconstraints and give constant-factor approximations to the optimal social\nwelfare.\n  We improve previous results in several settings: Our main focus is on matroid\ndouble auctions, where the set of buyers who obtain an item needs to be\nindependent in a matroid. We construct two mechanisms, the first being a\n$1/3$-approximation of the optimal social welfare satisfying strong\nbudget-balance and requiring the agents to trade in a customized order, the\nsecond being a $1/2$-approximation, weakly budget-balanced and able to deal\nwith online arrival determined by an adversary. In addition, we construct\nconstant-factor approximations in two-sided markets when buyers need to fulfill\na knapsack constraint. Also, in combinatorial double auctions, where buyers\nhave valuation functions over item bundles instead of being interested in only\none item, using similar techniques, we design a mechanism which is a\n$1/2$-approximation of the optimal social welfare, strongly budget-balanced and\ncan deal with online arrival of agents in an adversarial order.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:12:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Braun", "Alexander", ""], ["Kesselheim", "Thomas", ""]]}, {"id": "2105.15039", "submitter": "Luca Cardelli", "authors": "Luca Cardelli", "title": "Sequenceable Event Recorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With recent high-throughput technology we can synthesize large heterogeneous\ncollections of DNA structures, and also read them all out precisely in a single\nprocedure. Can we use these tools, not only to do things faster, but also to\ndevise new techniques and algorithms? In this paper we examine some DNA\nalgorithms that assume high-throughput synthesis and sequencing. We aim to\nmonitor, record, and read out the order in which a number $N$ of events occur,\nusing $N^2$ redundant detectors, and (after sequencing) reconstructing the\norder by transitive reduction.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:21:46 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 15:16:36 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 08:32:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cardelli", "Luca", ""]]}, {"id": "2105.15081", "submitter": "Alexander Wein", "authors": "Cheng Mao, Alexander S. Wein", "title": "Optimal Spectral Recovery of a Planted Vector in a Subspace", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a planted vector $v$ in an $n$-dimensional random subspace of\n$\\mathbb{R}^N$ is a generic task related to many problems in machine learning\nand statistics, such as dictionary learning, subspace recovery, and principal\ncomponent analysis. In this work, we study computationally efficient estimation\nand detection of a planted vector $v$ whose $\\ell_4$ norm differs from that of\na Gaussian vector with the same $\\ell_2$ norm. For instance, in the special\ncase of an $N \\rho$-sparse vector $v$ with Rademacher nonzero entries, our\nresults include the following:\n  (1) We give an improved analysis of (a slight variant of) the spectral method\nproposed by Hopkins, Schramm, Shi, and Steurer, showing that it approximately\nrecovers $v$ with high probability in the regime $n \\rho \\ll \\sqrt{N}$. In\ncontrast, previous work required either $\\rho \\ll 1/\\sqrt{n}$ or $n \\sqrt{\\rho}\n\\lesssim \\sqrt{N}$ for polynomial-time recovery. Our result subsumes both of\nthese conditions (up to logarithmic factors) and also treats the dense case\n$\\rho = 1$ which was not previously considered.\n  (2) Akin to $\\ell_\\infty$ bounds for eigenvector perturbation, we establish\nan entrywise error bound for the spectral estimator via a leave-one-out\nanalysis, from which it follows that thresholding recovers $v$ exactly.\n  (3) We study the associated detection problem and show that in the regime $n\n\\rho \\gg \\sqrt{N}$, any spectral method from a large class (and more generally,\nany low-degree polynomial of the input) fails to detect the planted vector.\nThis establishes optimality of our upper bounds and offers evidence that no\npolynomial-time algorithm can succeed when $n \\rho \\gg \\sqrt{N}$.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:10:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mao", "Cheng", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2105.15159", "submitter": "Chenhao Wang", "authors": "Zhongzheng Tang, Chenhao Wang, Hau Chan", "title": "On maximizing a monotone $k$-submodular function under a knapsack\n  constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a monotone $k$-submodular function $f$\nunder a knapsack constraint, where a $k$-submodular function is a natural\ngeneralization of a submodular function to $k$ dimensions. We present a\ndeterministic $(\\frac12-\\frac{1}{2e})$-approximation algorithm that evaluates\n$f$ $O(n^5k^4)$ times.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:03:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Tang", "Zhongzheng", ""], ["Wang", "Chenhao", ""], ["Chan", "Hau", ""]]}, {"id": "2105.15187", "submitter": "Anupam Gupta", "authors": "Vincent Cohen-Addad and Anupam Gupta and Philip N. Klein and Jason Li", "title": "A Quasipolynomial $(2+\\varepsilon)$-Approximation for Planar Sparsest\n  Cut", "comments": "To appear at STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The (non-uniform) sparsest cut problem is the following graph-partitioning\nproblem: given a \"supply\" graph, and demands on pairs of vertices, delete some\nsubset of supply edges to minimize the ratio of the supply edges cut to the\ntotal demand of the pairs separated by this deletion. Despite much effort,\nthere are only a handful of nontrivial classes of supply graphs for which\nconstant-factor approximations are known.\n  We consider the problem for planar graphs, and give a\n$(2+\\varepsilon)$-approximation algorithm that runs in quasipolynomial time.\nOur approach defines a new structural decomposition of an optimal solution\nusing a \"patching\" primitive. We combine this decomposition with a\nSherali-Adams-style linear programming relaxation of the problem, which we then\nround. This should be compared with the polynomial-time approximation algorithm\nof Rao (1999), which uses the metric linear programming relaxation and\n$\\ell_1$-embeddings, and achieves an $O(\\sqrt{\\log n})$-approximation in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:51:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Gupta", "Anupam", ""], ["Klein", "Philip N.", ""], ["Li", "Jason", ""]]}]