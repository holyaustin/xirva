[{"id": "1904.00051", "submitter": "Georg Hahn", "authors": "Elijah Pelofske, Georg Hahn, Hristo N. Djidjev", "title": "Solving large Minimum Vertex Cover problems on a quantum annealer", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-19-21008", "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimum vertex cover problem having applications in e.g.\nbiochemistry and network security. Quantum annealers can find the optimum\nsolution of such NP-hard problems, given they can be embedded on the hardware.\nThis is often infeasible due to limitations of the hardware connectivity\nstructure. This paper presents a decomposition algorithm for the minimum vertex\ncover problem: The algorithm recursively divides an arbitrary problem until the\ngenerated subproblems can be embedded and solved on the annealer. To speed up\nthe decomposition, we propose several pruning and reduction techniques. The\nperformance of our algorithm is assessed in a simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 18:58:04 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 14:27:18 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 03:53:10 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Pelofske", "Elijah", ""], ["Hahn", "Georg", ""], ["Djidjev", "Hristo N.", ""]]}, {"id": "1904.00692", "submitter": "N.S Narayanaswamy", "authors": "Girish Raguvir J, Manas Jyoti Kashyop and N. S. Narayanaswamy", "title": "Dynamic Data Structures for Interval Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamic graph coloring problem restricted to the class of\ninterval graphs. At each update step the algorithm is presented with an\ninterval to be colored, or a previously colored interval to delete. The goal of\nthe algorithm is to efficiently maintain a proper coloring of the intervals\nwith as few colors as possible by an online algorithm. In the incremental\nmodel, each update step presents the algorithm with an interval to be colored.\nThe problem is closely connected to the online vertex coloring problem of\ninterval graphs for which the Kierstead-Trotter (KT) algorithm achieves the\nbest possible competitive ratio. We first show that a sub-quadratic time direct\nimplementation of the KT-algorithm is unlikely to exist conditioned on the\ncorrectness of the Online Boolean Matrix Vector multiplication conjecture due\nto Henzinger et al. \\cite{DBLP:conf/stoc/HenzingerKNS15}. We then design an\nincremental algorithm that is subtly different from the KT-algorithm and uses\nat most $3 \\omega - 2$ colors, where $\\omega$ is the maximum clique in the\ninterval graph associated with the set of intervals. Our incremental data\nstructure maintains a proper coloring in amortized $O(\\log n + \\Delta)$ update\ntime where $n$ is the total number of intervals inserted and $\\Delta$ is the\nmaximum degree of a vertex in the interval graph. We then consider the fully\ndynamic framework involving insertions and deletions. On each update, our aim\nis to maintain a $3 \\omega - 2$ coloring of the remaining set of intervals,\nwhere $\\omega$ is the maximum clique in the interval graph associated with the\nremaining set of intervals. Our fully dynamic algorithm supports insertion of\nan interval in $O(\\log n + \\Delta \\log \\omega)$ worst case update time and\ndeletion of an interval in $O(\\Delta^2 \\log n)$ worst case update time.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 10:46:00 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 03:31:22 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["J", "Girish Raguvir", ""], ["Kashyop", "Manas Jyoti", ""], ["Narayanaswamy", "N. S.", ""]]}, {"id": "1904.00943", "submitter": "Weiming Feng", "authors": "Weiming Feng, Thomas P. Hayes, Yitong Yin", "title": "Distributed Metropolis Sampler with Optimal Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Metropolis-Hastings algorithm is a fundamental Markov chain Monte Carlo\n(MCMC) method for sampling and inference. With the advent of Big Data,\ndistributed and parallel variants of MCMC methods are attracting increased\nattention. In this paper, we give a distributed algorithm that can correctly\nsimulate sequential single-site Metropolis chains without any bias in a fully\nasynchronous message-passing model. Furthermore, if a natural Lipschitz\ncondition is satisfied by the Metropolis filters, our algorithm can simulate\n$N$-step Metropolis chains within $O(N/n+\\log n)$ rounds of asynchronous\ncommunications, where $n$ is the number of variables. For sequential\nsingle-site dynamics, whose mixing requires $\\Omega(n\\log n)$ steps, this\nachieves an optimal linear speedup. For several well-studied important\ngraphical models, including proper graph coloring, hardcore model, and Ising\nmodel, our condition for linear speedup is weaker than the respective\nuniqueness (mixing) conditions.\n  The novel idea in our algorithm is to resolve updates in advance: the local\nMetropolis filters can often be executed correctly before the full information\nabout neighboring spins is available. This achieves optimal parallelism without\nintroducing any bias.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:26:44 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 05:16:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Feng", "Weiming", ""], ["Hayes", "Thomas P.", ""], ["Yin", "Yitong", ""]]}, {"id": "1904.01135", "submitter": "Abu Reyan Ahmed", "authors": "Reyan Ahmed, Keaton Hamm, Mohammad Javad Latifi Jebelli, Stephen\n  Kobourov, Faryad Darabi Sahneh, and Richard Spence", "title": "Approximation algorithms and an integer program for multi-level graph\n  spanners", "comments": "This paper has been accepted in the Special Event on Analysis of\n  Experimental Algorithms (SEA^2 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a weighted graph $G(V,E)$ and $t \\ge 1$, a subgraph $H$ is a\n\\emph{$t$--spanner} of $G$ if the lengths of shortest paths in $G$ are\npreserved in $H$ up to a multiplicative factor of $t$. The \\emph{subsetwise\nspanner} problem aims to preserve distances in $G$ for only a subset of the\nvertices. We generalize the minimum-cost subsetwise spanner problem to one\nwhere vertices appear on multiple levels, which we call the \\emph{multi-level\ngraph spanner} (MLGS) problem, and describe two simple heuristics. Applications\nof this problem include road/network building and multi-level graph\nvisualization, especially where vertices may require different grades of\nservice.\n  We formulate a 0--1 integer linear program (ILP) of size $O(|E||V|^2)$ for\nthe more general minimum \\emph{pairwise spanner problem}, which resolves an\nopen question by Sigurd and Zachariasen on whether this problem admits a useful\npolynomial-size ILP. We extend this ILP formulation to the MLGS problem, and\nevaluate the heuristic and ILP performance on random graphs of up to 100\nvertices and 500 edges.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 22:48:08 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Ahmed", "Reyan", ""], ["Hamm", "Keaton", ""], ["Jebelli", "Mohammad Javad Latifi", ""], ["Kobourov", "Stephen", ""], ["Sahneh", "Faryad Darabi", ""], ["Spence", "Richard", ""]]}, {"id": "1904.01210", "submitter": "Takanori Maehara", "authors": "Ikumi Hide, Soh Kumabe, Takanori Maehara", "title": "Incorrect implementations of the Floyd--Warshall algorithm give correct\n  solutions after three repeats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Floyd--Warshall algorithm is a well-known algorithm for the all-pairs\nshortest path problem that is simply implemented by triply nested loops. In\nthis study, we show that the incorrect implementations of the Floyd--Warshall\nalgorithm that misorder the triply nested loops give correct solutions if these\nare repeated three times.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 04:39:28 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Hide", "Ikumi", ""], ["Kumabe", "Soh", ""], ["Maehara", "Takanori", ""]]}, {"id": "1904.01321", "submitter": "Giulia Bernardini", "authors": "Giulia Bernardini and Paola Bonizzoni and Gianluca Della Vedova and\n  Murray Patterson", "title": "A rearrangement distance for fully-labelled trees", "comments": "Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of comparing trees representing the evolutionary histories of\ncancerous tumors has turned out to be crucial, since there is a variety of\ndifferent methods which typically infer multiple possible trees. A departure\nfrom the widely studied setting of classical phylogenetics, where trees are\nleaf-labelled, tumoral trees are fully labelled, i.e., \\emph{every} vertex has\na label.\n  In this paper we provide a rearrangement distance measure between two\nfully-labelled trees. This notion originates from two operations: one which\nmodifies the topology of the tree, the other which permutes the labels of the\nvertices, hence leaving the topology unaffected. While we show that the\ndistance between two trees in terms of each such operation alone can be decided\nin polynomial time, the more general notion of distance when both operations\nare allowed is NP-hard to decide. Despite this result, we show that it is\nfixed-parameter tractable, and we give a 4-approximation algorithm when one of\nthe trees is binary.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 10:30:35 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Bernardini", "Giulia", ""], ["Bonizzoni", "Paola", ""], ["Della Vedova", "Gianluca", ""], ["Patterson", "Murray", ""]]}, {"id": "1904.01361", "submitter": "Martin Kouteck\\'y", "authors": "Friedrich Eisenbrand, Christoph Hunkenschr\\\"oder, Kim-Manuel Klein,\n  Martin Kouteck\\'y, Asaf Levin, Shmuel Onn", "title": "An Algorithmic Theory of Integer Programming", "comments": "Revision 2: - strengthened dual treedepth lower bound - simplified\n  proximity-scaling algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the general integer programming problem where the number of\nvariables $n$ is a variable part of the input. We consider two natural\nparameters of the constraint matrix $A$: its numeric measure $a$ and its\nsparsity measure $d$. We show that integer programming can be solved in time\n$g(a,d)\\textrm{poly}(n,L)$, where $g$ is some computable function of the\nparameters $a$ and $d$, and $L$ is the binary encoding length of the input. In\nparticular, integer programming is fixed-parameter tractable parameterized by\n$a$ and $d$, and is solvable in polynomial time for every fixed $a$ and $d$.\nOur results also extend to nonlinear separable convex objective functions.\nMoreover, for linear objectives, we derive a strongly-polynomial algorithm,\nthat is, with running time $g(a,d)\\textrm{poly}(n)$, independent of the rest of\nthe input data.\n  We obtain these results by developing an algorithmic framework based on the\nidea of iterative augmentation: starting from an initial feasible solution, we\nshow how to quickly find augmenting steps which rapidly converge to an optimum.\nA central notion in this framework is the Graver basis of the matrix $A$, which\nconstitutes a set of fundamental augmenting steps. The iterative augmentation\nidea is then enhanced via the use of other techniques such as new and improved\nbounds on the Graver basis, rapid solution of integer programs with bounded\nvariables, proximity theorems and a new proximity-scaling algorithm, the notion\nof a reduced objective function, and others.\n  As a consequence of our work, we advance the state of the art of solving\nblock-structured integer programs. In particular, we develop near-linear time\nalgorithms for $n$-fold, tree-fold, and $2$-stage stochastic integer programs.\nWe also discuss some of the many applications of these classes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 12:14:02 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 10:28:07 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Eisenbrand", "Friedrich", ""], ["Hunkenschr\u00f6der", "Christoph", ""], ["Klein", "Kim-Manuel", ""], ["Kouteck\u00fd", "Martin", ""], ["Levin", "Asaf", ""], ["Onn", "Shmuel", ""]]}, {"id": "1904.01495", "submitter": "Matthew Fahrbach", "authors": "Matthew Fahrbach, Dana Randall", "title": "Slow Mixing of Glauber Dynamics for the Six-Vertex Model in the Ordered\n  Phases", "comments": "28 pages, 6 figures, Proceedings of the 23rd International Conference\n  on Randomization and Computation (RANDOM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The six-vertex model in statistical physics is a weighted generalization of\nthe ice model on $\\mathbb{Z}^2$ (i.e., Eulerian orientations) and the\nzero-temperature three-state Potts model (i.e., proper three-colorings). The\nphase diagram of the model depicts its physical properties and suggests where\nlocal Markov chains will be efficient. In this paper, we analyze the mixing\ntime of Glauber dynamics for the six-vertex model in the ordered phases.\nSpecifically, we show that for all Boltzmann weights in the ferroelectric\nphase, there exist boundary conditions such that local Markov chains require\nexponential time to converge to equilibrium. This is the first rigorous result\nbounding the mixing time of Glauber dynamics in the ferroelectric phase. Our\nanalysis demonstrates a fundamental connection between correlated random walks\nand the dynamics of intersecting lattice path models (or routings). We analyze\nthe Glauber dynamics for the six-vertex model with free boundary conditions in\nthe antiferroelectric phase and significantly extend the region for which local\nMarkov chains are known to be slow mixing. This result relies on a Peierls\nargument and novel properties of weighted non-backtracking walks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:33:34 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 17:52:13 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Fahrbach", "Matthew", ""], ["Randall", "Dana", ""]]}, {"id": "1904.01543", "submitter": "Christopher Morris", "authors": "Christopher Morris, Gaurav Rattan, Petra Mutzel", "title": "Weisfeiler and Leman go sparse: Towards scalable higher-order graph\n  embeddings", "comments": "Accepted at NeurIPS 2020, extented version with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels based on the $1$-dimensional Weisfeiler-Leman algorithm and\ncorresponding neural architectures recently emerged as powerful tools for\n(supervised) learning with graphs. However, due to the purely local nature of\nthe algorithms, they might miss essential patterns in the given data and can\nonly handle binary relations. The $k$-dimensional Weisfeiler-Leman algorithm\naddresses this by considering $k$-tuples, defined over the set of vertices, and\ndefines a suitable notion of adjacency between these vertex tuples. Hence, it\naccounts for the higher-order interactions between vertices. However, it does\nnot scale and may suffer from overfitting when used in a machine learning\nsetting. Hence, it remains an important open problem to design WL-based graph\nlearning methods that are simultaneously expressive, scalable, and\nnon-overfitting. Here, we propose local variants and corresponding neural\narchitectures, which consider a subset of the original neighborhood, making\nthem more scalable, and less prone to overfitting. The expressive power of (one\nof) our algorithms is strictly higher than the original algorithm, in terms of\nability to distinguish non-isomorphic graphs. Our experimental study confirms\nthat the local algorithms, both kernel and neural architectures, lead to vastly\nreduced computation times, and prevent overfitting. The kernel version\nestablishes a new state-of-the-art for graph classification on a wide range of\nbenchmark datasets, while the neural version shows promising performance on\nlarge-scale molecular regression tasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 16:59:19 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 17:23:50 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 15:54:46 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Morris", "Christopher", ""], ["Rattan", "Gaurav", ""], ["Mutzel", "Petra", ""]]}, {"id": "1904.01570", "submitter": "Frank Gurski", "authors": "Frank Gurski and Dominique Komander and Carolin Rehs", "title": "Oriented coloring on recursively defined digraphs", "comments": "14 pages", "journal-ref": "Algorithms, 12(4), 87, 2019", "doi": "10.3390/a12040087", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coloring is one of the most famous problems in graph theory. The coloring\nproblem on undirected graphs has been well studied, whereas there are very few\nresults for coloring problems on directed graphs. An oriented k-coloring of an\noriented graph G=(V,A) is a partition of the vertex set V into k independent\nsets such that all the arcs linking two of these subsets have the same\ndirection. The oriented chromatic number of an oriented graph G is the smallest\nk such that G allows an oriented k-coloring. Deciding whether an acyclic\ndigraph allows an oriented 4-coloring is NP-hard. It follows, that finding the\nchromatic number of an oriented graph is an NP-hard problem. This motivates to\nconsider the problem on oriented co-graphs. After giving several\ncharacterizations for this graph class, we show a linear time algorithm which\ncomputes an optimal oriented coloring for an oriented co-graph. We further\nprove how the oriented chromatic number can be computed for the disjoint union\nand order composition from the oriented chromatic number of the involved\noriented co-graphs. It turns out that within oriented co-graphs the oriented\nchromatic number is equal to the length of a longest oriented path plus one. We\nalso show that the graph isomorphism problem on oriented co-graphs can be\nsolved in linear time.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 17:58:51 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 07:35:09 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Gurski", "Frank", ""], ["Komander", "Dominique", ""], ["Rehs", "Carolin", ""]]}, {"id": "1904.01793", "submitter": "Michael P. Kim", "authors": "Michael P. Kim and Aleksandra Korolova and Guy N. Rothblum and Gal\n  Yona", "title": "Preference-Informed Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study notions of fairness in decision-making systems when individuals have\ndiverse preferences over the possible outcomes of the decisions. Our starting\npoint is the seminal work of Dwork et al. which introduced a notion of\nindividual fairness (IF): given a task-specific similarity metric, every pair\nof individuals who are similarly qualified according to the metric should\nreceive similar outcomes. We show that when individuals have diverse\npreferences over outcomes, requiring IF may unintentionally lead to\nless-preferred outcomes for the very individuals that IF aims to protect. A\nnatural alternative to IF is the classic notion of fair division, envy-freeness\n(EF): no individual should prefer another individual's outcome over their own.\nAlthough EF allows for solutions where all individuals receive a\nhighly-preferred outcome, EF may also be overly-restrictive. For instance, if\nmany individuals agree on the best outcome, then if any individual receives\nthis outcome, they all must receive it, regardless of each individual's\nunderlying qualifications for the outcome.\n  We introduce and study a new notion of preference-informed individual\nfairness (PIIF) that is a relaxation of both individual fairness and\nenvy-freeness. At a high-level, PIIF requires that outcomes satisfy IF-style\nconstraints, but allows for deviations provided they are in line with\nindividuals' preferences. We show that PIIF can permit outcomes that are more\nfavorable to individuals than any IF solution, while providing considerably\nmore flexibility to the decision-maker than EF. In addition, we show how to\nefficiently optimize any convex objective over the outcomes subject to PIIF for\na rich class of individual preferences. Finally, we demonstrate the broad\napplicability of the PIIF framework by extending our definitions and algorithms\nto the multiple-task targeted advertising setting introduced by Dwork and\nIlvento.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 06:29:30 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 18:07:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kim", "Michael P.", ""], ["Korolova", "Aleksandra", ""], ["Rothblum", "Guy N.", ""], ["Yona", "Gal", ""]]}, {"id": "1904.02013", "submitter": "Valery Shchesnovich", "authors": "Valery Shchesnovich", "title": "On the classical complexity of sampling from quantum interference of\n  indistinguishable bosons", "comments": "15 pages, one figure; Revised Abstract and extended Introduction, new\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental demonstration of the quantum advantage over classical\nsimulations with Boson Sampling is currently under intensive investigation.\nThere seems to be a scalability issue to the necessary number of bosons on the\nlinear optical platforms and the experiments, such as the recent Boson Sampling\nwith $20$ photons on $60$-port interferometer by H.~Wang~\\textit{et al},\n\\textit{Phys. Rev. Lett.} \\textbf{123,} 250503 (2019), are usually carried out\non a small interferometer, much smaller than the size necessary for the\nno-collision regime. Before demonstration of quantum advantage, it is urgent to\nestimate exactly how the classical computations necessary for sampling from the\noutput distribution of Boson Sampling are reduced when a smaller-size\ninterferometer is used. The present work supplies such a result, valid with\narbitrarily close to $1$ probability, which reduces in the no-collision regime\nto the previous estimate by P.~Clifford and R.~Clifford. One of the results\nwith immediate application to current experiments with Boson Sampling is that\nclassically sampling from the interference of $N$ single bosons on an $M$-port\ninterferometer is at least as hard as that with $\\mathcal{N}= \\frac{N}{1+N/M}$\nsingle bosons in the no-collision regime, i.e., on a much larger interferometer\nwith at least $\\mathcal{M}\\gg N^2$ ports.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:00:12 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 15:06:40 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 22:42:16 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 12:53:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Shchesnovich", "Valery", ""]]}, {"id": "1904.02033", "submitter": "Ilya Razenshteyn", "authors": "Hao Chen and Ilaria Chillotti and Yihe Dong and Oxana Poburinnaya and\n  Ilya Razenshteyn and M. Sadegh Riazi", "title": "SANNS: Scaling Up Secure Approximate k-Nearest Neighbors Search", "comments": "18 pages, to appear at USENIX Security Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-Nearest Neighbor Search ($k$-NNS) is the backbone of several\ncloud-based services such as recommender systems, face recognition, and\ndatabase search on text and images. In these services, the client sends the\nquery to the cloud server and receives the response in which case the query and\nresponse are revealed to the service provider. Such data disclosures are\nunacceptable in several scenarios due to the sensitivity of data and/or privacy\nlaws.\n  In this paper, we introduce SANNS, a system for secure $k$-NNS that keeps\nclient's query and the search result confidential. SANNS comprises two\nprotocols: an optimized linear scan and a protocol based on a novel sublinear\ntime clustering-based algorithm. We prove the security of both protocols in the\nstandard semi-honest model. The protocols are built upon several\nstate-of-the-art cryptographic primitives such as lattice-based additively\nhomomorphic encryption, distributed oblivious RAM, and garbled circuits. We\nprovide several contributions to each of these primitives which are applicable\nto other secure computation tasks. Both of our protocols rely on a new circuit\nfor the approximate top-$k$ selection from $n$ numbers that is built from $O(n\n+ k^2)$ comparators.\n  We have implemented our proposed system and performed extensive experimental\nresults on four datasets in two different computation environments,\ndemonstrating more than $18-31\\times$ faster response time compared to\noptimally implemented protocols from the prior work. Moreover, SANNS is the\nfirst work that scales to the database of 10 million entries, pushing the limit\nby more than two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:38:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:53:48 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 15:41:33 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:15:50 GMT"}, {"version": "v5", "created": "Sun, 8 Mar 2020 23:59:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Chen", "Hao", ""], ["Chillotti", "Ilaria", ""], ["Dong", "Yihe", ""], ["Poburinnaya", "Oxana", ""], ["Razenshteyn", "Ilya", ""], ["Riazi", "M. Sadegh", ""]]}, {"id": "1904.02034", "submitter": "Martin Wilhelm", "authors": "Hanna Geppert and Martin Wilhelm", "title": "Internal versus external balancing in the evaluation of graph-based\n  number types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Number types for exact computation are usually based on directed acyclic\ngraphs. A poor graph structure can impair the efficency of their evaluation. In\nsuch cases the performance of a number type can be drastically improved by\nrestructuring the graph or by internally balancing error bounds with respect to\nthe graph's structure. We compare advantages and disadvantages of these two\nconcepts both theoretically and experimentally.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:41:19 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 12:20:38 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 12:49:43 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Geppert", "Hanna", ""], ["Wilhelm", "Martin", ""]]}, {"id": "1904.02077", "submitter": "Pengcheng Lin", "authors": "Peng-Cheng Lin and Wan-Lei Zhao", "title": "Graph based Nearest Neighbor Search: Promises and Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.DS cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph based nearest neighbor search gets more and more popular on\nlarge-scale retrieval tasks. The attractiveness of this type of approaches lies\nin its superior performance over most of the known nearest neighbor search\napproaches as well as its genericness to various metrics. In this paper, the\nrole of two strategies, namely hierarchical structure and graph diversification\nthat are adopted as the key steps in the graph based approaches, is\ninvestigated. We find the hierarchical structure could not achieve \"much better\nlogarithmic complexity scaling\" as it was claimed in the original paper,\nparticularly on high dimensional cases. Moreover, we find that similar high\nsearch speed efficiency as the one with hierarchical structure could be\nachieved with the support of flat k-NN graph after graph diversification.\nFinally, we point out the difficulty, that is faced by most of the graph based\nsearch approaches, is directly linked to \"curse of dimensionality\".\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 16:12:55 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 09:51:07 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 09:01:31 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 14:23:49 GMT"}, {"version": "v5", "created": "Tue, 18 Jun 2019 09:07:06 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Lin", "Peng-Cheng", ""], ["Zhao", "Wan-Lei", ""]]}, {"id": "1904.02119", "submitter": "Karl D\\\"aubel", "authors": "Karl D\\\"aubel", "title": "An Improved Upper Bound for the Ring Loading Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ring Loading Problem emerged in the 1990s to model an important special\ncase of telecommunication networks (SONET rings) which gained attention from\npractitioners and theorists alike. Given an undirected cycle on $n$ nodes\ntogether with non-negative demands between any pair of nodes, the Ring Loading\nProblem asks for an unsplittable routing of the demands such that the maximum\ncumulated demand on any edge is minimized. Let $L$ be the value of such a\nsolution. In the relaxed version of the problem, each demand can be split into\ntwo parts where the first part is routed clockwise while the second part is\nrouted counter-clockwise. Denote with $L^*$ the maximum load of a minimum split\nrouting solution. In a landmark paper, Schrijver, Seymour and Winkler [SSW98]\nshowed that $L \\leq L^* + 1.5D$, where $D$ is the maximum demand value. They\nalso found (implicitly) an instance of the Ring Loading Problem with $L = L^* +\n1.01D$. Recently, Skutella [Sku16] improved these bounds by showing that $L\n\\leq L^* + \\frac{19}{14}D$, and there exists an instance with $L = L^* + 1.1D$.\nWe contribute to this line of research by showing that $L \\leq L^* + 1.3D$. We\nalso take a first step towards lower and upper bounds for small instances.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 17:25:56 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 11:30:30 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["D\u00e4ubel", "Karl", ""]]}, {"id": "1904.02231", "submitter": "Maria Chiara Angelini", "authors": "Maria Chiara Angelini and Federico Ricci-Tersenghi", "title": "Monte Carlo algorithms are very effective in finding the largest\n  independent set in sparse random graphs", "comments": "14 pages, 12 figures", "journal-ref": "Phys. Rev. E 100, 013302 (2019)", "doi": "10.1103/PhysRevE.100.013302", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of stochastic algorithms based on Monte Carlo dynamics in\nsolving hard optimization problems is mostly unknown. Beyond the basic\nstatement that at a dynamical phase transition the ergodicity breaks and a\nMonte Carlo dynamics cannot sample correctly the probability distribution in\ntimes linear in the system size, there are almost no predictions nor intuitions\non the behavior of this class of stochastic dynamics. The situation is\nparticularly intricate because, when using a Monte Carlo based algorithm as an\noptimization algorithm, one is usually interested in the out of equilibrium\nbehavior which is very hard to analyse. Here we focus on the use of Parallel\nTempering in the search for the largest independent set in a sparse random\ngraph, showing that it can find solutions well beyond the dynamical threshold.\nComparison with state-of-the-art message passing algorithms reveals that\nparallel tempering is definitely the algorithm performing best, although a\ntheory explaining its behavior is still lacking.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 20:28:21 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Angelini", "Maria Chiara", ""], ["Ricci-Tersenghi", "Federico", ""]]}, {"id": "1904.02276", "submitter": "Tongyang Li", "authors": "Tongyang Li, Shouvanik Chakrabarti, Xiaodi Wu", "title": "Sublinear quantum algorithms for training linear and kernel-based\n  classifiers", "comments": "31 pages, 1 figure", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), PMLR 97:3815-3824, 2019", "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate quantum algorithms for classification, a fundamental problem\nin machine learning, with provable guarantees. Given $n$ $d$-dimensional data\npoints, the state-of-the-art (and optimal) classical algorithm for training\nclassifiers with constant margin runs in $\\tilde{O}(n+d)$ time. We design\nsublinear quantum algorithms for the same task running in $\\tilde{O}(\\sqrt{n}\n+\\sqrt{d})$ time, a quadratic improvement in both $n$ and $d$. Moreover, our\nalgorithms use the standard quantization of the classical input and generate\nthe same classical output, suggesting minimal overheads when used as\nsubroutines for end-to-end applications. We also demonstrate a tight lower\nbound (up to poly-log factors) and discuss the possibility of implementation on\nnear-term quantum machines. As a side result, we also give sublinear quantum\nalgorithms for approximating the equilibria of $n$-dimensional matrix zero-sum\ngames with optimal complexity $\\tilde{\\Theta}(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 00:00:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Tongyang", ""], ["Chakrabarti", "Shouvanik", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1904.02348", "submitter": "Yanchao Wang", "authors": "Yan-Chao Wang and Feng Lin and Hock-Soon Seah", "title": "Orthogonal Voronoi Diagram and Treemap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GR cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel space partitioning strategy for implicit\nhierarchy visualization such that the new plot not only has a tidy layout\nsimilar to the treemap, but also is flexible to data changes similar to the\nVoronoi treemap. To achieve this, we define a new distance function and\nneighborhood relationship between sites so that space will be divided by\naxis-aligned segments. Then a sweepline+skyline based heuristic algorithm is\nproposed to allocate the partitioned spaces to form an orthogonal Voronoi\ndiagram with orthogonal rectangles. To the best of our knowledge, it is the\nfirst time to use a sweepline-based strategy for the Voronoi treemap. Moreover,\nwe design a novel strategy to initialize the diagram status and modify the\nstatus update procedure so that the generation of our plot is more effective\nand efficient. We show that the proposed algorithm has an O(nlog(n)) complexity\nwhich is the same as the state-of-the-art Voronoi treemap. To this end, we show\nvia experiments on the artificial dataset and real-world dataset the\nperformance of our algorithm in terms of computation time, converge rate, and\naspect ratio. Finally, we discuss the pros and cons of our method and make a\nconclusion.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 05:05:49 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Yan-Chao", ""], ["Lin", "Feng", ""], ["Seah", "Hock-Soon", ""]]}, {"id": "1904.02425", "submitter": "Khaled Elbassioni", "authors": "Khaled Elbassioni", "title": "Quasi-polynomial Algorithms for List-coloring of Nearly Intersecting\n  Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hypergraph $\\mathcal{H}$ on $n$ vertices and $m$ edges is said to be {\\it\nnearly-intersecting} if every edge of $\\mathcal{H}$ intersects all but at most\npolylogarthmically many (in $m$ and $n$) other edges. Given lists of colors\n$\\mathcal{L}(v)$, for each vertex $v\\in V$, $\\mathcal{H}$ is said to be\n$\\mathcal{L}$-(list) colorable, if each vertex can be assigned a color from its\nlist such that no edge in $\\mathcal{H}$ is monochromatic. We show that\nlist-colorability for any nearly intersecting hypergraph, and lists drawn from\na set of constant size, can be checked in quasi-polynomial time in $m$ and $n$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:28:17 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Elbassioni", "Khaled", ""]]}, {"id": "1904.02763", "submitter": "Brad Shutters", "authors": "Brad Shutters, Timothy P. Hartke Jr. and Robert J. Sammelson", "title": "Compact Error-Resilient Self-Assembly of Recursively Defined Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A limitation to molecular implementations of tile-based self-assembly systems\nis the high rate of mismatch errors which has been observed to be between 1%\nand 10%. Controlling the physical conditions of the system to reduce this\nintrinsic error rate $\\epsilon$ prohibitively slows the growth rate of the\nsystem. This has motivated the development of techniques to redundantly encode\ninformation in the tiles of a system in such a way that the rate of mismatch\nerrors in the final assembly is reduced even without a reduction in $\\epsilon$.\nWinfree and Bekbolatov, and Chen and Goel, introduced such error-resilient\nsystems that reduce the mismatch error rate to $\\epsilon^k$ by replacing each\ntile in an error-prone system with a $k \\times k$ block of tiles in the\nerror-resilient system, but this increases the number of tile types used by a\nfactor of $k^2$, and the scale of the pattern produced by a factor of $k$.\nReif, Sahu and Yin, and Sahu and Reif, introduced compact error-resilient\nsystems for the self-assembly of Boolean arrays that reduce the mismatch error\nrate to $\\epsilon^2$ without increasing the scale of the pattern produced. In\nthis paper, we give a technique to design compact error-resilient systems for\nthe self-assembly of the recursively defined patterns introduced by Kautz and\nLathrop. We show that our compact error-resilient systems reduce the mismatch\nerror rate to $\\epsilon^2$ by using the independent error model introduced by\nSahu and Reif. Surprisingly, our error-resilient systems use the same number of\ntile types as the error-prone system from which they are constructed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 19:35:17 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 14:19:27 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Shutters", "Brad", ""], ["Hartke", "Timothy P.", "Jr."], ["Sammelson", "Robert J.", ""]]}, {"id": "1904.02809", "submitter": "Xuanrui Qi", "authors": "Reynald Affeldt, Jacques Garrigue, Xuanrui Qi, Kazunari Tanaka", "title": "Proving tree algorithms for succinct data structures", "comments": "Accepted to the 10th International Conference on Interactive Theorem\n  Proving (ITP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Succinct data structures give space-efficient representations of large\namounts of data without sacrificing performance. They rely one cleverly\ndesigned data representations and algorithms. We present here the formalization\nin Coq/SSReflect of two different tree-based succinct representations and their\naccompanying algorithms. One is the Level-Order Unary Degree Sequence, which\nencodes the structure of a tree in breadth-first order as a sequence of bits,\nwhere access operations can be defined in terms of Rank and Select, which work\nin constant time for static bit sequences. The other represents dynamic bit\nsequences as binary balanced trees, where Rank and Select present a low\nlogarithmic overhead compared to their static versions, and with efficient\ninsertion and deletion. The two can be stacked to provide a dynamic\nrepresentation of dictionaries for instance. While both representations are\nwell-known, we believe this to be their first formalization and a needed step\ntowards provably-safe implementations of big data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 22:20:12 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 09:49:48 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Affeldt", "Reynald", ""], ["Garrigue", "Jacques", ""], ["Qi", "Xuanrui", ""], ["Tanaka", "Kazunari", ""]]}, {"id": "1904.02824", "submitter": "Nil Mamano", "authors": "Juan Jose Besa, Timothy Johnson, Nil Mamano, Martha C. Osegueda", "title": "Taming the Knight's Tour: Minimizing Turns and Crossings", "comments": "27 pages, 21 figures. FUN 2020 (FUN with Algorithms)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two new metrics of simplicity for knight's tours: the number of\nturns and the number of crossings. We give a novel algorithm that produces\ntours with $9.5n+O(1)$ turns and $13n+O(1)$ crossings on a $n\\times n$ board.\nWe show lower bounds of $(6-\\varepsilon)n$, for any $\\varepsilon>0$, and\n$4n-O(1)$ on the respective problems of minimizing these metrics. Hence, we\nachieve approximation ratios of $19/12+o(1)$ and $13/4+o(1)$. We generalize our\ntechniques to rectangular boards, high-dimensional boards, symmetric tours, odd\nboards with a missing corner, and tours for $(1,4)$-leapers. In doing so, we\nshow that these extensions also admit a constant approximation ratio on the\nminimum number of turns, and on the number of crossings in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 23:31:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Besa", "Juan Jose", ""], ["Johnson", "Timothy", ""], ["Mamano", "Nil", ""], ["Osegueda", "Martha C.", ""]]}, {"id": "1904.02861", "submitter": "William Kuszmaul", "authors": "Michael A. Bender, Martin Farach-Colton, William Kuszmaul", "title": "Achieving Optimal Backlog in Multi-Processor Cup Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The single- and multi- processor cup games can be used to model natural\nproblems in areas such as processor scheduling, deamortization, and buffer\nmanagement. At the beginning of the single-processor cup game, $n$ cups are\ninitially empty. In each step of the game, a filler distributes $1$ unit of\nwater among the cups, and then an emptier selects a cup and removes $1 +\n\\epsilon$ units from that cup. The goal of the emptier is to minimize the\namount of water in the fullest cup, also known as the backlog. It is known that\nthe greedy algorithm (i.e., empty the fullest cup) achieves backlog $O(\\log\nn)$, and that no deterministic algorithm can do better. We show that the\nperformance of the greedy algorithm can be greatly improved with a small amount\nof randomization: After any step $i$, and for any $k \\ge \\Omega(\\log\n\\epsilon^{-1})$, the emptier achieves backlog at most $O(k)$ with probability\nat least $1 -O(2^{-2^k})$. Whereas bounds for the single-processor cup game\nhave been known for more than fifteen years, proving nontrivial bounds on\nbacklog for the multi-processor extension has remained open. We present a\nsimple analysis of the greedy algorithm for the multi-processor cup game,\nestablishing a backlog of $O(\\epsilon^{-1} \\log n)$, as long as $\\delta$, the\ngame's other speed-augmentation constant, is at least $1/poly(n)$. Turning to\nrandomized algorithms, we encounter an unexpected phenomenon: When the number\nof processors $p$ is large, the backlog after each step drops to\n\\emph{constant} with large probability. Specifically, we show that if $\\delta$\nand $\\epsilon$ satisfy reasonable constraints, then there exists an algorithm\nthat bounds the backlog after a given step by three or less with probability at\nleast $1 - O(\\exp(-\\Omega(\\epsilon^2 p))$. We further extend the guarantees of\nour randomized algorithm to consider larger backlogs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 03:40:58 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Bender", "Michael A.", ""], ["Farach-Colton", "Martin", ""], ["Kuszmaul", "William", ""]]}, {"id": "1904.02944", "submitter": "Meirav Zehavi", "authors": "Fedor V. Fomin, Daniel Lokshtanov, Fahad Panolan, Saket Saurabh,\n  Meirav Zehavi", "title": "Hitting Topological Minors is FPT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Topological Minor Deletion (TM-Deletion) problem input consists of an\nundirected graph $G$, a family of undirected graphs ${\\cal F}$ and an integer\n$k$. The task is to determine whether $G$ contains a set of vertices $S$ of\nsize at most $k$, such that the graph $G\\setminus S$ obtained from $G$ by\nremoving the vertices of $S$, contains no graph from ${\\cal F}$ as a\ntopological minor. We give an algorithm for TM-Deletionwith running time\n$f(h^\\star,k)\\cdot |V(G)|^{4}$. Here $h^\\star$ is the maximum size of a graph\nin ${\\cal F}$ and $f$ is a computable function of $h^\\star$ and $k$. This is\nthe first fixed parameter tractable algorithm (FPT) for the problem. In fact,\neven for the restricted case of planar inputs the first FPT algorithm was found\nonly recently by Golovach et al. [SODA 2020]. For this case we improve upon the\nalgorithm of Golovach et al. [SODA 2020] by designing an FPT algorithm with\nexplicit dependence on $k$ and $h^\\star$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 09:06:56 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:47:29 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1904.03117", "submitter": "Hans Bodlaender", "authors": "Hans L. Bodlaender, Benjamin Burton, Fedor V. Fomin, Alexander\n  Grigoriev", "title": "Knot Diagrams of Treewidth Two", "comments": "19 pages, 16 figures. The first version had erroneously three\n  subsections repeated; the updated version avoids this mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study knot diagrams for which the underlying graph has\ntreewidth two. We give a linear time algorithm for the following problem: given\na knot diagram of treewidth two, does it represent the unknot? We also show\nthat for a link diagram of treewidth two we can test in linear time if it\nrepresents the unlink. From the algorithm, it follows that a diagram of the\nunknot of treewidth 2 can always be reduced to the trivial diagram with at most\n$n$ (un)twist and (un)poke Reidemeister moves.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 15:20:32 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 11:34:12 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Burton", "Benjamin", ""], ["Fomin", "Fedor V.", ""], ["Grigoriev", "Alexander", ""]]}, {"id": "1904.03213", "submitter": "Lap Chi Lau", "authors": "Tsz Chiu Kwok, Lap Chi Lau, Akshay Ramachandran", "title": "Spectral analysis of matrix scaling and operator scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA math.OC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a spectral analysis for matrix scaling and operator scaling. We\nprove that if the input matrix or operator has a spectral gap, then a natural\ngradient flow has linear convergence. This implies that a simple gradient\ndescent algorithm also has linear convergence under the same assumption. The\nspectral gap condition for operator scaling is closely related to the notion of\nquantum expander studied in quantum information theory.\n  The spectral analysis also provides bounds on some important quantities of\nthe scaling problems, such as the condition number of the scaling solution and\nthe capacity of the matrix and operator. These bounds can be used in various\napplications of scaling problems, including matrix scaling on expander graphs,\npermanent lower bounds on random matrices, the Paulsen problem on random\nframes, and Brascamp-Lieb constants on random operators. In some applications,\nthe inputs of interest satisfy the spectral condition and we prove\nsignificantly stronger bounds than the worst case bounds.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 18:12:15 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Kwok", "Tsz Chiu", ""], ["Lau", "Lap Chi", ""], ["Ramachandran", "Akshay", ""]]}, {"id": "1904.03219", "submitter": "Lap Chi Lau", "authors": "Pak Hay Chan, Lap Chi Lau, Aaron Schild, Sam Chiu-wai Wong, Hong Zhou", "title": "Network design for s-t effective resistance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new problem of designing a network with small $s$-$t$ effective\nresistance. In this problem, we are given an undirected graph $G=(V,E)$, two\ndesignated vertices $s,t \\in V$, and a budget $k$. The goal is to choose a\nsubgraph of $G$ with at most $k$ edges to minimize the $s$-$t$ effective\nresistance. This problem is an interpolation between the shortest path problem\nand the minimum cost flow problem and has applications in electrical network\ndesign.\n  We present several algorithmic and hardness results for this problem and its\nvariants. On the hardness side, we show that the problem is NP-hard, and the\nweighted version is hard to approximate within a factor smaller than two\nassuming the small-set expansion conjecture. On the algorithmic side, we\nanalyze a convex programming relaxation of the problem and design a constant\nfactor approximation algorithm. The key of the rounding algorithm is a\nrandomized path-rounding procedure based on the optimality conditions and a\nflow decomposition of the fractional solution. We also use dynamic programming\nto obtain a fully polynomial time approximation scheme when the input graph is\na series-parallel graph, with better approximation ratio than the integrality\ngap of the convex program for these graphs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 18:24:08 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Chan", "Pak Hay", ""], ["Lau", "Lap Chi", ""], ["Schild", "Aaron", ""], ["Wong", "Sam Chiu-wai", ""], ["Zhou", "Hong", ""]]}, {"id": "1904.03248", "submitter": "Nithin Varma", "authors": "Nithin Varma and Yuichi Yoshida", "title": "Average Sensitivity of Graph Algorithms", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern applications of graphs algorithms, where the graphs of interest are\nlarge and dynamic, it is unrealistic to assume that an input representation\ncontains the full information of a graph being studied. Hence, it is desirable\nto use algorithms that, even when only a (large) subgraph is available, output\nsolutions that are close to the solutions output when the whole graph is\navailable. We formalize this idea by introducing the notion of average\nsensitivity of graph algorithms, which is the average earth mover's distance\nbetween the output distributions of an algorithm on a graph and its subgraph\nobtained by removing an edge, where the average is over the edges removed and\nthe distance between two outputs is the Hamming distance.\n  In this work, we initiate a systematic study of average sensitivity. After\nderiving basic properties of average sensitivity such as composition, we\nprovide efficient approximation algorithms with low average sensitivities for\nconcrete graph problems, including the minimum spanning forest problem, the\nglobal minimum cut problem, the minimum $s$-$t$ cut problem, and the maximum\nmatching problem. In addition, we prove that the average sensitivity of our\nglobal minimum cut algorithm is almost optimal, by showing a nearly matching\nlower bound. We also show that every algorithm for the 2-coloring problem has\naverage sensitivity linear in the number of vertices. One of the main ideas\ninvolved in designing our algorithms with low average sensitivity is the\nfollowing fact; if the presence of a vertex or an edge in the solution output\nby an algorithm can be decided locally, then the algorithm has a low average\nsensitivity, allowing us to reuse the analyses of known sublinear-time\nalgorithms and local computation algorithms (LCAs). Using this connection, we\nshow that every LCA for 2-coloring has linear query complexity, thereby\nanswering an open question.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 19:29:11 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 09:18:31 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 22:12:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Varma", "Nithin", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1904.03313", "submitter": "Ahmed El Alaoui", "authors": "Ahmed El Alaoui, Andrea Montanari", "title": "On the computational tractability of statistical estimation on amenable\n  graphs", "comments": "Stronger results, improved presentation. The transitivity assumption\n  on the limiting graph is removed. Instead, we introduce and use the notion of\n  a `tame' random rooted graph. 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a vector of discrete variables\n$(\\theta_1,\\cdots,\\theta_n)$, based on noisy observations $Y_{uv}$ of the pairs\n$(\\theta_u,\\theta_v)$ on the edges of a graph $G=([n],E)$. This setting\ncomprises a broad family of statistical estimation problems, including group\nsynchronization on graphs, community detection, and low-rank matrix estimation.\n  A large body of theoretical work has established sharp thresholds for weak\nand exact recovery, and sharp characterizations of the optimal reconstruction\naccuracy in such models, focusing however on the special case of\nErd\\\"os--R\\'enyi-type random graphs. The single most important finding of this\nline of work is the ubiquity of an information-computation gap. Namely, for\nmany models of interest, a large gap is found between the optimal accuracy\nachievable by any statistical method, and the optimal accuracy achieved by\nknown polynomial-time algorithms. Moreover, this gap is generally believed to\nbe robust to small amounts of additional side information revealed about the\n$\\theta_i$'s.\n  How does the structure of the graph $G$ affect this picture? Is the\ninformation-computation gap a general phenomenon or does it only apply to\nspecific families of graphs?\n  We prove that the picture is dramatically different for graph sequences\nconverging to amenable graphs (including, for instance, $d$-dimensional grids).\nWe consider a model in which an arbitrarily small fraction of the vertex labels\nis revealed, and show that a linear-time local algorithm can achieve\nreconstruction accuracy that is arbitrarily close to the information-theoretic\noptimum. We contrast this to the case of random graphs. Indeed, focusing on\ngroup synchronization on random regular graphs, we prove that the\ninformation-computation gap still persists even when a small amount of side\ninformation is revealed.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 22:48:23 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 20:40:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Alaoui", "Ahmed El", ""], ["Montanari", "Andrea", ""]]}, {"id": "1904.03467", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Density-friendly Graph Decomposition", "comments": "Journal version of the conference version", "journal-ref": null, "doi": "10.1145/3344210", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposing a graph into a hierarchical structure via $k$-core analysis is a\nstandard operation in any modern graph-mining toolkit. $k$-core decomposition\nis a simple and efficient method that allows to analyze a graph beyond its mere\ndegree distribution. More specifically, it is used to identify areas in the\ngraph of increasing centrality and connectedness, and it allows to reveal the\nstructural organization of the graph.\n  Despite the fact that $k$-core analysis relies on vertex degrees, $k$-cores\ndo not satisfy a certain, rather natural, density property. Simply put, the\nmost central $k$-core is not necessarily the densest subgraph. This\ninconsistency between $k$-cores and graph density provides the basis of our\nstudy.\n  We start by defining what it means for a subgraph to be locally-dense, and we\nshow that our definition entails a nested chain decomposition of the graph,\nsimilar to the one given by $k$-cores, but in this case the components are\narranged in order of increasing density. We show that such a locally-dense\ndecomposition for a graph $G=(V,E)$ can be computed in polynomial time. The\nrunning time of the exact decomposition algorithm is $O(|V|^2|E|)$ but is\nsignificantly faster in practice. In addition, we develop a linear-time\nalgorithm that provides a factor-2 approximation to the optimal locally-dense\ndecomposition. Furthermore, we show that the $k$-core decomposition is also a\nfactor-2 approximation, however, as demonstrated by our experimental\nevaluation, in practice $k$-cores have different structure than locally-dense\nsubgraphs, and as predicted by the theory, $k$-cores are not always\nwell-aligned with graph density.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 15:13:20 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:01:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1904.03581", "submitter": "Masayuki Miyamoto", "authors": "Masayuki Miyamoto, Masakazu Iwamura, Koichi Kise, and Fran\\c{c}ois Le\n  Gall", "title": "Quantum Speedup for the Minimum Steiner Tree Problem", "comments": "To appear in COCOON 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent breakthrough by Ambainis, Balodis, Iraids, Kokainis, Pr\\=usis and\nVihrovs (SODA'19) showed how to construct faster quantum algorithms for the\nTraveling Salesman Problem and a few other NP-hard problems by combining in a\nnovel way quantum search with classical dynamic programming. In this paper, we\nshow how to apply this approach to the minimum Steiner tree problem, a\nwell-known NP-hard problem, and construct the first quantum algorithm that\nsolves this problem faster than the best known classical algorithms. More\nprecisely, the complexity of our quantum algorithm is\n$\\mathcal{O}(1.812^k\\poly(n))$, where $n$ denotes the number of vertices in the\ngraph and $k$ denotes the number of terminals. In comparison, the best known\nclassical algorithm has complexity $\\mathcal{O}(2^k\\poly(n))$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 04:29:10 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 12:56:56 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 03:22:00 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Miyamoto", "Masayuki", ""], ["Iwamura", "Masakazu", ""], ["Kise", "Koichi", ""], ["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1904.03587", "submitter": "Yongli Zhu", "authors": "Yongli Zhu, Lingpeng Shi, Renchang Dai, Guangyi Liu", "title": "Fast Grid Splitting Detection for N-1 Contingency Analysis by Graph\n  Computing", "comments": "This paper has been accepted by the IEEE ISGT-ASIA 2019 conference,\n  Chengdu, China, May.21-24, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a graph-computing based grid splitting detection algorithm is\nproposed for contingency analysis in a graph-based EMS (Energy Management\nSystem). The graph model of a power system is established by storing its\nbus-branch information into the corresponding vertex objects and edge objects\nof the graph database. Numerical comparison to an up-to-date serial computing\nalgorithm is also investigated. Online tests on a real power system of China\nState Grid with 2752 buses and 3290 branches show that a 6 times speedup can be\nachieved, which lays a good foundation for advanced contingency analysis.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 05:37:03 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhu", "Yongli", ""], ["Shi", "Lingpeng", ""], ["Dai", "Renchang", ""], ["Liu", "Guangyi", ""]]}, {"id": "1904.03602", "submitter": "Amit Daniely", "authors": "Amit Daniely and Yishay Mansour", "title": "Competitive ratio versus regret minimization: achieving the best of both\n  worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online algorithms under both the competitive ratio criteria and\nthe regret minimization one. Our main goal is to build a unified methodology\nthat would be able to guarantee both criteria simultaneously.\n  For a general class of online algorithms, namely any Metrical Task System\n(MTS), we show that one can simultaneously guarantee the best known competitive\nratio and a natural regret bound. For the paging problem we further show an\nefficient online algorithm (polynomial in the number of pages) with this\nguarantee.\n  To this end, we extend an existing regret minimization algorithm\n(specifically, Kapralov and Panigrahy) to handle movement cost (the cost of\nswitching between states of the online system). We then show how to use the\nextended regret minimization algorithm to combine multiple online algorithms.\nOur end result is an online algorithm that can combine a \"base\" online\nalgorithm, having a guaranteed competitive ratio, with a range of online\nalgorithms that guarantee a small regret over any interval of time. The\ncombined algorithm guarantees both that the competitive ratio matches that of\nthe base algorithm and a low regret over any time interval.\n  As a by product, we obtain an expert algorithm with close to optimal regret\nbound on every time interval, even in the presence of switching costs. This\nresult is of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 08:09:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Daniely", "Amit", ""], ["Mansour", "Yishay", ""]]}, {"id": "1904.03723", "submitter": "Luke Postle", "authors": "Luke Postle", "title": "Linear-Time and Efficient Distributed Algorithms for List Coloring\n  Graphs on Surfaces", "comments": "20 pages, revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1994, Thomassen proved that every planar graph is 5-list-colorable. In\n1995, Thomassen proved that every planar graph of girth at least five is\n3-list-colorable. His proofs naturally lead to quadratic-time algorithms to\nfind such colorings. Here, we provide the first such linear-time algorithms to\nfind such colorings.\n  For a fixed surface S, Thomassen showed in 1997 that there exists a\nlinear-time algorithm to decide if a graph embedded in S is 5-colorable and\nsimilarly in 2003 if a graph of girth at least five embedded in S is\n3-colorable. Using the theory of hyperbolic families, the author and Thomas\nshowed such algorithms exist for list-colorings. Dvorak and Kawarabayashi\nactually gave an $O(n^{O(g+1)})$-time algorithm to find such colorings (if they\nexist) in n-vertex graphs where g is the Euler genus of the surface. Here we\nprovide the first such algorithm whose exponent does not depend on the genus;\nindeed, we provide a linear-time algorithm.\n  In 1988, Goldberg, Plotkin and Shannon provided a deterministic distributed\nalgorithm for 7-coloring n-vertex planar graphs in $O(\\log n)$ rounds. In 2018,\nAboulker, Bonamy, Bousquet, and Esperet provided a deterministic distributed\nalgorithm for 6-coloring n-vertex planar graphs in $O(\\log^3 n)$ rounds. Their\nalgorithm in fact works for 6-list-coloring. They also provided an $O(\\log^3\nn)$-round algorithm for 4-list-coloring triangle-free planar graphs. Chechik\nand Mukhtar independently obtained such algorithms for ordinary coloring in\n$O(\\log n)$ rounds, which is best possible in terms of running time. Here we\nprovide the first polylogarithmic deterministic distributed algorithms for\n5-coloring n-vertex planar graphs and similarly for 3-coloring planar graphs of\ngirth at least five. Indeed, these algorithms run in $O(\\log n)$ rounds, work\nalso for list-colorings, and even work on a fixed surface (assuming such a\ncoloring exists).\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 19:55:42 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 18:02:54 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Postle", "Luke", ""]]}, {"id": "1904.03741", "submitter": "Virginia Vassilevska Williams", "authors": "Mina Dalirrooyfard, Thuy Duong Vuong, Virginia Vassilevska Williams", "title": "Graph pattern detection: Hardness for all induced patterns and faster\n  non-induced cycles", "comments": "conference version to appear at STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the pattern detection problem in graphs: given a constant size\npattern graph $H$ and a host graph $G$, determine whether $G$ contains a\nsubgraph isomorphic to $H$. Our main results are:\n  * We prove that if a pattern $H$ contains a $k$-clique subgraph, then\ndetecting whether an $n$ node host graph contains a not necessarily induced\ncopy of $H$ requires at least the time for detecting whether an $n$ node graph\ncontains a $k$-clique. The previous result of this nature required that $H$\ncontains a $k$-clique which is disjoint from all other $k$-cliques of $H$.\n  * We show that if the famous Hadwiger conjecture from graph theory is true,\nthen detecting whether an $n$ node host graph contains a not necessarily\ninduced copy of a pattern with chromatic number $t$ requires at least the time\nfor detecting whether an $n$ node graph contains a $t$-clique. This implies\nthat: (1) under Hadwiger's conjecture for every $k$-node pattern $H$, finding\nan induced copy of $H$ requires at least the time of $\\sqrt k$-clique\ndetection, and at least size $\\omega(n^{\\sqrt{k}/4})$ for any constant depth\ncircuit, and (2) unconditionally, detecting an induced copy of a random\n$G(k,p)$ pattern w.h.p. requires at least the time of $\\Theta(k/\\log k)$-clique\ndetection, and hence also at least size $n^{\\Omega(k/\\log k)}$ for circuits of\nconstant depth.\n  * Finally, we consider the case when the pattern is a directed cycle on $k$\nnodes, and we would like to detect whether a directed $m$-edge graph $G$\ncontains a $k$-Cycle as a not necessarily induced subgraph. We resolve a 14\nyear old conjecture of [Yuster-Zwick SODA'04] on the complexity of $k$-Cycle\ndetection by giving a tight analysis of their $k$-Cycle algorithm. Our analysis\nimproves the best bounds for $k$-Cycle detection in directed graphs, for all\n$k>5$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 21:01:05 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Vuong", "Thuy Duong", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1904.03836", "submitter": "Guanyang Wang", "authors": "Guanyang Wang", "title": "A Fast MCMC for the Uniform Sampling of Binary Matrices with Fixed\n  Margins", "comments": null, "journal-ref": "Electronic Journal of Statistics 2020", "doi": "10.1214/20-EJS1702", "report-no": null, "categories": "stat.CO cs.DS math.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform sampling of binary matrix with fixed margins is an important and\ndifficult problem in statistics, computer science, ecology and so on. The\nwell-known swap algorithm would be inefficient when the size of the matrix\nbecomes large or when the matrix is too sparse/dense.\n  Here we propose the Rectangle Loop algorithm, a Markov chain Monte Carlo\nalgorithm to sample binary matrices with fixed margins uniformly. Theoretically\nthe Rectangle Loop algorithm is better than the swap algorithm in Peskun's\norder. Empirically studies also demonstrates the Rectangle Loop algorithm is\nremarkablely more efficient than the swap algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 04:41:15 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 02:22:32 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wang", "Guanyang", ""]]}, {"id": "1904.03858", "submitter": "Alexander Wein", "authors": "Alexander S. Wein, Ahmed El Alaoui, Cristopher Moore", "title": "The Kikuchi Hierarchy and Tensor PCA", "comments": "42 pages. This version adds results on odd-order tensor PCA and\n  even-arity XOR refutation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cond-mat.stat-mech cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the tensor PCA (principal component analysis) problem, we propose a new\nhierarchy of increasingly powerful algorithms with increasing runtime. Our\nhierarchy is analogous to the sum-of-squares (SOS) hierarchy but is instead\ninspired by statistical physics and related algorithms such as belief\npropagation and AMP (approximate message passing). Our level-$\\ell$ algorithm\ncan be thought of as a linearized message-passing algorithm that keeps track of\n$\\ell$-wise dependencies among the hidden variables. Specifically, our\nalgorithms are spectral methods based on the Kikuchi Hessian, which generalizes\nthe well-studied Bethe Hessian to the higher-order Kikuchi free energies.\n  It is known that AMP, the flagship algorithm of statistical physics, has\nsubstantially worse performance than SOS for tensor PCA. In this work we\n'redeem' the statistical physics approach by showing that our hierarchy gives a\npolynomial-time algorithm matching the performance of SOS. Our hierarchy also\nyields a continuum of subexponential-time algorithms, and we prove that these\nachieve the same (conjecturally optimal) tradeoff between runtime and\nstatistical power as SOS. Our proofs are much simpler than prior work, and also\napply to the related problem of refuting random $k$-XOR formulas. The results\nwe present here apply to tensor PCA for tensors of all orders, and to $k$-XOR\nwhen $k$ is even.\n  Our methods suggest a new avenue for systematically obtaining optimal\nalgorithms for Bayesian inference problems, and our results constitute a step\ntoward unifying the statistical physics and sum-of-squares approaches to\nalgorithm design.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 06:26:35 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:35:50 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Wein", "Alexander S.", ""], ["Alaoui", "Ahmed El", ""], ["Moore", "Cristopher", ""]]}, {"id": "1904.03874", "submitter": "Yuval Rabani", "authors": "S\\'ebastien Bubeck, Yuval Rabani", "title": "Parametrized Metrical Task Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider parametrized versions of metrical task systems and metrical\nservice systems, two fundamental models of online computing, where the\nconstrained parameter is the number of possible distinct requests $m$. Such\nparametrization occurs naturally in a wide range of applications. Striking\nexamples are certain power management problems, which are modeled as metrical\ntask systems with $m=2$. We characterize the competitive ratio in terms of the\nparameter $m$ for both deterministic and randomized algorithms on\nhierarchically separated trees. Our findings uncover a rich and unexpected\npicture that differs substantially from what is known or conjectured about the\nunparametrized versions of these problems. For metrical task systems, we show\nthat deterministic algorithms do not exhibit any asymptotic gain beyond\none-level trees (namely, uniform metric spaces), whereas randomized algorithms\ndo not exhibit any asymptotic gain even for one-level trees. In contrast, the\nspecial case of metrical service systems (subset chasing) behaves very\ndifferently. Both deterministic and randomized algorithms exhibit gain, for $m$\nsufficiently small compared to $n$, for any number of levels. Most\nsignificantly, they exhibit a large gain for uniform metric spaces and a\nsmaller gain for two-level trees. Moreover, it turns out that in these cases\n(as well as in the case of metrical task systems for uniform metric spaces with\n$m$ being an absolute constant), deterministic algorithms are essentially as\npowerful as randomized algorithms. This is surprising and runs counter to the\nubiquitous intuition/conjecture that, for most problems that can be modeled as\nmetrical task systems, the randomized competitive ratio is polylogarithmic in\nthe deterministic competitive ratio.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 07:34:20 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Rabani", "Yuval", ""]]}, {"id": "1904.03890", "submitter": "Simon Mauras", "authors": "Hugo Gimbert and Claire Mathieu and Simon Mauras", "title": "Two-Sided Matching Markets with Correlated Random Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY cs.DM cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable matching in a community consisting of men and women is a classical\ncombinatorial problem that has been the subject of intense theoretical and\nempirical study since its introduction in 1962 in a seminal paper by Gale and\nShapley, who designed the celebrated ``deferred acceptance'' algorithm for the\nproblem.\n  In the input, each participant ranks participants of the opposite type, so\nthe input consists of a collection of permutations, representing the preference\nlists. A bipartite matching is unstable if some man-woman pair is blocking:\nboth strictly prefer each other to their partner in the matching. Stability is\nan important economics concept in matching markets from the viewpoint of\nmanipulability. The unicity of a stable matching implies non-manipulability,\nand near-unicity implies limited manipulability, thus these are mathematical\nproperties related to the quality of stable matching algorithms.\n  This paper is a theoretical study of the effect of correlations on\napproximate manipulability of stable matching algorithms. Our approach is to go\nbeyond worst case, assuming that some of the input preference lists are drawn\nfrom a distribution. Our model encompasses a discrete probabilistic process\ninspired by a popularity model introduced by Immorlica and Mahdian, that\nprovides a way to capture correlation between preference lists. Approximate\nmanipulability is approached from several angles : when all stable partners of\na person have approximately the same rank; or when most persons have a unique\nstable partner. Another quantity of interest is a person's number of stable\npartners. Our results aim to paint a picture of the manipulability of stable\nmatchings in a ``beyond worst case'' setting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 08:49:45 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:10:11 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 18:10:58 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gimbert", "Hugo", ""], ["Mathieu", "Claire", ""], ["Mauras", "Simon", ""]]}, {"id": "1904.03950", "submitter": "Youming Qiao", "authors": "Xiaohui Bei, Shiteng Chen, Ji Guan, Youming Qiao, Xiaoming Sun", "title": "From independent sets and vertex colorings to isotropic spaces and\n  isotropic decompositions", "comments": "52 pages. v2: Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1970's, Lov\\'asz built a bridge between graphs and alternating matrix\nspaces, in the context of perfect matchings (FCT 1979). A similar connection\nbetween bipartite graphs and matrix spaces plays a key role in the recent\nresolutions of the non-commutative rank problem\n(Garg-Gurvits-Oliveira-Wigderson, FOCS 2016; Ivanyos-Qiao-Subrahmanyam, ITCS\n2017). In this paper, we lay the foundation for another bridge between graphs\nand alternating matrix spaces, in the context of independent sets and vertex\ncolorings. The corresponding structures in alternating matrix spaces are\nisotropic spaces and isotropic decompositions, both useful structures in group\ntheory and manifold theory.\n  We first show that the maximum independent set problem and the vertex\nc-coloring problem reduce to the maximum isotropic space problem and the\nisotropic c-decomposition problem, respectively. Next, we show that several\ntopics and results about independent sets and vertex colorings have natural\ncorrespondences for isotropic spaces and decompositions. These include\nalgorithmic problems, such as the maximum independent set problem for bipartite\ngraphs, and exact exponential-time algorithms for the chromatic number, as well\nas mathematical questions, such as the number of maximal independent sets, and\nthe relation between the maximum degree and the chromatic number. These\nconnections lead to new interactions between graph theory and algebra. Some\nresults have concrete applications to group theory and manifold theory, and we\ninitiate a variant of these structures in the context of quantum information\ntheory. Finally, we propose several open questions for further exploration.\n  This paper is dedicated to the memory of Ker-I Ko.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 11:02:56 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 01:36:57 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Bei", "Xiaohui", ""], ["Chen", "Shiteng", ""], ["Guan", "Ji", ""], ["Qiao", "Youming", ""], ["Sun", "Xiaoming", ""]]}, {"id": "1904.04045", "submitter": "Thomas Dybdahl Ahle", "authors": "Thomas Dybdahl Ahle, Jakob B{\\ae}k Tejs Knudsen", "title": "Subsets and Supermajorities: Optimal Hashing-based Set Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate and optimally solve a new generalized Set Similarity Search\nproblem, which assumes the size of the database and query sets are known in\nadvance. By creating polylog copies of our data-structure, we optimally solve\nany symmetric Approximate Set Similarity Search problem, including approximate\nversions of Subset Search, Maximum Inner Product Search (MIPS), Jaccard\nSimilarity Search and Partial Match.\n  Our algorithm can be seen as a natural generalization of previous work on Set\nas well as Euclidean Similarity Search, but conceptually it differs by\noptimally exploiting the information present in the sets as well as their\ncomplements, and doing so asymmetrically between queries and stored sets. Doing\nso we improve upon the best previous work: MinHash [J. Discrete Algorithms\n1998], SimHash [STOC 2002], Spherical LSF [SODA 2016, 2017] and Chosen Path\n[STOC 2017] by as much as a factor $n^{0.14}$ in both time and space; or in the\nnear-constant time regime, in space, by an arbitrarily large polynomial factor.\n  Turning the geometric concept, based on Boolean supermajority functions, into\na practical algorithm requires ideas from branching random walks on $\\mathbb\nZ^2$, for which we give the first non-asymptotic near tight analysis.\n  Our lower bounds follow from new hypercontractive arguments, which can be\nseen as characterizing the exact family of similarity search problems for which\nsupermajorities are optimal. The optimality holds for among all hashing based\ndata structures in the random setting, and by reductions, for 1 cell and 2 cell\nprobe data structures. As a side effect, we obtain new hypercontractive bounds\non the directed noise operator $T^{p_1 \\to p_2}_\\rho$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 13:23:03 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:14:54 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ahle", "Thomas Dybdahl", ""], ["Knudsen", "Jakob B\u00e6k Tejs", ""]]}, {"id": "1904.04126", "submitter": "Rajesh Jayaram", "authors": "Rajesh Jayaram, Gokarna Sharma, Srikanta Tirthapura, David P. Woodruff", "title": "Weighted Reservoir Sampling from Distributed Streams", "comments": "To appear in PODS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider message-efficient continuous random sampling from a distributed\nstream, where the probability of inclusion of an item in the sample is\nproportional to a weight associated with the item. The unweighted version,\nwhere all weights are equal, is well studied, and admits tight upper and lower\nbounds on message complexity. For weighted sampling with replacement, there is\na simple reduction to unweighted sampling with replacement. However, in many\napplications the stream has only a few heavy items which may dominate a random\nsample when chosen with replacement. Weighted sampling \\textit{without\nreplacement} (weighted SWOR) eludes this issue, since such heavy items can be\nsampled at most once.\n  In this work, we present the first message-optimal algorithm for weighted\nSWOR from a distributed stream. Our algorithm also has optimal space and time\ncomplexity. As an application of our algorithm for weighted SWOR, we derive the\nfirst distributed streaming algorithms for tracking \\textit{heavy hitters with\nresidual error}. Here the goal is to identify stream items that contribute\nsignificantly to the residual stream, once the heaviest items are removed.\nResidual heavy hitters generalize the notion of $\\ell_1$ heavy hitters and are\nimportant in streams that have a skewed distribution of weights. In addition to\nthe upper bound, we also provide a lower bound on the message complexity that\nis nearly tight up to a $\\log(1/\\epsilon)$ factor. Finally, we use our weighted\nsampling algorithm to improve the message complexity of distributed $L_1$\ntracking, also known as count tracking, which is a widely studied problem in\ndistributed streaming. We also derive a tight message lower bound, which closes\nthe message complexity of this fundamental problem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 15:25:29 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Jayaram", "Rajesh", ""], ["Sharma", "Gokarna", ""], ["Tirthapura", "Srikanta", ""], ["Woodruff", "David P.", ""]]}, {"id": "1904.04129", "submitter": "Huy Nguyen", "authors": "Huy L. Nguyen", "title": "A note on Cunningham's algorithm for matroid intersection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the matroid intersection problem, we are given two matroids of rank $r$ on\na common ground set $E$ of $n$ elements and the goal is to find the maximum set\nthat is independent in both matroids. In this note, we show that Cunningham's\nalgorithm for matroid intersection can be implemented to use $O(nr\\log^2(r))$\nindependent oracle calls.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 15:37:59 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Nguyen", "Huy L.", ""]]}, {"id": "1904.04216", "submitter": "Anindya De", "authors": "Anindya De, Elchanan Mossel and Joe Neeman", "title": "Junta correlation is testable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of tolerant junta testing is a natural and challenging problem\nwhich asks if the property of a function having some specified correlation with\na $k$-Junta is testable. In this paper we give an affirmative answer to this\nquestion: We show that given distance parameters $\\frac{1}{2} >c_u>c_{\\ell} \\ge\n0$, there is a tester which given oracle access to $f:\\{-1,1\\}^n \\rightarrow\n\\{-1,1\\}$, with query complexity $ 2^k \\cdot \\mathsf{poly}(k,1/|c_u-c_{\\ell}|)$\nand distinguishes between the following cases:\n  $\\mathbf{1.}$ The distance of $f$ from any $k$-junta is at least $c_u$;\n  $\\mathbf{2.}$ There is a $k$-junta $g$ which has distance at most $c_\\ell$\nfrom $f$.\n  This is the first non-trivial tester (i.e., query complexity is independent\nof $n$) which works for all $1/2 > c_u > c_\\ell \\ge 0$. The best previously\nknown results by Blais \\emph{et~ al.}, required $c_u \\ge 16 c_\\ell$. In fact,\nwith the same query complexity, we accomplish the stronger goal of identifying\nthe most correlated $k$-junta, up to permutations of the coordinates.\n  We can further improve the query complexity to $\\mathsf{poly}(k,\n1/|c_u-c_{\\ell}|)$ for the (weaker) task of distinguishing between the\nfollowing cases:\n  $\\mathbf{1.}$ The distance of $f$ from any $k'$-junta is at least $c_u$.\n  $\\mathbf{2.}$ There is a $k$-junta $g$ which is at a distance at most\n$c_\\ell$ from $f$.\n  Here $k'=O(k^2/|c_u-c_\\ell|)$.\n  Our main tools are Fourier analysis based algorithms that simulate oracle\naccess to influential coordinates of functions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:38:17 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["De", "Anindya", ""], ["Mossel", "Elchanan", ""], ["Neeman", "Joe", ""]]}, {"id": "1904.04228", "submitter": "Dominik Kempa", "authors": "Dominik Kempa and Tomasz Kociumaka", "title": "String Synchronizing Sets: Sublinear-Time BWT Construction and Optimal\n  LCE Data Structure", "comments": "Full version of a paper accepted to STOC 2019", "journal-ref": null, "doi": "10.1145/3313276.3316368", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Burrows-Wheeler transform (BWT) is an invertible text transformation that,\ngiven a text $T$ of length $n$, permutes its symbols according to the\nlexicographic order of suffixes of $T$. BWT is one of the most heavily studied\nalgorithms in data compression with numerous applications in indexing, sequence\nanalysis, and bioinformatics. Its construction is a bottleneck in many\nscenarios, and settling the complexity of this task is one of the most\nimportant unsolved problems in sequence analysis that has remained open for 25\nyears. Given a binary string of length $n$, occupying $O(n/\\log n)$ machine\nwords, the BWT construction algorithm due to Hon et al. (SIAM J. Comput., 2009)\nruns in $O(n)$ time and $O(n/\\log n)$ space. Recent advancements (Belazzougui,\nSTOC 2014, and Munro et al., SODA 2017) focus on removing the alphabet-size\ndependency in the time complexity, but they still require $\\Omega(n)$ time.\n  In this paper, we propose the first algorithm that breaks the $O(n)$-time\nbarrier for BWT construction. Given a binary string of length $n$, our\nprocedure builds the Burrows-Wheeler transform in $O(n/\\sqrt{\\log n})$ time and\n$O(n/\\log n)$ space. We complement this result with a conditional lower bound\nproving that any further progress in the time complexity of BWT construction\nwould yield faster algorithms for the very well studied problem of counting\ninversions: it would improve the state-of-the-art $O(m\\sqrt{\\log m})$-time\nsolution by Chan and P\\v{a}tra\\c{s}cu (SODA 2010). Our algorithm is based on a\nnovel concept of string synchronizing sets, which is of independent interest.\nAs one of the applications, we show that this technique lets us design a data\nstructure of the optimal size $O(n/\\log n)$ that answers Longest Common\nExtension queries (LCE queries) in $O(1)$ time and, furthermore, can be\ndeterministically constructed in the optimal $O(n/\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:56:21 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 21:52:51 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kempa", "Dominik", ""], ["Kociumaka", "Tomasz", ""]]}, {"id": "1904.04243", "submitter": "Duygu Vietz", "authors": "Duygu Vietz and Egon Wanke", "title": "The Fault-Tolerant Metric Dimension of Cographs", "comments": "arXiv admin note: text overlap with arXiv:1806.10389", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vertex set $U \\subseteq V$ of an undirected graph $G=(V,E)$ is a\n\\textit{resolving set} for $G$ if for every two distinct vertices $u,v \\in V$\nthere is a vertex $w \\in U$ such that the distance between $u$ and $w$ and the\ndistance between $v$ and $w$ are different. A resolving set $U$ is {\\em\nfault-tolerant} if for every vertex $u\\in U$ set $U\\setminus \\{u\\}$ is still a\nresolving set. {The \\em (fault-tolerant) Metric Dimension} of $G$ is the size\nof a smallest (fault-tolerant) resolving set for $G$. The {\\em weighted\n(fault-tolerant) Metric Dimension} for a given cost function $c: V\n\\longrightarrow \\mathbb{R}_+$ is the minimum weight of all (fault-tolerant)\nresolving sets. Deciding whether a given graph $G$ has (fault-tolerant) Metric\nDimension at most $k$ for some integer $k$ is known to be NP-complete. The\nweighted fault-tolerant Metric Dimension problem has not been studied\nextensively so far. In this paper we show that the weighted fault-tolerant\nmetric dimension problem can be solved in linear time on cographs.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 16:26:33 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Vietz", "Duygu", ""], ["Wanke", "Egon", ""]]}, {"id": "1904.04341", "submitter": "Mohit Daga", "authors": "Mohit Daga, Monika Henzinger, Danupon Nanongkai, Thatchaphol Saranurak", "title": "Distributed Edge Connectivity in Sublinear Time", "comments": "Accepted at 51st ACM Symposium on Theory of Computing (STOC 2019)", "journal-ref": null, "doi": "10.1145/3313276.3316346", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first sublinear-time algorithm for a distributed\nmessage-passing network sto compute its edge connectivity $\\lambda$ exactly in\nthe CONGEST model, as long as there are no parallel edges. Our algorithm takes\n$\\tilde O(n^{1-1/353}D^{1/353}+n^{1-1/706})$ time to compute $\\lambda$ and a\ncut of cardinality $\\lambda$ with high probability, where $n$ and $D$ are the\nnumber of nodes and the diameter of the network, respectively, and $\\tilde O$\nhides polylogarithmic factors. This running time is sublinear in $n$ (i.e.\n$\\tilde O(n^{1-\\epsilon})$) whenever $D$ is. Previous sublinear-time\ndistributed algorithms can solve this problem either (i) exactly only when\n$\\lambda=O(n^{1/8-\\epsilon})$ [Thurimella PODC'95; Pritchard, Thurimella, ACM\nTrans. Algorithms'11; Nanongkai, Su, DISC'14] or (ii) approximately [Ghaffari,\nKuhn, DISC'13; Nanongkai, Su, DISC'14].\n  To achieve this we develop and combine several new techniques. First, we\ndesign the first distributed algorithm that can compute a $k$-edge connectivity\ncertificate for any $k=O(n^{1-\\epsilon})$ in time $\\tilde O(\\sqrt{nk}+D)$.\nSecond, we show that by combining the recent distributed expander decomposition\ntechnique of [Chang, Pettie, Zhang, SODA'19] with techniques from the\nsequential deterministic edge connectivity algorithm of [Kawarabayashi, Thorup,\nSTOC'15], we can decompose the network into a sublinear number of clusters with\nsmall average diameter and without any mincut separating a cluster (except the\n`trivial' ones). Finally, by extending the tree packing technique from [Karger\nSTOC'96], we can find the minimum cut in time proportional to the number of\ncomponents. As a byproduct of this technique, we obtain an $\\tilde O(n)$-time\nalgorithm for computing exact minimum cut for weighted graphs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:23:20 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Daga", "Mohit", ""], ["Henzinger", "Monika", ""], ["Nanongkai", "Danupon", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "1904.04403", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Discovering Bands from Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-014-0359-9", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the underlying structure of a given graph is one of the\nfundamental goals in graph mining. Given a graph, we can often order vertices\nin a way that neighboring vertices have a higher probability of being connected\nto each other. This implies that the edges form a band around the diagonal in\nthe adjacency matrix. Such structure may rise for example if the graph was\ncreated over time: each vertex had an active time interval during which the\nvertex was connected with other active vertices.\n  The goal of this paper is to model this phenomenon. To this end, we formulate\nan optimization problem: given a graph and an integer $K$, we want to order\ngraph vertices and partition the ordered adjacency matrix into $K$ bands such\nthat bands closer to the diagonal are more dense. We measure the goodness of a\nsegmentation using the log-likelihood of a log-linear model, a flexible family\nof distributions containing many standard distributions. We divide the problem\ninto two subproblems: finding the order and finding the bands. We show that\ndiscovering bands can be done in polynomial time with isotonic regression, and\nwe also introduce a heuristic iterative approach. For discovering the order we\nuse Fiedler order accompanied with a simple combinatorial refinement. We\ndemonstrate empirically that our heuristic works well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 00:11:27 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1904.04453", "submitter": "Sorrachai Yingchareonthawornchai", "authors": "Danupon Nanongkai, Thatchaphol Saranurak, Sorrachai\n  Yingchareonthawornchai", "title": "Breaking Quadratic Time for Small Vertex Connectivity and an\n  Approximation Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex connectivity a classic extensively-studied problem. Given an integer\n$k$, its goal is to decide if an $n$-node $m$-edge graph can be disconnected by\nremoving $k$ vertices. Although a linear-time algorithm was postulated since\n1974 [Aho, Hopcroft and Ullman], and despite its sibling problem of edge\nconnectivity being resolved over two decades ago [Karger STOC'96], so far no\nvertex connectivity algorithms are faster than $O(n^2)$ time even for $k=4$ and\n$m=O(n)$. In the simplest case where $m=O(n)$ and $k=O(1)$, the $O(n^2)$ bound\ndates five decades back to [Kleitman IEEE Trans. Circuit Theory'69]. For\ngeneral $k$ and $m$, the best bound is $\\tilde{O}(\\min(kn^2,\nn^\\omega+nk^\\omega))$.\n  In this paper, we present a randomized Monte Carlo algorithm with\n$\\tilde{O}(m+k^{7/3}n^{4/3})$ time for any $k=O(\\sqrt{n})$. This gives the {\\em\nfirst subquadratic time} bound for any $4\\leq k \\leq o(n^{2/7})$ and improves\nall above classic bounds for all $k\\le n^{0.44}$. We also present a new\nrandomized Monte Carlo $(1+\\epsilon)$-approximation algorithm that is strictly\nfaster than the previous Henzinger's 2-approximation algorithm [J.\nAlgorithms'97] and all previous exact algorithms.\n  The key to our results is to avoid computing single-source connectivity,\nwhich was needed by all previous exact algorithms and is not known to admit\n$o(n^2)$ time. Instead, we design the first local algorithm for computing\nvertex connectivity; without reading the whole graph, our algorithm can find a\nseparator of size at most $k$ or certify that there is no separator of size at\nmost $k$ `near' a given seed node.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 03:46:16 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 17:52:06 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 19:18:46 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Nanongkai", "Danupon", ""], ["Saranurak", "Thatchaphol", ""], ["Yingchareonthawornchai", "Sorrachai", ""]]}, {"id": "1904.04475", "submitter": "Xianrui Meng", "authors": "Xianrui Meng, Dimitrios Papadopoulos, Alina Oprea, Nikos Triandopoulos", "title": "Private Two-Party Cluster Analysis Made Formal & Scalable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is widely used for predictive tasks in numerous\nimportant applications---most successfully, in the context of collaborative\nlearning, where a plurality of entities contribute their own datasets to\njointly deduce global ML models. Despite its efficacy, this new learning\nparadigm fails to encompass critical application domains, such as healthcare\nand security analytics, that involve learning over highly sensitive data,\nwherein privacy risks limit entities to individually deduce local models using\nsolely their own datasets.\n  In this work, we present the first comprehensive study for privacy-preserving\ncollaborative hierarchical clustering, overall featuring scalable cryptographic\nprotocols that allow two parties to safely perform cluster analysis over their\ncombined sensitive datasets. For this problem at hand, we introduce a formal\nsecurity notion that achieves the required balance between intended accuracy\nand privacy and presents a class of two-party hierarchical clustering protocols\nthat guarantee strong privacy protection, provable in our new security model.\nCrucially, our solution employs modular design and judicious use of\ncryptography to achieve high degrees of efficiency and extensibility.\nSpecifically, we extend our core protocol to obtain two secure variants that\nsignificantly improve performance, an optimized variant for single-linkage\nclustering and a scalable approximate variant. Finally, we provide a prototype\nimplementation of our approach and experimentally evaluate its feasibility and\nefficiency on synthetic and real datasets, obtaining encouraging results. For\nexample, end-to-end execution of our secure approximate protocol, over 1M\n10-dimensional records, completes in 35 sec, transferring only 896KB and\nachieving 97.09% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 05:58:28 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 04:09:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Meng", "Xianrui", ""], ["Papadopoulos", "Dimitrios", ""], ["Oprea", "Alina", ""], ["Triandopoulos", "Nikos", ""]]}, {"id": "1904.04501", "submitter": "Tomasz Krawczyk", "authors": "Tomasz Krawczyk", "title": "Testing isomorphism of circular-arc graphs -- Hsu's approach revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circular-arc graphs are intersection graphs of arcs on the circle. The aim of\nour work is to present a polynomial time algorithm testing whether two\ncircular-arc graphs are isomorphic. To accomplish our task we construct\ndecomposition trees, which are the structures representing all normalized\nintersection models of circular-arc graphs. Normalized models reflect the\nneighbourhood relation in circular-arc graphs and can be seen as their\ncanonical representations; in particular, every intersection model can be\neasily transformed into a normalized one.\n  Our work adapts and appropriately extends the previous work on the similar\ntopic done by Hsu [\\emph{SIAM J. Comput. 24(3), 411--439, (1995)}]. In his\nwork, Hsu developed decomposition trees representing all normalized models of\ncircular-arc graphs. However due to the counterexample given in [\\emph{Discrete\nMath. Theor. Comput. Sci., 15(1), 157--182, 2013}], his decomposition trees can\nnot be used by algorithms testing isomorphism of circular-arc graphs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 07:38:12 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 10:44:05 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 20:16:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Krawczyk", "Tomasz", ""]]}, {"id": "1904.04513", "submitter": "Shunsuke Inenaga", "authors": "Shunsuke Inenaga", "title": "Towards a complete perspective on labeled tree indexing: new size\n  bounds, efficient constructions, and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A labeled tree (or a trie) is a natural generalization of a string, which can\nalso be seen as a compact representation of a set of strings. This paper\nconsiders the labeled tree indexing problem, and provides a number of new\nresults on space bound analysis, and on algorithms for efficient construction\nand pattern matching queries. Kosaraju [FOCS 1989] was the first to consider\nthe labeled tree indexing problem, and he proposed the suffix tree for a\nbackward trie, where the strings in the trie are read in the leaf-to-root\ndirection. In contrast to a backward trie, we call a usual trie as a forward\ntrie. Despite a few follow-up works after Kosaraju's paper, indexing\nforward/backward tries is not well understood yet. In this paper, we show a\nfull perspective on the sizes of indexing structures such as suffix trees,\nDAWGs, CDAWGs, suffix arrays, affix trees, affix arrays for forward and\nbackward tries. Some of them take $O(n)$ space in the size $n$ of the input\ntrie, while the others can occupy $O(n^2)$ space in the worst case. In\nparticular, we show that the size of the DAWG for a forward trie with $n$ nodes\nis $\\Omega(\\sigma n)$, where $\\sigma$ is the number of distinct characters in\nthe trie. This becomes $\\Omega(n^2)$ for an alphabet of size $\\sigma =\n\\Theta(n)$. Still, we show that there is a compact $O(n)$-space implicit\nrepresentation of the DAWG for a forward trie, whose space requirement is\nindependent of the alphabet size. This compact representation allows for\nsimulating each DAWG edge traversal in $O(\\log \\sigma)$ time, and can be\nconstructed in $O(n)$ time and space over any integer alphabet of size $O(n)$.\nIn addition, this readily extends to the first indexing structure that permits\nbidirectional pattern searches over a trie within linear space in the input\ntrie size.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 08:05:42 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:18:07 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 10:26:27 GMT"}, {"version": "v4", "created": "Tue, 31 Mar 2020 06:46:51 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 08:27:29 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Inenaga", "Shunsuke", ""]]}, {"id": "1904.04720", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi, Yu Chen, Sanjeev Khanna", "title": "Polynomial Pass Lower Bounds for Graph Streaming Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new lower bounds that show that a polynomial number of passes are\nnecessary for solving some fundamental graph problems in the streaming model of\ncomputation. For instance, we show that any streaming algorithm that finds a\nweighted minimum $s$-$t$ cut in an $n$-vertex undirected graph requires\n$n^{2-o(1)}$ space unless it makes $n^{\\Omega(1)}$ passes over the stream.\n  To prove our lower bounds, we introduce and analyze a new four-player\ncommunication problem that we refer to as the hidden-pointer chasing problem.\nThis is a problem in spirit of the standard pointer chasing problem with the\nkey difference that the pointers in this problem are hidden to players and\nfinding each one of them requires solving another communication problem, namely\nthe set intersection problem. Our lower bounds for graph problems are then\nobtained by reductions from the hidden-pointer chasing problem.\n  Our hidden-pointer chasing problem appears flexible enough to find other\napplications and is therefore interesting in its own right. To showcase this,\nwe further present an interesting application of this problem beyond streaming\nalgorithms. Using a reduction from hidden-pointer chasing, we prove that any\nalgorithm for submodular function minimization needs to make $n^{2-o(1)}$ value\nqueries to the function unless it has a polynomial degree of adaptivity.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:00:14 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Assadi", "Sepehr", ""], ["Chen", "Yu", ""], ["Khanna", "Sanjeev", ""]]}, {"id": "1904.04828", "submitter": "Kevin Yeo", "authors": "Kasper Green Larsen and Tal Malkin and Omri Weinstein and Kevin Yeo", "title": "Lower Bounds for Oblivious Near-Neighbor Search", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an $\\Omega(d \\lg n/ (\\lg\\lg n)^2)$ lower bound on the dynamic\ncell-probe complexity of statistically $\\mathit{oblivious}$\napproximate-near-neighbor search ($\\mathsf{ANN}$) over the $d$-dimensional\nHamming cube. For the natural setting of $d = \\Theta(\\log n)$, our result\nimplies an $\\tilde{\\Omega}(\\lg^2 n)$ lower bound, which is a quadratic\nimprovement over the highest (non-oblivious) cell-probe lower bound for\n$\\mathsf{ANN}$. This is the first super-logarithmic $\\mathit{unconditional}$\nlower bound for $\\mathsf{ANN}$ against general (non black-box) data structures.\nWe also show that any oblivious $\\mathit{static}$ data structure for\ndecomposable search problems (like $\\mathsf{ANN}$) can be obliviously dynamized\nwith $O(\\log n)$ overhead in update and query time, strengthening a classic\nresult of Bentley and Saxe (Algorithmica, 1980).\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 14:08:53 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Malkin", "Tal", ""], ["Weinstein", "Omri", ""], ["Yeo", "Kevin", ""]]}, {"id": "1904.04860", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek and Venkatesan Guruswami", "title": "Bridging between 0/1 and Linear Programming via Random Walks", "comments": "19 pages, to appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the Strong Exponential Time Hypothesis, an integer linear program with\n$n$ Boolean-valued variables and $m$ equations cannot be solved in $c^n$ time\nfor any constant $c < 2$. If the domain of the variables is relaxed to $[0,1]$,\nthe associated linear program can of course be solved in polynomial time. In\nthis work, we give a natural algorithmic bridging between these extremes of\n$0$-$1$ and linear programming. Specifically, for any subset (finite union of\nintervals) $E \\subset [0,1]$ containing $\\{0,1\\}$, we give a random-walk based\nalgorithm with runtime $O_E((2-\\text{measure}(E))^n\\text{poly}(n,m))$ that\nfinds a solution in $E^n$ to any $n$-variable linear program with $m$\nconstraints that is feasible over $\\{0,1\\}^n$. Note that as $E$ expands from\n$\\{0,1\\}$ to $[0,1]$, the runtime improves smoothly from $2^n$ to polynomial.\n  Taking $E = [0,1/k) \\cup (1-1/k,1]$ in our result yields as a corollary a\nrandomized $(2-2/k)^{n}\\text{poly}(n)$ time algorithm for $k$-SAT. While our\napproach has some high level resemblance to Sch\\\"{o}ning's beautiful algorithm,\nour general algorithm is based on a more sophisticated random walk that\nincorporates several new ingredients, such as a multiplicative potential to\nmeasure progress, a judicious choice of starting distribution, and a time\nvarying distribution for the evolution of the random walk that is itself\ncomputed via an LP at each step (a solution to which is guaranteed based on the\nminimax theorem). Plugging the LP algorithm into our earlier polymorphic\nframework yields fast exponential algorithms for any CSP (like $k$-SAT,\n$1$-in-$3$-SAT, NAE $k$-SAT) that admit so-called `threshold partial\npolymorphisms.'\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:37:33 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1904.04916", "submitter": "Mordechai Shalom", "authors": "T{\\i}naz Ekim, Mordechai Shalom, Oylum \\c{S}eker", "title": "The Complexity of Subtree Intersection Representation of Chordal Graphs\n  and Linear Time Chordal Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that any chordal graph on $n$ vertices can be represented as the\nintersection of $n$ subtrees in a tree on $n$ nodes. This fact is recently used\nin [2] to generate random chordal graphs on $n$ vertices by generating $n$\nsubtrees of a tree on $n$ nodes. It follows that the space (and thus time)\ncomplexity of such an algorithm is at least the sum of the sizes of the\ngenerated subtrees assuming that a tree is given by a set of nodes. In [2],\nthis complexity was mistakenly claimed to be linear in the number $m$ of edges\nof the generated chordal graph. This error is corrected in [3] where the space\ncomplexity is shown to be $\\Omega(m n^{1/4})$. The exact complexity of the\nalgorithm is left as an open question.\n  In this paper, we show that the sum of the sizes of $n$ subtrees in a tree on\n$n$ nodes is $\\Theta(m\\sqrt{n})$. We also show that we can confine ourselves to\ncontraction-minimal subtree intersection representations since they are\nsufficient to generate every chordal graph. Furthermore, the sum of the sizes\nof the subtrees in such a representation is at most $2m+n$. We use this result\nto derive the first linear time random chordal graph generator. Based on\ncontraction-minimal representations, we also derive structural properties of\nchordal graphs related to their connectivity. In addition to these theoretical\nresults, we conduct experiments to study the quality of the chordal graphs\ngenerated by our algorithm and compare them to those in the literature. Our\nexperimental study indicates that the generated graphs do not have a restricted\nstructure and the sizes of maximal cliques are distributed fairly over the\nrange. Furthermore, our algorithm is simple to implement and produces graphs\nwith 10000 vertices and $4 . 10^7$ edges in less than one second on a laptop\ncomputer.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 21:23:15 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 06:53:25 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Ekim", "T\u0131naz", ""], ["Shalom", "Mordechai", ""], ["\u015eeker", "Oylum", ""]]}, {"id": "1904.05011", "submitter": "Yasuaki Kobayashi", "authors": "Yasuaki Kobayashi and Yusuke Kobayashi and Shuichi Miyazaki and Suguru\n  Tamaki", "title": "An FPT Algorithm for Max-Cut Parameterized by Crossing Number", "comments": "The same running time bound has been obtained independently and\n  simultaneously by Markus Chimani, Christine Dahn, Martina Juhnke-Kubitzke,\n  Nils M. Kriege, Petra Mutzel, and Alexander Nover arXiv:1903.06061", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Max-Cut problem is known to be NP-hard on general graphs, while it can be\nsolved in polynomial time on planar graphs. In this paper, we present a\nfixed-parameter tractable algorithm for the problem on `almost' planar graphs:\nGiven an $n$-vertex graph and its drawing with $k$ crossings, our algorithm\nruns in time $O(2^k(n+k)^{3/2} \\log (n + k))$. Previously, Dahn, Kriege and\nMutzel (IWOCA 2018) obtained an algorithm that, given an $n$-vertex graph and\nits $1$-planar drawing with $k$ crossings, runs in time $O(3^k n^{3/2} \\log\nn)$. Our result simultaneously improves the running time and removes the\n$1$-planarity restriction.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 06:06:15 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 05:11:58 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Kobayashi", "Yasuaki", ""], ["Kobayashi", "Yusuke", ""], ["Miyazaki", "Shuichi", ""], ["Tamaki", "Suguru", ""]]}, {"id": "1904.05066", "submitter": "Moustafa Nakechbandi", "authors": "Moustafa Nakechbandi (LITIS), Jean-Yves Colin (LITIS), Herv\\'e Mathieu\n  (GIN)", "title": "Minimum Spanning Trees in Weakly Dynamic Graphs", "comments": null, "journal-ref": "LOGISTIQUA 2017, 10th International Colloquium of Logistics and\n  Supply Chain Management, Apr 2017, Rabat, Morocco", "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study weakly dynamic undirected graphs, that can be used to\nrepresent some logistic networks. The goal is to deliver all the delivery\npoints in the network. The network exists in a mostly stable environment,\nexcept for a few edges known to be non-stable. The weight of each of these\nnon-stable edges may change at any time (bascule or lift bridge, elevator,\ntraffic congestion...). All other edges have stable weights that never change.\nThis problem can be now considered as a Minimum Spanning Tree (MST) problem on\na dynamic graph. We propose an efficient polynomial algorithm that computes in\nadvance alternative MSTs for all possible configurations. No additional\ncomputation is then needed after any change in the problem because the MSTs are\nalready known in all cases. We use these results to compute critical values for\nthe non-stable weights and to pre-compute best paths. When the non-stable\nweights change, the appropriate MST may then directly and immediately be used\nwithout any recomputation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:50:16 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Nakechbandi", "Moustafa", "", "LITIS"], ["Colin", "Jean-Yves", "", "LITIS"], ["Mathieu", "Herv\u00e9", "", "GIN"]]}, {"id": "1904.05220", "submitter": "Bj\\\"orn Feldkord", "authors": "Bj\\\"orn Feldkord and Friedhelm Meyer auf der Heide", "title": "The Mobile Server Problem", "comments": "A preliminary version appeared at SPAA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the mobile server problem, inspired by current trends to move\ncomputational tasks from cloud structures to multiple devices close to the end\nuser. An example for this are embedded systems in autonomous cars that\ncommunicate in order to coordinate their actions.\n  Our model is a variant of the classical Page Migration Problem. More\nformally, we consider a mobile server holding a data page. The server can move\nin the Euclidean space (of arbitrary dimension). In every round, requests for\ndata items from the page pop up at arbitrary points in the space. The requests\nare served, each at a cost of the distance from the requesting point and the\nserver, and the mobile server may move, at a cost $D$ times the distance\ntraveled for some constant $D$. We assume a maximum distance $m$ the server is\nallowed to move per round.\n  We show that no online algorithm can achieve a competitive ratio independent\nof the length of the input sequence in this setting. Hence we augment the\nmaximum movement distance of the online algorithms to $(1+\\delta)$ times the\nmaximum distance of the offline solution. We provide a deterministic algorithm\nwhich is simple to describe and works for multiple variants of our problem. The\nalgorithm achieves almost tight competitive ratios independent of the length of\nthe input sequence.\n  Our Algorithm also achieves a constant competitive ratio without resource\naugmentation in a variant where the distance between two consecutive requests\nis restricted to a constant smaller than the limit for the server.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:42:20 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Feldkord", "Bj\u00f6rn", ""], ["der Heide", "Friedhelm Meyer auf", ""]]}, {"id": "1904.05309", "submitter": "Erik Waingarten", "authors": "Xi Chen and Erik Waingarten", "title": "Testing Unateness Nearly Optimally", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $\\tilde{O}(n^{2/3}/\\epsilon^2)$-query algorithm that tests\nwhether an unknown Boolean function $f\\colon\\{0,1\\}^n\\rightarrow \\{0,1\\}$ is\nunate (i.e., every variable is either non-decreasing or non-increasing) or\n$\\epsilon$-far from unate. The upper bound is nearly optimal given the\n$\\tilde{\\Omega}(n^{2/3})$ lower~bound of [CWX17a]. The algorithm builds on a\nnovel use of the binary search procedure and its analysis over long random\npaths.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:18:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Chen", "Xi", ""], ["Waingarten", "Erik", ""]]}, {"id": "1904.05390", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek and Aviad Rubinstein", "title": "Constant-factor approximation of near-linear edit distance in\n  near-linear time", "comments": "40 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the edit distance between two strings of length $n$ can be\ncomputed within a factor of $f(\\epsilon)$ in $n^{1+\\epsilon}$ time as long as\nthe edit distance is at least $n^{1-\\delta}$ for some $\\delta(\\epsilon) > 0$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 18:55:56 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 18:54:41 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Rubinstein", "Aviad", ""]]}, {"id": "1904.05451", "submitter": "Zhao Song", "authors": "Aviad Rubinstein, Zhao Song", "title": "Reducing approximate Longest Common Subsequence to approximate Edit\n  Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Given a pair of strings, the problems of computing their Longest Common\nSubsequence and Edit Distance have been extensively studied for decades. For\nexact algorithms, LCS and Edit Distance (with character insertions and\ndeletions) are equivalent; the state of the art running time is (almost)\nquadratic and this is tight under plausible fine-grained complexity\nassumptions. But for approximation algorithms the picture is different: there\nis a long line of works with improved approximation factors for Edit Distance,\nbut for LCS (with binary strings) only a trivial $1/2$-approximation was known.\nIn this work we give a reduction from approximate LCS to approximate Edit\nDistance, yielding the first efficient $(1/2+\\epsilon)$-approximation algorithm\nfor LCS for some constant $\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:36:47 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Rubinstein", "Aviad", ""], ["Song", "Zhao", ""]]}, {"id": "1904.05452", "submitter": "Kevin Yeo", "authors": "Sarvar Patel and Giuseppe Persiano and Kevin Yeo", "title": "What Storage Access Privacy is Achievable with Small Overhead?", "comments": "To appear at PODS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious RAM (ORAM) and private information retrieval (PIR) are classic\ncryptographic primitives used to hide the access pattern to data whose storage\nhas been outsourced to an untrusted server. Unfortunately, both primitives\nrequire considerable overhead compared to plaintext access. For large-scale\nstorage infrastructure with highly frequent access requests, the degradation in\nresponse time and the exorbitant increase in resource costs incurred by either\nORAM or PIR prevent their usage. In an ideal scenario, a privacy-preserving\nstorage protocols with small overhead would be implemented for these heavily\ntrafficked storage systems to avoid negatively impacting either performance\nand/or costs. In this work, we study the problem of the best $\\mathit{storage\\\naccess\\ privacy}$ that is achievable with only $\\mathit{small\\ overhead}$ over\nplaintext access.\n  To answer this question, we consider $\\mathit{differential\\ privacy\\ access}$\nwhich is a generalization of the $\\mathit{oblivious\\ access}$ security notion\nthat are considered by ORAM and PIR. Quite surprisingly, we present strong\nevidence that constant overhead storage schemes may only be achieved with\nprivacy budgets of $\\epsilon = \\Omega(\\log n)$. We present asymptotically\noptimal constructions for differentially private variants of both ORAM and PIR\nwith privacy budgets $\\epsilon = \\Theta(\\log n)$ with only $O(1)$ overhead. In\naddition, we consider a more complex storage primitive called key-value storage\nin which data is indexed by keys from a large universe (as opposed to\nconsecutive integers in ORAM and PIR). We present a differentially private\nkey-value storage scheme with $\\epsilon = \\Theta(\\log n)$ and $O(\\log\\log n)$\noverhead. This construction uses a new oblivious, two-choice hashing scheme\nthat may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:41:35 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Patel", "Sarvar", ""], ["Persiano", "Giuseppe", ""], ["Yeo", "Kevin", ""]]}, {"id": "1904.05459", "submitter": "Michal Koucky", "authors": "Michal Kouck\\'y and Michael E. Saks", "title": "Constant factor approximations to edit distance on far input pairs in\n  nearly linear time", "comments": "Corrected typos. Revised argument in Section 4.9, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any $T \\geq 1$, there are constants $R=R(T) \\geq 1$ and\n$\\zeta=\\zeta(T)>0$ and a randomized algorithm that takes as input an integer\n$n$ and two strings $x,y$ of length at most $n$, and runs in time\n$O(n^{1+\\frac{1}{T}})$ and outputs an upper bound $U$ on the edit distance\n$ED(x,y)$ that with high probability, satisfies $U \\leq\nR(ED(x,y)+n^{1-\\zeta})$. In particular, on any input with $ED(x,y) \\geq\nn^{1-\\zeta}$ the algorithm outputs a constant factor approximation with high\nprobability.\n  A similar result has been proven independently by Brakensiek and Rubinstein\n(2019).\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 21:52:07 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 08:42:20 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Kouck\u00fd", "Michal", ""], ["Saks", "Michael E.", ""]]}, {"id": "1904.05474", "submitter": "Stefan Neumann", "authors": "Monika Henzinger, Stefan Neumann, Stefan Schmid", "title": "Efficient Distributed Workload (Re-)Embedding", "comments": "To appear at SIGMETRICS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern networked systems are increasingly reconfigurable, enabling\ndemand-aware infrastructures whose resources can be adjusted according to the\nworkload they currently serve. Such dynamic adjustments can be exploited to\nimprove network utilization and hence performance, by moving frequently\ninteracting communication partners closer, e.g., collocating them in the same\nserver or datacenter. However, dynamically changing the embedding of workloads\nis algorithmically challenging: communication patterns are often not known\nahead of time, but must be learned. During the learning process, overheads\nrelated to unnecessary moves (i.e., re-embeddings) should be minimized. This\npaper studies a fundamental model which captures the tradeoff between the\nbenefits and costs of dynamically collocating communication partners on $\\ell$\nservers, in an online manner. Our main contribution is a distributed online\nalgorithm which is asymptotically almost optimal, i.e., almost matches the\nlower bound (also derived in this paper) on the competitive ratio of any\n(distributed or centralized) online algorithm. As an application, we show that\nour algorithm can be used to solve a distributed union find problem in which\nthe sets are stored across multiple servers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 23:19:45 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Henzinger", "Monika", ""], ["Neumann", "Stefan", ""], ["Schmid", "Stefan", ""]]}, {"id": "1904.05510", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan and Mark Rudelson", "title": "Restricted Isometry Property under High Correlations", "comments": "30 pages, fixed minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrices satisfying the Restricted Isometry Property (RIP) play an important\nrole in the areas of compressed sensing and statistical learning. RIP matrices\nwith optimal parameters are mainly obtained via probabilistic arguments, as\nexplicit constructions seem hard. It is therefore interesting to ask whether a\nfixed matrix can be incorporated into a construction of restricted isometries.\nIn this paper, we construct a new broad ensemble of random matrices with\ndependent entries that satisfy the restricted isometry property. Our\nconstruction starts with a fixed (deterministic) matrix $X$ satisfying some\nsimple stable rank condition, and we show that the matrix $XR$, where $R$ is a\nrandom matrix drawn from various popular probabilistic models (including,\nsubgaussian, sparse, low-randomness, satisfying convex concentration property),\nsatisfies the RIP with high probability. These theorems have various\napplications in signal recovery, random matrix theory, dimensionality\nreduction, etc. Additionally, motivated by an application for understanding the\neffectiveness of word vector embeddings popular in natural language processing\nand machine learning applications, we investigate the RIP of the matrix\n$XR^{(l)}$ where $R^{(l)}$ is formed by taking all possible (disregarding\norder) $l$-way entrywise products of the columns of a random matrix $R$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 03:14:48 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:34:19 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Rudelson", "Mark", ""]]}, {"id": "1904.05532", "submitter": "Sandip Sinha", "authors": "Frank Ban, Xi Chen, Adam Freilich, Rocco A. Servedio, Sandip Sinha", "title": "Beyond trace reconstruction: Population recovery from the deletion\n  channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Population recovery} is the problem of learning an unknown distribution\nover an unknown set of $n$-bit strings, given access to independent draws from\nthe distribution that have been independently corrupted according to some noise\nchannel. Recent work has intensively studied such problems both for the\nbit-flip and erasure noise channels.\n  We initiate the study of population recovery under the \\emph{deletion\nchannel}, in which each bit is independently \\emph{deleted} with some fixed\nprobability and the surviving bits are concatenated and transmitted. This is a\nfar more challenging noise model than bit-flip~noise or erasure noise; indeed,\neven the simplest case in which the population size is 1 (corresponding to a\ntrivial distribution supported on a single string) corresponds to the\n\\emph{trace reconstruction} problem, a challenging problem that has received\nmuch recent attention (see e.g.~\\cite{DOS17,NP17,PZ17,HPP18,HHP18}).\n  We give algorithms and lower bounds for population recovery under the\ndeletion channel when the population size is some $\\ell>1$. As our main sample\ncomplexity upper bound, we show that for any $\\ell=o(\\log n/\\log \\log n)$, a\npopulation of $\\ell$ strings from $\\{0,1\\}^n$ can be learned under deletion\nchannel noise using $\\smash{2^{n^{1/2+o(1)}}}$ samples. On the lower bound\nside, we show that $n^{\\Omega(\\ell)}$ samples are required to perform\npopulation recovery under the deletion channel, for all $\\ell \\leq\nn^{1/2-\\epsilon}$.\n  Our upper bounds are obtained via a robust multivariate generalization of a\npolynomial-based analysis, due to Krasikov and Roddity \\cite{KR97}, of how the\n$k$-deck of a bit-string uniquely identifies the string; this is a very\ndifferent approach from recent algorithms for trace reconstruction (the\n$\\ell=1$ case). Our lower bounds build on moment-matching results of\nRoos~\\cite{Roo00} and Daskalakis and Papadimitriou~\\cite{DP15}.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 04:54:59 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Ban", "Frank", ""], ["Chen", "Xi", ""], ["Freilich", "Adam", ""], ["Servedio", "Rocco A.", ""], ["Sinha", "Sandip", ""]]}, {"id": "1904.05543", "submitter": "Yi Li", "authors": "Yi Li, Ruosong Wang, David P. Woodruff", "title": "Tight Bounds for the Subspace Sketch Problem with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the subspace sketch problem one is given an $n\\times d$ matrix $A$ with\n$O(\\log(nd))$ bit entries, and would like to compress it in an arbitrary way to\nbuild a small space data structure $Q_p$, so that for any given $x \\in\n\\mathbb{R}^d$, with probability at least $2/3$, one has\n$Q_p(x)=(1\\pm\\epsilon)\\|Ax\\|_p$, where $p\\geq 0$, and where the randomness is\nover the construction of $Q_p$. The central question is: How many bits are\nnecessary to store $Q_p$?\n  This problem has applications to the communication of approximating the\nnumber of non-zeros in a matrix product, the size of coresets in projective\nclustering, the memory of streaming algorithms for regression in the row-update\nmodel, and embedding subspaces of $L_p$ in functional analysis. A major open\nquestion is the dependence on the approximation factor $\\epsilon$.\n  We show if $p\\geq 0$ is not a positive even integer and\n$d=\\Omega(\\log(1/\\epsilon))$, then $\\tilde{\\Omega}(\\epsilon^{-2}d)$ bits are\nnecessary. On the other hand, if $p$ is a positive even integer, then there is\nan upper bound of $O(d^p\\log(nd))$ bits independent of $\\epsilon$. Our results\nare optimal up to logarithmic factors, and show in particular that one cannot\ncompress $A$ to $O(d)$ \"directions\" $v_1,\\dots,v_{O(d)}$, such that for any\n$x$, $\\|Ax\\|_1$ can be well-approximated from $\\langle\nv_1,x\\rangle,\\dots,\\langle v_{O(d)},x\\rangle$. Our lower bound rules out\narbitrary functions of these inner products (and in fact arbitrary data\nstructures built from $A$), and thus rules out the possibility of a singular\nvalue decomposition for $\\ell_1$ in a very strong sense. Indeed, as\n$\\epsilon\\to 0$, for $p = 1$ the space complexity becomes arbitrarily large,\nwhile for $p = 2$ it is at most $O(d^2 \\log(nd))$. As corollaries of our main\nlower bound, we obtain new lower bounds for a wide range of applications,\nincluding the above, which in many cases are optimal.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 06:01:52 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 00:42:57 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 12:19:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Yi", ""], ["Wang", "Ruosong", ""], ["Woodruff", "David P.", ""]]}, {"id": "1904.05682", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr (\\'Ecole Polytechnique, CNRS, LIX) and Timo K\\\"otzing\n  (Hasso Plattner Institute)", "title": "Multiplicative Up-Drift", "comments": "Significantly extended version of: Benjamin Doerr and Timo K\\\"otzing.\n  Multiplicative up-drift. In Genetic and Evolutionary Computation Conference,\n  GECCO 2019, pages 1470-1478. ACM, 2019", "journal-ref": null, "doi": "10.1145/3321707.3321819", "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drift analysis aims at translating the expected progress of an evolutionary\nalgorithm (or more generally, a random process) into a probabilistic guarantee\non its run time (hitting time). So far, drift arguments have been successfully\nemployed in the rigorous analysis of evolutionary algorithms, however, only for\nthe situation that the progress is constant or becomes weaker when approaching\nthe target.\n  Motivated by questions like how fast fit individuals take over a population,\nwe analyze random processes exhibiting a $(1+\\delta)$-multiplicative growth in\nexpectation. We prove a drift theorem translating this expected progress into a\nhitting time. This drift theorem gives a simple and insightful proof of the\nlevel-based theorem first proposed by Lehre (2011). Our version of this theorem\nhas, for the first time, the best-possible near-linear dependence on $1/\\delta$\n(the previous results had an at least near-quadratic dependence), and it only\nrequires a population size near-linear in $\\delta$ (this was super-quadratic in\nprevious results). These improvements immediately lead to stronger run time\nguarantees for a number of applications.\n  We also discuss the case of large $\\delta$ and show stronger results for this\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 13:24:14 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:35:02 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 20:37:05 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 14:43:02 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Doerr", "Benjamin", "", "\u00c9cole Polytechnique, CNRS, LIX"], ["K\u00f6tzing", "Timo", "", "Hasso Plattner Institute"]]}, {"id": "1904.05961", "submitter": "Hanlin Lu", "authors": "Hanlin Lu, Ming-Ju Li, Ting He, Shiqiang Wang, Vijaykrishnan Narayanan\n  and Kevin S Chan", "title": "Robust Coreset Construction for Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreset, which is a summary of the original dataset in the form of a small\nweighted set in the same sample space, provides a promising approach to enable\nmachine learning over distributed data. Although viewed as a proxy of the\noriginal dataset, each coreset is only designed to approximate the cost\nfunction of a specific machine learning problem, and thus different coresets\nare often required to solve different machine learning problems, increasing the\ncommunication overhead. We resolve this dilemma by developing robust coreset\nconstruction algorithms that can support a variety of machine learning\nproblems. Motivated by empirical evidence that suitably-weighted k-clustering\ncenters provide a robust coreset, we harden the observation by establishing\ntheoretical conditions under which the coreset provides a guaranteed\napproximation for a broad range of machine learning problems, and developing\nboth centralized and distributed algorithms to generate coresets satisfying the\nconditions. The robustness of the proposed algorithms is verified through\nextensive experiments on diverse datasets with respect to both supervised and\nunsupervised learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 21:39:10 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 02:02:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 20:11:43 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lu", "Hanlin", ""], ["Li", "Ming-Ju", ""], ["He", "Ting", ""], ["Wang", "Shiqiang", ""], ["Narayanan", "Vijaykrishnan", ""], ["Chan", "Kevin S", ""]]}, {"id": "1904.05974", "submitter": "Yuri Faenza", "authors": "Yuri Faenza, Telikepalli Kavitha", "title": "Quasi-popular Matchings, Optimality, and Extended Formulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G = ((A,B),E) be an instance of the stable marriage problem where every\nvertex ranks its neighbors in a strict order of preference. A matching M in G\nis popular if M does not lose a head-to-head election against any matching.\nPopular matchings are a well-studied generalization of stable matchings,\nintroduced with the goal of enlarging the set of admissible solutions, while\nmaintaining a certain level of fairness. Every stable matching is a min-size\npopular matching. Unfortunately, when there are edge costs, it is NP-hard to\nfind a popular matching of minimum cost -- even worse, the min-cost popular\nmatching problem is hard to approximate up to any factor.\n  Let opt be the cost of a min-cost popular matching. Our goal is to\nefficiently compute a matching of cost at most opt by paying the price of\nmildly relaxing popularity. Our main positive results are two bi-criteria\nalgorithms that find in polynomial time a near-popular or quasi-popular\nmatching of cost at most opt. Moreover, one of the algorithms finds a\nquasi-popular matching of cost at most that of a min-cost popular fractional\nmatching, which could be much smaller than opt.\n  Key to the other algorithm is a polynomial-size extended formulation for an\nintegral polytope sandwiched between the popular and quasi-popular matching\npolytopes. We complement these results by showing that it is NP-hard to find a\nquasi-popular matching of minimum cost, and that both the popular and\nquasi-popular matching polytopes have near-exponential extension complexity.\n  This version of the paper goes beyond the conference version [12] in the\nfollowing two points: (i) the algorithm for finding a quasi-popular matching of\ncost at most that of a min-cost popular fractional matching is new; (ii) the\nproofs from Section 6.1 and Section 7.3 are now self-contained (the conference\nversion used constructions from [10] to show these lower bounds).\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 22:33:03 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 05:34:20 GMT"}, {"version": "v3", "created": "Thu, 11 Jul 2019 00:01:33 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 19:29:59 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 04:08:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Faenza", "Yuri", ""], ["Kavitha", "Telikepalli", ""]]}, {"id": "1904.05995", "submitter": "Shelby Kimmel", "authors": "Kai DeLorenzo, Shelby Kimmel, R. Teal Witter", "title": "Applications of the quantum algorithm for st-connectivity", "comments": null, "journal-ref": "TQC 2019", "doi": "10.4230/LIPIcs.TQC.2019.6", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present quantum algorithms for various problems related to graph\nconnectivity. We give simple and query-optimal algorithms for cycle detection\nand odd-length cycle detection (bipartiteness) using a reduction to\nst-connectivity. Furthermore, we show that our algorithm for cycle detection\nhas improved performance under the promise of large circuit rank or a small\nnumber of edges. We also provide algorithms for detecting even-length cycles\nand for estimating the circuit rank of a graph. All of our algorithms have\nlogarithmic space complexity.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 00:56:28 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["DeLorenzo", "Kai", ""], ["Kimmel", "Shelby", ""], ["Witter", "R. Teal", ""]]}, {"id": "1904.06012", "submitter": "Archit Kulkarni", "authors": "Jorge Garza-Vargas, Archit Kulkarni", "title": "The Lanczos Algorithm Under Few Iterations: Concentration and Location\n  of the Output", "comments": "v2: A detailed discussion of the motivation and relevance of the main\n  results and definitions has been added. Minor corrections have been made. 38\n  pages, 3 figures", "journal-ref": "SIAM Journal on Matrix Analysis and Applications (2020), 41(3),\n  1312-1346", "doi": "10.1137/19M1275231", "report-no": null, "categories": "math.NA cs.DS cs.NA math.FA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Lanczos algorithm where the initial vector is sampled uniformly\nfrom $\\mathbb{S}^{n-1}$. Let $A$ be an $n \\times n$ Hermitian matrix. We show\nthat when run for few iterations, the output of Lanczos on $A$ is almost\ndeterministic. More precisely, we show that for any $ \\varepsilon \\in (0, 1)$\nthere exists $c >0$ depending only on $\\varepsilon$ and a certain global\nproperty of the spectrum of $A$ (in particular, not depending on $n$) such that\nwhen Lanczos is run for at most $c \\log n$ iterations, the output Jacobi\ncoefficients deviate from their medians by $t$ with probability at most\n$\\exp(-n^\\varepsilon t^2)$ for $t<\\Vert A \\Vert$. We directly obtain a similar\nresult for the Ritz values and vectors. Our techniques also yield asymptotic\nresults: Suppose one runs Lanczos on a sequence of Hermitian matrices $A_n \\in\nM_n(\\mathbb{C})$ whose spectral distributions converge in Kolmogorov distance\nwith rate $O(n^{-\\varepsilon})$ to a density $\\mu$ for some $\\varepsilon > 0$.\nThen we show that for large enough $n$, and for $k=O(\\sqrt{\\log n})$, the\nJacobi coefficients output after $k$ iterations concentrate around those for\n$\\mu$. The asymptotic setting is relevant since Lanczos is often used to\napproximate the spectral density of an infinite-dimensional operator by way of\nthe Jacobi coefficients; our result provides some theoretical justification for\nthis approach.\n  In a different direction, we show that Lanczos fails with high probability to\nidentify outliers of the spectrum when run for at most $c' \\log n$ iterations,\nwhere again $c'$ depends only on the same global property of the spectrum of\n$A$. Classical results imply that the bound $c' \\log n$ is tight up to a\nconstant factor.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 02:37:06 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 01:40:06 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Garza-Vargas", "Jorge", ""], ["Kulkarni", "Archit", ""]]}, {"id": "1904.06141", "submitter": "Fahad Panolan", "authors": "Fedor V. Fomin, Petr A. Golovach, Fahad Panolan, Kirill Simonov", "title": "Low-rank binary matrix approximation in column-sum norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider $\\ell_1$-Rank-$r$ Approximation over GF(2), where for a binary\n$m\\times n$ matrix ${\\bf A}$ and a positive integer $r$, one seeks a binary\nmatrix ${\\bf B}$ of rank at most $r$, minimizing the column-sum norm $||{\\bf A}\n-{\\bf B}||_1$. We show that for every $\\varepsilon\\in (0, 1)$, there is a\nrandomized $(1+\\varepsilon)$-approximation algorithm for $\\ell_1$-Rank-$r$\nApproximation over GF(2) of running time $m^{O(1)}n^{O(2^{4r}\\cdot\n\\varepsilon^{-4})}$. This is the first polynomial time approximation scheme\n(PTAS) for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 10:04:58 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Panolan", "Fahad", ""], ["Simonov", "Kirill", ""]]}, {"id": "1904.06150", "submitter": "Uwe Schwiegelshohn", "authors": "Chris Schwiegelshohn (Sapienza, University of Rome, Italy) and Uwe\n  Schwiegelshohn (TU Dortmund University, Germany)", "title": "Maximizing Online Utilization with Commitment", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate online scheduling with commitment for parallel identical\nmachines. Our objective is to maximize the total processing time of accepted\njobs. As soon as a job has been submitted, the commitment constraint forces us\nto decide immediately whether we accept or reject the job. Upon acceptance of a\njob, we must complete it before its deadline $d$ that satisfies $d \\geq\n(1+\\epsilon)\\cdot p + r$, with $p$ and $r$ being the processing time and the\nsubmission time of the job, respectively while $\\epsilon>0$ is the slack of the\nsystem. Since the hard case typically arises for near-tight deadlines, we\nconsider $\\varepsilon\\leq 1$. We use competitive analysis to evaluate our\nalgorithms. Our first main contribution is a deterministic preemptive online\nalgorithm with an almost tight competitive ratio on any number of machines. For\na single machine, the competitive factor matches the optimal bound\n$\\frac{1+\\epsilon}{\\epsilon}$ of the greedy acceptance policy. Then the\ncompetitive ratio improves with an increasing number of machines and approaches\n$(1+\\epsilon)\\cdot\\ln \\frac{1+\\epsilon}{\\epsilon}$ as the number of machines\nconverges to infinity. This is an exponential improvement over the greedy\nacceptance policy for small $\\epsilon$. In the non-preemptive case, we present\na deterministic algorithm on $m$ machines with a competitive ratio of $1+m\\cdot\n\\left(\\frac{1+\\epsilon}{\\epsilon}\\right)^{\\frac{1}{m}}$. This matches the\noptimal bound of $2+\\frac{1}{\\epsilon}$ of the greedy acceptance policy for a\nsingle machine while it again guarantees an exponential improvement over the\ngreedy acceptance policy for small $\\epsilon$ and large $m$. In addition, we\ndetermine an almost tight lower bound that approaches $m\\cdot\n\\left(\\frac{1}{\\epsilon}\\right)^{\\frac{1}{m}}$ for large $m$ and small\n$\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 10:39:07 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Schwiegelshohn", "Chris", "", "Sapienza, University of Rome, Italy"], ["Schwiegelshohn", "Uwe", "", "TU Dortmund University, Germany"]]}, {"id": "1904.06184", "submitter": "Takehiro Ito", "authors": "Marthe Bonamy, Nicolas Bousquet, Marc Heinrich, Takehiro Ito, Yusuke\n  Kobayashi, Arnaud Mary, Moritz M\\\"uhlenthaler, Kunihiro Wasa", "title": "The Perfect Matching Reconfiguration Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the perfect matching reconfiguration problem: Given two perfect\nmatchings of a graph, is there a sequence of flip operations that transforms\none into the other? Here, a flip operation exchanges the edges in an\nalternating cycle of length four. We are interested in the complexity of this\ndecision problem from the viewpoint of graph classes. We first prove that the\nproblem is PSPACE-complete even for split graphs and for bipartite graphs of\nbounded bandwidth with maximum degree five. We then investigate polynomial-time\nsolvable cases. Specifically, we prove that the problem is solvable in\npolynomial time for strongly orderable graphs (that include interval graphs and\nstrongly chordal graphs), for outerplanar graphs, and for cographs (also known\nas $P_4$-free graphs). Furthermore, for each yes-instance from these graph\nclasses, we show that a linear number of flip operations is sufficient and we\ncan exhibit a corresponding sequence of flip operations in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 12:22:24 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Bonamy", "Marthe", ""], ["Bousquet", "Nicolas", ""], ["Heinrich", "Marc", ""], ["Ito", "Takehiro", ""], ["Kobayashi", "Yusuke", ""], ["Mary", "Arnaud", ""], ["M\u00fchlenthaler", "Moritz", ""], ["Wasa", "Kunihiro", ""]]}, {"id": "1904.06455", "submitter": "Panagiotis (Panos P.) Markopoulos", "authors": "Dimitris G. Chachlakis, Ashley Prater-Bennette, and Panos P.\n  Markopoulos", "title": "L1-norm Tucker Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tucker decomposition is a common method for the analysis of multi-way/tensor\ndata. Standard Tucker has been shown to be sensitive against heavy corruptions,\ndue to its L2-norm-based formulation which places squared emphasis to\nperipheral entries. In this work, we explore L1-Tucker, an L1-norm based\nreformulation of standard Tucker decomposition. After formulating the problem,\nwe present two algorithms for its solution, namely L1-norm Higher-Order\nSingular Value Decomposition (L1-HOSVD) and L1-norm Higher-Order Orthogonal\nIterations (L1-HOOI). The presented algorithms are accompanied by complexity\nand convergence analysis. Our numerical studies on tensor reconstruction and\nclassification corroborate that L1-Tucker, implemented by means of the proposed\nmethods, attains similar performance to standard Tucker when the processed data\nare corruption-free, while it exhibits sturdy resistance against heavily\ncorrupted entries.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 00:35:22 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Chachlakis", "Dimitris G.", ""], ["Prater-Bennette", "Ashley", ""], ["Markopoulos", "Panos P.", ""]]}, {"id": "1904.06543", "submitter": "Sebastian Berndt", "authors": "Sebastian Berndt, Leah Epstein, Klaus Jansen, Asaf Levin, Marten\n  Maack, Lars Rohwedder", "title": "Online Bin Covering with Limited Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-online models where decisions may be revoked in a limited way have been\nstudied extensively in the last years.\n  This is motivated by the fact that the pure online model is often too\nrestrictive to model real-world applications, where some changes might be\nallowed. A well-studied measure of the amount of decisions that can be revoked\nis the migration factor $\\beta$: When an object $o$ of size $s(o)$ arrives, the\ndecisions for objects of total size at most $\\beta\\cdot s(o)$ may be revoked.\nUsually $\\beta$ should be a constant. This means that a small object only leads\nto small changes. This measure has been successfully investigated for\ndifferent, classic problems such as bin packing or makespan minimization. The\ndual of makespan minimization - the Santa Claus or machine covering problem -\nhas also been studied, whereas the dual of bin packing - the bin covering\nproblem - has not been looked at from such a perspective.\n  In this work, we extensively study the bin covering problem with migration in\ndifferent scenarios. We develop algorithms both for the static case - where\nonly insertions are allowed - and for the dynamic case, where items may also\ndepart. We also develop lower bounds for these scenarios both for amortized\nmigration and for worst-case migration showing that our algorithms have nearly\noptimal migration factor and asymptotic competitive ratio (up to an arbitrary\nsmall $\\eps$). We therefore resolve the competitiveness of the bin covering\nproblem with migration.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 13:10:16 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Berndt", "Sebastian", ""], ["Epstein", "Leah", ""], ["Jansen", "Klaus", ""], ["Levin", "Asaf", ""], ["Maack", "Marten", ""], ["Rohwedder", "Lars", ""]]}, {"id": "1904.06738", "submitter": "Chiranjib Bhattacharyya", "authors": "Chiranjib Bhattacharyya and Ravindran Kannan", "title": "Finding a latent k-simplex in O(k . nnz(data)) time via Subset Smoothing", "comments": "Added more discussion of special cases. The assumptions are also\n  modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that a large class of Latent variable models, such as\nMixed Membership Stochastic Block(MMSB) Models, Topic Models, and Adversarial\nClustering, can be unified through a geometric perspective, replacing model\nspecific assumptions and algorithms for individual models. The geometric\nperspective leads to the formulation: \\emph{find a latent $k-$ polytope $K$ in\n${\\bf R}^d$ given $n$ data points, each obtained by perturbing a latent point\nin $K$}. This problem does not seem to have been considered in the literature.\nThe most important contribution of this paper is to show that the latent\n$k-$polytope problem admits an efficient algorithm under deterministic\nassumptions which naturally hold in Latent variable models considered in this\npaper. ur algorithm runs in time $O^*(k\\; \\mbox{nnz})$ matching the best\nrunning time of algorithms in special cases considered here and is better when\nthe data is sparse, as is the case in applications. An important novelty of the\nalgorithm is the introduction of \\emph{subset smoothed polytope}, $K'$, the\nconvex hull of the ${n\\choose \\delta n}$ points obtained by averaging all\n$\\delta n$ subsets of the data points, for a given $\\delta \\in (0,1)$. We show\nthat $K$ and $K'$ are close in Hausdroff distance. Among the consequences of\nour algorithm are the following: (a) MMSB Models and Topic Models: the first\nquasi-input-sparsity time algorithm for parameter estimation for $k \\in\nO^*(1)$, (b) Adversarial Clustering: In $k-$means, if, an adversary is allowed\nto move many data points from each cluster an arbitrary amount towards the\nconvex hull of the centers of other clusters, our algorithm still estimates\ncluster centers well.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 18:29:13 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 23:30:28 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 16:41:12 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 06:51:19 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Bhattacharyya", "Chiranjib", ""], ["Kannan", "Ravindran", ""]]}, {"id": "1904.06745", "submitter": "Arsen Vasilyan", "authors": "Ronitt Rubinfeld, Arsen Vasilyan", "title": "Approximating the noise sensitivity of a monotone Boolean function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noise sensitivity of a Boolean function $f: \\{0,1\\}^n \\rightarrow\n\\{0,1\\}$ is one of its fundamental properties. A function of a positive noise\nparameter $\\delta$, it is denoted as $NS_{\\delta}[f]$. Here we study the\nalgorithmic problem of approximating it for monotone $f$, such that\n$NS_{\\delta}[f] \\geq 1/n^{C}$ for constant $C$, and where $\\delta$ satisfies\n$1/n \\leq \\delta \\leq 1/2$. For such $f$ and $\\delta$, we give a randomized\nalgorithm performing $O\\left(\\frac{\\min(1,\\sqrt{n} \\delta \\log^{1.5} n)\n}{NS_{\\delta}[f]} \\text{poly}\\left(\\frac{1}{\\epsilon}\\right)\\right)$ queries\nand approximating $NS_{\\delta}[f]$ to within a multiplicative factor of $(1\\pm\n\\epsilon)$. Given the same constraints on $f$ and $\\delta$, we also prove a\nlower bound of $\\Omega\\left(\\frac{\\min(1,\\sqrt{n} \\delta)}{NS_{\\delta}[f] \\cdot\nn^{\\xi}}\\right)$ on the query complexity of any algorithm that approximates\n$NS_{\\delta}[f]$ to within any constant factor, where $\\xi$ can be any positive\nconstant. Thus, our algorithm's query complexity is close to optimal in terms\nof its dependence on $n$.\n  We introduce a novel descending-ascending view of noise sensitivity, and use\nit as a central tool for the analysis of our algorithm. To prove lower bounds\non query complexity, we develop a technique that reduces computational\nquestions about query complexity to combinatorial questions about the existence\nof \"thin\" functions with certain properties. The existence of such \"thin\"\nfunctions is proved using the probabilistic method. These techniques also yield\npreviously unknown lower bounds on the query complexity of approximating other\nfundamental properties of Boolean functions: the total influence and the bias.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 19:37:05 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Rubinfeld", "Ronitt", ""], ["Vasilyan", "Arsen", ""]]}, {"id": "1904.06874", "submitter": "Miriam Schl\\\"oter", "authors": "Joseph Paat, Miriam Schl\\\"oter, Robert Weismantel", "title": "The Integrality Number of an Integer Program", "comments": "This is a preprint of an article published in Mathematical\n  Programming. The final authenticated version is available online at:\n  https://doi.org/10.1007/s10107-021-01651-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the integrality number of an integer program (IP) in inequality\nform. Roughly speaking, the integrality number is the smallest number of\ninteger constraints needed to solve an IP via a mixed integer (MIP) relaxation.\nOne notable property of this number is its invariance under unimodular\ntransformations of the constraint matrix. Considering the largest minor\n$\\Delta$ of the constraint matrix, our analysis allows us to make statements of\nthe following form: there exist numbers $\\tau(\\Delta)$ and $\\kappa(\\Delta)$\nsuch that an IP with $n\\geq \\tau(\\Delta)$ many variables and $n +\n\\kappa(\\Delta)\\cdot \\sqrt{n}$ many inequality constraints can be solved via a\nMIP relaxation with fewer than $n$ integer constraints. From our results it\nfollows that IPs defined by only $n$ constraints can be solved via a MIP\nrelaxation with $O(\\sqrt{\\Delta})$ many integer constraints.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 06:43:10 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 15:14:07 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 11:59:05 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 14:28:52 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 12:28:02 GMT"}, {"version": "v6", "created": "Wed, 7 Apr 2021 05:19:57 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Paat", "Joseph", ""], ["Schl\u00f6ter", "Miriam", ""], ["Weismantel", "Robert", ""]]}, {"id": "1904.07131", "submitter": "Noam Touitou", "authors": "Yossi Azar, Noam Touitou", "title": "General Framework for Metric Optimization Problems with Delay or with\n  Deadlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework used to construct and analyze\nalgorithms for online optimization problems with deadlines or with delay over a\nmetric space. Using this framework, we present algorithms for several different\nproblems. We present an $O(D^{2})$-competitive deterministic algorithm for\nonline multilevel aggregation with delay on a tree of depth $D$, an exponential\nimprovement over the $O(D^{4}2^{D})$-competitive algorithm of Bienkowski et al.\n(ESA '16), where the only previously-known improvement was for the special case\nof deadlines by Buchbinder et al. (SODA '17). We also present an\n$O(\\log^{2}n)$-competitive randomized algorithm for online service with delay\nover any general metric space of $n$ points, improving upon the\n$O(\\log^{4}n)$-competitive algorithm by Azar et al. (STOC '17). In addition, we\npresent the problem of online facility location with deadlines. In this\nproblem, requests arrive over time in a metric space, and need to be served\nuntil their deadlines by facilities that are opened momentarily for some cost.\nWe also consider the problem of facility location with delay, in which the\ndeadlines are replaced with arbitrary delay functions. For those problems, we\npresent $O(\\log^{2}n)$-competitive algorithms, with $n$ the number of points in\nthe metric space. The algorithmic framework we present includes techniques for\nthe design of algorithms as well as techniques for their analysis.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 15:36:20 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Azar", "Yossi", ""], ["Touitou", "Noam", ""]]}, {"id": "1904.07174", "submitter": "Ilias Zadik", "authors": "David Gamarnik and Ilias Zadik", "title": "The Landscape of the Planted Clique Problem: Dense subgraphs and the\n  Overlap Gap Property", "comments": "70 pages, 3 Figures. Added Figure 1 (phase diagram), and a new result\n  proving that the OGP implies the failure of an MCMC family to recover the\n  planted clique", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG math.OC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computational-statistical gap of the planted\nclique problem, where a clique of size $k$ is planted in an Erdos Renyi graph\n$G(n,\\frac{1}{2})$ resulting in a graph $G\\left(n,\\frac{1}{2},k\\right)$. The\ngoal is to recover the planted clique vertices by observing\n$G\\left(n,\\frac{1}{2},k\\right)$ . It is known that the clique can be recovered\nas long as $k \\geq \\left(2+\\epsilon\\right)\\log n $ for any $\\epsilon>0$, but no\npolynomial-time algorithm is known for this task unless $k=\\Omega\\left(\\sqrt{n}\n\\right)$. Following a statistical-physics inspired point of view as an attempt\nto understand this computational-statistical gap, we study the landscape of the\n\"sufficiently dense\" subgraphs of $G$ and their overlap with the planted\nclique.\n  Using the first moment method, we study the densest subgraph problems for\nsubgraphs with fixed, but arbitrary, overlap size with the planted clique, and\nprovide evidence of a phase transition for the presence of Overlap Gap Property\n(OGP) at $k=\\Theta\\left(\\sqrt{n}\\right)$. OGP is a concept introduced\noriginally in spin glass theory and known to suggest algorithmic hardness when\nit appears. We establish the presence of OGP when $k$ is a small positive power\nof $n$ by using a conditional second moment method. As our main technical tool,\nwe establish the first, to the best of our knowledge, concentration results for\nthe $K$-densest subgraph problem for the Erdos-Renyi model\n$G\\left(n,\\frac{1}{2}\\right)$ when $K=n^{0.5-\\epsilon}$ for arbitrary\n$\\epsilon>0$. Finally, to study the OGP we employ a certain form of\noverparametrization, which is conceptually aligned with a large body of recent\nwork in learning theory and optimization.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:44:00 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 10:56:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gamarnik", "David", ""], ["Zadik", "Ilias", ""]]}, {"id": "1904.07234", "submitter": "Gregory Gutin", "authors": "Jason Crampton, Gregory Gutin, Diptapriyo Majumdar", "title": "Bounded and Approximate Strong Satisfiability in Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a considerable amount of interest in recent years in the\nproblem of workflow satisfiability, which asks whether the existence of\nconstraints in a workflow specification makes it impossible to allocate\nauthorized users to each step in the workflow. Recent developments have seen\nthe workflow satisfiability problem (WSP) studied in the context of workflow\nspecifications in which the set of steps may vary from one instance of the\nworkflow to another. This, in turn, means that some constraints may only apply\nto certain workflow instances. Inevitably, WSP becomes more complex for such\nworkflow specifications. Other approaches have considered the possibility of\nassociating costs with the violation of `soft' constraints and authorizations.\nWorkflow satisfiability in this context becomes a question of minimizing the\ncost of allocating users to steps in the workflow. In this paper, we introduce\nnew problems, which we believe to be of practical relevance, that combine these\napproaches. In particular, we consider the question of whether, given a\nworkflow specification with costs and a `budget', all possible workflow\ninstances have an allocation of users to steps that does not exceed the budget.\nWe design a fixed-parameter tractable algorithm to solve this problem\nparameterized by the total number of steps, release points and xor branchings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:29:06 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory", ""], ["Majumdar", "Diptapriyo", ""]]}, {"id": "1904.07262", "submitter": "Francesco Bonchi", "authors": "Francesco Bonchi and Arijit Khan and Lorenzo Severini", "title": "Distance-generalized Core Decomposition", "comments": null, "journal-ref": "Proceedings of SIGMOD 2019", "doi": "10.1145/3299869.3324962", "report-no": null, "categories": "cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-core of a graph is defined as the maximal subgraph in which every\nvertex is connected to at least $k$ other vertices within that subgraph. In\nthis work we introduce a distance-based generalization of the notion of\n$k$-core, which we refer to as the $(k,h)$-core, i.e., the maximal subgraph in\nwhich every vertex has at least $k$ other vertices at distance $\\leq h$ within\nthat subgraph. We study the properties of the $(k,h)$-core showing that it\npreserves many of the nice features of the classic core decomposition (e.g.,\nits connection with the notion of distance-generalized chromatic number) and it\npreserves its usefulness to speed-up or approximate distance-generalized\nnotions of dense structures, such as $h$-club.\n  Computing the distance-generalized core decomposition over large networks is\nintrinsically complex. However, by exploiting clever upper and lower bounds we\ncan partition the computation in a set of totally independent subcomputations,\nopening the door to top-down exploration and to multithreading, and thus\nachieving an efficient algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 18:01:04 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Bonchi", "Francesco", ""], ["Khan", "Arijit", ""], ["Severini", "Lorenzo", ""]]}, {"id": "1904.07271", "submitter": "Xiangkun Shen", "authors": "Anupam Gupta, Amit Kumar, Viswanath Nagarajan, Xiangkun Shen", "title": "Stochastic Load Balancing on Unrelated Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of makespan minimization on unrelated machines when\njob sizes are stochastic. The goal is to find a fixed assignment of jobs to\nmachines, to minimize the expected value of the maximum load over all the\nmachines. For the identical machines special case when the size of a job is the\nsame across all machines, a constant-factor approximation algorithm has long\nbeen known. Our main result is the first constant-factor approximation\nalgorithm for the general case of unrelated machines. This is achieved by (i)\nformulating a lower bound using an exponential-size linear program that is\nefficiently computable, and (ii) rounding this linear program while satisfying\nonly a specific subset of the constraints that still suffice to bound the\nexpected makespan. We also consider two generalizations. The first is the\nbudgeted makespan minimization problem, where the goal is to minimize the\nexpected makespan subject to scheduling a target number (or reward) of jobs. We\nextend our main result to obtain a constant-factor approximation algorithm for\nthis problem. The second problem involves $q$-norm objectives, where we want to\nminimize the expected q-norm of the machine loads. Here we give an $O(q/\\log\nq)$-approximation algorithm, which is a constant-factor approximation for any\nfixed $q$.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 18:16:37 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Gupta", "Anupam", ""], ["Kumar", "Amit", ""], ["Nagarajan", "Viswanath", ""], ["Shen", "Xiangkun", ""]]}, {"id": "1904.07272", "submitter": "Aleksandrs Slivkins", "authors": "Aleksandrs Slivkins", "title": "Introduction to Multi-Armed Bandits", "comments": "Published with Foundations and Trends(R) in Machine Learning,\n  November 2019. The present version is a revision of the \"Foundations and\n  Trends\" publication. It contains numerous edits for presentation and accuracy\n  (based in part on readers' feedback), updated and expanded literature\n  reviews, and some new exercises", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandits a simple but very powerful framework for algorithms that\nmake decisions over time under uncertainty. An enormous body of work has\naccumulated over the years, covered in several books and surveys. This book\nprovides a more introductory, textbook-like treatment of the subject. Each\nchapter tackles a particular line of work, providing a self-contained,\nteachable technical introduction and a brief review of the further\ndevelopments; many of the chapters conclude with exercises.\n  The book is structured as follows. The first four chapters are on IID\nrewards, from the basic model to impossibility results to Bayesian priors to\nLipschitz rewards. The next three chapters cover adversarial rewards, from the\nfull-feedback version to adversarial bandits to extensions with linear rewards\nand combinatorially structured actions. Chapter 8 is on contextual bandits, a\nmiddle ground between IID and adversarial bandits in which the change in reward\ndistributions is completely explained by observable contexts. The last three\nchapters cover connections to economics, from learning in repeated games to\nbandits with supply/budget constraints to exploration in the presence of\nincentives. The appendix provides sufficient background on concentration and\nKL-divergence.\n  The chapters on \"bandits with similarity information\", \"bandits with\nknapsacks\" and \"bandits and agents\" can also be consumed as standalone surveys\non the respective topics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 18:17:01 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 20:45:01 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 14:39:03 GMT"}, {"version": "v4", "created": "Sun, 15 Sep 2019 02:06:22 GMT"}, {"version": "v5", "created": "Mon, 30 Sep 2019 00:15:42 GMT"}, {"version": "v6", "created": "Sat, 26 Jun 2021 20:15:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Slivkins", "Aleksandrs", ""]]}, {"id": "1904.07358", "submitter": "Andreas B\\\"artschi", "authors": "Andreas B\\\"artschi and Stephan Eidenbenz", "title": "Deterministic Preparation of Dicke States", "comments": null, "journal-ref": "22nd International Symposium on Fundamentals of Computation\n  Theory, FCT'19, 126-139, 2019", "doi": "10.1007/978-3-030-25027-0_9", "report-no": "LA-UR-19-22718", "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dicke state $|D_k^n\\rangle$ is an equal-weight superposition of all\n$n$-qubit states with Hamming Weight $k$ (i.e. all strings of length $n$ with\nexactly $k$ ones over a binary alphabet). Dicke states are an important class\nof entangled quantum states that among other things serve as starting states\nfor combinatorial optimization quantum algorithms.\n  We present a deterministic quantum algorithm for the preparation of Dicke\nstates. Implemented as a quantum circuit, our scheme uses $O(kn)$ gates, has\ndepth $O(n)$ and needs no ancilla qubits. The inductive nature of our approach\nallows for linear-depth preparation of arbitrary symmetric pure states and --\nused in reverse -- yields a quasilinear-depth circuit for efficient compression\nof quantum information in the form of symmetric pure states, improving on\nexisting work requiring quadratic depth. All of these properties even hold for\nLinear Nearest Neighbor architectures.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 23:05:53 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["B\u00e4rtschi", "Andreas", ""], ["Eidenbenz", "Stephan", ""]]}, {"id": "1904.07381", "submitter": "Chaitanya Swamy", "authors": "Andre Linhares and Chaitanya Swamy", "title": "Approximation Algorithms for Distributionally Robust Stochastic\n  Optimization with Black-Box Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-stage stochastic optimization is a framework for modeling uncertainty,\nwhere we have a probability distribution over possible realizations of the\ndata, called scenarios, and decisions are taken in two stages: we make\nfirst-stage decisions knowing only the underlying distribution and before a\nscenario is realized, and may take additional second-stage recourse actions\nafter a scenario is realized. The goal is typically to minimize the total\nexpected cost. A criticism of this model is that the underlying probability\ndistribution is itself often imprecise! To address this, a versatile approach\nthat has been proposed is the {\\em distributionally robust 2-stage model}:\ngiven a collection of probability distributions, our goal now is to minimize\nthe maximum expected total cost with respect to a distribution in this\ncollection.\n  We provide a framework for designing approximation algorithms in such\nsettings when the collection is a ball around a central distribution and the\ncentral distribution is accessed {\\em only via a sampling black box}.\n  We first show that one can utilize the {\\em sample average approximation}\n(SAA) method to reduce the problem to the case where the central distribution\nhas {\\em polynomial-size} support. We then show how to approximately solve a\nfractional relaxation of the SAA (i.e., polynomial-scenario\ncentral-distribution) problem. By complementing this via LP-rounding algorithms\nthat provide {\\em local} (i.e., per-scenario) approximation guarantees, we\nobtain the {\\em first} approximation algorithms for the distributionally robust\nversions of a variety of discrete-optimization problems including set cover,\nvertex cover, edge cover, facility location, and Steiner tree, with guarantees\nthat are, except for set cover, within $O(1)$-factors of the guarantees known\nfor the deterministic version of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 00:35:23 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Linhares", "Andre", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1904.07388", "submitter": "Stanislav Zivny", "authors": "Clement Carbonnel, Miguel Romero, Stanislav Zivny", "title": "Point-width and Max-CSPs", "comments": "Full version of a LICS'19 paper", "journal-ref": "ACM Transactions on Algorithms 16(4) Article no. 54 (2020)", "doi": "10.1145/3329862", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of (unbounded-arity) Max-CSPs under structural restrictions is\npoorly understood. The two most general hypergraph properties known to ensure\ntractability of Max-CSPs, $\\beta$-acyclicity and bounded (incidence) MIM-width,\nare incomparable and lead to very different algorithms.\n  We introduce the framework of point decompositions for hypergraphs and use it\nto derive a new sufficient condition for the tractability of (structurally\nrestricted) Max-CSPs, which generalises both bounded MIM-width and\n\\b{eta}-acyclicity. On the way, we give a new characterisation of bounded\nMIM-width and discuss other hypergraph properties which are relevant to the\ncomplexity of Max-CSPs, such as $\\beta$-hypertreewidth.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:10:13 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 17:57:23 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Carbonnel", "Clement", ""], ["Romero", "Miguel", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1904.07467", "submitter": "Dominik K\\\"oppl", "authors": "Kazuya Tsuruta and Dominik K\\\"oppl and Shunsuke Kanda and Yuto\n  Nakashima and Shunsuke Inenaga and Hideo Bannai and Masayuki Takeda", "title": "c-trie++: A Dynamic Trie Tailored for Fast Prefix Searches", "comments": null, "journal-ref": "Full version of conference paper at DCC, pages 243-252, 2020", "doi": "10.1109/DCC47342.2020.00032", "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dynamic set $K$ of $k$ strings of total length $n$ whose characters\nare drawn from an alphabet of size $\\sigma$, a keyword dictionary is a data\nstructure built on $K$ that provides locate, prefix search, and update\noperations on $K$. Under the assumption that $\\alpha = w / \\lg \\sigma$\ncharacters fit into a single machine word $w$, we propose a keyword dictionary\nthat represents $K$ in $n \\lg \\sigma + \\Theta(k \\lg n)$ bits of space,\nsupporting all operations in $O(m / \\alpha + \\lg \\alpha)$ expected time on an\ninput string of length $m$ in the word RAM model. This data structure is\nunderlined with an exhaustive practical evaluation, highlighting the practical\nusefulness of the proposed data structure, especially for prefix searches - one\nof the most elementary keyword dictionary operations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 05:20:47 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 07:37:22 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 07:43:59 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Tsuruta", "Kazuya", ""], ["K\u00f6ppl", "Dominik", ""], ["Kanda", "Shunsuke", ""], ["Nakashima", "Yuto", ""], ["Inenaga", "Shunsuke", ""], ["Bannai", "Hideo", ""], ["Takeda", "Masayuki", ""]]}, {"id": "1904.07683", "submitter": "Andreas Rosowski", "authors": "Andreas Rosowski", "title": "Fast Commutative Matrix Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the product of an nx3 matrix and a 3x3 matrix over a commutative\nring can be computed using 6n+3 multiplications. For two 3x3 matrices this\ngives us an algorithm using 21 multiplications. This is an improvement with\nrespect to Makarov's algorithm using 22 multiplications[13]. We generalize our\nresult for nx3 and 3x3 matrices and present an algorithm for computing the\nproduct of an lxn matrix and an nxm matrix over a commutative ring for odd n\nusing n(lm+l+m-1)/2 multiplications if m is odd and using (n(lm+l+m-1)+l-1)/2\nmultiplications if m is even. Waksman's and Islam's algorithm for odd n needs\n(n-1)(lm+l+m-1)/2+lm multiplications [10,19], thus in both cases less\nmultiplications are required by our algorithm. We also give an algorithm for\neven n using n(lm+l+m-1)/2 multiplications without making use of divisions,\nsince Waksman's and Islam's algorithm make use of some divisions by 2 [10,19].\nFurthermore we present a novelty for matrix multiplication: In this paper we\nshow that some non-bilinear algorithms with special properties can be used as\nrecursive algorithms. In comparison to bilinear algorithms for small nxn\nmatrices say n<20 we obtain some better results. From these non-bilinear\nalgorithms we finally obtain approximate non-bilinear algorithms. For instance\nwe obtain an approximate non-bilinear algorithm for 5x5 matrices that uses only\n89 multiplications. If at all it is possible to compare this algorithm with a\nbilinear algorithm we obtain a better result with respect to Smirnov's\nalgorithm [15].\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:05:49 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 06:22:54 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Rosowski", "Andreas", ""]]}, {"id": "1904.07700", "submitter": "Patrick Erik Bradley", "authors": "Patrick Erik Bradley, Markus Wilhelm Jahn", "title": "p-Adic scaled space filling curve indices for high dimensional data", "comments": "34 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space filling curves are widely used in Computer Science. In particular\nHilbert curves and their generalisations to higher dimension are used as an\nindexing method because of their nice locality properties. This article\ngeneralises this concept to the systematic construction of p-adic versions of\nHilbert curves based on affine transformations of the p-adic Gray code, and\ndevelops an efficient scaled indexing method for data taken from\nhigh-dimensional spaces based on these new curves, which with increasing\ndimension is shown to be less space consuming than the optimal standard static\nHilbert curve index. A measure is derived which allows to assess the local\nsparsity of a data set, and is tested on some data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:17:13 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Bradley", "Patrick Erik", ""], ["Jahn", "Markus Wilhelm", ""]]}, {"id": "1904.07764", "submitter": "Wensheng Gan", "authors": "Wensheng Gan, Jerry Chun-Wei Lin, Jiexiong Zhang, Han-Chieh Chao,\n  Hamido Fujita and Philip S. Yu", "title": "ProUM: Projection-based Utility Mining on Sequence Data", "comments": "Elsevier Information Science, 17 pages, 4 figures", "journal-ref": "Information Science, 2020", "doi": "10.1016/j.ins.2019.10.033", "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utility is an important concept in economics. A variety of applications\nconsider utility in real-life situations, which has lead to the emergence of\nutility-oriented mining (also called utility mining) in the recent decade.\nUtility mining has attracted a great amount of attention, but most of the\nexisting studies have been developed to deal with itemset-based data.\nTime-ordered sequence data is more commonly seen in real-world situations,\nwhich is different from itemset-based data. Since they are time-consuming and\nrequire large amount of memory usage, current utility mining algorithms still\nhave limitations when dealing with sequence data. In addition, the mining\nefficiency of utility mining on sequence data still needs to be improved,\nespecially for long sequences or when there is a low minimum utility threshold.\nIn this paper, we propose an efficient Projection-based Utility Mining (ProUM)\napproach to discover high-utility sequential patterns from sequence data. The\nutility-array structure is designed to store the necessary information of the\nsequence-order and utility. ProUM can significantly improve the mining\nefficiency by utilizing the projection technique in generating utility-array,\nand it effectively reduces the memory consumption. Furthermore, a new upper\nbound named sequence extension utility is proposed and several pruning\nstrategies are further applied to improve the efficiency of ProUM. By taking\nutility theory into account, the derived high-utility sequential patterns have\nmore insightful and interesting information than other kinds of patterns.\nExperimental results showed that the proposed ProUM algorithm significantly\noutperformed the state-of-the-art algorithms in terms of execution time, memory\nusage, and scalability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 15:34:40 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 09:18:50 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Gan", "Wensheng", ""], ["Lin", "Jerry Chun-Wei", ""], ["Zhang", "Jiexiong", ""], ["Chao", "Han-Chieh", ""], ["Fujita", "Hamido", ""], ["Yu", "Philip S.", ""]]}, {"id": "1904.07902", "submitter": "Radu Stefan Mincu", "authors": "Radu Stefan Mincu (1), Alexandru Popa (1 and 2) ((1) University of\n  Bucharest, Romania, (2) National Institute for Research and Development in\n  Informatics, Bucharest, Romania)", "title": "Heuristic algorithms for the Longest Filled Common Subsequence Problem", "comments": "Accepted and presented as a proceedings paper at SYNASC 2018", "journal-ref": null, "doi": "10.1109/SYNASC.2018.00075", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At CPM 2017, Castelli et al. define and study a new variant of the Longest\nCommon Subsequence Problem, termed the Longest Filled Common Subsequence\nProblem (LFCS). For the LFCS problem, the input consists of two strings $A$ and\n$B$ and a multiset of characters $\\mathcal{M}$. The goal is to insert the\ncharacters from $\\mathcal{M}$ into the string $B$, thus obtaining a new string\n$B^*$, such that the Longest Common Subsequence (LCS) between $A$ and $B^*$ is\nmaximized. Casteli et al. show that the problem is NP-hard and provide a\n3/5-approximation algorithm for the problem.\n  In this paper we study the problem from the experimental point of view. We\nintroduce, implement and test new heuristic algorithms and compare them with\nthe approximation algorithm of Casteli et al. Moreover, we introduce an Integer\nLinear Program (ILP) model for the problem and we use the state of the art ILP\nsolver, Gurobi, to obtain exact solution for moderate sized instances.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 18:06:25 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mincu", "Radu Stefan", "", "1 and 2"], ["Popa", "Alexandru", "", "1 and 2"]]}, {"id": "1904.07957", "submitter": "Robert Krauthgamer", "authors": "Robert Krauthgamer and David Reitblat", "title": "Almost-Smooth Histograms and Sliding-Window Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for the sliding-window model, an important variant of the\ndata-stream model, in which the goal is to compute some function of a\nfixed-length suffix of the stream. We extend the smooth-histogram framework of\nBraverman and Ostrovsky (FOCS 2007) to almost-smooth functions, which includes\nall subadditive functions. Specifically, we show that if a subadditive function\ncan be $(1+\\epsilon)$-approximated in the insertion-only streaming model, then\nit can be $(2+\\epsilon)$-approximated also in the sliding-window model with\nspace complexity larger by factor $O(\\epsilon^{-1}\\log w)$, where $w$ is the\nwindow size.\n  We demonstrate how our framework yields new approximation algorithms with\nrelatively little effort for a variety of problems that do not admit the\nsmooth-histogram technique. For example, in the frequency-vector model, a\nsymmetric norm is subadditive and thus we obtain a sliding-window\n$(2+\\epsilon)$-approximation algorithm for it. Another example is for streaming\nmatrices, where we derive a new sliding-window\n$(\\sqrt{2}+\\epsilon)$-approximation algorithm for Schatten $4$-norm. We then\nconsider graph streams and show that many graph problems are subadditive,\nincluding maximum submodular matching, minimum vertex-cover, and maximum\n$k$-cover, thereby deriving sliding-window $O(1)$-approximation algorithms for\nthem almost for free (using known insertion-only algorithms). Finally, we\ndesign for every $d\\in (1,2]$ an artificial function, based on the\nmaximum-matching size, whose almost-smoothness parameter is exactly $d$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:16:49 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:10:22 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Krauthgamer", "Robert", ""], ["Reitblat", "David", ""]]}, {"id": "1904.08037", "submitter": "Thatchaphol Saranurak", "authors": "Yi-Jun Chang, Thatchaphol Saranurak", "title": "Improved Distributed Expander Decomposition and Nearly Optimal Triangle\n  Enumeration", "comments": "To appear at PODC'19. Added open problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $(\\epsilon,\\phi)$-expander decomposition of a graph $G=(V,E)$ is a\nclustering of the vertices $V=V_{1}\\cup\\cdots\\cup V_{x}$ such that (1) each\ncluster $V_{i}$ induces subgraph with conductance at least $\\phi$, and (2) the\nnumber of inter-cluster edges is at most $\\epsilon|E|$. In this paper, we give\nan improved distributed expander decomposition.\n  Specifically, we construct an $(\\epsilon,\\phi)$-expander decomposition with\n$\\phi=(\\epsilon/\\log n)^{2^{O(k)}}$ in $O(n^{2/k}\\cdot\\text{poly}(1/\\phi,\\log\nn))$ rounds for any $\\epsilon\\in(0,1)$ and positive integer $k$. For example, a\n$(0.01,1/\\text{poly}\\log n)$-expander decomposition can be computed in\n$O(n^{\\gamma})$ rounds, for any arbitrarily small constant $\\gamma>0$.\nPreviously, the algorithm by Chang, Pettie, and Zhang can construct a\n$(1/6,1/\\text{poly}\\log n)$-expander decomposition using\n$\\tilde{O}(n^{1-\\delta})$ rounds for any $\\delta>0$, with a caveat that the\nalgorithm is allowed to throw away a set of edges into an extra part which\nforms a subgraph with arboricity at most $n^{\\delta}$. Our algorithm does not\nhave this caveat.\n  By slightly modifying the distributed algorithm for routing on expanders by\nGhaffari, Kuhn and Su [PODC'17], we obtain a triangle enumeration algorithm\nusing $\\tilde{O}(n^{1/3})$ rounds. This matches the lower bound by Izumi and Le\nGall [PODC'17] and Pandurangan, Robinson and Scquizzato [SPAA'18] of\n$\\tilde{\\Omega}(n^{1/3})$ which holds even in the CONGESTED CLIQUE model. This\nprovides the first non-trivial example for a distributed problem that has\nessentially the same complexity (up to a polylogarithmic factor) in both\nCONGEST and CONGESTED CLIQUE.\n  The key technique in our proof is the first distributed approximation\nalgorithm for finding a low conductance cut that is as balanced as possible.\nPrevious distributed sparse cut algorithms do not have this nearly most\nbalanced guarantee.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:50:26 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 02:53:30 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "1904.08053", "submitter": "Patrick Erik Bradley", "authors": "Markus Wilhelm Jahn, Patrick Erik Bradley", "title": "A scaled space-filling curve index applied to tropical rain forest tree\n  distributions", "comments": "9 pages, 3 tables, 5 figures; v2: abstract and introduction expanded,\n  several sentences reworded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to be able to process the increasing amount of spatial data,\nefficient methods for their handling need to be developed. One major challenge\nfor big spatial data is access. This can be achieved through space-filling\ncurves, as they have the property that nearby points on the curve are also\nnearby in space. They are able to handle higher dimensional data, too. Higher\ndimensional data is widely used e.g. in CityGML and is becoming more and more\nimportant. In a laboratory experiment on a tropical rain forest tree data set\nof 2.5 million points taken from an 18-dimensional space, it is demonstrated\nthat the recently constructed scaled Gray-Hilbert curve index performs better\nthan its standard static version, saving a significant amount of space for a\nprojection of the data set onto 8 attributes. The implementation is based on a\nbinary tree in a data-driven process, in a similar way as e.g. the R-tree. Its\nscalability allows the handling of different kinds of data distributions which\nare reflected in the tree structure of the index. The relative efficiency of\nthe scaled Gray-Hilbert curve in comparison with the best static version is\nseen to depend on the distribution of the point cloud. A local sparsity measure\nderived from properties of the corresponding trees can distinguish point clouds\nwith different tail distributions. The different resulting binary trees are\nvisualised to illustrate the influences of the different tail distributions\nthey have been built on.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:34:07 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 13:27:06 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jahn", "Markus Wilhelm", ""], ["Bradley", "Patrick Erik", ""]]}, {"id": "1904.08150", "submitter": "Pranabendu Misra", "authors": "Daniel Lokshtanov, Pranabendu Misra, Saket Saurabh, Meirav Zehavi", "title": "A Brief Note on Single Source Fault Tolerant Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a directed graph with $n$ vertices and $m$ edges, and let $s \\in\nV(G)$ be a designated source vertex. We consider the problem of single source\nreachability (SSR) from $s$ in presence of failures of edges (or vertices).\nFormally, a spanning subgraph $H$ of $G$ is a {\\em $k$-Fault Tolerant\nReachability Subgraph ($k$-FTRS)} if it has the following property. For any set\n$F$ of at most $k$ edges (or vertices) in $G$, and for any vertex $v\\in V(G)$,\nthe vertex $v$ is reachable from $s$ in $G-F$ if and only if it is reachable\nfrom $s$ in $H - F$. Baswana et.al. [STOC 2016, SICOMP 2018] showed that in the\nsetting above, for any positive integer $k$, we can compute a $k$-FTRS with\n$2^k n$ edges. In this paper, we give a much simpler algorithm for computing a\n$k$-FTRS, and observe that it extends to higher connectivity as well. Our\nresults follow from a simple application of \\emph{important separators}, a well\nknown technique in Parameterized Complexity.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:22:20 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Misra", "Pranabendu", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1904.08178", "submitter": "Charalampos Tsourakakis", "authors": "Charalampos E. Tsourakakis, Tianyi Chen, Naonori Kakimura, Jakub\n  Pachocki", "title": "Novel Dense Subgraph Discovery Primitives: Risk Aversion and Exclusion\n  Queries", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the densest subgraph problem, given a weighted undirected graph\n$G(V,E,w)$, with non-negative edge weights, we are asked to find a subset of\nnodes $S\\subseteq V$ that maximizes the degree density $w(S)/|S|$, where $w(S)$\nis the sum of the edge weights induced by $S$. This problem is a well studied\nproblem, known as the {\\em densest subgraph problem}, and is solvable in\npolynomial time. But what happens when the edge weights are negative? Is the\nproblem still solvable in polynomial time? Also, why should we care about the\ndensest subgraph problem in the presence of negative weights?\n  In this work we answer the aforementioned question. Specifically, we provide\ntwo novel graph mining primitives that are applicable to a wide variety of\napplications. Our primitives can be used to answer questions such as \"how can\nwe find a dense subgraph in Twitter with lots of replies and mentions but no\nfollows?\", \"how do we extract a dense subgraph with high expected reward and\nlow risk from an uncertain graph\"? We formulate both problems mathematically as\nspecial instances of dense subgraph discovery in graphs with negative weights.\nWe study the hardness of the problem, and we prove that the problem in general\nis NP-hard. We design an efficient approximation algorithm that works well in\nthe presence of small negative weights, and also an effective heuristic for the\nmore general case. Finally, we perform experiments on various real-world\nuncertain graphs, and a crawled Twitter multilayer graph that verify the value\nof the proposed primitives, and the practical value of our proposed algorithms.\n  The code and the data are available at \\url{https://github.com/negativedsd}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 10:51:09 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Tsourakakis", "Charalampos E.", ""], ["Chen", "Tianyi", ""], ["Kakimura", "Naonori", ""], ["Pachocki", "Jakub", ""]]}, {"id": "1904.08255", "submitter": "David Wajc", "authors": "Buddhima Gamlath, Michael Kapralov, Andreas Maggiori, Ola Svensson and\n  David Wajc", "title": "Online Matching with General Arrivals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online matching problem was introduced by Karp, Vazirani and Vazirani\nnearly three decades ago. In that seminal work, they studied this problem in\nbipartite graphs with vertices arriving only on one side, and presented optimal\ndeterministic and randomized algorithms for this setting. In comparison, more\ngeneral arrival models, such as edge arrivals and general vertex arrivals, have\nproven more challenging and positive results are known only for various\nrelaxations of the problem. In particular, even the basic question of whether\nrandomization allows one to beat the trivially-optimal deterministic\ncompetitive ratio of $\\frac{1}{2}$ for either of these models was open. In this\npaper, we resolve this question for both these natural arrival models, and show\nthe following.\n  1. For edge arrivals, randomization does not help --- no randomized algorithm\nis better than $\\frac{1}{2}$ competitive.\n  2. For general vertex arrivals, randomization helps --- there exists a\nrandomized $(\\frac{1}{2}+\\Omega(1))$-competitive online matching algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 13:10:38 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Gamlath", "Buddhima", ""], ["Kapralov", "Michael", ""], ["Maggiori", "Andreas", ""], ["Svensson", "Ola", ""], ["Wajc", "David", ""]]}, {"id": "1904.08355", "submitter": "Dimitrios Michail", "authors": "Dimitrios Michail and Joris Kinable and Barak Naveh and John V Sichi", "title": "JGraphT -- A Java library for graph data structures and algorithms", "comments": "Major Revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical software and graph-theoretical algorithmic packages to\nefficiently model, analyze and query graphs are crucial in an era where\nlarge-scale spatial, societal and economic network data are abundantly\navailable. One such package is JGraphT, a programming library which contains\nvery efficient and generic graph data-structures along with a large collection\nof state-of-the-art algorithms. The library is written in Java with stability,\ninteroperability and performance in mind. A distinctive feature of this library\nis the ability to model vertices and edges as arbitrary objects, thereby\npermitting natural representations of many common networks including\ntransportation, social and biological networks. Besides classic graph\nalgorithms such as shortest-paths and spanning-tree algorithms, the library\ncontains numerous advanced algorithms: graph and subgraph isomorphism; matching\nand flow problems; approximation algorithms for NP-hard problems such as\nindependent set and TSP; and several more exotic algorithms such as Berge graph\ndetection. Due to its versatility and generic design, JGraphT is currently used\nin large-scale commercial, non-commercial and academic research projects. In\nthis work we describe in detail the design and underlying structure of the\nlibrary, and discuss its most important features and algorithms. A\ncomputational study is conducted to evaluate the performance of JGraphT versus\na number of similar libraries. Experiments on a large number of graphs over a\nvariety of popular algorithms show that JGraphT is highly competitive with\nother established libraries such as NetworkX or the BGL.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:45:02 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:27:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Michail", "Dimitrios", ""], ["Kinable", "Joris", ""], ["Naveh", "Barak", ""], ["Sichi", "John V", ""]]}, {"id": "1904.08380", "submitter": "Laxman Dhulipala", "authors": "Laxman Dhulipala, Julian Shun, Guy Blelloch", "title": "Low-Latency Graph Streaming Using Compressed Purely-Functional Trees", "comments": "This is the full version of the paper appearing in the ACM SIGPLAN\n  conference on Programming Language Design and Implementation (PLDI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the dynamic nature of real-world graphs, there has been a growing\ninterest in the graph-streaming setting where a continuous stream of graph\nupdates is mixed with arbitrary graph queries. In principle, purely-functional\ntrees are an ideal choice for this setting due as they enable safe parallelism,\nlightweight snapshots, and strict serializability for queries. However,\ndirectly using them for graph processing would lead to significant space\noverhead and poor cache locality.\n  This paper presents C-trees, a compressed purely-functional search tree data\nstructure that significantly improves on the space usage and locality of\npurely-functional trees. The key idea is to use a chunking technique over trees\nin order to store multiple entries per tree-node. We design\ntheoretically-efficient and practical algorithms for performing batch updates\nto C-trees, and also show that we can store massive dynamic real-world graphs\nusing only a few bytes per edge, thereby achieving space usage close to that of\nthe best static graph processing frameworks.\n  To study the efficiency and applicability of our data structure, we designed\nAspen, a graph-streaming framework that extends the interface of Ligra with\noperations for updating graphs. We show that Aspen is faster than two\nstate-of-the-art graph-streaming systems, Stinger and LLAMA, while requiring\nless memory, and is competitive in performance with the state-of-the-art static\ngraph frameworks, Galois, GAP, and Ligra+. With Aspen, we are able to\nefficiently process the largest publicly-available graph with over two hundred\nbillion edges in the graph-streaming setting using a single commodity multicore\nserver with 1TB of memory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:28:18 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Dhulipala", "Laxman", ""], ["Shun", "Julian", ""], ["Blelloch", "Guy", ""]]}, {"id": "1904.08382", "submitter": "Sebastian Forster", "authors": "Sebastian Forster, Liu Yang", "title": "A Faster Local Algorithm for Detecting Bounded-Size Cuts with\n  Applications to Higher-Connectivity Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following \"local\" cut-detection problem in a directed graph: We\nare given a starting vertex $s$ and need to detect whether there is a cut with\nat most $k$ edges crossing the cut such that the side of the cut containing $s$\nhas at most $\\Delta$ interior edges. If we are given query access to the input\ngraph, then this problem can in principle be solved in sublinear time without\nreading the whole graph and with query complexity depending on $k$ and\n$\\Delta$. We design an elegant randomized procedure that solves a slack variant\nof this problem with $O(k^2 \\Delta)$ queries, improving in particular a\nprevious bound of $O((2(k+1))^{k+2} \\Delta)$ by Chechik et al. [SODA 2017]. In\nthis slack variant, the procedure must successfully detect a component\ncontaining $s$ with at most $k$ outgoing edges and $\\Delta$ interior edges if\nsuch a component exists, but the component it actually detects may have up to\n$O(k \\Delta)$ interior edges.\n  Besides being of interest on its own, such cut-detection procedures have been\nused in many algorithmic applications for higher-connectivity problems. Our new\ncut-detection procedure therefore almost readily implies (1) a faster vertex\nconnectivity algorithm which in particular has nearly linear running time for\npolylogarithmic value of the vertex connectivity, (2) a faster algorithm for\ncomputing the maximal $k$-edge connected subgraphs, and (3) faster property\ntesting algorithms for higher edge and vertex connectivity, which resolves two\nopen problems, one by Goldreich and Ron [STOC '97] and one by Orenstein and Ron\n[TCS 2011].\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:32:34 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 11:55:32 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Forster", "Sebastian", ""], ["Yang", "Liu", ""]]}, {"id": "1904.08391", "submitter": "Rohit Agrawal", "authors": "Rohit Agrawal", "title": "Samplers and Extractors for Unbounded Functions", "comments": "An extended abstract appeared in the proceedings of RANDOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler,\ndefined as an averaging sampler for approximating the mean of functions\n$f:\\{0,1\\}^m \\to \\mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and\nasked for explicit constructions. In this work, we give the first explicit\nconstructions of subgaussian samplers (and in fact averaging samplers for the\nbroader class of subexponential functions) that match the best-known\nconstructions of averaging samplers for $[0,1]$-bounded functions in the regime\nof parameters where the approximation error $\\varepsilon$ and failure\nprobability $\\delta$ are subconstant. Our constructions are established via an\nextension of the standard notion of randomness extractor (Nisan and Zuckerman,\nJCSS'96) where the error is measured by an arbitrary divergence rather than\ntotal variation distance, and a generalization of Zuckerman's equivalence\n(Random Struct. Alg.'97) between extractors and samplers. We believe that the\nframework we develop, and specifically the notion of an extractor for the\nKullback-Leibler (KL) divergence, are of independent interest. In particular,\nKL-extractors are stronger than both standard extractors and subgaussian\nsamplers, but we show that they exist with essentially the same parameters\n(constructively and non-constructively) as standard extractors.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:48:05 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 21:22:51 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Agrawal", "Rohit", ""]]}, {"id": "1904.08415", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "An Exponential Lower Bound for the Runtime of the cGA on Jump Functions", "comments": "To appear in the Proceedings of FOGA 2019. arXiv admin note: text\n  overlap with arXiv:1903.10983", "journal-ref": null, "doi": "10.1145/3299904.3340304", "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first runtime analysis of an estimation-of-distribution algorithm\n(EDA) on the multi-modal jump function class, Hasen\\\"ohrl and Sutton (GECCO\n2018) proved that the runtime of the compact genetic algorithm with suitable\nparameter choice on jump functions with high probability is at most polynomial\n(in the dimension) if the jump size is at most logarithmic (in the dimension),\nand is at most exponential in the jump size if the jump size is\nsuper-logarithmic. The exponential runtime guarantee was achieved with a\nhypothetical population size that is also exponential in the jump size.\nConsequently, this setting cannot lead to a better runtime.\n  In this work, we show that any choice of the hypothetical population size\nleads to a runtime that, with high probability, is at least exponential in the\njump size. This result might be the first non-trivial exponential lower bound\nfor EDAs that holds for arbitrary parameter settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:39:23 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 13:59:44 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1904.08819", "submitter": "Mosab Hassaan", "authors": "Mosab Hassaan and Karam Gouda", "title": "New Subgraph Isomorphism Algorithms: Vertex versus Path-at-a-time\n  Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are widely used to model complicated data semantics in many\napplication domains. In this paper, two novel and efficient algorithms Fast-ON\nand Fast-P are proposed for solving the subgraph isomorphism problem. The two\nalgorithms are based on Ullman algorithm [Ullmann 1976], apply vertex-at-a-time\nmatching manner and path-at-a-time matching manner respectively, and use\neffective heuristics to cut the search space. Comparing to the well-known\nalgorithms, Fast-ON and Fast-P achieve up to 1-4 orders of magnitude speed-up\nfor both dense and sparse graph data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:50:00 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Hassaan", "Mosab", ""], ["Gouda", "Karam", ""]]}, {"id": "1904.08832", "submitter": "Penghui Yao", "authors": "Penghui Yao", "title": "A doubly exponential upper bound on noisy EPR states for binary games", "comments": "The proof of Lemma C.9 is corrected. The presentation is improved.\n  Some typos are corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates the study of a class of entangled games, mono-state\ngames, denoted by $(G,\\psi)$, where $G$ is a two-player one-round game and\n$\\psi$ is a bipartite state independent of the game $G$. In the mono-state game\n$(G,\\psi)$, the players are only allowed to share arbitrary copies of $\\psi$.\nThis paper provides a doubly exponential upper bound on the copies of $\\psi$\nfor the players to approximate the value of the game to an arbitrarily small\nconstant precision for any mono-state binary game $(G,\\psi)$, if $\\psi$ is a\nnoisy EPR state, which is a two-qubit state with completely mixed states as\nmarginals and maximal correlation less than $1$. In particular, it includes\n$(1-\\epsilon)|\\Psi\\rangle\\langle\\Psi|+\\epsilon\\frac{I_2}{2}\\otimes\\frac{I_2}{2}$,\nan EPR state with an arbitrary depolarizing noise $\\epsilon>0$.The structure of\nthe proofs is built the recent framework about the decidability of the\nnon-interactive simulation of joint distributions, which is completely\ndifferent from all previous optimization-based approaches or \"Tsirelson's\nproblem\"-based approaches. This paper develops a series of new techniques about\nthe Fourier analysis on matrix spaces and proves a quantum invariance principle\nand a hypercontractive inequality of random operators. This novel approach\nprovides a new angle to study the decidability of the complexity class MIP$^*$,\na longstanding open problem in quantum complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:14:41 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 12:26:01 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 02:06:00 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yao", "Penghui", ""]]}, {"id": "1904.08934", "submitter": "Utkan Onur Candogan", "authors": "Utkan Onur Candogan, Venkat Chandrasekaran", "title": "Convex Graph Invariant Relaxations For Graph Edit Distance", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The edit distance between two graphs is a widely used measure of similarity\nthat evaluates the smallest number of vertex and edge deletions/insertions\nrequired to transform one graph to another. It is NP-hard to compute in\ngeneral, and a large number of heuristics have been proposed for approximating\nthis quantity. With few exceptions, these methods generally provide upper\nbounds on the edit distance between two graphs. In this paper, we propose a new\nfamily of computationally tractable convex relaxations for obtaining lower\nbounds on graph edit distance. These relaxations can be tailored to the\nstructural properties of the particular graphs via convex graph invariants.\nSpecific examples that we highlight in this paper include constraints on the\ngraph spectrum as well as (tractable approximations of) the stability number\nand the maximum-cut values of graphs. We prove under suitable conditions that\nour relaxations are tight (i.e., exactly compute the graph edit distance) when\none of the graphs consists of few eigenvalues. We also validate the utility of\nour framework on synthetic problems as well as real applications involving\nmolecular structure comparison problems in chemistry.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 01:23:13 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Candogan", "Utkan Onur", ""], ["Chandrasekaran", "Venkat", ""]]}, {"id": "1904.08954", "submitter": "Benjamin Moseley", "authors": "Sungjin Im and Benjamin Moseley", "title": "A Conditional Lower Bound on Graph Connectivity in MapReduce", "comments": "Preprint from 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce (and its open source implementation Hadoop) has become the de facto\nplatform for processing large data sets. MapReduce offers a streamlined\ncomputational framework by interleaving sequential and parallel computation\nwhile hiding underlying system issues from the programmer. Due to the\npopularity of MapReduce, there have been attempts in the theoretical computer\nscience community to understand the power and limitations of the MapReduce\nframework. In the most widely studied MapReduce models each machine has memory\nsub-linear in the input size to the problem, hence cannot see the entire input.\nThis restriction places many limitations on algorithms that can be developed\nfor the model; however, the current understanding of these restrictions is\nstill limited.\n  In this paper, our goal is to work towards understanding problems which do\nnot admit efficient algorithms in the MapReduce model. We study the basic\nquestion of determining if a graph is connected or not. We concentrate on\ninstances of this problem where an algorithm is to determine if a graph\nconsists of a single cycle or two disconnected cycles. In this problem, locally\nevery part of the graph is similar and the goal is to determine the global\nstructure of the graph. We consider a natural class of algorithms that can\nstore/process/transfer the information only in the form of paths and show that\nno randomized algorithm cannot answer the decision question in a\nsub-logarithmic number of rounds. Currently, there are no absolute super\nconstant lower bounds on the number of rounds known for any problem in\nMapReduce. We introduce some of the first lower bounds for a natural graph\nproblem, albeit for a restricted class of algorithms. We believe our result\nmakes progress towards understanding the limitations of MapReduce.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 18:01:33 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Im", "Sungjin", ""], ["Moseley", "Benjamin", ""]]}, {"id": "1904.09142", "submitter": "Thomas Erlebach", "authors": "Iago A. Carvalho, Thomas Erlebach, Kleitos Papadopoulos", "title": "An Efficient Algorithm for the Fast Delivery Problem", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-25027-0_12", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a problem where k autonomous mobile agents are initially located on\ndistinct nodes of a weighted graph (with n nodes and m edges). Each autonomous\nmobile agent has a predefined velocity and is only allowed to move along the\nedges of the graph. We are interested in delivering a package, initially\npositioned in a source node s, to a destination node y. The delivery is\nachieved by the collective effort of the autonomous mobile agents, which can\ncarry and exchange the package among them. The objective is to compute a\ndelivery schedule that minimizes the delivery time of the package. In this\npaper, we propose an O(kn log n + km) time algorithm for this problem. This\nimproves the previous state-of-the-art O(k^2 m + k n^2 + APSP) time algorithm\nfor this problem, where APSP stands for the running-time of an algorithm for\nthe All-Pairs Shortest Paths problem.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 10:50:51 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:55:18 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Carvalho", "Iago A.", ""], ["Erlebach", "Thomas", ""], ["Papadopoulos", "Kleitos", ""]]}, {"id": "1904.09216", "submitter": "Mehrdad Ghadiri", "authors": "Mehrdad Ghadiri, Richard Santiago, Bruce Shepherd", "title": "Beyond Submodular Maximization via One-Sided Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multilinear framework has achieved the breakthrough $1-1/e$ approximation\nfor maximizing a monotone submodular function subject to a matroid constraint.\nThis framework has a continuous optimization part and a rounding part. We\nextend both parts to a wider array of problems. In particular, we make a\nconceptual contribution by identifying a family of parameterized functions. As\na running example we focus on solving diversity problems $\\max\nf(S)=\\frac{1}{2}\\sum_{i,j\\in A}A_{ij}:S\\in\\mathcal{M}$, where $\\mathcal{M}$ is\na matroid. These diversity functions have $A_{ij}\\geq 0$ as a measure of\ndissimilarity of $i,j$, and $A$ has $0$-diagonal. The multilinear framework\ncannot be directly applied to the multilinear extension of such functions. We\nintroduce a new parameter for functions $F\\in{\\bf C}^2$ which measures the\napproximability of the associated problem $\\max\\{F(x):x\\in P\\}$, for solvable\ndownwards-closed polytopes $P$. A function $F$ is called one-sided\n$\\sigma$-smooth if $\\frac{1}{2}u^T\\nabla^2 F(x)\nu\\leq\\sigma\\cdot\\frac{||u||_1}{||x||_1}u^T\\nabla F(x)$ for all $u,x\\geq 0$,\n$x\\neq 0$.\n  We give an $\\Omega(1/\\sigma)$-approximation for the maximization problem of\nmonotone, normalized one-sided $\\sigma$-smooth $F$ with an additional property:\nnon-positive third order partial derivatives. Using the multilinear framework\nand new matroid rounding techniques for quadratic objectives, we give an\n$\\Omega(1/\\sigma^{3/2})$-approximation for maximizing a $\\sigma$-semi-metric\ndiversity function subject to matroid constraint. This improves upon the\nprevious best bound of $\\Omega(1/\\sigma^2)$ and we give evidence that it may be\ntight. For general one-sided smooth functions, we show the continuous process\ngives an $\\Omega(1/3^{2\\sigma})$-approximation, independent of $n$. In this\nsetting, by discretizing, we present a poly-time algorithm for multilinear\none-sided $\\sigma$-smooth functions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 14:47:01 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 18:30:53 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 11:36:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Santiago", "Richard", ""], ["Shepherd", "Bruce", ""]]}, {"id": "1904.09222", "submitter": "David Wajc", "authors": "Ilan Reuven Cohen and Binghui Peng and David Wajc", "title": "Tight Bounds for Online Edge Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vizing's celebrated theorem asserts that any graph of maximum degree $\\Delta$\nadmits an edge coloring using at most $\\Delta+1$ colors. In contrast, Bar-Noy,\nNaor and Motwani showed over a quarter century that the trivial greedy\nalgorithm, which uses $2\\Delta-1$ colors, is optimal among online algorithms.\nTheir lower bound has a caveat, however: it only applies to low-degree graphs,\nwith $\\Delta=O(\\log n)$, and they conjectured the existence of online\nalgorithms using $\\Delta(1+o(1))$ colors for $\\Delta=\\omega(\\log n)$. Progress\ntowards resolving this conjecture was only made under stochastic arrivals\n(Aggarwal et al., FOCS'03 and Bahmani et al., SODA'10).\n  We resolve the above conjecture for \\emph{adversarial} vertex arrivals in\nbipartite graphs, for which we present a $(1+o(1))\\Delta$-edge-coloring\nalgorithm for $\\Delta=\\omega(\\log n)$ known a priori. Surprisingly, if $\\Delta$\nis not known ahead of time, we show that no $\\big(\\frac{e}{e-1} - \\Omega(1)\n\\big) \\Delta$-edge-coloring algorithm exists. We then provide an optimal,\n$\\big(\\frac{e}{e-1}+o(1)\\big)\\Delta$-edge-coloring algorithm for unknown\n$\\Delta=\\omega(\\log n)$. Key to our results, and of possible independent\ninterest, is a novel fractional relaxation for edge coloring, for which we\npresent optimal fractional online algorithms and a near-lossless online\nrounding scheme, yielding our optimal randomized algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 15:09:14 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Cohen", "Ilan Reuven", ""], ["Peng", "Binghui", ""], ["Wajc", "David", ""]]}, {"id": "1904.09228", "submitter": "Jasper C.H. Lee", "authors": "Jasper C.H. Lee, Paul Valiant", "title": "Uncertainty about Uncertainty: Optimal Adaptive Algorithms for\n  Estimating Mixtures of Unknown Coins", "comments": "Full paper updated to reflect the new result in our SODA 2021\n  proceedings version: our new sample complexity lower bound includes\n  dependence on the failure probability, and hence is simultaneously tight in\n  all of the problem parameters up to a constant multiplicative factor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a mixture between two populations of coins, \"positive\" coins that each\nhave -- unknown and potentially different -- bias $\\geq\\frac{1}{2}+\\Delta$ and\n\"negative\" coins with bias $\\leq\\frac{1}{2}-\\Delta$, we consider the task of\nestimating the fraction $\\rho$ of positive coins to within additive error\n$\\epsilon$. We achieve an upper and lower bound of\n$\\Theta(\\frac{\\rho}{\\epsilon^2\\Delta^2}\\log\\frac{1}{\\delta})$ samples for a\n$1-\\delta$ probability of success, where crucially, our lower bound applies to\nall fully-adaptive algorithms. Thus, our sample complexity bounds have tight\ndependence for every relevant problem parameter. A crucial component of our\nlower bound proof is a decomposition lemma (see Lemmas 17 and 18) showing how\nto assemble partially-adaptive bounds into a fully-adaptive bound, which may be\nof independent interest: though we invoke it for the special case of Bernoulli\nrandom variables (coins), it applies to general distributions. We present\nsimulation results to demonstrate the practical efficacy of our approach for\nrealistic problem parameters for crowdsourcing applications, focusing on the\n\"rare events\" regime where $\\rho$ is small. The fine-grained adaptive flavor of\nboth our algorithm and lower bound contrasts with much previous work in\ndistributional testing and learning.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 15:22:04 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 04:29:50 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 05:07:48 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Lee", "Jasper C. H.", ""], ["Valiant", "Paul", ""]]}, {"id": "1904.09265", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle\n  Points", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze stochastic gradient algorithms for optimizing nonconvex problems.\nIn particular, our goal is to find local minima (second-order stationary\npoints) instead of just finding first-order stationary points which may be some\nbad unstable saddle points. We show that a simple perturbed version of\nstochastic recursive gradient descent algorithm (called SSRGD) can find an\n$(\\epsilon,\\delta)$-second-order stationary point with\n$\\widetilde{O}(\\sqrt{n}/\\epsilon^2 + \\sqrt{n}/\\delta^4 + n/\\delta^3)$\nstochastic gradient complexity for nonconvex finite-sum problems. As a\nby-product, SSRGD finds an $\\epsilon$-first-order stationary point with\n$O(n+\\sqrt{n}/\\epsilon^2)$ stochastic gradients. These results are almost\noptimal since Fang et al. [2018] provided a lower bound\n$\\Omega(\\sqrt{n}/\\epsilon^2)$ for finding even just an $\\epsilon$-first-order\nstationary point. We emphasize that SSRGD algorithm for finding second-order\nstationary points is as simple as for finding first-order stationary points\njust by adding a uniform perturbation sometimes, while all other algorithms for\nfinding second-order stationary points with similar gradient complexity need to\ncombine with a negative-curvature search subroutine (e.g., Neon2 [Allen-Zhu and\nLi, 2018]). Moreover, the simple SSRGD algorithm gets a simpler analysis.\nBesides, we also extend our results from nonconvex finite-sum problems to\nnonconvex online (expectation) problems, and prove the corresponding\nconvergence results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 16:59:46 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:56:33 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "1904.09266", "submitter": "Eduardo Castell\\'o Ferrer", "authors": "Eduardo Castell\\'o Ferrer and Thomas Hardjono and Alex 'Sandy'\n  Pentland and Marco Dorigo", "title": "Secure and secret cooperation in robotic swarms", "comments": "32 pages, 6 figures, submitted to Science Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.DS cs.ET cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The importance of swarm robotics systems in both academic research and\nreal-world applications is steadily increasing. However, to reach widespread\nadoption, new models that ensure the secure cooperation of large groups of\nrobots need to be developed. This work introduces a novel method to encapsulate\ncooperative robotic missions in an authenticated data structure known as Merkle\ntree. With this method, operators can provide the \"blueprint\" of the swarm's\nmission without disclosing its raw data. In other words, data verification can\nbe separated from data itself. We propose a system where robots in a swarm, to\ncooperate towards mission completion, have to \"prove\" their integrity to their\npeers by exchanging cryptographic proofs. We show the implications of this\napproach for two different swarm robotics missions: foraging and maze\nformation. In both missions, swarm robots were able to cooperate and carry out\nsequential operations without having explicit knowledge about the mission's\nhigh-level objectives. The results presented in this work demonstrate the\nfeasibility of using Merkle trees as a cooperation mechanism for swarm robotics\nsystems in both simulation and real-robot experiments, which has implications\nfor future decentralized robotics applications where security plays a crucial\nrole such as environmental monitoring, infrastructure surveillance, and\ndisaster management.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 17:00:13 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 01:14:07 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 21:45:13 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ferrer", "Eduardo Castell\u00f3", ""], ["Hardjono", "Thomas", ""], ["Pentland", "Alex 'Sandy'", ""], ["Dorigo", "Marco", ""]]}, {"id": "1904.09284", "submitter": "David Wajc", "authors": "Anupam Gupta, Guru Guruganesh, Binghui Peng and David Wajc", "title": "Stochastic Online Metric Matching", "comments": "Full version of ICALP 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimum-cost metric perfect matching problem under online i.i.d\narrivals. We are given a fixed metric with a server at each of the points, and\nthen requests arrive online, each drawn independently from a known probability\ndistribution over the points. Each request has to be matched to a free server,\nwith cost equal to the distance. The goal is to minimize the expected total\ncost of the matching.\n  Such stochastic arrival models have been widely studied for the maximization\nvariants of the online matching problem; however, the only known result for the\nminimization problem is a tight $O(\\log n)$-competitiveness for the\nrandom-order arrival model. This is in contrast with the adversarial model,\nwhere an optimal competitive ratio of $O(\\log n)$ has long been conjectured and\nremains a tantalizing open question.\n  In this paper, we show improved results in the i.i.d arrival model. We show\nhow the i.i.d model can be used to give substantially better algorithms: our\nmain result is an $O((\\log \\log \\log n)^2)$-competitive algorithm in this\nmodel. Along the way we give a $9$-competitive algorithm for the line and tree\nmetrics. Both results imply a strict separation between the i.i.d model and the\nadversarial and random order models, both for general metrics and these\nmuch-studied metrics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 17:49:41 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Gupta", "Anupam", ""], ["Guruganesh", "Guru", ""], ["Peng", "Binghui", ""], ["Wajc", "David", ""]]}, {"id": "1904.09354", "submitter": "Christopher Harshaw", "authors": "Christopher Harshaw and Moran Feldman and Justin Ward and Amin Karbasi", "title": "Submodular Maximization Beyond Non-negativity: Guarantees, Fast\n  Algorithms, and Applications", "comments": "submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally believed that submodular functions -- and the more general\nclass of $\\gamma$-weakly submodular functions -- may only be optimized under\nthe non-negativity assumption $f(S) \\geq 0$. In this paper, we show that once\nthe function is expressed as the difference $f = g - c$, where $g$ is monotone,\nnon-negative, and $\\gamma$-weakly submodular and $c$ is non-negative modular,\nthen strong approximation guarantees may be obtained. We present an algorithm\nfor maximizing $g - c$ under a $k$-cardinality constraint which produces a\nrandom feasible set $S$ such that $\\mathbb{E} \\left[ g(S) - c(S) \\right] \\geq\n(1 - e^{-\\gamma} - \\epsilon) g(OPT) - c(OPT)$, whose running time is $O\n(\\frac{n}{\\epsilon} \\log^2 \\frac{1}{\\epsilon})$, i.e., independent of $k$. We\nextend these results to the unconstrained setting by describing an algorithm\nwith the same approximation guarantees and faster $O(\\frac{n}{\\epsilon}\n\\log\\frac{1}{\\epsilon})$ runtime. The main techniques underlying our algorithms\nare two-fold: the use of a surrogate objective which varies the relative\nimportance between $g$ and $c$ throughout the algorithm, and a geometric sweep\nover possible $\\gamma$ values. Our algorithmic guarantees are complemented by a\nhardness result showing that no polynomial-time algorithm which accesses $g$\nthrough a value oracle can do better. We empirically demonstrate the success of\nour algorithms by applying them to experimental design on the Boston Housing\ndataset and directed vertex cover on the Email EU dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 22:00:09 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Harshaw", "Christopher", ""], ["Feldman", "Moran", ""], ["Ward", "Justin", ""], ["Karbasi", "Amin", ""]]}, {"id": "1904.09397", "submitter": "Pengfei Liu", "authors": "Pengfei Liu", "title": "A Combinatorial Algorithm for the Multi-commodity Flow Problem", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper researches combinatorial algorithms for the multi-commodity flow\nproblem. We relax the capacity constraints and introduce a penalty function $h$\nfor each arc. If the flow exceeds the capacity on arc $a$, arc $a$ would have a\npenalty cost. Based on the penalty function $h$, a new conception, equilibrium\npseudo-flow, is introduced. Then we design a combinatorial algorithm to obtain\nequilibrium pseudo-flow. If the equilibrium pseudo-flow is a\nnonzero-equilibrium pseudo-flow, there exists no feasible solution for the\nmulti-commodity flow problem; if the equilibrium pseudo-flow is a\nzero-equilibrium pseudo-flow, there exists a feasible solution for the\nmulti-commodity flow problem and the zero-equilibrium pseudo-flow is the\nfeasible solution. At last, a non-linear description of the multi-commodity\nflow problem is given, whose solution is equilibrium pseudo-flow. Besides, the\ncontent in this paper can be easily generalized to minimum cost multi-commodity\nflow problem.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 03:57:27 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 14:19:10 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 12:59:29 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 02:03:17 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Liu", "Pengfei", ""]]}, {"id": "1904.09438", "submitter": "Yu Nakahata", "authors": "Takashi Horiyama, Jun Kawahara, Shin-ichi Minato, Yu Nakahata", "title": "Decomposing a Graph into Unigraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unigraphs are graphs uniquely determined by their own degree sequence up to\nisomorphism. There are many subclasses of unigraphs such as threshold graphs,\nsplit matrogenic graphs, matroidal graphs, and matrogenic graphs. Unigraphs and\nthese subclasses are well studied in the literature. Nevertheless, there are\nfew results on superclasses of unigraphs. In this paper, we introduce two types\nof generalizations of unigraphs: $k$-unigraphs and $k$-strong unigraphs. We say\nthat a graph $G$ is a $k$-unigraph if $G$ can be partitioned into $k$\nunigraphs. $G$ is a $k$-strong unigraph if not only each subgraph is a unigraph\nbut also the whole graph can be uniquely determined up to isomorphism, by using\nthe degree sequences of all the subgraphs in the partition. We describe a\nrelation between $k$-strong unigraphs and the subgraph isomorphism problem. We\nshow some properties of $k$-(strong) unigraphs and algorithmic results on\ncalculating the minimum $k$ such that a graph $G$ is a $k$-(strong) unigraph.\nThis paper will open many other research topics.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 12:05:49 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Horiyama", "Takashi", ""], ["Kawahara", "Jun", ""], ["Minato", "Shin-ichi", ""], ["Nakahata", "Yu", ""]]}, {"id": "1904.09470", "submitter": "Charis Papadopoulos", "authors": "Athanasios L. Konstantinidis and Charis Papadopoulos", "title": "Cluster Deletion on Interval Graphs and Split Related Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the {\\sc Cluster Deletion} problem the goal is to remove the minimum\nnumber of edges of a given graph, such that every connected component of the\nresulting graph constitutes a clique. It is known that the decision version of\n{\\sc Cluster Deletion} is NP-complete on ($P_5$-free) chordal graphs, whereas\n{\\sc Cluster Deletion} is solved in polynomial time on split graphs. However,\nthe existence of a polynomial-time algorithm of {\\sc Cluster Deletion} on\ninterval graphs, a proper subclass of chordal graphs, remained a well-known\nopen problem. Our main contribution is that we settle this problem in the\naffirmative, by providing a polynomial-time algorithm for {\\sc Cluster\nDeletion} on interval graphs. Moreover, despite the simple formulation of the\nalgorithm on split graphs, we show that {\\sc Cluster Deletion} remains\nNP-complete on a natural and slight generalization of split graphs that\nconstitutes a proper subclass of $P_5$-free chordal graphs. To complement our\nresults, we provide two polynomial-time algorithms for {\\sc Cluster Deletion}\non subclasses of such generalizations of split graphs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 17:24:41 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Konstantinidis", "Athanasios L.", ""], ["Papadopoulos", "Charis", ""]]}, {"id": "1904.09562", "submitter": "Ce Jin", "authors": "Ce Jin", "title": "An Improved FPTAS for 0-1 Knapsack", "comments": "To appear at ICALP'19", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2019.76", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 0-1 knapsack problem is an important NP-hard problem that admits fully\npolynomial-time approximation schemes (FPTASs). Previously the fastest FPTAS by\nChan (2018) with approximation factor $1+\\varepsilon$ runs in $\\tilde O(n +\n(1/\\varepsilon)^{12/5})$ time, where $\\tilde O$ hides polylogarithmic factors.\nIn this paper we present an improved algorithm in $\\tilde\nO(n+(1/\\varepsilon)^{9/4})$ time, with only a $(1/\\varepsilon)^{1/4}$ gap from\nthe quadratic conditional lower bound based on $(\\min,+)$-convolution. Our\nimprovement comes from a multi-level extension of Chan's number-theoretic\nconstruction, and a greedy lemma that reduces unnecessary computation spent on\ncheap items.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 08:05:34 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Jin", "Ce", ""]]}, {"id": "1904.09618", "submitter": "Andrew McGregor", "authors": "Akshay Krishnamurthy and Arya Mazumdar and Andrew McGregor and\n  Soumyabrata Pal", "title": "Trace Reconstruction: Generalized and Parameterized", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the beautifully simple-to-state problem of trace reconstruction, the goal\nis to reconstruct an unknown binary string $x$ given random \"traces\" of $x$\nwhere each trace is generated by deleting each coordinate of $x$ independently\nwith probability $p<1$. The problem is well studied both when the unknown\nstring is arbitrary and when it is chosen uniformly at random. For both\nsettings, there is still an exponential gap between upper and lower sample\ncomplexity bounds and our understanding of the problem is still surprisingly\nlimited. In this paper, we consider natural parameterizations and\ngeneralizations of this problem in an effort to attain a deeper and more\ncomprehensive understanding.\n  We prove that $\\exp(O(n^{1/4} \\sqrt{\\log n}))$ traces suffice for\nreconstructing arbitrary matrices. In the matrix version of the problem, each\nrow and column of an unknown $\\sqrt{n}\\times \\sqrt{n}$ matrix is deleted\nindependently with probability $p$. Our results contrasts with the best known\nresults for sequence reconstruction where the best known upper bound is\n$\\exp(O(n^{1/3}))$. An optimal result for random matrix reconstruction: we show\nthat $\\Theta(\\log n)$ traces are necessary and sufficient. This is in contrast\nto the problem for random sequences where there is a super-logarithmic lower\nbound and the best known upper bound is $\\exp({O}(\\log^{1/3} n))$. We show that\n$\\exp(O(k^{1/3}\\log^{2/3} n))$ traces suffice to reconstruct $k$-sparse\nstrings, providing an improvement over the best known sequence reconstruction\nresults when $k = o(n/\\log^2 n)$. We show that $\\textrm{poly}(n)$ traces\nsuffice if $x$ is $k$-sparse and we additionally have a \"separation\" promise,\nspecifically that the indices of 1's in $x$ all differ by $\\Omega(k \\log n)$.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 15:46:30 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 19:49:54 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Mazumdar", "Arya", ""], ["McGregor", "Andrew", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "1904.09667", "submitter": "Benjamin Moseley", "authors": "Benjamin Moseley", "title": "Scheduling to Approximate Minimization Objectives on Identical Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers scheduling on identical machines. The scheduling\nobjective considered in this paper generalizes most scheduling minimization\nproblems. In the problem, there are $n$ jobs and each job $j$ is associated\nwith a monotonically increasing function $g_j$. The goal is to design a\nschedule that minimizes $\\sum_{j \\in [n]} g_{j}(C_j)$ where $C_j$ is the\ncompletion time of job $j$ in the schedule. An $O(1)$-approximation is known\nfor the single machine case. On multiple machines, this paper shows that if the\nscheduler is required to be either non-migratory or non-preemptive then any\nalgorithm has an unbounded approximation ratio. Using preemption and migration,\nthis paper gives a $O(\\log \\log nP)$-approximation on multiple machines, the\nfirst result on multiple machines. These results imply the first non-trivial\npositive results for several special cases of the problem considered, such as\nthroughput minimization and tardiness.\n  Natural linear programs known for the problem have a poor integrality gap.\nThe results are obtained by strengthening a natural linear program for the\nproblem with a set of covering inequalities we call job cover inequalities.\nThis linear program is rounded to an integral solution by building on\nquasi-uniform sampling and rounding techniques.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 21:53:38 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Moseley", "Benjamin", ""]]}, {"id": "1904.09690", "submitter": "William Kuszmaul", "authors": "William Kuszmaul", "title": "Dynamic Time Warping in Strongly Subquadratic Time: Algorithms for the\n  Low-Distance Regime and Approximate Evaluation", "comments": null, "journal-ref": "46th International Colloquium on Automata, Languages, and\n  Programming (ICALP 2019), Series 132, Article 75", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic time warping distance (DTW) is a widely used distance measure between\ntime series. The best known algorithms for computing DTW run in near quadratic\ntime, and conditional lower bounds prohibit the existence of significantly\nfaster algorithms. The lower bounds do not prevent a faster algorithm for the\nspecial case in which the DTW is small, however. For an arbitrary metric space\n$\\Sigma$ with distances normalized so that the smallest non-zero distance is\none, we present an algorithm which computes $\\operatorname{dtw}(x, y)$ for two\nstrings $x$ and $y$ over $\\Sigma$ in time $O(n \\cdot \\operatorname{dtw}(x,\ny))$. We also present an approximation algorithm which computes\n$\\operatorname{dtw}(x, y)$ within a factor of $O(n^\\epsilon)$ in time\n$\\tilde{O}(n^{2 - \\epsilon})$ for $0 < \\epsilon < 1$. The algorithm allows for\nthe strings $x$ and $y$ to be taken over an arbitrary well-separated tree\nmetric with logarithmic depth and at most exponential aspect ratio. Extending\nour techniques further, we also obtain the first approximation algorithm for\nedit distance to work with characters taken from an arbitrary metric space,\nproviding an $n^\\epsilon$-approximation in time $\\tilde{O}(n^{2 - \\epsilon})$,\nwith high probability. Additionally, we present a simple reduction from\ncomputing edit distance to computing DTW. Applying our reduction to a\nconditional lower bound of Bringmann and K\\\"unnemann pertaining to edit\ndistance over $\\{0, 1\\}$, we obtain a conditional lower bound for computing DTW\nover a three letter alphabet (with distances of zero and one). This improves on\na previous result of Abboud, Backurs, and Williams. With a similar approach, we\nprove a reduction from computing edit distance to computing longest LCS length.\nThis means that one can recover conditional lower bounds for LCS directly from\nthose for edit distance, which was not previously thought to be the case.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 01:28:15 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:43:00 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Kuszmaul", "William", ""]]}, {"id": "1904.09710", "submitter": "Pan Peng", "authors": "Pan Peng", "title": "Robust Clustering Oracle and Local Reconstructor of Cluster Structure of\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the massive size of modern network data, local algorithms that run in\nsublinear time for analyzing the cluster structure of the graph are receiving\ngrowing interest. Two typical examples are local graph clustering algorithms\nthat find a cluster from a seed node with running time proportional to the size\nof the output set, and clusterability testing algorithms that decide if a graph\ncan be partitioned into a few clusters in the framework of property testing.\n  In this work, we develop sublinear time algorithms for analyzing the cluster\nstructure of graphs with noisy partial information. By using conductance based\ndefinitions for measuring the quality of clusters and the cluster structure, we\nformalize a definition of noisy clusterable graphs with bounded maximum degree.\nThe algorithm is given query access to the adjacency list to such a graph. We\nthen formalize the notion of robust clustering oracle for a noisy clusterable\ngraph, and give an algorithm that builds such an oracle in sublinear time,\nwhich can be further used to support typical queries (e.g., IsOutlier($s$),\nSameCluster($s,t$)) regarding the cluster structure of the graph in sublinear\ntime. All the answers are consistent with a partition of $G$ in which all but a\nsmall fraction of vertices belong to some good cluster. We also give a local\nreconstructor for a noisy clusterable graph that provides query access to a\nreconstructed graph that is guaranteed to be clusterable in sublinear time. All\nthe query answers are consistent with a clusterable graph which is guaranteed\nto be close to the original graph.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 03:39:34 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Peng", "Pan", ""]]}, {"id": "1904.09841", "submitter": "Cameron Musco", "authors": "Cameron Musco and Christopher Musco and David P. Woodruff", "title": "Simple Heuristics Yield Provable Algorithms for Masked Low-Rank\n  Approximation", "comments": "ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $masked\\ low-rank\\ approximation$, one is given $A \\in \\mathbb{R}^{n\n\\times n}$ and binary mask matrix $W \\in \\{0,1\\}^{n \\times n}$. The goal is to\nfind a rank-$k$ matrix $L$ for which: $$cost(L) = \\sum_{i=1}^{n} \\sum_{j =\n1}^{n} W_{i,j} \\cdot (A_{i,j} - L_{i,j} )^2 \\leq OPT + \\epsilon \\|A\\|_F^2 ,$$\nwhere $OPT = \\min_{rank-k\\ \\hat{L}} cost(\\hat L)$ and $\\epsilon$ is a given\nerror parameter. Depending on the choice of $W$, this problem captures factor\nanalysis, low-rank plus diagonal decomposition, robust PCA, low-rank matrix\ncompletion, low-rank plus block matrix approximation, and many problems. Many\nof these problems are NP-hard, and while some algorithms with provable\nguarantees are known, they either 1) run in time $n^{\\Omega(k^2/\\epsilon)}$ or\n2) make strong assumptions, e.g., that $A$ is incoherent or that $W$ is random.\n  In this work, we show that a common polynomial time heuristic, which simply\nsets $A$ to $0$ where $W$ is $0$, and then finds a standard low-rank\napproximation, yields bicriteria approximation guarantees for this problem. In\nparticular, for rank $k' > k$ depending on the $public\\ coin\\ partition\\\nnumber$ of $W$, the heuristic outputs rank-$k'$ $L$ with cost$(L) \\leq OPT +\n\\epsilon \\|A\\|_F^2$. This partition number is in turn bounded by the\n$randomized\\ communication\\ complexity$ of $W$, when interpreted as a\ntwo-player communication matrix. For many important examples of masked low-rank\napproximation, including all those listed above, this result yields bicriteria\napproximation guarantees with $k' = k \\cdot poly(\\log n/\\epsilon)$.\n  Further, we show that different models of communication yield algorithms for\nnatural variants of masked low-rank approximation. For example, multi-player\nnumber-in-hand communication complexity connects to masked tensor decomposition\nand non-deterministic communication complexity to masked Boolean low-rank\nfactorization.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:01:07 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 14:55:26 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 17:33:07 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 05:32:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Woodruff", "David P.", ""]]}, {"id": "1904.09958", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty", "title": "Almost Optimal Testers for Concise Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give improved and almost optimal testers for several classes of Boolean\nfunctions on $n$ inputs that have concise representation in the uniform and\ndistribution-free model. Classes, such as $k$-junta, $k$-linear functions,\n$s$-term DNF, $s$-term monotone DNF, $r$-DNF, decision list, $r$-decision list,\nsize-$s$ decision tree, size-$s$ Boolean formula, size-$s$ branching programs,\n$s$-sparse polynomials over the binary field and function with Fourier degree\nat most $d$. The method can be extended to several other classes of functions\nover any domain that can be approximated by functions that have a small number\nof relevant variables.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 17:16:07 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 15:42:40 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 12:13:37 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bshouty", "Nader H.", ""]]}, {"id": "1904.10210", "submitter": "Mordechai Shalom", "authors": "Yuval Emek, Shay Kutten, Mordechai Shalom, Shmuel Zaks", "title": "Hierarchical b-Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matching of a graph is a subset of edges no two of which share a common\nvertex, and a maximum matching is a matching of maximum cardinality. In a\n$b$-matching every vertex $v$ has an associated bound $b_v$, and a maximum\n$b$-matching is a maximum set of edges, such that every vertex $v$ appears in\nat most $b_v$ of them. We study an extension of this problem, termed {\\em\nHierarchical b-Matching}. In this extension, the vertices are arranged in a\nhierarchical manner. At the first level the vertices are partitioned into\ndisjoint subsets, with a given bound for each subset. At the second level the\nset of these subsets is again partitioned into disjoint subsets, with a given\nbound for each subset, and so on. In an {\\em Hierarchical b-matching} we look\nfor a maximum set of edges, that will obey all bounds (that is, no vertex $v$\nparticipates in more than $b_v$ edges, then all the vertices in one subset do\nnot participate in more that that subset's bound of edges, and so on\nhierarchically). We propose a polynomial-time algorithm for this new problem,\nthat works for any number of levels of this hierarchical structure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 09:03:02 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Emek", "Yuval", ""], ["Kutten", "Shay", ""], ["Shalom", "Mordechai", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1904.10215", "submitter": "Mordechai Shalom", "authors": "Yuval Emek, Shay Kutten, Mordechai Shalom, Shmuel Zaks", "title": "Multicast Communications in Tree Networks with Heterogeneous Capacity\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely studied problem in communication networks is that of finding the\nmaximum number of communication requests that can be scheduled concurrently,\nsubject to node and/or link capacity constraints. In this paper, we consider\nthe problem of finding the largest number of multicast communication requests\nthat can be serviced simultaneously by a network of tree topology, subject to\nheterogeneous capacity constraints. This problem generalizes the following two\nproblems studied in the literature: a) the problem of finding a largest induced\n$k$-colorable subgraph of a chordal graph, b) the maximum multi-commodity flow\nproblem in tree networks.\n  The problem is already known to be NP-hard and to admit a $c$-approximation\n($c \\approx 1.58$) in the case of homogeneous capacity constraints. We first\nshow that the problem is much harder to approximate in the heterogeneous case.\nWe then use a generalization of a classical algorithm to obtain an\n$M$-approximation where $M$ is the maximum number of leaves of the subtrees\nrepresenting the multicast communications. Surprisingly, the same algorithm,\nthough in various disguises, is used in the literature at least four times to\nsolve related problems (though the analysis is different).\n  The special case of the problem where instances are restricted to unicast\ncommunications in a star topology network is known to be polynomial-time\nsolvable. We extend this result and show that the problem can be solved in\npolynomial time for a set of paths in a tree that share a common vertex.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 09:13:36 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 14:27:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Emek", "Yuval", ""], ["Kutten", "Shay", ""], ["Shalom", "Mordechai", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1904.10454", "submitter": "Daniel Wiebking", "authors": "Daniel Wiebking", "title": "Normalizers and permutational isomorphisms in simply-exponential time", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that normalizers and permutational isomorphisms of permutation groups\ngiven by generating sets can be computed in time simply exponential in the\ndegree of the groups. The result is obtained by exploiting canonical forms for\npermutation groups (up to permutational isomorphism).\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:28:15 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wiebking", "Daniel", ""]]}, {"id": "1904.10680", "submitter": "Micha{\\l} Pilipczuk", "authors": "Vincent Cohen-Addad, Marcin Pilipczuk, Micha{\\l} Pilipczuk", "title": "A Polynomial-Time Approximation Scheme for Facility Location on Planar\n  Graphs", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic Facility Location problem on planar graphs\n(non-uniform, uncapacitated). Given an edge-weighted planar graph $G$, a set of\nclients $C\\subseteq V(G)$, a set of facilities $F\\subseteq V(G)$, and opening\ncosts $\\mathsf{open} \\colon F \\to \\mathbb{R}_{\\geq 0}$, the goal is to find a\nsubset $D$ of $F$ that minimizes $\\sum_{c \\in C} \\min_{f \\in D}\n\\mathrm{dist}(c,f) + \\sum_{f \\in D} \\mathsf{open}(f)$.\n  The Facility Location problem remains one of the most classic and fundamental\noptimization problem for which it is not known whether it admits a\npolynomial-time approximation scheme (PTAS) on planar graphs despite\nsignificant effort for obtaining one. We solve this open problem by giving an\nalgorithm that for any $\\varepsilon>0$, computes a solution of cost at most\n$(1+\\varepsilon)$ times the optimum in time $n^{2^{O(\\varepsilon^{-2} \\log\n(1/\\varepsilon))}}$.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:08:19 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1904.10701", "submitter": "Ran Duan", "authors": "Ran Duan, Ce Jin, Hongxun Wu", "title": "Faster Algorithms for All Pairs Non-decreasing Paths Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an improved algorithm for the All Pairs\nNon-decreasing Paths (APNP) problem on weighted simple digraphs, which has\nrunning time $\\tilde{O}(n^{\\frac{3 + \\omega}{2}}) = \\tilde{O}(n^{2.686})$. Here\n$n$ is the number of vertices, and $\\omega < 2.373$ is the exponent of time\ncomplexity of fast matrix multiplication [Williams 2012, Le Gall 2014]. This\nmatches the current best upper bound for $(\\max, \\min)$-matrix product [Duan,\nPettie 2009] which is reducible to APNP. Thus, further improvement for APNP\nwill imply a faster algorithm for $(\\max, \\min)$-matrix product. The previous\nbest upper bound for APNP on weighted digraphs was $\\tilde{O}(n^{\\frac{1}{2}(3\n+ \\frac{3 - \\omega}{\\omega + 1} + \\omega)}) = \\tilde{O}(n^{2.78})$ [Duan, Gu,\nZhang 2018]. We also show an $\\tilde{O}(n^2)$ time algorithm for APNP in\nundirected graphs which also reaches optimal within logarithmic factors.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 08:56:58 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Duan", "Ran", ""], ["Jin", "Ce", ""], ["Wu", "Hongxun", ""]]}, {"id": "1904.10719", "submitter": "Amit Kumar", "authors": "Mehul Kumar, Amit Kumar and C. Pandu Rangan", "title": "Reoptimization of Path Vertex Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most optimization problems are notoriously hard. Considerable efforts must be\nspent in obtaining an optimal solution to certain instances that we encounter\nin the real world scenarios. Often it turns out that input instances get\nmodified locally in some small ways due to changes in the application world.\nThe natural question here is, given an optimal solution for an old instance\n$I_O$, can we construct an optimal solution for the new instance $I_N$, where\n$I_N$ is the instance $I_O$ with some local modifications. Reoptimization of\nNP-hard optimization problem precisely addresses this concern. It turns out\nthat for some reoptimization versions of the NP-hard problems, we may only hope\nto obtain an approximate solution to a new instance. In this paper, we\nspecifically address the reoptimization of path vertex cover problem. The\nobjective in $k$-$path$ vertex cover problem is to compute a minimum subset $S$\nof the vertices in a graph $G$ such that after removal of $S$ from $G$ there is\nno path with $k$ vertices in the graph. We show that when a constant number of\nvertices are inserted, reoptimizing unweighted $k$-$path$ vertex cover problem\nadmits a PTAS. For weighted $3$-$path$ vertex cover problem, we show that when\na constant number of vertices are inserted, the reoptimization algorithm\nachieves an approximation factor of $1.5$, hence an improvement from known\n$2$-approximation algorithm for the optimization version. We provide\nreoptimization algorithm for weighted $k$-$path$ vertex cover problem $(k \\geq\n4)$ on bounded degree graphs, which is also an NP-hard problem. Given a\n$\\rho$-approximation algorithm for $k$-$path$ vertex cover problem on bounded\ndegree graphs, we show that it can be reoptimized within an approximation\nfactor of $(2-\\frac{1}{\\rho})$ under constant number of vertex insertions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:49:59 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Kumar", "Mehul", ""], ["Kumar", "Amit", ""], ["Rangan", "C. Pandu", ""]]}, {"id": "1904.10748", "submitter": "Kaito Fujii", "authors": "Kaito Fujii, Shinsaku Sakaue", "title": "Beyond Adaptive Submodularity: Approximation Guarantees of Greedy Policy\n  with Adaptive Submodularity Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new concept named adaptive submodularity ratio to study the\ngreedy policy for sequential decision making. While the greedy policy is known\nto perform well for a wide variety of adaptive stochastic optimization problems\nin practice, its theoretical properties have been analyzed only for a limited\nclass of problems. We narrow the gap between theory and practice by using\nadaptive submodularity ratio, which enables us to prove approximation\nguarantees of the greedy policy for a substantially wider class of problems.\nExamples of newly analyzed problems include important applications such as\nadaptive influence maximization and adaptive feature selection. Our adaptive\nsubmodularity ratio also provides bounds of adaptivity gaps. Experiments\nconfirm that the greedy policy performs well with the applications being\nconsidered compared to standard heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 11:18:47 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Fujii", "Kaito", ""], ["Sakaue", "Shinsaku", ""]]}, {"id": "1904.10850", "submitter": "Dariusz Dereniowski", "authors": "Jurek Czyzowicz and Dariusz Dereniowski and Andrzej Pelc", "title": "Building a Nest by an Automaton", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot modeled as a deterministic finite automaton has to build a structure\nfrom material available to it. The robot navigates in the infinite oriented\ngrid $\\mathbb{Z} \\times \\mathbb{Z}$. Some cells of the grid are full (contain a\nbrick) and others are empty. The subgraph of the grid induced by full cells,\ncalled the field, is initially connected. The (Manhattan) distance between the\nfarthest cells of the field is called its span. The robot starts at a full\ncell. It can carry at most one brick at a time. At each step it can pick a\nbrick from a full cell, move to an adjacent cell and drop a brick at an empty\ncell. The aim of the robot is to construct the most compact possible structure\ncomposed of all bricks, i.e., a nest. That is, the robot has to move all bricks\nin such a way that the span of the resulting field be the smallest. Our main\nresult is the design of a deterministic finite automaton that accomplishes this\ntask and subsequently stops, for every initially connected field, in time\n$O(sz)$, where $s$ is the span of the initial field and $z$ is the number of\nbricks. We show that this complexity is optimal.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 14:45:44 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Czyzowicz", "Jurek", ""], ["Dereniowski", "Dariusz", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1904.11134", "submitter": "Nikolaj Tatti", "authors": "Michael Mampaey, Jilles Vreeken, Nikolaj Tatti", "title": "Summarizing Data Succinctly with the Most Informative Itemsets", "comments": "Journal version. The previous version is the conference version", "journal-ref": null, "doi": "10.1145/2382577.2382580", "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge discovery from data is an inherently iterative process. That is,\nwhat we know about the data greatly determines our expectations, and therefore,\nwhat results we would find interesting and/or surprising. Given new knowledge\nabout the data, our expectations will change. Hence, in order to avoid\nredundant results, knowledge discovery algorithms ideally should follow such an\niterative updating procedure.\n  With this in mind, we introduce a well-founded approach for succinctly\nsummarizing data with the most informative itemsets; using a probabilistic\nmaximum entropy model, we iteratively find the itemset that provides us the\nmost novel information--that is, for which the frequency in the data surprises\nus the most---and in turn we update our model accordingly. As we use the\nMaximum Entropy principle to obtain unbiased probabilistic models, and only\ninclude those itemsets that are most informative with regard to the current\nmodel, the summaries we construct are guaranteed to be both descriptive and\nnon-redundant.\n  The algorithm that we present, called MTV, can either discover the top-$k$\nmost informative itemsets, or we can employ either the Bayesian Information\nCriterion (BIC) or the Minimum Description Length (MDL) principle to\nautomatically identify the set of itemsets that together summarize the data\nwell. In other words, our method will `tell you what you need to know' about\nthe data. Importantly, it is a one-phase algorithm: rather than picking\nitemsets from a user-provided candidate set, itemsets and their supports are\nmined on-the-fly. To further its applicability, we provide an efficient method\nto compute the maximum entropy distribution using Quick Inclusion-Exclusion.\n  Experiments on our method, using synthetic, benchmark, and real data, show\nthat the discovered summaries are succinct, and correctly identify the key\npatterns in the data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 02:59:53 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 01:16:11 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Mampaey", "Michael", ""], ["Vreeken", "Jilles", ""], ["Tatti", "Nikolaj", ""]]}, {"id": "1904.11244", "submitter": "Falko Hegerfeld", "authors": "Falko Hegerfeld and Stefan Kratsch", "title": "On adaptive algorithms for maximum matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fundamental Maximum Matching problem the task is to find a maximum\ncardinality set of pairwise disjoint edges in a given undirected graph. The\nfastest algorithm for this problem, due to Micali and Vazirani, runs in time\n$\\mathcal{O}(\\sqrt{n}m)$ and stands unbeaten since 1980. It is complemented by\nfaster, often linear-time, algorithms for various special graph classes.\nMoreover, there are fast parameterized algorithms, e.g., time\n$\\mathcal{O}(km\\log n)$ relative to tree-width $k$, which outperform\n$\\mathcal{O}(\\sqrt{n}m)$ when the parameter is sufficiently small.\n  We show that the Micali-Vazirani algorithm, and in fact any algorithm\nfollowing the phase framework of Hopcroft and Karp, is adaptive to beneficial\ninput structure. We exhibit several graph classes for which such algorithms run\nin linear time $\\mathcal{O}(n+m)$. More strongly, we show that they run in time\n$\\mathcal{O}(\\sqrt{k}m)$ for graphs that are $k$ vertex deletions away from any\nof several such classes, without explicitly computing an optimal or approximate\ndeletion set; before, most such bounds were at least $\\Omega(km)$. Thus, any\nphase-based matching algorithm with linear-time phases obliviously interpolates\nbetween linear time for $k=\\mathcal{O}(1)$ and the worst case of\n$\\mathcal{O}(\\sqrt{n}m)$ when $k=\\Theta(n)$. We complement our findings by\nproving that the phase framework by itself still allows $\\Omega(\\sqrt{n})$\nphases, and hence time $\\Omega(\\sqrt{n}m)$, even on paths, cographs, and\nbipartite chain graphs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 10:03:35 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Hegerfeld", "Falko", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1904.11263", "submitter": "Mantas Mikaitis", "authors": "Michael Hopkins and Mantas Mikaitis and Dave R. Lester and Steve\n  Furber", "title": "Stochastic rounding and reduced-precision fixed-point arithmetic for\n  solving neural ordinary differential equations", "comments": "Submitted to Philosophical Transactions of the Royal Society A", "journal-ref": null, "doi": "10.1098/rsta.2019.0052", "report-no": null, "categories": "cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although double-precision floating-point arithmetic currently dominates\nhigh-performance computing, there is increasing interest in smaller and simpler\narithmetic types. The main reasons are potential improvements in energy\nefficiency and memory footprint and bandwidth. However, simply switching to\nlower-precision types typically results in increased numerical errors. We\ninvestigate approaches to improving the accuracy of reduced-precision\nfixed-point arithmetic types, using examples in an important domain for\nnumerical computation in neuroscience: the solution of Ordinary Differential\nEquations (ODEs). The Izhikevich neuron model is used to demonstrate that\nrounding has an important role in producing accurate spike timings from\nexplicit ODE solution algorithms. In particular, fixed-point arithmetic with\nstochastic rounding consistently results in smaller errors compared to single\nprecision floating-point and fixed-point arithmetic with round-to-nearest\nacross a range of neuron behaviours and ODE solvers. A computationally much\ncheaper alternative is also investigated, inspired by the concept of dither\nthat is a widely understood mechanism for providing resolution below the least\nsignificant bit (LSB) in digital signal processing. These results will have\nimplications for the solution of ODEs in other subject areas, and should also\nbe directly relevant to the huge range of practical problems that are\nrepresented by Partial Differential Equations (PDEs).\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 11:26:40 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 16:20:46 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 11:38:58 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 08:42:45 GMT"}, {"version": "v5", "created": "Wed, 22 Jan 2020 10:07:04 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Hopkins", "Michael", ""], ["Mikaitis", "Mantas", ""], ["Lester", "Dave R.", ""], ["Furber", "Steve", ""]]}, {"id": "1904.11285", "submitter": "Jesper Nederlof", "authors": "Jesper Nederlof", "title": "Detecting and Counting Small Patterns in Planar Graphs in Subexponential\n  Parameterized Time", "comments": "25 pages, 1 figure, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that takes as input an $n$-vertex planar graph $G$\nand a $k$-vertex pattern graph $P$, and computes the number of (induced) copies\nof $P$ in $G$ in $2^{O(k/\\log k)}n^{O(1)}$ time. If $P$ is a matching,\nindependent set, or connected bounded maximum degree graph, the runtime reduces\nto $2^{\\tilde{O}(\\sqrt{k})}n^{O(1)}$.\n  While our algorithm counts all copies of $P$, it also improves the fastest\nalgorithms that only detect copies of $P$. Before our work, no $2^{O(k/\\log\nk)}n^{O(1)}$ time algorithms for detecting unrestricted patterns $P$ were\nknown, and by a result of Bodlaender et al. [ICALP 2016] a $2^{o(k/\\log\nk)}n^{O(1)}$ time algorithm would violate the Exponential Time Hypothesis\n(ETH). Furthermore, it was only known how to detect copies of a fixed connected\nbounded maximum degree pattern $P$ in $2^{\\tilde{O}(\\sqrt{k})}n^{O(1)}$ time\nprobabilistically. For counting problems, it was a repeatedly asked open\nquestion whether $2^{o(k)}n^{O(1)}$ time algorithms exist that count even\nspecial patterns such as independent sets, matchings and paths in planar\ngraphs. The above results resolve this question in a strong sense by giving\nalgorithms for counting versions of problems with running times equal to the\nETH lower bounds for their decision versions.\n  Generally speaking, our algorithm counts copies of $P$ in time proportional\nto its number of non-isomorphic separations of order $\\tilde{O}(\\sqrt{k})$. The\nalgorithm introduces a new recursive approach to construct families of balanced\ncycle separators in planar graphs that have limited overlap inspired by methods\nfrom Fomin et al. [FOCS 2016], a new `efficient' inclusion-exclusion based\nargument and uses methods from Bodlaender et al. [ICALP 2016].\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:11:02 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Nederlof", "Jesper", ""]]}, {"id": "1904.11323", "submitter": "Vitaly Aksenov", "authors": "Vitaly Aksenov Dan Alistarh Petr Kuznetsov", "title": "Performance Prediction for Coarse-Grained Locking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard design pattern found in many concurrent data structures, such as\nhash tables or ordered containers, is an alternation of parallelizable sections\nthat incur no data conflicts and critical sections that must run sequentially\nand are protected with locks. A lock can be viewed as a queue that arbitrates\nthe order in which the critical sections are executed, and a natural question\nis whether we can use stochastic analysis to predict the resulting throughput.\nAs a preliminary evidence to the affirmative, we describe a simple model that\ncan be used to predict the throughput of coarse-grained lock-based algorithms.\nWe show that our model works well for CLH lock, and we expect it to work for\nother popular lock designs such as TTAS, MCS, etc.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 13:25:57 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Kuznetsov", "Vitaly Aksenov Dan Alistarh Petr", ""]]}, {"id": "1904.11440", "submitter": "Keren Censor-Hillel", "authors": "Matthias Bonne and Keren Censor-Hillel", "title": "Distributed Detection of Cliques in Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an in-depth study of the fundamental problems of finding\nsmall subgraphs in distributed dynamic networks. While some problems are\ntrivially easy to handle, such as detecting a triangle that emerges after an\nedge insertion, we show that, perhaps somewhat surprisingly, other problems\nexhibit a wide range of complexities in terms of the trade-offs between their\nround and bandwidth complexities. In the case of triangles, which are only\naffected by the topology of the immediate neighborhood, some end results are:\n  \\begin{itemize}\n  \\item The bandwidth complexity of $1$-round dynamic triangle detection or\nlisting is $\\Theta(1)$.\n  \\item The bandwidth complexity of $1$-round dynamic triangle membership\nlisting is $\\Theta(1)$ for node/edge deletions, $\\Theta(n^{1/2})$ for edge\ninsertions, and $\\Theta(n)$ for node insertions.\n  \\item The bandwidth complexity of $1$-round dynamic triangle membership\ndetection is $\\Theta(1)$ for node/edge deletions, $O(\\log n)$ for edge\ninsertions, and $\\Theta(n)$ for node insertions.\n  \\end{itemize}\n  Most of our upper and lower bounds are \\emph{tight}. Additionally, we provide\nalmost always tight upper and lower bounds for larger cliques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:32:21 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Bonne", "Matthias", ""], ["Censor-Hillel", "Keren", ""]]}, {"id": "1904.11446", "submitter": "Simon Apers", "authors": "Simon Apers", "title": "Quantum Walk Sampling by Growing Seed Sets", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a new algorithm for creating a superposition over the\nedge set of a graph, encoding a quantum sample of the random walk stationary\ndistribution. The algorithm requires a number of quantum walk steps scaling as\n$\\widetilde{O}(m^{1/3} \\delta^{-1/3})$, with $m$ the number of edges and\n$\\delta$ the random walk spectral gap. This improves on existing strategies by\ninitially growing a classical seed set in the graph, from which a quantum walk\nis then run. The algorithm leads to a number of improvements: (i) it provides a\nnew bound on the setup cost of quantum walk search algorithms, (ii) it yields a\nnew algorithm for $st$-connectivity, and (iii) it allows to create a\nsuperposition over the isomorphisms of an $n$-node graph in time\n$\\widetilde{O}(2^{n/3})$, surpassing the $\\Omega(2^{n/2})$ barrier set by index\nerasure.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:43:02 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Apers", "Simon", ""]]}, {"id": "1904.11601", "submitter": "Nikhil Vyas", "authors": "Mina Dalirrooyfard, Virginia Vassilevska Williams, Nikhil Vyas, Nicole\n  Wein", "title": "Tight Approximation Algorithms for Bichromatic Graph Diameter and\n  Related Problems", "comments": "To appear in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the most fundamental and well-studied graph parameters are the\nDiameter (the largest shortest paths distance) and Radius (the smallest\ndistance for which a \"center\" node can reach all other nodes). The natural and\nimportant $ST$-variant considers two subsets $S$ and $T$ of the vertex set and\nlets the $ST$-diameter be the maximum distance between a node in $S$ and a node\nin $T$, and the $ST$-radius be the minimum distance for a node of $S$ to reach\nall nodes of $T$. The bichromatic variant is the special case in which $S$ and\n$T$ partition the vertex set.\n  In this paper we present a comprehensive study of the approximability of $ST$\nand Bichromatic Diameter, Radius, and Eccentricities, and variants, in graphs\nwith and without directions and weights. We give the first nontrivial\napproximation algorithms for most of these problems, including time/accuracy\ntrade-off upper and lower bounds. We show that nearly all of our obtained\nbounds are tight under the Strong Exponential Time Hypothesis (SETH), or the\nrelated Hitting Set Hypothesis.\n  For instance, for Bichromatic Diameter in undirected weighted graphs with $m$\nedges, we present an $\\tilde{O}(m^{3/2})$ time $5/3$-approximation algorithm,\nand show that under SETH, neither the running time, nor the approximation\nfactor can be significantly improved while keeping the other unchanged.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 21:45:29 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Williams", "Virginia Vassilevska", ""], ["Vyas", "Nikhil", ""], ["Wein", "Nicole", ""]]}, {"id": "1904.11606", "submitter": "Nikhil Vyas", "authors": "Mina Dalirrooyfard, Virginia Vassilevska Williams, Nikhil Vyas, Nicole\n  Wein, Yinzhan Xu, Yuancheng Yu", "title": "Approximation Algorithms for Min-Distance Problems", "comments": "To appear in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fundamental graph parameters such as the Diameter and Radius in\ndirected graphs, when distances are measured using a somewhat unorthodox but\nnatural measure: the distance between $u$ and $v$ is the minimum of the\nshortest path distances from $u$ to $v$ and from $v$ to $u$. The center node in\na graph under this measure can for instance represent the optimal location for\na hospital to ensure the fastest medical care for everyone, as one can either\ngo to the hospital, or a doctor can be sent to help.\n  By computing All-Pairs Shortest Paths, all pairwise distances and thus the\nparameters we study can be computed exactly in $\\tilde{O}(mn)$ time for\ndirected graphs on $n$ vertices, $m$ edges and nonnegative edge weights.\nFurthermore, this time bound is tight under the Strong Exponential Time\nHypothesis [Roditty-Vassilevska W. STOC 2013] so it is natural to study how\nwell these parameters can be approximated in $O(mn^{1-\\epsilon})$ time for\nconstant $\\epsilon>0$. Abboud, Vassilevska Williams, and Wang [SODA 2016] gave\na polynomial factor approximation for Diameter and Radius, as well as a\nconstant factor approximation for both problems in the special case where the\ngraph is a DAG. We greatly improve upon these bounds by providing the first\nconstant factor approximations for Diameter, Radius and the related\nEccentricities problem in general graphs. Additionally, we provide a hierarchy\nof algorithms for Diameter that gives a time/accuracy trade-off.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 22:00:54 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 13:06:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Williams", "Virginia Vassilevska", ""], ["Vyas", "Nikhil", ""], ["Wein", "Nicole", ""], ["Xu", "Yinzhan", ""], ["Yu", "Yuancheng", ""]]}, {"id": "1904.11668", "submitter": "Jos\\'e A. Soto", "authors": "Arturo I. Merino and Jos\\'e A. Soto", "title": "The minimum cost query problem on matroids with uncertainty areas", "comments": "20 pages. A preliminary version appears in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimum weight basis problem on matroid when elements' weights\nare uncertain. For each element we only know a set of possible values (an\nuncertainty area) that contains its real weight. In some cases there exist\nbases that are uniformly optimal, that is, they are minimum weight bases for\nevery possible weight function obeying the uncertainty areas. In other cases,\ncomputing such a basis is not possible unless we perform some queries for the\nexact value of some elements.\n  Our main result is a polynomial time algorithm for the following problem.\nGiven a matroid with uncertainty areas and a query cost function on its\nelements, find the set of elements of minimum total cost that we need to\nsimultaneously query such that, no matter their revelation, the resulting\ninstance admits a uniformly optimal base. We also provide combinatorial\ncharacterizations of all uniformly optimal bases, when one exists; and of all\nsets of queries that can be performed so that after revealing the corresponding\nweights the resulting instance admits a uniformly optimal base.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 04:43:13 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Merino", "Arturo I.", ""], ["Soto", "Jos\u00e9 A.", ""]]}, {"id": "1904.11757", "submitter": "Jan-Hendrik Lorenz", "authors": "Jan-Hendrik Lorenz, Julian Nickerl", "title": "The Potential of Restarts for ProbSAT", "comments": "Eurocast 2019", "journal-ref": null, "doi": "10.1007/978-3-030-45093-9_43", "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyses the potential of restarts for probSAT, a quite successful\nalgorithm for k-SAT, by estimating its runtime distributions on random 3-SAT\ninstances that are close to the phase transition. We estimate an optimal\nrestart time from empirical data, reaching a potential speedup factor of 1.39.\nCalculating restart times from fitted probability distributions reduces this\nfactor to a maximum of 1.30. A spin-off result is that the Weibull distribution\napproximates the runtime distribution for over 93% of the used instances well.\nA machine learning pipeline is presented to compute a restart time for a\nfixed-cutoff strategy to exploit this potential. The main components of the\npipeline are a random forest for determining the distribution type and a neural\nnetwork for the distribution's parameters. ProbSAT performs statistically\nsignificantly better than Luby's restart strategy and the policy without\nrestarts when using the presented approach. The structure is particularly\nadvantageous on hard problems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 10:51:11 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lorenz", "Jan-Hendrik", ""], ["Nickerl", "Julian", ""]]}, {"id": "1904.11777", "submitter": "Seeun William Umboh", "authors": "Joseph (Seffi) Naor and Seeun William Umboh and David P. Williamson", "title": "Tight Bounds for Online Weighted Tree Augmentation", "comments": "Preliminary version in ICALP19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weighted Tree Augmentation problem (WTAP) is a fundamental problem in\nnetwork design. In this paper, we consider this problem in the online setting.\nWe are given an $n$-vertex spanning tree $T$ and an additional set $L$ of edges\n(called links) with costs. Then, terminal pairs arrive one-by-one and our task\nis to maintain a low-cost subset of links $F$ such that every terminal pair\nthat has arrived so far is $2$-edge-connected in $T \\cup F$. This online\nproblem was first studied by Gupta, Krishnaswamy and Ravi (SICOMP 2012) who\nused it as a subroutine for the online survivable network design problem. They\ngave a deterministic $O(\\log^2 n)$-competitive algorithm and showed an\n$\\Omega(\\log n)$ lower bound on the competitive ratio of randomized algorithms.\nThe case when $T$ is a path is also interesting: it is exactly the online\ninterval set cover problem, which also captures as a special case the parking\npermit problem studied by Meyerson (FOCS 2005). The contribution of this paper\nis to give tight results for online weighted tree and path augmentation\nproblems. The main result of this work is a deterministic $O(\\log\nn)$-competitive algorithm for online WTAP, which is tight up to constant\nfactors.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 11:42:45 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Joseph", "", "", "Seffi"], ["Naor", "", ""], ["Umboh", "Seeun William", ""], ["Williamson", "David P.", ""]]}, {"id": "1904.11807", "submitter": "Kun He", "authors": "Weiming Feng, Kun He, Xiaoming Sun, Yitong Yin", "title": "Dynamic inference in probabilistic graphical models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models, such as Markov random fields (MRFs), are\nuseful for describing high-dimensional distributions in terms of local\ndependence structures. The probabilistic inference is a fundamental problem\nrelated to graphical models, and sampling is a main approach for the problem.\nIn this paper, we study probabilistic inference problems when the graphical\nmodel itself is changing dynamically with time. Such dynamic inference problems\narise naturally in today's application, e.g.~multivariate time-series data\nanalysis and practical learning procedures.\n  We give a dynamic algorithm for sampling-based probabilistic inferences in\nMRFs, where each dynamic update can change the underlying graph and all\nparameters of the MRF simultaneously, as long as the total amount of changes is\nbounded. More precisely, suppose that the MRF has $n$ variables and\npolylogarithmic-bounded maximum degree, and $N(n)$ independent samples are\nsufficient for the inference for a polynomial function $N(\\cdot)$. Our\nalgorithm dynamically maintains an answer to the inference problem using\n$\\widetilde{O}(n N(n))$ space cost, and $\\widetilde{O}(N(n) + n)$ incremental\ntime cost upon each update to the MRF, as long as the well-known\nDobrushin-Shlosman condition is satisfied by the MRFs. Compared to the static\ncase, which requires $\\Omega(n N(n))$ time cost for redrawing all $N(n)$\nsamples whenever the MRF changes, our dynamic algorithm gives a\n$\\widetilde\\Omega(\\min\\{n, N(n)\\})$-factor speedup. Our approach relies on a\nnovel dynamic sampling technique, which transforms local Markov chains (a.k.a.\nsingle-site dynamics) to dynamic sampling algorithms, and an \"algorithmic\nLipschitz\" condition that we establish for sampling from graphical models,\nnamely, when the MRF changes by a small difference, samples can be modified to\nreflect the new distribution, with cost proportional to the difference on MRF.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 12:45:30 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 05:58:58 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Feng", "Weiming", ""], ["He", "Kun", ""], ["Sun", "Xiaoming", ""], ["Yin", "Yitong", ""]]}, {"id": "1904.11810", "submitter": "Karoliina Lehtinen", "authors": "Karoliina Lehtinen, Sven Schewe, Dominik Wojtczak", "title": "Improving the complexity of Parys' recursive algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parys has recently proposed a quasi-polynomial version of Zielonka's\nrecursive algorithm for solving parity games. In this brief note we suggest a\nvariation of his algorithm that improves the complexity to meet the\nstate-of-the-art complexity of broadly $2^{O((\\log n)(\\log c))}$, while\nproviding polynomial bounds when the number of colours is logarithmic.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 12:49:13 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 10:52:56 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 12:33:49 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 17:11:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Lehtinen", "Karoliina", ""], ["Schewe", "Sven", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1904.11895", "submitter": "Shantanav Chakraborty", "authors": "Shantanav Chakraborty, Kyle Luh, J\\'er\\'emie Roland", "title": "On analog quantum algorithms for the mixing of Markov chains", "comments": "The section concerning time-averaged mixing (Sec VIII) has been\n  updated: Now contains numerical plots and an intuitive discussion on the\n  random matrix theory results used to derive the results of arXiv:2001.06305", "journal-ref": "Phys. Rev. A 102, 022423 (2020)", "doi": "10.1103/PhysRevA.102.022423", "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of sampling from the stationary distribution of a Markov chain\nfinds widespread applications in a variety of fields. The time required for a\nMarkov chain to converge to its stationary distribution is known as the\nclassical mixing time. In this article, we deal with analog quantum algorithms\nfor mixing. First, we provide an analog quantum algorithm that given a Markov\nchain, allows us to sample from its stationary distribution in a time that\nscales as the sum of the square root of the classical mixing time and the\nsquare root of the classical hitting time. Our algorithm makes use of the\nframework of interpolated quantum walks and relies on Hamiltonian evolution in\nconjunction with von Neumann measurements.\n  There also exists a different notion for quantum mixing: the problem of\nsampling from the limiting distribution of quantum walks, defined in a\ntime-averaged sense. In this scenario, the quantum mixing time is defined as\nthe time required to sample from a distribution that is close to this limiting\ndistribution. Recently we provided an upper bound on the quantum mixing time\nfor Erd\\\"os-Renyi random graphs [Phys. Rev. Lett. 124, 050501 (2020)]. Here, we\nalso extend and expand upon our findings therein. Namely, we provide an\nintuitive understanding of the state-of-the-art random matrix theory tools used\nto derive our results. In particular, for our analysis we require information\nabout macroscopic, mesoscopic and microscopic statistics of eigenvalues of\nrandom matrices which we highlight here. Furthermore, we provide numerical\nsimulations that corroborate our analytical findings and extend this notion of\nmixing from simple graphs to any ergodic, reversible, Markov chain.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 15:26:02 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 10:19:23 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Chakraborty", "Shantanav", ""], ["Luh", "Kyle", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1904.11946", "submitter": "Mehraneh Liaee", "authors": "Samuel Haney, Mehraneh Liaee, Bruce M. Maggs, Debmalya Panigrahi,\n  Rajmohan Rajaraman, and Ravi Sundaram", "title": "Retracting Graphs to Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the algorithmic study of retracting a graph into a cycle in the\ngraph, which seeks a mapping of the graph vertices to the cycle vertices, so as\nto minimize the maximum stretch of any edge, subject to the constraint that the\nrestriction of the mapping to the cycle is the identity map. This problem has\nits roots in the rich theory of retraction of topological spaces, and has\nstrong ties to well-studied metric embedding problems such as minimum bandwidth\nand 0-extension.\n  Our first result is an O(min{k, sqrt{n}})-approximation for retracting any\ngraph on n nodes to a cycle with k nodes. We also show a surprising connection\nto Sperner's Lemma that rules out the possibility of improving this result\nusing natural convex relaxations of the problem. Nevertheless, if the problem\nis restricted to planar graphs, we show that we can overcome these integrality\ngaps using an exact combinatorial algorithm, which is the technical centerpiece\nof the paper. Building on our planar graph algorithm, we also obtain a\nconstant-factor approximation algorithm for retraction of points in the\nEuclidean plane to a uniform cycle.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:24:27 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Haney", "Samuel", ""], ["Liaee", "Mehraneh", ""], ["Maggs", "Bruce M.", ""], ["Panigrahi", "Debmalya", ""], ["Rajaraman", "Rajmohan", ""], ["Sundaram", "Ravi", ""]]}, {"id": "1904.11965", "submitter": "Michael J(\\\"U)Nger", "authors": "Michael Juenger, Elisabeth Lobe, Petra Mutzel, Gerhard Reinelt, Franz\n  Rendl, Giovanni Rinaldi, Tobias Stollenwerk", "title": "Performance of a Quantum Annealer for Ising Ground State Computations on\n  Chimera Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PF quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum annealing is getting increasing attention in combinatorial\noptimization. The quantum processing unit by D-Wave is constructed to\napproximately solve Ising models on so-called Chimera graphs. Ising models are\nequivalent to quadratic unconstrained binary optimization (QUBO) problems and\nmaximum cut problems on the associated graphs. We have tailored branch-and-cut\nas well as semidefinite programming algorithms for solving Ising models for\nChimera graphs to provable optimality and use the strength of these approaches\nfor comparing our solution values to those obtained on the current quantum\nannealing machine D-Wave 2000Q. This allows for the assessment of the quality\nof solutions produced by the D-Wave hardware. It has been a matter of\ndiscussion in the literature how well the D-Wave hardware performs at its\nnative task, and our experiments shed some more light on this issue.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:39:06 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Juenger", "Michael", ""], ["Lobe", "Elisabeth", ""], ["Mutzel", "Petra", ""], ["Reinelt", "Gerhard", ""], ["Rendl", "Franz", ""], ["Rinaldi", "Giovanni", ""], ["Stollenwerk", "Tobias", ""]]}, {"id": "1904.12000", "submitter": "Vahan Mkrtchyan", "authors": "Federico Cor\\`o and Gianlorenzo D'Angelo and Vahan Mkrtchyan", "title": "On the fixed-parameter tractability of the maximum connectivity\n  improvement problem", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Maximum Connectivity Improvement (MCI) problem, we are given a\ndirected graph $G=(V,E)$ and an integer $B$ and we are asked to find $B$ new\nedges to be added to $G$ in order to maximize the number of connected pairs of\nvertices in the resulting graph. The MCI problem has been studied from the\napproximation point of view. In this paper, we approach it from the\nparameterized complexity perspective in the case of directed acyclic graphs. We\nshow several hardness and algorithmic results with respect to different natural\nparameters. Our main result is that the problem is $W[2]$-hard for parameter\n$B$ and it is FPT for parameters $|V| - B$ and $\\nu$, the matching number of\n$G$. We further characterize the MCI problem with respect to other\ncomplementary parameters.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 18:03:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Cor\u00f2", "Federico", ""], ["D'Angelo", "Gianlorenzo", ""], ["Mkrtchyan", "Vahan", ""]]}, {"id": "1904.12011", "submitter": "Vahan Mkrtchyan", "authors": "Vahan Mkrtchyan and Garik Petrosyan and K. Subramani", "title": "Parameterized algorithms for Partial vertex covers in bipartite graphs", "comments": "12 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the weighted partial vertex cover problem (WPVC), we are given a graph\n$G=(V,E)$, cost function $c:V\\rightarrow N$, profit function $p:E\\rightarrow\nN$, and positive integers $R$ and $L$. The goal is to check whether there is a\nsubset $V'\\subseteq V$ of cost at most $R$, such that the total profit of edges\ncovered by $V'$ is at least $L$. In this paper we study the fixed-parameter\ntractability of WPVC in bipartite graphs (WPVCB). By extending the methods of\nAmini et al., we show that WPVCB is FPT with respect to $R$ if $c\\equiv 1$. On\nthe negative side, it is $W[1]$-hard for arbitrary $c$, even when $p\\equiv 1$.\nIn particular, WPVCB is $W[1]$-hard parameterized by $R$. We complement this\nnegative result by proving that for bounded-degree graphs WPVC is FPT with\nrespect to $R$. The same result holds for the case of WPVCB when we allow to\ntake only one fractional vertex. Additionally, we show that WPVC is FPT with\nrespect to $L$. Finally, we discuss a variant of PVCB in which the edges\ncovered are constrained to include a matching of prescribed size and derive a\nparamterized algorithm for the same.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 18:32:44 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Mkrtchyan", "Vahan", ""], ["Petrosyan", "Garik", ""], ["Subramani", "K.", ""]]}, {"id": "1904.12042", "submitter": "Hung Le", "authors": "Hung Le and Shay Solomon", "title": "Truly Optimal Euclidean Spanners", "comments": "59 pages, 23 figures, rewriting section 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean spanners are important geometric structures, having found numerous\napplications over the years. Cornerstone results in this area from the late 80s\nand early 90s state that for any $d$-dimensional $n$-point Euclidean space,\nthere exists a $(1+\\epsilon)$-spanner with $nO(\\epsilon^{-d+1})$ edges and\nlightness $O(\\epsilon^{-2d})$. Surprisingly, the fundamental question of\nwhether or not these dependencies on $\\epsilon$ and $d$ for small $d$ can be\nimproved has remained elusive, even for $d = 2$. This question naturally arises\nin any application of Euclidean spanners where precision is a necessity.\n  The state-of-the-art bounds $nO(\\epsilon^{-d+1})$ and $O(\\epsilon^{-2d})$ on\nthe size and lightness of spanners are realized by the {\\em greedy} spanner. In\n2016, Filtser and Solomon proved that, in low dimensional spaces, the greedy\nspanner is near-optimal. The question of whether the greedy spanner is truly\noptimal remained open to date.\n  The contribution of this paper is two-fold. We resolve these longstanding\nquestions by nailing down the exact dependencies on $\\epsilon$ and $d$ and\nshowing that the greedy spanner is truly optimal. Specifically, for any $d=\nO(1), \\epsilon = \\Omega({n}^{-\\frac{1}{d-1}})$:\n  - We show that any $(1+\\epsilon)$-spanner must have $n\n\\Omega(\\epsilon^{-d+1})$ edges, implying that the greedy (and other) spanners\nachieve the optimal size.\n  - We show that any $(1+\\epsilon)$-spanner must have lightness\n$\\Omega(\\epsilon^{-d})$, and then improve the upper bound on the lightness of\nthe greedy spanner from $O(\\epsilon^{-2d})$ to $O(\\epsilon^{-d})$.\n  We then complement our negative result for the size of spanners with a rather\ncounterintuitive positive result: Steiner points lead to a quadratic\nimprovement in the size of spanners! Our bound for the size of Steiner spanners\nis tight as well (up to lower-order terms).\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 20:45:24 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:21:37 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 04:09:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Le", "Hung", ""], ["Solomon", "Shay", ""]]}, {"id": "1904.12061", "submitter": "Haitao Wang", "authors": "Christopher Johnson and Haitao Wang", "title": "A Linear-Time Algorithm for Radius-Optimally Augmenting Paths in a\n  Metric Space", "comments": "A preliminary version to appear in WADS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a path graph of $n$ vertices embedded in a metric space. We\nconsider the problem of adding a new edge to $P$ to minimize the radius of the\nresulting graph. Previously, a similar problem for minimizing the diameter of\nthe graph was solved in $O(n\\log n)$ time. To the best of our knowledge, the\nproblem of minimizing the radius has not been studied before. In this paper, we\npresent an $O(n)$ time algorithm for the problem, which is optimal.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 22:10:17 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Johnson", "Christopher", ""], ["Wang", "Haitao", ""]]}, {"id": "1904.12068", "submitter": "Kai Li", "authors": "Yuzhe Tang, Ju Chen, Kai Li, Jianliang Xu, Qi Zhang", "title": "Authenticated Key-Value Stores with Hardware Enclaves", "comments": "eLSM, Enclave, key-value store, ADS, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticated data storage on an untrusted platform is an important computing\nparadigm for cloud applications ranging from big-data outsourcing, to\ncryptocurrency and certificate transparency log. These modern applications\nincreasingly feature update-intensive workloads, whereas existing authenticated\ndata structures (ADSs) designed with in-place updates are inefficient to handle\nsuch workloads. In this paper, we address this issue and propose a novel\nauthenticated log-structured merge tree (eLSM) based key-value store by\nleveraging Intel SGX enclaves.\n  We present a system design that runs the code of eLSM store inside enclave.\nTo circumvent the limited enclave memory (128 MB with the latest Intel CPUs),\nwe propose to place the memory buffer of the eLSM store outside the enclave and\nprotect the buffer using a new authenticated data structure by digesting\nindividual LSM-tree levels. We design protocols to support query authentication\nin data integrity, completeness (under range queries), and freshness. The proof\nin our protocol is made small by including only the Merkle proofs at selective\nlevels.\n  We implement eLSM on top of Google LevelDB and Facebook RocksDB with minimal\ncode change and performance interference. We evaluate the performance of eLSM\nunder the YCSB workload benchmark and show a performance advantage of up to\n4.5X speedup.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 22:45:04 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 19:28:39 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 23:38:02 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Tang", "Yuzhe", ""], ["Chen", "Ju", ""], ["Li", "Kai", ""], ["Xu", "Jianliang", ""], ["Zhang", "Qi", ""]]}, {"id": "1904.12217", "submitter": "Eyal Rozenberg", "authors": "Eyal Rozenberg", "title": "A computational model for analytic column stores", "comments": "A monograph. 99 pages (+ title page) with 27 figures. Full title\n  including subtitle: \"A computational model for analytic column stores with\n  focus on columnar representations of data and composite compression schemes\".\n  ACM classes given in lexicographic order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an abstract model for the computations performed by\nanalytic column stores or columnar query processors. The model is based on\ncircuits whose wires carry columns rather than scalar values, and whose nodes\napply operators with column inputs and outputs. This model allows expression of\nmost of the architectural features of existing column-store DBMSes through\ncolumnar execution plans, rather than such features being implemented\nsui-generis, and without the column store maintaining significant out-of-plan\ndata. A strict adherence to columnarity allows for a relatively simple and\nrobust model; enabling extensive and intensive optimization of almost all\naspects of query processing; and also enabling massive uniform parallelization\nof query process on modern hardware. Moreover, the computational model's\nexpressivity makes it useful also as an \\emph{analytical} tool for considering\ndesign aspects and features of existing column stores, individually and\ncomparatively.\n  To achieve the model's wide expressiveness, much of this work develops\nrepresentation schemes of relevant data structures as combinations of plain\ncolumns, with columnar circuits used as scheme encoders and decoders. A\nparticular focus is given to schemes which also compress the data, and their\nuse in query execution --- as an integral part of the computation: Subcircuits\nof larger columnar circuits, not black boxes. Decoder and encoder circuits are\nthus also composed to form more elaborate schemes. Such formulation allows both\nfor an alternative view of well-known compression schemes, and for the\ndevelopment of new columnar compression schemes with useful features; these\nshould be of independent interest irrespective of column store systems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 21:59:11 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 19:52:53 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rozenberg", "Eyal", ""]]}, {"id": "1904.12248", "submitter": "Wensheng Gan", "authors": "Wensheng Gan, Jerry Chun-Wei Lin, Jiexiong Zhang, Philippe\n  Fournier-Viger, Han-Chieh Chao, and Philip S. Yu", "title": "Fast Utility Mining on Complex Sequences", "comments": "Under review in IEEE TKDE, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-utility sequential pattern mining is an emerging topic in the field of\nKnowledge Discovery in Databases. It consists of discovering subsequences\nhaving a high utility (importance) in sequences, referred to as high-utility\nsequential patterns (HUSPs). HUSPs can be applied to many real-life\napplications, such as market basket analysis, E-commerce recommendation,\nclick-stream analysis and scenic route planning. For example, in economics and\ntargeted marketing, understanding economic behavior of consumers is quite\nchallenging, such as finding credible and reliable information on product\nprofitability. Several algorithms have been proposed to address this problem by\nefficiently mining utility-based useful sequential patterns. Nevertheless, the\nperformance of these algorithms can be unsatisfying in terms of runtime and\nmemory usage due to the combinatorial explosion of the search space for low\nutility threshold and large databases. Hence, this paper proposes a more\nefficient algorithm for the task of high-utility sequential pattern mining,\ncalled HUSP-ULL. It utilizes a lexicographic sequence (LS)-tree and a\nutility-linked (UL)-list structure to fast discover HUSPs. Furthermore, two\npruning strategies are introduced in HUSP-ULL to obtain tight upper-bounds on\nthe utility of candidate sequences, and reduce the search space by pruning\nunpromising candidates early. Substantial experiments both on real-life and\nsynthetic datasets show that the proposed algorithm can effectively and\nefficiently discover the complete set of HUSPs and outperforms the\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 03:16:56 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Gan", "Wensheng", ""], ["Lin", "Jerry Chun-Wei", ""], ["Zhang", "Jiexiong", ""], ["Fournier-Viger", "Philippe", ""], ["Chao", "Han-Chieh", ""], ["Yu", "Philip S.", ""]]}, {"id": "1904.12258", "submitter": "Liwei Zeng", "authors": "Liwei Zeng, Karen Smilowitz, Sunil Chopra", "title": "Generalizing the Covering Path Problem on a Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the covering path problem on a grid of R^{2}. We generalize earlier\nresults on a rectangular grid and prove that the covering path cost can be\nbounded by the area and perimeter of the grid. We provide (2+\\epsilon) and\n(1+\\epsilon)-approximations for the problem on a general grid and on a convex\ngrid, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 05:03:56 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zeng", "Liwei", ""], ["Smilowitz", "Karen", ""], ["Chopra", "Sunil", ""]]}, {"id": "1904.12334", "submitter": "Euiwoong Lee", "authors": "Vincent Cohen-Addad, Anupam Gupta, Amit Kumar, Euiwoong Lee, Jason Li", "title": "Tight FPT Approximations for $k$-Median and $k$-Means", "comments": "20 pages, to appear in ICALP 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the fine-grained complexity of approximating the classical\n$k$-median / $k$-means clustering problems in general metric spaces. We show\nhow to improve the approximation factors to $(1+2/e+\\varepsilon)$ and\n$(1+8/e+\\varepsilon)$ respectively, using algorithms that run in\nfixed-parameter time. Moreover, we show that we cannot do better in FPT time,\nmodulo recent complexity-theoretic conjectures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 15:10:07 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Gupta", "Anupam", ""], ["Kumar", "Amit", ""], ["Lee", "Euiwoong", ""], ["Li", "Jason", ""]]}, {"id": "1904.12337", "submitter": "Abhranil Chatterjee", "authors": "V.Arvind and Abhranil Chatterjee and Rajit Datta and Partha\n  Mukhopadhyay", "title": "Efficient Black-Box Identity Testing over Free Group Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hrube\\v{s} and Wigderson [HW14] initiated the study of noncommutative\narithmetic circuits with division computing a noncommutative rational function\nin the free skew field, and raised the question of rational identity testing.\nIt is now known that the problem can be solved in deterministic polynomial time\nin the white-box model for noncommutative formulas with inverses, and in\nrandomized polynomial time in the black-box model [GGOW16, IQS18, DM18], where\nthe running time is polynomial in the size of the formula. The complexity of\nidentity testing of noncommutative rational functions remains open in general\n(when the formula size is not polynomially bounded). We solve the problem for a\nnatural special case. We consider polynomial expressions in the free group\nalgebra $\\mathbb{F}\\langle X, X^{-1}\\rangle$ where $X=\\{x_1, x_2, \\ldots,\nx_n\\}$, a subclass of rational expressions of inversion height one. Our main\nresults are the following. 1. Given a degree $d$ expression $f$ in\n$\\mathbb{F}\\langle X, X^{-1}\\rangle$ as a black-box, we obtain a randomized\n$\\text{poly}(n,d)$ algorithm to check whether $f$ is an identically zero\nexpression or not. We obtain this by generalizing the Amitsur-Levitzki theorem\n[AL50] to $\\mathbb{F}\\langle X, X^{-1}\\rangle$. This also yields a\ndeterministic identity testing algorithm (and even an expression reconstruction\nalgorithm) that is polynomial time in the sparsity of the input expression. 2.\nGiven an expression $f$ in $\\mathbb{F}\\langle X, X^{-1}\\rangle$ of degree at\nmost $D$, and sparsity $s$, as black-box, we can check whether $f$ is\nidentically zero or not in randomized $\\text{poly}(n,\\log s, \\log D)$ time.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 15:48:00 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Arvind", "V.", ""], ["Chatterjee", "Abhranil", ""], ["Datta", "Rajit", ""], ["Mukhopadhyay", "Partha", ""]]}, {"id": "1904.12370", "submitter": "Sebastiano Vigna", "authors": "Stefano Marchini, Sebastiano Vigna", "title": "Compact Fenwick trees for dynamic ranking and selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fenwick tree is a classical implicit data structure that stores an array\nin such a way that modifying an element, accessing an element, computing a\nprefix sum and performing a predecessor search on prefix sums all take\nlogarithmic time. We introduce a number of variants which improve the classical\nimplementation of the tree: in particular, we can reduce its size when an upper\nbound on the array element is known, and we can perform much faster predecessor\nsearches. Our aim is to use our variants to implement an efficient dynamic bit\nvector: our structure is able to perform updates, ranking and selection in\nlogarithmic time, with a space overhead in the order of a few percents,\noutperforming existing data structures with the same purpose. Along the way, we\nhighlight the pernicious interplay between the arithmetic behind the Fenwick\ntree and the structure of current CPU caches, suggesting simple solutions that\nimprove performance significantly.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 19:04:24 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 14:04:03 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Marchini", "Stefano", ""], ["Vigna", "Sebastiano", ""]]}, {"id": "1904.12427", "submitter": "Nicole Wein", "authors": "Shay Solomon and Nicole Wein", "title": "Improved Dynamic Graph Coloring", "comments": "Appeared in ESA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the fundamental problem of graph coloring in fully dynamic\ngraphs. Since the problem of computing an optimal coloring, or even\napproximating it to within $n^{1-\\epsilon}$ for any $\\epsilon > 0$, is NP-hard\nin static graphs, there is no hope to achieve any meaningful computational\nresults for general graphs in the dynamic setting. It is therefore only natural\nto consider the combinatorial aspects of dynamic coloring, or alternatively,\nstudy restricted families of graphs.\n  Towards understanding the combinatorial aspects of this problem, one may\nassume a black-box access to a static algorithm for $C$-coloring any subgraph\nof the dynamic graph, and investigate the trade-off between the number of\ncolors and the number of recolorings per update step. In WADS'17, Barba et al.\ndevised two complementary algorithms: For any $\\beta > 0$ the first\n(respectively, second) maintains an $O(C \\beta n^{1/\\beta})$ (resp., $O(C\n\\beta)$)-coloring while recoloring $O(\\beta)$ (resp., $O(\\beta n^{1/\\beta})$)\nvertices per update. Our contribution is two-fold:\n  - We devise a new algorithm for general graphs that improves significantly\nupon the first trade-off in a wide range of parameters: For any $\\beta > 0$, we\nget a $\\tilde{O}(\\frac{C}{\\beta}\\log^2 n)$-coloring with $O(\\beta)$ recolorings\nper update, where the $\\tilde{O}$ notation supresses polyloglog$(n)$ factors.\nIn particular, for $\\beta=O(1)$ we get constant recolorings with polylog$(n)$\ncolors; this is an exponential improvement over the previous bound.\n  - For uniformly sparse graphs, we use low out-degree orientations to\nstrengthen the above result by bounding the update time of the algorithm rather\nthan the number of recolorings. Then, we further improve this result by\nintroducing a new data structure that refines bounded out-degree edge\norientations and is of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 02:45:41 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 18:07:01 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 18:44:31 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Solomon", "Shay", ""], ["Wein", "Nicole", ""]]}, {"id": "1904.12467", "submitter": "Srikrishnan Divakaran", "authors": "Srikrishnan Divakaran", "title": "A Fast Scalable Heuristic for Bin Packing", "comments": "16 pages. arXiv admin note: text overlap with arXiv:1902.03422", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a fast scalable heuristic for bin packing that\npartitions the given problem into identical sub-problems of constant size and\nsolves these constant size sub-problems by considering only a constant number\nof bin configurations with bounded unused space. We present some empirical\nevidence to support the scalability of our heuristic and its tighter empirical\nanalysis of hard instances due to improved lower bound on the necessary wastage\nin an optimal solution.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 06:48:38 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Divakaran", "Srikrishnan", ""]]}, {"id": "1904.12500", "submitter": "Julien Baste", "authors": "Julien Baste", "title": "Composing dynamic programming tree-decomposition-based algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two integers $\\ell$ and $p$ as well as $\\ell$ graph classes\n$\\mathcal{H}_1,\\ldots,\\mathcal{H}_\\ell$, the problems\n$\\mathsf{GraphPart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell,p)$,\n$\\mathsf{VertPart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell)$, and\n$\\mathsf{EdgePart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell)$ ask, given graph\n$G$ as input, whether $V(G)$, $V(G)$, $E(G)$ respectively can be partitioned\ninto $\\ell$ sets $S_1, \\ldots, S_\\ell$ such that, for each $i$ between $1$ and\n$\\ell$, $G[V_i] \\in \\mathcal{H}_i$, $G[V_i] \\in \\mathcal{H}_i$, $(V(G),S_i) \\in\n\\mathcal{H}_i$ respectively. Moreover in $\\mathsf{GraphPart}(\\mathcal{H}_1,\n\\ldots, \\mathcal{H}_\\ell,p)$, we request that the number of edges with\nendpoints in different sets of the partition is bounded by $p$. We show that if\nthere exist dynamic programming tree-decomposition-based algorithms for\nrecognizing the graph classes $\\mathcal{H}_i$, for each $i$, then we can\nconstructively create a dynamic programming tree-decomposition-based algorithms\nfor $\\mathsf{GraphPart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell,p)$,\n$\\mathsf{VertPart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell)$, and\n$\\mathsf{EdgePart}(\\mathcal{H}_1, \\ldots, \\mathcal{H}_\\ell)$. We show that, in\nsome known cases, the obtained running times are comparable to those of the\nbest know algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 08:50:29 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Baste", "Julien", ""]]}, {"id": "1904.12503", "submitter": "Maximilian Katzmann", "authors": "Thomas Bl\\\"asius, Philipp Fischbeck, Tobias Friedrich, Maximilian\n  Katzmann", "title": "Solving Vertex Cover in Polynomial Time on Hyperbolic Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The VertexCover problem is proven to be computationally hard in different\nways: It is NP-complete to find an optimal solution and even NP-hard to find an\napproximation with reasonable factors. In contrast, recent experiments suggest\nthat on many real-world networks the run time to solve VertexCover is way\nsmaller than even the best known FPT-approaches can explain. Similarly, greedy\nalgorithms deliver very good approximations to the optimal solution in\npractice.\n  We link these observations to two properties that are observed in many\nreal-world networks, namely a heterogeneous degree distribution and high\nclustering. To formalize these properties and explain the observed behavior, we\nanalyze how a branch-and-reduce algorithm performs on hyperbolic random graphs,\nwhich have become increasingly popular for modeling real-world networks. In\nfact, we are able to show that the VertexCover problem on hyperbolic random\ngraphs can be solved in polynomial time, with high probability.\n  The proof relies on interesting structural properties of hyperbolic random\ngraphs. Since these predictions of the model are interesting in their own\nright, we conducted experiments on real-world networks showing that these\nproperties are also observed in practice. When utilizing the same structural\nproperties in an adaptive greedy algorithm, further experiments suggest that,\non real instances, this leads to better approximations than the standard greedy\napproach within reasonable time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 08:53:12 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 13:28:49 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 09:01:36 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Bl\u00e4sius", "Thomas", ""], ["Fischbeck", "Philipp", ""], ["Friedrich", "Tobias", ""], ["Katzmann", "Maximilian", ""]]}, {"id": "1904.12596", "submitter": "Alessandra Tappini", "authors": "Giuseppe Liotta, Ignaz Rutter and Alessandra Tappini", "title": "Graph Planarity Testing with Hierarchical Embedding Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical embedding constraints define a set of allowed cyclic orders for\nthe edges incident to the vertices of a graph. These constraints are expressed\nin terms of FPQ-trees. FPQ-trees are a variant of PQ-trees that includes\nF-nodes in addition to P- and to Q-nodes. An F-node represents a permutation\nthat is fixed, i.e., it cannot be reversed. Let $G$ be a graph such that every\nvertex of $G$ is equipped with a set of FPQ-trees encoding hierarchical\nembedding constraints for its incident edges. We study the problem of testing\nwhether $G$ admits a planar embedding such that, for each vertex $v$ of $G$,\nthe cyclic order of the edges incident to $v$ is described by at least one of\nthe FPQ-trees associated with~$v$. We prove that the problem is fixed-parameter\ntractable for biconnected graphs, where the parameters are the treewidth of $G$\nand the number of FPQ-trees associated with every vertex of $G$. We also show\nthat the problem is NP-complete if parameterized by the number of FPQ-trees\nonly, and W[1]-hard if parameterized by the treewidth only. Besides being\ninteresting on its own right, the study of planarity testing with hierarchical\nembedding constraints can be used to address other planarity testing problems.\nIn particular, we apply our techniques to the study of NodeTrix planarity\ntesting of clustered graphs. We show that NodeTrix planarity testing with fixed\nsides is fixed-parameter tractable when parameterized by the size of the\nclusters and by the treewidth of the multi-graph obtained by collapsing the\nclusters to single vertices, provided that this graph is biconnected.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 12:21:10 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 15:07:06 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 16:09:05 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liotta", "Giuseppe", ""], ["Rutter", "Ignaz", ""], ["Tappini", "Alessandra", ""]]}, {"id": "1904.12682", "submitter": "Shunji Umetani", "authors": "Naoya Uematsu, Shunji Umetani, Yoshinobu Kawahara", "title": "An efficient branch-and-cut algorithm for approximately submodular\n  function maximization", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.04177", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When approaching to problems in computer science, we often encounter\nsituations where a subset of a finite set maximizing some utility function\nneeds to be selected. Some of such utility functions are known to be\napproximately submodular. For the problem of maximizing an approximately\nsubmodular function (ASFM problem), a greedy algorithm quickly finds good\nfeasible solutions for many instances while guaranteeing\n($1-e^{-\\gamma}$)-approximation ratio for a given submodular ratio $\\gamma$.\nHowever, we still encounter its applications that ask more accurate or exactly\noptimal solutions within a reasonable computation time. In this paper, we\npresent an efficient branch-and-cut algorithm for the non-decreasing ASFM\nproblem based on its binary integer programming (BIP) formulation with an\nexponential number of constraints. To this end, we first derive a BIP\nformulation of the ASFM problem and then, develop an improved constraint\ngeneration algorithm that starts from a reduced BIP problem with a small subset\nof constraints and repeats solving the reduced BIP problem while adding a\npromising set of constraints at each iteration. Moreover, we incorporate it\ninto a branch-and-cut algorithm to attain good upper bounds while solving a\nsmaller number of nodes of a search tree. The computational results for three\ntypes of well-known benchmark instances show that our algorithm performs better\nthan the conventional exact algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 05:44:00 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Uematsu", "Naoya", ""], ["Umetani", "Shunji", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1904.12728", "submitter": "Alessio Mazzetto", "authors": "Alessio Mazzetto, Andrea Pietracaprina, Geppino Pucci", "title": "Accurate MapReduce Algorithms for $k$-median and $k$-means in General\n  Metric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Center-based clustering is a fundamental primitive for data analysis and\nbecomes very challenging for large datasets. In this paper, we focus on the\npopular $k$-median and $k$-means variants which, given a set $P$ of points from\na metric space and a parameter $k<|P|$, require to identify a set $S$ of $k$\ncenters minimizing, respectively, the sum of the distances and of the squared\ndistances of all points in $P$ from their closest centers. Our specific focus\nis on general metric spaces, for which it is reasonable to require that the\ncenters belong to the input set (i.e., $S \\subseteq P$). We present\ncoreset-based 3-round distributed approximation algorithms for the above\nproblems using the MapReduce computational model. The algorithms are rather\nsimple and obliviously adapt to the intrinsic complexity of the dataset,\ncaptured by the doubling dimension $D$ of the metric space. Remarkably, the\nalgorithms attain approximation ratios that can be made arbitrarily close to\nthose achievable by the best known polynomial-time sequential approximations,\nand they are very space efficient for small $D$, requiring local memory sizes\nsubstantially sublinear in the input size. To the best of our knowledge, no\nprevious distributed approaches were able to attain similar quality-performance\nguarantees in general metric spaces.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 14:12:15 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 19:58:38 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Mazzetto", "Alessio", ""], ["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""]]}, {"id": "1904.12777", "submitter": "Abdullah Almethen", "authors": "Abdullah Almethen, Othon Michail, Igor Potapov", "title": "Pushing Lines Helps: Efficient Universal Centralised Transformations for\n  Programmable Matter", "comments": "40 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a discrete system of entities residing on a\ntwo-dimensional square grid. Each entity is modelled as a node occupying a\ndistinct cell of the grid. The set of all $n$ nodes forms initially a connected\nshape $A$. Entities are equipped with a linear-strength pushing mechanism that\ncan push a whole line of entities, from 1 to $n$, in parallel in a single\ntime-step. A target connected shape $B$ is also provided and the goal is to\n\\emph{transform} $A$ into $B$ via a sequence of line movements. Existing models\nbased on local movement of individual nodes, such as rotating or sliding a\nsingle node, can be shown to be special cases of the present model, therefore\ntheir (inefficient, $\\Theta(n^2)$) \\emph{universal transformations} carry over.\nOur main goal is to investigate whether the parallelism inherent in this new\ntype of movement can be exploited for efficient, i.e., sub-quadratic\nworst-case, transformations. As a first step towards this, we restrict\nattention solely to centralised transformations and leave the distributed case\nas a direction for future research. Our results are positive. By focusing on\nthe apparently hard instance of transforming a diagonal $A$ into a straight\nline $B$, we first obtain transformations of time $O(n\\sqrt{n})$ without and\nwith preserving the connectivity of the shape throughout the transformation.\nThen, we further improve by providing two $O(n\\log n)$-time transformations for\nthis problem. By building upon these ideas, we first manage to develop an\n$O(n\\sqrt{n})$-time universal transformation. Our main result is then an $ O(n\n\\log n) $-time universal transformation. We leave as an interesting open\nproblem a suspected $\\Omega(n\\log n)$-time lower bound.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:38:41 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Almethen", "Abdullah", ""], ["Michail", "Othon", ""], ["Potapov", "Igor", ""]]}, {"id": "1904.12804", "submitter": "Lorenzo De Stefani", "authors": "Lorenzo De Stefani", "title": "The I/O complexity of hybrid algorithms for square matrix multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotically tight lower bounds are derived for the I/O complexity of a\ngeneral class of hybrid algorithms computing the product of $n \\times n$ square\nmatrices combining ``\\emph{Strassen-like}'' fast matrix multiplication approach\nwith computational complexity $\\Theta{n^{\\log_2 7}}$, and ``\\emph{standard}''\nmatrix multiplication algorithms with computational complexity\n$\\Omega\\left(n^3\\right)$. We present a novel and tight\n$\\Omega\\left(\\left(\\frac{n}{\\max\\{\\sqrt{M},n_0\\}}\\right)^{\\log_2\n7}\\left(\\max\\{1,\\frac{n_0}{M}\\}\\right)^3M\\right)$ lower bound for the I/O\ncomplexity a class of ``\\emph{uniform, non-stationary}'' hybrid algorithms when\nexecuted in a two-level storage hierarchy with $M$ words of fast memory, where\n$n_0$ denotes the threshold size of sub-problems which are computed using\nstandard algorithms with algebraic complexity $\\Omega\\left(n^3\\right)$.\n  The lower bound is actually derived for the more general class of\n``\\emph{non-uniform, non-stationary}'' hybrid algorithms which allow recursive\ncalls to have a different structure, even when they refer to the multiplication\nof matrices of the same size and in the same recursive level, although the\nquantitative expressions become more involved. Our results are the first I/O\nlower bounds for these classes of hybrid algorithms. All presented lower bounds\napply even if the recomputation of partial results is allowed and are\nasymptotically tight.\n  The proof technique combines the analysis of the Grigoriev's flow of the\nmatrix multiplication function, combinatorial properties of the encoding\nfunctions used by fast Strassen-like algorithms, and an application of the\nLoomis-Whitney geometric theorem for the analysis of standard matrix\nmultiplication algorithms.\n  Extensions of the lower bounds for a parallel model with $P$ processors are\nalso discussed.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 16:39:50 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["De Stefani", "Lorenzo", ""]]}, {"id": "1904.13043", "submitter": "Xue Chen", "authors": "Xue Chen and Eric Price", "title": "Estimating the Frequency of a Clustered Signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of locating a signal whose frequencies are \"off grid\"\nand clustered in a narrow band. Given noisy sample access to a function $g(t)$\nwith Fourier spectrum in a narrow range $[f_0 - \\Delta, f_0 + \\Delta]$, how\naccurately is it possible to identify $f_0$? We present generic conditions on\n$g$ that allow for efficient, accurate estimates of the frequency. We then show\nbounds on these conditions for $k$-Fourier-sparse signals that imply recovery\nof $f_0$ to within $\\Delta + \\tilde{O}(k^3)$ from samples on $[-1, 1]$. This\nimproves upon the best previous bound of $O\\big( \\Delta + \\tilde{O}(k^5)\n\\big)^{1.5}$. We also show that no algorithm can do better than $\\Delta +\n\\tilde{O}(k^2)$. In the process we provide a new $\\tilde{O}(k^3)$ bound on the\nratio between the maximum and average value of continuous $k$-Fourier-sparse\nsignals, which has independent application.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 04:08:40 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Chen", "Xue", ""], ["Price", "Eric", ""]]}, {"id": "1904.13077", "submitter": "Marcin Pilipczuk", "authors": "Wojciech Czerwi\\'nski and Wojciech Nadara and Marcin Pilipczuk", "title": "Improved bounds for the excluded-minor approximation of treedepth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treedepth, a more restrictive graph width parameter than treewidth and\npathwidth, plays a major role in the theory of sparse graph classes. We show\nthat there exists a constant $C$ such that for every positive integers $a,b$\nand a graph $G$, if the treedepth of $G$ is at least $Cab$, then the treewidth\nof $G$ is at least $a$ or $G$ contains a subcubic (i.e., of maximum degree at\nmost $3$) tree of treedepth at least $b$ as a subgraph.\n  As a direct corollary, we obtain that every graph of treedepth $\\Omega(k^3)$\nis either of treewidth at least $k$, contains a subdivision of full binary tree\nof depth $k$, or contains a path of length $2^k$. This improves the bound of\n$\\Omega(k^5 \\log^2 k)$ of Kawarabayashi and Rossman [SODA 2018].\n  We also show an application of our techniques for approximation algorithms of\ntreedepth: given a graph $G$ of treedepth $k$ and treewidth $t$, one can in\npolynomial time compute a treedepth decomposition of $G$ of width\n$\\mathcal{O}(kt \\log^{3/2} t)$. This improves upon a bound of $\\mathcal{O}(kt^2\n\\log t)$ stemming from a tradeoff between known results.\n  The main technical ingredient in our result is a proof that every tree of\ntreedepth $d$ contains a subcubic subtree of treedepth at least $d \\cdot \\log_3\n((1+\\sqrt{5})/2)$.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 07:11:32 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 10:44:35 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Czerwi\u0144ski", "Wojciech", ""], ["Nadara", "Wojciech", ""], ["Pilipczuk", "Marcin", ""]]}, {"id": "1904.13101", "submitter": "Amjad Ibrahim", "authors": "Amjad Ibrahim, Simon Rehwald, Alexander Pretschner", "title": "Efficiently Checking Actual Causality with SAT Solving", "comments": "18 pages, In: Dependable Software Systems Engineering, p. to appear\n  (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent formal approaches towards causality have made the concept ready for\nincorporation into the technical world. However, causality reasoning is\ncomputationally hard; and no general algorithmic approach exists that\nefficiently infers the causes for effects. Thus, checking causality in the\ncontext of complex, multi-agent, and distributed socio-technical systems is a\nsignificant challenge. Therefore, we conceptualize an intelligent and novel\nalgorithmic approach towards checking causality in acyclic causal models with\nbinary variables, utilizing the optimization power in the solvers of the\nBoolean Satisfiability Problem (SAT). We present two SAT encodings, and an\nempirical evaluation of their efficiency and scalability. We show that\ncausality is computed efficiently in less than 5 seconds for models that\nconsist of more than 4000 variables.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 08:38:10 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Ibrahim", "Amjad", ""], ["Rehwald", "Simon", ""], ["Pretschner", "Alexander", ""]]}, {"id": "1904.13239", "submitter": "Lu Bai", "authors": "Lu Bai, Luca Rossi, Lixin Cui, Jian Cheng, Edwin R. Hancock", "title": "A Quantum-inspired Similarity Measure for the Analysis of Complete\n  Weighted Graphs", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 2019", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel method for measuring the similarity between complete\nweighted graphs, which are probed by means of discrete-time quantum walks.\nDirectly probing complete graphs using discrete-time quantum walks is\nintractable due to the cost of simulating the quantum walk. We overcome this\nproblem by extracting a commute-time minimum spanning tree from the complete\nweighted graph. The spanning tree is probed by a discrete time quantum walk\nwhich is initialised using a weighted version of the Perron-Frobenius operator.\nThis naturally encapsulates the edge weight information for the spanning tree\nextracted from the original graph. For each pair of complete weighted graphs to\nbe compared, we simulate a discrete-time quantum walk on each of the\ncorresponding commute time minimum spanning trees, and then compute the\nassociated density matrices for the quantum walks. The probability of the walk\nvisiting each edge of the spanning tree is given by the diagonal elements of\nthe density matrices. The similarity between each pair of graphs is then\ncomputed using either a) the inner product or b) the negative exponential of\nthe Jensen-Shannon divergence between the probability distributions. We show\nthat in both cases the resulting similarity measure is positive definite and\ntherefore corresponds to a kernel on the graphs. We perform a series of\nexperiments on publicly available graph datasets from a variety of different\ndomains, together with time-varying financial networks extracted from data for\nthe New York Stock Exchange. Our experiments demonstrate the effectiveness of\nthe proposed similarity measures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 17:41:03 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Bai", "Lu", ""], ["Rossi", "Luca", ""], ["Cui", "Lixin", ""], ["Cheng", "Jian", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1904.13309", "submitter": "Ahad N. Zehmakan", "authors": "Bernd G\\\"artner and Ahad N. Zehmakan", "title": "Phase Transition in Democratic Opinion Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a community where initially, each individual is positive or negative\nregarding a reform proposal. In each round, individuals gather randomly in\nfixed rooms of different sizes, and all individuals in a room agree on the\nmajority opinion in the room (with ties broken in favor of the negative\nopinion). The Galam model---introduced in statistical physics, specifically\nsociophysics---approximates this basic random process. We approach the model\nfrom a more mathematical perspective and study the threshold behavior and the\nconsensus time of the model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:17:37 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["G\u00e4rtner", "Bernd", ""], ["Zehmakan", "Ahad N.", ""]]}, {"id": "1904.13369", "submitter": "Sayan Bandyapadhyay", "authors": "Sayan Bandyapadhyay, Saeed Mehrabi", "title": "Constrained Orthogonal Segment Stabbing", "comments": "to appear at CCCG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $S$ and $D$ each be a set of orthogonal line segments in the plane. A\nline segment $s\\in S$ \\emph{stabs} a line segment $s'\\in D$ if $s\\cap\ns'\\neq\\emptyset$. It is known that the problem of stabbing the line segments in\n$D$ with the minimum number of line segments of $S$ is NP-hard. However, no\nbetter than $O(\\log |S\\cup D|)$-approximation is known for the problem. In this\npaper, we introduce a constrained version of this problem in which every\nhorizontal line segment of $S\\cup D$ intersects a common vertical line. We\nstudy several versions of the problem, depending on which line segments are\nused for stabbing and which line segments must be stabbed. We obtain several\nNP-hardness and constant approximation results for these versions. Our finding\nimplies, the problem remains NP-hard even under the extra assumption on input,\nbut small constant approximation algorithms can be designed.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:04:08 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 14:34:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Bandyapadhyay", "Sayan", ""], ["Mehrabi", "Saeed", ""]]}, {"id": "1904.13389", "submitter": "Lin Chen", "authors": "MohammadHossein Bateni, Lin Chen, Hossein Esfandiari, Thomas Fu, Vahab\n  S. Mirrokni, Afshin Rostamizadeh", "title": "Categorical Feature Compression via Submodular Optimization", "comments": "Accepted to ICML 2019. Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, learning from categorical features with very large\nvocabularies (e.g., 28 million for the Criteo click prediction dataset) has\nbecome a practical challenge for machine learning researchers and\npractitioners. We design a highly-scalable vocabulary compression algorithm\nthat seeks to maximize the mutual information between the compressed\ncategorical feature and the target binary labels and we furthermore show that\nits solution is guaranteed to be within a $1-1/e \\approx 63\\%$ factor of the\nglobal optimal solution. To achieve this, we introduce a novel\nre-parametrization of the mutual information objective, which we prove is\nsubmodular, and design a data structure to query the submodular function in\namortized $O(\\log n )$ time (where $n$ is the input vocabulary size). Our\ncomplete algorithm is shown to operate in $O(n \\log n )$ time. Additionally, we\ndesign a distributed implementation in which the query data structure is\ndecomposed across $O(k)$ machines such that each machine only requires $O(\\frac\nn k)$ space, while still preserving the approximation guarantee and using only\nlogarithmic rounds of computation. We also provide analysis of simple\nalternative heuristic compression methods to demonstrate they cannot achieve\nany approximation guarantee. Using the large-scale Criteo learning task, we\ndemonstrate better performance in retaining mutual information and also verify\ncompetitive learning performance compared to other baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:45:13 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Bateni", "MohammadHossein", ""], ["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Thomas", ""], ["Mirrokni", "Vahab S.", ""], ["Rostamizadeh", "Afshin", ""]]}]