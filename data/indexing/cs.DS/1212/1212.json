[{"id": "1212.0106", "submitter": "Gregory Gutin", "authors": "R. Crowston, G. Gutin, M. Jones, V. Raman, S. Saurabh and A. Yeo", "title": "Fixed-parameter tractability of satisfying beyond the number of\n  variables", "comments": null, "journal-ref": "Algorithmica, 2012", "doi": "10.1007/s00453-012-9697-4", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a CNF formula $F$ as a multiset of clauses: $F=\\{c_1,..., c_m\\}$.\nThe set of variables of $F$ will be denoted by $V(F)$. Let $B_F$ denote the\nbipartite graph with partite sets $V(F)$ and $F$ and with an edge between $v\n\\in V(F)$ and $c \\in F$ if $v \\in c$ or $\\bar{v} \\in c$. The matching number\n$\\nu(F)$ of $F$ is the size of a maximum matching in $B_F$. In our main result,\nwe prove that the following parameterization of {\\sc MaxSat} (denoted by\n$(\\nu(F)+k)$-\\textsc{SAT}) is fixed-parameter tractable: Given a formula $F$,\ndecide whether we can satisfy at least $\\nu(F)+k$ clauses in $F$, where $k$ is\nthe parameter.\n  A formula $F$ is called variable-matched if $\\nu(F)=|V(F)|.$ Let\n$\\delta(F)=|F|-|V(F)|$ and $\\delta^*(F)=\\max_{F'\\subseteq F} \\delta(F').$ Our\nmain result implies fixed-parameter tractability of {\\sc MaxSat} parameterized\nby $\\delta(F)$ for variable-matched formulas $F$; this complements related\nresults of Kullmann (2000) and Szeider (2004) for {\\sc MaxSat} parameterized by\n$\\delta^*(F)$.\n  To obtain our main result, we reduce $(\\nu(F)+k)$-\\textsc{SAT} into the\nfollowing parameterization of the {\\sc Hitting Set} problem (denoted by\n$(m-k)$-{\\sc Hitting Set}): given a collection $\\cal C$ of $m$ subsets of a\nground set $U$ of $n$ elements, decide whether there is $X\\subseteq U$ such\nthat $C\\cap X\\neq \\emptyset$ for each $C\\in \\cal C$ and $|X|\\le m-k,$ where $k$\nis the parameter. Gutin, Jones and Yeo (2011) proved that $(m-k)$-{\\sc Hitting\nSet} is fixed-parameter tractable by obtaining an exponential kernel for the\nproblem. We obtain two algorithms for $(m-k)$-{\\sc Hitting Set}: a\ndeterministic algorithm of runtime $O((2e)^{2k+O(\\log^2 k)} (m+n)^{O(1)})$ and\na randomized algorithm of expected runtime $O(8^{k+O(\\sqrt{k})} (m+n)^{O(1)})$.\nOur deterministic algorithm improves an algorithm that follows from the\nkernelization result of Gutin, Jones and Yeo (2011).\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 12:53:29 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Crowston", "R.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""], ["Raman", "V.", ""], ["Saurabh", "S.", ""], ["Yeo", "A.", ""]]}, {"id": "1212.0117", "submitter": "Gregory Gutin", "authors": "R. Crowston, G. Gutin, M. Jones, S. Saurabh and A. Yeo", "title": "Parameterized Study of the Test Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We carry out a systematic study of a natural covering problem, used for\nidentification across several areas, in the realm of parameterized complexity.\nIn the {\\sc Test Cover} problem we are given a set $[n]=\\{1,...,n\\}$ of items\ntogether with a collection, $\\cal T$, of distinct subsets of these items called\ntests. We assume that $\\cal T$ is a test cover, i.e., for each pair of items\nthere is a test in $\\cal T$ containing exactly one of these items. The\nobjective is to find a minimum size subcollection of $\\cal T$, which is still a\ntest cover. The generic parameterized version of {\\sc Test Cover} is denoted by\n$p(k,n,|{\\cal T}|)$-{\\sc Test Cover}. Here, we are given $([n],\\cal{T})$ and a\npositive integer parameter $k$ as input and the objective is to decide whether\nthere is a test cover of size at most $p(k,n,|{\\cal T}|)$. We study four\nparameterizations for {\\sc Test Cover} and obtain the following:\n  (a) $k$-{\\sc Test Cover}, and $(n-k)$-{\\sc Test Cover} are fixed-parameter\ntractable (FPT).\n  (b) $(|{\\cal T}|-k)$-{\\sc Test Cover} and $(\\log n+k)$-{\\sc Test Cover} are\nW[1]-hard. Thus, it is unlikely that these problems are FPT.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 14:38:25 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Crowston", "R.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""], ["Saurabh", "S.", ""], ["Yeo", "A.", ""]]}, {"id": "1212.0202", "submitter": "Vladimir Braverman", "authors": "Vladimir Braverman and Rafail Ostrovsky", "title": "Approximating Large Frequency Moments with Pick-and-Drop Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data stream $D = \\{p_1,p_2,...,p_m\\}$ of size $m$ of numbers from\n$\\{1,..., n\\}$, the frequency of $i$ is defined as $f_i = |\\{j: p_j = i\\}|$.\nThe $k$-th \\emph{frequency moment} of $D$ is defined as $F_k = \\sum_{i=1}^n\nf_i^k$. We consider the problem of approximating frequency moments in\ninsertion-only streams for $k\\ge 3$. For any constant $c$ we show an\n$O(n^{1-2/k}\\log(n)\\log^{(c)}(n))$ upper bound on the space complexity of the\nproblem. Here $\\log^{(c)}(n)$ is the iterative $\\log$ function. To simplify the\npresentation, we make the following assumptions: $n$ and $m$ are polynomially\nfar; approximation error $\\epsilon$ and parameter $k$ are constants. We observe\na natural bijection between streams and special matrices. Our main technical\ncontribution is a non-uniform sampling method on matrices. We call our method a\n\\emph{pick-and-drop sampling}; it samples a heavy element (i.e., element $i$\nwith frequency $\\Omega(F_k)$) with probability $\\Omega(1/n^{1-2/k})$ and gives\napproximation $\\tilde{f_i} \\ge (1-\\epsilon)f_i$. In addition, the estimations\nnever exceed the real values, that is $ \\tilde{f_j} \\le f_j$ for all $j$. As a\nresult, we reduce the space complexity of finding a heavy element to\n$O(n^{1-2/k}\\log(n))$ bits. We apply our method of recursive sketches and\nresolve the problem with $O(n^{1-2/k}\\log(n)\\log^{(c)}(n))$ bits.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 11:32:47 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2012 10:21:29 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Braverman", "Vladimir", ""], ["Ostrovsky", "Rafail", ""]]}, {"id": "1212.0297", "submitter": "Aleksandar Nikolov", "authors": "Aleksandar Nikolov and Kunal Talwar and Li Zhang", "title": "The Geometry of Differential Privacy: the Sparse and Approximate Cases", "comments": null, "journal-ref": null, "doi": "10.1145/2488608.2488652", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study trade-offs between accuracy and privacy in the context\nof linear queries over histograms. This is a rich class of queries that\nincludes contingency tables and range queries, and has been a focus of a long\nline of work. For a set of $d$ linear queries over a database $x \\in \\R^N$, we\nseek to find the differentially private mechanism that has the minimum mean\nsquared error. For pure differential privacy, an $O(\\log^2 d)$ approximation to\nthe optimal mechanism is known. Our first contribution is to give an $O(\\log^2\nd)$ approximation guarantee for the case of $(\\eps,\\delta)$-differential\nprivacy. Our mechanism is simple, efficient and adds correlated Gaussian noise\nto the answers. We prove its approximation guarantee relative to the hereditary\ndiscrepancy lower bound of Muthukrishnan and Nikolov, using tools from convex\ngeometry.\n  We next consider this question in the case when the number of queries exceeds\nthe number of individuals in the database, i.e. when $d > n \\triangleq\n\\|x\\|_1$. It is known that better mechanisms exist in this setting. Our second\nmain contribution is to give an $(\\eps,\\delta)$-differentially private\nmechanism which is optimal up to a $\\polylog(d,N)$ factor for any given query\nset $A$ and any given upper bound $n$ on $\\|x\\|_1$. This approximation is\nachieved by coupling the Gaussian noise addition approach with a linear\nregression step. We give an analogous result for the $\\eps$-differential\nprivacy setting. We also improve on the mean squared error upper bound for\nanswering counting queries on a database of size $n$ by Blum, Ligett, and Roth,\nand match the lower bound implied by the work of Dinur and Nissim up to\nlogarithmic factors.\n  The connection between hereditary discrepancy and the privacy mechanism\nenables us to derive the first polylogarithmic approximation to the hereditary\ndiscrepancy of a matrix $A$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 06:44:32 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Nikolov", "Aleksandar", ""], ["Talwar", "Kunal", ""], ["Zhang", "Li", ""]]}, {"id": "1212.0308", "submitter": "Xavier Caruso", "authors": "Xavier Caruso (IRMAR)", "title": "Random matrix over a DVR and LU factorization", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let R be a discrete valuation ring (DVR) and K be its fraction field. If M is\na matrix over R admitting a LU decomposition, it could happen that the entries\nof the factors L and U do not lie in R, but just in K. Having a good control on\nthe valuations of these entries is very important for algorithmic applications.\nIn the paper, we prove that in average these valuations are not too large and\nexplain how one can apply this result to provide an efficient algorithm\ncomputing a basis of a coherent sheaf over A^1 from the knowledge of its\nstalks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 08:25:29 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Caruso", "Xavier", "", "IRMAR"]]}, {"id": "1212.0640", "submitter": "Sasanka Roy", "authors": "Ritankar Mandal and Anirban Ghosh and Sasanka Roy and Subhas C. Nandy", "title": "Greedy is good: An experimental study on minimum clique cover and\n  maximum independent set problems for randomly generated rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set ${\\cal R}=\\{R_1,R_2,..., R_n\\}$ of $n$ randomly positioned axis\nparallel rectangles in 2D, the problem of computing the minimum clique cover\n(MCC) and maximum independent set (MIS) for the intersection graph $G({\\cal\nR})$ of the members in $\\cal R$ are both computationally hard \\cite{CC05}. For\nthe MCC problem, it is proved that polynomial time constant factor\napproximation is impossible to obtain \\cite{PT11}. Though such a result is not\nproved yet for the MIS problem, no polynomial time constant factor\napproximation algorithm exists in the literature. We study the performance of\ngreedy algorithms for computing these two parameters of $G({\\cal R})$.\nExperimental results shows that for each of the MCC and MIS problems, the\ncorresponding greedy algorithm produces a solution that is very close to its\noptimum solution. Scheinerman \\cite{Scheinerman80} showed that the size of MIS\nis tightly bounded by $\\sqrt{n}$ for a random instance of the 1D version of the\nproblem, (i.e., for the interval graph). Our experiment shows that the size of\nindependent set and the clique cover produced by the greedy algorithm is at\nleast $2\\sqrt{n}$ and at most $3\\sqrt{n}$, respectively. Thus the\nexperimentally obtained approximation ratio of the greedy algorithm for MIS\nproblem is at most 3/2 and the same for the MCC problem is at least 2/3.\nFinally we will provide refined greedy algorithms based on a concept of {\\it\nsimplicial rectangle}. The characteristics of this algorithm may be of interest\nin getting a provably constant factor approximation algorithm for random\ninstance of both the problems. We believe that the result also holds true for\nany finite dimension.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 08:50:27 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Mandal", "Ritankar", ""], ["Ghosh", "Anirban", ""], ["Roy", "Sasanka", ""], ["Nandy", "Subhas C.", ""]]}, {"id": "1212.0703", "submitter": "Kurt Mehlhorn", "authors": "Tomasz Jurkiewicz, Kurt Mehlhorn", "title": "The Cost of Address Translation", "comments": "A extended abstract of this paper was published in the proceedings of\n  ALENEX13, New Orleans, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computers are not random access machines (RAMs). They have a memory\nhierarchy, multiple cores, and virtual memory. In this paper, we address the\ncomputational cost of address translation in virtual memory. Starting point for\nour work is the observation that the analysis of some simple algorithms (random\nscan of an array, binary search, heapsort) in either the RAM model or the EM\nmodel (external memory model) does not correctly predict growth rates of actual\nrunning times. We propose the VAT model (virtual address translation) to\naccount for the cost of address translations and analyze the algorithms\nmentioned above and others in the model. The predictions agree with the\nmeasurements. We also analyze the VAT-cost of cache-oblivious algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 12:55:21 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 14:16:01 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Jurkiewicz", "Tomasz", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1212.0752", "submitter": "Bundit Laekhanukit", "authors": "Bundit Laekhanukit", "title": "Parameters of Two-Prover-One-Round Game and The Hardness of Connectivity\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing parameters of Two-Prover-One-Round Game (2P1R) is an important\ntask in PCPs literature as it would imply a smaller PCP with the same or\nstronger soundness. While this is a basic question in PCPs community, the\nconnection between the parameters of PCPs and hardness of approximations is\nsometime obscure to approximation algorithm community. In this paper, we\ninvestigate the connection between the parameters of 2P1R and the hardness of\napproximating the class of so-called connectivity problems, which includes as\nsubclasses the survivable network design and (multi)cut problems. Based on\nrecent development on 2P1R by Chan (ECCC 2011) and several techniques in PCPs\nliterature, we improve hardness results of some connectivity problems that are\nin the form $k^\\sigma$, for some (very) small constant $\\sigma>0$, to hardness\nresults of the form $k^c$ for some explicit constant $c$, where $k$ is a\nconnectivity parameter. In addition, we show how to convert these hardness into\nhardness results of the form $D^{c'}$, where $D$ is the number of demand pairs\n(or the number of terminals).\n  Thus, we give improved hardness results of k^{1/2-\\epsilon} and\nk^{1/10-\\epsilon} for the root $k$-connectivity problem on directed and\nundirected graphs, k^{1/6-\\epsilon} for the vertex-connectivity survivable\nnetwork design problem on undirected graphs, and k^{1/6-\\epsilon} for the\nvertex-connectivity $k$-route cut problem on undirected graphs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 15:10:41 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2012 01:22:32 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Laekhanukit", "Bundit", ""]]}, {"id": "1212.0804", "submitter": "Tamara Mchedlidze David", "authors": "Emilio Di Giacomo and Giuseppe Liotta and Tamara Mchedlidze", "title": "How many vertex locations can be arbitrarily chosen when drawing planar\n  graphs?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proven that every set $S$ of distinct points in the plane with\ncardinality $\\lceil \\frac{\\sqrt{\\log_2 n}-1}{4} \\rceil$ can be a subset of the\nvertices of a crossing-free straight-line drawing of any planar graph with $n$\nvertices. It is also proven that if $S$ is restricted to be a one-sided convex\npoint set, its cardinality increases to $\\lceil \\sqrt[3]{n} \\rceil$. The proofs\nare constructive and give rise to O(n)-time drawing algorithms. As a part of\nour proofs, we show that every maximal planar graph contains a large induced\nbiconnected outerplanar graphs and a large induced outerpath (an outerplanar\ngraph whose weak dual is a path).\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 17:33:45 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Di Giacomo", "Emilio", ""], ["Liotta", "Giuseppe", ""], ["Mchedlidze", "Tamara", ""]]}, {"id": "1212.0884", "submitter": "Brendan Lucier", "authors": "Christian Borgs, Michael Brautbar, Jennifer Chayes, Brendan Lucier", "title": "Maximizing Social Influence in Nearly Optimal Time", "comments": "Previous title was \"Influence Maximization in Social Networks:\n  Towards an Optimal Algorithmic Solution\". An extended abstract of this work\n  appeared in SODA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion is a fundamental graph process, underpinning such phenomena as\nepidemic disease contagion and the spread of innovation by word-of-mouth. We\naddress the algorithmic problem of finding a set of k initial seed nodes in a\nnetwork so that the expected size of the resulting cascade is maximized, under\nthe standard independent cascade model of network diffusion. Runtime is a\nprimary consideration for this problem due to the massive size of the relevant\ninput networks.\n  We provide a fast algorithm for the influence maximization problem, obtaining\nthe near-optimal approximation factor of (1 - 1/e - epsilon), for any epsilon >\n0, in time O((m+n)k log(n) / epsilon^2). Our algorithm is runtime-optimal (up\nto a logarithmic factor) and substantially improves upon the previously\nbest-known algorithms which run in time Omega(mnk POLY(1/epsilon)).\nFurthermore, our algorithm can be modified to allow early termination: if it is\nterminated after O(beta(m+n)k log(n)) steps for some beta < 1 (which can depend\non n), then it returns a solution with approximation factor O(beta). Finally,\nwe show that this runtime is optimal (up to logarithmic factors) for any beta\nand fixed seed size k.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 21:53:07 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2012 15:52:11 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2013 14:16:02 GMT"}, {"version": "v4", "created": "Fri, 20 Sep 2013 13:42:07 GMT"}, {"version": "v5", "created": "Wed, 22 Jun 2016 00:56:34 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Borgs", "Christian", ""], ["Brautbar", "Michael", ""], ["Chayes", "Jennifer", ""], ["Lucier", "Brendan", ""]]}, {"id": "1212.0927", "submitter": "Ke Wu", "authors": "Ke Wu, Philip Resnik", "title": "Two Algorithms for Finding $k$ Shortest Paths of a Weighted Pushdown\n  Automaton", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce efficient algorithms for finding the $k$ shortest paths of a\nweighted pushdown automaton (WPDA), a compact representation of a weighted set\nof strings with potential applications in parsing and machine translation. Both\nof our algorithms are derived from the same weighted deductive logic\ndescription of the execution of a WPDA using different search strategies.\nExperimental results show our Algorithm 2 adds very little overhead vs. the\nsingle shortest path algorithm, even with a large $k$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 03:50:46 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 05:39:15 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2013 16:35:34 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Wu", "Ke", ""], ["Resnik", "Philip", ""]]}, {"id": "1212.0979", "submitter": "Kurt Mehlhorn", "authors": "Ran Duan and Kurt Mehlhorn", "title": "A Combinatorial Polynomial Algorithm for the Linear Arrow-Debreu Market", "comments": "Preliminary version in ICALP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first combinatorial polynomial time algorithm for computing\nthe equilibrium of the Arrow-Debreu market model with linear utilities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 09:37:13 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 14:40:26 GMT"}, {"version": "v3", "created": "Mon, 24 Mar 2014 15:51:40 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Duan", "Ran", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1212.1053", "submitter": "Xavier Caruso", "authors": "Xavier Caruso (IRMAR), David Lubicz (IRMAR)", "title": "Linear Algebra over Z_p[[u]] and related rings", "comments": "38 pages", "journal-ref": "LMS J. Comput. Math. 17 (2014) 302-344", "doi": "10.1112/S146115701300034X", "report-no": null, "categories": "math.NT cs.DS math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let R be a complete discrete valuation ring, S=R[[u]] and n a positive\ninteger. The aim of this paper is to explain how to compute efficiently usual\noperations such as sum and intersection of sub-S-modules of S^d. As S is not\nprincipal, it is not possible to have a uniform bound on the number of\ngenerators of the modules resulting of these operations. We explain how to\nmitigate this problem, following an idea of Iwasawa, by computing an\napproximation of the result of these operations up to a quasi-isomorphism. In\nthe course of the analysis of the p-adic and u-adic precisions of the\ncomputations, we have to introduce more general coefficient rings that may be\ninteresting for their own sake. Being able to perform linear algebra operations\nmodulo quasi-isomorphism with S-modules has applications in Iwasawa theory and\np-adic Hodge theory.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 08:26:58 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Caruso", "Xavier", "", "IRMAR"], ["Lubicz", "David", "", "IRMAR"]]}, {"id": "1212.1089", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato", "title": "An Efficient Simulation Algorithm on Kripke Structures", "comments": "Conference version appeared in Proceedings of the 38th International\n  Symposium on Mathematical Foundations of Computer Science (MFCS'13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of algorithms for computing the simulation preorder (and\nequivalence) on Kripke structures are available. Let Sigma denote the state\nspace, -> the transition relation and Psim the partition of Sigma induced by\nsimulation equivalence. While some algorithms are designed to reach the best\nspace bounds, whose dominating additive term is |Psim|^2, other algorithms are\ndevised to attain the best time complexity O(|Psim||->|). We present a novel\nsimulation algorithm which is both space and time efficient: it runs in\nO(|Psim|^2 log|Psim| + |Sigma|log|Sigma|) space and O(|Psim||->|log|Sigma|)\ntime. Our simulation algorithm thus reaches the best space bounds while closely\napproaching the best time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 16:27:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 11:08:13 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2013 13:51:00 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Ranzato", "Francesco", ""]]}, {"id": "1212.1095", "submitter": "Daniel Reem", "authors": "Daniel Reem", "title": "The projector algorithm: a simple parallel algorithm for computing\n  Voronoi diagrams and Delaunay graphs", "comments": "This is a major revision; re-organization and better presentation of\n  some parts; correction of several inaccuracies; improvement of some proofs\n  and figures; added references; modification of the title; the paper is long\n  but more than half of it is composed of proofs and references: it is\n  sufficient to look at pages 5, 7--11 in order to understand the algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Voronoi diagram is a certain geometric data structure which has numerous\napplications in various scientific and technological fields. The theory of\nalgorithms for computing 2D Euclidean Voronoi diagrams of point sites is rich\nand useful, with several different and important algorithms. However, this\ntheory has been quite steady during the last few decades in the sense that no\nessentially new algorithms have entered the game. In addition, most of the\nknown algorithms are serial in nature and hence cast inherent difficulties on\nthe possibility to compute the diagram in parallel. In this paper we present\nthe projector algorithm: a new and simple algorithm which enables the\n(combinatorial) computation of 2D Voronoi diagrams. The algorithm is\nsignificantly different from previous ones and some of the involved concepts in\nit are in the spirit of linear programming and optics. Parallel implementation\nis naturally supported since each Voronoi cell can be computed independently of\nthe other cells. A new combinatorial structure for representing the cells (and\nany convex polytope) is described along the way and the computation of the\ninduced Delaunay graph is obtained almost automatically.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 18:17:57 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 05:03:45 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2015 18:58:00 GMT"}, {"version": "v4", "created": "Sun, 12 Aug 2018 16:54:07 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Reem", "Daniel", ""]]}, {"id": "1212.1121", "submitter": "Isabelle Stanton", "authors": "Isabelle Stanton", "title": "Streaming Balanced Graph Partitioning for Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent explosion in the size of stored data, partially due\nto advances in storage technology, and partially due to the growing popularity\nof cloud-computing and the vast quantities of data generated. This motivates\nthe need for streaming algorithms that can compute approximate solutions\nwithout full random access to all of the data.\n  We model the problem of loading a graph onto a distributed cluster as\ncomputing an approximately balanced $k$-partitioning of a graph in a streaming\nfashion with only one pass over the data. We give lower bounds on this problem,\nshowing that no algorithm can obtain an $o(n)$ approximation with a random or\nadversarial stream ordering. We analyze two variants of a randomized greedy\nalgorithm, one that prefers the $\\arg\\max$ and one that is proportional, on\nrandom graphs with embedded balanced $k$-cuts and are able to theoretically\nbound the performance of each algorithms - the $\\arg\\max$ algorithm is able to\nrecover the embedded $k$-cut, while, surprisingly, the proportional variant can\nnot. This matches the experimental results in [25].\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 18:16:32 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Stanton", "Isabelle", ""]]}, {"id": "1212.1186", "submitter": "Quan Geng", "authors": "Quan Geng, and Pramod Viswanath", "title": "The Optimal Mechanism in Differential Privacy", "comments": "40 pages, 5 figures. Part of this work was presented in DIMACS\n  Workshop on Recent Work on Differential Privacy across Computer Science,\n  October 24 - 26, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the optimal $\\epsilon$-differentially private mechanism for single\nreal-valued query function under a very general utility-maximization (or\ncost-minimization) framework. The class of noise probability distributions in\nthe optimal mechanism has {\\em staircase-shaped} probability density functions\nwhich are symmetric (around the origin), monotonically decreasing and\ngeometrically decaying. The staircase mechanism can be viewed as a {\\em\ngeometric mixture of uniform probability distributions}, providing a simple\nalgorithmic description for the mechanism. Furthermore, the staircase mechanism\nnaturally generalizes to discrete query output settings as well as more\nabstract settings. We explicitly derive the optimal noise probability\ndistributions with minimum expectation of noise amplitude and power. Comparing\nthe optimal performances with those of the Laplacian mechanism, we show that in\nthe high privacy regime ($\\epsilon$ is small), Laplacian mechanism is\nasymptotically optimal as $\\epsilon \\to 0$; in the low privacy regime\n($\\epsilon$ is large), the minimum expectation of noise amplitude and minimum\nnoise power are $\\Theta(\\Delta e^{-\\frac{\\epsilon}{2}})$ and $\\Theta(\\Delta^2\ne^{-\\frac{2\\epsilon}{3}})$ as $\\epsilon \\to +\\infty$, while the expectation of\nnoise amplitude and power using the Laplacian mechanism are\n$\\frac{\\Delta}{\\epsilon}$ and $\\frac{2\\Delta^2}{\\epsilon^2}$, where $\\Delta$ is\nthe sensitivity of the query function. We conclude that the gains are more\npronounced in the low privacy regime.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 21:35:29 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 19:11:18 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2013 19:22:42 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Geng", "Quan", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1212.1464", "submitter": "Manuel Gomez Rodriguez", "authors": "Manuel Gomez Rodriguez, Jure Leskovec, Bernhard Sch\\\"olkopf", "title": "Structure and Dynamics of Information Pathways in Online Media", "comments": "To Appear at the 6th International Conference on Web Search and Data\n  Mining (WSDM '13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion of information, spread of rumors and infectious diseases are all\ninstances of stochastic processes that occur over the edges of an underlying\nnetwork. Many times networks over which contagions spread are unobserved, and\nsuch networks are often dynamic and change over time. In this paper, we\ninvestigate the problem of inferring dynamic networks based on information\ndiffusion data. We assume there is an unobserved dynamic network that changes\nover time, while we observe the results of a dynamic process spreading over the\nedges of the network. The task then is to infer the edges and the dynamics of\nthe underlying network.\n  We develop an on-line algorithm that relies on stochastic convex optimization\nto efficiently solve the dynamic network inference problem. We apply our\nalgorithm to information diffusion among 3.3 million mainstream media and blog\nsites and experiment with more than 179 million different pieces of information\nspreading over the network in a one year period. We study the evolution of\ninformation pathways in the online media space and find interesting insights.\nInformation pathways for general recurrent topics are more stable across time\nthan for on-going news events. Clusters of news media sites and blogs often\nemerge and vanish in matter of days for on-going news events. Major social\nmovements and events involving civil population, such as the Libyan's civil war\nor Syria's uprise, lead to an increased amount of information pathways among\nblogs as well as in the overall increase in the network centrality of blogs and\nsocial media sites.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 21:01:07 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Rodriguez", "Manuel Gomez", ""], ["Leskovec", "Jure", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1212.1522", "submitter": "Vasilis Gkatzelis", "authors": "Richard Cole, Vasilis Gkatzelis, Gagan Goel", "title": "Mechanism Design for Fair Division", "comments": "arXiv admin note: substantial text overlap with arXiv:1203.4627", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic problem of fair division from a mechanism design\nperspective, using {\\em Proportional Fairness} as a benchmark. In particular,\nwe aim to allocate a collection of divisible items to a set of agents while\nincentivizing the agents to be truthful in reporting their valuations. For the\nvery large class of homogeneous valuations, we design a truthful mechanism that\nprovides {\\em every agent} with at least a $1/e\\approx 0.368$ fraction of her\nProportionally Fair valuation. To complement this result, we show that no\ntruthful mechanism can guarantee more than a $0.5$ fraction, even for the\nrestricted class of additive linear valuations. We also propose another\nmechanism for additive linear valuations that works really well when every item\nis highly demanded. To guarantee truthfulness, our mechanisms discard a\ncarefully chosen fraction of the allocated resources; we conclude by uncovering\ninteresting connections between our mechanisms and known mechanisms that use\nmoney instead.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 02:31:27 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2013 05:47:58 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2014 00:14:37 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Cole", "Richard", ""], ["Gkatzelis", "Vasilis", ""], ["Goel", "Gagan", ""]]}, {"id": "1212.1527", "submitter": "Chaitanya Swamy", "authors": "Yuval Rabani, Leonard Schulman, Chaitanya Swamy", "title": "Learning Mixtures of Arbitrary Distributions over Large Discrete Domains", "comments": "Update of previous version with improved aperture and sample-size\n  lower bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for learning a mixture of {\\em unstructured}\ndistributions. This problem arises in various unsupervised learning scenarios,\nfor example in learning {\\em topic models} from a corpus of documents spanning\nseveral topics. We show how to learn the constituents of a mixture of $k$\narbitrary distributions over a large discrete domain $[n]=\\{1,2,\\dots,n\\}$ and\nthe mixture weights, using $O(n\\polylog n)$ samples. (In the topic-model\nlearning setting, the mixture constituents correspond to the topic\ndistributions.) This task is information-theoretically impossible for $k>1$\nunder the usual sampling process from a mixture distribution. However, there\nare situations (such as the above-mentioned topic model case) in which each\nsample point consists of several observations from the same mixture\nconstituent. This number of observations, which we call the {\\em \"sampling\naperture\"}, is a crucial parameter of the problem. We obtain the {\\em first}\nbounds for this mixture-learning problem {\\em without imposing any assumptions\non the mixture constituents.} We show that efficient learning is possible\nexactly at the information-theoretically least-possible aperture of $2k-1$.\nThus, we achieve near-optimal dependence on $n$ and optimal aperture. While the\nsample-size required by our algorithm depends exponentially on $k$, we prove\nthat such a dependence is {\\em unavoidable} when one considers general\nmixtures. A sequence of tools contribute to the algorithm, such as\nconcentration results for random matrices, dimension reduction, moment\nestimations, and sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 04:03:06 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 18:41:14 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2013 04:18:49 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Rabani", "Yuval", ""], ["Schulman", "Leonard", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1212.1609", "submitter": "Stavros Kolliopoulos", "authors": "Stavros G. Kolliopoulos and Yannis Moysoglou", "title": "The 2-valued case of makespan minimization with assignment constraints", "comments": "8 pages, 1 figure, to appear in Information Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following special case of minimizing makespan. A set of jobs\n$J$ and a set of machines $M$ are given. Each job $j \\in J$ can be scheduled on\na machine from a subset $M_j$ of $M$. The processing time of $j$ is the same on\nall machines in $M_j.$ The jobs are of two sizes, namely $b$ (big) and $s$\n(small). We present a polynomial-time algorithm that approximates the value of\nthe optimal makespan within a factor of 1.883 and some further improvements\nwhen every job can be scheduled on at most two machines.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 14:03:44 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Kolliopoulos", "Stavros G.", ""], ["Moysoglou", "Yannis", ""]]}, {"id": "1212.1754", "submitter": "Frans Schalekamp", "authors": "Frans Schalekamp, Rene Sitters, Suzanne van der Ster, Leen Stougie,\n  Victor Verdugo and Anke van Zuylen", "title": "Split Scheduling with Uniform Setup Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a scheduling problem in which jobs may be split into parts, where\nthe parts of a split job may be processed simultaneously on more than one\nmachine. Each part of a job requires a setup time, however, on the machine\nwhere the job part is processed. During setup a machine cannot process or set\nup any other job. We concentrate on the basic case in which setup times are\njob-, machine-, and sequence-independent. Problems of this kind were\nencountered when modelling practical problems in planning disaster relief\noperations. Our main algorithmic result is a polynomial-time algorithm for\nminimising total completion time on two parallel identical machines. We argue\nwhy the same problem with three machines is not an easy extension of the\ntwo-machine case, leaving the complexity of this case as a tantalising open\nproblem. We give a constant-factor approximation algorithm for the general case\nwith any number of machines and a polynomial-time approximation scheme for a\nfixed number of machines. For the version with objective minimising weighted\ntotal completion time we prove NP-hardness. Finally, we conclude with an\noverview of the state of the art for other split scheduling problems with job-,\nmachine-, and sequence-independent setup times.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 02:57:18 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Schalekamp", "Frans", ""], ["Sitters", "Rene", ""], ["van der Ster", "Suzanne", ""], ["Stougie", "Leen", ""], ["Verdugo", "Victor", ""], ["van Zuylen", "Anke", ""]]}, {"id": "1212.1831", "submitter": "Shayan Oveis Gharan", "authors": "Shayan Oveis Gharan and Luca Trevisan", "title": "A New Regularity Lemma and Faster Approximation Algorithms for Low\n  Threshold Rank Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kolla and Tulsiani [KT07,Kolla11} and Arora, Barak and Steurer [ABS10]\nintroduced the technique of subspace enumeration, which gives approximation\nalgorithms for graph problems such as unique games and small set expansion; the\nrunning time of such algorithms is exponential in the threshold-rank of the\ngraph.\n  Guruswami and Sinop [GS11,GS12], and Barak, Raghavendra, and Steurer [BRS11]\ndeveloped an alternative approach to the design of approximation algorithms for\ngraphs of bounded threshold-rank, based on semidefinite programming relaxations\nin the Lassere hierarchy and on novel rounding techniques. These algorithms are\nfaster than the ones based on subspace enumeration and work on a broad class of\nproblems.\n  In this paper we develop a third approach to the design of such algorithms.\nWe show, constructively, that graphs of bounded threshold-rank satisfy a weak\nSzemeredi regularity lemma analogous to the one proved by Frieze and Kannan\n[FK99] for dense graphs. The existence of efficient approximation algorithms is\nthen a consequence of the regularity lemma, as shown by Frieze and Kannan.\nApplying our method to the Max Cut problem, we devise an algorithm that is\nfaster than all previous algorithms, and is easier to describe and analyze.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 19:31:11 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Gharan", "Shayan Oveis", ""], ["Trevisan", "Luca", ""]]}, {"id": "1212.1881", "submitter": "Georg Gottlob", "authors": "Georg Gottlob", "title": "Deciding Monotone Duality and Identifying Frequent Itemsets in Quadratic\n  Logspace", "comments": "Preprint of a paper which appeared in: Proceedings of the 32nd ACM\n  SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS 2013,\n  New York, NY,USA, June 22-27,2013, pp.25-36", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monotone duality problem is defined as follows: Given two monotone\nformulas f and g in iredundant DNF, decide whether f and g are dual. This\nproblem is the same as duality testing for hypergraphs, that is, checking\nwhether a hypergraph H consists of precisely all minimal transversals of a\nsimple hypergraph G. By exploiting a recent problem-decomposition method by\nBoros and Makino (ICALP 2009), we show that duality testing for hypergraphs,\nand thus for monotone DNFs, is feasible in DSPACE[log^2 n], i.e., in quadratic\nlogspace. As the monotone duality problem is equivalent to a number of problems\nin the areas of databases, data mining, and knowledge discovery, the results\npresented here yield new complexity results for those problems, too. For\nexample, it follows from our results that whenever for a Boolean-valued\nrelation (whose attributes represent items), a number of maximal frequent\nitemsets and a number of minimal infrequent itemsets are known, then it can be\ndecided in quadratic logspace whether there exist additional frequent or\ninfrequent itemsets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 11:36:09 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 18:16:02 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 16:55:31 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Gottlob", "Georg", ""]]}, {"id": "1212.1884", "submitter": "Diodato Ferraioli", "authors": "Vincenzo Auletta, Diodato Ferraioli, Francesco Pasquale, Paolo Penna\n  and Giuseppe Persiano", "title": "Convergence to Equilibrium of Logit Dynamics for Strategic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first general bounds on the mixing time of the Markov chain\nassociated to the logit dynamics for wide classes of strategic games. The logit\ndynamics with inverse noise beta describes the behavior of a complex system\nwhose individual components act selfishly and keep responding according to some\npartial (\"noisy\") knowledge of the system, where the capacity of the agent to\nknow the system and compute her best move is measured by the inverse of the\nparameter beta.\n  In particular, we prove nearly tight bounds for potential games and games\nwith dominant strategies. Our results show that, for potential games, the\nmixing time is upper and lower bounded by an exponential in the inverse of the\nnoise and in the maximum potential difference. Instead, for games with dominant\nstrategies, the mixing time cannot grow arbitrarily with the inverse of the\nnoise.\n  Finally, we refine our analysis for a subclass of potential games called\ngraphical coordination games, a class of games that have been previously\nstudied in Physics and, more recently, in Computer Science in the context of\ndiffusion of new technologies. We give evidence that the mixing time of the\nlogit dynamics for these games strongly depends on the structure of the\nunderlying graph. We prove that the mixing time of the logit dynamics for these\ngames can be upper bounded by a function that is exponential in the cutwidth of\nthe underlying graph and in the inverse of noise. Moreover, we consider two\nspecific and popular network topologies, the clique and the ring. For games\nplayed on a clique we prove an almost matching lower bound on the mixing time\nof the logit dynamics that is exponential in the inverse of the noise and in\nthe maximum potential difference, while for games played on a ring we prove\nthat the time of convergence of the logit dynamics to its stationary\ndistribution is significantly shorter.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 11:53:59 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2012 11:50:09 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Auletta", "Vincenzo", ""], ["Ferraioli", "Diodato", ""], ["Pasquale", "Francesco", ""], ["Penna", "Paolo", ""], ["Persiano", "Giuseppe", ""]]}, {"id": "1212.1909", "submitter": "Luay Nakhleh", "authors": "Yun Yu and Luay Nakhleh", "title": "Fast Algorithms for Reconciliation under Hybridization and Incomplete\n  Lineage Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconciling a gene tree with a species tree is an important task that reveals\nmuch about the evolution of genes, genomes, and species, as well as about the\nmolecular function of genes. A wide array of computational tools have been\ndevised for this task under certain evolutionary events such as hybridization,\ngene duplication/loss, or incomplete lineage sorting. Work on reconciling gene\ntree with species phylogenies under two or more of these events have also begun\nto emerge. Our group recently devised both parsimony and probabilistic\nframeworks for reconciling a gene tree with a phylogenetic network, thus\nallowing for the detection of hybridization in the presence of incomplete\nlineage sorting. While the frameworks were general and could handle any\ntopology, they are computationally intensive, rendering their application to\nlarge datasets infeasible. In this paper, we present two novel approaches to\naddress the computational challenges of the two frameworks that are based on\nthe concept of ancestral configurations. Our approaches still compute exact\nsolutions while improving the computational time by up to five orders of\nmagnitude. These substantial gains in speed scale the applicability of these\nunified reconciliation frameworks to much larger data sets. We discuss how the\ntopological features of the gene tree and phylogenetic network may affect the\nperformance of the new algorithms. We have implemented the algorithms in our\nPhyloNet software package, which is publicly available in open source.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 18:12:55 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Yu", "Yun", ""], ["Nakhleh", "Luay", ""]]}, {"id": "1212.1958", "submitter": "Richard Brent", "authors": "Shi Bai, Richard P. Brent and Emmanuel Thom\\'e", "title": "Root optimization of polynomials in the number field sieve", "comments": "16 pages, 18 references", "journal-ref": "Mathematics of Computation 84 (2015), 2447-2457", "doi": "10.1090/S0025-5718-2015-02926-3", "report-no": null, "categories": "math.NT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general number field sieve (GNFS) is the most efficient algorithm known\nfor factoring large integers. It consists of several stages, the first one\nbeing polynomial selection. The quality of the chosen polynomials in polynomial\nselection can be modelled in terms of size and root properties. In this paper,\nwe describe some algorithms for selecting polynomials with very good root\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 03:05:08 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Bai", "Shi", ""], ["Brent", "Richard P.", ""], ["Thom\u00e9", "Emmanuel", ""]]}, {"id": "1212.2236", "submitter": "Gerhard Woeginger", "authors": "Gerhard J. Woeginger", "title": "Core stability in hedonic coalition formation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many economic, social and political situations individuals carry out\nactivities in groups (coalitions) rather than alone and on their own. Examples\nrange from households and sport clubs to research networks, political parties\nand trade unions. The underlying game theoretic framework is known as coalition\nformation.\n  This survey discusses the notion of core stability in hedonic coalition\nformation (where each player's happiness only depends on the other members of\nhis coalition but not on how the remaining players outside his coalition are\ngrouped). We present the central concepts and algorithmic approaches in the\narea, provide many examples, and pose a number of open problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 22:23:19 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Woeginger", "Gerhard J.", ""]]}, {"id": "1212.2264", "submitter": "Ali Pinar", "authors": "Madhav Jha and C. Seshadhri and Ali Pinar", "title": "A space efficient streaming algorithm for triangle counting using the\n  birthday paradox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a space efficient algorithm that approximates the transitivity\n(global clustering coefficient) and total triangle count with only a single\npass through a graph given as a stream of edges. Our procedure is based on the\nclassic probabilistic result, the birthday paradox. When the transitivity is\nconstant and there are more edges than wedges (common properties for social\nnetworks), we can prove that our algorithm requires $O(\\sqrt{n})$ space ($n$ is\nthe number of vertices) to provide accurate estimates. We run a detailed set of\nexperiments on a variety of real graphs and demonstrate that the memory\nrequirement of the algorithm is a tiny fraction of the graph. For example, even\nfor a graph with 200 million edges, our algorithm stores just 60,000 edges to\ngive accurate results. Being a single pass streaming algorithm, our procedure\nalso maintains a real-time estimate of the transitivity/number of triangles of\na graph, by storing a minuscule fraction of edges.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 01:02:12 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 18:33:51 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2013 04:38:31 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Jha", "Madhav", ""], ["Seshadhri", "C.", ""], ["Pinar", "Ali", ""]]}, {"id": "1212.2284", "submitter": "Tyson Williams", "authors": "Heng Guo and Tyson Williams", "title": "The Complexity of Planar Boolean #CSP with Complex Weights", "comments": "38 pages, 12 figures, preliminary version appeared at ICALP 2013.\n  arXiv admin note: text overlap with arXiv:1207.2354, arXiv:1008.0683 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a complexity dichotomy theorem for symmetric complex-weighted\nBoolean #CSP when the constraint graph of the input must be planar. The\nproblems that are #P-hard over general graphs but tractable over planar graphs\nare precisely those with a holographic reduction to matchgates. This\ngeneralizes a theorem of Cai, Lu, and Xia for the case of real weights. We also\nobtain a dichotomy theorem for a symmetric arity 4 signature with complex\nweights in the planar Holant framework, which we use in the proof of our #CSP\ndichotomy. In particular, we reduce the problem of evaluating the Tutte\npolynomial of a planar graph at the point (3,3) to counting the number of\nEulerian orientations over planar 4-regular graphs to show the latter is\n#P-hard. This strengthens a theorem by Huang and Lu to the planar setting. Our\nproof techniques combine new ideas with refinements and extensions of existing\ntechniques. These include planar pairings, the recursive unary construction,\nthe anti-gadget technique, and pinning in the Hadamard basis.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 03:05:01 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 15:30:43 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1212.2386", "submitter": "Kishore Jaganathan", "authors": "Kishore Jaganathan, Babak Hassibi", "title": "Reconstruction of Integers from Pairwise Distances", "comments": "14 pages, 4 figures, submitted to ICASSP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of integers, one can easily construct the set of their pairwise\ndistances. We consider the inverse problem: given a set of pairwise distances,\nfind the integer set which realizes the pairwise distance set. This problem\narises in a lot of fields in engineering and applied physics, and has\nconfounded researchers for over 60 years. It is one of the few fundamental\nproblems that are neither known to be NP-hard nor solvable by polynomial-time\nalgorithms. Whether unique recovery is possible also remains an open question.\n  In many practical applications where this problem occurs, the integer set is\nnaturally sparse (i.e., the integers are sufficiently spaced), a property which\nhas not been explored. In this work, we exploit the sparse nature of the\ninteger set and develop a polynomial-time algorithm which provably recovers the\nset of integers (up to linear shift and reversal) from the set of their\npairwise distances with arbitrarily high probability if the sparsity is\n$O(n^{1/2-\\eps})$. Numerical simulations verify the effectiveness of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 11:20:36 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Jaganathan", "Kishore", ""], ["Hassibi", "Babak", ""]]}, {"id": "1212.2479", "submitter": "Mark Hopkins", "authors": "Mark Hopkins", "title": "LAYERWIDTH: Analysis of a New Metric for Directed Acyclic Graphs", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-321-328", "categories": "cs.DS cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new property of directed acyclic graphs (DAGs), called\nlayerwidth, arising from a class of DAGs proposed by Eiter and Lukasiewicz.\nThis class of DAGs permits certain problems of structural model-based causality\nand explanation to be tractably solved. In this paper, we first address an open\nquestion raised by Eiter and Lukasiewicz - the computational complexity of\ndeciding whether a given graph has a bounded layerwidth. After proving that\nthis problem is NP-complete, we proceed by proving numerous important\nproperties of layerwidth that are helpful in efficiently computing the optimal\nlayerwidth. Finally, we compare this new DAG property to two other important\nDAG properties: treewidth and bandwidth.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:04 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Hopkins", "Mark", ""]]}, {"id": "1212.2485", "submitter": "Yong Gao", "authors": "Yong Gao", "title": "Phase Transition of Tractability in Constraint Satisfaction and Bayesian\n  Network Inference", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-265-271", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been great interest in identifying tractable subclasses of NP\ncomplete problems and designing efficient algorithms for these tractable\nclasses. Constraint satisfaction and Bayesian network inference are two\nexamples of such problems that are of great importance in AI and algorithms. In\nthis paper we study, under the frameworks of random constraint satisfaction\nproblems and random Bayesian networks, a typical tractable subclass\ncharacterized by the treewidth of the problems. We show that the property of\nhaving a bounded treewidth for CSPs and Bayesian network inference problem has\na phase transition that occurs while the underlying structures of problems are\nstill sparse. This implies that algorithms making use of treewidth based\nstructural knowledge only work efficiently in a limited range of random\ninstance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:37 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Gao", "Yong", ""]]}, {"id": "1212.2573", "submitter": "K. S. Sesh Kumar", "authors": "K. S. Sesh Kumar (LIENS, INRIA Paris - Rocquencourt), Francis Bach\n  (LIENS, INRIA Paris - Rocquencourt)", "title": "Convex Relaxations for Learning Bounded Treewidth Decomposable Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the structure of undirected graphical\nmodels with bounded treewidth, within the maximum likelihood framework. This is\nan NP-hard problem and most approaches consider local search techniques. In\nthis paper, we pose it as a combinatorial optimization problem, which is then\nrelaxed to a convex optimization problem that involves searching over the\nforest and hyperforest polytopes with special structures, independently. A\nsupergradient method is used to solve the dual problem, with a run-time\ncomplexity of $O(k^3 n^{k+2} \\log n)$ for each iteration, where $n$ is the\nnumber of variables and $k$ is a bound on the treewidth. We compare our\napproach to state-of-the-art methods on synthetic datasets and classical\nbenchmarks, showing the gains of the novel convex approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 18:22:31 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Kumar", "K. S. Sesh", "", "LIENS, INRIA Paris - Rocquencourt"], ["Bach", "Francis", "", "LIENS, INRIA Paris - Rocquencourt"]]}, {"id": "1212.2778", "submitter": "Vincenzo Bonifaci", "authors": "Vincenzo Bonifaci and Alberto Marchetti-Spaccamela and Sebastian\n  Stiller and Andreas Wiese", "title": "Feasibility Tests for Recurrent Real-Time Tasks in the Sporadic DAG\n  Model", "comments": null, "journal-ref": "Proceedings of the 2013 25th Euromicro Conference on Real-Time\n  Systems", "doi": "10.1109/ECRTS.2013.32", "report-no": null, "categories": "cs.DS cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model has been proposed in [Baruah et al., in Proceedings of the IEEE\nReal-Time Systems Symposium 2012] for representing recurrent\nprecedence-constrained tasks to be executed on multiprocessor platforms, where\neach recurrent task is modeled by a directed acyclic graph (DAG), a period, and\na relative deadline. Each vertex of the DAG represents a sequential job, while\nthe edges of the DAG represent precedence constraints between these jobs. All\nthe jobs of the DAG are released simultaneously and have to be completed within\nsome specified relative deadline. The task may release jobs in this manner an\nunbounded number of times, with successive releases occurring at least the\nspecified period apart. The feasibility problem is to determine whether such a\nrecurrent task can be scheduled to always meet all deadlines on a specified\nnumber of dedicated processors.\n  The case of a single task has been considered in [Baruah et al., 2012]. The\nmain contribution of this paper is to consider the case of multiple tasks. We\nshow that EDF has a speedup bound of 2-1/m, where m is the number of\nprocessors. Moreover, we present polynomial and pseudopolynomial schedulability\ntests, of differing effectiveness, for determining whether a set of sporadic\nDAG tasks can be scheduled by EDF to meet all deadlines on a specified number\nof processors.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 11:37:48 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Bonifaci", "Vincenzo", ""], ["Marchetti-Spaccamela", "Alberto", ""], ["Stiller", "Sebastian", ""], ["Wiese", "Andreas", ""]]}, {"id": "1212.2952", "submitter": "Dominik Kempa", "authors": "Juha K\\\"arkk\\\"ainen, Dominik Kempa, Simon J. Puglisi", "title": "Linear Time Lempel-Ziv Factorization: Simple, Fast, Small", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-38905-4_19", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the LZ factorization (or LZ77 parsing) of a string is a\ncomputational bottleneck in many diverse applications, including data\ncompression, text indexing, and pattern discovery. We describe new linear time\nLZ factorization algorithms, some of which require only 2n log n + O(log n)\nbits of working space to factorize a string of length n. These are the most\nspace efficient linear time algorithms to date, using n log n bits less space\nthan any previous linear time algorithm. The algorithms are also practical,\nsimple to implement, and very fast in practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 20:35:53 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["K\u00e4rkk\u00e4inen", "Juha", ""], ["Kempa", "Dominik", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1212.3055", "submitter": "Alexander Gamkrelidze", "authors": "Alexander Gamkrelidze, Gunter Hotz, Levan Varamashvili", "title": "New Invariants for the Graph Isomorphism Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel polynomial-time algorithm to compute graph\ninvariants based on the modified random walk idea on graphs. However not proved\nto be a full graph invariant by now, our method gives the right answer for the\ngraph instances other well-known methods could not compute (such as special\nFurer Gadgets and point-line incidence graphs of finite projective planes of\nhigher degrees\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 05:35:32 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2015 10:39:32 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Gamkrelidze", "Alexander", ""], ["Hotz", "Gunter", ""], ["Varamashvili", "Levan", ""]]}, {"id": "1212.3079", "submitter": "Sayan Bhattacharya", "authors": "Sayan Bhattacharya, Janardhan Kulkarni, Xiaoming Xu", "title": "Constant-Competitive Prior-Free Auction with Ordered Bidders", "comments": "The same result has been obtained independently by E. Koutsoupias, S.\n  Leonardi and T. Roughgarden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in Microeconomics is to design auctions with good revenue\nproperties. In this setting, the bidders' valuations for the items are private\nknowledge, but they are drawn from publicly known prior distributions. The goal\nis to find a truthful auction (no bidder can gain in utility by misreporting\nher valuation) that maximizes the expected revenue.\n  Naturally, the optimal-auction is sensitive to the prior distributions. An\nintriguing question is to design a truthful auction that is oblivious to these\npriors, and yet manages to get a constant factor of the optimal revenue. Such\nauctions are called prior-free.\n  Goldberg et al. presented a constant-approximate prior-free auction when\nthere are identical copies of an item available in unlimited supply, bidders\nare unit-demand, and their valuations are drawn from i.i.d. distributions. The\nrecent work of Leonardi et al. [STOC 2012] generalized this problem to non\ni.i.d. bidders, assuming that the auctioneer knows the ordering of their\nreserve prices. Leonardi et al. proposed a prior-free auction that achieves a\n$O(\\log^* n)$ approximation. We improve upon this result, by giving the first\nprior-free auction with constant approximation guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 07:59:44 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 17:25:29 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Bhattacharya", "Sayan", ""], ["Kulkarni", "Janardhan", ""], ["Xu", "Xiaoming", ""]]}, {"id": "1212.3193", "submitter": "Oscar Martinez", "authors": "Oscar Martinez", "title": "An Efficient Algorithm to Calculate the Center of the Biggest Inscribed\n  Circle in an Irregular Polygon", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an efficient algorithm to find the center of the biggest\ncircle inscribed in a given polygon is described. This work was inspired by the\npublication of Daniel Garcia-Castellanos & Umberto Lombardo and their algorithm\nused to find a landmass' poles of inaccessibility. Two more efficient\nalgorithms were found, one of them only applicable when the problem can be\ndescribed as a linear problem, like in the case of a convex polygon.\n  Keywords: distance geometry, euclidean distance, inscribed circle, irregular\npolygon, algorithm, mathematical optimization, Monte Carlo, linear programming,\nmaximin\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 15:17:06 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Martinez", "Oscar", ""]]}, {"id": "1212.3233", "submitter": "Marcin Bienkowski", "authors": "Marcin Bienkowski, Jaroslaw Byrka, Marek Chrobak, Neil Dobbs, Tomasz\n  Nowicki, Maxim Sviridenko, Grzegorz Swirszcz, Neal E. Young", "title": "Approximation Algorithms for the Joint Replenishment Problem with\n  Deadlines", "comments": null, "journal-ref": "J. Scheduling 18(6): 545-560 (2015)", "doi": "10.1007/s10951-014-0392-y", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Joint Replenishment Problem (JRP) is a fundamental optimization problem\nin supply-chain management, concerned with optimizing the flow of goods from a\nsupplier to retailers. Over time, in response to demands at the retailers, the\nsupplier ships orders, via a warehouse, to the retailers. The objective is to\nschedule these orders to minimize the sum of ordering costs and retailers'\nwaiting costs.\n  We study the approximability of JRP-D, the version of JRP with deadlines,\nwhere instead of waiting costs the retailers impose strict deadlines. We study\nthe integrality gap of the standard linear-program (LP) relaxation, giving a\nlower bound of 1.207, a stronger, computer-assisted lower bound of 1.245, as\nwell as an upper bound and approximation ratio of 1.574. The best previous\nupper bound and approximation ratio was 1.667; no lower bound was previously\npublished. For the special case when all demand periods are of equal length we\ngive an upper bound of 1.5, a lower bound of 1.2, and show APX-hardness.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 17:30:58 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 11:18:51 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2015 23:24:34 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Bienkowski", "Marcin", ""], ["Byrka", "Jaroslaw", ""], ["Chrobak", "Marek", ""], ["Dobbs", "Neil", ""], ["Nowicki", "Tomasz", ""], ["Sviridenko", "Maxim", ""], ["Swirszcz", "Grzegorz", ""], ["Young", "Neal E.", ""]]}, {"id": "1212.3403", "submitter": "Longkun Guo l", "authors": "Longkun Guo, Kewen Liao", "title": "A Parameterized Approximation Algorithm for The Shallow-Light Steiner\n  Tree Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given graph $G=(V,\\, E)$ with a terminal set $S$ and a selected root\n$r\\in S$, a positive integer cost and a delay on every edge and a delay\nconstraint $D\\in Z^{+}$, the shallow-light Steiner tree (\\emph{SLST}) problem\nis to compute a minimum cost tree spanning the terminals of $S$, in which the\ndelay between root and every vertex is restrained by $D$. This problem is\nNP-hard and very hard to approximate. According to known inapproximability\nresults, this problem admits no approximation with ratio better than factor\n$(1,\\, O(\\log^{2}n))$ unless $NP\\subseteq DTIME(n^{\\log\\log n})$\n\\cite{khandekar2013some}, while it admits no approximation ratio better than\n$(1,\\, O(\\log|V|))$ for D=4 unless $NP\\subseteq DTIME(n^{\\log\\log n})$\n\\cite{bar2001generalized}. Hence, the paper focus on parameterized algorithm\nfor \\emph{SLST}. We firstly present an exact algorithm for \\emph{SLST} with\ntime complexity $O(3^{|S|}|V|D+2^{|S|}|V|^{2}D^{2}+|V|^{3}D^{3})$, where $|S|$\nand $|V|$ are the number of terminals and vertices respectively. This is a\npseudo polynomial time parameterized algorithm with respect to the\nparameterization: \"number of terminals\". Later, we improve this algorithm such\nthat it runs in polynomial time\n$O(\\frac{|V|^{2}}{\\epsilon}3^{|S|}+\\frac{|V|^{4}}{\\epsilon}2^{|S|}+\\frac{|V|^{6}}{\\epsilon})$,\nand computes a Steiner tree with delay bounded by $(1+\\epsilon)D$ and cost\nbounded by the cost of an optimum solution, where $\\epsilon>0$ is any small\nreal number. To the best of our knowledge, this is the first parameterized\napproximation algorithm for the \\emph{SLST} problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 07:23:08 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2013 16:42:06 GMT"}], "update_date": "2013-09-04", "authors_parsed": [["Guo", "Longkun", ""], ["Liao", "Kewen", ""]]}, {"id": "1212.3471", "submitter": "Marek Karpinski", "authors": "Marek Karpinski, Andrzej Lingas, Dzmitry Sledneu", "title": "Optimal Cuts and Partitions in Tree Metrics in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial time dynamic programming algorithm for optimal\npartitions in the shortest path metric induced by a tree. This resolves, among\nother things, the exact complexity status of the optimal partition problems in\none dimensional geometric metric settings. Our method of solution could be also\nof independent interest in other applications. We discuss also an extension of\nour method to the class of metrics induced by the bounded treewidth graphs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 13:52:42 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Karpinski", "Marek", ""], ["Lingas", "Andrzej", ""], ["Sledneu", "Dzmitry", ""]]}, {"id": "1212.3517", "submitter": "Mikael Gast", "authors": "Mikael Gast, Mathias Hauptmann, Marek Karpinski", "title": "Inapproximability of Dominating Set in Power Law Graphs", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give logarithmic lower bounds for the approximability of the Minimum\nDominating Set problem in connected (alpha,beta)-Power Law Graphs. We give also\na best up to now upper approximation bound on the problem for the case of the\nparameters beta>2. We develop also a new functional method for proving lower\napproximation bounds and display a sharp phase transition between\napproximability and inapproximability of the underlying problem. This method\ncould also be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 16:31:32 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Gast", "Mikael", ""], ["Hauptmann", "Mathias", ""], ["Karpinski", "Marek", ""]]}, {"id": "1212.3849", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Eldar Fischer, Hamed Hatami, Pooya Hatami,\n  Shachar Lovett", "title": "Every locally characterized affine-invariant property is testable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F = F_p for any fixed prime p >= 2. An affine-invariant property is a\nproperty of functions on F^n that is closed under taking affine transformations\nof the domain. We prove that all affine-invariant property having local\ncharacterizations are testable. In fact, we show a proximity-oblivious test for\nany such property P, meaning that there is a test that, given an input function\nf, makes a constant number of queries to f, always accepts if f satisfies P,\nand rejects with positive probability if the distance between f and P is\nnonzero. More generally, we show that any affine-invariant property that is\nclosed under taking restrictions to subspaces and has bounded complexity is\ntestable.\n  We also prove that any property that can be described as the property of\ndecomposing into a known structure of low-degree polynomials is locally\ncharacterized and is, hence, testable. For example, whether a function is a\nproduct of two degree-d polynomials, whether a function splits into a product\nof d linear polynomials, and whether a function has low rank are all examples\nof degree-structural properties and are therefore locally characterized.\n  Our results depend on a new Gowers inverse theorem by Tao and Ziegler for low\ncharacteristic fields that decomposes any polynomial with large Gowers norm\ninto a function of low-degree non-classical polynomials. We establish a new\nequidistribution result for high rank non-classical polynomials that drives the\nproofs of both the testability results and the local characterization of\ndegree-structural properties.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 23:22:01 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 07:34:07 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Fischer", "Eldar", ""], ["Hatami", "Hamed", ""], ["Hatami", "Pooya", ""], ["Lovett", "Shachar", ""]]}, {"id": "1212.3889", "submitter": "Shashank Mehta", "authors": "Pawan Aurora, Sumit Singh, Shashank K. Mehta", "title": "Partial Degree Bounded Edge Packing Problem with Arbitrary Bounds", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Partial Degree Bounded Edge Packing (PDBEP) problem introduced\nin [5] by Zhang. They have shown that this problem is NP-Hard even for uniform\ndegree constraint. They also presented approximation algorithms for the case\nwhen all the vertices have degree constraint of 1 and 2 with approximation\nratio of 2 and 32=11 respectively. In this work we study general degree\nconstraint case (arbitrary degree constraint for each vertex) and present two\ncombinatorial approximation algorithms with approximation factors 4 and 2. We\nalso study integer program based solution and present an iterative rounding\nalgorithm with approximation factor 3/(1 - \\epsilon)^2 for any positive\n\\epsilon. Next we study the same problem with weighted edges. In this case we\npresent an O(log n) approximation algorithm. Zhang has given an exact O(n^2)\ncomplexity algorithm for trees in case of uniform degree constraint. We improve\ntheir result by giving O(nlog n) complexity exact algorithm for trees with\ngeneral degree constraint.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 05:28:46 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Aurora", "Pawan", ""], ["Singh", "Sumit", ""], ["Mehta", "Shashank K.", ""]]}, {"id": "1212.3981", "submitter": "Joseph Cheriyan", "authors": "Joseph Cheriyan and Laszlo A. Vegh", "title": "Approximating Minimum-Cost k-Node Connected Subgraphs via\n  Independence-Free Graphs", "comments": "20 pages, 1 figure, 28 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a 6-approximation algorithm for the minimum-cost $k$-node\nconnected spanning subgraph problem, assuming that the number of nodes is at\nleast $k^3(k-1)+k$. We apply a combinatorial preprocessing, based on the\nFrank-Tardos algorithm for $k$-outconnectivity, to transform any input into an\ninstance such that the iterative rounding method gives a 2-approximation\nguarantee. This is the first constant-factor approximation algorithm even in\nthe asymptotic setting of the problem, that is, the restriction to instances\nwhere the number of nodes is lower bounded by a function of $k$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 13:14:03 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Cheriyan", "Joseph", ""], ["Vegh", "Laszlo A.", ""]]}, {"id": "1212.4016", "submitter": "Shahin Kamali", "authors": "Joan Boyar, Shahin Kamali, Kim S. Larsen, Alejandro L\\'opez-Ortiz", "title": "Online Bin Packing with Advice", "comments": "19 pages, 1 figure (2 subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online bin packing problem under the advice complexity model\nwhere the 'online constraint' is relaxed and an algorithm receives partial\ninformation about the future requests. We provide tight upper and lower bounds\nfor the amount of advice an algorithm needs to achieve an optimal packing. We\nalso introduce an algorithm that, when provided with log n + o(log n) bits of\nadvice, achieves a competitive ratio of 3/2 for the general problem. This\nalgorithm is simple and is expected to find real-world applications. We\nintroduce another algorithm that receives 2n + o(n) bits of advice and achieves\na competitive ratio of 4/3 + {\\epsilon}. Finally, we provide a lower bound\nargument that implies that advice of linear size is required for an algorithm\nto achieve a competitive ratio better than 9/8.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 15:05:06 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2013 21:38:18 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Boyar", "Joan", ""], ["Kamali", "Shahin", ""], ["Larsen", "Kim S.", ""], ["L\u00f3pez-Ortiz", "Alejandro", ""]]}, {"id": "1212.4080", "submitter": "Eric Mjolsness", "authors": "David Orendorff and Eric Mjolsness", "title": "A Hierarchical Exact Accelerated Stochastic Simulation Algorithm", "comments": "22 pages, 3 figures", "journal-ref": "J. Chem. Phys. 137, 214104 (2012)", "doi": "10.1063/1.4766353", "report-no": null, "categories": "q-bio.MN cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm, \"HiER-leap\", is derived which improves on the computational\nproperties of the ER-leap algorithm for exact accelerated simulation of\nstochastic chemical kinetics. Unlike ER-leap, HiER-leap utilizes a hierarchical\nor divide-and-conquer organization of reaction channels into tightly coupled\n\"blocks\" and is thereby able to speed up systems with many reaction channels.\nLike ER-leap, HiER-leap is based on the use of upper and lower bounds on the\nreaction propensities to define a rejection sampling algorithm with inexpensive\nearly rejection and acceptance steps. But in HiER-leap, large portions of\nintra-block sampling may be done in parallel. An accept/reject step is used to\nsynchronize across blocks. This method scales well when many reaction channels\nare present and has desirable asymptotic properties. The algorithm is exact,\nparallelizable and achieves a significant speedup over SSA and ER-leap on\ncertain problems. This algorithm offers a potentially important step towards\nefficient in silico modeling of entire organisms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 17:42:45 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Orendorff", "David", ""], ["Mjolsness", "Eric", ""]]}, {"id": "1212.4129", "submitter": "Bundit Laekhanukit", "authors": "Parinya Chalermsook, Bundit Laekhanukit, Danupon Nanongkai", "title": "Graph Products Revisited: Tight Approximation Hardness of Induced\n  Matching, Poset Dimension and More", "comments": "Preliminary version is published in SODA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph product is a fundamental tool with rich applications in both graph\ntheory and theoretical computer science. It is usually studied in the form\n$f(G*H)$ where $G$ and $H$ are graphs, * is a graph product and $f$ is a graph\nproperty. For example, if $f$ is the independence number and * is the\ndisjunctive product, then the product is known to be multiplicative:\n$f(G*H)=f(G)f(H)$.\n  In this paper, we study graph products in the following non-standard form:\n$f((G\\oplus H)*J)$ where $G$, $H$ and $J$ are graphs, $\\oplus$ and * are two\ndifferent graph products and $f$ is a graph property. We show that if $f$ is\nthe induced and semi-induced matching number, then for some products $\\oplus$\nand *, it is subadditive in the sense that $f((G\\oplus H)*J)\\leq\nf(G*J)+f(H*J)$. Moreover, when $f$ is the poset dimension number, it is almost\nsubadditive.\n  As applications of this result (we only need $J=K_2$ here), we obtain tight\nhardness of approximation for various problems in discrete mathematics and\ncomputer science: bipartite induced and semi-induced matching (a.k.a. maximum\nexpanding sequences), poset dimension, maximum feasible subsystem with 0/1\ncoefficients, unit-demand min-buying and single-minded pricing, donation center\nlocation, boxicity, cubicity, threshold dimension and independent packing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 20:38:28 GMT"}, {"version": "v2", "created": "Sat, 18 Oct 2014 20:55:49 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Chalermsook", "Parinya", ""], ["Laekhanukit", "Bundit", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "1212.4372", "submitter": "Widad Machmouchi", "authors": "Paul Beame, Raphael Clifford, Widad Machmouchi", "title": "Sliding Windows with Limited Storage", "comments": "The results of this paper are superceded by the paper at:\n  arXiv:1309.3690", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider time-space tradeoffs for exactly computing frequency moments and\norder statistics over sliding windows. Given an input of length 2n-1, the task\nis to output the function of each window of length n, giving n outputs in\ntotal. Computations over sliding windows are related to direct sum problems\nexcept that inputs to instances almost completely overlap.\n  We show an average case and randomized time-space tradeoff lower bound of TS\nin Omega(n^2) for multi-way branching programs, and hence standard RAM and\nword-RAM models, to compute the number of distinct elements, F_0, in sliding\nwindows over alphabet [n]. The same lower bound holds for computing the\nlow-order bit of F_0 and computing any frequency moment F_k for k not equal to\n1. We complement this lower bound with a TS in \\tilde O(n^2) deterministic RAM\nalgorithm for exactly computing F_k in sliding windows.\n  We show time-space separations between the complexity of sliding-window\nelement distinctness and that of sliding-window $F_0\\bmod 2$ computation. In\nparticular for alphabet [n] there is a very simple errorless sliding-window\nalgorithm for element distinctness that runs in O(n) time on average and uses\nO(log{n}) space.\n  We show that any algorithm for a single element distinctness instance can be\nextended to an algorithm for the sliding-window version of element distinctness\nwith at most a polylogarithmic increase in the time-space product.\n  Finally, we show that the sliding-window computation of order statistics such\nas the maximum and minimum can be computed with only a logarithmic increase in\ntime, but that a TS in Omega(n^2) lower bound holds for sliding-window\ncomputation of order statistics such as the median, a nearly linear increase in\ntime when space is small.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 14:50:45 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2013 21:30:55 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2013 02:32:31 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Beame", "Paul", ""], ["Clifford", "Raphael", ""], ["Machmouchi", "Widad", ""]]}, {"id": "1212.4613", "submitter": "Travis Gagie", "authors": "Travis Gagie, Wing-Kai Hon and Tsung-Han Ku", "title": "New Algorithms for Position Heaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several results about position heaps, a relatively new alternative\nto suffix trees and suffix arrays. First, we show that, if we limit the maximum\nlength of patterns to be sought, then we can also limit the height of the heap\nand reduce the worst-case cost of insertions and deletions. Second, we show how\nto build a position heap in linear time independent of the size of the\nalphabet. Third, we show how to augment a position heap such that it supports\naccess to the corresponding suffix array, and vice versa. Fourth, we introduce\na variant of a position heap that can be simulated efficiently by a compressed\nsuffix array with a linear number of extra bits.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 10:03:47 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2013 15:14:10 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Gagie", "Travis", ""], ["Hon", "Wing-Kai", ""], ["Ku", "Tsung-Han", ""]]}, {"id": "1212.4756", "submitter": "Matthew Patitz", "authors": "Erik D. Demaine, Martin L. Demaine, S\\'andor P. Fekete, Matthew J.\n  Patitz, Robert T. Schweller, Andrew Winslow, and Damien Woods", "title": "One Tile to Rule Them All: Simulating Any Turing Machine, Tile Assembly\n  System, or Tiling System with a Single Puzzle Piece", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the power of tile self-assembly models that extend\nthe well-studied abstract Tile Assembly Model (aTAM) by permitting tiles of\nshapes beyond unit squares. Our main result shows the surprising fact that any\naTAM system, consisting of many different tile types, can be simulated by a\nsingle tile type of a general shape. As a consequence, we obtain a single\nuniversal tile type of a single (constant-size) shape that serves as a\n\"universal tile machine\": the single universal tile type can simulate any\ndesired aTAM system when given a single seed assembly that encodes the desired\naTAM system. We also show how to adapt this result to convert any of a variety\nof plane tiling systems (such as Wang tiles) into a \"nearly\" plane tiling\nsystem with a single tile (but with small gaps between the tiles). All of these\nresults rely on the ability to both rotate and translate tiles; by contrast, we\nshow that a single nonrotatable tile, of arbitrary shape, can produce\nassemblies which either grow infinitely or cannot grow at all, implying\ndrastically limited computational power.\n  On the positive side, we show how to simulate arbitrary cellular automata for\na limited number of steps using a single nonrotatable tile and a linear-size\nseed assembly.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 17:37:27 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Fekete", "S\u00e1ndor P.", ""], ["Patitz", "Matthew J.", ""], ["Schweller", "Robert T.", ""], ["Winslow", "Andrew", ""], ["Woods", "Damien", ""]]}, {"id": "1212.4771", "submitter": "Perouz Taslakian", "authors": "David Bremner, Timothy M. Chan, Erik D. Demaine, Jeff Erickson, Ferran\n  Hurtado, John Iacono, Stefan Langerman, Mihai Patrascu, Perouz Taslakian", "title": "Necklaces, Convolutions, and X+Y", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give subquadratic algorithms that, given two necklaces each with n beads\nat arbitrary positions, compute the optimal rotation of the necklaces to best\nalign the beads. Here alignment is measured according to the p norm of the\nvector of distances between pairs of beads from opposite necklaces in the best\nperfect matching. We show surprisingly different results for p = 1, p even, and\np = \\infty. For p even, we reduce the problem to standard convolution, while\nfor p = \\infty and p = 1, we reduce the problem to (min, +) convolution and\n(median, +) convolution. Then we solve the latter two convolution problems in\nsubquadratic time, which are interesting results in their own right. These\nresults shed some light on the classic sorting X + Y problem, because the\nconvolutions can be viewed as computing order statistics on the antidiagonals\nof the X + Y matrix. All of our algorithms run in o(n^2) time, whereas the\nobvious algorithms for these problems run in \\Theta(n^2) time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 18:07:20 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Bremner", "David", ""], ["Chan", "Timothy M.", ""], ["Demaine", "Erik D.", ""], ["Erickson", "Jeff", ""], ["Hurtado", "Ferran", ""], ["Iacono", "John", ""], ["Langerman", "Stefan", ""], ["Patrascu", "Mihai", ""], ["Taslakian", "Perouz", ""]]}, {"id": "1212.4777", "submitter": "Ankur Moitra", "authors": "Sanjeev Arora, Rong Ge, Yoni Halpern, David Mimno, Ankur Moitra, David\n  Sontag, Yichen Wu, Michael Zhu", "title": "A Practical Algorithm for Topic Modeling with Provable Guarantees", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models provide a useful method for dimensionality reduction and\nexploratory data analysis in large text corpora. Most approaches to topic model\ninference have been based on a maximum likelihood objective. Efficient\nalgorithms exist that approximate this objective, but they have no provable\nguarantees. Recently, algorithms have been introduced that provide provable\nbounds, but these algorithms are not practical because they are inefficient and\nnot robust to violations of model assumptions. In this paper we present an\nalgorithm for topic model inference that is both provable and practical. The\nalgorithm produces results comparable to the best MCMC implementations while\nrunning orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 18:14:51 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Halpern", "Yoni", ""], ["Mimno", "David", ""], ["Moitra", "Ankur", ""], ["Sontag", "David", ""], ["Wu", "Yichen", ""], ["Zhu", "Michael", ""]]}, {"id": "1212.4779", "submitter": "Suqi Cheng", "authors": "Suqi Cheng, Huawei Shen, Junming Huang, Guoqing Zhang, Xueqi Cheng", "title": "StaticGreedy: solving the scalability-accuracy dilemma in influence\n  maximization", "comments": "10 pages, 8 figures, this paper has been published in the proceedings\n  of CIKM2013", "journal-ref": null, "doi": "10.1145/2505515.2505541", "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization, defined as a problem of finding a set of seed nodes\nto trigger a maximized spread of influence, is crucial to viral marketing on\nsocial networks. For practical viral marketing on large scale social networks,\nit is required that influence maximization algorithms should have both\nguaranteed accuracy and high scalability. However, existing algorithms suffer a\nscalability-accuracy dilemma: conventional greedy algorithms guarantee the\naccuracy with expensive computation, while the scalable heuristic algorithms\nsuffer from unstable accuracy.\n  In this paper, we focus on solving this scalability-accuracy dilemma. We\npoint out that the essential reason of the dilemma is the surprising fact that\nthe submodularity, a key requirement of the objective function for a greedy\nalgorithm to approximate the optimum, is not guaranteed in all conventional\ngreedy algorithms in the literature of influence maximization. Therefore a\ngreedy algorithm has to afford a huge number of Monte Carlo simulations to\nreduce the pain caused by unguaranteed submodularity. Motivated by this\ncritical finding, we propose a static greedy algorithm, named StaticGreedy, to\nstrictly guarantee the submodularity of influence spread function during the\nseed selection process. The proposed algorithm makes the computational expense\ndramatically reduced by two orders of magnitude without loss of accuracy.\nMoreover, we propose a dynamical update strategy which can speed up the\nStaticGreedy algorithm by 2-7 times on large scale social networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 18:21:23 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2013 07:33:48 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2014 08:49:29 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Cheng", "Suqi", ""], ["Shen", "Huawei", ""], ["Huang", "Junming", ""], ["Zhang", "Guoqing", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1212.4797", "submitter": "Pascal Lenzner", "authors": "Bernd Kawald and Pascal Lenzner", "title": "On Dynamics in Selfish Network Creation", "comments": "36 pages, 16 figures. To appear at SPAA'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dynamic behavior of several variants of the Network Creation\nGame, introduced by Fabrikant et al. [PODC'03]. Equilibrium networks in these\nmodels have desirable properties like low social cost and small diameter, which\nmakes them attractive for the decentralized creation of overlay-networks.\nUnfortunately, due to the non-constructiveness of the Nash equilibrium, no\ndistributed algorithm for finding such networks is known. We treat these games\nas sequential-move games and analyze whether (uncoordinated) selfish play\neventually converges to an equilibrium state. Thus, we shed light on one of the\nmost natural algorithms for this problem: distributed local search, where in\neach step some agent performs a myopic selfish improving move.\n  We show that fast convergence is guaranteed for all versions of Swap Games,\nintroduced by Alon et al. [SPAA'10], if the initial network is a tree, and show\nthat this process can be sped up to an almost optimal number of moves. For\nnon-tree networks we show the surprising result that even one non-tree edge\nsuffices to destroy the convergence guarantee and no move policy can enforce\nconvergence. This answers an open problem from Ehsani et al. [SPAA'11] in the\nnegative. We extend our negative results to the well-studied original version\nand prove that there is no convergence guarantee -- even if all agents play\noptimally. Furthermore, we show the quite surprising result that employing\ncost-sharing yields even worse dynamic behavior.\n  Finally, we contrast our mostly negative theoretical results by a careful\nempirical study. Our simulations indicate two positive facts: (1) The\nnon-convergent behavior seems to be confined to a small set of pathological\ninstances and is unlikely to show up in practice. (2) In all our simulations we\nobserved a remarkably fast convergence towards a stable network in O(n) steps,\nwhere n is the number of agents.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 19:17:57 GMT"}, {"version": "v2", "created": "Tue, 28 May 2013 14:56:08 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Kawald", "Bernd", ""], ["Lenzner", "Pascal", ""]]}, {"id": "1212.4969", "submitter": "Michel Feldmann", "authors": "Michel Feldmann", "title": "Polynomial time factoring algorithm using Bayesian arithmetic", "comments": "13 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper, we have shown that any Boolean formula can be encoded as\na linear programming problem in the framework of Bayesian probability theory.\nWhen applied to NP-complete algorithms, this leads to the fundamental\nconclusion that P = NP. Now, we implement this concept in elementary arithmetic\nand especially in multiplication. This provides a polynomial time deterministic\nfactoring algorithm, while no such algorithm is known to day. This result\nclearly appeals for a revaluation of the current cryptosystems. The Bayesian\narithmetic environment can also be regarded as a toy model for quantum\nmechanics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 10:39:22 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Feldmann", "Michel", ""]]}, {"id": "1212.5098", "submitter": "Donald Sheehy", "authors": "Gary L. Miller and Donald R. Sheehy", "title": "A New Approach to Output-Sensitive Voronoi Diagrams and Delaunay\n  Triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new algorithm for computing the Voronoi diagram of a set of $n$\npoints in constant-dimensional Euclidean space.\n  The running time of our algorithm is $O(f \\log n \\log \\Delta)$ where $f$ is\nthe output complexity of the Voronoi diagram and $\\Delta$ is the spread of the\ninput, the ratio of largest to smallest pairwise distances.\n  Despite the simplicity of the algorithm and its analysis, it improves on the\nstate of the art for all inputs with polynomial spread and near-linear output\nsize.\n  The key idea is to first build the Voronoi diagram of a superset of the input\npoints using ideas from Voronoi refinement mesh generation.\n  Then, the extra points are removed in a straightforward way that allows the\ntotal work to be bounded in terms of the output complexity, yielding the output\nsensitive bound.\n  The removal only involves local flips and is inspired by kinetic data\nstructures.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 15:49:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 12:45:41 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Miller", "Gary L.", ""], ["Sheehy", "Donald R.", ""]]}, {"id": "1212.5132", "submitter": "Ilias Diakonikolas", "authors": "Anindya De, Ilias Diakonikolas, Rocco A. Servedio", "title": "The Inverse Shapley Value Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $f$ a weighted voting scheme used by $n$ voters to choose between two\ncandidates, the $n$ \\emph{Shapley-Shubik Indices} (or {\\em Shapley values}) of\n$f$ provide a measure of how much control each voter can exert over the overall\noutcome of the vote. Shapley-Shubik indices were introduced by Lloyd Shapley\nand Martin Shubik in 1954 \\cite{SS54} and are widely studied in social choice\ntheory as a measure of the \"influence\" of voters. The \\emph{Inverse Shapley\nValue Problem} is the problem of designing a weighted voting scheme which\n(approximately) achieves a desired input vector of values for the\nShapley-Shubik indices. Despite much interest in this problem no provably\ncorrect and efficient algorithm was known prior to our work.\n  We give the first efficient algorithm with provable performance guarantees\nfor the Inverse Shapley Value Problem. For any constant $\\eps > 0$ our\nalgorithm runs in fixed poly$(n)$ time (the degree of the polynomial is\nindependent of $\\eps$) and has the following performance guarantee: given as\ninput a vector of desired Shapley values, if any \"reasonable\" weighted voting\nscheme (roughly, one in which the threshold is not too skewed) approximately\nmatches the desired vector of values to within some small error, then our\nalgorithm explicitly outputs a weighted voting scheme that achieves this vector\nof Shapley values to within error $\\eps.$ If there is a \"reasonable\" voting\nscheme in which all voting weights are integers at most $\\poly(n)$ that\napproximately achieves the desired Shapley values, then our algorithm runs in\ntime $\\poly(n)$ and outputs a weighted voting scheme that achieves the target\nvector of Shapley values to within error $\\eps=n^{-1/8}.$\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 16:38:11 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["De", "Anindya", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1212.5353", "submitter": "Subhas Nandy C.", "authors": "Minati De, Subhas C. Nandy, Sasanka Roy", "title": "Convex Hull and Linear Programming in Read-only Setup with Limited\n  Work-space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prune-and-search is an important paradigm for solving many important\ngeometric problems. We show that the general prune-and-search technique can be\nimplemented where the objects are given in read-only memory. As examples we\nconsider convex-hull in 2D, and linear programming in 2D and 3D. For the\nconvex-hull problem, designing sub-quadratic algorithm in a read-only setup\nwith sub-linear space is an open problem for a long time. We first propose a\nsimple algorithm for this problem that runs in $O(n^{3/2+\\epsilon)}$ time and\n$O(n^(1/2))$ space. Next, we consider a restricted version of the problem where\nthe points in $P$ are given in sorted order with respect to their\n$x$-coordinates in a read-only array. For the linear programming problems, the\nconstraints are given in the read-only array. The last three algorithms use\n{\\it prune-and-search}, and their time and extra work-space complexities are\n$O(n^{1 + \\epsilon})$ and $O(\\log n)$ respectively, where $\\epsilon$ is a small\nconstant satisfying $\\sqrt{\\frac{\\log\\log n}{\\log n}} < \\epsilon < 1$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 07:43:55 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["De", "Minati", ""], ["Nandy", "Subhas C.", ""], ["Roy", "Sasanka", ""]]}, {"id": "1212.5645", "submitter": "Rajat Tandon", "authors": "Rajat Tandon", "title": "Algorithm to Compute Squares of 1st N Natural Numbers Without Using\n  Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Processors may find some elementary operations to be faster than the others.\nAlthough an operation may be conceptually as simple as some other operation,\nthe processing speeds of the two can vary. A clever programmer will always try\nto choose the faster instructions for the job. This paper presents an algorithm\nto display squares of 1st N natural numbers without using multiplication (*\noperator). Instead, the same work can be done using addition (+ operator). The\nresults can also be used to compute the sum of those squares. If we compare the\nnormal method of computing the squares of 1st N natural numbers with this\nmethod, we can conclude that the algorithm discussed in the paper is more\noptimized in terms of time complexity.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2012 02:06:21 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Tandon", "Rajat", ""]]}, {"id": "1212.5880", "submitter": "Ran Wolff", "authors": "Ran Wolff", "title": "Local Thresholding in General Network Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local thresholding algorithms were first presented more than a decade ago and\nhave since been applied to a variety of data mining tasks in peer-to-peer\nsystems, wireless sensor networks, and in grid systems. One critical assumption\nmade by those algorithms has always been cycle-free routing. The existence of\neven one cycle may lead all peers to the wrong outcome. Outside the lab,\nunfortunately, cycle freedom is not easy to achieve.\n  This work is the first to lift the requirement of cycle freedom by presenting\na local thresholding algorithm suitable for general network graphs. The\nalgorithm relies on a new repositioning of the problem in weighted vector\narithmetics, on a new stopping rule, whose proof does not require that the\nnetwork be cycle free, and on new methods for balance correction when the\nstopping rule fails.\n  The new stopping and update rules permit calculation of the very same\nfunctions that were calculable using previous algorithms, which do assume cycle\nfreedom. The algorithm is implemented on a standard peer-to-peer simulator and\nis validated for networks of up to 80,000 peers, organized in three different\ntopologies, which are representative of the topology of major current\ndistributed systems: the Internet, structured peer-to-peer systems, and\nwireless sensor networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 09:22:28 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2013 08:20:12 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Wolff", "Ran", ""]]}, {"id": "1212.6039", "submitter": "Haitao Wang", "authors": "Danny Z. Chen and Haitao Wang", "title": "Weak Visibility Queries of Line Segments in Simple Polygons", "comments": "16 pages, 9 figures. A preliminary version of this paper appeared in\n  ISAAC 2012 and we have improved results in this full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple polygon P in the plane, we present new algorithms and data\nstructures for computing the weak visibility polygon from any query line\nsegment in P. We build a data structure in O(n) time and O(n) space that can\ncompute the visibility polygon for any query line segment s in O(k log n) time,\nwhere k is the size of the visibility polygon of s and n is the number of\nvertices of P. Alternatively, we build a data structure in O(n^3) time and\nO(n^3) space that can compute the visibility polygon for any query line segment\nin O(k + log n) time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2012 12:57:44 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Chen", "Danny Z.", ""], ["Wang", "Haitao", ""]]}, {"id": "1212.6055", "submitter": "Seifedine Kadry Seifedine Kadry", "authors": "Seifedine Kadry, Ayman Abdallah, Chibli Joumaa", "title": "On The Optimization of Dijkstras Algorithm", "comments": "Informatics in Control, Automation and Robotics, Volume 2,\n  Springer-Verlag Berlin Heidelberg 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose some amendment on Dijkstras algorithm in order to\noptimize it by reducing the number of iterations. The main idea is to solve the\nproblem where more than one node satisfies the condition of the second step in\nthe traditional Dijkstras algorithm. After application of the proposed\nmodifications, the maximum number of iterations of Dijkstras algorithm is less\nthan the number of the graphs nodes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2012 14:18:45 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Kadry", "Seifedine", ""], ["Abdallah", "Ayman", ""], ["Joumaa", "Chibli", ""]]}, {"id": "1212.6176", "submitter": "Parter Merav", "authors": "Shiri Chechik, M. P. Johnson, Merav Parter and David Peleg", "title": "Secluded Connectivity Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a setting where possibly sensitive information sent over a path in a\nnetwork is visible to every {neighbor} of the path, i.e., every neighbor of\nsome node on the path, thus including the nodes on the path itself. The\nexposure of a path $P$ can be measured as the number of nodes adjacent to it,\ndenoted by $N[P]$. A path is said to be secluded if its exposure is small. A\nsimilar measure can be applied to other connected subgraphs, such as Steiner\ntrees connecting a given set of terminals. Such subgraphs may be relevant due\nto considerations of privacy, security or revenue maximization. This paper\nconsiders problems related to minimum exposure connectivity structures such as\npaths and Steiner trees. It is shown that on unweighted undirected $n$-node\ngraphs, the problem of finding the minimum exposure path connecting a given\npair of vertices is strongly inapproximable, i.e., hard to approximate within a\nfactor of $O(2^{\\log^{1-\\epsilon}n})$ for any $\\epsilon>0$ (under an\nappropriate complexity assumption), but is approximable with ratio\n$\\sqrt{\\Delta}+3$, where $\\Delta$ is the maximum degree in the graph. One of\nour main results concerns the class of bounded-degree graphs, which is shown to\nexhibit the following interesting dichotomy. On the one hand, the minimum\nexposure path problem is NP-hard on node-weighted or directed bounded-degree\ngraphs (even when the maximum degree is 4). On the other hand, we present a\npolynomial algorithm (based on a nontrivial dynamic program) for the problem on\nunweighted undirected bounded-degree graphs. Likewise, the problem is shown to\nbe polynomial also for the class of (weighted or unweighted) bounded-treewidth\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 13:28:08 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Chechik", "Shiri", ""], ["Johnson", "M. P.", ""], ["Parter", "Merav", ""], ["Peleg", "David", ""]]}, {"id": "1212.6327", "submitter": "Marko Grgurovi\\v{c}", "authors": "Andrej Brodnik and Marko Grgurovi\\v{c}", "title": "Speeding up shortest path algorithms", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an arbitrary, non-negatively weighted, directed graph $G=(V,E)$ we\npresent an algorithm that computes all pairs shortest paths in time\n$\\mathcal{O}(m^* n + m \\lg n + nT_\\psi(m^*, n))$, where $m^*$ is the number of\ndifferent edges contained in shortest paths and $T_\\psi(m^*, n)$ is a running\ntime of an algorithm to solve a single-source shortest path problem (SSSP).\nThis is a substantial improvement over a trivial $n$ times application of\n$\\psi$ that runs in $\\mathcal{O}(nT_\\psi(m,n))$. In our algorithm we use $\\psi$\nas a black box and hence any improvement on $\\psi$ results also in improvement\nof our algorithm.\n  Furthermore, a combination of our method, Johnson's reweighting technique and\ntopological sorting results in an $\\mathcal{O}(m^*n + m \\lg n)$ all-pairs\nshortest path algorithm for arbitrarily-weighted directed acyclic graphs.\n  In addition, we also point out a connection between the complexity of a\ncertain sorting problem defined on shortest paths and SSSP.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2012 08:59:40 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Brodnik", "Andrej", ""], ["Grgurovi\u010d", "Marko", ""]]}, {"id": "1212.6382", "submitter": "Jasine Babu", "authors": "Jasine Babu and Manu Basavaraju and L. Sunil Chandran and Deepak\n  Rajendraprasad", "title": "2-connecting Outerplanar Graphs without Blowing Up the Pathwidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a connected outerplanar graph G of pathwidth p, we give an algorithm to\nadd edges to G to get a supergraph of G, which is 2-vertex-connected,\nouterplanar and of pathwidth O(p). This settles an open problem raised by\nBiedl, in the context of computing minimum height planar straight line drawings\nof outerplanar graphs, with their vertices placed on a two dimensional grid. In\nconjunction with the result of this paper, the constant factor approximation\nalgorithm for this problem obtained by Biedl for 2-vertex-connected outerplanar\ngraphs will work for all outer planar graphs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2012 15:09:02 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2013 13:32:57 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2014 18:20:32 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Babu", "Jasine", ""], ["Basavaraju", "Manu", ""], ["Chandran", "L. Sunil", ""], ["Rajendraprasad", "Deepak", ""]]}, {"id": "1212.6492", "submitter": "David  Gao", "authors": "Changzhi Wu, Chaojie Li, and David Yang Gao", "title": "Canonical Primal-Dual Method for Solving Non-convex Minimization\n  Problems", "comments": "21 pages, 6 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new primal-dual algorithm is presented for solving a class of non-convex\nminimization problems. This algorithm is based on canonical duality theory such\nthat the original non-convex minimization problem is first reformulated as a\nconvex-concave saddle point optimization problem, which is then solved by a\nquadratically perturbed primal-dual method. %It is proved that the popular SDP\nmethod is indeed a special case of the canonical duality theory. Numerical\nexamples are illustrated. Comparing with the existing results, the proposed\nalgorithm can achieve better performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2012 09:30:57 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Wu", "Changzhi", ""], ["Li", "Chaojie", ""], ["Gao", "David Yang", ""]]}, {"id": "1212.6781", "submitter": "Daniel Dadush", "authors": "Daniel Dadush, Gabor Kun", "title": "Lattice Sparsification and the Approximate Closest Vector Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a deterministic algorithm for solving the (1+eps)-approximate Closest\nVector Problem (CVP) on any n dimensional lattice and any norm in\n2^{O(n)}(1+1/eps)^n time and 2^n poly(n) space. Our algorithm builds on the\nlattice point enumeration techniques of Micciancio and Voulgaris (STOC 2010)\nand Dadush, Peikert and Vempala (FOCS 2011), and gives an elegant,\ndeterministic alternative to the \"AKS Sieve\" based algorithms for (1+eps)-CVP\n(Ajtai, Kumar, and Sivakumar; STOC 2001 and CCC 2002). Furthermore, assuming\nthe existence of a poly(n)-space and 2^{O(n)} time algorithm for exact CVP in\nthe l_2 norm, the space complexity of our algorithm can be reduced to\npolynomial.\n  Our main technical contribution is a method for \"sparsifying\" any input\nlattice while approximately maintaining its metric structure. To this end, we\nemploy the idea of random sublattice restrictions, which was first employed by\nKhot (FOCS 2003) for the purpose of proving hardness for Shortest Vector\nProblem (SVP) under l_p norms.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2012 21:29:27 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Dadush", "Daniel", ""], ["Kun", "Gabor", ""]]}, {"id": "1212.6831", "submitter": "Mingyu Xiao", "authors": "Mingyu Xiao and Hiroshi Nagamochi", "title": "An Exact Algorithm for TSP in Degree-3 Graphs via Circuit Procedure and\n  Amortization on Connectivity Structure", "comments": "24 pages and 4 figures", "journal-ref": "Algorithmica 74(2): 713-741 (2016)", "doi": "10.1007/s00453-015-9970-4", "report-no": null, "categories": "cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The paper presents an O^*(1.2312^n)-time and polynomial-space algorithm for\nthe traveling salesman problem in an n-vertex graph with maximum degree 3. This\nimproves the previous time bounds of O^*(1.251^n) by Iwama and Nakashima and\nO^*(1.260^n) by Eppstein. Our algorithm is a simple branch-and-search\nalgorithm. The only branch rule is designed on a cut-circuit structure of a\ngraph induced by unprocessed edges. To improve a time bound by a simple\nanalysis on measure and conquer, we introduce an amortization scheme over the\ncut-circuit structure by defining the measure of an instance to be the sum of\nnot only weights of vertices but also weights of connected components of the\ninduced graph.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 07:28:15 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Xiao", "Mingyu", ""], ["Nagamochi", "Hiroshi", ""]]}, {"id": "1212.6846", "submitter": "Sagar Kale", "authors": "Sagar Kale", "title": "Maximizing a Nonnegative, Monotone, Submodular Function Constrained to\n  Matchings", "comments": "Withdrawn because the main result is implied by a more general result\n  about p-independence-system (which generalize matchings) in the paper by\n  Calinescu, Chekuri, Pal, and Vondrak, Maximizing a Monotone Submodular\n  Function Subject to a Matroid Constraint, SIAM J. Comput., 2011, Vol 40, No\n  6, pp. 1740-1766", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions have many applications. Matchings have many\napplications. The bitext word alignment problem can be modeled as the problem\nof maximizing a nonnegative, monotone, submodular function constrained to\nmatchings in a complete bipartite graph where each vertex corresponds to a word\nin the two input sentences and each edge represents a potential word-to-word\ntranslation. We propose a more general problem of maximizing a nonnegative,\nmonotone, submodular function defined on the edge set of a complete graph\nconstrained to matchings; we call this problem the CSM-Matching problem.\nCSM-Matching also generalizes the maximum-weight matching problem, which has a\npolynomial-time algorithm; however, we show that it is NP-hard to approximate\nCSM-Matching within a factor of e/(e-1) by reducing the max k-cover problem to\nit. Our main result is a simple, greedy, 3-approximation algorithm for\nCSM-Matching. Then we reduce CSM-Matching to maximizing a nonnegative,\nmonotone, submodular function over two matroids, i.e., CSM-2-Matroids.\nCSM-2-Matroids has a (2+epsilon)-approximation algorithm - called LSV2. We show\nthat we can find a (4+epsilon)-approximate solution to CSM-Matching using LSV2.\nWe extend this approach to similar problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 09:32:51 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 21:20:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kale", "Sagar", ""]]}, {"id": "1212.6848", "submitter": "Gregory Gutin", "authors": "R. Crowston, G. Gutin, M. Jones, G. Muciaccia", "title": "Maximum Balanced Subgraph Problem Parameterized Above Lower Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider graphs without loops or parallel edges in which every edge is\nassigned + or -. Such a signed graph is balanced if its vertex set can be\npartitioned into parts $V_1$ and $V_2$ such that all edges between vertices in\nthe same part have sign + and all edges between vertices of different parts\nhave sign $-$ (one of the parts may be empty). It is well-known that every\nconnected signed graph with $n$ vertices and $m$ edges has a balanced subgraph\nwith at least $\\frac{m}{2} + \\frac{n-1}{4}$ edges and this bound is tight. We\nconsider the following parameterized problem: given a connected signed graph\n$G$ with $n$ vertices and $m$ edges, decide whether $G$ has a balanced subgraph\nwith at least $\\frac{m}{2} + \\frac{n-1}{4}+\\frac{k}{4}$ edges, where $k$ is the\nparameter.\n  We obtain an algorithm for the problem of runtime $8^k(kn)^{O(1)}$. We also\nprove that for each instance $(G,k)$ of the problem, in polynomial time, we can\neither solve $(G,k)$ or produce an equivalent instance $(G',k')$ such that\n$k'\\le k$ and $|V(G')|=O(k^3)$. Our first result generalizes a result of\nCrowston, Jones and Mnich (ICALP 2012) on the corresponding parameterization of\nMax Cut (when every edge of $G$ has sign $-$). Our second result generalizes\nand significantly improves the corresponding result of Crowston, Jones and\nMnich: they showed that $|V(G')|=O(k^5)$.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 10:01:10 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 13:40:17 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Crowston", "R.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""], ["Muciaccia", "G.", ""]]}, {"id": "1212.6925", "submitter": "Krzysztof Onak", "authors": "Venkatesan Guruswami and Krzysztof Onak", "title": "Superlinear lower bounds for multipass graph processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove $n^{1+\\Omega(1/p)}/p^{O(1)}$ lower bounds for the space complexity\nof $p$-pass streaming algorithms solving the following problems on $n$-vertex\ngraphs:\n  * testing if an undirected graph has a perfect matching (this implies lower\nbounds for computing a maximum matching or even just the maximum matching\nsize),\n  * testing if two specific vertices are at distance at most $2(p+1)$ in an\nundirected graph,\n  * testing if there is a directed path from $s$ to $t$ for two specific\nvertices $s$ and $t$ in a directed graph.\n  Prior to our result, it was known that these problems require $\\Omega(n^2)$\nspace in one pass, but no $n^{1+\\Omega(1)}$ lower bound was known for any $p\\ge\n2$.\n  These streaming results follow from a communication complexity lower bound\nfor a communication game in which the players hold two graphs on the same set\nof vertices. The task of the players is to find out whether the sets of\nvertices at distance exactly $p+1$ from a specific vertex intersect. The game\nrequires a significant amount of communication only if the players are forced\nto speak in a specific difficult order. This is reminiscent of lower bounds for\ncommunication problems such as indexing and pointer chasing. Among other\nthings, our line of attack requires proving an information cost lower bound for\na decision version of the classic pointer chasing problem and a direct sum type\ntheorem for the disjunction of several instances of this problem.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 16:57:22 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2013 02:29:10 GMT"}, {"version": "v3", "created": "Mon, 18 Aug 2014 17:15:18 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2016 22:20:14 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Onak", "Krzysztof", ""]]}]