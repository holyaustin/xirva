[{"id": "1109.0094", "submitter": "Heba Affify", "authors": "Heba Afify, Muhammad Islam and Manal Abdel Wahed", "title": "DNA Lossless Differential Compression Algorithm based on Similarity of\n  Genomic Sequence Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern biological science produces vast amounts of genomic sequence data.\nThis is fuelling the need for efficient algorithms for sequence compression and\nanalysis. Data compression and the associated techniques coming from\ninformation theory are often perceived as being of interest for data\ncommunication and storage. In recent years, a substantial effort has been made\nfor the application of textual data compression techniques to various\ncomputational biology tasks, ranging from storage and indexing of large\ndatasets to comparison of genomic databases. This paper presents a differential\ncompression algorithm that is based on production of difference sequences\naccording to op-code table in order to optimize the compression of homologous\nsequences in dataset. Therefore, the stored data are composed of reference\nsequence, the set of differences, and differences locations, instead of storing\neach sequence individually. This algorithm does not require a priori knowledge\nabout the statistics of the sequence set. The algorithm was applied to three\ndifferent datasets of genomic sequences, it achieved up to 195-fold compression\nrate corresponding to 99.4% space saving.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 05:39:35 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Afify", "Heba", ""], ["Islam", "Muhammad", ""], ["Wahed", "Manal Abdel", ""]]}, {"id": "1109.0312", "submitter": "Joseph Simons", "authors": "Michael T. Goodrich and Joseph A. Simons", "title": "Fully Retroactive Approximate Range and Nearest Neighbor Searching", "comments": "24 pages, 4 figures. To appear at the 22nd International Symposium on\n  Algorithms and Computation (ISAAC 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe fully retroactive dynamic data structures for approximate range\nreporting and approximate nearest neighbor reporting. We show how to maintain,\nfor any positive constant $d$, a set of $n$ points in $\\R^d$ indexed by time\nsuch that we can perform insertions or deletions at any point in the timeline\nin $O(\\log n)$ amortized time. We support, for any small constant $\\epsilon>0$,\n$(1+\\epsilon)$-approximate range reporting queries at any point in the timeline\nin $O(\\log n + k)$ time, where $k$ is the output size. We also show how to\nanswer $(1+\\epsilon)$-approximate nearest neighbor queries for any point in the\npast or present in $O(\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 21:57:42 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Simons", "Joseph A.", ""]]}, {"id": "1109.0562", "submitter": "Tamon Stephen", "authors": "Mehrnoush Malekesmaeili, Cedric Chauve, Tamon Stephen", "title": "A tight bound on the length of odd cycles in the incompatibility graph\n  of a non-C1P matrix", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binary matrix has the consecutive ones property (C1P) if it is possible to\norder the columns so that all 1s are consecutive in every row. In [McConnell,\nSODA 2004 768-777] the notion of incompatibility graph of a binary matrix was\nintroduced and it was shown that odd cycles of this graph provide a certificate\nthat a matrix does not have the consecutive ones property. A bound of (k+2) was\nclaimed for the smallest odd cycle of a non-C1P matrix with k columns. In this\nnote we show that this result can be obtained simply and directly via Tucker\npatterns, and that the correct bound is (k+2) when k is even, but (k+3) when k\nis odd.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 21:26:43 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Malekesmaeili", "Mehrnoush", ""], ["Chauve", "Cedric", ""], ["Stephen", "Tamon", ""]]}, {"id": "1109.0604", "submitter": "Yitong Yin", "authors": "Liang Li, Pinyan Lu, Yitong Yin", "title": "Approximate Counting via Correlation Decay in Spin Systems", "comments": "29 pages, 1 figure, to appear in SODA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first deterministic fully polynomial-time approximation scheme\n(FPTAS) for computing the partition function of a two-state spin system on an\narbitrary graph, when the parameters of the system satisfy the uniqueness\ncondition on infinite regular trees. This condition is of physical significance\nand is believed to be the right boundary between approximable and\ninapproximable.\n  The FPTAS is based on the correlation decay technique introduced by\nBandyopadhyay and Gamarnik [SODA 06] and Weitz [STOC 06]. The classic\ncorrelation decay is defined with respect to graph distance. Although this\ndefinition has natural physical meanings, it does not directly support an FPTAS\nfor systems on arbitrary graphs, because for graphs with unbounded degrees, the\nlocal computation that provides a desirable precision by correlation decay may\ntake super-polynomial time. We introduce a notion of computationally efficient\ncorrelation decay, in which the correlation decay is measured in a refined\nmetric instead of graph distance. We use a potential method to analyze the\namortized behavior of this correlation decay and establish a correlation decay\nthat guarantees an inverse-polynomial precision by polynomial-time local\ncomputation. This gives us an FPTAS for spin systems on arbitrary graphs. This\nnew notion of correlation decay properly reflects the algorithmic aspect of the\nspin systems, and may be used for designing FPTAS for other counting problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2011 08:08:17 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 04:21:02 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Li", "Liang", ""], ["Lu", "Pinyan", ""], ["Yin", "Yitong", ""]]}, {"id": "1109.0782", "submitter": "Jeremy Gibbons Jeremy Gibbons", "authors": "Jeremy Gibbons (University of Oxford)", "title": "Maximum Segment Sum, Monadically (distilled tutorial, with solutions)", "comments": "Revision of the article in Proceedings DSL 2011, EPTCS 66,\n  arXiv:1109.0323, to provide solutions to the exercises", "journal-ref": "EPTCS 66, 2011, pp. 181-194", "doi": "10.4204/EPTCS.66.9", "report-no": null, "categories": "cs.DS cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum segment sum problem is to compute, given a list of integers, the\nlargest of the sums of the contiguous segments of that list. This problem\nspecification maps directly onto a cubic-time algorithm; however, there is a\nvery elegant linear-time solution too. The problem is a classic exercise in the\nmathematics of program construction, illustrating important principles such as\ncalculational development, pointfree reasoning, algebraic structure, and\ndatatype-genericity. Here, we take a sideways look at the datatype-generic\nversion of the problem in terms of monadic functional programming, instead of\nthe traditional relational approach; the presentation is tutorial in style, and\nleavened with exercises for the reader.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:00 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2011 15:37:23 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Gibbons", "Jeremy", "", "University of Oxford"]]}, {"id": "1109.0783", "submitter": "EPTCS", "authors": "Jerzy Karczmarczuk (University of Caen, France)", "title": "Specific \"scientific\" data structures, and their processing", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 195-209", "doi": "10.4204/EPTCS.66.10", "report-no": null, "categories": "cs.DS cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming physicists use, as all programmers, arrays, lists, tuples,\nrecords, etc., and this requires some change in their thought patterns while\nconverting their formulae into some code, since the \"data structures\" operated\nupon, while elaborating some theory and its consequences, are rather: power\nseries and Pad\\'e approximants, differential forms and other instances of\ndifferential algebras, functionals (for the variational calculus), trajectories\n(solutions of differential equations), Young diagrams and Feynman graphs, etc.\nSuch data is often used in a [semi-]numerical setting, not necessarily\n\"symbolic\", appropriate for the computer algebra packages. Modules adapted to\nsuch data may be \"just libraries\", but often they become specific, embedded\nsub-languages, typically mapped into object-oriented frameworks, with\noverloaded mathematical operations. Here we present a functional approach to\nthis philosophy. We show how the usage of Haskell datatypes and - fundamental\nfor our tutorial - the application of lazy evaluation makes it possible to\noperate upon such data (in particular: the \"infinite\" sequences) in a natural\nand comfortable manner.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:07 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Karczmarczuk", "Jerzy", "", "University of Caen, France"]]}, {"id": "1109.0784", "submitter": "EPTCS", "authors": "Oleg Kiselyov", "title": "Implementing Explicit and Finding Implicit Sharing in Embedded DSLs", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 210-225", "doi": "10.4204/EPTCS.66.11", "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aliasing, or sharing, is prominent in many domains, denoting that two\ndifferently-named objects are in fact identical: a change in one object (memory\ncell, circuit terminal, disk block) is instantly reflected in the other.\nLanguages for modelling such domains should let the programmer explicitly\ndefine the sharing among objects or expressions. A DSL compiler may find other\nidentical expressions and share them, implicitly. Such common subexpression\nelimination is crucial to the efficient implementation of DSLs. Sharing is\ntricky in embedded DSL, since host aliasing may correspond to copying of the\nunderlying objects rather than their sharing.\n  This tutorial summarizes discussions of implementing sharing in Haskell DSLs\nfor automotive embedded systems and hardware description languages. The\ntechnique has since been used in a Haskell SAT solver and the DSL for music\nsynthesis. We demonstrate the embedding in pure Haskell of a simple DSL with a\nlanguage form for explicit sharing. The DSL also has implicit sharing,\nimplemented via hash-consing. Explicit sharing greatly speeds up hash-consing.\nThe seemingly imperative nature of hash-consing is hidden beneath a simple\ncombinator language. The overall implementation remains pure functional and\neasy to reason about.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:14 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Kiselyov", "Oleg", ""]]}, {"id": "1109.1053", "submitter": "Jan Vondrak", "authors": "Shaddin Dughmi, Tim Roughgarden, Jan Vondrak and Qiqi Yan", "title": "An approximately truthful-in-expectation mechanism for combinatorial\n  auctions using value queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript presents an alternative implementation of the\ntruthful-in-expectation mechanism of Dughmi, Roughgarden and Yan for\ncombinatorial auctions with weighted-matroid-rank-sum valuations. The new\nimplementation uses only value queries and is approximately\ntruthful-in-expectation, in the sense that by reporting truthfully each agent\nmaximizes his utility within a multiplicative 1-o(1) factor. It still provides\nan optimal (1-1/e-o(1))-approximation in social welfare. We achieve this by\nfirst presenting an approximately maximal-in-distributional-range allocation\nrule and then showing a black-box transformation to an approximately\ntruthful-in-expectation mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 04:10:13 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Dughmi", "Shaddin", ""], ["Roughgarden", "Tim", ""], ["Vondrak", "Jan", ""], ["Yan", "Qiqi", ""]]}, {"id": "1109.1055", "submitter": "Jan Vondrak", "authors": "Shaddin Dughmi and Jan Vondrak", "title": "Limitations of randomized mechanisms for combinatorial auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a randomized mechanism has been discovered [Dughmi, Roughgarden and\nYan; STOC'11] for combinatorial auctions that is truthful in expectation and\nguarantees a (1-1/e)-approximation to the optimal social welfare when players\nhave coverage valuations. This approximation ratio is the best possible even\nfor non-truthful algorithms, assuming $P \\neq NP$. Given the recent sequence of\nnegative results for combinatorial auctions under more restrictive notions of\nincentive compatibility, this development raises a natural question: Are\ntruthful-in-expectation mechanisms compatible with polynomial-time\napproximation in a way that deterministic or universally truthful mechanisms\nare not? In particular, can polynomial-time truthful-in-expectation mechanisms\nguarantee a near-optimal approximation ratio for more general variants of\ncombinatorial auctions?\n  We prove that this is not the case. Specifically, the result of Dughmi,\nRoughgarden and Yan cannot be extended to combinatorial auctions with\nsubmodular valuations in the value oracle model. (Absent strategic\nconsiderations, a (1-1/e)-approximation is still achievable in this setting.)\nMore precisely, we prove that there is a constant \\gamma>0 such that there is\nno randomized mechanism that is truthful-in-expectation--- or even\napproximately truthful-in-expectation --- and guarantees an\nm^{-\\gamma}-approximation to the optimal social welfare for combinatorial\nauctions with submodular valuations in the value oracle model. We also prove an\nanalogous result for the flexible combinatorial public projects (CPP) problem.\nBoth our results present an unexpected separation between coverage functions\nand submodular functions, which does not occur for these problems without\nstrategic considerations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 04:22:10 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Dughmi", "Shaddin", ""], ["Vondrak", "Jan", ""]]}, {"id": "1109.1146", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Vaclav Hlavac", "title": "A Distributed Mincut/Maxflow Algorithm Combining Path Augmentation and\n  Push-Relabel", "comments": "40 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": "K333-43/11, CTU-CMP-2011-03", "categories": "cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel distributed algorithm for the minimum cut problem. We\nprimarily aim at solving large sparse problems. Assuming vertices of the graph\nare partitioned into several regions, the algorithm performs path augmentations\ninside the regions and updates of the push-relabel style between the regions.\nThe interaction between regions is considered expensive (regions are loaded\ninto the memory one-by-one or located on separate machines in a network). The\nalgorithm works in sweeps - passes over all regions. Let $B$ be the set of\nvertices incident to inter-region edges of the graph. We present a sequential\nand parallel versions of the algorithm which terminate in at most $2|B|^2+1$\nsweeps. The competing algorithm by Delong and Boykov uses push-relabel updates\ninside regions. In the case of a fixed partition we prove that this algorithm\nhas a tight $O(n^2)$ bound on the number of sweeps, where $n$ is the number of\nvertices. We tested sequential versions of the algorithms on instances of\nmaxflow problems in computer vision. Experimentally, the number of sweeps\nrequired by the new algorithm is much lower than for the Delong and Boykov's\nvariant. Large problems (up to $10^8$ vertices and $6\\cdot 10^8$ edges) are\nsolved using under 1GB of memory in about 10 sweeps.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 11:19:13 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Hlavac", "Vaclav", ""]]}, {"id": "1109.1152", "submitter": "Antoine Vigneron", "authors": "Herv\\'e Fournier and Antoine Vigneron", "title": "A deterministic algorithm for fitting a step function to a weighted\n  point-set", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of n points in the plane, each point having a positive weight,\nand an integer k>0, we present an optimal O(n \\log n)-time deterministic\nalgorithm to compute a step function with k steps that minimizes the maximum\nweighted vertical distance to the input points. It matches the expected time\nbound of the best known randomized algorithm for this problem. Our approach\nrelies on Cole's improved parametric searching technique.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 11:55:08 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 12:05:50 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Fournier", "Herv\u00e9", ""], ["Vigneron", "Antoine", ""]]}, {"id": "1109.1325", "submitter": "Edith Cohen", "authors": "Edith Cohen and Haim Kaplan", "title": "Get the Most out of Your Sample: Optimal Unbiased Estimators using\n  Partial Information", "comments": "This is a full version of a PODS 2011 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.NI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random sampling is an essential tool in the processing and transmission of\ndata. It is used to summarize data too large to store or manipulate and meet\nresource constraints on bandwidth or battery power. Estimators that are applied\nto the sample facilitate fast approximate processing of queries posed over the\noriginal data and the value of the sample hinges on the quality of these\nestimators.\n  Our work targets data sets such as request and traffic logs and sensor\nmeasurements, where data is repeatedly collected over multiple {\\em instances}:\ntime periods, locations, or snapshots.\n  We are interested in queries that span multiple instances, such as distinct\ncounts and distance measures over selected records. These queries are used for\napplications ranging from planning to anomaly and change detection.\n  Unbiased low-variance estimators are particularly effective as the relative\nerror decreases with the number of selected record keys.\n  The Horvitz-Thompson estimator, known to minimize variance for sampling with\n\"all or nothing\" outcomes (which reveals exacts value or no information on\nestimated quantity), is not optimal for multi-instance operations for which an\noutcome may provide partial information.\n  We present a general principled methodology for the derivation of (Pareto)\noptimal unbiased estimators over sampled instances and aim to understand its\npotential. We demonstrate significant improvement in estimate accuracy of\nfundamental queries for common sampling schemes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 23:42:06 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "1109.1465", "submitter": "Carsten Gutwenger", "authors": "Christian Bachmaier, Franz J. Brandenburg, Philip Effinger, Carsten\n  Gutwenger, Jyrki Katajainen, Karsten Klein, Miro Sp\\\"onemann, Matthias\n  Stegmaier, Michael Wybrow", "title": "The Open Graph Archive: A Community-Driven Effort", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to evaluate, compare, and tune graph algorithms, experiments on well\ndesigned benchmark sets have to be performed. Together with the goal of\nreproducibility of experimental results, this creates a demand for a public\narchive to gather and store graph instances. Such an archive would ideally\nallow annotation of instances or sets of graphs with additional information\nlike graph properties and references to the respective experiments and results.\nHere we examine the requirements, and introduce a new community project with\nthe aim of producing an easily accessible library of graphs. Through successful\ncommunity involvement, it is expected that the archive will contain a\nrepresentative selection of both real-world and generated graph instances,\ncovering significant application areas as well as interesting classes of\ngraphs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 14:17:43 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Bachmaier", "Christian", ""], ["Brandenburg", "Franz J.", ""], ["Effinger", "Philip", ""], ["Gutwenger", "Carsten", ""], ["Katajainen", "Jyrki", ""], ["Klein", "Karsten", ""], ["Sp\u00f6nemann", "Miro", ""], ["Stegmaier", "Matthias", ""], ["Wybrow", "Michael", ""]]}, {"id": "1109.1494", "submitter": "Markus Jalsenius", "authors": "Ayelet Butman, Peter Clifford, Raphael Clifford, Markus Jalsenius, Noa\n  Lewenstein, Benny Porat, Ely Porat, Benjamin Sach", "title": "Pattern Matching under Polynomial Transformation", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of pattern matching problems where a normalising\ntransformation is applied at every alignment. Normalised pattern matching plays\na key role in fields as diverse as image processing and musical information\nprocessing where application specific transformations are often applied to the\ninput. By considering the class of polynomial transformations of the input, we\nprovide fast algorithms and the first lower bounds for both new and old\nproblems. Given a pattern of length m and a longer text of length n where both\nare assumed to contain integer values only, we first show O(n log m) time\nalgorithms for pattern matching under linear transformations even when wildcard\nsymbols can occur in the input. We then show how to extend the technique to\npolynomial transformations of arbitrary degree. Next we consider the problem of\nfinding the minimum Hamming distance under polynomial transformation. We show\nthat, for any epsilon>0, there cannot exist an O(n m^(1-epsilon)) time\nalgorithm for additive and linear transformations conditional on the hardness\nof the classic 3SUM problem. Finally, we consider a version of the Hamming\ndistance problem under additive transformations with a bound k on the maximum\ndistance that need be reported. We give a deterministic O(nk log k) time\nsolution which we then improve by careful use of randomisation to O(n sqrt(k\nlog k) log n) time for sufficiently small k. Our randomised solution outputs\nthe correct answer at every position with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 15:46:51 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2011 11:13:43 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Butman", "Ayelet", ""], ["Clifford", "Peter", ""], ["Clifford", "Raphael", ""], ["Jalsenius", "Markus", ""], ["Lewenstein", "Noa", ""], ["Porat", "Benny", ""], ["Porat", "Ely", ""], ["Sach", "Benjamin", ""]]}, {"id": "1109.1579", "submitter": "Benjmain Moseley", "authors": "Alina Ene, Sungjin Im, Benjamin Moseley", "title": "Fast Clustering using MapReduce", "comments": "Accepted to KDD 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering problems have numerous applications and are becoming more\nchallenging as the size of the data increases. In this paper, we consider\ndesigning clustering algorithms that can be used in MapReduce, the most popular\nprogramming environment for processing large datasets. We focus on the\npractical and popular clustering problems, $k$-center and $k$-median. We\ndevelop fast clustering algorithms with constant factor approximation\nguarantees. From a theoretical perspective, we give the first analysis that\nshows several clustering algorithms are in $\\mathcal{MRC}^0$, a theoretical\nMapReduce class introduced by Karloff et al. \\cite{KarloffSV10}. Our algorithms\nuse sampling to decrease the data size and they run a time consuming clustering\nalgorithm such as local search or Lloyd's algorithm on the resulting data set.\nOur algorithms have sufficient flexibility to be used in practice since they\nrun in a constant number of MapReduce rounds. We complement these results by\nperforming experiments using our algorithms. We compare the empirical\nperformance of our algorithms to several sequential and parallel algorithms for\nthe $k$-median problem. The experiments show that our algorithms' solutions are\nsimilar to or better than the other algorithms' solutions. Furthermore, on data\nsets that are sufficiently large, our algorithms are faster than the other\nparallel algorithms that we tested.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 21:10:36 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Ene", "Alina", ""], ["Im", "Sungjin", ""], ["Moseley", "Benjamin", ""]]}, {"id": "1109.1693", "submitter": "Oded Schwartz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Oded Schwartz", "title": "Graph Expansion and Communication Costs of Fast Matrix Multiplication", "comments": null, "journal-ref": "Proceedings of the 23rd annual symposium on parallelism in\n  algorithms and architectures. ACM, 1-12. 2011 (a shorter conference version)", "doi": "10.1145/1989493.1989495", "report-no": "UCB/EECS-2011-40", "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication cost of algorithms (also known as I/O-complexity) is shown\nto be closely related to the expansion properties of the corresponding\ncomputation graphs. We demonstrate this on Strassen's and other fast matrix\nmultiplication algorithms, and obtain first lower bounds on their communication\ncosts.\n  In the sequential case, where the processor has a fast memory of size $M$,\ntoo small to store three $n$-by-$n$ matrices, the lower bound on the number of\nwords moved between fast and slow memory is, for many of the matrix\nmultiplication algorithms, $\\Omega((\\frac{n}{\\sqrt M})^{\\omega_0}\\cdot M)$,\nwhere $\\omega_0$ is the exponent in the arithmetic count (e.g., $\\omega_0 = \\lg\n7$ for Strassen, and $\\omega_0 = 3$ for conventional matrix multiplication).\nWith $p$ parallel processors, each with fast memory of size $M$, the lower\nbound is $p$ times smaller.\n  These bounds are attainable both for sequential and for parallel algorithms\nand hence optimal. These bounds can also be attained by many fast algorithms in\nlinear algebra (e.g., algorithms for LU, QR, and solving the Sylvester\nequation).\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 11:36:00 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Schwartz", "Oded", ""]]}, {"id": "1109.1729", "submitter": "Nan Wang", "authors": "Nan Wang and Jizhong Han and Jinyun Fang", "title": "Anomaly Sequences Detection from Logs Based on Compression", "comments": "7 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining information from logs is an old and still active research topic. In\nrecent years, with the rapid emerging of cloud computing, log mining becomes\nincreasingly important to industry. This paper focus on one major mission of\nlog mining: anomaly detection, and proposes a novel method for mining abnormal\nsequences from large logs. Different from previous anomaly detection systems\nwhich based on statistics, probabilities and Markov assumption, our approach\nmeasures the strangeness of a sequence using compression. It first trains a\ngrammar about normal behaviors using grammar-based compression, then measures\nthe information quantities and densities of questionable sequences according to\nincrementation of grammar length. We have applied our approach on mining some\nreal bugs from fine grained execution logs. We have also tested its ability on\nintrusion detection using some publicity available system call traces. The\nexperiments show that our method successfully selects the strange sequences\nwhich related to bugs or attacking.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 14:34:57 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Wang", "Nan", ""], ["Han", "Jizhong", ""], ["Fang", "Jinyun", ""]]}, {"id": "1109.1801", "submitter": "Ali Pinar", "authors": "Richard Chen, Amy Cohn, Ali Pinar", "title": "An Implicit Optimization Approach for Survivable Network Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing a network of minimum cost while\nsatisfying a prescribed survivability criterion. The survivability criterion\nrequires that a feasible flow must still exists (i.e. all demands can be\nsatisfied without violating arc capacities) even after the disruption of a\nsubset of the network's arcs. Specifically, we consider the case in which a\ndisruption (random or malicious) can destroy a subset of the arcs, with the\ncost of the disruption not to exceed a disruption budget. This problem takes\nthe form of a tri-level, two-player game, in which the network operator designs\n(or augments) the network, then the attacker launches a disruption that\ndestroys a subset of arcs, and then the network operator attempts to find a\nfeasible flow over the residual network. We first show how this can be modeled\nas a two-stage stochastic program from the network operator's perspective, with\neach of the exponential number of potential attacks considered as a disruption\nscenario. We then reformulate this problem, via a Benders decomposition, to\nconsider the recourse decisions implicitly, greatly reducing the number of\nvariables but at the expense of an exponential increase in the number of\nconstraints. We next develop a cut-generation based algorithm. Rather than\n\\emph{explicitly} considering each disruption scenario to identify these\nBenders cuts, however, we develop a bi-level program and corresponding\nseparation algorithm that enables us to \\emph{implicitly} evaluate the\nexponential set of disruption scenarios. Our computational results demonstrate\nthe efficacy of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 18:44:56 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Chen", "Richard", ""], ["Cohn", "Amy", ""], ["Pinar", "Ali", ""]]}, {"id": "1109.2158", "submitter": "Eric Berberich", "authors": "Eric Berberich, Dan Halperin, Michael Kerber, Roza Pogalnikova", "title": "Deconstructing Approximate Offsets", "comments": "18 pages, 11 figures, previous version accepted at SoCG 2011,\n  submitted to DCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the offset-deconstruction problem: Given a polygonal shape Q with\nn vertices, can it be expressed, up to a tolerance \\eps in Hausdorff distance,\nas the Minkowski sum of another polygonal shape P with a disk of fixed radius?\nIf it does, we also seek a preferably simple-looking solution P; then, P's\noffset constitutes an accurate, vertex-reduced, and smoothened approximation of\nQ. We give an O(n log n)-time exact decision algorithm that handles any\npolygonal shape, assuming the real-RAM model of computation. A variant of the\nalgorithm, which we have implemented using CGAL, is based on rational\narithmetic and answers the same deconstruction problem up to an uncertainty\nparameter \\delta; its running time additionally depends on \\delta. If the input\nshape is found to be approximable, this algorithm also computes an approximate\nsolution for the problem. It also allows us to solve parameter-optimization\nproblems induced by the offset-deconstruction problem. For convex shapes, the\ncomplexity of the exact decision algorithm drops to O(n), which is also the\ntime required to compute a solution P with at most one more vertex than a\nvertex-minimal one.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 20:53:39 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Berberich", "Eric", ""], ["Halperin", "Dan", ""], ["Kerber", "Michael", ""], ["Pogalnikova", "Roza", ""]]}, {"id": "1109.2176", "submitter": "Preyas Popat", "authors": "Subhash Khot, Preyas Popat, Nisheeth K. Vishnoi", "title": "$2^{\\log^{1-\\eps} n}$ Hardness for Closest Vector Problem with\n  Preprocessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for an arbitrarily small constant $\\eps>0,$ assuming NP$\\not\n\\subseteq$DTIME$(2^{{\\log^{O(1/\\eps)} n}})$, the preprocessing versions of the\nclosest vector problem and the nearest codeword problem are hard to approximate\nwithin a factor better than $2^{\\log ^{1-\\eps}n}.$ This improves upon the\nprevious hardness factor of $(\\log n)^\\delta$ for some $\\delta > 0$ due to\n\\cite{AKKV05}.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 00:00:21 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Khot", "Subhash", ""], ["Popat", "Preyas", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1109.2229", "submitter": "Aaron Roth", "authors": "Avrim Blum, Katrina Ligett, Aaron Roth", "title": "A Learning Theory Approach to Non-Interactive Database Privacy", "comments": "Full Version. Extended Abstract appeared in STOC 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate that, ignoring computational constraints, it is\npossible to privately release synthetic databases that are useful for large\nclasses of queries -- much larger in size than the database itself.\nSpecifically, we give a mechanism that privately releases synthetic data for a\nclass of queries over a discrete domain with error that grows as a function of\nthe size of the smallest net approximately representing the answers to that\nclass of queries. We show that this in particular implies a mechanism for\ncounting queries that gives error guarantees that grow only with the\nVC-dimension of the class of queries, which itself grows only logarithmically\nwith the size of the query class.\n  We also show that it is not possible to privately release even simple classes\nof queries (such as intervals and their generalizations) over continuous\ndomains. Despite this, we give a privacy-preserving polynomial time algorithm\nthat releases information useful for all halfspace queries, given a slight\nrelaxation of the utility guarantee. This algorithm does not release synthetic\ndata, but instead another data structure capable of representing an answer for\neach query. We also give an efficient algorithm for releasing synthetic data\nfor the class of interval queries and axis-aligned rectangles of constant\ndimension.\n  Finally, inspired by learning theory, we introduce a new notion of data\nprivacy, which we call distributional privacy, and show that it is strictly\nstronger than the prevailing privacy notion, differential privacy.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 15:23:14 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Blum", "Avrim", ""], ["Ligett", "Katrina", ""], ["Roth", "Aaron", ""]]}, {"id": "1109.2231", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Burle Sharma and Sasmita Tripathy", "title": "Characterization of Request Sequences for List Accessing Problem and New\n  Theoretical Results for MTF Algorithm", "comments": "06 pages, 1 figure", "journal-ref": "International Journal of Computer Applications, Volume 22-- No.8,\n  May 2011", "doi": "10.5120/2601-3627", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  List Accessing Problem is a well studied research problem in the context of\nlinear search. Input to the list accessing problem is an unsorted linear list\nof distinct elements along with a sequence of requests, where each request is\nan access operation on an element of the list. A list accessing algorithm\nreorganizes the list while processing a request sequence on the list in order\nto minimize the access cost. Move-To-Front algorithm has been proved to be the\nbest performing list accessing online algorithm till date in the literature.\nCharacterization of the input request sequences corresponding to practical real\nlife situations is a big challenge for the list accessing problem. As far as\nour knowledge is concerned, no characterization for the request sequences has\nbeen done in the literature till date for the list accessing problem. In this\npaper, we have characterized the request sequences for the list accessing\nproblem based on several factors such as size of the list, size of the request\nsequence, ordering of elements and frequency of occurrence of elements in the\nrequest sequence. We have made a comprehensive study of MTF list accessing\nalgorithm and obtained new theoretical results for our characterized special\nclass of request sequences. Our characterization will open up a new direction\nof research for empirical analysis of list accessing algorithms for real life\ninputs.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 15:37:28 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Sharma", "Burle", ""], ["Tripathy", "Sasmita", ""]]}, {"id": "1109.2232", "submitter": "Rakesh Mohanty", "authors": "Rakesh Mohanty, Seetaya Bhoi and Sasmita Tripathy", "title": "A New Proposed Cost Model for List Accessing Problem using Buffering", "comments": "05 Pages, 2 figures", "journal-ref": "International Journal of Computer Applications, Volume 22-- No.8,\n  May 2011", "doi": "10.5120/2604-3631", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many existing well known cost models for the list accessing\nproblem. The standard cost model developed by Sleator and Tarjan is most widely\nused. In this paper, we have made a comprehensive study of the existing cost\nmodels and proposed a new cost model for the list accessing problem. In our\nproposed cost model, for calculating the processing cost of request sequence\nusing a singly linked list, we consider the access cost, matching cost and\nreplacement cost. The cost of processing a request sequence is the sum of\naccess cost, matching cost and replacement cost. We have proposed a novel\nmethod for processing the request sequence which does not consider the\nrearrangement of the list and uses the concept of buffering, matching, look\nahead and flag bit.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 15:44:34 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Mohanty", "Rakesh", ""], ["Bhoi", "Seetaya", ""], ["Tripathy", "Sasmita", ""]]}, {"id": "1109.2304", "submitter": "Chris Russell", "authors": "Srikumar Ramalingam and Chris Russell and Lubor Ladicky and Philip\n  H.S. Torr", "title": "Efficient Minimization of Higher Order Submodular Functions using\n  Monotonic Boolean Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function minimization is a key problem in a wide variety of\napplications in machine learning, economics, game theory, computer vision, and\nmany others. The general solver has a complexity of $O(n^3 \\log^2 n . E +n^4\n{\\log}^{O(1)} n)$ where $E$ is the time required to evaluate the function and\n$n$ is the number of variables \\cite{Lee2015}. On the other hand, many computer\nvision and machine learning problems are defined over special subclasses of\nsubmodular functions that can be written as the sum of many submodular cost\nfunctions defined over cliques containing few variables. In such functions, the\npseudo-Boolean (or polynomial) representation \\cite{BorosH02} of these\nsubclasses are of degree (or order, or clique size) $k$ where $k \\ll n$. In\nthis work, we develop efficient algorithms for the minimization of this useful\nsubclass of submodular functions. To do this, we define novel mapping that\ntransform submodular functions of order $k$ into quadratic ones. The underlying\nidea is to use auxiliary variables to model the higher order terms and the\ntransformation is found using a carefully constructed linear program. In\nparticular, we model the auxiliary variables as monotonic Boolean functions,\nallowing us to obtain a compact transformation using as few auxiliary variables\nas possible.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 10:58:44 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 19:10:05 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Ramalingam", "Srikumar", ""], ["Russell", "Chris", ""], ["Ladicky", "Lubor", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1109.2348", "submitter": "Axel Eirola", "authors": "Axel Eirola", "title": "Lossless data compression on GPGPU architectures", "comments": "Aalto University special course on data compression course\n  assignment. (http://www.cs.hut.fi/~travis/compression/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern graphics processors provide exceptional computa- tional power, but\nonly for certain computational models. While they have revolutionized\ncomputation in many fields, compression has been largely unnaffected. This\npaper aims to explain the current issues and possibili- ties in GPGPU\ncompression. This is done by a high level overview of the GPGPU computational\nmodel in the context of compression algorithms; along with a more in-depth\nanalysis of how one would implement bzip2 on a GPGPU architecture.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 20:15:40 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Eirola", "Axel", ""]]}, {"id": "1109.2378", "submitter": "Daniel M\\\"ullner", "authors": "Daniel M\\\"ullner", "title": "Modern hierarchical, agglomerative clustering algorithms", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents algorithms for hierarchical, agglomerative clustering\nwhich perform most efficiently in the general-purpose setup that is given in\nmodern standard software. Requirements are: (1) the input data is given by\npairwise dissimilarities between data points, but extensions to vector data are\nalso discussed (2) the output is a \"stepwise dendrogram\", a data structure\nwhich is shared by all implementations in current standard software. We present\nalgorithms (old and new) which perform clustering in this setting efficiently,\nboth in an asymptotic worst-case analysis and from a practical point of view.\nThe main contributions of this paper are: (1) We present a new algorithm which\nis suitable for any distance update scheme and performs significantly better\nthan the existing algorithms. (2) We prove the correctness of two algorithms by\nRohlf and Murtagh, which is necessary in each case for different reasons. (3)\nWe give well-founded recommendations for the best current algorithms for the\nvarious agglomerative clustering schemes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 05:49:11 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["M\u00fcllner", "Daniel", ""]]}, {"id": "1109.2477", "submitter": "Daniel Dadush", "authors": "Daniel Dadush", "title": "A O(1/eps^2)^n Time Sieving Algorithm for Approximate Integer\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Integer Programming Problem (IP) for a polytope P \\subseteq R^n is to\nfind an integer point in P or decide that P is integer free. We give an\nalgorithm for an approximate version of this problem, which correctly decides\nwhether P contains an integer point or whether a (1+\\eps) scaling of P around\nits barycenter is integer free in time O(1/\\eps^2)^n. We reduce this\napproximate IP question to an approximate Closest Vector Problem (CVP) in a\n\"near-symmetric\" semi-norm, which we solve via a sieving technique first\ndeveloped by Ajtai, Kumar, and Sivakumar (STOC 2001). Our main technical\ncontribution is an extension of the AKS sieving technique which works for any\nnear-symmetric semi-norm. Our results also extend to general convex bodies and\nlattices.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 14:19:29 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2011 03:03:03 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Dadush", "Daniel", ""]]}, {"id": "1109.2641", "submitter": "Christian Sommer", "authors": "Christian Sommer", "title": "More Compact Oracles for Approximate Distances in Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance oracles are data structures that provide fast (possibly approximate)\nanswers to shortest-path and distance queries in graphs. The tradeoff between\nthe space requirements and the query time of distance oracles is of particular\ninterest and the main focus of this paper.\n  In FOCS'01, Thorup introduced approximate distance oracles for planar graphs.\nHe proved that, for any eps>0 and for any planar graph on n nodes, there exists\na (1+eps)-approximate distance oracle using space O(n eps^{-1} log n) such that\napproximate distance queries can be answered in time O(1/eps).\n  Ten years later, we give the first improvements on the space-querytime\ntradeoff for planar graphs.\n  * We give the first oracle having a space-time product with subquadratic\ndependency on 1/eps. For space ~O(n log n) we obtain query time ~O(1/eps)\n(assuming polynomial edge weights). The space shows a doubly logarithmic\ndependency on 1/eps only. We believe that the dependency on eps may be almost\noptimal.\n  * For the case of moderate edge weights (average bounded by polylog(n), which\nappears to be the case for many real-world road networks), we hit a \"sweet\nspot,\" improving upon Thorup's oracle both in terms of eps and n. Our oracle\nuses space ~O(n log log n) and it has query time ~O(log log log n + 1/eps).\n  (Asymptotic notation in this abstract hides low-degree polynomials in\nlog(1/eps) and log*(n).)\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 22:17:33 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2011 22:38:46 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Sommer", "Christian", ""]]}, {"id": "1109.2885", "submitter": "Rajeev Raman", "authors": "Mordecai J. Golin, John Iacono, Danny Krizanc, Rajeev Raman, S.\n  Srinivasa Rao, Sunil Shende", "title": "Encoding 2-D Range Maximum Queries", "comments": "Full version of ISAAC 2011 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the \\emph{two-dimensional range maximum query (2D-RMQ)} problem:\ngiven an array $A$ of ordered values, to pre-process it so that we can find the\nposition of the smallest element in the sub-matrix defined by a\n(user-specified) range of rows and range of columns. We focus on determining\nthe \\emph{effective} entropy of 2D-RMQ, i.e., how many bits are needed to\nencode $A$ so that 2D-RMQ queries can be answered \\emph{without} access to $A$.\nWe give tight upper and lower bounds on the expected effective entropy for the\ncase when $A$ contains independent identically-distributed random values, and\nnew upper and lower bounds for arbitrary $A$, for the case when $A$ contains\nfew rows. The latter results improve upon previous upper and lower bounds by\nBrodal et al. (ESA 2010). In some cases we also give data structures whose\nspace usage is close to the effective entropy and answer 2D-RMQ queries\nrapidly.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 19:04:03 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 16:58:51 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Golin", "Mordecai J.", ""], ["Iacono", "John", ""], ["Krizanc", "Danny", ""], ["Raman", "Rajeev", ""], ["Rao", "S. Srinivasa", ""], ["Shende", "Sunil", ""]]}, {"id": "1109.2930", "submitter": "Travis Gagie", "authors": "Travis Gagie and Pawe{\\l} Gawrychowski and Christopher Hoobin and\n  Simon J. Puglisi", "title": "Faster Approximate Pattern Matching in Compressed Repetitive Texts", "comments": "Journal version of ISAAC '11 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the imminent growth of massive, highly redundant genomic\ndatabases, we study the problem of compressing a string database while\nsimultaneously supporting fast random access, substring extraction and pattern\nmatching to the underlying string(s). Bille et al. (2011) recently showed how,\ngiven a straight-line program with $r$ rules for a string $s$ of length $n$, we\ncan build an $\\Oh{r}$-word data structure that allows us to extract any\nsubstring of length $m$ in $\\Oh{\\log n + m}$ time. They also showed how, given\na pattern $p$ of length $m$ and an edit distance (k \\leq m), their data\nstructure supports finding all \\occ approximate matches to $p$ in $s$ in $\\Oh{r\n(\\min (m k, k^4 + m) + \\log n) + \\occ}$ time. Rytter (2003) and Charikar et al.\n(2005) showed that $r$ is always at least the number $z$ of phrases in the LZ77\nparse of $s$, and gave algorithms for building straight-line programs with\n$\\Oh{z \\log n}$ rules. In this paper we give a simple $\\Oh{z \\log n}$-word data\nstructure that takes the same time for substring extraction but only $\\Oh{z\n\\min (m k, k^4 + m) + \\occ}$ time for approximate pattern matching.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 21:10:01 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2012 10:21:23 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2012 08:16:54 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2012 17:09:31 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Gagie", "Travis", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Hoobin", "Christopher", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1109.2998", "submitter": "Weng-Long Chang", "authors": "Weng-Long Chang, Mang Feng, Kawuu Weicheng Lin, Chih-Chiang Wang, and\n  Ju-Chin Chen", "title": "Quantum Algorithms of Solving the Backtracking of One-dimensional\n  Cellular Automata", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [Wolfram 1982; Wolfram 1983; Wolfram 2002], the backtracking of\none-dimensional cellular automata is to find out which of the 2n possible\ninitial configurations of width n evolve to a specific configuration. In this\npaper, in one-dimensional cellular automata for a specific configuration of\nwidth n, its unique initial configuration can be found by mean of the proposed\nquantum algorithm with polynomial quantum gates, polynomial quantum bits and\nthe successful probability that is the same as that of Shor's quantum\norder-finding algorithm in [Shor 1994].\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 05:54:57 GMT"}], "update_date": "2011-09-15", "authors_parsed": [["Chang", "Weng-Long", ""], ["Feng", "Mang", ""], ["Lin", "Kawuu Weicheng", ""], ["Wang", "Chih-Chiang", ""], ["Chen", "Ju-Chin", ""]]}, {"id": "1109.3056", "submitter": "Petr  Kuznetsov", "authors": "Carole Delporte-Gallet, Hugues Fauconnier, Eli Gafni, Petr Kuznetsov", "title": "Wait-Freedom with Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and propose a new way of thinking about failure detectors which\nallows us to define, quite surprisingly, what it means to solve a distributed\ntask \\emph{wait-free} \\emph{using a failure detector}. In our model, the system\nis composed of \\emph{computation} processes that obtain inputs and are supposed\nto output in a finite number of steps and \\emph{synchronization} processes that\nare subject to failures and can query a failure detector. We assume that, under\nthe condition that \\emph{correct} synchronization processes take sufficiently\nmany steps, they provide the computation processes with enough \\emph{advice} to\nsolve the given task wait-free: every computation process outputs in a finite\nnumber of its own steps, regardless of the behavior of other computation\nprocesses. Every task can thus be characterized by the \\emph{weakest} failure\ndetector that allows for solving it, and we show that every such failure\ndetector captures a form of set agreement. We then obtain a complete\nclassification of tasks, including ones that evaded comprehensible\ncharacterization so far, such as renaming or weak symmetry breaking.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 11:36:29 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 09:56:09 GMT"}, {"version": "v3", "created": "Sun, 13 May 2012 17:33:31 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Delporte-Gallet", "Carole", ""], ["Fauconnier", "Hugues", ""], ["Gafni", "Eli", ""], ["Kuznetsov", "Petr", ""]]}, {"id": "1109.3114", "submitter": "Shiri Chechik", "authors": "Shiri Chechik", "title": "Improved Distance Oracles and Spanners for Vertex-Labeled Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an undirected weighted graph G=(V,E) with |V|=n and |E|=m, where\neach vertex v is assigned a label from a set L of \\ell labels. We show how to\nconstruct a compact distance oracle that can answer queries of the form: \"what\nis the distance from v to the closest lambda-labeled node\" for a given node v\nin V and label lambda in L.\n  This problem was introduced by Hermelin, Levy, Weimann and Yuster [ICALP\n2011] where they present several results for this problem. In the first result,\nthey show how to construct a vertex-label distance oracle of expected size\nO(kn^{1+1/k}) with stretch (4k - 5) and query time O(k). In a second result,\nthey show how to reduce the size of the data structure to O(kn \\ell^{1/k}) at\nthe expense of a huge stretch, the stretch of this construction grows\nexponentially in k, (2^k-1). In the third result they present a dynamic\nvertex-label distance oracle that is capable of handling label changes in a\nsub-linear time. The stretch of this construction is also exponential in k, (2\n3^{k-1}+1).\n  We manage to significantly improve the stretch of their constructions,\nreducing the dependence on k from exponential to polynomial (4k-5), without\nrequiring any tradeoff regarding any of the other variables.\n  In addition, we introduce the notion of vertex-label spanners: subgraphs that\npreserve distances between every node v and label lambda. We present an\nefficient construction for vertex-label spanners with stretch-size tradeoff\nclose to optimal.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 15:45:40 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 14:45:54 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Chechik", "Shiri", ""]]}, {"id": "1109.3316", "submitter": "Kevin Verbeek", "authors": "Kevin Buchin, Bettina Speckmann, Kevin Verbeek", "title": "Angle-Restricted Steiner Arborescences for Flow Map Layout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variant of the geometric Steiner arborescence problem,\nmotivated by the layout of flow maps. Flow maps show the movement of objects\nbetween places. They reduce visual clutter by bundling lines smoothly and\navoiding self-intersections. To capture these properties, our angle-restricted\nSteiner arborescences, or flux trees, connect several targets to a source with\na tree of minimal length whose arcs obey a certain restriction on the angle\nthey form with the source.\n  We study the properties of optimal flux trees and show that they are planar\nand consist of logarithmic spirals and straight lines. Flux trees have the\nshallow-light property. We show that computing optimal flux trees is NP-hard.\nHence we consider a variant of flux trees which uses only logarithmic spirals.\nSpiral trees approximate flux trees within a factor depending on the angle\nrestriction. Computing optimal spiral trees remains NP-hard, but we present an\nefficient 2-approximation, which can be extended to avoid \"positive monotone\"\nobstacles.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 11:22:51 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Buchin", "Kevin", ""], ["Speckmann", "Bettina", ""], ["Verbeek", "Kevin", ""]]}, {"id": "1109.3401", "submitter": "\\\"Ozg\\\"ur  \\\"Ozkan", "authors": "Lisa Hellerstein, \\\"Ozg\\\"ur \\\"Ozkan, Linda Sellie", "title": "Max-Throughput for (Conservative) k-of-n Testing", "comments": "17 pages. An extended abstract of this paper appeared in the\n  Proceedings of the 22nd International Symposium on Algorithms and Computation\n  (ISAAC 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a variant of k-of-n testing that we call conservative k-of-n\ntesting. We present a polynomial-time, combinatorial algorithm for the problem\nof maximizing throughput of conservative k-of-n testing, in a parallel setting.\nThis extends previous work of Kodialam and Condon et al., who presented\ncombinatorial algorithms for parallel pipelined filter ordering, which is the\nspecial case where k=1 (or k = n). We also consider the problem of maximizing\nthroughput for standard k-of-n testing, and show how to obtain a\npolynomial-time algorithm based on the ellipsoid method using previous\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 16:58:28 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 02:38:45 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Hellerstein", "Lisa", ""], ["\u00d6zkan", "\u00d6zg\u00fcr", ""], ["Sellie", "Linda", ""]]}, {"id": "1109.3418", "submitter": "Huiwen Yu", "authors": "Martin Furer and Huiwen Yu", "title": "Packing-Based Approximation Algorithm for the k-Set Cover Problem", "comments": "26 pages, 5 figures", "journal-ref": "Proceedings 22nd International Symposium on Algorithms and\n  Computation (ISAAC 2011). Springer-Verlag LNCS 7074:484-493", "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a packing-based approximation algorithm for the $k$-Set Cover\nproblem. We introduce a new local search-based $k$-set packing heuristic, and\ncall it Restricted $k$-Set Packing. We analyze its tight approximation ratio\nvia a complicated combinatorial argument. Equipped with the Restricted $k$-Set\nPacking algorithm, our $k$-Set Cover algorithm is composed of the $k$-Set\nPacking heuristic \\cite{schrijver} for $k\\geq 7$, Restricted $k$-Set Packing\nfor $k=6,5,4$ and the semi-local $(2,1)$-improvement \\cite{furer} for 3-Set\nCover. We show that our algorithm obtains a tight approximation ratio of\n$H_k-0.6402+\\Theta(\\frac{1}{k})$, where $H_k$ is the $k$-th harmonic number.\nFor small $k$, our results are 1.8667 for $k=6$, 1.7333 for $k=5$ and 1.5208\nfor $k=4$. Our algorithm improves the currently best approximation ratio for\nthe $k$-Set Cover problem of any $k\\geq 4$.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 18:42:22 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Furer", "Martin", ""], ["Yu", "Huiwen", ""]]}, {"id": "1109.3544", "submitter": "Matthias Hellwig", "authors": "Matthias Hellwig and Alexander Souza", "title": "Approximation Algorithms for Variable-Sized and Generalized Bin Covering", "comments": "Improved Approximation Guarantee for Generalized Bin Covering and\n  added AFPTAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Generalized Bin Covering (GBC) problem: We are given $m$ bin\ntypes, where each bin of type $i$ has profit $p_i$ and demand $d_i$.\nFurthermore, there are $n$ items, where item $j$ has size $s_j$. A bin of type\n$i$ is covered if the set of items assigned to it has total size at least the\ndemand $d_i$. In that case, the profit of $p_i$ is earned and the objective is\nto maximize the total profit. To the best of our knowledge, only the cases $p_i\n= d_i = 1$ (Bin Covering) and $p_i = d_i$ (Variable-Sized Bin Covering (VSBC))\nhave been treated before. We study two models of bin supply: In the unit supply\nmodel, we have exactly one bin of each type, i.\\,e., we have individual bins.\nBy contrast, in the infinite supply model, we have arbitrarily many bins of\neach type. Clearly, the unit supply model is a generalization of the infinite\nsupply model. To the best of our knowledge the unit supply model has not been\nstudied yet.\n  Our results for the unit supply model hold not only asymptotically, but for\nall instances. This contrasts most of the previous work on \\prob{Bin Covering}.\nWe prove that there is a combinatorial 5-approximation algorithm for GBC with\nunit supply, which has running time $\\bigO{nm\\sqrt{m+n}}$. Furthermore, for\nVSBC we show that the natural and fast Next Fit Decreasing ($\\NFD$) algorithm\nis a 9/4-approximation in the unit supply model. The bound is tight for the\nalgorithm and close to being best-possible. We show that there is an AFPTAS for\nVSBC in the \\emph{infinite} supply model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 08:03:50 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2012 09:11:56 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Hellwig", "Matthias", ""], ["Souza", "Alexander", ""]]}, {"id": "1109.3843", "submitter": "Michael Mahoney", "authors": "Petros Drineas and Malik Magdon-Ismail and Michael W. Mahoney and\n  David P. Woodruff", "title": "Fast approximation of matrix coherence and statistical leverage", "comments": "29 pages; conference version is in ICML; journal version is in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical leverage scores of a matrix $A$ are the squared row-norms of\nthe matrix containing its (top) left singular vectors and the coherence is the\nlargest leverage score. These quantities are of interest in recently-popular\nproblems such as matrix completion and Nystr\\\"{o}m-based low-rank matrix\napproximation as well as in large-scale statistical data analysis applications\nmore generally; moreover, they are of interest since they define the key\nstructural nonuniformity that must be dealt with in developing fast randomized\nmatrix algorithms. Our main result is a randomized algorithm that takes as\ninput an arbitrary $n \\times d$ matrix $A$, with $n \\gg d$, and that returns as\noutput relative-error approximations to all $n$ of the statistical leverage\nscores. The proposed algorithm runs (under assumptions on the precise values of\n$n$ and $d$) in $O(n d \\log n)$ time, as opposed to the $O(nd^2)$ time required\nby the na\\\"{i}ve algorithm that involves computing an orthogonal basis for the\nrange of $A$. Our analysis may be viewed in terms of computing a relative-error\napproximation to an underconstrained least-squares approximation problem, or,\nrelatedly, it may be viewed as an application of Johnson-Lindenstrauss type\nideas. Several practically-important extensions of our basic result are also\ndescribed, including the approximation of so-called cross-leverage scores, the\nextension of these ideas to matrices with $n \\approx d$, and the extension to\nstreaming environments.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 04:38:12 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2012 00:13:53 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Drineas", "Petros", ""], ["Magdon-Ismail", "Malik", ""], ["Mahoney", "Michael W.", ""], ["Woodruff", "David P.", ""]]}, {"id": "1109.3890", "submitter": "Yakov Nekrich Yakov Nekrich", "authors": "Yakov Nekrich", "title": "A Dynamic Stabbing-Max Data Structure with Sub-Logarithmic Query Time", "comments": "Extended version of a paper accepted to ISAAC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a dynamic data structure that answers\none-dimensional stabbing-max queries in optimal $O(\\log n/\\log\\log n)$ time.\nOur data structure uses linear space and supports insertions and deletions in\n$O(\\log n)$ and $O(\\log n/\\log \\log n)$ amortized time respectively.\n  We also describe a $O(n(\\log n/\\log\\log n)^{d-1})$ space data structure that\nanswers $d$-dimensional stabbing-max queries in $O((\\log n/\\log\\log n)^{d})$\ntime. Insertions and deletions are supported in $O((\\log n/\\log\\log\nn)^d\\log\\log n)$ and $O((\\log n/\\log\\log n)^d)$ amortized time respectively.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 17:17:01 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Nekrich", "Yakov", ""]]}, {"id": "1109.3893", "submitter": "Laszlo Vegh", "authors": "Laszlo A. Vegh", "title": "Concave Generalized Flows with Applications to Market Equilibria", "comments": "Major revision. Instead of highest gain augmenting paths, we employ\n  the Fat-Path framework. Many parts simplified, running time for the linear\n  case improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.GT q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a nonlinear extension of the generalized network flow model, with\nthe flow leaving an arc being an increasing concave function of the flow\nentering it, as proposed by Truemper and Shigeno. We give a polynomial time\ncombinatorial algorithm for solving corresponding flow maximization problems,\nfinding an epsilon-approximate solution in O(m(m+log n)log(MUm/epsilon))\narithmetic operations and value oracle queries, where M and U are upper bounds\non simple parameters. This also gives a new algorithm for linear generalized\nflows, an efficient, purely scaling variant of the Fat-Path algorithm by\nGoldberg, Plotkin and Tardos, not using any cycle cancellations.\n  We show that this general convex programming model serves as a common\nframework for several market equilibrium problems, including the linear Fisher\nmarket model and its various extensions. Our result immediately extends these\nmarket models to more general settings. We also obtain a combinatorial\nalgorithm for nonsymmetric Arrow-Debreu Nash bargaining, settling an open\nquestion by Vazirani.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 17:50:26 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2011 20:07:22 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2012 00:18:17 GMT"}], "update_date": "2012-04-06", "authors_parsed": [["Vegh", "Laszlo A.", ""]]}, {"id": "1109.3934", "submitter": "Ton Kloks", "authors": "Ton Kloks and Yue-Li Wang", "title": "A linear-time algorithm for the strong chromatic index of Halin graphs", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there exists a linear-time algorithm that computes the strong\nchromatic index of Halin graphs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 03:14:22 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Kloks", "Ton", ""], ["Wang", "Yue-Li", ""]]}, {"id": "1109.3954", "submitter": "Travis Gagie", "authors": "Travis Gagie and Pawe{\\l} Gawrychowski and Juha K\\\"arkk\\\"ainen and\n  Yakov Nekrich and Simon J. Puglisi", "title": "A Faster Grammar-Based Self-Index", "comments": "journal version of LATA '12 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To store and search genomic databases efficiently, researchers have recently\nstarted building compressed self-indexes based on grammars. In this paper we\nshow how, given a straight-line program with $r$ rules for a string (S [1..n])\nwhose LZ77 parse consists of $z$ phrases, we can store a self-index for $S$ in\n$\\Oh{r + z \\log \\log n}$ space such that, given a pattern (P [1..m]), we can\nlist the $\\occ$ occurrences of $P$ in $S$ in $\\Oh{m^2 + \\occ \\log \\log n}$\ntime. If the straight-line program is balanced and we accept a small\nprobability of building a faulty index, then we can reduce the $\\Oh{m^2}$ term\nto $\\Oh{m \\log m}$. All previous self-indexes are larger or slower in the worst\ncase.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 07:10:06 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2011 07:04:30 GMT"}, {"version": "v3", "created": "Thu, 15 Dec 2011 05:49:32 GMT"}, {"version": "v4", "created": "Sun, 17 Jun 2012 09:11:52 GMT"}, {"version": "v5", "created": "Sun, 9 Sep 2012 08:10:34 GMT"}, {"version": "v6", "created": "Wed, 26 Sep 2012 20:34:19 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Gagie", "Travis", ""], ["Gawrychowski", "Pawe\u0142", ""], ["K\u00e4rkk\u00e4inen", "Juha", ""], ["Nekrich", "Yakov", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1109.3987", "submitter": "Damianos Gavalas", "authors": "Damianos Gavalas, Grammati Pantziou, Charalampos Konstantopoulos,\n  Basilis Mamalis", "title": "Clustering of Mobile Ad Hoc Networks: An Adaptive Broadcast Period\n  Approach", "comments": "7 pages, 9 figures; IEEE International Conference on Communications,\n  2006. ICC '06", "journal-ref": null, "doi": "10.1109/ICC.2006.255712", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organization, scalability and routing have been identified as key problems\nhindering viability and commercial success of mobile ad hoc networks.\nClustering of mobile nodes among separate domains has been proposed as an\nefficient approach to address those issues. In this work, we introduce an\nefficient distributed clustering algorithm that uses both location and energy\nmetrics for cluster formation. Our proposed solution mainly addresses cluster\nstability, manageability and energy efficiency issues. Also, unlike existing\nactive clustering methods, our algorithm relieves the network from the\nunnecessary burden of control messages broadcasting, especially for relatively\nstatic network topologies. This is achieved through adapting broadcast period\naccording to mobile nodes mobility pattern. The efficiency, scalability and\ncompetence of our algorithm against alternative approaches have been\ndemonstrated through simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 10:14:29 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Gavalas", "Damianos", ""], ["Pantziou", "Grammati", ""], ["Konstantopoulos", "Charalampos", ""], ["Mamalis", "Basilis", ""]]}, {"id": "1109.4034", "submitter": "Pawel Gawrychowski", "authors": "Pawel Gawrychowski", "title": "Tying up the loose ends in fully LZW-compressed pattern matching", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a natural generalization of the classical pattern matching\nproblem: given compressed representations of a pattern p[1..M] and a text\nt[1..N] of sizes m and n, respectively, does p occur in t? We develop an\noptimal linear time solution for the case when both p and t are compressed\nusing the LZW method. This improves the previously known O((n+m)log(n+m)) time\nsolution of Gasieniec and Rytter, and essentially closes the line of research\ndevoted to studying LZW-compressed exact pattern matching.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 14:20:02 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Gawrychowski", "Pawel", ""]]}, {"id": "1109.4114", "submitter": "Ramesh Sitaraman", "authors": "Konstantin Andreev, Bruce M. Maggs, Adam Meyerson, Jevan Saks, Ramesh\n  K. Sitaraman", "title": "Algorithms for Constructing Overlay Networks For Live Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial time approximation algorithm for constructing an\noverlay multicast network for streaming live media events over the Internet.\nThe class of overlay networks constructed by our algorithm include networks\nused by Akamai Technologies to deliver live media events to a global audience\nwith high fidelity. We construct networks consisting of three stages of nodes.\nThe nodes in the first stage are the entry points that act as sources for the\nlive streams. Each source forwards each of its streams to one or more nodes in\nthe second stage that are called reflectors. A reflector can split an incoming\nstream into multiple identical outgoing streams, which are then sent on to\nnodes in the third and final stage that act as sinks and are located in edge\nnetworks near end-users. As the packets in a stream travel from one stage to\nthe next, some of them may be lost. A sink combines the packets from multiple\ninstances of the same stream (by reordering packets and discarding duplicates)\nto form a single instance of the stream with minimal loss. Our primary\ncontribution is an algorithm that constructs an overlay network that provably\nsatisfies capacity and reliability constraints to within a constant factor of\noptimal, and minimizes cost to within a logarithmic factor of optimal. Further\nin the common case where only the transmission costs are minimized, we show\nthat our algorithm produces a solution that has cost within a factor of 2 of\noptimal. We also implement our algorithm and evaluate it on realistic traces\nderived from Akamai's live streaming network. Our empirical results show that\nour algorithm can be used to efficiently construct large-scale overlay networks\nin practice with near-optimal cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 18:27:18 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Andreev", "Konstantin", ""], ["Maggs", "Bruce M.", ""], ["Meyerson", "Adam", ""], ["Saks", "Jevan", ""], ["Sitaraman", "Ramesh K.", ""]]}, {"id": "1109.4373", "submitter": "Miguel Mosteiro", "authors": "Paulo S. Almeida, Carlos Baquero, Martin Farach-Colton, Paulo Jesus,\n  and Miguel A. Mosteiro", "title": "Fault-Tolerant Aggregation: Flow-Updating Meets Mass-Distribution", "comments": "18 pages, 5 figures, To appear in OPODIS 2011", "journal-ref": null, "doi": "10.1007/978-3-642-25873-2_35", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-Updating (FU) is a fault-tolerant technique that has proved to be\nefficient in practice for the distributed computation of aggregate functions in\ncommunication networks where individual processors do not have access to global\ninformation. Previous distributed aggregation protocols, based on repeated\nsharing of input values (or mass) among processors, sometimes called\nMass-Distribution (MD) protocols, are not resilient to communication failures\n(or message loss) because such failures yield a loss of mass. In this paper, we\npresent a protocol which we call Mass-Distribution with Flow-Updating (MDFU).\nWe obtain MDFU by applying FU techniques to classic MD. We analyze the\nconvergence time of MDFU showing that stochastic message loss produces low\noverhead. This is the first convergence proof of an FU-based algorithm. We\nevaluate MDFU experimentally, comparing it with previous MD and FU protocols,\nand verifying the behavior predicted by the analysis. Finally, given that MDFU\nincurs a fixed deviation proportional to the message-loss rate, we adjust the\naccuracy of MDFU heuristically in a new protocol called MDFU with Linear\nPrediction (MDFU-LP). The evaluation shows that both MDFU and MDFU-LP behave\nvery well in practice, even under high rates of message loss and even changing\nthe input values dynamically.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 17:30:49 GMT"}], "update_date": "2012-11-16", "authors_parsed": [["Almeida", "Paulo S.", ""], ["Baquero", "Carlos", ""], ["Farach-Colton", "Martin", ""], ["Jesus", "Paulo", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1109.4460", "submitter": "Stephane Durocher", "authors": "Stephane Durocher", "title": "A Simple Linear-Space Data Structure for Constant-Time Range Minimum\n  Query", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the range minimum query problem and present a new O(n)-space data\nstructure that supports queries in O(1) time. Although previous data structures\nexist whose asymptotic bounds match ours, our goal is to introduce a new\nsolution that is simple, intuitive, and practical without increasing costs for\nquery time or space.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 02:12:27 GMT"}], "update_date": "2011-09-22", "authors_parsed": [["Durocher", "Stephane", ""]]}, {"id": "1109.4590", "submitter": "Zoltan Toroczkai", "authors": "H. Kim, C.I. Del Genio, K.E. Bassler and Z. Toroczkai", "title": "Constructing and sampling directed graphs with given degree sequences", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": "10.1088/1367-2630/14/2/023012", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactions between the components of complex networks are often\ndirected. Proper modeling of such systems frequently requires the construction\nof ensembles of digraphs with a given sequence of in- and out-degrees. As the\nnumber of simple labeled graphs with a given degree sequence is typically very\nlarge even for short sequences, sampling methods are needed for statistical\nstudies. Currently, there are two main classes of methods that generate\nsamples. One of the existing methods first generates a restricted class of\ngraphs, then uses a Markov Chain Monte-Carlo algorithm based on edge swaps to\ngenerate other realizations. As the mixing time of this process is still\nunknown, the independence of the samples is not well controlled. The other\nclass of methods is based on the Configuration Model that may lead to\nunacceptably many sample rejections due to self-loops and multiple edges. Here\nwe present an algorithm that can directly construct all possible realizations\nof a given bi-degree sequence by simple digraphs. Our method is rejection free,\nguarantees the independence of the constructed samples, and provides their\nweight. The weights can then be used to compute statistical averages of network\nobservables as if they were obtained from uniformly distributed sampling, or\nfrom any other chosen distribution.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 17:08:51 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Kim", "H.", ""], ["Del Genio", "C. I.", ""], ["Bassler", "K. E.", ""], ["Toroczkai", "Z.", ""]]}, {"id": "1109.4680", "submitter": "Sebastiano Vigna", "authors": "Paolo Boldi, Sebastiano Vigna", "title": "The Push Algorithm for Spectral Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The push algorithm was proposed first by Jeh and Widom in the context of\npersonalized PageRank computations (albeit the name \"push algorithm\" was\nactually used by Andersen, Chung and Lang in a subsequent paper). In this note\nwe describe the algorithm at a level of generality that make the computation of\nthe spectral ranking of any nonnegative matrix possible. Actually, the main\ncontribution of this note is that the description is very simple (almost\ntrivial), and it requires only a few elementary linear-algebra computations.\nAlong the way, we give new precise ways of estimating the convergence of the\nalgorithm, and describe some of the contribution of the existing literature,\nwhich again turn out to be immediate when recast in our framework.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 00:42:48 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Boldi", "Paolo", ""], ["Vigna", "Sebastiano", ""]]}, {"id": "1109.4729", "submitter": "Erik Jan van Leeuwen", "authors": "Marek Cygan and Fedor V. Fomin and Erik Jan van Leeuwen", "title": "Parameterized Complexity of Firefighting Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Firefighter problem is to place firefighters on the vertices of a graph\nto prevent a fire with known starting point from lighting up the entire graph.\nIn each time step, a firefighter may be permanently placed on an unburned\nvertex and the fire spreads to its neighborhood in the graph in so far no\nfirefighters are protecting those vertices. The goal is to let as few vertices\nburn as possible. This problem is known to be NP-complete, even when restricted\nto bipartite graphs or to trees of maximum degree three. Initial study showed\nthe Firefighter problem to be fixed-parameter tractable on trees in various\nparameterizations. We complete these results by showing that the problem is in\nFPT on general graphs when parameterized by the number of burned vertices, but\nhas no polynomial kernel on trees, resolving an open problem. Conversely, we\nshow that the problem is W[1]-hard when parameterized by the number of unburned\nvertices, even on bipartite graphs. For both parameterizations, we additionally\ngive refined algorithms on trees, improving on the running times of the known\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 08:41:54 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Cygan", "Marek", ""], ["Fomin", "Fedor V.", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "1109.4910", "submitter": "Per Austrin", "authors": "Per Austrin, Toniann Pitassi, Yu Wu", "title": "Inapproximability of Treewidth, One-Shot Pebbling, and Related Layout\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of a number of graph problems: treewidth and\npathwidth of graphs, one-shot black (and black-white) pebbling costs of\ndirected acyclic graphs, and a variety of different graph layout problems such\nas minimum cut linear arrangement and interval graph completion. We show that,\nassuming the recently introduced Small Set Expansion Conjecture, all of these\nproblems are hard to approximate within any constant factor.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 18:43:46 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Austrin", "Per", ""], ["Pitassi", "Toniann", ""], ["Wu", "Yu", ""]]}, {"id": "1109.4919", "submitter": "Leo Lahti", "authors": "Leo Lahti", "title": "A brief overview on the BioPAX and SBML standards for formal\n  presentation of complex biological knowledge", "comments": "14 pages, 2 figures, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.MN", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A brief informal overview on the BioPAX and SBML standards for formal\npresentation of complex biological knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 19:15:57 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Lahti", "Leo", ""]]}, {"id": "1109.5002", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis, Sebastien Roch", "title": "Alignment-free phylogenetic reconstruction: Sample complexity via a\n  branching process analysis", "comments": "Published in at http://dx.doi.org/10.1214/12-AAP852 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 2, 693-721", "doi": "10.1214/12-AAP852", "report-no": "IMS-AAP-AAP852", "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient phylogenetic reconstruction algorithm allowing\ninsertions and deletions which provably achieves a sequence-length requirement\n(or sample complexity) growing polynomially in the number of taxa. Our\nalgorithm is distance-based, that is, it relies on pairwise sequence\ncomparisons. More importantly, our approach largely bypasses the difficult\nproblem of multiple sequence alignment.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 05:38:55 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 12:10:49 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Roch", "Sebastien", ""]]}, {"id": "1109.5018", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Monika Henzinger", "title": "An O(n^2) Time Algorithm for Alternating B\\\"uchi Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the winning set for B{\\\"u}chi objectives in alternating games on\ngraphs is a central problem in computer aided verification with a large number\nof applications. The long standing best known upper bound for solving the\nproblem is $\\tilde{O}(n \\cdot m)$, where $n$ is the number of vertices and $m$\nis the number of edges in the graph. We are the first to break the\n$\\tilde{O}(n\\cdot m)$ bound by presenting a new technique that reduces the\nrunning time to $O(n^2)$. This bound also leads to an $O(n^2)$ algorithm time\nfor computing the set of almost-sure winning vertices in alternating games with\nprobabilistic transitions (improving an earlier bound of $\\tilde{O}(n\\cdot m)$)\nand in concurrent graph games with constant actions (improving an earlier bound\nof $O(n^3)$). We also show that the same technique can be used to compute the\nmaximal end-component decomposition of a graph in time $O(n^2)$. Finally, we\nshow how to maintain the winning set for B{\\\"u}chi objectives in alternating\ngames under a sequence of edge insertions or a sequence of edge deletions in\nO(n) amortized time per operation. This is the first dynamic algorithm for this\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 08:45:53 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Monika", ""]]}, {"id": "1109.5036", "submitter": "Daniel Kral", "authors": "Zdenek Dvorak and Daniel Kral and Robin Thomas", "title": "Testing first-order properties for subclasses of sparse graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 11:30:05 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2013 17:18:57 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dvorak", "Zdenek", ""], ["Kral", "Daniel", ""], ["Thomas", "Robin", ""]]}, {"id": "1109.5135", "submitter": "Frederic Magniez", "authors": "Troy Lee and Frederic Magniez and Miklos Santha", "title": "A learning graph based quantum query algorithm for finding constant-size\n  subgraphs", "comments": "The analysis has been refined and a second algorithm included", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $H$ be a fixed $k$-vertex graph with $m$ edges and minimum degree $d >0$.\nWe use the learning graph framework of Belovs to show that the bounded-error\nquantum query complexity of determining if an $n$-vertex graph contains $H$ as\na subgraph is $O(n^{2-2/k-t})$, where $ t = \\max{\\frac{k^2-\n2(m+1)}{k(k+1)(m+1)}, \\frac{2k - d - 3}{k(d+1)(m-d+2)}}$. The previous best\nalgorithm of Magniez et al. had complexity $\\widetilde O(n^{2-2/k})$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 17:27:24 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2011 18:47:16 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2012 08:14:03 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Lee", "Troy", ""], ["Magniez", "Frederic", ""], ["Santha", "Miklos", ""]]}, {"id": "1109.5242", "submitter": "Mark Jerrum", "authors": "Leslie Ann Goldberg, Mark Jerrum", "title": "A Counterexample to rapid mixing of the Ge-Stefankovic Process", "comments": null, "journal-ref": "Electronic Communications in Probability, 17 (2012) no. 5, 1-6", "doi": "10.1214/ECP.v17-1712", "report-no": null, "categories": "math.PR cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ge and Stefankovic have recently introduced a novel two-variable graph\npolynomial. When specialised to a bipartite graphs G and evaluated at the point\n(1/2,1) this polynomial gives the number of independent sets in the graph.\nInspired by this polynomial, they also introduced a Markov chain which, if\nrapidly mixing, would provide an efficient sampling procedure for independent\nsets in G. This sampling procedure in turn would imply the existence of\nefficient approximation algorithms for a number of significant counting\nproblems whose complexity is so far unresolved. The proposed Markov chain is\npromising, in the sense that it overcomes the most obvious barrier to mixing.\nHowever, we show here, by exhibiting a sequence of counterexamples, that the\nmixing time of their Markov chain is exponential in the size of the input when\nthe input is chosen from a particular infinite family of bipartite graphs.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2011 08:14:24 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1109.5269", "submitter": "Markus Jalsenius", "authors": "Markus Jalsenius, Benny Porat, Benjamin Sach", "title": "Parameterized Matching in the Streaming Model", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of parameterized matching in a stream where we want to\noutput matches between a pattern of length m and the last m symbols of the\nstream before the next symbol arrives. Parameterized matching is a natural\ngeneralisation of exact matching where an arbitrary one-to-one relabelling of\npattern symbols is allowed. We show how this problem can be solved in constant\ntime per arriving stream symbol and sublinear, near optimal space with high\nprobability. Our results are surprising and important: it has been shown that\nalmost no streaming pattern matching problems can be solved (not even\nrandomised) in less than Theta(m) space, with exact matching as the only known\nproblem to have a sublinear, near optimal space solution. Here we demonstrate\nthat a similar sublinear, near optimal space solution is achievable for an even\nmore challenging problem. The proof is considerably more complex than that for\nexact matching.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2011 14:08:31 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 20:17:10 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2012 16:05:57 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Jalsenius", "Markus", ""], ["Porat", "Benny", ""], ["Sach", "Benjamin", ""]]}, {"id": "1109.5325", "submitter": "Dimitris Fotakis", "authors": "Dimitris Fotakis and Paraschos Koutris", "title": "Online Sum-Radii Clustering", "comments": "Supported by the project AlgoNow, co-financed by the European Union\n  (European Social Fund - ESF) and Greek national funds, through the\n  Operational Program \"Education and Lifelong Learning\", under the research\n  funding program THALES. An extended abstract of this work appeared in the\n  Proc. of MFCS 2012, B. Rovan, V. Sassone, and P. Widmayer (Editors), LNCS\n  7464, pp. 395-406, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Online Sum-Radii Clustering, n demand points arrive online and must be\nirrevocably assigned to a cluster upon arrival. The cost of each cluster is the\nsum of a fixed opening cost and its radius, and the objective is to minimize\nthe total cost of the clusters opened by the algorithm. We show that the\ndeterministic competitive ratio of Online Sum-Radii Clustering for general\nmetric spaces is \\Theta(\\log n), where the upper bound follows from a\nprimal-dual algorithm and holds for general metric spaces, and the lower bound\nis valid for ternary Hierarchically Well-Separated Trees (HSTs) and for the\nEuclidean plane. Combined with the results of (Csirik et al., MFCS 2010), this\nresult demonstrates that the deterministic competitive ratio of Online\nSum-Radii Clustering changes abruptly, from constant to logarithmic, when we\nmove from the line to the plane. We also show that Online Sum-Radii Clustering\nin metric spaces induced by HSTs is closely related to the Parking Permit\nproblem introduced by (Meyerson, FOCS 2005). Exploiting the relation to Parking\nPermit, we obtain a lower bound of \\Omega(\\log\\log n) on the randomized\ncompetitive ratio of Online Sum-Radii Clustering in tree metrics. Moreover, we\npresent a simple randomized O(\\log n)-competitive algorithm, and a\ndeterministic O(\\log\\log n)-competitive algorithm for the fractional version of\nthe problem.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2011 06:08:37 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 12:24:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Koutris", "Paraschos", ""]]}, {"id": "1109.5423", "submitter": "Frederick Matsen IV", "authors": "Frederick A. Matsen and Aaron Gallagher", "title": "Reconciling taxonomy and phylogenetic inference: formalism and\n  algorithms for describing discord and inferring taxonomic roots", "comments": "Version submitted to Algorithms for Molecular Biology. A number of\n  fixes from previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although taxonomy is often used informally to evaluate the results of\nphylogenetic inference and find the root of phylogenetic trees, algorithmic\nmethods to do so are lacking. In this paper we formalize these procedures and\ndevelop algorithms to solve the relevant problems. In particular, we introduce\na new algorithm that solves a \"subcoloring\" problem for expressing the\ndifference between the taxonomy and phylogeny at a given rank. This algorithm\nimproves upon the current best algorithm in terms of asymptotic complexity for\nthe parameter regime of interest; we also describe a branch-and-bound algorithm\nthat saves orders of magnitude in computation on real data sets. We also\ndevelop a formalism and an algorithm for rooting phylogenetic trees according\nto a taxonomy. All of these algorithms are implemented in freely-available\nsoftware.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 01:00:52 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2011 22:54:31 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Matsen", "Frederick A.", ""], ["Gallagher", "Aaron", ""]]}, {"id": "1109.5579", "submitter": "Nicolas Curien", "authors": "Nicolas Curien", "title": "Strong convergence of partial match queries in random quadtrees", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the rescaled costs of partial match queries in a random\ntwo-dimensional quadtree converge almost surely towards a random limit which is\nidentified as the terminal value of a martingale. Our approach shares many\nsimilarities with the theory of self-similar fragmentations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 14:10:09 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Curien", "Nicolas", ""]]}, {"id": "1109.5615", "submitter": "Praveen Manjunatha", "authors": "M. Praveen", "title": "A Regularity Measure for Context Free Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parikh's theorem states that every Context Free Language (CFL) has the same\nParikh image as that of a regular language. A finite state automaton accepting\nsuch a regular language is called a Parikh-equivalent automaton. In the worst\ncase, the number of states in any non-deterministic Parikh-equivalent automaton\nis exponentially large in the size of the Context Free Grammar (CFG). We\nassociate a regularity width d with a CFG that measures the closeness of the\nCFL with regular languages. The degree m of a CFG is one less than the maximum\nnumber of variable occurrences in the right hand side of any production. Given\na CFG with n variables, we construct a Parikh-equivalent non-deterministic\nautomaton whose number of states is upper bounded by a polynomial in $n\n(d^{2d(m+1)}), the degree of the polynomial being a small fixed constant. Our\nprocedure is constructive and runs in time polynomial in the size of the\nautomaton. In the terminology of parameterized complexity, we prove that\nconstructing a Parikh-equivalent automaton for a given CFG is Fixed Parameter\nTractable (FPT) when the degree m and regularity width d are parameters. We\nalso give an example from program verification domain where the degree and\nregularity are small compared to the size of the grammar.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 15:43:45 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Praveen", "M.", ""]]}, {"id": "1109.5635", "submitter": "Krzysztof Onak", "authors": "Alexandr Andoni and Krzysztof Onak", "title": "Approximating Edit Distance in Near-Linear Time", "comments": "Preliminary version appeared in STOC 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to compute the edit distance between two strings of length n up\nto a factor of 2^{\\~O(sqrt(log n))} in n^(1+o(1)) time. This is the first\nsub-polynomial approximation algorithm for this problem that runs in\nnear-linear time, improving on the state-of-the-art n^(1/3+o(1)) approximation.\nPreviously, approximation of 2^{\\~O(sqrt(log n))} was known only for embedding\nedit distance into l_1, and it is not known if that embedding can be computed\nin less than quadratic time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 16:48:20 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Andoni", "Alexandr", ""], ["Onak", "Krzysztof", ""]]}, {"id": "1109.5664", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis, Malik Magdon-Ismail", "title": "Deterministic Feature Selection for $k$-means Clustering", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2013.2255021", "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study feature selection for $k$-means clustering. Although the literature\ncontains many methods with good empirical performance, algorithms with provable\ntheoretical behavior have only recently been developed. Unfortunately, these\nalgorithms are randomized and fail with, say, a constant probability. We\naddress this issue by presenting a deterministic feature selection algorithm\nfor k-means with theoretical guarantees. At the heart of our algorithm lies a\ndeterministic method for decompositions of the identity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 18:44:00 GMT"}, {"version": "v2", "created": "Sun, 1 Jan 2012 19:03:07 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2013 02:30:59 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2013 20:52:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Boutsidis", "Christos", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1109.5720", "submitter": "Jierui Xie", "authors": "Jierui Xie and Boleslaw K. Szymanski and Xiaoming Liu", "title": "SLPA: Uncovering Overlapping Communities in Social Networks via A\n  Speaker-listener Interaction Dynamic Process", "comments": "IEEE ICDM 2011 Workshop on DMCCI xiej2@rpi.edu", "journal-ref": "Proc. Data Mining Technologies for Computational Collective\n  Intelligence Workshop at ICDM, Vancouver, CA, 2011, pp. 344-349", "doi": null, "report-no": null, "categories": "cs.SI cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap is one of the characteristics of social networks, in which a person\nmay belong to more than one social group. For this reason, discovering\noverlapping structures is necessary for realistic social analysis. In this\npaper, we present a novel, general framework to detect and analyze both\nindividual overlapping nodes and entire communities. In this framework, nodes\nexchange labels according to dynamic interaction rules. A specific\nimplementation called Speaker-listener Label Propagation Algorithm (SLPA1)\ndemonstrates an excellent performance in identifying both overlapping nodes and\noverlapping communities with different degrees of diversity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 20:33:27 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2011 03:24:43 GMT"}, {"version": "v3", "created": "Thu, 10 Nov 2011 21:40:33 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Xie", "Jierui", ""], ["Szymanski", "Boleslaw K.", ""], ["Liu", "Xiaoming", ""]]}, {"id": "1109.5804", "submitter": "Petr Hlin\\v{e}n\\'y", "authors": "Robert Ganian and Petr Hlin\\v{e}n\\'y and Alexander Langer and Jan\n  Obdr\\v{z}\\'alek and Peter Rossmanith and Somnath Sikdar", "title": "Lower Bounds on the Complexity of MSO1 Model-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important algorithmic meta-theorems is a famous result by\nCourcelle, which states that any graph problem definable in monadic\nsecond-order logic with edge-set quantifications (i.e., MSO2 model-checking) is\ndecidable in linear time on any class of graphs of bounded tree-width.\nRecently, Kreutzer and Tazari proved a corresponding complexity lower-bound -\nthat MSO2 model-checking is not even in XP wrt. the formula size as parameter\nfor graph classes that are subgraph-closed and whose tree-width is\npoly-logarithmically unbounded. Of course, this is not an unconditional result\nbut holds modulo a certain complexity-theoretic assumption, namely, the\nExponential Time Hypothesis (ETH).\n  In this paper we present a closely related result. We show that even MSO1\nmodel-checking with a fixed set of vertex labels, but without edge-set\nquantifications, is not in XP wrt. the formula size as parameter for graph\nclasses which are subgraph-closed and whose tree-width is poly-logarithmically\nunbounded unless the non-uniform ETH fails. In comparison to Kreutzer and\nTazari; $(1)$ we use a stronger prerequisite, namely non-uniform instead of\nuniform ETH, to avoid the effectiveness assumption and the construction of\ncertain obstructions used in their proofs; and $(2)$ we assume a different set\nof problems to be efficiently decidable, namely MSO1-definable properties on\nvertex labeled graphs instead of MSO2-definable properties on unlabeled graphs.\n  Our result has an interesting consequence in the realm of digraph width\nmeasures: Strengthening the recent result, we show that no subdigraph-monotone\nmeasure can be \"algorithmically useful\", unless it is within a poly-logarithmic\nfactor of undirected tree-width.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 08:45:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2012 21:20:13 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Ganian", "Robert", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Langer", "Alexander", ""], ["Obdr\u017e\u00e1lek", "Jan", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1109.5931", "submitter": "Ravishankar Krishnaswamy", "authors": "Anupam Gupta, Ravishankar Krishnaswamy, and Kirk Pruhs", "title": "Online Primal-Dual For Non-linear Optimization with Applications to\n  Speed Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reinterpret some online greedy algorithms for a class of nonlinear\n\"load-balancing\" problems as solving a mathematical program online. For\nexample, we consider the problem of assigning jobs to (unrelated) machines to\nminimize the sum of the alpha^{th}-powers of the loads plus assignment costs\n(the online Generalized Assignment Problem); or choosing paths to connect\nterminal pairs to minimize the alpha^{th}-powers of the edge loads (online\nrouting with speed-scalable routers). We give analyses of these online\nalgorithms using the dual of the primal program as a lower bound for the\noptimal algorithm, much in the spirit of online primal-dual results for linear\nproblems.\n  We then observe that a wide class of uni-processor speed scaling problems\n(with essentially arbitrary scheduling objectives) can be viewed as such load\nbalancing problems with linear assignment costs. This connection gives new\nalgorithms for problems that had resisted solutions using the dominant\npotential function approaches used in the speed scaling literature, as well as\nalternate, cleaner proofs for other known results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 15:19:08 GMT"}], "update_date": "2011-09-28", "authors_parsed": [["Gupta", "Anupam", ""], ["Krishnaswamy", "Ravishankar", ""], ["Pruhs", "Kirk", ""]]}, {"id": "1109.5981", "submitter": "Xiangrui Meng", "authors": "Xiangrui Meng and Michael A. Saunders, and Michael W. Mahoney", "title": "LSRN: A Parallel Iterative Solver for Strongly Over- or Under-Determined\n  Systems", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a parallel iterative least squares solver named \\texttt{LSRN}\nthat is based on random normal projection. \\texttt{LSRN} computes the\nmin-length solution to $\\min_{x \\in \\mathbb{R}^n} \\|A x - b\\|_2$, where $A \\in\n\\mathbb{R}^{m \\times n}$ with $m \\gg n$ or $m \\ll n$, and where $A$ may be\nrank-deficient. Tikhonov regularization may also be included. Since $A$ is only\ninvolved in matrix-matrix and matrix-vector multiplications, it can be a dense\nor sparse matrix or a linear operator, and \\texttt{LSRN} automatically speeds\nup when $A$ is sparse or a fast linear operator. The preconditioning phase\nconsists of a random normal projection, which is embarrassingly parallel, and a\nsingular value decomposition of size $\\lceil \\gamma \\min(m,n) \\rceil \\times\n\\min(m,n)$, where $\\gamma$ is moderately larger than 1, e.g., $\\gamma = 2$. We\nprove that the preconditioned system is well-conditioned, with a strong\nconcentration result on the extreme singular values, and hence that the number\nof iterations is fully predictable when we apply LSQR or the Chebyshev\nsemi-iterative method. As we demonstrate, the Chebyshev method is particularly\nefficient for solving large problems on clusters with high communication cost.\nNumerical results demonstrate that on a shared-memory machine, \\texttt{LSRN}\noutperforms LAPACK's DGELSD on large dense problems, and MATLAB's backslash\n(SuiteSparseQR) on sparse problems. Further experiments demonstrate that\n\\texttt{LSRN} scales well on an Amazon Elastic Compute Cloud cluster.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 18:06:44 GMT"}, {"version": "v2", "created": "Sat, 18 Feb 2012 20:39:18 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Meng", "Xiangrui", ""], ["Saunders", "Michael A.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1109.6178", "submitter": "Ning Xie", "authors": "Noga Alon, Ronitt Rubinfeld, Shai Vardi, Ning Xie", "title": "Space-efficient Local Computation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Rubinfeld et al. (ICS 2011, pp. 223--238) proposed a new model of\nsublinear algorithms called \\emph{local computation algorithms}. In this model,\na computation problem $F$ may have more than one legal solution and each of\nthem consists of many bits. The local computation algorithm for $F$ should\nanswer in an online fashion, for any index $i$, the $i^{\\mathrm{th}}$ bit of\nsome legal solution of $F$. Further, all the answers given by the algorithm\nshould be consistent with at least one solution of $F$.\n  In this work, we continue the study of local computation algorithms. In\nparticular, we develop a technique which under certain conditions can be\napplied to construct local computation algorithms that run not only in\npolylogarithmic time but also in polylogarithmic \\emph{space}. Moreover, these\nlocal computation algorithms are easily parallelizable and can answer all\nparallel queries consistently. Our main technical tools are pseudorandom\nnumbers with bounded independence and the theory of branching processes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2011 11:56:40 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 04:27:23 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Alon", "Noga", ""], ["Rubinfeld", "Ronitt", ""], ["Vardi", "Shai", ""], ["Xie", "Ning", ""]]}, {"id": "1109.6643", "submitter": "Francesco Versaci", "authors": "Gianfranco Bilardi, Francesco Versaci", "title": "Optimal Eviction Policies for Stochastic Address Traces", "comments": "37 pages, 3 figures", "journal-ref": "Theoretical Computer Science, Volume 514, 25 November 2013, Pages\n  36-60", "doi": "10.1016/j.tcs.2013.01.016", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The eviction problem for memory hierarchies is studied for the Hidden Markov\nReference Model (HMRM) of the memory trace, showing how miss minimization can\nbe naturally formulated in the optimal control setting. In addition to the\ntraditional version assuming a buffer of fixed capacity, a relaxed version is\nalso considered, in which buffer occupancy can vary and its average is\nconstrained. Resorting to multiobjective optimization, viewing occupancy as a\ncost rather than as a constraint, the optimal eviction policy is obtained by\ncomposing solutions for the individual addressable items.\n  This approach is then specialized to the Least Recently Used Stack Model\n(LRUSM), a type of HMRM often considered for traces, which includes V-1\nparameters, where V is the size of the virtual space. A gain optimal policy for\nany target average occupancy is obtained which (i) is computable in time O(V)\nfrom the model parameters, (ii) is optimal also for the fixed capacity case,\nand (iii) is characterized in terms of priorities, with the name of Least\nProfit Rate (LPR) policy. An O(log C) upper bound (being C the buffer capacity)\nis derived for the ratio between the expected miss rate of LPR and that of OPT,\nthe optimal off-line policy; the upper bound is tightened to O(1), under\nreasonable constraints on the LRUSM parameters. Using the stack-distance\nframework, an algorithm is developed to compute the number of misses incurred\nby LPR on a given input trace, simultaneously for all buffer capacities, in\ntime O(log V) per access.\n  Finally, some results are provided for miss minimization over a finite\nhorizon and over an infinite horizon under bias optimality, a criterion more\nstringent than gain optimality.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 19:55:13 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 17:42:35 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2013 14:15:06 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Bilardi", "Gianfranco", ""], ["Versaci", "Francesco", ""]]}, {"id": "1109.6925", "submitter": "Clemens P J Adolphs", "authors": "C. P. J. Adolphs and P. Berenbrink", "title": "Distributed Selfish Load Balancing with Weights and Speeds", "comments": "29 pages, submitted to STACS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider neighborhood load balancing in the context of\nselfish clients. We assume that a network of n processors and m tasks is given.\nThe processors may have different speeds and the tasks may have different\nweights. Every task is controlled by a selfish user. The objective of the user\nis to allocate his/her task to a processor with minimum load. We revisit the\nconcurrent probabilistic protocol introduced in [6], which works in sequential\nrounds. In each round every task is allowed to query the load of one randomly\nchosen neighboring processor. If that load is smaller the task will migrate to\nthat processor with a suitably chosen probability. Using techniques from\nspectral graph theory we obtain upper bounds on the expected convergence time\ntowards approximate and exact Nash equilibria that are significantly better\nthan the previous results in [6]. We show results for uniform tasks on\nnon-uniform processors and the general case where the tasks have different\nweights and the machines have speeds. To the best of our knowledge, these are\nthe first results for this general setting.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 18:49:41 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Adolphs", "C. P. J.", ""], ["Berenbrink", "P.", ""]]}]