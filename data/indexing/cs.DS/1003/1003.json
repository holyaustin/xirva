[{"id": "1003.0139", "submitter": "Rolf Fagerberg", "authors": "Prosenjit Bose (1), Karim Dou\\\"ieb (1), Vida Dujmovic (1), Rolf\n  Fagerberg (2) ((1) School of Computer Science, Carleton University, (2)\n  Department of Mathematics and Computer Science, University of Southern\n  Denmark)", "title": "An O(loglog n)-Competitive Binary Search Tree with Optimal Worst-Case\n  Access Times", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": "10.1007/978-3-642-13731-0_5", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the zipper tree, an $O(\\log \\log n)$-competitive online binary\nsearch tree that performs each access in $O(\\log n)$ worst-case time. This\nshows that for binary search trees, optimal worst-case access time and\nnear-optimal amortized access time can be guaranteed simultaneously.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2010 23:39:35 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bose", "Prosenjit", ""], ["Dou\u00efeb", "Karim", ""], ["Dujmovic", "Vida", ""], ["Fagerberg", "Rolf", ""]]}, {"id": "1003.0150", "submitter": "Yun Kuen Cheung", "authors": "Y. K. Cheung, Philippe Flajolet, Mordecai Golin, C. Y. James Lee", "title": "Multidimensional Divide-and-Conquer and Weighted Digital Sums", "comments": "44 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies three types of functions arising separately in the\nanalysis of algorithms that we analyze exactly using similar Mellin transform\ntechniques. The first is the solution to a Multidimensional Divide-and-Conquer\n(MDC) recurrence that arises when solving problems on points in $d$-dimensional\nspace. The second involves weighted digital sums. Write $n$ in its binary\nrepresentation $n=(b_i b_{i-1}... b_1 b_0)_2$ and set $S_M(n) = \\sum_{t=0}^i\nt^{\\bar{M}} b_t 2^t$. We analyze the average $TS_M(n) = \\frac{1}{n}\\sum_{j<n}\nS_M(j)$. The third is a different variant of weighted digital sums. Write $n$\nas $n=2^{i_1} + 2^{i_2} + ... + 2^{i_k}$ with $i_1 > i_2 > ... > i_k\\geq 0$ and\nset $W_M(n) = \\sum_{t=1}^k t^M 2^{i_t}$. We analyze the average $TW_M(n) =\n\\frac{1}{n}\\sum_{j<n} W_M(j)$.\n  We show that both the MDC functions and $TS_M(n)$ (with $d=M+1$) have\nsolutions of the form $\\lambda_d n \\lg^{d-1}n + \\sum_{m=0}^{d-2}(n\\lg^m\nn)A_{d,m}(\\lg n) + c_d,$ where $\\lambda_d,c_d$ are constants and $A_{d,m}(u)$'s\nare periodic functions with period one (given by absolutely convergent Fourier\nseries). We also show that $TW_M(n)$ has a solution of the form $n G_M(\\lg n) +\nd_M \\lg^M n + \\sum_{d=0}^{M-1}(\\lg^d n)G_{M,d}(\\lg n),$ where $d_M$ is a\nconstant, $G_M(u)$ and $G_{M,d}(u)$'s are again periodic functions with period\none (given by absolutely convergent Fourier series).\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2010 05:20:30 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Cheung", "Y. K.", ""], ["Flajolet", "Philippe", ""], ["Golin", "Mordecai", ""], ["Lee", "C. Y. James", ""]]}, {"id": "1003.0167", "submitter": "Atri Rudra", "authors": "Nikhil Bansal, Anupam Gupta, Viswanath Nagarajan and Atri Rudra", "title": "When LP is the Cure for Your Matching Woes: Approximating Stochastic\n  Matchings", "comments": "This paper has been withdrawn due to new merged paper\n  arXiv:1008.5356v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This results in this paper have been merged with the result in\narXiv:1002.3763v1\n  The authors would like to withdraw this version.\n  Please see arXiv:1008.5356v1 for the merged version.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2010 06:32:18 GMT"}, {"version": "v2", "created": "Fri, 3 Sep 2010 01:29:37 GMT"}], "update_date": "2010-09-06", "authors_parsed": [["Bansal", "Nikhil", ""], ["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""], ["Rudra", "Atri", ""]]}, {"id": "1003.0722", "submitter": "Viswanath Nagarajan", "authors": "Anupam Gupta, Viswanath Nagarajan, R. Ravi", "title": "Approximation Algorithms for Optimal Decision Trees and Adaptive TSP\n  Problems", "comments": "28 pages; to appear in Mathematics of Operations Research", "journal-ref": null, "doi": "10.1287/moor.2016.0831", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing optimal decision trees: given a\ncollection of tests which can disambiguate between a set of $m$ possible\ndiseases, each test having a cost, and the a-priori likelihood of the patient\nhaving any particular disease, what is a good adaptive strategy to perform\nthese tests to minimize the expected cost to identify the disease? We settle\nthe approximability of this problem by giving a tight $O(\\log m)$-approximation\nalgorithm. We also consider a more substantial generalization, the Adaptive TSP\nproblem. Given an underlying metric space, a random subset $S$ of cities is\ndrawn from a known distribution, but $S$ is initially unknown to us--we get\ninformation about whether any city is in $S$ only when we visit the city in\nquestion. What is a good adaptive way of visiting all the cities in the random\nsubset $S$ while minimizing the expected distance traveled? For this problem,\nwe give the first poly-logarithmic approximation, and show that this algorithm\nis best possible unless we can improve the approximation guarantees for the\nwell-known group Steiner tree problem.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 03:58:29 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2010 22:56:28 GMT"}, {"version": "v3", "created": "Fri, 21 Apr 2017 13:32:42 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Gupta", "Anupam", ""], ["Nagarajan", "Viswanath", ""], ["Ravi", "R.", ""]]}, {"id": "1003.1251", "submitter": "Arnab Bhattacharya", "authors": "Viswanath Gunturi, Shashi Shekhar, Arnab Bhattacharya", "title": "Minimum Spanning Tree on Spatio-Temporal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a spatio-temporal network (ST network) where edge properties vary with\ntime, a time-sub-interval minimum spanning tree (TSMST) is a collection of\nminimum spanning trees of the ST network, where each tree is associated with a\ntime interval. During this time interval, the total cost of tree is least among\nall the spanning trees. The TSMST problem aims to identify a collection of\ndistinct minimum spanning trees and their respective time-sub-intervals under\nthe constraint that the edge weight functions are piecewise linear. This is an\nimportant problem in ST network application domains such as wireless sensor\nnetworks (e.g., energy efficient routing). Computing TSMST is challenging\nbecause the ranking of candidate spanning trees is non-stationary over a given\ntime interval. Existing methods such as dynamic graph algorithms and kinetic\ndata structures assume separable edge weight functions. In contrast, we propose\nnovel algorithms to find TSMST for large ST networks by accounting for both\nseparable and non-separable piecewise linear edge weight functions. The\nalgorithms are based on the ordering of edges in edge-order-intervals and\nintersection points of edge weight functions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 12:39:18 GMT"}, {"version": "v2", "created": "Fri, 21 May 2010 12:34:40 GMT"}], "update_date": "2010-05-24", "authors_parsed": [["Gunturi", "Viswanath", ""], ["Shekhar", "Shashi", ""], ["Bhattacharya", "Arnab", ""]]}, {"id": "1003.1260", "submitter": "Ildiko Schlotter", "authors": "D\\'aniel Marx, Ildik\\'o Schlotter", "title": "Cleaning Interval Graphs", "comments": "40 pages, 7 eps figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a special case of the Induced Subgraph Isomorphism problem,\nwhere both input graphs are interval graphs. We show the NP-hardness of this\nproblem, and we prove fixed-parameter tractability of the problem with\nnon-standard parameterization, where the parameter is the difference\n|V(G)|-|V(H)|, with G and H being the larger and the smaller input graph,\nrespectively. Intuitively, we can interpret this problem as \"cleaning\" the\ngraph G, regarded as a pattern containing extra vertices indicating errors, in\norder to obtain the graph H representing the original pattern. We also prove\nW[1]-hardness for the standard parameterization where the parameter is |V(H)|.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 13:26:55 GMT"}], "update_date": "2010-03-08", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Schlotter", "Ildik\u00f3", ""]]}, {"id": "1003.1266", "submitter": "Ulrike von Luxburg", "authors": "Ulrike von Luxburg, Agnes Radl, Matthias Hein", "title": "Hitting and commute times in large graphs are often misleading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next to the shortest path distance, the second most popular distance function\nbetween vertices in a graph is the commute distance (resistance distance). For\ntwo vertices u and v, the hitting time H_{uv} is the expected time it takes a\nrandom walk to travel from u to v. The commute time is its symmetrized version\nC_{uv} = H_{uv} + H_{vu}. In our paper we study the behavior of hitting times\nand commute distances when the number n of vertices in the graph is very large.\nWe prove that as n converges to infinty, hitting times and commute distances\nconverge to expressions that do not take into account the global structure of\nthe graph at all. Namely, the hitting time H_{uv} converges to 1/d_v and the\ncommute time to 1/d_u + 1/d_v where d_u and d_v denote the degrees of vertices\nu and v. In these cases, the hitting and commute times are misleading in the\nsense that they do not provide information about the structure of the graph. We\nfocus on two major classes of random graphs: random geometric graphs (k-nearest\nneighbor graphs, epsilon-graphs, Gaussian similarity graphs) and random graphs\nwith given expected degrees (in particular, Erdos-Renyi graphs with and without\nplanted partitions)\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 13:54:11 GMT"}, {"version": "v2", "created": "Thu, 26 May 2011 08:07:41 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["von Luxburg", "Ulrike", ""], ["Radl", "Agnes", ""], ["Hein", "Matthias", ""]]}, {"id": "1003.1295", "submitter": "Jaroslaw Byrka", "authors": "Jaroslaw Byrka, Aravind Srinivasan, and Chaitanya Swamy", "title": "Fault-Tolerant Facility Location: a randomized dependent LP-rounding\n  algorithm", "comments": "conference paper + proofs in appendices", "journal-ref": null, "doi": "10.1007/978-3-642-13036-6_19", "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new randomized LP-rounding 1.725-approximation algorithm for the\nmetric Fault-Tolerant Uncapacitated Facility Location problem. This improves on\nthe previously best known 2.076-approximation algorithm of Swamy & Shmoys. To\nthe best of our knowledge, our work provides the first application of a\ndependent-rounding technique in the domain of facility location. The analysis\nof our algorithm benefits from, and extends, methods developed for\nUncapacitated Facility Location; it also helps uncover new properties of the\ndependent-rounding approach. An important concept that we develop is a novel,\nhierarchical clustering scheme. Typically, LP-rounding approximation algorithms\nfor facility location problems are based on partitioning facilities into\ndisjoint clusters and opening at least one facility in each cluster. We extend\nthis approach and construct a laminar family of clusters, which then guides the\nrounding procedure. It allows to exploit properties of dependent rounding, and\nprovides a quite tight analysis resulting in the improved approximation ratio.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 15:57:50 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Byrka", "Jaroslaw", ""], ["Srinivasan", "Aravind", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1003.1320", "submitter": "Glencora Borradaile", "authors": "Glencora Borradaile, Piotr Sankowski, Christian Wulff-Nilsen", "title": "Min st-Cut Oracle for Planar Graphs with Near-Linear Preprocessing Time", "comments": "This is the final version submitted for journal publication and has\n  improved the running time of an earlier version by a log n factor. This\n  version includes the bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an undirected $n$-vertex planar graph $G$ with non-negative edge-weights,\nwe consider the following type of query: given two vertices $s$ and $t$ in $G$,\nwhat is the weight of a min $st$-cut in $G$? We show how to answer such queries\nin constant time with $O(n\\log^4n)$ preprocessing time and $O(n\\log n)$ space.\nWe use a Gomory-Hu tree to represent all the pairwise min cuts implicitly.\nPreviously, no subquadratic time algorithm was known for this problem. Since\nall-pairs min cut and the minimum cycle basis are dual problems in planar\ngraphs, we also obtain an implicit representation of a minimum cycle basis in\n$O(n\\log^4n)$ time and $O(n\\log n)$ space. Additionally, an explicit\nrepresentation can be obtained in $O(C)$ time and space where $C$ is the size\nof the basis.\n  These results require that shortest paths are unique. This can be guaranteed\neither by using randomization without overhead, or deterministically with an\nadditional $\\log^2 n$ factor in the preprocessing times.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 17:43:56 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2010 19:45:57 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2013 21:02:44 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2013 15:49:47 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Borradaile", "Glencora", ""], ["Sankowski", "Piotr", ""], ["Wulff-Nilsen", "Christian", ""]]}, {"id": "1003.1412", "submitter": "Valmir Barbosa", "authors": "Valmir C. Barbosa", "title": "Network conduciveness with application to the graph-coloring and\n  independent-set optimization transitions", "comments": null, "journal-ref": "PLoS ONE 5 (2010), e11232", "doi": "10.1371/journal.pone.0011232", "report-no": null, "categories": "cond-mat.stat-mech cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of a network's conduciveness, a probabilistically\ninterpretable measure of how the network's structure allows it to be conducive\nto roaming agents, in certain conditions, from one portion of the network to\nanother. We exemplify its use through an application to the two problems in\ncombinatorial optimization that, given an undirected graph, ask that its\nso-called chromatic and independence numbers be found. Though NP-hard, when\nsolved on sequences of expanding random graphs there appear marked transitions\nat which optimal solutions can be obtained substantially more easily than right\nbefore them. We demonstrate that these phenomena can be understood by resorting\nto the network that represents the solution space of the problems for each\ngraph and examining its conduciveness between the non-optimal solutions and the\noptimal ones. At the said transitions, this network becomes strikingly more\nconducive in the direction of the optimal solutions than it was just before\nthem, while at the same time becoming less conducive in the opposite direction.\nWe believe that, besides becoming useful also in other areas in which network\ntheory has a role to play, network conduciveness may become instrumental in\nhelping clarify further issues related to NP-hardness that remain poorly\nunderstood.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2010 18:19:11 GMT"}], "update_date": "2010-07-12", "authors_parsed": [["Barbosa", "Valmir C.", ""]]}, {"id": "1003.1507", "submitter": "Jochen Koenemann", "authors": "Deeparnab Chakrabarty, Elyot Grant, Jochen Koenemann", "title": "On Column-restricted and Priority Covering Integer Programs", "comments": "28 pages, 6 figures, extended abstract to appear in proceedings of\n  IPCO 2010.", "journal-ref": null, "doi": "10.1007/978-3-642-13036-6_27", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a column-restricted covering integer program (CCIP), all the non-zero\nentries of any column of the constraint matrix are equal. Such programs capture\ncapacitated versions of covering problems. In this paper, we study the\napproximability of CCIPs, in particular, their relation to the integrality gaps\nof the underlying 0,1-CIP.\n  If the underlying 0,1-CIP has an integrality gap O(gamma), and assuming that\nthe integrality gap of the priority version of the 0,1-CIP is O(omega), we give\na factor O(gamma + omega) approximation algorithm for the CCIP. Priority\nversions of 0,1-CIPs (PCIPs) naturally capture quality of service type\nconstraints in a covering problem.\n  We investigate priority versions of the line (PLC) and the (rooted) tree\ncover (PTC) problems. Apart from being natural objects to study, these problems\nfall in a class of fundamental geometric covering problems. We bound the\nintegrality of certain classes of this PCIP by a constant. Algorithmically, we\ngive a polytime exact algorithm for PLC, show that the PTC problem is APX-hard,\nand give a factor 2-approximation algorithm for it.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2010 18:08:12 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Chakrabarty", "Deeparnab", ""], ["Grant", "Elyot", ""], ["Koenemann", "Jochen", ""]]}, {"id": "1003.1517", "submitter": "Aaron Roth", "authors": "Anupam Gupta, Aaron Roth, Grant Schoenebeck, Kunal Talwar", "title": "Constrained Non-Monotone Submodular Maximization: Offline and Secretary\n  Algorithms", "comments": "In the Proceedings of WINE 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained submodular maximization problems have long been studied, with\nnear-optimal results known under a variety of constraints when the submodular\nfunction is monotone. The case of non-monotone submodular maximization is less\nunderstood: the first approximation algorithms even for the unconstrainted\nsetting were given by Feige et al. (FOCS '07). More recently, Lee et al. (STOC\n'09, APPROX '09) show how to approximately maximize non-monotone submodular\nfunctions when the constraints are given by the intersection of p matroid\nconstraints; their algorithm is based on local-search procedures that consider\np-swaps, and hence the running time may be n^Omega(p), implying their algorithm\nis polynomial-time only for constantly many matroids. In this paper, we give\nalgorithms that work for p-independence systems (which generalize constraints\ngiven by the intersection of p matroids), where the running time is poly(n,p).\nOur algorithm essentially reduces the non-monotone maximization problem to\nmultiple runs of the greedy algorithm previously used in the monotone case.\n  Our idea of using existing algorithms for monotone functions to solve the\nnon-monotone case also works for maximizing a submodular function with respect\nto a knapsack constraint: we get a simple greedy-based constant-factor\napproximation for this problem.\n  With these simpler algorithms, we are able to adapt our approach to\nconstrained non-monotone submodular maximization to the (online) secretary\nsetting, where elements arrive one at a time in random order, and the algorithm\nmust make irrevocable decisions about whether or not to select each element as\nit arrives. We give constant approximations in this secretary setting when the\nalgorithm is constrained subject to a uniform matroid or a partition matroid,\nand give an O(log k) approximation when it is constrained by a general matroid\nof rank k.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2010 19:27:48 GMT"}, {"version": "v2", "created": "Wed, 6 Oct 2010 00:21:20 GMT"}], "update_date": "2010-10-07", "authors_parsed": [["Gupta", "Anupam", ""], ["Roth", "Aaron", ""], ["Schoenebeck", "Grant", ""], ["Talwar", "Kunal", ""]]}, {"id": "1003.1940", "submitter": "Vamsi Kundeti", "authors": "Vamsi Kundeti, Sanguthevar Rajasekaran, Hieu Dinh", "title": "Efficient Parallel and Out of Core Algorithms for Constructing Large\n  Bi-directed de Bruijn Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assembling genomic sequences from a set of overlapping reads is one of the\nmost fundamental problems in computational biology. Algorithms addressing the\nassembly problem fall into two broad categories -- based on the data structures\nwhich they employ. The first class uses an overlap/string graph and the second\ntype uses a de Bruijn graph. However with the recent advances in short read\nsequencing technology, de Bruijn graph based algorithms seem to play a vital\nrole in practice.\n  Efficient algorithms for building these massive de Bruijn graphs are very\nessential in large sequencing projects based on short reads. In Jackson et. al.\nICPP-2008, an $O(n/p)$ time parallel algorithm has been given for this problem.\nHere $n$ is the size of the input and $p$ is the number of processors. This\nalgorithm enumerates all possible bi-directed edges which can overlap with a\nnode and ends up generating $\\Theta(n\\Sigma)$ messages.\n  In this paper we present a $\\Theta(n/p)$ time parallel algorithm with a\ncommunication complexity equal to that of parallel sorting and is not sensitive\nto $\\Sigma$. The generality of our algorithm makes it very easy to extend it\neven to the out-of-core model and in this case it has an optimal I/O complexity\nof $\\Theta(\\frac{n\\log(n/B)}{B\\log(M/B)})$. We demonstrate the scalability of\nour parallel algorithm on a SGI/Altix computer. A comparison of our algorithm\nwith that of Jackson et. al. ICPP-2008 reveals that our algorithm is faster. We\nalso provide efficient algorithms for the bi-directed chain compaction problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2010 17:54:01 GMT"}], "update_date": "2010-03-10", "authors_parsed": [["Kundeti", "Vamsi", ""], ["Rajasekaran", "Sanguthevar", ""], ["Dinh", "Hieu", ""]]}, {"id": "1003.2084", "submitter": "Rena Bakhshi", "authors": "Rena Bakhshi and J\\\"org Endrullis and Wan Fokkink and Jun Pang", "title": "Asynchronous Bounded Expected Delay Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commonly used asynchronous bounded delay (ABD) network models assume a\nfixed bound on message delay. We propose a probabilistic network model, called\nasynchronous bounded expected delay (ABE) model. Instead of a strict bound, the\nABE model requires only a bound on the expected message delay. While the\nconditions of ABD networks restrict the set of possible executions, in ABE\nnetworks all asynchronous executions are possible, but executions with\nextremely long delays are less probable. In contrast to ABD networks, ABE\nnetworks cannot be synchronised efficiently. At the example of an election\nalgorithm, we show that the minimal assumptions of ABE networks are sufficient\nfor the development of efficient algorithms. For anonymous, unidirectional ABE\nrings of known size N we devise a probabilistic leader election algorithm\nhaving average message and time complexity O(N).\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2010 11:39:08 GMT"}, {"version": "v2", "created": "Mon, 30 May 2011 17:10:44 GMT"}, {"version": "v3", "created": "Tue, 7 Jun 2011 09:05:23 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Bakhshi", "Rena", ""], ["Endrullis", "J\u00f6rg", ""], ["Fokkink", "Wan", ""], ["Pang", "Jun", ""]]}, {"id": "1003.2839", "submitter": "Vamsi Kundeti", "authors": "Vamsi Kundeti, Sanguthevar Rajasekaran, Hieu Dinh", "title": "On the Border Length Minimization Problem (BLMP) on a Square Array", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein/Peptide microarrays are rapidly gaining momentum in the diagnosis of\ncancer. High-density and highthroughput peptide arrays are being extensively\nused to detect tumor biomarkers, examine kinase activity, identify antibodies\nhaving low serum titers and locate antibody signatures. Improving the yield of\nmicroarray fabrication involves solving a hard combinatorial optimization\nproblem called the Border Length Minimization Problem (BLMP). An important\nquestion that remained open for the past seven years is if the BLMP is\ntractable or not. We settle this open problem by proving that the BLMP is\nNP-hard. We also present a hierarchical refinement algorithm which can refine\nany heuristic solution for the BLMP problem. We also prove that the\nTSP+1-threading heuristic is an O(N)- approximation. The hierarchical\nrefinement solver is available as an opensource code at\nhttp://launchpad.net/blm-solve.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 02:33:43 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2010 00:37:20 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Kundeti", "Vamsi", ""], ["Rajasekaran", "Sanguthevar", ""], ["Dinh", "Hieu", ""]]}, {"id": "1003.2958", "submitter": "Ioannis Koutis", "authors": "Ioannis Koutis and Gary L. Miller and Richard Peng", "title": "Approaching optimality for solving SDD systems", "comments": "To appear in FOCS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that on input of an $n$-vertex $m$-edge weighted\ngraph $G$ and a value $k$, produces an {\\em incremental sparsifier} $\\hat{G}$\nwith $n-1 + m/k$ edges, such that the condition number of $G$ with $\\hat{G}$ is\nbounded above by $\\tilde{O}(k\\log^2 n)$, with probability $1-p$. The algorithm\nruns in time\n  $$\\tilde{O}((m \\log{n} + n\\log^2{n})\\log(1/p)).$$\n  As a result, we obtain an algorithm that on input of an $n\\times n$ symmetric\ndiagonally dominant matrix $A$ with $m$ non-zero entries and a vector $b$,\ncomputes a vector ${x}$ satisfying $||{x}-A^{+}b||_A<\\epsilon ||A^{+}b||_A $,\nin expected time\n  $$\\tilde{O}(m\\log^2{n}\\log(1/\\epsilon)).$$\n  The solver is based on repeated applications of the incremental sparsifier\nthat produces a chain of graphs which is then used as input to a recursive\npreconditioned Chebyshev iteration.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 16:37:51 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2010 05:14:39 GMT"}, {"version": "v3", "created": "Tue, 3 Aug 2010 07:43:16 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Koutis", "Ioannis", ""], ["Miller", "Gary L.", ""], ["Peng", "Richard", ""]]}, {"id": "1003.2977", "submitter": "Viswanath Nagarajan", "authors": "Nikhil Bansal, Rohit Khandekar, Jochen Konemann, Viswanath Nagarajan,\n  Britta Peis", "title": "On Generalizations of Network Design Problems with Degree Bounds", "comments": "v2, 24 pages, 4 figures", "journal-ref": null, "doi": "10.1007/978-3-642-13036-6_9", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative rounding and relaxation have arguably become the method of choice\nin dealing with unconstrained and constrained network design problems. In this\npaper we extend the scope of the iterative relaxation method in two directions:\n(1) by handling more complex degree constraints in the minimum spanning tree\nproblem (namely, laminar crossing spanning tree), and (2) by incorporating\n`degree bounds' in other combinatorial optimization problems such as matroid\nintersection and lattice polyhedra. We give new or improved approximation\nalgorithms, hardness results, and integrality gaps for these problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 17:49:56 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2010 03:56:28 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bansal", "Nikhil", ""], ["Khandekar", "Rohit", ""], ["Konemann", "Jochen", ""], ["Nagarajan", "Viswanath", ""], ["Peis", "Britta", ""]]}, {"id": "1003.3085", "submitter": "Maxim Babenko", "authors": "Maxim Babenko, Ignat Kolesnichenko, Ilya Razenshteyn", "title": "A Linear Time Algorithm for Finding Three Edge-Disjoint Paths in\n  Eulerian Networks", "comments": "SOFSEM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an undirected graph $G = (VG, EG)$ and a set of six \\emph{terminals}\n$T = \\set{s_1, s_2, s_3, t_1, t_2, t_3} \\subseteq VG$. The goal is to find a\ncollection $\\calP$ of three edge-disjoint paths $P_1$, $P_2$, and $P_3$, where\n$P_i$ connects nodes $s_i$ and $t_i$ ($i = 1, 2, 3$). Results obtained by\nRobertson and Seymour by graph minor techniques imply a polynomial time\nsolvability of this problem. The time bound of their algorithm is $O(m^3)$\n(hereinafter we assume $n := \\abs{VG}$, $m := \\abs{EG}$, $n = O(m)$). In this\npaper we consider a special, \\emph{Eulerian} case of $G$ and $T$. Namely,\nconstruct the \\emph{demand graph} $H = (VG, \\set{s_1t_1, s_2t_2, s_3t_3})$. The\nedges of $H$ correspond to the desired paths in $\\calP$. In the Eulerian case\nthe degrees of all nodes in the (multi-) graph $G + H$ ($ = (VG, EG \\cup EH)$)\nare even. Schrijver showed that, under the assumption of Eulerianess, cut\nconditions provide a criterion for the existence of $\\calP$. This, in\nparticular, implies that checking for existence of $\\calP$ can be done in\n$O(m)$ time. Our result is a combinatorial $O(m)$-time algorithm that\nconstructs $\\calP$ (if the latter exists).\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 06:26:43 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Babenko", "Maxim", ""], ["Kolesnichenko", "Ignat", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1003.3131", "submitter": "Martin Hoefer", "authors": "Martin Hoefer", "title": "Strategic Cooperation in Cost Sharing Games", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider strategic cost sharing games with so-called\narbitrary sharing based on various combinatorial optimization problems, such as\nvertex and set cover, facility location, and network design problems. We\nconcentrate on the existence and computational complexity of strong equilibria,\nin which no coalition can improve the cost of each of its members. Our main\nresult reveals a connection between strong equilibrium in strategic games and\nthe core in traditional coalitional cost sharing games studied in economics.\nFor set cover and facility location games this results in a tight\ncharacterization of the existence of strong equilibrium using the integrality\ngap of suitable linear programming formulations. Furthermore, it allows to\nderive all existing results for strong equilibria in network design cost\nsharing games with arbitrary sharing via a unified approach. In addition, we\nare able to show that in general the strong price of anarchy is always 1. This\nshould be contrasted with the price of anarchy of \\Theta(n) for Nash\nequilibria. Finally, we indicate that the LP-approach can also be used to\ncompute near-optimal and near-stable approximate strong equilibria.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 11:54:54 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Hoefer", "Martin", ""]]}, {"id": "1003.3406", "submitter": "Tanya Khovanova", "authors": "Tanya Khovanova, Konstantin Knop, Alexey Radul", "title": "Baron Munchhausen's Sequence", "comments": "26 pages", "journal-ref": "Journal of Integer Sequences, v.13 (2010), Article 10.8.7", "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.DS math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a coin-weighing puzzle that appeared in the all-Russian math\nOlympiad in 2000. We liked the puzzle because the methods of analysis differ\nfrom classical coin-weighing puzzles. We generalize the puzzle by varying the\nnumber of participating coins, and deduce a complete solution, perhaps\nsurprisingly, the objective can be achieved in no more than two weighings\nregardless of the number of coins involved.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 16:55:11 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Khovanova", "Tanya", ""], ["Knop", "Konstantin", ""], ["Radul", "Alexey", ""]]}, {"id": "1003.3418", "submitter": "John Fearnley", "authors": "John Fearnley", "title": "Exponential Lower Bounds For Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study policy iteration for infinite-horizon Markov decision processes. It\nhas recently been shown policy iteration style algorithms have exponential\nlower bounds in a two player game setting. We extend these lower bounds to\nMarkov decision processes with the total reward and average-reward optimality\ncriteria.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 17:48:58 GMT"}], "update_date": "2010-03-18", "authors_parsed": [["Fearnley", "John", ""]]}, {"id": "1003.3536", "submitter": "Bin Jiang", "authors": "Bin Jiang and Xintao Liu", "title": "Computing the Fewest-turn Map Directions based on the Connectivity of\n  Natural Roads", "comments": "12 pages, 5 figures, and 4 tables, language editing, some significant\n  revisions, missing references added", "journal-ref": "International Journal of Geographical Information Science, 25(7),\n  2011, 1069-1082", "doi": null, "report-no": null, "categories": "cs.CG cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduced a novel approach to computing the fewest-turn\nmap directions or routes based on the concept of natural roads. Natural roads\nare joined road segments that perceptually constitute good continuity. This\napproach relies on the connectivity of natural roads rather than that of road\nsegments for computing routes or map directions. Because of this, the derived\nroutes posses the fewest turns. However, what we intend to achieve are the\nroutes that not only possess the fewest turns, but are also as short as\npossible. This kind of map direction is more effective and favorable by people,\nbecause they bear less cognitive burden. Furthermore, the computation of the\nroutes is more efficient, since it is based on the graph encoding the\nconnectivity of roads, which is significantly smaller than the graph of road\nsegments. We made experiments applied to eight urban street networks from North\nAmerica and Europe in order to illustrate the above stated advantages. The\nexperimental results indicate that the fewest-turn routes posses fewer turns\nand shorter distances than the simplest paths and the routes provided by Google\nMaps. For example, the fewest-turn-and-shortest routes are on average 15%\nshorter than the routes suggested by Google Maps, while the number of turns is\njust half as much. This approach is a key technology behind FromToMap.org - a\nweb mapping service using openstreetmap data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 09:49:19 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2010 18:48:52 GMT"}, {"version": "v3", "created": "Fri, 14 May 2010 22:56:14 GMT"}, {"version": "v4", "created": "Sat, 21 Aug 2010 10:40:28 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Jiang", "Bin", ""], ["Liu", "Xintao", ""]]}, {"id": "1003.3676", "submitter": "Marcus Ritt", "authors": "Mayron C\\'esar O. Moreira, Marcus Ritt, Alysson M. Costa, Antonio A.\n  Chaves", "title": "Simple heuristics for the assembly line worker assignment and balancing\n  problem", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s10732-012-9195-5", "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose simple heuristics for the assembly line worker assignment and\nbalancing problem. This problem typically occurs in assembly lines in sheltered\nwork centers for the disabled. Different from the classical simple assembly\nline balancing problem, the task execution times vary according to the assigned\nworker. We develop a constructive heuristic framework based on task and worker\npriority rules defining the order in which the tasks and workers should be\nassigned to the workstations. We present a number of such rules and compare\ntheir performance across three possible uses: as a stand-alone method, as an\ninitial solution generator for meta-heuristics, and as a decoder for a hybrid\ngenetic algorithm. Our results show that the heuristics are fast, they obtain\ngood results as a stand-alone method and are efficient when used as a initial\nsolution generator or as a solution decoder within more elaborate approaches.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 20:29:03 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2012 19:39:27 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Moreira", "Mayron C\u00e9sar O.", ""], ["Ritt", "Marcus", ""], ["Costa", "Alysson M.", ""], ["Chaves", "Antonio A.", ""]]}, {"id": "1003.3821", "submitter": "Dan Guralnik", "authors": "Dan Guralnik", "title": "A Formal Approach to Modeling the Memory of a Living Organism", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a living organism as an observer of the evolution of its\nenvironment recording sensory information about the state space X of the\nenvironment in real time. Sensory information is sampled and then processed on\ntwo levels. On the biological level, the organism serves as an evaluation\nmechanism of the subjective relevance of the incoming data to the observer: the\nobserver assigns excitation values to events in X it could recognize using its\nsensory equipment. On the algorithmic level, sensory input is used for updating\na database, the memory of the observer whose purpose is to serve as a\ngeometric/combinatorial model of X, whose nodes are weighted by the excitation\nvalues produced by the evaluation mechanism. These values serve as a guidance\nsystem for deciding how the database should transform as observation data\nmounts. We define a searching problem for the proposed model and discuss the\nmodel's flexibility and its computational efficiency, as well as the\npossibility of implementing it as a dynamic network of neuron-like units. We\nshow how various easily observable properties of the human memory and thought\nprocess can be explained within the framework of this model. These include:\nreasoning (with efficiency bounds), errors, temporary and permanent loss of\ninformation. We are also able to define general learning problems in terms of\nthe new model, such as the language acquisition problem.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2010 15:56:37 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Guralnik", "Dan", ""]]}, {"id": "1003.3967", "submitter": "Andreas Krause", "authors": "Daniel Golovin and Andreas Krause", "title": "Adaptive Submodularity: Theory and Applications in Active Learning and\n  Stochastic Optimization", "comments": "60 pages, 6 figures. Version 5 addresses a flaw in the proof of\n  Theorem 13 identified by Nan and Saligrama (2017). The revision includes a\n  weaker version of Theorem 13, guaranteeing squared logarithmic approximation\n  under an additional strong adaptive submodularity condition. This condition\n  is met by all applications considered in the paper, as discussed in the\n  revised Sections 7, 8 and 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving stochastic optimization problems under partial observability, where\none needs to adaptively make decisions with uncertain outcomes, is a\nfundamental but notoriously difficult challenge. In this paper, we introduce\nthe concept of adaptive submodularity, generalizing submodular set functions to\nadaptive policies. We prove that if a problem satisfies this property, a simple\nadaptive greedy algorithm is guaranteed to be competitive with the optimal\npolicy. In addition to providing performance guarantees for both stochastic\nmaximization and coverage, adaptive submodularity can be exploited to\ndrastically speed up the greedy algorithm by using lazy evaluations. We\nillustrate the usefulness of the concept by giving several examples of adaptive\nsubmodular objectives arising in diverse applications including sensor\nplacement, viral marketing and active learning. Proving adaptive submodularity\nfor these problems allows us to recover existing results in these applications\nas special cases, improve approximation guarantees and handle natural\ngeneralizations.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2010 04:06:22 GMT"}, {"version": "v2", "created": "Mon, 24 May 2010 02:25:04 GMT"}, {"version": "v3", "created": "Mon, 30 Aug 2010 23:00:54 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2012 03:04:19 GMT"}, {"version": "v5", "created": "Wed, 6 Dec 2017 08:21:07 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Golovin", "Daniel", ""], ["Krause", "Andreas", ""]]}, {"id": "1003.4012", "submitter": "Christoph Fretter", "authors": "Christoph Fretter, Lachezar Krumov, Karsten Weihe, Matthias\n  M\\\"uller-Hannemann, and Marc-Thorsten H\\\"utt", "title": "Phase Synchronization in Railway Timetables", "comments": null, "journal-ref": "European Physical Journal B, Volume 77, Number 2, 281-289 (2010)", "doi": "10.1140/epjb/e2010-00234-y", "report-no": null, "categories": "cs.DS math.OC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timetable construction belongs to the most important optimization problems in\npublic transport. Finding optimal or near-optimal timetables under the\nsubsidiary conditions of minimizing travel times and other criteria is a\ntargeted contribution to the functioning of public transport. In addition to\nefficiency (given, e.g., by minimal average travel times), a significant\nfeature of a timetable is its robustness against delay propagation. Here we\nstudy the balance of efficiency and robustness in long-distance railway\ntimetables (in particular the current long-distance railway timetable in\nGermany) from the perspective of synchronization, exploiting the fact that a\nmajor part of the trains run nearly periodically. We find that synchronization\nis highest at intermediate-sized stations. We argue that this synchronization\nperspective opens a new avenue towards an understanding of railway timetables\nby representing them as spatio-temporal phase patterns. Robustness and\nefficiency can then be viewed as properties of this phase pattern.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2010 19:00:06 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Fretter", "Christoph", ""], ["Krumov", "Lachezar", ""], ["Weihe", "Karsten", ""], ["M\u00fcller-Hannemann", "Matthias", ""], ["H\u00fctt", "Marc-Thorsten", ""]]}, {"id": "1003.4261", "submitter": "Assaf Naor", "authors": "Assaf Naor", "title": "L_1 embeddings of the Heisenberg group and fast estimation of graph\n  isoperimetry", "comments": "To appear in Proceedings of the International Congress of\n  Mathematicians, Hyderabad India, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey connections between the theory of bi-Lipschitz embeddings and the\nSparsest Cut Problem in combinatorial optimization. The story of the Sparsest\nCut Problem is a striking example of the deep interplay between analysis,\ngeometry, and probability on the one hand, and computational issues in discrete\nmathematics on the other. We explain how the key ideas evolved over the past 20\nyears, emphasizing the interactions with Banach space theory, geometric measure\ntheory, and geometric group theory. As an important illustrative example, we\nshall examine recently established connections to the the structure of the\nHeisenberg group, and the incompatibility of its Carnot-Carath\\'eodory geometry\nwith the geometry of the Lebesgue space $L_1$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 20:00:31 GMT"}], "update_date": "2010-03-24", "authors_parsed": [["Naor", "Assaf", ""]]}, {"id": "1003.4314", "submitter": "Daniel Karapetyan", "authors": "Daniel Karapetyan and Gregory Gutin", "title": "A New Approach to Population Sizing for Memetic Algorithms: A Case Study\n  for the Multidimensional Assignment Problem", "comments": "25 pages", "journal-ref": "Evolutionary Computation 19(3), pages 345-371, 2011", "doi": "10.1162/EVCO_a_00026", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic Algorithms are known to be a powerful technique in solving hard\noptimization problems. To design a memetic algorithm one needs to make a host\nof decisions; selecting a population size is one of the most important among\nthem. Most algorithms in the literature fix the population size to a certain\nconstant value. This reduces the algorithm's quality since the optimal\npopulation size varies for different instances, local search procedures and\nrunning times. In this paper we propose an adjustable population size. It is\ncalculated as a function of the running time of the whole algorithm and the\naverage running time of the local search for the given instance. Note that in\nmany applications the running time of a heuristic should be limited and\ntherefore we use this limit as a parameter of the algorithm. The average\nrunning time of the local search procedure is obtained during the algorithm's\nrun. Some coefficients which are independent with respect to the instance or\nthe local search are to be tuned before the algorithm run; we provide a\nprocedure to find these coefficients. The proposed approach was used to develop\na memetic algorithm for the Multidimensional Assignment Problem (MAP or s-AP in\nthe case of s dimensions) which is an extension of the well-known assignment\nproblem. MAP is NP-hard and has a host of applications. We show that using\nadjustable population size makes the algorithm flexible to perform well for\ninstances of very different sizes and types and for different running times and\nlocal searches. This allows us to select the most efficient local search for\nevery instance type. The results of computational experiments for several\ninstance families and sizes prove that the proposed algorithm performs\nefficiently for a wide range of the running times and clearly outperforms the\nstate-of-the art 3-AP memetic algorithm being given the same time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 00:27:13 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Gutin", "Gregory", ""]]}, {"id": "1003.4366", "submitter": "Marco Nissen", "authors": "Marco Nissen", "title": "Graph Iterators: Decoupling Graph Structures from Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I will present a way to implement graph algorithms which is different from\ntraditional methods. This work was motivated by the belief that some ideas from\nsoftware engineering should be applied to graph algorithms. Re-usability of\nsoftware is an important and difficult problem in general, and this is\nparticularly true for graph algorithms. The scientific literature demonstrates\nplenty of applications of graph algorithms as subroutines for other algorithms.\nMoreover, many practical problems from various domains may be modeled as graph\nproblems and hence solved by means of graph algorithms. Chapter 2 introduces\nsome data structures that will be used in 5 basic graph algorithms in chapter\n3. Chapter 4 discusses an implementation of a maximum cardinality matching\nalgorithm for general graphs. Chapter 5 explains some techniques in C++, which\nare useful to implement the data structures and algorithms in an efficient way.\nFinally chapter 6 contains some concluding remarks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 10:23:07 GMT"}], "update_date": "2010-03-24", "authors_parsed": [["Nissen", "Marco", ""]]}, {"id": "1003.4847", "submitter": "Jesper Jacobsen", "authors": "Andrea Bedini (INFN, Sezione di Milano), Jesper Lykke Jacobsen\n  (LPTENS)", "title": "A tree-decomposed transfer matrix for computing exact Potts model\n  partition functions for arbitrary graphs, with applications to planar graph\n  colourings", "comments": "5 pages, 3 figures. Version 2 has been substantially expanded.\n  Version 3 shows that the worst-case running time is sub-exponential in the\n  number of vertices", "journal-ref": null, "doi": "10.1088/1751-8113/43/38/385001", "report-no": null, "categories": "math-ph cond-mat.stat-mech cs.DS math.CO math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining tree decomposition and transfer matrix techniques provides a very\ngeneral algorithm for computing exact partition functions of statistical models\ndefined on arbitrary graphs. The algorithm is particularly efficient in the\ncase of planar graphs. We illustrate it by computing the Potts model partition\nfunctions and chromatic polynomials (the number of proper vertex colourings\nusing Q colours) for large samples of random planar graphs with up to N=100\nvertices. In the latter case, our algorithm yields a sub-exponential average\nrunning time of ~ exp(1.516 sqrt(N)), a substantial improvement over the\nexponential running time ~ exp(0.245 N) provided by the hitherto best known\nalgorithm. We study the statistics of chromatic roots of random planar graphs\nin some detail, comparing the findings with results for finite pieces of a\nregular lattice.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 10:39:19 GMT"}, {"version": "v2", "created": "Mon, 31 May 2010 06:37:21 GMT"}, {"version": "v3", "created": "Fri, 6 Aug 2010 14:03:00 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bedini", "Andrea", "", "INFN, Sezione di Milano"], ["Jacobsen", "Jesper Lykke", "", "LPTENS"]]}, {"id": "1003.4942", "submitter": "Charalampos Tsourakakis", "authors": "Gary L. Miller, Richard Peng, Russell Schwartz, Charalampos E.\n  Tsourakakis", "title": "Approximate Dynamic Programming using Halfspace Queries and Multiscale\n  Monge decomposition", "comments": "1) 12 pages 2) Updated 2nd Version: Removed section 3.3 of 1st\n  version, updated references (for more details see\n  www.cs.cmu.edu/~ctsourak/approxdp_note.txt)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P=(P_1, P_2, \\ldots, P_n)$, $P_i \\in \\field{R}$ for all $i$, be a signal\nand let $C$ be a constant. In this work our goal is to find a function\n$F:[n]\\rightarrow \\field{R}$ which optimizes the following objective function:\n  $$ \\min_{F} \\sum_{i=1}^n (P_i-F_i)^2 + C\\times |\\{i:F_i \\neq F_{i+1} \\} | $$\n  The above optimization problem reduces to solving the following recurrence,\nwhich can be done efficiently using dynamic programming in $O(n^2)$ time:\n  $$ OPT_i = \\min_{0 \\leq j \\leq i-1} [ OPT_j + \\sum_{k=j+1}^i (P_k -\n(\\sum_{m=j+1}^i P_m)/(i-j) )^2 ]+ C $$\n  The above recurrence arises naturally in applications where we wish to\napproximate the original signal $P$ with another signal $F$ which consists\nideally of few piecewise constant segments. Such applications include database\n(e.g., histogram construction), speech recognition, biology (e.g., denoising\naCGH data) applications and many more.\n  In this work we present two new techniques for optimizing dynamic programming\nthat can handle cost functions not treated by other standard methods. The basis\nof our first algorithm is the definition of a constant-shifted variant of the\nobjective function that can be efficiently approximated using state of the art\nmethods for range searching. Our technique approximates the optimal value of\nour objective function within additive $\\epsilon$ error and runs in\n$\\tilde{O}(n^{1.5} \\log{(\\frac{U}{\\epsilon}))}$ time, where $U = \\max_i f_i$.\nThe second algorithm we provide solves a similar recurrence within a factor of\n$\\epsilon$ and runs in $O(n \\log^2n / \\epsilon)$. The new technique introduced\nby our algorithm is the decomposition of the initial problem into a small\n(logarithmic) number of Monge optimization subproblems which we can speed up\nusing existing techniques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 16:06:44 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2010 18:37:12 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Miller", "Gary L.", ""], ["Peng", "Richard", ""], ["Schwartz", "Russell", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1003.5330", "submitter": "Daniel Karapetyan", "authors": "Daniel Karapetyan and Gregory Gutin", "title": "Lin-Kernighan Heuristic Adaptations for the Generalized Traveling\n  Salesman Problem", "comments": "25 pages", "journal-ref": "European Journal of Operational Research 208(3), pages 221-232,\n  2011", "doi": "10.1016/j.ejor.2010.08.011", "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lin-Kernighan heuristic is known to be one of the most successful\nheuristics for the Traveling Salesman Problem (TSP). It has also proven its\nefficiency in application to some other problems. In this paper we discuss\npossible adaptations of TSP heuristics for the Generalized Traveling Salesman\nProblem (GTSP) and focus on the case of the Lin-Kernighan algorithm. At first,\nwe provide an easy-to-understand description of the original Lin-Kernighan\nheuristic. Then we propose several adaptations, both trivial and complicated.\nFinally, we conduct a fair competition between all the variations of the\nLin-Kernighan adaptation and some other GTSP heuristics. It appears that our\nadaptation of the Lin-Kernighan algorithm for the GTSP reproduces the success\nof the original heuristic. Different variations of our adaptation outperform\nall other heuristics in a wide range of trade-offs between solution quality and\nrunning time, making Lin-Kernighan the state-of-the-art GTSP local search.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2010 22:46:05 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2010 18:11:37 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Gutin", "Gregory", ""]]}, {"id": "1003.5390", "submitter": "Vibeke Libby Dr.", "authors": "Vibeke Libby", "title": "A Fast Algorithm for Determining the Existence and Value of Integer\n  Roots of N", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that all perfect odd integer squares not divisible by 3, can be\nusefully written as sqrt(N) = a + 18p, where the constant a is determined by\nthe basic properties of N. The equation can be solved deterministically by an\nefficient four step algorithm that is solely based on integer arithmetic. There\nis no required multiplication or division by multiple digit integers, nor does\nthe algorithm need a seed value. It finds the integer p when N is a perfect\nsquare, and certifies N as a non-square when the algorithm terminates without a\nsolution. The number of iterations scales approximately as log(sqrt(N)/2) for\nsquare roots. The paper also outlines how one of the methods discussed for\nsquares can be extended to finding an arbitrary root of N. Finally, we present\na rule that distinguishes products of twin primes from squares.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 18:38:39 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Libby", "Vibeke", ""]]}, {"id": "1003.5461", "submitter": "Antonio Vera", "authors": "Antonio Ignacio Vera (INRIA Lorraine - LORIA)", "title": "A Note on Integer Factorization Using Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit Schnorr's lattice-based integer factorization algorithm, now with\nan effective point of view. We present effective versions of Theorem 2 of\nSchnorr's \"Factoring integers and computing discrete logarithms via diophantine\napproximation\" paper, as well as new elementary properties of the Prime Number\nLattice bases of Schnorr and Adleman.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 08:45:56 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Vera", "Antonio Ignacio", "", "INRIA Lorraine - LORIA"]]}, {"id": "1003.5474", "submitter": "Ilia Zvedeniouk Mr", "authors": "Ilia Zvedeniouk and Sanjay Chawla", "title": "Angle Tree: Nearest Neighbor Search in High Dimensions with Low\n  Intrinsic Dimensionality", "comments": "To be submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of tree-based space-partitioning indexing structures\nfor data with low intrinsic dimensionality embedded in a high dimensional\nspace. We call this extension an Angle Tree. Our extension can be applied to\nboth classical kd-trees as well as the more recent rp-trees. The key idea of\nour approach is to store the angle (the \"dihedral angle\") between the data\nregion (which is a low dimensional manifold) and the random hyperplane that\nsplits the region (the \"splitter\"). We show that the dihedral angle can be used\nto obtain a tight lower bound on the distance between the query point and any\npoint on the opposite side of the splitter. This in turn can be used to\nefficiently prune the search space. We introduce a novel randomized strategy to\nefficiently calculate the dihedral angle with a high degree of accuracy.\nExperiments and analysis on real and synthetic data sets shows that the Angle\nTree is the most efficient known indexing structure for nearest neighbor\nqueries in terms of preprocessing and space usage while achieving high accuracy\nand fast search time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 09:24:31 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2010 04:23:38 GMT"}], "update_date": "2010-04-19", "authors_parsed": [["Zvedeniouk", "Ilia", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1003.5907", "submitter": "Aleksander M{\\ka}dry", "authors": "Aleksander Madry", "title": "Faster Approximation Schemes for Fractional Multicommodity Flow Problems\n  via Dynamic Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine the work of Garg and Konemann, and Fleischer with ideas from\ndynamic graph algorithms to obtain faster (1-eps)-approximation schemes for\nvarious versions of the multicommodity flow problem. In particular, if eps is\nmoderately small and the size of every number used in the input instance is\npolynomially bounded, the running times of our algorithms match - up to\npoly-logarithmic factors and some provably optimal terms - the Omega(mn)\nflow-decomposition barrier for single-commodity flow.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 19:53:12 GMT"}, {"version": "v2", "created": "Mon, 24 May 2010 01:54:03 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Madry", "Aleksander", ""]]}, {"id": "1003.5964", "submitter": "Eric Vigoda", "authors": "Daniel Stefankovic and Eric Vigoda", "title": "Fast Convergence of MCMC Algorithms for Phylogenetic Reconstruction with\n  Homogeneous Data on Closely Related Species", "comments": "To appear in SIAM Journal of Discrete Mathematics (SIDMA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a Markov chain for phylogenetic reconstruction which uses\na popular transition between tree topologies known as subtree\npruning-and-regrafting (SPR). We analyze the Markov chain in the simpler\nsetting that the generating tree consists of very short edge lengths, short\nenough so that each sample from the generating tree (or character in\nphylogenetic terminology) is likely to have only one mutation, and that there\nenough samples so that the data looks like the generating distribution. We\nprove in this setting that the Markov chain is rapidly mixing, i.e., it quickly\nconverges to its stationary distribution, which is the posterior distribution\nover tree topologies. Our proofs use that the leading term of the maximum\nlikelihood function of a tree T is the maximum parsimony score, which is the\nsize of the minimum cut in T needed to realize single edge cuts of the\ngenerating tree. Our main contribution is a combinatorial proof that in our\nsimplified setting, SPR moves are guaranteed to converge quickly to the maximum\nparsimony tree. Our results are in contrast to recent works showing examples\nwith heterogeneous data (namely, the data is generated from a mixture\ndistribution) where many natural Markov chains are exponentially slow to\nconverge to the stationary distribution.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2010 03:03:34 GMT"}, {"version": "v2", "created": "Thu, 5 May 2011 16:18:15 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Stefankovic", "Daniel", ""], ["Vigoda", "Eric", ""]]}, {"id": "1003.6124", "submitter": "Alfredo Braunstein", "authors": "Fabrizio Altarelli, Alfredo Braunstein, Abolfazl Ramezanpour, Riccardo\n  Zecchina", "title": "Statistical physics of optimization under uncertainty", "comments": "This article has been withdrawn because it was replaced by\n  arXiv:1105.3657 with a different name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization under uncertainty deals with the problem of optimizing\nstochastic cost functions given some partial information on their inputs. These\nproblems are extremely difficult to solve and yet pervade all areas of\ntechnological and natural sciences. We propose a general approach to solve such\nlarge-scale stochastic optimization problems and a Survey Propagation based\nalgorithm that implements it. In the problems we consider some of the\nparameters are not known at the time of the first optimization, but are\nextracted later independently of each other from known distributions. As an\nillustration, we apply our method to the stochastic bipartite matching problem,\nin the two-stage and multi-stage cases. The efficiency of our approach, which\ndoes not rely on sampling techniques, allows us to validate the analytical\npredictions with large-scale numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2010 19:40:09 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2011 13:21:22 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Altarelli", "Fabrizio", ""], ["Braunstein", "Alfredo", ""], ["Ramezanpour", "Abolfazl", ""], ["Zecchina", "Riccardo", ""]]}]