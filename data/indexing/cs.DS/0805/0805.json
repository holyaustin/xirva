[{"id": "0805.0389", "submitter": "Chaitanya Swamy", "authors": "Chaitanya Swamy", "title": "Algorithms for Probabilistically-Constrained Models of Risk-Averse\n  Stochastic Optimization with Black-Box Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider various stochastic models that incorporate the notion of\nrisk-averseness into the standard 2-stage recourse model, and develop novel\ntechniques for solving the algorithmic problems arising in these models. A key\nnotable feature of our work that distinguishes it from work in some other\nrelated models, such as the (standard) budget model and the (demand-) robust\nmodel, is that we obtain results in the black-box setting, that is, where one\nis given only sampling access to the underlying distribution. Our first model,\nwhich we call the risk-averse budget model, incorporates the notion of\nrisk-averseness via a probabilistic constraint that restricts the probability\n(according to the underlying distribution) with which the second-stage cost may\nexceed a given budget B to at most a given input threshold \\rho. We also a\nconsider a closely-related model that we call the risk-averse robust model,\nwhere we seek to minimize the first-stage cost and the (1-\\rho)-quantile of the\nsecond-stage cost.\n  We obtain approximation algorithms for a variety of combinatorial\noptimization problems including the set cover, vertex cover, multicut on trees,\nmin cut, and facility location problems, in the risk-averse budget and robust\nmodels with black-box distributions. We obtain near-optimal solutions that\npreserve the budget approximately and incur a small blow-up of the probability\nthreshold (both of which are unavoidable). To the best of our knowledge, these\nare the first approximation results for problems involving probabilistic\nconstraints and black-box distributions. A major component of our results is a\nfully polynomial approximation scheme for solving the LP-relaxation of the\nrisk-averse problem.\n", "versions": [{"version": "v1", "created": "Sun, 4 May 2008 03:57:52 GMT"}], "update_date": "2008-05-06", "authors_parsed": [["Swamy", "Chaitanya", ""]]}, {"id": "0805.0747", "submitter": "Daniel Lemire", "authors": "Hazel Webb, Owen Kaser, Daniel Lemire", "title": "Pruning Attribute Values From Data Cubes with Diamond Dicing", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-08-011 (UNB Saint John)", "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stored in a data warehouse are inherently multidimensional, but most\ndata-pruning techniques (such as iceberg and top-k queries) are unidimensional.\nHowever, analysts need to issue multidimensional queries. For example, an\nanalyst may need to select not just the most profitable stores\nor--separately--the most profitable products, but simultaneous sets of stores\nand products fulfilling some profitability constraints. To fill this need, we\npropose a new operator, the diamond dice. Because of the interaction between\ndimensions, the computation of diamonds is challenging. We present the first\ndiamond-dicing experiments on large data sets. Experiments show that we can\ncompute diamond cubes over fact tables containing 100 million facts in less\nthan 35 minutes using a standard PC.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2008 15:45:15 GMT"}], "update_date": "2008-05-07", "authors_parsed": [["Webb", "Hazel", ""], ["Kaser", "Owen", ""], ["Lemire", "Daniel", ""]]}, {"id": "0805.0851", "submitter": "Sebastien Tixeuil", "authors": "Samuel Bernard (LIP6), St\\'ephane Devismes (LRI), Maria Gradinariu\n  Potop-Butucaru (LIP6, INRIA Rocquencourt), S\\'ebastien Tixeuil (LIP6)", "title": "Bounds for self-stabilization in unidirectional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6524", "categories": "cs.DS cs.CC cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm is self-stabilizing if after faults and attacks hit\nthe system and place it in some arbitrary global state, the systems recovers\nfrom this catastrophic situation without external intervention in finite time.\nUnidirectional networks preclude many common techniques in self-stabilization\nfrom being used, such as preserving local predicates. In this paper, we\ninvestigate the intrinsic complexity of achieving self-stabilization in\nunidirectional networks, and focus on the classical vertex coloring problem.\nWhen deterministic solutions are considered, we prove a lower bound of $n$\nstates per process (where $n$ is the network size) and a recovery time of at\nleast $n(n-1)/2$ actions in total. We present a deterministic algorithm with\nmatching upper bounds that performs in arbitrary graphs. When probabilistic\nsolutions are considered, we observe that at least $\\Delta + 1$ states per\nprocess and a recovery time of $\\Omega(n)$ actions in total are required (where\n$\\Delta$ denotes the maximal degree of the underlying simple undirected graph).\nWe present a probabilistically self-stabilizing algorithm that uses\n$\\mathtt{k}$ states per process, where $\\mathtt{k}$ is a parameter of the\nalgorithm. When $\\mathtt{k}=\\Delta+1$, the algorithm recovers in expected\n$O(\\Delta n)$ actions. When $\\mathtt{k}$ may grow arbitrarily, the algorithm\nrecovers in expected O(n) actions in total. Thus, our algorithm can be made\noptimal with respect to space or time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2008 07:39:14 GMT"}, {"version": "v2", "created": "Tue, 13 May 2008 08:06:10 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bernard", "Samuel", "", "LIP6"], ["Devismes", "St\u00e9phane", "", "LRI"], ["Potop-Butucaru", "Maria Gradinariu", "", "LIP6, INRIA Rocquencourt"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0805.1071", "submitter": "Zoya Svitkina", "authors": "Zoya Svitkina and Lisa Fleischer", "title": "Submodular approximation: sampling-based algorithms and lower bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce several generalizations of classical computer science problems\nobtained by replacing simpler objective functions with general submodular\nfunctions. The new problems include submodular load balancing, which\ngeneralizes load balancing or minimum-makespan scheduling, submodular sparsest\ncut and submodular balanced cut, which generalize their respective graph cut\nproblems, as well as submodular function minimization with a cardinality lower\nbound. We establish upper and lower bounds for the approximability of these\nproblems with a polynomial number of queries to a function-value oracle. The\napproximation guarantees for most of our algorithms are of the order of\nsqrt(n/ln n). We show that this is the inherent difficulty of the problems by\nproving matching lower bounds. We also give an improved lower bound for the\nproblem of approximately learning a monotone submodular function. In addition,\nwe present an algorithm for approximately learning submodular functions with\nspecial structure, whose guarantee is close to the lower bound. Although quite\nrestrictive, the class of functions with this structure includes the ones that\nare used for lower bounds both by us and in previous work. This demonstrates\nthat if there are significantly stronger lower bounds for this problem, they\nrely on more general submodular functions.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2008 21:37:18 GMT"}, {"version": "v2", "created": "Wed, 24 Sep 2008 23:31:37 GMT"}, {"version": "v3", "created": "Mon, 31 May 2010 23:57:44 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Svitkina", "Zoya", ""], ["Fleischer", "Lisa", ""]]}, {"id": "0805.1213", "submitter": "Florin Constantin", "authors": "Florin Constantin, Jon Feldman, S. Muthukrishnan and Martin Pal", "title": "Online Ad Slotting With Cancellations", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many advertisers buy advertisements (ads) on the Internet or on traditional\nmedia and seek simple, online mechanisms to reserve ad slots in advance. Media\npublishers represent a vast and varying inventory, and they too seek automatic,\nonline mechanisms for pricing and allocating such reservations. In this paper,\nwe present and study a simple model for auctioning such ad slots in advance.\nBidders arrive sequentially and report which slots they are interested in. The\nseller must decide immediately whether or not to grant a reservation. Our model\nallows a seller to accept reservations, but possibly cancel the allocations\nlater and pay the bidder a cancellation compensation (bump payment). Our main\nresult is an online mechanism to derive prices and bump payments that is\nefficient to implement. This mechanism has many desirable properties. It is\nindividually rational; winners have an incentive to be honest and bidding one's\ntrue value dominates any lower bid. Our mechanism's efficiency is within a\nconstant fraction of the a posteriori optimally efficient solution. Its revenue\nis within a constant fraction of the a posteriori revenue of the\nVickrey-Clarke-Groves mechanism. Our results make no assumptions about the\norder of arrival of bids or the value distribution of bidders and still hold if\nthe items for sale are elements of a matroid, a more general setting than slot\nallocation.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2008 18:12:50 GMT"}], "update_date": "2008-05-09", "authors_parsed": [["Constantin", "Florin", ""], ["Feldman", "Jon", ""], ["Muthukrishnan", "S.", ""], ["Pal", "Martin", ""]]}, {"id": "0805.1257", "submitter": "Chadi Kari", "authors": "Chadi Kari, Alexander Russell and Narasimha Shashidhar", "title": "Randomized Work-Competitive Scheduling for Cooperative Computing on\n  $k$-partite Task Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in distributed computing is the task of cooperatively\nexecuting a given set of $t$ tasks by $p$ processors where the communication\nmedium is dynamic and subject to failures. The dynamics of the communication\nmedium lead to groups of processors being disconnected and possibly reconnected\nduring the entire course of the computation furthermore tasks can have\ndependencies among them. In this paper, we present a randomized algorithm whose\ncompetitive ratio is dependent on the dynamics of the communication medium and\nalso on the nature of the dependencies among the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2008 00:27:28 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2012 23:52:01 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Kari", "Chadi", ""], ["Russell", "Alexander", ""], ["Shashidhar", "Narasimha", ""]]}, {"id": "0805.1348", "submitter": "Yakov Nekrich", "authors": "Marek Karpinski, Yakov Nekrich", "title": "Searching for Frequent Colors in Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new variant of colored orthogonal range searching problem: given a\nquery rectangle $Q$ all colors $c$, such that at least a fraction $\\tau$ of all\npoints in $Q$ are of color $c$, must be reported. We describe several data\nstructures for that problem that use pseudo-linear space and answer queries in\npoly-logarithmic time.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2008 13:47:55 GMT"}], "update_date": "2008-05-12", "authors_parsed": [["Karpinski", "Marek", ""], ["Nekrich", "Yakov", ""]]}, {"id": "0805.1401", "submitter": "Mustaq Ahmed", "authors": "Mustaq Ahmed, Sandip Das, Sachin Lodha, Anna Lubiw, Anil Maheshwari,\n  Sasanka Roy", "title": "Approximation Algorithms for Shortest Descending Paths in Terrains", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A path from s to t on a polyhedral terrain is descending if the height of a\npoint p never increases while we move p along the path from s to t. No\nefficient algorithm is known to find a shortest descending path (SDP) from s to\nt in a polyhedral terrain. We give two approximation algorithms (more\nprecisely, FPTASs) that solve the SDP problem on general terrains. Both\nalgorithms are simple, robust and easy to implement.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2008 19:39:19 GMT"}], "update_date": "2008-05-12", "authors_parsed": [["Ahmed", "Mustaq", ""], ["Das", "Sandip", ""], ["Lodha", "Sachin", ""], ["Lubiw", "Anna", ""], ["Maheshwari", "Anil", ""], ["Roy", "Sasanka", ""]]}, {"id": "0805.1487", "submitter": "Spyros Sioutas SS", "authors": "Lagogiannis George, Lorentzos Nikos, Sioutas Spyros, Theodoridis\n  Evaggelos", "title": "A Time Efficient Indexing Scheme for Complex Spatiotemporal Retrieval", "comments": "6 pages, 7 figures, submitted to Sigmod Record", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is concerned with the time efficient processing of spatiotemporal\npredicates, i.e. spatial predicates associated with an exact temporal\nconstraint. A set of such predicates forms a buffer query or a Spatio-temporal\nPattern (STP) Query with time. In the more general case of an STP query, the\ntemporal dimension is introduced via the relative order of the spatial\npredicates (STP queries with order). Therefore, the efficient processing of a\nspatiotemporal predicate is crucial for the efficient implementation of more\ncomplex queries of practical interest. We propose an extension of a known\napproach, suitable for processing spatial predicates, which has been used for\nthe efficient manipulation of STP queries with order. The extended method is\nsupported by efficient indexing structures. We also provide experimental\nresults that show the efficiency of the technique.\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2008 17:18:32 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["George", "Lagogiannis", ""], ["Nikos", "Lorentzos", ""], ["Spyros", "Sioutas", ""], ["Evaggelos", "Theodoridis", ""]]}, {"id": "0805.1598", "submitter": "Peiyush Jain", "authors": "Peiyush Jain", "title": "A Simple In-Place Algorithm for In-Shuffle", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a simple, linear time, in-place algorithm for performing a\n2-way in-shuffle which can be used with little modification for certain other\nk-way shuffles.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2008 09:28:18 GMT"}], "update_date": "2008-05-13", "authors_parsed": [["Jain", "Peiyush", ""]]}, {"id": "0805.1661", "submitter": "Glenn Hickey", "authors": "G. Hickey, P. Carmi, A. Maheshwari, N. Zeh", "title": "NAPX: A Polynomial Time Approximation Scheme for the Noah's Ark Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Noah's Ark Problem (NAP) is an NP-Hard optimization problem with\nrelevance to ecological conservation management. It asks to maximize the\nphylogenetic diversity (PD) of a set of taxa given a fixed budget, where each\ntaxon is associated with a cost of conservation and a probability of\nextinction. NAP has received renewed interest with the rise in availability of\ngenetic sequence data, allowing PD to be used as a practical measure of\nbiodiversity. However, only simplified instances of the problem, where one or\nmore parameters are fixed as constants, have as of yet been addressed in the\nliterature. We present NAPX, the first algorithm for the general version of NAP\nthat returns a $1 - \\epsilon$ approximation of the optimal solution. It runs in\n$O(\\frac{n B^2 h^2 \\log^2n}{\\log^2(1 - \\epsilon)})$ time where $n$ is the\nnumber of species, and $B$ is the total budget and $h$ is the height of the\ninput tree. We also provide improved bounds for its expected running time.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2008 15:04:26 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2008 18:57:31 GMT"}], "update_date": "2008-10-27", "authors_parsed": [["Hickey", "G.", ""], ["Carmi", "P.", ""], ["Maheshwari", "A.", ""], ["Zeh", "N.", ""]]}, {"id": "0805.2630", "submitter": "Kamesh Munagala", "authors": "Sudipto Guha and Kamesh Munagala", "title": "Sequential Design of Experiments via Linear Programming", "comments": "The results and presentation in this paper are subsumed by the\n  article \"Approximation algorithms for Bayesian multi-armed bandit problems\"\n  http://arxiv.org/abs/1306.3525", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated multi-armed bandit problem in decision theory models the basic\ntrade-off between exploration, or learning about the state of a system, and\nexploitation, or utilizing the system. In this paper we study the variant of\nthe multi-armed bandit problem where the exploration phase involves costly\nexperiments and occurs before the exploitation phase; and where each play of an\narm during the exploration phase updates a prior belief about the arm. The\nproblem of finding an inexpensive exploration strategy to optimize a certain\nexploitation objective is NP-Hard even when a single play reveals all\ninformation about an arm, and all exploration steps cost the same.\n  We provide the first polynomial time constant-factor approximation algorithm\nfor this class of problems. We show that this framework also generalizes\nseveral problems of interest studied in the context of data acquisition in\nsensor networks. Our analyses also extends to switching and setup costs, and to\nconcave utility objectives.\n  Our solution approach is via a novel linear program rounding technique based\non stochastic packing. In addition to yielding exploration policies whose\nperformance is within a small constant factor of the adaptive optimal policy, a\nnice feature of this approach is that the resulting policies explore the arms\nsequentially without revisiting any arm. Sequentiality is a well-studied\nconcept in decision theory, and is very desirable in domains where multiple\nexplorations can be conducted in parallel, for instance, in the sensor network\ncontext.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2008 22:48:22 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2013 15:13:17 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Guha", "Sudipto", ""], ["Munagala", "Kamesh", ""]]}, {"id": "0805.2646", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Mihalis Yannakakis", "title": "Small Approximate Pareto Sets for Bi-objective Shortest Paths and Other\n  Problems", "comments": "submitted full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of computing a minimum set of solutions that\napproximates within a specified accuracy $\\epsilon$ the Pareto curve of a\nmultiobjective optimization problem. We show that for a broad class of\nbi-objective problems (containing many important widely studied problems such\nas shortest paths, spanning tree, and many others), we can compute in\npolynomial time an $\\epsilon$-Pareto set that contains at most twice as many\nsolutions as the minimum such set. Furthermore we show that the factor of 2 is\ntight for these problems, i.e., it is NP-hard to do better. We present upper\nand lower bounds for three or more objectives, as well as for the dual problem\nof computing a specified number $k$ of solutions which provide a good\napproximation to the Pareto curve.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2008 06:10:19 GMT"}], "update_date": "2008-05-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "0805.2671", "submitter": "Spyros Sioutas SS", "authors": "Spyros Sioutas", "title": "Finger Indexed Sets: New Approaches", "comments": "13 pages, 1 figure, Submitted to Journal of Universal Computer\n  Science (J.UCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the particular case we have insertions/deletions at the tail of a given\nset S of $n$ one-dimensional elements, we present a simpler and more concrete\nalgorithm than that presented in [Anderson, 2007] achieving the same (but also\namortized) upper bound of $O(\\sqrt{logd/loglogd})$ for finger searching\nqueries, where $d$ is the number of sorted keys between the finger element and\nthe target element we are looking for. Furthermore, in general case we have\ninsertions/deletions anywhere we present a new randomized algorithm achieving\nthe same expected time bounds. Even the new solutions achieve the optimal\nbounds in amortized or expected case, the advantage of simplicity is of great\nimportance due to practical merits we gain.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2008 14:05:12 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Sioutas", "Spyros", ""]]}, {"id": "0805.2681", "submitter": "Spyros Sioutas SS", "authors": "Spyros Sioutas, Dimitrios Sofotassios, Kostas Tsichlas, Dimitrios\n  Sotiropoulos, Panayiotis Vlamos", "title": "Canonical polygon Queries on the plane: a New Approach", "comments": "7 pages, 9 figures, Accepted for publication in Journal of Computers\n  (JCP), http://www.informatik.uni-trier.de/~ley/db/journals/jcp/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polygon retrieval problem on points is the problem of preprocessing a set\nof $n$ points on the plane, so that given a polygon query, the subset of points\nlying inside it can be reported efficiently.\n  It is of great interest in areas such as Computer Graphics, CAD applications,\nSpatial Databases and GIS developing tasks. In this paper we study the problem\nof canonical $k$-vertex polygon queries on the plane. A canonical $k$-vertex\npolygon query always meets the following specific property: a point retrieval\nquery can be transformed into a linear number (with respect to the number of\nvertices) of point retrievals for orthogonal objects such as rectangles and\ntriangles (throughout this work we call a triangle orthogonal iff two of its\nedges are axis-parallel).\n  We present two new algorithms for this problem. The first one requires\n$O(n\\log^2{n})$ space and $O(k\\frac{log^3n}{loglogn}+A)$ query time. A simple\nmodification scheme on first algorithm lead us to a second solution, which\nconsumes $O(n^2)$ space and $O(k \\frac{logn}{loglogn}+A)$ query time, where $A$\ndenotes the size of the answer and $k$ is the number of vertices.\n  The best previous solution for the general polygon retrieval problem uses\n$O(n^2)$ space and answers a query in $O(k\\log{n}+A)$ time, where $k$ is the\nnumber of vertices. It is also very complicated and difficult to be implemented\nin a standard imperative programming language such as C or C++.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2008 16:00:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2009 10:23:50 GMT"}], "update_date": "2009-07-30", "authors_parsed": [["Sioutas", "Spyros", ""], ["Sofotassios", "Dimitrios", ""], ["Tsichlas", "Kostas", ""], ["Sotiropoulos", "Dimitrios", ""], ["Vlamos", "Panayiotis", ""]]}, {"id": "0805.3742", "submitter": "Henrik B\\\"a\\\"arnhielm", "authors": "Henrik B\\\"a\\\"arnhielm", "title": "Algorithmic problems in twisted groups of Lie type", "comments": "The author's PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis contains a collection of algorithms for working with the twisted\ngroups of Lie type known as Suzuki groups, and small and large Ree groups. The\ntwo main problems under consideration are constructive recognition and\nconstructive membership testing. We also consider problems of generating and\nconjugating Sylow and maximal subgroups. The algorithms are motivated by, and\nform a part of, the Matrix Group Recognition Project. Obtaining both\ntheoretically and practically efficient algorithms has been a central goal. The\nalgorithms have been developed with, and implemented in, the computer algebra\nsystem MAGMA.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2008 04:21:29 GMT"}, {"version": "v2", "created": "Sun, 8 Jun 2008 10:34:21 GMT"}], "update_date": "2008-06-08", "authors_parsed": [["B\u00e4\u00e4rnhielm", "Henrik", ""]]}, {"id": "0805.3901", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Eun Jung Kim", "title": "Properly Coloured Cycles and Paths: Results and Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a number of results and seven conjectures on\nproperly edge-coloured (PC) paths and cycles in edge-coloured multigraphs. We\noverview some known results and prove new ones. In particular, we consider a\nfamily of transformations of an edge-coloured multigraph $G$ into an ordinary\ngraph that allow us to check the existence PC cycles and PC $(s,t)$-paths in\n$G$ and, if they exist, to find shortest ones among them. We raise a problem of\nfinding the optimal transformation and consider a possible solution to the\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2008 09:17:21 GMT"}, {"version": "v2", "created": "Fri, 30 May 2008 14:33:10 GMT"}, {"version": "v3", "created": "Sat, 31 May 2008 07:48:28 GMT"}], "update_date": "2008-05-31", "authors_parsed": [["Gutin", "Gregory", ""], ["Kim", "Eun Jung", ""]]}, {"id": "0805.4147", "submitter": "Meng He", "authors": "Prosenjit Bose, Eric Y. Chen, Meng He, Anil Maheshwari, Pat Morin", "title": "Succinct Geometric Indexes Supporting Point Location Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to design data structures called succinct geometric indexes of\nnegligible space (more precisely, o(n) bits) that, by taking advantage of the n\npoints in the data set permuted and stored elsewhere as a sequence, to support\ngeometric queries in optimal time. Our first and main result is a succinct\ngeometric index that can answer point location queries, a fundamental problem\nin computational geometry, on planar triangulations in O(lg n) time. We also\ndesign three variants of this index. The first supports point location using\n$\\lg n + 2\\sqrt{\\lg n} + O(\\lg^{1/4} n)$ point-line comparisons. The second\nsupports point location in o(lg n) time when the coordinates are integers\nbounded by U. The last variant can answer point location in O(H+1) expected\ntime, where H is the entropy of the query distribution. These results match the\nquery efficiency of previous point location structures that use O(n) words or\nO(n lg n) bits, while saving drastic amounts of space.\n  We then generalize our succinct geometric index to planar subdivisions, and\ndesign indexes for other types of queries. Finally, we apply our techniques to\ndesign the first implicit data structures that support point location in\n$O(\\lg^2 n)$ time.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2008 15:15:05 GMT"}], "update_date": "2008-05-28", "authors_parsed": [["Bose", "Prosenjit", ""], ["Chen", "Eric Y.", ""], ["He", "Meng", ""], ["Maheshwari", "Anil", ""], ["Morin", "Pat", ""]]}, {"id": "0805.4300", "submitter": "Shai  Gutner", "authors": "Noga Alon and Shai Gutner", "title": "Balanced Families of Perfect Hash Functions and Their Applications", "comments": null, "journal-ref": "Proc. of 34th ICALP (2007), 435-446", "doi": null, "report-no": null, "categories": "cs.DS cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of perfect hash functions is a well-studied topic. In this\npaper, this concept is generalized with the following definition. We say that a\nfamily of functions from $[n]$ to $[k]$ is a $\\delta$-balanced $(n,k)$-family\nof perfect hash functions if for every $S \\subseteq [n]$, $|S|=k$, the number\nof functions that are 1-1 on $S$ is between $T/\\delta$ and $\\delta T$ for some\nconstant $T>0$. The standard definition of a family of perfect hash functions\nrequires that there will be at least one function that is 1-1 on $S$, for each\n$S$ of size $k$. In the new notion of balanced families, we require the number\nof 1-1 functions to be almost the same (taking $\\delta$ to be close to 1) for\nevery such $S$. Our main result is that for any constant $\\delta > 1$, a\n$\\delta$-balanced $(n,k)$-family of perfect hash functions of size $2^{O(k \\log\n\\log k)} \\log n$ can be constructed in time $2^{O(k \\log \\log k)} n \\log n$.\nUsing the technique of color-coding we can apply our explicit constructions to\ndevise approximation algorithms for various counting problems in graphs. In\nparticular, we exhibit a deterministic polynomial time algorithm for\napproximating both the number of simple paths of length $k$ and the number of\nsimple cycles of size $k$ for any $k \\leq O(\\frac{\\log n}{\\log \\log \\log n})$\nin a graph with $n$ vertices. The approximation is up to any fixed desirable\nrelative error.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2008 09:49:18 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Alon", "Noga", ""], ["Gutner", "Shai", ""]]}]